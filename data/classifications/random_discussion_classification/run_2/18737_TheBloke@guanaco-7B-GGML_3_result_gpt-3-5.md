## https://huggingface.co/TheBloke/guanaco-7B-GGML/discussions/3

contains_question: yes

question_part: I was running some testing on all the guanaco-7B.ggml models and I'm getting bad/gibberish results from the q3_K_S version (only). Other q3_K_S models I test with seem to be working fine, so I don't think it's a llamacpp issue.