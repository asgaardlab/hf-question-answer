## https://huggingface.co/TheBloke/WizardLM-30B-Uncensored-GGML/discussions/1

contains_question: yes

question_part: But which version do I use for a M2 Macbook Pro? From what I found I think I have to use the GGML variant from this repo, but what about q4_0, q5_0 etc? And are there any params I have to mess with on Llama.cpp once I add it to /model folder