## https://huggingface.co/WhereIsAI/UAE-Large-V1/discussions/14

contains_question: yes
question_part: 
Was wondering if the model has a token limit of 512 by default when I load it via
or do I have to explicity set the token limit?
Another thing that confuses me is the Prompts. I'm using the model for Retrieval and Summarizing. Do I have to apply the prompts?
Last question: How do I use the onnx format. Will the angle-emb package support it directly? Right now it loads the safetensors version from HF. Or do I have to pip install onnx, in which case how do I configure it for Prompts.C