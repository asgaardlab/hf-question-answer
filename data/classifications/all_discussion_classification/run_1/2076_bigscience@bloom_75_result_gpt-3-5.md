## https://huggingface.co/bigscience/bloom/discussions/75

contains_question: yes
question_part: I have a question regarding the architecture. In the HF documentation, it is mentioned that Bloom is similar to GPT-3 but the model card indicates that the architecture is derived from Megatron-GPT2. GPT-3 has a similar parameter count as Bloom and also has fixed bugs compared to GPT-2. What is the best way to describe Bloom's architecture? GPT-2 or GPT-3 like?