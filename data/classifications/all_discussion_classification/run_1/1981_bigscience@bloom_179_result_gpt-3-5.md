## https://huggingface.co/bigscience/bloom/discussions/179

contains_question: yes
question_part: I have been receiving the error "Model is overloaded, please wait for a bit" every time I've tried using the bloom Inference API in the last 16 hours. I'm a new user (Pro plan, if that makes any difference) trying to get started, and I haven't yet made a successful API call. Is there anything that commonly triggers this error, or is this a true overload?