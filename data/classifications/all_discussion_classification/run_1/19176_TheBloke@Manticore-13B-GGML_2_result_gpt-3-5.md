## https://huggingface.co/TheBloke/Manticore-13B-GGML/discussions/2

contains_question: yes

question_part: Also, is there a way to run in llama.cpp interactive mode (for example with Wizard-Mega model it was pretty neat as it remembered the prior conversation) 