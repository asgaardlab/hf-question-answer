## https://huggingface.co/bigscience/bloom/discussions/268

contains_question: yes
question_part: Hi, I noticed that there already exists bloom-int8 and bloom-fp16 models. Anyone know where can find bloom-int4 model, or how can I quantize a 4bit model locally?