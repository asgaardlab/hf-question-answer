## https://huggingface.co/EleutherAI/gpt-neox-20b/discussions/16

contains_question: yes

question_part: Can you please explain whether I can fine-tune the slim version (40GB) of this model on 2xA6000 GPUs using the transformers library