## https://huggingface.co/WizardLM/WizardCoder-15B-V1.0/discussions/3

contains_question: yes

question_part: I was wondering what the reccomended amount of VRAM neccesary would be to run this model using KoboldAI or oobabooga web-ui. I apologize if this is a question generated by ignorance of the inner working of LLMs and AI in general but appreciate any help or info you could share to enlighten me.