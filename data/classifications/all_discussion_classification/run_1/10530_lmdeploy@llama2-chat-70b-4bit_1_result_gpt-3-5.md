## https://huggingface.co/lmdeploy/llama2-chat-70b-4bit/discussions/1

contains_question: yes

question_part: I would like to know when the 4bit quantized 70B weights will be released. What is the approximate memory requirement to quantize the 70B model