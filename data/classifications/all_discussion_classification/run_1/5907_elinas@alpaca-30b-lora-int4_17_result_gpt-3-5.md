## https://huggingface.co/elinas/alpaca-30b-lora-int4/discussions/17

contains_question: yes

question_part: 
How to get this running on Oobabooga with RTX 4080 16GB?
I want to run "alpaca-30b-4bit-128g.safetensors" which I think is the best model Alpaca-30b-lora-int4 right? 
When I load the  "alpaca-30b-4bit-128g.safetensors" I can make it start to fill VRAM or System RAM but it always crashes with various errors neat end. 
I don't know what to set Model Type too? Or Wbits or Groupsize? I assume groupsize 128. I have tried checking auto devices or CPU etc. Generally I can't get this to work at all. Various errors mostly trace back errors. 
This is not the only kind of error I get.