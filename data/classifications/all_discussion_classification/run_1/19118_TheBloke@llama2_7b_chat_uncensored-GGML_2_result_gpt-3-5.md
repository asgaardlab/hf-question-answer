## https://huggingface.co/TheBloke/llama2_7b_chat_uncensored-GGML/discussions/2

contains_question: yes

question_part: 
How to deploy?
Are there usually other files for the tokenizer etc. with the model that are missing here?
Or if you could maybe point me to a good source of information how to deploy llama2 models locally using python, I would very much appreciate it.
I know this might be the wrong place to ask, but I really would love to deploy this particular model locally within python.