## https://huggingface.co/audreyt/Breeze-7B-Instruct-64k-v0.1-GGUF/discussions/1

contains_question: yes

question_part: We were having trouble using llama.cpp (`convert.py`) to convert from MTKâ€™s provided weights ourselves, but we never had any success. Is it possible for you to share how to convert this kind of model into GGUF, like what patch might have been required for the tool to work. I have attempted token padding option with no avail, though the recent commits seems to claim that the conversion tool is fixed.