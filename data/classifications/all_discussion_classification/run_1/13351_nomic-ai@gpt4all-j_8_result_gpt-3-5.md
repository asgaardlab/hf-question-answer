## https://huggingface.co/nomic-ai/gpt4all-j/discussions/8

contains_question: yes

question_part: I tried to play with fine tuning and I got a standard size 24Gb. I was able only to convert it to f16. But the size is still bit - 12Gb. How can I reduce even more?