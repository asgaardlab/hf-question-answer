## https://huggingface.co/MetaIX/Alpaca-30B-Int4/discussions/1

contains_question: yes

question_part: Is this model a 4-bit version of one of the lora trained versions like this one: https://huggingface.co/baseten/alpaca-30b
Or is this trained with standard fine-tuning/training scripts?