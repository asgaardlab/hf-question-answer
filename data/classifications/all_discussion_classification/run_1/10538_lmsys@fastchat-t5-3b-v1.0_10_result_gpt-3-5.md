## https://huggingface.co/lmsys/fastchat-t5-3b-v1.0/discussions/10

contains_question: yes

question_part: In LLM pipeline  I have tried parameters like ```early_stopping=False```  setting ```min_new tokens``` and increasing ```max_new_tokens```  but nothing seems to work. Kindly explain how these parameters affect length of output.