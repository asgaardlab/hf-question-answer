## https://huggingface.co/openlm-research/open_llama_7b/discussions/3

contains_question: yes

question_part: Why does the model output the embedding for the <s> token?
Was this done by design or is it an API bug?