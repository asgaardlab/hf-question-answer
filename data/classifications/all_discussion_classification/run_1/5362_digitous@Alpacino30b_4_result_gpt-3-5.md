## https://huggingface.co/digitous/Alpacino30b/discussions/4

contains_question: yes

question_part: The Alpaca dataset contains instructions that result in models behaving "As an AI" and sometimes refusing certain instruction.  I'm wondering if, or how much, this negatively affects Alpachino's generation capabilities.  Have you noticed anything in this regard? I've also heard that 30b models can sometimes produce lower quality work than smaller models like 13b when it comes to narrative over time, also just curious if you've experienced anything like that.