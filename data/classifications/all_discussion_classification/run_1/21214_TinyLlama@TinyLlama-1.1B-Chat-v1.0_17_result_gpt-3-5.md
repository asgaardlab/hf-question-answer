## https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/discussions/17

contains_question: yes

question_part: Quick question, for your DPO, do you still have to follow that template from your example? Or do you just use the raw training data from  openbmb/UltraFeedback directly (i..e, no need to wrap them onto template)?