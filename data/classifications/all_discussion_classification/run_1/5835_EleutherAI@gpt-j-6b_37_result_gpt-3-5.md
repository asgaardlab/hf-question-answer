## https://huggingface.co/EleutherAI/gpt-j-6b/discussions/37

contains_question: yes
question_part: My model is in a .bin format and ~6 Gb; is there a way to reload the model without reperforming 8 bit quantization again?