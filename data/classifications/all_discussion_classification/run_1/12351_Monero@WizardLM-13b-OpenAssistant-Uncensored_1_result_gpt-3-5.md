## https://huggingface.co/Monero/WizardLM-13b-OpenAssistant-Uncensored/discussions/1

contains_question: yes  
question_part: You're on the right approach with model. Can you make a 30b 4-bit quantized version?