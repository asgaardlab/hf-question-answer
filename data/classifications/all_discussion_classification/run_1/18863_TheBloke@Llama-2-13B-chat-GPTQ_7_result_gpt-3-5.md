## https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/7

contains_question: yes

question_part: Does the quantization lower the context length or is it something that can be adjusted?