## https://huggingface.co/TheBloke/CodeLlama-7B-GGUF/discussions/3

contains_question: yes
question_part: I'm running codellama-7b.Q4_K_M.gguf on CPU with text-generation-webui without GPU. Is (0.9 tokens/s) normal for this configuration?