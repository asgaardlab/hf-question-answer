## https://huggingface.co/TheBloke/PMC_LLAMA-7B-GGML/discussions/1

contains_question: yes

question_part: I noticed on Chaoyi-wu's repo there was a 10 epoch trained model. Have you made a GGML version of this? Or are the current quantized models based on the 10 epoch version (in the model cards it says 5 epochs)?