## https://huggingface.co/mosaicml/mpt-7b/discussions/13

contains_question: yes

question_part: Can this be fine-tuned with triton backed flash attention and alibi using the huggingface transformers trainer?