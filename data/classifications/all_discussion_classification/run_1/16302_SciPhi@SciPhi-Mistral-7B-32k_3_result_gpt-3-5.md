## https://huggingface.co/SciPhi/SciPhi-Mistral-7B-32k/discussions/3

contains_question: yes

question_part: The model starts giving gibberish output when the input exceeds 8-10k tokens. It says 32k, is that the context length it supports