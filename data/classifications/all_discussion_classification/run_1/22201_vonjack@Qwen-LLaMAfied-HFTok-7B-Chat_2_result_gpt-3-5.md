## https://huggingface.co/vonjack/Qwen-LLaMAfied-HFTok-7B-Chat/discussions/2

contains_question: yes  
question_part: How to merge the bias item of c_attn = nn.Linear(config.hidden_size, 3 * self.projection_size) into LLama