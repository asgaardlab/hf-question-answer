## https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ/discussions/4

contains_question: yes

question_part: Hello, I have been trying to get an answer from this model.
If I load with AutoGPTQ - I receive no error when loading, or asking. But the result is always:
Output generated in 0.42 seconds (0.00 tokens/s, 0 tokens, context 61, seed 1544358233)
Output generated in 0.42 seconds (0.00 tokens/s, 0 tokens, context 32, seed 168168177)