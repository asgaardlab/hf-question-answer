## https://huggingface.co/Mikael110/llama-2-7b-guanaco-fp16/discussions/3

contains_question: yes

question_part:  
1. Did you use the [jupyter notebook ](https://github.com/artidoro/qlora/tree/main/examples) or the [script](https://github.com/artidoro/qlora/blob/main/scripts/finetune_guanaco_7b.sh)
2. How did you merge the adapter. Can you please share the script. 
3. What is GPU memory and system memory to required to fine tune the model and how much time it took