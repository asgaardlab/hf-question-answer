## https://huggingface.co/TheBloke/Llama-2-13B-GGML/discussions/3

contains_question: yes

question_part: Is it possible to make GGML models with 4096 context?