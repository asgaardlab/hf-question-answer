## https://huggingface.co/JorisCos/ConvTasNet_Libri2Mix_sepnoisy_16k/discussions/1

contains_question: yes

question_part: Running it locally on my CPU or even on the GPU the inference takes quite longer (+1.8s even with ONNX runtime). 

Do you have any idea how hugging face achieves this result on CPU? Any possibility to tune it locally?