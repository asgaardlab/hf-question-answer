## https://huggingface.co/lighteternal/gpt2-finetuned-greek/discussions/2

contains_question: yes
question_part: When I use the model's tokenizer in order to tokenize a Greek sentence I get [‘Î’, ‘ł’, ‘Î¿’, ‘Î¹Î¿’, ‘ĠÏĦÏģÎ¯Î³ÏīÎ½Î¿’, ‘ĠÎ»ÎŃÎ³ÎµÏĦÎ±Î¹’, ‘ĠÎ±Î¼Î²’, ‘Î»Ïħ’, ‘Î³ÏİÎ½’, ‘Î¹Î¿’, ‘?’] Is this normal? Should't I see tokens or sub-word tokens in Greek? Also when I open the vocabulary I don't see any Greek words.