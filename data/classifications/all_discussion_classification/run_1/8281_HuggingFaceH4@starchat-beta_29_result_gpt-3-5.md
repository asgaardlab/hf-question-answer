## https://huggingface.co/HuggingFaceH4/starchat-beta/discussions/29

contains_question: yes

question_part: 
1. Does SFT take so much memory over (loading model as a checkpoint and inferencing) ?

2. And any way I can do this in less memory and more time ? (as I plan to do SFT with a 15B model which takes ~60GB just for loading model checkpoint)