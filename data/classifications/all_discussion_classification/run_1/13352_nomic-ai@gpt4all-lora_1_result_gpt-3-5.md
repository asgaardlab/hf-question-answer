## https://huggingface.co/nomic-ai/gpt4all-lora/discussions/1

contains_question: yes

question_part: what is the difference between:
- the "quantized gpt4all model checkpoint: gpt4all-lora-quantized.bin."
- the "Trained LoRa Weights: gpt4all-lora (four full epochs of training)" available here?
Aren't "trained weights" and "model checkpoints" the same thing?