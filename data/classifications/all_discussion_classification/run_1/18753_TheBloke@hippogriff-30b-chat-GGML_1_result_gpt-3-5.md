## https://huggingface.co/TheBloke/hippogriff-30b-chat-GGML/discussions/1

contains_question: yes
question_part: 
Existing on-prem scale-out for mere mortals...?
What's the current state/recommendations for fine-tuning a medium-sized model, if you do not have a datacenter full of A100s, but rather a heterogeneous set of machines with various NVIDIA GPUs, like GeForce 1k to 4k series (like 1080ti, 2080, 3090, 4090) and/or less costly older Teslas (like e.g. M40, P40, etc).
The same question for inference, for large models