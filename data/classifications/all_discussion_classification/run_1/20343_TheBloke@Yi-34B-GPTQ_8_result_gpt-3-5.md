## https://huggingface.co/TheBloke/Yi-34B-GPTQ/discussions/8

contains_question: yes

question_part: What is the minimum EC2 Instance to deploy this model ? I would expect it to fit in 24 GB GPU, so ml.g5.xlarge should be sufficient