## https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit/discussions/5

contains_question: yes
question_part: How to configure llama.cpp, what the best configration for tmp and other parameters and prompt file i saw changes to this parameters make huge differnces so i wonder if some one has found the best combination