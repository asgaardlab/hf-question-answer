## https://huggingface.co/Yukang/LongAlpaca-70B/discussions/2

contains_question: yes

question_part: Any chance of a 16K model?
Are there any plans to train a 16K version that would be useable for a broader audience?
Truncating max_seq_length to 16K on load seems to degrade performance.