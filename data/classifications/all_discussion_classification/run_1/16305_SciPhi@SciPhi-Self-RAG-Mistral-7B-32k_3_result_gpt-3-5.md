## https://huggingface.co/SciPhi/SciPhi-Self-RAG-Mistral-7B-32k/discussions/3

contains_question: yes

question_part: 
Could you help me with one question about memory? 
Now i see your model work with 32k context window, but if i use my context ~23k tokens, i have error about memory, but i work with A100 80GB.
Maybe i don't understand and your working context window less then 32k tokens or i must use special settings?