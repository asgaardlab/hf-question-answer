## https://huggingface.co/Salesforce/codegen-350M-multi/discussions/3

contains_question: yes

question_part: It seems like the tokenizer configuration has the setting "model_max_length": 1024, while the model can take inputs up to 2048. Is this an oversight?