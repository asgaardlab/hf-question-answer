## https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/discussions/21

contains_question: yes
question_part:  Hi! I want to deploy one of the models using Text Generation Inference (https://github.com/huggingface/text-generation-inference#using-a-private-or-gated-model), but I can't use this repo directly cause it contains many bin files, therefore I thought about downloading one of them and putting into separate model repo. But seems like it doesn't really work, can somebody suggest something on this