## https://huggingface.co/mistralai/Mixtral-8x7B-v0.1/discussions/9

contains_question: yes

question_part: I am trying to deploy this model on the A100 p4d sagemaker endpoint instance. What are the configs for TGI that can be used for sub second real time inference?