## https://huggingface.co/chavinlo/gpt4-x-alpaca/discussions/15

contains_question: yes

question_part: Why do I get the error "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB (GPU 0; 23.99 GiB total capacity; 22.82 GiB already allocated; 0 bytes free; 23.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF" ?