## https://huggingface.co/Writer/camel-5b-hf/discussions/4

contains_question: yes
question_part: How many tokens ( max ) can the model consume at a time so that it is able to generate response without breaking up?