## https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ/discussions/7

contains_question: yes

question_part: Hello, sorry for offtopic but I'm new here and don't know other way to message you. You are doin a very great job for comunity providing so much models quantised for allowing ppls with low computing resources to run models on their computers. Thank you very much for that! Please quantise these models in GPTQ 4 bits (it will be ideally to run on laptops with Nvidia 4050 6gb vram or higher ) togethercomputer/LLaMA-2-7B-32K  ; cerebras/btlm-3b-8k-base ; James-WYang/BigTranslate . Thank you very much if you can help! And thanks anyway for the great job you are doing for all !