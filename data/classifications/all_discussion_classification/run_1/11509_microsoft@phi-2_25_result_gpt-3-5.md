## https://huggingface.co/microsoft/phi-2/discussions/25

contains_question: yes

question_part: so while training the phi-2, I didn't get it why finetuning phi -2 which is just 2B taking more GPU than 7B models like mistral 7b or Llama 2 7b.