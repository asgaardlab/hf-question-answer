## https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ/discussions/25

contains_question: yes
question_part: Why the input prompt is part of the output? So how token is calculated? the output token is `max_new_tokens` and the `max_new_tokens`+`output tokens` needs to be less than 4096