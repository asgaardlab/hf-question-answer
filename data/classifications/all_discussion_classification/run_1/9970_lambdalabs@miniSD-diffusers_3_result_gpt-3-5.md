## https://huggingface.co/lambdalabs/miniSD-diffusers/discussions/3

contains_question: yes
question_part: How do I finetune the attention layers of the unet?