## https://huggingface.co/LoneStriker/Nous-Capybara-limarpv3-34B-3.0bpw-h6-exl2-2/discussions/1

contains_question: yes

question_part: I thought I might be able to load this model on a colab T4 GPU instance since its size is less than 15GB of VRAM, but I don't know why it couldn't fit and I got this crash