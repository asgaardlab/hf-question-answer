## https://huggingface.co/keldenl/RedPajama-INCITE-Chat-3B-v1-GGML/discussions/1

contains_question: yes
question_part: I'm highly interested in testing it out, especially considering I heard quantization for models below 7B params doesn't quite work produce good results. Given all the custom deps we need to have, do you happen to already have a ipynb we could try out for inference?