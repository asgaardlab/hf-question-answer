## https://huggingface.co/bigscience/bloom/discussions/180

contains_question: yes  
question_part: how were the two datasets combined for training? Is it a simple concatenation so that during training the model will first be trained on Wikipedia documents and later GitHub, or were the datasets mixed in some way?