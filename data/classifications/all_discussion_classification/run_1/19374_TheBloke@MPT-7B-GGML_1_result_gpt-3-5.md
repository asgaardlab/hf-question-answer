## https://huggingface.co/TheBloke/MPT-7B-GGML/discussions/1

contains_question: yes

question_part: Non llama.cpp GPU compatible libraries? I see that it (currently) only works with ggml and rustformers' llm. Do either of those support GPU? If not, are GPTQ versions of MPT-7B-* possible?