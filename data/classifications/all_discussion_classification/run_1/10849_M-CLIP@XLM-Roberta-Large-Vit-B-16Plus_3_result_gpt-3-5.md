## https://huggingface.co/M-CLIP/XLM-Roberta-Large-Vit-B-16Plus/discussions/3

contains_question: yes

question_part: I'm just trying this model and compared to the multilingual models from sentence-transformers or the large laion xlm-roberta models, the inference performance is very slow. I.e., about 61x slower than 'sentence-transformers-clip-ViT-B-32-multilingual-v1' and about 4x slower than the 'laion/CLIP-ViT-H-14-frozen-xlm-roberta-large-laion5B-s13B-b90'.