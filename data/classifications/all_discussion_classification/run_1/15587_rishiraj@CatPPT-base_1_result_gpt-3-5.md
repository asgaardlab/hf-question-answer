## https://huggingface.co/rishiraj/CatPPT-base/discussions/1

contains_question: yes

question_part: Am I missing something? A foundational model, as defined everywhere, including at HF, isn't a fine-tune, let alone a slerp merge. A foundational model is an unsupervised model made from a large corpus of data trained using millions of dollars in hardware over months, such as Mistral, or a non-fine-tuned modification like Solar. This is just a slerp merge of two Mistral fine-tunes. It's no more a foundational model than the 100s of other Mistral mergers. Just because you did additional fine-tuning when making your CatPPL version doesn't change the fact that this CatPPL-Base is just a slerp merge.