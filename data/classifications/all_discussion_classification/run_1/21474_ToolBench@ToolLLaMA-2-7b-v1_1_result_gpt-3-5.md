## https://huggingface.co/ToolBench/ToolLLaMA-2-7b-v1/discussions/1

contains_question: yes

question_part: what about an quantized version so we can load in Exlama with large context size?