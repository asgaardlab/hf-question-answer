## https://huggingface.co/BlinkDL/rwkv-4-raven/discussions/17

contains_question: yes

question_part: Just as curious observation, raven models (both 7B and 14B) cannot really reflect on their failed tasks, or partially failed tasks. Maybe due to their relatively tiny size, compared to giant OpenAI models?

Most of the time, they just respond "yes, I did it correctly". Or maybe, do you think, it can be solved by more example data?