## https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B/discussions/5

contains_question: yes
question_part: Maybe I'm doing something wrong but when I try to use the pipeline method to do some inference with a cuda device (16 GB of GPU RAM), I still get a "Killed" message meaning my CPU RAM is running out.