## https://huggingface.co/cekal/mpt-7b-gpt4/discussions/2

contains_question: yes

question_part: since this is a lora model.
could you share a colab notebook for 8 bit inference of the mpt-7b-gpt4 model?
if not, would be great to have a reference notebook for inference nonetheless.