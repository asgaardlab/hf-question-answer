## https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5/discussions/3

contains_question: yes
question_part: 
-> what is the max context length for this model.
-> does this model uses same parameters as in any other text-generation model like temperature, sampling, top_p, top_k etc.,
-> what are the example prompts to use this model for use cases like context based QA, etc.,