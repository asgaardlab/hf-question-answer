## https://huggingface.co/TheBloke/mpt-30B-chat-GGML/discussions/1

contains_question: yes

question_part: Are GPTQ version of the mpt models possible? Just out of curiosity, is there any limitation on having GPTQ version the MPT models, I could not find a gptq version of the for the mpt-7B, so I am concern there are limitations or are they on the way?