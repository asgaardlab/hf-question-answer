## https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/12

contains_question: yes  
question_part: Why this has the same inference speed as the actual llama-2, wasn't this supposed to be faster