## https://huggingface.co/shuvom/my-mixtral-2x7B/discussions/1

contains_question: yes
question_part: I have a question: How did you combine parts of other pre-trained models into MoE? I'm trying to find a way how.