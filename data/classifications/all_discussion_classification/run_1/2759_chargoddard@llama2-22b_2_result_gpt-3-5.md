## https://huggingface.co/chargoddard/llama2-22b/discussions/2

contains_question: yes
question_part: "Can you make the same with 3B openllama model with some additional attention heads from Llama 7b? something like that idk"