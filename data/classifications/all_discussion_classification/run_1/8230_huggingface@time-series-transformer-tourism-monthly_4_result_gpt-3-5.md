## https://huggingface.co/huggingface/time-series-transformer-tourism-monthly/discussions/4

contains_question: yes

question_part: As the info on these arguments is fairly sparse currently, I'd really like any additional explanation and recommendations regarding what I should be using as config arguments.
I'm not very sure of what the lags should be, as I want to use the whole input sequence as context features to the Transformer model.
I may also be confused as to what the input_size, context_length, and prediction length should be, due to the fact that the blog (https://huggingface.co/blog/time-series-transformers) and the documentation both use only single-valued targets.