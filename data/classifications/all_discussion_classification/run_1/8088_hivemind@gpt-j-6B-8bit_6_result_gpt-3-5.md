## https://huggingface.co/hivemind/gpt-j-6B-8bit/discussions/6

contains_question: yes  
question_part: What's the difference between this notebook and `load_in_8bit`? Is it LoRA, and how could this be implemented with `load_in_8bit`?