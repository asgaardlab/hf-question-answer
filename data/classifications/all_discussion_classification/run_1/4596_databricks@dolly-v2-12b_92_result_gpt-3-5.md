## https://huggingface.co/databricks/dolly-v2-12b/discussions/92

contains_question: yes  
question_part: Here, my question is, is it meaningful to add conversational buffer memory to this application (Q&A) because when I logically think, LLM expects Prompt + Question + relevant chunks.