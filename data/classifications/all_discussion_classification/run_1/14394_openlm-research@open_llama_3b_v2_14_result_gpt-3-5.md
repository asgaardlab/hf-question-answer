## https://huggingface.co/openlm-research/open_llama_3b_v2/discussions/14

contains_question: yes

question_part: One thing I observed here was _seems to me_, the model refuses to generate eos token so that the conversation seems endlessly. What can I do to make it happen?