## https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML/discussions/3

contains_question: yes

question_part: In free Colab works with the model of up to llama-2_13B, but with Colab pro could the 70B_q2_K model be used?