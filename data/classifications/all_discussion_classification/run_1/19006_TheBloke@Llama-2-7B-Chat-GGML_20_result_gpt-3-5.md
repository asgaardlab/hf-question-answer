## https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/discussions/20

contains_question: yes
question_part: LLama is supposed to have 2048 tokens but i keep getting error for more than 512 tokens. I am prompting to write summary of text which has greater lengths, any solution