## https://huggingface.co/microsoft/phi-1_5/discussions/29

contains_question: yes

question_part: Size of tokenizer vocab  is 50257, while size of vocab in config is 51200. Any particular reason for this? Also how should we deal when we add extra tokens in tokenizer (Resizing of embedding layer of model).