## https://huggingface.co/openai/whisper-large-v3/discussions/4

contains_question: yes

question_part: Why float16? Why not Float32
So why was the decision made to only release the float16 version, or is that the way it was trained from the get to? All other whisper models are in float32, everything up to large-v2? Any admins care to enlighten the rest of us? Thanks.