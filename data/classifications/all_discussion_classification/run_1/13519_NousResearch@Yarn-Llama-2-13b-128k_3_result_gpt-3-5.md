## https://huggingface.co/NousResearch/Yarn-Llama-2-13b-128k/discussions/3

contains_question: yes
question_part: Can someone make a GGUF and GPTQ format for llama.cpp