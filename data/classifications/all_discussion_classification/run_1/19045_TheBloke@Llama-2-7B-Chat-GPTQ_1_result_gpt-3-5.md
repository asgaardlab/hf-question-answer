## https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ/discussions/1

contains_question: yes

question_part: Why do these have no 'max_length' and have max_position_embeddings=2048 while meta-llama ones have  "max_length": 4096, "max_position_embeddings": 4096 Can these not be properly used for 4k context?