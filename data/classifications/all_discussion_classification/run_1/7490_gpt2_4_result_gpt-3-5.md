## https://huggingface.co/gpt2/discussions/4

contains_question: yes

question_part: Are linebreaks relevant for training/finetuning?
What's common practice for data preprocessing? Does it matter for the text (not the formatting) if the net was trained on wrapped text?