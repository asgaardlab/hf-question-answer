## https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10/discussions/3

contains_question: yes

question_part: Is there an open issue on https://github.com/huggingface/text-generation-inference tracking the sharded 16 bit floating point problem?