## https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/38

contains_question: yes

question_part: How can I convert this GPTQ quantised LLM to that class