## https://huggingface.co/abhishek/llama-2-7b-hf-small-shards/discussions/2

contains_question: yes

question_part: Is it possible to train the "llamav2 7b" model on a custom dataset using Google Colab Pro, which offers approximately 32 GB of system RAM and 16 GB of GPU RAM?