## https://huggingface.co/bigscience/mt0-xxl/discussions/2

contains_question: yes

question_part: I also ran some of the cases from xP3 dataset for zh and noticed those cases with short answers tend to be good, while those with longer answers would show various kind of issues, including 1) words repeated immediately one after another sometimes, 2) grammatically incorrect sentences, 3) irrelevant contents, and 4) uncoherent context etc.
Is there something missing somewhere?
BTW, do you mind sharing the "best" parameters used for calling the "model.generate()" in a locally deployed mt0-xxl model please?