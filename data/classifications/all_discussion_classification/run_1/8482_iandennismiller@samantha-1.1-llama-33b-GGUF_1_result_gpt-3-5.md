## https://huggingface.co/iandennismiller/samantha-1.1-llama-33b-GGUF/discussions/1

contains_question: yes
question_part: how this model differs from the Ministral 7B in terms of overall output quality ? I'm freaking out (because noob) to understand how shall I train Samantha on my own language but I have troubles understanding the starting point. for the ministral has been used the ChatML format but I did not understand if for both the ministral as well the llama the same dataset has been used (ehartford/samantha-data). I have been told to translate the samantha-1.1.json but at the same time i am wondering if:

1) do i need to translate all the json/jsonl file under the folder "data" as well 
2) how to fine-tune Samantha using the translated dataset(s) 

do you have any suggestion or some channel/ml/whatever place where could I ask ? many thanks, appreciated