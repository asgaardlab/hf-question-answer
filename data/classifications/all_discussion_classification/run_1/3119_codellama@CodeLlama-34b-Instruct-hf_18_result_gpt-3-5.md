## https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf/discussions/18

contains_question: yes

question_part: When CodeLlama-34b-Instruct-hf was deployed and the default parameters were used for inference, it was found that the inference effect was very different from the hugging face, did the online inference do anything optimized?