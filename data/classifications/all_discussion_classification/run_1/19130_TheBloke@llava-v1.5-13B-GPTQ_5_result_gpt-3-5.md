## https://huggingface.co/TheBloke/llava-v1.5-13B-GPTQ/discussions/5

contains_question: yes

question_part: Can you make a GPTQ version of  "Llava-v1.5-7B" so we could run it on LowVRAM?