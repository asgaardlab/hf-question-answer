## https://huggingface.co/tiiuae/falcon-7b-instruct/discussions/70

contains_question: yes

question_part: Can this github issue address our specific problems mentioned above? 
https://github.com/oobabooga/text-generation-webui/issues/2260 

My queries are basically:
1. Is it even feasible to do inference on this machine or should we go for G4dn.8xlarge as we are facing so many issues in Inf2?
2. Can we try Llama 2 on Inferentia 2 8xlarge machine or this is not supported? If not, which machine instance we should try considering cost-effectiveness