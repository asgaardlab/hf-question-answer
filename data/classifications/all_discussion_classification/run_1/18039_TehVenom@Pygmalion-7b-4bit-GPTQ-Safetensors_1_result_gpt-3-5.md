## https://huggingface.co/TehVenom/Pygmalion-7b-4bit-GPTQ-Safetensors/discussions/1

contains_question: yes

question_part: And a whole bunch more. Might be the model or might be my code (although loading the quantized 7B with 128 groupsize seems to work fine). But since I'm still learning, I can't say for absolutely sure.