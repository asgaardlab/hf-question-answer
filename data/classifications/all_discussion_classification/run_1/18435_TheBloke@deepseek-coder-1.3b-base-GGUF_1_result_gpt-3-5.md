## https://huggingface.co/TheBloke/deepseek-coder-1.3b-base-GGUF/discussions/1

contains_question: yes  
question_part: Not sure if this is the right place to ask this, but the GGUF version of this model doesn't seem to tokenise and detokenise the special strings for fill in the middle correctly. Is there some way to look at the tokenizer configuration within the GGUF? Could quantisation somehow lead to this