## https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ/discussions/24

contains_question: yes

question_part: What does it mean by the inject_fused_attention disabled for 70B model?
                What does it mean by the `inject_fused_attention` has to be disabled for 70B model?