## https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct/discussions/10

contains_question: yes

question_part: if I set `trust_remote_code = False`when loading the model, will it just be the normal LlamaForCausalLM? If so, then running with 32K length would require too much computational power