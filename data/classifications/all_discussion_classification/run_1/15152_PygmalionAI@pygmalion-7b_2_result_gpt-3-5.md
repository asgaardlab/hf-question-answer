## https://huggingface.co/PygmalionAI/pygmalion-7b/discussions/2

contains_question: yes

question_part: Hi is there a way to help support this for a 30b version. Happy to chip in. 30b for me is where Llama starts to be truly coherent and vast, but if computing cost is a problem I'm happy to help fund.