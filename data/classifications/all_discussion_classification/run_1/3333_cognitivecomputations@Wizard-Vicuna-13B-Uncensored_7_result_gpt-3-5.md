## https://huggingface.co/cognitivecomputations/Wizard-Vicuna-13B-Uncensored/discussions/7

contains_question: yes

question_part: Any plans on expanding the context length with landmark attention?