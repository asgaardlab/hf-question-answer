## https://huggingface.co/KoboldAI/OPT-30B-Erebus/discussions/1

contains_question: yes
question_part: Would used k, p, and m series Tesla GPU's be suitable for such? And how much VRAM would i be looking at to run a 30b model?