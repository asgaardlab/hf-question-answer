## https://huggingface.co/THUDM/cogvlm-chat-hf/discussions/14

contains_question: yes

question_part: Any plans to support gradient checkpointing and flash attention for training/finetuning? Would be very helpful to get this working on fewer resources.