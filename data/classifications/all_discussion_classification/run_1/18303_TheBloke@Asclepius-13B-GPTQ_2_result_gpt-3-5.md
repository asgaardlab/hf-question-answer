## https://huggingface.co/TheBloke/Asclepius-13B-GPTQ/discussions/2

contains_question: yes

question_part: I used the code in https://huggingface.co/TheBloke/Asclepius-13B-GPTQ#you-can-then-use-the-following-code to try to load the gptq-8bit--1g-actorder_True model revision, but when trying to generate text, I get the error below in Auto-GPTQ.