## https://huggingface.co/TheBloke/Llama-2-70B-GPTQ/discussions/11

contains_question: yes  
question_part: how to quant llama2 70b model with AutoGPTQ, but I can not success.