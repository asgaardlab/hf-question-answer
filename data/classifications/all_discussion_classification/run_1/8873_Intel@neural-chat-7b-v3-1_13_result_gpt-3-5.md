## https://huggingface.co/Intel/neural-chat-7b-v3-1/discussions/13

contains_question: yes

question_part: Hi here! I'm curious about the huge gap w.r.t. Mistral in the DROP benchmark of the `lm-eval-harness`, did you use the same revision of `EleutherAI/lm-eval-harness`? Also did you run any other evaluation to see the reason why it excels that much at DROP compared to other SFT + DPO fine-tunes e.g. Zephyr? Is there any data contamination coming from the dataset used for training? A bunch of questions ðŸ˜… Feel free to answer in case you checked the issues with DROP, because the gap compared to other models seems huge and would be nice to investigate, maybe the data just has better quality!