## https://huggingface.co/8bit-coder/alpaca-7b-nativeEnhanced/discussions/5

contains_question: yes
question_part: Can we get the GPTQ quantized model?