## https://huggingface.co/lmsys/vicuna-13b-delta-v0/discussions/10

contains_question: yes
question_part: Why is model_max_length set to 1000000000000000019884624838656 in the tokenizer config? Isn't the context length for vicuna 2048