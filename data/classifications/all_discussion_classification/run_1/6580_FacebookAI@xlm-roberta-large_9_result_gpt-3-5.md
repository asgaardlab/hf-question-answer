## https://huggingface.co/FacebookAI/xlm-roberta-large/discussions/9

contains_question: yes

question_part: 
Hi, I'm trying to transform the xlm-roberta-xxlarge model from [here](https://github.com/facebookresearch/fairseq/tree/main/examples/xlmr#pre-trained-models), from Pytorch's .pt to Hugging Face's .bin but I'm having a hard time.
How could I generate the tokenizer.json from the dict.txt and sentencepiece.bpe.model they provide?
Also how can I generate the config.json required to load the statedict model.pt?