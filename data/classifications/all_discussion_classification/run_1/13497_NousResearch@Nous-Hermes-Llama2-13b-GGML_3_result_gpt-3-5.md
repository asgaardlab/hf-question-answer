## https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GGML/discussions/3

contains_question: yes

question_part: Hello, I have issues using this model in inference UI apps like Faraday and LM Studio. Most of the time the model just doesn't work. Initially it looks promising, it loads into the RAM and VRAM, CPU starts processing, but then after a moment it all stops and the model unloads from both RAM and VRAM and nothing is generated. Yesterday I was able to briefly load and even use the model in LM Studio for a while, but after some time it stopped working again and kept giving me errors about failing model.

Is there anything I could do to fix the problem, please. Any help would be appreciated, thanks!