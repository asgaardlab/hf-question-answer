## https://huggingface.co/jphme/Llama-2-13b-chat-german/discussions/4

contains_question: yes
question_part: thanks for providing the model! Would it be possible to provide a gptq-quantized version?