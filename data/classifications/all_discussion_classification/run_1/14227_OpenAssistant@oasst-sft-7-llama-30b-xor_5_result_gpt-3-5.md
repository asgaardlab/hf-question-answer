## https://huggingface.co/OpenAssistant/oasst-sft-7-llama-30b-xor/discussions/5

contains_question: yes
question_part: Could we run a XOR converted model using docker + huggingface/text-generation-inference? 
Have you tried anything like this?