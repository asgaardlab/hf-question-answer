## https://huggingface.co/RachidAR/WizardLM-Uncensored-SCOT-ST-30B-Q3_K_S-GGML/discussions/1

contains_question: yes

question_part: Could you please, if you have the time, quantize and publish the Q3_K_M, which seems the best compromise between a perplexity close to the 30b models we are used to have now and the size/speed benefits granted by q3_0 