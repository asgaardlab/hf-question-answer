## https://huggingface.co/sentence-transformers/all-mpnet-base-v2/discussions/15

contains_question: yes

question_part: I see that 'By default, input text longer than 384 word pieces is truncated'. However, in the tokenizer config I see model_max_length is 512. Does the model respect this? Or do i need to set the max seq length somewhere?