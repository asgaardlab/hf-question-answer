## https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GPTQ/discussions/2

contains_question: yes

question_part: I am getting the following error when trying to load the model using either ExLLaMA or AutoGPTQ. Actually there is no tokenizer.model file, but how can this be solved?