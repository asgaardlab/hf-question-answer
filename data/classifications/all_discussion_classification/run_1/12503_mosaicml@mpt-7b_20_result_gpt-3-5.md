## https://huggingface.co/mosaicml/mpt-7b/discussions/20

contains_question: yes
question_part: Anyone know the trained context length of the 7B instruct and chat models?