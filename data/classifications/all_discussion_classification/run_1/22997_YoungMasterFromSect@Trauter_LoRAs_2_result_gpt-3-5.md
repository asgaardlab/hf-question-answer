## https://huggingface.co/YoungMasterFromSect/Trauter_LoRAs/discussions/2

contains_question: yes

question_part: I noticed most lora models you shared are of ~150M, assuming you're using a large R in lora training (128?).