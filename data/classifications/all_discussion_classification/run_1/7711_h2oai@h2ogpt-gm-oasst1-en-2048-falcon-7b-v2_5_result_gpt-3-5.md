## https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2/discussions/5

contains_question: yes

question_part: 
No special tokens ?

I noticed that <|prompt|> is not added as a special token, was that an error in training or should it be like this? 

What are the advantages of this model in comparison to the official OpenAssistant 7B Falcon variant?
I'm not familiar with the differences between the datasets, this one appears to use one of the early variants ?