## https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/discussions/7

contains_question: yes
question_part: Not sure what I am doing wrong but while running the model with ollama I get a lot of `<0x0A>`'s. Would appreciate any hint. I replace `<0x0A>` with `\n` right now in code but still is it a config error or inconsistency in the training data?