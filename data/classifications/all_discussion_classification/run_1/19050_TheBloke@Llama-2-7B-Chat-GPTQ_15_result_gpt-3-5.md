## https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ/discussions/15

contains_question: yes
question_part: can anyone provide a code for faster gpu inference from GPTQ model, for me it takes around 2 mins to get the response