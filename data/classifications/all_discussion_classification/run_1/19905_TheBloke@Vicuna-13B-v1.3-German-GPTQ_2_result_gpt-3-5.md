## https://huggingface.co/TheBloke/Vicuna-13B-v1.3-German-GPTQ/discussions/2

contains_question: yes

question_part: I tried loading the model revision="gptq-8bit-128g-actorder_True", as shown in the documentation using python but it is loading by default the main branch model. Also is it good for German because I have tried ggml model and it was giving excellent results but saw other discussion saying German responses are funny.