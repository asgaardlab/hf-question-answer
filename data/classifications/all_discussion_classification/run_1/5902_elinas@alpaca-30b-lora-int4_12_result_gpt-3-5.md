## https://huggingface.co/elinas/alpaca-30b-lora-int4/discussions/12

contains_question: yes  
question_part: I feel like I would need to convert my 30B Llama Model from Huggingface format into another format and put it into ../alpaca-30b-lora-int4 folder. So I can use it from GPTQ, but I don't know how that works with this repo and there is no info provided.