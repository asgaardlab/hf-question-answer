## https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/discussions/6

contains_question: yes
question_part: My question is: What type of compute instances you guys use for this model in production environment. It is ~400 MB PyTorch model. **For inference, do you guys use CPU or GPU instance?** Would it matter in inference as well? I know it is a big difference in training. But is it the same with the inference.