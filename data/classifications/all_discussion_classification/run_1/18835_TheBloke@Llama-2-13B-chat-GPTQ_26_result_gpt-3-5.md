## https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/26

contains_question: yes

question_part: I fine-tuned llama-2 on my dataset and now I want to convert it to the gptq_model-4bit-128g.safetensors format. Could you please tell me how I can do this? What script or method can I use to achieve this