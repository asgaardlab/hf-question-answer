## https://huggingface.co/CultriX/MistralTrix-v1/discussions/7

contains_question: yes

question_part: Like several of the top '7B' models on the leaderboard, this is actually a 9B, downstream of https://huggingface.co/zyh3826/GML-Mistral-merged-v1, a merge that combined the first 32 layers (ie all of them) of one Mistral-7B finetune with the last 8 layers of another Mistral finetune, creating a model that is about 9B parameters.