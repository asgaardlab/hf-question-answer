## https://huggingface.co/zaq-hack/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-bpw300-h6-exl2/discussions/1

contains_question: yes

question_part: Would it be possible to do a smaller quant for 16GB 4080 owners? Maybe 2.4bpw? I'd like to test it, too. Btw, did you base on instruct-v0.1 or instruct-v0.2?