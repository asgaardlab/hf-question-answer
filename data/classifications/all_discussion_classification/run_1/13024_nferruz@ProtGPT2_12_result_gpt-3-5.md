## https://huggingface.co/nferruz/ProtGPT2/discussions/12

contains_question: yes

question_part: This makes me think that padding was not used at training time, as the tokenizer does  not have a padding token.