## https://huggingface.co/tloen/alpaca-lora-7b/discussions/2

contains_question: yes
question_part: How can be this model here MIT licensed, when it is based on Stanford Alpaca, which in turn is based on LLaMA, and which in turn again it is based on OpenAIâ€™s text-davinci-003, whose terms of use prohibit developing models that compete with OpenAI?