## https://huggingface.co/SnypzZz/Llama2-13b-Language-translate/discussions/6

contains_question: yes
question_part: It would be really nice if someone converted this model into other formats for GPU and efficient CPU based inference, also some instructions on how to use it inside textgenui etc. Would be neat