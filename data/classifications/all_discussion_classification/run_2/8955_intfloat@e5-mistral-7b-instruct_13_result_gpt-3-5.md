## https://huggingface.co/intfloat/e5-mistral-7b-instruct/discussions/13

contains_question: yes
question_part: To me, this begs the question: could we distill these high quality embeddings into a smaller model (e.g. [bge-small](https://huggingface.co/BAAI/bge-small-en-v1.5)) to 1) improve the performance of the smaller student model and 2) create longer sequence length models without requiring long-sequence labeled training data.