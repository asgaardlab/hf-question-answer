## https://huggingface.co/Xenova/gpt-3.5-turbo-16k/discussions/2

contains_question: yes
question_part: Hi: I am using your tokenizer to avoid tiktoken because I don't have permission to do it. However I always get this warning: "Tokenizer class GPT3 5 Tokenizer does not exist or is not currently imported." How can I fix it?