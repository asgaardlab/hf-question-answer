## https://huggingface.co/sileod/deberta-v3-base-tasksource-nli/discussions/4

contains_question: yes

question_part: What are the preprocessing steps used on the data for the inference API? I notice different outputs for the same inference I run on my notebook vs the api and I was wondering what I could steps I could take to match the inference api. FYI, I am using the zero-shot-classification pipeline