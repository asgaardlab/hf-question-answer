## https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/27

contains_question: yes

question_part: I just wanted to know if the gptq model is the one needed to run the model on a gpu? and if so, what type of graphics card do you need to run the 7B, 13B or 70B models? And is it possible to run the model on several small graphics cards?