## https://huggingface.co/TheBloke/LlongOrca-13B-16K-GGUF/discussions/2

contains_question: yes

question_part: But it is continuously throwing CudaOutOfMemory. So, can you say if this is normal and it requires more memory or maybe my code base has some memory leakage? If it requires more memory can you please give me estimated requirements for finetuning 13b-16k models.