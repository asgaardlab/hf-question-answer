## https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-AWQ/discussions/1

contains_question: yes

question_part: I might try the GGUF versions for now - but I'm curious what your recommendations are for this model, how much vRAM, etc.