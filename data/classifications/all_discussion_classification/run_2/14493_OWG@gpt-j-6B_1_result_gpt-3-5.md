## https://huggingface.co/OWG/gpt-j-6B/discussions/1

contains_question: yes
question_part: Is the ORT model fp32 or fp16, if it is fp32 can you share some way to export it to fp16 to able to fit in 16GB GPU?