## https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0/discussions/7

contains_question: yes  
question_part: I read that this model had 16k context length without any changes and could go up to 100k. why is that