## https://huggingface.co/TheBloke/Nous-Hermes-13B-SuperHOT-8K-GPTQ/discussions/1

contains_question: yes
question_part: One thing I did notice from the non-superHOT was that after reaching a large enough context size, around 3200~ context,(FYI, max_new_token was set to 800), the model tends to repeats the previous responses specially if you try to reference any elements in its context memory or what the user and AI has said.