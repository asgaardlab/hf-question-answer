## https://huggingface.co/Undi95/Mistral-11B-v0.1/discussions/1

contains_question: yes

question_part: I guess their is no performance boost? I believe this model is made to create further room for learning, isn't it? Suppose I increase its heads (duplicate heads or add heads from OpenChat-3.5) and run a train for dataset between 1b-50b tokens of RedPajama will any performance increment will be sighted?