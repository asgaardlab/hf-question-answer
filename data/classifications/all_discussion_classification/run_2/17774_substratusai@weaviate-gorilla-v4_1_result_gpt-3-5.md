## https://huggingface.co/substratusai/weaviate-gorilla-v4/discussions/1

contains_question: yes
question_part: Hi, I'm trying to understand why the model output would be different when deployed to an Inference Endpoint using the default settings. Any insight as to what I may be doing wrong with deploying the model to an inference endpoint would be much appreciated.