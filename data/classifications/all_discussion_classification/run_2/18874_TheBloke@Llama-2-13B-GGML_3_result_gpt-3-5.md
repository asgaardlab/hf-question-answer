## https://huggingface.co/TheBloke/Llama-2-13B-GGML/discussions/3

contains_question: yes

question_part: Meta reports that the base models support 4096 context. Is it possible to make GGML models with 4096 context?