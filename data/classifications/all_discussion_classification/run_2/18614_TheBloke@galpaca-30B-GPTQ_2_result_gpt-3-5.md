## https://huggingface.co/TheBloke/galpaca-30B-GPTQ/discussions/2

contains_question: yes
question_part: Would you consider also generating a GPTQ 4bit version of the medalpaca model (llama finetuned on a bunch of medical datasets + alpaca) - https://huggingface.co/medalpaca/medalpaca-13b - as well? Thank you so much in advance!