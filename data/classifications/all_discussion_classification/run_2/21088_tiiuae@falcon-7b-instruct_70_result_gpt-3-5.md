## https://huggingface.co/tiiuae/falcon-7b-instruct/discussions/70

contains_question: yes

question_part: Can this github issue address our specific problems mentioned above? 
Is it even feasible to do inference on this machine or should we go for G4dn.8xlarge as we are facing so many issues in Inf2?
Can we try Llama 2 on Inferentia 2 8xlarge machine or this is not supported? If not, which machine instance we should try considering cost-effectiveness