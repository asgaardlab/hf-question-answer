## https://huggingface.co/cerebras/Cerebras-GPT-13B/discussions/4

contains_question: yes

question_part: The example in Quickstart loads the model into cpu for running. I know model.cuda() can move the model to gpu for small models. How to distribute the model to multiple gpus and to run the generation for large models.