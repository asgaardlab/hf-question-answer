## https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ/discussions/13

contains_question: yes

question_part: Can anybody enlighten me how to inference 70b-GPTQ model (chat or non-chat) using oobabooga/text-generation-webui