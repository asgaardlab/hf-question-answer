## https://huggingface.co/huggingface/falcon-40b-gptq/discussions/3

contains_question: yes

question_part: Error: Warmup(Generation("Not enough memory to handle 20 total tokens with 10 prefill tokens. You need to decrease `--max-batch-total-tokens` or `--max-batch-prefill-tokens`"))