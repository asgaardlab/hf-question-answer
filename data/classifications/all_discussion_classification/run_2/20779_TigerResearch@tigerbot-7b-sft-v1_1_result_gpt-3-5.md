## https://huggingface.co/TigerResearch/tigerbot-7b-sft-v1/discussions/1

contains_question: yes
question_part: Just curious, does the training dataset includes the truthfulqa dataset which is being used during evaluation for Open LLM LB? If so, is it still fair to use truthfulqa as a metric to evaluate this model? Because compared with other 7B, (or maybe 65B/70B) models, the truthfulqa metric is very high.