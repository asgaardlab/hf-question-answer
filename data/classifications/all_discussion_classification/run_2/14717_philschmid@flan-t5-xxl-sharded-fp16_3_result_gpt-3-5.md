## https://huggingface.co/philschmid/flan-t5-xxl-sharded-fp16/discussions/3

contains_question: yes

question_part: Hi @philschmid, I can see you used Artifact-AI/flan-t5-xxl-sharded-fp16. What exactly is this model? Did the authors just cast the model weights to fp16 and then saved the model to reduce inference latency and cost?