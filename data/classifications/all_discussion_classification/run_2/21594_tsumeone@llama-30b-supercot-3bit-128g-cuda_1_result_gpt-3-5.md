## https://huggingface.co/tsumeone/llama-30b-supercot-3bit-128g-cuda/discussions/1

contains_question: yes

question_part: The 30B 3bit 128G model seems to meet a sweet spot that outperform 13B fp16 model: ![msedge_wKQ6yw1t6Z.png](https://cdn-uploads.huggingface.co/production/uploads/64438bcb1bc692d87b237c04/iF9f5bjIL4_9Dhhb-MRoi.png) Which motivated me to just about convert the model by myself.