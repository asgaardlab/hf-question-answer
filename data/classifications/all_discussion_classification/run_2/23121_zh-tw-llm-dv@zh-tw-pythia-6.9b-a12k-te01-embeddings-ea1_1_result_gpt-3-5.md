## https://huggingface.co/zh-tw-llm-dv/zh-tw-pythia-6.9b-a12k-te01-embeddings-ea1/discussions/1

contains_question: yes

question_part: Could you please post more information to explain clearly for each LLM uploaded in "zh-tw-llm-dv"?
For example, what does a12k, te01, v1-a_2, v1-b_1,  ea1, ... mean? What model is the latest/best one for chat/instruct/base model now?
Besides, do I understand correctly that the model name with "tw" was trained on pure Traditional Chinese while "zh-tw" was trained on both Simplified and Traditional Chinese?