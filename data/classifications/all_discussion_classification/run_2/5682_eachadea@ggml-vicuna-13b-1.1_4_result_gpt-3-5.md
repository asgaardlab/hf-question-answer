## https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/discussions/4

contains_question: yes
question_part: how much RAM does the 13b 4 bit quantized model require