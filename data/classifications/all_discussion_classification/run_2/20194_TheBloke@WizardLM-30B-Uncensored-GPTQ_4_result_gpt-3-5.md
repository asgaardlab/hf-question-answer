## https://huggingface.co/TheBloke/WizardLM-30B-Uncensored-GPTQ/discussions/4

contains_question: yes
question_part: I'm looking for some clarification on whether this model was quantized with or without the "--act-order" flag. The README is conflicting because it says it was quantized without "--act-order" flag but the filename has "act-order" instead of "no-act-order", and the example command for quantizing the model does include the "--act-order" flag.