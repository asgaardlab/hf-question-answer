## https://huggingface.co/TheBloke/Falcon-180B-Chat-GPTQ/discussions/4

contains_question: yes
question_part: I'm trying to see if the 4bit GPTQ variant will work on a g5.48xlarge instance (8 * A10-24GB).
Why I'm seeing the following error: "NotImplementedError: Tensor Parallelism is not implemented for 14 not divisible by 8".