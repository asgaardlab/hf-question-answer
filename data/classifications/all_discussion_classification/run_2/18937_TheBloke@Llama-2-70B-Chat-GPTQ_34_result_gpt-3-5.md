## https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ/discussions/34

contains_question: yes

question_part: Are there any benchmark comparisions for the Quantized model vs the full model? I want to gauge the performance drop introduced by quantization.