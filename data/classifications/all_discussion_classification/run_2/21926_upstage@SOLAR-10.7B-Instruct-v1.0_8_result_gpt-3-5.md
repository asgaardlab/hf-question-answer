## https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0/discussions/8

contains_question: yes

question_part: This model showed highest benchmark in the open llm leaderboard however when i try fine tune with SFTtrainer, this models shows lower performance with comparison to just llama2-13b-chat model. I did even try to tune hyperparameters for optimization several times, it didn't work. Is there any specific reason for this reason?