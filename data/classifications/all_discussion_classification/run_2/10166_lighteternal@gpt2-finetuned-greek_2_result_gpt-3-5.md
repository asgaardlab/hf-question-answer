## https://huggingface.co/lighteternal/gpt2-finetuned-greek/discussions/2

contains_question: yes

question_part: When I use the model's tokenizer in order to tokenize a Greek sentence I get Is this normal? Should't I see tokens or sub-word tokens in Greek?