## https://huggingface.co/llmware/bling-sheared-llama-2.7b-0.1/discussions/5

contains_question: yes

question_part: is it possible to utilize Qlora for fine-tuning Bling Models? Additionally, if we plan to further train these models on specialized documents, instructions, and knowledge bases, what is the required amount of GPU resources