## https://huggingface.co/google/flan-t5-xxl/discussions/23

contains_question: yes

question_part: Fine tune xxl using 24GB GPU? Is it possible to fine tune the xxl model using one 3090 with 24 GB VRAM? If not, how much memory is required? Can the model be fine tuned in 8 bit mode to reduce the memory requirements, like in inferences?