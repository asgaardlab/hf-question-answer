## https://huggingface.co/TheBloke/Llama-2-7B-GPTQ/discussions/9

contains_question: yes

question_part: Can I run this Llama-2-7B-GPTQ version on it? Does the model require more specs? Are there any other open-source LLMs that can be used in these specifications?