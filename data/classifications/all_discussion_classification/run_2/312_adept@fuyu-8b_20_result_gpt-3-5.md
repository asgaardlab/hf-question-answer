## https://huggingface.co/adept/fuyu-8b/discussions/20

contains_question: yes

question_part: Is it possible to quantize this model to AWQ. GPTQ or GGUF at present?