## https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ/discussions/23

contains_question: yes

question_part: I've created an issue over on the text-generation-inference page linked below for brevity. In short, I can't load this model in Kubernetes. 