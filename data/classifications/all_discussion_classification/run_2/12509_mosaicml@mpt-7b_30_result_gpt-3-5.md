## https://huggingface.co/mosaicml/mpt-7b/discussions/30

contains_question: yes
question_part: I seem to be running into a problem at [this line number](https://github.com/PanQiWei/AutoGPTQ/blob/main/auto_gptq/modeling/_base.py#L190). It seems the attentions are not being passed in the `kwargs`. How can that be remedied?