## https://huggingface.co/m33393/llama-65b-gptq-cuda-4bit-32g-safetensors/discussions/1

contains_question: yes
question_part: can I run it on a RTX4090?