## https://huggingface.co/dillfrescott/Nous-Hermes-2-SOLAR-10.7B-x2-MoE/discussions/1

contains_question: yes

question_part: 
- is the process "Black magic"? Like is there a limit to how many times one can merge models to end up with something like a 100B parameter model?
- Does the model deteriorate with more consecutive merges?
- How does this work exactly and why does it work?
- How did you find this? Where you experimenting with merging models?
- Does this process work with every model? even old ones, smaller ones or bigger models like 20B and above?
- and lastly, would it be possible to do this with for example Pygmalion 6B and create a 10 or 11B version of that model?