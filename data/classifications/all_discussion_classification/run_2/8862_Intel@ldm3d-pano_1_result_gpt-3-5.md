## https://huggingface.co/Intel/ldm3d-pano/discussions/1

contains_question: yes

question_part: First,  I followed the guidance of  ldm3d huggingface space  and generated some panoramas images. but I found that the performace of panoramas generated by ldm3d-pano checkpoints is not as good as that in the demo(https://www.youtube.com/watch?v=3hbUo-hwAs0).  In the generated settings, the height is 1024, the width is 2048, and the prompt text is "360 view of a beautiful garden in CG style", use default values for other parameters. However, the result style is not CG style and geometric deformation is serious. Could you tell me some suggestions about generating better quality panoramas? 

Second,  The dataset used in the original paper was LAION-400M, which does not contain panorama images. So the ldm3d-pano model was trained on another dataset that contains panoramas image, depth image and caption tuple? 

Three, I found some bugs in the generated panorama images,  and that is, inconsistencies at the stitching. Have you considered how to deal with this bug, whether to solve it directly from the model structure or through post-processing?