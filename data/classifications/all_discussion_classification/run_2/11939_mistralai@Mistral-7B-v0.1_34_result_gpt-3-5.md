## https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/34

contains_question: yes

question_part: Why adaptor_model.bin becomes much larger than llama familes?
What is the main reason that mistralai model has so many trainable parameters than llama models (^)(# of trainable parameter 33M ~ 67M)