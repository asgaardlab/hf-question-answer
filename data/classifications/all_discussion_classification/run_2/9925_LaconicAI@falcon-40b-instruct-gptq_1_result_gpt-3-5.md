## https://huggingface.co/LaconicAI/falcon-40b-instruct-gptq/discussions/1

contains_question: yes

question_part: 
Will this model work in OobaBooga (text-generation-webui) on a single 4090 card system with any settings?
Is this possible with some settings, checking CPU to offload some...anyway to optimize it further, etc..?