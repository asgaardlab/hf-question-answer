## https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ/discussions/22

contains_question: yes

question_part: I'd like to ask if you have made any performance comparisons for Llama2 70B chat models vs GPTQ quant, like you did [here](https://huggingface.co/TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ/discussions/1#64c04973a8a2dcaa166ca75f).