## https://huggingface.co/AI4PD/ZymCTRL/discussions/2

contains_question: yes

question_part: 
Q1.  For fine-tuning (Example 2), is there a minimum memory requirement in GPU?
Q2.  Does it make sense to fine-tune the pretrained ZymCTRL with a custom tokenizer (in which smiles strings are tokenized, instead of EC numbers)?  In general, any restriction on the length of prompts in the train set?