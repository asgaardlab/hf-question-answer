## https://huggingface.co/bigscience/bloom/discussions/195

contains_question: yes

question_part: I am planning to run inference on the 176B model, but I could not find much information, regarding the minimum requirements.
If anyone has experience with this, could you please provide some insights on what is the minimum set-up required to run inference on the 176B model?