## https://huggingface.co/teknium/Phi-Hermes-1.3B/discussions/5

contains_question: yes
question_part: DPO Version

How would this model behave if one would do the UltraLM DPO training?