## https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GPTQ/discussions/2

contains_question: yes
question_part: I followed instructions from https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GPTQ#python-code-example-inference-from-this-gptq-model (I tried installations from wheel and from source).
Is mixtral not runnable with autoGPTQ yet?