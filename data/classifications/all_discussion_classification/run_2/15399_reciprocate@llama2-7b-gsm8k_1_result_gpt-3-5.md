## https://huggingface.co/reciprocate/llama2-7b-gsm8k/discussions/1

contains_question: yes
question_part: Hello, thanks for sharing the model. Could you please provide more info about the finetuning recipe (LR, num-epochs, batch-size) on GSM8k dataset? And also, have you used only GSM8k for finetuning or have you combined it with some other data (e.g. MathQA)