## https://huggingface.co/GreenBitAI/yi-34b-w4a16g32/discussions/2

contains_question: yes

question_part: One application of quantized models I'm interested in is long context inference. Will you make a 2 bit Yi-34b-200k?