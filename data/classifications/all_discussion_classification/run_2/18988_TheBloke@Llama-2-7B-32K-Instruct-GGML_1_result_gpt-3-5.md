## https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GGML/discussions/1

contains_question: yes

question_part: Running  Llama-2-7B-32K-Instruct-GGML with llama.cpp ?