## https://huggingface.co/bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-LoRA/discussions/1

contains_question: yes
question_part: "Could you provide any info on how the pertaining on 8k was done? Like a link  to the repository which was used to pretrain the additional 100 steps on 8k context?"