## https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/discussions/3

contains_question: yes
question_part: Should I open an issue in the llama.cpp repo to get this working?