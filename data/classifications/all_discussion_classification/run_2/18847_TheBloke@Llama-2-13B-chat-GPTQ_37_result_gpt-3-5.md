## https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/37

contains_question: yes
question_part: Is there any particular guide that i can follow to get this up and running? i have an 4 x A100 80GB and confused about how to go around, which model to run (the original one/quantised, GPTQ/GGML, AutoGPTQ/Exllama, what's llama.cpp). a guide to understand all these formats would be helpful.