## https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-GGML/discussions/3

contains_question: yes

question_part: Llama.cpp is roughly 2seconds per token slower on v3 for me which I didn't expect.