## https://huggingface.co/eachadea/legacy-ggml-vicuna-7b-4bit/discussions/5

contains_question: yes

question_part: How to configure llama.cpp, what the best configuration for tmp and other parameters and prompt file i saw changes to this parameters make huge differences so i wonder if someone has found the best combination