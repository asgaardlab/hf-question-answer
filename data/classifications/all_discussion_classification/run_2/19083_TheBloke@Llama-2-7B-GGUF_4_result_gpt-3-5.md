## https://huggingface.co/TheBloke/Llama-2-7B-GGUF/discussions/4

contains_question: yes

question_part: Is this intended?  It seems to depend on whether `LLAMA_NO_K_QUANTS` is set during compilation and `quantize_output_tensor` during quantization time. Is that something you changed in your process?