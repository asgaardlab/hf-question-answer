## https://huggingface.co/TheBloke/mpt-30B-chat-GGML/discussions/5

contains_question: yes

question_part: 
Why not llama.cpp ?
Why can't this run on llama.cpp when it can run on others that use llama.cpp?
What's missing?