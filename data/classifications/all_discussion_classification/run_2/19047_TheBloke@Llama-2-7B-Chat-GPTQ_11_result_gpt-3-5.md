## https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ/discussions/11

contains_question: yes
question_part: I am having a very low inference speed. It takes around 40-50 seconds to provide the answer even for simple prompts. How can I speedup this inference time