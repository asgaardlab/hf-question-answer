## https://huggingface.co/reeducator/bluemoonrp-30b/discussions/1

contains_question: yes
question_part: Is it possible in future to post version with Groupsize = None? So it will be possible to fit full context on consumer grade GPU, like 4090 24Gb. Version with 128g gives out of memory error when context almost full.