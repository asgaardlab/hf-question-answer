## https://huggingface.co/patrickvonplaten/wav2vec2-conformer-rel-pos-large-960h-ft-4-gram/discussions/1

contains_question: yes  
question_part: Hi, as the intro said "Wav2Vec2-Conformer with relative position embeddings, pre-trained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio", but in the Github readme, the pre-train dataset is 60k Libri-Light. Which one is correct? Thanks a lot!