## https://huggingface.co/impira/layoutlm-document-qa/discussions/4

contains_question: yes

question_part: Do you know why we have "tokenizer_class": "RobertaTokenizer", in the config file instead of LayoutLMTokenizer? Is RobertaTokenizer used in fine-tuning this downstream QA task?