## https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/13

contains_question: yes

question_part: Is there any way to perform inference on CPU with the model?