## https://huggingface.co/tiiuae/falcon-40b/discussions/34

contains_question: yes

question_part: I'm trying to figure out whether falcon is using Flash attention (it is per its model card), but I found no related code in the repo such as `from flash_attn.flash_attention import FlashMHA`etc. Am I missing something?