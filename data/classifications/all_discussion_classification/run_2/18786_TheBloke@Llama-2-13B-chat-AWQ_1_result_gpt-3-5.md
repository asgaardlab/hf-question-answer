## https://huggingface.co/TheBloke/Llama-2-13B-chat-AWQ/discussions/1

contains_question: yes  
question_part: "any idea how to test this for inferencing using vllm"