## https://huggingface.co/mrm8488/falcoder-7b/discussions/3

contains_question: yes

question_part: My queries are basically: 1.Is it even feasible to do inference on this machine or should we go for G4dn.8xlarge as we are facing so many issues in Inf2? 2. Can we try Llama 2 on Inferentia 2 8xlarge machine or this is not supported? If not, which machine instance we should try considering cost-effectiveness