## https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-4bit/discussions/2

contains_question: yes

question_part: How did you perform the GPTQ quantization of this model?