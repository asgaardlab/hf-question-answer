## https://huggingface.co/TheBloke/alfred-40B-1023-AWQ/discussions/1

contains_question: yes

question_part: When running the model using vLLM 0.2.2 (either via the server command line or using the LLM constructor), I get the following error: