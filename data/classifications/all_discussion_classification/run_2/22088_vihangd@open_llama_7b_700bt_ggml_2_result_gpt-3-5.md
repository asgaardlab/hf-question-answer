## https://huggingface.co/vihangd/open_llama_7b_700bt_ggml/discussions/2

contains_question: yes

question_part: Hello @vihangd, would you kindly consider quantizing the full release model? Also there are some new quantized methods such as q4_K_M and others, would you kindly consider those additional methods if you do the former?