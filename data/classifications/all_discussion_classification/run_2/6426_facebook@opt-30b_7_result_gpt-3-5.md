## https://huggingface.co/facebook/opt-30b/discussions/7

contains_question: yes

question_part: One question that I have is whether it would be generally possible to separate the weights for different backends to make it faster to load the model (e.g., only download PyTorch-specific weights, etc.)