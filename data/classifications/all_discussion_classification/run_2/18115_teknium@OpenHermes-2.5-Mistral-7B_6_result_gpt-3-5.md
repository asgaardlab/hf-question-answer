## https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B/discussions/6

contains_question: yes

question_part: What is the context length for this model? Does it sustain multi-round conversations well, and can it extract facts buried deep inside long prompts