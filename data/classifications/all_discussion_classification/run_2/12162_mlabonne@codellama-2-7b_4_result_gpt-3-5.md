## https://huggingface.co/mlabonne/codellama-2-7b/discussions/4

contains_question: yes

question_part: Hey, I was trying to quantize it by following your article https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html but the tokenizer.model file is missing, can you help us how we can use your quantization tutorial (gguf) on  colab fine tuning files?