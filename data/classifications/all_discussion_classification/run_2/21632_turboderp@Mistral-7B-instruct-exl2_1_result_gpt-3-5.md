## https://huggingface.co/turboderp/Mistral-7B-instruct-exl2/discussions/1

contains_question: yes

question_part: What command did you use to quantize the model? I don't fully understand how your quantizer works when the context length is longer.