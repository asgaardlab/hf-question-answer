## https://huggingface.co/PygmalionAI/pygmalion-13b/discussions/3

contains_question: yes

question_part: Add SHA256 for LLaMA itself and the PyTorch conversion?
Is it possible the SHA256 hashes for both the vanilla LLaMA-13B and the PyTorch conversion could also be added to the description for troubleshooting purposes?