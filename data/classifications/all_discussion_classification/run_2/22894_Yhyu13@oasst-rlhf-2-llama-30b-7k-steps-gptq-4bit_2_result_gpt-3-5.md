## https://huggingface.co/Yhyu13/oasst-rlhf-2-llama-30b-7k-steps-gptq-4bit/discussions/2

contains_question: yes

question_part: I just wanted to make a request if it's possible that you could quantify this model at 2 bits.