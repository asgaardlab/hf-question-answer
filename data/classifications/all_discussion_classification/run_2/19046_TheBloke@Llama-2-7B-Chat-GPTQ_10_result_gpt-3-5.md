## https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ/discussions/10

contains_question: yes

question_part: Can you please tell me what is the GPU requirement to run this model? If 5GB VRAM is too less, then can you suggest a chat GPTQ model which would run with this kind of GPU? Also, is there any location in the documentation of these models which refer the basic GPU requirements for these models?