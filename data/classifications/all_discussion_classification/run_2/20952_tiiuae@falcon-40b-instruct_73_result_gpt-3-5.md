## https://huggingface.co/tiiuae/falcon-40b-instruct/discussions/73

contains_question: yes
question_part: As the length of the chat increases, the inference time sometimes doubles and can take up to 2-3 minutes per prompt. I'm using an NVIDIA RTX 3090 Ti for inference. Below is the code snippet I'm using for prediction:
