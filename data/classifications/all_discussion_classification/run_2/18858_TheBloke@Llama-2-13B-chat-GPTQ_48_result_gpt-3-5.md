## https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/48

contains_question: yes

question_part: 
Can anybody solve this problem? Or I just want to know how fast GPTQ models are. Thanks :)