## https://huggingface.co/TheBloke/goliath-120b-GGUF/discussions/3

contains_question: yes

question_part: @TheBloke maybe you know the quick fix to 
```
ggml_new_object: not enough space in the context's memory pool (needed 1638880, available 1638544)
```
error while trying to run the goliath-120b.Q2_K.gguf model with llama-cpp-python?