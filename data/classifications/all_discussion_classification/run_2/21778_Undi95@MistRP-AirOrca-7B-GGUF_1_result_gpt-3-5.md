## https://huggingface.co/Undi95/MistRP-AirOrca-7B-GGUF/discussions/1

contains_question: yes

question_part: I have a request: You put out new models in such a high pace that it becomes hard to keep track of what the underlying models capacities are. Would you please add a suggestion for the maximum usable context size to the model cards?