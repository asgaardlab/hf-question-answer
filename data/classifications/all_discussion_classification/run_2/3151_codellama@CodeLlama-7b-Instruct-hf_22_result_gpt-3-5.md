## https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf/discussions/22

contains_question: yes

question_part: The inference speed is extremly slow (It runs more than ten minutes without producing the response for a request). Any suggestion on how to solve this problem?