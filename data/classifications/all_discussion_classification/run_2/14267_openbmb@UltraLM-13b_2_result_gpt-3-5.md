## https://huggingface.co/openbmb/UltraLM-13b/discussions/2

contains_question: yes  
question_part: How much VRAM is required to run inference?