## https://huggingface.co/TheBloke/Llama-2-70B-Chat-GPTQ/discussions/32

contains_question: yes
question_part: I feel like it's important for the model that I can fine-tune the output of the model without using lora. Do you know how to insert some  code to achieve this function in llama2，thanks！