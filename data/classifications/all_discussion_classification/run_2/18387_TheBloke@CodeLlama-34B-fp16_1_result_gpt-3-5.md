## https://huggingface.co/TheBloke/CodeLlama-34B-fp16/discussions/1

contains_question: yes

question_part: The minimum recommended vRAM needed for this model assumes using Accelerate or `device_map="auto"` and is denoted by the size of the "largest layer".