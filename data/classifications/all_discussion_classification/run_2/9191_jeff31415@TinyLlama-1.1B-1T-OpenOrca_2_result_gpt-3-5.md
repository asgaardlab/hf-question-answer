## https://huggingface.co/jeff31415/TinyLlama-1.1B-1T-OpenOrca/discussions/2

contains_question: yes
question_part: I was wondering if there is some remedy for the issue of ChatML taking up many tokens. Is there something I'm missing here or is it really supposed to be 7 tokens?