## https://huggingface.co/TheBloke/deepseek-llm-7B-chat-GGUF/discussions/1

contains_question: yes

question_part: Hi, Could you please share the steps to convert this model into GGUF format? I tried to the convert.py from llama.cpp, but got an error: Exception: Vocab size mismatch (model has 102400, but tokenizer.model has 32000).