## https://huggingface.co/google/flan-t5-xl/discussions/16

contains_question: yes
question_part: If I have a large list consisting of input_texts, how can I give them to the model.generate() function? Is there a way to perform this inference in batches?