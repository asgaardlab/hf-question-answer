## https://huggingface.co/StanleyRoberts/Nix/discussions/1

contains_question: yes

question_part: Can you elaborate on what is meant by "longer input lengths"?  Does this model support a longer context than 2048 tokens?  If so, that would be quite unusual, and quite interesting.