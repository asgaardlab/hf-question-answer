## https://huggingface.co/jphme/Llama-2-13b-chat-german/discussions/4

contains_question: yes

question_part: Would it be possible to provide a gptq-quantized version?