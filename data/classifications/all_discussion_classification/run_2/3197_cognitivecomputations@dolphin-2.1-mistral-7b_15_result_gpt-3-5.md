## https://huggingface.co/cognitivecomputations/dolphin-2.1-mistral-7b/discussions/15

contains_question: yes
question_part: It appears to be set at a default of 512 tokens and does start to fail rather quickly once that has been reached. I am confused as to whether this model is capable of utilizing the 8k context tokens I have seen articles talk about, if so what config settings do I need to modify or what generation method do I need to try