## https://huggingface.co/microsoft/Promptist/discussions/1

contains_question: yes
question_part: After reading the paper couple times, I'm still not clear on what actually happens during inference? I understand we call GPT-2 to rephrase the original prompt, but what happens after that? What's the performance of the entire inference pipeline (inference time for example) and is there a way to boost it?