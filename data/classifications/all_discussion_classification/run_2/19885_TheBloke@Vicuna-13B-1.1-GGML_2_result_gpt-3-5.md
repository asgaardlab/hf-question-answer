## https://huggingface.co/TheBloke/Vicuna-13B-1.1-GGML/discussions/2

contains_question: yes

question_part: Can the quantized models be downloaded using the transformers library? How do we specify which quantized model (i.e 4bit) to be used?