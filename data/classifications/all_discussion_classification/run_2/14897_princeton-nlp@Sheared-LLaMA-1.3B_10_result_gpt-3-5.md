## https://huggingface.co/princeton-nlp/Sheared-LLaMA-1.3B/discussions/10

contains_question: yes

question_part: However, when I launched the training procedure, I found that the model yielded loss directly (does the model have loss function embedded inside?), and the loss had no grad_func attached on it so the error occurred during backward phase. Could anyone tell me the reason of the problem?