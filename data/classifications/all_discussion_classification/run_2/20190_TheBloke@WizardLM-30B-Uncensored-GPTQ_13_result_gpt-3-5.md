## https://huggingface.co/TheBloke/WizardLM-30B-Uncensored-GPTQ/discussions/13

contains_question: yes

question_part: Is there some way of sharding this model to my two GPUs?