## https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GPTQ/discussions/2

contains_question: yes

question_part: However, the code is trying to find modelling_flash_llama.py from the togethercomputer repo even though I have the file in the local directory. Since I have no internet on the pc, I just get an error here "Could not locate the modelling_flash_llama.py inside togethercomputer//LLaMA-2-7B-32K. Is there any way to work around this