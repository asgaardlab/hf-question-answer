## https://huggingface.co/Vulkane/120-Days-of-Sodom-LoRA-Mistral-7b/discussions/1

contains_question: yes

question_part: So I get a ton of errors when I try to train CPU only on ez trainer, even though I have a correctly formatted json file. Any tips for how one might get into training on the shallow end? Trynna get a dataset I've made into trained into Synthia7b 1.3  (the mistral version of Synthia).  Fully merged, no lora adapter. It's long format stories broken into 140 chunks. Tough to work out if you aren't a python fellow! All this stuff reminds me of writing batch files. Wish ML was easier lol!