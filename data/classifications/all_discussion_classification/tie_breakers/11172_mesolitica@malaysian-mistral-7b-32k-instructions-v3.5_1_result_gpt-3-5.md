## https://huggingface.co/mesolitica/malaysian-mistral-7b-32k-instructions-v3.5/discussions/1

contains_question: yes
question_part: Hi, I'm trying to quantize this model with llama.cpp but it complains that tokenizer.model is missing so I took the file from https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2. Would this negatively affect anything?