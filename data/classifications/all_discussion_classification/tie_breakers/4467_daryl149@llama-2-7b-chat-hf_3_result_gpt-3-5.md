## https://huggingface.co/daryl149/llama-2-7b-chat-hf/discussions/3

contains_question: yes

question_part: when printing 'tokenizer.model_max_length', I got a number like '1000000000000000019884624838656'. the model_max_length is supposed to be 4k? Not sure where this behavior stems from.