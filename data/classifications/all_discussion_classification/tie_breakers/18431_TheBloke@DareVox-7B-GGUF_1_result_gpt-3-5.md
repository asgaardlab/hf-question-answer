## https://huggingface.co/TheBloke/DareVox-7B-GGUF/discussions/1

contains_question: yes
question_part: Please add at least one example for function calling in llama-cpp-python and at least one example for function calling when model is being hosted through end point (ollama or llama cpp server or kobold etc).