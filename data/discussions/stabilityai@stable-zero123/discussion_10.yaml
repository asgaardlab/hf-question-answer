!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JPJ2
conflicting_files: null
created_at: 2024-01-09 00:32:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6370f29a91284164d1b3ee85/hLOEPawlnpPVh3z_ibNrO.png?w=200&h=200&f=face
      fullname: MyWhyAI
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JPJ2
      type: user
    createdAt: '2024-01-09T00:32:52.000Z'
    data:
      edited: true
      editors:
      - JPJ2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9840943217277527
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6370f29a91284164d1b3ee85/hLOEPawlnpPVh3z_ibNrO.png?w=200&h=200&f=face
          fullname: MyWhyAI
          isHf: false
          isPro: false
          name: JPJ2
          type: user
        html: '<p>I''ve tried out Stable-zero123 model to generate 3d models and it''s
          terribly slow. The fastest speeds I got are .22it/s. Trying a similar model
          called Magic123 runs at around 25it/s. Why is there such a big difference?
          </p>

          <p>Edit*:<br>You can get it to run quickly by changing the batch size to
          [4, 2, 1]. Here is a video I made showing you how to install it.<br><a rel="nofollow"
          href="https://www.youtube.com/watch?v=jaRr5W80N8E">https://www.youtube.com/watch?v=jaRr5W80N8E</a></p>

          '
        raw: "I've tried out Stable-zero123 model to generate 3d models and it's terribly\
          \ slow. The fastest speeds I got are .22it/s. Trying a similar model called\
          \ Magic123 runs at around 25it/s. Why is there such a big difference? \n\
          \nEdit*:\nYou can get it to run quickly by changing the batch size to [4,\
          \ 2, 1]. Here is a video I made showing you how to install it.\nhttps://www.youtube.com/watch?v=jaRr5W80N8E"
        updatedAt: '2024-01-14T15:25:21.574Z'
      numEdits: 1
      reactions: []
    id: 659c94342a539c20c082b52a
    type: comment
  author: JPJ2
  content: "I've tried out Stable-zero123 model to generate 3d models and it's terribly\
    \ slow. The fastest speeds I got are .22it/s. Trying a similar model called Magic123\
    \ runs at around 25it/s. Why is there such a big difference? \n\nEdit*:\nYou can\
    \ get it to run quickly by changing the batch size to [4, 2, 1]. Here is a video\
    \ I made showing you how to install it.\nhttps://www.youtube.com/watch?v=jaRr5W80N8E"
  created_at: 2024-01-09 00:32:52+00:00
  edited: true
  hidden: false
  id: 659c94342a539c20c082b52a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6370f29a91284164d1b3ee85/hLOEPawlnpPVh3z_ibNrO.png?w=200&h=200&f=face
      fullname: MyWhyAI
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JPJ2
      type: user
    createdAt: '2024-01-14T15:31:35.000Z'
    data:
      status: closed
    id: 65a3fe57cb2c2799ac0845ad
    type: status-change
  author: JPJ2
  created_at: 2024-01-14 15:31:35+00:00
  id: 65a3fe57cb2c2799ac0845ad
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: stabilityai/stable-zero123
repo_type: model
status: closed
target_branch: null
title: Slow with RTX 4090 cards using WSL any fix?
