!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gsarti
conflicting_files: null
created_at: 2022-11-30 14:45:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670231290373-5e7749883d77a72421292d07.jpeg?w=200&h=200&f=face
      fullname: Gabriele Sarti
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gsarti
      type: user
    createdAt: '2022-11-30T14:45:00.000Z'
    data:
      edited: false
      editors:
      - gsarti
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670231290373-5e7749883d77a72421292d07.jpeg?w=200&h=200&f=face
          fullname: Gabriele Sarti
          isHf: false
          isPro: false
          name: gsarti
          type: user
        html: '<p>Hi,</p>

          <p>I am trying to use the model but as reported <a rel="nofollow" href="https://github.com/alirezamshi/small100/issues/1">in
          the Github repo</a> currently the <code>max_length</code> is set to 20 by
          default. Would it be possible to add a more lenient default limit (e.g.
          128 tokens), and maybe also the <code>num_beams = 5</code> used in the paper
          to the model config for default usage?</p>

          <p>Thanks in advance!</p>

          '
        raw: "Hi,\r\n\r\nI am trying to use the model but as reported [in the Github\
          \ repo](https://github.com/alirezamshi/small100/issues/1) currently the\
          \ `max_length` is set to 20 by default. Would it be possible to add a more\
          \ lenient default limit (e.g. 128 tokens), and maybe also the `num_beams\
          \ = 5` used in the paper to the model config for default usage?\r\n\r\n\
          Thanks in advance!"
        updatedAt: '2022-11-30T14:45:00.642Z'
      numEdits: 0
      reactions: []
    id: 63876c6c23da90491eba2130
    type: comment
  author: gsarti
  content: "Hi,\r\n\r\nI am trying to use the model but as reported [in the Github\
    \ repo](https://github.com/alirezamshi/small100/issues/1) currently the `max_length`\
    \ is set to 20 by default. Would it be possible to add a more lenient default\
    \ limit (e.g. 128 tokens), and maybe also the `num_beams = 5` used in the paper\
    \ to the model config for default usage?\r\n\r\nThanks in advance!"
  created_at: 2022-11-30 14:45:00+00:00
  edited: false
  hidden: false
  id: 63876c6c23da90491eba2130
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667394938142-63615355a46f0cdd62e707f5.png?w=200&h=200&f=face
      fullname: Alireza Mohammadshahi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: alirezamsh
      type: user
    createdAt: '2022-11-30T15:46:05.000Z'
    data:
      edited: false
      editors:
      - alirezamsh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667394938142-63615355a46f0cdd62e707f5.png?w=200&h=200&f=face
          fullname: Alireza Mohammadshahi
          isHf: false
          isPro: false
          name: alirezamsh
          type: user
        html: '<p>Hi,</p>

          <p>Thanks for your message and concern. I updated the model card to include
          our default generation config. We use beam size of 5 and maximum target
          length of 256 tokens.</p>

          <p>Please let me know if you have further concerns!</p>

          <p>Best,<br>Alireza</p>

          '
        raw: 'Hi,


          Thanks for your message and concern. I updated the model card to include
          our default generation config. We use beam size of 5 and maximum target
          length of 256 tokens.


          Please let me know if you have further concerns!


          Best,

          Alireza'
        updatedAt: '2022-11-30T15:46:05.132Z'
      numEdits: 0
      reactions: []
    id: 63877abda616fb0ef6d93ded
    type: comment
  author: alirezamsh
  content: 'Hi,


    Thanks for your message and concern. I updated the model card to include our default
    generation config. We use beam size of 5 and maximum target length of 256 tokens.


    Please let me know if you have further concerns!


    Best,

    Alireza'
  created_at: 2022-11-30 15:46:05+00:00
  edited: false
  hidden: false
  id: 63877abda616fb0ef6d93ded
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670231290373-5e7749883d77a72421292d07.jpeg?w=200&h=200&f=face
      fullname: Gabriele Sarti
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gsarti
      type: user
    createdAt: '2022-12-01T08:03:35.000Z'
    data:
      edited: false
      editors:
      - gsarti
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670231290373-5e7749883d77a72421292d07.jpeg?w=200&h=200&f=face
          fullname: Gabriele Sarti
          isHf: false
          isPro: false
          name: gsarti
          type: user
        html: '<p>Thank you for your answer! Wouldn''t it be more practical to have
          these as defaults in the <code>config.json</code> file?</p>

          '
        raw: Thank you for your answer! Wouldn't it be more practical to have these
          as defaults in the `config.json` file?
        updatedAt: '2022-12-01T08:03:35.559Z'
      numEdits: 0
      reactions: []
    id: 63885fd72f5ae2fc12e6829d
    type: comment
  author: gsarti
  content: Thank you for your answer! Wouldn't it be more practical to have these
    as defaults in the `config.json` file?
  created_at: 2022-12-01 08:03:35+00:00
  edited: false
  hidden: false
  id: 63885fd72f5ae2fc12e6829d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667394938142-63615355a46f0cdd62e707f5.png?w=200&h=200&f=face
      fullname: Alireza Mohammadshahi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: alirezamsh
      type: user
    createdAt: '2022-12-01T08:49:45.000Z'
    data:
      edited: true
      editors:
      - alirezamsh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667394938142-63615355a46f0cdd62e707f5.png?w=200&h=200&f=face
          fullname: Alireza Mohammadshahi
          isHf: false
          isPro: false
          name: alirezamsh
          type: user
        html: '<p>Sure. Added. Thanks for your message.</p>

          '
        raw: Sure. Added. Thanks for your message.
        updatedAt: '2022-12-01T09:18:27.120Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - gsarti
    id: 63886aa9ea62800e28314ca0
    type: comment
  author: alirezamsh
  content: Sure. Added. Thanks for your message.
  created_at: 2022-12-01 08:49:45+00:00
  edited: true
  hidden: false
  id: 63886aa9ea62800e28314ca0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667394938142-63615355a46f0cdd62e707f5.png?w=200&h=200&f=face
      fullname: Alireza Mohammadshahi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: alirezamsh
      type: user
    createdAt: '2022-12-01T15:15:52.000Z'
    data:
      edited: false
      editors:
      - alirezamsh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667394938142-63615355a46f0cdd62e707f5.png?w=200&h=200&f=face
          fullname: Alireza Mohammadshahi
          isHf: false
          isPro: false
          name: alirezamsh
          type: user
        html: '<p>I am closing the case, please don''t hesitate to open it if you
          have further concerns. Thanks.</p>

          '
        raw: I am closing the case, please don't hesitate to open it if you have further
          concerns. Thanks.
        updatedAt: '2022-12-01T15:15:52.267Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - gsarti
      relatedEventId: 6388c528ec1f539adc098661
    id: 6388c528ec1f539adc098660
    type: comment
  author: alirezamsh
  content: I am closing the case, please don't hesitate to open it if you have further
    concerns. Thanks.
  created_at: 2022-12-01 15:15:52+00:00
  edited: false
  hidden: false
  id: 6388c528ec1f539adc098660
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667394938142-63615355a46f0cdd62e707f5.png?w=200&h=200&f=face
      fullname: Alireza Mohammadshahi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: alirezamsh
      type: user
    createdAt: '2022-12-01T15:15:52.000Z'
    data:
      status: closed
    id: 6388c528ec1f539adc098661
    type: status-change
  author: alirezamsh
  created_at: 2022-12-01 15:15:52+00:00
  id: 6388c528ec1f539adc098661
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: alirezamsh/small100
repo_type: model
status: closed
target_branch: null
title: Match evaluation settings in `config.json`
