!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MoritzLaurer
conflicting_files: null
created_at: 2023-07-10 09:05:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2023-07-10T10:05:13.000Z'
    data:
      edited: false
      editors:
      - MoritzLaurer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9288771748542786
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
          fullname: Moritz Laurer
          isHf: true
          isPro: false
          name: MoritzLaurer
          type: user
        html: '<p>Very interesting model and multi-task learning approach!<br>Which
          datasets were included for training the NLI classification head that is
          used for 0-shot classification? I understand that it is mostly this collection
          <a href="https://huggingface.co/datasets/tasksource/zero-shot-label-nli">https://huggingface.co/datasets/tasksource/zero-shot-label-nli</a>
          ? Was something else included for training the NLI head?<br>Did you use
          a binary head (entailment vs. contradiction+neutral)?</p>

          '
        raw: "Very interesting model and multi-task learning approach!\r\nWhich datasets\
          \ were included for training the NLI classification head that is used for\
          \ 0-shot classification? I understand that it is mostly this collection\
          \ https://huggingface.co/datasets/tasksource/zero-shot-label-nli ? Was something\
          \ else included for training the NLI head?\r\nDid you use a binary head\
          \ (entailment vs. contradiction+neutral)?"
        updatedAt: '2023-07-10T10:05:13.750Z'
      numEdits: 0
      reactions: []
    id: 64abd7d9cfbdb3063b604682
    type: comment
  author: MoritzLaurer
  content: "Very interesting model and multi-task learning approach!\r\nWhich datasets\
    \ were included for training the NLI classification head that is used for 0-shot\
    \ classification? I understand that it is mostly this collection https://huggingface.co/datasets/tasksource/zero-shot-label-nli\
    \ ? Was something else included for training the NLI head?\r\nDid you use a binary\
    \ head (entailment vs. contradiction+neutral)?"
  created_at: 2023-07-10 09:05:13+00:00
  edited: false
  hidden: false
  id: 64abd7d9cfbdb3063b604682
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
      fullname: Damien Sileo
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sileod
      type: user
    createdAt: '2023-07-10T11:35:31.000Z'
    data:
      edited: false
      editors:
      - sileod
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9085004925727844
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
          fullname: Damien Sileo
          isHf: false
          isPro: false
          name: sileod
          type: user
        html: '<p>Hi, thank you! It''s a threeway NLI head<br>I used weight sharing
          for allmost all threeway class, so the backbone+head was trained on dozens
          of NLI datasets (including <code>label-nli</code>)<br>Thus, the checkpoint
          as it is loaded by huggingface can perform zero-shot classification (being
          trained to do so) and standard NLI<br>In addition, using tasknet.load_pipeline,
          you can change the head + a task embedding. By changing the head, you can
          directly predict for a new task (e.g. sentiment analysis). The task embeddings
          helps the model focus on a task. For NLI tasks, even if you don''t change
          the head, you can change the task embedding with tasknet.load_pipeline,
          and make the model a bit more focused for entailment based zero shot NLI,
          for instance.</p>

          '
        raw: 'Hi, thank you! It''s a threeway NLI head

          I used weight sharing for allmost all threeway class, so the backbone+head
          was trained on dozens of NLI datasets (including `label-nli`)

          Thus, the checkpoint as it is loaded by huggingface can perform zero-shot
          classification (being trained to do so) and standard NLI

          In addition, using tasknet.load_pipeline, you can change the head + a task
          embedding. By changing the head, you can directly predict for a new task
          (e.g. sentiment analysis). The task embeddings helps the model focus on
          a task. For NLI tasks, even if you don''t change the head, you can change
          the task embedding with tasknet.load_pipeline, and make the model a bit
          more focused for entailment based zero shot NLI, for instance.'
        updatedAt: '2023-07-10T11:35:31.205Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MoritzLaurer
    id: 64abed03e0194304264afbef
    type: comment
  author: sileod
  content: 'Hi, thank you! It''s a threeway NLI head

    I used weight sharing for allmost all threeway class, so the backbone+head was
    trained on dozens of NLI datasets (including `label-nli`)

    Thus, the checkpoint as it is loaded by huggingface can perform zero-shot classification
    (being trained to do so) and standard NLI

    In addition, using tasknet.load_pipeline, you can change the head + a task embedding.
    By changing the head, you can directly predict for a new task (e.g. sentiment
    analysis). The task embeddings helps the model focus on a task. For NLI tasks,
    even if you don''t change the head, you can change the task embedding with tasknet.load_pipeline,
    and make the model a bit more focused for entailment based zero shot NLI, for
    instance.'
  created_at: 2023-07-10 10:35:31+00:00
  edited: false
  hidden: false
  id: 64abed03e0194304264afbef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2023-07-10T12:06:06.000Z'
    data:
      status: closed
    id: 64abf42ead9d232d9f6d41be
    type: status-change
  author: MoritzLaurer
  created_at: 2023-07-10 11:06:06+00:00
  id: 64abf42ead9d232d9f6d41be
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: sileod/deberta-v3-base-tasksource-nli
repo_type: model
status: closed
target_branch: null
title: Which datasets are included in the NLI training data / NLI head?
