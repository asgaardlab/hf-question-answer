!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nlpsingh
conflicting_files: null
created_at: 2023-08-15 19:53:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5b574366aaf5970f110692bb30122c67.svg
      fullname: Satyen Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nlpsingh
      type: user
    createdAt: '2023-08-15T20:53:06.000Z'
    data:
      edited: false
      editors:
      - nlpsingh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9157000184059143
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5b574366aaf5970f110692bb30122c67.svg
          fullname: Satyen Singh
          isHf: false
          isPro: false
          name: nlpsingh
          type: user
        html: '<p>What are the preprocessing steps used on the data for the inference
          API? I notice different outputs for the same inference I run on my notebook
          vs the api and I was wondering what I could steps I could take to match
          the inference api. FYI, I am using the zero-shot-classification pipeline</p>

          '
        raw: What are the preprocessing steps used on the data for the inference API?
          I notice different outputs for the same inference I run on my notebook vs
          the api and I was wondering what I could steps I could take to match the
          inference api. FYI, I am using the zero-shot-classification pipeline
        updatedAt: '2023-08-15T20:53:06.466Z'
      numEdits: 0
      reactions: []
    id: 64dbe5b2bb090cef55882c42
    type: comment
  author: nlpsingh
  content: What are the preprocessing steps used on the data for the inference API?
    I notice different outputs for the same inference I run on my notebook vs the
    api and I was wondering what I could steps I could take to match the inference
    api. FYI, I am using the zero-shot-classification pipeline
  created_at: 2023-08-15 19:53:06+00:00
  edited: false
  hidden: false
  id: 64dbe5b2bb090cef55882c42
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
      fullname: Damien Sileo
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sileod
      type: user
    createdAt: '2023-08-15T21:20:26.000Z'
    data:
      edited: false
      editors:
      - sileod
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9723743796348572
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
          fullname: Damien Sileo
          isHf: false
          isPro: false
          name: sileod
          type: user
        html: '<p>Hi, is the difference significant ? I don''t know what is under
          the hood of the hosted API, I expect it be the standard zero shot pipeline.
          Perhaps they apply some kind of quantization.<br>I''ll also check if there
          is a difference on other models or if it''s just me</p>

          '
        raw: 'Hi, is the difference significant ? I don''t know what is under the
          hood of the hosted API, I expect it be the standard zero shot pipeline.
          Perhaps they apply some kind of quantization.

          I''ll also check if there is a difference on other models or if it''s just
          me'
        updatedAt: '2023-08-15T21:20:26.990Z'
      numEdits: 0
      reactions: []
    id: 64dbec1a3764a5137e8cd554
    type: comment
  author: sileod
  content: 'Hi, is the difference significant ? I don''t know what is under the hood
    of the hosted API, I expect it be the standard zero shot pipeline. Perhaps they
    apply some kind of quantization.

    I''ll also check if there is a difference on other models or if it''s just me'
  created_at: 2023-08-15 20:20:26+00:00
  edited: false
  hidden: false
  id: 64dbec1a3764a5137e8cd554
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5b574366aaf5970f110692bb30122c67.svg
      fullname: Satyen Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nlpsingh
      type: user
    createdAt: '2023-08-15T21:28:29.000Z'
    data:
      edited: false
      editors:
      - nlpsingh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8670719265937805
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5b574366aaf5970f110692bb30122c67.svg
          fullname: Satyen Singh
          isHf: false
          isPro: false
          name: nlpsingh
          type: user
        html: '<p>For some instances, the difference is significant. The inference
          api correctly marks the answer as the top choice whereas when I run the
          pipeline on my end, it is one of the least probable choices. </p>

          '
        raw: 'For some instances, the difference is significant. The inference api
          correctly marks the answer as the top choice whereas when I run the pipeline
          on my end, it is one of the least probable choices. '
        updatedAt: '2023-08-15T21:28:29.938Z'
      numEdits: 0
      reactions: []
    id: 64dbedfda34448aee686eef3
    type: comment
  author: nlpsingh
  content: 'For some instances, the difference is significant. The inference api correctly
    marks the answer as the top choice whereas when I run the pipeline on my end,
    it is one of the least probable choices. '
  created_at: 2023-08-15 20:28:29+00:00
  edited: false
  hidden: false
  id: 64dbedfda34448aee686eef3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: sileod/deberta-v3-base-tasksource-nli
repo_type: model
status: open
target_branch: null
title: Different results than  Inference API
