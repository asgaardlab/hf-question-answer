!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zokica
conflicting_files: null
created_at: 2023-04-15 15:41:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
      fullname: Zoran
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zokica
      type: user
    createdAt: '2023-04-15T16:41:52.000Z'
    data:
      edited: true
      editors:
      - zokica
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
          fullname: Zoran
          isHf: false
          isPro: false
          name: zokica
          type: user
        html: "<p>I Tried to calculate cola as described here (<a href=\"https://huggingface.co/sileod/deberta-v3-base-tasksource-adapters\"\
          >https://huggingface.co/sileod/deberta-v3-base-tasksource-adapters</a>),\
          \ but it does not work at all</p>\n<p>I get error:</p>\n<p>reshaped_logits\
          \ = logits.view(-1, num_choices)<br>RuntimeError: shape '[-1, 6]' is invalid\
          \ for input of size 4</p>\n<p>#############################################################<br>##############################################################<br>from\
          \ tasknet import Adapter<br>from transformers import AutoModelForMultipleChoice,AutoTokenizer</p>\n\
          <p>model_name=\"sileod/deberta-v3-base-tasksource-nli\"<br>tokenizer3 =\
          \ AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")<br>model3\
          \ = AutoModelForMultipleChoice.from_pretrained(model_name,ignore_mismatched_sizes=True,\
          \ cache_dir=\"/root/Desktop/models/\", low_cpu_mem_usage=True)<br>adapter\
          \ = Adapter.from_pretrained(model_name.replace('nli','adapters'))<br>model_for_rlhf\
          \ = adapter.adapt_model_to_task(model3, 'glue/cola') #glue/cola  #hh-rlhf</p>\n\
          <p>if 1==1:<br>    def cola(sentences1):<br>        import torch<br>   \
          \     import time<br>        beg = time.time()<br>        inputs = tokenizer3(sentences1,\
          \ return_tensors=\"pt\", padding=True, truncation=True, max_length=40).to(\"\
          cpu\")<br>        with torch.no_grad():<br>            outputs = model_for_rlhf(**inputs)</p>\n\
          <pre><code>    the_cola_scores = []\n    print(\"outputs.logits\",outputs.logits)\n\
          \    for aout in outputs.logits:\n        cola_prediction = torch.nn.functional.softmax(aout)[1].item()\n\
          \        the_cola_scores.append(round(cola_prediction,2))\n    \n    if\
          \ 1==1:\n        try: del cola_prediction\n        except:pass    \n   \
          \ \n    return the_cola_scores\n</code></pre>\n<p>import time<br>timea =\
          \ time.time<br>sentences1 = [\"I likes apples\",\"I love apples.\"]<br>cola\
          \ = cola(sentences1)<br>print(cola,timea - time.time )<br>####################################################<br>####################################################</p>\n"
        raw: "I Tried to calculate cola as described here (https://huggingface.co/sileod/deberta-v3-base-tasksource-adapters),\
          \ but it does not work at all\n\nI get error:\n\nreshaped_logits = logits.view(-1,\
          \ num_choices)\nRuntimeError: shape '[-1, 6]' is invalid for input of size\
          \ 4\n\n#############################################################\n##############################################################\n\
          from tasknet import Adapter\nfrom transformers import AutoModelForMultipleChoice,AutoTokenizer\n\
          \nmodel_name=\"sileod/deberta-v3-base-tasksource-nli\" \ntokenizer3 = AutoTokenizer.from_pretrained(\"\
          microsoft/deberta-v3-base\")\nmodel3 = AutoModelForMultipleChoice.from_pretrained(model_name,ignore_mismatched_sizes=True,\
          \ cache_dir=\"/root/Desktop/models/\", low_cpu_mem_usage=True)\nadapter\
          \ = Adapter.from_pretrained(model_name.replace('nli','adapters'))\nmodel_for_rlhf\
          \ = adapter.adapt_model_to_task(model3, 'glue/cola') #glue/cola  #hh-rlhf\n\
          \n\n\nif 1==1:\n    def cola(sentences1):\n        import torch\n      \
          \  import time\n        beg = time.time()\n        inputs = tokenizer3(sentences1,\
          \ return_tensors=\"pt\", padding=True, truncation=True, max_length=40).to(\"\
          cpu\")\n        with torch.no_grad():\n            outputs = model_for_rlhf(**inputs)\n\
          \    \n        the_cola_scores = []\n        print(\"outputs.logits\",outputs.logits)\n\
          \        for aout in outputs.logits:\n            cola_prediction = torch.nn.functional.softmax(aout)[1].item()\n\
          \            the_cola_scores.append(round(cola_prediction,2))\n        \n\
          \        if 1==1:\n            try: del cola_prediction\n            except:pass\
          \    \n        \n        return the_cola_scores\n\nimport time  \ntimea\
          \ = time.time  \nsentences1 = [\"I likes apples\",\"I love apples.\"]  \
          \  \ncola = cola(sentences1)    \nprint(cola,timea - time.time )  \n####################################################\n\
          ####################################################"
        updatedAt: '2023-04-15T16:49:57.710Z'
      numEdits: 1
      reactions: []
    id: 643ad3d0fe6d02a5a2e51405
    type: comment
  author: zokica
  content: "I Tried to calculate cola as described here (https://huggingface.co/sileod/deberta-v3-base-tasksource-adapters),\
    \ but it does not work at all\n\nI get error:\n\nreshaped_logits = logits.view(-1,\
    \ num_choices)\nRuntimeError: shape '[-1, 6]' is invalid for input of size 4\n\
    \n#############################################################\n##############################################################\n\
    from tasknet import Adapter\nfrom transformers import AutoModelForMultipleChoice,AutoTokenizer\n\
    \nmodel_name=\"sileod/deberta-v3-base-tasksource-nli\" \ntokenizer3 = AutoTokenizer.from_pretrained(\"\
    microsoft/deberta-v3-base\")\nmodel3 = AutoModelForMultipleChoice.from_pretrained(model_name,ignore_mismatched_sizes=True,\
    \ cache_dir=\"/root/Desktop/models/\", low_cpu_mem_usage=True)\nadapter = Adapter.from_pretrained(model_name.replace('nli','adapters'))\n\
    model_for_rlhf = adapter.adapt_model_to_task(model3, 'glue/cola') #glue/cola \
    \ #hh-rlhf\n\n\n\nif 1==1:\n    def cola(sentences1):\n        import torch\n\
    \        import time\n        beg = time.time()\n        inputs = tokenizer3(sentences1,\
    \ return_tensors=\"pt\", padding=True, truncation=True, max_length=40).to(\"cpu\"\
    )\n        with torch.no_grad():\n            outputs = model_for_rlhf(**inputs)\n\
    \    \n        the_cola_scores = []\n        print(\"outputs.logits\",outputs.logits)\n\
    \        for aout in outputs.logits:\n            cola_prediction = torch.nn.functional.softmax(aout)[1].item()\n\
    \            the_cola_scores.append(round(cola_prediction,2))\n        \n    \
    \    if 1==1:\n            try: del cola_prediction\n            except:pass \
    \   \n        \n        return the_cola_scores\n\nimport time  \ntimea = time.time\
    \  \nsentences1 = [\"I likes apples\",\"I love apples.\"]    \ncola = cola(sentences1)\
    \    \nprint(cola,timea - time.time )  \n####################################################\n\
    ####################################################"
  created_at: 2023-04-15 15:41:52+00:00
  edited: true
  hidden: false
  id: 643ad3d0fe6d02a5a2e51405
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
      fullname: Damien Sileo
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sileod
      type: user
    createdAt: '2023-04-15T17:05:15.000Z'
    data:
      edited: false
      editors:
      - sileod
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
          fullname: Damien Sileo
          isHf: false
          isPro: false
          name: sileod
          type: user
        html: '<p>Hi!<br>For cola, you have to use auto model for sequence classification.</p>

          '
        raw: 'Hi!

          For cola, you have to use auto model for sequence classification.'
        updatedAt: '2023-04-15T17:05:15.894Z'
      numEdits: 0
      reactions: []
    id: 643ad94b1f1627233570cd49
    type: comment
  author: sileod
  content: 'Hi!

    For cola, you have to use auto model for sequence classification.'
  created_at: 2023-04-15 16:05:15+00:00
  edited: false
  hidden: false
  id: 643ad94b1f1627233570cd49
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
      fullname: Zoran
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zokica
      type: user
    createdAt: '2023-04-15T17:46:14.000Z'
    data:
      edited: true
      editors:
      - zokica
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
          fullname: Zoran
          isHf: false
          isPro: false
          name: zokica
          type: user
        html: '<p>Hi, thanks, it work when I use   model3 = AutoModelForSequenceClassification.from_pretrained(</p>

          <p>However results are pretty bad, not sure why:<br>sentences1 = ["I was
          there because I like apples.","I are there because i loves apples."]<br>[0.59,
          0.65]</p>

          <p>So it comes out as if second sentence is better than the first one. I
          checked other models and probability for second sentence is low around 0.5
          while the first should be around 0.99.<br>Logits are (first and second sentence)
          outputs.logits tensor([[ 0.0077,  0.3910],<br>        [-0.1509,  0.4893]])</p>

          '
        raw: "Hi, thanks, it work when I use   model3 = AutoModelForSequenceClassification.from_pretrained(\n\
          \nHowever results are pretty bad, not sure why:\nsentences1 = [\"I was there\
          \ because I like apples.\",\"I are there because i loves apples.\"] \n[0.59,\
          \ 0.65]\n\nSo it comes out as if second sentence is better than the first\
          \ one. I checked other models and probability for second sentence is low\
          \ around 0.5 while the first should be around 0.99.\nLogits are (first and\
          \ second sentence) outputs.logits tensor([[ 0.0077,  0.3910],\n        [-0.1509,\
          \  0.4893]])"
        updatedAt: '2023-04-15T17:55:12.708Z'
      numEdits: 2
      reactions: []
    id: 643ae2e69462a44ea6e9bb81
    type: comment
  author: zokica
  content: "Hi, thanks, it work when I use   model3 = AutoModelForSequenceClassification.from_pretrained(\n\
    \nHowever results are pretty bad, not sure why:\nsentences1 = [\"I was there because\
    \ I like apples.\",\"I are there because i loves apples.\"] \n[0.59, 0.65]\n\n\
    So it comes out as if second sentence is better than the first one. I checked\
    \ other models and probability for second sentence is low around 0.5 while the\
    \ first should be around 0.99.\nLogits are (first and second sentence) outputs.logits\
    \ tensor([[ 0.0077,  0.3910],\n        [-0.1509,  0.4893]])"
  created_at: 2023-04-15 16:46:14+00:00
  edited: true
  hidden: false
  id: 643ae2e69462a44ea6e9bb81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
      fullname: Damien Sileo
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sileod
      type: user
    createdAt: '2023-04-15T18:14:16.000Z'
    data:
      edited: false
      editors:
      - sileod
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
          fullname: Damien Sileo
          isHf: false
          isPro: false
          name: sileod
          type: user
        html: "<p>It is possible that cola was undertrained. There are 500 tasks and\
          \ cola is relatively small (8k samples).<br>I am currently running much\
          \ longer tasksource pretraining. But it could also due failure in the tasknet\
          \ code to load the adapter. I'll look into it monday and I'll get back to\
          \ you</p>\n<p>PS: I advise you to use pipeline to do what you do.</p>\n\
          <pre><code># !pip install tasknet\nfrom tasknet import Adapter\nfrom transformers\
          \ import AutoModelForMultipleChoice, AutoModelForSequenceClassification,\
          \ TextClassificationPipeline, AutoTokenizer\n\nmodel_name=\"sileod/deberta-v3-base-tasksource-nli\"\
          \nmodel = AutoModelForSequenceClassification.from_pretrained(model_name,ignore_mismatched_sizes=True)\n\
          adapter = Adapter.from_pretrained(model_name.replace('nli','adapters'))\n\
          model = adapter.adapt_model_to_task(model, 'glue/cola')\n\npipe = TextClassificationPipeline(\n\
          \    model=model,\n    tokenizer=AutoTokenizer.from_pretrained(model_name))\n\
          pipe([\"We yelled ourselves.\",\"We yelled ourselves hoarse.\"])\n</code></pre>\n"
        raw: "It is possible that cola was undertrained. There are 500 tasks and cola\
          \ is relatively small (8k samples).\nI am currently running much longer\
          \ tasksource pretraining. But it could also due failure in the tasknet code\
          \ to load the adapter. I'll look into it monday and I'll get back to you\n\
          \nPS: I advise you to use pipeline to do what you do.\n\n```\n# !pip install\
          \ tasknet\nfrom tasknet import Adapter\nfrom transformers import AutoModelForMultipleChoice,\
          \ AutoModelForSequenceClassification, TextClassificationPipeline, AutoTokenizer\n\
          \nmodel_name=\"sileod/deberta-v3-base-tasksource-nli\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name,ignore_mismatched_sizes=True)\n\
          adapter = Adapter.from_pretrained(model_name.replace('nli','adapters'))\n\
          model = adapter.adapt_model_to_task(model, 'glue/cola')\n\npipe = TextClassificationPipeline(\n\
          \    model=model,\n    tokenizer=AutoTokenizer.from_pretrained(model_name))\n\
          pipe([\"We yelled ourselves.\",\"We yelled ourselves hoarse.\"])\n```"
        updatedAt: '2023-04-15T18:14:16.103Z'
      numEdits: 0
      reactions: []
    id: 643ae9781f162723357129fc
    type: comment
  author: sileod
  content: "It is possible that cola was undertrained. There are 500 tasks and cola\
    \ is relatively small (8k samples).\nI am currently running much longer tasksource\
    \ pretraining. But it could also due failure in the tasknet code to load the adapter.\
    \ I'll look into it monday and I'll get back to you\n\nPS: I advise you to use\
    \ pipeline to do what you do.\n\n```\n# !pip install tasknet\nfrom tasknet import\
    \ Adapter\nfrom transformers import AutoModelForMultipleChoice, AutoModelForSequenceClassification,\
    \ TextClassificationPipeline, AutoTokenizer\n\nmodel_name=\"sileod/deberta-v3-base-tasksource-nli\"\
    \nmodel = AutoModelForSequenceClassification.from_pretrained(model_name,ignore_mismatched_sizes=True)\n\
    adapter = Adapter.from_pretrained(model_name.replace('nli','adapters'))\nmodel\
    \ = adapter.adapt_model_to_task(model, 'glue/cola')\n\npipe = TextClassificationPipeline(\n\
    \    model=model,\n    tokenizer=AutoTokenizer.from_pretrained(model_name))\n\
    pipe([\"We yelled ourselves.\",\"We yelled ourselves hoarse.\"])\n```"
  created_at: 2023-04-15 17:14:16+00:00
  edited: false
  hidden: false
  id: 643ae9781f162723357129fc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
      fullname: Zoran
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zokica
      type: user
    createdAt: '2023-04-15T18:27:33.000Z'
    data:
      edited: true
      editors:
      - zokica
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
          fullname: Zoran
          isHf: false
          isPro: false
          name: zokica
          type: user
        html: '<p>Ok, thanks very much for the fast answer. I think this model should
          be state of the art for Cola, all models are trained on just this dataset
          so it should be sufficient data. </p>

          <p>What is strange is that I get the same result with  adapter model and
          model without  using the adapt_model_to_task. However, when replaced ''glue/cola''
          with other task it gave different output.</p>

          <p>I tried the pipeline, it yields the same result.</p>

          '
        raw: "Ok, thanks very much for the fast answer. I think this model should\
          \ be state of the art for Cola, all models are trained on just this dataset\
          \ so it should be sufficient data. \n\nWhat is strange is that I get the\
          \ same result with  adapter model and model without  using the adapt_model_to_task.\
          \ However, when replaced 'glue/cola' with other task it gave different output.\n\
          \nI tried the pipeline, it yields the same result."
        updatedAt: '2023-04-15T18:28:07.075Z'
      numEdits: 1
      reactions: []
    id: 643aec9518e9973bc821597a
    type: comment
  author: zokica
  content: "Ok, thanks very much for the fast answer. I think this model should be\
    \ state of the art for Cola, all models are trained on just this dataset so it\
    \ should be sufficient data. \n\nWhat is strange is that I get the same result\
    \ with  adapter model and model without  using the adapt_model_to_task. However,\
    \ when replaced 'glue/cola' with other task it gave different output.\n\nI tried\
    \ the pipeline, it yields the same result."
  created_at: 2023-04-15 17:27:33+00:00
  edited: true
  hidden: false
  id: 643aec9518e9973bc821597a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
      fullname: Damien Sileo
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sileod
      type: user
    createdAt: '2023-04-15T18:33:54.000Z'
    data:
      edited: false
      editors:
      - sileod
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
          fullname: Damien Sileo
          isHf: false
          isPro: false
          name: sileod
          type: user
        html: '<p>I think that FINE-TUNING this model on cola will lead to state of
          the art (for base-size)<br>You can see that it is ranked first on cola  <a
          rel="nofollow" href="https://ibm.github.io/model-recycling/microsoft_deberta-v3-base_table">https://ibm.github.io/model-recycling/microsoft_deberta-v3-base_table</a></p>

          <p>At the current state, it should have good results but not better than
          a model that is fine-tuned, deberta-v3-base-tasksource is currently trained
          for less than one epoch, as multi-task training is way longer.</p>

          '
        raw: 'I think that FINE-TUNING this model on cola will lead to state of the
          art (for base-size)

          You can see that it is ranked first on cola  https://ibm.github.io/model-recycling/microsoft_deberta-v3-base_table


          At the current state, it should have good results but not better than a
          model that is fine-tuned, deberta-v3-base-tasksource is currently trained
          for less than one epoch, as multi-task training is way longer.'
        updatedAt: '2023-04-15T18:33:54.953Z'
      numEdits: 0
      reactions: []
    id: 643aee1218e9973bc8216480
    type: comment
  author: sileod
  content: 'I think that FINE-TUNING this model on cola will lead to state of the
    art (for base-size)

    You can see that it is ranked first on cola  https://ibm.github.io/model-recycling/microsoft_deberta-v3-base_table


    At the current state, it should have good results but not better than a model
    that is fine-tuned, deberta-v3-base-tasksource is currently trained for less than
    one epoch, as multi-task training is way longer.'
  created_at: 2023-04-15 17:33:54+00:00
  edited: false
  hidden: false
  id: 643aee1218e9973bc8216480
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
      fullname: Zoran
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zokica
      type: user
    createdAt: '2023-04-17T18:30:57.000Z'
    data:
      edited: false
      editors:
      - zokica
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
          fullname: Zoran
          isHf: false
          isPro: false
          name: zokica
          type: user
        html: '<p>Yes, deberta is beter even than roberta</p>

          '
        raw: Yes, deberta is beter even than roberta
        updatedAt: '2023-04-17T18:30:57.331Z'
      numEdits: 0
      reactions: []
    id: 643d906151e2958ef6cd9105
    type: comment
  author: zokica
  content: Yes, deberta is beter even than roberta
  created_at: 2023-04-17 17:30:57+00:00
  edited: false
  hidden: false
  id: 643d906151e2958ef6cd9105
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
      fullname: Damien Sileo
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sileod
      type: user
    createdAt: '2023-04-21T13:59:59.000Z'
    data:
      edited: true
      editors:
      - sileod
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
          fullname: Damien Sileo
          isHf: false
          isPro: false
          name: sileod
          type: user
        html: '<p>Hi.<br>There was a problem with the adapters.<br>The poolers were
          not shared during the multi-task training. They should have been included
          in the adapter. I am re-running the training from scratch (with more tasks
          as well) with a single pooler.<br>There will be a new version in a week,
          and pipeline loading  will be much cleaner.</p>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          tasknet <span class="hljs-keyword">import</span> load_pipeline

          pipeline = load_pipeline(model_name, task_name)

          <span class="hljs-built_in">print</span>(pipeline.model, pipeline(<span
          class="hljs-string">''example to test''</span>))

          </code></pre>

          '
        raw: 'Hi.

          There was a problem with the adapters.

          The poolers were not shared during the multi-task training. They should
          have been included in the adapter. I am re-running the training from scratch
          (with more tasks as well) with a single pooler.

          There will be a new version in a week, and pipeline loading  will be much
          cleaner.

          ```python

          from tasknet import load_pipeline

          pipeline = load_pipeline(model_name, task_name)

          print(pipeline.model, pipeline(''example to test''))

          ```'
        updatedAt: '2023-04-21T14:20:30.495Z'
      numEdits: 2
      reactions: []
    id: 644296df8569978432f777df
    type: comment
  author: sileod
  content: 'Hi.

    There was a problem with the adapters.

    The poolers were not shared during the multi-task training. They should have been
    included in the adapter. I am re-running the training from scratch (with more
    tasks as well) with a single pooler.

    There will be a new version in a week, and pipeline loading  will be much cleaner.

    ```python

    from tasknet import load_pipeline

    pipeline = load_pipeline(model_name, task_name)

    print(pipeline.model, pipeline(''example to test''))

    ```'
  created_at: 2023-04-21 12:59:59+00:00
  edited: true
  hidden: false
  id: 644296df8569978432f777df
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
      fullname: Zoran
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zokica
      type: user
    createdAt: '2023-04-21T18:35:33.000Z'
    data:
      edited: false
      editors:
      - zokica
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
          fullname: Zoran
          isHf: false
          isPro: false
          name: zokica
          type: user
        html: '<p>Awesome, thanks.</p>

          '
        raw: Awesome, thanks.
        updatedAt: '2023-04-21T18:35:33.062Z'
      numEdits: 0
      reactions: []
    id: 6442d7758569978432fc35e2
    type: comment
  author: zokica
  content: Awesome, thanks.
  created_at: 2023-04-21 17:35:33+00:00
  edited: false
  hidden: false
  id: 6442d7758569978432fc35e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9b1a2df9402e9c26e1eb7c818af9bae0.svg
      fullname: Jiwan Chung
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jiwan-chung
      type: user
    createdAt: '2023-04-27T15:24:39.000Z'
    data:
      edited: true
      editors:
      - jiwan-chung
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9b1a2df9402e9c26e1eb7c818af9bae0.svg
          fullname: Jiwan Chung
          isHf: false
          isPro: false
          name: jiwan-chung
          type: user
        html: '<p>I''m looking forward to your update as well :)</p>

          '
        raw: I'm looking forward to your update as well :)
        updatedAt: '2023-04-27T15:24:53.669Z'
      numEdits: 1
      reactions: []
    id: 644a93b7cb45734dfd425cb6
    type: comment
  author: jiwan-chung
  content: I'm looking forward to your update as well :)
  created_at: 2023-04-27 14:24:39+00:00
  edited: true
  hidden: false
  id: 644a93b7cb45734dfd425cb6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
      fullname: Zoran
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zokica
      type: user
    createdAt: '2023-04-27T15:40:07.000Z'
    data:
      edited: false
      editors:
      - zokica
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/821999165e9e61b42c7f989404f5ffdf.svg
          fullname: Zoran
          isHf: false
          isPro: false
          name: zokica
          type: user
        html: '<p>You did the update?</p>

          '
        raw: You did the update?
        updatedAt: '2023-04-27T15:40:07.657Z'
      numEdits: 0
      reactions: []
    id: 644a9757d4483bfaa06b2ad0
    type: comment
  author: zokica
  content: You did the update?
  created_at: 2023-04-27 14:40:07+00:00
  edited: false
  hidden: false
  id: 644a9757d4483bfaa06b2ad0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
      fullname: Damien Sileo
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sileod
      type: user
    createdAt: '2023-07-10T13:51:07.000Z'
    data:
      edited: false
      editors:
      - sileod
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9765568971633911
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
          fullname: Damien Sileo
          isHf: false
          isPro: false
          name: sileod
          type: user
        html: '<p>(It is done)</p>

          '
        raw: (It is done)
        updatedAt: '2023-07-10T13:51:07.745Z'
      numEdits: 0
      reactions: []
    id: 64ac0ccba8ec0fddb73b40e0
    type: comment
  author: sileod
  content: (It is done)
  created_at: 2023-07-10 12:51:07+00:00
  edited: false
  hidden: false
  id: 64ac0ccba8ec0fddb73b40e0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/4d68767d363f7bc5605906c0e994f132.svg
      fullname: Damien Sileo
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sileod
      type: user
    createdAt: '2023-07-10T13:51:10.000Z'
    data:
      status: closed
    id: 64ac0cce2820aaefc8250271
    type: status-change
  author: sileod
  created_at: 2023-07-10 12:51:10+00:00
  id: 64ac0cce2820aaefc8250271
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: sileod/deberta-v3-base-tasksource-nli
repo_type: model
status: closed
target_branch: null
title: Does not work at all, i tried to calculate cola
