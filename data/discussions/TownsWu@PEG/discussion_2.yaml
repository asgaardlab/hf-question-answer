!!python/object:huggingface_hub.community.DiscussionWithDetails
author: evan209
conflicting_files: null
created_at: 2024-01-04 07:15:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4e67ae4f40e083cd477e73c0ecc09834.svg
      fullname: zha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: evan209
      type: user
    createdAt: '2024-01-04T07:15:37.000Z'
    data:
      edited: false
      editors:
      - evan209
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9999942183494568
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4e67ae4f40e083cd477e73c0ecc09834.svg
          fullname: zha
          isHf: false
          isPro: false
          name: evan209
          type: user
        html: "<p>\u914D\u7F6E\u8BE5\u600E\u4E48\u914D\u7F6E\uFF0C\u6709\u6CA1\u6709\
          \u4F7F\u7528\u65B9\u6CD5</p>\n"
        raw: "\u914D\u7F6E\u8BE5\u600E\u4E48\u914D\u7F6E\uFF0C\u6709\u6CA1\u6709\u4F7F\
          \u7528\u65B9\u6CD5"
        updatedAt: '2024-01-04T07:15:37.947Z'
      numEdits: 0
      reactions: []
    id: 65965b196009f96c50c55004
    type: comment
  author: evan209
  content: "\u914D\u7F6E\u8BE5\u600E\u4E48\u914D\u7F6E\uFF0C\u6709\u6CA1\u6709\u4F7F\
    \u7528\u65B9\u6CD5"
  created_at: 2024-01-04 07:15:37+00:00
  edited: false
  hidden: false
  id: 65965b196009f96c50c55004
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/de455e9b10516ff8b951f1609c8b131e.svg
      fullname: tongwu
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: TownsWu
      type: user
    createdAt: '2024-01-04T07:26:14.000Z'
    data:
      edited: true
      editors:
      - TownsWu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2613532245159149
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/de455e9b10516ff8b951f1609c8b131e.svg
          fullname: tongwu
          isHf: false
          isPro: false
          name: TownsWu
          type: user
        html: "<p>\u53EF\u4EE5\u53C2\u8003\u4EE5\u4E0B\u4EE3\u7801</p>\n<p>from pydantic\
          \ import BaseModel, Extra, Field<br>from typing import Any, Dict, List,\
          \ Optional<br>from langchain.embeddings.base import Embeddings<br>import\
          \ torch<br>from tqdm import tqdm<br>import sys<br>import os<br>sys.path.append(os.path.join(os.path.abspath(os.path.dirname(<strong>file</strong>)),\
          \ '..'))</p>\n<p>class HuggingFaceLLMEmbeddings(BaseModel, Embeddings):<br>\
          \    client: Any<br>    tokenizer: Any<br>    client_rerank: Any<br>   \
          \ model_name: str = ''<br>    batch_size: int = 1<br>    trunc_max_length:\
          \ int = 512<br>    mean_token_size: int = 0<br>    cache_folder: Optional[str]\
          \ = None<br>    model_kwargs: Dict[str, Any] = Field(default_factory=dict)<br>\
          \    encode_kwargs: Dict[str, Any] = Field(default_factory=dict)</p>\n<pre><code>def\
          \ __init__(self, model_path='', batch_size=1, trunc_length=512,  **kwargs:\
          \ Any):\n    super().__init__(**kwargs)\n    self.mean_token_size = 0\n\
          \    from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n\
          \    embedding_model_name = model_path\n    self.trunc_max_length = trunc_length\n\
          \    self.batch_size = batch_size\n\n    with torch.no_grad():\n       \
          \ self.tokenizer = AutoTokenizer.from_pretrained(embedding_model_name, trust_remote_code=True)\n\
          \        \n        self.client = AutoModel.from_pretrained(embedding_model_name)\n\
          \     \n        if torch.cuda.is_available():\n            available_gpus\
          \ = [i for i in range(torch.cuda.device_count())]\n            if len(available_gpus)\
          \ == 1:\n                self.client = self.client.cuda()\n            \
          \    self.client_rerank = self.client_rerank.cuda()\n            else:\n\
          \                self.client = torch.nn.DataParallel(self.client, device_ids=available_gpus).cuda()\n\
          \                self.client_rerank = torch.nn.DataParallel(self.client_rerank,\
          \ device_ids=available_gpus).cuda()\n        self.client.eval()\n      \n\
          \nclass Config:\n    \"\"\"Configuration for this pydantic object.\"\"\"\
          \n    extra = Extra.forbid\n\ndef embed_documents(self, texts: List[str],\
          \ use_tqdm=True, use_instruction=False) -&gt; List[List[float]]:\n    embeddings_all\
          \ = []\n    with torch.no_grad():\n        if use_instruction:\n       \
          \     instruction = \"\u4E3A\u8FD9\u4E2A\u53E5\u5B50\u751F\u6210\u8868\u793A\
          \u4EE5\u7528\u4E8E\u68C0\u7D22\u76F8\u5173\u6587\u7AE0\uFF1A\"\n       \
          \ else:\n            instruction = ''\n        texts = list(map(lambda x:\
          \  instruction + x.replace(\"\\n\", \" \"), texts))\n        tbar = tqdm(range(0,\
          \ len(texts), self.batch_size)) if use_tqdm else range(0, len(texts), self.batch_size)\n\
          \        for i in tbar:\n            texts_ = self.tokenizer(texts[i: min(i\
          \ + self.batch_size, len(texts))], truncation=True, max_length=self.trunc_max_length,\
          \ padding=True, return_tensors='pt')\n            if torch.cuda.is_available():\n\
          \                texts_ = texts_.to('cuda')\n            model_output =\
          \ self.client(**texts_)\n            model_output = model_output[0][:, 0]\n\
          \            embeddings = model_output\n            embeddings /= embeddings.norm(dim=-1,\
          \ keepdim=True)\n            embeddings_all.append(embeddings.cpu())\n \
          \   embeddings_all = torch.cat(embeddings_all, dim=0)\n    return embeddings_all.tolist()\n\
          \ndef embed_query(self, texts: List[str], use_tqdm= False) -&gt; List[List[float]]:\n\
          \    #\u5BF9\u4E8Es2p\u4EFB\u52A1\uFF0C\u53EF\u4EE5\u8BBE\u7F6Euse_instruction=True\uFF0C\
          \u5BF9\u4E8Es2s\u4EFB\u52A1, \u53EF\u4EE5\u8BBE\u7F6Euse_instruction=False\n\
          \    embedding = self.embed_documents(texts, use_tqdm=use_tqdm, use_instruction=False)\n\
          \    return embedding\n</code></pre>\n"
        raw: "\u53EF\u4EE5\u53C2\u8003\u4EE5\u4E0B\u4EE3\u7801\n\nfrom pydantic import\
          \ BaseModel, Extra, Field\nfrom typing import Any, Dict, List, Optional\n\
          from langchain.embeddings.base import Embeddings\nimport torch\nfrom tqdm\
          \ import tqdm\nimport sys\nimport os\nsys.path.append(os.path.join(os.path.abspath(os.path.dirname(__file__)),\
          \ '..'))\n\nclass HuggingFaceLLMEmbeddings(BaseModel, Embeddings):\n   \
          \ client: Any\n    tokenizer: Any\n    client_rerank: Any\n    model_name:\
          \ str = ''\n    batch_size: int = 1\n    trunc_max_length: int = 512\n \
          \   mean_token_size: int = 0\n    cache_folder: Optional[str] = None\n \
          \   model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n    encode_kwargs:\
          \ Dict[str, Any] = Field(default_factory=dict)\n\n    def __init__(self,\
          \ model_path='', batch_size=1, trunc_length=512,  **kwargs: Any):\n    \
          \    super().__init__(**kwargs)\n        self.mean_token_size = 0\n    \
          \    from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n\
          \        embedding_model_name = model_path\n        self.trunc_max_length\
          \ = trunc_length\n        self.batch_size = batch_size\n\n        with torch.no_grad():\n\
          \            self.tokenizer = AutoTokenizer.from_pretrained(embedding_model_name,\
          \ trust_remote_code=True)\n            \n            self.client = AutoModel.from_pretrained(embedding_model_name)\n\
          \         \n            if torch.cuda.is_available():\n                available_gpus\
          \ = [i for i in range(torch.cuda.device_count())]\n                if len(available_gpus)\
          \ == 1:\n                    self.client = self.client.cuda()\n        \
          \            self.client_rerank = self.client_rerank.cuda()\n          \
          \      else:\n                    self.client = torch.nn.DataParallel(self.client,\
          \ device_ids=available_gpus).cuda()\n                    self.client_rerank\
          \ = torch.nn.DataParallel(self.client_rerank, device_ids=available_gpus).cuda()\n\
          \            self.client.eval()\n          \n\n    class Config:\n     \
          \   \"\"\"Configuration for this pydantic object.\"\"\"\n        extra =\
          \ Extra.forbid\n\n    def embed_documents(self, texts: List[str], use_tqdm=True,\
          \ use_instruction=False) -> List[List[float]]:\n        embeddings_all =\
          \ []\n        with torch.no_grad():\n            if use_instruction:\n \
          \               instruction = \"\u4E3A\u8FD9\u4E2A\u53E5\u5B50\u751F\u6210\
          \u8868\u793A\u4EE5\u7528\u4E8E\u68C0\u7D22\u76F8\u5173\u6587\u7AE0\uFF1A\
          \"\n            else:\n                instruction = ''\n            texts\
          \ = list(map(lambda x:  instruction + x.replace(\"\\n\", \" \"), texts))\n\
          \            tbar = tqdm(range(0, len(texts), self.batch_size)) if use_tqdm\
          \ else range(0, len(texts), self.batch_size)\n            for i in tbar:\n\
          \                texts_ = self.tokenizer(texts[i: min(i + self.batch_size,\
          \ len(texts))], truncation=True, max_length=self.trunc_max_length, padding=True,\
          \ return_tensors='pt')\n                if torch.cuda.is_available():\n\
          \                    texts_ = texts_.to('cuda')\n                model_output\
          \ = self.client(**texts_)\n                model_output = model_output[0][:,\
          \ 0]\n                embeddings = model_output\n                embeddings\
          \ /= embeddings.norm(dim=-1, keepdim=True)\n                embeddings_all.append(embeddings.cpu())\n\
          \        embeddings_all = torch.cat(embeddings_all, dim=0)\n        return\
          \ embeddings_all.tolist()\n\n    def embed_query(self, texts: List[str],\
          \ use_tqdm= False) -> List[List[float]]:\n        #\u5BF9\u4E8Es2p\u4EFB\
          \u52A1\uFF0C\u53EF\u4EE5\u8BBE\u7F6Euse_instruction=True\uFF0C\u5BF9\u4E8E\
          s2s\u4EFB\u52A1, \u53EF\u4EE5\u8BBE\u7F6Euse_instruction=False\n       \
          \ embedding = self.embed_documents(texts, use_tqdm=use_tqdm, use_instruction=False)\n\
          \        return embedding"
        updatedAt: '2024-01-04T07:31:24.639Z'
      numEdits: 2
      reactions: []
    id: 65965d9646624a86ff41f3a9
    type: comment
  author: TownsWu
  content: "\u53EF\u4EE5\u53C2\u8003\u4EE5\u4E0B\u4EE3\u7801\n\nfrom pydantic import\
    \ BaseModel, Extra, Field\nfrom typing import Any, Dict, List, Optional\nfrom\
    \ langchain.embeddings.base import Embeddings\nimport torch\nfrom tqdm import\
    \ tqdm\nimport sys\nimport os\nsys.path.append(os.path.join(os.path.abspath(os.path.dirname(__file__)),\
    \ '..'))\n\nclass HuggingFaceLLMEmbeddings(BaseModel, Embeddings):\n    client:\
    \ Any\n    tokenizer: Any\n    client_rerank: Any\n    model_name: str = ''\n\
    \    batch_size: int = 1\n    trunc_max_length: int = 512\n    mean_token_size:\
    \ int = 0\n    cache_folder: Optional[str] = None\n    model_kwargs: Dict[str,\
    \ Any] = Field(default_factory=dict)\n    encode_kwargs: Dict[str, Any] = Field(default_factory=dict)\n\
    \n    def __init__(self, model_path='', batch_size=1, trunc_length=512,  **kwargs:\
    \ Any):\n        super().__init__(**kwargs)\n        self.mean_token_size = 0\n\
    \        from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n\
    \        embedding_model_name = model_path\n        self.trunc_max_length = trunc_length\n\
    \        self.batch_size = batch_size\n\n        with torch.no_grad():\n     \
    \       self.tokenizer = AutoTokenizer.from_pretrained(embedding_model_name, trust_remote_code=True)\n\
    \            \n            self.client = AutoModel.from_pretrained(embedding_model_name)\n\
    \         \n            if torch.cuda.is_available():\n                available_gpus\
    \ = [i for i in range(torch.cuda.device_count())]\n                if len(available_gpus)\
    \ == 1:\n                    self.client = self.client.cuda()\n              \
    \      self.client_rerank = self.client_rerank.cuda()\n                else:\n\
    \                    self.client = torch.nn.DataParallel(self.client, device_ids=available_gpus).cuda()\n\
    \                    self.client_rerank = torch.nn.DataParallel(self.client_rerank,\
    \ device_ids=available_gpus).cuda()\n            self.client.eval()\n        \
    \  \n\n    class Config:\n        \"\"\"Configuration for this pydantic object.\"\
    \"\"\n        extra = Extra.forbid\n\n    def embed_documents(self, texts: List[str],\
    \ use_tqdm=True, use_instruction=False) -> List[List[float]]:\n        embeddings_all\
    \ = []\n        with torch.no_grad():\n            if use_instruction:\n     \
    \           instruction = \"\u4E3A\u8FD9\u4E2A\u53E5\u5B50\u751F\u6210\u8868\u793A\
    \u4EE5\u7528\u4E8E\u68C0\u7D22\u76F8\u5173\u6587\u7AE0\uFF1A\"\n            else:\n\
    \                instruction = ''\n            texts = list(map(lambda x:  instruction\
    \ + x.replace(\"\\n\", \" \"), texts))\n            tbar = tqdm(range(0, len(texts),\
    \ self.batch_size)) if use_tqdm else range(0, len(texts), self.batch_size)\n \
    \           for i in tbar:\n                texts_ = self.tokenizer(texts[i: min(i\
    \ + self.batch_size, len(texts))], truncation=True, max_length=self.trunc_max_length,\
    \ padding=True, return_tensors='pt')\n                if torch.cuda.is_available():\n\
    \                    texts_ = texts_.to('cuda')\n                model_output\
    \ = self.client(**texts_)\n                model_output = model_output[0][:, 0]\n\
    \                embeddings = model_output\n                embeddings /= embeddings.norm(dim=-1,\
    \ keepdim=True)\n                embeddings_all.append(embeddings.cpu())\n   \
    \     embeddings_all = torch.cat(embeddings_all, dim=0)\n        return embeddings_all.tolist()\n\
    \n    def embed_query(self, texts: List[str], use_tqdm= False) -> List[List[float]]:\n\
    \        #\u5BF9\u4E8Es2p\u4EFB\u52A1\uFF0C\u53EF\u4EE5\u8BBE\u7F6Euse_instruction=True\uFF0C\
    \u5BF9\u4E8Es2s\u4EFB\u52A1, \u53EF\u4EE5\u8BBE\u7F6Euse_instruction=False\n \
    \       embedding = self.embed_documents(texts, use_tqdm=use_tqdm, use_instruction=False)\n\
    \        return embedding"
  created_at: 2024-01-04 07:26:14+00:00
  edited: true
  hidden: false
  id: 65965d9646624a86ff41f3a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4e67ae4f40e083cd477e73c0ecc09834.svg
      fullname: zha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: evan209
      type: user
    createdAt: '2024-01-04T08:04:09.000Z'
    data:
      edited: false
      editors:
      - evan209
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 1.0000275373458862
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4e67ae4f40e083cd477e73c0ecc09834.svg
          fullname: zha
          isHf: false
          isPro: false
          name: evan209
          type: user
        html: "<p>\u975E\u5E38\u611F\u8C22</p>\n"
        raw: "\u975E\u5E38\u611F\u8C22"
        updatedAt: '2024-01-04T08:04:09.799Z'
      numEdits: 0
      reactions: []
    id: 65966679994d0ef58175eb37
    type: comment
  author: evan209
  content: "\u975E\u5E38\u611F\u8C22"
  created_at: 2024-01-04 08:04:09+00:00
  edited: false
  hidden: false
  id: 65966679994d0ef58175eb37
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TownsWu/PEG
repo_type: model
status: open
target_branch: null
title: "\u8BF7\u95EE\u600E\u4E48\u4F7F\u7528HuggingFaceEmbeddings \u6765\u8FDB\u884C\
  embedding"
