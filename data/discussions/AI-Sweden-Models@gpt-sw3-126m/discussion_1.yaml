!!python/object:huggingface_hub.community.DiscussionWithDetails
author: birgermoell
conflicting_files: null
created_at: 2023-01-01 14:37:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2023-01-01T14:37:57.000Z'
    data:
      edited: true
      editors:
      - birgermoell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
          fullname: Birger Moell
          isHf: false
          isPro: false
          name: birgermoell
          type: user
        html: '<p>I''m trying out loading a model with trlx and getting the following
          error.</p>

          <p>Example code</p>

          <p>import trlx<br>trainer = trlx.train(''AI-Sweden/gpt-sw3-126m'', dataset=[(''dolphins'',
          ''geese''), (1.0, 100.0)])<br>print("trainer: ", trainer)</p>

          <p>OSError: AI-Sweden/gpt-sw3-126m does not appear to have a file named
          pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.</p>

          <p>Steps to reproduce.</p>

          <p>Install trlx following the documentation here and then run the code.<br><a
          rel="nofollow" href="https://github.com/CarperAI/trlx">https://github.com/CarperAI/trlx</a></p>

          <p>If you compare it to <a href="https://huggingface.co/EleutherAI/gpt-j-6B/tree/main">https://huggingface.co/EleutherAI/gpt-j-6B/tree/main</a>
          there are additional files in their model folder</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1672584239517-6033e34a9aa44495c80dd043.png"><img
          alt="Screenshot 2023-01-01 at 15.43.31.png" src="https://cdn-uploads.huggingface.co/production/uploads/1672584239517-6033e34a9aa44495c80dd043.png"></a></p>

          <p>Files in the gpt-sw3-126m repo<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1672584307116-6033e34a9aa44495c80dd043.png"><img
          alt="Screenshot 2023-01-01 at 15.44.41.png" src="https://cdn-uploads.huggingface.co/production/uploads/1672584307116-6033e34a9aa44495c80dd043.png"></a></p>

          '
        raw: 'I''m trying out loading a model with trlx and getting the following
          error.


          Example code


          import trlx

          trainer = trlx.train(''AI-Sweden/gpt-sw3-126m'', dataset=[(''dolphins'',
          ''geese''), (1.0, 100.0)])

          print("trainer: ", trainer)


          OSError: AI-Sweden/gpt-sw3-126m does not appear to have a file named pytorch_model.bin,
          tf_model.h5, model.ckpt or flax_model.msgpack.


          Steps to reproduce.


          Install trlx following the documentation here and then run the code.

          https://github.com/CarperAI/trlx


          If you compare it to https://huggingface.co/EleutherAI/gpt-j-6B/tree/main
          there are additional files in their model folder


          ![Screenshot 2023-01-01 at 15.43.31.png](https://cdn-uploads.huggingface.co/production/uploads/1672584239517-6033e34a9aa44495c80dd043.png)


          Files in the gpt-sw3-126m repo

          ![Screenshot 2023-01-01 at 15.44.41.png](https://cdn-uploads.huggingface.co/production/uploads/1672584307116-6033e34a9aa44495c80dd043.png)'
        updatedAt: '2023-01-01T14:47:00.464Z'
      numEdits: 7
      reactions: []
    id: 63b19ac57804d5cadcdd8f60
    type: comment
  author: birgermoell
  content: 'I''m trying out loading a model with trlx and getting the following error.


    Example code


    import trlx

    trainer = trlx.train(''AI-Sweden/gpt-sw3-126m'', dataset=[(''dolphins'', ''geese''),
    (1.0, 100.0)])

    print("trainer: ", trainer)


    OSError: AI-Sweden/gpt-sw3-126m does not appear to have a file named pytorch_model.bin,
    tf_model.h5, model.ckpt or flax_model.msgpack.


    Steps to reproduce.


    Install trlx following the documentation here and then run the code.

    https://github.com/CarperAI/trlx


    If you compare it to https://huggingface.co/EleutherAI/gpt-j-6B/tree/main there
    are additional files in their model folder


    ![Screenshot 2023-01-01 at 15.43.31.png](https://cdn-uploads.huggingface.co/production/uploads/1672584239517-6033e34a9aa44495c80dd043.png)


    Files in the gpt-sw3-126m repo

    ![Screenshot 2023-01-01 at 15.44.41.png](https://cdn-uploads.huggingface.co/production/uploads/1672584307116-6033e34a9aa44495c80dd043.png)'
  created_at: 2023-01-01 14:37:57+00:00
  edited: true
  hidden: false
  id: 63b19ac57804d5cadcdd8f60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/664cb1911654e25ae51dc83e1f32f1ef.svg
      fullname: "Joey \xD6hman"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JoeyOhman
      type: user
    createdAt: '2023-01-01T14:52:29.000Z'
    data:
      edited: false
      editors:
      - JoeyOhman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/664cb1911654e25ae51dc83e1f32f1ef.svg
          fullname: "Joey \xD6hman"
          isHf: false
          isPro: false
          name: JoeyOhman
          type: user
        html: '<p>Hey, without having looked deeply I think it could simply be a problem
          with repository/model path. Try<br><code>AI-Sweden-Models/gpt-sw3-126m</code></p>

          '
        raw: 'Hey, without having looked deeply I think it could simply be a problem
          with repository/model path. Try

          `AI-Sweden-Models/gpt-sw3-126m`'
        updatedAt: '2023-01-01T14:52:29.214Z'
      numEdits: 0
      reactions: []
    id: 63b19e2df9ddaf1a16af902a
    type: comment
  author: JoeyOhman
  content: 'Hey, without having looked deeply I think it could simply be a problem
    with repository/model path. Try

    `AI-Sweden-Models/gpt-sw3-126m`'
  created_at: 2023-01-01 14:52:29+00:00
  edited: false
  hidden: false
  id: 63b19e2df9ddaf1a16af902a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2023-01-01T14:55:58.000Z'
    data:
      edited: false
      editors:
      - birgermoell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
          fullname: Birger Moell
          isHf: false
          isPro: false
          name: birgermoell
          type: user
        html: '<p>Great. That actually solved the issue but I got a new one. Might
          be related to trlx so not sure if this is related to the model.</p>

          '
        raw: Great. That actually solved the issue but I got a new one. Might be related
          to trlx so not sure if this is related to the model.
        updatedAt: '2023-01-01T14:55:58.053Z'
      numEdits: 0
      reactions: []
    id: 63b19efe000cd823283cac8e
    type: comment
  author: birgermoell
  content: Great. That actually solved the issue but I got a new one. Might be related
    to trlx so not sure if this is related to the model.
  created_at: 2023-01-01 14:55:58+00:00
  edited: false
  hidden: false
  id: 63b19efe000cd823283cac8e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2023-01-01T14:56:25.000Z'
    data:
      edited: false
      editors:
      - birgermoell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
          fullname: Birger Moell
          isHf: false
          isPro: false
          name: birgermoell
          type: user
        html: '<p>Seems to be related to dimensions of the output, but this could
          be related to trlx.<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1672584963744-6033e34a9aa44495c80dd043.png"><img
          alt="Screenshot 2023-01-01 at 15.55.04.png" src="https://cdn-uploads.huggingface.co/production/uploads/1672584963744-6033e34a9aa44495c80dd043.png"></a></p>

          '
        raw: 'Seems to be related to dimensions of the output, but this could be related
          to trlx.

          ![Screenshot 2023-01-01 at 15.55.04.png](https://cdn-uploads.huggingface.co/production/uploads/1672584963744-6033e34a9aa44495c80dd043.png)'
        updatedAt: '2023-01-01T14:56:25.617Z'
      numEdits: 0
      reactions: []
    id: 63b19f19f9b8103903a6397a
    type: comment
  author: birgermoell
  content: 'Seems to be related to dimensions of the output, but this could be related
    to trlx.

    ![Screenshot 2023-01-01 at 15.55.04.png](https://cdn-uploads.huggingface.co/production/uploads/1672584963744-6033e34a9aa44495c80dd043.png)'
  created_at: 2023-01-01 14:56:25+00:00
  edited: false
  hidden: false
  id: 63b19f19f9b8103903a6397a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2023-01-01T14:56:42.000Z'
    data:
      edited: false
      editors:
      - birgermoell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
          fullname: Birger Moell
          isHf: false
          isPro: false
          name: birgermoell
          type: user
        html: '<p>RuntimeError: Expected size for first two dimensions of batch2 tensor
          to be: [1536, 2] but got: [1536, 1].</p>

          '
        raw: 'RuntimeError: Expected size for first two dimensions of batch2 tensor
          to be: [1536, 2] but got: [1536, 1].'
        updatedAt: '2023-01-01T14:56:42.394Z'
      numEdits: 0
      reactions: []
    id: 63b19f2a000cd823283cae87
    type: comment
  author: birgermoell
  content: 'RuntimeError: Expected size for first two dimensions of batch2 tensor
    to be: [1536, 2] but got: [1536, 1].'
  created_at: 2023-01-01 14:56:42+00:00
  edited: false
  hidden: false
  id: 63b19f2a000cd823283cae87
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2023-01-01T14:59:11.000Z'
    data:
      edited: true
      editors:
      - birgermoell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
          fullname: Birger Moell
          isHf: false
          isPro: false
          name: birgermoell
          type: user
        html: "<p>Btw <span data-props=\"{&quot;user&quot;:&quot;JoeyOhman&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/JoeyOhman\"\
          >@<span class=\"underline\">JoeyOhman</span></a></span>\n\n\t</span></span>\
          \ , it said in the readme you should load it like this.</p>\n<pre><code>import\
          \ torch\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n\
          \n# Initialize Variables\nmodel_name = \"AI-Sweden/gpt-sw3-126m\"\ndevice\
          \ = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprompt = \"Tr\xE4\
          d \xE4r fina f\xF6r att\"\n\n# Initialize Tokenizer &amp; Model\ntokenizer\
          \ = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\
          model.eval()\nmodel.to(device)\n</code></pre>\n<p>Maybe just update the\
          \ readme to.</p>\n<pre><code>import torch\nfrom transformers import pipeline,\
          \ AutoTokenizer, AutoModelForCausalLM\n\n# Initialize Variables\nmodel_name\
          \ = \"AI-Sweden-Models/gpt-sw3-126m\"\ndevice = \"cuda:0\" if torch.cuda.is_available()\
          \ else \"cpu\"\nprompt = \"Tr\xE4d \xE4r fina f\xF6r att\"\n\n# Initialize\
          \ Tokenizer &amp; Model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\
          model = AutoModelForCausalLM.from_pretrained(model_name)\nmodel.eval()\n\
          model.to(device)\n</code></pre>\n"
        raw: "Btw @JoeyOhman , it said in the readme you should load it like this.\n\
          ```\nimport torch\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n\
          \n# Initialize Variables\nmodel_name = \"AI-Sweden/gpt-sw3-126m\"\ndevice\
          \ = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprompt = \"Tr\xE4\
          d \xE4r fina f\xF6r att\"\n\n# Initialize Tokenizer & Model\ntokenizer =\
          \ AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\
          model.eval()\nmodel.to(device)\n```\nMaybe just update the readme to.\n\
          ```\nimport torch\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n\
          \n# Initialize Variables\nmodel_name = \"AI-Sweden-Models/gpt-sw3-126m\"\
          \ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprompt\
          \ = \"Tr\xE4d \xE4r fina f\xF6r att\"\n\n# Initialize Tokenizer & Model\n\
          tokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\
          model.eval()\nmodel.to(device)\n```"
        updatedAt: '2023-01-01T14:59:34.208Z'
      numEdits: 1
      reactions: []
    id: 63b19fbff9ddaf1a16afa2a6
    type: comment
  author: birgermoell
  content: "Btw @JoeyOhman , it said in the readme you should load it like this.\n\
    ```\nimport torch\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n\
    \n# Initialize Variables\nmodel_name = \"AI-Sweden/gpt-sw3-126m\"\ndevice = \"\
    cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprompt = \"Tr\xE4d \xE4r fina\
    \ f\xF6r att\"\n\n# Initialize Tokenizer & Model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\
    model = AutoModelForCausalLM.from_pretrained(model_name)\nmodel.eval()\nmodel.to(device)\n\
    ```\nMaybe just update the readme to.\n```\nimport torch\nfrom transformers import\
    \ pipeline, AutoTokenizer, AutoModelForCausalLM\n\n# Initialize Variables\nmodel_name\
    \ = \"AI-Sweden-Models/gpt-sw3-126m\"\ndevice = \"cuda:0\" if torch.cuda.is_available()\
    \ else \"cpu\"\nprompt = \"Tr\xE4d \xE4r fina f\xF6r att\"\n\n# Initialize Tokenizer\
    \ & Model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\
    model.eval()\nmodel.to(device)\n```"
  created_at: 2023-01-01 14:59:11+00:00
  edited: true
  hidden: false
  id: 63b19fbff9ddaf1a16afa2a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/664cb1911654e25ae51dc83e1f32f1ef.svg
      fullname: "Joey \xD6hman"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JoeyOhman
      type: user
    createdAt: '2023-01-01T15:11:01.000Z'
    data:
      edited: false
      editors:
      - JoeyOhman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/664cb1911654e25ae51dc83e1f32f1ef.svg
          fullname: "Joey \xD6hman"
          isHf: false
          isPro: false
          name: JoeyOhman
          type: user
        html: '<p>Yeah, we recently changed the repository name and will fix this
          as soon as possible. Thanks! </p>

          <p>I don''t know why you get that error and I don''t have access to my computer
          until a few days (maybe someone else will jump in here before that). However,
          something that concerns me is that it seems to use <code>GPT2TokenizerFast</code>
          and not the <code>GPTSw3Tokenizer</code>. It might not be related to the
          error but will probably give you unexpected behavior later on. The config
          file does point to the correct tokenizer, please let us know if you think
          that problem could be on our end!</p>

          '
        raw: "Yeah, we recently changed the repository name and will fix this as soon\
          \ as possible. Thanks! \n\nI don't know why you get that error and I don't\
          \ have access to my computer until a few days (maybe someone else will jump\
          \ in here before that). However, something that concerns me is that it seems\
          \ to use `GPT2TokenizerFast` and not the `GPTSw3Tokenizer`. It might not\
          \ be related to the error but will probably give you unexpected behavior\
          \ later on. The config file does point to the correct tokenizer, please\
          \ let us know if you think that problem could be on our end!"
        updatedAt: '2023-01-01T15:11:01.762Z'
      numEdits: 0
      reactions: []
    id: 63b1a2851bc4bb9da218026a
    type: comment
  author: JoeyOhman
  content: "Yeah, we recently changed the repository name and will fix this as soon\
    \ as possible. Thanks! \n\nI don't know why you get that error and I don't have\
    \ access to my computer until a few days (maybe someone else will jump in here\
    \ before that). However, something that concerns me is that it seems to use `GPT2TokenizerFast`\
    \ and not the `GPTSw3Tokenizer`. It might not be related to the error but will\
    \ probably give you unexpected behavior later on. The config file does point to\
    \ the correct tokenizer, please let us know if you think that problem could be\
    \ on our end!"
  created_at: 2023-01-01 15:11:01+00:00
  edited: false
  hidden: false
  id: 63b1a2851bc4bb9da218026a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2023-01-01T15:29:50.000Z'
    data:
      edited: false
      editors:
      - birgermoell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
          fullname: Birger Moell
          isHf: false
          isPro: false
          name: birgermoell
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;JoeyOhman&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/JoeyOhman\">@<span class=\"\
          underline\">JoeyOhman</span></a></span>\n\n\t</span></span>  There is no\
          \ tokenizer.json or tokenizer_config.json in this repository. Could it be\
          \ that this makes huggingface use a default tokenizer that somehow breaks\
          \ things?</p>\n"
        raw: '@JoeyOhman  There is no tokenizer.json or tokenizer_config.json in this
          repository. Could it be that this makes huggingface use a default tokenizer
          that somehow breaks things?'
        updatedAt: '2023-01-01T15:29:50.842Z'
      numEdits: 0
      reactions: []
    id: 63b1a6eef9b8103903a6977d
    type: comment
  author: birgermoell
  content: '@JoeyOhman  There is no tokenizer.json or tokenizer_config.json in this
    repository. Could it be that this makes huggingface use a default tokenizer that
    somehow breaks things?'
  created_at: 2023-01-01 15:29:50+00:00
  edited: false
  hidden: false
  id: 63b1a6eef9b8103903a6977d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2023-01-01T21:37:11.000Z'
    data:
      edited: false
      editors:
      - birgermoell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
          fullname: Birger Moell
          isHf: false
          isPro: false
          name: birgermoell
          type: user
        html: '<p>Install transformers from source and installing sentencepiece resolved
          the issue. Then I could load the tokenizer with the following code.<br>self.tokenizer
          = AutoTokenizer.from_pretrained("AI-Sweden-Models/gpt-sw3-126m", use_auth_token=True)</p>

          '
        raw: 'Install transformers from source and installing sentencepiece resolved
          the issue. Then I could load the tokenizer with the following code.

          self.tokenizer = AutoTokenizer.from_pretrained("AI-Sweden-Models/gpt-sw3-126m",
          use_auth_token=True)'
        updatedAt: '2023-01-01T21:37:11.565Z'
      numEdits: 0
      reactions: []
      relatedEventId: 63b1fd07f9b8103903aad7f1
    id: 63b1fd07f9b8103903aad7f0
    type: comment
  author: birgermoell
  content: 'Install transformers from source and installing sentencepiece resolved
    the issue. Then I could load the tokenizer with the following code.

    self.tokenizer = AutoTokenizer.from_pretrained("AI-Sweden-Models/gpt-sw3-126m",
    use_auth_token=True)'
  created_at: 2023-01-01 21:37:11+00:00
  edited: false
  hidden: false
  id: 63b1fd07f9b8103903aad7f0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2023-01-01T21:37:11.000Z'
    data:
      status: closed
    id: 63b1fd07f9b8103903aad7f1
    type: status-change
  author: birgermoell
  created_at: 2023-01-01 21:37:11+00:00
  id: 63b1fd07f9b8103903aad7f1
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2023-01-03T22:37:54.000Z'
    data:
      status: open
    id: 63b4ae423e02c8e7cb773cb6
    type: status-change
  author: birgermoell
  created_at: 2023-01-03 22:37:54+00:00
  id: 63b4ae423e02c8e7cb773cb6
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/664cb1911654e25ae51dc83e1f32f1ef.svg
      fullname: "Joey \xD6hman"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JoeyOhman
      type: user
    createdAt: '2023-01-10T15:33:05.000Z'
    data:
      edited: false
      editors:
      - JoeyOhman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/664cb1911654e25ae51dc83e1f32f1ef.svg
          fullname: "Joey \xD6hman"
          isHf: false
          isPro: false
          name: JoeyOhman
          type: user
        html: '<p>Sorry for the delayed answer and great that you solved it!</p>

          <p>The README:s now have the correct repository path and a note about how
          to use the access token. Installing from source is required right now, but
          not for much longer as GPTSw3 should be included in HF Transformer''s next
          official release.</p>

          '
        raw: 'Sorry for the delayed answer and great that you solved it!


          The README:s now have the correct repository path and a note about how to
          use the access token. Installing from source is required right now, but
          not for much longer as GPTSw3 should be included in HF Transformer''s next
          official release.'
        updatedAt: '2023-01-10T15:33:05.168Z'
      numEdits: 0
      reactions: []
    id: 63bd853108409827334dfaa6
    type: comment
  author: JoeyOhman
  content: 'Sorry for the delayed answer and great that you solved it!


    The README:s now have the correct repository path and a note about how to use
    the access token. Installing from source is required right now, but not for much
    longer as GPTSw3 should be included in HF Transformer''s next official release.'
  created_at: 2023-01-10 15:33:05+00:00
  edited: false
  hidden: false
  id: 63bd853108409827334dfaa6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: AI-Sweden-Models/gpt-sw3-126m
repo_type: model
status: open
target_branch: null
title: Trying to use the model with training on trlx
