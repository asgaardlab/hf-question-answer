!!python/object:huggingface_hub.community.DiscussionWithDetails
author: webslug
conflicting_files: null
created_at: 2023-08-26 00:32:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/100a08fb1d2d9294880437fda47c9f93.svg
      fullname: Tim Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: webslug
      type: user
    createdAt: '2023-08-26T01:32:16.000Z'
    data:
      edited: false
      editors:
      - webslug
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9326234459877014
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/100a08fb1d2d9294880437fda47c9f93.svg
          fullname: Tim Smith
          isHf: false
          isPro: false
          name: webslug
          type: user
        html: '<p>Hi I tried codellama-7b.ggmlv3.Q2_K.bin in the text generation web
          ui but I get little to no output on Instruct mode.  Chat mode barely works.  I''ve
          increased the threads.  </p>

          <p>Not sure why it''s not working but the model seems incapable of generating
          code.</p>

          '
        raw: "Hi I tried codellama-7b.ggmlv3.Q2_K.bin in the text generation web ui\
          \ but I get little to no output on Instruct mode.  Chat mode barely works.\
          \  I've increased the threads.  \r\n\r\nNot sure why it's not working but\
          \ the model seems incapable of generating code."
        updatedAt: '2023-08-26T01:32:16.500Z'
      numEdits: 0
      reactions: []
    id: 64e95620e0242abe3944ddbf
    type: comment
  author: webslug
  content: "Hi I tried codellama-7b.ggmlv3.Q2_K.bin in the text generation web ui\
    \ but I get little to no output on Instruct mode.  Chat mode barely works.  I've\
    \ increased the threads.  \r\n\r\nNot sure why it's not working but the model\
    \ seems incapable of generating code."
  created_at: 2023-08-26 00:32:16+00:00
  edited: false
  hidden: false
  id: 64e95620e0242abe3944ddbf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-26T11:18:40.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9307057857513428
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>This is the base model so it''s not been fine tuned I believe, so
          it won''t necessarily be great at answering questions.  Try one the -Instruct
          or -Python model with the prompt template which I just added to their READMEs:
          </p>

          <pre><code>[INST] Write code to solve the following coding problem that
          obeys the constraints and

          passes the example test cases. Please wrap your code answer using ```:

          {PROMPT}

          [/INST]

          </code></pre>

          '
        raw: "This is the base model so it's not been fine tuned I believe, so it\
          \ won't necessarily be great at answering questions.  Try one the -Instruct\
          \ or -Python model with the prompt template which I just added to their\
          \ READMEs: \n```\n[INST] Write code to solve the following coding problem\
          \ that obeys the constraints and\npasses the example test cases. Please\
          \ wrap your code answer using ```:\n{PROMPT}\n[/INST]\n```"
        updatedAt: '2023-08-26T11:19:05.409Z'
      numEdits: 1
      reactions: []
    id: 64e9df90e0242abe3952aacc
    type: comment
  author: TheBloke
  content: "This is the base model so it's not been fine tuned I believe, so it won't\
    \ necessarily be great at answering questions.  Try one the -Instruct or -Python\
    \ model with the prompt template which I just added to their READMEs: \n```\n\
    [INST] Write code to solve the following coding problem that obeys the constraints\
    \ and\npasses the example test cases. Please wrap your code answer using ```:\n\
    {PROMPT}\n[/INST]\n```"
  created_at: 2023-08-26 10:18:40+00:00
  edited: true
  hidden: false
  id: 64e9df90e0242abe3952aacc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/100a08fb1d2d9294880437fda47c9f93.svg
      fullname: Tim Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: webslug
      type: user
    createdAt: '2023-08-30T15:38:52.000Z'
    data:
      edited: false
      editors:
      - webslug
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9914714694023132
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/100a08fb1d2d9294880437fda47c9f93.svg
          fullname: Tim Smith
          isHf: false
          isPro: false
          name: webslug
          type: user
        html: '<p>Thank you very much, I will try that.</p>

          '
        raw: Thank you very much, I will try that.
        updatedAt: '2023-08-30T15:38:52.258Z'
      numEdits: 0
      reactions: []
    id: 64ef628cc23e876cacad2300
    type: comment
  author: webslug
  content: Thank you very much, I will try that.
  created_at: 2023-08-30 14:38:52+00:00
  edited: false
  hidden: false
  id: 64ef628cc23e876cacad2300
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/CodeLlama-7B-GGML
repo_type: model
status: open
target_branch: null
title: Little to no output
