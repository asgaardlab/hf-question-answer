!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pratikhublikar
conflicting_files: null
created_at: 2023-08-23 09:16:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64463819821905a4826c2d10/_7T4cslaL7rh1hIQNrBFz.png?w=200&h=200&f=face
      fullname: Pratik Hublikar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pratikhublikar
      type: user
    createdAt: '2023-08-23T10:16:24.000Z'
    data:
      edited: false
      editors:
      - pratikhublikar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9482973217964172
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64463819821905a4826c2d10/_7T4cslaL7rh1hIQNrBFz.png?w=200&h=200&f=face
          fullname: Pratik Hublikar
          isHf: false
          isPro: false
          name: pratikhublikar
          type: user
        html: '<p>I am building a question answering assistant using the model. What
          prompts can I use so that the responses generated by the model are brief,
          to the point and coherent?</p>

          '
        raw: I am building a question answering assistant using the model. What prompts
          can I use so that the responses generated by the model are brief, to the
          point and coherent?
        updatedAt: '2023-08-23T10:16:24.738Z'
      numEdits: 0
      reactions: []
    id: 64e5dc7820f70879e7901c5a
    type: comment
  author: pratikhublikar
  content: I am building a question answering assistant using the model. What prompts
    can I use so that the responses generated by the model are brief, to the point
    and coherent?
  created_at: 2023-08-23 09:16:24+00:00
  edited: false
  hidden: false
  id: 64e5dc7820f70879e7901c5a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/13bb6b205ed6ada66fc4312ed2d5117f.svg
      fullname: Daniel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: spectral9
      type: user
    createdAt: '2023-08-31T17:44:37.000Z'
    data:
      edited: true
      editors:
      - spectral9
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3617725372314453
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/13bb6b205ed6ada66fc4312ed2d5117f.svg
          fullname: Daniel
          isHf: false
          isPro: false
          name: spectral9
          type: user
        html: "<p>An example using Langchain's <code>prompts</code>:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">from</span> langchain.llms\
          \ <span class=\"hljs-keyword\">import</span> CTransformers\n<span class=\"\
          hljs-keyword\">from</span> langchain.prompts <span class=\"hljs-keyword\"\
          >import</span> PromptTemplate\n<span class=\"hljs-keyword\">from</span>\
          \ langchain.chains <span class=\"hljs-keyword\">import</span> LLMChain\n\
          \nmodel_path : <span class=\"hljs-built_in\">str</span> = <span class=\"\
          hljs-string\">\"models/Llama-2-7B-Chat-GGML/llama-2-7b-chat.ggmlv3.q4_0.bin\"\
          </span>\n\nllm = CTransformers(\n            model=model_path, \n      \
          \      model_type=<span class=\"hljs-string\">'llama'</span>, \n       \
          \ )\n\nprompt = PromptTemplate(\n        input_variables=[<span class=\"\
          hljs-string\">\"product\"</span>],\n        template=<span class=\"hljs-string\"\
          >\"What is a good name for a company that makes {product}? Answer with a\
          \ simple list only.\"</span>,\n    )\n\nllmchain = LLMChain(llm=llm, prompt=prompt)\n\
          <span class=\"hljs-built_in\">print</span>(llmchain.run(<span class=\"hljs-string\"\
          >\"podcast player\"</span>))\n</code></pre>\n"
        raw: "An example using Langchain's `prompts`:\n```python\nfrom langchain.llms\
          \ import CTransformers\nfrom langchain.prompts import PromptTemplate\nfrom\
          \ langchain.chains import LLMChain\n\nmodel_path : str = \"models/Llama-2-7B-Chat-GGML/llama-2-7b-chat.ggmlv3.q4_0.bin\"\
          \n\nllm = CTransformers(\n            model=model_path, \n            model_type='llama',\
          \ \n        )\n\nprompt = PromptTemplate(\n        input_variables=[\"product\"\
          ],\n        template=\"What is a good name for a company that makes {product}?\
          \ Answer with a simple list only.\",\n    )\n\nllmchain = LLMChain(llm=llm,\
          \ prompt=prompt)\nprint(llmchain.run(\"podcast player\"))\n\n```"
        updatedAt: '2023-08-31T17:44:53.817Z'
      numEdits: 1
      reactions: []
    id: 64f0d185f3f6b6314c96ffc1
    type: comment
  author: spectral9
  content: "An example using Langchain's `prompts`:\n```python\nfrom langchain.llms\
    \ import CTransformers\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains\
    \ import LLMChain\n\nmodel_path : str = \"models/Llama-2-7B-Chat-GGML/llama-2-7b-chat.ggmlv3.q4_0.bin\"\
    \n\nllm = CTransformers(\n            model=model_path, \n            model_type='llama',\
    \ \n        )\n\nprompt = PromptTemplate(\n        input_variables=[\"product\"\
    ],\n        template=\"What is a good name for a company that makes {product}?\
    \ Answer with a simple list only.\",\n    )\n\nllmchain = LLMChain(llm=llm, prompt=prompt)\n\
    print(llmchain.run(\"podcast player\"))\n\n```"
  created_at: 2023-08-31 16:44:37+00:00
  edited: true
  hidden: false
  id: 64f0d185f3f6b6314c96ffc1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d7507a88cccda089571855e0e796cd23.svg
      fullname: Vincenzo Manzoni
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vincenzomanzoni
      type: user
    createdAt: '2023-09-01T13:33:23.000Z'
    data:
      edited: true
      editors:
      - vincenzomanzoni
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5600112676620483
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d7507a88cccda089571855e0e796cd23.svg
          fullname: Vincenzo Manzoni
          isHf: false
          isPro: false
          name: vincenzomanzoni
          type: user
        html: '<p>The prompt template of Llama2 is <code>&lt;s&gt;[INST]\n&lt;&lt;SYS&gt;&gt;\n{system_prompt}\n&lt;&lt;/SYS&gt;&gt;\n\n{user_prompt}[/INST]</code>
          (ref. <a href="https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat/blob/main/model.py">https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat/blob/main/model.py</a>).
          Does CTransformers library handles this automatically? Otherwise how can
          it work your example? Thanks, Vincenzo</p>

          '
        raw: The prompt template of Llama2 is ```<s>[INST]\n<<SYS>>\n{system_prompt}\n<</SYS>>\n\n{user_prompt}[/INST]```
          (ref. https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat/blob/main/model.py).
          Does CTransformers library handles this automatically? Otherwise how can
          it work your example? Thanks, Vincenzo
        updatedAt: '2023-09-01T13:36:17.494Z'
      numEdits: 3
      reactions: []
    id: 64f1e823a7fc07f2169938ea
    type: comment
  author: vincenzomanzoni
  content: The prompt template of Llama2 is ```<s>[INST]\n<<SYS>>\n{system_prompt}\n<</SYS>>\n\n{user_prompt}[/INST]```
    (ref. https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat/blob/main/model.py).
    Does CTransformers library handles this automatically? Otherwise how can it work
    your example? Thanks, Vincenzo
  created_at: 2023-09-01 12:33:23+00:00
  edited: true
  hidden: false
  id: 64f1e823a7fc07f2169938ea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14822a1d02d5edf0107f002a0a406658.svg
      fullname: Anna Hung
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Annorita
      type: user
    createdAt: '2023-09-27T09:00:33.000Z'
    data:
      edited: false
      editors:
      - Annorita
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9347456693649292
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14822a1d02d5edf0107f002a0a406658.svg
          fullname: Anna Hung
          isHf: false
          isPro: false
          name: Annorita
          type: user
        html: '<p>The  PR that dealing with this issue just got merged: <a rel="nofollow"
          href="https://github.com/huggingface/transformers/pull/25323">https://github.com/huggingface/transformers/pull/25323</a>
          </p>

          '
        raw: 'The  PR that dealing with this issue just got merged: https://github.com/huggingface/transformers/pull/25323 '
        updatedAt: '2023-09-27T09:00:33.166Z'
      numEdits: 0
      reactions: []
    id: 6513ef31a6755fc9774c8afd
    type: comment
  author: Annorita
  content: 'The  PR that dealing with this issue just got merged: https://github.com/huggingface/transformers/pull/25323 '
  created_at: 2023-09-27 08:00:33+00:00
  edited: false
  hidden: false
  id: 6513ef31a6755fc9774c8afd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 21
repo_id: TheBloke/Llama-2-7B-Chat-GGML
repo_type: model
status: open
target_branch: null
title: Prompts for Question Answering Assistant
