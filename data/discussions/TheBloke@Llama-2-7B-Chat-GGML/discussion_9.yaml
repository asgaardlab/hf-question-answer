!!python/object:huggingface_hub.community.DiscussionWithDetails
author: st01cs
conflicting_files: null
created_at: 2023-07-25 11:03:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63f0c9892f7c0152e86c714b/G5388jZs-DfQFd1r86Bku.jpeg?w=200&h=200&f=face
      fullname: Jia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: st01cs
      type: user
    createdAt: '2023-07-25T12:03:36.000Z'
    data:
      edited: true
      editors:
      - st01cs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6414944529533386
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63f0c9892f7c0152e86c714b/G5388jZs-DfQFd1r86Bku.jpeg?w=200&h=200&f=face
          fullname: Jia
          isHf: false
          isPro: false
          name: st01cs
          type: user
        html: "<p>Hi,</p>\n<p>I deploy llama-2-7b-chat.ggmlv3.q6_K.bin with llama-cpp-python[server].\
          \ </p>\n<p>Try to access it with OpenAI API,</p>\n<pre><code>curl -X 'POST'\
          \ \\\n  'http://llama07.server.com/v1/chat/completions' \\\n  -H 'accept:\
          \ application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n\
          \  \"messages\": [\n    {\n      \"content\": \"You are a helpful assistant.\"\
          ,\n      \"role\": \"system\"\n    },\n    {\n      \"content\": \"Write\
          \ a poem for France?\",\n      \"role\": \"user\"\n    }\n  ]\n}'\n</code></pre>\n\
          <p>its response body,</p>\n<pre><code>{\n  \"id\": \"chatcmpl-93a635e0-af7a-4b78-8e96-f93c84b59c69\"\
          ,\n  \"object\": \"chat.completion\",\n  \"created\": 1690286307,\n  \"\
          model\": \"/models/llama-2-7b-chat.ggmlv3.q6_K.bin\",\n  \"choices\": [\n\
          \    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"\
          assistant\",\n        \"content\": \"Of course! Here is a poem for France:\\\
          n\\nFrance, the land\"\n      },\n      \"finish_reason\": \"length\"\n\
          \    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 26,\n    \"completion_tokens\"\
          : 16,\n    \"total_tokens\": 42\n  }\n}\n</code></pre>\n<p>It always return\
          \ little tokens, how can I get the full poem in this case ?  </p>\n<p>Thanks\
          \ a lot for your job!</p>\n"
        raw: "Hi,\n\nI deploy llama-2-7b-chat.ggmlv3.q6_K.bin with llama-cpp-python[server].\
          \ \n\nTry to access it with OpenAI API,\n\n```\ncurl -X 'POST' \\\n  'http://llama07.server.com/v1/chat/completions'\
          \ \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json'\
          \ \\\n  -d '{\n  \"messages\": [\n    {\n      \"content\": \"You are a\
          \ helpful assistant.\",\n      \"role\": \"system\"\n    },\n    {\n   \
          \   \"content\": \"Write a poem for France?\",\n      \"role\": \"user\"\
          \n    }\n  ]\n}'\n\n```\nits response body,\n\n```\n{\n  \"id\": \"chatcmpl-93a635e0-af7a-4b78-8e96-f93c84b59c69\"\
          ,\n  \"object\": \"chat.completion\",\n  \"created\": 1690286307,\n  \"\
          model\": \"/models/llama-2-7b-chat.ggmlv3.q6_K.bin\",\n  \"choices\": [\n\
          \    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"\
          assistant\",\n        \"content\": \"Of course! Here is a poem for France:\\\
          n\\nFrance, the land\"\n      },\n      \"finish_reason\": \"length\"\n\
          \    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 26,\n    \"completion_tokens\"\
          : 16,\n    \"total_tokens\": 42\n  }\n}\n```\n\nIt always return little\
          \ tokens, how can I get the full poem in this case ?  \n\nThanks a lot for\
          \ your job!"
        updatedAt: '2023-07-25T12:04:41.922Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - st01cs
    id: 64bfba184c96ee2c9a306e6e
    type: comment
  author: st01cs
  content: "Hi,\n\nI deploy llama-2-7b-chat.ggmlv3.q6_K.bin with llama-cpp-python[server].\
    \ \n\nTry to access it with OpenAI API,\n\n```\ncurl -X 'POST' \\\n  'http://llama07.server.com/v1/chat/completions'\
    \ \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json'\
    \ \\\n  -d '{\n  \"messages\": [\n    {\n      \"content\": \"You are a helpful\
    \ assistant.\",\n      \"role\": \"system\"\n    },\n    {\n      \"content\"\
    : \"Write a poem for France?\",\n      \"role\": \"user\"\n    }\n  ]\n}'\n\n\
    ```\nits response body,\n\n```\n{\n  \"id\": \"chatcmpl-93a635e0-af7a-4b78-8e96-f93c84b59c69\"\
    ,\n  \"object\": \"chat.completion\",\n  \"created\": 1690286307,\n  \"model\"\
    : \"/models/llama-2-7b-chat.ggmlv3.q6_K.bin\",\n  \"choices\": [\n    {\n    \
    \  \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n   \
    \     \"content\": \"Of course! Here is a poem for France:\\n\\nFrance, the land\"\
    \n      },\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n\
    \    \"prompt_tokens\": 26,\n    \"completion_tokens\": 16,\n    \"total_tokens\"\
    : 42\n  }\n}\n```\n\nIt always return little tokens, how can I get the full poem\
    \ in this case ?  \n\nThanks a lot for your job!"
  created_at: 2023-07-25 11:03:36+00:00
  edited: true
  hidden: false
  id: 64bfba184c96ee2c9a306e6e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63f0c9892f7c0152e86c714b/G5388jZs-DfQFd1r86Bku.jpeg?w=200&h=200&f=face
      fullname: Jia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: st01cs
      type: user
    createdAt: '2023-07-25T12:06:54.000Z'
    data:
      edited: false
      editors:
      - st01cs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6173042058944702
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63f0c9892f7c0152e86c714b/G5388jZs-DfQFd1r86Bku.jpeg?w=200&h=200&f=face
          fullname: Jia
          isHf: false
          isPro: false
          name: st01cs
          type: user
        html: "<p>By the way, I set llama-cpp-python with following params,</p>\n\
          <pre><code>    -e USE_MLOCK=0 \\\n    -e N_THREADS=64 \\\n    -e N_BATCH=2048\
          \ \\\n    -e N_CTX=8192 \\\n</code></pre>\n"
        raw: "By the way, I set llama-cpp-python with following params,\n\n```\n \
          \   -e USE_MLOCK=0 \\\n\t-e N_THREADS=64 \\\n\t-e N_BATCH=2048 \\\n\t-e\
          \ N_CTX=8192 \\\n```\n"
        updatedAt: '2023-07-25T12:06:54.598Z'
      numEdits: 0
      reactions: []
    id: 64bfbade20b68b2464f1c5a4
    type: comment
  author: st01cs
  content: "By the way, I set llama-cpp-python with following params,\n\n```\n   \
    \ -e USE_MLOCK=0 \\\n\t-e N_THREADS=64 \\\n\t-e N_BATCH=2048 \\\n\t-e N_CTX=8192\
    \ \\\n```\n"
  created_at: 2023-07-25 11:06:54+00:00
  edited: false
  hidden: false
  id: 64bfbade20b68b2464f1c5a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63f0c9892f7c0152e86c714b/G5388jZs-DfQFd1r86Bku.jpeg?w=200&h=200&f=face
      fullname: Jia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: st01cs
      type: user
    createdAt: '2023-08-01T05:25:11.000Z'
    data:
      edited: true
      editors:
      - st01cs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5329335927963257
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63f0c9892f7c0152e86c714b/G5388jZs-DfQFd1r86Bku.jpeg?w=200&h=200&f=face
          fullname: Jia
          isHf: false
          isPro: false
          name: st01cs
          type: user
        html: "<pre><code>curl -X 'POST' \\\n  'http://llama07.server.com/v1/chat/completions'\
          \ \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json'\
          \ \\\n  -d '{\n  \"max_tokens\": 512,\n  \"messages\": [\n    {\n      \"\
          content\": \"You are a helpful assistant.\",\n      \"role\": \"system\"\
          \n    },\n    {\n      \"content\": \"Write a poem for France?\",\n    \
          \  \"role\": \"user\"\n    }\n  ]\n}'\n</code></pre>\n"
        raw: "```\ncurl -X 'POST' \\\n  'http://llama07.server.com/v1/chat/completions'\
          \ \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json'\
          \ \\\n  -d '{\n  \"max_tokens\": 512,\n  \"messages\": [\n    {\n      \"\
          content\": \"You are a helpful assistant.\",\n      \"role\": \"system\"\
          \n    },\n    {\n      \"content\": \"Write a poem for France?\",\n    \
          \  \"role\": \"user\"\n    }\n  ]\n}'\n\n```"
        updatedAt: '2023-08-01T05:25:30.845Z'
      numEdits: 1
      reactions: []
      relatedEventId: 64c897377dba66c3a7cbff49
    id: 64c897377dba66c3a7cbff47
    type: comment
  author: st01cs
  content: "```\ncurl -X 'POST' \\\n  'http://llama07.server.com/v1/chat/completions'\
    \ \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json'\
    \ \\\n  -d '{\n  \"max_tokens\": 512,\n  \"messages\": [\n    {\n      \"content\"\
    : \"You are a helpful assistant.\",\n      \"role\": \"system\"\n    },\n    {\n\
    \      \"content\": \"Write a poem for France?\",\n      \"role\": \"user\"\n\
    \    }\n  ]\n}'\n\n```"
  created_at: 2023-08-01 04:25:11+00:00
  edited: true
  hidden: false
  id: 64c897377dba66c3a7cbff47
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63f0c9892f7c0152e86c714b/G5388jZs-DfQFd1r86Bku.jpeg?w=200&h=200&f=face
      fullname: Jia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: st01cs
      type: user
    createdAt: '2023-08-01T05:25:11.000Z'
    data:
      status: closed
    id: 64c897377dba66c3a7cbff49
    type: status-change
  author: st01cs
  created_at: 2023-08-01 04:25:11+00:00
  id: 64c897377dba66c3a7cbff49
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a9b2af19bb7cf1ae9adf5bea206f754d.svg
      fullname: awarity.ai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: awarity-dev
      type: user
    createdAt: '2023-11-09T23:06:53.000Z'
    data:
      edited: false
      editors:
      - awarity-dev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9854806661605835
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a9b2af19bb7cf1ae9adf5bea206f754d.svg
          fullname: awarity.ai
          isHf: false
          isPro: false
          name: awarity-dev
          type: user
        html: '<p>Did you ever get a solution to this?</p>

          '
        raw: Did you ever get a solution to this?
        updatedAt: '2023-11-09T23:06:53.295Z'
      numEdits: 0
      reactions: []
    id: 654d660d2fdbbde41e6bcd92
    type: comment
  author: awarity-dev
  content: Did you ever get a solution to this?
  created_at: 2023-11-09 23:06:53+00:00
  edited: false
  hidden: false
  id: 654d660d2fdbbde41e6bcd92
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: TheBloke/Llama-2-7B-Chat-GGML
repo_type: model
status: closed
target_branch: null
title: llama-2-7b-chat response too little tokens?
