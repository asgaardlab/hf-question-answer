!!python/object:huggingface_hub.community.DiscussionWithDetails
author: krishnapiya
conflicting_files: null
created_at: 2024-01-19 05:51:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04c6f7fa0ca737fc2aa509c43238a4a5.svg
      fullname: Krishnapriya s
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: krishnapiya
      type: user
    createdAt: '2024-01-19T05:51:52.000Z'
    data:
      edited: true
      editors:
      - krishnapiya
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/04c6f7fa0ca737fc2aa509c43238a4a5.svg
          fullname: Krishnapriya s
          isHf: false
          isPro: false
          name: krishnapiya
          type: user
        html: '<p>GGML_ASSERT: /tmp/pip-install-3q_fwex4/llama-cpp-python_520e3a5b95cc4b339cb4759635dc8a44/vendor/llama.cpp/ggml-cuda.cu:6741:
          ptr == (void *) (g_cuda_pool_addr[device] + g_cuda_pool_used[device])<br>Could
          not attach to process.  If your uid matches the uid of the target<br>process,
          check the setting of /proc/sys/kernel/yama/ptrace_scope, or try<br>again
          as the root user.  For more details, see /etc/sysctl.d/10-ptrace.conf<br>ptrace:
          Operation not permitted.<br>No stack.<br>The program is not being run.</p>

          <p>The above error is created while I try to process multiple request at
          a time.The error is happening from a chat bot created using Llama-2-7b chat
          GGUF file locally</p>

          '
        raw: 'GGML_ASSERT: /tmp/pip-install-3q_fwex4/llama-cpp-python_520e3a5b95cc4b339cb4759635dc8a44/vendor/llama.cpp/ggml-cuda.cu:6741:
          ptr == (void *) (g_cuda_pool_addr[device] + g_cuda_pool_used[device])

          Could not attach to process.  If your uid matches the uid of the target

          process, check the setting of /proc/sys/kernel/yama/ptrace_scope, or try

          again as the root user.  For more details, see /etc/sysctl.d/10-ptrace.conf

          ptrace: Operation not permitted.

          No stack.

          The program is not being run.


          The above error is created while I try to process multiple request at a
          time.The error is happening from a chat bot created using Llama-2-7b chat
          GGUF file locally'
        updatedAt: '2024-01-19T05:57:33.180Z'
      numEdits: 2
      reactions: []
    id: 65aa0df868ee94fe11e54d5e
    type: comment
  author: krishnapiya
  content: 'GGML_ASSERT: /tmp/pip-install-3q_fwex4/llama-cpp-python_520e3a5b95cc4b339cb4759635dc8a44/vendor/llama.cpp/ggml-cuda.cu:6741:
    ptr == (void *) (g_cuda_pool_addr[device] + g_cuda_pool_used[device])

    Could not attach to process.  If your uid matches the uid of the target

    process, check the setting of /proc/sys/kernel/yama/ptrace_scope, or try

    again as the root user.  For more details, see /etc/sysctl.d/10-ptrace.conf

    ptrace: Operation not permitted.

    No stack.

    The program is not being run.


    The above error is created while I try to process multiple request at a time.The
    error is happening from a chat bot created using Llama-2-7b chat GGUF file locally'
  created_at: 2024-01-19 05:51:52+00:00
  edited: true
  hidden: false
  id: 65aa0df868ee94fe11e54d5e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2024-01-19T17:27:21.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9625431895256042
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;krishnapiya&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/krishnapiya\"\
          >@<span class=\"underline\">krishnapiya</span></a></span>\n\n\t</span></span>\
          \ well i dont know a solution but you should post this issue on the gguf\
          \ model not this one. this is ggml and completely outdated</p>\n"
        raw: '@krishnapiya well i dont know a solution but you should post this issue
          on the gguf model not this one. this is ggml and completely outdated'
        updatedAt: '2024-01-19T17:27:21.459Z'
      numEdits: 0
      reactions: []
    id: 65aab0f9a92a64ef5b5af840
    type: comment
  author: YaTharThShaRma999
  content: '@krishnapiya well i dont know a solution but you should post this issue
    on the gguf model not this one. this is ggml and completely outdated'
  created_at: 2024-01-19 17:27:21+00:00
  edited: false
  hidden: false
  id: 65aab0f9a92a64ef5b5af840
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 38
repo_id: TheBloke/Llama-2-7B-Chat-GGML
repo_type: model
status: open
target_branch: null
title: Program terminated while giving multiple request at a time
