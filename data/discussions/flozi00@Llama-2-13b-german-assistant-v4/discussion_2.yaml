!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KnutJaegersberg
conflicting_files: null
created_at: 2023-08-15 18:28:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-08-15T19:28:35.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9490726590156555
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>A twitter contact suggested to me it could make sense to continue
          pretraining of one of the larger models, i.e. mpt-30b or falcon-40b on some
          German data.<br>What do you think about this?<br>Do you have ideas how to
          realize that? Perhaps continuing pretraining for some 50b tokens would cost
          100k euros or so. </p>

          '
        raw: "A twitter contact suggested to me it could make sense to continue pretraining\
          \ of one of the larger models, i.e. mpt-30b or falcon-40b on some German\
          \ data. \r\nWhat do you think about this? \r\nDo you have ideas how to realize\
          \ that? Perhaps continuing pretraining for some 50b tokens would cost 100k\
          \ euros or so. "
        updatedAt: '2023-08-15T19:28:35.408Z'
      numEdits: 0
      reactions: []
    id: 64dbd1e3fcf8221c9186eeb5
    type: comment
  author: KnutJaegersberg
  content: "A twitter contact suggested to me it could make sense to continue pretraining\
    \ of one of the larger models, i.e. mpt-30b or falcon-40b on some German data.\
    \ \r\nWhat do you think about this? \r\nDo you have ideas how to realize that?\
    \ Perhaps continuing pretraining for some 50b tokens would cost 100k euros or\
    \ so. "
  created_at: 2023-08-15 18:28:35+00:00
  edited: false
  hidden: false
  id: 64dbd1e3fcf8221c9186eeb5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654892015542-605b1cf890a4b6bc0eef99ad.jpeg?w=200&h=200&f=face
      fullname: Florian Zimmermeister
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: flozi00
      type: user
    createdAt: '2023-08-15T19:44:06.000Z'
    data:
      edited: false
      editors:
      - flozi00
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9593951106071472
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654892015542-605b1cf890a4b6bc0eef99ad.jpeg?w=200&h=200&f=face
          fullname: Florian Zimmermeister
          isHf: false
          isPro: false
          name: flozi00
          type: user
        html: "<p>I am already preparing the 70b model training on large scale german\
          \ data :-)<br>Stay tuned</p>\n<p>If you want to speed up the process we\
          \ could speak about some ways to help financing that, my Employer is the\
          \ defacto main sponsor of training and inference hardware in their data\
          \ centers.<br>So one way would be telling them my name when buying new hardware\
          \ or directly contact them to find a way of financial support.<br>Pinging\
          \ <span data-props=\"{&quot;user&quot;:&quot;jphme&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jphme\">@<span class=\"\
          underline\">jphme</span></a></span>\n\n\t</span></span> who was also interested\
          \ in german LLM research group<br>Maybe we could open an slack or something</p>\n"
        raw: 'I am already preparing the 70b model training on large scale german
          data :-)

          Stay tuned


          If you want to speed up the process we could speak about some ways to help
          financing that, my Employer is the defacto main sponsor of training and
          inference hardware in their data centers.

          So one way would be telling them my name when buying new hardware or directly
          contact them to find a way of financial support.

          Pinging @jphme who was also interested in german LLM research group

          Maybe we could open an slack or something'
        updatedAt: '2023-08-15T19:44:06.489Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - KnutJaegersberg
    id: 64dbd586c1209f7d499f7206
    type: comment
  author: flozi00
  content: 'I am already preparing the 70b model training on large scale german data
    :-)

    Stay tuned


    If you want to speed up the process we could speak about some ways to help financing
    that, my Employer is the defacto main sponsor of training and inference hardware
    in their data centers.

    So one way would be telling them my name when buying new hardware or directly
    contact them to find a way of financial support.

    Pinging @jphme who was also interested in german LLM research group

    Maybe we could open an slack or something'
  created_at: 2023-08-15 18:44:06+00:00
  edited: false
  hidden: false
  id: 64dbd586c1209f7d499f7206
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654892015542-605b1cf890a4b6bc0eef99ad.jpeg?w=200&h=200&f=face
      fullname: Florian Zimmermeister
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: flozi00
      type: user
    createdAt: '2023-08-16T07:09:02.000Z'
    data:
      edited: false
      editors:
      - flozi00
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8174626231193542
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654892015542-605b1cf890a4b6bc0eef99ad.jpeg?w=200&h=200&f=face
          fullname: Florian Zimmermeister
          isHf: false
          isPro: false
          name: flozi00
          type: user
        html: '<p><a rel="nofollow" href="https://join.slack.com/t/slack-dtc7771/shared_invite/zt-219keplqu-hLwjm0xcFAOX7enERfBz0Q">https://join.slack.com/t/slack-dtc7771/shared_invite/zt-219keplqu-hLwjm0xcFAOX7enERfBz0Q</a></p>

          <p>Just created an slack for german llm''s, would be happy plan more training
          runs there</p>

          '
        raw: 'https://join.slack.com/t/slack-dtc7771/shared_invite/zt-219keplqu-hLwjm0xcFAOX7enERfBz0Q


          Just created an slack for german llm''s, would be happy plan more training
          runs there'
        updatedAt: '2023-08-16T07:09:02.108Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - KnutJaegersberg
    id: 64dc760e7266618e856b3c95
    type: comment
  author: flozi00
  content: 'https://join.slack.com/t/slack-dtc7771/shared_invite/zt-219keplqu-hLwjm0xcFAOX7enERfBz0Q


    Just created an slack for german llm''s, would be happy plan more training runs
    there'
  created_at: 2023-08-16 06:09:02+00:00
  edited: false
  hidden: false
  id: 64dc760e7266618e856b3c95
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-08-16T14:11:13.000Z'
    data:
      status: closed
    id: 64dcd90192f46d7e573ff30d
    type: status-change
  author: KnutJaegersberg
  created_at: 2023-08-16 13:11:13+00:00
  id: 64dcd90192f46d7e573ff30d
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: flozi00/Llama-2-13b-german-assistant-v4
repo_type: model
status: closed
target_branch: null
title: 'Continue pretraining of some larger models? '
