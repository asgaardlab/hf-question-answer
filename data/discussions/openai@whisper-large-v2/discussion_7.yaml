!!python/object:huggingface_hub.community.DiscussionWithDetails
author: eikosa
conflicting_files: null
created_at: 2022-12-09 01:14:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3db5f5e484e802f6ef7f8e664c63acec.svg
      fullname: eiko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eikosa
      type: user
    createdAt: '2022-12-09T01:14:22.000Z'
    data:
      edited: false
      editors:
      - eikosa
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3db5f5e484e802f6ef7f8e664c63acec.svg
          fullname: eiko
          isHf: false
          isPro: false
          name: eikosa
          type: user
        html: '<p>How can I process long audio recordings with this model? (1-60 min)</p>

          '
        raw: How can I process long audio recordings with this model? (1-60 min)
        updatedAt: '2022-12-09T01:14:22.361Z'
      numEdits: 0
      reactions: []
    id: 63928bee0655b17e7c4e0e6e
    type: comment
  author: eikosa
  content: How can I process long audio recordings with this model? (1-60 min)
  created_at: 2022-12-09 01:14:22+00:00
  edited: false
  hidden: false
  id: 63928bee0655b17e7c4e0e6e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2022-12-12T16:18:12.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>You can use <code>pipeline</code> as per the demo at: <a href=\"\
          https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2\">https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2</a></p>\n\
          <p>This will enable you to transcribe files of up to arbitrary length:</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span>\
          \ transformers <span class=\"hljs-keyword\">import</span> pipeline\n\ndevice\
          \ = <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">if</span>\
          \ torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> <span\
          \ class=\"hljs-string\">\"cpu\"</span>\n\npipe = pipeline(\n    task=<span\
          \ class=\"hljs-string\">\"automatic-speech-recognition\"</span>,\n    model=<span\
          \ class=\"hljs-string\">\"openai/whisper-large-v2\"</span>,\n    chunk_length_s=<span\
          \ class=\"hljs-number\">30</span>,\n    device=device,\n)\n\nout = pipe(audio)[<span\
          \ class=\"hljs-string\">\"text\"</span>]\n</code></pre>\n<p>where <code>audio</code>\
          \ is the path to an audio file or a loaded audio array (see <a rel=\"nofollow\"\
          \ href=\"https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201\"\
          >https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201</a>)</p>\n"
        raw: "You can use `pipeline` as per the demo at: https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2\n\
          \nThis will enable you to transcribe files of up to arbitrary length:\n\n\
          ```python\nfrom transformers import pipeline\n\ndevice = 0 if torch.cuda.is_available()\
          \ else \"cpu\"\n\npipe = pipeline(\n    task=\"automatic-speech-recognition\"\
          ,\n    model=\"openai/whisper-large-v2\",\n    chunk_length_s=30,\n    device=device,\n\
          )\n\nout = pipe(audio)[\"text\"]\n```\nwhere `audio` is the path to an audio\
          \ file or a loaded audio array (see https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201)"
        updatedAt: '2022-12-12T16:19:54.788Z'
      numEdits: 1
      reactions: []
    id: 639754443cd6591aebc12533
    type: comment
  author: sanchit-gandhi
  content: "You can use `pipeline` as per the demo at: https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2\n\
    \nThis will enable you to transcribe files of up to arbitrary length:\n\n```python\n\
    from transformers import pipeline\n\ndevice = 0 if torch.cuda.is_available() else\
    \ \"cpu\"\n\npipe = pipeline(\n    task=\"automatic-speech-recognition\",\n  \
    \  model=\"openai/whisper-large-v2\",\n    chunk_length_s=30,\n    device=device,\n\
    )\n\nout = pipe(audio)[\"text\"]\n```\nwhere `audio` is the path to an audio file\
    \ or a loaded audio array (see https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201)"
  created_at: 2022-12-12 16:18:12+00:00
  edited: true
  hidden: false
  id: 639754443cd6591aebc12533
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3db5f5e484e802f6ef7f8e664c63acec.svg
      fullname: eiko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eikosa
      type: user
    createdAt: '2022-12-13T09:15:13.000Z'
    data:
      edited: false
      editors:
      - eikosa
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3db5f5e484e802f6ef7f8e664c63acec.svg
          fullname: eiko
          isHf: false
          isPro: false
          name: eikosa
          type: user
        html: "<blockquote>\n<p>You can use <code>pipeline</code> as per the demo\
          \ at: <a href=\"https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2\"\
          >https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2</a></p>\n\
          <p>This will enable you to transcribe files of up to arbitrary length:</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span>\
          \ transformers <span class=\"hljs-keyword\">import</span> pipeline\n\ndevice\
          \ = <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">if</span>\
          \ torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> <span\
          \ class=\"hljs-string\">\"cpu\"</span>\n\npipe = pipeline(\n    task=<span\
          \ class=\"hljs-string\">\"automatic-speech-recognition\"</span>,\n    model=<span\
          \ class=\"hljs-string\">\"openai/whisper-large-v2\"</span>,\n    chunk_length_s=<span\
          \ class=\"hljs-number\">30</span>,\n    device=device,\n)\n\nout = pipe(audio)[<span\
          \ class=\"hljs-string\">\"text\"</span>]\n</code></pre>\n<p>where <code>audio</code>\
          \ is the path to an audio file or a loaded audio array (see <a rel=\"nofollow\"\
          \ href=\"https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201\"\
          >https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201</a>)</p>\n\
          </blockquote>\n<p>how can i set output language with this method</p>\n"
        raw: "> You can use `pipeline` as per the demo at: https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2\n\
          > \n> This will enable you to transcribe files of up to arbitrary length:\n\
          > \n> ```python\n> from transformers import pipeline\n> \n> device = 0 if\
          \ torch.cuda.is_available() else \"cpu\"\n> \n> pipe = pipeline(\n>    \
          \ task=\"automatic-speech-recognition\",\n>     model=\"openai/whisper-large-v2\"\
          ,\n>     chunk_length_s=30,\n>     device=device,\n> )\n> \n> out = pipe(audio)[\"\
          text\"]\n> ```\n> where `audio` is the path to an audio file or a loaded\
          \ audio array (see https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201)\n\
          \nhow can i set output language with this method"
        updatedAt: '2022-12-13T09:15:13.543Z'
      numEdits: 0
      reactions: []
    id: 639842a183eb5084bd04baeb
    type: comment
  author: eikosa
  content: "> You can use `pipeline` as per the demo at: https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2\n\
    > \n> This will enable you to transcribe files of up to arbitrary length:\n> \n\
    > ```python\n> from transformers import pipeline\n> \n> device = 0 if torch.cuda.is_available()\
    \ else \"cpu\"\n> \n> pipe = pipeline(\n>     task=\"automatic-speech-recognition\"\
    ,\n>     model=\"openai/whisper-large-v2\",\n>     chunk_length_s=30,\n>     device=device,\n\
    > )\n> \n> out = pipe(audio)[\"text\"]\n> ```\n> where `audio` is the path to\
    \ an audio file or a loaded audio array (see https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201)\n\
    \nhow can i set output language with this method"
  created_at: 2022-12-13 09:15:13+00:00
  edited: false
  hidden: false
  id: 639842a183eb5084bd04baeb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2022-12-13T13:39:39.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;eikosa&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/eikosa\">@<span class=\"\
          underline\">eikosa</span></a></span>\n\n\t</span></span>! Just make sure\
          \ you've installed Transformers from main:</p>\n<pre><code>pip install git+https://github.com/huggingface/transformers\n\
          </code></pre>\n<p>Then you can change the language as follows:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> pipeline\n\ndevice = <span\
          \ class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">if</span>\
          \ torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> <span\
          \ class=\"hljs-string\">\"cpu\"</span>\n\npipe = pipeline(\n    task=<span\
          \ class=\"hljs-string\">\"automatic-speech-recognition\"</span>,\n    model=<span\
          \ class=\"hljs-string\">\"openai/whisper-large-v2\"</span>,\n    chunk_length_s=<span\
          \ class=\"hljs-number\">30</span>,\n    device=device,\n)\n\n<span class=\"\
          hljs-comment\"># change language as required</span>\npipe.model.config.forced_decoder_ids\
          \ = pipe.tokenizer.get_decoder_prompt_ids(language=<span class=\"hljs-string\"\
          >\"Spanish\"</span>, task=<span class=\"hljs-string\">\"transcribe\"</span>)\n\
          \nout = pipe(audio)[<span class=\"hljs-string\">\"text\"</span>]\n</code></pre>\n"
        raw: "Hey @eikosa! Just make sure you've installed Transformers from main:\n\
          ```\npip install git+https://github.com/huggingface/transformers\n```\n\n\
          Then you can change the language as follows:\n```python\nfrom transformers\
          \ import pipeline\n\ndevice = 0 if torch.cuda.is_available() else \"cpu\"\
          \n\npipe = pipeline(\n    task=\"automatic-speech-recognition\",\n    model=\"\
          openai/whisper-large-v2\",\n    chunk_length_s=30,\n    device=device,\n\
          )\n\n# change language as required\npipe.model.config.forced_decoder_ids\
          \ = pipe.tokenizer.get_decoder_prompt_ids(language=\"Spanish\", task=\"\
          transcribe\")\n\nout = pipe(audio)[\"text\"]\n```"
        updatedAt: '2022-12-13T13:39:39.930Z'
      numEdits: 0
      reactions: []
    id: 6398809b11095028d87b16a2
    type: comment
  author: sanchit-gandhi
  content: "Hey @eikosa! Just make sure you've installed Transformers from main:\n\
    ```\npip install git+https://github.com/huggingface/transformers\n```\n\nThen\
    \ you can change the language as follows:\n```python\nfrom transformers import\
    \ pipeline\n\ndevice = 0 if torch.cuda.is_available() else \"cpu\"\n\npipe = pipeline(\n\
    \    task=\"automatic-speech-recognition\",\n    model=\"openai/whisper-large-v2\"\
    ,\n    chunk_length_s=30,\n    device=device,\n)\n\n# change language as required\n\
    pipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=\"\
    Spanish\", task=\"transcribe\")\n\nout = pipe(audio)[\"text\"]\n```"
  created_at: 2022-12-13 13:39:39+00:00
  edited: false
  hidden: false
  id: 6398809b11095028d87b16a2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7345644ea1bc7836993c49dd8c62be81.svg
      fullname: Kirankumar A M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kirankumaram
      type: user
    createdAt: '2022-12-27T11:16:27.000Z'
    data:
      edited: false
      editors:
      - kirankumaram
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7345644ea1bc7836993c49dd8c62be81.svg
          fullname: Kirankumar A M
          isHf: false
          isPro: false
          name: kirankumaram
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span><br>If\
          \ we use the pipeline as mentioned in <a href=\"https://huggingface.co/openai/whisper-large-v2\"\
          >https://huggingface.co/openai/whisper-large-v2</a> instead of the one which\
          \ you had specified above, transcription stops after 30 second mark. Can\
          \ this be solved?</p>\n"
        raw: "Hi @sanchit-gandhi \nIf we use the pipeline as mentioned in https://huggingface.co/openai/whisper-large-v2\
          \ instead of the one which you had specified above, transcription stops\
          \ after 30 second mark. Can this be solved?"
        updatedAt: '2022-12-27T11:16:27.998Z'
      numEdits: 0
      reactions: []
    id: 63aad40b280f90fa7000f4d5
    type: comment
  author: kirankumaram
  content: "Hi @sanchit-gandhi \nIf we use the pipeline as mentioned in https://huggingface.co/openai/whisper-large-v2\
    \ instead of the one which you had specified above, transcription stops after\
    \ 30 second mark. Can this be solved?"
  created_at: 2022-12-27 11:16:27+00:00
  edited: false
  hidden: false
  id: 63aad40b280f90fa7000f4d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-01-26T16:36:35.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;kirankumaram&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/kirankumaram\"\
          >@<span class=\"underline\">kirankumaram</span></a></span>\n\n\t</span></span>,\
          \ sorry for the late reply! You just need to specify <code>chunk_length_s=30</code>\
          \ when you instantiate the pipeline:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> pipeline\n\ndevice = <span class=\"hljs-number\">0</span>\
          \ <span class=\"hljs-keyword\">if</span> torch.cuda.is_available() <span\
          \ class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"cpu\"\
          </span>\n\npipe = pipeline(\n    task=<span class=\"hljs-string\">\"automatic-speech-recognition\"\
          </span>,\n    model=<span class=\"hljs-string\">\"openai/whisper-large-v2\"\
          </span>,\n    chunk_length_s=<span class=\"hljs-number\">30</span>,  <span\
          \ class=\"hljs-comment\"># &lt;- this arg lets us do long form transcriptions!</span>\n\
          \    device=device,\n)\n\n<span class=\"hljs-comment\"># load your audio\
          \ as required</span>\naudio = ...\n\n<span class=\"hljs-comment\"># inference</span>\n\
          out = pipe(audio)[<span class=\"hljs-string\">\"text\"</span>]\n<span class=\"\
          hljs-built_in\">print</span>(out)\n</code></pre>\n"
        raw: "Hey @kirankumaram, sorry for the late reply! You just need to specify\
          \ `chunk_length_s=30` when you instantiate the pipeline:\n```python\nfrom\
          \ transformers import pipeline\n\ndevice = 0 if torch.cuda.is_available()\
          \ else \"cpu\"\n\npipe = pipeline(\n    task=\"automatic-speech-recognition\"\
          ,\n    model=\"openai/whisper-large-v2\",\n    chunk_length_s=30,  # <-\
          \ this arg lets us do long form transcriptions!\n    device=device,\n)\n\
          \n# load your audio as required\naudio = ...\n\n# inference\nout = pipe(audio)[\"\
          text\"]\nprint(out)\n```"
        updatedAt: '2023-01-26T16:36:35.381Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - kirankumaram
        - Blacky372
    id: 63d2ac13bc3d31862320913e
    type: comment
  author: sanchit-gandhi
  content: "Hey @kirankumaram, sorry for the late reply! You just need to specify\
    \ `chunk_length_s=30` when you instantiate the pipeline:\n```python\nfrom transformers\
    \ import pipeline\n\ndevice = 0 if torch.cuda.is_available() else \"cpu\"\n\n\
    pipe = pipeline(\n    task=\"automatic-speech-recognition\",\n    model=\"openai/whisper-large-v2\"\
    ,\n    chunk_length_s=30,  # <- this arg lets us do long form transcriptions!\n\
    \    device=device,\n)\n\n# load your audio as required\naudio = ...\n\n# inference\n\
    out = pipe(audio)[\"text\"]\nprint(out)\n```"
  created_at: 2023-01-26 16:36:35+00:00
  edited: false
  hidden: false
  id: 63d2ac13bc3d31862320913e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: openai/whisper-large-v2
repo_type: model
status: open
target_branch: null
title: Long Audio Files
