!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zhaofeng3012
conflicting_files: null
created_at: 2023-08-23 08:20:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a36d0b26387c436069233c1163da0cca.svg
      fullname: zhaofeng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zhaofeng3012
      type: user
    createdAt: '2023-08-23T09:20:25.000Z'
    data:
      edited: false
      editors:
      - zhaofeng3012
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8813678026199341
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a36d0b26387c436069233c1163da0cca.svg
          fullname: zhaofeng
          isHf: false
          isPro: false
          name: zhaofeng3012
          type: user
        html: '<p>Hello everyone, I have a question. </p>

          <p>I fine-tuned the model and got some files including pytorch_model.bin(about
          6.17G).</p>

          <p>As the title describes, I want convert the model(pytorch_model.bin, about
          6.17G) to .pt file(about 2.87G).</p>

          <p>I tried to use torch.load() and torch.save(), but the output .pt file
          can''t load to use. I''m not sure whether I''m using these functions incorrectly.</p>

          <p>I would be grateful if someone could answer my doubts.<br>THX!!!</p>

          '
        raw: "Hello everyone, I have a question. \r\n\r\nI fine-tuned the model and\
          \ got some files including pytorch_model.bin(about 6.17G).\r\n\r\nAs the\
          \ title describes, I want convert the model(pytorch_model.bin, about 6.17G)\
          \ to .pt file(about 2.87G).\r\n\r\nI tried to use torch.load() and torch.save(),\
          \ but the output .pt file can't load to use. I'm not sure whether I'm using\
          \ these functions incorrectly.\r\n\r\nI would be grateful if someone could\
          \ answer my doubts.\r\nTHX!!!\r\n"
        updatedAt: '2023-08-23T09:20:25.680Z'
      numEdits: 0
      reactions: []
    id: 64e5cf59fe53a047e5f37697
    type: comment
  author: zhaofeng3012
  content: "Hello everyone, I have a question. \r\n\r\nI fine-tuned the model and\
    \ got some files including pytorch_model.bin(about 6.17G).\r\n\r\nAs the title\
    \ describes, I want convert the model(pytorch_model.bin, about 6.17G) to .pt file(about\
    \ 2.87G).\r\n\r\nI tried to use torch.load() and torch.save(), but the output\
    \ .pt file can't load to use. I'm not sure whether I'm using these functions incorrectly.\r\
    \n\r\nI would be grateful if someone could answer my doubts.\r\nTHX!!!\r\n"
  created_at: 2023-08-23 08:20:25+00:00
  edited: false
  hidden: false
  id: 64e5cf59fe53a047e5f37697
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/261b6a765df39af93e00ccf73a014daf.svg
      fullname: Oliver
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: olivetty
      type: user
    createdAt: '2023-09-03T17:16:36.000Z'
    data:
      edited: false
      editors:
      - olivetty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9097118973731995
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/261b6a765df39af93e00ccf73a014daf.svg
          fullname: Oliver
          isHf: false
          isPro: false
          name: olivetty
          type: user
        html: '<p>Did you find any solution to this? I have the same problem. Have
          a finetuned Whisper model in .bin and want a PT file so I can use it in
          the audio webui! :) </p>

          '
        raw: 'Did you find any solution to this? I have the same problem. Have a finetuned
          Whisper model in .bin and want a PT file so I can use it in the audio webui!
          :) '
        updatedAt: '2023-09-03T17:16:36.157Z'
      numEdits: 0
      reactions: []
    id: 64f4bf7427ad026d79c6ac57
    type: comment
  author: olivetty
  content: 'Did you find any solution to this? I have the same problem. Have a finetuned
    Whisper model in .bin and want a PT file so I can use it in the audio webui! :) '
  created_at: 2023-09-03 16:16:36+00:00
  edited: false
  hidden: false
  id: 64f4bf7427ad026d79c6ac57
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/a36d0b26387c436069233c1163da0cca.svg
      fullname: zhaofeng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zhaofeng3012
      type: user
    createdAt: '2023-09-04T00:50:48.000Z'
    data:
      status: closed
    id: 64f529e868947e600d786e27
    type: status-change
  author: zhaofeng3012
  created_at: 2023-09-03 23:50:48+00:00
  id: 64f529e868947e600d786e27
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-09-04T16:27:02.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9452943801879883
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>You might need to use some quantisation / casting of the weights?
          </p>

          '
        raw: 'You might need to use some quantisation / casting of the weights? '
        updatedAt: '2023-09-04T16:27:02.706Z'
      numEdits: 0
      reactions: []
    id: 64f60556b093b649f41d4f4c
    type: comment
  author: ArthurZ
  content: 'You might need to use some quantisation / casting of the weights? '
  created_at: 2023-09-04 15:27:02+00:00
  edited: false
  hidden: false
  id: 64f60556b093b649f41d4f4c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-09-04T16:46:47.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5548378229141235
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>The weights <code>pytorch_model.bin</code> are saved using <code>torch.save</code>\
          \ under-the-hood when we call <code>.save_pretrained</code>: <a rel=\"nofollow\"\
          \ href=\"https://github.com/huggingface/transformers/blob/034bc5d26ad7c0e284265d92d3da39d786138545/src/transformers/modeling_utils.py#L1752\"\
          >https://github.com/huggingface/transformers/blob/034bc5d26ad7c0e284265d92d3da39d786138545/src/transformers/modeling_utils.py#L1752</a></p>\n\
          <p>Thus, you can load them with <code>torch.load</code>:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> WhisperForConditionalGeneration\n\
          <span class=\"hljs-keyword\">import</span> tempfile\n<span class=\"hljs-keyword\"\
          >import</span> torch\n\nmodel = WhisperForConditionalGeneration.from_pretrained(<span\
          \ class=\"hljs-string\">\"openai/whisper-tiny.en\"</span>)\n\n<span class=\"\
          hljs-keyword\">with</span> tempfile.TemporaryDirectory() <span class=\"\
          hljs-keyword\">as</span> tmp_dir_name:\n    model.save_pretrained(tmp_dir_name)\n\
          \    state_dict = torch.load(<span class=\"hljs-string\">f\"<span class=\"\
          hljs-subst\">{tmp_dir_name}</span>/pytorch_model.bin\"</span>)\n</code></pre>\n\
          <p>Of course, if you have the model weights saved locally already, there\
          \ is no need to save the state dict again, just load the state dict from\
          \ the saved path.</p>\n"
        raw: "The weights `pytorch_model.bin` are saved using `torch.save` under-the-hood\
          \ when we call `.save_pretrained`: https://github.com/huggingface/transformers/blob/034bc5d26ad7c0e284265d92d3da39d786138545/src/transformers/modeling_utils.py#L1752\n\
          \nThus, you can load them with `torch.load`:\n```python\nfrom transformers\
          \ import WhisperForConditionalGeneration\nimport tempfile\nimport torch\n\
          \nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\"\
          )\n\nwith tempfile.TemporaryDirectory() as tmp_dir_name:\n    model.save_pretrained(tmp_dir_name)\n\
          \    state_dict = torch.load(f\"{tmp_dir_name}/pytorch_model.bin\")\n```\n\
          \nOf course, if you have the model weights saved locally already, there\
          \ is no need to save the state dict again, just load the state dict from\
          \ the saved path."
        updatedAt: '2023-09-06T13:39:36.662Z'
      numEdits: 2
      reactions: []
    id: 64f609f7653739023198ba79
    type: comment
  author: sanchit-gandhi
  content: "The weights `pytorch_model.bin` are saved using `torch.save` under-the-hood\
    \ when we call `.save_pretrained`: https://github.com/huggingface/transformers/blob/034bc5d26ad7c0e284265d92d3da39d786138545/src/transformers/modeling_utils.py#L1752\n\
    \nThus, you can load them with `torch.load`:\n```python\nfrom transformers import\
    \ WhisperForConditionalGeneration\nimport tempfile\nimport torch\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"\
    openai/whisper-tiny.en\")\n\nwith tempfile.TemporaryDirectory() as tmp_dir_name:\n\
    \    model.save_pretrained(tmp_dir_name)\n    state_dict = torch.load(f\"{tmp_dir_name}/pytorch_model.bin\"\
    )\n```\n\nOf course, if you have the model weights saved locally already, there\
    \ is no need to save the state dict again, just load the state dict from the saved\
    \ path."
  created_at: 2023-09-04 15:46:47+00:00
  edited: true
  hidden: false
  id: 64f609f7653739023198ba79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645b71d19522edfc8e4e8cdd/7RabLiPkl3V8QoP0KISmk.png?w=200&h=200&f=face
      fullname: OpenAi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GPT-4
      type: user
    createdAt: '2023-09-05T16:38:24.000Z'
    data:
      edited: false
      editors:
      - GPT-4
      hidden: false
      identifiedLanguage:
        language: da
        probability: 0.8588969111442566
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/645b71d19522edfc8e4e8cdd/7RabLiPkl3V8QoP0KISmk.png?w=200&h=200&f=face
          fullname: OpenAi
          isHf: false
          isPro: false
          name: GPT-4
          type: user
        html: '<p>Idk</p>

          '
        raw: Idk
        updatedAt: '2023-09-05T16:38:24.894Z'
      numEdits: 0
      reactions: []
    id: 64f75980886c925e536ae3da
    type: comment
  author: GPT-4
  content: Idk
  created_at: 2023-09-05 15:38:24+00:00
  edited: false
  hidden: false
  id: 64f75980886c925e536ae3da
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 61
repo_id: openai/whisper-large-v2
repo_type: model
status: closed
target_branch: null
title: How to convert the model(pytorch_model.bin) to .pt file?
