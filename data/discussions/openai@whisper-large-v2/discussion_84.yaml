!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ss3332
conflicting_files: null
created_at: 2023-10-21 13:39:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b18ef467d730cc7b26f53528d7b55579.svg
      fullname: 's s '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ss3332
      type: user
    createdAt: '2023-10-21T14:39:20.000Z'
    data:
      edited: false
      editors:
      - ss3332
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9704779982566833
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b18ef467d730cc7b26f53528d7b55579.svg
          fullname: 's s '
          isHf: false
          isPro: false
          name: ss3332
          type: user
        html: '<p>The default behavior using the sample code is to run on CPU and
          I''ve not yet seen an explicit example of loading it on the GPU.  Passing
          <code>input_features</code> as a tensor isn''t doing it so I''m wondering
          if there''s a switch somewhere.  I looked around for <code>gpu</code> and
          <code>cuda</code> in the model class but didn''t see anything obvious.</p>

          '
        raw: The default behavior using the sample code is to run on CPU and I've
          not yet seen an explicit example of loading it on the GPU.  Passing `input_features`
          as a tensor isn't doing it so I'm wondering if there's a switch somewhere.  I
          looked around for `gpu` and `cuda` in the model class but didn't see anything
          obvious.
        updatedAt: '2023-10-21T14:39:20.365Z'
      numEdits: 0
      reactions: []
    id: 6533e2987139c5dd8d7446db
    type: comment
  author: ss3332
  content: The default behavior using the sample code is to run on CPU and I've not
    yet seen an explicit example of loading it on the GPU.  Passing `input_features`
    as a tensor isn't doing it so I'm wondering if there's a switch somewhere.  I
    looked around for `gpu` and `cuda` in the model class but didn't see anything
    obvious.
  created_at: 2023-10-21 13:39:20+00:00
  edited: false
  hidden: false
  id: 6533e2987139c5dd8d7446db
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b18ef467d730cc7b26f53528d7b55579.svg
      fullname: 's s '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ss3332
      type: user
    createdAt: '2023-10-21T15:00:39.000Z'
    data:
      edited: false
      editors:
      - ss3332
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6082236766815186
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b18ef467d730cc7b26f53528d7b55579.svg
          fullname: 's s '
          isHf: false
          isPro: false
          name: ss3332
          type: user
        html: "<p>Closing.  Solution is below, have to move the model <code>to(device)</code>\
          \ as well as the inputs.</p>\n<pre><code>device = \"cuda:0\" if torch.cuda.is_available()\
          \ else \"cpu\"\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\"\
          )\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\"\
          ).to(device)\n...\n...\ninput_features = processor(\n       output[\"array\"\
          ], sampling_rate=output[\"sampling_rate\"], return_tensors=\"pt\"\n    ).input_features.to(device)\n\
          </code></pre>\n"
        raw: "Closing.  Solution is below, have to move the model `to(device)` as\
          \ well as the inputs.\n\n```\ndevice = \"cuda:0\" if torch.cuda.is_available()\
          \ else \"cpu\"\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\"\
          )\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\"\
          ).to(device)\n...\n...\ninput_features = processor(\n       output[\"array\"\
          ], sampling_rate=output[\"sampling_rate\"], return_tensors=\"pt\"\n    ).input_features.to(device)\n\
          ```"
        updatedAt: '2023-10-21T15:00:39.691Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6533e797438f63b08e4204cf
    id: 6533e797438f63b08e4204ca
    type: comment
  author: ss3332
  content: "Closing.  Solution is below, have to move the model `to(device)` as well\
    \ as the inputs.\n\n```\ndevice = \"cuda:0\" if torch.cuda.is_available() else\
    \ \"cpu\"\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\"\
    )\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\"\
    ).to(device)\n...\n...\ninput_features = processor(\n       output[\"array\"],\
    \ sampling_rate=output[\"sampling_rate\"], return_tensors=\"pt\"\n    ).input_features.to(device)\n\
    ```"
  created_at: 2023-10-21 14:00:39+00:00
  edited: false
  hidden: false
  id: 6533e797438f63b08e4204ca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/b18ef467d730cc7b26f53528d7b55579.svg
      fullname: 's s '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ss3332
      type: user
    createdAt: '2023-10-21T15:00:39.000Z'
    data:
      status: closed
    id: 6533e797438f63b08e4204cf
    type: status-change
  author: ss3332
  created_at: 2023-10-21 14:00:39+00:00
  id: 6533e797438f63b08e4204cf
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 84
repo_id: openai/whisper-large-v2
repo_type: model
status: closed
target_branch: null
title: Running on GPU?
