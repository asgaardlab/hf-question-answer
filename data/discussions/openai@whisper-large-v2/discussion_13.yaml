!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dkras
conflicting_files: null
created_at: 2023-01-09 04:28:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/90269a130d56f6278e5053df51ebca16.svg
      fullname: Dan Kras
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dkras
      type: user
    createdAt: '2023-01-09T04:28:29.000Z'
    data:
      edited: false
      editors:
      - dkras
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/90269a130d56f6278e5053df51ebca16.svg
          fullname: Dan Kras
          isHf: false
          isPro: false
          name: dkras
          type: user
        html: '<p>Hey all - forgive me in advance here for any silly questions / misunderstanding
          - pretty new to this.</p>

          <p>I''ve been playing around with transcribing an ~8 minute audio file using
          a variety of methods as a test.</p>

          <p>First, I transcribed with whisper on my own machine (e.g. <a rel="nofollow"
          href="https://github.com/openai/whisper#python-usage">using this example</a>).
          This works well! (though slow). </p>

          <p>Then, I deployed a HF inference endpoint using this model (openai/whisper-large-v2),
          and transcribed the file with something like:</p>

          <pre><code>curl https://foobar.us-east-1.aws.endpoints.huggingface.cloud
          \

          -X POST \

          --data-binary ''@sample1.flac'' \

          -H "Authorization: Bearer ABC" \

          -H "Content-Type: audio/flac"

          </code></pre>

          <p>Unfortunately, it seems like the results from the HF inference endpoint
          are significantly worse than the local results (though they both use the
          <code>large-v2</code> model). About ~30% of the transcription / audio is
          "missing". Certain "chunks" of the transcription are just not there (like
          sections of say 20 seconds or so of audio do not get transcribed).</p>

          <p>Any tips or tricks to help debug why this may be happening?</p>

          '
        raw: "Hey all - forgive me in advance here for any silly questions / misunderstanding\
          \ - pretty new to this.\r\n\r\nI've been playing around with transcribing\
          \ an ~8 minute audio file using a variety of methods as a test.\r\n\r\n\
          First, I transcribed with whisper on my own machine (e.g. [using this example](https://github.com/openai/whisper#python-usage)).\
          \ This works well! (though slow). \r\n\r\nThen, I deployed a HF inference\
          \ endpoint using this model (openai/whisper-large-v2), and transcribed the\
          \ file with something like:\r\n```\r\ncurl https://foobar.us-east-1.aws.endpoints.huggingface.cloud\
          \ \\\r\n-X POST \\\r\n--data-binary '@sample1.flac' \\\r\n-H \"Authorization:\
          \ Bearer ABC\" \\\r\n-H \"Content-Type: audio/flac\"\r\n```\r\n\r\nUnfortunately,\
          \ it seems like the results from the HF inference endpoint are significantly\
          \ worse than the local results (though they both use the `large-v2` model).\
          \ About ~30% of the transcription / audio is \"missing\". Certain \"chunks\"\
          \ of the transcription are just not there (like sections of say 20 seconds\
          \ or so of audio do not get transcribed).\r\n\r\nAny tips or tricks to help\
          \ debug why this may be happening?"
        updatedAt: '2023-01-09T04:28:29.795Z'
      numEdits: 0
      reactions: []
    id: 63bb97ed9726f7e58f95a80b
    type: comment
  author: dkras
  content: "Hey all - forgive me in advance here for any silly questions / misunderstanding\
    \ - pretty new to this.\r\n\r\nI've been playing around with transcribing an ~8\
    \ minute audio file using a variety of methods as a test.\r\n\r\nFirst, I transcribed\
    \ with whisper on my own machine (e.g. [using this example](https://github.com/openai/whisper#python-usage)).\
    \ This works well! (though slow). \r\n\r\nThen, I deployed a HF inference endpoint\
    \ using this model (openai/whisper-large-v2), and transcribed the file with something\
    \ like:\r\n```\r\ncurl https://foobar.us-east-1.aws.endpoints.huggingface.cloud\
    \ \\\r\n-X POST \\\r\n--data-binary '@sample1.flac' \\\r\n-H \"Authorization:\
    \ Bearer ABC\" \\\r\n-H \"Content-Type: audio/flac\"\r\n```\r\n\r\nUnfortunately,\
    \ it seems like the results from the HF inference endpoint are significantly worse\
    \ than the local results (though they both use the `large-v2` model). About ~30%\
    \ of the transcription / audio is \"missing\". Certain \"chunks\" of the transcription\
    \ are just not there (like sections of say 20 seconds or so of audio do not get\
    \ transcribed).\r\n\r\nAny tips or tricks to help debug why this may be happening?"
  created_at: 2023-01-09 04:28:29+00:00
  edited: false
  hidden: false
  id: 63bb97ed9726f7e58f95a80b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-01-13T15:39:31.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Hey! When you ran the model locally, what code did you use? This
          could come from the discrepancy between the <code>pipeline</code> and just
          running the model on its own.</p>

          '
        raw: Hey! When you ran the model locally, what code did you use? This could
          come from the discrepancy between the `pipeline` and just running the model
          on its own.
        updatedAt: '2023-01-13T15:39:31.319Z'
      numEdits: 0
      reactions: []
    id: 63c17b331584c1120fed8c70
    type: comment
  author: ArthurZ
  content: Hey! When you ran the model locally, what code did you use? This could
    come from the discrepancy between the `pipeline` and just running the model on
    its own.
  created_at: 2023-01-13 15:39:31+00:00
  edited: false
  hidden: false
  id: 63c17b331584c1120fed8c70
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/90269a130d56f6278e5053df51ebca16.svg
      fullname: Dan Kras
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dkras
      type: user
    createdAt: '2023-01-13T17:39:19.000Z'
    data:
      edited: false
      editors:
      - dkras
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/90269a130d56f6278e5053df51ebca16.svg
          fullname: Dan Kras
          isHf: false
          isPro: false
          name: dkras
          type: user
        html: '<p>something like:</p>

          <pre><code>import whisper

          model = whisper.load_model(''large-v2'')

          model.transcribe(''test.mp3'')

          </code></pre>

          '
        raw: 'something like:

          ```

          import whisper

          model = whisper.load_model(''large-v2'')

          model.transcribe(''test.mp3'')

          ```'
        updatedAt: '2023-01-13T17:39:19.790Z'
      numEdits: 0
      reactions: []
    id: 63c197471b5c1a514dcd5e7c
    type: comment
  author: dkras
  content: 'something like:

    ```

    import whisper

    model = whisper.load_model(''large-v2'')

    model.transcribe(''test.mp3'')

    ```'
  created_at: 2023-01-13 17:39:19+00:00
  edited: false
  hidden: false
  id: 63c197471b5c1a514dcd5e7c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/90269a130d56f6278e5053df51ebca16.svg
      fullname: Dan Kras
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dkras
      type: user
    createdAt: '2023-01-22T02:23:11.000Z'
    data:
      status: closed
    id: 63cc9e0f28e49dcd9f726afa
    type: status-change
  author: dkras
  created_at: 2023-01-22 02:23:11+00:00
  id: 63cc9e0f28e49dcd9f726afa
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43d5b96985ec4fd04ce222ef544e1494.svg
      fullname: Matt Bridges
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: itsindigo
      type: user
    createdAt: '2023-07-26T21:07:02.000Z'
    data:
      edited: false
      editors:
      - itsindigo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9404040575027466
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43d5b96985ec4fd04ce222ef544e1494.svg
          fullname: Matt Bridges
          isHf: false
          isPro: false
          name: itsindigo
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;dkras&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/dkras\">@<span class=\"\
          underline\">dkras</span></a></span>\n\n\t</span></span> -- interested to\
          \ hear if you resolved this, as I'm experiencing something very similar\
          \ with 20-30s chunks of transcript missing when generating from audio</p>\n"
        raw: Hey @dkras -- interested to hear if you resolved this, as I'm experiencing
          something very similar with 20-30s chunks of transcript missing when generating
          from audio
        updatedAt: '2023-07-26T21:07:02.067Z'
      numEdits: 0
      reactions: []
    id: 64c18af664e3e59137ca6c72
    type: comment
  author: itsindigo
  content: Hey @dkras -- interested to hear if you resolved this, as I'm experiencing
    something very similar with 20-30s chunks of transcript missing when generating
    from audio
  created_at: 2023-07-26 20:07:02+00:00
  edited: false
  hidden: false
  id: 64c18af664e3e59137ca6c72
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: openai/whisper-large-v2
repo_type: model
status: closed
target_branch: null
title: Poor transcription performance vs. running whisper locally
