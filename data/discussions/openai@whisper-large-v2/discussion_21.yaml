!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Go2Device
conflicting_files: null
created_at: 2023-02-13 15:55:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/59ff6ff3e7c99fb0d59a3cdce159b59b.svg
      fullname: Go2Device
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Go2Device
      type: user
    createdAt: '2023-02-13T15:55:16.000Z'
    data:
      edited: false
      editors:
      - Go2Device
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/59ff6ff3e7c99fb0d59a3cdce159b59b.svg
          fullname: Go2Device
          isHf: false
          isPro: false
          name: Go2Device
          type: user
        html: "<p>Hello everyone, what are the memory requirements to fine tune this\
          \ model?<br>I try to train the large-v2 model locally on my 3090 with 24GB\
          \  vRAM and even with <code> --auto_find_batch_size</code> I get <code>RuntimeError:\
          \ No executable batch size found, reached zero.</code> or running in CUDA\
          \ OOM.<br>My Workstation is running Ubuntu 22.04, CUDA 11.6, Python 3.9.16,\
          \ pytorch1.13.1 and the <code>run_speech_recognition_seq2seq.py</code> script\
          \ from <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/blob/fd5320bb574ac86745d3aeb60ba2372abc4204ba/examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py\"\
          >Hugging Face</a></p>\n<pre><code class=\"language-bash\">python3 run_speech_recognition_seq2seq.py\
          \ \\\n    --model_name_or_path=<span class=\"hljs-string\">\"openai/whisper-large-v2\"\
          </span> \\\n    --dataset_name=<span class=\"hljs-string\">\"mozilla-foundation/common_voice_11_0\"\
          </span> \\\n    --dataset_config_name=<span class=\"hljs-string\">\"de\"\
          </span> \\\n    --language=<span class=\"hljs-string\">\"german\"</span>\
          \ \\\n    --train_split_name=<span class=\"hljs-string\">\"train+validation\"\
          </span> \\\n    --eval_split_name=<span class=\"hljs-string\">\"test\"</span>\
          \ \\\n    --max_steps=<span class=\"hljs-string\">\"5000\"</span> \\\n \
          \   --output_dir=<span class=\"hljs-string\">\"./whisper-large-v2-de\"</span>\
          \ \\\n    --auto_find_batch_size \\\n    --gradient_accumulation_steps=<span\
          \ class=\"hljs-string\">\"2\"</span> \\\n    --logging_steps=<span class=\"\
          hljs-string\">\"25\"</span> \\\n    --learning_rate=<span class=\"hljs-string\"\
          >\"1e-5\"</span> \\\n    --warmup_steps=<span class=\"hljs-string\">\"500\"\
          </span> \\\n    --evaluation_strategy=<span class=\"hljs-string\">\"steps\"\
          </span> \\\n    --eval_steps=<span class=\"hljs-string\">\"1000\"</span>\
          \ \\\n    --save_strategy=<span class=\"hljs-string\">\"steps\"</span> \\\
          \n    --save_steps=<span class=\"hljs-string\">\"1000\"</span> \\\n    --generation_max_length=<span\
          \ class=\"hljs-string\">\"225\"</span> \\\n    --preprocessing_num_workers=<span\
          \ class=\"hljs-string\">\"1\"</span> \\\n    --length_column_name=<span\
          \ class=\"hljs-string\">\"input_length\"</span> \\\n    --max_duration_in_seconds=<span\
          \ class=\"hljs-string\">\"30\"</span> \\\n    --text_column_name=<span class=\"\
          hljs-string\">\"sentence\"</span> \\\n    --freeze_feature_encoder=<span\
          \ class=\"hljs-string\">\"False\"</span> \\\n    --report_to=<span class=\"\
          hljs-string\">\"tensorboard\"</span> \\\n    --metric_for_best_model=<span\
          \ class=\"hljs-string\">\"wer\"</span> \\\n    --gradient_checkpointing\
          \ \\\n    --group_by_length \\\n    --fp16 \\\n    --overwrite_output_dir\
          \ \\\n    --do_train \\\n    --do_eval \\\n    --predict_with_generate \\\
          \n    --use_auth_token \n</code></pre>\n"
        raw: "Hello everyone, what are the memory requirements to fine tune this model?\r\
          \nI try to train the large-v2 model locally on my 3090 with 24GB  vRAM and\
          \ even with ``` --auto_find_batch_size``` I get ```RuntimeError: No executable\
          \ batch size found, reached zero.``` or running in CUDA OOM.\r\nMy Workstation\
          \ is running Ubuntu 22.04, CUDA 11.6, Python 3.9.16, pytorch1.13.1 and the\
          \ ```run_speech_recognition_seq2seq.py``` script from [Hugging Face](https://github.com/huggingface/transformers/blob/fd5320bb574ac86745d3aeb60ba2372abc4204ba/examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py)\r\
          \n```bash\r\npython3 run_speech_recognition_seq2seq.py \\\r\n\t--model_name_or_path=\"\
          openai/whisper-large-v2\" \\\r\n\t--dataset_name=\"mozilla-foundation/common_voice_11_0\"\
          \ \\\r\n\t--dataset_config_name=\"de\" \\\r\n\t--language=\"german\" \\\r\
          \n\t--train_split_name=\"train+validation\" \\\r\n\t--eval_split_name=\"\
          test\" \\\r\n\t--max_steps=\"5000\" \\\r\n\t--output_dir=\"./whisper-large-v2-de\"\
          \ \\\r\n\t--auto_find_batch_size \\\r\n\t--gradient_accumulation_steps=\"\
          2\" \\\r\n\t--logging_steps=\"25\" \\\r\n\t--learning_rate=\"1e-5\" \\\r\
          \n\t--warmup_steps=\"500\" \\\r\n\t--evaluation_strategy=\"steps\" \\\r\n\
          \t--eval_steps=\"1000\" \\\r\n\t--save_strategy=\"steps\" \\\r\n\t--save_steps=\"\
          1000\" \\\r\n\t--generation_max_length=\"225\" \\\r\n\t--preprocessing_num_workers=\"\
          1\" \\\r\n\t--length_column_name=\"input_length\" \\\r\n\t--max_duration_in_seconds=\"\
          30\" \\\r\n\t--text_column_name=\"sentence\" \\\r\n\t--freeze_feature_encoder=\"\
          False\" \\\r\n\t--report_to=\"tensorboard\" \\\r\n\t--metric_for_best_model=\"\
          wer\" \\\r\n\t--gradient_checkpointing \\\r\n\t--group_by_length \\\r\n\t\
          --fp16 \\\r\n\t--overwrite_output_dir \\\r\n\t--do_train \\\r\n\t--do_eval\
          \ \\\r\n\t--predict_with_generate \\\r\n\t--use_auth_token \r\n```"
        updatedAt: '2023-02-13T15:55:16.459Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - dpieski
    id: 63ea5d64c9d1e22a28c07553
    type: comment
  author: Go2Device
  content: "Hello everyone, what are the memory requirements to fine tune this model?\r\
    \nI try to train the large-v2 model locally on my 3090 with 24GB  vRAM and even\
    \ with ``` --auto_find_batch_size``` I get ```RuntimeError: No executable batch\
    \ size found, reached zero.``` or running in CUDA OOM.\r\nMy Workstation is running\
    \ Ubuntu 22.04, CUDA 11.6, Python 3.9.16, pytorch1.13.1 and the ```run_speech_recognition_seq2seq.py```\
    \ script from [Hugging Face](https://github.com/huggingface/transformers/blob/fd5320bb574ac86745d3aeb60ba2372abc4204ba/examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py)\r\
    \n```bash\r\npython3 run_speech_recognition_seq2seq.py \\\r\n\t--model_name_or_path=\"\
    openai/whisper-large-v2\" \\\r\n\t--dataset_name=\"mozilla-foundation/common_voice_11_0\"\
    \ \\\r\n\t--dataset_config_name=\"de\" \\\r\n\t--language=\"german\" \\\r\n\t\
    --train_split_name=\"train+validation\" \\\r\n\t--eval_split_name=\"test\" \\\r\
    \n\t--max_steps=\"5000\" \\\r\n\t--output_dir=\"./whisper-large-v2-de\" \\\r\n\
    \t--auto_find_batch_size \\\r\n\t--gradient_accumulation_steps=\"2\" \\\r\n\t\
    --logging_steps=\"25\" \\\r\n\t--learning_rate=\"1e-5\" \\\r\n\t--warmup_steps=\"\
    500\" \\\r\n\t--evaluation_strategy=\"steps\" \\\r\n\t--eval_steps=\"1000\" \\\
    \r\n\t--save_strategy=\"steps\" \\\r\n\t--save_steps=\"1000\" \\\r\n\t--generation_max_length=\"\
    225\" \\\r\n\t--preprocessing_num_workers=\"1\" \\\r\n\t--length_column_name=\"\
    input_length\" \\\r\n\t--max_duration_in_seconds=\"30\" \\\r\n\t--text_column_name=\"\
    sentence\" \\\r\n\t--freeze_feature_encoder=\"False\" \\\r\n\t--report_to=\"tensorboard\"\
    \ \\\r\n\t--metric_for_best_model=\"wer\" \\\r\n\t--gradient_checkpointing \\\r\
    \n\t--group_by_length \\\r\n\t--fp16 \\\r\n\t--overwrite_output_dir \\\r\n\t--do_train\
    \ \\\r\n\t--do_eval \\\r\n\t--predict_with_generate \\\r\n\t--use_auth_token \r\
    \n```"
  created_at: 2023-02-13 15:55:16+00:00
  edited: false
  hidden: false
  id: 63ea5d64c9d1e22a28c07553
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-02-17T14:23:21.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Go2Device&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Go2Device\"\
          >@<span class=\"underline\">Go2Device</span></a></span>\n\n\t</span></span>!\
          \ I reckon you'll be able to fine-tune the large-v2 model with a 24GB GPU\
          \ if you use DeepSpeed. It's quite a straightforward extension to the training\
          \ set-up you've already got, see <a rel=\"nofollow\" href=\"https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#deepspeed\"\
          >https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#deepspeed</a>\
          \ for details</p>\n"
        raw: Hey @Go2Device! I reckon you'll be able to fine-tune the large-v2 model
          with a 24GB GPU if you use DeepSpeed. It's quite a straightforward extension
          to the training set-up you've already got, see https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#deepspeed
          for details
        updatedAt: '2023-02-17T14:23:21.118Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Go2Device
        - NeoYxm
      - count: 1
        reaction: "\U0001F91D"
        users:
        - artyomboyko
    id: 63ef8dd902c246819b9c7e09
    type: comment
  author: sanchit-gandhi
  content: Hey @Go2Device! I reckon you'll be able to fine-tune the large-v2 model
    with a 24GB GPU if you use DeepSpeed. It's quite a straightforward extension to
    the training set-up you've already got, see https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#deepspeed
    for details
  created_at: 2023-02-17 14:23:21+00:00
  edited: false
  hidden: false
  id: 63ef8dd902c246819b9c7e09
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/59ff6ff3e7c99fb0d59a3cdce159b59b.svg
      fullname: Go2Device
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Go2Device
      type: user
    createdAt: '2023-02-17T20:46:18.000Z'
    data:
      edited: false
      editors:
      - Go2Device
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/59ff6ff3e7c99fb0d59a3cdce159b59b.svg
          fullname: Go2Device
          isHf: false
          isPro: false
          name: Go2Device
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>!\
          \ Thank you for this hint. Now, my CPU RAM are not enough (48GB).<br>But\
          \ thankful this is cheaper to fix then a bigger GPU.<br>For now, I canceled\
          \ this project and will take a look in few months.</p>\n"
        raw: 'Hey @sanchit-gandhi! Thank you for this hint. Now, my CPU RAM are not
          enough (48GB).

          But thankful this is cheaper to fix then a bigger GPU.

          For now, I canceled this project and will take a look in few months.

          '
        updatedAt: '2023-02-17T20:46:18.065Z'
      numEdits: 0
      reactions: []
      relatedEventId: 63efe79a02ab9938d77deccb
    id: 63efe79a02ab9938d77decca
    type: comment
  author: Go2Device
  content: 'Hey @sanchit-gandhi! Thank you for this hint. Now, my CPU RAM are not
    enough (48GB).

    But thankful this is cheaper to fix then a bigger GPU.

    For now, I canceled this project and will take a look in few months.

    '
  created_at: 2023-02-17 20:46:18+00:00
  edited: false
  hidden: false
  id: 63efe79a02ab9938d77decca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/59ff6ff3e7c99fb0d59a3cdce159b59b.svg
      fullname: Go2Device
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Go2Device
      type: user
    createdAt: '2023-02-17T20:46:18.000Z'
    data:
      status: closed
    id: 63efe79a02ab9938d77deccb
    type: status-change
  author: Go2Device
  created_at: 2023-02-17 20:46:18+00:00
  id: 63efe79a02ab9938d77deccb
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-02-22T13:57:18.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Go2Device&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Go2Device\"\
          >@<span class=\"underline\">Go2Device</span></a></span>\n\n\t</span></span>!\
          \ What error are you getting regarding CPU RAM? It might be that we need\
          \ to reduce the dataset's <a href=\"https://huggingface.co/docs/datasets/v2.10.0/en/package_reference/main_classes#datasets.DatasetDict.map.writer_batch_size\"\
          ><code>writer_batch_size</code></a> to a lower value (lower value = less\
          \ CPU memory but slower processing). Happy to help explore other solutions\
          \ to reducing CPU RAM! This is the first time I've heard CPU RAM being a\
          \ limiting factor for fine-tuning Whisper so I'm eager to find a solution\
          \ here!</p>\n"
        raw: Hey @Go2Device! What error are you getting regarding CPU RAM? It might
          be that we need to reduce the dataset's [`writer_batch_size`](https://huggingface.co/docs/datasets/v2.10.0/en/package_reference/main_classes#datasets.DatasetDict.map.writer_batch_size)
          to a lower value (lower value = less CPU memory but slower processing).
          Happy to help explore other solutions to reducing CPU RAM! This is the first
          time I've heard CPU RAM being a limiting factor for fine-tuning Whisper
          so I'm eager to find a solution here!
        updatedAt: '2023-02-22T13:57:18.931Z'
      numEdits: 0
      reactions: []
    id: 63f61f3e8391e36bb357055d
    type: comment
  author: sanchit-gandhi
  content: Hey @Go2Device! What error are you getting regarding CPU RAM? It might
    be that we need to reduce the dataset's [`writer_batch_size`](https://huggingface.co/docs/datasets/v2.10.0/en/package_reference/main_classes#datasets.DatasetDict.map.writer_batch_size)
    to a lower value (lower value = less CPU memory but slower processing). Happy
    to help explore other solutions to reducing CPU RAM! This is the first time I've
    heard CPU RAM being a limiting factor for fine-tuning Whisper so I'm eager to
    find a solution here!
  created_at: 2023-02-22 13:57:18+00:00
  edited: false
  hidden: false
  id: 63f61f3e8391e36bb357055d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/59ff6ff3e7c99fb0d59a3cdce159b59b.svg
      fullname: Go2Device
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Go2Device
      type: user
    createdAt: '2023-03-01T13:29:08.000Z'
    data:
      edited: false
      editors:
      - Go2Device
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/59ff6ff3e7c99fb0d59a3cdce159b59b.svg
          fullname: Go2Device
          isHf: false
          isPro: false
          name: Go2Device
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ ! Thank you for your offer to help me in this case. Currently a other\
          \ model is in training, but when this finished i will again test whisper.</p>\n"
        raw: Hello @sanchit-gandhi ! Thank you for your offer to help me in this case.
          Currently a other model is in training, but when this finished i will again
          test whisper.
        updatedAt: '2023-03-01T13:29:08.392Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - sanchit-gandhi
    id: 63ff53246bb959b94e70ab78
    type: comment
  author: Go2Device
  content: Hello @sanchit-gandhi ! Thank you for your offer to help me in this case.
    Currently a other model is in training, but when this finished i will again test
    whisper.
  created_at: 2023-03-01 13:29:08+00:00
  edited: false
  hidden: false
  id: 63ff53246bb959b94e70ab78
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/59ff6ff3e7c99fb0d59a3cdce159b59b.svg
      fullname: Go2Device
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Go2Device
      type: user
    createdAt: '2023-03-17T14:45:45.000Z'
    data:
      edited: false
      editors:
      - Go2Device
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/59ff6ff3e7c99fb0d59a3cdce159b59b.svg
          fullname: Go2Device
          isHf: false
          isPro: false
          name: Go2Device
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>,\
          \ I am Ready to start a new test. I upgraded my RAM from 48 up to 64 GB.<br>For\
          \ the other project I reinstalled my Workstation and now using Docker for\
          \ training.<br>Have you a working NGC Dockerfile for whisper and Transformers?<br>Nvidias\
          \ nvcr.io/nvidia/pytorch Container do not have torchaudio and finding the\
          \ matching version isint quite easy.<br>Thanks</p>\n"
        raw: "Hey @sanchit-gandhi, I am Ready to start a new test. I upgraded my RAM\
          \ from 48 up to 64 GB.\nFor the other project I reinstalled my Workstation\
          \ and now using Docker for training.\nHave you a working NGC Dockerfile\
          \ for whisper and Transformers? \nNvidias nvcr.io/nvidia/pytorch Container\
          \ do not have torchaudio and finding the matching version isint quite easy.\n\
          Thanks"
        updatedAt: '2023-03-17T14:45:45.538Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64147d19ec0fc4be8fb0282b
    id: 64147d19ec0fc4be8fb02828
    type: comment
  author: Go2Device
  content: "Hey @sanchit-gandhi, I am Ready to start a new test. I upgraded my RAM\
    \ from 48 up to 64 GB.\nFor the other project I reinstalled my Workstation and\
    \ now using Docker for training.\nHave you a working NGC Dockerfile for whisper\
    \ and Transformers? \nNvidias nvcr.io/nvidia/pytorch Container do not have torchaudio\
    \ and finding the matching version isint quite easy.\nThanks"
  created_at: 2023-03-17 13:45:45+00:00
  edited: false
  hidden: false
  id: 64147d19ec0fc4be8fb02828
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/59ff6ff3e7c99fb0d59a3cdce159b59b.svg
      fullname: Go2Device
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Go2Device
      type: user
    createdAt: '2023-03-17T14:45:45.000Z'
    data:
      status: open
    id: 64147d19ec0fc4be8fb0282b
    type: status-change
  author: Go2Device
  created_at: 2023-03-17 13:45:45+00:00
  id: 64147d19ec0fc4be8fb0282b
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-03-17T17:04:53.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Go2Device&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Go2Device\"\
          >@<span class=\"underline\">Go2Device</span></a></span>\n\n\t</span></span>!\
          \ There isn't a docker file, but it's pretty easy to get set-up with a pip\
          \ env! This is a very in-depth guide as to how you can set-up an env for\
          \ fine-tuning Whisper: <a rel=\"nofollow\" href=\"https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#set-up-an-environment\"\
          >https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#set-up-an-environment</a></p>\n"
        raw: 'Hey @Go2Device! There isn''t a docker file, but it''s pretty easy to
          get set-up with a pip env! This is a very in-depth guide as to how you can
          set-up an env for fine-tuning Whisper: https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#set-up-an-environment'
        updatedAt: '2023-03-17T17:04:53.208Z'
      numEdits: 0
      reactions: []
    id: 64149db501a998c81c20781d
    type: comment
  author: sanchit-gandhi
  content: 'Hey @Go2Device! There isn''t a docker file, but it''s pretty easy to get
    set-up with a pip env! This is a very in-depth guide as to how you can set-up
    an env for fine-tuning Whisper: https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#set-up-an-environment'
  created_at: 2023-03-17 16:04:53+00:00
  edited: false
  hidden: false
  id: 64149db501a998c81c20781d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-03-17T17:06:22.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>You can ignore the bit about installing ffmpeg! It's all handled\
          \ by datasets now \U0001F917</p>\n"
        raw: "You can ignore the bit about installing ffmpeg! It's all handled by\
          \ datasets now \U0001F917"
        updatedAt: '2023-03-17T17:06:22.232Z'
      numEdits: 0
      reactions: []
    id: 64149e0e01a998c81c2091f6
    type: comment
  author: sanchit-gandhi
  content: "You can ignore the bit about installing ffmpeg! It's all handled by datasets\
    \ now \U0001F917"
  created_at: 2023-03-17 16:06:22+00:00
  edited: false
  hidden: false
  id: 64149e0e01a998c81c2091f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d88b4e05582ec4baaabb6ca9f97f1791.svg
      fullname: "Tu\u1EA5n L\xEA"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tuanle
      type: user
    createdAt: '2023-04-26T19:03:14.000Z'
    data:
      edited: false
      editors:
      - tuanle
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d88b4e05582ec4baaabb6ca9f97f1791.svg
          fullname: "Tu\u1EA5n L\xEA"
          isHf: false
          isPro: false
          name: tuanle
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Go2Device&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Go2Device\"\
          >@<span class=\"underline\">Go2Device</span></a></span>\n\n\t</span></span>!\
          \ What is your recommended batch size after using Deepspeed with 24GB vRAM\
          \ ? How much time does it take to complete ?<br>Thank you bro</p>\n"
        raw: 'Hey @Go2Device! What is your recommended batch size after using Deepspeed
          with 24GB vRAM ? How much time does it take to complete ?

          Thank you bro'
        updatedAt: '2023-04-26T19:03:14.979Z'
      numEdits: 0
      reactions: []
    id: 64497572b3cd701e0a06b552
    type: comment
  author: tuanle
  content: 'Hey @Go2Device! What is your recommended batch size after using Deepspeed
    with 24GB vRAM ? How much time does it take to complete ?

    Thank you bro'
  created_at: 2023-04-26 18:03:14+00:00
  edited: false
  hidden: false
  id: 64497572b3cd701e0a06b552
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-05-02T11:07:56.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;tuanle&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/tuanle\">@<span class=\"\
          underline\">tuanle</span></a></span>\n\n\t</span></span> - you should probably\
          \ set the batch size in accordance with your device (e.g. keep increasing\
          \ it in multiples of 2 until you get an OOM). There are some rough speed\
          \ figures here: <a rel=\"nofollow\" href=\"https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-batch-sizes-with-deepspeed\"\
          >https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-batch-sizes-with-deepspeed</a></p>\n"
        raw: 'Hey @tuanle - you should probably set the batch size in accordance with
          your device (e.g. keep increasing it in multiples of 2 until you get an
          OOM). There are some rough speed figures here: https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-batch-sizes-with-deepspeed'
        updatedAt: '2023-05-02T11:07:56.714Z'
      numEdits: 0
      reactions: []
    id: 6450ef0c8f876fbfc5ed54f6
    type: comment
  author: sanchit-gandhi
  content: 'Hey @tuanle - you should probably set the batch size in accordance with
    your device (e.g. keep increasing it in multiples of 2 until you get an OOM).
    There are some rough speed figures here: https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-batch-sizes-with-deepspeed'
  created_at: 2023-05-02 10:07:56+00:00
  edited: false
  hidden: false
  id: 6450ef0c8f876fbfc5ed54f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/296aa1cb64629adc3b5292566d50a64e.svg
      fullname: H Puc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: honzapucalek
      type: user
    createdAt: '2023-06-08T01:55:41.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/296aa1cb64629adc3b5292566d50a64e.svg
          fullname: H Puc
          isHf: false
          isPro: false
          name: honzapucalek
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-06-08T02:47:48.390Z'
      numEdits: 1
      reactions: []
    id: 6481351dbb25a636c9e65f19
    type: comment
  author: honzapucalek
  content: This comment has been hidden
  created_at: 2023-06-08 00:55:41+00:00
  edited: true
  hidden: true
  id: 6481351dbb25a636c9e65f19
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/296aa1cb64629adc3b5292566d50a64e.svg
      fullname: H Puc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: honzapucalek
      type: user
    createdAt: '2023-06-08T22:40:49.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/296aa1cb64629adc3b5292566d50a64e.svg
          fullname: H Puc
          isHf: false
          isPro: false
          name: honzapucalek
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-06-08T23:15:33.346Z'
      numEdits: 0
      reactions: []
    id: 648258f101021570f410266d
    type: comment
  author: honzapucalek
  content: This comment has been hidden
  created_at: 2023-06-08 21:40:49+00:00
  edited: true
  hidden: true
  id: 648258f101021570f410266d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f0cfbe52a259b855d290e/xmeMuNoi-3Ka5Ux_X5dJn.jpeg?w=200&h=200&f=face
      fullname: Artyom Boyko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: artyomboyko
      type: user
    createdAt: '2023-08-29T14:53:32.000Z'
    data:
      edited: false
      editors:
      - artyomboyko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7702843546867371
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f0cfbe52a259b855d290e/xmeMuNoi-3Ka5Ux_X5dJn.jpeg?w=200&h=200&f=face
          fullname: Artyom Boyko
          isHf: false
          isPro: false
          name: artyomboyko
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>.\
          \ Table <a rel=\"nofollow\" href=\"https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-batch-sizes-with-deepspeed\"\
          >https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-batch-sizes-with-deepspeed</a>\
          \ does not list values for 24GB, what do you recommend?</p>\n"
        raw: Hi @sanchit-gandhi. Table https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-batch-sizes-with-deepspeed
          does not list values for 24GB, what do you recommend?
        updatedAt: '2023-08-29T14:53:32.927Z'
      numEdits: 0
      reactions: []
    id: 64ee066c0ef0ca5db165be89
    type: comment
  author: artyomboyko
  content: Hi @sanchit-gandhi. Table https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-batch-sizes-with-deepspeed
    does not list values for 24GB, what do you recommend?
  created_at: 2023-08-29 13:53:32+00:00
  edited: false
  hidden: false
  id: 64ee066c0ef0ca5db165be89
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-09-06T15:18:03.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8833398222923279
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;artyomboyko&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/artyomboyko\"\
          >@<span class=\"underline\">artyomboyko</span></a></span>\n\n\t</span></span>\
          \ - you'll have to experiment to find what works here! Try bs=32 first.\
          \ If it OOMs, then drop it to bs=16. If it OOMs again, drop it to bs=8,\
          \ and so on... Once you go lower than bs=8, it's worth adding gradient accumulation\
          \ steps so you maintain a reasonable batch size (see <a rel=\"nofollow\"\
          \ href=\"https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-training-configurations\"\
          >https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-training-configurations</a>)</p>\n"
        raw: Hey @artyomboyko - you'll have to experiment to find what works here!
          Try bs=32 first. If it OOMs, then drop it to bs=16. If it OOMs again, drop
          it to bs=8, and so on... Once you go lower than bs=8, it's worth adding
          gradient accumulation steps so you maintain a reasonable batch size (see
          https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-training-configurations)
        updatedAt: '2023-09-06T15:18:58.778Z'
      numEdits: 1
      reactions: []
    id: 64f8982bd493d8b0d2b7bb02
    type: comment
  author: sanchit-gandhi
  content: Hey @artyomboyko - you'll have to experiment to find what works here! Try
    bs=32 first. If it OOMs, then drop it to bs=16. If it OOMs again, drop it to bs=8,
    and so on... Once you go lower than bs=8, it's worth adding gradient accumulation
    steps so you maintain a reasonable batch size (see https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event#recommended-training-configurations)
  created_at: 2023-09-06 14:18:03+00:00
  edited: true
  hidden: false
  id: 64f8982bd493d8b0d2b7bb02
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e6e5aa88b74e5e307142c507ba7591cb.svg
      fullname: Gupta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sunnnnny
      type: user
    createdAt: '2023-10-12T12:46:00.000Z'
    data:
      edited: false
      editors:
      - Sunnnnny
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9080475568771362
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e6e5aa88b74e5e307142c507ba7591cb.svg
          fullname: Gupta
          isHf: false
          isPro: false
          name: Sunnnnny
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ , I have finetuned the whisper mode and save the model into a local folder\
          \ , now I am facing difficulties while trying to load the model, any suggestions\
          \ will be helpful</p>\n"
        raw: 'Hi @sanchit-gandhi , I have finetuned the whisper mode and save the
          model into a local folder , now I am facing difficulties while trying to
          load the model, any suggestions will be helpful

          '
        updatedAt: '2023-10-12T12:46:00.123Z'
      numEdits: 0
      reactions: []
    id: 6527ea882dbb58b8e2876499
    type: comment
  author: Sunnnnny
  content: 'Hi @sanchit-gandhi , I have finetuned the whisper mode and save the model
    into a local folder , now I am facing difficulties while trying to load the model,
    any suggestions will be helpful

    '
  created_at: 2023-10-12 11:46:00+00:00
  edited: false
  hidden: false
  id: 6527ea882dbb58b8e2876499
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-10-13T16:47:32.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.673907995223999
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Sunnnnny&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Sunnnnny\"\
          >@<span class=\"underline\">Sunnnnny</span></a></span>\n\n\t</span></span>\
          \ - you can load the model from pre-trained by specifying the path to your\
          \ save folder:</p>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span>\
          \ WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(<span\
          \ class=\"hljs-string\">\"/path/to/save/dir\"</span>)\n</code></pre>\n<p>Alternatively,\
          \ you can use the <a href=\"https://huggingface.co/openai/whisper-large-v2#long-form-transcription\"\
          >pipeline</a> for easy inference:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> pipeline\n\nasr_pipe = pipeline(<span class=\"hljs-string\"\
          >\"automatic-speech-recognition\"</span>, model=<span class=\"hljs-string\"\
          >\"/path/to/save/dir\"</span>)\nasr_pipe(<span class=\"hljs-string\">\"\
          https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\"</span>)\n\
          </code></pre>\n<p>Could you please share a code-snippet that shows what\
          \ you've tried and what's not working (i.e. the full traceback)?</p>\n"
        raw: 'Hey @Sunnnnny - you can load the model from pre-trained by specifying
          the path to your save folder:

          ```python

          from transformers import WhisperForConditionalGeneration


          model = WhisperForConditionalGeneration.from_pretrained("/path/to/save/dir")

          ```


          Alternatively, you can use the [pipeline](https://huggingface.co/openai/whisper-large-v2#long-form-transcription)
          for easy inference:

          ```python

          from transformers import pipeline


          asr_pipe = pipeline("automatic-speech-recognition", model="/path/to/save/dir")

          asr_pipe("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac")

          ```


          Could you please share a code-snippet that shows what you''ve tried and
          what''s not working (i.e. the full traceback)?'
        updatedAt: '2023-10-13T16:48:30.861Z'
      numEdits: 1
      reactions: []
    id: 652974a4b355406e2da6d9f7
    type: comment
  author: sanchit-gandhi
  content: 'Hey @Sunnnnny - you can load the model from pre-trained by specifying
    the path to your save folder:

    ```python

    from transformers import WhisperForConditionalGeneration


    model = WhisperForConditionalGeneration.from_pretrained("/path/to/save/dir")

    ```


    Alternatively, you can use the [pipeline](https://huggingface.co/openai/whisper-large-v2#long-form-transcription)
    for easy inference:

    ```python

    from transformers import pipeline


    asr_pipe = pipeline("automatic-speech-recognition", model="/path/to/save/dir")

    asr_pipe("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac")

    ```


    Could you please share a code-snippet that shows what you''ve tried and what''s
    not working (i.e. the full traceback)?'
  created_at: 2023-10-13 15:47:32+00:00
  edited: true
  hidden: false
  id: 652974a4b355406e2da6d9f7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 21
repo_id: openai/whisper-large-v2
repo_type: model
status: open
target_branch: null
title: Memory requirements for local training
