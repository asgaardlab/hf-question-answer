!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sboudouk
conflicting_files: null
created_at: 2023-02-23 09:42:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef04a63ee181be3f305dbb8c33b1682e.svg
      fullname: Sami
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sboudouk
      type: user
    createdAt: '2023-02-23T09:42:20.000Z'
    data:
      edited: false
      editors:
      - sboudouk
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef04a63ee181be3f305dbb8c33b1682e.svg
          fullname: Sami
          isHf: false
          isPro: false
          name: sboudouk
          type: user
        html: '<p>By using the same audios, I do not get the same transcription from
          Whisper large v2 on HF and the Whisper large v2 that I pulled from Github
          on my python script.</p>

          <p>I think I have to mess with settings (temperature ?) but I can''t see
          what settings are used on hugging face.</p>

          <p>Any idea to make my local Whisper large v2 instance to match the one
          hosted on here on hugging face or why do I have different results ? (I''d
          say they are different from 5 to 10%) </p>

          <p>Thanks.</p>

          '
        raw: "By using the same audios, I do not get the same transcription from Whisper\
          \ large v2 on HF and the Whisper large v2 that I pulled from Github on my\
          \ python script.\r\n\r\nI think I have to mess with settings (temperature\
          \ ?) but I can't see what settings are used on hugging face.\r\n\r\nAny\
          \ idea to make my local Whisper large v2 instance to match the one hosted\
          \ on here on hugging face or why do I have different results ? (I'd say\
          \ they are different from 5 to 10%) \r\n\r\nThanks."
        updatedAt: '2023-02-23T09:42:20.049Z'
      numEdits: 0
      reactions: []
    id: 63f734fcdf66696652ede311
    type: comment
  author: sboudouk
  content: "By using the same audios, I do not get the same transcription from Whisper\
    \ large v2 on HF and the Whisper large v2 that I pulled from Github on my python\
    \ script.\r\n\r\nI think I have to mess with settings (temperature ?) but I can't\
    \ see what settings are used on hugging face.\r\n\r\nAny idea to make my local\
    \ Whisper large v2 instance to match the one hosted on here on hugging face or\
    \ why do I have different results ? (I'd say they are different from 5 to 10%)\
    \ \r\n\r\nThanks."
  created_at: 2023-02-23 09:42:20+00:00
  edited: false
  hidden: false
  id: 63f734fcdf66696652ede311
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-02-23T11:30:12.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;sboudouk&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sboudouk\"\
          >@<span class=\"underline\">sboudouk</span></a></span>\n\n\t</span></span>!\
          \ We use the default generation kwargs in HF: <a href=\"https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig.temperature\"\
          >https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig.temperature</a></p>\n\
          <p>You can override these by passing them to the <code>.generate</code>\
          \ method if you're using model/processor, or by forwarding <code>generate_kwargs={\"\
          temperature\": 1}</code> to the pipeline if you're using the pipeline.</p>\n\
          <p>Do you have a code snippet for your comparison? If you could share it\
          \ I'd be happy to provide some pointers as to where we can make changes!</p>\n"
        raw: 'Hey @sboudouk! We use the default generation kwargs in HF: https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig.temperature


          You can override these by passing them to the `.generate` method if you''re
          using model/processor, or by forwarding `generate_kwargs={"temperature":
          1}` to the pipeline if you''re using the pipeline.


          Do you have a code snippet for your comparison? If you could share it I''d
          be happy to provide some pointers as to where we can make changes!'
        updatedAt: '2023-02-23T11:30:12.878Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - kurianbenoy
    id: 63f74e441cb66f416c6b0b78
    type: comment
  author: sanchit-gandhi
  content: 'Hey @sboudouk! We use the default generation kwargs in HF: https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig.temperature


    You can override these by passing them to the `.generate` method if you''re using
    model/processor, or by forwarding `generate_kwargs={"temperature": 1}` to the
    pipeline if you''re using the pipeline.


    Do you have a code snippet for your comparison? If you could share it I''d be
    happy to provide some pointers as to where we can make changes!'
  created_at: 2023-02-23 11:30:12+00:00
  edited: false
  hidden: false
  id: 63f74e441cb66f416c6b0b78
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef04a63ee181be3f305dbb8c33b1682e.svg
      fullname: Sami
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sboudouk
      type: user
    createdAt: '2023-02-23T16:28:54.000Z'
    data:
      edited: false
      editors:
      - sboudouk
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef04a63ee181be3f305dbb8c33b1682e.svg
          fullname: Sami
          isHf: false
          isPro: false
          name: sboudouk
          type: user
        html: '<p>Sure, thanks for the link , struggled to find the default generation
          kwargs, kind of new to HF.</p>

          <p>Here is the snippet where I build my whisper model instance in my python
          code:</p>

          <p><code>transcribe = model.transcribe(audio, language=''fr'', temperature=0.0)</code></p>

          <p>So from my understanding, I need to add every correspounding kwargs as
          a parameter to transcribe just as I added the language and the temperature
          ?</p>

          '
        raw: 'Sure, thanks for the link , struggled to find the default generation
          kwargs, kind of new to HF.


          Here is the snippet where I build my whisper model instance in my python
          code:


          `transcribe = model.transcribe(audio, language=''fr'', temperature=0.0)`


          So from my understanding, I need to add every correspounding kwargs as a
          parameter to transcribe just as I added the language and the temperature
          ?'
        updatedAt: '2023-02-23T16:28:54.328Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - kurianbenoy
    id: 63f79446ae70dee4802e21a4
    type: comment
  author: sboudouk
  content: 'Sure, thanks for the link , struggled to find the default generation kwargs,
    kind of new to HF.


    Here is the snippet where I build my whisper model instance in my python code:


    `transcribe = model.transcribe(audio, language=''fr'', temperature=0.0)`


    So from my understanding, I need to add every correspounding kwargs as a parameter
    to transcribe just as I added the language and the temperature ?'
  created_at: 2023-02-23 16:28:54+00:00
  edited: false
  hidden: false
  id: 63f79446ae70dee4802e21a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-03-03T14:20:13.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;sboudouk&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sboudouk\"\
          >@<span class=\"underline\">sboudouk</span></a></span>\n\n\t</span></span>!\
          \ Yep, you can just pass <code>generate_kwargs</code> as required:</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">import</span>\
          \ torch\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"\
          hljs-keyword\">import</span> pipeline\n<span class=\"hljs-keyword\">from</span>\
          \ datasets <span class=\"hljs-keyword\">import</span> load_dataset\n\ndevice\
          \ = <span class=\"hljs-string\">\"cuda:0\"</span> <span class=\"hljs-keyword\"\
          >if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span>\
          \ <span class=\"hljs-string\">\"cpu\"</span>\n\npipe = pipeline(\n  <span\
          \ class=\"hljs-string\">\"automatic-speech-recognition\"</span>,\n  model=<span\
          \ class=\"hljs-string\">\"openai/whisper-large-v2\"</span>,\n  chunk_length_s=<span\
          \ class=\"hljs-number\">30</span>,\n  device=device,\n)\n\nds = load_dataset(<span\
          \ class=\"hljs-string\">\"hf-internal-testing/librispeech_asr_dummy\"</span>,\
          \ <span class=\"hljs-string\">\"clean\"</span>, split=<span class=\"hljs-string\"\
          >\"validation\"</span>)\nsample = ds[<span class=\"hljs-number\">0</span>][<span\
          \ class=\"hljs-string\">\"audio\"</span>]\n\ngenerate_kwargs = {<span class=\"\
          hljs-string\">\"language\"</span>: <span class=\"hljs-string\">\"&lt;|fr|&gt;\"\
          </span>, <span class=\"hljs-string\">\"temperature\"</span>: <span class=\"\
          hljs-number\">0.0</span>}  <span class=\"hljs-comment\"># add any other\
          \ generate kwargs you require </span>\nprediction = pipe(sample, generate_kwargs=generate_kwargs\
          \ )[<span class=\"hljs-string\">\"text\"</span>]\n</code></pre>\n"
        raw: "Hey @sboudouk! Yep, you can just pass `generate_kwargs` as required:\n\
          \n```python\nimport torch\nfrom transformers import pipeline\nfrom datasets\
          \ import load_dataset\n\ndevice = \"cuda:0\" if torch.cuda.is_available()\
          \ else \"cpu\"\n\npipe = pipeline(\n  \"automatic-speech-recognition\",\n\
          \  model=\"openai/whisper-large-v2\",\n  chunk_length_s=30,\n  device=device,\n\
          )\n\nds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"\
          clean\", split=\"validation\")\nsample = ds[0][\"audio\"]\n\ngenerate_kwargs\
          \ = {\"language\": \"<|fr|>\", \"temperature\": 0.0}  # add any other generate\
          \ kwargs you require \nprediction = pipe(sample, generate_kwargs=generate_kwargs\
          \ )[\"text\"]\n```"
        updatedAt: '2023-03-03T14:20:39.533Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - sboudouk
    id: 6402021d9fe2fcff94cbc82f
    type: comment
  author: sanchit-gandhi
  content: "Hey @sboudouk! Yep, you can just pass `generate_kwargs` as required:\n\
    \n```python\nimport torch\nfrom transformers import pipeline\nfrom datasets import\
    \ load_dataset\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\
    \n\npipe = pipeline(\n  \"automatic-speech-recognition\",\n  model=\"openai/whisper-large-v2\"\
    ,\n  chunk_length_s=30,\n  device=device,\n)\n\nds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\"\
    , \"clean\", split=\"validation\")\nsample = ds[0][\"audio\"]\n\ngenerate_kwargs\
    \ = {\"language\": \"<|fr|>\", \"temperature\": 0.0}  # add any other generate\
    \ kwargs you require \nprediction = pipe(sample, generate_kwargs=generate_kwargs\
    \ )[\"text\"]\n```"
  created_at: 2023-03-03 14:20:13+00:00
  edited: true
  hidden: false
  id: 6402021d9fe2fcff94cbc82f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d7602462dd75b22ff3a6ed4feb98c225.svg
      fullname: Alexander Klochay
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Superchik
      type: user
    createdAt: '2023-05-30T22:56:36.000Z'
    data:
      edited: true
      editors:
      - Superchik
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d7602462dd75b22ff3a6ed4feb98c225.svg
          fullname: Alexander Klochay
          isHf: false
          isPro: false
          name: Superchik
          type: user
        html: '<p>Can I use <code>generate_kwargs</code> in HF API?</p>

          '
        raw: Can I use ``generate_kwargs`` in HF API?
        updatedAt: '2023-05-30T22:56:49.896Z'
      numEdits: 1
      reactions: []
    id: 64767f2457108da176009225
    type: comment
  author: Superchik
  content: Can I use ``generate_kwargs`` in HF API?
  created_at: 2023-05-30 21:56:36+00:00
  edited: true
  hidden: false
  id: 64767f2457108da176009225
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-05-31T14:22:00.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Which API <span data-props=\"{&quot;user&quot;:&quot;Superchik&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Superchik\"\
          >@<span class=\"underline\">Superchik</span></a></span>\n\n\t</span></span>?\
          \ For the <code>pipeline</code>, you can use the structure defined above.\
          \ For <code>feature_extractor</code> + <code>model</code>, you can simply\
          \ set <code>language=\"fr\"</code> when you call <code>model.generate</code>:</p>\n\
          <pre><code class=\"language-python\">model.generate(input_features, language=<span\
          \ class=\"hljs-string\">\"fr\"</span>, task=<span class=\"hljs-string\"\
          >\"transcribe\"</span>)\n</code></pre>\n<p>See the following doc for more\
          \ details: <a href=\"https://huggingface.co/docs/transformers/model_doc/whisper#transformers.WhisperForConditionalGeneration.forward.example\"\
          >https://huggingface.co/docs/transformers/model_doc/whisper#transformers.WhisperForConditionalGeneration.forward.example</a></p>\n"
        raw: 'Which API @Superchik? For the `pipeline`, you can use the structure
          defined above. For `feature_extractor` + `model`, you can simply set `language="fr"`
          when you call `model.generate`:


          ```python

          model.generate(input_features, language="fr", task="transcribe")

          ```


          See the following doc for more details: https://huggingface.co/docs/transformers/model_doc/whisper#transformers.WhisperForConditionalGeneration.forward.example'
        updatedAt: '2023-05-31T14:22:00.274Z'
      numEdits: 0
      reactions: []
    id: 6477580804aa03da2abb7b2b
    type: comment
  author: sanchit-gandhi
  content: 'Which API @Superchik? For the `pipeline`, you can use the structure defined
    above. For `feature_extractor` + `model`, you can simply set `language="fr"` when
    you call `model.generate`:


    ```python

    model.generate(input_features, language="fr", task="transcribe")

    ```


    See the following doc for more details: https://huggingface.co/docs/transformers/model_doc/whisper#transformers.WhisperForConditionalGeneration.forward.example'
  created_at: 2023-05-31 13:22:00+00:00
  edited: false
  hidden: false
  id: 6477580804aa03da2abb7b2b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d7602462dd75b22ff3a6ed4feb98c225.svg
      fullname: Alexander Klochay
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Superchik
      type: user
    createdAt: '2023-05-31T21:19:29.000Z'
    data:
      edited: true
      editors:
      - Superchik
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d7602462dd75b22ff3a6ed4feb98c225.svg
          fullname: Alexander Klochay
          isHf: false
          isPro: false
          name: Superchik
          type: user
        html: "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">import</span>\
          \ requests\n\nAPI_URL = <span class=\"hljs-string\">\"https://api-inference.huggingface.co/models/openai/whisper-large-v2\"\
          </span>\nheaders = {<span class=\"hljs-string\">\"Authorization\"</span>:\
          \ <span class=\"hljs-string\">\"Bearer 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\"\
          </span>}\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\
          \ function_\">query</span>(<span class=\"hljs-params\">filename</span>):\n\
          \    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\"\
          >open</span>(filename, <span class=\"hljs-string\">\"rb\"</span>) <span\
          \ class=\"hljs-keyword\">as</span> f:\n        data = f.read()\n    response\
          \ = requests.post(API_URL, headers=headers, data=data)\n    <span class=\"\
          hljs-keyword\">return</span> response.json()\n\noutput = query(<span class=\"\
          hljs-string\">\"sample1.flac\"</span>)\n</code></pre>\n"
        raw: "```python\nimport requests\n\nAPI_URL = \"https://api-inference.huggingface.co/models/openai/whisper-large-v2\"\
          \nheaders = {\"Authorization\": \"Bearer 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\"\
          }\n\ndef query(filename):\n    with open(filename, \"rb\") as f:\n     \
          \   data = f.read()\n    response = requests.post(API_URL, headers=headers,\
          \ data=data)\n    return response.json()\n\noutput = query(\"sample1.flac\"\
          )\n```"
        updatedAt: '2023-05-31T21:20:04.341Z'
      numEdits: 1
      reactions: []
    id: 6477b9e1bb7681ad670e1ec5
    type: comment
  author: Superchik
  content: "```python\nimport requests\n\nAPI_URL = \"https://api-inference.huggingface.co/models/openai/whisper-large-v2\"\
    \nheaders = {\"Authorization\": \"Bearer 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\"\
    }\n\ndef query(filename):\n    with open(filename, \"rb\") as f:\n        data\
    \ = f.read()\n    response = requests.post(API_URL, headers=headers, data=data)\n\
    \    return response.json()\n\noutput = query(\"sample1.flac\")\n```"
  created_at: 2023-05-31 20:19:29+00:00
  edited: true
  hidden: false
  id: 6477b9e1bb7681ad670e1ec5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 23
repo_id: openai/whisper-large-v2
repo_type: model
status: open
target_branch: null
title: Don't have same results with Whisper on HF and Whisper from Github using Python
