!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wadexiao
conflicting_files: null
created_at: 2023-07-16 04:39:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bcf2bc0bac1d707f4ad4e16aef3bfdf2.svg
      fullname: wadexiao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wadexiao
      type: user
    createdAt: '2023-07-16T05:39:00.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      - wadexiao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7413420081138611
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: '<p>below is my code</p>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          transformers <span class="hljs-keyword">import</span> pipeline


          speech_recognizer = pipeline(<span class="hljs-string">"automatic-speech-recognition"</span>,
          chunk_length_s=<span class="hljs-number">30</span>, model=<span class="hljs-string">"openai/whisper-large-v2"</span>)


          s=speech_recognizer(<span class="hljs-string">r"C:\Users\Administrator\Desktop\bad.mp3"</span>,
          max_new_tokens=<span class="hljs-number">8000</span>)

          <span class="hljs-built_in">print</span>(s[<span class="hljs-string">''text''</span>])

          </code></pre>

          <p>the time of the audio almost 210s, but why does it only display text
          about the first 30s of the audio, event change the , chunk_length_s=200s,
          I want to see the full text, how can I do it?</p>

          '
        raw: 'below is my code

          ```python

          from transformers import pipeline


          speech_recognizer = pipeline("automatic-speech-recognition", chunk_length_s=30,
          model="openai/whisper-large-v2")


          s=speech_recognizer(r"C:\Users\Administrator\Desktop\bad.mp3", max_new_tokens=8000)

          print(s[''text''])

          ```


          the time of the audio almost 210s, but why does it only display text about
          the first 30s of the audio, event change the , chunk_length_s=200s, I want
          to see the full text, how can I do it?'
        updatedAt: '2023-07-25T17:35:05.061Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MMYDatasets
    id: 64b382749a88b423da69a374
    type: comment
  author: wadexiao
  content: 'below is my code

    ```python

    from transformers import pipeline


    speech_recognizer = pipeline("automatic-speech-recognition", chunk_length_s=30,
    model="openai/whisper-large-v2")


    s=speech_recognizer(r"C:\Users\Administrator\Desktop\bad.mp3", max_new_tokens=8000)

    print(s[''text''])

    ```


    the time of the audio almost 210s, but why does it only display text about the
    first 30s of the audio, event change the , chunk_length_s=200s, I want to see
    the full text, how can I do it?'
  created_at: 2023-07-16 04:39:00+00:00
  edited: true
  hidden: false
  id: 64b382749a88b423da69a374
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-07-25T17:36:17.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9239358305931091
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;wadexiao&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/wadexiao\"\
          >@<span class=\"underline\">wadexiao</span></a></span>\n\n\t</span></span>\
          \ - are you able to share your audio so I can reproduce locally please?\
          \ Your code looks correct otherwise.</p>\n"
        raw: Hey @wadexiao - are you able to share your audio so I can reproduce locally
          please? Your code looks correct otherwise.
        updatedAt: '2023-07-25T17:36:17.640Z'
      numEdits: 0
      reactions: []
    id: 64c0081121793e6634e2c8b0
    type: comment
  author: sanchit-gandhi
  content: Hey @wadexiao - are you able to share your audio so I can reproduce locally
    please? Your code looks correct otherwise.
  created_at: 2023-07-25 16:36:17+00:00
  edited: false
  hidden: false
  id: 64c0081121793e6634e2c8b0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64823e3c93362a0d12ff6d3f/aKWiDHu0ZDKLNzUnOF5qA.jpeg?w=200&h=200&f=face
      fullname: Felipe De La Cruz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: felipedelacruz
      type: user
    createdAt: '2023-08-17T20:54:26.000Z'
    data:
      edited: false
      editors:
      - felipedelacruz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5347220301628113
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64823e3c93362a0d12ff6d3f/aKWiDHu0ZDKLNzUnOF5qA.jpeg?w=200&h=200&f=face
          fullname: Felipe De La Cruz
          isHf: false
          isPro: false
          name: felipedelacruz
          type: user
        html: '<p>I have the same issue, the output is just the first 15 or 20 seconds
          for audio of 2 minutes, like 100 tokens approx.</p>

          <pre><code>from transformers import WhisperProcessor, WhisperForConditionalGeneration

          import soundfile as sf


          processor = WhisperProcessor.from_pretrained("openai/whisper-medium")

          model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-medium")

          forced_decoder_ids = processor.get_decoder_prompt_ids(language="spanish",
          task="transcribe")


          wav_path = "audios/output1.wav"


          audio_data, sample_rate = sf.read(wav_path)


          input_features = processor(audio_data, sampling_rate=sample_rate, return_tensors="pt").input_features


          predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids,
          max_new_tokens=4000)


          transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)

          </code></pre>

          '
        raw: 'I have the same issue, the output is just the first 15 or 20 seconds
          for audio of 2 minutes, like 100 tokens approx.


          ```

          from transformers import WhisperProcessor, WhisperForConditionalGeneration

          import soundfile as sf


          processor = WhisperProcessor.from_pretrained("openai/whisper-medium")

          model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-medium")

          forced_decoder_ids = processor.get_decoder_prompt_ids(language="spanish",
          task="transcribe")


          wav_path = "audios/output1.wav"


          audio_data, sample_rate = sf.read(wav_path)


          input_features = processor(audio_data, sampling_rate=sample_rate, return_tensors="pt").input_features


          predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids,
          max_new_tokens=4000)


          transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)

          ```'
        updatedAt: '2023-08-17T20:54:26.882Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - MMYDatasets
        - alexivaner
    id: 64de89021499c62d84bc2aa2
    type: comment
  author: felipedelacruz
  content: 'I have the same issue, the output is just the first 15 or 20 seconds for
    audio of 2 minutes, like 100 tokens approx.


    ```

    from transformers import WhisperProcessor, WhisperForConditionalGeneration

    import soundfile as sf


    processor = WhisperProcessor.from_pretrained("openai/whisper-medium")

    model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-medium")

    forced_decoder_ids = processor.get_decoder_prompt_ids(language="spanish", task="transcribe")


    wav_path = "audios/output1.wav"


    audio_data, sample_rate = sf.read(wav_path)


    input_features = processor(audio_data, sampling_rate=sample_rate, return_tensors="pt").input_features


    predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids,
    max_new_tokens=4000)


    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)

    ```'
  created_at: 2023-08-17 19:54:26+00:00
  edited: false
  hidden: false
  id: 64de89021499c62d84bc2aa2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-08-18T18:37:07.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.642822802066803
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;felipedelacruz&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/felipedelacruz\"\
          >@<span class=\"underline\">felipedelacruz</span></a></span>\n\n\t</span></span>\
          \ - for long-form transcription, it's advised to use the <code>pipeline</code>\
          \ class:</p>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >import</span> torch\n<span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> pipeline\n<span class=\"hljs-keyword\"\
          >from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n\
          \ndevice = <span class=\"hljs-string\">\"cuda:0\"</span> <span class=\"\
          hljs-keyword\">if</span> torch.cuda.is_available() <span class=\"hljs-keyword\"\
          >else</span> <span class=\"hljs-string\">\"cpu\"</span>\n\npipe = pipeline(\n\
          \  <span class=\"hljs-string\">\"automatic-speech-recognition\"</span>,\n\
          \  model=<span class=\"hljs-string\">\"openai/whisper-large-v2\"</span>,\n\
          \  chunk_length_s=<span class=\"hljs-number\">30</span>,\n  device=device,\n\
          )\n\n<span class=\"hljs-comment\"># to transcribe a local file</span>\n\
          wav_path = <span class=\"hljs-string\">\"audios/output1.wav\"</span>\nprediction\
          \ = pipe(wav_path, batch_size=<span class=\"hljs-number\">8</span>)[<span\
          \ class=\"hljs-string\">\"text\"</span>]\n\n<span class=\"hljs-comment\"\
          ># we can also return timestamps for the predictions</span>\nprediction\
          \ = pipe(wav_path, batch_size=<span class=\"hljs-number\">8</span>, return_timestamps=<span\
          \ class=\"hljs-literal\">True</span>)[<span class=\"hljs-string\">\"chunks\"\
          </span>]\n</code></pre>\n"
        raw: "Hey @felipedelacruz - for long-form transcription, it's advised to use\
          \ the `pipeline` class:\n```python\nimport torch\nfrom transformers import\
          \ pipeline\nfrom datasets import load_dataset\n\ndevice = \"cuda:0\" if\
          \ torch.cuda.is_available() else \"cpu\"\n\npipe = pipeline(\n  \"automatic-speech-recognition\"\
          ,\n  model=\"openai/whisper-large-v2\",\n  chunk_length_s=30,\n  device=device,\n\
          )\n\n# to transcribe a local file\nwav_path = \"audios/output1.wav\"\nprediction\
          \ = pipe(wav_path, batch_size=8)[\"text\"]\n\n# we can also return timestamps\
          \ for the predictions\nprediction = pipe(wav_path, batch_size=8, return_timestamps=True)[\"\
          chunks\"]\n```"
        updatedAt: '2023-08-18T18:37:28.941Z'
      numEdits: 1
      reactions: []
    id: 64dfba53a58c70fcc79e300a
    type: comment
  author: sanchit-gandhi
  content: "Hey @felipedelacruz - for long-form transcription, it's advised to use\
    \ the `pipeline` class:\n```python\nimport torch\nfrom transformers import pipeline\n\
    from datasets import load_dataset\n\ndevice = \"cuda:0\" if torch.cuda.is_available()\
    \ else \"cpu\"\n\npipe = pipeline(\n  \"automatic-speech-recognition\",\n  model=\"\
    openai/whisper-large-v2\",\n  chunk_length_s=30,\n  device=device,\n)\n\n# to\
    \ transcribe a local file\nwav_path = \"audios/output1.wav\"\nprediction = pipe(wav_path,\
    \ batch_size=8)[\"text\"]\n\n# we can also return timestamps for the predictions\n\
    prediction = pipe(wav_path, batch_size=8, return_timestamps=True)[\"chunks\"]\n\
    ```"
  created_at: 2023-08-18 17:37:07+00:00
  edited: true
  hidden: false
  id: 64dfba53a58c70fcc79e300a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62846faa99bff5076f0a93b4/oTEr0Ns7Kmez7CzvcQEtL.jpeg?w=200&h=200&f=face
      fullname: Imran ullah
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Imran1
      type: user
    createdAt: '2023-09-16T09:09:53.000Z'
    data:
      edited: false
      editors:
      - Imran1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9172086715698242
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62846faa99bff5076f0a93b4/oTEr0Ns7Kmez7CzvcQEtL.jpeg?w=200&h=200&f=face
          fullname: Imran ullah
          isHf: false
          isPro: false
          name: Imran1
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ hi, as you suggest for long audio or video  to transcribe use pipeline.\
          \ But they not working I am using the same technique. </p>\n<p>I have 10\
          \ minutes video and they just transcribe 30 sec.</p>\n"
        raw: "@sanchit-gandhi hi, as you suggest for long audio or video  to transcribe\
          \ use pipeline. But they not working I am using the same technique. \n\n\
          I have 10 minutes video and they just transcribe 30 sec."
        updatedAt: '2023-09-16T09:09:53.141Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MMYDatasets
    id: 650570e1a61b2c010ed9de3d
    type: comment
  author: Imran1
  content: "@sanchit-gandhi hi, as you suggest for long audio or video  to transcribe\
    \ use pipeline. But they not working I am using the same technique. \n\nI have\
    \ 10 minutes video and they just transcribe 30 sec."
  created_at: 2023-09-16 08:09:53+00:00
  edited: false
  hidden: false
  id: 650570e1a61b2c010ed9de3d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-09-19T18:09:40.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8530107140541077
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Imran1&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Imran1\">@<span class=\"\
          underline\">Imran1</span></a></span>\n\n\t</span></span> - do you have a\
          \ reproducible codesnippet to show the behaviour you're seeing where only\
          \ the first 30s of an audio is transcribed? If you set <code>chunk_length_s=30</code>\
          \ when you initialise the <code>pipeline</code> (as done above), then chunking\
          \ should be enabled, meaning you can transcribe audio files of arbitrary\
          \ length.</p>\n"
        raw: Hey @Imran1 - do you have a reproducible codesnippet to show the behaviour
          you're seeing where only the first 30s of an audio is transcribed? If you
          set `chunk_length_s=30` when you initialise the `pipeline` (as done above),
          then chunking should be enabled, meaning you can transcribe audio files
          of arbitrary length.
        updatedAt: '2023-09-19T18:09:40.777Z'
      numEdits: 0
      reactions: []
    id: 6509e3e4ed23af2c5d2d4083
    type: comment
  author: sanchit-gandhi
  content: Hey @Imran1 - do you have a reproducible codesnippet to show the behaviour
    you're seeing where only the first 30s of an audio is transcribed? If you set
    `chunk_length_s=30` when you initialise the `pipeline` (as done above), then chunking
    should be enabled, meaning you can transcribe audio files of arbitrary length.
  created_at: 2023-09-19 17:09:40+00:00
  edited: false
  hidden: false
  id: 6509e3e4ed23af2c5d2d4083
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bcf2bc0bac1d707f4ad4e16aef3bfdf2.svg
      fullname: wadexiao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wadexiao
      type: user
    createdAt: '2023-09-23T13:08:07.000Z'
    data:
      edited: true
      editors:
      - wadexiao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5842726230621338
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bcf2bc0bac1d707f4ad4e16aef3bfdf2.svg
          fullname: wadexiao
          isHf: false
          isPro: false
          name: wadexiao
          type: user
        html: "<p>hi, <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span><br>sure,\
          \ below is my audio<br><audio src=\"https://cdn-uploads.huggingface.co/production/uploads/64b38065f44fd957490e79af/EK5e1kQPiJvW1dawJv2l7.mpga\"\
          \ controls=\"\"></audio></p>\n"
        raw: 'hi, @sanchit-gandhi

          sure, below is my audio

          <audio controls src="https://cdn-uploads.huggingface.co/production/uploads/64b38065f44fd957490e79af/EK5e1kQPiJvW1dawJv2l7.mpga"></audio>

          '
        updatedAt: '2023-09-23T13:08:56.100Z'
      numEdits: 1
      reactions: []
    id: 650ee337be0fdd6ffe6c3080
    type: comment
  author: wadexiao
  content: 'hi, @sanchit-gandhi

    sure, below is my audio

    <audio controls src="https://cdn-uploads.huggingface.co/production/uploads/64b38065f44fd957490e79af/EK5e1kQPiJvW1dawJv2l7.mpga"></audio>

    '
  created_at: 2023-09-23 12:08:07+00:00
  edited: true
  hidden: false
  id: 650ee337be0fdd6ffe6c3080
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-09-28T18:22:50.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6809484958648682
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;wadexiao&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/wadexiao\"\
          >@<span class=\"underline\">wadexiao</span></a></span>\n\n\t</span></span>,\
          \ it worked perfectly fine fore me using the code snippet I shared before:</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">import</span>\
          \ torch\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"\
          hljs-keyword\">import</span> pipeline\n\ndevice = <span class=\"hljs-string\"\
          >\"cuda:0\"</span> <span class=\"hljs-keyword\">if</span> torch.cuda.is_available()\
          \ <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"\
          cpu\"</span>\n\npipe = pipeline(\n  <span class=\"hljs-string\">\"automatic-speech-recognition\"\
          </span>,\n  model=<span class=\"hljs-string\">\"openai/whisper-large-v2\"\
          </span>,\n  chunk_length_s=<span class=\"hljs-number\">30</span>,\n  device=device,\n\
          )\n\naudio = <span class=\"hljs-string\">\"https://cdn-uploads.huggingface.co/production/uploads/64b38065f44fd957490e79af/EK5e1kQPiJvW1dawJv2l7.mpga\"\
          </span>\ntext = pipe(audio, batch_size=<span class=\"hljs-number\">16</span>)\n\
          <span class=\"hljs-built_in\">print</span>(text)\n</code></pre>\n<p>Let\
          \ me know if you continue to encounter any issues, more than happy to help\
          \ here!</p>\n"
        raw: "Hey @wadexiao, it worked perfectly fine fore me using the code snippet\
          \ I shared before:\n\n```python\nimport torch\nfrom transformers import\
          \ pipeline\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\
          \n\npipe = pipeline(\n  \"automatic-speech-recognition\",\n  model=\"openai/whisper-large-v2\"\
          ,\n  chunk_length_s=30,\n  device=device,\n)\n\naudio = \"https://cdn-uploads.huggingface.co/production/uploads/64b38065f44fd957490e79af/EK5e1kQPiJvW1dawJv2l7.mpga\"\
          \ntext = pipe(audio, batch_size=16)\nprint(text)\n```\n\nLet me know if\
          \ you continue to encounter any issues, more than happy to help here!"
        updatedAt: '2023-09-28T18:22:50.322Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - felipedelacruz
    id: 6515c47aff0ecf2255f55f4a
    type: comment
  author: sanchit-gandhi
  content: "Hey @wadexiao, it worked perfectly fine fore me using the code snippet\
    \ I shared before:\n\n```python\nimport torch\nfrom transformers import pipeline\n\
    \ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\npipe = pipeline(\n\
    \  \"automatic-speech-recognition\",\n  model=\"openai/whisper-large-v2\",\n \
    \ chunk_length_s=30,\n  device=device,\n)\n\naudio = \"https://cdn-uploads.huggingface.co/production/uploads/64b38065f44fd957490e79af/EK5e1kQPiJvW1dawJv2l7.mpga\"\
    \ntext = pipe(audio, batch_size=16)\nprint(text)\n```\n\nLet me know if you continue\
    \ to encounter any issues, more than happy to help here!"
  created_at: 2023-09-28 17:22:50+00:00
  edited: false
  hidden: false
  id: 6515c47aff0ecf2255f55f4a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/268b1cddcfdf229792751e17ea747e43.svg
      fullname: Muzzammil
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MMYDatasets
      type: user
    createdAt: '2023-11-29T11:24:02.000Z'
    data:
      edited: true
      editors:
      - MMYDatasets
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9582056999206543
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/268b1cddcfdf229792751e17ea747e43.svg
          fullname: Muzzammil
          isHf: false
          isPro: false
          name: MMYDatasets
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>,\
          \ I am having the same problem here as <span data-props=\"{&quot;user&quot;:&quot;wadexiao&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/wadexiao\"\
          >@<span class=\"underline\">wadexiao</span></a></span>\n\n\t</span></span>.\
          \ </p>\n<p>I've tried running your above code on a 2-minute audio file,\
          \ and it only provides the text for the first few seconds. I have also tried\
          \ running the model that I wanted using a gradio app from HuggingFace and\
          \ I get the same thing... after a while, the transcription stops. </p>\n\
          <p>Any solutions for this? </p>\n"
        raw: "Hi @sanchit-gandhi, I am having the same problem here as @wadexiao.\
          \ \n\nI've tried running your above code on a 2-minute audio file, and it\
          \ only provides the text for the first few seconds. I have also tried running\
          \ the model that I wanted using a gradio app from HuggingFace and I get\
          \ the same thing... after a while, the transcription stops. \n\nAny solutions\
          \ for this? "
        updatedAt: '2023-11-29T11:40:42.713Z'
      numEdits: 1
      reactions: []
    id: 65671f52a5ec0231cb474e60
    type: comment
  author: MMYDatasets
  content: "Hi @sanchit-gandhi, I am having the same problem here as @wadexiao. \n\
    \nI've tried running your above code on a 2-minute audio file, and it only provides\
    \ the text for the first few seconds. I have also tried running the model that\
    \ I wanted using a gradio app from HuggingFace and I get the same thing... after\
    \ a while, the transcription stops. \n\nAny solutions for this? "
  created_at: 2023-11-29 11:24:02+00:00
  edited: true
  hidden: false
  id: 65671f52a5ec0231cb474e60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-11-29T14:03:49.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8575533032417297
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;MMYDatasets&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/MMYDatasets\"\
          >@<span class=\"underline\">MMYDatasets</span></a></span>\n\n\t</span></span>!\
          \ Could you share the audio file and code that you're using so that we reproduce\
          \ the error on our side? Thanks!</p>\n"
        raw: Hey @MMYDatasets! Could you share the audio file and code that you're
          using so that we reproduce the error on our side? Thanks!
        updatedAt: '2023-11-29T14:03:49.177Z'
      numEdits: 0
      reactions: []
    id: 656744c5a9a1a6a50d3ea0d8
    type: comment
  author: sanchit-gandhi
  content: Hey @MMYDatasets! Could you share the audio file and code that you're using
    so that we reproduce the error on our side? Thanks!
  created_at: 2023-11-29 14:03:49+00:00
  edited: false
  hidden: false
  id: 656744c5a9a1a6a50d3ea0d8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/268b1cddcfdf229792751e17ea747e43.svg
      fullname: Muzzammil
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MMYDatasets
      type: user
    createdAt: '2023-11-29T14:20:47.000Z'
    data:
      edited: false
      editors:
      - MMYDatasets
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7254195213317871
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/268b1cddcfdf229792751e17ea747e43.svg
          fullname: Muzzammil
          isHf: false
          isPro: false
          name: MMYDatasets
          type: user
        html: '<p>The code that I am using is this one, which you shared: </p>

          <p>import torch<br>from transformers import pipeline</p>

          <p>device = "cuda:0" if torch.cuda.is_available() else "cpu"</p>

          <p>pipe = pipeline(<br>  "automatic-speech-recognition",<br>  model="openai/whisper-large-v2",<br>  chunk_length_s=30,<br>  device=device,<br>)</p>

          <p>audio = "<a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64b38065f44fd957490e79af/EK5e1kQPiJvW1dawJv2l7.mpga&quot;">https://cdn-uploads.huggingface.co/production/uploads/64b38065f44fd957490e79af/EK5e1kQPiJvW1dawJv2l7.mpga"</a><br>text
          = pipe(audio, batch_size=16)<br>print(text)</p>

          <p>As for the file, its an mp3 file which is about 2 minutes in length.
          </p>

          <p><audio src="https://cdn-uploads.huggingface.co/production/uploads/65671e8a77fe61d0fce9dde0/HCSF1wW79K6be5ucybPHb.mpga"
          controls=""></audio></p>

          '
        raw: "The code that I am using is this one, which you shared: \n\nimport torch\n\
          from transformers import pipeline\n\ndevice = \"cuda:0\" if torch.cuda.is_available()\
          \ else \"cpu\"\n\npipe = pipeline(\n  \"automatic-speech-recognition\",\n\
          \  model=\"openai/whisper-large-v2\",\n  chunk_length_s=30,\n  device=device,\n\
          )\n\naudio = \"https://cdn-uploads.huggingface.co/production/uploads/64b38065f44fd957490e79af/EK5e1kQPiJvW1dawJv2l7.mpga\"\
          \ntext = pipe(audio, batch_size=16)\nprint(text)\n\nAs for the file, its\
          \ an mp3 file which is about 2 minutes in length. \n\n<audio controls src=\"\
          https://cdn-uploads.huggingface.co/production/uploads/65671e8a77fe61d0fce9dde0/HCSF1wW79K6be5ucybPHb.mpga\"\
          ></audio>\n"
        updatedAt: '2023-11-29T14:20:47.670Z'
      numEdits: 0
      reactions: []
    id: 656748bf6b1e4d61d8bd371c
    type: comment
  author: MMYDatasets
  content: "The code that I am using is this one, which you shared: \n\nimport torch\n\
    from transformers import pipeline\n\ndevice = \"cuda:0\" if torch.cuda.is_available()\
    \ else \"cpu\"\n\npipe = pipeline(\n  \"automatic-speech-recognition\",\n  model=\"\
    openai/whisper-large-v2\",\n  chunk_length_s=30,\n  device=device,\n)\n\naudio\
    \ = \"https://cdn-uploads.huggingface.co/production/uploads/64b38065f44fd957490e79af/EK5e1kQPiJvW1dawJv2l7.mpga\"\
    \ntext = pipe(audio, batch_size=16)\nprint(text)\n\nAs for the file, its an mp3\
    \ file which is about 2 minutes in length. \n\n<audio controls src=\"https://cdn-uploads.huggingface.co/production/uploads/65671e8a77fe61d0fce9dde0/HCSF1wW79K6be5ucybPHb.mpga\"\
    ></audio>\n"
  created_at: 2023-11-29 14:20:47+00:00
  edited: false
  hidden: false
  id: 656748bf6b1e4d61d8bd371c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-11-29T15:21:21.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: ar
        probability: 0.9350292086601257
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>I don't know Arabic, but the transcription looks to be improved\
          \ when we return timestamps:</p>\n<pre><code class=\"language-python\"><span\
          \ class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> pipeline\n\
          \ndevice = <span class=\"hljs-string\">\"cuda:0\"</span> <span class=\"\
          hljs-keyword\">if</span> torch.cuda.is_available() <span class=\"hljs-keyword\"\
          >else</span> <span class=\"hljs-string\">\"cpu\"</span>\n\npipe = pipeline(\n\
          \  <span class=\"hljs-string\">\"automatic-speech-recognition\"</span>,\n\
          \  model=<span class=\"hljs-string\">\"openai/whisper-large-v2\"</span>,\n\
          \  chunk_length_s=<span class=\"hljs-number\">30</span>,\n  device=device,\n\
          )\n\naudio = <span class=\"hljs-string\">\"https://cdn-uploads.huggingface.co/production/uploads/65671e8a77fe61d0fce9dde0/HCSF1wW79K6be5ucybPHb.mpga\"\
          </span>\noutput = pipe(audio, batch_size=<span class=\"hljs-number\">16</span>,\
          \ generate_kwargs={<span class=\"hljs-string\">\"task\"</span>: <span class=\"\
          hljs-string\">\"transcribe\"</span>}, return_timestamps=<span class=\"hljs-literal\"\
          >True</span>)\n<span class=\"hljs-built_in\">print</span>(output[<span class=\"\
          hljs-string\">\"text\"</span>])\n</code></pre>\n<p><strong>Print Output</strong></p>\n\
          <pre><code> \u0627\u0644\u0648\u062D\u062F\u0629 \u0627\u0644\u062B\u0627\
          \u0645\u0646\u0629 \u0627\u0644\u062C\u0648 \u0648\u0627\u0644\u0645\u0644\
          \u0627\u0628\u0633 \u0643\u064A\u0641 \u0627\u0644\u062C\u0648 \u0639\u0646\
          \u062F\u0643\u0645\u061F \u0631\u0627\u0628\u0639\u0627\u064B \u0627\u0644\
          \u0627\u0633\u062A\u0645\u0627\u0639 \u0648\u0627\u0644\u0645\u062D\u0627\
          \u062F\u062B\u0629 \u0627\u0644\u062A\u062F\u0631\u064A\u0628 \u0627\u0644\
          \u062A\u0627\u0633\u0639 \u0639\u0634\u0631 \u0627\u0633\u062A\u0645\u0639\
          \ \u0625\u0644\u0649 \u0627\u0644\u0646\u0634\u0631\u0629 \u0627\u0644\u062C\
          \u0648\u064A\u0629 \u062B\u0645 \u0623\u062C\u0628 \u0639\u0646 \u0627\u0644\
          \u0623\u0633\u0626\u0644\u0629 \u0623\u0644\u0641 \u0636\u0639 \u0639\u0644\
          \u0627\u0645\u0629 \u0635\u062D \u0623\u0648 \u062E\u0637\u0623 \u062B\u0645\
          \ \u0635\u062D\u062D \u0627\u0644\u062E\u0637\u0623 \u064A\u062A\u0648\u0642\
          \u0639 \u063A\u062F\u0627 \u0623\u0646 \u062A\u0633\u062A\u0645\u0631 \u062F\
          \u0631\u062C\u0627\u062A \u0627\u0644\u062D\u0631\u0627\u0631\u0629 \u0641\
          \u064A \u0627\u0644\u0627\u0646\u062E\u0641\u0627\u0636 \u0645\u0639 \u0648\
          \u062C\u0648\u062F \u0633\u0645\u0627\u0621 \u0635\u0627\u0641\u064A\u0629\
          \ \u0627\u062D\u064A\u0627\u0646\u0627 \u0648\u063A\u0627\u0626\u0645\u0629\
          \ \u062C\u0632\u0626\u064A\u0629 \u0627\u062D\u064A\u0627\u0646\u0627 \u0627\
          \u062E\u0631\u0649 \u0643\u0645\u0627 \u064A\u0644\u0627\u062D\u0638 \u0633\
          \u0642\u0648\u0637 \u0627\u0645\u0637\u0627\u0631 \u062E\u0641\u064A\u0641\
          \u0629 \u0639\u0644\u0649 \u0628\u0639\u0636 \u0627\u0644\u0628\u0644\u0627\
          \u062F \u0645\u062B\u0644 \u062A\u0631\u0643\u064A\u0627 \u0648\u064A\u0637\
          \u0627\u0644\u064A\u0627 \u0648\u0638\u0647\u0648\u0631 \u0635\u062D\u0628\
          \ \u0643\u062B\u064A\u0641\u0629 \u0641\u064A \u0641\u062A\u0631\u0629 \u0627\
          \u0644\u0638\u0647\u064A\u0631\u0629 \u0645\u0639 \u0627\u062D\u062A\u0645\
          \u0627\u0644 \u0632\u064A\u0627\u062F\u0629 \u0627\u0644\u0631\u0637\u0648\
          \u0628\u0629 \u0641\u064A \u0627\u0644\u0644\u064A\u0644 \u0648\u0627\u0644\
          \u0635\u0628\u0627\u062D \u0627\u0644\u0628\u0627\u0643\u0631 \u0648\u0645\
          \u0645\u0627 \u064A\u0644\u0627\u062D\u0638 \u0623\u064A\u0636\u0627 \u0632\
          \u064A\u0627\u062F\u0629 \u062F\u0631\u062C\u0627\u062A \u0627\u0644\u062D\
          \u0631\u0627\u0631\u0629 \u0639\u0644\u0649 \u0628\u0639\u0636 \u0627\u0644\
          \u0628\u0644\u0627\u062F \u0645\u062B\u0644 \u0627\u0644\u0633\u0639\u0648\
          \u062F\u064A\u0629 \u0648\u0645\u0635\u0631 \u062A\u062A\u062F\u0631\u062C\
          \u0627\u062A \u0627\u0644\u062D\u0631\u0627\u0631\u0629 \u0639\u0644\u0649\
          \ \u0628\u0639\u0636 \u0627\u0644\u0628\u0644\u0627\u062F \u0645\u062B\u0644\
          \ \u0627\u0644\u0633\u0639\u0648\u062F\u064A\u0629 \u0648\u0645\u0635\u0631\
          \ \u0623\u0645\u0627 \u0639\u0646 \u062F\u0631\u062C\u0627\u062A \u0627\u0644\
          \u062D\u0631\u0627\u0631\u0629 \u0627\u0644\u0645\u062A\u0648\u0642\u0639\
          \u0629 \u063A\u062F\u0627 \u0641\u0647\u064A \u0627\u0644\u0633\u0639\u0648\
          \u062F\u064A\u0629 \u0627\u0644\u0639\u0638\u0645\u0629 35 \u0648\u0627\u0644\
          \u0635\u063A\u0631\u0649 25\u0645\u0633 \u0648\u0639\u0634\u0631\u0648\u0646\
          \ \u0645\u0635\u0631 \u0627\u0644\u0639\u0638\u0645\u0649 \u062B\u0644\u0627\
          \u062B\u0648\u0646 \u0648\u0627\u0644\u0635\u063A\u0631\u0649 \u0639\u0634\
          \u0631\u0648\u0646 \u062A\u0631\u0643\u064A\u0627 \u0627\u0644\u0639\u0638\
          \u0645\u0649 \u062B\u0644\u0627\u062B \u0639\u0634\u0631\u0629 \u0648\u0627\
          \u0644\u0635\u063A\u0631\u0649 \u062A\u0633\u0639 \u0627\u064A\u0637\u0627\
          \u0644\u064A\u0627 \u0627\u0644\u0639\u0638\u0645\u0649 \u062A\u0633\u0639\
          \ \u062F\u0631\u062C\u0627\u062A \u0627\u0644\u0635\u063A\u0631\u0649 \u0627\
          \u0631\u0628\u0639 \u062F\u0631\u062C\u0627\u062A\n</code></pre>\n"
        raw: "I don't know Arabic, but the transcription looks to be improved when\
          \ we return timestamps:\n```python\nimport torch\nfrom transformers import\
          \ pipeline\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\
          \n\npipe = pipeline(\n  \"automatic-speech-recognition\",\n  model=\"openai/whisper-large-v2\"\
          ,\n  chunk_length_s=30,\n  device=device,\n)\n\naudio = \"https://cdn-uploads.huggingface.co/production/uploads/65671e8a77fe61d0fce9dde0/HCSF1wW79K6be5ucybPHb.mpga\"\
          \noutput = pipe(audio, batch_size=16, generate_kwargs={\"task\": \"transcribe\"\
          }, return_timestamps=True)\nprint(output[\"text\"])\n```\n\n**Print Output**\n\
          \n```\n \u0627\u0644\u0648\u062D\u062F\u0629 \u0627\u0644\u062B\u0627\u0645\
          \u0646\u0629 \u0627\u0644\u062C\u0648 \u0648\u0627\u0644\u0645\u0644\u0627\
          \u0628\u0633 \u0643\u064A\u0641 \u0627\u0644\u062C\u0648 \u0639\u0646\u062F\
          \u0643\u0645\u061F \u0631\u0627\u0628\u0639\u0627\u064B \u0627\u0644\u0627\
          \u0633\u062A\u0645\u0627\u0639 \u0648\u0627\u0644\u0645\u062D\u0627\u062F\
          \u062B\u0629 \u0627\u0644\u062A\u062F\u0631\u064A\u0628 \u0627\u0644\u062A\
          \u0627\u0633\u0639 \u0639\u0634\u0631 \u0627\u0633\u062A\u0645\u0639 \u0625\
          \u0644\u0649 \u0627\u0644\u0646\u0634\u0631\u0629 \u0627\u0644\u062C\u0648\
          \u064A\u0629 \u062B\u0645 \u0623\u062C\u0628 \u0639\u0646 \u0627\u0644\u0623\
          \u0633\u0626\u0644\u0629 \u0623\u0644\u0641 \u0636\u0639 \u0639\u0644\u0627\
          \u0645\u0629 \u0635\u062D \u0623\u0648 \u062E\u0637\u0623 \u062B\u0645 \u0635\
          \u062D\u062D \u0627\u0644\u062E\u0637\u0623 \u064A\u062A\u0648\u0642\u0639\
          \ \u063A\u062F\u0627 \u0623\u0646 \u062A\u0633\u062A\u0645\u0631 \u062F\u0631\
          \u062C\u0627\u062A \u0627\u0644\u062D\u0631\u0627\u0631\u0629 \u0641\u064A\
          \ \u0627\u0644\u0627\u0646\u062E\u0641\u0627\u0636 \u0645\u0639 \u0648\u062C\
          \u0648\u062F \u0633\u0645\u0627\u0621 \u0635\u0627\u0641\u064A\u0629 \u0627\
          \u062D\u064A\u0627\u0646\u0627 \u0648\u063A\u0627\u0626\u0645\u0629 \u062C\
          \u0632\u0626\u064A\u0629 \u0627\u062D\u064A\u0627\u0646\u0627 \u0627\u062E\
          \u0631\u0649 \u0643\u0645\u0627 \u064A\u0644\u0627\u062D\u0638 \u0633\u0642\
          \u0648\u0637 \u0627\u0645\u0637\u0627\u0631 \u062E\u0641\u064A\u0641\u0629\
          \ \u0639\u0644\u0649 \u0628\u0639\u0636 \u0627\u0644\u0628\u0644\u0627\u062F\
          \ \u0645\u062B\u0644 \u062A\u0631\u0643\u064A\u0627 \u0648\u064A\u0637\u0627\
          \u0644\u064A\u0627 \u0648\u0638\u0647\u0648\u0631 \u0635\u062D\u0628 \u0643\
          \u062B\u064A\u0641\u0629 \u0641\u064A \u0641\u062A\u0631\u0629 \u0627\u0644\
          \u0638\u0647\u064A\u0631\u0629 \u0645\u0639 \u0627\u062D\u062A\u0645\u0627\
          \u0644 \u0632\u064A\u0627\u062F\u0629 \u0627\u0644\u0631\u0637\u0648\u0628\
          \u0629 \u0641\u064A \u0627\u0644\u0644\u064A\u0644 \u0648\u0627\u0644\u0635\
          \u0628\u0627\u062D \u0627\u0644\u0628\u0627\u0643\u0631 \u0648\u0645\u0645\
          \u0627 \u064A\u0644\u0627\u062D\u0638 \u0623\u064A\u0636\u0627 \u0632\u064A\
          \u0627\u062F\u0629 \u062F\u0631\u062C\u0627\u062A \u0627\u0644\u062D\u0631\
          \u0627\u0631\u0629 \u0639\u0644\u0649 \u0628\u0639\u0636 \u0627\u0644\u0628\
          \u0644\u0627\u062F \u0645\u062B\u0644 \u0627\u0644\u0633\u0639\u0648\u062F\
          \u064A\u0629 \u0648\u0645\u0635\u0631 \u062A\u062A\u062F\u0631\u062C\u0627\
          \u062A \u0627\u0644\u062D\u0631\u0627\u0631\u0629 \u0639\u0644\u0649 \u0628\
          \u0639\u0636 \u0627\u0644\u0628\u0644\u0627\u062F \u0645\u062B\u0644 \u0627\
          \u0644\u0633\u0639\u0648\u062F\u064A\u0629 \u0648\u0645\u0635\u0631 \u0623\
          \u0645\u0627 \u0639\u0646 \u062F\u0631\u062C\u0627\u062A \u0627\u0644\u062D\
          \u0631\u0627\u0631\u0629 \u0627\u0644\u0645\u062A\u0648\u0642\u0639\u0629\
          \ \u063A\u062F\u0627 \u0641\u0647\u064A \u0627\u0644\u0633\u0639\u0648\u062F\
          \u064A\u0629 \u0627\u0644\u0639\u0638\u0645\u0629 35 \u0648\u0627\u0644\u0635\
          \u063A\u0631\u0649 25\u0645\u0633 \u0648\u0639\u0634\u0631\u0648\u0646 \u0645\
          \u0635\u0631 \u0627\u0644\u0639\u0638\u0645\u0649 \u062B\u0644\u0627\u062B\
          \u0648\u0646 \u0648\u0627\u0644\u0635\u063A\u0631\u0649 \u0639\u0634\u0631\
          \u0648\u0646 \u062A\u0631\u0643\u064A\u0627 \u0627\u0644\u0639\u0638\u0645\
          \u0649 \u062B\u0644\u0627\u062B \u0639\u0634\u0631\u0629 \u0648\u0627\u0644\
          \u0635\u063A\u0631\u0649 \u062A\u0633\u0639 \u0627\u064A\u0637\u0627\u0644\
          \u064A\u0627 \u0627\u0644\u0639\u0638\u0645\u0649 \u062A\u0633\u0639 \u062F\
          \u0631\u062C\u0627\u062A \u0627\u0644\u0635\u063A\u0631\u0649 \u0627\u0631\
          \u0628\u0639 \u062F\u0631\u062C\u0627\u062A\n```"
        updatedAt: '2023-11-29T15:21:21.301Z'
      numEdits: 0
      reactions: []
    id: 656756f10e4b5ff9d51eb99e
    type: comment
  author: sanchit-gandhi
  content: "I don't know Arabic, but the transcription looks to be improved when we\
    \ return timestamps:\n```python\nimport torch\nfrom transformers import pipeline\n\
    \ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\npipe = pipeline(\n\
    \  \"automatic-speech-recognition\",\n  model=\"openai/whisper-large-v2\",\n \
    \ chunk_length_s=30,\n  device=device,\n)\n\naudio = \"https://cdn-uploads.huggingface.co/production/uploads/65671e8a77fe61d0fce9dde0/HCSF1wW79K6be5ucybPHb.mpga\"\
    \noutput = pipe(audio, batch_size=16, generate_kwargs={\"task\": \"transcribe\"\
    }, return_timestamps=True)\nprint(output[\"text\"])\n```\n\n**Print Output**\n\
    \n```\n \u0627\u0644\u0648\u062D\u062F\u0629 \u0627\u0644\u062B\u0627\u0645\u0646\
    \u0629 \u0627\u0644\u062C\u0648 \u0648\u0627\u0644\u0645\u0644\u0627\u0628\u0633\
    \ \u0643\u064A\u0641 \u0627\u0644\u062C\u0648 \u0639\u0646\u062F\u0643\u0645\u061F\
    \ \u0631\u0627\u0628\u0639\u0627\u064B \u0627\u0644\u0627\u0633\u062A\u0645\u0627\
    \u0639 \u0648\u0627\u0644\u0645\u062D\u0627\u062F\u062B\u0629 \u0627\u0644\u062A\
    \u062F\u0631\u064A\u0628 \u0627\u0644\u062A\u0627\u0633\u0639 \u0639\u0634\u0631\
    \ \u0627\u0633\u062A\u0645\u0639 \u0625\u0644\u0649 \u0627\u0644\u0646\u0634\u0631\
    \u0629 \u0627\u0644\u062C\u0648\u064A\u0629 \u062B\u0645 \u0623\u062C\u0628 \u0639\
    \u0646 \u0627\u0644\u0623\u0633\u0626\u0644\u0629 \u0623\u0644\u0641 \u0636\u0639\
    \ \u0639\u0644\u0627\u0645\u0629 \u0635\u062D \u0623\u0648 \u062E\u0637\u0623\
    \ \u062B\u0645 \u0635\u062D\u062D \u0627\u0644\u062E\u0637\u0623 \u064A\u062A\u0648\
    \u0642\u0639 \u063A\u062F\u0627 \u0623\u0646 \u062A\u0633\u062A\u0645\u0631 \u062F\
    \u0631\u062C\u0627\u062A \u0627\u0644\u062D\u0631\u0627\u0631\u0629 \u0641\u064A\
    \ \u0627\u0644\u0627\u0646\u062E\u0641\u0627\u0636 \u0645\u0639 \u0648\u062C\u0648\
    \u062F \u0633\u0645\u0627\u0621 \u0635\u0627\u0641\u064A\u0629 \u0627\u062D\u064A\
    \u0627\u0646\u0627 \u0648\u063A\u0627\u0626\u0645\u0629 \u062C\u0632\u0626\u064A\
    \u0629 \u0627\u062D\u064A\u0627\u0646\u0627 \u0627\u062E\u0631\u0649 \u0643\u0645\
    \u0627 \u064A\u0644\u0627\u062D\u0638 \u0633\u0642\u0648\u0637 \u0627\u0645\u0637\
    \u0627\u0631 \u062E\u0641\u064A\u0641\u0629 \u0639\u0644\u0649 \u0628\u0639\u0636\
    \ \u0627\u0644\u0628\u0644\u0627\u062F \u0645\u062B\u0644 \u062A\u0631\u0643\u064A\
    \u0627 \u0648\u064A\u0637\u0627\u0644\u064A\u0627 \u0648\u0638\u0647\u0648\u0631\
    \ \u0635\u062D\u0628 \u0643\u062B\u064A\u0641\u0629 \u0641\u064A \u0641\u062A\u0631\
    \u0629 \u0627\u0644\u0638\u0647\u064A\u0631\u0629 \u0645\u0639 \u0627\u062D\u062A\
    \u0645\u0627\u0644 \u0632\u064A\u0627\u062F\u0629 \u0627\u0644\u0631\u0637\u0648\
    \u0628\u0629 \u0641\u064A \u0627\u0644\u0644\u064A\u0644 \u0648\u0627\u0644\u0635\
    \u0628\u0627\u062D \u0627\u0644\u0628\u0627\u0643\u0631 \u0648\u0645\u0645\u0627\
    \ \u064A\u0644\u0627\u062D\u0638 \u0623\u064A\u0636\u0627 \u0632\u064A\u0627\u062F\
    \u0629 \u062F\u0631\u062C\u0627\u062A \u0627\u0644\u062D\u0631\u0627\u0631\u0629\
    \ \u0639\u0644\u0649 \u0628\u0639\u0636 \u0627\u0644\u0628\u0644\u0627\u062F \u0645\
    \u062B\u0644 \u0627\u0644\u0633\u0639\u0648\u062F\u064A\u0629 \u0648\u0645\u0635\
    \u0631 \u062A\u062A\u062F\u0631\u062C\u0627\u062A \u0627\u0644\u062D\u0631\u0627\
    \u0631\u0629 \u0639\u0644\u0649 \u0628\u0639\u0636 \u0627\u0644\u0628\u0644\u0627\
    \u062F \u0645\u062B\u0644 \u0627\u0644\u0633\u0639\u0648\u062F\u064A\u0629 \u0648\
    \u0645\u0635\u0631 \u0623\u0645\u0627 \u0639\u0646 \u062F\u0631\u062C\u0627\u062A\
    \ \u0627\u0644\u062D\u0631\u0627\u0631\u0629 \u0627\u0644\u0645\u062A\u0648\u0642\
    \u0639\u0629 \u063A\u062F\u0627 \u0641\u0647\u064A \u0627\u0644\u0633\u0639\u0648\
    \u062F\u064A\u0629 \u0627\u0644\u0639\u0638\u0645\u0629 35 \u0648\u0627\u0644\u0635\
    \u063A\u0631\u0649 25\u0645\u0633 \u0648\u0639\u0634\u0631\u0648\u0646 \u0645\u0635\
    \u0631 \u0627\u0644\u0639\u0638\u0645\u0649 \u062B\u0644\u0627\u062B\u0648\u0646\
    \ \u0648\u0627\u0644\u0635\u063A\u0631\u0649 \u0639\u0634\u0631\u0648\u0646 \u062A\
    \u0631\u0643\u064A\u0627 \u0627\u0644\u0639\u0638\u0645\u0649 \u062B\u0644\u0627\
    \u062B \u0639\u0634\u0631\u0629 \u0648\u0627\u0644\u0635\u063A\u0631\u0649 \u062A\
    \u0633\u0639 \u0627\u064A\u0637\u0627\u0644\u064A\u0627 \u0627\u0644\u0639\u0638\
    \u0645\u0649 \u062A\u0633\u0639 \u062F\u0631\u062C\u0627\u062A \u0627\u0644\u0635\
    \u063A\u0631\u0649 \u0627\u0631\u0628\u0639 \u062F\u0631\u062C\u0627\u062A\n```"
  created_at: 2023-11-29 15:21:21+00:00
  edited: false
  hidden: false
  id: 656756f10e4b5ff9d51eb99e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 50
repo_id: openai/whisper-large-v2
repo_type: model
status: open
target_branch: null
title: Why not print the entire text of the audio?
