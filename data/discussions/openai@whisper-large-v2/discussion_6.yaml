!!python/object:huggingface_hub.community.DiscussionWithDetails
author: eikosa
conflicting_files: null
created_at: 2022-12-09 00:27:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3db5f5e484e802f6ef7f8e664c63acec.svg
      fullname: eiko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eikosa
      type: user
    createdAt: '2022-12-09T00:27:41.000Z'
    data:
      edited: false
      editors:
      - eikosa
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3db5f5e484e802f6ef7f8e664c63acec.svg
          fullname: eiko
          isHf: false
          isPro: false
          name: eikosa
          type: user
        html: '<p>How can I run this model with an mp3 for example I have?</p>

          '
        raw: How can I run this model with an mp3 for example I have?
        updatedAt: '2022-12-09T00:27:41.270Z'
      numEdits: 0
      reactions: []
    id: 639280fdd1954863c54f0c1f
    type: comment
  author: eikosa
  content: How can I run this model with an mp3 for example I have?
  created_at: 2022-12-09 00:27:41+00:00
  edited: false
  hidden: false
  id: 639280fdd1954863c54f0c1f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3db5f5e484e802f6ef7f8e664c63acec.svg
      fullname: eiko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eikosa
      type: user
    createdAt: '2022-12-09T01:09:09.000Z'
    data:
      status: closed
    id: 63928ab5339e67c02ccb71a9
    type: status-change
  author: eikosa
  created_at: 2022-12-09 01:09:09+00:00
  id: 63928ab5339e67c02ccb71a9
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3db5f5e484e802f6ef7f8e664c63acec.svg
      fullname: eiko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eikosa
      type: user
    createdAt: '2022-12-09T01:13:27.000Z'
    data:
      edited: true
      editors:
      - eikosa
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3db5f5e484e802f6ef7f8e664c63acec.svg
          fullname: eiko
          isHf: false
          isPro: false
          name: eikosa
          type: user
        html: '<p>Answer is:</p>

          <pre><code>speech, sr = torchaudio.load("asd.ogg")


          sampling_rate = 16_000


          resampler = torchaudio.transforms.Resample(sr, sampling_rate)

          speech = speech.squeeze()

          speech = resampler(speech)



          input_speech = speech

          </code></pre>

          '
        raw: 'Answer is:

          ```

          speech, sr = torchaudio.load("asd.ogg")


          sampling_rate = 16_000


          resampler = torchaudio.transforms.Resample(sr, sampling_rate)

          speech = speech.squeeze()

          speech = resampler(speech)



          input_speech = speech

          ```'
        updatedAt: '2022-12-09T01:13:38.395Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - sanchit-gandhi
    id: 63928bb7339e67c02ccb8af7
    type: comment
  author: eikosa
  content: 'Answer is:

    ```

    speech, sr = torchaudio.load("asd.ogg")


    sampling_rate = 16_000


    resampler = torchaudio.transforms.Resample(sr, sampling_rate)

    speech = speech.squeeze()

    speech = resampler(speech)



    input_speech = speech

    ```'
  created_at: 2022-12-09 01:13:27+00:00
  edited: true
  hidden: false
  id: 63928bb7339e67c02ccb8af7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2022-12-12T16:19:25.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>You can use <code>pipeline</code> as per the demo at <a href=\"\
          https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2\">https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2</a></p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span>\
          \ transformers <span class=\"hljs-keyword\">import</span> pipeline\n\ndevice\
          \ = <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">if</span>\
          \ torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> <span\
          \ class=\"hljs-string\">\"cpu\"</span>\n\npipe = pipeline(\n    task=<span\
          \ class=\"hljs-string\">\"automatic-speech-recognition\"</span>,\n    model=<span\
          \ class=\"hljs-string\">\"openai/whisper-large-v2\"</span>,\n    chunk_length_s=<span\
          \ class=\"hljs-number\">30</span>,\n    device=device,\n)\n\nout = pipe(audio)[<span\
          \ class=\"hljs-string\">\"text\"</span>]\n</code></pre>\n<p>where <code>audio</code>\
          \ is the path to an audio file or a loaded audio array (see <a rel=\"nofollow\"\
          \ href=\"https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201\"\
          >https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201</a>)</p>\n"
        raw: "You can use `pipeline` as per the demo at https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2\n\
          \n```python\nfrom transformers import pipeline\n\ndevice = 0 if torch.cuda.is_available()\
          \ else \"cpu\"\n\npipe = pipeline(\n    task=\"automatic-speech-recognition\"\
          ,\n    model=\"openai/whisper-large-v2\",\n    chunk_length_s=30,\n    device=device,\n\
          )\n\nout = pipe(audio)[\"text\"]\n```\nwhere `audio` is the path to an audio\
          \ file or a loaded audio array (see https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201)"
        updatedAt: '2022-12-12T16:19:25.945Z'
      numEdits: 0
      reactions: []
    id: 6397548d3b879d4a973339b5
    type: comment
  author: sanchit-gandhi
  content: "You can use `pipeline` as per the demo at https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2\n\
    \n```python\nfrom transformers import pipeline\n\ndevice = 0 if torch.cuda.is_available()\
    \ else \"cpu\"\n\npipe = pipeline(\n    task=\"automatic-speech-recognition\"\
    ,\n    model=\"openai/whisper-large-v2\",\n    chunk_length_s=30,\n    device=device,\n\
    )\n\nout = pipe(audio)[\"text\"]\n```\nwhere `audio` is the path to an audio file\
    \ or a loaded audio array (see https://github.com/huggingface/transformers/blob/c1b9a11dd4be8af32b3274be7c9774d5a917c56d/src/transformers/pipelines/automatic_speech_recognition.py#L201)"
  created_at: 2022-12-12 16:19:25+00:00
  edited: false
  hidden: false
  id: 6397548d3b879d4a973339b5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: openai/whisper-large-v2
repo_type: model
status: closed
target_branch: null
title: How to use a normal file with model?
