!!python/object:huggingface_hub.community.DiscussionWithDetails
author: atulyaatul
conflicting_files: null
created_at: 2023-09-28 05:28:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b4baa4d8385855ff468ae96bd72f2ca1.svg
      fullname: Atul Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: atulyaatul
      type: user
    createdAt: '2023-09-28T06:28:35.000Z'
    data:
      edited: false
      editors:
      - atulyaatul
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9545421600341797
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b4baa4d8385855ff468ae96bd72f2ca1.svg
          fullname: Atul Singh
          isHf: false
          isPro: false
          name: atulyaatul
          type: user
        html: '<p>I''m working with 8000hz frequency audio, and I''ve observed strange
          behavior with the Whisper model for translation and transcription. I''m
          using the Hugging Face pipeline with the Whisper large v2 model, and it''s
          working well for translation, but for transcription, it''s repeating the
          same word in the whole output. I''ve tried converting the audio to 16000hz
          and normalizing it, but I''m still getting the same results.</p>

          '
        raw: I'm working with 8000hz frequency audio, and I've observed strange behavior
          with the Whisper model for translation and transcription. I'm using the
          Hugging Face pipeline with the Whisper large v2 model, and it's working
          well for translation, but for transcription, it's repeating the same word
          in the whole output. I've tried converting the audio to 16000hz and normalizing
          it, but I'm still getting the same results.
        updatedAt: '2023-09-28T06:28:35.061Z'
      numEdits: 0
      reactions: []
    id: 65151d13e31c0e2e3d14f4c4
    type: comment
  author: atulyaatul
  content: I'm working with 8000hz frequency audio, and I've observed strange behavior
    with the Whisper model for translation and transcription. I'm using the Hugging
    Face pipeline with the Whisper large v2 model, and it's working well for translation,
    but for transcription, it's repeating the same word in the whole output. I've
    tried converting the audio to 16000hz and normalizing it, but I'm still getting
    the same results.
  created_at: 2023-09-28 05:28:35+00:00
  edited: false
  hidden: false
  id: 65151d13e31c0e2e3d14f4c4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-09-28T18:12:58.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.900315523147583
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Do you have a reproducible code snippet for this <span data-props=\"\
          {&quot;user&quot;:&quot;atulyaatul&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/atulyaatul\">@<span class=\"underline\"\
          >atulyaatul</span></a></span>\n\n\t</span></span>? Would be happy to take\
          \ a look! Otherwise an easy thing to try is decoding with timestamps (pass\
          \ <code>return_timestamps=True</code>), which often reduces hallucinations.\
          \ If inference speed is less of a consideration, you can also activate beam\
          \ search by passing <code>generate_kwargs={\"num_beams\": 2}</code> to the\
          \ pipeline</p>\n"
        raw: 'Do you have a reproducible code snippet for this @atulyaatul? Would
          be happy to take a look! Otherwise an easy thing to try is decoding with
          timestamps (pass `return_timestamps=True`), which often reduces hallucinations.
          If inference speed is less of a consideration, you can also activate beam
          search by passing `generate_kwargs={"num_beams": 2}` to the pipeline'
        updatedAt: '2023-09-28T18:12:58.547Z'
      numEdits: 0
      reactions: []
    id: 6515c22ac979eb9ca72a2bd3
    type: comment
  author: sanchit-gandhi
  content: 'Do you have a reproducible code snippet for this @atulyaatul? Would be
    happy to take a look! Otherwise an easy thing to try is decoding with timestamps
    (pass `return_timestamps=True`), which often reduces hallucinations. If inference
    speed is less of a consideration, you can also activate beam search by passing
    `generate_kwargs={"num_beams": 2}` to the pipeline'
  created_at: 2023-09-28 17:12:58+00:00
  edited: false
  hidden: false
  id: 6515c22ac979eb9ca72a2bd3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 70
repo_id: openai/whisper-large-v2
repo_type: model
status: open
target_branch: null
title: model failing to transcribe but working fine for translation
