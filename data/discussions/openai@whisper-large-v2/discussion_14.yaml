!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kirankumaram
conflicting_files: null
created_at: 2023-01-16 06:39:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7345644ea1bc7836993c49dd8c62be81.svg
      fullname: Kirankumar A M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kirankumaram
      type: user
    createdAt: '2023-01-16T06:39:01.000Z'
    data:
      edited: false
      editors:
      - kirankumaram
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7345644ea1bc7836993c49dd8c62be81.svg
          fullname: Kirankumar A M
          isHf: false
          isPro: false
          name: kirankumaram
          type: user
        html: '<p>Will the flexibility of getting ''segments'' be added to the final
          output similar to how we get it while using the whisper library directly
          in python. Sample code is shown in the image below.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1673851085337-636c9340aae2da3c76bd54db.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1673851085337-636c9340aae2da3c76bd54db.png"></a></p>

          '
        raw: "Will the flexibility of getting 'segments' be added to the final output\
          \ similar to how we get it while using the whisper library directly in python.\
          \ Sample code is shown in the image below.\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1673851085337-636c9340aae2da3c76bd54db.png)\r\
          \n"
        updatedAt: '2023-01-16T06:39:01.606Z'
      numEdits: 0
      reactions: []
    id: 63c4f1058d95a5c7706fe57d
    type: comment
  author: kirankumaram
  content: "Will the flexibility of getting 'segments' be added to the final output\
    \ similar to how we get it while using the whisper library directly in python.\
    \ Sample code is shown in the image below.\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1673851085337-636c9340aae2da3c76bd54db.png)\r\
    \n"
  created_at: 2023-01-16 06:39:01+00:00
  edited: false
  hidden: false
  id: 63c4f1058d95a5c7706fe57d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/7345644ea1bc7836993c49dd8c62be81.svg
      fullname: Kirankumar A M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kirankumaram
      type: user
    createdAt: '2023-01-16T06:39:18.000Z'
    data:
      from: Additional outputs from the models apart from the transcribed text
      to: Additional output from the model apart from the transcribed text
    id: 63c4f116bfd39d7373ac9e02
    type: title-change
  author: kirankumaram
  created_at: 2023-01-16 06:39:18+00:00
  id: 63c4f116bfd39d7373ac9e02
  new_title: Additional output from the model apart from the transcribed text
  old_title: Additional outputs from the models apart from the transcribed text
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-01-16T17:04:32.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: '<p>I don''t think we''re planning on adding transcriptions on a segment-wise
          basis. Once <a rel="nofollow" href="https://github.com/huggingface/transformers/pull/20620#issuecomment-1344452967">this
          PR</a> is merged we''ll have utterance level time-stamps though</p>

          '
        raw: I don't think we're planning on adding transcriptions on a segment-wise
          basis. Once [this PR](https://github.com/huggingface/transformers/pull/20620#issuecomment-1344452967)
          is merged we'll have utterance level time-stamps though
        updatedAt: '2023-01-16T17:04:32.993Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - kirankumaram
    id: 63c583a0addb8fa3e08be52f
    type: comment
  author: sanchit-gandhi
  content: I don't think we're planning on adding transcriptions on a segment-wise
    basis. Once [this PR](https://github.com/huggingface/transformers/pull/20620#issuecomment-1344452967)
    is merged we'll have utterance level time-stamps though
  created_at: 2023-01-16 17:04:32+00:00
  edited: false
  hidden: false
  id: 63c583a0addb8fa3e08be52f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/be54a659ccc279e2a5f81431907850f5.svg
      fullname: Gustav
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: orangediamond
      type: user
    createdAt: '2023-01-21T17:22:47.000Z'
    data:
      edited: true
      editors:
      - orangediamond
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/be54a659ccc279e2a5f81431907850f5.svg
          fullname: Gustav
          isHf: false
          isPro: false
          name: orangediamond
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>,\
          \ I am new on HF so this might be a silly question but how do you employ\
          \ the changes introduced in the PR? Is it done centrally so that whisper-large-v2\
          \ eventually can be deployed with them?</p>\n"
        raw: Hi @sanchit-gandhi, I am new on HF so this might be a silly question
          but how do you employ the changes introduced in the PR? Is it done centrally
          so that whisper-large-v2 eventually can be deployed with them?
        updatedAt: '2023-01-21T17:23:20.370Z'
      numEdits: 2
      reactions: []
    id: 63cc1f6728e49dcd9f68cd73
    type: comment
  author: orangediamond
  content: Hi @sanchit-gandhi, I am new on HF so this might be a silly question but
    how do you employ the changes introduced in the PR? Is it done centrally so that
    whisper-large-v2 eventually can be deployed with them?
  created_at: 2023-01-21 17:22:47+00:00
  edited: true
  hidden: false
  id: 63cc1f6728e49dcd9f68cd73
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-01-24T11:49:34.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;orangediamond&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/orangediamond\"\
          >@<span class=\"underline\">orangediamond</span></a></span>\n\n\t</span></span>!\
          \ You can get the latest changes by pip installing transformers from the\
          \ <code>main</code> branch (see <a href=\"https://huggingface.co/docs/transformers/installation#install-from-source\"\
          >https://huggingface.co/docs/transformers/installation#install-from-source</a>):</p>\n\
          <pre><code>pip install git+https://github.com/huggingface/transformers\n\
          </code></pre>\n<p>Otherwise, a new PyPI package version (4.26.0) should\
          \ be available later this week which has the latest changes:</p>\n<pre><code>pip\
          \ install -U transformers\n</code></pre>\n<p>If you want the changes now\
          \ you're better off installing from the <code>main</code> branch! Otherwise\
          \ keep tabs on <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/releases\"\
          >https://github.com/huggingface/transformers/releases</a> for the releases</p>\n"
        raw: 'Hey @orangediamond! You can get the latest changes by pip installing
          transformers from the `main` branch (see https://huggingface.co/docs/transformers/installation#install-from-source):

          ```

          pip install git+https://github.com/huggingface/transformers

          ```


          Otherwise, a new PyPI package version (4.26.0) should be available later
          this week which has the latest changes:

          ```

          pip install -U transformers

          ```

          If you want the changes now you''re better off installing from the `main`
          branch! Otherwise keep tabs on https://github.com/huggingface/transformers/releases
          for the releases'
        updatedAt: '2023-01-24T11:49:34.032Z'
      numEdits: 0
      reactions: []
    id: 63cfc5ce52cfe3a134d2c0c9
    type: comment
  author: sanchit-gandhi
  content: 'Hey @orangediamond! You can get the latest changes by pip installing transformers
    from the `main` branch (see https://huggingface.co/docs/transformers/installation#install-from-source):

    ```

    pip install git+https://github.com/huggingface/transformers

    ```


    Otherwise, a new PyPI package version (4.26.0) should be available later this
    week which has the latest changes:

    ```

    pip install -U transformers

    ```

    If you want the changes now you''re better off installing from the `main` branch!
    Otherwise keep tabs on https://github.com/huggingface/transformers/releases for
    the releases'
  created_at: 2023-01-24 11:49:34+00:00
  edited: false
  hidden: false
  id: 63cfc5ce52cfe3a134d2c0c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/be54a659ccc279e2a5f81431907850f5.svg
      fullname: Gustav
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: orangediamond
      type: user
    createdAt: '2023-01-24T14:09:36.000Z'
    data:
      edited: false
      editors:
      - orangediamond
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/be54a659ccc279e2a5f81431907850f5.svg
          fullname: Gustav
          isHf: false
          isPro: false
          name: orangediamond
          type: user
        html: "<p>Thanks for your reply <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>!\
          \ I was actually not referring to local installation (sorry for being unclear)\
          \ but rather to deploying the discussed changes as inference endpoints.\
          \ As far as I can tell, the Whisper model that gets deployed does not contain\
          \ the changes <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/pull/20620\"\
          >here</a> - any pointers to that end? I might be misunderstanding how everything\
          \ ties together in the Hugging Face ecosystem.</p>\n"
        raw: Thanks for your reply @sanchit-gandhi! I was actually not referring to
          local installation (sorry for being unclear) but rather to deploying the
          discussed changes as inference endpoints. As far as I can tell, the Whisper
          model that gets deployed does not contain the changes [here](https://github.com/huggingface/transformers/pull/20620)
          - any pointers to that end? I might be misunderstanding how everything ties
          together in the Hugging Face ecosystem.
        updatedAt: '2023-01-24T14:09:36.541Z'
      numEdits: 0
      reactions: []
    id: 63cfe6a06ffd32ed00935083
    type: comment
  author: orangediamond
  content: Thanks for your reply @sanchit-gandhi! I was actually not referring to
    local installation (sorry for being unclear) but rather to deploying the discussed
    changes as inference endpoints. As far as I can tell, the Whisper model that gets
    deployed does not contain the changes [here](https://github.com/huggingface/transformers/pull/20620)
    - any pointers to that end? I might be misunderstanding how everything ties together
    in the Hugging Face ecosystem.
  created_at: 2023-01-24 14:09:36+00:00
  edited: false
  hidden: false
  id: 63cfe6a06ffd32ed00935083
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/be54a659ccc279e2a5f81431907850f5.svg
      fullname: Gustav
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: orangediamond
      type: user
    createdAt: '2023-01-28T12:05:16.000Z'
    data:
      edited: false
      editors:
      - orangediamond
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/be54a659ccc279e2a5f81431907850f5.svg
          fullname: Gustav
          isHf: false
          isPro: false
          name: orangediamond
          type: user
        html: "<p>I have investigated a few things without luck:</p>\n<ul>\n<li>Setting\
          \ <code>return_timestamps = True</code>with <a href=\"https://huggingface.co/docs/api-inference/detailed_parameters\"\
          >detailed parameters</a> when calling the inference API does not seem to\
          \ be possible</li>\n<li>Creating a custom model with the option predefined\
          \ in <code>generation_config.json</code> does not seem to work for me -\
          \ I don't see a way to fork a model repository, and if I manually clone\
          \ it I am unable to push the pretrained models using git LFS</li>\n<li>Loading\
          \ and invoking the model locally is unfortunately not viable</li>\n</ul>\n\
          <p>Not sure what to try at this point. If anyone (maybe <span data-props=\"\
          {&quot;user&quot;:&quot;sanchit-gandhi&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/sanchit-gandhi\">@<span class=\"underline\"\
          >sanchit-gandhi</span></a></span>\n\n\t</span></span> - sorry for the extra\
          \ ping) has ideas I'm all ears\uFEFF\U0001F64F</p>\n"
        raw: "I have investigated a few things without luck:\n\n- Setting `return_timestamps\
          \ = True`with [detailed parameters](https://huggingface.co/docs/api-inference/detailed_parameters)\
          \ when calling the inference API does not seem to be possible\n- Creating\
          \ a custom model with the option predefined in `generation_config.json`\
          \ does not seem to work for me - I don't see a way to fork a model repository,\
          \ and if I manually clone it I am unable to push the pretrained models using\
          \ git LFS\n- Loading and invoking the model locally is unfortunately not\
          \ viable \n\nNot sure what to try at this point. If anyone (maybe @sanchit-gandhi\
          \ - sorry for the extra ping) has ideas I'm all ears\uFEFF\U0001F64F"
        updatedAt: '2023-01-28T12:05:16.838Z'
      numEdits: 0
      reactions: []
    id: 63d50f7c98e20226041ce0d2
    type: comment
  author: orangediamond
  content: "I have investigated a few things without luck:\n\n- Setting `return_timestamps\
    \ = True`with [detailed parameters](https://huggingface.co/docs/api-inference/detailed_parameters)\
    \ when calling the inference API does not seem to be possible\n- Creating a custom\
    \ model with the option predefined in `generation_config.json` does not seem to\
    \ work for me - I don't see a way to fork a model repository, and if I manually\
    \ clone it I am unable to push the pretrained models using git LFS\n- Loading\
    \ and invoking the model locally is unfortunately not viable \n\nNot sure what\
    \ to try at this point. If anyone (maybe @sanchit-gandhi - sorry for the extra\
    \ ping) has ideas I'm all ears\uFEFF\U0001F64F"
  created_at: 2023-01-28 12:05:16+00:00
  edited: false
  hidden: false
  id: 63d50f7c98e20226041ce0d2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-01-31T10:17:55.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;orangediamond&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/orangediamond\"\
          >@<span class=\"underline\">orangediamond</span></a></span>\n\n\t</span></span>,</p>\n\
          <p>Thanks for clarifying and apologies for the delayed response! Indeed,\
          \ it seems like detailed parameters are not supported for the ASR pipeline.\
          \ Would a custom inference handler be better suited in this case? <a href=\"\
          https://huggingface.co/docs/inference-endpoints/guides/custom_handler#create-custom-inference-handler\"\
          >https://huggingface.co/docs/inference-endpoints/guides/custom_handler#create-custom-inference-handler</a></p>\n\
          <p>Here, you might be able to adjust the <code>return_timestamps</code>\
          \ arg and set it to True.</p>\n<p>We just need to make sure that we've installed\
          \ Transformers from main. To do so, we can add the following to our requirements\
          \ file <a href=\"https://huggingface.co/docs/inference-endpoints/guides/custom_dependencies#add-custom-dependencies\"\
          >https://huggingface.co/docs/inference-endpoints/guides/custom_dependencies#add-custom-dependencies</a>:</p>\n\
          <pre><code>git+https://github.com/huggingface/transformers\n</code></pre>\n\
          <p>This will install the main branch of transformers, which has the latest\
          \ changes for Whisper.</p>\n"
        raw: 'Hey @orangediamond,


          Thanks for clarifying and apologies for the delayed response! Indeed, it
          seems like detailed parameters are not supported for the ASR pipeline. Would
          a custom inference handler be better suited in this case? https://huggingface.co/docs/inference-endpoints/guides/custom_handler#create-custom-inference-handler


          Here, you might be able to adjust the `return_timestamps` arg and set it
          to True.


          We just need to make sure that we''ve installed Transformers from main.
          To do so, we can add the following to our requirements file https://huggingface.co/docs/inference-endpoints/guides/custom_dependencies#add-custom-dependencies:

          ```

          git+https://github.com/huggingface/transformers

          ```

          This will install the main branch of transformers, which has the latest
          changes for Whisper.'
        updatedAt: '2023-01-31T10:17:55.537Z'
      numEdits: 0
      reactions: []
    id: 63d8ead3d3ea5e766912ea34
    type: comment
  author: sanchit-gandhi
  content: 'Hey @orangediamond,


    Thanks for clarifying and apologies for the delayed response! Indeed, it seems
    like detailed parameters are not supported for the ASR pipeline. Would a custom
    inference handler be better suited in this case? https://huggingface.co/docs/inference-endpoints/guides/custom_handler#create-custom-inference-handler


    Here, you might be able to adjust the `return_timestamps` arg and set it to True.


    We just need to make sure that we''ve installed Transformers from main. To do
    so, we can add the following to our requirements file https://huggingface.co/docs/inference-endpoints/guides/custom_dependencies#add-custom-dependencies:

    ```

    git+https://github.com/huggingface/transformers

    ```

    This will install the main branch of transformers, which has the latest changes
    for Whisper.'
  created_at: 2023-01-31 10:17:55+00:00
  edited: false
  hidden: false
  id: 63d8ead3d3ea5e766912ea34
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/be54a659ccc279e2a5f81431907850f5.svg
      fullname: Gustav
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: orangediamond
      type: user
    createdAt: '2023-02-03T18:21:04.000Z'
    data:
      edited: true
      editors:
      - orangediamond
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/be54a659ccc279e2a5f81431907850f5.svg
          fullname: Gustav
          isHf: false
          isPro: false
          name: orangediamond
          type: user
        html: "<p>Thanks for the suggestion! I do seem to be getting the same error\
          \ when attempting to <code>git push</code> anything to HF. This is what\
          \ I have done:</p>\n<ol>\n<li>I cloned the whisper-large-v2 with <code>GIT_LFS_SKIP_SMUDGE=1</code>\
          \ and used it as a template for my experiment.</li>\n</ol>\n<pre><code>\u03BB\
          \ GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/openai/whisper-large-v2\n\
          </code></pre>\n<ol start=\"2\">\n<li>I created a custom handler as described\
          \ in your link</li>\n</ol>\n<pre><code>from typing import Dict, List, Any\n\
          from transformers import pipeline\n\nclass EndpointHandler():\n    def __init__(self,\
          \ path=\"\"):\n        self.pipeline = pipeline(\n            \"automatic-speech-recognition\"\
          ,\n            model=\"openai/whisper-large-v2\",\n            chunk_length_s=30,\n\
          \            device=device,\n        )\n\n    def __call__(self, data: Dict[str,\
          \ Any]) -&gt; List[Dict[str, Any]]:\n        inputs = data.pop(\"inputs\"\
          , data)\n\n        prediction = self.pipeline(inputs, return_timestamps=True)\n\
          \        return prediction\n</code></pre>\n<ol start=\"3\">\n<li>I created\
          \ <code>requirements.txt</code> with <code>git+https://github.com/huggingface/transformers</code>\
          \ as the only dependency</li>\n<li>I now have the following files in my\
          \ repo:</li>\n</ol>\n<pre><code>\u03BB ls\nadded_tokens.json  generation_config.json\
          \  merges.txt       preprocessor_config.json  README.md         special_tokens_map.json\
          \  tokenizer_config.json\nconfig.json        handler.py              normalizer.json\
          \  pytorch_model.bin         requirements.txt  tf_model.h5             \
          \ vocab.json\n</code></pre>\n<ol start=\"5\">\n<li>I <code>git add .</code>,\
          \ <code>git commit -m [...]</code> and attempt to push:</li>\n</ol>\n<pre><code>\u03BB\
          \ git push\nUploading LFS objects:   0% (0/2), 0 B | 0 B/s, done.\nbatch\
          \ response: Repository not found\nerror: failed to push some refs to 'https://huggingface.co/orangediamond/whizper'\n\
          </code></pre>\n<p>For reference I use the following remote:</p>\n<pre><code>\u03BB\
          \ git remote get-url --all origin\nhttps://huggingface.co/orangediamond/whizper\n\
          </code></pre>\n<p>I am clearly doing something wrong but it is unclear to\
          \ me what exactly it is. Any ideas <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>?</p>\n"
        raw: "Thanks for the suggestion! I do seem to be getting the same error when\
          \ attempting to `git push` anything to HF. This is what I have done:\n\n\
          1. I cloned the whisper-large-v2 with `GIT_LFS_SKIP_SMUDGE=1` and used it\
          \ as a template for my experiment.\n```\n\u03BB GIT_LFS_SKIP_SMUDGE=1 git\
          \ clone https://huggingface.co/openai/whisper-large-v2\n```\n2. I created\
          \ a custom handler as described in your link\n```\nfrom typing import Dict,\
          \ List, Any\nfrom transformers import pipeline\n\nclass EndpointHandler():\n\
          \    def __init__(self, path=\"\"):\n        self.pipeline = pipeline(\n\
          \            \"automatic-speech-recognition\",\n            model=\"openai/whisper-large-v2\"\
          ,\n            chunk_length_s=30,\n            device=device,\n        )\n\
          \n    def __call__(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n\
          \        inputs = data.pop(\"inputs\", data)\n\n        prediction = self.pipeline(inputs,\
          \ return_timestamps=True)\n        return prediction\n```\n3. I created\
          \ `requirements.txt` with `git+https://github.com/huggingface/transformers`\
          \ as the only dependency\n4. I now have the following files in my repo:\
          \ \n```\n\u03BB ls\nadded_tokens.json  generation_config.json  merges.txt\
          \       preprocessor_config.json  README.md         special_tokens_map.json\
          \  tokenizer_config.json\nconfig.json        handler.py              normalizer.json\
          \  pytorch_model.bin         requirements.txt  tf_model.h5             \
          \ vocab.json\n```\n5. I `git add .`, `git commit -m [...]` and attempt to\
          \ push:\n```\n\u03BB git push\nUploading LFS objects:   0% (0/2), 0 B |\
          \ 0 B/s, done.\nbatch response: Repository not found\nerror: failed to push\
          \ some refs to 'https://huggingface.co/orangediamond/whizper'\n```\n\nFor\
          \ reference I use the following remote:\n```\n\u03BB git remote get-url\
          \ --all origin\nhttps://huggingface.co/orangediamond/whizper\n```\n\nI am\
          \ clearly doing something wrong but it is unclear to me what exactly it\
          \ is. Any ideas @sanchit-gandhi?"
        updatedAt: '2023-02-03T18:24:11.274Z'
      numEdits: 4
      reactions: []
    id: 63dd50906278d678e247d843
    type: comment
  author: orangediamond
  content: "Thanks for the suggestion! I do seem to be getting the same error when\
    \ attempting to `git push` anything to HF. This is what I have done:\n\n1. I cloned\
    \ the whisper-large-v2 with `GIT_LFS_SKIP_SMUDGE=1` and used it as a template\
    \ for my experiment.\n```\n\u03BB GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/openai/whisper-large-v2\n\
    ```\n2. I created a custom handler as described in your link\n```\nfrom typing\
    \ import Dict, List, Any\nfrom transformers import pipeline\n\nclass EndpointHandler():\n\
    \    def __init__(self, path=\"\"):\n        self.pipeline = pipeline(\n     \
    \       \"automatic-speech-recognition\",\n            model=\"openai/whisper-large-v2\"\
    ,\n            chunk_length_s=30,\n            device=device,\n        )\n\n \
    \   def __call__(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:\n      \
    \  inputs = data.pop(\"inputs\", data)\n\n        prediction = self.pipeline(inputs,\
    \ return_timestamps=True)\n        return prediction\n```\n3. I created `requirements.txt`\
    \ with `git+https://github.com/huggingface/transformers` as the only dependency\n\
    4. I now have the following files in my repo: \n```\n\u03BB ls\nadded_tokens.json\
    \  generation_config.json  merges.txt       preprocessor_config.json  README.md\
    \         special_tokens_map.json  tokenizer_config.json\nconfig.json        handler.py\
    \              normalizer.json  pytorch_model.bin         requirements.txt  tf_model.h5\
    \              vocab.json\n```\n5. I `git add .`, `git commit -m [...]` and attempt\
    \ to push:\n```\n\u03BB git push\nUploading LFS objects:   0% (0/2), 0 B | 0 B/s,\
    \ done.\nbatch response: Repository not found\nerror: failed to push some refs\
    \ to 'https://huggingface.co/orangediamond/whizper'\n```\n\nFor reference I use\
    \ the following remote:\n```\n\u03BB git remote get-url --all origin\nhttps://huggingface.co/orangediamond/whizper\n\
    ```\n\nI am clearly doing something wrong but it is unclear to me what exactly\
    \ it is. Any ideas @sanchit-gandhi?"
  created_at: 2023-02-03 18:21:04+00:00
  edited: true
  hidden: false
  id: 63dd50906278d678e247d843
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-02-10T13:14:27.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;orangediamond&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/orangediamond\"\
          >@<span class=\"underline\">orangediamond</span></a></span>\n\n\t</span></span>,\
          \ sorry for the delayed response! The repo <code>orangediamond/whizper</code>\
          \ exists on the Hub before you do the Git push? I can't see it there (but\
          \ it might be private). Could you make sure that you're correctly pushing\
          \ to the target repo?</p>\n"
        raw: Hey @orangediamond, sorry for the delayed response! The repo `orangediamond/whizper`
          exists on the Hub before you do the Git push? I can't see it there (but
          it might be private). Could you make sure that you're correctly pushing
          to the target repo?
        updatedAt: '2023-02-10T13:14:27.883Z'
      numEdits: 0
      reactions: []
    id: 63e6433363037c7d960e3ea5
    type: comment
  author: sanchit-gandhi
  content: Hey @orangediamond, sorry for the delayed response! The repo `orangediamond/whizper`
    exists on the Hub before you do the Git push? I can't see it there (but it might
    be private). Could you make sure that you're correctly pushing to the target repo?
  created_at: 2023-02-10 13:14:27+00:00
  edited: false
  hidden: false
  id: 63e6433363037c7d960e3ea5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/be54a659ccc279e2a5f81431907850f5.svg
      fullname: Gustav
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: orangediamond
      type: user
    createdAt: '2023-02-10T15:00:09.000Z'
    data:
      edited: true
      editors:
      - orangediamond
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/be54a659ccc279e2a5f81431907850f5.svg
          fullname: Gustav
          isHf: false
          isPro: false
          name: orangediamond
          type: user
        html: "<p>No worries <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>.\
          \ It does exist (privately) but I am not sure if it does so in the capacity\
          \ that is required:</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1676041105118-6363ebe5084f4905978483b3.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1676041105118-6363ebe5084f4905978483b3.png\"\
          ></a></p>\n<p>I would have imagined the above to suffice as far as being\
          \ able to push to the repo goes?</p>\n"
        raw: 'No worries @sanchit-gandhi. It does exist (privately) but I am not sure
          if it does so in the capacity that is required:


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1676041105118-6363ebe5084f4905978483b3.png)


          I would have imagined the above to suffice as far as being able to push
          to the repo goes?'
        updatedAt: '2023-02-10T15:03:59.556Z'
      numEdits: 1
      reactions: []
    id: 63e65bf95c3664766ec2d306
    type: comment
  author: orangediamond
  content: 'No worries @sanchit-gandhi. It does exist (privately) but I am not sure
    if it does so in the capacity that is required:


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1676041105118-6363ebe5084f4905978483b3.png)


    I would have imagined the above to suffice as far as being able to push to the
    repo goes?'
  created_at: 2023-02-10 15:00:09+00:00
  edited: true
  hidden: false
  id: 63e65bf95c3664766ec2d306
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-02-10T15:06:07.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;orangediamond&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/orangediamond\"\
          >@<span class=\"underline\">orangediamond</span></a></span>\n\n\t</span></span>!\
          \ Indeed, that should be sufficient. Maybe worth trying clone the repo explicitly\
          \ to your local device, moving all the files there and then pushing from\
          \ within the repo?</p>\n<p>Maybe out of context: would a HF Space suffice\
          \ for your deployment? E.g. the one here: <a href=\"https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2\"\
          >https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2</a></p>\n\
          <p>You can click \"view API\" at the bottom of the page to see how to send\
          \ requests etc</p>\n"
        raw: 'Hey @orangediamond! Indeed, that should be sufficient. Maybe worth trying
          clone the repo explicitly to your local device, moving all the files there
          and then pushing from within the repo?


          Maybe out of context: would a HF Space suffice for your deployment? E.g.
          the one here: https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2


          You can click "view API" at the bottom of the page to see how to send requests
          etc'
        updatedAt: '2023-02-10T15:07:46.205Z'
      numEdits: 1
      reactions: []
    id: 63e65d5f26fa42e117f3dc76
    type: comment
  author: sanchit-gandhi
  content: 'Hey @orangediamond! Indeed, that should be sufficient. Maybe worth trying
    clone the repo explicitly to your local device, moving all the files there and
    then pushing from within the repo?


    Maybe out of context: would a HF Space suffice for your deployment? E.g. the one
    here: https://huggingface.co/spaces/sanchit-gandhi/whisper-large-v2


    You can click "view API" at the bottom of the page to see how to send requests
    etc'
  created_at: 2023-02-10 15:06:07+00:00
  edited: true
  hidden: false
  id: 63e65d5f26fa42e117f3dc76
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 14
repo_id: openai/whisper-large-v2
repo_type: model
status: open
target_branch: null
title: Additional output from the model apart from the transcribed text
