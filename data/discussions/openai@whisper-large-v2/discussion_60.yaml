!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nehacho
conflicting_files: null
created_at: 2023-08-21 21:09:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6689707ab31f5dbbe964dec881b7b525.svg
      fullname: Neha Cholera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nehacho
      type: user
    createdAt: '2023-08-21T22:09:20.000Z'
    data:
      edited: false
      editors:
      - nehacho
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.821877121925354
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6689707ab31f5dbbe964dec881b7b525.svg
          fullname: Neha Cholera
          isHf: false
          isPro: false
          name: nehacho
          type: user
        html: '<p>Hi, I was wondering if anyone has tried to fine tune the whisper
          large v2 and was facing an OOM error. I would appreciate some help on this
          issue.</p>

          <p>I have 8 GPUs 16 GB each and I am fine tuning whisper large using deep
          speed, yet I am facing OOM error. Here is what my training args look like
          :<br>training_args = Seq2SeqTrainingArguments(<br>        output_dir = "/home/ec2-user/SageMaker/whisper-large-finetuned-1.5M-ATM-CS-100-1000-8000Steps",<br>        per_device_train_batch_size
          = 2, # if you get cuda out-of-memory issue, try to decrease batch size by
          2x<br>        gradient_accumulation_steps = 4 ,  # increase by 2x for every
          2x decrease in batch size<br>        learning_rate = 1e-5,<br>        warmup_steps
          = 10,<br>        max_steps = 4000,<br>        gradient_checkpointing = True,<br>        fp16
          = True,<br>        evaluation_strategy = "steps",<br>        per_device_eval_batch_size
          = 2,<br>        eval_accumulation_steps = 2,<br>        predict_with_generate
          = True,<br>        generation_max_length = 225,<br>        save_steps =
          1000,<br>        eval_steps = 1000,<br>        logging_steps = 50,<br>        load_best_model_at_end
          = True,<br>        metric_for_best_model = "wer",<br>        greater_is_better
          = False,<br>        push_to_hub = False,<br>        optim="adafactor",<br>        deepspeed="/home/ec2-user/SageMaker/packages/WhisperFinetune/src/whisper_fine_tune/ds_config.json"<br>    )</p>

          '
        raw: "Hi, I was wondering if anyone has tried to fine tune the whisper large\
          \ v2 and was facing an OOM error. I would appreciate some help on this issue.\r\
          \n\r\nI have 8 GPUs 16 GB each and I am fine tuning whisper large using\
          \ deep speed, yet I am facing OOM error. Here is what my training args look\
          \ like : \r\ntraining_args = Seq2SeqTrainingArguments(\r\n        output_dir\
          \ = \"/home/ec2-user/SageMaker/whisper-large-finetuned-1.5M-ATM-CS-100-1000-8000Steps\"\
          ,\r\n        per_device_train_batch_size = 2, # if you get cuda out-of-memory\
          \ issue, try to decrease batch size by 2x\r\n        gradient_accumulation_steps\
          \ = 4 ,  # increase by 2x for every 2x decrease in batch size\r\n      \
          \  learning_rate = 1e-5,\r\n        warmup_steps = 10,\r\n        max_steps\
          \ = 4000,\r\n        gradient_checkpointing = True,\r\n        fp16 = True,\r\
          \n        evaluation_strategy = \"steps\",\r\n        per_device_eval_batch_size\
          \ = 2,\r\n        eval_accumulation_steps = 2,\r\n        predict_with_generate\
          \ = True,\r\n        generation_max_length = 225,\r\n        save_steps\
          \ = 1000,\r\n        eval_steps = 1000,\r\n        logging_steps = 50,\r\
          \n        load_best_model_at_end = True,\r\n        metric_for_best_model\
          \ = \"wer\",\r\n        greater_is_better = False,\r\n        push_to_hub\
          \ = False,\r\n        optim=\"adafactor\",\r\n        deepspeed=\"/home/ec2-user/SageMaker/packages/WhisperFinetune/src/whisper_fine_tune/ds_config.json\"\
          \r\n    )"
        updatedAt: '2023-08-21T22:09:20.306Z'
      numEdits: 0
      reactions: []
    id: 64e3e090cf8c236f303dfa3d
    type: comment
  author: nehacho
  content: "Hi, I was wondering if anyone has tried to fine tune the whisper large\
    \ v2 and was facing an OOM error. I would appreciate some help on this issue.\r\
    \n\r\nI have 8 GPUs 16 GB each and I am fine tuning whisper large using deep speed,\
    \ yet I am facing OOM error. Here is what my training args look like : \r\ntraining_args\
    \ = Seq2SeqTrainingArguments(\r\n        output_dir = \"/home/ec2-user/SageMaker/whisper-large-finetuned-1.5M-ATM-CS-100-1000-8000Steps\"\
    ,\r\n        per_device_train_batch_size = 2, # if you get cuda out-of-memory\
    \ issue, try to decrease batch size by 2x\r\n        gradient_accumulation_steps\
    \ = 4 ,  # increase by 2x for every 2x decrease in batch size\r\n        learning_rate\
    \ = 1e-5,\r\n        warmup_steps = 10,\r\n        max_steps = 4000,\r\n     \
    \   gradient_checkpointing = True,\r\n        fp16 = True,\r\n        evaluation_strategy\
    \ = \"steps\",\r\n        per_device_eval_batch_size = 2,\r\n        eval_accumulation_steps\
    \ = 2,\r\n        predict_with_generate = True,\r\n        generation_max_length\
    \ = 225,\r\n        save_steps = 1000,\r\n        eval_steps = 1000,\r\n     \
    \   logging_steps = 50,\r\n        load_best_model_at_end = True,\r\n        metric_for_best_model\
    \ = \"wer\",\r\n        greater_is_better = False,\r\n        push_to_hub = False,\r\
    \n        optim=\"adafactor\",\r\n        deepspeed=\"/home/ec2-user/SageMaker/packages/WhisperFinetune/src/whisper_fine_tune/ds_config.json\"\
    \r\n    )"
  created_at: 2023-08-21 21:09:20+00:00
  edited: false
  hidden: false
  id: 64e3e090cf8c236f303dfa3d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-08-25T14:15:10.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8088793754577637
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Serious firepower <span data-props=\"{&quot;user&quot;:&quot;nehacho&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nehacho\"\
          >@<span class=\"underline\">nehacho</span></a></span>\n\n\t</span></span>!\
          \ What's your DS config looking like? And are you launching with multiple\
          \ CUDA devices as per this guide?</p>\n<ul>\n<li>Python script: <a href=\"\
          https://huggingface.co/docs/transformers/main_classes/deepspeed#deployment-with-multiple-gpus\"\
          >https://huggingface.co/docs/transformers/main_classes/deepspeed#deployment-with-multiple-gpus</a></li>\n\
          <li>Jupyter Notebook: <a href=\"https://huggingface.co/docs/transformers/main_classes/deepspeed#deployment-in-notebooks\"\
          >https://huggingface.co/docs/transformers/main_classes/deepspeed#deployment-in-notebooks</a></li>\n\
          </ul>\n"
        raw: 'Serious firepower @nehacho! What''s your DS config looking like? And
          are you launching with multiple CUDA devices as per this guide?

          * Python script: https://huggingface.co/docs/transformers/main_classes/deepspeed#deployment-with-multiple-gpus

          * Jupyter Notebook: https://huggingface.co/docs/transformers/main_classes/deepspeed#deployment-in-notebooks


          '
        updatedAt: '2023-08-25T14:15:10.335Z'
      numEdits: 0
      reactions: []
    id: 64e8b76e2292cd13a0bb5682
    type: comment
  author: sanchit-gandhi
  content: 'Serious firepower @nehacho! What''s your DS config looking like? And are
    you launching with multiple CUDA devices as per this guide?

    * Python script: https://huggingface.co/docs/transformers/main_classes/deepspeed#deployment-with-multiple-gpus

    * Jupyter Notebook: https://huggingface.co/docs/transformers/main_classes/deepspeed#deployment-in-notebooks


    '
  created_at: 2023-08-25 13:15:10+00:00
  edited: false
  hidden: false
  id: 64e8b76e2292cd13a0bb5682
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6689707ab31f5dbbe964dec881b7b525.svg
      fullname: Neha Cholera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nehacho
      type: user
    createdAt: '2023-08-25T16:55:28.000Z'
    data:
      edited: false
      editors:
      - nehacho
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9213671684265137
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6689707ab31f5dbbe964dec881b7b525.svg
          fullname: Neha Cholera
          isHf: false
          isPro: false
          name: nehacho
          type: user
        html: '<p>Hey, I could make it run at last. Just tweaked the DS config. Thank
          you for the response though. Appreciate it!</p>

          '
        raw: Hey, I could make it run at last. Just tweaked the DS config. Thank you
          for the response though. Appreciate it!
        updatedAt: '2023-08-25T16:55:28.183Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64e8dd0018d79efd5311b297
    id: 64e8dd0018d79efd5311b293
    type: comment
  author: nehacho
  content: Hey, I could make it run at last. Just tweaked the DS config. Thank you
    for the response though. Appreciate it!
  created_at: 2023-08-25 15:55:28+00:00
  edited: false
  hidden: false
  id: 64e8dd0018d79efd5311b293
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/6689707ab31f5dbbe964dec881b7b525.svg
      fullname: Neha Cholera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nehacho
      type: user
    createdAt: '2023-08-25T16:55:28.000Z'
    data:
      status: closed
    id: 64e8dd0018d79efd5311b297
    type: status-change
  author: nehacho
  created_at: 2023-08-25 15:55:28+00:00
  id: 64e8dd0018d79efd5311b297
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-09-06T15:27:02.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.43966659903526306
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Awesome! Nice job <span data-props=\"{&quot;user&quot;:&quot;nehacho&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nehacho\"\
          >@<span class=\"underline\">nehacho</span></a></span>\n\n\t</span></span>!</p>\n"
        raw: Awesome! Nice job @nehacho!
        updatedAt: '2023-09-06T15:27:02.866Z'
      numEdits: 0
      reactions: []
    id: 64f89a4633fd3f0fcb764458
    type: comment
  author: sanchit-gandhi
  content: Awesome! Nice job @nehacho!
  created_at: 2023-09-06 14:27:02+00:00
  edited: false
  hidden: false
  id: 64f89a4633fd3f0fcb764458
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/860a732f77f2dbe9a4d3990ddc921f6e.svg
      fullname: vahid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vahidmirnezami
      type: user
    createdAt: '2023-12-05T14:47:46.000Z'
    data:
      edited: false
      editors:
      - vahidmirnezami
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9593468308448792
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/860a732f77f2dbe9a4d3990ddc921f6e.svg
          fullname: vahid
          isHf: false
          isPro: false
          name: vahidmirnezami
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;nehacho&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/nehacho\">@<span class=\"\
          underline\">nehacho</span></a></span>\n\n\t</span></span>. would you please\
          \ provide the DS config that works for you?</p>\n"
        raw: Hi @nehacho. would you please provide the DS config that works for you?
        updatedAt: '2023-12-05T14:47:46.841Z'
      numEdits: 0
      reactions: []
    id: 656f3812fa2f36ad5af51dc5
    type: comment
  author: vahidmirnezami
  content: Hi @nehacho. would you please provide the DS config that works for you?
  created_at: 2023-12-05 14:47:46+00:00
  edited: false
  hidden: false
  id: 656f3812fa2f36ad5af51dc5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 60
repo_id: openai/whisper-large-v2
repo_type: model
status: closed
target_branch: null
title: Whisper Large FineTuning with 8 16 GB GPUs, running into OOM error
