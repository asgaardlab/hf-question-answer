!!python/object:huggingface_hub.community.DiscussionWithDetails
author: artyomboyko
conflicting_files: null
created_at: 2023-01-22 13:01:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f0cfbe52a259b855d290e/xmeMuNoi-3Ka5Ux_X5dJn.jpeg?w=200&h=200&f=face
      fullname: Artyom Boyko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: artyomboyko
      type: user
    createdAt: '2023-01-22T13:01:10.000Z'
    data:
      edited: false
      editors:
      - artyomboyko
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f0cfbe52a259b855d290e/xmeMuNoi-3Ka5Ux_X5dJn.jpeg?w=200&h=200&f=face
          fullname: Artyom Boyko
          isHf: false
          isPro: false
          name: artyomboyko
          type: user
        html: "<p>Good afternoon. Is there any way to generate audio transcoding without\
          \ breaking sentences.</p>\n<p>For example, when transcribing a video get\
          \ instead of:</p>\n<pre><code>00:00:08,960 --&gt; 00:00:13,840 This video\
          \ is an introductory video about coders, decoders and codecs.\n00:00:13,840\
          \ --&gt; 00:00:18,640. In this episode we try to understand what a transformer\
          \ network is all about,\n00:00:18,640 --&gt; 00:00:24,720 and try to explain\
          \ it in simple, high-level terms. \n</code></pre>\n<p>The following:</p>\n\
          <pre><code>00:00:08,960 --&gt; 00:00:18,640 This video is an introductory\
          \ video to a series of videos about coders, decoders, and coder decoders.\n\
          00:00:18,640 --&gt; 00:00:24,720 In this series we will try to understand\
          \ what a transformer network is and try to explain it in simple, high-level\
          \ terms.\n</code></pre>\n<p>???</p>\n"
        raw: "Good afternoon. Is there any way to generate audio transcoding without\
          \ breaking sentences.\r\n\r\nFor example, when transcribing a video get\
          \ instead of:\r\n```\r\n00:00:08,960 --> 00:00:13,840 This video is an introductory\
          \ video about coders, decoders and codecs.\r\n00:00:13,840 --> 00:00:18,640.\
          \ In this episode we try to understand what a transformer network is all\
          \ about,\r\n00:00:18,640 --> 00:00:24,720 and try to explain it in simple,\
          \ high-level terms. \r\n```\r\nThe following:\r\n\r\n```\r\n00:00:08,960\
          \ --> 00:00:18,640 This video is an introductory video to a series of videos\
          \ about coders, decoders, and coder decoders.\r\n00:00:18,640 --> 00:00:24,720\
          \ In this series we will try to understand what a transformer network is\
          \ and try to explain it in simple, high-level terms.\r\n```\r\n???"
        updatedAt: '2023-01-22T13:01:10.037Z'
      numEdits: 0
      reactions: []
    id: 63cd33961c8a5d1d7d74dc96
    type: comment
  author: artyomboyko
  content: "Good afternoon. Is there any way to generate audio transcoding without\
    \ breaking sentences.\r\n\r\nFor example, when transcribing a video get instead\
    \ of:\r\n```\r\n00:00:08,960 --> 00:00:13,840 This video is an introductory video\
    \ about coders, decoders and codecs.\r\n00:00:13,840 --> 00:00:18,640. In this\
    \ episode we try to understand what a transformer network is all about,\r\n00:00:18,640\
    \ --> 00:00:24,720 and try to explain it in simple, high-level terms. \r\n```\r\
    \nThe following:\r\n\r\n```\r\n00:00:08,960 --> 00:00:18,640 This video is an\
    \ introductory video to a series of videos about coders, decoders, and coder decoders.\r\
    \n00:00:18,640 --> 00:00:24,720 In this series we will try to understand what\
    \ a transformer network is and try to explain it in simple, high-level terms.\r\
    \n```\r\n???"
  created_at: 2023-01-22 13:01:10+00:00
  edited: false
  hidden: false
  id: 63cd33961c8a5d1d7d74dc96
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-01-24T13:31:07.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey @ElectricSecretAgent! Could you simply piece together the transcriptions\
          \ and take the first/last timestamps?</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> pipeline\n\
          <span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\"\
          >import</span> load_dataset\n\nmodel = <span class=\"hljs-string\">\"openai/whisper-tiny\"\
          </span>\ndevice = <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\"\
          >if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span>\
          \ <span class=\"hljs-string\">\"cpu\"</span>\n\npipe = pipeline(\n    task=<span\
          \ class=\"hljs-string\">\"automatic-speech-recognition\"</span>,\n    model=model,\n\
          \    chunk_length_s=<span class=\"hljs-number\">30</span>,\n    device=device,\n\
          )\n\n<span class=\"hljs-comment\"># replace this with the loading/inference\
          \ for your audio sample</span>\nls_dummy = load_dataset(<span class=\"hljs-string\"\
          >\"hf-internal-testing/librispeech_asr_dummy\"</span>, <span class=\"hljs-string\"\
          >\"clean\"</span>, split=<span class=\"hljs-string\">\"validation\"</span>)\n\
          out = pipe(ls_dummy[<span class=\"hljs-number\">0</span>][<span class=\"\
          hljs-string\">\"audio\"</span>], return_timestamps=<span class=\"hljs-literal\"\
          >True</span>)\n\n<span class=\"hljs-comment\"># join all the text together</span>\n\
          text = [chunk[<span class=\"hljs-string\">\"text\"</span>] <span class=\"\
          hljs-keyword\">for</span> chunk <span class=\"hljs-keyword\">in</span> out[<span\
          \ class=\"hljs-string\">\"chunks\"</span>]]\ntext = <span class=\"hljs-string\"\
          >\"\"</span>.join(text)\n\n<span class=\"hljs-comment\"># get first timestamp\
          \ of first chunk</span>\nstart = out[<span class=\"hljs-string\">\"chunks\"\
          </span>][<span class=\"hljs-number\">0</span>][<span class=\"hljs-string\"\
          >\"timestamp\"</span>][<span class=\"hljs-number\">0</span>]\n<span class=\"\
          hljs-comment\"># get last timestamp of last chunk</span>\nend = out[<span\
          \ class=\"hljs-string\">\"chunks\"</span>][-<span class=\"hljs-number\"\
          >1</span>][<span class=\"hljs-string\">\"timestamp\"</span>][-<span class=\"\
          hljs-number\">1</span>]\n\n<span class=\"hljs-built_in\">print</span>(<span\
          \ class=\"hljs-string\">f\"<span class=\"hljs-subst\">{start}</span> -&gt;\
          \ <span class=\"hljs-subst\">{end}</span>: <span class=\"hljs-subst\">{text}</span>\"\
          </span>)\n</code></pre>\n<p><strong>Print output</strong>:</p>\n<pre><code>0.0\
          \ -&gt; 5.44:  Mr. Quilter is the apostle of the middle classes and we are\
          \ glad to welcome his gospel.\n</code></pre>\n"
        raw: "Hey @ElectricSecretAgent! Could you simply piece together the transcriptions\
          \ and take the first/last timestamps?\n\n```python\nimport torch\nfrom transformers\
          \ import pipeline\nfrom datasets import load_dataset\n\nmodel = \"openai/whisper-tiny\"\
          \ndevice = 0 if torch.cuda.is_available() else \"cpu\"\n\npipe = pipeline(\n\
          \    task=\"automatic-speech-recognition\",\n    model=model,\n    chunk_length_s=30,\n\
          \    device=device,\n)\n\n# replace this with the loading/inference for\
          \ your audio sample\nls_dummy = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\"\
          , \"clean\", split=\"validation\")\nout = pipe(ls_dummy[0][\"audio\"], return_timestamps=True)\n\
          \n# join all the text together\ntext = [chunk[\"text\"] for chunk in out[\"\
          chunks\"]]\ntext = \"\".join(text)\n\n# get first timestamp of first chunk\n\
          start = out[\"chunks\"][0][\"timestamp\"][0]\n# get last timestamp of last\
          \ chunk\nend = out[\"chunks\"][-1][\"timestamp\"][-1]\n\nprint(f\"{start}\
          \ -> {end}: {text}\")\n```\n**Print output**:\n```\n0.0 -> 5.44:  Mr. Quilter\
          \ is the apostle of the middle classes and we are glad to welcome his gospel.\n\
          ```"
        updatedAt: '2023-01-24T13:32:24.405Z'
      numEdits: 4
      reactions: []
    id: 63cfdd9b68ef6e7fad9868fd
    type: comment
  author: sanchit-gandhi
  content: "Hey @ElectricSecretAgent! Could you simply piece together the transcriptions\
    \ and take the first/last timestamps?\n\n```python\nimport torch\nfrom transformers\
    \ import pipeline\nfrom datasets import load_dataset\n\nmodel = \"openai/whisper-tiny\"\
    \ndevice = 0 if torch.cuda.is_available() else \"cpu\"\n\npipe = pipeline(\n \
    \   task=\"automatic-speech-recognition\",\n    model=model,\n    chunk_length_s=30,\n\
    \    device=device,\n)\n\n# replace this with the loading/inference for your audio\
    \ sample\nls_dummy = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\"\
    , \"clean\", split=\"validation\")\nout = pipe(ls_dummy[0][\"audio\"], return_timestamps=True)\n\
    \n# join all the text together\ntext = [chunk[\"text\"] for chunk in out[\"chunks\"\
    ]]\ntext = \"\".join(text)\n\n# get first timestamp of first chunk\nstart = out[\"\
    chunks\"][0][\"timestamp\"][0]\n# get last timestamp of last chunk\nend = out[\"\
    chunks\"][-1][\"timestamp\"][-1]\n\nprint(f\"{start} -> {end}: {text}\")\n```\n\
    **Print output**:\n```\n0.0 -> 5.44:  Mr. Quilter is the apostle of the middle\
    \ classes and we are glad to welcome his gospel.\n```"
  created_at: 2023-01-24 13:31:07+00:00
  edited: true
  hidden: false
  id: 63cfdd9b68ef6e7fad9868fd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f0cfbe52a259b855d290e/xmeMuNoi-3Ka5Ux_X5dJn.jpeg?w=200&h=200&f=face
      fullname: Artyom Boyko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: artyomboyko
      type: user
    createdAt: '2023-01-25T16:08:54.000Z'
    data:
      edited: false
      editors:
      - artyomboyko
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f0cfbe52a259b855d290e/xmeMuNoi-3Ka5Ux_X5dJn.jpeg?w=200&h=200&f=face
          fullname: Artyom Boyko
          isHf: false
          isPro: false
          name: artyomboyko
          type: user
        html: '<p>Thanks. I test it.</p>

          '
        raw: Thanks. I test it.
        updatedAt: '2023-01-25T16:08:54.355Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - artyomboyko
    id: 63d15416119416cdbe14e9c3
    type: comment
  author: artyomboyko
  content: Thanks. I test it.
  created_at: 2023-01-25 16:08:54+00:00
  edited: false
  hidden: false
  id: 63d15416119416cdbe14e9c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d86ee02f822c9bebea2fe6cab5ac8ad.svg
      fullname: David Zhuang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cnbeining
      type: user
    createdAt: '2023-03-24T01:04:38.000Z'
    data:
      edited: false
      editors:
      - cnbeining
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d86ee02f822c9bebea2fe6cab5ac8ad.svg
          fullname: David Zhuang
          isHf: false
          isPro: false
          name: cnbeining
          type: user
        html: '<p>See ACICFG''s implementation(with VAD, forced alignment and translation
          pipeline): <a rel="nofollow" href="https://colab.research.google.com/github/cnbeining/Whisper_Notebook/blob/master/WhisperX.ipynb">https://colab.research.google.com/github/cnbeining/Whisper_Notebook/blob/master/WhisperX.ipynb</a></p>

          '
        raw: 'See ACICFG''s implementation(with VAD, forced alignment and translation
          pipeline): https://colab.research.google.com/github/cnbeining/Whisper_Notebook/blob/master/WhisperX.ipynb'
        updatedAt: '2023-03-24T01:04:38.757Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - artyomboyko
    id: 641cf726b54f6cf02b04537e
    type: comment
  author: cnbeining
  content: 'See ACICFG''s implementation(with VAD, forced alignment and translation
    pipeline): https://colab.research.google.com/github/cnbeining/Whisper_Notebook/blob/master/WhisperX.ipynb'
  created_at: 2023-03-24 00:04:38+00:00
  edited: false
  hidden: false
  id: 641cf726b54f6cf02b04537e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f0cfbe52a259b855d290e/xmeMuNoi-3Ka5Ux_X5dJn.jpeg?w=200&h=200&f=face
      fullname: Artyom Boyko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: artyomboyko
      type: user
    createdAt: '2023-03-30T18:05:33.000Z'
    data:
      edited: false
      editors:
      - artyomboyko
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f0cfbe52a259b855d290e/xmeMuNoi-3Ka5Ux_X5dJn.jpeg?w=200&h=200&f=face
          fullname: Artyom Boyko
          isHf: false
          isPro: false
          name: artyomboyko
          type: user
        html: '<p>Thanks!</p>

          '
        raw: Thanks!
        updatedAt: '2023-03-30T18:05:33.896Z'
      numEdits: 0
      reactions: []
    id: 6425cf6d37a416bff53cf287
    type: comment
  author: artyomboyko
  content: Thanks!
  created_at: 2023-03-30 17:05:33+00:00
  edited: false
  hidden: false
  id: 6425cf6d37a416bff53cf287
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-04-04T16:59:22.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: '<p>You can also set <code>batch_size=...</code> in the transformers
          implementation to speed-up transcription for long audio samples:</p>

          <pre><code class="language-python">out = pipe(ls_dummy[<span class="hljs-number">0</span>][<span
          class="hljs-string">"audio"</span>], return_timestamps=<span class="hljs-literal">True</span>,
          batch_size=<span class="hljs-number">4</span>)

          </code></pre>

          '
        raw: 'You can also set `batch_size=...` in the transformers implementation
          to speed-up transcription for long audio samples:

          ```python

          out = pipe(ls_dummy[0]["audio"], return_timestamps=True, batch_size=4)

          ```'
        updatedAt: '2023-04-04T16:59:22.572Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - artyomboyko
    id: 642c576a0d7975d94272813e
    type: comment
  author: sanchit-gandhi
  content: 'You can also set `batch_size=...` in the transformers implementation to
    speed-up transcription for long audio samples:

    ```python

    out = pipe(ls_dummy[0]["audio"], return_timestamps=True, batch_size=4)

    ```'
  created_at: 2023-04-04 15:59:22+00:00
  edited: false
  hidden: false
  id: 642c576a0d7975d94272813e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: openai/whisper-large-v2
repo_type: model
status: open
target_branch: null
title: Audio transcribing, timestamping for whole sentences.
