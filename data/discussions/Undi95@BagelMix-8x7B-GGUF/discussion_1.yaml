!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tonatiuhmira
conflicting_files: null
created_at: 2024-01-13 23:00:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678247086118-noauth.jpeg?w=200&h=200&f=face
      fullname: Tonatiuh Miramontes Perez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tonatiuhmira
      type: user
    createdAt: '2024-01-13T23:00:26.000Z'
    data:
      edited: false
      editors:
      - Tonatiuhmira
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9322099089622498
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678247086118-noauth.jpeg?w=200&h=200&f=face
          fullname: Tonatiuh Miramontes Perez
          isHf: false
          isPro: false
          name: Tonatiuhmira
          type: user
        html: "<p>Hi, just been testing this model (q4_0, 8K context),<br>found it\
          \ quite interesting using the ChatML prompt, allowing for good \"asssitant\"\
          \ interactions, and even when RP it abides quite well to the character,\
          \ but then it tends to repeat the same phrases indefinitely, regardless\
          \ of the temperature or CFG. Besides of the initial response for a 2k character\
          \ taking about 2 min, the following responses are very acceptable in speed\
          \ (approx 3 token/s), having offloaded only 10 layers to GPU. So I think\
          \ it is a very well performant model, considering my setup is quite limited\
          \ (RX6800, 16 GB VRAM + Ryzen 7600x w/64 GB DDR5@6000MT/s).<br>Under SillyTavern,\
          \ \"Roleplay\" preset seems to cause the model to hallucinate in excess\
          \ and produce extra long and repetitive responses.<br>When tested as \"\
          assistant\", it was notorious that there remains a strong censorship within\
          \ the model, frequently highlighting ethic implications, power imbalances\
          \ and so on,  even if explicitly commanded not to do so.<br>Considering\
          \ it is the quantized version, it seems this technique is quite promising.</p>\n\
          <p>Thank you for your work, <span data-props=\"{&quot;user&quot;:&quot;Undi95&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Undi95\"\
          >@<span class=\"underline\">Undi95</span></a></span>\n\n\t</span></span>\
          \ .</p>\n"
        raw: "Hi, just been testing this model (q4_0, 8K context),\r\nfound it quite\
          \ interesting using the ChatML prompt, allowing for good \"asssitant\" interactions,\
          \ and even when RP it abides quite well to the character, but then it tends\
          \ to repeat the same phrases indefinitely, regardless of the temperature\
          \ or CFG. Besides of the initial response for a 2k character taking about\
          \ 2 min, the following responses are very acceptable in speed (approx 3\
          \ token/s), having offloaded only 10 layers to GPU. So I think it is a very\
          \ well performant model, considering my setup is quite limited (RX6800,\
          \ 16 GB VRAM + Ryzen 7600x w/64 GB DDR5@6000MT/s). \r\nUnder SillyTavern,\
          \ \"Roleplay\" preset seems to cause the model to hallucinate in excess\
          \ and produce extra long and repetitive responses.\r\nWhen tested as \"\
          assistant\", it was notorious that there remains a strong censorship within\
          \ the model, frequently highlighting ethic implications, power imbalances\
          \ and so on,  even if explicitly commanded not to do so.\r\nConsidering\
          \ it is the quantized version, it seems this technique is quite promising.\r\
          \n\r\nThank you for your work, @Undi95 ."
        updatedAt: '2024-01-13T23:00:26.042Z'
      numEdits: 0
      reactions: []
    id: 65a3160a9c370409e6d6b037
    type: comment
  author: Tonatiuhmira
  content: "Hi, just been testing this model (q4_0, 8K context),\r\nfound it quite\
    \ interesting using the ChatML prompt, allowing for good \"asssitant\" interactions,\
    \ and even when RP it abides quite well to the character, but then it tends to\
    \ repeat the same phrases indefinitely, regardless of the temperature or CFG.\
    \ Besides of the initial response for a 2k character taking about 2 min, the following\
    \ responses are very acceptable in speed (approx 3 token/s), having offloaded\
    \ only 10 layers to GPU. So I think it is a very well performant model, considering\
    \ my setup is quite limited (RX6800, 16 GB VRAM + Ryzen 7600x w/64 GB DDR5@6000MT/s).\
    \ \r\nUnder SillyTavern, \"Roleplay\" preset seems to cause the model to hallucinate\
    \ in excess and produce extra long and repetitive responses.\r\nWhen tested as\
    \ \"assistant\", it was notorious that there remains a strong censorship within\
    \ the model, frequently highlighting ethic implications, power imbalances and\
    \ so on,  even if explicitly commanded not to do so.\r\nConsidering it is the\
    \ quantized version, it seems this technique is quite promising.\r\n\r\nThank\
    \ you for your work, @Undi95 ."
  created_at: 2024-01-13 23:00:26+00:00
  edited: false
  hidden: false
  id: 65a3160a9c370409e6d6b037
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2024-01-14T03:11:10.000Z'
    data:
      edited: false
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9891294836997986
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<p>Hello, thanks for the feedback, I tried this to see what would be
          the reaction mixing a base who accept so much different prompting system,
          but yeah, even myself don''t really find it better that what exist right
          now. Still, I decided to let it up if people were curious!</p>

          '
        raw: Hello, thanks for the feedback, I tried this to see what would be the
          reaction mixing a base who accept so much different prompting system, but
          yeah, even myself don't really find it better that what exist right now.
          Still, I decided to let it up if people were curious!
        updatedAt: '2024-01-14T03:11:10.646Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Tonatiuhmira
        - PrimeD
    id: 65a350ce215aabac488a608b
    type: comment
  author: Undi95
  content: Hello, thanks for the feedback, I tried this to see what would be the reaction
    mixing a base who accept so much different prompting system, but yeah, even myself
    don't really find it better that what exist right now. Still, I decided to let
    it up if people were curious!
  created_at: 2024-01-14 03:11:10+00:00
  edited: false
  hidden: false
  id: 65a350ce215aabac488a608b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Undi95/BagelMix-8x7B-GGUF
repo_type: model
status: open
target_branch: null
title: Interesting model (feedback).
