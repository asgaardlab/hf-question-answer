!!python/object:huggingface_hub.community.DiscussionWithDetails
author: timlim123
conflicting_files: null
created_at: 2023-12-07 03:40:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12ec5e367e2eac1650b2961097f74fa2.svg
      fullname: Lim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: timlim123
      type: user
    createdAt: '2023-12-07T03:40:37.000Z'
    data:
      edited: true
      editors:
      - timlim123
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7693989872932434
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12ec5e367e2eac1650b2961097f74fa2.svg
          fullname: Lim
          isHf: false
          isPro: false
          name: timlim123
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;teknium&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/teknium\">@<span class=\"\
          underline\">teknium</span></a></span>\n\n\t</span></span> ,</p>\n<p>I believe\
          \ you trained using axolotl with this dataset config:</p>\n<pre><code>datasets:\n\
          \  - path: /data/chat_data/full_dataset_chat.jsonl\n    type: sharegpt\n\
          \    conversation: chatml\ndataset_prepared_path: last_run_prepared\n</code></pre>\n\
          <p>Did you realised that Axolotl actually adds an extra linebreak (somehow)\
          \ and it becomes <code>&lt;|im_end|&gt;\\n\\n</code> ? or did you create\
          \ your own custom dataset and dataloader?  Hope to see your release of the\
          \ configuration file and dataset format. </p>\n<p>I found out by debugging\
          \ step-by-step to run through the repo, the last few label tokens will be\
          \ always be  [....., 28766, 321, 28730, 416, 28766, 28767, 13, 13, 2] which\
          \ when decoded is <code>&lt;|im_end|&gt;\\n\\n&lt;/s&gt;</code>.</p>\n<p>Issue\
          \ could be here (extra <code>\\n</code> in sep): <a rel=\"nofollow\" href=\"\
          https://github.com/OpenAccess-AI-Collective/axolotl/blob/a48dbf6561cc74c275a48070f397334a2c367dd5/src/axolotl/prompt_strategies/sharegpt.py#L16\"\
          >https://github.com/OpenAccess-AI-Collective/axolotl/blob/a48dbf6561cc74c275a48070f397334a2c367dd5/src/axolotl/prompt_strategies/sharegpt.py#L16</a></p>\n"
        raw: "Hi @teknium ,\n\nI believe you trained using axolotl with this dataset\
          \ config:\n```\ndatasets:\n  - path: /data/chat_data/full_dataset_chat.jsonl\n\
          \    type: sharegpt\n    conversation: chatml\ndataset_prepared_path: last_run_prepared\n\
          ```\nDid you realised that Axolotl actually adds an extra linebreak (somehow)\
          \ and it becomes `<|im_end|>\\n\\n` ? or did you create your own custom\
          \ dataset and dataloader?  Hope to see your release of the configuration\
          \ file and dataset format. \n\nI found out by debugging step-by-step to\
          \ run through the repo, the last few label tokens will be always be  [.....,\
          \ 28766, 321, 28730, 416, 28766, 28767, 13, 13, 2] which when decoded is\
          \ `<|im_end|>\\n\\n</s>`.\n\nIssue could be here (extra `\\n` in sep): https://github.com/OpenAccess-AI-Collective/axolotl/blob/a48dbf6561cc74c275a48070f397334a2c367dd5/src/axolotl/prompt_strategies/sharegpt.py#L16\n\
          \n"
        updatedAt: '2023-12-07T03:42:54.892Z'
      numEdits: 1
      reactions: []
    id: 65713eb53e68d88fd621d1ad
    type: comment
  author: timlim123
  content: "Hi @teknium ,\n\nI believe you trained using axolotl with this dataset\
    \ config:\n```\ndatasets:\n  - path: /data/chat_data/full_dataset_chat.jsonl\n\
    \    type: sharegpt\n    conversation: chatml\ndataset_prepared_path: last_run_prepared\n\
    ```\nDid you realised that Axolotl actually adds an extra linebreak (somehow)\
    \ and it becomes `<|im_end|>\\n\\n` ? or did you create your own custom dataset\
    \ and dataloader?  Hope to see your release of the configuration file and dataset\
    \ format. \n\nI found out by debugging step-by-step to run through the repo, the\
    \ last few label tokens will be always be  [....., 28766, 321, 28730, 416, 28766,\
    \ 28767, 13, 13, 2] which when decoded is `<|im_end|>\\n\\n</s>`.\n\nIssue could\
    \ be here (extra `\\n` in sep): https://github.com/OpenAccess-AI-Collective/axolotl/blob/a48dbf6561cc74c275a48070f397334a2c367dd5/src/axolotl/prompt_strategies/sharegpt.py#L16\n\
    \n"
  created_at: 2023-12-07 03:40:37+00:00
  edited: true
  hidden: false
  id: 65713eb53e68d88fd621d1ad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-12-12T09:23:20.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7979404926300049
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: "<blockquote>\n<p>Hi <span data-props=\"{&quot;user&quot;:&quot;teknium&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/teknium\"\
          >@<span class=\"underline\">teknium</span></a></span>\n\n\t</span></span>\
          \ ,</p>\n<p>I believe you trained using axolotl with this dataset config:</p>\n\
          <pre><code>datasets:\n  - path: /data/chat_data/full_dataset_chat.jsonl\n\
          \    type: sharegpt\n    conversation: chatml\ndataset_prepared_path: last_run_prepared\n\
          </code></pre>\n<p>Did you realised that Axolotl actually adds an extra linebreak\
          \ (somehow) and it becomes <code>&lt;|im_end|&gt;\\n\\n</code> ? or did\
          \ you create your own custom dataset and dataloader?  Hope to see your release\
          \ of the configuration file and dataset format. </p>\n<p>I found out by\
          \ debugging step-by-step to run through the repo, the last few label tokens\
          \ will be always be  [....., 28766, 321, 28730, 416, 28766, 28767, 13, 13,\
          \ 2] which when decoded is <code>&lt;|im_end|&gt;\\n\\n&lt;/s&gt;</code>.</p>\n\
          <p>Issue could be here (extra <code>\\n</code> in sep): <a rel=\"nofollow\"\
          \ href=\"https://github.com/OpenAccess-AI-Collective/axolotl/blob/a48dbf6561cc74c275a48070f397334a2c367dd5/src/axolotl/prompt_strategies/sharegpt.py#L16\"\
          >https://github.com/OpenAccess-AI-Collective/axolotl/blob/a48dbf6561cc74c275a48070f397334a2c367dd5/src/axolotl/prompt_strategies/sharegpt.py#L16</a></p>\n\
          </blockquote>\n<p>I believe they changed things for chatml format after\
          \ this was trained</p>\n"
        raw: "> Hi @teknium ,\n> \n> I believe you trained using axolotl with this\
          \ dataset config:\n> ```\n> datasets:\n>   - path: /data/chat_data/full_dataset_chat.jsonl\n\
          >     type: sharegpt\n>     conversation: chatml\n> dataset_prepared_path:\
          \ last_run_prepared\n> ```\n> Did you realised that Axolotl actually adds\
          \ an extra linebreak (somehow) and it becomes `<|im_end|>\\n\\n` ? or did\
          \ you create your own custom dataset and dataloader?  Hope to see your release\
          \ of the configuration file and dataset format. \n> \n> I found out by debugging\
          \ step-by-step to run through the repo, the last few label tokens will be\
          \ always be  [....., 28766, 321, 28730, 416, 28766, 28767, 13, 13, 2] which\
          \ when decoded is `<|im_end|>\\n\\n</s>`.\n> \n> Issue could be here (extra\
          \ `\\n` in sep): https://github.com/OpenAccess-AI-Collective/axolotl/blob/a48dbf6561cc74c275a48070f397334a2c367dd5/src/axolotl/prompt_strategies/sharegpt.py#L16\n\
          \nI believe they changed things for chatml format after this was trained"
        updatedAt: '2023-12-12T09:23:20.231Z'
      numEdits: 0
      reactions: []
    id: 65782688277dceb6056c6410
    type: comment
  author: teknium
  content: "> Hi @teknium ,\n> \n> I believe you trained using axolotl with this dataset\
    \ config:\n> ```\n> datasets:\n>   - path: /data/chat_data/full_dataset_chat.jsonl\n\
    >     type: sharegpt\n>     conversation: chatml\n> dataset_prepared_path: last_run_prepared\n\
    > ```\n> Did you realised that Axolotl actually adds an extra linebreak (somehow)\
    \ and it becomes `<|im_end|>\\n\\n` ? or did you create your own custom dataset\
    \ and dataloader?  Hope to see your release of the configuration file and dataset\
    \ format. \n> \n> I found out by debugging step-by-step to run through the repo,\
    \ the last few label tokens will be always be  [....., 28766, 321, 28730, 416,\
    \ 28766, 28767, 13, 13, 2] which when decoded is `<|im_end|>\\n\\n</s>`.\n> \n\
    > Issue could be here (extra `\\n` in sep): https://github.com/OpenAccess-AI-Collective/axolotl/blob/a48dbf6561cc74c275a48070f397334a2c367dd5/src/axolotl/prompt_strategies/sharegpt.py#L16\n\
    \nI believe they changed things for chatml format after this was trained"
  created_at: 2023-12-12 09:23:20+00:00
  edited: false
  hidden: false
  id: 65782688277dceb6056c6410
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: teknium/OpenHermes-2.5-Mistral-7B
repo_type: model
status: open
target_branch: null
title: Axolotl prompt format (sharegpt, chatml) could differ from yours
