!!python/object:huggingface_hub.community.DiscussionWithDetails
author: duishoev
conflicting_files: null
created_at: 2024-01-04 10:40:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0d0d96d59dd06658157d71ac62aa5557.svg
      fullname: N D
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: duishoev
      type: user
    createdAt: '2024-01-04T10:40:09.000Z'
    data:
      edited: false
      editors:
      - duishoev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9482084512710571
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0d0d96d59dd06658157d71ac62aa5557.svg
          fullname: N D
          isHf: false
          isPro: false
          name: duishoev
          type: user
        html: '<p>This looks interesting. I fine tuned in my local mac for some tasks
          and the performance was not stellar. Do you mind sharing some tips or codebase
          to fine tune phi-2? Would greatly appreciate, thanks.</p>

          '
        raw: This looks interesting. I fine tuned in my local mac for some tasks and
          the performance was not stellar. Do you mind sharing some tips or codebase
          to fine tune phi-2? Would greatly appreciate, thanks.
        updatedAt: '2024-01-04T10:40:09.546Z'
      numEdits: 0
      reactions: []
    id: 65968b0986ae7ac1a566bbd4
    type: comment
  author: duishoev
  content: This looks interesting. I fine tuned in my local mac for some tasks and
    the performance was not stellar. Do you mind sharing some tips or codebase to
    fine tune phi-2? Would greatly appreciate, thanks.
  created_at: 2024-01-04 10:40:09+00:00
  edited: false
  hidden: false
  id: 65968b0986ae7ac1a566bbd4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2024-01-04T11:39:33.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.20366929471492767
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: "<p>You can checkout my tunes here <a href=\"https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora\"\
          >https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora</a></p>\n\
          <p>here is my script for using llama_factory</p>\n<pre><code>#!/bin/bash\n\
          \neval \"$(conda shell.bash hook)\"\nconda activate llama_factory\n\nMODEL_NAME=phi-2\n\
          STAGE=sft\nEPOCH=1.0 <a href=\"/cognitivecomputations/dolphin-2_6-phi-2/discussions/3\"\
          >#3</a>.0\nDATA=alpaca_gpt4_en\n\nFT_TYPE=lora\nLoRA_TARGET=Wqkv #q_proj,v_proj\n\
          TEMPLATE=default\nPREDICTION_SAMPLES=20\n\nMODEL_PATH=./models/$MODEL_NAME\n\
          if [ ! -d $MODEL_PATH ]; then\n    echo \"Model not found: $MODEL_PATH\"\
          \n    return 1\nfi\n\nSAVE_PATH=./models/$STAGE/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH-$FT_TYPE\n\
          if [ ! -d $SAVE_PATH ]; then\n    mkdir -p $SAVE_PATH\nfi\n\nDO_TRAIN=false\n\
          DO_PREDICT=false\nDO_EXPORT=false\n\nfor arg in \"$@\"\ndo\n if [[ \"$arg\"\
          \ == \"--train\" ]]; then\n   echo \"The '--train' argument is present in\
          \ an argument: $arg\"\n   DO_TRAIN=true\n fi\n  if [[ \"$arg\" == \"--pred\"\
          \ ]]; then\n   echo \"The '--pred' argument is present in an argument: $arg\"\
          \n   DO_PREDICT=true\n fi\n  if [[ \"$arg\" == \"--exp\" ]]; then\n   echo\
          \ \"The '--exp' argument is present in an argument: $arg\"\n   DO_EXPORT=true\n\
          \ fi\ndone\n\nif [ $DO_TRAIN == true ]; then\n    CUDA_VISIBLE_DEVICES=0\
          \ python src/train_bash.py \\\n        --seed 42 \\\n        --stage $STAGE\
          \ \\\n        --model_name_or_path $MODEL_PATH \\\n        --dataset $DATA\
          \ \\\n        --val_size .1 \\\n        --template $TEMPLATE \\\n      \
          \  --finetuning_type $FT_TYPE \\\n        --do_train \\\n        --lora_target\
          \ $LoRA_TARGET \\\n        --output_dir $SAVE_PATH \\\n        --overwrite_output_dir\
          \ \\\n        --overwrite_cache \\\n        --per_device_train_batch_size\
          \ 1 \\\n        --gradient_accumulation_steps 4 \\\n        --lr_scheduler_type\
          \ cosine \\\n        --logging_steps 10 \\\n        --save_steps 1000 \\\
          \n        --learning_rate 5e-5 \\\n        --num_train_epochs $EPOCH \\\n\
          \        --do_eval \\\n        --evaluation_strategy epoch \\\n        --per_device_eval_batch_size\
          \ 1 \\\n        --prediction_loss_only \\\n        --plot_loss \\\n    \
          \    --quantization_bit 4 \\\n        --report_to tensorboard \\\n     \
          \   |&amp; tee $SAVE_PATH/train_eval_log.txt\nfi\n\nif [ $DO_PREDICT ==\
          \ true ]; then\n    SAVE_PATH_PREDICT=$SAVE_PATH/Predict_$PREDICTION_SAMPLES\n\
          \    if [ ! -d $SAVE_PATH_PREDICT ]; then\n        mkdir -p $SAVE_PATH_PREDICT\n\
          \    fi\n    CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n      \
          \  --stage $STAGE \\\n        --model_name_or_path $MODEL_PATH \\\n    \
          \    --do_predict \\\n        --max_samples $PREDICTION_SAMPLES \\\n   \
          \     --predict_with_generate \\\n        --dataset $DATA \\\n        --template\
          \ $TEMPLATE \\\n        --finetuning_type $FT_TYPE \\\n        --adapter_name_or_path\
          \ $SAVE_PATH \\\n        --output_dir $SAVE_PATH_PREDICT \\\n        --per_device_eval_batch_size\
          \ 1 \\\n        |&amp; tee $SAVE_PATH_PREDICT/predict_log.txt\nfi\n\nif\
          \ [ $DO_EXPORT == true ]; then\n    EXPORT_PATH=./models/export/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH\n\
          \    if [ ! -d $EXPORT_PATH ]; then\n        mkdir -p $EXPORT_PATH\n   \
          \ fi\n    CUDA_VISIBLE_DEVICES=0 python src/export_model.py \\\n       \
          \ --model_name_or_path $MODEL_PATH \\\n        --adapter_name_or_path $SAVE_PATH\
          \ \\\n        --template $TEMPLATE \\\n        --finetuning_type $FT_TYPE\
          \ \\\n        --export_dir $EXPORT_PATH \\\n        --export_size 5 \\\n\
          \        |&amp; tee $EXPORT_PATH/export_log.txt\nfi\n</code></pre>\n"
        raw: "You can checkout my tunes here https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora\n\
          \nhere is my script for using llama_factory\n\n```\n#!/bin/bash\n\neval\
          \ \"$(conda shell.bash hook)\"\nconda activate llama_factory\n\nMODEL_NAME=phi-2\n\
          STAGE=sft\nEPOCH=1.0 #3.0\nDATA=alpaca_gpt4_en\n\nFT_TYPE=lora\nLoRA_TARGET=Wqkv\
          \ #q_proj,v_proj\nTEMPLATE=default\nPREDICTION_SAMPLES=20\n\nMODEL_PATH=./models/$MODEL_NAME\n\
          if [ ! -d $MODEL_PATH ]; then\n    echo \"Model not found: $MODEL_PATH\"\
          \n    return 1\nfi\n\nSAVE_PATH=./models/$STAGE/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH-$FT_TYPE\n\
          if [ ! -d $SAVE_PATH ]; then\n    mkdir -p $SAVE_PATH\nfi\n\nDO_TRAIN=false\n\
          DO_PREDICT=false\nDO_EXPORT=false\n\nfor arg in \"$@\"\ndo\n if [[ \"$arg\"\
          \ == \"--train\" ]]; then\n   echo \"The '--train' argument is present in\
          \ an argument: $arg\"\n   DO_TRAIN=true\n fi\n  if [[ \"$arg\" == \"--pred\"\
          \ ]]; then\n   echo \"The '--pred' argument is present in an argument: $arg\"\
          \n   DO_PREDICT=true\n fi\n  if [[ \"$arg\" == \"--exp\" ]]; then\n   echo\
          \ \"The '--exp' argument is present in an argument: $arg\"\n   DO_EXPORT=true\n\
          \ fi\ndone\n\nif [ $DO_TRAIN == true ]; then\n    CUDA_VISIBLE_DEVICES=0\
          \ python src/train_bash.py \\\n        --seed 42 \\\n        --stage $STAGE\
          \ \\\n        --model_name_or_path $MODEL_PATH \\\n        --dataset $DATA\
          \ \\\n        --val_size .1 \\\n        --template $TEMPLATE \\\n      \
          \  --finetuning_type $FT_TYPE \\\n        --do_train \\\n        --lora_target\
          \ $LoRA_TARGET \\\n        --output_dir $SAVE_PATH \\\n        --overwrite_output_dir\
          \ \\\n        --overwrite_cache \\\n        --per_device_train_batch_size\
          \ 1 \\\n        --gradient_accumulation_steps 4 \\\n        --lr_scheduler_type\
          \ cosine \\\n        --logging_steps 10 \\\n        --save_steps 1000 \\\
          \n        --learning_rate 5e-5 \\\n        --num_train_epochs $EPOCH \\\n\
          \        --do_eval \\\n        --evaluation_strategy epoch \\\n        --per_device_eval_batch_size\
          \ 1 \\\n        --prediction_loss_only \\\n        --plot_loss \\\n    \
          \    --quantization_bit 4 \\\n        --report_to tensorboard \\\n     \
          \   |& tee $SAVE_PATH/train_eval_log.txt\nfi\n\nif [ $DO_PREDICT == true\
          \ ]; then\n    SAVE_PATH_PREDICT=$SAVE_PATH/Predict_$PREDICTION_SAMPLES\n\
          \    if [ ! -d $SAVE_PATH_PREDICT ]; then\n        mkdir -p $SAVE_PATH_PREDICT\n\
          \    fi\n    CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n      \
          \  --stage $STAGE \\\n        --model_name_or_path $MODEL_PATH \\\n    \
          \    --do_predict \\\n        --max_samples $PREDICTION_SAMPLES \\\n   \
          \     --predict_with_generate \\\n        --dataset $DATA \\\n        --template\
          \ $TEMPLATE \\\n        --finetuning_type $FT_TYPE \\\n        --adapter_name_or_path\
          \ $SAVE_PATH \\\n        --output_dir $SAVE_PATH_PREDICT \\\n        --per_device_eval_batch_size\
          \ 1 \\\n        |& tee $SAVE_PATH_PREDICT/predict_log.txt\nfi\n\nif [ $DO_EXPORT\
          \ == true ]; then\n    EXPORT_PATH=./models/export/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH\n\
          \    if [ ! -d $EXPORT_PATH ]; then\n        mkdir -p $EXPORT_PATH\n   \
          \ fi\n    CUDA_VISIBLE_DEVICES=0 python src/export_model.py \\\n       \
          \ --model_name_or_path $MODEL_PATH \\\n        --adapter_name_or_path $SAVE_PATH\
          \ \\\n        --template $TEMPLATE \\\n        --finetuning_type $FT_TYPE\
          \ \\\n        --export_dir $EXPORT_PATH \\\n        --export_size 5 \\\n\
          \        |& tee $EXPORT_PATH/export_log.txt\nfi\n```"
        updatedAt: '2024-01-04T11:39:33.941Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - hf-delta
        - sam-ezai
    id: 659698f572376a9c31b94610
    type: comment
  author: Yhyu13
  content: "You can checkout my tunes here https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora\n\
    \nhere is my script for using llama_factory\n\n```\n#!/bin/bash\n\neval \"$(conda\
    \ shell.bash hook)\"\nconda activate llama_factory\n\nMODEL_NAME=phi-2\nSTAGE=sft\n\
    EPOCH=1.0 #3.0\nDATA=alpaca_gpt4_en\n\nFT_TYPE=lora\nLoRA_TARGET=Wqkv #q_proj,v_proj\n\
    TEMPLATE=default\nPREDICTION_SAMPLES=20\n\nMODEL_PATH=./models/$MODEL_NAME\nif\
    \ [ ! -d $MODEL_PATH ]; then\n    echo \"Model not found: $MODEL_PATH\"\n    return\
    \ 1\nfi\n\nSAVE_PATH=./models/$STAGE/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH-$FT_TYPE\n\
    if [ ! -d $SAVE_PATH ]; then\n    mkdir -p $SAVE_PATH\nfi\n\nDO_TRAIN=false\n\
    DO_PREDICT=false\nDO_EXPORT=false\n\nfor arg in \"$@\"\ndo\n if [[ \"$arg\" ==\
    \ \"--train\" ]]; then\n   echo \"The '--train' argument is present in an argument:\
    \ $arg\"\n   DO_TRAIN=true\n fi\n  if [[ \"$arg\" == \"--pred\" ]]; then\n   echo\
    \ \"The '--pred' argument is present in an argument: $arg\"\n   DO_PREDICT=true\n\
    \ fi\n  if [[ \"$arg\" == \"--exp\" ]]; then\n   echo \"The '--exp' argument is\
    \ present in an argument: $arg\"\n   DO_EXPORT=true\n fi\ndone\n\nif [ $DO_TRAIN\
    \ == true ]; then\n    CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n  \
    \      --seed 42 \\\n        --stage $STAGE \\\n        --model_name_or_path $MODEL_PATH\
    \ \\\n        --dataset $DATA \\\n        --val_size .1 \\\n        --template\
    \ $TEMPLATE \\\n        --finetuning_type $FT_TYPE \\\n        --do_train \\\n\
    \        --lora_target $LoRA_TARGET \\\n        --output_dir $SAVE_PATH \\\n \
    \       --overwrite_output_dir \\\n        --overwrite_cache \\\n        --per_device_train_batch_size\
    \ 1 \\\n        --gradient_accumulation_steps 4 \\\n        --lr_scheduler_type\
    \ cosine \\\n        --logging_steps 10 \\\n        --save_steps 1000 \\\n   \
    \     --learning_rate 5e-5 \\\n        --num_train_epochs $EPOCH \\\n        --do_eval\
    \ \\\n        --evaluation_strategy epoch \\\n        --per_device_eval_batch_size\
    \ 1 \\\n        --prediction_loss_only \\\n        --plot_loss \\\n        --quantization_bit\
    \ 4 \\\n        --report_to tensorboard \\\n        |& tee $SAVE_PATH/train_eval_log.txt\n\
    fi\n\nif [ $DO_PREDICT == true ]; then\n    SAVE_PATH_PREDICT=$SAVE_PATH/Predict_$PREDICTION_SAMPLES\n\
    \    if [ ! -d $SAVE_PATH_PREDICT ]; then\n        mkdir -p $SAVE_PATH_PREDICT\n\
    \    fi\n    CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n        --stage\
    \ $STAGE \\\n        --model_name_or_path $MODEL_PATH \\\n        --do_predict\
    \ \\\n        --max_samples $PREDICTION_SAMPLES \\\n        --predict_with_generate\
    \ \\\n        --dataset $DATA \\\n        --template $TEMPLATE \\\n        --finetuning_type\
    \ $FT_TYPE \\\n        --adapter_name_or_path $SAVE_PATH \\\n        --output_dir\
    \ $SAVE_PATH_PREDICT \\\n        --per_device_eval_batch_size 1 \\\n        |&\
    \ tee $SAVE_PATH_PREDICT/predict_log.txt\nfi\n\nif [ $DO_EXPORT == true ]; then\n\
    \    EXPORT_PATH=./models/export/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH\n    if [ !\
    \ -d $EXPORT_PATH ]; then\n        mkdir -p $EXPORT_PATH\n    fi\n    CUDA_VISIBLE_DEVICES=0\
    \ python src/export_model.py \\\n        --model_name_or_path $MODEL_PATH \\\n\
    \        --adapter_name_or_path $SAVE_PATH \\\n        --template $TEMPLATE \\\
    \n        --finetuning_type $FT_TYPE \\\n        --export_dir $EXPORT_PATH \\\n\
    \        --export_size 5 \\\n        |& tee $EXPORT_PATH/export_log.txt\nfi\n\
    ```"
  created_at: 2024-01-04 11:39:33+00:00
  edited: false
  hidden: false
  id: 659698f572376a9c31b94610
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: cognitivecomputations/dolphin-2_6-phi-2
repo_type: model
status: open
target_branch: null
title: Fine-tuning best practices?
