!!python/object:huggingface_hub.community.DiscussionWithDetails
author: krrish-litellm
conflicting_files: null
created_at: 2023-08-15 01:18:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/40c021efc35b828bf680444905affb11.svg
      fullname: Krrish Dholakia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: krrish-litellm
      type: user
    createdAt: '2023-08-15T02:18:01.000Z'
    data:
      edited: true
      editors:
      - krrish-litellm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8760668635368347
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/40c021efc35b828bf680444905affb11.svg
          fullname: Krrish Dholakia
          isHf: false
          isPro: false
          name: krrish-litellm
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;flavoredquark&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/flavoredquark\"\
          >@<span class=\"underline\">flavoredquark</span></a></span>\n\n\t</span></span>\
          \ / <span data-props=\"{&quot;user&quot;:&quot;arielnlee&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/arielnlee\">@<span class=\"\
          underline\">arielnlee</span></a></span>\n\n\t</span></span> </p>\n<p>What's\
          \ the best way for me to deploy this model? I'd love to make a demo of this\
          \ with LiteLLM - <a rel=\"nofollow\" href=\"https://github.com/BerriAI/litellm\"\
          >https://github.com/BerriAI/litellm</a>. </p>\n<p>Lite currently works with\
          \ Replicate, Azure, Together.ai and HF Inference Endpoints. </p>\n<p>I'm\
          \ facing issues with HF Inference endpoints due to quota limitations, so\
          \ curious if you've tried any other provider. </p>\n"
        raw: "Hi @flavoredquark / @arielnlee \n\nWhat's the best way for me to deploy\
          \ this model? I'd love to make a demo of this with LiteLLM - https://github.com/BerriAI/litellm.\
          \ \n\nLite currently works with Replicate, Azure, Together.ai and HF Inference\
          \ Endpoints. \n\nI'm facing issues with HF Inference endpoints due to quota\
          \ limitations, so curious if you've tried any other provider. "
        updatedAt: '2023-08-15T02:18:30.663Z'
      numEdits: 1
      reactions: []
    id: 64dae059ff83b3386a318ee9
    type: comment
  author: krrish-litellm
  content: "Hi @flavoredquark / @arielnlee \n\nWhat's the best way for me to deploy\
    \ this model? I'd love to make a demo of this with LiteLLM - https://github.com/BerriAI/litellm.\
    \ \n\nLite currently works with Replicate, Azure, Together.ai and HF Inference\
    \ Endpoints. \n\nI'm facing issues with HF Inference endpoints due to quota limitations,\
    \ so curious if you've tried any other provider. "
  created_at: 2023-08-15 01:18:01+00:00
  edited: true
  hidden: false
  id: 64dae059ff83b3386a318ee9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: garage-bAInd/Platypus2-70B-instruct
repo_type: model
status: open
target_branch: null
title: 'Call w/ LiteLLM '
