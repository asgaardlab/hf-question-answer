!!python/object:huggingface_hub.community.DiscussionWithDetails
author: danielpark
conflicting_files: null
created_at: 2023-08-21 12:07:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63c6712883ce71db8ed9f78d/TJq6tY_DMiwAK2WfF04LR.jpeg?w=200&h=200&f=face
      fullname: Minwoo Park
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: danielpark
      type: user
    createdAt: '2023-08-21T13:07:26.000Z'
    data:
      edited: true
      editors:
      - danielpark
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9387139081954956
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63c6712883ce71db8ed9f78d/TJq6tY_DMiwAK2WfF04LR.jpeg?w=200&h=200&f=face
          fullname: Minwoo Park
          isHf: false
          isPro: false
          name: danielpark
          type: user
        html: '<p>Thank you for sharing valuable insights.</p>

          <ol>

          <li><p>Where can I find the detailed heuristics mentioned in the paper?
          I''d like to review the specific algorithms and code.</p>

          </li>

          <li><p>Is it possible to explicitly verify the performance of the model
          before and after modifying the attention module as mentioned in the paper?
          Can we obtain specific information about the performance difference between
          before and after changing the attention module? Are there any models that
          have been compared under controlled conditions with only structural changes
          affecting their performance?</p>

          </li>

          </ol>

          '
        raw: 'Thank you for sharing valuable insights.


          1) Where can I find the detailed heuristics mentioned in the paper? I''d
          like to review the specific algorithms and code.


          2) Is it possible to explicitly verify the performance of the model before
          and after modifying the attention module as mentioned in the paper? Can
          we obtain specific information about the performance difference between
          before and after changing the attention module? Are there any models that
          have been compared under controlled conditions with only structural changes
          affecting their performance?'
        updatedAt: '2023-08-21T13:07:58.812Z'
      numEdits: 1
      reactions: []
    id: 64e3618ec21dd0c666f09cdc
    type: comment
  author: danielpark
  content: 'Thank you for sharing valuable insights.


    1) Where can I find the detailed heuristics mentioned in the paper? I''d like
    to review the specific algorithms and code.


    2) Is it possible to explicitly verify the performance of the model before and
    after modifying the attention module as mentioned in the paper? Can we obtain
    specific information about the performance difference between before and after
    changing the attention module? Are there any models that have been compared under
    controlled conditions with only structural changes affecting their performance?'
  created_at: 2023-08-21 12:07:26+00:00
  edited: true
  hidden: false
  id: 64e3618ec21dd0c666f09cdc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: garage-bAInd/Platypus2-70B-instruct
repo_type: model
status: open
target_branch: null
title: ' Inquiries Regarding Detailed Heuristics and Attention Module Modifications
  in the Paper'
