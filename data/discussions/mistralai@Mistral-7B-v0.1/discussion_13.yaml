!!python/object:huggingface_hub.community.DiscussionWithDetails
author: alexsherstinsky
conflicting_files: null
created_at: 2023-09-28 17:25:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-09-28T18:25:35.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9611466526985168
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: '<p>Hello,</p>

          <p>I tried to run <a href="https://huggingface.co/mistralai/Mistral-7B-v0.1">https://huggingface.co/mistralai/Mistral-7B-v0.1</a>
          in a free Google Colab notebook (for a fine-tuning experiment).  However,
          unfortunately, I am getting a CPU-side out-of-memory error (kernel crashes)
          while trying to even download the model checkpoint from HuggingFace to the
          notebook (in other words, the process does not even get to the GPU stage).  Am
          I doing something wrong?  Or is this model just too large for the free-tier
          Google Colab account?  I counted that the two binary files add up to 15GB,
          but am not sure if this is the correct calculation.  Or perhaps there is
          a special technique that has to be employed in order to be able to download
          this model?  It would be nice to get the official guidance; or maybe somebody
          knowledgeable can advise.</p>

          <p>Thank you very much in advance for your help.</p>

          '
        raw: "Hello,\r\n\r\nI tried to run https://huggingface.co/mistralai/Mistral-7B-v0.1\
          \ in a free Google Colab notebook (for a fine-tuning experiment).  However,\
          \ unfortunately, I am getting a CPU-side out-of-memory error (kernel crashes)\
          \ while trying to even download the model checkpoint from HuggingFace to\
          \ the notebook (in other words, the process does not even get to the GPU\
          \ stage).  Am I doing something wrong?  Or is this model just too large\
          \ for the free-tier Google Colab account?  I counted that the two binary\
          \ files add up to 15GB, but am not sure if this is the correct calculation.\
          \  Or perhaps there is a special technique that has to be employed in order\
          \ to be able to download this model?  It would be nice to get the official\
          \ guidance; or maybe somebody knowledgeable can advise.\r\n\r\nThank you\
          \ very much in advance for your help."
        updatedAt: '2023-09-28T18:25:35.645Z'
      numEdits: 0
      reactions: []
    id: 6515c51fff0ecf2255f57698
    type: comment
  author: alexsherstinsky
  content: "Hello,\r\n\r\nI tried to run https://huggingface.co/mistralai/Mistral-7B-v0.1\
    \ in a free Google Colab notebook (for a fine-tuning experiment).  However, unfortunately,\
    \ I am getting a CPU-side out-of-memory error (kernel crashes) while trying to\
    \ even download the model checkpoint from HuggingFace to the notebook (in other\
    \ words, the process does not even get to the GPU stage).  Am I doing something\
    \ wrong?  Or is this model just too large for the free-tier Google Colab account?\
    \  I counted that the two binary files add up to 15GB, but am not sure if this\
    \ is the correct calculation.  Or perhaps there is a special technique that has\
    \ to be employed in order to be able to download this model?  It would be nice\
    \ to get the official guidance; or maybe somebody knowledgeable can advise.\r\n\
    \r\nThank you very much in advance for your help."
  created_at: 2023-09-28 17:25:35+00:00
  edited: false
  hidden: false
  id: 6515c51fff0ecf2255f57698
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d640330f269385f2ac5a097483cb83c6.svg
      fullname: KISHORE KUMAR
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kishorekumr
      type: user
    createdAt: '2023-09-28T19:17:21.000Z'
    data:
      edited: true
      editors:
      - Kishorekumr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9973126649856567
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d640330f269385f2ac5a097483cb83c6.svg
          fullname: KISHORE KUMAR
          isHf: false
          isPro: false
          name: Kishorekumr
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2023-09-28T19:18:13.163Z'
      numEdits: 1
      reactions: []
    id: 6515d1414256270d6fa22f27
    type: comment
  author: Kishorekumr
  content: '+1'
  created_at: 2023-09-28 18:17:21+00:00
  edited: true
  hidden: false
  id: 6515d1414256270d6fa22f27
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/65143e1c4f08b815c8db57a0/JqkwKiJmLFRkH0NK3L8XH.jpeg?w=200&h=200&f=face
      fullname: Devendra Singh Chaplot
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: devendrachaplot
      type: user
    createdAt: '2023-09-28T21:45:34.000Z'
    data:
      edited: false
      editors:
      - devendrachaplot
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4530927538871765
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/65143e1c4f08b815c8db57a0/JqkwKiJmLFRkH0NK3L8XH.jpeg?w=200&h=200&f=face
          fullname: Devendra Singh Chaplot
          isHf: false
          isPro: false
          name: devendrachaplot
          type: user
        html: '<p>Maybe this is useful:<br><a rel="nofollow" href="https://colab.research.google.com/drive/1F2PeWl5FOHv4sjd7XTEu40JjqbFhC3LB?usp=sharing">https://colab.research.google.com/drive/1F2PeWl5FOHv4sjd7XTEu40JjqbFhC3LB?usp=sharing</a></p>

          '
        raw: 'Maybe this is useful:

          https://colab.research.google.com/drive/1F2PeWl5FOHv4sjd7XTEu40JjqbFhC3LB?usp=sharing'
        updatedAt: '2023-09-28T21:45:34.646Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - clem
        - julien-c
        - alir
    id: 6515f3fe65ab7c2a2e026b73
    type: comment
  author: devendrachaplot
  content: 'Maybe this is useful:

    https://colab.research.google.com/drive/1F2PeWl5FOHv4sjd7XTEu40JjqbFhC3LB?usp=sharing'
  created_at: 2023-09-28 20:45:34+00:00
  edited: false
  hidden: false
  id: 6515f3fe65ab7c2a2e026b73
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-09-29T00:09:36.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9737311005592346
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: '<p>Thank you very much; this is helpful, although it does not answer
          the question about the amount of memory needed.  Still, thank you for the
          very useful notebook.</p>

          '
        raw: Thank you very much; this is helpful, although it does not answer the
          question about the amount of memory needed.  Still, thank you for the very
          useful notebook.
        updatedAt: '2023-09-29T00:09:36.540Z'
      numEdits: 0
      reactions: []
    id: 651615c001d873dd1912d436
    type: comment
  author: alexsherstinsky
  content: Thank you very much; this is helpful, although it does not answer the question
    about the amount of memory needed.  Still, thank you for the very useful notebook.
  created_at: 2023-09-28 23:09:36+00:00
  edited: false
  hidden: false
  id: 651615c001d873dd1912d436
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae6006ff15a7e6e63e042b2987d20a5d.svg
      fullname: Anuvrat Shukla
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ianuvrat
      type: user
    createdAt: '2023-09-29T03:26:50.000Z'
    data:
      edited: false
      editors:
      - ianuvrat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9212526679039001
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae6006ff15a7e6e63e042b2987d20a5d.svg
          fullname: Anuvrat Shukla
          isHf: false
          isPro: false
          name: ianuvrat
          type: user
        html: '<p>I want to run quantized version. This model runs out of memory in
          free google colab </p>

          '
        raw: 'I want to run quantized version. This model runs out of memory in free
          google colab '
        updatedAt: '2023-09-29T03:26:50.203Z'
      numEdits: 0
      reactions: []
    id: 651643fa4256270d6fb04095
    type: comment
  author: ianuvrat
  content: 'I want to run quantized version. This model runs out of memory in free
    google colab '
  created_at: 2023-09-29 02:26:50+00:00
  edited: false
  hidden: false
  id: 651643fa4256270d6fb04095
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6006e05f2bcf0d7837a96f3173193a3.svg
      fullname: Girraj jangid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: girrajjangid
      type: user
    createdAt: '2023-09-29T05:20:22.000Z'
    data:
      edited: false
      editors:
      - girrajjangid
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5357895493507385
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6006e05f2bcf0d7837a96f3173193a3.svg
          fullname: Girraj jangid
          isHf: false
          isPro: false
          name: girrajjangid
          type: user
        html: '<p>I am still getting OUT OF MEMORY error. Even using this notebook
          <a rel="nofollow" href="https://colab.research.google.com/drive/1F2PeWl5FOHv4sjd7XTEu40JjqbFhC3LB?usp=sharing">https://colab.research.google.com/drive/1F2PeWl5FOHv4sjd7XTEu40JjqbFhC3LB?usp=sharing</a>
          </p>

          '
        raw: 'I am still getting OUT OF MEMORY error. Even using this notebook https://colab.research.google.com/drive/1F2PeWl5FOHv4sjd7XTEu40JjqbFhC3LB?usp=sharing '
        updatedAt: '2023-09-29T05:20:22.504Z'
      numEdits: 0
      reactions: []
    id: 65165e966f8a6fa0d994cefc
    type: comment
  author: girrajjangid
  content: 'I am still getting OUT OF MEMORY error. Even using this notebook https://colab.research.google.com/drive/1F2PeWl5FOHv4sjd7XTEu40JjqbFhC3LB?usp=sharing '
  created_at: 2023-09-29 04:20:22+00:00
  edited: false
  hidden: false
  id: 65165e966f8a6fa0d994cefc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-09-29T06:11:14.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9581344723701477
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: '<p>Yes; I believe that downloading the model requires 15GB, which is
          more RAM than the free Colab account has.  The memory gets freed up after
          the download, but it is needed for the download to succeed.  Thank you.</p>

          '
        raw: Yes; I believe that downloading the model requires 15GB, which is more
          RAM than the free Colab account has.  The memory gets freed up after the
          download, but it is needed for the download to succeed.  Thank you.
        updatedAt: '2023-09-29T06:11:14.675Z'
      numEdits: 0
      reactions: []
    id: 65166a82c33a8b19196f24d7
    type: comment
  author: alexsherstinsky
  content: Yes; I believe that downloading the model requires 15GB, which is more
    RAM than the free Colab account has.  The memory gets freed up after the download,
    but it is needed for the download to succeed.  Thank you.
  created_at: 2023-09-29 05:11:14+00:00
  edited: false
  hidden: false
  id: 65166a82c33a8b19196f24d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6006e05f2bcf0d7837a96f3173193a3.svg
      fullname: Girraj jangid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: girrajjangid
      type: user
    createdAt: '2023-09-29T08:54:08.000Z'
    data:
      edited: false
      editors:
      - girrajjangid
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5447456240653992
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6006e05f2bcf0d7837a96f3173193a3.svg
          fullname: Girraj jangid
          isHf: false
          isPro: false
          name: girrajjangid
          type: user
        html: '<p>Thanks me later.<br>You can load it using this on free colab.</p>

          <p>!pip -q install git+<a rel="nofollow" href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a>
          # need to install from github<br>!pip -q install bitsandbytes accelerate
          xformers einops</p>

          <p>import torch<br>import transformers<br>from transformers import AutoTokenizer,
          AutoModelForCausalLM</p>

          <p>model_id = "mistralai/Mistral-7B-Instruct-v0.1"<br>bnb_config = transformers.BitsAndBytesConfig(<br>    load_in_4bit=True,<br>    bnb_4bit_use_double_quant=True,<br>    bnb_4bit_quant_type="nf4",<br>    bnb_4bit_compute_dtype=torch.bfloat16<br>)</p>

          <p>model = transformers.AutoModelForCausalLM.from_pretrained(<br>    model_id,<br>    trust_remote_code=True,<br>    quantization_config=bnb_config,<br>    device_map=''auto'',<br>)</p>

          <p>tokenizer = transformers.AutoTokenizer.from_pretrained(<br>    model_id,<br>)</p>

          <p>text = "<s>[INST] What is your favourite condiment? [/INST]Well, I''m
          quite partial to a good squeeze of fresh lemon juice. It adds just the right
          amount of zesty flavour to whatever I''m cooking up in the kitchen!</s>
          [INST] Do you have mayonnaise recipes? [/INST]"<br>encodeds = tokenizer(text,
          return_tensors="pt", add_special_tokens=False)<br>model_inputs = encodeds</p>

          <p>generated_ids = model.generate(**model_inputs, max_new_tokens=200, do_sample=True)<br>decoded
          = tokenizer.batch_decode(generated_ids)<br>print(decoded[0])</p>

          '
        raw: "Thanks me later.\nYou can load it using this on free colab.\n\n\n!pip\
          \ -q install git+https://github.com/huggingface/transformers # need to install\
          \ from github\n!pip -q install bitsandbytes accelerate xformers einops\n\
          \nimport torch\nimport transformers\nfrom transformers import AutoTokenizer,\
          \ AutoModelForCausalLM\n\nmodel_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\
          \nbnb_config = transformers.BitsAndBytesConfig(\n    load_in_4bit=True,\n\
          \    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n\
          \    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n\
          \    model_id,\n    trust_remote_code=True,\n    quantization_config=bnb_config,\n\
          \    device_map='auto',\n)\n\ntokenizer = transformers.AutoTokenizer.from_pretrained(\n\
          \    model_id,\n)\n\ntext = \"<s>[INST] What is your favourite condiment?\
          \ [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice.\
          \ It adds just the right amount of zesty flavour to whatever I'm cooking\
          \ up in the kitchen!</s> [INST] Do you have mayonnaise recipes? [/INST]\"\
          \nencodeds = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n\
          model_inputs = encodeds\n\ngenerated_ids = model.generate(**model_inputs,\
          \ max_new_tokens=200, do_sample=True)\ndecoded = tokenizer.batch_decode(generated_ids)\n\
          print(decoded[0])\n"
        updatedAt: '2023-09-29T08:54:08.265Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\u2764\uFE0F"
        users:
        - clem
        - girrajjangid
        - bphanzhu
        - saied
    id: 651690b0b26534355c13e92f
    type: comment
  author: girrajjangid
  content: "Thanks me later.\nYou can load it using this on free colab.\n\n\n!pip\
    \ -q install git+https://github.com/huggingface/transformers # need to install\
    \ from github\n!pip -q install bitsandbytes accelerate xformers einops\n\nimport\
    \ torch\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
    \nmodel_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\nbnb_config = transformers.BitsAndBytesConfig(\n\
    \    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"\
    nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n\
    \    model_id,\n    trust_remote_code=True,\n    quantization_config=bnb_config,\n\
    \    device_map='auto',\n)\n\ntokenizer = transformers.AutoTokenizer.from_pretrained(\n\
    \    model_id,\n)\n\ntext = \"<s>[INST] What is your favourite condiment? [/INST]Well,\
    \ I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right\
    \ amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> [INST]\
    \ Do you have mayonnaise recipes? [/INST]\"\nencodeds = tokenizer(text, return_tensors=\"\
    pt\", add_special_tokens=False)\nmodel_inputs = encodeds\n\ngenerated_ids = model.generate(**model_inputs,\
    \ max_new_tokens=200, do_sample=True)\ndecoded = tokenizer.batch_decode(generated_ids)\n\
    print(decoded[0])\n"
  created_at: 2023-09-29 07:54:08+00:00
  edited: false
  hidden: false
  id: 651690b0b26534355c13e92f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae6006ff15a7e6e63e042b2987d20a5d.svg
      fullname: Anuvrat Shukla
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ianuvrat
      type: user
    createdAt: '2023-09-29T09:36:49.000Z'
    data:
      edited: false
      editors:
      - ianuvrat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9078672528266907
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae6006ff15a7e6e63e042b2987d20a5d.svg
          fullname: Anuvrat Shukla
          isHf: false
          isPro: false
          name: ianuvrat
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;girrajjangid&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/girrajjangid\"\
          >@<span class=\"underline\">girrajjangid</span></a></span>\n\n\t</span></span>\
          \ , its using system RAM in colab ..why? It runs out of memory with your\
          \ code</p>\n"
        raw: '@girrajjangid , its using system RAM in colab ..why? It runs out of
          memory with your code'
        updatedAt: '2023-09-29T09:36:49.085Z'
      numEdits: 0
      reactions: []
    id: 65169ab11e7b9224c9ed3a42
    type: comment
  author: ianuvrat
  content: '@girrajjangid , its using system RAM in colab ..why? It runs out of memory
    with your code'
  created_at: 2023-09-29 08:36:49+00:00
  edited: false
  hidden: false
  id: 65169ab11e7b9224c9ed3a42
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d9c0fde3bc3b15a9df1263a67e12983a.svg
      fullname: Someone13574
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: someone13574
      type: user
    createdAt: '2023-09-29T14:21:41.000Z'
    data:
      edited: true
      editors:
      - someone13574
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9112641215324402
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d9c0fde3bc3b15a9df1263a67e12983a.svg
          fullname: Someone13574
          isHf: false
          isPro: false
          name: someone13574
          type: user
        html: "<p>I\u2019ve managed to load it into the gpu in a free instance by\
          \ loading it when it is sharded into 2gb files <a href=\"https://huggingface.co/someone13574/Mistral-7B-v0.1-sharded\"\
          >https://huggingface.co/someone13574/Mistral-7B-v0.1-sharded</a></p>\n"
        raw: "I\u2019ve managed to load it into the gpu in a free instance by loading\
          \ it when it is sharded into 2gb files https://huggingface.co/someone13574/Mistral-7B-v0.1-sharded\n"
        updatedAt: '2023-09-29T14:21:58.534Z'
      numEdits: 1
      reactions:
      - count: 4
        reaction: "\u2764\uFE0F"
        users:
        - alexsherstinsky
        - gnomealone
        - Subhanandh
        - osanseviero
    id: 6516dd75a1a5e5d61769e0fa
    type: comment
  author: someone13574
  content: "I\u2019ve managed to load it into the gpu in a free instance by loading\
    \ it when it is sharded into 2gb files https://huggingface.co/someone13574/Mistral-7B-v0.1-sharded\n"
  created_at: 2023-09-29 13:21:41+00:00
  edited: true
  hidden: false
  id: 6516dd75a1a5e5d61769e0fa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-09-30T14:17:51.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9563164114952087
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: '<p>Thank you everybody for your very helpful responses.  I will be
          learning from them in the coming days.  Much appreciated!</p>

          '
        raw: Thank you everybody for your very helpful responses.  I will be learning
          from them in the coming days.  Much appreciated!
        updatedAt: '2023-09-30T14:17:51.703Z'
      numEdits: 0
      reactions: []
    id: 65182e0fb239dc7a34d881a2
    type: comment
  author: alexsherstinsky
  content: Thank you everybody for your very helpful responses.  I will be learning
    from them in the coming days.  Much appreciated!
  created_at: 2023-09-30 13:17:51+00:00
  edited: false
  hidden: false
  id: 65182e0fb239dc7a34d881a2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-09-30T14:35:53.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9862397909164429
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;someone13574&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/someone13574\"\
          >@<span class=\"underline\">someone13574</span></a></span>\n\n\t</span></span>\
          \ Would you be so kind as to point to the tools and/or code for how you\
          \ carried out the sharding?  I feel that it would be useful to a lot of\
          \ people.  Thank you very much in advance.</p>\n"
        raw: '@someone13574 Would you be so kind as to point to the tools and/or code
          for how you carried out the sharding?  I feel that it would be useful to
          a lot of people.  Thank you very much in advance.'
        updatedAt: '2023-09-30T14:35:53.643Z'
      numEdits: 0
      reactions: []
    id: 65183249a28f86d3e9da6055
    type: comment
  author: alexsherstinsky
  content: '@someone13574 Would you be so kind as to point to the tools and/or code
    for how you carried out the sharding?  I feel that it would be useful to a lot
    of people.  Thank you very much in advance.'
  created_at: 2023-09-30 13:35:53+00:00
  edited: false
  hidden: false
  id: 65183249a28f86d3e9da6055
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d9c0fde3bc3b15a9df1263a67e12983a.svg
      fullname: Someone13574
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: someone13574
      type: user
    createdAt: '2023-09-30T18:05:40.000Z'
    data:
      edited: true
      editors:
      - someone13574
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5562203526496887
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d9c0fde3bc3b15a9df1263a67e12983a.svg
          fullname: Someone13574
          isHf: false
          isPro: false
          name: someone13574
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;alexsherstinsky&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/alexsherstinsky\"\
          >@<span class=\"underline\">alexsherstinsky</span></a></span>\n\n\t</span></span>\
          \ Just a simple script using huggingface transformers. You do need enough\
          \ ram to fit the model though.</p>\n<pre><code class=\"language-py\"><span\
          \ class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> AutoModelForCausalLM\n\
          \nmodel = AutoModelForCausalLM.from_pretrained(<span class=\"hljs-string\"\
          >\"model/\"</span>, low_cpu_mem_usage=<span class=\"hljs-literal\">True</span>,\
          \ torch_dtype=torch.float16, device_map=<span class=\"hljs-string\">\"cpu\"\
          </span>)\nmodel.save_pretrained(<span class=\"hljs-string\">\"sharded\"\
          </span>, max_shard_size=<span class=\"hljs-string\">\"2GB\"</span>)\n</code></pre>\n"
        raw: '@alexsherstinsky Just a simple script using huggingface transformers.
          You do need enough ram to fit the model though.


          ```py

          import torch

          from transformers import AutoModelForCausalLM


          model = AutoModelForCausalLM.from_pretrained("model/", low_cpu_mem_usage=True,
          torch_dtype=torch.float16, device_map="cpu")

          model.save_pretrained("sharded", max_shard_size="2GB")

          ```'
        updatedAt: '2023-09-30T18:05:52.155Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - JoshuaCAlpuerto
        - CWKSC
    id: 651863742b4fffcb41e0b6b3
    type: comment
  author: someone13574
  content: '@alexsherstinsky Just a simple script using huggingface transformers.
    You do need enough ram to fit the model though.


    ```py

    import torch

    from transformers import AutoModelForCausalLM


    model = AutoModelForCausalLM.from_pretrained("model/", low_cpu_mem_usage=True,
    torch_dtype=torch.float16, device_map="cpu")

    model.save_pretrained("sharded", max_shard_size="2GB")

    ```'
  created_at: 2023-09-30 17:05:40+00:00
  edited: true
  hidden: false
  id: 651863742b4fffcb41e0b6b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-01T04:56:07.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9584276676177979
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;someone13574&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/someone13574\"\
          >@<span class=\"underline\">someone13574</span></a></span>\n\n\t</span></span>\
          \ Thank you so much for this code and the explanation.  Yes, this really\
          \ helps -- because in terms of RAM, I can use my development machine, which\
          \ is Mac M1 Max with 64GB RAM, and then upload the results to HuggingFace\
          \ -- and then go from there (I verified that your sharded model fits very\
          \ comfortably in the free Google Colab tier instance with the T4 GPU.  So\
          \ thank you very much again for this.  Cheers!</p>\n"
        raw: '@someone13574 Thank you so much for this code and the explanation.  Yes,
          this really helps -- because in terms of RAM, I can use my development machine,
          which is Mac M1 Max with 64GB RAM, and then upload the results to HuggingFace
          -- and then go from there (I verified that your sharded model fits very
          comfortably in the free Google Colab tier instance with the T4 GPU.  So
          thank you very much again for this.  Cheers!'
        updatedAt: '2023-10-01T04:56:07.223Z'
      numEdits: 0
      reactions: []
    id: 6518fbe7757417990d2cbe72
    type: comment
  author: alexsherstinsky
  content: '@someone13574 Thank you so much for this code and the explanation.  Yes,
    this really helps -- because in terms of RAM, I can use my development machine,
    which is Mac M1 Max with 64GB RAM, and then upload the results to HuggingFace
    -- and then go from there (I verified that your sharded model fits very comfortably
    in the free Google Colab tier instance with the T4 GPU.  So thank you very much
    again for this.  Cheers!'
  created_at: 2023-10-01 03:56:07+00:00
  edited: false
  hidden: false
  id: 6518fbe7757417990d2cbe72
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-02T23:56:38.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9505791068077087
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;someone13574&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/someone13574\"\
          >@<span class=\"underline\">someone13574</span></a></span>\n\n\t</span></span>\
          \ I have a follow up question for you, if I may, please.  In the line <code>model.save_pretrained()</code>\
          \ -- I do not see the path specified.  Is it possible to save the sharded\
          \ model to a HuggingFace location in my account?  Thank you.  Also, once\
          \ I get this to work on my end, I would like to use it in a pull request\
          \ to an open source library.  What is the best way to acknowledge you for\
          \ this idea?  Thank you very much again.</p>\n"
        raw: '@someone13574 I have a follow up question for you, if I may, please.  In
          the line `model.save_pretrained()` -- I do not see the path specified.  Is
          it possible to save the sharded model to a HuggingFace location in my account?  Thank
          you.  Also, once I get this to work on my end, I would like to use it in
          a pull request to an open source library.  What is the best way to acknowledge
          you for this idea?  Thank you very much again.'
        updatedAt: '2023-10-02T23:56:38.726Z'
      numEdits: 0
      reactions: []
    id: 651b58b6fb8e5721f7edc39b
    type: comment
  author: alexsherstinsky
  content: '@someone13574 I have a follow up question for you, if I may, please.  In
    the line `model.save_pretrained()` -- I do not see the path specified.  Is it
    possible to save the sharded model to a HuggingFace location in my account?  Thank
    you.  Also, once I get this to work on my end, I would like to use it in a pull
    request to an open source library.  What is the best way to acknowledge you for
    this idea?  Thank you very much again.'
  created_at: 2023-10-02 22:56:38+00:00
  edited: false
  hidden: false
  id: 651b58b6fb8e5721f7edc39b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-03T00:13:39.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7102451324462891
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;someone13574&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/someone13574\"\
          >@<span class=\"underline\">someone13574</span></a></span>\n\n\t</span></span>\
          \ Oh, I think we just say <code>model.save_pretrained(path_on_hugging_face,\
          \ max_shard_size=\"2GB\")</code> -- is this correct?</p>\n"
        raw: '@someone13574 Oh, I think we just say `model.save_pretrained(path_on_hugging_face,
          max_shard_size="2GB")` -- is this correct?'
        updatedAt: '2023-10-03T00:13:39.969Z'
      numEdits: 0
      reactions: []
    id: 651b5cb39571da71a4c3ddc5
    type: comment
  author: alexsherstinsky
  content: '@someone13574 Oh, I think we just say `model.save_pretrained(path_on_hugging_face,
    max_shard_size="2GB")` -- is this correct?'
  created_at: 2023-10-02 23:13:39+00:00
  edited: false
  hidden: false
  id: 651b5cb39571da71a4c3ddc5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d9c0fde3bc3b15a9df1263a67e12983a.svg
      fullname: Someone13574
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: someone13574
      type: user
    createdAt: '2023-10-03T03:53:26.000Z'
    data:
      edited: true
      editors:
      - someone13574
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9442017078399658
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d9c0fde3bc3b15a9df1263a67e12983a.svg
          fullname: Someone13574
          isHf: false
          isPro: false
          name: someone13574
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;alexsherstinsky&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/alexsherstinsky\"\
          >@<span class=\"underline\">alexsherstinsky</span></a></span>\n\n\t</span></span>\
          \ <code>model.save_pretrained()</code> saves the model to the local path\
          \ specified, which in the case of the code example I put above was a directory\
          \ called <code>sharded</code>. Then you can just upload it manually from\
          \ the website. I believe that you can push directly to huggingface using\
          \ <code>push_to_hub()</code>, but I'm not sure if anything other than safetensors\
          \ are supported, or if sharded models are supported. I just did it manually.</p>\n\
          <p>(Also, I don't need to be acknowledged.)</p>\n"
        raw: '@alexsherstinsky `model.save_pretrained()` saves the model to the local
          path specified, which in the case of the code example I put above was a
          directory called `sharded`. Then you can just upload it manually from the
          website. I believe that you can push directly to huggingface using `push_to_hub()`,
          but I''m not sure if anything other than safetensors are supported, or if
          sharded models are supported. I just did it manually.


          (Also, I don''t need to be acknowledged.)'
        updatedAt: '2023-10-03T03:54:13.208Z'
      numEdits: 1
      reactions: []
    id: 651b90361088bf68c36a7709
    type: comment
  author: someone13574
  content: '@alexsherstinsky `model.save_pretrained()` saves the model to the local
    path specified, which in the case of the code example I put above was a directory
    called `sharded`. Then you can just upload it manually from the website. I believe
    that you can push directly to huggingface using `push_to_hub()`, but I''m not
    sure if anything other than safetensors are supported, or if sharded models are
    supported. I just did it manually.


    (Also, I don''t need to be acknowledged.)'
  created_at: 2023-10-03 02:53:26+00:00
  edited: true
  hidden: false
  id: 651b90361088bf68c36a7709
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-03T04:14:46.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8701761960983276
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;someone13574&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/someone13574\"\
          >@<span class=\"underline\">someone13574</span></a></span>\n\n\t</span></span>\
          \ Got it -- really appreciate your explanation.  Thanks a lot!</p>\n"
        raw: '@someone13574 Got it -- really appreciate your explanation.  Thanks
          a lot!'
        updatedAt: '2023-10-03T04:14:46.586Z'
      numEdits: 0
      reactions: []
    id: 651b95363265a1bb83a0bf6c
    type: comment
  author: alexsherstinsky
  content: '@someone13574 Got it -- really appreciate your explanation.  Thanks a
    lot!'
  created_at: 2023-10-03 03:14:46+00:00
  edited: false
  hidden: false
  id: 651b95363265a1bb83a0bf6c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-03T05:08:12.000Z'
    data:
      edited: true
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9380731582641602
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;someone13574&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/someone13574\"\
          >@<span class=\"underline\">someone13574</span></a></span>\n\n\t</span></span>\
          \ Sorry to bother you again: one more question, if I may, please.  I tried\
          \ your procedure, but ended up with only 7 (instead of 8) shard files. \
          \ In addition, I did not get README in there.  Even more importantly, I\
          \ did not get the added tokens JSON file.  Could you please share the code\
          \ for how you added the special tokens </p>\n<pre><code>{\n  \"&lt;/s&gt;\"\
          : 2,\n  \"&lt;s&gt;\": 1,\n  \"&lt;unk&gt;\": 0\n}\n</code></pre>\n<p>to\
          \ your tokenizer ?</p>\n<p>Just in case it helps, here is the code I used:</p>\n\
          <pre><code>mistral_7b_original_base_model_name: str = \"mistralai/Mistral-7B-v0.1\"\
          \n\nmistral_7b_sharded_base_model_name: str = \"alexsherstinsky/Mistral-7B-v0.1-sharded\"\
          \n\noriginal_base_model_tokenizer: LlamaTokenizerFast = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=mistral_7b_original_base_model_name,\
          \ trust_remote_code=True, padding_side='left')\n\noriginal_base_model: MistralForCausalLM\
          \ = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=mistral_7b_original_base_model_name,\
          \ torch_dtype=torch.float16, trust_remote_code=True, device_map=\"auto\"\
          , low_cpu_mem_usage=True)\n\noriginal_base_model.save_pretrained(save_directory=f\"\
          /content/models/{mistral_7b_sharded_base_model_name}\", max_shard_size=\"\
          2GB\", push_to_hub=True)\n\noriginal_base_model_tokenizer.save_pretrained(save_directory=f\"\
          /content/models/{mistral_7b_sharded_base_model_name}\", legacy_format=False,\
          \ push_to_hub=True)\n</code></pre>\n<p>Thanks a lot again!</p>\n"
        raw: "@someone13574 Sorry to bother you again: one more question, if I may,\
          \ please.  I tried your procedure, but ended up with only 7 (instead of\
          \ 8) shard files.  In addition, I did not get README in there.  Even more\
          \ importantly, I did not get the added tokens JSON file.  Could you please\
          \ share the code for how you added the special tokens \n```\n{\n  \"</s>\"\
          : 2,\n  \"<s>\": 1,\n  \"<unk>\": 0\n}\n```\nto your tokenizer ?\n\nJust\
          \ in case it helps, here is the code I used:\n```\nmistral_7b_original_base_model_name:\
          \ str = \"mistralai/Mistral-7B-v0.1\"\n\nmistral_7b_sharded_base_model_name:\
          \ str = \"alexsherstinsky/Mistral-7B-v0.1-sharded\"\n\noriginal_base_model_tokenizer:\
          \ LlamaTokenizerFast = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=mistral_7b_original_base_model_name,\
          \ trust_remote_code=True, padding_side='left')\n\noriginal_base_model: MistralForCausalLM\
          \ = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=mistral_7b_original_base_model_name,\
          \ torch_dtype=torch.float16, trust_remote_code=True, device_map=\"auto\"\
          , low_cpu_mem_usage=True)\n\noriginal_base_model.save_pretrained(save_directory=f\"\
          /content/models/{mistral_7b_sharded_base_model_name}\", max_shard_size=\"\
          2GB\", push_to_hub=True)\n\noriginal_base_model_tokenizer.save_pretrained(save_directory=f\"\
          /content/models/{mistral_7b_sharded_base_model_name}\", legacy_format=False,\
          \ push_to_hub=True)\n```\n\nThanks a lot again!"
        updatedAt: '2023-10-03T05:35:16.581Z'
      numEdits: 4
      reactions: []
    id: 651ba1bc63cd12f4ba822020
    type: comment
  author: alexsherstinsky
  content: "@someone13574 Sorry to bother you again: one more question, if I may,\
    \ please.  I tried your procedure, but ended up with only 7 (instead of 8) shard\
    \ files.  In addition, I did not get README in there.  Even more importantly,\
    \ I did not get the added tokens JSON file.  Could you please share the code for\
    \ how you added the special tokens \n```\n{\n  \"</s>\": 2,\n  \"<s>\": 1,\n \
    \ \"<unk>\": 0\n}\n```\nto your tokenizer ?\n\nJust in case it helps, here is\
    \ the code I used:\n```\nmistral_7b_original_base_model_name: str = \"mistralai/Mistral-7B-v0.1\"\
    \n\nmistral_7b_sharded_base_model_name: str = \"alexsherstinsky/Mistral-7B-v0.1-sharded\"\
    \n\noriginal_base_model_tokenizer: LlamaTokenizerFast = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=mistral_7b_original_base_model_name,\
    \ trust_remote_code=True, padding_side='left')\n\noriginal_base_model: MistralForCausalLM\
    \ = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=mistral_7b_original_base_model_name,\
    \ torch_dtype=torch.float16, trust_remote_code=True, device_map=\"auto\", low_cpu_mem_usage=True)\n\
    \noriginal_base_model.save_pretrained(save_directory=f\"/content/models/{mistral_7b_sharded_base_model_name}\"\
    , max_shard_size=\"2GB\", push_to_hub=True)\n\noriginal_base_model_tokenizer.save_pretrained(save_directory=f\"\
    /content/models/{mistral_7b_sharded_base_model_name}\", legacy_format=False, push_to_hub=True)\n\
    ```\n\nThanks a lot again!"
  created_at: 2023-10-03 04:08:12+00:00
  edited: true
  hidden: false
  id: 651ba1bc63cd12f4ba822020
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d9c0fde3bc3b15a9df1263a67e12983a.svg
      fullname: Someone13574
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: someone13574
      type: user
    createdAt: '2023-10-03T21:16:37.000Z'
    data:
      edited: false
      editors:
      - someone13574
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9139296412467957
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d9c0fde3bc3b15a9df1263a67e12983a.svg
          fullname: Someone13574
          isHf: false
          isPro: false
          name: someone13574
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;alexsherstinsky&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/alexsherstinsky\"\
          >@<span class=\"underline\">alexsherstinsky</span></a></span>\n\n\t</span></span>\
          \ I just copied the files not save from <code>save_pretrained</code>, such\
          \ as the tokenizer and all other files other than the model weights and\
          \ the weight index over from the original model, as they should be the same\
          \ whether or not the model is sharded.</p>\n"
        raw: '@alexsherstinsky I just copied the files not save from `save_pretrained`,
          such as the tokenizer and all other files other than the model weights and
          the weight index over from the original model, as they should be the same
          whether or not the model is sharded.'
        updatedAt: '2023-10-03T21:16:37.173Z'
      numEdits: 0
      reactions: []
    id: 651c84b5d2fa2cc67191f909
    type: comment
  author: someone13574
  content: '@alexsherstinsky I just copied the files not save from `save_pretrained`,
    such as the tokenizer and all other files other than the model weights and the
    weight index over from the original model, as they should be the same whether
    or not the model is sharded.'
  created_at: 2023-10-03 20:16:37+00:00
  edited: false
  hidden: false
  id: 651c84b5d2fa2cc67191f909
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-03T21:28:46.000Z'
    data:
      edited: true
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9808882474899292
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;someone13574&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/someone13574\"\
          >@<span class=\"underline\">someone13574</span></a></span>\n\n\t</span></span>\
          \ Got it -- this was very helpful.  Do you by chance know how we could have\
          \ ended up with the different number of shard files?  Or did you copy the\
          \ original base model's one as well?  Thanks a lot!</p>\n"
        raw: '@someone13574 Got it -- this was very helpful.  Do you by chance know
          how we could have ended up with the different number of shard files?  Or
          did you copy the original base model''s one as well?  Thanks a lot!'
        updatedAt: '2023-10-03T21:29:39.562Z'
      numEdits: 1
      reactions: []
    id: 651c878e379ec502de53856a
    type: comment
  author: alexsherstinsky
  content: '@someone13574 Got it -- this was very helpful.  Do you by chance know
    how we could have ended up with the different number of shard files?  Or did you
    copy the original base model''s one as well?  Thanks a lot!'
  created_at: 2023-10-03 20:28:46+00:00
  edited: true
  hidden: false
  id: 651c878e379ec502de53856a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d9c0fde3bc3b15a9df1263a67e12983a.svg
      fullname: Someone13574
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: someone13574
      type: user
    createdAt: '2023-10-03T23:36:43.000Z'
    data:
      edited: false
      editors:
      - someone13574
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9902467727661133
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d9c0fde3bc3b15a9df1263a67e12983a.svg
          fullname: Someone13574
          isHf: false
          isPro: false
          name: someone13574
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;alexsherstinsky&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/alexsherstinsky\"\
          >@<span class=\"underline\">alexsherstinsky</span></a></span>\n\n\t</span></span>\
          \ Not sure what would have caused that.</p>\n"
        raw: '@alexsherstinsky Not sure what would have caused that.'
        updatedAt: '2023-10-03T23:36:43.126Z'
      numEdits: 0
      reactions: []
    id: 651ca58b552be122da69504d
    type: comment
  author: someone13574
  content: '@alexsherstinsky Not sure what would have caused that.'
  created_at: 2023-10-03 22:36:43+00:00
  edited: false
  hidden: false
  id: 651ca58b552be122da69504d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-04T08:07:13.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7919124960899353
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;someone13574&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/someone13574\"\
          >@<span class=\"underline\">someone13574</span></a></span>\n\n\t</span></span>\
          \ No matter what I have tried, I am unable to shard the way you have --\
          \ I always get 7 instead of 8 files.  I even tried to download your model\
          \ and upload it sharded, and still get 7 files.  And loading my sharded\
          \ result fails with this exception:</p>\n<pre><code>/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py\
          \ in set_module_tensor_to_device(module, tensor_name, device, value, dtype,\
          \ fp16_statistics)\n    315                     module._parameters[tensor_name]\
          \ = param_cls(new_value, requires_grad=old_value.requires_grad)\n    316\
          \         elif isinstance(value, torch.Tensor):\n--&gt; 317            \
          \ new_value = value.to(device)\n    318         else:\n    319         \
          \    new_value = torch.tensor(value, device=device)\n\nNotImplementedError:\
          \ Cannot copy out of meta tensor; no data!\n</code></pre>\n<p>Could the\
          \ problem be the version of PyTorch and HuggingFace Transformers libraries\
          \ that I am using and which may be wrong?  Could you please tell me the\
          \ versions of these packages that you are using?</p>\n<p>I think that my\
          \ PyTorch version is 2.0.1+cu118 and Transformers version is 4.35.0.dev0\
          \ -- could this be my issue?</p>\n<p>Thanks a lot for your help.</p>\n"
        raw: "@someone13574 No matter what I have tried, I am unable to shard the\
          \ way you have -- I always get 7 instead of 8 files.  I even tried to download\
          \ your model and upload it sharded, and still get 7 files.  And loading\
          \ my sharded result fails with this exception:\n```\n/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py\
          \ in set_module_tensor_to_device(module, tensor_name, device, value, dtype,\
          \ fp16_statistics)\n    315                     module._parameters[tensor_name]\
          \ = param_cls(new_value, requires_grad=old_value.requires_grad)\n    316\
          \         elif isinstance(value, torch.Tensor):\n--> 317             new_value\
          \ = value.to(device)\n    318         else:\n    319             new_value\
          \ = torch.tensor(value, device=device)\n\nNotImplementedError: Cannot copy\
          \ out of meta tensor; no data!\n```\n\nCould the problem be the version\
          \ of PyTorch and HuggingFace Transformers libraries that I am using and\
          \ which may be wrong?  Could you please tell me the versions of these packages\
          \ that you are using?\n\nI think that my PyTorch version is 2.0.1+cu118\
          \ and Transformers version is 4.35.0.dev0 -- could this be my issue?\n\n\
          Thanks a lot for your help."
        updatedAt: '2023-10-04T08:07:13.754Z'
      numEdits: 0
      reactions: []
    id: 651d1d310c0c6b8fc8708cc7
    type: comment
  author: alexsherstinsky
  content: "@someone13574 No matter what I have tried, I am unable to shard the way\
    \ you have -- I always get 7 instead of 8 files.  I even tried to download your\
    \ model and upload it sharded, and still get 7 files.  And loading my sharded\
    \ result fails with this exception:\n```\n/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py\
    \ in set_module_tensor_to_device(module, tensor_name, device, value, dtype, fp16_statistics)\n\
    \    315                     module._parameters[tensor_name] = param_cls(new_value,\
    \ requires_grad=old_value.requires_grad)\n    316         elif isinstance(value,\
    \ torch.Tensor):\n--> 317             new_value = value.to(device)\n    318  \
    \       else:\n    319             new_value = torch.tensor(value, device=device)\n\
    \nNotImplementedError: Cannot copy out of meta tensor; no data!\n```\n\nCould\
    \ the problem be the version of PyTorch and HuggingFace Transformers libraries\
    \ that I am using and which may be wrong?  Could you please tell me the versions\
    \ of these packages that you are using?\n\nI think that my PyTorch version is\
    \ 2.0.1+cu118 and Transformers version is 4.35.0.dev0 -- could this be my issue?\n\
    \nThanks a lot for your help."
  created_at: 2023-10-04 07:07:13+00:00
  edited: false
  hidden: false
  id: 651d1d310c0c6b8fc8708cc7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-04T19:00:39.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9638177156448364
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;someone13574&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/someone13574\"\
          >@<span class=\"underline\">someone13574</span></a></span>\n\n\t</span></span>\
          \ I believe that I found the issue.  It seems that the needed version of\
          \ transformers should be <code>4.34.0</code>.  When I used that and did\
          \ the sharding from my local machine (instead of Google Colab), everything\
          \ worked properly.  Sorry to have disturbed you with the messages, and thank\
          \ you again for your help.</p>\n"
        raw: '@someone13574 I believe that I found the issue.  It seems that the needed
          version of transformers should be `4.34.0`.  When I used that and did the
          sharding from my local machine (instead of Google Colab), everything worked
          properly.  Sorry to have disturbed you with the messages, and thank you
          again for your help.'
        updatedAt: '2023-10-04T19:00:39.978Z'
      numEdits: 0
      reactions: []
    id: 651db65749a1ea808c3ccf2e
    type: comment
  author: alexsherstinsky
  content: '@someone13574 I believe that I found the issue.  It seems that the needed
    version of transformers should be `4.34.0`.  When I used that and did the sharding
    from my local machine (instead of Google Colab), everything worked properly.  Sorry
    to have disturbed you with the messages, and thank you again for your help.'
  created_at: 2023-10-04 18:00:39+00:00
  edited: false
  hidden: false
  id: 651db65749a1ea808c3ccf2e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658503618672-noauth.jpeg?w=200&h=200&f=face
      fullname: lerela
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lerela
      type: user
    createdAt: '2023-10-05T08:01:04.000Z'
    data:
      edited: false
      editors:
      - lerela
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9627056121826172
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658503618672-noauth.jpeg?w=200&h=200&f=face
          fullname: lerela
          isHf: false
          isPro: false
          name: lerela
          type: user
        html: '<p>Glad that you could make it work, supported version at the moment
          is indeed 4.34.0. We''ve clarified the README in that regard!</p>

          '
        raw: Glad that you could make it work, supported version at the moment is
          indeed 4.34.0. We've clarified the README in that regard!
        updatedAt: '2023-10-05T08:01:04.006Z'
      numEdits: 0
      reactions: []
      relatedEventId: 651e6d40073d85a99d19b0e9
    id: 651e6d40073d85a99d19b0e6
    type: comment
  author: lerela
  content: Glad that you could make it work, supported version at the moment is indeed
    4.34.0. We've clarified the README in that regard!
  created_at: 2023-10-05 07:01:04+00:00
  edited: false
  hidden: false
  id: 651e6d40073d85a99d19b0e6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658503618672-noauth.jpeg?w=200&h=200&f=face
      fullname: lerela
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lerela
      type: user
    createdAt: '2023-10-05T08:01:04.000Z'
    data:
      status: closed
    id: 651e6d40073d85a99d19b0e9
    type: status-change
  author: lerela
  created_at: 2023-10-05 07:01:04+00:00
  id: 651e6d40073d85a99d19b0e9
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-05T14:46:35.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9454882144927979
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;lerela&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/lerela\">@<span class=\"\
          underline\">lerela</span></a></span>\n\n\t</span></span> Thank you for confirming.\
          \  Perhaps Mistral AI would consider making the official model sharded in\
          \ order to make it easier for new users to use it in low-resource hardware\
          \ environments.  Thanks again.</p>\n"
        raw: '@lerela Thank you for confirming.  Perhaps Mistral AI would consider
          making the official model sharded in order to make it easier for new users
          to use it in low-resource hardware environments.  Thanks again.'
        updatedAt: '2023-10-05T14:46:35.919Z'
      numEdits: 0
      reactions: []
    id: 651ecc4bfc791e23f7fdb48e
    type: comment
  author: alexsherstinsky
  content: '@lerela Thank you for confirming.  Perhaps Mistral AI would consider making
    the official model sharded in order to make it easier for new users to use it
    in low-resource hardware environments.  Thanks again.'
  created_at: 2023-10-05 13:46:35+00:00
  edited: false
  hidden: false
  id: 651ecc4bfc791e23f7fdb48e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3b19d15f0d03e6393408c0e358c8d0dc.svg
      fullname: Manu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Manu9000k
      type: user
    createdAt: '2023-10-06T05:07:01.000Z'
    data:
      edited: false
      editors:
      - Manu9000k
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9072957038879395
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3b19d15f0d03e6393408c0e358c8d0dc.svg
          fullname: Manu
          isHf: false
          isPro: false
          name: Manu9000k
          type: user
        html: '<p>Can you please share the full colab example?</p>

          '
        raw: Can you please share the full colab example?
        updatedAt: '2023-10-06T05:07:01.730Z'
      numEdits: 0
      reactions: []
    id: 651f95f56d11340cd334127f
    type: comment
  author: Manu9000k
  content: Can you please share the full colab example?
  created_at: 2023-10-06 04:07:01+00:00
  edited: false
  hidden: false
  id: 651f95f56d11340cd334127f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-06T05:30:28.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9166834950447083
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Manu9000k&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Manu9000k\">@<span class=\"\
          underline\">Manu9000k</span></a></span>\n\n\t</span></span> I am preparing\
          \ it and hope to share early next week; I will paste it here -- thank you\
          \ for asking.</p>\n"
        raw: '@Manu9000k I am preparing it and hope to share early next week; I will
          paste it here -- thank you for asking.'
        updatedAt: '2023-10-06T05:30:28.543Z'
      numEdits: 0
      reactions: []
    id: 651f9b749b25c6baa492e19a
    type: comment
  author: alexsherstinsky
  content: '@Manu9000k I am preparing it and hope to share early next week; I will
    paste it here -- thank you for asking.'
  created_at: 2023-10-06 04:30:28+00:00
  edited: false
  hidden: false
  id: 651f9b749b25c6baa492e19a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-07T08:26:49.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5283184051513672
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Manu9000k&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Manu9000k\">@<span class=\"\
          underline\">Manu9000k</span></a></span>\n\n\t</span></span> Here it is:\
          \ <a rel=\"nofollow\" href=\"https://predibase.com/blog/fine-tuning-mistral-7b-on-a-single-gpu-with-ludwig\"\
          >https://predibase.com/blog/fine-tuning-mistral-7b-on-a-single-gpu-with-ludwig</a>\
          \ -- enjoy!</p>\n"
        raw: '@Manu9000k Here it is: https://predibase.com/blog/fine-tuning-mistral-7b-on-a-single-gpu-with-ludwig
          -- enjoy!'
        updatedAt: '2023-10-07T08:26:49.473Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - Manu9000k
        - CWKSC
    id: 65211649706c7551487c999a
    type: comment
  author: alexsherstinsky
  content: '@Manu9000k Here it is: https://predibase.com/blog/fine-tuning-mistral-7b-on-a-single-gpu-with-ludwig
    -- enjoy!'
  created_at: 2023-10-07 07:26:49+00:00
  edited: false
  hidden: false
  id: 65211649706c7551487c999a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3b19d15f0d03e6393408c0e358c8d0dc.svg
      fullname: Manu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Manu9000k
      type: user
    createdAt: '2023-10-08T08:46:11.000Z'
    data:
      edited: false
      editors:
      - Manu9000k
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7045485377311707
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3b19d15f0d03e6393408c0e358c8d0dc.svg
          fullname: Manu
          isHf: false
          isPro: false
          name: Manu9000k
          type: user
        html: "<p>Thanks a lot <span data-props=\"{&quot;user&quot;:&quot;alexsherstinsky&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/alexsherstinsky\"\
          >@<span class=\"underline\">alexsherstinsky</span></a></span>\n\n\t</span></span>\
          \ you are the best!!!!</p>\n"
        raw: Thanks a lot @alexsherstinsky you are the best!!!!
        updatedAt: '2023-10-08T08:46:11.350Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - alexsherstinsky
    id: 65226c532a16045c09585b54
    type: comment
  author: Manu9000k
  content: Thanks a lot @alexsherstinsky you are the best!!!!
  created_at: 2023-10-08 07:46:11+00:00
  edited: false
  hidden: false
  id: 65226c532a16045c09585b54
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-08T14:48:13.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9201360940933228
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Manu9000k&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Manu9000k\">@<span class=\"\
          underline\">Manu9000k</span></a></span>\n\n\t</span></span> Thank you very\
          \ much!  It is really my pleasure -- I am glad it helps -- enjoy!</p>\n"
        raw: '@Manu9000k Thank you very much!  It is really my pleasure -- I am glad
          it helps -- enjoy!'
        updatedAt: '2023-10-08T14:48:13.972Z'
      numEdits: 0
      reactions: []
    id: 6522c12d9334173c628517ff
    type: comment
  author: alexsherstinsky
  content: '@Manu9000k Thank you very much!  It is really my pleasure -- I am glad
    it helps -- enjoy!'
  created_at: 2023-10-08 13:48:13+00:00
  edited: false
  hidden: false
  id: 6522c12d9334173c628517ff
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0878bc930e27371f55e24196c199ff62.svg
      fullname: Dx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NPap
      type: user
    createdAt: '2023-10-10T10:37:51.000Z'
    data:
      edited: false
      editors:
      - NPap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9591819643974304
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0878bc930e27371f55e24196c199ff62.svg
          fullname: Dx
          isHf: false
          isPro: false
          name: NPap
          type: user
        html: '<p>Okay, now the loading issue is out of the way, has anyone succeeded
          in finetuning Mistral through google colab?</p>

          '
        raw: Okay, now the loading issue is out of the way, has anyone succeeded in
          finetuning Mistral through google colab?
        updatedAt: '2023-10-10T10:37:51.943Z'
      numEdits: 0
      reactions: []
    id: 6525297fdb38bef85b0d8c2a
    type: comment
  author: NPap
  content: Okay, now the loading issue is out of the way, has anyone succeeded in
    finetuning Mistral through google colab?
  created_at: 2023-10-10 09:37:51+00:00
  edited: false
  hidden: false
  id: 6525297fdb38bef85b0d8c2a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-10T10:57:39.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9477519392967224
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: "<p>I think you should be able to do that if you use the left library\
          \ cc <span data-props=\"{&quot;user&quot;:&quot;ybelkada&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ybelkada\">@<span class=\"\
          underline\">ybelkada</span></a></span>\n\n\t</span></span> we have tutorials\
          \ for Llama I think no? </p>\n"
        raw: 'I think you should be able to do that if you use the left library cc
          @ybelkada we have tutorials for Llama I think no? '
        updatedAt: '2023-10-10T10:57:39.304Z'
      numEdits: 0
      reactions: []
    id: 65252e23db38bef85b0e22d8
    type: comment
  author: ArthurZ
  content: 'I think you should be able to do that if you use the left library cc @ybelkada
    we have tutorials for Llama I think no? '
  created_at: 2023-10-10 09:57:39+00:00
  edited: false
  hidden: false
  id: 65252e23db38bef85b0e22d8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0878bc930e27371f55e24196c199ff62.svg
      fullname: Dx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NPap
      type: user
    createdAt: '2023-10-10T10:59:55.000Z'
    data:
      edited: false
      editors:
      - NPap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9687992930412292
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0878bc930e27371f55e24196c199ff62.svg
          fullname: Dx
          isHf: false
          isPro: false
          name: NPap
          type: user
        html: "<blockquote>\n<p>I think you should be able to do that if you use the\
          \ left library cc <span data-props=\"{&quot;user&quot;:&quot;ybelkada&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ybelkada\"\
          >@<span class=\"underline\">ybelkada</span></a></span>\n\n\t</span></span>\
          \ we have tutorials for Llama I think no?</p>\n</blockquote>\n<p>I've tried\
          \ Llama and it worked with a few dirty fixes currently but this one has\
          \ a different tokenizer and attention mechanism (if I'm not mistaken) so\
          \ I'm not sure if peft/bits&amp;bytes/SFFTrainer are good to go for that.\
          \ (These are the components I'm using)</p>\n"
        raw: '> I think you should be able to do that if you use the left library
          cc @ybelkada we have tutorials for Llama I think no?


          I''ve tried Llama and it worked with a few dirty fixes currently but this
          one has a different tokenizer and attention mechanism (if I''m not mistaken)
          so I''m not sure if peft/bits&bytes/SFFTrainer are good to go for that.
          (These are the components I''m using)'
        updatedAt: '2023-10-10T10:59:55.135Z'
      numEdits: 0
      reactions: []
    id: 65252eab1a4bb97e35ce7bbd
    type: comment
  author: NPap
  content: '> I think you should be able to do that if you use the left library cc
    @ybelkada we have tutorials for Llama I think no?


    I''ve tried Llama and it worked with a few dirty fixes currently but this one
    has a different tokenizer and attention mechanism (if I''m not mistaken) so I''m
    not sure if peft/bits&bytes/SFFTrainer are good to go for that. (These are the
    components I''m using)'
  created_at: 2023-10-10 09:59:55+00:00
  edited: false
  hidden: false
  id: 65252eab1a4bb97e35ce7bbd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2023-10-10T14:40:12.000Z'
    data:
      edited: false
      editors:
      - lysandre
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3435228765010834
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: "<p>cc <span data-props=\"{&quot;user&quot;:&quot;ybelkada&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ybelkada\"\
          >@<span class=\"underline\">ybelkada</span></a></span>\n\n\t</span></span>\
          \ for peft/bitsandbytes/SFT Trainer</p>\n"
        raw: cc @ybelkada for peft/bitsandbytes/SFT Trainer
        updatedAt: '2023-10-10T14:40:12.229Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - lunarflu
    id: 6525624c3623a4a71cd5fb62
    type: comment
  author: lysandre
  content: cc @ybelkada for peft/bitsandbytes/SFT Trainer
  created_at: 2023-10-10 13:40:12+00:00
  edited: false
  hidden: false
  id: 6525624c3623a4a71cd5fb62
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
      fullname: Alex Sherstinsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alexsherstinsky
      type: user
    createdAt: '2023-10-10T14:52:44.000Z'
    data:
      edited: false
      editors:
      - alexsherstinsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6544241905212402
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da9e4bdafcf7595956abcf/Wf8o2zTUEghptxk-ao_43.jpeg?w=200&h=200&f=face
          fullname: Alex Sherstinsky
          isHf: false
          isPro: false
          name: alexsherstinsky
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;NPap&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/NPap\">@<span class=\"\
          underline\">NPap</span></a></span>\n\n\t</span></span> Have you tried the\
          \ procedure outlined in <a href=\"https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/13#65211649706c7551487c999a\"\
          >https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/13#65211649706c7551487c999a</a>\
          \ (an earlier message above)?  Thank you.</p>\n"
        raw: '@NPap Have you tried the procedure outlined in https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/13#65211649706c7551487c999a
          (an earlier message above)?  Thank you.'
        updatedAt: '2023-10-10T14:52:44.170Z'
      numEdits: 0
      reactions: []
    id: 6525653cea63baa5b718594c
    type: comment
  author: alexsherstinsky
  content: '@NPap Have you tried the procedure outlined in https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/13#65211649706c7551487c999a
    (an earlier message above)?  Thank you.'
  created_at: 2023-10-10 13:52:44+00:00
  edited: false
  hidden: false
  id: 6525653cea63baa5b718594c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-10-10T19:32:24.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8678555488586426
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: '<p>Hi everyone,</p>

          <p>You can indeed fine-tune Mistral-7B on a free tier google colab instance.
          I made a colab notebook for it here: <a rel="nofollow" href="https://colab.research.google.com/drive/1DNenc5BpdqaS10prtklYyIe9qW_7gUnb?usp=sharing">https://colab.research.google.com/drive/1DNenc5BpdqaS10prtklYyIe9qW_7gUnb?usp=sharing</a>
          </p>

          <p>Make sure to use the sharded version of the model that I have pushed
          under my namespace <a href="https://huggingface.co/ybelkada/Mistral-7B-v0.1-bf16-sharded">here</a>
          as currently since the largest shard is 10GB, it leads to CPU OOM if you
          try to use <code>mistralai/Mistral-7B-v0.1</code></p>

          <p>I recommend to train your model with <code>packing</code> to avoid issues
          presented in this GH thread: <a rel="nofollow" href="https://github.com/huggingface/transformers/issues/26498">https://github.com/huggingface/transformers/issues/26498</a>
          </p>

          <p>Let us know here how the training goes - fine-tuning the model on the
          entire guanaco dataset seems to take ~4 hours. This can be further reduced
          down once <code>torch.scaled_dot_product_attention</code> will be integrated
          in transformers core : <a rel="nofollow" href="https://github.com/huggingface/transformers/pull/26572">https://github.com/huggingface/transformers/pull/26572</a></p>

          '
        raw: "Hi everyone,\n\nYou can indeed fine-tune Mistral-7B on a free tier google\
          \ colab instance. I made a colab notebook for it here: https://colab.research.google.com/drive/1DNenc5BpdqaS10prtklYyIe9qW_7gUnb?usp=sharing\
          \ \n\nMake sure to use the sharded version of the model that I have pushed\
          \ under my namespace [here](https://huggingface.co/ybelkada/Mistral-7B-v0.1-bf16-sharded)\
          \ as currently since the largest shard is 10GB, it leads to CPU OOM if you\
          \ try to use `mistralai/Mistral-7B-v0.1`\n\nI recommend to train your model\
          \ with `packing` to avoid issues presented in this GH thread: https://github.com/huggingface/transformers/issues/26498\
          \ \n\nLet us know here how the training goes - fine-tuning the model on\
          \ the entire guanaco dataset seems to take ~4 hours. This can be further\
          \ reduced down once `torch.scaled_dot_product_attention` will be integrated\
          \ in transformers core : https://github.com/huggingface/transformers/pull/26572\n\
          \n"
        updatedAt: '2023-10-10T19:32:24.293Z'
      numEdits: 0
      reactions:
      - count: 7
        reaction: "\u2764\uFE0F"
        users:
        - ArthurZ
        - alexsherstinsky
        - NPap
        - Benan
        - lysandre
        - famert
        - krumeto
    id: 6525a6c8d5a9686516be439b
    type: comment
  author: ybelkada
  content: "Hi everyone,\n\nYou can indeed fine-tune Mistral-7B on a free tier google\
    \ colab instance. I made a colab notebook for it here: https://colab.research.google.com/drive/1DNenc5BpdqaS10prtklYyIe9qW_7gUnb?usp=sharing\
    \ \n\nMake sure to use the sharded version of the model that I have pushed under\
    \ my namespace [here](https://huggingface.co/ybelkada/Mistral-7B-v0.1-bf16-sharded)\
    \ as currently since the largest shard is 10GB, it leads to CPU OOM if you try\
    \ to use `mistralai/Mistral-7B-v0.1`\n\nI recommend to train your model with `packing`\
    \ to avoid issues presented in this GH thread: https://github.com/huggingface/transformers/issues/26498\
    \ \n\nLet us know here how the training goes - fine-tuning the model on the entire\
    \ guanaco dataset seems to take ~4 hours. This can be further reduced down once\
    \ `torch.scaled_dot_product_attention` will be integrated in transformers core\
    \ : https://github.com/huggingface/transformers/pull/26572\n\n"
  created_at: 2023-10-10 18:32:24+00:00
  edited: false
  hidden: false
  id: 6525a6c8d5a9686516be439b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bb63faebb159929917e9ec55bc2ca63e.svg
      fullname: Andrew Huang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ahuang11
      type: user
    createdAt: '2023-10-13T05:05:57.000Z'
    data:
      edited: false
      editors:
      - ahuang11
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8619765639305115
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bb63faebb159929917e9ec55bc2ca63e.svg
          fullname: Andrew Huang
          isHf: false
          isPro: false
          name: ahuang11
          type: user
        html: '<p>Thanks for sharing the notebook! I was wondering if you need to
          format the training dataset to conform to:</p>

          <p><code>&lt;s&gt;[INST] What is your favourite condiment? [/INST] Well,
          I''m quite partial to a good squeeze of fresh lemon juice. It adds just
          the right amount of zesty flavour to whatever I''m cooking up in the kitchen!&lt;/s&gt;</code></p>

          <p>Or does the tokenizer automatically do that?</p>

          <p>like mentioned in <a rel="nofollow" href="https://adithyask.medium.com/a-beginners-guide-to-fine-tuning-mistral-7b-instruct-model-0f39647b20fe">https://adithyask.medium.com/a-beginners-guide-to-fine-tuning-mistral-7b-instruct-model-0f39647b20fe</a>
          and <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1#instruction-format">https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1#instruction-format</a></p>

          '
        raw: 'Thanks for sharing the notebook! I was wondering if you need to format
          the training dataset to conform to:

          ```<s>[INST] What is your favourite condiment? [/INST]

          Well, I''m quite partial to a good squeeze of fresh lemon juice. It adds
          just the right amount of zesty flavour to whatever I''m cooking up in the
          kitchen!</s>```


          Or does the tokenizer automatically do that?


          like mentioned in https://adithyask.medium.com/a-beginners-guide-to-fine-tuning-mistral-7b-instruct-model-0f39647b20fe
          and https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1#instruction-format'
        updatedAt: '2023-10-13T05:05:57.022Z'
      numEdits: 0
      reactions: []
    id: 6528d035d63c4798ed7f513b
    type: comment
  author: ahuang11
  content: 'Thanks for sharing the notebook! I was wondering if you need to format
    the training dataset to conform to:

    ```<s>[INST] What is your favourite condiment? [/INST]

    Well, I''m quite partial to a good squeeze of fresh lemon juice. It adds just
    the right amount of zesty flavour to whatever I''m cooking up in the kitchen!</s>```


    Or does the tokenizer automatically do that?


    like mentioned in https://adithyask.medium.com/a-beginners-guide-to-fine-tuning-mistral-7b-instruct-model-0f39647b20fe
    and https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1#instruction-format'
  created_at: 2023-10-13 04:05:57+00:00
  edited: false
  hidden: false
  id: 6528d035d63c4798ed7f513b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0878bc930e27371f55e24196c199ff62.svg
      fullname: Dx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NPap
      type: user
    createdAt: '2023-10-13T06:39:26.000Z'
    data:
      edited: false
      editors:
      - NPap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8702612519264221
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0878bc930e27371f55e24196c199ff62.svg
          fullname: Dx
          isHf: false
          isPro: false
          name: NPap
          type: user
        html: '<blockquote>

          <p>Thanks for sharing the notebook! I was wondering if you need to format
          the training dataset to conform to:</p>

          <pre><code class="language-<s>[INST]">Well, I''m quite partial to a good
          squeeze of fresh lemon juice. It adds just the right amount of zesty flavour
          to whatever I''m cooking up in the kitchen!&lt;/s&gt;```


          Or does the tokenizer automatically do that?


          like mentioned in https://adithyask.medium.com/a-beginners-guide-to-fine-tuning-mistral-7b-instruct-model-0f39647b20fe
          and https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1#instruction-format

          </code></pre>

          </blockquote>

          <p>Check the tokenizers parameters, I think its eos, bos, and special tokens
          arguments. (Thats for the <s> and </s>, I think you will need to put [INST]
          and [/INST] yourself)</p>

          '
        raw: "> Thanks for sharing the notebook! I was wondering if you need to format\
          \ the training dataset to conform to:\n> ```<s>[INST] What is your favourite\
          \ condiment? [/INST]\n> Well, I'm quite partial to a good squeeze of fresh\
          \ lemon juice. It adds just the right amount of zesty flavour to whatever\
          \ I'm cooking up in the kitchen!</s>```\n> \n> Or does the tokenizer automatically\
          \ do that?\n> \n> like mentioned in https://adithyask.medium.com/a-beginners-guide-to-fine-tuning-mistral-7b-instruct-model-0f39647b20fe\
          \ and https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1#instruction-format\n\
          \nCheck the tokenizers parameters, I think its eos, bos, and special tokens\
          \ arguments. (Thats for the <s> and </s>, I think you will need to put [INST]\
          \ and [/INST] yourself)"
        updatedAt: '2023-10-13T06:39:26.599Z'
      numEdits: 0
      reactions: []
    id: 6528e61e991ea63f6f1761f4
    type: comment
  author: NPap
  content: "> Thanks for sharing the notebook! I was wondering if you need to format\
    \ the training dataset to conform to:\n> ```<s>[INST] What is your favourite condiment?\
    \ [/INST]\n> Well, I'm quite partial to a good squeeze of fresh lemon juice. It\
    \ adds just the right amount of zesty flavour to whatever I'm cooking up in the\
    \ kitchen!</s>```\n> \n> Or does the tokenizer automatically do that?\n> \n> like\
    \ mentioned in https://adithyask.medium.com/a-beginners-guide-to-fine-tuning-mistral-7b-instruct-model-0f39647b20fe\
    \ and https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1#instruction-format\n\
    \nCheck the tokenizers parameters, I think its eos, bos, and special tokens arguments.\
    \ (Thats for the <s> and </s>, I think you will need to put [INST] and [/INST]\
    \ yourself)"
  created_at: 2023-10-13 05:39:26+00:00
  edited: false
  hidden: false
  id: 6528e61e991ea63f6f1761f4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-13T09:56:57.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5764344930648804
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>The chat templating can be used following <a href="https://huggingface.co/docs/transformers/main/chat_templating">this
          blog</a> for chat formating! </p>

          '
        raw: 'The chat templating can be used following [this blog](https://huggingface.co/docs/transformers/main/chat_templating)
          for chat formating! '
        updatedAt: '2023-10-13T09:56:57.590Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - NPap
        - ahuang11
        - lysandre
    id: 65291469598467feb346c889
    type: comment
  author: ArthurZ
  content: 'The chat templating can be used following [this blog](https://huggingface.co/docs/transformers/main/chat_templating)
    for chat formating! '
  created_at: 2023-10-13 08:56:57+00:00
  edited: false
  hidden: false
  id: 65291469598467feb346c889
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: mistralai/Mistral-7B-v0.1
repo_type: model
status: closed
target_branch: null
title: Is it possible to run Mistral-7B-v0.1 in the free-tier Google Colab notebook?
