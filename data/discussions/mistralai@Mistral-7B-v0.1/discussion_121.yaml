!!python/object:huggingface_hub.community.DiscussionWithDetails
author: clemennntt
conflicting_files: null
created_at: 2024-01-24 18:41:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0f8d3231f7c1c897f59c4875659ce4ff.svg
      fullname: L
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: clemennntt
      type: user
    createdAt: '2024-01-24T18:41:26.000Z'
    data:
      edited: false
      editors:
      - clemennntt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7758706212043762
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0f8d3231f7c1c897f59c4875659ce4ff.svg
          fullname: L
          isHf: false
          isPro: false
          name: clemennntt
          type: user
        html: '<p>Hi there, just a question I don''t understand why my kernel crashed
          when I run :<br>tokenizer = LlamaTokenizer.from_pretrained("mistral-7B-v0.1_extract")<br>model
          = MistralForCausalLM.from_pretrained("mistral-7B-v0.1_extract")</p>

          <p>Note : mistral_7B-v0.1_extract is th efolder where I extracted the content
          from the raw checkpoints.<br>If I use "mistralai/Mistral-7B-v0.1" directly
          I have the same issue.</p>

          <p>This is the output : {<br>    "stack": "The Kernel crashed while executing
          code in the the current cell or a previous cell. Please review the code
          in the cell(s) to identify a possible cause of the failure."<br>}</p>

          '
        raw: "Hi there, just a question I don't understand why my kernel crashed when\
          \ I run :\r\ntokenizer = LlamaTokenizer.from_pretrained(\"mistral-7B-v0.1_extract\"\
          )\r\nmodel = MistralForCausalLM.from_pretrained(\"mistral-7B-v0.1_extract\"\
          )\r\n\r\nNote : mistral_7B-v0.1_extract is th efolder where I extracted\
          \ the content from the raw checkpoints.\r\nIf I use \"mistralai/Mistral-7B-v0.1\"\
          \ directly I have the same issue.\r\n\r\nThis is the output : {\r\n\t\"\
          stack\": \"The Kernel crashed while executing code in the the current cell\
          \ or a previous cell. Please review the code in the cell(s) to identify\
          \ a possible cause of the failure.\"\r\n}"
        updatedAt: '2024-01-24T18:41:26.557Z'
      numEdits: 0
      reactions: []
    id: 65b159d6fcead433ffe5c46f
    type: comment
  author: clemennntt
  content: "Hi there, just a question I don't understand why my kernel crashed when\
    \ I run :\r\ntokenizer = LlamaTokenizer.from_pretrained(\"mistral-7B-v0.1_extract\"\
    )\r\nmodel = MistralForCausalLM.from_pretrained(\"mistral-7B-v0.1_extract\")\r\
    \n\r\nNote : mistral_7B-v0.1_extract is th efolder where I extracted the content\
    \ from the raw checkpoints.\r\nIf I use \"mistralai/Mistral-7B-v0.1\" directly\
    \ I have the same issue.\r\n\r\nThis is the output : {\r\n\t\"stack\": \"The Kernel\
    \ crashed while executing code in the the current cell or a previous cell. Please\
    \ review the code in the cell(s) to identify a possible cause of the failure.\"\
    \r\n}"
  created_at: 2024-01-24 18:41:26+00:00
  edited: false
  hidden: false
  id: 65b159d6fcead433ffe5c46f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 121
repo_id: mistralai/Mistral-7B-v0.1
repo_type: model
status: open
target_branch: null
title: Kernel crashed while loading checkpoint shards
