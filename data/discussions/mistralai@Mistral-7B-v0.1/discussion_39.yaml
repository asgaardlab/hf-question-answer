!!python/object:huggingface_hub.community.DiscussionWithDetails
author: codegood
conflicting_files: null
created_at: 2023-10-05 02:24:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14c0faec86334a15d040ef3219f7a63f.svg
      fullname: Stephan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: codegood
      type: user
    createdAt: '2023-10-05T03:24:11.000Z'
    data:
      edited: false
      editors:
      - codegood
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8392952084541321
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14c0faec86334a15d040ef3219f7a63f.svg
          fullname: Stephan
          isHf: false
          isPro: false
          name: codegood
          type: user
        html: '<p>Can this model be used for QA task and if yes, what should the prompt
          look like?</p>

          '
        raw: "Can this model be used for QA task and if yes, what should the prompt\
          \ look like?\r\n\r\n"
        updatedAt: '2023-10-05T03:24:11.576Z'
      numEdits: 0
      reactions: []
    id: 651e2c5bb9b33dc240c1e0d5
    type: comment
  author: codegood
  content: "Can this model be used for QA task and if yes, what should the prompt\
    \ look like?\r\n\r\n"
  created_at: 2023-10-05 02:24:11+00:00
  edited: false
  hidden: false
  id: 651e2c5bb9b33dc240c1e0d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658503618672-noauth.jpeg?w=200&h=200&f=face
      fullname: lerela
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lerela
      type: user
    createdAt: '2023-10-05T09:44:33.000Z'
    data:
      edited: false
      editors:
      - lerela
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5600032806396484
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1658503618672-noauth.jpeg?w=200&h=200&f=face
          fullname: lerela
          isHf: false
          isPro: false
          name: lerela
          type: user
        html: '<p>You need the Instruct version for that: <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1">https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1</a></p>

          <p>Prompt is documented here: <a rel="nofollow" href="https://docs.mistral.ai/llm/mistral-instruct-v0.1#chat-template">https://docs.mistral.ai/llm/mistral-instruct-v0.1#chat-template</a></p>

          '
        raw: 'You need the Instruct version for that: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1


          Prompt is documented here: https://docs.mistral.ai/llm/mistral-instruct-v0.1#chat-template'
        updatedAt: '2023-10-05T09:44:33.322Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - KrishnaKaasyap
    id: 651e85819ba9e96d54ebdd0b
    type: comment
  author: lerela
  content: 'You need the Instruct version for that: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1


    Prompt is documented here: https://docs.mistral.ai/llm/mistral-instruct-v0.1#chat-template'
  created_at: 2023-10-05 08:44:33+00:00
  edited: false
  hidden: false
  id: 651e85819ba9e96d54ebdd0b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28f196d2613db3e381b9f242636a9e9b.svg
      fullname: Danek Maximov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DanekBigLike
      type: user
    createdAt: '2023-10-05T14:37:29.000Z'
    data:
      edited: false
      editors:
      - DanekBigLike
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9243965148925781
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28f196d2613db3e381b9f242636a9e9b.svg
          fullname: Danek Maximov
          isHf: false
          isPro: false
          name: DanekBigLike
          type: user
        html: '<p>Is it possible to further train the model (LoRa or Checkpoint) and
          how? (Sorry if this is a stupid question, I''m still a newbie)</p>

          '
        raw: Is it possible to further train the model (LoRa or Checkpoint) and how?
          (Sorry if this is a stupid question, I'm still a newbie)
        updatedAt: '2023-10-05T14:37:29.232Z'
      numEdits: 0
      reactions: []
    id: 651eca29fb2de4bf4b18071c
    type: comment
  author: DanekBigLike
  content: Is it possible to further train the model (LoRa or Checkpoint) and how?
    (Sorry if this is a stupid question, I'm still a newbie)
  created_at: 2023-10-05 13:37:29+00:00
  edited: false
  hidden: false
  id: 651eca29fb2de4bf4b18071c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-10-05T14:46:57.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9328886866569519
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>not an expert but ooba offers in-GUI lora training </p>

          '
        raw: 'not an expert but ooba offers in-GUI lora training '
        updatedAt: '2023-10-05T14:46:57.452Z'
      numEdits: 0
      reactions: []
    id: 651ecc61063e54a50ca24ecb
    type: comment
  author: Nurb432
  content: 'not an expert but ooba offers in-GUI lora training '
  created_at: 2023-10-05 13:46:57+00:00
  edited: false
  hidden: false
  id: 651ecc61063e54a50ca24ecb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28f196d2613db3e381b9f242636a9e9b.svg
      fullname: Danek Maximov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DanekBigLike
      type: user
    createdAt: '2023-10-05T15:40:30.000Z'
    data:
      edited: true
      editors:
      - DanekBigLike
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9847151637077332
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28f196d2613db3e381b9f242636a9e9b.svg
          fullname: Danek Maximov
          isHf: false
          isPro: false
          name: DanekBigLike
          type: user
        html: '<p>Do ooba of them support Mistral?</p>

          '
        raw: Do ooba of them support Mistral?
        updatedAt: '2023-10-05T15:41:24.932Z'
      numEdits: 1
      reactions: []
    id: 651ed8eec2f92699e28cb4dd
    type: comment
  author: DanekBigLike
  content: Do ooba of them support Mistral?
  created_at: 2023-10-05 14:40:30+00:00
  edited: true
  hidden: false
  id: 651ed8eec2f92699e28cb4dd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28f196d2613db3e381b9f242636a9e9b.svg
      fullname: Danek Maximov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DanekBigLike
      type: user
    createdAt: '2023-10-05T16:03:36.000Z'
    data:
      edited: false
      editors:
      - DanekBigLike
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.26302680373191833
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28f196d2613db3e381b9f242636a9e9b.svg
          fullname: Danek Maximov
          isHf: false
          isPro: false
          name: DanekBigLike
          type: user
        html: '<p>If I try to run through text generation web, I get this error:</p>

          <p>Traceback (most recent call last):<br>  File "E:\ai\ruai\saiga\text-generation-webui\modules\ui_model_menu.py",
          line 194, in load_model_wrapper<br>    shared.model, shared.tokenizer =
          load_model(shared.model_name, loader)<br>  File "E:\ai\ruai\saiga\text-generation-webui\modules\models.py",
          line 75, in load_model<br>    output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>  File
          "E:\ai\ruai\saiga\text-generation-webui\modules\models.py", line 136, in
          huggingface_loader<br>    config = AutoConfig.from_pretrained(path_to_model,
          trust_remote_code=shared.args.trust_remote_code)<br>  File "C:\Users\remot.conda\envs\textgen2\lib\site-packages\transformers\models\auto\configuration_auto.py",
          line 1039, in from_pretrained<br>    config_class = CONFIG_MAPPING[config_dict["model_type"]]<br>  File
          "C:\Users\remot.conda\envs\textgen2\lib\site-packages\transformers\models\auto\configuration_auto.py",
          line 734, in <strong>getitem</strong><br>    raise KeyError(key)<br>KeyError:
          ''mistral''</p>

          '
        raw: "If I try to run through text generation web, I get this error:\n\nTraceback\
          \ (most recent call last):\n  File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\\
          modules\\ui_model_menu.py\", line 194, in load_model_wrapper\n    shared.model,\
          \ shared.tokenizer = load_model(shared.model_name, loader)\n  File \"E:\\\
          ai\\ruai\\saiga\\text-generation-webui\\modules\\models.py\", line 75, in\
          \ load_model\n    output = load_func_map[loader](model_name)\n  File \"\
          E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\models.py\", line 136,\
          \ in huggingface_loader\n    config = AutoConfig.from_pretrained(path_to_model,\
          \ trust_remote_code=shared.args.trust_remote_code)\n  File \"C:\\Users\\\
          remot\\.conda\\envs\\textgen2\\lib\\site-packages\\transformers\\models\\\
          auto\\configuration_auto.py\", line 1039, in from_pretrained\n    config_class\
          \ = CONFIG_MAPPING[config_dict[\"model_type\"]]\n  File \"C:\\Users\\remot\\\
          .conda\\envs\\textgen2\\lib\\site-packages\\transformers\\models\\auto\\\
          configuration_auto.py\", line 734, in __getitem__\n    raise KeyError(key)\n\
          KeyError: 'mistral'"
        updatedAt: '2023-10-05T16:03:36.625Z'
      numEdits: 0
      reactions: []
    id: 651ede58063e54a50ca4d94d
    type: comment
  author: DanekBigLike
  content: "If I try to run through text generation web, I get this error:\n\nTraceback\
    \ (most recent call last):\n  File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\\
    modules\\ui_model_menu.py\", line 194, in load_model_wrapper\n    shared.model,\
    \ shared.tokenizer = load_model(shared.model_name, loader)\n  File \"E:\\ai\\\
    ruai\\saiga\\text-generation-webui\\modules\\models.py\", line 75, in load_model\n\
    \    output = load_func_map[loader](model_name)\n  File \"E:\\ai\\ruai\\saiga\\\
    text-generation-webui\\modules\\models.py\", line 136, in huggingface_loader\n\
    \    config = AutoConfig.from_pretrained(path_to_model, trust_remote_code=shared.args.trust_remote_code)\n\
    \  File \"C:\\Users\\remot\\.conda\\envs\\textgen2\\lib\\site-packages\\transformers\\\
    models\\auto\\configuration_auto.py\", line 1039, in from_pretrained\n    config_class\
    \ = CONFIG_MAPPING[config_dict[\"model_type\"]]\n  File \"C:\\Users\\remot\\.conda\\\
    envs\\textgen2\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\"\
    , line 734, in __getitem__\n    raise KeyError(key)\nKeyError: 'mistral'"
  created_at: 2023-10-05 15:03:36+00:00
  edited: false
  hidden: false
  id: 651ede58063e54a50ca4d94d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-10-05T16:10:25.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9244096279144287
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>For what its worth, I can run mistral converted to gguf on ooba
          just fine on CPU.   Cant say about ''regular'' model. My GPU is dedicated
          for other uses.</p>

          '
        raw: 'For what its worth, I can run mistral converted to gguf on ooba just
          fine on CPU.   Cant say about ''regular'' model. My GPU is dedicated for
          other uses.

          '
        updatedAt: '2023-10-05T16:10:25.782Z'
      numEdits: 0
      reactions: []
    id: 651edff1dbf879b8c579259e
    type: comment
  author: Nurb432
  content: 'For what its worth, I can run mistral converted to gguf on ooba just fine
    on CPU.   Cant say about ''regular'' model. My GPU is dedicated for other uses.

    '
  created_at: 2023-10-05 15:10:25+00:00
  edited: false
  hidden: false
  id: 651edff1dbf879b8c579259e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d38fcaa72d9f9cb04ba8e7f72211e34.svg
      fullname: Bohan Du
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: acrastt
      type: user
    createdAt: '2023-10-06T04:29:40.000Z'
    data:
      edited: false
      editors:
      - acrastt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.30085062980651855
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d38fcaa72d9f9cb04ba8e7f72211e34.svg
          fullname: Bohan Du
          isHf: false
          isPro: false
          name: acrastt
          type: user
        html: '<blockquote>

          <p>If I try to run through text generation web, I get this error:</p>

          <p>Traceback (most recent call last):<br>  File "E:\ai\ruai\saiga\text-generation-webui\modules\ui_model_menu.py",
          line 194, in load_model_wrapper<br>    shared.model, shared.tokenizer =
          load_model(shared.model_name, loader)<br>  File "E:\ai\ruai\saiga\text-generation-webui\modules\models.py",
          line 75, in load_model<br>    output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>  File
          "E:\ai\ruai\saiga\text-generation-webui\modules\models.py", line 136, in
          huggingface_loader<br>    config = AutoConfig.from_pretrained(path_to_model,
          trust_remote_code=shared.args.trust_remote_code)<br>  File "C:\Users\remot.conda\envs\textgen2\lib\site-packages\transformers\models\auto\configuration_auto.py",
          line 1039, in from_pretrained<br>    config_class = CONFIG_MAPPING[config_dict["model_type"]]<br>  File
          "C:\Users\remot.conda\envs\textgen2\lib\site-packages\transformers\models\auto\configuration_auto.py",
          line 734, in <strong>getitem</strong><br>    raise KeyError(key)<br>KeyError:
          ''mistral''</p>

          </blockquote>

          <p>Can you try re-downloading Transformers from Github?</p>

          '
        raw: "> If I try to run through text generation web, I get this error:\n>\
          \ \n> Traceback (most recent call last):\n>   File \"E:\\ai\\ruai\\saiga\\\
          text-generation-webui\\modules\\ui_model_menu.py\", line 194, in load_model_wrapper\n\
          >     shared.model, shared.tokenizer = load_model(shared.model_name, loader)\n\
          >   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\models.py\"\
          , line 75, in load_model\n>     output = load_func_map[loader](model_name)\n\
          >   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\models.py\"\
          , line 136, in huggingface_loader\n>     config = AutoConfig.from_pretrained(path_to_model,\
          \ trust_remote_code=shared.args.trust_remote_code)\n>   File \"C:\\Users\\\
          remot\\.conda\\envs\\textgen2\\lib\\site-packages\\transformers\\models\\\
          auto\\configuration_auto.py\", line 1039, in from_pretrained\n>     config_class\
          \ = CONFIG_MAPPING[config_dict[\"model_type\"]]\n>   File \"C:\\Users\\\
          remot\\.conda\\envs\\textgen2\\lib\\site-packages\\transformers\\models\\\
          auto\\configuration_auto.py\", line 734, in __getitem__\n>     raise KeyError(key)\n\
          > KeyError: 'mistral'\n\nCan you try re-downloading Transformers from Github?"
        updatedAt: '2023-10-06T04:29:40.746Z'
      numEdits: 0
      reactions: []
    id: 651f8d34755e92f7f13e610c
    type: comment
  author: acrastt
  content: "> If I try to run through text generation web, I get this error:\n> \n\
    > Traceback (most recent call last):\n>   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\\
    modules\\ui_model_menu.py\", line 194, in load_model_wrapper\n>     shared.model,\
    \ shared.tokenizer = load_model(shared.model_name, loader)\n>   File \"E:\\ai\\\
    ruai\\saiga\\text-generation-webui\\modules\\models.py\", line 75, in load_model\n\
    >     output = load_func_map[loader](model_name)\n>   File \"E:\\ai\\ruai\\saiga\\\
    text-generation-webui\\modules\\models.py\", line 136, in huggingface_loader\n\
    >     config = AutoConfig.from_pretrained(path_to_model, trust_remote_code=shared.args.trust_remote_code)\n\
    >   File \"C:\\Users\\remot\\.conda\\envs\\textgen2\\lib\\site-packages\\transformers\\\
    models\\auto\\configuration_auto.py\", line 1039, in from_pretrained\n>     config_class\
    \ = CONFIG_MAPPING[config_dict[\"model_type\"]]\n>   File \"C:\\Users\\remot\\\
    .conda\\envs\\textgen2\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\"\
    , line 734, in __getitem__\n>     raise KeyError(key)\n> KeyError: 'mistral'\n\
    \nCan you try re-downloading Transformers from Github?"
  created_at: 2023-10-06 03:29:40+00:00
  edited: false
  hidden: false
  id: 651f8d34755e92f7f13e610c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28f196d2613db3e381b9f242636a9e9b.svg
      fullname: Danek Maximov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DanekBigLike
      type: user
    createdAt: '2023-10-06T20:14:07.000Z'
    data:
      edited: false
      editors:
      - DanekBigLike
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.41849464178085327
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28f196d2613db3e381b9f242636a9e9b.svg
          fullname: Danek Maximov
          isHf: false
          isPro: false
          name: DanekBigLike
          type: user
        html: '<blockquote>

          <blockquote>

          <p>If I try to run through text generation web, I get this error:</p>

          <p>Traceback (most recent call last):<br>  File "E:\ai\ruai\saiga\text-generation-webui\modules\ui_model_menu.py",
          line 194, in load_model_wrapper<br>    shared.model, shared.tokenizer =
          load_model(shared.model_name, loader)<br>  File "E:\ai\ruai\saiga\text-generation-webui\modules\models.py",
          line 75, in load_model<br>    output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>  File
          "E:\ai\ruai\saiga\text-generation-webui\modules\models.py", line 136, in
          huggingface_loader<br>    config = AutoConfig.from_pretrained(path_to_model,
          trust_remote_code=shared.args.trust_remote_code)<br>  File "C:\Users\remot.conda\envs\textgen2\lib\site-packages\transformers\models\auto\configuration_auto.py",
          line 1039, in from_pretrained<br>    config_class = CONFIG_MAPPING[config_dict["model_type"]]<br>  File
          "C:\Users\remot.conda\envs\textgen2\lib\site-packages\transformers\models\auto\configuration_auto.py",
          line 734, in <strong>getitem</strong><br>    raise KeyError(key)<br>KeyError:
          ''mistral''</p>

          </blockquote>

          <p>Can you try re-downloading Transformers from Github?</p>

          </blockquote>

          <p>I''ll try, thanks. (Do you mean that Mistral is using a new version of
          the transformer? If not, it probably won''t work, since Llama starts without
          problems)</p>

          '
        raw: "> > If I try to run through text generation web, I get this error:\n\
          > > \n> > Traceback (most recent call last):\n> >   File \"E:\\ai\\ruai\\\
          saiga\\text-generation-webui\\modules\\ui_model_menu.py\", line 194, in\
          \ load_model_wrapper\n> >     shared.model, shared.tokenizer = load_model(shared.model_name,\
          \ loader)\n> >   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\\
          models.py\", line 75, in load_model\n> >     output = load_func_map[loader](model_name)\n\
          > >   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\models.py\"\
          , line 136, in huggingface_loader\n> >     config = AutoConfig.from_pretrained(path_to_model,\
          \ trust_remote_code=shared.args.trust_remote_code)\n> >   File \"C:\\Users\\\
          remot\\.conda\\envs\\textgen2\\lib\\site-packages\\transformers\\models\\\
          auto\\configuration_auto.py\", line 1039, in from_pretrained\n> >     config_class\
          \ = CONFIG_MAPPING[config_dict[\"model_type\"]]\n> >   File \"C:\\Users\\\
          remot\\.conda\\envs\\textgen2\\lib\\site-packages\\transformers\\models\\\
          auto\\configuration_auto.py\", line 734, in __getitem__\n> >     raise KeyError(key)\n\
          > > KeyError: 'mistral'\n> \n> Can you try re-downloading Transformers from\
          \ Github?\n\nI'll try, thanks. (Do you mean that Mistral is using a new\
          \ version of the transformer? If not, it probably won't work, since Llama\
          \ starts without problems)"
        updatedAt: '2023-10-06T20:14:07.064Z'
      numEdits: 0
      reactions: []
    id: 65206a8f974423bd3ead57ce
    type: comment
  author: DanekBigLike
  content: "> > If I try to run through text generation web, I get this error:\n>\
    \ > \n> > Traceback (most recent call last):\n> >   File \"E:\\ai\\ruai\\saiga\\\
    text-generation-webui\\modules\\ui_model_menu.py\", line 194, in load_model_wrapper\n\
    > >     shared.model, shared.tokenizer = load_model(shared.model_name, loader)\n\
    > >   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\models.py\"\
    , line 75, in load_model\n> >     output = load_func_map[loader](model_name)\n\
    > >   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\models.py\"\
    , line 136, in huggingface_loader\n> >     config = AutoConfig.from_pretrained(path_to_model,\
    \ trust_remote_code=shared.args.trust_remote_code)\n> >   File \"C:\\Users\\remot\\\
    .conda\\envs\\textgen2\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\"\
    , line 1039, in from_pretrained\n> >     config_class = CONFIG_MAPPING[config_dict[\"\
    model_type\"]]\n> >   File \"C:\\Users\\remot\\.conda\\envs\\textgen2\\lib\\site-packages\\\
    transformers\\models\\auto\\configuration_auto.py\", line 734, in __getitem__\n\
    > >     raise KeyError(key)\n> > KeyError: 'mistral'\n> \n> Can you try re-downloading\
    \ Transformers from Github?\n\nI'll try, thanks. (Do you mean that Mistral is\
    \ using a new version of the transformer? If not, it probably won't work, since\
    \ Llama starts without problems)"
  created_at: 2023-10-06 19:14:07+00:00
  edited: false
  hidden: false
  id: 65206a8f974423bd3ead57ce
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d38fcaa72d9f9cb04ba8e7f72211e34.svg
      fullname: Bohan Du
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: acrastt
      type: user
    createdAt: '2023-10-06T23:58:46.000Z'
    data:
      edited: false
      editors:
      - acrastt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4058064818382263
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d38fcaa72d9f9cb04ba8e7f72211e34.svg
          fullname: Bohan Du
          isHf: false
          isPro: false
          name: acrastt
          type: user
        html: '<blockquote>

          <blockquote>

          <blockquote>

          <p>If I try to run through text generation web, I get this error:</p>

          <p>Traceback (most recent call last):<br>  File "E:\ai\ruai\saiga\text-generation-webui\modules\ui_model_menu.py",
          line 194, in load_model_wrapper<br>    shared.model, shared.tokenizer =
          load_model(shared.model_name, loader)<br>  File "E:\ai\ruai\saiga\text-generation-webui\modules\models.py",
          line 75, in load_model<br>    output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>  File
          "E:\ai\ruai\saiga\text-generation-webui\modules\models.py", line 136, in
          huggingface_loader<br>    config = AutoConfig.from_pretrained(path_to_model,
          trust_remote_code=shared.args.trust_remote_code)<br>  File "C:\Users\remot.conda\envs\textgen2\lib\site-packages\transformers\models\auto\configuration_auto.py",
          line 1039, in from_pretrained<br>    config_class = CONFIG_MAPPING[config_dict["model_type"]]<br>  File
          "C:\Users\remot.conda\envs\textgen2\lib\site-packages\transformers\models\auto\configuration_auto.py",
          line 734, in <strong>getitem</strong><br>    raise KeyError(key)<br>KeyError:
          ''mistral''</p>

          </blockquote>

          <p>Can you try re-downloading Transformers from Github?</p>

          </blockquote>

          <p>I''ll try, thanks. (Do you mean that Mistral is using a new version of
          the transformer? If not, it probably won''t work, since Llama starts without
          problems)<br>Yeah.</p>

          </blockquote>

          '
        raw: "> > > If I try to run through text generation web, I get this error:\n\
          > > > \n> > > Traceback (most recent call last):\n> > >   File \"E:\\ai\\\
          ruai\\saiga\\text-generation-webui\\modules\\ui_model_menu.py\", line 194,\
          \ in load_model_wrapper\n> > >     shared.model, shared.tokenizer = load_model(shared.model_name,\
          \ loader)\n> > >   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\\
          models.py\", line 75, in load_model\n> > >     output = load_func_map[loader](model_name)\n\
          > > >   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\models.py\"\
          , line 136, in huggingface_loader\n> > >     config = AutoConfig.from_pretrained(path_to_model,\
          \ trust_remote_code=shared.args.trust_remote_code)\n> > >   File \"C:\\\
          Users\\remot\\.conda\\envs\\textgen2\\lib\\site-packages\\transformers\\\
          models\\auto\\configuration_auto.py\", line 1039, in from_pretrained\n>\
          \ > >     config_class = CONFIG_MAPPING[config_dict[\"model_type\"]]\n>\
          \ > >   File \"C:\\Users\\remot\\.conda\\envs\\textgen2\\lib\\site-packages\\\
          transformers\\models\\auto\\configuration_auto.py\", line 734, in __getitem__\n\
          > > >     raise KeyError(key)\n> > > KeyError: 'mistral'\n> > \n> > Can\
          \ you try re-downloading Transformers from Github?\n> \n> I'll try, thanks.\
          \ (Do you mean that Mistral is using a new version of the transformer? If\
          \ not, it probably won't work, since Llama starts without problems)\nYeah."
        updatedAt: '2023-10-06T23:58:46.156Z'
      numEdits: 0
      reactions: []
    id: 65209f360d3a8171bd83c844
    type: comment
  author: acrastt
  content: "> > > If I try to run through text generation web, I get this error:\n\
    > > > \n> > > Traceback (most recent call last):\n> > >   File \"E:\\ai\\ruai\\\
    saiga\\text-generation-webui\\modules\\ui_model_menu.py\", line 194, in load_model_wrapper\n\
    > > >     shared.model, shared.tokenizer = load_model(shared.model_name, loader)\n\
    > > >   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\models.py\"\
    , line 75, in load_model\n> > >     output = load_func_map[loader](model_name)\n\
    > > >   File \"E:\\ai\\ruai\\saiga\\text-generation-webui\\modules\\models.py\"\
    , line 136, in huggingface_loader\n> > >     config = AutoConfig.from_pretrained(path_to_model,\
    \ trust_remote_code=shared.args.trust_remote_code)\n> > >   File \"C:\\Users\\\
    remot\\.conda\\envs\\textgen2\\lib\\site-packages\\transformers\\models\\auto\\\
    configuration_auto.py\", line 1039, in from_pretrained\n> > >     config_class\
    \ = CONFIG_MAPPING[config_dict[\"model_type\"]]\n> > >   File \"C:\\Users\\remot\\\
    .conda\\envs\\textgen2\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\"\
    , line 734, in __getitem__\n> > >     raise KeyError(key)\n> > > KeyError: 'mistral'\n\
    > > \n> > Can you try re-downloading Transformers from Github?\n> \n> I'll try,\
    \ thanks. (Do you mean that Mistral is using a new version of the transformer?\
    \ If not, it probably won't work, since Llama starts without problems)\nYeah."
  created_at: 2023-10-06 22:58:46+00:00
  edited: false
  hidden: false
  id: 65209f360d3a8171bd83c844
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 39
repo_id: mistralai/Mistral-7B-v0.1
repo_type: model
status: open
target_branch: null
title: Question answering
