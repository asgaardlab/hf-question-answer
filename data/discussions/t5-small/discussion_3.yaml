!!python/object:huggingface_hub.community.DiscussionWithDetails
author: NikGC
conflicting_files: null
created_at: 2022-10-08 14:17:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4a24f190ae6601e7f181294a4195e3fa.svg
      fullname: Nik C
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NikGC
      type: user
    createdAt: '2022-10-08T15:17:38.000Z'
    data:
      edited: false
      editors:
      - NikGC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4a24f190ae6601e7f181294a4195e3fa.svg
          fullname: Nik C
          isHf: false
          isPro: false
          name: NikGC
          type: user
        html: '<p>Please help with the following error. I am a student and trying
          to run this model in Visual Studio Code and getting this error. No idea
          how to fix it. </p>

          <p>FutureWarning: This tokenizer was incorrectly instantiated with a model
          max length of 512 which will be corrected in Transformers v5.<br>For now,
          this behavior is kept to avoid breaking backwards compatibility when padding/encoding
          with <code>truncation is True</code>.</p>

          <ul>

          <li>Be aware that you SHOULD NOT rely on t5-small automatically truncating
          your input to 512 when padding/encoding.</li>

          <li>If you want to encode/pad to sequences longer than 512 you can either
          instantiate this tokenizer with <code>model_max_length</code> or pass <code>max_length</code>
          when encoding/padding.</li>

          <li>To avoid this warning, please instantiate this tokenizer with <code>model_max_length</code>
          set to your preferred value.<br>warnings.warn(</li>

          </ul>

          '
        raw: "Please help with the following error. I am a student and trying to run\
          \ this model in Visual Studio Code and getting this error. No idea how to\
          \ fix it. \r\n\r\nFutureWarning: This tokenizer was incorrectly instantiated\
          \ with a model max length of 512 which will be corrected in Transformers\
          \ v5.\r\nFor now, this behavior is kept to avoid breaking backwards compatibility\
          \ when padding/encoding with `truncation is True`.\r\n- Be aware that you\
          \ SHOULD NOT rely on t5-small automatically truncating your input to 512\
          \ when padding/encoding.\r\n- If you want to encode/pad to sequences longer\
          \ than 512 you can either instantiate this tokenizer with `model_max_length`\
          \ or pass `max_length` when encoding/padding.\r\n- To avoid this warning,\
          \ please instantiate this tokenizer with `model_max_length` set to your\
          \ preferred value.\r\n  warnings.warn("
        updatedAt: '2022-10-08T15:17:38.360Z'
      numEdits: 0
      reactions: []
    id: 6341949265e26459e0b2d2be
    type: comment
  author: NikGC
  content: "Please help with the following error. I am a student and trying to run\
    \ this model in Visual Studio Code and getting this error. No idea how to fix\
    \ it. \r\n\r\nFutureWarning: This tokenizer was incorrectly instantiated with\
    \ a model max length of 512 which will be corrected in Transformers v5.\r\nFor\
    \ now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding\
    \ with `truncation is True`.\r\n- Be aware that you SHOULD NOT rely on t5-small\
    \ automatically truncating your input to 512 when padding/encoding.\r\n- If you\
    \ want to encode/pad to sequences longer than 512 you can either instantiate this\
    \ tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\r\
    \n- To avoid this warning, please instantiate this tokenizer with `model_max_length`\
    \ set to your preferred value.\r\n  warnings.warn("
  created_at: 2022-10-08 14:17:38+00:00
  edited: false
  hidden: false
  id: 6341949265e26459e0b2d2be
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8fa2548533742eab81a92050e20b76a5.svg
      fullname: li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: adopemind
      type: user
    createdAt: '2022-10-22T10:19:08.000Z'
    data:
      edited: false
      editors:
      - adopemind
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8fa2548533742eab81a92050e20b76a5.svg
          fullname: li
          isHf: false
          isPro: false
          name: adopemind
          type: user
        html: '<p>from transformers import AutoTokenizer<br>    tokenizer = AutoTokenizer.from_pretrained("t5-small",model_max_length=512)#
          just do it</p>

          '
        raw: "from transformers import AutoTokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\"\
          t5-small\",model_max_length=512)# just do it"
        updatedAt: '2022-10-22T10:19:08.794Z'
      numEdits: 0
      reactions: []
    id: 6353c39c43577a0f5421eab4
    type: comment
  author: adopemind
  content: "from transformers import AutoTokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\"\
    t5-small\",model_max_length=512)# just do it"
  created_at: 2022-10-22 09:19:08+00:00
  edited: false
  hidden: false
  id: 6353c39c43577a0f5421eab4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: t5-small
repo_type: model
status: open
target_branch: null
title: '`model_max_length` set to your preferred value.'
