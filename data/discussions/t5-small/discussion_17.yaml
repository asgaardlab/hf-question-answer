!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AayushShah
conflicting_files: null
created_at: 2023-09-06 10:50:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
      fullname: AayushShah
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AayushShah
      type: user
    createdAt: '2023-09-06T11:50:41.000Z'
    data:
      edited: true
      editors:
      - AayushShah
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9529386758804321
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
          fullname: AayushShah
          isHf: false
          isPro: false
          name: AayushShah
          type: user
        html: "<p>I am glad that the community has exported the \"ONNX\" files for\
          \ this model. I came to know that I will have to seperately use the \"encoder_model.onnx\"\
          \ and \"decoder_model.onnx\" to make a successful forward pass.</p>\n<p>I\
          \ am unable to find any proper guide to run an inferance through such encoder-decoder\
          \ model using <code>onnxruntime</code> library.<br>Can anyone please help\
          \ me through this? </p>\n<h2 id=\"\U0001F3AF-objective\">\U0001F3AF Objective</h2>\n\
          <p>My objective is to <strong>summarize</strong> the given text. I am not\
          \ sure how to perform a successful inference. In the past I have worked\
          \ with onnxruntime with GPT2 but that is causal LM model and here it is\
          \ different.</p>\n<p><em>(I am totally fine if you could provide a code\
          \ in Java/Python)</em></p>\n<p>I would highly appreciate your help \U0001F64F\
          \U0001F3FB<br>Thank you so much.</p>\n"
        raw: "I am glad that the community has exported the \"ONNX\" files for this\
          \ model. I came to know that I will have to seperately use the \"encoder_model.onnx\"\
          \ and \"decoder_model.onnx\" to make a successful forward pass.\n\nI am\
          \ unable to find any proper guide to run an inferance through such encoder-decoder\
          \ model using `onnxruntime` library.\nCan anyone please help me through\
          \ this? \n\n## \U0001F3AF Objective\nMy objective is to **summarize** the\
          \ given text. I am not sure how to perform a successful inference. In the\
          \ past I have worked with onnxruntime with GPT2 but that is causal LM model\
          \ and here it is different.\n\n*(I am totally fine if you could provide\
          \ a code in Java/Python)*\n\nI would highly appreciate your help \U0001F64F\
          \U0001F3FB\nThank you so much."
        updatedAt: '2023-09-06T12:02:08.600Z'
      numEdits: 1
      reactions: []
    id: 64f8679120ca770b6eae57e0
    type: comment
  author: AayushShah
  content: "I am glad that the community has exported the \"ONNX\" files for this\
    \ model. I came to know that I will have to seperately use the \"encoder_model.onnx\"\
    \ and \"decoder_model.onnx\" to make a successful forward pass.\n\nI am unable\
    \ to find any proper guide to run an inferance through such encoder-decoder model\
    \ using `onnxruntime` library.\nCan anyone please help me through this? \n\n##\
    \ \U0001F3AF Objective\nMy objective is to **summarize** the given text. I am\
    \ not sure how to perform a successful inference. In the past I have worked with\
    \ onnxruntime with GPT2 but that is causal LM model and here it is different.\n\
    \n*(I am totally fine if you could provide a code in Java/Python)*\n\nI would\
    \ highly appreciate your help \U0001F64F\U0001F3FB\nThank you so much."
  created_at: 2023-09-06 10:50:41+00:00
  edited: true
  hidden: false
  id: 64f8679120ca770b6eae57e0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2023-09-06T19:54:51.000Z'
    data:
      edited: false
      editors:
      - lysandre
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9455208778381348
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;AayushShah&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/AayushShah\"\
          >@<span class=\"underline\">AayushShah</span></a></span>\n\n\t</span></span>,\
          \ I think this question might be better suited for the <a rel=\"nofollow\"\
          \ href=\"https://github.com/huggingface/optimum/issues\">optimum issues</a>\
          \ as not linked to t5</p>\n"
        raw: Hey @AayushShah, I think this question might be better suited for the
          [optimum issues](https://github.com/huggingface/optimum/issues) as not linked
          to t5
        updatedAt: '2023-09-06T19:54:51.673Z'
      numEdits: 0
      reactions: []
    id: 64f8d90b54d0fd40d8114c79
    type: comment
  author: lysandre
  content: Hey @AayushShah, I think this question might be better suited for the [optimum
    issues](https://github.com/huggingface/optimum/issues) as not linked to t5
  created_at: 2023-09-06 18:54:51+00:00
  edited: false
  hidden: false
  id: 64f8d90b54d0fd40d8114c79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
      fullname: AayushShah
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AayushShah
      type: user
    createdAt: '2023-09-07T04:36:53.000Z'
    data:
      edited: false
      editors:
      - AayushShah
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5840851068496704
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
          fullname: AayushShah
          isHf: false
          isPro: false
          name: AayushShah
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;lysandre&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/lysandre\">@<span class=\"\
          underline\">lysandre</span></a></span>\n\n\t</span></span> you are right\
          \ mate, apologies \U0001F64F\U0001F609</p>\n"
        raw: "@lysandre you are right mate, apologies \U0001F64F\U0001F609"
        updatedAt: '2023-09-07T04:36:53.305Z'
      numEdits: 0
      reactions: []
    id: 64f95365a92703ef65147666
    type: comment
  author: AayushShah
  content: "@lysandre you are right mate, apologies \U0001F64F\U0001F609"
  created_at: 2023-09-07 03:36:53+00:00
  edited: false
  hidden: false
  id: 64f95365a92703ef65147666
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1651743336129-624c60cba8ec93a7ac188b56.png?w=200&h=200&f=face
      fullname: "F\xE9lix Marty"
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: fxmarty
      type: user
    createdAt: '2023-09-11T12:08:48.000Z'
    data:
      edited: false
      editors:
      - fxmarty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5583393573760986
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1651743336129-624c60cba8ec93a7ac188b56.png?w=200&h=200&f=face
          fullname: "F\xE9lix Marty"
          isHf: true
          isPro: false
          name: fxmarty
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;AayushShah&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/AayushShah\"\
          >@<span class=\"underline\">AayushShah</span></a></span>\n\n\t</span></span>,\
          \ <a href=\"https://huggingface.co/docs/optimum/main/en/index\">Optimum\
          \ library</a> has a <code>ORTModelForSeq2SeqLM</code> class that leverages\
          \ ONNX Runtime and may be relevant to you:<br><a href=\"https://huggingface.co/docs/optimum/main/en/onnxruntime/usage_guides/models#sequencetosequence-models\"\
          >https://huggingface.co/docs/optimum/main/en/onnxruntime/usage_guides/models#sequencetosequence-models</a><br><a\
          \ href=\"https://huggingface.co/docs/optimum/main/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTModelForSeq2SeqLM\"\
          >https://huggingface.co/docs/optimum/main/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTModelForSeq2SeqLM</a></p>\n"
        raw: 'Hi @AayushShah, [Optimum library](https://huggingface.co/docs/optimum/main/en/index)
          has a `ORTModelForSeq2SeqLM` class that leverages ONNX Runtime and may be
          relevant to you:

          https://huggingface.co/docs/optimum/main/en/onnxruntime/usage_guides/models#sequencetosequence-models

          https://huggingface.co/docs/optimum/main/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTModelForSeq2SeqLM'
        updatedAt: '2023-09-11T12:08:48.924Z'
      numEdits: 0
      reactions: []
    id: 64ff0350ed03a2a237d64605
    type: comment
  author: fxmarty
  content: 'Hi @AayushShah, [Optimum library](https://huggingface.co/docs/optimum/main/en/index)
    has a `ORTModelForSeq2SeqLM` class that leverages ONNX Runtime and may be relevant
    to you:

    https://huggingface.co/docs/optimum/main/en/onnxruntime/usage_guides/models#sequencetosequence-models

    https://huggingface.co/docs/optimum/main/en/onnxruntime/package_reference/modeling_ort#optimum.onnxruntime.ORTModelForSeq2SeqLM'
  created_at: 2023-09-11 11:08:48+00:00
  edited: false
  hidden: false
  id: 64ff0350ed03a2a237d64605
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 17
repo_id: t5-small
repo_type: model
status: open
target_branch: null
title: Can I get the script to run an inference through T5 ONNX using `onnxruntime`?
