!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rishihazra
conflicting_files: null
created_at: 2022-10-24 20:06:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4b68612a3f8bdbddc54323455977950b.svg
      fullname: Rishi Hazra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rishihazra
      type: user
    createdAt: '2022-10-24T21:06:26.000Z'
    data:
      edited: true
      editors:
      - rishihazra
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4b68612a3f8bdbddc54323455977950b.svg
          fullname: Rishi Hazra
          isHf: false
          isPro: false
          name: rishihazra
          type: user
        html: '<p>Hi,</p>

          <p>I intend to fine-tune the t5 model with a custom loss function (REINFORCE)
          since I do not have access to the immediate decoder outputs. Instead, I''d
          be using the decoder output for another downstream task which generates
          the pipeline non-differentiable. As such, I''m trying to find out how efficient
          it is to train using REINFORCE by using the probability of output generation:
          P(decoder_output). Is there a way to obtain the output generation logits
          for greedy decoding, something like:  </p>

          <pre><code class="language-python">model.generate(input_ids).logits

          </code></pre>

          <p>I tried to set output_scores = True, but that didn''t work. On a different
          note, I could generate the output and use it alongside the input to get  the
          logits using</p>

          <pre><code class="language-python">output_ids = model.generate(input_ids)

          model(input_ids, output_ids).logits

          </code></pre>

          <p>However, I think this might output incorrect probabilities owing to the
          teacher forcing. Is that correct?</p>

          <p>Thanks !</p>

          '
        raw: "Hi,\n\nI intend to fine-tune the t5 model with a custom loss function\
          \ (REINFORCE) since I do not have access to the immediate decoder outputs.\
          \ Instead, I'd be using the decoder output for another downstream task which\
          \ generates the pipeline non-differentiable. As such, I'm trying to find\
          \ out how efficient it is to train using REINFORCE by using the probability\
          \ of output generation: P(decoder_output). Is there a way to obtain the\
          \ output generation logits for greedy decoding, something like:  \n```python\n\
          model.generate(input_ids).logits\n```\nI tried to set output_scores = True,\
          \ but that didn't work. On a different note, I could generate the output\
          \ and use it alongside the input to get  the logits using\n```python\noutput_ids\
          \ = model.generate(input_ids)\nmodel(input_ids, output_ids).logits\n```\n\
          However, I think this might output incorrect probabilities owing to the\
          \ teacher forcing. Is that correct?\n\nThanks !"
        updatedAt: '2022-10-24T21:33:17.084Z'
      numEdits: 1
      reactions: []
    id: 6356fe529e266741a8d10bea
    type: comment
  author: rishihazra
  content: "Hi,\n\nI intend to fine-tune the t5 model with a custom loss function\
    \ (REINFORCE) since I do not have access to the immediate decoder outputs. Instead,\
    \ I'd be using the decoder output for another downstream task which generates\
    \ the pipeline non-differentiable. As such, I'm trying to find out how efficient\
    \ it is to train using REINFORCE by using the probability of output generation:\
    \ P(decoder_output). Is there a way to obtain the output generation logits for\
    \ greedy decoding, something like:  \n```python\nmodel.generate(input_ids).logits\n\
    ```\nI tried to set output_scores = True, but that didn't work. On a different\
    \ note, I could generate the output and use it alongside the input to get  the\
    \ logits using\n```python\noutput_ids = model.generate(input_ids)\nmodel(input_ids,\
    \ output_ids).logits\n```\nHowever, I think this might output incorrect probabilities\
    \ owing to the teacher forcing. Is that correct?\n\nThanks !"
  created_at: 2022-10-24 20:06:26+00:00
  edited: true
  hidden: false
  id: 6356fe529e266741a8d10bea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/4b68612a3f8bdbddc54323455977950b.svg
      fullname: Rishi Hazra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rishihazra
      type: user
    createdAt: '2022-10-24T21:33:56.000Z'
    data:
      from: logits for model.generate()
      to: scores for model.generate()
    id: 635704c4a6d00e9b0ed72a2e
    type: title-change
  author: rishihazra
  created_at: 2022-10-24 20:33:56+00:00
  id: 635704c4a6d00e9b0ed72a2e
  new_title: scores for model.generate()
  old_title: logits for model.generate()
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/4b68612a3f8bdbddc54323455977950b.svg
      fullname: Rishi Hazra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rishihazra
      type: user
    createdAt: '2022-10-24T21:34:17.000Z'
    data:
      status: closed
    id: 635704d9cf1cf1f5e5c04cdc
    type: status-change
  author: rishihazra
  created_at: 2022-10-24 20:34:17+00:00
  id: 635704d9cf1cf1f5e5c04cdc
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/4b68612a3f8bdbddc54323455977950b.svg
      fullname: Rishi Hazra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rishihazra
      type: user
    createdAt: '2022-10-24T21:34:28.000Z'
    data:
      status: open
    id: 635704e4d11d85992dfe4cdd
    type: status-change
  author: rishihazra
  created_at: 2022-10-24 20:34:28+00:00
  id: 635704e4d11d85992dfe4cdd
  new_status: open
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: t5-small
repo_type: model
status: open
target_branch: null
title: scores for model.generate()
