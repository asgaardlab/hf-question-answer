!!python/object:huggingface_hub.community.DiscussionWithDetails
author: halsayed
conflicting_files: null
created_at: 2023-11-16 16:52:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a15ef25be097d466f52f0fa8d0fb3846.svg
      fullname: Husain Ebrahim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: halsayed
      type: user
    createdAt: '2023-11-16T16:52:13.000Z'
    data:
      edited: false
      editors:
      - halsayed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8974125981330872
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a15ef25be097d466f52f0fa8d0fb3846.svg
          fullname: Husain Ebrahim
          isHf: false
          isPro: false
          name: halsayed
          type: user
        html: '<p>Hi Core42 team,</p>

          <p>Thanks for creating this opensource arabic model. I tested the model
          based on the provided example on the model card and I got very slow performance.
          I''m using A100 80GB, so I would expect a much better performance than the
          results shown on the image below. is this correct?</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/631ae8f93d2766182dac42fb/vWuhSG7lkpc4bqmOmHUf2.png"><img
          alt="jais_performance.png" src="https://cdn-uploads.huggingface.co/production/uploads/631ae8f93d2766182dac42fb/vWuhSG7lkpc4bqmOmHUf2.png"></a></p>

          '
        raw: "Hi Core42 team,\r\n\r\nThanks for creating this opensource arabic model.\
          \ I tested the model based on the provided example on the model card and\
          \ I got very slow performance. I'm using A100 80GB, so I would expect a\
          \ much better performance than the results shown on the image below. is\
          \ this correct?\r\n\r\n\r\n![jais_performance.png](https://cdn-uploads.huggingface.co/production/uploads/631ae8f93d2766182dac42fb/vWuhSG7lkpc4bqmOmHUf2.png)\r\
          \n"
        updatedAt: '2023-11-16T16:52:13.808Z'
      numEdits: 0
      reactions: []
    id: 655648bdb4b2833e078f8631
    type: comment
  author: halsayed
  content: "Hi Core42 team,\r\n\r\nThanks for creating this opensource arabic model.\
    \ I tested the model based on the provided example on the model card and I got\
    \ very slow performance. I'm using A100 80GB, so I would expect a much better\
    \ performance than the results shown on the image below. is this correct?\r\n\r\
    \n\r\n![jais_performance.png](https://cdn-uploads.huggingface.co/production/uploads/631ae8f93d2766182dac42fb/vWuhSG7lkpc4bqmOmHUf2.png)\r\
    \n"
  created_at: 2023-11-16 16:52:13+00:00
  edited: false
  hidden: false
  id: 655648bdb4b2833e078f8631
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9b3b2d12ad3e1959aacfefbb931986dd.svg
      fullname: samta kamboj
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: samta-kamboj
      type: user
    createdAt: '2023-11-17T05:59:18.000Z'
    data:
      edited: false
      editors:
      - samta-kamboj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8641694188117981
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9b3b2d12ad3e1959aacfefbb931986dd.svg
          fullname: samta kamboj
          isHf: false
          isPro: false
          name: samta-kamboj
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;halsayed&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/halsayed\">@<span class=\"\
          underline\">halsayed</span></a></span>\n\n\t</span></span> Thanks for using\
          \ Jais. You may get better inference speed using 2 x A100 80GB GPUs as the\
          \ model size is ~(30x4)GB and all layers of the model could fit on 2 GPUs.</p>\n"
        raw: '@halsayed Thanks for using Jais. You may get better inference speed
          using 2 x A100 80GB GPUs as the model size is ~(30x4)GB and all layers of
          the model could fit on 2 GPUs.'
        updatedAt: '2023-11-17T05:59:18.302Z'
      numEdits: 0
      reactions: []
    id: 65570136c7c44ce359025854
    type: comment
  author: samta-kamboj
  content: '@halsayed Thanks for using Jais. You may get better inference speed using
    2 x A100 80GB GPUs as the model size is ~(30x4)GB and all layers of the model
    could fit on 2 GPUs.'
  created_at: 2023-11-17 05:59:18+00:00
  edited: false
  hidden: false
  id: 65570136c7c44ce359025854
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a15ef25be097d466f52f0fa8d0fb3846.svg
      fullname: Husain Ebrahim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: halsayed
      type: user
    createdAt: '2023-11-17T17:20:13.000Z'
    data:
      edited: false
      editors:
      - halsayed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7976484298706055
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a15ef25be097d466f52f0fa8d0fb3846.svg
          fullname: Husain Ebrahim
          isHf: false
          isPro: false
          name: halsayed
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;samta-kamboj&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/samta-kamboj\"\
          >@<span class=\"underline\">samta-kamboj</span></a></span>\n\n\t</span></span>\
          \ thanks, increasing GPU solved the problem. Was there any attempt to quantize\
          \ the model and reduce the vram footprint?</p>\n"
        raw: '@samta-kamboj thanks, increasing GPU solved the problem. Was there any
          attempt to quantize the model and reduce the vram footprint?'
        updatedAt: '2023-11-17T17:20:13.163Z'
      numEdits: 0
      reactions: []
    id: 6557a0cd48c3a02fed79a030
    type: comment
  author: halsayed
  content: '@samta-kamboj thanks, increasing GPU solved the problem. Was there any
    attempt to quantize the model and reduce the vram footprint?'
  created_at: 2023-11-17 17:20:13+00:00
  edited: false
  hidden: false
  id: 6557a0cd48c3a02fed79a030
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: core42/jais-30b-chat-v1
repo_type: model
status: open
target_branch: null
title: Model inference speed  ....
