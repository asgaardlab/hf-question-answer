!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Infinity4B
conflicting_files: null
created_at: 2023-09-03 09:53:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c25b2610eb58139cfac86e8fa2611f01.svg
      fullname: Xi Wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Infinity4B
      type: user
    createdAt: '2023-09-03T10:53:50.000Z'
    data:
      edited: false
      editors:
      - Infinity4B
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5048040151596069
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c25b2610eb58139cfac86e8fa2611f01.svg
          fullname: Xi Wang
          isHf: false
          isPro: false
          name: Infinity4B
          type: user
        html: '<p>Hi, I am trying to recover pygmalion-7b checkpoints, and I use the
          llama checkpoints in <a href="https://huggingface.co/nyanko7/LLaMA-7B/tree/main">https://huggingface.co/nyanko7/LLaMA-7B/tree/main</a>.
          I use tools from transformers 4.32.1 to convert the llama into huggingface
          format. However, after this, I run the xor_codec.py, but cannot get the
          same rhash. The result is:<br>4608facb4910118f8dfa80f090cbc4dc  config.json<br>2917a1cafb895cf57e746cfd7696bfe5  generation_config.json<br>7c1a3308e53852f3480ea70ded180460  pytorch_model-00001-of-00002.bin<br>6a5100ef132c7c4ec0b4bf1716870357  pytorch_model-00002-of-00002.bin<br>81648ef3915ed2e83d49fed93122d53e  pytorch_model.bin.index.json<br>6b2e0a735969660e720c27061ef3f3d3  special_tokens_map.json<br>9b3cf7b8c0e4783dbc1419b4cafe8e1e  tokenizer_config.json<br>fdb311c39b8659a5d5c1991339bafc09  tokenizer.json<br>eeec4125e9c7560836b4873b6f8e3025  tokenizer.model<br>I
          make sure the sha256sum of checkpoints of the llama-7b and the xor_encoded_files
          are correct.<br>Could you explain why I can''t get the correct model?</p>

          '
        raw: "Hi, I am trying to recover pygmalion-7b checkpoints, and I use the llama\
          \ checkpoints in https://huggingface.co/nyanko7/LLaMA-7B/tree/main. I use\
          \ tools from transformers 4.32.1 to convert the llama into huggingface format.\
          \ However, after this, I run the xor_codec.py, but cannot get the same rhash.\
          \ The result is:\r\n4608facb4910118f8dfa80f090cbc4dc  config.json\r\n2917a1cafb895cf57e746cfd7696bfe5\
          \  generation_config.json\r\n7c1a3308e53852f3480ea70ded180460  pytorch_model-00001-of-00002.bin\r\
          \n6a5100ef132c7c4ec0b4bf1716870357  pytorch_model-00002-of-00002.bin\r\n\
          81648ef3915ed2e83d49fed93122d53e  pytorch_model.bin.index.json\r\n6b2e0a735969660e720c27061ef3f3d3\
          \  special_tokens_map.json\r\n9b3cf7b8c0e4783dbc1419b4cafe8e1e  tokenizer_config.json\r\
          \nfdb311c39b8659a5d5c1991339bafc09  tokenizer.json\r\neeec4125e9c7560836b4873b6f8e3025\
          \  tokenizer.model\r\nI make sure the sha256sum of checkpoints of the llama-7b\
          \ and the xor_encoded_files are correct.\r\nCould you explain why I can't\
          \ get the correct model?"
        updatedAt: '2023-09-03T10:53:50.696Z'
      numEdits: 0
      reactions: []
    id: 64f465becc9886db80a4928f
    type: comment
  author: Infinity4B
  content: "Hi, I am trying to recover pygmalion-7b checkpoints, and I use the llama\
    \ checkpoints in https://huggingface.co/nyanko7/LLaMA-7B/tree/main. I use tools\
    \ from transformers 4.32.1 to convert the llama into huggingface format. However,\
    \ after this, I run the xor_codec.py, but cannot get the same rhash. The result\
    \ is:\r\n4608facb4910118f8dfa80f090cbc4dc  config.json\r\n2917a1cafb895cf57e746cfd7696bfe5\
    \  generation_config.json\r\n7c1a3308e53852f3480ea70ded180460  pytorch_model-00001-of-00002.bin\r\
    \n6a5100ef132c7c4ec0b4bf1716870357  pytorch_model-00002-of-00002.bin\r\n81648ef3915ed2e83d49fed93122d53e\
    \  pytorch_model.bin.index.json\r\n6b2e0a735969660e720c27061ef3f3d3  special_tokens_map.json\r\
    \n9b3cf7b8c0e4783dbc1419b4cafe8e1e  tokenizer_config.json\r\nfdb311c39b8659a5d5c1991339bafc09\
    \  tokenizer.json\r\neeec4125e9c7560836b4873b6f8e3025  tokenizer.model\r\nI make\
    \ sure the sha256sum of checkpoints of the llama-7b and the xor_encoded_files\
    \ are correct.\r\nCould you explain why I can't get the correct model?"
  created_at: 2023-09-03 09:53:50+00:00
  edited: false
  hidden: false
  id: 64f465becc9886db80a4928f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: PygmalionAI/pygmalion-7b
repo_type: model
status: open
target_branch: null
title: Unable to recover checkpoints in applying the XORs
