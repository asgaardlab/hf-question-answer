!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TingchenFu
conflicting_files: null
created_at: 2023-04-08 02:11:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3c8589b68a942b4afd54df2ae4b96336.svg
      fullname: Tingchen Fu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TingchenFu
      type: user
    createdAt: '2023-04-08T03:11:15.000Z'
    data:
      edited: false
      editors:
      - TingchenFu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3c8589b68a942b4afd54df2ae4b96336.svg
          fullname: Tingchen Fu
          isHf: false
          isPro: false
          name: TingchenFu
          type: user
        html: '<p>According to the BLOOM paper BLOOM: A 176B-Parameter Open-Access
          Multilingual Language Model, all bloom model was trained with a sequence
          length of 2048, but why the n_embed is only 1024 in config.json?</p>

          '
        raw: 'According to the BLOOM paper BLOOM: A 176B-Parameter Open-Access Multilingual
          Language Model, all bloom model was trained with a sequence length of 2048,
          but why the n_embed is only 1024 in config.json?'
        updatedAt: '2023-04-08T03:11:15.993Z'
      numEdits: 0
      reactions: []
    id: 6430db5332a732121cd9495c
    type: comment
  author: TingchenFu
  content: 'According to the BLOOM paper BLOOM: A 176B-Parameter Open-Access Multilingual
    Language Model, all bloom model was trained with a sequence length of 2048, but
    why the n_embed is only 1024 in config.json?'
  created_at: 2023-04-08 02:11:15+00:00
  edited: false
  hidden: false
  id: 6430db5332a732121cd9495c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
      fullname: Christopher Akiki
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: cakiki
      type: user
    createdAt: '2023-04-11T09:07:25.000Z'
    data:
      edited: false
      editors:
      - cakiki
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
          fullname: Christopher Akiki
          isHf: false
          isPro: false
          name: cakiki
          type: user
        html: '<p>2048 is the hidden dimension, not the sequence size. That same parameter
          is 14336 for the full-sized model: <a href="https://huggingface.co/bigscience/bloom/blob/main/config.json#L16">https://huggingface.co/bigscience/bloom/blob/main/config.json#L16</a></p>

          '
        raw: '2048 is the hidden dimension, not the sequence size. That same parameter
          is 14336 for the full-sized model: https://huggingface.co/bigscience/bloom/blob/main/config.json#L16'
        updatedAt: '2023-04-11T09:07:25.029Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6435234de60b21004eca478b
    id: 6435234de60b21004eca478a
    type: comment
  author: cakiki
  content: '2048 is the hidden dimension, not the sequence size. That same parameter
    is 14336 for the full-sized model: https://huggingface.co/bigscience/bloom/blob/main/config.json#L16'
  created_at: 2023-04-11 08:07:25+00:00
  edited: false
  hidden: false
  id: 6435234de60b21004eca478a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
      fullname: Christopher Akiki
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: cakiki
      type: user
    createdAt: '2023-04-11T09:07:25.000Z'
    data:
      status: closed
    id: 6435234de60b21004eca478b
    type: status-change
  author: cakiki
  created_at: 2023-04-11 08:07:25+00:00
  id: 6435234de60b21004eca478b
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: bigscience/bloomz-560m
repo_type: model
status: closed
target_branch: null
title: In config.json we only have n_embed=1024 while BLOOM was trained with a sequence
  length of 2048.
