!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hiyouga
conflicting_files: []
created_at: 2023-12-29 09:29:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642fef28a043f0ac7defa8a9/RwOEkuj3fOnOA54tGR7Ea.png?w=200&h=200&f=face
      fullname: hoshi hiyouga
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hiyouga
      type: user
    createdAt: '2023-12-29T09:29:52.000Z'
    data:
      edited: true
      editors:
      - hiyouga
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642fef28a043f0ac7defa8a9/RwOEkuj3fOnOA54tGR7Ea.png?w=200&h=200&f=face
          fullname: hoshi hiyouga
          isHf: false
          isPro: false
          name: hiyouga
          type: user
        html: "<h3 id=\"reproduce\">Reproduce</h3>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> AutoTokenizer\ntok = AutoTokenizer.from_pretrained(<span\
          \ class=\"hljs-string\">\"THUDM/chatglm3-6b\"</span>, trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>)\ntok.save_pretrained(<span class=\"\
          hljs-string\">\"original\"</span>)\n<span class=\"hljs-comment\"># ('original/tokenizer_config.json',\
          \ 'original/special_tokens_map.json', 'original/tokenizer.model', 'original/added_tokens.json')</span>\n\
          tok = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"original\"\
          </span>, trust_remote_code=<span class=\"hljs-literal\">True</span>)\n</code></pre>\n\
          <p>It throws</p>\n<pre><code>Traceback (most recent call last):\n  File\
          \ \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 774, in from_pretrained\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\n  File \"/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2028, in from_pretrained\n    return cls._from_pretrained(\n  File\
          \ \"/site-packages/transformers/tokenization_utils_base.py\", line 2260,\
          \ in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \  File \"huggingface/modules/transformers_modules/original/tokenization_chatglm.py\"\
          , line 108, in __init__\n    super().__init__(padding_side=padding_side,\
          \ clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n  File \"\
          /site-packages/transformers/tokenization_utils.py\", line 363, in __init__\n\
          \    super().__init__(**kwargs)\n  File \"/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1602, in __init__\n    super().__init__(**kwargs)\n  File \"/site-packages/transformers/tokenization_utils_base.py\"\
          , line 861, in __init__\n    setattr(self, key, value)\nAttributeError:\
          \ can't set attribute 'eos_token'\n</code></pre>\n<h3 id=\"after-fix\">After\
          \ fix</h3>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer\n\
          tok = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"THUDM/chatglm3-6b\"\
          </span>, trust_remote_code=<span class=\"hljs-literal\">True</span>)\ntok.save_pretrained(<span\
          \ class=\"hljs-string\">\"new\"</span>)\n<span class=\"hljs-comment\">#\
          \ ('new/tokenizer_config.json', 'new/special_tokens_map.json', 'new/tokenizer.model',\
          \ 'new/added_tokens.json')</span>\ntok = AutoTokenizer.from_pretrained(<span\
          \ class=\"hljs-string\">\"new\"</span>, trust_remote_code=<span class=\"\
          hljs-literal\">True</span>)\n</code></pre>\n<p>The tokenizer can be correctly\
          \ loaded while spitting out the following info.</p>\n<pre><code>Setting\
          \ eos_token is not supported, use the default one.\nSetting pad_token is\
          \ not supported, use the default one.\nSetting unk_token is not supported,\
          \ use the default one.\n</code></pre>\n"
        raw: "### Reproduce\n\n```python\nfrom transformers import AutoTokenizer\n\
          tok = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\", trust_remote_code=True)\n\
          tok.save_pretrained(\"original\")\n# ('original/tokenizer_config.json',\
          \ 'original/special_tokens_map.json', 'original/tokenizer.model', 'original/added_tokens.json')\n\
          tok = AutoTokenizer.from_pretrained(\"original\", trust_remote_code=True)\n\
          ```\n\nIt throws\n\n```\nTraceback (most recent call last):\n  File \"<stdin>\"\
          , line 1, in <module>\n  File \"/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 774, in from_pretrained\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\n  File \"/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2028, in from_pretrained\n    return cls._from_pretrained(\n  File\
          \ \"/site-packages/transformers/tokenization_utils_base.py\", line 2260,\
          \ in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \  File \"huggingface/modules/transformers_modules/original/tokenization_chatglm.py\"\
          , line 108, in __init__\n    super().__init__(padding_side=padding_side,\
          \ clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n  File \"\
          /site-packages/transformers/tokenization_utils.py\", line 363, in __init__\n\
          \    super().__init__(**kwargs)\n  File \"/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1602, in __init__\n    super().__init__(**kwargs)\n  File \"/site-packages/transformers/tokenization_utils_base.py\"\
          , line 861, in __init__\n    setattr(self, key, value)\nAttributeError:\
          \ can't set attribute 'eos_token'\n```\n\n### After fix\n\n```python\nfrom\
          \ transformers import AutoTokenizer\ntok = AutoTokenizer.from_pretrained(\"\
          THUDM/chatglm3-6b\", trust_remote_code=True)\ntok.save_pretrained(\"new\"\
          )\n# ('new/tokenizer_config.json', 'new/special_tokens_map.json', 'new/tokenizer.model',\
          \ 'new/added_tokens.json')\ntok = AutoTokenizer.from_pretrained(\"new\"\
          , trust_remote_code=True)\n```\n\nThe tokenizer can be correctly loaded\
          \ while spitting out the following info.\n\n```\nSetting eos_token is not\
          \ supported, use the default one.\nSetting pad_token is not supported, use\
          \ the default one.\nSetting unk_token is not supported, use the default\
          \ one.\n```"
        updatedAt: '2023-12-29T09:50:59.831Z'
      numEdits: 3
      reactions: []
    id: 658e919057a556fbe161a465
    type: comment
  author: hiyouga
  content: "### Reproduce\n\n```python\nfrom transformers import AutoTokenizer\ntok\
    \ = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\", trust_remote_code=True)\n\
    tok.save_pretrained(\"original\")\n# ('original/tokenizer_config.json', 'original/special_tokens_map.json',\
    \ 'original/tokenizer.model', 'original/added_tokens.json')\ntok = AutoTokenizer.from_pretrained(\"\
    original\", trust_remote_code=True)\n```\n\nIt throws\n\n```\nTraceback (most\
    \ recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/site-packages/transformers/models/auto/tokenization_auto.py\"\
    , line 774, in from_pretrained\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\n  File \"/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2028, in from_pretrained\n    return cls._from_pretrained(\n  File \"/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2260, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
    \  File \"huggingface/modules/transformers_modules/original/tokenization_chatglm.py\"\
    , line 108, in __init__\n    super().__init__(padding_side=padding_side, clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n\
    \  File \"/site-packages/transformers/tokenization_utils.py\", line 363, in __init__\n\
    \    super().__init__(**kwargs)\n  File \"/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1602, in __init__\n    super().__init__(**kwargs)\n  File \"/site-packages/transformers/tokenization_utils_base.py\"\
    , line 861, in __init__\n    setattr(self, key, value)\nAttributeError: can't\
    \ set attribute 'eos_token'\n```\n\n### After fix\n\n```python\nfrom transformers\
    \ import AutoTokenizer\ntok = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\"\
    , trust_remote_code=True)\ntok.save_pretrained(\"new\")\n# ('new/tokenizer_config.json',\
    \ 'new/special_tokens_map.json', 'new/tokenizer.model', 'new/added_tokens.json')\n\
    tok = AutoTokenizer.from_pretrained(\"new\", trust_remote_code=True)\n```\n\n\
    The tokenizer can be correctly loaded while spitting out the following info.\n\
    \n```\nSetting eos_token is not supported, use the default one.\nSetting pad_token\
    \ is not supported, use the default one.\nSetting unk_token is not supported,\
    \ use the default one.\n```"
  created_at: 2023-12-29 09:29:52+00:00
  edited: true
  hidden: false
  id: 658e919057a556fbe161a465
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642fef28a043f0ac7defa8a9/RwOEkuj3fOnOA54tGR7Ea.png?w=200&h=200&f=face
      fullname: hoshi hiyouga
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hiyouga
      type: user
    createdAt: '2023-12-29T09:29:53.000Z'
    data:
      oid: 72e7f646bc14c58534be3abd4001116bf20c18cc
      parents:
      - 456aa875cf1f46623006edaa23103774ea9c0eae
      subject: fix can't set attribute 'eos_token' when loading the saved tokenizer
    id: 658e91910000000000000000
    type: commit
  author: hiyouga
  created_at: 2023-12-29 09:29:53+00:00
  id: 658e91910000000000000000
  oid: 72e7f646bc14c58534be3abd4001116bf20c18cc
  summary: fix can't set attribute 'eos_token' when loading the saved tokenizer
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/RQJQZouD-Qnt70k0dVjHU.png?w=200&h=200&f=face
      fullname: Yuxuan Zhang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: zRzRzRzRzRzRzR
      type: user
    createdAt: '2023-12-29T12:07:43.000Z'
    data:
      status: merged
    id: 658eb68ff5a209eeacc97ccc
    type: status-change
  author: zRzRzRzRzRzRzR
  created_at: 2023-12-29 12:07:43+00:00
  id: 658eb68ff5a209eeacc97ccc
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 6d10497ab99fa606ad954e2530106dd8ec361fe0
num: 27
repo_id: THUDM/chatglm3-6b
repo_type: model
status: merged
target_branch: refs/heads/main
title: fix can't set attribute 'eos_token' when loading the saved tokenizer
