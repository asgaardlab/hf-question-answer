!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kornpow
conflicting_files: null
created_at: 2024-01-24 00:00:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c2f901da3bea1bdde0dab664a79b42d0.svg
      fullname: kp
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kornpow
      type: user
    createdAt: '2024-01-24T00:00:49.000Z'
    data:
      edited: false
      editors:
      - kornpow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9216894507408142
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c2f901da3bea1bdde0dab664a79b42d0.svg
          fullname: kp
          isHf: false
          isPro: false
          name: kornpow
          type: user
        html: '<p>As I have been working with this model, I have learned that it isn''t
          necessarily magic and you don''t get the amazing results from the documentation
          without a lot of hard work.</p>

          <p>There are a lot of factors:<br>The size of the <code>init_image</code>.
          You could possibly resize your input images to yield interesting results.<br>The
          <code>init_image</code> itself. There are better or worse ones.<br>The various
          configuration knobs, like <code>guidance_scale</code>, <code>controlnet_conditioning_scale</code>,
          <code>strength</code>, and <code>num_inference_steps</code>.</p>

          <p>It would be really great if your examples could be expanded to show the
          raw input images (qr code + style image ), the prompt, and the settings
          used, to generate the output image. Your example code uses images which
          are in S3, which are unavailable for the public to view.</p>

          <p>In the same vain, it seems to me like this is best for blending the two
          input images together, I have yet to see how the prompt really improves
          things, so potentially examples could help there.</p>

          '
        raw: "As I have been working with this model, I have learned that it isn't\
          \ necessarily magic and you don't get the amazing results from the documentation\
          \ without a lot of hard work.\r\n\r\nThere are a lot of factors:\r\nThe\
          \ size of the `init_image`. You could possibly resize your input images\
          \ to yield interesting results.\r\nThe `init_image` itself. There are better\
          \ or worse ones.\r\nThe various configuration knobs, like `guidance_scale`,\
          \ `controlnet_conditioning_scale`, `strength`, and `num_inference_steps`.\r\
          \n\r\nIt would be really great if your examples could be expanded to show\
          \ the raw input images (qr code + style image ), the prompt, and the settings\
          \ used, to generate the output image. Your example code uses images which\
          \ are in S3, which are unavailable for the public to view.\r\n\r\nIn the\
          \ same vain, it seems to me like this is best for blending the two input\
          \ images together, I have yet to see how the prompt really improves things,\
          \ so potentially examples could help there."
        updatedAt: '2024-01-24T00:00:49.886Z'
      numEdits: 0
      reactions: []
    id: 65b05331b233ea8ce639690a
    type: comment
  author: kornpow
  content: "As I have been working with this model, I have learned that it isn't necessarily\
    \ magic and you don't get the amazing results from the documentation without a\
    \ lot of hard work.\r\n\r\nThere are a lot of factors:\r\nThe size of the `init_image`.\
    \ You could possibly resize your input images to yield interesting results.\r\n\
    The `init_image` itself. There are better or worse ones.\r\nThe various configuration\
    \ knobs, like `guidance_scale`, `controlnet_conditioning_scale`, `strength`, and\
    \ `num_inference_steps`.\r\n\r\nIt would be really great if your examples could\
    \ be expanded to show the raw input images (qr code + style image ), the prompt,\
    \ and the settings used, to generate the output image. Your example code uses\
    \ images which are in S3, which are unavailable for the public to view.\r\n\r\n\
    In the same vain, it seems to me like this is best for blending the two input\
    \ images together, I have yet to see how the prompt really improves things, so\
    \ potentially examples could help there."
  created_at: 2024-01-24 00:00:49+00:00
  edited: false
  hidden: false
  id: 65b05331b233ea8ce639690a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 42
repo_id: DionTimmer/controlnet_qrcode
repo_type: model
status: open
target_branch: null
title: Input images + output examples
