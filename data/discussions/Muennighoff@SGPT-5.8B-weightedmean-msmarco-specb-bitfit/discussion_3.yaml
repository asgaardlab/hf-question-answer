!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KnutJaegersberg
conflicting_files: null
created_at: 2023-07-15 07:30:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-07-15T08:30:25.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8710487484931946
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>Is it possible to use your procedure to make sentence embeddings
          from the new open source llms?<br>SGPT and sentence-t5 were long sota embeddings.<br>Take
          one of the better, new llms.<br>With 4 bit quantization, can one create
          like sota mpt-30b sentence embeddings that run on consumer hardware? </p>

          '
        raw: "Is it possible to use your procedure to make sentence embeddings from\
          \ the new open source llms? \r\nSGPT and sentence-t5 were long sota embeddings.\
          \ \r\nTake one of the better, new llms. \r\nWith 4 bit quantization, can\
          \ one create like sota mpt-30b sentence embeddings that run on consumer\
          \ hardware? "
        updatedAt: '2023-07-15T08:30:25.423Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Muennighoff
    id: 64b25921849c9e54e091c8d1
    type: comment
  author: KnutJaegersberg
  content: "Is it possible to use your procedure to make sentence embeddings from\
    \ the new open source llms? \r\nSGPT and sentence-t5 were long sota embeddings.\
    \ \r\nTake one of the better, new llms. \r\nWith 4 bit quantization, can one create\
    \ like sota mpt-30b sentence embeddings that run on consumer hardware? "
  created_at: 2023-07-15 07:30:25+00:00
  edited: false
  hidden: false
  id: 64b25921849c9e54e091c8d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2023-07-15T10:25:56.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9530641436576843
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: "<p>Yeah it's a great idea &amp; i've been waiting for a bigger OSS\
          \ LLM to arrive to do just that; As many use cases for embeddings are commercial\
          \ it has to be an OSS one like you said, i.e. not llama</p>\n<p>MPT-30B\
          \ or Falcon seem like good candidates, but I think it's worth waiting for\
          \ <a rel=\"nofollow\" href=\"https://www.mosaicml.com/blog/introducing-ai2-olmo\"\
          >https://www.mosaicml.com/blog/introducing-ai2-olmo</a> \U0001F9D0</p>\n"
        raw: "Yeah it's a great idea & i've been waiting for a bigger OSS LLM to arrive\
          \ to do just that; As many use cases for embeddings are commercial it has\
          \ to be an OSS one like you said, i.e. not llama\n\nMPT-30B or Falcon seem\
          \ like good candidates, but I think it's worth waiting for https://www.mosaicml.com/blog/introducing-ai2-olmo\
          \ \U0001F9D0"
        updatedAt: '2023-07-15T10:25:56.120Z'
      numEdits: 0
      reactions: []
    id: 64b27434ce290f8e9a833621
    type: comment
  author: Muennighoff
  content: "Yeah it's a great idea & i've been waiting for a bigger OSS LLM to arrive\
    \ to do just that; As many use cases for embeddings are commercial it has to be\
    \ an OSS one like you said, i.e. not llama\n\nMPT-30B or Falcon seem like good\
    \ candidates, but I think it's worth waiting for https://www.mosaicml.com/blog/introducing-ai2-olmo\
    \ \U0001F9D0"
  created_at: 2023-07-15 09:25:56+00:00
  edited: false
  hidden: false
  id: 64b27434ce290f8e9a833621
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-07-15T13:44:26.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.939454972743988
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>Interesting, but arriving early 2024. That''s waiting half a year,
          an eternity in this space. Then again, I guess it is relatively costly to
          produce sgpt embeddings the larger the model gets, right? </p>

          '
        raw: 'Interesting, but arriving early 2024. That''s waiting half a year, an
          eternity in this space. Then again, I guess it is relatively costly to produce
          sgpt embeddings the larger the model gets, right? '
        updatedAt: '2023-07-15T13:44:26.021Z'
      numEdits: 0
      reactions: []
    id: 64b2a2ba28fd98e7cce9230d
    type: comment
  author: KnutJaegersberg
  content: 'Interesting, but arriving early 2024. That''s waiting half a year, an
    eternity in this space. Then again, I guess it is relatively costly to produce
    sgpt embeddings the larger the model gets, right? '
  created_at: 2023-07-15 12:44:26+00:00
  edited: false
  hidden: false
  id: 64b2a2ba28fd98e7cce9230d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2023-07-15T19:57:51.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9360286593437195
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: "<p>True it's quite far off \U0001F605</p>\n<p>Yeah the larger the model\
          \ the more expensive - I think it may be worth adding a linear layer at\
          \ the end to downscale the embedding size to e.g. 2048 for those very large\
          \ models</p>\n"
        raw: "True it's quite far off \U0001F605\n\nYeah the larger the model the\
          \ more expensive - I think it may be worth adding a linear layer at the\
          \ end to downscale the embedding size to e.g. 2048 for those very large\
          \ models"
        updatedAt: '2023-07-15T19:57:51.354Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - KnutJaegersberg
    id: 64b2fa3f35c2e9909c50816b
    type: comment
  author: Muennighoff
  content: "True it's quite far off \U0001F605\n\nYeah the larger the model the more\
    \ expensive - I think it may be worth adding a linear layer at the end to downscale\
    \ the embedding size to e.g. 2048 for those very large models"
  created_at: 2023-07-15 18:57:51+00:00
  edited: false
  hidden: false
  id: 64b2fa3f35c2e9909c50816b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-07-15T20:40:16.000Z'
    data:
      status: closed
    id: 64b30430689a9a23014107c4
    type: status-change
  author: KnutJaegersberg
  created_at: 2023-07-15 19:40:16+00:00
  id: 64b30430689a9a23014107c4
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Muennighoff/SGPT-5.8B-weightedmean-msmarco-specb-bitfit
repo_type: model
status: closed
target_branch: null
title: 'open llama sgpt? '
