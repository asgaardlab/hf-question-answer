!!python/object:huggingface_hub.community.DiscussionWithDetails
author: appliedstuff
conflicting_files: null
created_at: 2023-07-28 12:47:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/beabf70201af07b24a5fa5681b44a6f6.svg
      fullname: PK
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: appliedstuff
      type: user
    createdAt: '2023-07-28T13:47:38.000Z'
    data:
      edited: false
      editors:
      - appliedstuff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9514302611351013
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/beabf70201af07b24a5fa5681b44a6f6.svg
          fullname: PK
          isHf: false
          isPro: false
          name: appliedstuff
          type: user
        html: '<p>Hi,<br>I just checked the data set you used for the german adapation.
          I just found training examples that are either in German or English language.
          Is that the way one makes them understand another language (i.e. german)?</p>

          <p>Do you have some background knowledge how you come up with your approach
          and reasoning how you decide what data to use and how you want make the
          model usable in german?</p>

          <p>Do you checked the quality? Any metrics to measure your results?</p>

          '
        raw: "Hi,\r\nI just checked the data set you used for the german adapation.\
          \ I just found training examples that are either in German or English language.\
          \ Is that the way one makes them understand another language (i.e. german)?\r\
          \n\r\nDo you have some background knowledge how you come up with your approach\
          \ and reasoning how you decide what data to use and how you want make the\
          \ model usable in german?\r\n\r\nDo you checked the quality? Any metrics\
          \ to measure your results?"
        updatedAt: '2023-07-28T13:47:38.779Z'
      numEdits: 0
      reactions: []
    id: 64c3c6fad68946edad477a64
    type: comment
  author: appliedstuff
  content: "Hi,\r\nI just checked the data set you used for the german adapation.\
    \ I just found training examples that are either in German or English language.\
    \ Is that the way one makes them understand another language (i.e. german)?\r\n\
    \r\nDo you have some background knowledge how you come up with your approach and\
    \ reasoning how you decide what data to use and how you want make the model usable\
    \ in german?\r\n\r\nDo you checked the quality? Any metrics to measure your results?"
  created_at: 2023-07-28 12:47:38+00:00
  edited: false
  hidden: false
  id: 64c3c6fad68946edad477a64
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654892015542-605b1cf890a4b6bc0eef99ad.jpeg?w=200&h=200&f=face
      fullname: Florian Zimmermeister
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: flozi00
      type: user
    createdAt: '2023-07-28T17:57:06.000Z'
    data:
      edited: false
      editors:
      - flozi00
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9490016102790833
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654892015542-605b1cf890a4b6bc0eef99ad.jpeg?w=200&h=200&f=face
          fullname: Florian Zimmermeister
          isHf: false
          isPro: false
          name: flozi00
          type: user
        html: '<p>I am always improving the dataset and continuing training more and
          more models.<br>So for example I already reached eval losses of less than
          0.2<br>Since I am focused on German the largest part of this dataset is
          German.<br>If you want to have special use cases to support 2 languages
          in same quality I would either add translation prompts (translate x to y)
          between these languages or translate each entry into both languages so each
          entry is doubled but in seperate langs.</p>

          '
        raw: "I am always improving the dataset and continuing training more and more\
          \ models.\nSo for example I already reached eval losses of less than 0.2\
          \ \nSince I am focused on German the largest part of this dataset is German.\n\
          If you want to have special use cases to support 2 languages in same quality\
          \ I would either add translation prompts (translate x to y) between these\
          \ languages or translate each entry into both languages so each entry is\
          \ doubled but in seperate langs."
        updatedAt: '2023-07-28T17:57:06.919Z'
      numEdits: 0
      reactions: []
    id: 64c40172bf1103bae846e23c
    type: comment
  author: flozi00
  content: "I am always improving the dataset and continuing training more and more\
    \ models.\nSo for example I already reached eval losses of less than 0.2 \nSince\
    \ I am focused on German the largest part of this dataset is German.\nIf you want\
    \ to have special use cases to support 2 languages in same quality I would either\
    \ add translation prompts (translate x to y) between these languages or translate\
    \ each entry into both languages so each entry is doubled but in seperate langs."
  created_at: 2023-07-28 16:57:06+00:00
  edited: false
  hidden: false
  id: 64c40172bf1103bae846e23c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7076a9a25757cbcaa0653128ffc3084f.svg
      fullname: Ulymp
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ulymp
      type: user
    createdAt: '2023-07-29T00:21:29.000Z'
    data:
      edited: false
      editors:
      - ulymp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9783855080604553
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7076a9a25757cbcaa0653128ffc3084f.svg
          fullname: Ulymp
          isHf: false
          isPro: false
          name: ulymp
          type: user
        html: '<p>Could not successfully try this out yet. But does it even make sense
          to try to finetune Llama-2 in any other language than English? AFAIK it
          was only trained on English language sources.</p>

          <p>IMO Falcon would be much better suited for this task since it has been
          trained on multiple languages, including German.</p>

          '
        raw: 'Could not successfully try this out yet. But does it even make sense
          to try to finetune Llama-2 in any other language than English? AFAIK it
          was only trained on English language sources.


          IMO Falcon would be much better suited for this task since it has been trained
          on multiple languages, including German.'
        updatedAt: '2023-07-29T00:21:29.915Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - appliedstuff
    id: 64c45b89cd148315dc0f8ff2
    type: comment
  author: ulymp
  content: 'Could not successfully try this out yet. But does it even make sense to
    try to finetune Llama-2 in any other language than English? AFAIK it was only
    trained on English language sources.


    IMO Falcon would be much better suited for this task since it has been trained
    on multiple languages, including German.'
  created_at: 2023-07-28 23:21:29+00:00
  edited: false
  hidden: false
  id: 64c45b89cd148315dc0f8ff2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654892015542-605b1cf890a4b6bc0eef99ad.jpeg?w=200&h=200&f=face
      fullname: Florian Zimmermeister
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: flozi00
      type: user
    createdAt: '2023-07-29T09:23:21.000Z'
    data:
      edited: false
      editors:
      - flozi00
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.923458993434906
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654892015542-605b1cf890a4b6bc0eef99ad.jpeg?w=200&h=200&f=face
          fullname: Florian Zimmermeister
          isHf: false
          isPro: false
          name: flozi00
          type: user
        html: '<p>Llama can be adapted to German pretty fast, less than 12 hours to
          reach good answers.<br>The llama 2 13b model reaches an 0.18 eval loss while
          falcon 7b is around 0.3.</p>

          '
        raw: 'Llama can be adapted to German pretty fast, less than 12 hours to reach
          good answers.

          The llama 2 13b model reaches an 0.18 eval loss while falcon 7b is around
          0.3.'
        updatedAt: '2023-07-29T09:23:21.701Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - appliedstuff
    id: 64c4da898f31d1e6c6856ee3
    type: comment
  author: flozi00
  content: 'Llama can be adapted to German pretty fast, less than 12 hours to reach
    good answers.

    The llama 2 13b model reaches an 0.18 eval loss while falcon 7b is around 0.3.'
  created_at: 2023-07-29 08:23:21+00:00
  edited: false
  hidden: false
  id: 64c4da898f31d1e6c6856ee3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/beabf70201af07b24a5fa5681b44a6f6.svg
      fullname: PK
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: appliedstuff
      type: user
    createdAt: '2023-07-30T13:08:57.000Z'
    data:
      edited: false
      editors:
      - appliedstuff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8804154396057129
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/beabf70201af07b24a5fa5681b44a6f6.svg
          fullname: PK
          isHf: false
          isPro: false
          name: appliedstuff
          type: user
        html: '<blockquote>

          <p>Llama can be adapted to German pretty fast, less than 12 hours to reach
          good answers.<br>The llama 2 13b model reaches an 0.18 eval loss while falcon
          7b is around 0.3.</p>

          </blockquote>

          <p>Great, to get a discussion started here. So, good to hear that it only
          takes this small time for finetuning and also the loss seems a good indicator
          it learns some German :-)  </p>

          <p>But what do you mean with "reach good answers". When I take a look at
          The Blokes GGML version of your model (see <a href="https://huggingface.co/TheBloke/llama-2-13B-German-Assistant-v2-GGML/discussions/1">https://huggingface.co/TheBloke/llama-2-13B-German-Assistant-v2-GGML/discussions/1</a>)
          the results are not usable. So can you ask the original model what it replies
          to the question "Wie weit ist der Abstand zwischen Erde und Sonne?"</p>

          <p>That would be very helpful! Thank you so much for your work!!! Very interesting!
          </p>

          '
        raw: "> Llama can be adapted to German pretty fast, less than 12 hours to\
          \ reach good answers.\n> The llama 2 13b model reaches an 0.18 eval loss\
          \ while falcon 7b is around 0.3.\n\nGreat, to get a discussion started here.\
          \ So, good to hear that it only takes this small time for finetuning and\
          \ also the loss seems a good indicator it learns some German :-)  \n\nBut\
          \ what do you mean with \"reach good answers\". When I take a look at The\
          \ Blokes GGML version of your model (see https://huggingface.co/TheBloke/llama-2-13B-German-Assistant-v2-GGML/discussions/1)\
          \ the results are not usable. So can you ask the original model what it\
          \ replies to the question \"Wie weit ist der Abstand zwischen Erde und Sonne?\"\
          \n\nThat would be very helpful! Thank you so much for your work!!! Very\
          \ interesting! "
        updatedAt: '2023-07-30T13:08:57.670Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Pawloo
    id: 64c660e98f31d1e6c6ab7787
    type: comment
  author: appliedstuff
  content: "> Llama can be adapted to German pretty fast, less than 12 hours to reach\
    \ good answers.\n> The llama 2 13b model reaches an 0.18 eval loss while falcon\
    \ 7b is around 0.3.\n\nGreat, to get a discussion started here. So, good to hear\
    \ that it only takes this small time for finetuning and also the loss seems a\
    \ good indicator it learns some German :-)  \n\nBut what do you mean with \"reach\
    \ good answers\". When I take a look at The Blokes GGML version of your model\
    \ (see https://huggingface.co/TheBloke/llama-2-13B-German-Assistant-v2-GGML/discussions/1)\
    \ the results are not usable. So can you ask the original model what it replies\
    \ to the question \"Wie weit ist der Abstand zwischen Erde und Sonne?\"\n\nThat\
    \ would be very helpful! Thank you so much for your work!!! Very interesting! "
  created_at: 2023-07-30 12:08:57+00:00
  edited: false
  hidden: false
  id: 64c660e98f31d1e6c6ab7787
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654892015542-605b1cf890a4b6bc0eef99ad.jpeg?w=200&h=200&f=face
      fullname: Florian Zimmermeister
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: flozi00
      type: user
    createdAt: '2023-07-30T13:32:02.000Z'
    data:
      edited: false
      editors:
      - flozi00
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9278126358985901
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654892015542-605b1cf890a4b6bc0eef99ad.jpeg?w=200&h=200&f=face
          fullname: Florian Zimmermeister
          isHf: false
          isPro: false
          name: flozi00
          type: user
        html: '<p>At the moment my inference instance is offline but we are working
          on getting it online again, then you can test it there</p>

          '
        raw: At the moment my inference instance is offline but we are working on
          getting it online again, then you can test it there
        updatedAt: '2023-07-30T13:32:02.409Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - appliedstuff
    id: 64c66652d07620bdc9c8010c
    type: comment
  author: flozi00
  content: At the moment my inference instance is offline but we are working on getting
    it online again, then you can test it there
  created_at: 2023-07-30 12:32:02+00:00
  edited: false
  hidden: false
  id: 64c66652d07620bdc9c8010c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: flozi00/Llama-2-13B-german-assistant-v2
repo_type: model
status: open
target_branch: null
title: Reason for used data set
