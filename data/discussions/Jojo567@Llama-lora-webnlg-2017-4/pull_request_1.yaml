!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Jojo567
conflicting_files: []
created_at: 2023-06-07 17:55:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ba853473148d430d4eee81706dfe0d1f.svg
      fullname: Jiahao Dong
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Jojo567
      type: user
    createdAt: '2023-06-07T18:55:24.000Z'
    data:
      edited: false
      editors:
      - Jojo567
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ba853473148d430d4eee81706dfe0d1f.svg
          fullname: Jiahao Dong
          isHf: false
          isPro: false
          name: Jojo567
          type: user
        html: ''
        raw: ''
        updatedAt: '2023-06-07T18:55:24.024Z'
      numEdits: 0
      reactions: []
    id: 6480d29c9aafd41918adf0d1
    type: comment
  author: Jojo567
  content: ''
  created_at: 2023-06-07 17:55:24+00:00
  edited: false
  hidden: false
  id: 6480d29c9aafd41918adf0d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/ba853473148d430d4eee81706dfe0d1f.svg
      fullname: Jiahao Dong
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Jojo567
      type: user
    createdAt: '2023-06-07T18:55:24.000Z'
    data:
      oid: 96890333672e273364e49a95a8e3e021cf3225b5
      parents:
      - 9c3d96863635ec7589862c270f1b1fe1e77cb2b2
      subject: Llama 7B lora fine-tune 2 epoch training on webNLG2017, 64 token length
        for both context and completion
    id: 6480d29c0000000000000000
    type: commit
  author: Jojo567
  created_at: 2023-06-07 17:55:24+00:00
  id: 6480d29c0000000000000000
  oid: 96890333672e273364e49a95a8e3e021cf3225b5
  summary: Llama 7B lora fine-tune 2 epoch training on webNLG2017, 64 token length
    for both context and completion
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ba853473148d430d4eee81706dfe0d1f.svg
      fullname: Jiahao Dong
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Jojo567
      type: user
    createdAt: '2023-06-07T18:55:43.000Z'
    data:
      status: merged
    id: 6480d2af40facadc5572e40b
    type: status-change
  author: Jojo567
  created_at: 2023-06-07 17:55:43+00:00
  id: 6480d2af40facadc5572e40b
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: ae6ee9d205dcdb62be75ac1942f70b49d33da98c
num: 1
repo_id: Jojo567/Llama-lora-webnlg-2017-4
repo_type: model
status: merged
target_branch: refs/heads/main
title: Llama 7B lora fine-tune 2 epoch training on webNLG2017, 64 token length for
  both context and completion
