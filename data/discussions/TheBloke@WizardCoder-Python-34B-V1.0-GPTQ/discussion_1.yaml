!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lucasjin
conflicting_files: null
created_at: 2023-08-27 12:42:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9fbbb8eaaa7b19752b336cf228d4679e.svg
      fullname: lucasjin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lucasjin
      type: user
    createdAt: '2023-08-27T13:42:14.000Z'
    data:
      edited: false
      editors:
      - lucasjin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9574136734008789
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9fbbb8eaaa7b19752b336cf228d4679e.svg
          fullname: lucasjin
          isHf: false
          isPro: false
          name: lucasjin
          type: user
        html: '<p>The other (coderllama GPTQ) model seems corrupted, the result not
          right.</p>

          <p>Does this GPTQ weights is right?</p>

          '
        raw: "The other (coderllama GPTQ) model seems corrupted, the result not right.\r\
          \n\r\nDoes this GPTQ weights is right?"
        updatedAt: '2023-08-27T13:42:14.816Z'
      numEdits: 0
      reactions: []
    id: 64eb52b6171e6c9862c711bf
    type: comment
  author: lucasjin
  content: "The other (coderllama GPTQ) model seems corrupted, the result not right.\r\
    \n\r\nDoes this GPTQ weights is right?"
  created_at: 2023-08-27 12:42:14+00:00
  edited: false
  hidden: false
  id: 64eb52b6171e6c9862c711bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d97b20672975167a8355f54b5edf248.svg
      fullname: Patrick Shechet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kajuberdut
      type: user
    createdAt: '2023-08-27T15:10:48.000Z'
    data:
      edited: true
      editors:
      - kajuberdut
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9293331503868103
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d97b20672975167a8355f54b5edf248.svg
          fullname: Patrick Shechet
          isHf: false
          isPro: false
          name: kajuberdut
          type: user
        html: '<p>I haven''t tried this one but I have used TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True
          for several things and that model works fine. </p>

          <p>WizardCoder-Python (this model) is an instruct tuned model while CodeLlama-34B-Python
          is a continuation model so there is no prompt template and you must write
          enough of whatever code you want that the model can see what it should finish.
          If you were running into trouble with the fact that CodeLlama-Python doesn''t
          let you ask questions / give instructions in a template, WizardCoder might
          be a better choice for you!</p>

          '
        raw: "I haven't tried this one but I have used TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
          \ for several things and that model works fine. \n\nWizardCoder-Python (this\
          \ model) is an instruct tuned model while CodeLlama-34B-Python is a continuation\
          \ model so there is no prompt template and you must write enough of whatever\
          \ code you want that the model can see what it should finish. If you were\
          \ running into trouble with the fact that CodeLlama-Python doesn't let you\
          \ ask questions / give instructions in a template, WizardCoder might be\
          \ a better choice for you!"
        updatedAt: '2023-08-27T15:11:06.417Z'
      numEdits: 1
      reactions: []
    id: 64eb677801df1b139e850a76
    type: comment
  author: kajuberdut
  content: "I haven't tried this one but I have used TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
    \ for several things and that model works fine. \n\nWizardCoder-Python (this model)\
    \ is an instruct tuned model while CodeLlama-34B-Python is a continuation model\
    \ so there is no prompt template and you must write enough of whatever code you\
    \ want that the model can see what it should finish. If you were running into\
    \ trouble with the fact that CodeLlama-Python doesn't let you ask questions /\
    \ give instructions in a template, WizardCoder might be a better choice for you!"
  created_at: 2023-08-27 14:10:48+00:00
  edited: true
  hidden: false
  id: 64eb677801df1b139e850a76
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9fbbb8eaaa7b19752b336cf228d4679e.svg
      fullname: lucasjin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lucasjin
      type: user
    createdAt: '2023-08-28T02:34:22.000Z'
    data:
      edited: false
      editors:
      - lucasjin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8728896975517273
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9fbbb8eaaa7b19752b336cf228d4679e.svg
          fullname: lucasjin
          isHf: false
          isPro: false
          name: lucasjin
          type: user
        html: '<p>thanks, but I preivous tried also a instructed model.</p>

          <p>What diffference between this one and TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True
          ?</p>

          '
        raw: 'thanks, but I preivous tried also a instructed model.


          What diffference between this one and TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True
          ?'
        updatedAt: '2023-08-28T02:34:22.062Z'
      numEdits: 0
      reactions: []
    id: 64ec07aef156bb3ae1f40ccd
    type: comment
  author: lucasjin
  content: 'thanks, but I preivous tried also a instructed model.


    What diffference between this one and TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True
    ?'
  created_at: 2023-08-28 01:34:22+00:00
  edited: false
  hidden: false
  id: 64ec07aef156bb3ae1f40ccd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d97b20672975167a8355f54b5edf248.svg
      fullname: Patrick Shechet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kajuberdut
      type: user
    createdAt: '2023-08-28T02:41:23.000Z'
    data:
      edited: true
      editors:
      - kajuberdut
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8023790121078491
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d97b20672975167a8355f54b5edf248.svg
          fullname: Patrick Shechet
          isHf: false
          isPro: false
          name: kajuberdut
          type: user
        html: '<blockquote>

          <p>thanks, but I preivous tried also a instructed model.</p>

          <p>What diffference between this one and TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True
          ?</p>

          </blockquote>

          <p>I don''t know about this wizard coder model but if you are looking for
          verified good performance check out the screenshots here using the Phind
          model: <a href="https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/discussions/1#64ead499e74f54587cd6336d">https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/discussions/1#64ead499e74f54587cd6336d</a>
          </p>

          '
        raw: "> thanks, but I preivous tried also a instructed model.\n> \n> What\
          \ diffference between this one and TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
          \ ?\n\nI don't know about this wizard coder model but if you are looking\
          \ for verified good performance check out the screenshots here using the\
          \ Phind model: https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/discussions/1#64ead499e74f54587cd6336d "
        updatedAt: '2023-08-28T02:42:20.080Z'
      numEdits: 2
      reactions: []
    id: 64ec0953c2bcaa4525e8e58f
    type: comment
  author: kajuberdut
  content: "> thanks, but I preivous tried also a instructed model.\n> \n> What diffference\
    \ between this one and TheBloke_CodeLlama-34B-Python-GPTQ_gptq-4bit-32g-actorder_True\
    \ ?\n\nI don't know about this wizard coder model but if you are looking for verified\
    \ good performance check out the screenshots here using the Phind model: https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/discussions/1#64ead499e74f54587cd6336d "
  created_at: 2023-08-28 01:41:23+00:00
  edited: true
  hidden: false
  id: 64ec0953c2bcaa4525e8e58f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/WizardCoder-Python-34B-V1.0-GPTQ
repo_type: model
status: open
target_branch: null
title: Does the result right?
