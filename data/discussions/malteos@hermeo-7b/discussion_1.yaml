!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aari1995
conflicting_files: null
created_at: 2023-12-13 13:03:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f3801ab7e583543386217ac/4xMdDV1gws7nxCJrU321H.jpeg?w=200&h=200&f=face
      fullname: Aaron Chibb
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aari1995
      type: user
    createdAt: '2023-12-13T13:03:23.000Z'
    data:
      edited: false
      editors:
      - aari1995
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9935031533241272
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f3801ab7e583543386217ac/4xMdDV1gws7nxCJrU321H.jpeg?w=200&h=200&f=face
          fullname: Aaron Chibb
          isHf: false
          isPro: false
          name: aari1995
          type: user
        html: "<p>Thank you for the great model Malte!</p>\n<p><span data-props=\"\
          {&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/TheBloke\">@<span class=\"underline\">TheBloke</span></a></span>\n\
          \n\t</span></span> I think it would be much appreciated to have this maybe\
          \ on your page as well? :-) It is a mix of the German Leo LMs and OpenHermes\
          \ and seems to perform really well!</p>\n"
        raw: "Thank you for the great model Malte!\r\n\r\n@TheBloke I think it would\
          \ be much appreciated to have this maybe on your page as well? :-) It is\
          \ a mix of the German Leo LMs and OpenHermes and seems to perform really\
          \ well!"
        updatedAt: '2023-12-13T13:03:23.747Z'
      numEdits: 0
      reactions: []
    id: 6579ab9b1f74237369b49c7e
    type: comment
  author: aari1995
  content: "Thank you for the great model Malte!\r\n\r\n@TheBloke I think it would\
    \ be much appreciated to have this maybe on your page as well? :-) It is a mix\
    \ of the German Leo LMs and OpenHermes and seems to perform really well!"
  created_at: 2023-12-13 13:03:23+00:00
  edited: false
  hidden: false
  id: 6579ab9b1f74237369b49c7e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655902177104-5efda656ff69163f6f59e5d2.png?w=200&h=200&f=face
      fullname: malteos
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: malteos
      type: user
    createdAt: '2024-01-02T11:03:40.000Z'
    data:
      edited: false
      editors:
      - malteos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9929273128509521
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655902177104-5efda656ff69163f6f59e5d2.png?w=200&h=200&f=face
          fullname: malteos
          isHf: false
          isPro: false
          name: malteos
          type: user
        html: '<p>Thanks! I haven''t done any quantization myself yet but I''ll have
          a look into it.</p>

          '
        raw: Thanks! I haven't done any quantization myself yet but I'll have a look
          into it.
        updatedAt: '2024-01-02T11:03:40.236Z'
      numEdits: 0
      reactions: []
    id: 6593ed8cf5a209eeaca0b620
    type: comment
  author: malteos
  content: Thanks! I haven't done any quantization myself yet but I'll have a look
    into it.
  created_at: 2024-01-02 11:03:40+00:00
  edited: false
  hidden: false
  id: 6593ed8cf5a209eeaca0b620
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655902177104-5efda656ff69163f6f59e5d2.png?w=200&h=200&f=face
      fullname: malteos
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: malteos
      type: user
    createdAt: '2024-01-05T08:36:38.000Z'
    data:
      edited: false
      editors:
      - malteos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7688352465629578
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655902177104-5efda656ff69163f6f59e5d2.png?w=200&h=200&f=face
          fullname: malteos
          isHf: false
          isPro: false
          name: malteos
          type: user
        html: '<p>There is already an AWQ quantized version: <a href="https://huggingface.co/mayflowergmbh/hermeo-7b-awq">https://huggingface.co/mayflowergmbh/hermeo-7b-awq</a></p>

          '
        raw: 'There is already an AWQ quantized version: https://huggingface.co/mayflowergmbh/hermeo-7b-awq'
        updatedAt: '2024-01-05T08:36:38.373Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - aari1995
    id: 6597bf96a839f520f4766d18
    type: comment
  author: malteos
  content: 'There is already an AWQ quantized version: https://huggingface.co/mayflowergmbh/hermeo-7b-awq'
  created_at: 2024-01-05 08:36:38+00:00
  edited: false
  hidden: false
  id: 6597bf96a839f520f4766d18
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f3801ab7e583543386217ac/4xMdDV1gws7nxCJrU321H.jpeg?w=200&h=200&f=face
      fullname: Aaron Chibb
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aari1995
      type: user
    createdAt: '2024-01-05T18:28:50.000Z'
    data:
      edited: false
      editors:
      - aari1995
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9559576511383057
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f3801ab7e583543386217ac/4xMdDV1gws7nxCJrU321H.jpeg?w=200&h=200&f=face
          fullname: Aaron Chibb
          isHf: false
          isPro: false
          name: aari1995
          type: user
        html: '<p>Thank you very much - I am actually working on another solely german
          quantization technique boosting the models German capacities and replies.
          It works really good so far  I think and has lots of potential, but WIP
          and will likely be updated next week, adding some more stuff.</p>

          <p><a href="https://huggingface.co/aari1995/germeo-7b-awq">https://huggingface.co/aari1995/germeo-7b-awq</a></p>

          <p>Also at the moment I sadly have troubles evaluating the model on the
          German benchmarks as it does not really support AWQ. If you have an idea
          let me know.</p>

          <p>Open for feedback!</p>

          '
        raw: 'Thank you very much - I am actually working on another solely german
          quantization technique boosting the models German capacities and replies.
          It works really good so far  I think and has lots of potential, but WIP
          and will likely be updated next week, adding some more stuff.


          https://huggingface.co/aari1995/germeo-7b-awq


          Also at the moment I sadly have troubles evaluating the model on the German
          benchmarks as it does not really support AWQ. If you have an idea let me
          know.


          Open for feedback!'
        updatedAt: '2024-01-05T18:28:50.056Z'
      numEdits: 0
      reactions: []
    id: 65984a62a3259bc417713173
    type: comment
  author: aari1995
  content: 'Thank you very much - I am actually working on another solely german quantization
    technique boosting the models German capacities and replies. It works really good
    so far  I think and has lots of potential, but WIP and will likely be updated
    next week, adding some more stuff.


    https://huggingface.co/aari1995/germeo-7b-awq


    Also at the moment I sadly have troubles evaluating the model on the German benchmarks
    as it does not really support AWQ. If you have an idea let me know.


    Open for feedback!'
  created_at: 2024-01-05 18:28:50+00:00
  edited: false
  hidden: false
  id: 65984a62a3259bc417713173
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655902177104-5efda656ff69163f6f59e5d2.png?w=200&h=200&f=face
      fullname: malteos
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: malteos
      type: user
    createdAt: '2024-01-08T08:37:40.000Z'
    data:
      edited: false
      editors:
      - malteos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9589795470237732
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655902177104-5efda656ff69163f6f59e5d2.png?w=200&h=200&f=face
          fullname: malteos
          isHf: false
          isPro: false
          name: malteos
          type: user
        html: '<p>What exactly is the problem? The latest transformers version does
          support AWQ, right? Feel free to reach out to me. I am happy to help.</p>

          '
        raw: What exactly is the problem? The latest transformers version does support
          AWQ, right? Feel free to reach out to me. I am happy to help.
        updatedAt: '2024-01-08T08:37:40.174Z'
      numEdits: 0
      reactions: []
    id: 659bb4546da3461e28623a55
    type: comment
  author: malteos
  content: What exactly is the problem? The latest transformers version does support
    AWQ, right? Feel free to reach out to me. I am happy to help.
  created_at: 2024-01-08 08:37:40+00:00
  edited: false
  hidden: false
  id: 659bb4546da3461e28623a55
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f3801ab7e583543386217ac/4xMdDV1gws7nxCJrU321H.jpeg?w=200&h=200&f=face
      fullname: Aaron Chibb
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aari1995
      type: user
    createdAt: '2024-01-08T09:10:45.000Z'
    data:
      edited: false
      editors:
      - aari1995
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9333881139755249
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f3801ab7e583543386217ac/4xMdDV1gws7nxCJrU321H.jpeg?w=200&h=200&f=face
          fullname: Aaron Chibb
          isHf: false
          isPro: false
          name: aari1995
          type: user
        html: '<p>Yes I also figured that out and it works now, thank you very much!<br>At
          the moment I need to find time to do the MMLU Eval as it takes 26 hours
          on my 3090 ti.<br>So far the benchmarks look good and are slightly worse
          but the models output is guaranteed German:</p>

          <p>ARC-DE: 0.514<br>Hellaswag-DE: 0.651<br>TruthfulQA-DE: 0.508</p>

          <p>I''ll keep you updated.</p>

          '
        raw: 'Yes I also figured that out and it works now, thank you very much!

          At the moment I need to find time to do the MMLU Eval as it takes 26 hours
          on my 3090 ti.

          So far the benchmarks look good and are slightly worse but the models output
          is guaranteed German:


          ARC-DE: 0.514

          Hellaswag-DE: 0.651

          TruthfulQA-DE: 0.508


          I''ll keep you updated.'
        updatedAt: '2024-01-08T09:10:45.140Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - malteos
    id: 659bbc1549da9ffd2812d7c6
    type: comment
  author: aari1995
  content: 'Yes I also figured that out and it works now, thank you very much!

    At the moment I need to find time to do the MMLU Eval as it takes 26 hours on
    my 3090 ti.

    So far the benchmarks look good and are slightly worse but the models output is
    guaranteed German:


    ARC-DE: 0.514

    Hellaswag-DE: 0.651

    TruthfulQA-DE: 0.508


    I''ll keep you updated.'
  created_at: 2024-01-08 09:10:45+00:00
  edited: false
  hidden: false
  id: 659bbc1549da9ffd2812d7c6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f3801ab7e583543386217ac/4xMdDV1gws7nxCJrU321H.jpeg?w=200&h=200&f=face
      fullname: Aaron Chibb
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aari1995
      type: user
    createdAt: '2024-01-11T10:09:34.000Z'
    data:
      edited: false
      editors:
      - aari1995
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.874966561794281
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f3801ab7e583543386217ac/4xMdDV1gws7nxCJrU321H.jpeg?w=200&h=200&f=face
          fullname: Aaron Chibb
          isHf: false
          isPro: false
          name: aari1995
          type: user
        html: "<p><a href=\"https://huggingface.co/aari1995/germeo-7b-awq\">https://huggingface.co/aari1995/germeo-7b-awq</a></p>\n\
          <p>Evaluation done. MMLU 0.522 (improvement). Resulting in an average of\
          \ 0.563 (DE-Average). I think it is a good use case of knowledge transfer\
          \ from English to German with \"keeping the model German\". It replies solely\
          \ in German. <span data-props=\"{&quot;user&quot;:&quot;floleuerer&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/floleuerer\"\
          >@<span class=\"underline\">floleuerer</span></a></span>\n\n\t</span></span>\
          \ created  a <a href=\"https://huggingface.co/spaces/floleuerer/german_llm_outputs\"\
          >benchmark</a> for German response rates - in contact to see if there is\
          \ an improvement.</p>\n<p>Malte, would you be up for further experiments\
          \ on knowledge transfer or a call? I am experimenting also with <a href=\"\
          https://huggingface.co/aari1995/germeo-7b-laser\">laser</a> and want to\
          \ see whether a non-bilingual model can achieve improvements with quantization\
          \ / pruning methods.</p>\n"
        raw: 'https://huggingface.co/aari1995/germeo-7b-awq


          Evaluation done. MMLU 0.522 (improvement). Resulting in an average of 0.563
          (DE-Average). I think it is a good use case of knowledge transfer from English
          to German with "keeping the model German". It replies solely in German.
          @floleuerer created  a [benchmark](https://huggingface.co/spaces/floleuerer/german_llm_outputs)
          for German response rates - in contact to see if there is an improvement.


          Malte, would you be up for further experiments on knowledge transfer or
          a call? I am experimenting also with [laser](https://huggingface.co/aari1995/germeo-7b-laser)
          and want to see whether a non-bilingual model can achieve improvements with
          quantization / pruning methods.'
        updatedAt: '2024-01-11T10:09:34.011Z'
      numEdits: 0
      reactions: []
    id: 659fbe5ed729f54013f087d8
    type: comment
  author: aari1995
  content: 'https://huggingface.co/aari1995/germeo-7b-awq


    Evaluation done. MMLU 0.522 (improvement). Resulting in an average of 0.563 (DE-Average).
    I think it is a good use case of knowledge transfer from English to German with
    "keeping the model German". It replies solely in German. @floleuerer created  a
    [benchmark](https://huggingface.co/spaces/floleuerer/german_llm_outputs) for German
    response rates - in contact to see if there is an improvement.


    Malte, would you be up for further experiments on knowledge transfer or a call?
    I am experimenting also with [laser](https://huggingface.co/aari1995/germeo-7b-laser)
    and want to see whether a non-bilingual model can achieve improvements with quantization
    / pruning methods.'
  created_at: 2024-01-11 10:09:34+00:00
  edited: false
  hidden: false
  id: 659fbe5ed729f54013f087d8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: malteos/hermeo-7b
repo_type: model
status: open
target_branch: null
title: GGUF format
