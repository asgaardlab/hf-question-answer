!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jacobgoldenart
conflicting_files: null
created_at: 2023-08-11 19:10:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/50ccb3eb90953cc0e3f6be92f6e09568.svg
      fullname: Jacob Golden
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jacobgoldenart
      type: user
    createdAt: '2023-08-11T20:10:23.000Z'
    data:
      edited: false
      editors:
      - jacobgoldenart
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9530240297317505
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/50ccb3eb90953cc0e3f6be92f6e09568.svg
          fullname: Jacob Golden
          isHf: false
          isPro: false
          name: jacobgoldenart
          type: user
        html: '<p>Hi, Is this the full model that I can use with MLC-LLM or do I need
          to use this with the Lllama 2 model weights itself? Thanks</p>

          '
        raw: Hi, Is this the full model that I can use with MLC-LLM or do I need to
          use this with the Lllama 2 model weights itself? Thanks
        updatedAt: '2023-08-11T20:10:23.297Z'
      numEdits: 0
      reactions: []
    id: 64d695af3be3c57959b58cbc
    type: comment
  author: jacobgoldenart
  content: Hi, Is this the full model that I can use with MLC-LLM or do I need to
    use this with the Lllama 2 model weights itself? Thanks
  created_at: 2023-08-11 19:10:23+00:00
  edited: false
  hidden: false
  id: 64d695af3be3c57959b58cbc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/57567fa8f741e2f177dbbd3a5ac8ff32.svg
      fullname: Charlie Ruan
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: CharlieFRuan
      type: user
    createdAt: '2023-08-11T21:17:55.000Z'
    data:
      edited: false
      editors:
      - CharlieFRuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6386083960533142
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/57567fa8f741e2f177dbbd3a5ac8ff32.svg
          fullname: Charlie Ruan
          isHf: false
          isPro: false
          name: CharlieFRuan
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;jacobgoldenart&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/jacobgoldenart\"\
          >@<span class=\"underline\">jacobgoldenart</span></a></span>\n\n\t</span></span>,\
          \ this is the full model compiled from <a href=\"https://huggingface.co/georgesung/llama2_7b_chat_uncensored\"\
          >https://huggingface.co/georgesung/llama2_7b_chat_uncensored</a>.</p>\n\
          <p>So you can directly clone this huggingface repo and follow the steps\
          \ in <a rel=\"nofollow\" href=\"https://github.com/mlc-ai/notebooks/blob/main/mlc-llm/tutorial_chat_module_getting_started.ipynb\"\
          >the tutorial here</a>, essentially cloning this repo instead of the other\
          \ llama2 repo.</p>\n"
        raw: 'Hi @jacobgoldenart, this is the full model compiled from https://huggingface.co/georgesung/llama2_7b_chat_uncensored.


          So you can directly clone this huggingface repo and follow the steps in
          [the tutorial here](https://github.com/mlc-ai/notebooks/blob/main/mlc-llm/tutorial_chat_module_getting_started.ipynb),
          essentially cloning this repo instead of the other llama2 repo.'
        updatedAt: '2023-08-11T21:17:55.755Z'
      numEdits: 0
      reactions: []
    id: 64d6a5830f992cf1ce5262c0
    type: comment
  author: CharlieFRuan
  content: 'Hi @jacobgoldenart, this is the full model compiled from https://huggingface.co/georgesung/llama2_7b_chat_uncensored.


    So you can directly clone this huggingface repo and follow the steps in [the tutorial
    here](https://github.com/mlc-ai/notebooks/blob/main/mlc-llm/tutorial_chat_module_getting_started.ipynb),
    essentially cloning this repo instead of the other llama2 repo.'
  created_at: 2023-08-11 20:17:55+00:00
  edited: false
  hidden: false
  id: 64d6a5830f992cf1ce5262c0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: mlc-ai/mlc-chat-georgesung-llama2-7b-chat-uncensored-q4f16_1
repo_type: model
status: open
target_branch: null
title: Is this the full model?
