!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hoyle
conflicting_files: null
created_at: 2023-04-02 18:46:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5746d6bf2fa25c5e53c5b33f6a9b52f7.svg
      fullname: Alexander Hoyle
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hoyle
      type: user
    createdAt: '2023-04-02T19:46:13.000Z'
    data:
      edited: false
      editors:
      - hoyle
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5746d6bf2fa25c5e53c5b33f6a9b52f7.svg
          fullname: Alexander Hoyle
          isHf: false
          isPro: false
          name: hoyle
          type: user
        html: '<p>Wanted to note that I was getting bad results with the <code>q4_1</code>
          models (both with 30B and 13B/7B), but when I switched to <code>q4_0</code>
          it was much better. Note that it still requires some conversions (<code>convert-unversioned-ggml-to-ggml.py</code>
          then <code>migrate-ggml-2023-03-30-pr613.py</code>). Maybe worth adding
          to the readme / doing the conversions here?</p>

          <p>Thanks for uploading!</p>

          <p><a rel="nofollow" href="https://www.github.com/ggerganov/llama.cpp/issues/397#issuecomment-1493381230">See
          my comment on the quantization thread in llama.cpp for more info</a></p>

          '
        raw: "Wanted to note that I was getting bad results with the `q4_1` models\
          \ (both with 30B and 13B/7B), but when I switched to `q4_0` it was much\
          \ better. Note that it still requires some conversions (`convert-unversioned-ggml-to-ggml.py`\
          \ then `migrate-ggml-2023-03-30-pr613.py`). Maybe worth adding to the readme\
          \ / doing the conversions here?\r\n\r\nThanks for uploading!\r\n\r\n[See\
          \ my comment on the quantization thread in llama.cpp for more info](https://www.github.com/ggerganov/llama.cpp/issues/397#issuecomment-1493381230)"
        updatedAt: '2023-04-02T19:46:13.816Z'
      numEdits: 0
      reactions: []
    id: 6429db854e073875f6a9b23e
    type: comment
  author: hoyle
  content: "Wanted to note that I was getting bad results with the `q4_1` models (both\
    \ with 30B and 13B/7B), but when I switched to `q4_0` it was much better. Note\
    \ that it still requires some conversions (`convert-unversioned-ggml-to-ggml.py`\
    \ then `migrate-ggml-2023-03-30-pr613.py`). Maybe worth adding to the readme /\
    \ doing the conversions here?\r\n\r\nThanks for uploading!\r\n\r\n[See my comment\
    \ on the quantization thread in llama.cpp for more info](https://www.github.com/ggerganov/llama.cpp/issues/397#issuecomment-1493381230)"
  created_at: 2023-04-02 18:46:13+00:00
  edited: false
  hidden: false
  id: 6429db854e073875f6a9b23e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
      fullname: Pi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Pi3141
      type: user
    createdAt: '2023-04-02T20:03:34.000Z'
    data:
      edited: false
      editors:
      - Pi3141
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
          fullname: Pi
          isHf: false
          isPro: false
          name: Pi3141
          type: user
        html: '<p>No. I won''t convert the old q4_0 because it''s for people with
          alpaca.cpp (outdated). People with llama.cpp should just use q4_1 instead.
          In my testing, it was better than q4_0 so I''m not sure why you got the
          opposite result.</p>

          '
        raw: No. I won't convert the old q4_0 because it's for people with alpaca.cpp
          (outdated). People with llama.cpp should just use q4_1 instead. In my testing,
          it was better than q4_0 so I'm not sure why you got the opposite result.
        updatedAt: '2023-04-02T20:03:34.716Z'
      numEdits: 0
      reactions: []
    id: 6429df964059ac9e68395a03
    type: comment
  author: Pi3141
  content: No. I won't convert the old q4_0 because it's for people with alpaca.cpp
    (outdated). People with llama.cpp should just use q4_1 instead. In my testing,
    it was better than q4_0 so I'm not sure why you got the opposite result.
  created_at: 2023-04-02 19:03:34+00:00
  edited: false
  hidden: false
  id: 6429df964059ac9e68395a03
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5746d6bf2fa25c5e53c5b33f6a9b52f7.svg
      fullname: Alexander Hoyle
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hoyle
      type: user
    createdAt: '2023-04-02T20:06:30.000Z'
    data:
      edited: true
      editors:
      - hoyle
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5746d6bf2fa25c5e53c5b33f6a9b52f7.svg
          fullname: Alexander Hoyle
          isHf: false
          isPro: false
          name: hoyle
          type: user
        html: '<p>Fair enough! It''s easy enough to do on the user end anyway.</p>

          <p>That said, if it''s not too much trouble, would you mind very much running
          the prompt in the comment I linked? I''m so curious why I was getting dramatically
          worse results with q4_1 vs q4_0, but maybe it''s just something weird on
          my end (I had noticed in the <code>ggml</code> repo that the jury is still
          out on which approach is better). It was happening both with your model
          and with one I consolidated and quantized myself.</p>

          '
        raw: 'Fair enough! It''s easy enough to do on the user end anyway.


          That said, if it''s not too much trouble, would you mind very much running
          the prompt in the comment I linked? I''m so curious why I was getting dramatically
          worse results with q4_1 vs q4_0, but maybe it''s just something weird on
          my end (I had noticed in the `ggml` repo that the jury is still out on which
          approach is better). It was happening both with your model and with one
          I consolidated and quantized myself.'
        updatedAt: '2023-04-02T20:08:14.630Z'
      numEdits: 2
      reactions: []
    id: 6429e0463d772f5e52c51865
    type: comment
  author: hoyle
  content: 'Fair enough! It''s easy enough to do on the user end anyway.


    That said, if it''s not too much trouble, would you mind very much running the
    prompt in the comment I linked? I''m so curious why I was getting dramatically
    worse results with q4_1 vs q4_0, but maybe it''s just something weird on my end
    (I had noticed in the `ggml` repo that the jury is still out on which approach
    is better). It was happening both with your model and with one I consolidated
    and quantized myself.'
  created_at: 2023-04-02 19:06:30+00:00
  edited: true
  hidden: false
  id: 6429e0463d772f5e52c51865
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
      fullname: Pi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Pi3141
      type: user
    createdAt: '2023-04-03T01:32:14.000Z'
    data:
      edited: false
      editors:
      - Pi3141
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
          fullname: Pi
          isHf: false
          isPro: false
          name: Pi3141
          type: user
        html: "<blockquote>\n<p>That said, if it's not too much trouble, would you\
          \ mind very much running the prompt in the comment I linked? I'm so curious\
          \ why I was getting dramatically worse results with q4_1 vs q4_0, but maybe\
          \ it's just something weird on my end (I had noticed in the <code>ggml</code>\
          \ repo that the jury is still out on which approach is better). It was happening\
          \ both with your model and with one I consolidated and quantized myself.</p>\n\
          </blockquote>\n<p>I've just tested it myself. I've noticed that you did\
          \ not follow the Alpaca prompt template:</p>\n<pre><code>Below is an instruction\
          \ that describes a task. Write a response that appropriately completes the\
          \ request. \n\n### Instruction: instruction goes here\n\n### Response:\n\
          </code></pre>\n<p>Here's the response i got from q4_0</p>\n<blockquote>\n\
          <p>Stoner by John Williams is a novel set in the American West. It follows\
          \ the story of a man named Stoner, who is a loner living in the desert,\
          \ with no connection to the modern world. He encounters various people and\
          \ events during his journey, and through these encounters he is forced to\
          \ confront his past and confront his inner demons. Ultimately, Stone must\
          \ come to terms with his past and make peace with himself before he can\
          \ move on.</p>\n</blockquote>\n<p>Here's the response i got from q4_1</p>\n\
          <blockquote>\n<p>Stoner is a novel by John Williams that tells the story\
          \ of a man named William Stoner, who struggles to find his place in the\
          \ world. Stoner is a farm boy who goes to college to study agriculture,\
          \ but later finds himself drawn to literature. He becomes a teacher, and\
          \ his life is punctuated by moments of personal triumph and despair, as\
          \ well as the larger events of the world around him. The novel is a poignant\
          \ story of the search for meaning and connection in a life that feels small\
          \ and unfulfilled.</p>\n</blockquote>\n"
        raw: "> That said, if it's not too much trouble, would you mind very much\
          \ running the prompt in the comment I linked? I'm so curious why I was getting\
          \ dramatically worse results with q4_1 vs q4_0, but maybe it's just something\
          \ weird on my end (I had noticed in the `ggml` repo that the jury is still\
          \ out on which approach is better). It was happening both with your model\
          \ and with one I consolidated and quantized myself.\n\nI've just tested\
          \ it myself. I've noticed that you did not follow the Alpaca prompt template:\n\
          ```\nBelow is an instruction that describes a task. Write a response that\
          \ appropriately completes the request. \n\n### Instruction: instruction\
          \ goes here\n\n### Response:\n```\n\nHere's the response i got from q4_0\n\
          > Stoner by John Williams is a novel set in the American West. It follows\
          \ the story of a man named Stoner, who is a loner living in the desert,\
          \ with no connection to the modern world. He encounters various people and\
          \ events during his journey, and through these encounters he is forced to\
          \ confront his past and confront his inner demons. Ultimately, Stone must\
          \ come to terms with his past and make peace with himself before he can\
          \ move on.\n\nHere's the response i got from q4_1\n> Stoner is a novel by\
          \ John Williams that tells the story of a man named William Stoner, who\
          \ struggles to find his place in the world. Stoner is a farm boy who goes\
          \ to college to study agriculture, but later finds himself drawn to literature.\
          \ He becomes a teacher, and his life is punctuated by moments of personal\
          \ triumph and despair, as well as the larger events of the world around\
          \ him. The novel is a poignant story of the search for meaning and connection\
          \ in a life that feels small and unfulfilled."
        updatedAt: '2023-04-03T01:32:14.393Z'
      numEdits: 0
      reactions: []
    id: 642a2c9e316c9207b7c36e0f
    type: comment
  author: Pi3141
  content: "> That said, if it's not too much trouble, would you mind very much running\
    \ the prompt in the comment I linked? I'm so curious why I was getting dramatically\
    \ worse results with q4_1 vs q4_0, but maybe it's just something weird on my end\
    \ (I had noticed in the `ggml` repo that the jury is still out on which approach\
    \ is better). It was happening both with your model and with one I consolidated\
    \ and quantized myself.\n\nI've just tested it myself. I've noticed that you did\
    \ not follow the Alpaca prompt template:\n```\nBelow is an instruction that describes\
    \ a task. Write a response that appropriately completes the request. \n\n### Instruction:\
    \ instruction goes here\n\n### Response:\n```\n\nHere's the response i got from\
    \ q4_0\n> Stoner by John Williams is a novel set in the American West. It follows\
    \ the story of a man named Stoner, who is a loner living in the desert, with no\
    \ connection to the modern world. He encounters various people and events during\
    \ his journey, and through these encounters he is forced to confront his past\
    \ and confront his inner demons. Ultimately, Stone must come to terms with his\
    \ past and make peace with himself before he can move on.\n\nHere's the response\
    \ i got from q4_1\n> Stoner is a novel by John Williams that tells the story of\
    \ a man named William Stoner, who struggles to find his place in the world. Stoner\
    \ is a farm boy who goes to college to study agriculture, but later finds himself\
    \ drawn to literature. He becomes a teacher, and his life is punctuated by moments\
    \ of personal triumph and despair, as well as the larger events of the world around\
    \ him. The novel is a poignant story of the search for meaning and connection\
    \ in a life that feels small and unfulfilled."
  created_at: 2023-04-03 00:32:14+00:00
  edited: false
  hidden: false
  id: 642a2c9e316c9207b7c36e0f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5746d6bf2fa25c5e53c5b33f6a9b52f7.svg
      fullname: Alexander Hoyle
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hoyle
      type: user
    createdAt: '2023-04-03T02:56:32.000Z'
    data:
      edited: true
      editors:
      - hoyle
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5746d6bf2fa25c5e53c5b33f6a9b52f7.svg
          fullname: Alexander Hoyle
          isHf: false
          isPro: false
          name: hoyle
          type: user
        html: '<p>Thank you! Really appreciate it. I have used the right prompt template
          when testing Alpaca, but I''d made that comment about LLaMA---sorry for
          the confusion.</p>

          <p>At any rate, it does look like something on my end. You''re getting almost
          the opposite results as me (your q4_0 inaccurate, q4_1 accurate).</p>

          <p>Again, thanks for running it. I''m running the most recent llama.cpp
          on apple silicon, which feels like the best case scenario, but I guess there''s
          always room for bugs</p>

          '
        raw: 'Thank you! Really appreciate it. I have used the right prompt template
          when testing Alpaca, but I''d made that comment about LLaMA---sorry for
          the confusion.


          At any rate, it does look like something on my end. You''re getting almost
          the opposite results as me (your q4_0 inaccurate, q4_1 accurate).


          Again, thanks for running it. I''m running the most recent llama.cpp on
          apple silicon, which feels like the best case scenario, but I guess there''s
          always room for bugs'
        updatedAt: '2023-04-03T02:58:44.733Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Pi3141
    id: 642a40603bccbc25885172a8
    type: comment
  author: hoyle
  content: 'Thank you! Really appreciate it. I have used the right prompt template
    when testing Alpaca, but I''d made that comment about LLaMA---sorry for the confusion.


    At any rate, it does look like something on my end. You''re getting almost the
    opposite results as me (your q4_0 inaccurate, q4_1 accurate).


    Again, thanks for running it. I''m running the most recent llama.cpp on apple
    silicon, which feels like the best case scenario, but I guess there''s always
    room for bugs'
  created_at: 2023-04-03 01:56:32+00:00
  edited: true
  hidden: false
  id: 642a40603bccbc25885172a8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/5746d6bf2fa25c5e53c5b33f6a9b52f7.svg
      fullname: Alexander Hoyle
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hoyle
      type: user
    createdAt: '2023-04-03T03:17:23.000Z'
    data:
      from: Issues with
      to: Issues with q4_1
    id: 642a454335f537352b8fa49e
    type: title-change
  author: hoyle
  created_at: 2023-04-03 02:17:23+00:00
  id: 642a454335f537352b8fa49e
  new_title: Issues with q4_1
  old_title: Issues with
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
      fullname: Pi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Pi3141
      type: user
    createdAt: '2023-04-03T04:23:39.000Z'
    data:
      edited: false
      editors:
      - Pi3141
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
          fullname: Pi
          isHf: false
          isPro: false
          name: Pi3141
          type: user
        html: "<p>You're welcome \U0001F601</p>\n"
        raw: "You're welcome \U0001F601"
        updatedAt: '2023-04-03T04:23:39.795Z'
      numEdits: 0
      reactions: []
      relatedEventId: 642a54cb6801699f7c43146a
    id: 642a54cb6801699f7c431469
    type: comment
  author: Pi3141
  content: "You're welcome \U0001F601"
  created_at: 2023-04-03 03:23:39+00:00
  edited: false
  hidden: false
  id: 642a54cb6801699f7c431469
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
      fullname: Pi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Pi3141
      type: user
    createdAt: '2023-04-03T04:23:39.000Z'
    data:
      status: closed
    id: 642a54cb6801699f7c43146a
    type: status-change
  author: Pi3141
  created_at: 2023-04-03 03:23:39+00:00
  id: 642a54cb6801699f7c43146a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: Pi3141/alpaca-lora-30B-ggml
repo_type: model
status: closed
target_branch: null
title: Issues with q4_1
