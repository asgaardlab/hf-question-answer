!!python/object:huggingface_hub.community.DiscussionWithDetails
author: appvoid
conflicting_files: null
created_at: 2023-03-28 18:46:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a813dedbb9e28866a91b27/i2pGYzY1htiY-L3WFPSgl.jpeg?w=200&h=200&f=face
      fullname: appvoid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: appvoid
      type: user
    createdAt: '2023-03-28T19:46:32.000Z'
    data:
      edited: false
      editors:
      - appvoid
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a813dedbb9e28866a91b27/i2pGYzY1htiY-L3WFPSgl.jpeg?w=200&h=200&f=face
          fullname: appvoid
          isHf: false
          isPro: false
          name: appvoid
          type: user
        html: '<p>First of all, <strong>I really do appreciate what you did.</strong>
          I''m getting remarkable results from this one. I''m looking forward to know
          if you are going to upload the 65B one. That would be really great!</p>

          '
        raw: First of all, **I really do appreciate what you did.** I'm getting remarkable
          results from this one. I'm looking forward to know if you are going to upload
          the 65B one. That would be really great!
        updatedAt: '2023-03-28T19:46:32.562Z'
      numEdits: 0
      reactions: []
    id: 6423441823b98d5ee6e93b15
    type: comment
  author: appvoid
  content: First of all, **I really do appreciate what you did.** I'm getting remarkable
    results from this one. I'm looking forward to know if you are going to upload
    the 65B one. That would be really great!
  created_at: 2023-03-28 18:46:32+00:00
  edited: false
  hidden: false
  id: 6423441823b98d5ee6e93b15
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
      fullname: Pi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Pi3141
      type: user
    createdAt: '2023-03-28T20:46:00.000Z'
    data:
      edited: false
      editors:
      - Pi3141
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
          fullname: Pi
          isHf: false
          isPro: false
          name: Pi3141
          type: user
        html: '<p>Most likely not, for two reasons:</p>

          <ol>

          <li>I cannot make the LoRA weights because my GPU isn''t powerful enough
          and no one has made 65B Alpaca LoRA weights yet.</li>

          <li>Merging the weights and quantizing the models uses a lot of RAM. 30B
          needed 85GB so I had to use swap. 65B would probably use 170GB or more,
          and I don''t have enough space for a swap that large.</li>

          </ol>

          '
        raw: 'Most likely not, for two reasons:

          1. I cannot make the LoRA weights because my GPU isn''t powerful enough
          and no one has made 65B Alpaca LoRA weights yet.

          2. Merging the weights and quantizing the models uses a lot of RAM. 30B
          needed 85GB so I had to use swap. 65B would probably use 170GB or more,
          and I don''t have enough space for a swap that large.'
        updatedAt: '2023-03-28T20:46:00.372Z'
      numEdits: 0
      reactions: []
    id: 6423520871e9217e46b21298
    type: comment
  author: Pi3141
  content: 'Most likely not, for two reasons:

    1. I cannot make the LoRA weights because my GPU isn''t powerful enough and no
    one has made 65B Alpaca LoRA weights yet.

    2. Merging the weights and quantizing the models uses a lot of RAM. 30B needed
    85GB so I had to use swap. 65B would probably use 170GB or more, and I don''t
    have enough space for a swap that large.'
  created_at: 2023-03-28 19:46:00+00:00
  edited: false
  hidden: false
  id: 6423520871e9217e46b21298
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a813dedbb9e28866a91b27/i2pGYzY1htiY-L3WFPSgl.jpeg?w=200&h=200&f=face
      fullname: appvoid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: appvoid
      type: user
    createdAt: '2023-03-28T21:56:05.000Z'
    data:
      edited: false
      editors:
      - appvoid
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a813dedbb9e28866a91b27/i2pGYzY1htiY-L3WFPSgl.jpeg?w=200&h=200&f=face
          fullname: appvoid
          isHf: false
          isPro: false
          name: appvoid
          type: user
        html: '<p>Holy weight!</p>

          <p>That things is humongous. Hopefully someone do it soon. Anyway, thanks
          for this one though.</p>

          '
        raw: 'Holy weight!


          That things is humongous. Hopefully someone do it soon. Anyway, thanks for
          this one though.'
        updatedAt: '2023-03-28T21:56:05.508Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - Pi3141
    id: 6423627571e9217e46b27c53
    type: comment
  author: appvoid
  content: 'Holy weight!


    That things is humongous. Hopefully someone do it soon. Anyway, thanks for this
    one though.'
  created_at: 2023-03-28 20:56:05+00:00
  edited: false
  hidden: false
  id: 6423627571e9217e46b27c53
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a813dedbb9e28866a91b27/i2pGYzY1htiY-L3WFPSgl.jpeg?w=200&h=200&f=face
      fullname: appvoid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: appvoid
      type: user
    createdAt: '2023-03-28T21:56:19.000Z'
    data:
      status: closed
    id: 642362835aed4fac78a1247c
    type: status-change
  author: appvoid
  created_at: 2023-03-28 20:56:19+00:00
  id: 642362835aed4fac78a1247c
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: Pi3141/alpaca-lora-30B-ggml
repo_type: model
status: closed
target_branch: null
title: Will we get 65B?
