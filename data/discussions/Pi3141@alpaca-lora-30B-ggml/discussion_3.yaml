!!python/object:huggingface_hub.community.DiscussionWithDetails
author: c2d03041
conflicting_files: null
created_at: 2023-03-21 08:57:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe585159a71d09896504f02eaa1ebc0b.svg
      fullname: Liam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: c2d03041
      type: user
    createdAt: '2023-03-21T09:57:22.000Z'
    data:
      edited: false
      editors:
      - c2d03041
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe585159a71d09896504f02eaa1ebc0b.svg
          fullname: Liam
          isHf: false
          isPro: false
          name: c2d03041
          type: user
        html: "<p>The fix is this:</p>\n<pre><code class=\"language-diff\"><span class=\"\
          hljs-comment\">diff --git a/main.cpp b/main.cpp</span>\n<span class=\"hljs-comment\"\
          >index 3321818..3fa487b 100644</span>\n<span class=\"hljs-comment\">---\
          \ a/main.cpp</span>\n<span class=\"hljs-comment\">+++ b/main.cpp</span>\n\
          <span class=\"hljs-meta\">@@ -34,8 +34,8 @@</span> static const int EOS_TOKEN_ID\
          \ = 2;\n // determine number of model parts based on the dimension\n static\
          \ const std::map&lt;int, int&gt; LLAMA_N_PARTS = {\n     { 4096, 1 },\n\
          <span class=\"hljs-deletion\">-    { 5120, 2 },</span>\n<span class=\"hljs-deletion\"\
          >-    { 6656, 4 },</span>\n<span class=\"hljs-addition\">+    { 5120, 1\
          \ },</span>\n<span class=\"hljs-addition\">+    { 6656, 1 },</span>\n  \
          \   { 8192, 8 },\n };\n \n<span class=\"hljs-meta\">@@ -43,10 +43,10 @@</span>\
          \ static const std::map&lt;int, int&gt; LLAMA_N_PARTS = {\n struct llama_hparams\
          \ {\n     int32_t n_vocab = 32000;\n     int32_t n_ctx   = 512;   // this\
          \ is provided as user input?\n<span class=\"hljs-deletion\">-    int32_t\
          \ n_embd  = 4096;</span>\n<span class=\"hljs-addition\">+    int32_t n_embd\
          \  = 5120;</span>\n     int32_t n_mult  = 256;\n<span class=\"hljs-deletion\"\
          >-    int32_t n_head  = 32;</span>\n<span class=\"hljs-deletion\">-    int32_t\
          \ n_layer = 32;</span>\n<span class=\"hljs-addition\">+    int32_t n_head\
          \  = 40;</span>\n<span class=\"hljs-addition\">+    int32_t n_layer = 40;</span>\n\
          \     int32_t n_rot   = 64;\n     int32_t f16     = 1;\n };\n</code></pre>\n"
        raw: "The fix is this:\r\n\r\n```diff\r\ndiff --git a/main.cpp b/main.cpp\r\
          \nindex 3321818..3fa487b 100644\r\n--- a/main.cpp\r\n+++ b/main.cpp\r\n\
          @@ -34,8 +34,8 @@ static const int EOS_TOKEN_ID = 2;\r\n // determine number\
          \ of model parts based on the dimension\r\n static const std::map<int, int>\
          \ LLAMA_N_PARTS = {\r\n     { 4096, 1 },\r\n-    { 5120, 2 },\r\n-    {\
          \ 6656, 4 },\r\n+    { 5120, 1 },\r\n+    { 6656, 1 },\r\n     { 8192, 8\
          \ },\r\n };\r\n \r\n@@ -43,10 +43,10 @@ static const std::map<int, int>\
          \ LLAMA_N_PARTS = {\r\n struct llama_hparams {\r\n     int32_t n_vocab =\
          \ 32000;\r\n     int32_t n_ctx   = 512;   // this is provided as user input?\r\
          \n-    int32_t n_embd  = 4096;\r\n+    int32_t n_embd  = 5120;\r\n     int32_t\
          \ n_mult  = 256;\r\n-    int32_t n_head  = 32;\r\n-    int32_t n_layer =\
          \ 32;\r\n+    int32_t n_head  = 40;\r\n+    int32_t n_layer = 40;\r\n  \
          \   int32_t n_rot   = 64;\r\n     int32_t f16     = 1;\r\n };\r\n\r\n```"
        updatedAt: '2023-03-21T09:57:22.576Z'
      numEdits: 0
      reactions: []
    id: 64197f82e8a6183a8caacc93
    type: comment
  author: c2d03041
  content: "The fix is this:\r\n\r\n```diff\r\ndiff --git a/main.cpp b/main.cpp\r\n\
    index 3321818..3fa487b 100644\r\n--- a/main.cpp\r\n+++ b/main.cpp\r\n@@ -34,8\
    \ +34,8 @@ static const int EOS_TOKEN_ID = 2;\r\n // determine number of model\
    \ parts based on the dimension\r\n static const std::map<int, int> LLAMA_N_PARTS\
    \ = {\r\n     { 4096, 1 },\r\n-    { 5120, 2 },\r\n-    { 6656, 4 },\r\n+    {\
    \ 5120, 1 },\r\n+    { 6656, 1 },\r\n     { 8192, 8 },\r\n };\r\n \r\n@@ -43,10\
    \ +43,10 @@ static const std::map<int, int> LLAMA_N_PARTS = {\r\n struct llama_hparams\
    \ {\r\n     int32_t n_vocab = 32000;\r\n     int32_t n_ctx   = 512;   // this\
    \ is provided as user input?\r\n-    int32_t n_embd  = 4096;\r\n+    int32_t n_embd\
    \  = 5120;\r\n     int32_t n_mult  = 256;\r\n-    int32_t n_head  = 32;\r\n- \
    \   int32_t n_layer = 32;\r\n+    int32_t n_head  = 40;\r\n+    int32_t n_layer\
    \ = 40;\r\n     int32_t n_rot   = 64;\r\n     int32_t f16     = 1;\r\n };\r\n\r\
    \n```"
  created_at: 2023-03-21 08:57:22+00:00
  edited: false
  hidden: false
  id: 64197f82e8a6183a8caacc93
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/fe585159a71d09896504f02eaa1ebc0b.svg
      fullname: Liam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: c2d03041
      type: user
    createdAt: '2023-03-21T09:57:42.000Z'
    data:
      from: 'lama.cpp: llama_model_load: llama_model_load: tensor ''tok_embeddings.weight''
        has wrong size in model file main'
      to: 'llama.cpp: llama_model_load: llama_model_load: tensor ''tok_embeddings.weight''
        has wrong size in model file main'
    id: 64197f9659097c6418e84950
    type: title-change
  author: c2d03041
  created_at: 2023-03-21 08:57:42+00:00
  id: 64197f9659097c6418e84950
  new_title: 'llama.cpp: llama_model_load: llama_model_load: tensor ''tok_embeddings.weight''
    has wrong size in model file main'
  old_title: 'lama.cpp: llama_model_load: llama_model_load: tensor ''tok_embeddings.weight''
    has wrong size in model file main'
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ac714445aab02c044399cb3f68e8a2fa.svg
      fullname: Dmitry Makarov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mdimai666
      type: user
    createdAt: '2023-03-21T12:14:39.000Z'
    data:
      edited: false
      editors:
      - mdimai666
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ac714445aab02c044399cb3f68e8a2fa.svg
          fullname: Dmitry Makarov
          isHf: false
          isPro: false
          name: mdimai666
          type: user
        html: '<p>its work for me) thanks!</p>

          '
        raw: its work for me) thanks!
        updatedAt: '2023-03-21T12:14:39.099Z'
      numEdits: 0
      reactions: []
    id: 64199faf574e08d856069a42
    type: comment
  author: mdimai666
  content: its work for me) thanks!
  created_at: 2023-03-21 11:14:39+00:00
  edited: false
  hidden: false
  id: 64199faf574e08d856069a42
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
      fullname: Pi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Pi3141
      type: user
    createdAt: '2023-03-21T12:49:10.000Z'
    data:
      edited: false
      editors:
      - Pi3141
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
          fullname: Pi
          isHf: false
          isPro: false
          name: Pi3141
          type: user
        html: '<p>Glad you got it to work. However, just one little comment. It''s
          not anything major that will break stuff. </p>

          <p>llama_hparams doesn''t need to be changed since that''s the default Paramus
          for 7B. If you want to change it, here are the correct values for 30B:<br>int32_t
          n_embd: 6656<br>int32_t n_head: 52<br>int32_t n_layer: 60</p>

          '
        raw: "Glad you got it to work. However, just one little comment. It's not\
          \ anything major that will break stuff. \n\nllama_hparams doesn't need to\
          \ be changed since that's the default Paramus for 7B. If you want to change\
          \ it, here are the correct values for 30B:\nint32_t n_embd: 6656\nint32_t\
          \ n_head: 52\nint32_t n_layer: 60"
        updatedAt: '2023-03-21T12:49:10.311Z'
      numEdits: 0
      reactions: []
    id: 6419a7c6f0415b2ec83563a0
    type: comment
  author: Pi3141
  content: "Glad you got it to work. However, just one little comment. It's not anything\
    \ major that will break stuff. \n\nllama_hparams doesn't need to be changed since\
    \ that's the default Paramus for 7B. If you want to change it, here are the correct\
    \ values for 30B:\nint32_t n_embd: 6656\nint32_t n_head: 52\nint32_t n_layer:\
    \ 60"
  created_at: 2023-03-21 11:49:10+00:00
  edited: false
  hidden: false
  id: 6419a7c6f0415b2ec83563a0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4b682c5ecf848fb1042a4c524726e55a.svg
      fullname: Alejandro Cuevas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Agcuevas
      type: user
    createdAt: '2023-03-22T02:22:37.000Z'
    data:
      edited: false
      editors:
      - Agcuevas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4b682c5ecf848fb1042a4c524726e55a.svg
          fullname: Alejandro Cuevas
          isHf: false
          isPro: false
          name: Agcuevas
          type: user
        html: '<p>how can I recompile the main.cpp once i make the corrections? The
          "npx dalai alpaca install" command takes the old main.cpp from a repository.</p>

          '
        raw: how can I recompile the main.cpp once i make the corrections? The "npx
          dalai alpaca install" command takes the old main.cpp from a repository.
        updatedAt: '2023-03-22T02:22:37.860Z'
      numEdits: 0
      reactions: []
    id: 641a666dd4fe9bc691d603b4
    type: comment
  author: Agcuevas
  content: how can I recompile the main.cpp once i make the corrections? The "npx
    dalai alpaca install" command takes the old main.cpp from a repository.
  created_at: 2023-03-22 01:22:37+00:00
  edited: false
  hidden: false
  id: 641a666dd4fe9bc691d603b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
      fullname: Pi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Pi3141
      type: user
    createdAt: '2023-03-22T02:58:29.000Z'
    data:
      edited: false
      editors:
      - Pi3141
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/615a1b7a321f65c4da59c3d3/799xClAlAoFuljSgOlxs2.png?w=200&h=200&f=face
          fullname: Pi
          isHf: false
          isPro: false
          name: Pi3141
          type: user
        html: '<blockquote>

          <p>how can I recompile the main.cpp once i make the corrections? The "npx
          dalai alpaca install" command takes the old main.cpp from a repository.</p>

          </blockquote>

          <p>Modify alpaca.js in Dalai and change <code>https://github.com/candywrap/alpaca.cpp.git</code>
          to <code>https://github.com/ItsPi3141/alpaca.cpp.git</code></p>

          '
        raw: '> how can I recompile the main.cpp once i make the corrections? The
          "npx dalai alpaca install" command takes the old main.cpp from a repository.


          Modify alpaca.js in Dalai and change `https://github.com/candywrap/alpaca.cpp.git`
          to `https://github.com/ItsPi3141/alpaca.cpp.git`'
        updatedAt: '2023-03-22T02:58:29.134Z'
      numEdits: 0
      reactions: []
    id: 641a6ed5b351b601790c92f8
    type: comment
  author: Pi3141
  content: '> how can I recompile the main.cpp once i make the corrections? The "npx
    dalai alpaca install" command takes the old main.cpp from a repository.


    Modify alpaca.js in Dalai and change `https://github.com/candywrap/alpaca.cpp.git`
    to `https://github.com/ItsPi3141/alpaca.cpp.git`'
  created_at: 2023-03-22 01:58:29+00:00
  edited: false
  hidden: false
  id: 641a6ed5b351b601790c92f8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Pi3141/alpaca-lora-30B-ggml
repo_type: model
status: open
target_branch: null
title: 'llama.cpp: llama_model_load: llama_model_load: tensor ''tok_embeddings.weight''
  has wrong size in model file main'
