!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ehrencrona
conflicting_files: null
created_at: 2022-07-20 14:27:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e4b4a9b050821ebadac45feb6f80c3e9.svg
      fullname: Andreas Ehrencrona
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ehrencrona
      type: user
    createdAt: '2022-07-20T15:27:09.000Z'
    data:
      edited: false
      editors:
      - ehrencrona
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e4b4a9b050821ebadac45feb6f80c3e9.svg
          fullname: Andreas Ehrencrona
          isHf: false
          isPro: false
          name: ehrencrona
          type: user
        html: '<p>There seems to be more tokens defined in the tokenizer than in the
          model config:</p>

          <pre><code>from transformers import TFGPT2LMHeadModel, GPT2Tokenizer


          cls = "birgermoell/swedish-gpt"


          model = TFGPT2LMHeadModel.from_pretrained(cls, from_pt=True)

          tokenizer = GPT2Tokenizer.from_pretrained(cls)


          (tokenizer.vocab_size, model.config.vocab_size)

          </code></pre>

          <p>gives me</p>

          <p><code>(50265, 50257)</code> </p>

          <p>Could there be some sort of version mismatch?</p>

          '
        raw: "There seems to be more tokens defined in the tokenizer than in the model\
          \ config:\r\n\r\n```\r\nfrom transformers import TFGPT2LMHeadModel, GPT2Tokenizer\r\
          \n\r\ncls = \"birgermoell/swedish-gpt\"\r\n\r\nmodel = TFGPT2LMHeadModel.from_pretrained(cls,\
          \ from_pt=True)\r\ntokenizer = GPT2Tokenizer.from_pretrained(cls)\r\n\r\n\
          (tokenizer.vocab_size, model.config.vocab_size)\r\n```\r\n\r\ngives me\r\
          \n\r\n```(50265, 50257)``` \r\n\r\nCould there be some sort of version mismatch?\r\
          \n"
        updatedAt: '2022-07-20T15:27:09.306Z'
      numEdits: 0
      reactions: []
    id: 62d81ecdad693a1a9627c02c
    type: comment
  author: ehrencrona
  content: "There seems to be more tokens defined in the tokenizer than in the model\
    \ config:\r\n\r\n```\r\nfrom transformers import TFGPT2LMHeadModel, GPT2Tokenizer\r\
    \n\r\ncls = \"birgermoell/swedish-gpt\"\r\n\r\nmodel = TFGPT2LMHeadModel.from_pretrained(cls,\
    \ from_pt=True)\r\ntokenizer = GPT2Tokenizer.from_pretrained(cls)\r\n\r\n(tokenizer.vocab_size,\
    \ model.config.vocab_size)\r\n```\r\n\r\ngives me\r\n\r\n```(50265, 50257)```\
    \ \r\n\r\nCould there be some sort of version mismatch?\r\n"
  created_at: 2022-07-20 14:27:09+00:00
  edited: false
  hidden: false
  id: 62d81ecdad693a1a9627c02c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e4b4a9b050821ebadac45feb6f80c3e9.svg
      fullname: Andreas Ehrencrona
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ehrencrona
      type: user
    createdAt: '2022-07-20T15:45:21.000Z'
    data:
      edited: false
      editors:
      - ehrencrona
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e4b4a9b050821ebadac45feb6f80c3e9.svg
          fullname: Andreas Ehrencrona
          isHf: false
          isPro: false
          name: ehrencrona
          type: user
        html: '<p>BTW, this can also be seen by entering "asha" in the inference input
          field, which gives you an "unknown error". This is because it''s one of
          the last words in the vocabulary and therefore results in an out of range
          index somewhere.</p>

          '
        raw: BTW, this can also be seen by entering "asha" in the inference input
          field, which gives you an "unknown error". This is because it's one of the
          last words in the vocabulary and therefore results in an out of range index
          somewhere.
        updatedAt: '2022-07-20T15:45:21.556Z'
      numEdits: 0
      reactions: []
    id: 62d823114de25ae5d52b3fd2
    type: comment
  author: ehrencrona
  content: BTW, this can also be seen by entering "asha" in the inference input field,
    which gives you an "unknown error". This is because it's one of the last words
    in the vocabulary and therefore results in an out of range index somewhere.
  created_at: 2022-07-20 14:45:21+00:00
  edited: false
  hidden: false
  id: 62d823114de25ae5d52b3fd2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: birgermoell/swedish-gpt
repo_type: model
status: open
target_branch: null
title: Vocabulary size mismatch between tokenizer and model
