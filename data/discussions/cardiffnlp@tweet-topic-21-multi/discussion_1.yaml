!!python/object:huggingface_hub.community.DiscussionWithDetails
author: thaheem422
conflicting_files: null
created_at: 2022-08-04 09:52:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d02aec3b2e601249feb5c6515a4e6e2c.svg
      fullname: Muhammad Arslan Thaheem
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thaheem422
      type: user
    createdAt: '2022-08-04T10:52:33.000Z'
    data:
      edited: false
      editors:
      - thaheem422
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d02aec3b2e601249feb5c6515a4e6e2c.svg
          fullname: Muhammad Arslan Thaheem
          isHf: false
          isPro: false
          name: thaheem422
          type: user
        html: '<p>Hi, I am having an issue with the results. I am getting different
          results on hugging face website and by using code on my computer. The results
          on hugging face are correct but I get incorrect results on my computer.
          for example I get "learning and educational" on hugging face and "business
          and entrepreneurship" on my computer for "The best way to predict the future
          is to create it.<br>@ferozekhaan."</p>

          '
        raw: "Hi, I am having an issue with the results. I am getting different results\
          \ on hugging face website and by using code on my computer. The results\
          \ on hugging face are correct but I get incorrect results on my computer.\
          \ for example I get \"learning and educational\" on hugging face and \"\
          business and entrepreneurship\" on my computer for \"The best way to predict\
          \ the future is to create it. \r\n@ferozekhaan.\""
        updatedAt: '2022-08-04T10:52:33.839Z'
      numEdits: 0
      reactions: []
    id: 62eba4f1e344293995e4f35a
    type: comment
  author: thaheem422
  content: "Hi, I am having an issue with the results. I am getting different results\
    \ on hugging face website and by using code on my computer. The results on hugging\
    \ face are correct but I get incorrect results on my computer. for example I get\
    \ \"learning and educational\" on hugging face and \"business and entrepreneurship\"\
    \ on my computer for \"The best way to predict the future is to create it. \r\n\
    @ferozekhaan.\""
  created_at: 2022-08-04 09:52:33+00:00
  edited: false
  hidden: false
  id: 62eba4f1e344293995e4f35a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8a5b8377c821ddcc2d2ba3bf394f4581.svg
      fullname: Dimosthenis Antypas
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: antypasd
      type: user
    createdAt: '2022-08-04T11:32:11.000Z'
    data:
      edited: true
      editors:
      - antypasd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8a5b8377c821ddcc2d2ba3bf394f4581.svg
          fullname: Dimosthenis Antypas
          isHf: false
          isPro: false
          name: antypasd
          type: user
        html: '<p>Hello, I  tried the example you provided on Google''s colab and
          I am getting "learning and educational" as on hugging face. I am not really
          sure why are you getting different results to be honest. Maybe try setting
          the model to evaluation by using <code>model.eval()</code> before making
          the predictions. Can you provide some more info about your setup.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1659612517272-62459586c77c7a30e2a664ea.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1659612517272-62459586c77c7a30e2a664ea.png"></a></p>

          <pre><code># Torch

          model = AutoModelForSequenceClassification.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')

          tokenizer = AutoTokenizer.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')


          class_mapping = model.config.id2label



          tokens = tokenizer(text, return_tensors=''pt'')

          output = model(**tokens)


          scores = output[0][0].detach().numpy()

          scores = expit(scores)

          print(class_mapping[np.argmax(scores)])


          &gt;&gt; ''learning_&amp;_educational''


          # TF

          tf_model = TFAutoModelForSequenceClassification.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')

          tokenizer = AutoTokenizer.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')


          class_mapping = model.config.id2label


          # Example text

          text = "The best way to predict the future is to create it. @ferozekhaan."

          tokens = tokenizer(text, return_tensors=''tf'')

          output = tf_model(**tokens)

          scores = output[0][0]


          print(class_mapping[np.argmax(scores)])

          &gt;&gt; learning_&amp;_educational

          </code></pre>

          '
        raw: 'Hello, I  tried the example you provided on Google''s colab and I am
          getting "learning and educational" as on hugging face. I am not really sure
          why are you getting different results to be honest. Maybe try setting the
          model to evaluation by using `model.eval()` before making the predictions.
          Can you provide some more info about your setup.




          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1659612517272-62459586c77c7a30e2a664ea.png)



          ```

          # Torch

          model = AutoModelForSequenceClassification.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')

          tokenizer = AutoTokenizer.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')


          class_mapping = model.config.id2label



          tokens = tokenizer(text, return_tensors=''pt'')

          output = model(**tokens)


          scores = output[0][0].detach().numpy()

          scores = expit(scores)

          print(class_mapping[np.argmax(scores)])


          >> ''learning_&_educational''


          # TF

          tf_model = TFAutoModelForSequenceClassification.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')

          tokenizer = AutoTokenizer.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')


          class_mapping = model.config.id2label


          # Example text

          text = "The best way to predict the future is to create it. @ferozekhaan."

          tokens = tokenizer(text, return_tensors=''tf'')

          output = tf_model(**tokens)

          scores = output[0][0]


          print(class_mapping[np.argmax(scores)])

          >> learning_&_educational

          ```'
        updatedAt: '2022-08-04T11:32:35.055Z'
      numEdits: 1
      reactions: []
    id: 62ebae3b665533d42abfb060
    type: comment
  author: antypasd
  content: 'Hello, I  tried the example you provided on Google''s colab and I am getting
    "learning and educational" as on hugging face. I am not really sure why are you
    getting different results to be honest. Maybe try setting the model to evaluation
    by using `model.eval()` before making the predictions. Can you provide some more
    info about your setup.




    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1659612517272-62459586c77c7a30e2a664ea.png)



    ```

    # Torch

    model = AutoModelForSequenceClassification.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')

    tokenizer = AutoTokenizer.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')


    class_mapping = model.config.id2label



    tokens = tokenizer(text, return_tensors=''pt'')

    output = model(**tokens)


    scores = output[0][0].detach().numpy()

    scores = expit(scores)

    print(class_mapping[np.argmax(scores)])


    >> ''learning_&_educational''


    # TF

    tf_model = TFAutoModelForSequenceClassification.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')

    tokenizer = AutoTokenizer.from_pretrained(''cardiffnlp/tweet-topic-21-multi'')


    class_mapping = model.config.id2label


    # Example text

    text = "The best way to predict the future is to create it. @ferozekhaan."

    tokens = tokenizer(text, return_tensors=''tf'')

    output = tf_model(**tokens)

    scores = output[0][0]


    print(class_mapping[np.argmax(scores)])

    >> learning_&_educational

    ```'
  created_at: 2022-08-04 10:32:11+00:00
  edited: true
  hidden: false
  id: 62ebae3b665533d42abfb060
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: cardiffnlp/tweet-topic-21-multi
repo_type: model
status: open
target_branch: null
title: Different results on hugging face and by using code
