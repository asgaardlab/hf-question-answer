!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Alrat233
conflicting_files: null
created_at: 2023-10-26 02:38:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2c64357f4a58c708d2975bbc6a0e9303.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Alrat233
      type: user
    createdAt: '2023-10-26T03:38:30.000Z'
    data:
      edited: false
      editors:
      - Alrat233
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9769864678382874
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2c64357f4a58c708d2975bbc6a0e9303.svg
          fullname: Liu
          isHf: false
          isPro: false
          name: Alrat233
          type: user
        html: '<p>I used both 2.4bpw and 2.18bpw of this model for comparison because
          my 3090 was running low on  memory using 2.4bpw.I found that with 2.18bpw,
          after multiple rounds of dialogue, it was easy to repeat the dialogue, such
          as "go to your bedroom", which would repeat the meaning three times with
          three different sentence patterns.My repeated penalty setting is 1.15, using
          the L2 recommended setting.<br>Finally, I like the  model after quantization
          very much. Compared with the 20B model, the 70B model can really understand
          what is the perspective of {{char}} and maintain its own role  in role-playing,
          and will no longer speak or act for {{user}} at will. The use effect is
          very good</p>

          '
        raw: "I used both 2.4bpw and 2.18bpw of this model for comparison because\
          \ my 3090 was running low on  memory using 2.4bpw.I found that with 2.18bpw,\
          \ after multiple rounds of dialogue, it was easy to repeat the dialogue,\
          \ such as \"go to your bedroom\", which would repeat the meaning three times\
          \ with three different sentence patterns.My repeated penalty setting is\
          \ 1.15, using the L2 recommended setting.\r\nFinally, I like the  model\
          \ after quantization very much. Compared with the 20B model, the 70B model\
          \ can really understand what is the perspective of {{char}} and maintain\
          \ its own role  in role-playing, and will no longer speak or act for {{user}}\
          \ at will. The use effect is very good"
        updatedAt: '2023-10-26T03:38:30.676Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - waldie
    id: 6539df36907002a4e19b4109
    type: comment
  author: Alrat233
  content: "I used both 2.4bpw and 2.18bpw of this model for comparison because my\
    \ 3090 was running low on  memory using 2.4bpw.I found that with 2.18bpw, after\
    \ multiple rounds of dialogue, it was easy to repeat the dialogue, such as \"\
    go to your bedroom\", which would repeat the meaning three times with three different\
    \ sentence patterns.My repeated penalty setting is 1.15, using the L2 recommended\
    \ setting.\r\nFinally, I like the  model after quantization very much. Compared\
    \ with the 20B model, the 70B model can really understand what is the perspective\
    \ of {{char}} and maintain its own role  in role-playing, and will no longer speak\
    \ or act for {{user}} at will. The use effect is very good"
  created_at: 2023-10-26 02:38:30+00:00
  edited: false
  hidden: false
  id: 6539df36907002a4e19b4109
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: waldie/Euryale-1.3-L2-70B-2.18bpw-h6-exl2
repo_type: model
status: open
target_branch: null
title: Thanks. It's working fine
