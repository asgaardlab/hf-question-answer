!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kunnik
conflicting_files: null
created_at: 2022-10-28 18:28:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/abfd6e1cbb5b100508ec6a1734b5b958.svg
      fullname: KP Unnikrishnan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kunnik
      type: user
    createdAt: '2022-10-28T19:28:09.000Z'
    data:
      edited: false
      editors:
      - kunnik
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/abfd6e1cbb5b100508ec6a1734b5b958.svg
          fullname: KP Unnikrishnan
          isHf: false
          isPro: false
          name: kunnik
          type: user
        html: '<p>After the pre-learning phase, I would like to provide an image to
          the model and see its representation at each level of the latent space.
          Could someone advice me how I can do this? I have not found an easy way.</p>

          <p>Initially I don''t need to see the representations in the entire encoder-decoder;
          just its part used for Diffusion.</p>

          <p>I am a researcher who works in bringing architectures and algorithms
          from Neuroscience into Deep Learning. Here, I want to see the Representations
          and Operations (R &amp; O) in each of the latent spaces. The mammalian visual
          system has optimized its R&amp;O over millions of years and I have an inkling
          that some of it can enhance the current version of Latent/Stable Diffusion
          models.</p>

          <p>Unni</p>

          <p>KP Unnikrishnan, PhD<br>eNeuroLearn, Ann Arbor, MI</p>

          '
        raw: "After the pre-learning phase, I would like to provide an image to the\
          \ model and see its representation at each level of the latent space. Could\
          \ someone advice me how I can do this? I have not found an easy way.\r\n\
          \r\nInitially I don't need to see the representations in the entire encoder-decoder;\
          \ just its part used for Diffusion.\r\n\r\nI am a researcher who works in\
          \ bringing architectures and algorithms from Neuroscience into Deep Learning.\
          \ Here, I want to see the Representations and Operations (R & O) in each\
          \ of the latent spaces. The mammalian visual system has optimized its R&O\
          \ over millions of years and I have an inkling that some of it can enhance\
          \ the current version of Latent/Stable Diffusion models.\r\n\r\nUnni\r\n\
          \r\nKP Unnikrishnan, PhD\r\neNeuroLearn, Ann Arbor, MI\r\n"
        updatedAt: '2022-10-28T19:28:09.377Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - mishig
        - alex-ianosi
    id: 635c2d491a1cf10f9e5ce66b
    type: comment
  author: kunnik
  content: "After the pre-learning phase, I would like to provide an image to the\
    \ model and see its representation at each level of the latent space. Could someone\
    \ advice me how I can do this? I have not found an easy way.\r\n\r\nInitially\
    \ I don't need to see the representations in the entire encoder-decoder; just\
    \ its part used for Diffusion.\r\n\r\nI am a researcher who works in bringing\
    \ architectures and algorithms from Neuroscience into Deep Learning. Here, I want\
    \ to see the Representations and Operations (R & O) in each of the latent spaces.\
    \ The mammalian visual system has optimized its R&O over millions of years and\
    \ I have an inkling that some of it can enhance the current version of Latent/Stable\
    \ Diffusion models.\r\n\r\nUnni\r\n\r\nKP Unnikrishnan, PhD\r\neNeuroLearn, Ann\
    \ Arbor, MI\r\n"
  created_at: 2022-10-28 18:28:09+00:00
  edited: false
  hidden: false
  id: 635c2d491a1cf10f9e5ce66b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/abfd6e1cbb5b100508ec6a1734b5b958.svg
      fullname: KP Unnikrishnan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kunnik
      type: user
    createdAt: '2022-11-01T14:12:00.000Z'
    data:
      edited: false
      editors:
      - kunnik
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/abfd6e1cbb5b100508ec6a1734b5b958.svg
          fullname: KP Unnikrishnan
          isHf: false
          isPro: false
          name: kunnik
          type: user
        html: '<p>This is a follow-up to my earlier post; it is a copy of my LinkedIn
          post today.</p>

          <p>Neuroscience can help Stable Diffusion</p>

          <p>This is a follow-up to my last post on #latentspace representations in
          #stablediffusion models. I now have a clearer picture on how #neuroscience
          can help.</p>

          <p>Here are a few images from the most helpful #github notebook by johnowhitaker
          and banacl:</p>

          <p>The LHS is the input and the RHS is the output of the Autoencoder. The
          box in the middle shows the #latentspace representations of this parrot.
          Notice how you can look at each of the images within the box and recognize
          that it is a parrot. That is because the latent spaces of this #stablediffusion
          model is in what neuroscientists call retino-topic representations.</p>

          <p>In the mammalian visual system, retino-topic representations disappear
          after the first stage (LGN). All "mammalian latent spaces" are in feature-extracted
          representations. Since this system has evolved over hundreds of millions
          of years, it has been optimized for #perception and #cognition.</p>

          <p>I would like to posit that the current #stablediffusion models can become
          a lot more efficient by incorporating some "Neurosciene Inside". I plan
          to pursue this. If anyone is interested, please drop me a note via #linkedin
          or to kunnik at gmail dot com.<br>Activate to view larger image</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1667311752522-635c2070ca038892de068259.png"><img
          alt="Parrot-latent.png" src="https://cdn-uploads.huggingface.co/production/uploads/1667311752522-635c2070ca038892de068259.png"></a></p>

          '
        raw: 'This is a follow-up to my earlier post; it is a copy of my LinkedIn
          post today.


          Neuroscience can help Stable Diffusion


          This is a follow-up to my last post on #latentspace representations in #stablediffusion
          models. I now have a clearer picture on how #neuroscience can help.


          Here are a few images from the most helpful #github notebook by johnowhitaker
          and banacl:


          The LHS is the input and the RHS is the output of the Autoencoder. The box
          in the middle shows the #latentspace representations of this parrot. Notice
          how you can look at each of the images within the box and recognize that
          it is a parrot. That is because the latent spaces of this #stablediffusion
          model is in what neuroscientists call retino-topic representations.


          In the mammalian visual system, retino-topic representations disappear after
          the first stage (LGN). All "mammalian latent spaces" are in feature-extracted
          representations. Since this system has evolved over hundreds of millions
          of years, it has been optimized for #perception and #cognition.


          I would like to posit that the current #stablediffusion models can become
          a lot more efficient by incorporating some "Neurosciene Inside". I plan
          to pursue this. If anyone is interested, please drop me a note via #linkedin
          or to kunnik at gmail dot com.

          Activate to view larger image



          ![Parrot-latent.png](https://cdn-uploads.huggingface.co/production/uploads/1667311752522-635c2070ca038892de068259.png)

          '
        updatedAt: '2022-11-01T14:12:00.280Z'
      numEdits: 0
      reactions: []
      relatedEventId: 636129306945df7441b1a4c7
    id: 636129306945df7441b1a4c6
    type: comment
  author: kunnik
  content: 'This is a follow-up to my earlier post; it is a copy of my LinkedIn post
    today.


    Neuroscience can help Stable Diffusion


    This is a follow-up to my last post on #latentspace representations in #stablediffusion
    models. I now have a clearer picture on how #neuroscience can help.


    Here are a few images from the most helpful #github notebook by johnowhitaker
    and banacl:


    The LHS is the input and the RHS is the output of the Autoencoder. The box in
    the middle shows the #latentspace representations of this parrot. Notice how you
    can look at each of the images within the box and recognize that it is a parrot.
    That is because the latent spaces of this #stablediffusion model is in what neuroscientists
    call retino-topic representations.


    In the mammalian visual system, retino-topic representations disappear after the
    first stage (LGN). All "mammalian latent spaces" are in feature-extracted representations.
    Since this system has evolved over hundreds of millions of years, it has been
    optimized for #perception and #cognition.


    I would like to posit that the current #stablediffusion models can become a lot
    more efficient by incorporating some "Neurosciene Inside". I plan to pursue this.
    If anyone is interested, please drop me a note via #linkedin or to kunnik at gmail
    dot com.

    Activate to view larger image



    ![Parrot-latent.png](https://cdn-uploads.huggingface.co/production/uploads/1667311752522-635c2070ca038892de068259.png)

    '
  created_at: 2022-11-01 13:12:00+00:00
  edited: false
  hidden: false
  id: 636129306945df7441b1a4c6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/abfd6e1cbb5b100508ec6a1734b5b958.svg
      fullname: KP Unnikrishnan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kunnik
      type: user
    createdAt: '2022-11-01T14:12:00.000Z'
    data:
      status: closed
    id: 636129306945df7441b1a4c7
    type: status-change
  author: kunnik
  created_at: 2022-11-01 13:12:00+00:00
  id: 636129306945df7441b1a4c7
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 136
repo_id: CompVis/stable-diffusion-v1-4
repo_type: model
status: closed
target_branch: null
title: Internal representations in Latent Spaces
