!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sgt101
conflicting_files: null
created_at: 2022-08-26 17:32:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e267426537c8c6649155116e248ee496.svg
      fullname: simon thompson
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sgt101
      type: user
    createdAt: '2022-08-26T18:32:57.000Z'
    data:
      edited: false
      editors:
      - sgt101
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e267426537c8c6649155116e248ee496.svg
          fullname: simon thompson
          isHf: false
          isPro: false
          name: sgt101
          type: user
        html: '<p>I tried changing the device to MPS... but no dice..</p>

          <p>torch.backends.mps.is_available() is true - but autocast is defeating
          me </p>

          <p>Any ideas? </p>

          '
        raw: "I tried changing the device to MPS... but no dice..\r\n\r\ntorch.backends.mps.is_available()\
          \ is true - but autocast is defeating me \r\n\r\nAny ideas? "
        updatedAt: '2022-08-26T18:32:57.502Z'
      numEdits: 0
      reactions: []
    id: 630911d9ff78e2aead91c86d
    type: comment
  author: sgt101
  content: "I tried changing the device to MPS... but no dice..\r\n\r\ntorch.backends.mps.is_available()\
    \ is true - but autocast is defeating me \r\n\r\nAny ideas? "
  created_at: 2022-08-26 17:32:57+00:00
  edited: false
  hidden: false
  id: 630911d9ff78e2aead91c86d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1642412329881-5e6b7a61d4cd9779932a7601.png?w=200&h=200&f=face
      fullname: Loreto Parisi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: loretoparisi
      type: user
    createdAt: '2022-08-26T18:58:24.000Z'
    data:
      edited: true
      editors:
      - loretoparisi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1642412329881-5e6b7a61d4cd9779932a7601.png?w=200&h=200&f=face
          fullname: Loreto Parisi
          isHf: false
          isPro: false
          name: loretoparisi
          type: user
        html: "<p>This script works on Apple M1</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\"\
          >from</span> PIL <span class=\"hljs-keyword\">import</span> Image\n<span\
          \ class=\"hljs-keyword\">from</span> io <span class=\"hljs-keyword\">import</span>\
          \ BytesIO\n\n<span class=\"hljs-keyword\">from</span> torch <span class=\"\
          hljs-keyword\">import</span> autocast\n\n<span class=\"hljs-keyword\">from</span>\
          \ image_to_image <span class=\"hljs-keyword\">import</span> *\n\ndevice\
          \ = <span class=\"hljs-string\">'cuda'</span> <span class=\"hljs-keyword\"\
          >if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span>\
          \ <span class=\"hljs-string\">'cpu'</span>\n<span class=\"hljs-built_in\"\
          >print</span>(<span class=\"hljs-string\">f'running on <span class=\"hljs-subst\"\
          >{device}</span>'</span>)\n\npipei2i = StableDiffusionImg2ImgPipeline.from_pretrained(\n\
          \    <span class=\"hljs-string\">\"CompVis/stable-diffusion-v1-4\"</span>,\n\
          \    <span class=\"hljs-comment\">#revision=\"fp16\", </span>\n    <span\
          \ class=\"hljs-comment\">#torch_dtype=torch.float16,</span>\n    use_auth_token=<span\
          \ class=\"hljs-literal\">True</span>\n).to(device)\n\n\nresponse = requests.get(<span\
          \ class=\"hljs-string\">'https://pbs.twimg.com/media/Fa1_7_vWYAEwfX-.png'</span>)\n\
          init_image = Image.<span class=\"hljs-built_in\">open</span>(BytesIO(response.content)).convert(<span\
          \ class=\"hljs-string\">\"RGB\"</span>)\ninit_image = init_image.resize((<span\
          \ class=\"hljs-number\">512</span>, <span class=\"hljs-number\">512</span>))\n\
          init_image = preprocess(init_image)\n\nprompt = <span class=\"hljs-string\"\
          >\"a cat, artstation\"</span>\nsamples = <span class=\"hljs-number\">2</span>\n\
          steps = <span class=\"hljs-number\">50</span>\nstrength = <span class=\"\
          hljs-number\">0.75</span>\nscale = <span class=\"hljs-number\">7.5</span>\n\
          outputs = []\n<span class=\"hljs-keyword\">if</span> device==<span class=\"\
          hljs-string\">'cuda'</span>:\n    <span class=\"hljs-keyword\">with</span>\
          \ autocast(<span class=\"hljs-string\">\"cuda\"</span>):\n        outputs\
          \ = pipei2i(prompt=[prompt]*samples, \n            init_image=init_image,\
          \ \n            strength=strength,\n            num_inference_steps=steps,\n\
          \            guidance_scale=scale)\n<span class=\"hljs-keyword\">else</span>:\n\
          \    outputs = pipei2i(prompt=[prompt]*samples, \n        init_image=init_image,\
          \ \n        strength=strength,\n        num_inference_steps=steps,\n   \
          \     guidance_scale=scale)\n\nsafe_images = []\nunsafe_images = []\n<span\
          \ class=\"hljs-comment\"># {'sample': [&lt;PIL.Image.Image image mode=RGB\
          \ size=512x512 at 0x7FEE48615510&gt;], 'nsfw_content_detected': [False]}</span>\n\
          <span class=\"hljs-keyword\">for</span> i, image <span class=\"hljs-keyword\"\
          >in</span> <span class=\"hljs-built_in\">enumerate</span>(outputs[<span\
          \ class=\"hljs-string\">\"sample\"</span>]):\n    <span class=\"hljs-keyword\"\
          >if</span>(outputs[<span class=\"hljs-string\">\"nsfw_content_detected\"\
          </span>][i]):\n        unsafe_images.append(image)\n    <span class=\"hljs-keyword\"\
          >else</span>:\n        safe_images.append(image)\n\n<span class=\"hljs-keyword\"\
          >for</span> (index,image) <span class=\"hljs-keyword\">in</span> <span class=\"\
          hljs-built_in\">enumerate</span>(safe_images):\n    image.save(<span class=\"\
          hljs-string\">f\"safe_<span class=\"hljs-subst\">{index}</span>.png\"</span>)\n\
          <span class=\"hljs-keyword\">for</span> (index,image) <span class=\"hljs-keyword\"\
          >in</span> <span class=\"hljs-built_in\">enumerate</span>(unsafe_images):\n\
          \    image.save(<span class=\"hljs-string\">f\"unsafe_<span class=\"hljs-subst\"\
          >{index}</span>.png\"</span>)\n</code></pre>\n<p>requirements are</p>\n\
          <pre><code>scipy\ntorch\ntransformers\ndiffusers\nftfy\n</code></pre>\n\
          <p>This is what I can see from Activity Monitor during the operation<br><a\
          \ rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1661540269785-5e6b7a61d4cd9779932a7601.png\"\
          ><img alt=\"Screenshot 2022-08-26 at 20.57.31.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1661540269785-5e6b7a61d4cd9779932a7601.png\"\
          ></a></p>\n<p>See <a rel=\"nofollow\" href=\"https://github.com/huggingface/diffusers/issues/239\"\
          >here</a> for more details and dependencies.</p>\n"
        raw: "This script works on Apple M1\n\n```python\nimport requests\nfrom PIL\
          \ import Image\nfrom io import BytesIO\n\nfrom torch import autocast\n\n\
          from image_to_image import *\n\ndevice = 'cuda' if torch.cuda.is_available()\
          \ else 'cpu'\nprint(f'running on {device}')\n\npipei2i = StableDiffusionImg2ImgPipeline.from_pretrained(\n\
          \    \"CompVis/stable-diffusion-v1-4\",\n    #revision=\"fp16\", \n    #torch_dtype=torch.float16,\n\
          \    use_auth_token=True\n).to(device)\n\n\nresponse = requests.get('https://pbs.twimg.com/media/Fa1_7_vWYAEwfX-.png')\n\
          init_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\ninit_image\
          \ = init_image.resize((512, 512))\ninit_image = preprocess(init_image)\n\
          \nprompt = \"a cat, artstation\"\nsamples = 2\nsteps = 50\nstrength = 0.75\n\
          scale = 7.5\noutputs = []\nif device=='cuda':\n    with autocast(\"cuda\"\
          ):\n        outputs = pipei2i(prompt=[prompt]*samples, \n            init_image=init_image,\
          \ \n            strength=strength,\n            num_inference_steps=steps,\n\
          \            guidance_scale=scale)\nelse:\n    outputs = pipei2i(prompt=[prompt]*samples,\
          \ \n        init_image=init_image, \n        strength=strength,\n      \
          \  num_inference_steps=steps,\n        guidance_scale=scale)\n\nsafe_images\
          \ = []\nunsafe_images = []\n# {'sample': [<PIL.Image.Image image mode=RGB\
          \ size=512x512 at 0x7FEE48615510>], 'nsfw_content_detected': [False]}\n\
          for i, image in enumerate(outputs[\"sample\"]):\n    if(outputs[\"nsfw_content_detected\"\
          ][i]):\n        unsafe_images.append(image)\n    else:\n        safe_images.append(image)\n\
          \nfor (index,image) in enumerate(safe_images):\n    image.save(f\"safe_{index}.png\"\
          )\nfor (index,image) in enumerate(unsafe_images):\n    image.save(f\"unsafe_{index}.png\"\
          )\n```\n\nrequirements are\n\n```\nscipy\ntorch\ntransformers\ndiffusers\n\
          ftfy\n```\n\nThis is what I can see from Activity Monitor during the operation\n\
          ![Screenshot 2022-08-26 at 20.57.31.png](https://cdn-uploads.huggingface.co/production/uploads/1661540269785-5e6b7a61d4cd9779932a7601.png)\n\
          \n\nSee [here](https://github.com/huggingface/diffusers/issues/239) for\
          \ more details and dependencies."
        updatedAt: '2022-08-26T19:06:42.163Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - patrickvonplaten
    id: 630917d01a8d77fa319047c4
    type: comment
  author: loretoparisi
  content: "This script works on Apple M1\n\n```python\nimport requests\nfrom PIL\
    \ import Image\nfrom io import BytesIO\n\nfrom torch import autocast\n\nfrom image_to_image\
    \ import *\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'running\
    \ on {device}')\n\npipei2i = StableDiffusionImg2ImgPipeline.from_pretrained(\n\
    \    \"CompVis/stable-diffusion-v1-4\",\n    #revision=\"fp16\", \n    #torch_dtype=torch.float16,\n\
    \    use_auth_token=True\n).to(device)\n\n\nresponse = requests.get('https://pbs.twimg.com/media/Fa1_7_vWYAEwfX-.png')\n\
    init_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\ninit_image\
    \ = init_image.resize((512, 512))\ninit_image = preprocess(init_image)\n\nprompt\
    \ = \"a cat, artstation\"\nsamples = 2\nsteps = 50\nstrength = 0.75\nscale = 7.5\n\
    outputs = []\nif device=='cuda':\n    with autocast(\"cuda\"):\n        outputs\
    \ = pipei2i(prompt=[prompt]*samples, \n            init_image=init_image, \n \
    \           strength=strength,\n            num_inference_steps=steps,\n     \
    \       guidance_scale=scale)\nelse:\n    outputs = pipei2i(prompt=[prompt]*samples,\
    \ \n        init_image=init_image, \n        strength=strength,\n        num_inference_steps=steps,\n\
    \        guidance_scale=scale)\n\nsafe_images = []\nunsafe_images = []\n# {'sample':\
    \ [<PIL.Image.Image image mode=RGB size=512x512 at 0x7FEE48615510>], 'nsfw_content_detected':\
    \ [False]}\nfor i, image in enumerate(outputs[\"sample\"]):\n    if(outputs[\"\
    nsfw_content_detected\"][i]):\n        unsafe_images.append(image)\n    else:\n\
    \        safe_images.append(image)\n\nfor (index,image) in enumerate(safe_images):\n\
    \    image.save(f\"safe_{index}.png\")\nfor (index,image) in enumerate(unsafe_images):\n\
    \    image.save(f\"unsafe_{index}.png\")\n```\n\nrequirements are\n\n```\nscipy\n\
    torch\ntransformers\ndiffusers\nftfy\n```\n\nThis is what I can see from Activity\
    \ Monitor during the operation\n![Screenshot 2022-08-26 at 20.57.31.png](https://cdn-uploads.huggingface.co/production/uploads/1661540269785-5e6b7a61d4cd9779932a7601.png)\n\
    \n\nSee [here](https://github.com/huggingface/diffusers/issues/239) for more details\
    \ and dependencies."
  created_at: 2022-08-26 17:58:24+00:00
  edited: true
  hidden: false
  id: 630917d01a8d77fa319047c4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c9b4c997095f48aa8f4c316c744d81b5.svg
      fullname: Farley Lai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: farleylai
      type: user
    createdAt: '2022-08-28T19:20:26.000Z'
    data:
      edited: false
      editors:
      - farleylai
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c9b4c997095f48aa8f4c316c744d81b5.svg
          fullname: Farley Lai
          isHf: false
          isPro: false
          name: farleylai
          type: user
        html: '<p>See discussions and instructions here for M1/M2 setup:<br><a rel="nofollow"
          href="https://github.com/CompVis/stable-diffusion/issues/25#issuecomment-1229430133">https://github.com/CompVis/stable-diffusion/issues/25#issuecomment-1229430133</a></p>

          '
        raw: 'See discussions and instructions here for M1/M2 setup:

          https://github.com/CompVis/stable-diffusion/issues/25#issuecomment-1229430133'
        updatedAt: '2022-08-28T19:20:26.926Z'
      numEdits: 0
      reactions: []
    id: 630bbffa79d18d5e53e7a9c2
    type: comment
  author: farleylai
  content: 'See discussions and instructions here for M1/M2 setup:

    https://github.com/CompVis/stable-diffusion/issues/25#issuecomment-1229430133'
  created_at: 2022-08-28 18:20:26+00:00
  edited: false
  hidden: false
  id: 630bbffa79d18d5e53e7a9c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1642412329881-5e6b7a61d4cd9779932a7601.png?w=200&h=200&f=face
      fullname: Loreto Parisi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: loretoparisi
      type: user
    createdAt: '2022-08-31T14:29:10.000Z'
    data:
      edited: true
      editors:
      - loretoparisi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1642412329881-5e6b7a61d4cd9779932a7601.png?w=200&h=200&f=face
          fullname: Loreto Parisi
          isHf: false
          isPro: false
          name: loretoparisi
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;patrickvonplaten&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/patrickvonplaten\"\
          >@<span class=\"underline\">patrickvonplaten</span></a></span>\n\n\t</span></span>\
          \ I now get</p>\n<pre><code>TypeError: Cannot convert a MPS Tensor to float64\
          \ dtype as the MPS framework doesn't support float64. Please use float32\
          \ instead.\n</code></pre>\n<p> setting the fallback <code>export PYTORCH_ENABLE_MPS_FALLBACK=1;</code>\
          \ it works as I can clearly see it from logs:</p>\n<pre><code> UserWarning:\
          \ The operator 'aten::index.Tensor' is not currently supported on the MPS\
          \ backend and will fall back to run on the CPU. This may have performance\
          \ implications. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n\
          \  pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]),\
          \ input_ids.argmax(dim=-1)]\n</code></pre>\n<p>and in the code torch it\
          \ recognizes <code>mps</code> and I suppose loading  the pipeline with fp32</p>\n\
          <pre><code class=\"language-python\">device = <span class=\"hljs-string\"\
          >'cuda'</span> <span class=\"hljs-keyword\">if</span> torch.cuda.is_available()\
          \ <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">'cpu'</span>\n\
          device = <span class=\"hljs-string\">'mps'</span> <span class=\"hljs-keyword\"\
          >if</span> torch.backends.mps.is_available() <span class=\"hljs-keyword\"\
          >else</span> device\n<span class=\"hljs-built_in\">print</span>(<span class=\"\
          hljs-string\">f'running on <span class=\"hljs-subst\">{device}</span>'</span>)\n\
          \n...\n\npipe = StableDiffusionPipeline.from_pretrained(\n    <span class=\"\
          hljs-string\">\"CompVis/stable-diffusion-v1-3\"</span>, \n    scheduler=lms,\n\
          \    use_auth_token=<span class=\"hljs-literal\">True</span>\n).to(device)\n\
          </code></pre>\n<p>I'm using the latest <code>diffusers</code>, while in\
          \ the thread you shared some possibile solution is using forks / hacks /\
          \ etc.</p>\n<p>The whole traceback is </p>\n<pre><code>Traceback (most recent\
          \ call last):\n  File \"diffuser.py\", line 65, in &lt;module&gt;\n    guidance_scale=scale,\n\
          \  File \"/Projects/bloom/.venv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/Projects/bloom/pipeline_stable_diffusion.py\", line 142, in __call__\n\
          \    noise_pred = self.unet(latent_model_input, t, encoder_hidden_states=text_embeddings)[\"\
          sample\"]\n  File \"/Users/musixmatch/Documents/Projects/bloom/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n\
          \  File \"/Projects/bloom/.venv/lib/python3.7/site-packages/diffusers/models/unet_2d_condition.py\"\
          , line 134, in forward\n    timesteps = timesteps[None].to(sample.device)\n\
          TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework\
          \ doesn't support float64. Please use float32 instead.\n</code></pre>\n\
          <p>Thanks!</p>\n"
        raw: "@patrickvonplaten I now get\n\n```\nTypeError: Cannot convert a MPS\
          \ Tensor to float64 dtype as the MPS framework doesn't support float64.\
          \ Please use float32 instead.\n```\n setting the fallback `export PYTORCH_ENABLE_MPS_FALLBACK=1;`\
          \ it works as I can clearly see it from logs:\n\n```\n UserWarning: The\
          \ operator 'aten::index.Tensor' is not currently supported on the MPS backend\
          \ and will fall back to run on the CPU. This may have performance implications.\
          \ (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n\
          \  pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]),\
          \ input_ids.argmax(dim=-1)]\n```\n\nand in the code torch it recognizes\
          \ `mps` and I suppose loading  the pipeline with fp32\n\n```python\ndevice\
          \ = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice = 'mps' if torch.backends.mps.is_available()\
          \ else device\nprint(f'running on {device}')\n\n...\n\npipe = StableDiffusionPipeline.from_pretrained(\n\
          \    \"CompVis/stable-diffusion-v1-3\", \n    scheduler=lms,\n    use_auth_token=True\n\
          ).to(device)\n\n```\n\nI'm using the latest `diffusers`, while in the thread\
          \ you shared some possibile solution is using forks / hacks / etc.\n\nThe\
          \ whole traceback is \n\n```\nTraceback (most recent call last):\n  File\
          \ \"diffuser.py\", line 65, in <module>\n    guidance_scale=scale,\n  File\
          \ \"/Projects/bloom/.venv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/Projects/bloom/pipeline_stable_diffusion.py\", line 142, in __call__\n\
          \    noise_pred = self.unet(latent_model_input, t, encoder_hidden_states=text_embeddings)[\"\
          sample\"]\n  File \"/Users/musixmatch/Documents/Projects/bloom/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n\
          \  File \"/Projects/bloom/.venv/lib/python3.7/site-packages/diffusers/models/unet_2d_condition.py\"\
          , line 134, in forward\n    timesteps = timesteps[None].to(sample.device)\n\
          TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework\
          \ doesn't support float64. Please use float32 instead.\n```\nThanks!"
        updatedAt: '2022-08-31T14:42:06.099Z'
      numEdits: 4
      reactions: []
    id: 630f7036197cd3f24e7f3b9f
    type: comment
  author: loretoparisi
  content: "@patrickvonplaten I now get\n\n```\nTypeError: Cannot convert a MPS Tensor\
    \ to float64 dtype as the MPS framework doesn't support float64. Please use float32\
    \ instead.\n```\n setting the fallback `export PYTORCH_ENABLE_MPS_FALLBACK=1;`\
    \ it works as I can clearly see it from logs:\n\n```\n UserWarning: The operator\
    \ 'aten::index.Tensor' is not currently supported on the MPS backend and will\
    \ fall back to run on the CPU. This may have performance implications. (Triggered\
    \ internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n\
    \  pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]),\
    \ input_ids.argmax(dim=-1)]\n```\n\nand in the code torch it recognizes `mps`\
    \ and I suppose loading  the pipeline with fp32\n\n```python\ndevice = 'cuda'\
    \ if torch.cuda.is_available() else 'cpu'\ndevice = 'mps' if torch.backends.mps.is_available()\
    \ else device\nprint(f'running on {device}')\n\n...\n\npipe = StableDiffusionPipeline.from_pretrained(\n\
    \    \"CompVis/stable-diffusion-v1-3\", \n    scheduler=lms,\n    use_auth_token=True\n\
    ).to(device)\n\n```\n\nI'm using the latest `diffusers`, while in the thread you\
    \ shared some possibile solution is using forks / hacks / etc.\n\nThe whole traceback\
    \ is \n\n```\nTraceback (most recent call last):\n  File \"diffuser.py\", line\
    \ 65, in <module>\n    guidance_scale=scale,\n  File \"/Projects/bloom/.venv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\"\
    , line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/Projects/bloom/pipeline_stable_diffusion.py\"\
    , line 142, in __call__\n    noise_pred = self.unet(latent_model_input, t, encoder_hidden_states=text_embeddings)[\"\
    sample\"]\n  File \"/Users/musixmatch/Documents/Projects/bloom/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
    , line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File\
    \ \"/Projects/bloom/.venv/lib/python3.7/site-packages/diffusers/models/unet_2d_condition.py\"\
    , line 134, in forward\n    timesteps = timesteps[None].to(sample.device)\nTypeError:\
    \ Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support\
    \ float64. Please use float32 instead.\n```\nThanks!"
  created_at: 2022-08-31 13:29:10+00:00
  edited: true
  hidden: false
  id: 630f7036197cd3f24e7f3b9f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
      fullname: Pedro Cuenca
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pcuenq
      type: user
    createdAt: '2022-08-31T18:04:47.000Z'
    data:
      edited: false
      editors:
      - pcuenq
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
          fullname: Pedro Cuenca
          isHf: true
          isPro: false
          name: pcuenq
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;loretoparisi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/loretoparisi\"\
          >@<span class=\"underline\">loretoparisi</span></a></span>\n\n\t</span></span>\
          \ !</p>\n<p>We are working on official support for <code>mps</code> in Diffusers,\
          \ hold tight for a couple days :)</p>\n"
        raw: 'Hi @loretoparisi !


          We are working on official support for `mps` in Diffusers, hold tight for
          a couple days :)'
        updatedAt: '2022-08-31T18:04:47.728Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - madams
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - loretoparisi
    id: 630fa2bfe52a259b856403e2
    type: comment
  author: pcuenq
  content: 'Hi @loretoparisi !


    We are working on official support for `mps` in Diffusers, hold tight for a couple
    days :)'
  created_at: 2022-08-31 17:04:47+00:00
  edited: false
  hidden: false
  id: 630fa2bfe52a259b856403e2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 17
repo_id: CompVis/stable-diffusion-v1-4
repo_type: model
status: open
target_branch: null
title: Has anyone run this using an M1?
