!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aday777
conflicting_files: null
created_at: 2022-08-23 02:05:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ca4756c1f006fc97a2b092dc85f36f72.svg
      fullname: austin day
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aday777
      type: user
    createdAt: '2022-08-23T03:05:33.000Z'
    data:
      edited: false
      editors:
      - aday777
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ca4756c1f006fc97a2b092dc85f36f72.svg
          fullname: austin day
          isHf: false
          isPro: false
          name: aday777
          type: user
        html: '<p>Hi, thanks for making this available. I''m coming from using Dalle2,
          and after playing around with this a bit, I''m finding that stable diffusion
          doesn''t really <em>get</em> what I''m saying in the prompt as much. For
          example, "a hamster going super saiyan, digital art". In Dalle2, it will
          actually do this quite well, making a hamster that is kind of on fire. When
          I use stable diffusion with the same prompt, it''s like it ignores the hamster
          part, just giving me a stock image from dragonball or something. Are there
          parameters that we can change to modify its behavior? Is there something
          I''m doing wrong? Is there additional training we can do to improve this
          aspect? Thanks!</p>

          '
        raw: Hi, thanks for making this available. I'm coming from using Dalle2, and
          after playing around with this a bit, I'm finding that stable diffusion
          doesn't really *get* what I'm saying in the prompt as much. For example,
          "a hamster going super saiyan, digital art". In Dalle2, it will actually
          do this quite well, making a hamster that is kind of on fire. When I use
          stable diffusion with the same prompt, it's like it ignores the hamster
          part, just giving me a stock image from dragonball or something. Are there
          parameters that we can change to modify its behavior? Is there something
          I'm doing wrong? Is there additional training we can do to improve this
          aspect? Thanks!
        updatedAt: '2022-08-23T03:05:33.281Z'
      numEdits: 0
      reactions: []
    id: 630443fd5c70c21d0eaebe5e
    type: comment
  author: aday777
  content: Hi, thanks for making this available. I'm coming from using Dalle2, and
    after playing around with this a bit, I'm finding that stable diffusion doesn't
    really *get* what I'm saying in the prompt as much. For example, "a hamster going
    super saiyan, digital art". In Dalle2, it will actually do this quite well, making
    a hamster that is kind of on fire. When I use stable diffusion with the same prompt,
    it's like it ignores the hamster part, just giving me a stock image from dragonball
    or something. Are there parameters that we can change to modify its behavior?
    Is there something I'm doing wrong? Is there additional training we can do to
    improve this aspect? Thanks!
  created_at: 2022-08-23 02:05:33+00:00
  edited: false
  hidden: false
  id: 630443fd5c70c21d0eaebe5e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f41b208bbbdafebe521845140f006c68.svg
      fullname: kishore G
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ghpkishore
      type: user
    createdAt: '2022-08-23T04:04:18.000Z'
    data:
      edited: false
      editors:
      - ghpkishore
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f41b208bbbdafebe521845140f006c68.svg
          fullname: kishore G
          isHf: false
          isPro: false
          name: ghpkishore
          type: user
        html: "<p>You can add classifier free guidance values to it.  Basically if\
          \ i remember correctly, the parameters value is -C.   So it would be \u201C\
          prompt\u201D -C 7</p>\n"
        raw: "You can add classifier free guidance values to it.  Basically if i remember\
          \ correctly, the parameters value is -C.   So it would be \u201Cprompt\u201D\
          \ -C 7"
        updatedAt: '2022-08-23T04:04:18.137Z'
      numEdits: 0
      reactions: []
    id: 630451c25c70c21d0eaf231d
    type: comment
  author: ghpkishore
  content: "You can add classifier free guidance values to it.  Basically if i remember\
    \ correctly, the parameters value is -C.   So it would be \u201Cprompt\u201D -C\
    \ 7"
  created_at: 2022-08-23 03:04:18+00:00
  edited: false
  hidden: false
  id: 630451c25c70c21d0eaf231d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2022-08-23T18:22:49.000Z'
    data:
      edited: false
      editors:
      - patrickvonplaten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
          fullname: Patrick von Platen
          isHf: true
          isPro: false
          name: patrickvonplaten
          type: user
        html: '<p><code>guidance_scale</code> can indeed help quite a bit here! Here
          you can see how to use it with <code>diffusers</code>: <a href="https://huggingface.co/CompVis/stable-diffusion-v1-4#examples">https://huggingface.co/CompVis/stable-diffusion-v1-4#examples</a></p>

          <p>Also prompt engineering like pre-pending something like "High photo-realistic
          &lt;your/prompt&gt;" can help</p>

          '
        raw: '`guidance_scale` can indeed help quite a bit here! Here you can see
          how to use it with `diffusers`: https://huggingface.co/CompVis/stable-diffusion-v1-4#examples


          Also prompt engineering like pre-pending something like "High photo-realistic
          <your/prompt>" can help'
        updatedAt: '2022-08-23T18:22:49.963Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - velaia
    id: 63051af9c7fed54edfa8ff02
    type: comment
  author: patrickvonplaten
  content: '`guidance_scale` can indeed help quite a bit here! Here you can see how
    to use it with `diffusers`: https://huggingface.co/CompVis/stable-diffusion-v1-4#examples


    Also prompt engineering like pre-pending something like "High photo-realistic
    <your/prompt>" can help'
  created_at: 2022-08-23 17:22:49+00:00
  edited: false
  hidden: false
  id: 63051af9c7fed54edfa8ff02
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ca4756c1f006fc97a2b092dc85f36f72.svg
      fullname: austin day
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aday777
      type: user
    createdAt: '2022-08-24T00:12:47.000Z'
    data:
      edited: false
      editors:
      - aday777
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ca4756c1f006fc97a2b092dc85f36f72.svg
          fullname: austin day
          isHf: false
          isPro: false
          name: aday777
          type: user
        html: '<p>Thanks! I''ll play around with these. I ran it like ... 1000 times,
          and a few of them gave me the proper image, so it''s in there somewhere.
          Just a matter of teasing it out I guess, haha.</p>

          '
        raw: Thanks! I'll play around with these. I ran it like ... 1000 times, and
          a few of them gave me the proper image, so it's in there somewhere. Just
          a matter of teasing it out I guess, haha.
        updatedAt: '2022-08-24T00:12:47.131Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - patrickvonplaten
        - velaia
    id: 63056cff80bc5e03dad30cc3
    type: comment
  author: aday777
  content: Thanks! I'll play around with these. I ran it like ... 1000 times, and
    a few of them gave me the proper image, so it's in there somewhere. Just a matter
    of teasing it out I guess, haha.
  created_at: 2022-08-23 23:12:47+00:00
  edited: false
  hidden: false
  id: 63056cff80bc5e03dad30cc3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: CompVis/stable-diffusion-v1-4
repo_type: model
status: open
target_branch: null
title: 'How to improve quality of outputs? '
