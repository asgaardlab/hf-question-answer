!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ymd1337
conflicting_files: null
created_at: 2022-08-24 17:09:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/63fa488ad7642df72d7f01495c46676f.svg
      fullname: mengda yang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ymd1337
      type: user
    createdAt: '2022-08-24T18:09:58.000Z'
    data:
      edited: false
      editors:
      - ymd1337
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/63fa488ad7642df72d7f01495c46676f.svg
          fullname: mengda yang
          isHf: false
          isPro: false
          name: ymd1337
          type: user
        html: '<p>Hello team stability ai,</p>

          <p>Thank you for your amazong work and thank you for sharing it with the
          world. Big kudos to everyone who have put effort to make this happen.<br>I''m
          really new to Hugging Face and this question might be stupid. In the webpage
          version there is a field that I can specify a random seed that I can retrieve
          the same image with the same input text plus the same seed every time. I
          wonder if we have the same functionality from the python API and how I am
          able to do this.</p>

          <p>Best,<br>ymd</p>

          '
        raw: "Hello team stability ai,\r\n\r\nThank you for your amazong work and\
          \ thank you for sharing it with the world. Big kudos to everyone who have\
          \ put effort to make this happen.\r\nI'm really new to Hugging Face and\
          \ this question might be stupid. In the webpage version there is a field\
          \ that I can specify a random seed that I can retrieve the same image with\
          \ the same input text plus the same seed every time. I wonder if we have\
          \ the same functionality from the python API and how I am able to do this.\r\
          \n\r\nBest,\r\nymd\r\n"
        updatedAt: '2022-08-24T18:09:58.419Z'
      numEdits: 0
      reactions: []
    id: 63066976435ec751b72aaaea
    type: comment
  author: ymd1337
  content: "Hello team stability ai,\r\n\r\nThank you for your amazong work and thank\
    \ you for sharing it with the world. Big kudos to everyone who have put effort\
    \ to make this happen.\r\nI'm really new to Hugging Face and this question might\
    \ be stupid. In the webpage version there is a field that I can specify a random\
    \ seed that I can retrieve the same image with the same input text plus the same\
    \ seed every time. I wonder if we have the same functionality from the python\
    \ API and how I am able to do this.\r\n\r\nBest,\r\nymd\r\n"
  created_at: 2022-08-24 17:09:58+00:00
  edited: false
  hidden: false
  id: 63066976435ec751b72aaaea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    createdAt: '2022-08-25T08:01:46.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-05-02T08:22:16.685Z'
      numEdits: 0
      reactions: []
    id: 63072c6a3e3112970f9d783f
    type: comment
  author: deleted
  content: This comment has been hidden
  created_at: 2022-08-25 07:01:46+00:00
  edited: true
  hidden: true
  id: 63072c6a3e3112970f9d783f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
      fullname: Pedro Cuenca
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pcuenq
      type: user
    createdAt: '2022-08-25T15:35:54.000Z'
    data:
      edited: false
      editors:
      - pcuenq
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
          fullname: Pedro Cuenca
          isHf: true
          isPro: false
          name: pcuenq
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;ymd1337&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ymd1337\">@<span class=\"\
          underline\">ymd1337</span></a></span>\n\n\t</span></span> and @samrahimi123!</p>\n\
          <p>We've just merged a new feature in the main branch of \U0001F917 Diffusers\
          \ that allows this use case, and there's a colab that demonstrates it: <a\
          \ rel=\"nofollow\" href=\"https://colab.research.google.com/github/pcuenca/diffusers-examples/blob/main/notebooks/stable-diffusion-seeds.ipynb\"\
          >https://colab.research.google.com/github/pcuenca/diffusers-examples/blob/main/notebooks/stable-diffusion-seeds.ipynb</a></p>\n\
          <p>There was an interesting discussion about API design choices here: <a\
          \ rel=\"nofollow\" href=\"https://github.com/huggingface/diffusers/issues/208\"\
          >https://github.com/huggingface/diffusers/issues/208</a></p>\n<p>Feel free\
          \ to try it out and provide any feedback!</p>\n"
        raw: "Hi @ymd1337 and @samrahimi123!\n\nWe've just merged a new feature in\
          \ the main branch of \U0001F917 Diffusers that allows this use case, and\
          \ there's a colab that demonstrates it: https://colab.research.google.com/github/pcuenca/diffusers-examples/blob/main/notebooks/stable-diffusion-seeds.ipynb\n\
          \nThere was an interesting discussion about API design choices here: https://github.com/huggingface/diffusers/issues/208\n\
          \nFeel free to try it out and provide any feedback!"
        updatedAt: '2022-08-25T15:35:54.755Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\u2764\uFE0F"
        users:
        - patrickvonplaten
        - julien-c
        - wangjun
        - NourEldin-Osama
    id: 630796da4b2a17f13f5a63c5
    type: comment
  author: pcuenq
  content: "Hi @ymd1337 and @samrahimi123!\n\nWe've just merged a new feature in the\
    \ main branch of \U0001F917 Diffusers that allows this use case, and there's a\
    \ colab that demonstrates it: https://colab.research.google.com/github/pcuenca/diffusers-examples/blob/main/notebooks/stable-diffusion-seeds.ipynb\n\
    \nThere was an interesting discussion about API design choices here: https://github.com/huggingface/diffusers/issues/208\n\
    \nFeel free to try it out and provide any feedback!"
  created_at: 2022-08-25 14:35:54+00:00
  edited: false
  hidden: false
  id: 630796da4b2a17f13f5a63c5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/63fa488ad7642df72d7f01495c46676f.svg
      fullname: mengda yang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ymd1337
      type: user
    createdAt: '2022-08-27T06:26:48.000Z'
    data:
      edited: false
      editors:
      - ymd1337
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/63fa488ad7642df72d7f01495c46676f.svg
          fullname: mengda yang
          isHf: false
          isPro: false
          name: ymd1337
          type: user
        html: '<p>Amazing!</p>

          '
        raw: Amazing!
        updatedAt: '2022-08-27T06:26:48.169Z'
      numEdits: 0
      reactions: []
    id: 6309b9282ff113e0fb27f0f9
    type: comment
  author: ymd1337
  content: Amazing!
  created_at: 2022-08-27 05:26:48+00:00
  edited: false
  hidden: false
  id: 6309b9282ff113e0fb27f0f9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c8ecf5b0316733b9f7d4bf8031fef56e.svg
      fullname: goichi harada
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dahara1
      type: user
    createdAt: '2022-08-28T06:34:12.000Z'
    data:
      edited: true
      editors:
      - dahara1
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c8ecf5b0316733b9f7d4bf8031fef56e.svg
          fullname: goichi harada
          isHf: false
          isPro: false
          name: dahara1
          type: user
        html: "<p>Hello.<br>I have tried to run it on my local PC (RTX 3060, NVIDIA-SMI\
          \ 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7) using the\
          \ Colab source as a reference, but it produces 3 different images.</p>\n\
          <p>Can you give me any advice?</p>\n<p>install </p>\n<p>If you install diffusers\
          \ directly, you will get the following error when you run the script.<br>so\
          \ I install stable-diffusion first.</p>\n<pre><code>site-packages/torch/cuda/__init__.py:146:\
          \ UserWarning:\nNVIDIA GeForce RTX 3060 with CUDA capability sm_86 is not\
          \ compatible with the current PyTorch installation.\nThe current PyTorch\
          \ install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\nIf you want\
          \ to use the NVIDIA GeForce RTX 3060 GPU with PyTorch, please check the\
          \ instructions at https://pytorch.org/get-started/locally/\n\n  warnings.warn(incompatible_device_warn.format(device_name,\
          \ capability, \" \".join(arch_list), device_name))\nTraceback (most recent\
          \ call last):\n  File \"/home/dev3/work/hdu/testinstall/./seed_test.py\"\
          , line 30, in &lt;module&gt;\n    latents = torch.randn(\nRuntimeError:\
          \ CUDA error: no kernel image is available for execution on the device\n\
          CUDA kernel errors might be asynchronously reported at some other API call,so\
          \ the stacktrace below might be incorrect.\nFor debugging consider passing\
          \ CUDA_LAUNCH_BLOCKING=1.\n</code></pre>\n<pre><code>git clone https://github.com/CompVis/stable-diffusion\n\
          cd stable-diffusion/\nconda env create -f environment.yaml\n\n# Automatically\
          \ ldm activate\n(ldm)\npip install git+https://github.com/huggingface/diffusers.git\n\
          pip install transformers scipy ftfy\n</code></pre>\n<p>Then run the following\
          \ script to obtain three different images.</p>\n<pre><code>#!/usr/bin/env\
          \ python\n\nimport torch\nfrom diffusers import StableDiffusionPipeline\n\
          \ndevice = \"cuda\"\nmodel_id = \"CompVis/stable-diffusion-v1-4\"\nprompt\
          \ = \"Labrador in the style of Vermeer\"\nfile = \"seed_test_\"\n\npipe\
          \ = StableDiffusionPipeline.from_pretrained(\n    model_id,\n    revision=\"\
          fp16\",\n    torch_dtype=torch.float16,\n    use_auth_token=True,\n).to(device)\n\
          \nnum_images = 1\nwidth = 512\nheight = 512\n\n# first try\nlatents = None\n\
          #seed: int = 7183698734589870\nseed: int = 0\n\ngenerator = torch.Generator(device=device)\n\
          generator = generator.manual_seed(seed)\nlatents = torch.randn(\n      \
          \  (1, pipe.unet.in_channels, height // 8, width // 8),\n        generator\
          \ = generator,\n        device = device\n)\n\nwith torch.autocast(\"cuda\"\
          ):\n    images = pipe(\n        [prompt] * num_images,\n        guidance_scale=7.5,\n\
          \        latents = latents,\n    )[\"sample\"]\n    images[0].save(file\
          \ + \"_test_seed_1.jpg\")\n\n# second try\ngenerator = torch.Generator(device=device)\n\
          generator = generator.manual_seed(seed)\n\nlatents = torch.randn(\n    \
          \    (1, pipe.unet.in_channels, height // 8, width // 8),\n        generator\
          \ = generator,\n        device = device\n)\nwith torch.autocast(\"cuda\"\
          ):\n    images = pipe(\n        [prompt] * num_images,\n        guidance_scale=7.5,\n\
          \        latents = latents,\n    )[\"sample\"]\n    images[0].save(file\
          \ + \"_test_seed_2.jpg\")\n\n#third try\nwith torch.autocast(\"cuda\"):\n\
          \    images = pipe(\n        [prompt] * num_images,\n        guidance_scale=7.5,\n\
          \        latents = latents,\n    )[\"sample\"]\n    images[0].save(file\
          \ + \"_test_seed_3.jpg\")\n</code></pre>\n"
        raw: "Hello. \nI have tried to run it on my local PC (RTX 3060, NVIDIA-SMI\
          \ 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7) using the\
          \ Colab source as a reference, but it produces 3 different images.\n\nCan\
          \ you give me any advice?\n\ninstall \n\nIf you install diffusers directly,\
          \ you will get the following error when you run the script.\nso I install\
          \ stable-diffusion first.\n```\nsite-packages/torch/cuda/__init__.py:146:\
          \ UserWarning:\nNVIDIA GeForce RTX 3060 with CUDA capability sm_86 is not\
          \ compatible with the current PyTorch installation.\nThe current PyTorch\
          \ install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\nIf you want\
          \ to use the NVIDIA GeForce RTX 3060 GPU with PyTorch, please check the\
          \ instructions at https://pytorch.org/get-started/locally/\n\n  warnings.warn(incompatible_device_warn.format(device_name,\
          \ capability, \" \".join(arch_list), device_name))\nTraceback (most recent\
          \ call last):\n  File \"/home/dev3/work/hdu/testinstall/./seed_test.py\"\
          , line 30, in <module>\n    latents = torch.randn(\nRuntimeError: CUDA error:\
          \ no kernel image is available for execution on the device\nCUDA kernel\
          \ errors might be asynchronously reported at some other API call,so the\
          \ stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n\
          ```\n\n```\ngit clone https://github.com/CompVis/stable-diffusion\ncd stable-diffusion/\n\
          conda env create -f environment.yaml\n\n# Automatically ldm activate\n(ldm)\n\
          pip install git+https://github.com/huggingface/diffusers.git\npip install\
          \ transformers scipy ftfy\n\n```\n\nThen run the following script to obtain\
          \ three different images.\n\n```\n#!/usr/bin/env python\n\nimport torch\n\
          from diffusers import StableDiffusionPipeline\n\ndevice = \"cuda\"\nmodel_id\
          \ = \"CompVis/stable-diffusion-v1-4\"\nprompt = \"Labrador in the style\
          \ of Vermeer\"\nfile = \"seed_test_\"\n\npipe = StableDiffusionPipeline.from_pretrained(\n\
          \    model_id,\n    revision=\"fp16\",\n    torch_dtype=torch.float16,\n\
          \    use_auth_token=True,\n).to(device)\n\nnum_images = 1\nwidth = 512\n\
          height = 512\n\n# first try\nlatents = None\n#seed: int = 7183698734589870\n\
          seed: int = 0\n\ngenerator = torch.Generator(device=device)\ngenerator =\
          \ generator.manual_seed(seed)\nlatents = torch.randn(\n        (1, pipe.unet.in_channels,\
          \ height // 8, width // 8),\n        generator = generator,\n        device\
          \ = device\n)\n\nwith torch.autocast(\"cuda\"):\n    images = pipe(\n  \
          \      [prompt] * num_images,\n        guidance_scale=7.5,\n        latents\
          \ = latents,\n    )[\"sample\"]\n    images[0].save(file + \"_test_seed_1.jpg\"\
          )\n\n# second try\ngenerator = torch.Generator(device=device)\ngenerator\
          \ = generator.manual_seed(seed)\n\nlatents = torch.randn(\n        (1, pipe.unet.in_channels,\
          \ height // 8, width // 8),\n        generator = generator,\n        device\
          \ = device\n)\nwith torch.autocast(\"cuda\"):\n    images = pipe(\n    \
          \    [prompt] * num_images,\n        guidance_scale=7.5,\n        latents\
          \ = latents,\n    )[\"sample\"]\n    images[0].save(file + \"_test_seed_2.jpg\"\
          )\n\n#third try\nwith torch.autocast(\"cuda\"):\n    images = pipe(\n  \
          \      [prompt] * num_images,\n        guidance_scale=7.5,\n        latents\
          \ = latents,\n    )[\"sample\"]\n    images[0].save(file + \"_test_seed_3.jpg\"\
          )\n```"
        updatedAt: '2022-08-28T11:42:08.309Z'
      numEdits: 3
      reactions: []
    id: 630b0c644c0945d20b814a7a
    type: comment
  author: dahara1
  content: "Hello. \nI have tried to run it on my local PC (RTX 3060, NVIDIA-SMI 515.65.01\
    \    Driver Version: 515.65.01    CUDA Version: 11.7) using the Colab source as\
    \ a reference, but it produces 3 different images.\n\nCan you give me any advice?\n\
    \ninstall \n\nIf you install diffusers directly, you will get the following error\
    \ when you run the script.\nso I install stable-diffusion first.\n```\nsite-packages/torch/cuda/__init__.py:146:\
    \ UserWarning:\nNVIDIA GeForce RTX 3060 with CUDA capability sm_86 is not compatible\
    \ with the current PyTorch installation.\nThe current PyTorch install supports\
    \ CUDA capabilities sm_37 sm_50 sm_60 sm_70.\nIf you want to use the NVIDIA GeForce\
    \ RTX 3060 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n\
    \n  warnings.warn(incompatible_device_warn.format(device_name, capability, \"\
    \ \".join(arch_list), device_name))\nTraceback (most recent call last):\n  File\
    \ \"/home/dev3/work/hdu/testinstall/./seed_test.py\", line 30, in <module>\n \
    \   latents = torch.randn(\nRuntimeError: CUDA error: no kernel image is available\
    \ for execution on the device\nCUDA kernel errors might be asynchronously reported\
    \ at some other API call,so the stacktrace below might be incorrect.\nFor debugging\
    \ consider passing CUDA_LAUNCH_BLOCKING=1.\n```\n\n```\ngit clone https://github.com/CompVis/stable-diffusion\n\
    cd stable-diffusion/\nconda env create -f environment.yaml\n\n# Automatically\
    \ ldm activate\n(ldm)\npip install git+https://github.com/huggingface/diffusers.git\n\
    pip install transformers scipy ftfy\n\n```\n\nThen run the following script to\
    \ obtain three different images.\n\n```\n#!/usr/bin/env python\n\nimport torch\n\
    from diffusers import StableDiffusionPipeline\n\ndevice = \"cuda\"\nmodel_id =\
    \ \"CompVis/stable-diffusion-v1-4\"\nprompt = \"Labrador in the style of Vermeer\"\
    \nfile = \"seed_test_\"\n\npipe = StableDiffusionPipeline.from_pretrained(\n \
    \   model_id,\n    revision=\"fp16\",\n    torch_dtype=torch.float16,\n    use_auth_token=True,\n\
    ).to(device)\n\nnum_images = 1\nwidth = 512\nheight = 512\n\n# first try\nlatents\
    \ = None\n#seed: int = 7183698734589870\nseed: int = 0\n\ngenerator = torch.Generator(device=device)\n\
    generator = generator.manual_seed(seed)\nlatents = torch.randn(\n        (1, pipe.unet.in_channels,\
    \ height // 8, width // 8),\n        generator = generator,\n        device =\
    \ device\n)\n\nwith torch.autocast(\"cuda\"):\n    images = pipe(\n        [prompt]\
    \ * num_images,\n        guidance_scale=7.5,\n        latents = latents,\n   \
    \ )[\"sample\"]\n    images[0].save(file + \"_test_seed_1.jpg\")\n\n# second try\n\
    generator = torch.Generator(device=device)\ngenerator = generator.manual_seed(seed)\n\
    \nlatents = torch.randn(\n        (1, pipe.unet.in_channels, height // 8, width\
    \ // 8),\n        generator = generator,\n        device = device\n)\nwith torch.autocast(\"\
    cuda\"):\n    images = pipe(\n        [prompt] * num_images,\n        guidance_scale=7.5,\n\
    \        latents = latents,\n    )[\"sample\"]\n    images[0].save(file + \"_test_seed_2.jpg\"\
    )\n\n#third try\nwith torch.autocast(\"cuda\"):\n    images = pipe(\n        [prompt]\
    \ * num_images,\n        guidance_scale=7.5,\n        latents = latents,\n   \
    \ )[\"sample\"]\n    images[0].save(file + \"_test_seed_3.jpg\")\n```"
  created_at: 2022-08-28 05:34:12+00:00
  edited: true
  hidden: false
  id: 630b0c644c0945d20b814a7a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
      fullname: Pedro Cuenca
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pcuenq
      type: user
    createdAt: '2022-08-28T13:01:12.000Z'
    data:
      edited: false
      editors:
      - pcuenq
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
          fullname: Pedro Cuenca
          isHf: true
          isPro: false
          name: pcuenq
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;dahara1&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/dahara1\">@<span class=\"\
          underline\">dahara1</span></a></span>\n\n\t</span></span> !</p>\n<p>That\
          \ change is supported in the <code>main</code> branch of diffusers, but\
          \ is not yet available in the latest PyPi distribution. I see that you are\
          \ attempting to install from github, which is correct, but I'm not sure\
          \ how you are managing your virtual environments. Can you please run this\
          \ code in your environment to verify that the <code>latents</code> parameter\
          \ is indeed supported?</p>\n<pre><code class=\"language-Python\"><span class=\"\
          hljs-keyword\">import</span> inspect\n<span class=\"hljs-string\">'latents'</span>\
          \ <span class=\"hljs-keyword\">in</span> inspect.signature(pipe.__call__).parameters\n\
          </code></pre>\n<p>The expression should be <code>True</code> if the parameter\
          \ (<code>latents</code>) is supported. If it isn't, please try to uninstall\
          \ <code>diffusers</code> then run your code again.</p>\n<p>In addition,\
          \ there's a warning in your output about your GPU not being fully supported\
          \ by the PyTorch version you have installed. I'd recommend you reinstall\
          \ PyTorch from this page so your generations can run as fast as possible\
          \ :) <a rel=\"nofollow\" href=\"https://pytorch.org/get-started/locally/\"\
          >https://pytorch.org/get-started/locally/</a></p>\n<p>Please, let us know\
          \ how it goes!</p>\n"
        raw: 'Hi @dahara1 !


          That change is supported in the `main` branch of diffusers, but is not yet
          available in the latest PyPi distribution. I see that you are attempting
          to install from github, which is correct, but I''m not sure how you are
          managing your virtual environments. Can you please run this code in your
          environment to verify that the `latents` parameter is indeed supported?


          ```Python

          import inspect

          ''latents'' in inspect.signature(pipe.__call__).parameters

          ```


          The expression should be `True` if the parameter (`latents`) is supported.
          If it isn''t, please try to uninstall `diffusers` then run your code again.


          In addition, there''s a warning in your output about your GPU not being
          fully supported by the PyTorch version you have installed. I''d recommend
          you reinstall PyTorch from this page so your generations can run as fast
          as possible :) https://pytorch.org/get-started/locally/


          Please, let us know how it goes!'
        updatedAt: '2022-08-28T13:01:12.403Z'
      numEdits: 0
      reactions: []
    id: 630b67188b327c7b8b981c42
    type: comment
  author: pcuenq
  content: 'Hi @dahara1 !


    That change is supported in the `main` branch of diffusers, but is not yet available
    in the latest PyPi distribution. I see that you are attempting to install from
    github, which is correct, but I''m not sure how you are managing your virtual
    environments. Can you please run this code in your environment to verify that
    the `latents` parameter is indeed supported?


    ```Python

    import inspect

    ''latents'' in inspect.signature(pipe.__call__).parameters

    ```


    The expression should be `True` if the parameter (`latents`) is supported. If
    it isn''t, please try to uninstall `diffusers` then run your code again.


    In addition, there''s a warning in your output about your GPU not being fully
    supported by the PyTorch version you have installed. I''d recommend you reinstall
    PyTorch from this page so your generations can run as fast as possible :) https://pytorch.org/get-started/locally/


    Please, let us know how it goes!'
  created_at: 2022-08-28 12:01:12+00:00
  edited: false
  hidden: false
  id: 630b67188b327c7b8b981c42
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c8ecf5b0316733b9f7d4bf8031fef56e.svg
      fullname: goichi harada
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dahara1
      type: user
    createdAt: '2022-08-28T16:01:16.000Z'
    data:
      edited: false
      editors:
      - dahara1
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c8ecf5b0316733b9f7d4bf8031fef56e.svg
          fullname: goichi harada
          isHf: false
          isPro: false
          name: dahara1
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;pcuenq&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/pcuenq\">@<span class=\"\
          underline\">pcuenq</span></a></span>\n\n\t</span></span> !</p>\n<p>Thank\
          \ you for replay.</p>\n<p>It's false.<br>So I unistall diffusers.</p>\n\
          <pre><code>pip uninstall diffusers\nFound existing installation: diffusers\
          \ 0.2.4\nUninstalling diffusers-0.2.4:\n  Would remove:\n    /home/dev3/local/miniconda/envs/ldm_test/lib/python3.8/site-packages/diffusers-0.2.4.dist-info/*\n\
          \    /home/dev3/local/miniconda/envs/ldm_test/lib/python3.8/site-packages/diffusers/*\n\
          Proceed (y/n)? y\n  Successfully uninstalled diffusers-0.2.4\n</code></pre>\n\
          <p>but re-install  diffusers from github huggingface/diffusers still false.<br>I\
          \ think something is conflicting because I installed stable diffusion on\
          \ conda first.</p>\n<p>Conclusion.<br>I will try to install PyTorch from\
          \ source</p>\n<p>I can install and run stable diffusion with It's instruction.<br><a\
          \ rel=\"nofollow\" href=\"https://github.com/CompVis/stable-diffusion\"\
          >https://github.com/CompVis/stable-diffusion</a></p>\n<pre><code>conda env\
          \ create -f environment.yaml\nconda activate ldm\n</code></pre>\n<p>but\
          \ I can't run code snipet from stable-diffusion-seeds.ipynb in this conda\
          \ enviroment because there are some conflicts or something wrong.</p>\n\
          <p>so I tried new conda enviroment with below command.</p>\n<pre><code>conda\
          \ create -n hdu2 --clone base\nconda activate hdu2\n# from https://pytorch.org/get-started/locally/\n\
          conda install pytorch torchvision torchaudio cudatoolkit=11.6 -c pytorch\
          \ -c conda-forge\n\npip install git+https://github.com/huggingface/diffusers.git\n\
          pip install transformers scipy ftfy\n</code></pre>\n<p>but when I ran the\
          \ script, there is CUDA error.</p>\n<pre><code>miniconda/envs/hdu2/lib/python3.9/site-packages/torch/cuda/__init__.py:146:\
          \ UserWarning:\nNVIDIA GeForce RTX 3060 with CUDA capability sm_86 is not\
          \ compatible with the current PyTorch installation.\nThe current PyTorch\
          \ install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\nIf you want\
          \ to use the NVIDIA GeForce RTX 3060 GPU with PyTorch, please check the\
          \ instructions at https://pytorch.org/get-started/locally/\n\n  warnings.warn(incompatible_device_warn.format(device_name,\
          \ capability, \" \".join(arch_list), device_name))\nTraceback (most recent\
          \ call last):\n  File \"/home/dev3/work/hdu/testinstall/./seed_test.py\"\
          , line 34, in &lt;module&gt;\n    latents = torch.randn(\nRuntimeError:\
          \ CUDA error: no kernel image is available for execution on the device\n\
          CUDA kernel errors might be asynchronously reported at some other API call,so\
          \ the stacktrace below might be incorrect.\nFor debugging consider passing\
          \ CUDA_LAUNCH_BLOCKING=1.\n</code></pre>\n<p>so I decide source install.<br>Thank\
          \ you.</p>\n"
        raw: "Hi @pcuenq !\n\nThank you for replay.\n\nIt's false.\nSo I unistall\
          \ diffusers.\n```\npip uninstall diffusers\nFound existing installation:\
          \ diffusers 0.2.4\nUninstalling diffusers-0.2.4:\n  Would remove:\n    /home/dev3/local/miniconda/envs/ldm_test/lib/python3.8/site-packages/diffusers-0.2.4.dist-info/*\n\
          \    /home/dev3/local/miniconda/envs/ldm_test/lib/python3.8/site-packages/diffusers/*\n\
          Proceed (y/n)? y\n  Successfully uninstalled diffusers-0.2.4\n```\nbut re-install\
          \  diffusers from github huggingface/diffusers still false.\nI think something\
          \ is conflicting because I installed stable diffusion on conda first.\n\n\
          Conclusion.\nI will try to install PyTorch from source\n\nI can install\
          \ and run stable diffusion with It's instruction.\nhttps://github.com/CompVis/stable-diffusion\n\
          ```\nconda env create -f environment.yaml\nconda activate ldm\n```\nbut\
          \ I can't run code snipet from stable-diffusion-seeds.ipynb in this conda\
          \ enviroment because there are some conflicts or something wrong.\n\nso\
          \ I tried new conda enviroment with below command.\n```\nconda create -n\
          \ hdu2 --clone base\nconda activate hdu2\n# from https://pytorch.org/get-started/locally/\n\
          conda install pytorch torchvision torchaudio cudatoolkit=11.6 -c pytorch\
          \ -c conda-forge\n\npip install git+https://github.com/huggingface/diffusers.git\n\
          pip install transformers scipy ftfy\n\n```\n\nbut when I ran the script,\
          \ there is CUDA error.\n```\nminiconda/envs/hdu2/lib/python3.9/site-packages/torch/cuda/__init__.py:146:\
          \ UserWarning:\nNVIDIA GeForce RTX 3060 with CUDA capability sm_86 is not\
          \ compatible with the current PyTorch installation.\nThe current PyTorch\
          \ install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\nIf you want\
          \ to use the NVIDIA GeForce RTX 3060 GPU with PyTorch, please check the\
          \ instructions at https://pytorch.org/get-started/locally/\n\n  warnings.warn(incompatible_device_warn.format(device_name,\
          \ capability, \" \".join(arch_list), device_name))\nTraceback (most recent\
          \ call last):\n  File \"/home/dev3/work/hdu/testinstall/./seed_test.py\"\
          , line 34, in <module>\n    latents = torch.randn(\nRuntimeError: CUDA error:\
          \ no kernel image is available for execution on the device\nCUDA kernel\
          \ errors might be asynchronously reported at some other API call,so the\
          \ stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n\
          ```\n\nso I decide source install.\nThank you."
        updatedAt: '2022-08-28T16:01:16.008Z'
      numEdits: 0
      reactions: []
    id: 630b914c4c0945d20b862324
    type: comment
  author: dahara1
  content: "Hi @pcuenq !\n\nThank you for replay.\n\nIt's false.\nSo I unistall diffusers.\n\
    ```\npip uninstall diffusers\nFound existing installation: diffusers 0.2.4\nUninstalling\
    \ diffusers-0.2.4:\n  Would remove:\n    /home/dev3/local/miniconda/envs/ldm_test/lib/python3.8/site-packages/diffusers-0.2.4.dist-info/*\n\
    \    /home/dev3/local/miniconda/envs/ldm_test/lib/python3.8/site-packages/diffusers/*\n\
    Proceed (y/n)? y\n  Successfully uninstalled diffusers-0.2.4\n```\nbut re-install\
    \  diffusers from github huggingface/diffusers still false.\nI think something\
    \ is conflicting because I installed stable diffusion on conda first.\n\nConclusion.\n\
    I will try to install PyTorch from source\n\nI can install and run stable diffusion\
    \ with It's instruction.\nhttps://github.com/CompVis/stable-diffusion\n```\nconda\
    \ env create -f environment.yaml\nconda activate ldm\n```\nbut I can't run code\
    \ snipet from stable-diffusion-seeds.ipynb in this conda enviroment because there\
    \ are some conflicts or something wrong.\n\nso I tried new conda enviroment with\
    \ below command.\n```\nconda create -n hdu2 --clone base\nconda activate hdu2\n\
    # from https://pytorch.org/get-started/locally/\nconda install pytorch torchvision\
    \ torchaudio cudatoolkit=11.6 -c pytorch -c conda-forge\n\npip install git+https://github.com/huggingface/diffusers.git\n\
    pip install transformers scipy ftfy\n\n```\n\nbut when I ran the script, there\
    \ is CUDA error.\n```\nminiconda/envs/hdu2/lib/python3.9/site-packages/torch/cuda/__init__.py:146:\
    \ UserWarning:\nNVIDIA GeForce RTX 3060 with CUDA capability sm_86 is not compatible\
    \ with the current PyTorch installation.\nThe current PyTorch install supports\
    \ CUDA capabilities sm_37 sm_50 sm_60 sm_70.\nIf you want to use the NVIDIA GeForce\
    \ RTX 3060 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n\
    \n  warnings.warn(incompatible_device_warn.format(device_name, capability, \"\
    \ \".join(arch_list), device_name))\nTraceback (most recent call last):\n  File\
    \ \"/home/dev3/work/hdu/testinstall/./seed_test.py\", line 34, in <module>\n \
    \   latents = torch.randn(\nRuntimeError: CUDA error: no kernel image is available\
    \ for execution on the device\nCUDA kernel errors might be asynchronously reported\
    \ at some other API call,so the stacktrace below might be incorrect.\nFor debugging\
    \ consider passing CUDA_LAUNCH_BLOCKING=1.\n```\n\nso I decide source install.\n\
    Thank you."
  created_at: 2022-08-28 15:01:16+00:00
  edited: false
  hidden: false
  id: 630b914c4c0945d20b862324
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
      fullname: Pedro Cuenca
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pcuenq
      type: user
    createdAt: '2022-08-28T17:05:41.000Z'
    data:
      edited: false
      editors:
      - pcuenq
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
          fullname: Pedro Cuenca
          isHf: true
          isPro: false
          name: pcuenq
          type: user
        html: '<p>Hi there!</p>

          <p>A couple of suggestions for your PyTorch install:</p>

          <ul>

          <li>First, please verify what version of CUDA you have installed in your
          computer. If you run <code>nvidia-smi -q --display="COMPUTE"</code>, look
          for the line that says <code>CUDA Version</code>, then use the PyTorch distribution
          that matches that version, or the closest one that is smaller than it. For
          example, if you have CUDA 11.4 installed, select the PyTorch distribution
          for CUDA 11.3.</li>

          <li>This might not make a difference, but it''s worth a try: instead of
          installing PyTorch using conda, perhaps you can use <code>pip</code> after
          you enable your virtual environment.</li>

          </ul>

          <p>Good luck!</p>

          '
        raw: 'Hi there!


          A couple of suggestions for your PyTorch install:


          - First, please verify what version of CUDA you have installed in your computer.
          If you run `nvidia-smi -q --display="COMPUTE"`, look for the line that says
          `CUDA Version`, then use the PyTorch distribution that matches that version,
          or the closest one that is smaller than it. For example, if you have CUDA
          11.4 installed, select the PyTorch distribution for CUDA 11.3.

          - This might not make a difference, but it''s worth a try: instead of installing
          PyTorch using conda, perhaps you can use `pip` after you enable your virtual
          environment.


          Good luck!'
        updatedAt: '2022-08-28T17:05:41.074Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - dahara1
    id: 630ba065cd26ad7f60d9629b
    type: comment
  author: pcuenq
  content: 'Hi there!


    A couple of suggestions for your PyTorch install:


    - First, please verify what version of CUDA you have installed in your computer.
    If you run `nvidia-smi -q --display="COMPUTE"`, look for the line that says `CUDA
    Version`, then use the PyTorch distribution that matches that version, or the
    closest one that is smaller than it. For example, if you have CUDA 11.4 installed,
    select the PyTorch distribution for CUDA 11.3.

    - This might not make a difference, but it''s worth a try: instead of installing
    PyTorch using conda, perhaps you can use `pip` after you enable your virtual environment.


    Good luck!'
  created_at: 2022-08-28 16:05:41+00:00
  edited: false
  hidden: false
  id: 630ba065cd26ad7f60d9629b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c8ecf5b0316733b9f7d4bf8031fef56e.svg
      fullname: goichi harada
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dahara1
      type: user
    createdAt: '2022-08-29T04:53:06.000Z'
    data:
      edited: false
      editors:
      - dahara1
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c8ecf5b0316733b9f7d4bf8031fef56e.svg
          fullname: goichi harada
          isHf: false
          isPro: false
          name: dahara1
          type: user
        html: '<p>Hi !</p>

          <p>Thank you your advice and Amazing!</p>

          <p>Using the same Seed(6363507785059417) from Colab outputs a picture of
          a yellow dog that looks identical to me.<br>However, the byte size is different
          so it must be slightly different.</p>

          <p>-rw-rw-r--  1 dev3 dev3 499832 Aug 29 13:29 orginal_colab.png<br>-rw-rw-r--  1
          dev3 dev3 499758 Aug 29 13:35 same_seed_test_file.png</p>

          <p>reference information</p>

          <p>My CUDA is CUDA Toolkit 11.7 Update 1 (<a rel="nofollow" href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;">https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;</a>
          target_version=22.04&amp;target_type=runfile_local), which I installed manually.</p>

          <p>I also installed PyTorch from source.(<a rel="nofollow" href="https://github.com/pytorch/pytorch#install-pytorch">https://github.com/pytorch/pytorch#install-pytorch</a>)</p>

          <p>then</p>

          <p>pip install git+<a rel="nofollow" href="https://github.com/huggingface/diffusers.git">https://github.com/huggingface/diffusers.git</a><br>pip
          install transformers<br>pip install ftfy</p>

          <p>and It worked!<br>Thank you.</p>

          '
        raw: "Hi !\n\nThank you your advice and Amazing!\n\nUsing the same Seed(6363507785059417)\
          \ from Colab outputs a picture of a yellow dog that looks identical to me.\
          \ \nHowever, the byte size is different so it must be slightly different.\n\
          \n-rw-rw-r--  1 dev3 dev3 499832 Aug 29 13:29 orginal_colab.png\n-rw-rw-r--\
          \  1 dev3 dev3 499758 Aug 29 13:35 same_seed_test_file.png\n\nreference\
          \ information\n\nMy CUDA is CUDA Toolkit 11.7 Update 1 (https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&\
          \ target_version=22.04&target_type=runfile_local), which I installed manually.\n\
          \nI also installed PyTorch from source.(https://github.com/pytorch/pytorch#install-pytorch)\n\
          \nthen\n\npip install git+https://github.com/huggingface/diffusers.git\n\
          pip install transformers\npip install ftfy\n\nand It worked!\nThank you."
        updatedAt: '2022-08-29T04:53:06.964Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - pcuenq
    id: 630c46328b327c7b8ba15fe0
    type: comment
  author: dahara1
  content: "Hi !\n\nThank you your advice and Amazing!\n\nUsing the same Seed(6363507785059417)\
    \ from Colab outputs a picture of a yellow dog that looks identical to me. \n\
    However, the byte size is different so it must be slightly different.\n\n-rw-rw-r--\
    \  1 dev3 dev3 499832 Aug 29 13:29 orginal_colab.png\n-rw-rw-r--  1 dev3 dev3\
    \ 499758 Aug 29 13:35 same_seed_test_file.png\n\nreference information\n\nMy CUDA\
    \ is CUDA Toolkit 11.7 Update 1 (https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&\
    \ target_version=22.04&target_type=runfile_local), which I installed manually.\n\
    \nI also installed PyTorch from source.(https://github.com/pytorch/pytorch#install-pytorch)\n\
    \nthen\n\npip install git+https://github.com/huggingface/diffusers.git\npip install\
    \ transformers\npip install ftfy\n\nand It worked!\nThank you."
  created_at: 2022-08-29 03:53:06+00:00
  edited: false
  hidden: false
  id: 630c46328b327c7b8ba15fe0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: CompVis/stable-diffusion-v1-4
repo_type: model
status: open
target_branch: null
title: Random seed specification?
