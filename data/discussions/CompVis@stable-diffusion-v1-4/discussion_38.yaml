!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xalex
conflicting_files: null
created_at: 2022-09-05 16:37:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
      fullname: Alex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xalex
      type: user
    createdAt: '2022-09-05T17:37:12.000Z'
    data:
      edited: false
      editors:
      - xalex
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
          fullname: Alex
          isHf: false
          isPro: false
          name: xalex
          type: user
        html: '<p>I wonder how one can get bigger results without having the computing
          power for large resolutions. Can you recommend other networks for upscaling?</p>

          '
        raw: I wonder how one can get bigger results without having the computing
          power for large resolutions. Can you recommend other networks for upscaling?
        updatedAt: '2022-09-05T17:37:12.074Z'
      numEdits: 0
      reactions: []
    id: 631633c893ab42acfb0639d1
    type: comment
  author: xalex
  content: I wonder how one can get bigger results without having the computing power
    for large resolutions. Can you recommend other networks for upscaling?
  created_at: 2022-09-05 16:37:12+00:00
  edited: false
  hidden: false
  id: 631633c893ab42acfb0639d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
      fullname: Alex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xalex
      type: user
    createdAt: '2022-09-05T17:37:39.000Z'
    data:
      edited: true
      editors:
      - xalex
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
          fullname: Alex
          isHf: false
          isPro: false
          name: xalex
          type: user
        html: '<p>And some brainstorming ideas:</p>

          <p>Do you think, if a pipeline using inpainting/img2img would be interesting?<br>I
          tried to scale a result with gimp and then use img2img with low strength
          to see if I could improve it patch-by-patch thinking about if the differences
          at the boundaries could be fixed using the inpainting pipeline. The problem
          here is, that with low strength the input is only slightly changed and the
          quality does not improve at all and with larger strength the style changes.</p>

          <p>Maybe one could upscale the initialization and use patches from the upscaled
          noise as initialization in the img2img process?<br>Or to avoid losing details
          one could try to generate noise, e.g., in Full-HD resolution and then downscale
          it for the initial image, e.g., in 640x384 resolution. Afterward one can
          upscale the image and use patches from the upscaled image with patches from
          the original noise together with the img2img pipeline.</p>

          <p>The advantage would be, that it would not only upscale, but could also
          add finer details to the patches.</p>

          '
        raw: 'And some brainstorming ideas:


          Do you think, if a pipeline using inpainting/img2img would be interesting?

          I tried to scale a result with gimp and then use img2img with low strength
          to see if I could improve it patch-by-patch thinking about if the differences
          at the boundaries could be fixed using the inpainting pipeline. The problem
          here is, that with low strength the input is only slightly changed and the
          quality does not improve at all and with larger strength the style changes.


          Maybe one could upscale the initialization and use patches from the upscaled
          noise as initialization in the img2img process?

          Or to avoid losing details one could try to generate noise, e.g., in Full-HD
          resolution and then downscale it for the initial image, e.g., in 640x384
          resolution. Afterward one can upscale the image and use patches from the
          upscaled image with patches from the original noise together with the img2img
          pipeline.


          The advantage would be, that it would not only upscale, but could also add
          finer details to the patches.'
        updatedAt: '2022-09-05T17:49:24.660Z'
      numEdits: 1
      reactions: []
    id: 631633e33edbcfbc5d459044
    type: comment
  author: xalex
  content: 'And some brainstorming ideas:


    Do you think, if a pipeline using inpainting/img2img would be interesting?

    I tried to scale a result with gimp and then use img2img with low strength to
    see if I could improve it patch-by-patch thinking about if the differences at
    the boundaries could be fixed using the inpainting pipeline. The problem here
    is, that with low strength the input is only slightly changed and the quality
    does not improve at all and with larger strength the style changes.


    Maybe one could upscale the initialization and use patches from the upscaled noise
    as initialization in the img2img process?

    Or to avoid losing details one could try to generate noise, e.g., in Full-HD resolution
    and then downscale it for the initial image, e.g., in 640x384 resolution. Afterward
    one can upscale the image and use patches from the upscaled image with patches
    from the original noise together with the img2img pipeline.


    The advantage would be, that it would not only upscale, but could also add finer
    details to the patches.'
  created_at: 2022-09-05 16:37:39+00:00
  edited: true
  hidden: false
  id: 631633e33edbcfbc5d459044
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616001397867-5f17f0a0925b9863e28ad517.png?w=200&h=200&f=face
      fullname: Victor Mustar
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: true
      name: victor
      type: user
    createdAt: '2022-09-06T14:47:30.000Z'
    data:
      edited: false
      editors:
      - victor
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616001397867-5f17f0a0925b9863e28ad517.png?w=200&h=200&f=face
          fullname: Victor Mustar
          isHf: true
          isPro: true
          name: victor
          type: user
        html: '<p>Hey, I stumbled across <a rel="nofollow" href="https://www.reddit.com/r/StableDiffusion/comments/x45uk6/my_process_to_upscale_an_image_through_img2img/?utm_source=share&amp;utm_medium=web2x&amp;context=3">this
          reddit post</a>, might be interesting to you.</p>

          '
        raw: Hey, I stumbled across [this reddit post](https://www.reddit.com/r/StableDiffusion/comments/x45uk6/my_process_to_upscale_an_image_through_img2img/?utm_source=share&utm_medium=web2x&context=3),
          might be interesting to you.
        updatedAt: '2022-09-06T14:47:30.402Z'
      numEdits: 0
      reactions: []
    id: 63175d82c92fd6fee31ad371
    type: comment
  author: victor
  content: Hey, I stumbled across [this reddit post](https://www.reddit.com/r/StableDiffusion/comments/x45uk6/my_process_to_upscale_an_image_through_img2img/?utm_source=share&utm_medium=web2x&context=3),
    might be interesting to you.
  created_at: 2022-09-06 13:47:30+00:00
  edited: false
  hidden: false
  id: 63175d82c92fd6fee31ad371
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2022-09-06T21:20:45.000Z'
    data:
      edited: false
      editors:
      - patrickvonplaten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
          fullname: Patrick von Platen
          isHf: true
          isPro: false
          name: patrickvonplaten
          type: user
        html: '<p>This should also help to significantly reduce memory requirements
          allowing for larger images:<br><a rel="nofollow" href="https://mobile.twitter.com/PatrickPlaten/status/1567185296453779456">https://mobile.twitter.com/PatrickPlaten/status/1567185296453779456</a></p>

          '
        raw: 'This should also help to significantly reduce memory requirements allowing
          for larger images:

          https://mobile.twitter.com/PatrickPlaten/status/1567185296453779456'
        updatedAt: '2022-09-06T21:20:45.035Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - tompham97
    id: 6317b9ad83d8d2fd90328bb6
    type: comment
  author: patrickvonplaten
  content: 'This should also help to significantly reduce memory requirements allowing
    for larger images:

    https://mobile.twitter.com/PatrickPlaten/status/1567185296453779456'
  created_at: 2022-09-06 20:20:45+00:00
  edited: false
  hidden: false
  id: 6317b9ad83d8d2fd90328bb6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
      fullname: Alex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xalex
      type: user
    createdAt: '2022-09-07T19:08:53.000Z'
    data:
      edited: false
      editors:
      - xalex
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
          fullname: Alex
          isHf: false
          isPro: false
          name: xalex
          type: user
        html: '<ul>

          <li>I tried bigger rendering with the attention slicing and it kind of works,
          but produces no good results. The network seems not to be trained for larger
          sizes and you get often the things from your prompt several times in your
          image.</li>

          <li>I also tried inpainting for extrapolating. I generated a 512x512 image,
          than I increased the canvas size and made a mask covering the empty area
          and some overlap. The results depend very much (even with low/high strength)
          on the initialization of the empty area.</li>

          <li>Real-EsrGAN provides nice upscaling. I still have to experiment with
          using img2img to improve on EsrGAN results.</li>

          <li>The method in the Reddit post looks way too complicated, especially
          when it is necessary to change the prompt for different patches.<br>-It
          may be worth to try (for some prompts) to generate a large image with duplicated
          objects due to a too large size and then use inpainting to remove the unwanted
          objects, possibly with another prompt, which does not contain the object
          descriptions. (e.g. first "A forest with a bird" and then removing all but
          one bird and inpainting "A forest")</li>

          </ul>

          '
        raw: '- I tried bigger rendering with the attention slicing and it kind of
          works, but produces no good results. The network seems not to be trained
          for larger sizes and you get often the things from your prompt several times
          in your image.

          - I also tried inpainting for extrapolating. I generated a 512x512 image,
          than I increased the canvas size and made a mask covering the empty area
          and some overlap. The results depend very much (even with low/high strength)
          on the initialization of the empty area.

          - Real-EsrGAN provides nice upscaling. I still have to experiment with using
          img2img to improve on EsrGAN results.

          - The method in the Reddit post looks way too complicated, especially when
          it is necessary to change the prompt for different patches.

          -It may be worth to try (for some prompts) to generate a large image with
          duplicated objects due to a too large size and then use inpainting to remove
          the unwanted objects, possibly with another prompt, which does not contain
          the object descriptions. (e.g. first "A forest with a bird" and then removing
          all but one bird and inpainting "A forest")'
        updatedAt: '2022-09-07T19:08:53.926Z'
      numEdits: 0
      reactions: []
    id: 6318ec454f6f4fdbf912e1a4
    type: comment
  author: xalex
  content: '- I tried bigger rendering with the attention slicing and it kind of works,
    but produces no good results. The network seems not to be trained for larger sizes
    and you get often the things from your prompt several times in your image.

    - I also tried inpainting for extrapolating. I generated a 512x512 image, than
    I increased the canvas size and made a mask covering the empty area and some overlap.
    The results depend very much (even with low/high strength) on the initialization
    of the empty area.

    - Real-EsrGAN provides nice upscaling. I still have to experiment with using img2img
    to improve on EsrGAN results.

    - The method in the Reddit post looks way too complicated, especially when it
    is necessary to change the prompt for different patches.

    -It may be worth to try (for some prompts) to generate a large image with duplicated
    objects due to a too large size and then use inpainting to remove the unwanted
    objects, possibly with another prompt, which does not contain the object descriptions.
    (e.g. first "A forest with a bird" and then removing all but one bird and inpainting
    "A forest")'
  created_at: 2022-09-07 18:08:53+00:00
  edited: false
  hidden: false
  id: 6318ec454f6f4fdbf912e1a4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 38
repo_id: CompVis/stable-diffusion-v1-4
repo_type: model
status: open
target_branch: null
title: Best ways for upscaling the results?
