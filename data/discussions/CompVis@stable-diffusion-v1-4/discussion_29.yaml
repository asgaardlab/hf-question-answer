!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Vehrn
conflicting_files: null
created_at: 2022-08-30 13:22:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/32134dc204a7e6d466a2d12fe658f2b8.svg
      fullname: Nunya Business
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vehrn
      type: user
    createdAt: '2022-08-30T14:22:32.000Z'
    data:
      edited: false
      editors:
      - Vehrn
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/32134dc204a7e6d466a2d12fe658f2b8.svg
          fullname: Nunya Business
          isHf: false
          isPro: false
          name: Vehrn
          type: user
        html: '<p> I see CUDA is the default in the setup scripts. When running the
          setup I get the following error on my 6800AMD GPU. AssertionError: Torch
          not compiled with CUDA enabled </p>

          <p>Thanks in advance.</p>

          '
        raw: " I see CUDA is the default in the setup scripts. When running the setup\
          \ I get the following error on my 6800AMD GPU. AssertionError: Torch not\
          \ compiled with CUDA enabled \r\n\r\nThanks in advance."
        updatedAt: '2022-08-30T14:22:32.427Z'
      numEdits: 0
      reactions: []
    id: 630e1d28d818ed99de8a7c74
    type: comment
  author: Vehrn
  content: " I see CUDA is the default in the setup scripts. When running the setup\
    \ I get the following error on my 6800AMD GPU. AssertionError: Torch not compiled\
    \ with CUDA enabled \r\n\r\nThanks in advance."
  created_at: 2022-08-30 13:22:32+00:00
  edited: false
  hidden: false
  id: 630e1d28d818ed99de8a7c74
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4f56391e3dfdd327cb588f1c838701e0.svg
      fullname: Anand
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: harishanand95
      type: user
    createdAt: '2022-08-30T17:32:21.000Z'
    data:
      edited: true
      editors:
      - harishanand95
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4f56391e3dfdd327cb588f1c838701e0.svg
          fullname: Anand
          isHf: false
          isPro: false
          name: harishanand95
          type: user
        html: "<h2 id=\"how-to-run-compvisstable-diffusion-on-amd-linux\">How to run\
          \ <a rel=\"nofollow\" href=\"https://github.com/CompVis/stable-diffusion\"\
          >CompVis/stable-diffusion</a> on AMD Linux</h2>\n<pre><code># AMD Driver\
          \ installation: https://docs.amd.com/bundle/ROCm-Installation-Guide-v5.1/page/How_to_Install_ROCm.html\n\
          # command would be something like this after installing amdgpu-install\n\
          # sudo amdgpu-install --rocmrelease=5.2.3 --usecase=dkms,graphics,rocm,lrt,hip,hiplibsdk\n\
          # if its installed already, try rocm-smi command it will show available\
          \ GPUs\n\ncd stable-diffusion/\nconda env create -f environment.yaml\nconda\
          \ activate ldm\nconda remove cudatoolkit -y\npip3 uninstall torch torchvision\
          \ -y \n# Install PyTorch ROCm\npip3 install torch torchvision torchaudio\
          \ --extra-index-url https://download.pytorch.org/whl/rocm5.1.1\npip3 install\
          \ transformers==4.19.2 scann kornia==0.6.4 torchmetrics==0.6.0\n\n# Place\
          \ the model as model.ckpt in the models/ldm/stable-diffusion-v1/ folder\n\
          python scripts/txt2img.py --prompt \"a photograph of an astronaut riding\
          \ a horse\" --plms\n</code></pre>\n<h2 id=\"how-to-run-huggingfacediffusers-on-amd-linux\"\
          >How to run <a rel=\"nofollow\" href=\"https://github.com/huggingface/diffusers\"\
          >huggingface/diffusers</a> on AMD Linux</h2>\n<pre><code class=\"language-bash\"\
          >git <span class=\"hljs-built_in\">clone</span> https://github.com/huggingface/diffusers.git\n\
          <span class=\"hljs-built_in\">cd</span> diffusers/\npip3 install -e .\n\
          pip3 uninstall torch \npip3 install torch torchvision torchaudio --extra-index-url\
          \ https://download.pytorch.org/whl/rocm5.1.1\n</code></pre>\n<p> Run the\
          \ code without autocast.. (<a rel=\"nofollow\" href=\"https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines#text-to-image-generation-with-stable-diffusion\"\
          >https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines#text-to-image-generation-with-stable-diffusion</a>)</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-comment\"># make\
          \ sure you're logged in with `huggingface-cli login`</span>\n<span class=\"\
          hljs-keyword\">from</span> diffusers <span class=\"hljs-keyword\">import</span>\
          \ StableDiffusionPipeline, LMSDiscreteScheduler\n\npipe = StableDiffusionPipeline.from_pretrained(<span\
          \ class=\"hljs-string\">\"CompVis/stable-diffusion-v1-4\"</span>, use_auth_token=<span\
          \ class=\"hljs-literal\">True</span>)\npipe = pipe.to(<span class=\"hljs-string\"\
          >\"cuda\"</span>)\n\nprompt = <span class=\"hljs-string\">\"a photo of an\
          \ astronaut riding a horse on mars\"</span>\nimage = pipe(prompt)[<span\
          \ class=\"hljs-string\">\"sample\"</span>][<span class=\"hljs-number\">0</span>]\
          \ \nimage.save(<span class=\"hljs-string\">\"astronaut_rides_horse.png\"\
          </span>)\n</code></pre>\n<p>If you are on Windows, try this MLIR/IREE  approach:\
          \ <a rel=\"nofollow\" href=\"https://github.com/nod-ai/SHARK/blob/main/shark/examples/shark_inference/stable_diffusion/stable_diffusion_amd.md\"\
          >https://github.com/nod-ai/SHARK/blob/main/shark/examples/shark_inference/stable_diffusion/stable_diffusion_amd.md</a><br>ONNX\
          \ DirectML approach on Windows (Slower ) : <a rel=\"nofollow\" href=\"https://gist.github.com/harishanand95/75f4515e6187a6aa3261af6ac6f61269\"\
          >https://gist.github.com/harishanand95/75f4515e6187a6aa3261af6ac6f61269</a></p>\n"
        raw: "## How to run [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion)\
          \ on AMD Linux \n\n```\n# AMD Driver installation: https://docs.amd.com/bundle/ROCm-Installation-Guide-v5.1/page/How_to_Install_ROCm.html\n\
          # command would be something like this after installing amdgpu-install\n\
          # sudo amdgpu-install --rocmrelease=5.2.3 --usecase=dkms,graphics,rocm,lrt,hip,hiplibsdk\n\
          # if its installed already, try rocm-smi command it will show available\
          \ GPUs\n\ncd stable-diffusion/\nconda env create -f environment.yaml\nconda\
          \ activate ldm\nconda remove cudatoolkit -y\npip3 uninstall torch torchvision\
          \ -y \n# Install PyTorch ROCm\npip3 install torch torchvision torchaudio\
          \ --extra-index-url https://download.pytorch.org/whl/rocm5.1.1\npip3 install\
          \ transformers==4.19.2 scann kornia==0.6.4 torchmetrics==0.6.0\n\n# Place\
          \ the model as model.ckpt in the models/ldm/stable-diffusion-v1/ folder\n\
          python scripts/txt2img.py --prompt \"a photograph of an astronaut riding\
          \ a horse\" --plms\n```\n\n## How to run [huggingface/diffusers](https://github.com/huggingface/diffusers)\
          \ on AMD Linux \n\n```bash\ngit clone https://github.com/huggingface/diffusers.git\n\
          cd diffusers/\npip3 install -e .\npip3 uninstall torch \npip3 install torch\
          \ torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/rocm5.1.1\n\
          ```\n Run the code without autocast.. (https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines#text-to-image-generation-with-stable-diffusion)\n\
          \n```python\n# make sure you're logged in with `huggingface-cli login`\n\
          from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler\n\n\
          pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\"\
          , use_auth_token=True)\npipe = pipe.to(\"cuda\")\n\nprompt = \"a photo of\
          \ an astronaut riding a horse on mars\"\nimage = pipe(prompt)[\"sample\"\
          ][0] \nimage.save(\"astronaut_rides_horse.png\")\n```\n\nIf you are on Windows,\
          \ try this MLIR/IREE  approach: https://github.com/nod-ai/SHARK/blob/main/shark/examples/shark_inference/stable_diffusion/stable_diffusion_amd.md\n\
          ONNX DirectML approach on Windows (Slower ) : https://gist.github.com/harishanand95/75f4515e6187a6aa3261af6ac6f61269"
        updatedAt: '2022-12-02T21:53:43.792Z'
      numEdits: 3
      reactions:
      - count: 8
        reaction: "\u2764\uFE0F"
        users:
        - julien-c
        - NimaBoscarino
        - harishanand95
        - multimodalart
        - astropop
        - osanseviero
        - patrickvonplaten
        - anton-l
      - count: 5
        reaction: "\U0001F44D"
        users:
        - panopstor
        - osanseviero
        - patrickvonplaten
        - anton-l
        - julien-c
    id: 630e49a583f64e3516785431
    type: comment
  author: harishanand95
  content: "## How to run [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion)\
    \ on AMD Linux \n\n```\n# AMD Driver installation: https://docs.amd.com/bundle/ROCm-Installation-Guide-v5.1/page/How_to_Install_ROCm.html\n\
    # command would be something like this after installing amdgpu-install\n# sudo\
    \ amdgpu-install --rocmrelease=5.2.3 --usecase=dkms,graphics,rocm,lrt,hip,hiplibsdk\n\
    # if its installed already, try rocm-smi command it will show available GPUs\n\
    \ncd stable-diffusion/\nconda env create -f environment.yaml\nconda activate ldm\n\
    conda remove cudatoolkit -y\npip3 uninstall torch torchvision -y \n# Install PyTorch\
    \ ROCm\npip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/rocm5.1.1\n\
    pip3 install transformers==4.19.2 scann kornia==0.6.4 torchmetrics==0.6.0\n\n\
    # Place the model as model.ckpt in the models/ldm/stable-diffusion-v1/ folder\n\
    python scripts/txt2img.py --prompt \"a photograph of an astronaut riding a horse\"\
    \ --plms\n```\n\n## How to run [huggingface/diffusers](https://github.com/huggingface/diffusers)\
    \ on AMD Linux \n\n```bash\ngit clone https://github.com/huggingface/diffusers.git\n\
    cd diffusers/\npip3 install -e .\npip3 uninstall torch \npip3 install torch torchvision\
    \ torchaudio --extra-index-url https://download.pytorch.org/whl/rocm5.1.1\n```\n\
    \ Run the code without autocast.. (https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines#text-to-image-generation-with-stable-diffusion)\n\
    \n```python\n# make sure you're logged in with `huggingface-cli login`\nfrom diffusers\
    \ import StableDiffusionPipeline, LMSDiscreteScheduler\n\npipe = StableDiffusionPipeline.from_pretrained(\"\
    CompVis/stable-diffusion-v1-4\", use_auth_token=True)\npipe = pipe.to(\"cuda\"\
    )\n\nprompt = \"a photo of an astronaut riding a horse on mars\"\nimage = pipe(prompt)[\"\
    sample\"][0] \nimage.save(\"astronaut_rides_horse.png\")\n```\n\nIf you are on\
    \ Windows, try this MLIR/IREE  approach: https://github.com/nod-ai/SHARK/blob/main/shark/examples/shark_inference/stable_diffusion/stable_diffusion_amd.md\n\
    ONNX DirectML approach on Windows (Slower ) : https://gist.github.com/harishanand95/75f4515e6187a6aa3261af6ac6f61269"
  created_at: 2022-08-30 16:32:21+00:00
  edited: true
  hidden: false
  id: 630e49a583f64e3516785431
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ff60201c2af69b94f94287/flc8mFRrST35P3DFEOufY.jpeg?w=200&h=200&f=face
      fullname: Boi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boi-doingthings
      type: user
    createdAt: '2022-09-08T20:32:35.000Z'
    data:
      edited: false
      editors:
      - boi-doingthings
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ff60201c2af69b94f94287/flc8mFRrST35P3DFEOufY.jpeg?w=200&h=200&f=face
          fullname: Boi
          isHf: false
          isPro: false
          name: boi-doingthings
          type: user
        html: '<p>May I ask how much VRAM does your device had. I am facing memory
          troubles on my 3070 with a 8 GB VRAM.</p>

          '
        raw: May I ask how much VRAM does your device had. I am facing memory troubles
          on my 3070 with a 8 GB VRAM.
        updatedAt: '2022-09-08T20:32:35.134Z'
      numEdits: 0
      reactions: []
    id: 631a51630867652f5387e370
    type: comment
  author: boi-doingthings
  content: May I ask how much VRAM does your device had. I am facing memory troubles
    on my 3070 with a 8 GB VRAM.
  created_at: 2022-09-08 19:32:35+00:00
  edited: false
  hidden: false
  id: 631a51630867652f5387e370
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 29
repo_id: CompVis/stable-diffusion-v1-4
repo_type: model
status: open
target_branch: null
title: Can this be run with an AMD GPU?
