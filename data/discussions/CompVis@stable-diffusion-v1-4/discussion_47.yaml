!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Keyloggeduser
conflicting_files: null
created_at: 2022-09-10 16:31:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6701fc1ad0cc94f8f22a7f7f70c7c0fd.svg
      fullname: Keylogge Duser
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Keyloggeduser
      type: user
    createdAt: '2022-09-10T17:31:11.000Z'
    data:
      edited: false
      editors:
      - Keyloggeduser
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6701fc1ad0cc94f8f22a7f7f70c7c0fd.svg
          fullname: Keylogge Duser
          isHf: false
          isPro: false
          name: Keyloggeduser
          type: user
        html: '<p>Hey,</p>

          <p>Just went this guide on installing this and running the first example
          I got a memory error. Anyone else run into this?</p>

          <p>Posting entire terminal log ---&gt;</p>

          <p>(base) C:\Users\User&gt;cd C:\stable-diffusion\stable-diffusion-main</p>

          <p>(base) C:\stable-diffusion\stable-diffusion-main&gt;conda activate ldm</p>

          <p>(ldm) C:\stable-diffusion\stable-diffusion-main&gt;python scripts/txt2img.py
          --prompt "a close-up portrait of a cat by pablo picasso, vivid, abstract
          art, colorful, vibrant" --plms --n_iter 5 --n_samples 1<br>Global seed set
          to 42<br>Loading model from models/ldm/stable-diffusion-v1/model.ckpt<br>Traceback
          (most recent call last):<br>  File "scripts/txt2img.py", line 344, in <br>    main()<br>  File
          "scripts/txt2img.py", line 240, in main<br>    model = load_model_from_config(config,
          f"{opt.ckpt}")<br>  File "scripts/txt2img.py", line 50, in load_model_from_config<br>    pl_sd
          = torch.load(ckpt, map_location="cpu")<br>  File "C:\Users\User.conda\envs\ldm\lib\site-packages\torch\serialization.py",
          line 712, in load<br>    return _load(opened_zipfile, map_location, pickle_module,
          **pickle_load_args)<br>  File "C:\Users\User.conda\envs\ldm\lib\site-packages\torch\serialization.py",
          line 1046, in _load<br>    result = unpickler.load()<br>  File "C:\Users\User.conda\envs\ldm\lib\site-packages\torch\serialization.py",
          line 1016, in persistent_load<br>    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))<br>  File
          "C:\Users\User.conda\envs\ldm\lib\site-packages\torch\serialization.py",
          line 997, in load_tensor<br>    storage = zip_file.get_storage_from_record(name,
          numel, torch._UntypedStorage).storage()._untyped()<br>RuntimeError: [enforce
          fail at C:\cb\pytorch_1000000000000\work\c10\core\impl\alloc_cpu.cpp:81]
          data. DefaultCPUAllocator: not enough memory: you tried to allocate 2359296
          bytes.</p>

          <p>Any help would be greatly appreciated,<br>Thanks,<br>-KLU</p>

          '
        raw: "Hey,\r\n\r\nJust went this guide on installing this and running the\
          \ first example I got a memory error. Anyone else run into this?\r\n\r\n\
          Posting entire terminal log --->\r\n\r\n(base) C:\\Users\\User>cd C:\\stable-diffusion\\\
          stable-diffusion-main\r\n\r\n(base) C:\\stable-diffusion\\stable-diffusion-main>conda\
          \ activate ldm\r\n\r\n(ldm) C:\\stable-diffusion\\stable-diffusion-main>python\
          \ scripts/txt2img.py --prompt \"a close-up portrait of a cat by pablo picasso,\
          \ vivid, abstract art, colorful, vibrant\" --plms --n_iter 5 --n_samples\
          \ 1\r\nGlobal seed set to 42\r\nLoading model from models/ldm/stable-diffusion-v1/model.ckpt\r\
          \nTraceback (most recent call last):\r\n  File \"scripts/txt2img.py\", line\
          \ 344, in <module>\r\n    main()\r\n  File \"scripts/txt2img.py\", line\
          \ 240, in main\r\n    model = load_model_from_config(config, f\"{opt.ckpt}\"\
          )\r\n  File \"scripts/txt2img.py\", line 50, in load_model_from_config\r\
          \n    pl_sd = torch.load(ckpt, map_location=\"cpu\")\r\n  File \"C:\\Users\\\
          User\\.conda\\envs\\ldm\\lib\\site-packages\\torch\\serialization.py\",\
          \ line 712, in load\r\n    return _load(opened_zipfile, map_location, pickle_module,\
          \ **pickle_load_args)\r\n  File \"C:\\Users\\User\\.conda\\envs\\ldm\\lib\\\
          site-packages\\torch\\serialization.py\", line 1046, in _load\r\n    result\
          \ = unpickler.load()\r\n  File \"C:\\Users\\User\\.conda\\envs\\ldm\\lib\\\
          site-packages\\torch\\serialization.py\", line 1016, in persistent_load\r\
          \n    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\r\n\
          \  File \"C:\\Users\\User\\.conda\\envs\\ldm\\lib\\site-packages\\torch\\\
          serialization.py\", line 997, in load_tensor\r\n    storage = zip_file.get_storage_from_record(name,\
          \ numel, torch._UntypedStorage).storage()._untyped()\r\nRuntimeError: [enforce\
          \ fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81]\
          \ data. DefaultCPUAllocator: not enough memory: you tried to allocate 2359296\
          \ bytes.\r\n\r\n\r\n\r\nAny help would be greatly appreciated,\r\nThanks,\r\
          \n-KLU"
        updatedAt: '2022-09-10T17:31:11.617Z'
      numEdits: 0
      reactions: []
    id: 631cc9dfa31a0a462ca1c765
    type: comment
  author: Keyloggeduser
  content: "Hey,\r\n\r\nJust went this guide on installing this and running the first\
    \ example I got a memory error. Anyone else run into this?\r\n\r\nPosting entire\
    \ terminal log --->\r\n\r\n(base) C:\\Users\\User>cd C:\\stable-diffusion\\stable-diffusion-main\r\
    \n\r\n(base) C:\\stable-diffusion\\stable-diffusion-main>conda activate ldm\r\n\
    \r\n(ldm) C:\\stable-diffusion\\stable-diffusion-main>python scripts/txt2img.py\
    \ --prompt \"a close-up portrait of a cat by pablo picasso, vivid, abstract art,\
    \ colorful, vibrant\" --plms --n_iter 5 --n_samples 1\r\nGlobal seed set to 42\r\
    \nLoading model from models/ldm/stable-diffusion-v1/model.ckpt\r\nTraceback (most\
    \ recent call last):\r\n  File \"scripts/txt2img.py\", line 344, in <module>\r\
    \n    main()\r\n  File \"scripts/txt2img.py\", line 240, in main\r\n    model\
    \ = load_model_from_config(config, f\"{opt.ckpt}\")\r\n  File \"scripts/txt2img.py\"\
    , line 50, in load_model_from_config\r\n    pl_sd = torch.load(ckpt, map_location=\"\
    cpu\")\r\n  File \"C:\\Users\\User\\.conda\\envs\\ldm\\lib\\site-packages\\torch\\\
    serialization.py\", line 712, in load\r\n    return _load(opened_zipfile, map_location,\
    \ pickle_module, **pickle_load_args)\r\n  File \"C:\\Users\\User\\.conda\\envs\\\
    ldm\\lib\\site-packages\\torch\\serialization.py\", line 1046, in _load\r\n  \
    \  result = unpickler.load()\r\n  File \"C:\\Users\\User\\.conda\\envs\\ldm\\\
    lib\\site-packages\\torch\\serialization.py\", line 1016, in persistent_load\r\
    \n    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\r\n  File\
    \ \"C:\\Users\\User\\.conda\\envs\\ldm\\lib\\site-packages\\torch\\serialization.py\"\
    , line 997, in load_tensor\r\n    storage = zip_file.get_storage_from_record(name,\
    \ numel, torch._UntypedStorage).storage()._untyped()\r\nRuntimeError: [enforce\
    \ fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81]\
    \ data. DefaultCPUAllocator: not enough memory: you tried to allocate 2359296\
    \ bytes.\r\n\r\n\r\n\r\nAny help would be greatly appreciated,\r\nThanks,\r\n\
    -KLU"
  created_at: 2022-09-10 16:31:11+00:00
  edited: false
  hidden: false
  id: 631cc9dfa31a0a462ca1c765
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
      fullname: Alex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xalex
      type: user
    createdAt: '2022-09-11T14:04:39.000Z'
    data:
      edited: false
      editors:
      - xalex
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
          fullname: Alex
          isHf: false
          isPro: false
          name: xalex
          type: user
        html: '<ol>

          <li>Maybe you don''t have enough graphics memory? Try to enable attention
          slicing to be able to run the model with less memory.</li>

          <li>Enable torch memory splitting: <code>PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100
          python myscript.py</code></li>

          </ol>

          <p>If your graphics card doesn''t have enough memory you can run the model
          on CPU. It will be much slower, but at least it may fit into your CPU RAM.</p>

          '
        raw: '1) Maybe you don''t have enough graphics memory? Try to enable attention
          slicing to be able to run the model with less memory.

          2) Enable torch memory splitting: `PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100
          python myscript.py`


          If your graphics card doesn''t have enough memory you can run the model
          on CPU. It will be much slower, but at least it may fit into your CPU RAM.'
        updatedAt: '2022-09-11T14:04:39.763Z'
      numEdits: 0
      reactions: []
    id: 631deaf7a0cb8eb6a403be42
    type: comment
  author: xalex
  content: '1) Maybe you don''t have enough graphics memory? Try to enable attention
    slicing to be able to run the model with less memory.

    2) Enable torch memory splitting: `PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100
    python myscript.py`


    If your graphics card doesn''t have enough memory you can run the model on CPU.
    It will be much slower, but at least it may fit into your CPU RAM.'
  created_at: 2022-09-11 13:04:39+00:00
  edited: false
  hidden: false
  id: 631deaf7a0cb8eb6a403be42
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663073215355-631f61feb6628770f6f0f1a0.png?w=200&h=200&f=face
      fullname: GEOGAN
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: geogan
      type: user
    createdAt: '2022-09-12T21:41:46.000Z'
    data:
      edited: false
      editors:
      - geogan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663073215355-631f61feb6628770f6f0f1a0.png?w=200&h=200&f=face
          fullname: GEOGAN
          isHf: false
          isPro: false
          name: geogan
          type: user
        html: '<p>I wish someone would just say in plain English where exactly and
          how to set an environment variable to to the above "PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100"</p>

          <p>A lot of sh1te on every web search about it but nobody saying it.</p>

          '
        raw: 'I wish someone would just say in plain English where exactly and how
          to set an environment variable to to the above "PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100"


          A lot of sh1te on every web search about it but nobody saying it.'
        updatedAt: '2022-09-12T21:41:46.996Z'
      numEdits: 0
      reactions: []
    id: 631fa79ac6b20f03c826a66a
    type: comment
  author: geogan
  content: 'I wish someone would just say in plain English where exactly and how to
    set an environment variable to to the above "PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100"


    A lot of sh1te on every web search about it but nobody saying it.'
  created_at: 2022-09-12 20:41:46+00:00
  edited: false
  hidden: false
  id: 631fa79ac6b20f03c826a66a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
      fullname: Alex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xalex
      type: user
    createdAt: '2022-09-12T21:44:13.000Z'
    data:
      edited: true
      editors:
      - xalex
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
          fullname: Alex
          isHf: false
          isPro: false
          name: xalex
          type: user
        html: '<p>Two options:</p>

          <pre><code>export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100

          python myscript.py

          </code></pre>

          <p>Or just for the script (you just write it before the command):</p>

          <pre><code>PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100 python myscript.py

          </code></pre>

          <p>I think you can go down to 21 MB, and I don''t know what the trade-off
          is, but probably you may get performance issues when memory is fragmented
          instead of allocated in a block.</p>

          <p>Bash syntax. If you use powershell or similar it will look different,
          then search how it is done there. Or install a bash, maybe from cygwin or
          unxutils.</p>

          '
        raw: "Two options:\n\n    export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100\n\
          \    python myscript.py\n\nOr just for the script (you just write it before\
          \ the command):\n\n    PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100 python\
          \ myscript.py\n\nI think you can go down to 21 MB, and I don't know what\
          \ the trade-off is, but probably you may get performance issues when memory\
          \ is fragmented instead of allocated in a block.\n\nBash syntax. If you\
          \ use powershell or similar it will look different, then search how it is\
          \ done there. Or install a bash, maybe from cygwin or unxutils."
        updatedAt: '2022-09-12T23:07:48.083Z'
      numEdits: 3
      reactions: []
    id: 631fa82db45367a05fec467b
    type: comment
  author: xalex
  content: "Two options:\n\n    export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100\n\
    \    python myscript.py\n\nOr just for the script (you just write it before the\
    \ command):\n\n    PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:100 python myscript.py\n\
    \nI think you can go down to 21 MB, and I don't know what the trade-off is, but\
    \ probably you may get performance issues when memory is fragmented instead of\
    \ allocated in a block.\n\nBash syntax. If you use powershell or similar it will\
    \ look different, then search how it is done there. Or install a bash, maybe from\
    \ cygwin or unxutils."
  created_at: 2022-09-12 20:44:13+00:00
  edited: true
  hidden: false
  id: 631fa82db45367a05fec467b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/075950e97471af5c571ce6d1b118dc0f.svg
      fullname: Kamil S.Kom
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kamilskom
      type: user
    createdAt: '2022-09-13T11:46:31.000Z'
    data:
      edited: false
      editors:
      - kamilskom
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/075950e97471af5c571ce6d1b118dc0f.svg
          fullname: Kamil S.Kom
          isHf: false
          isPro: false
          name: kamilskom
          type: user
        html: '<p>as an alternative you can try <a rel="nofollow" href="https://github.com/basujindal/stable-diffusion">https://github.com/basujindal/stable-diffusion</a>,
          it''s a fork of stable diffusion for GPU with less than 10 GB memory. The
          nice thing about this fork is all the edit is in optimizedSD folder so you
          can just copy this folder to your main repo</p>

          '
        raw: as an alternative you can try https://github.com/basujindal/stable-diffusion,
          it's a fork of stable diffusion for GPU with less than 10 GB memory. The
          nice thing about this fork is all the edit is in optimizedSD folder so you
          can just copy this folder to your main repo
        updatedAt: '2022-09-13T11:46:31.369Z'
      numEdits: 0
      reactions: []
    id: 63206d9744a1fe6c92c75364
    type: comment
  author: kamilskom
  content: as an alternative you can try https://github.com/basujindal/stable-diffusion,
    it's a fork of stable diffusion for GPU with less than 10 GB memory. The nice
    thing about this fork is all the edit is in optimizedSD folder so you can just
    copy this folder to your main repo
  created_at: 2022-09-13 10:46:31+00:00
  edited: false
  hidden: false
  id: 63206d9744a1fe6c92c75364
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
      fullname: Alex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xalex
      type: user
    createdAt: '2022-09-13T11:50:36.000Z'
    data:
      edited: true
      editors:
      - xalex
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0ae9421c953e42655df328f4af0c8fa2.svg
          fullname: Alex
          isHf: false
          isPro: false
          name: xalex
          type: user
        html: '<p>Current <code>diffusers</code> has some of the new optimizations
          as well. You only need to add <code>enable_attention_slicing()</code> after
          loading the model and (optionally) load the fp16 model.<br>You will probably
          still need about 6 GB of VRAM, but it is much less than before. And it doesn''t
          seem to scale linearly, I get 512^2 into 6 GB and 1024^2 into 12 GB.</p>

          '
        raw: 'Current `diffusers` has some of the new optimizations as well. You only
          need to add `enable_attention_slicing()` after loading the model and (optionally)
          load the fp16 model.

          You will probably still need about 6 GB of VRAM, but it is much less than
          before. And it doesn''t seem to scale linearly, I get 512^2 into 6 GB and
          1024^2 into 12 GB.'
        updatedAt: '2022-09-13T11:51:07.837Z'
      numEdits: 1
      reactions: []
    id: 63206e8c8a09d76e80dea168
    type: comment
  author: xalex
  content: 'Current `diffusers` has some of the new optimizations as well. You only
    need to add `enable_attention_slicing()` after loading the model and (optionally)
    load the fp16 model.

    You will probably still need about 6 GB of VRAM, but it is much less than before.
    And it doesn''t seem to scale linearly, I get 512^2 into 6 GB and 1024^2 into
    12 GB.'
  created_at: 2022-09-13 10:50:36+00:00
  edited: true
  hidden: false
  id: 63206e8c8a09d76e80dea168
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663073215355-631f61feb6628770f6f0f1a0.png?w=200&h=200&f=face
      fullname: GEOGAN
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: geogan
      type: user
    createdAt: '2022-09-13T12:06:34.000Z'
    data:
      edited: true
      editors:
      - geogan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663073215355-631f61feb6628770f6f0f1a0.png?w=200&h=200&f=face
          fullname: GEOGAN
          isHf: false
          isPro: false
          name: geogan
          type: user
        html: '<p>I had already tried using export on the "Anaconda Prompt (Miniconda3)"
          console I was told to use to run the python script</p>

          <p>python scripts/txt2img.py</p>

          <p>But I just get:</p>

          <p>''export'' is not recognized as an internal or external command,<br>operable
          program or batch file.</p>

          <p>Anyway I''m not sure if that''s just a bad hack or workaround which slows
          things down massively (4x slower?)</p>

          <p>I though my problem was I was using the big 32-bit weights by using the
          7GB sd-v1-4-full-ema.ckpt file... so I tried to use the 16-bit weights in
          4GB sd-v1-4.ckpt instead which I read somewhere is what you should do if
          memory issues... but when I use that I get SAME memory problem???</p>

          <p>RuntimeError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU
          0; 8.00 GiB total capacity; 6.13 GiB already allocated; 0 bytes free; 6.73
          GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated
          memory try setting max_split_size_mb to avoid fragmentation.  See documentation
          for Memory Management and PYTORCH_CUDA_ALLOC_CONF</p>

          <p>ps.. for anyone looking... <a rel="nofollow" href="https://pytorch.org/docs/stable/notes/cuda.html#memory-management">https://pytorch.org/docs/stable/notes/cuda.html#memory-management</a></p>

          '
        raw: 'I had already tried using export on the "Anaconda Prompt (Miniconda3)"
          console I was told to use to run the python script


          python scripts/txt2img.py


          But I just get:


          ''export'' is not recognized as an internal or external command,

          operable program or batch file.


          Anyway I''m not sure if that''s just a bad hack or workaround which slows
          things down massively (4x slower?)


          I though my problem was I was using the big 32-bit weights by using the
          7GB sd-v1-4-full-ema.ckpt file... so I tried to use the 16-bit weights in
          4GB sd-v1-4.ckpt instead which I read somewhere is what you should do if
          memory issues... but when I use that I get SAME memory problem???


          RuntimeError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0;
          8.00 GiB total capacity; 6.13 GiB already allocated; 0 bytes free; 6.73
          GiB reserved in total by PyTorch) If reserved memory is >> allocated memory
          try setting max_split_size_mb to avoid fragmentation.  See documentation
          for Memory Management and PYTORCH_CUDA_ALLOC_CONF


          ps.. for anyone looking... https://pytorch.org/docs/stable/notes/cuda.html#memory-management'
        updatedAt: '2022-09-13T12:08:32.038Z'
      numEdits: 2
      reactions: []
    id: 6320724ae2df20f3c0e0c4e0
    type: comment
  author: geogan
  content: 'I had already tried using export on the "Anaconda Prompt (Miniconda3)"
    console I was told to use to run the python script


    python scripts/txt2img.py


    But I just get:


    ''export'' is not recognized as an internal or external command,

    operable program or batch file.


    Anyway I''m not sure if that''s just a bad hack or workaround which slows things
    down massively (4x slower?)


    I though my problem was I was using the big 32-bit weights by using the 7GB sd-v1-4-full-ema.ckpt
    file... so I tried to use the 16-bit weights in 4GB sd-v1-4.ckpt instead which
    I read somewhere is what you should do if memory issues... but when I use that
    I get SAME memory problem???


    RuntimeError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 8.00 GiB
    total capacity; 6.13 GiB already allocated; 0 bytes free; 6.73 GiB reserved in
    total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb
    to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    ps.. for anyone looking... https://pytorch.org/docs/stable/notes/cuda.html#memory-management'
  created_at: 2022-09-13 11:06:34+00:00
  edited: true
  hidden: false
  id: 6320724ae2df20f3c0e0c4e0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663073215355-631f61feb6628770f6f0f1a0.png?w=200&h=200&f=face
      fullname: GEOGAN
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: geogan
      type: user
    createdAt: '2022-09-13T12:53:55.000Z'
    data:
      edited: true
      editors:
      - geogan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663073215355-631f61feb6628770f6f0f1a0.png?w=200&h=200&f=face
          fullname: GEOGAN
          isHf: false
          isPro: false
          name: geogan
          type: user
        html: '<p>FYI - Using original fork for txt2img GPU memory usage on my 8GB
          3070 when it fails with out of memory...</p>

          <p>python scripts/txt2img.py --prompt "a close-up portrait of a cat by pablo
          picasso, vivid, abstract art, colorful, vibrant" --plms --n_iter 5 --n_samples
          1</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1663073481567-631f61feb6628770f6f0f1a0.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1663073481567-631f61feb6628770f6f0f1a0.png"></a></p>

          <p>Using the fork above for same... it finishes without error on 3070</p>

          <p>python optimizedSD/optimized_txt2img.py --prompt "Cyberpunk style image
          of a Tesla car reflection in rain" --H 512 --W 512 --seed 27 --n_iter 2
          --n_samples 5 --ddim_steps 50</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1663073526817-631f61feb6628770f6f0f1a0.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1663073526817-631f61feb6628770f6f0f1a0.png"></a></p>

          <p>I don''t know why arguments are different though... can''t use origianl
          command line... says "--plms" is invalid argument</p>

          '
        raw: 'FYI - Using original fork for txt2img GPU memory usage on my 8GB 3070
          when it fails with out of memory...


          python scripts/txt2img.py --prompt "a close-up portrait of a cat by pablo
          picasso, vivid, abstract art, colorful, vibrant" --plms --n_iter 5 --n_samples
          1


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1663073481567-631f61feb6628770f6f0f1a0.png)


          Using the fork above for same... it finishes without error on 3070


          python optimizedSD/optimized_txt2img.py --prompt "Cyberpunk style image
          of a Tesla car reflection in rain" --H 512 --W 512 --seed 27 --n_iter 2
          --n_samples 5 --ddim_steps 50


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1663073526817-631f61feb6628770f6f0f1a0.png)


          I don''t know why arguments are different though... can''t use origianl
          command line... says "--plms" is invalid argument'
        updatedAt: '2022-09-13T12:56:32.802Z'
      numEdits: 1
      reactions: []
    id: 63207d63d494d1413ce8f150
    type: comment
  author: geogan
  content: 'FYI - Using original fork for txt2img GPU memory usage on my 8GB 3070
    when it fails with out of memory...


    python scripts/txt2img.py --prompt "a close-up portrait of a cat by pablo picasso,
    vivid, abstract art, colorful, vibrant" --plms --n_iter 5 --n_samples 1


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1663073481567-631f61feb6628770f6f0f1a0.png)


    Using the fork above for same... it finishes without error on 3070


    python optimizedSD/optimized_txt2img.py --prompt "Cyberpunk style image of a Tesla
    car reflection in rain" --H 512 --W 512 --seed 27 --n_iter 2 --n_samples 5 --ddim_steps
    50


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1663073526817-631f61feb6628770f6f0f1a0.png)


    I don''t know why arguments are different though... can''t use origianl command
    line... says "--plms" is invalid argument'
  created_at: 2022-09-13 11:53:55+00:00
  edited: true
  hidden: false
  id: 63207d63d494d1413ce8f150
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 47
repo_id: CompVis/stable-diffusion-v1-4
repo_type: model
status: open
target_branch: null
title: RuntimeError... not enough memory???
