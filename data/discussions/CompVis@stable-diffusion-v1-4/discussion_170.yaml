!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sk2893
conflicting_files: null
created_at: 2022-12-14 13:35:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0a5ee2ea5ac77e785a20be5e5a18202e.svg
      fullname: saikrishna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sk2893
      type: user
    createdAt: '2022-12-14T13:35:42.000Z'
    data:
      edited: false
      editors:
      - sk2893
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0a5ee2ea5ac77e785a20be5e5a18202e.svg
          fullname: saikrishna
          isHf: false
          isPro: false
          name: sk2893
          type: user
        html: '<p>Hi using the stable diffusion v1.4 onnx model, I was trying to get
          inference on OPENVINO Execution provider.<br>Using installation of required
          packages related to openvino in a python environment,<br>Modified onnx_utils.py
          from diffusers library to give support of openvino execution provider.</p>

          <p>While running the inference, facing an issue related to model loading
          using Core of openvino. Facing following error<br>"image = pipe(prompt).images[0]
          File "onnx_openvpy39\lib\site-packages\diffusers\pipelines\stable_diffusion\pipeline_onnx_stable_diffusion.py",
          line 274, in <strong>call</strong> noise_pred = self.unet(sample=latent_model_input,
          timestep=timestep, encoder_hidden_states=text_embeddings) File "onnx_openvpy39\lib\site-packages\diffusers\onnx_utils.py",
          line 62, in <strong>call</strong> return self.model.run(None, inputs) File
          "onnx_openvpy39\lib\site-packages\onnxruntime\capi\onnxruntime_inference_collection.py",
          line 192, in run return self._sess.run(output_names, input_feed, run_options)
          onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError]
          : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running OpenVINO-EP-subgraph_4
          node. Name:''OpenVINOExecutionProvider_OpenVINO-EP-subgraph_4_0'' Status
          Message: C:\Users\sfatima\source\repos\onnxruntime_newmodel\onnxruntime\onnxruntime\core\providers\openvino\ov_interface.cc:36
          class std::shared_ptr __cdecl onnxruntime::openvino_ep::OVCore::ReadModel(const
          class std::basic_string&lt;char,struct std::char_traits,class std::allocator
          &gt; &amp;) const [OpenVINO-EP] [OpenVINO-EP] Exception while Reading network:
          invalid external data: ExternalDataInfo(data_full_path: weights.pb, offset:
          1738007040, data_length: 13107200, sha1_digest: 0)"</p>

          <p>System information:<br>Windows 11<br>pip install onnxruntime-openvino=1.11.0<br>pip
          install openvino==2022.1<br>Python version: 3.9<br>onnx model from stable-diffusion
          : <a href="https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/onnx">https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/onnx</a></p>

          <p>To reproduce:<br><code><br>"""<br>from diffusers import OnnxStableDiffusionPipeline<br>import
          onnxruntime as rt<br>import openvino.utils as utils</code></p><code>

          <p>pipe = OnnxStableDiffusionPipeline.from_pretrained(<br>"CompVis/stable-diffusion-v1-4",<br>revision="onnx",<br>provider="OpenVINOExecutionProvider",<br>provider_options=[{''device_type''
          : device}]<br>)<br>prompt = "a photo of an astronaut riding a horse on mars"<br>#Running
          the session by passing in the input data of the model<br>image = pipe(prompt).images[0]<br>"""</p>

          </code>'
        raw: "Hi using the stable diffusion v1.4 onnx model, I was trying to get inference\
          \ on OPENVINO Execution provider. \r\nUsing installation of required packages\
          \ related to openvino in a python environment, \r\nModified onnx_utils.py\
          \ from diffusers library to give support of openvino execution provider.\r\
          \n\r\nWhile running the inference, facing an issue related to model loading\
          \ using Core of openvino. Facing following error\r\n\"image = pipe(prompt).images[0]\
          \ File \"onnx_openvpy39\\lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\\
          pipeline_onnx_stable_diffusion.py\", line 274, in __call__ noise_pred =\
          \ self.unet(sample=latent_model_input, timestep=timestep, encoder_hidden_states=text_embeddings)\
          \ File \"onnx_openvpy39\\lib\\site-packages\\diffusers\\onnx_utils.py\"\
          , line 62, in __call__ return self.model.run(None, inputs) File \"onnx_openvpy39\\\
          lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\"\
          , line 192, in run return self._sess.run(output_names, input_feed, run_options)\
          \ onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError]\
          \ : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running\
          \ OpenVINO-EP-subgraph_4 node. Name:'OpenVINOExecutionProvider_OpenVINO-EP-subgraph_4_0'\
          \ Status Message: C:\\Users\\sfatima\\source\\repos\\onnxruntime_newmodel\\\
          onnxruntime\\onnxruntime\\core\\providers\\openvino\\ov_interface.cc:36\
          \ class std::shared_ptr<class ov::Model> __cdecl onnxruntime::openvino_ep::OVCore::ReadModel(const\
          \ class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char>\
          \ > &) const [OpenVINO-EP] [OpenVINO-EP] Exception while Reading network:\
          \ invalid external data: ExternalDataInfo(data_full_path: weights.pb, offset:\
          \ 1738007040, data_length: 13107200, sha1_digest: 0)\"\r\n\r\nSystem information:\r\
          \nWindows 11\r\npip install onnxruntime-openvino=1.11.0\r\npip install openvino==2022.1\r\
          \nPython version: 3.9\r\nonnx model from stable-diffusion : https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/onnx\r\
          \n\r\nTo reproduce:\r\n<code snippet>\r\n\"\"\"\r\nfrom diffusers import\
          \ OnnxStableDiffusionPipeline\r\nimport onnxruntime as rt\r\nimport openvino.utils\
          \ as utils\r\n\r\npipe = OnnxStableDiffusionPipeline.from_pretrained(\r\n\
          \"CompVis/stable-diffusion-v1-4\",\r\nrevision=\"onnx\",\r\nprovider=\"\
          OpenVINOExecutionProvider\",\r\nprovider_options=[{'device_type' : device}]\r\
          \n)\r\nprompt = \"a photo of an astronaut riding a horse on mars\"\r\n#Running\
          \ the session by passing in the input data of the model\r\nimage = pipe(prompt).images[0]\r\
          \n\"\"\""
        updatedAt: '2022-12-14T13:35:42.968Z'
      numEdits: 0
      reactions: []
    id: 6399d12e91474dc8955e8166
    type: comment
  author: sk2893
  content: "Hi using the stable diffusion v1.4 onnx model, I was trying to get inference\
    \ on OPENVINO Execution provider. \r\nUsing installation of required packages\
    \ related to openvino in a python environment, \r\nModified onnx_utils.py from\
    \ diffusers library to give support of openvino execution provider.\r\n\r\nWhile\
    \ running the inference, facing an issue related to model loading using Core of\
    \ openvino. Facing following error\r\n\"image = pipe(prompt).images[0] File \"\
    onnx_openvpy39\\lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_onnx_stable_diffusion.py\"\
    , line 274, in __call__ noise_pred = self.unet(sample=latent_model_input, timestep=timestep,\
    \ encoder_hidden_states=text_embeddings) File \"onnx_openvpy39\\lib\\site-packages\\\
    diffusers\\onnx_utils.py\", line 62, in __call__ return self.model.run(None, inputs)\
    \ File \"onnx_openvpy39\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\"\
    , line 192, in run return self._sess.run(output_names, input_feed, run_options)\
    \ onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError]\
    \ : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running OpenVINO-EP-subgraph_4\
    \ node. Name:'OpenVINOExecutionProvider_OpenVINO-EP-subgraph_4_0' Status Message:\
    \ C:\\Users\\sfatima\\source\\repos\\onnxruntime_newmodel\\onnxruntime\\onnxruntime\\\
    core\\providers\\openvino\\ov_interface.cc:36 class std::shared_ptr<class ov::Model>\
    \ __cdecl onnxruntime::openvino_ep::OVCore::ReadModel(const class std::basic_string<char,struct\
    \ std::char_traits<char>,class std::allocator<char> > &) const [OpenVINO-EP] [OpenVINO-EP]\
    \ Exception while Reading network: invalid external data: ExternalDataInfo(data_full_path:\
    \ weights.pb, offset: 1738007040, data_length: 13107200, sha1_digest: 0)\"\r\n\
    \r\nSystem information:\r\nWindows 11\r\npip install onnxruntime-openvino=1.11.0\r\
    \npip install openvino==2022.1\r\nPython version: 3.9\r\nonnx model from stable-diffusion\
    \ : https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/onnx\r\n\r\nTo reproduce:\r\
    \n<code snippet>\r\n\"\"\"\r\nfrom diffusers import OnnxStableDiffusionPipeline\r\
    \nimport onnxruntime as rt\r\nimport openvino.utils as utils\r\n\r\npipe = OnnxStableDiffusionPipeline.from_pretrained(\r\
    \n\"CompVis/stable-diffusion-v1-4\",\r\nrevision=\"onnx\",\r\nprovider=\"OpenVINOExecutionProvider\"\
    ,\r\nprovider_options=[{'device_type' : device}]\r\n)\r\nprompt = \"a photo of\
    \ an astronaut riding a horse on mars\"\r\n#Running the session by passing in\
    \ the input data of the model\r\nimage = pipe(prompt).images[0]\r\n\"\"\""
  created_at: 2022-12-14 13:35:42+00:00
  edited: false
  hidden: false
  id: 6399d12e91474dc8955e8166
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0a5ee2ea5ac77e785a20be5e5a18202e.svg
      fullname: saikrishna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sk2893
      type: user
    createdAt: '2022-12-14T13:37:04.000Z'
    data:
      edited: true
      editors:
      - sk2893
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0a5ee2ea5ac77e785a20be5e5a18202e.svg
          fullname: saikrishna
          isHf: false
          isPro: false
          name: sk2893
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;pcuenq&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/pcuenq\">@<span class=\"\
          underline\">pcuenq</span></a></span>\n\n\t</span></span>, <span data-props=\"\
          {&quot;user&quot;:&quot;bes-dev&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/bes-dev\">@<span class=\"underline\">bes-dev</span></a></span>\n\
          \n\t</span></span>  can you share your thoughts. And also <span data-props=\"\
          {&quot;user&quot;:&quot;bes-dev&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/bes-dev\">@<span class=\"underline\">bes-dev</span></a></span>\n\
          \n\t</span></span> can you share steps followed to create stable-diffusion-v1.4.ckpt\
          \ to onnx models with respect to vae_encoder, vae_decoder, unet.</p>\n"
        raw: '@pcuenq, @bes-dev  can you share your thoughts. And also @bes-dev can
          you share steps followed to create stable-diffusion-v1.4.ckpt to onnx models
          with respect to vae_encoder, vae_decoder, unet.'
        updatedAt: '2022-12-14T13:40:33.135Z'
      numEdits: 1
      reactions: []
    id: 6399d18091474dc8955e8b27
    type: comment
  author: sk2893
  content: '@pcuenq, @bes-dev  can you share your thoughts. And also @bes-dev can
    you share steps followed to create stable-diffusion-v1.4.ckpt to onnx models with
    respect to vae_encoder, vae_decoder, unet.'
  created_at: 2022-12-14 13:37:04+00:00
  edited: true
  hidden: false
  id: 6399d18091474dc8955e8b27
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 170
repo_id: CompVis/stable-diffusion-v1-4
repo_type: model
status: open
target_branch: null
title: Onnxruntime inferencing using openvino execution provider based on stable diffusion
  onnx model
