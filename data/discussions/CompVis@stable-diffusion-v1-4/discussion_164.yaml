!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BABIFIT
conflicting_files: null
created_at: 2022-12-11 01:12:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c5ac7d22f9b1feee090c85b70a245c01.svg
      fullname: JS
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BABIFIT
      type: user
    createdAt: '2022-12-11T01:12:10.000Z'
    data:
      edited: false
      editors:
      - BABIFIT
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c5ac7d22f9b1feee090c85b70a245c01.svg
          fullname: JS
          isHf: false
          isPro: false
          name: BABIFIT
          type: user
        html: '<p>I''m getting this error:<br>Traceback (most recent call last):<br>  File
          "D:\PGRM\DecSD\diffusers\examples\inference\save_onnx.py", line 66, in <br>    convert_to_onnx(pipe.unet,
          pipe.vae.post_quant_conv, pipe.vae.decoder, text_encoder, height=512, width=512)<br>  File
          "D:\PGRM\DecSD\diffusers\examples\inference\save_onnx.py", line 41, in convert_to_onnx<br>    traced_model
          = torch.jit.trace(unet, check_inputs[0], check_inputs=[check_inputs[1]],
          strict=True)<br>  File "C:\Users\MYNAME\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\jit_trace.py",
          line 759, in trace<br>    return trace_module(<br>  File "C:\Users\MYNAME\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\jit_trace.py",
          line 976, in trace_module<br>    module._c._create_method_from_trace(<br>RuntimeError:
          Encountering a dict at the output of the tracer might cause the trace to
          be incorrect, this is only valid if the container structure does not change
          based on the module''s inputs. Consider using a constant container instead
          (e.g. for <code>list</code>, use a <code>tuple</code> instead. for <code>dict</code>,
          use a <code>NamedTuple</code> instead). If you absolutely need this and
          know the side effects, pass strict=False to trace() to allow this behavior.</p>

          <p>I have no idea how to solve it, and changing strict=True to False gave
          me a completely different error</p>

          '
        raw: "I'm getting this error:\r\nTraceback (most recent call last):\r\n  File\
          \ \"D:\\PGRM\\DecSD\\diffusers\\examples\\inference\\save_onnx.py\", line\
          \ 66, in <module>\r\n    convert_to_onnx(pipe.unet, pipe.vae.post_quant_conv,\
          \ pipe.vae.decoder, text_encoder, height=512, width=512)\r\n  File \"D:\\\
          PGRM\\DecSD\\diffusers\\examples\\inference\\save_onnx.py\", line 41, in\
          \ convert_to_onnx\r\n    traced_model = torch.jit.trace(unet, check_inputs[0],\
          \ check_inputs=[check_inputs[1]], strict=True)\r\n  File \"C:\\Users\\MYNAME\\\
          AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\\
          jit\\_trace.py\", line 759, in trace\r\n    return trace_module(\r\n  File\
          \ \"C:\\Users\\MYNAME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\\
          site-packages\\torch\\jit\\_trace.py\", line 976, in trace_module\r\n  \
          \  module._c._create_method_from_trace(\r\nRuntimeError: Encountering a\
          \ dict at the output of the tracer might cause the trace to be incorrect,\
          \ this is only valid if the container structure does not change based on\
          \ the module's inputs. Consider using a constant container instead (e.g.\
          \ for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead).\
          \ If you absolutely need this and know the side effects, pass strict=False\
          \ to trace() to allow this behavior.\r\n\r\nI have no idea how to solve\
          \ it, and changing strict=True to False gave me a completely different error"
        updatedAt: '2022-12-11T01:12:10.674Z'
      numEdits: 0
      reactions:
      - count: 13
        reaction: "\U0001F44D"
        users:
        - GaborToth2
        - kolinni
        - GabMes
        - Aerodymeus
        - tomocska
        - mikeallenfpv
        - vlastimirs
        - bombthezoms
        - PyrateGFX
        - Mercen505
        - Pixeljunk
        - Petr007
        - Milor123
      - count: 1
        reaction: "\U0001F614"
        users:
        - Petr007
    id: 63952e6a813195ccb1368053
    type: comment
  author: BABIFIT
  content: "I'm getting this error:\r\nTraceback (most recent call last):\r\n  File\
    \ \"D:\\PGRM\\DecSD\\diffusers\\examples\\inference\\save_onnx.py\", line 66,\
    \ in <module>\r\n    convert_to_onnx(pipe.unet, pipe.vae.post_quant_conv, pipe.vae.decoder,\
    \ text_encoder, height=512, width=512)\r\n  File \"D:\\PGRM\\DecSD\\diffusers\\\
    examples\\inference\\save_onnx.py\", line 41, in convert_to_onnx\r\n    traced_model\
    \ = torch.jit.trace(unet, check_inputs[0], check_inputs=[check_inputs[1]], strict=True)\r\
    \n  File \"C:\\Users\\MYNAME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\\
    site-packages\\torch\\jit\\_trace.py\", line 759, in trace\r\n    return trace_module(\r\
    \n  File \"C:\\Users\\MYNAME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\\
    site-packages\\torch\\jit\\_trace.py\", line 976, in trace_module\r\n    module._c._create_method_from_trace(\r\
    \nRuntimeError: Encountering a dict at the output of the tracer might cause the\
    \ trace to be incorrect, this is only valid if the container structure does not\
    \ change based on the module's inputs. Consider using a constant container instead\
    \ (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead).\
    \ If you absolutely need this and know the side effects, pass strict=False to\
    \ trace() to allow this behavior.\r\n\r\nI have no idea how to solve it, and changing\
    \ strict=True to False gave me a completely different error"
  created_at: 2022-12-11 01:12:10+00:00
  edited: false
  hidden: false
  id: 63952e6a813195ccb1368053
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/42b271d3b5a0508e4d6ee0449eb50ab7.svg
      fullname: ET
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomocska
      type: user
    createdAt: '2022-12-12T22:48:38.000Z'
    data:
      edited: false
      editors:
      - tomocska
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/42b271d3b5a0508e4d6ee0449eb50ab7.svg
          fullname: ET
          isHf: false
          isPro: false
          name: tomocska
          type: user
        html: '<p>Same here</p>

          '
        raw: Same here
        updatedAt: '2022-12-12T22:48:38.307Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F614"
        users:
        - Petr007
    id: 6397afc64729741afab81e7f
    type: comment
  author: tomocska
  content: Same here
  created_at: 2022-12-12 22:48:38+00:00
  edited: false
  hidden: false
  id: 6397afc64729741afab81e7f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/53bf952df2c0525d1277ad4d86b1edd6.svg
      fullname: x x
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GabMes
      type: user
    createdAt: '2022-12-18T03:18:07.000Z'
    data:
      edited: false
      editors:
      - GabMes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/53bf952df2c0525d1277ad4d86b1edd6.svg
          fullname: x x
          isHf: false
          isPro: false
          name: GabMes
          type: user
        html: '<p>Same here</p>

          '
        raw: Same here
        updatedAt: '2022-12-18T03:18:07.088Z'
      numEdits: 0
      reactions: []
    id: 639e866f7145123e0d5a5665
    type: comment
  author: GabMes
  content: Same here
  created_at: 2022-12-18 03:18:07+00:00
  edited: false
  hidden: false
  id: 639e866f7145123e0d5a5665
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b66a3eaae2d3041558ce340228a5981e.svg
      fullname: Michael Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mikeallenfpv
      type: user
    createdAt: '2022-12-19T03:26:47.000Z'
    data:
      edited: false
      editors:
      - mikeallenfpv
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b66a3eaae2d3041558ce340228a5981e.svg
          fullname: Michael Smith
          isHf: false
          isPro: false
          name: mikeallenfpv
          type: user
        html: '<p>Another one here</p>

          '
        raw: Another one here
        updatedAt: '2022-12-19T03:26:47.002Z'
      numEdits: 0
      reactions: []
    id: 639fd9f72e13e54dcbc6b8fb
    type: comment
  author: mikeallenfpv
  content: Another one here
  created_at: 2022-12-19 03:26:47+00:00
  edited: false
  hidden: false
  id: 639fd9f72e13e54dcbc6b8fb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/063b43aca31212ed9ee5b380e01f8821.svg
      fullname: MixaelMitre
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MixaelMitre
      type: user
    createdAt: '2022-12-19T14:33:21.000Z'
    data:
      edited: false
      editors:
      - MixaelMitre
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/063b43aca31212ed9ee5b380e01f8821.svg
          fullname: MixaelMitre
          isHf: false
          isPro: false
          name: MixaelMitre
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2022-12-19T14:33:21.732Z'
      numEdits: 0
      reactions: []
    id: 63a0763145edac9f75f6edcb
    type: comment
  author: MixaelMitre
  content: '+1'
  created_at: 2022-12-19 14:33:21+00:00
  edited: false
  hidden: false
  id: 63a0763145edac9f75f6edcb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2a09d2ac0669ba8bcbc90b0c017f47b3.svg
      fullname: Toby Gagan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: minne2
      type: user
    createdAt: '2022-12-22T06:25:27.000Z'
    data:
      edited: false
      editors:
      - minne2
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2a09d2ac0669ba8bcbc90b0c017f47b3.svg
          fullname: Toby Gagan
          isHf: false
          isPro: false
          name: minne2
          type: user
        html: '<p>What exact card are you using OP?</p>

          '
        raw: What exact card are you using OP?
        updatedAt: '2022-12-22T06:25:27.830Z'
      numEdits: 0
      reactions: []
    id: 63a3f857d1956595f799ad83
    type: comment
  author: minne2
  content: What exact card are you using OP?
  created_at: 2022-12-22 06:25:27+00:00
  edited: false
  hidden: false
  id: 63a3f857d1956595f799ad83
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c5ac7d22f9b1feee090c85b70a245c01.svg
      fullname: JS
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BABIFIT
      type: user
    createdAt: '2022-12-22T06:29:16.000Z'
    data:
      edited: false
      editors:
      - BABIFIT
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c5ac7d22f9b1feee090c85b70a245c01.svg
          fullname: JS
          isHf: false
          isPro: false
          name: BABIFIT
          type: user
        html: '<blockquote>

          <p>What exact card are you using OP?</p>

          </blockquote>

          <p>6750xt on windows 11 paired with r5 3600 and 32gb ram</p>

          '
        raw: '> What exact card are you using OP?


          6750xt on windows 11 paired with r5 3600 and 32gb ram'
        updatedAt: '2022-12-22T06:29:16.128Z'
      numEdits: 0
      reactions: []
    id: 63a3f93cf91ad3ea5702c27f
    type: comment
  author: BABIFIT
  content: '> What exact card are you using OP?


    6750xt on windows 11 paired with r5 3600 and 32gb ram'
  created_at: 2022-12-22 06:29:16+00:00
  edited: false
  hidden: false
  id: 63a3f93cf91ad3ea5702c27f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7baf6b15b3151f232efbad50da424d95.svg
      fullname: Vlastimir Stankovic
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vlastimirs
      type: user
    createdAt: '2022-12-23T20:25:18.000Z'
    data:
      edited: false
      editors:
      - vlastimirs
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7baf6b15b3151f232efbad50da424d95.svg
          fullname: Vlastimir Stankovic
          isHf: false
          isPro: false
          name: vlastimirs
          type: user
        html: '<p>And another one here :)</p>

          '
        raw: And another one here :)
        updatedAt: '2022-12-23T20:25:18.697Z'
      numEdits: 0
      reactions: []
    id: 63a60eaee7b46b843bec923f
    type: comment
  author: vlastimirs
  content: And another one here :)
  created_at: 2022-12-23 20:25:18+00:00
  edited: false
  hidden: false
  id: 63a60eaee7b46b843bec923f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7baf6b15b3151f232efbad50da424d95.svg
      fullname: Vlastimir Stankovic
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vlastimirs
      type: user
    createdAt: '2022-12-23T20:25:37.000Z'
    data:
      edited: false
      editors:
      - vlastimirs
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7baf6b15b3151f232efbad50da424d95.svg
          fullname: Vlastimir Stankovic
          isHf: false
          isPro: false
          name: vlastimirs
          type: user
        html: '<p>RX 6700 XT here</p>

          '
        raw: RX 6700 XT here
        updatedAt: '2022-12-23T20:25:37.464Z'
      numEdits: 0
      reactions: []
    id: 63a60ec168b3757ecace1e10
    type: comment
  author: vlastimirs
  content: RX 6700 XT here
  created_at: 2022-12-23 20:25:37+00:00
  edited: false
  hidden: false
  id: 63a60ec168b3757ecace1e10
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/62816b4123724fa233262d0263c786d9.svg
      fullname: Scott
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: designlook
      type: user
    createdAt: '2022-12-27T02:15:44.000Z'
    data:
      edited: true
      editors:
      - designlook
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/62816b4123724fa233262d0263c786d9.svg
          fullname: Scott
          isHf: false
          isPro: false
          name: designlook
          type: user
        html: '<p>Same here for AMD Radeon RX 6800S on Windows 11 with AMD Ryzen 9</p>

          '
        raw: Same here for AMD Radeon RX 6800S on Windows 11 with AMD Ryzen 9
        updatedAt: '2022-12-27T02:17:16.257Z'
      numEdits: 1
      reactions: []
    id: 63aa55508949ceef24a004a1
    type: comment
  author: designlook
  content: Same here for AMD Radeon RX 6800S on Windows 11 with AMD Ryzen 9
  created_at: 2022-12-27 02:15:44+00:00
  edited: true
  hidden: false
  id: 63aa55508949ceef24a004a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0741110ffb6b963c63ca082bbbb265c6.svg
      fullname: Lee Bennett
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: PyrateGFX
      type: user
    createdAt: '2022-12-30T07:08:23.000Z'
    data:
      edited: true
      editors:
      - PyrateGFX
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0741110ffb6b963c63ca082bbbb265c6.svg
          fullname: Lee Bennett
          isHf: false
          isPro: false
          name: PyrateGFX
          type: user
        html: '<p>Yeah yeah Me Too!!! What is the fix for this!</p>

          <p>Traceback (most recent call last):<br>  File "E:\AI\diffusers-dml\examples\inference\save_onnx.py",
          line 16, in <br>    pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4",
          scheduler=lms, use_auth_token=True)<br>  File "E:\AI\diffusers-dml\src\diffusers\pipeline_utils.py",
          line 240, in from_pretrained<br>    load_method = getattr(class_obj, load_method_name)<br>TypeError:
          getattr(): attribute name must be string</p>

          '
        raw: "Yeah yeah Me Too!!! What is the fix for this!\n\nTraceback (most recent\
          \ call last):\n  File \"E:\\AI\\diffusers-dml\\examples\\inference\\save_onnx.py\"\
          , line 16, in <module>\n    pipe = StableDiffusionPipeline.from_pretrained(\"\
          CompVis/stable-diffusion-v1-4\", scheduler=lms, use_auth_token=True)\n \
          \ File \"E:\\AI\\diffusers-dml\\src\\diffusers\\pipeline_utils.py\", line\
          \ 240, in from_pretrained\n    load_method = getattr(class_obj, load_method_name)\n\
          TypeError: getattr(): attribute name must be string"
        updatedAt: '2022-12-30T23:11:21.376Z'
      numEdits: 1
      reactions: []
    id: 63ae8e67126883557b69fe58
    type: comment
  author: PyrateGFX
  content: "Yeah yeah Me Too!!! What is the fix for this!\n\nTraceback (most recent\
    \ call last):\n  File \"E:\\AI\\diffusers-dml\\examples\\inference\\save_onnx.py\"\
    , line 16, in <module>\n    pipe = StableDiffusionPipeline.from_pretrained(\"\
    CompVis/stable-diffusion-v1-4\", scheduler=lms, use_auth_token=True)\n  File \"\
    E:\\AI\\diffusers-dml\\src\\diffusers\\pipeline_utils.py\", line 240, in from_pretrained\n\
    \    load_method = getattr(class_obj, load_method_name)\nTypeError: getattr():\
    \ attribute name must be string"
  created_at: 2022-12-30 07:08:23+00:00
  edited: true
  hidden: false
  id: 63ae8e67126883557b69fe58
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8d636032e3978890a629aefd0d701d74.svg
      fullname: Kristian Cesarini
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bluerider
      type: user
    createdAt: '2023-01-01T21:43:16.000Z'
    data:
      edited: true
      editors:
      - Bluerider
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8d636032e3978890a629aefd0d701d74.svg
          fullname: Kristian Cesarini
          isHf: false
          isPro: false
          name: Bluerider
          type: user
        html: '<p>Same here with a RX 580</p>

          <p>C:\Users**\AppData\Local\Programs\Python\Python310\lib\site-packages\diffusers\models\resnet.py:122:
          TracerWarning: Converting a tensor to a Python boolean might cause the trace
          to be incorrect. We can''t record the data flow of Python values, so this
          value will be treated as a constant in the future. This means that the trace
          might not generalize to other inputs!<br>  if hidden_states.shape[0] &gt;=
          64:<br>Traceback (most recent call last):<br>  File "C:\r\diffusers\examples\inference\save_onnx.py",
          line 66, in <br>    convert_to_onnx(pipe.unet, pipe.vae.post_quant_conv,
          pipe.vae.decoder, text_encoder, height=512, width=512)<br>  File "C:\r\diffusers\examples\inference\save_onnx.py",
          line 41, in convert_to_onnx<br>    traced_model = torch.jit.trace(unet,
          check_inputs[0], check_inputs=[check_inputs[1]], strict=True)<br>  File
          "C:\Users**\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\jit_trace.py",
          line 759, in trace<br>    return trace_module(<br>  File "C:\Users**\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\jit_trace.py",
          line 976, in trace_module<br>    module._c._create_method_from_trace(<br>RuntimeError:
          Encountering a dict at the output of the tracer might cause the trace to
          be incorrect, this is only valid if the container structure does not change
          based on the module''s inputs. Consider using a constant container instead
          (e.g. for <code>list</code>, use a <code>tuple</code> instead. for <code>dict</code>,
          use a <code>NamedTuple</code> instead). If you absolutely need this and
          know the side effects, pass strict=False to trace() to allow this behavior.</p>

          '
        raw: "Same here with a RX 580\n\nC:\\Users\\**\\AppData\\Local\\Programs\\\
          Python\\Python310\\lib\\site-packages\\diffusers\\models\\resnet.py:122:\
          \ TracerWarning: Converting a tensor to a Python boolean might cause the\
          \ trace to be incorrect. We can't record the data flow of Python values,\
          \ so this value will be treated as a constant in the future. This means\
          \ that the trace might not generalize to other inputs!\n  if hidden_states.shape[0]\
          \ >= 64:\nTraceback (most recent call last):\n  File \"C:\\r\\diffusers\\\
          examples\\inference\\save_onnx.py\", line 66, in <module>\n    convert_to_onnx(pipe.unet,\
          \ pipe.vae.post_quant_conv, pipe.vae.decoder, text_encoder, height=512,\
          \ width=512)\n  File \"C:\\r\\diffusers\\examples\\inference\\save_onnx.py\"\
          , line 41, in convert_to_onnx\n    traced_model = torch.jit.trace(unet,\
          \ check_inputs[0], check_inputs=[check_inputs[1]], strict=True)\n  File\
          \ \"C:\\Users\\**\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\\
          torch\\jit\\_trace.py\", line 759, in trace\n    return trace_module(\n\
          \  File \"C:\\Users\\**\\AppData\\Local\\Programs\\Python\\Python310\\lib\\\
          site-packages\\torch\\jit\\_trace.py\", line 976, in trace_module\n    module._c._create_method_from_trace(\n\
          RuntimeError: Encountering a dict at the output of the tracer might cause\
          \ the trace to be incorrect, this is only valid if the container structure\
          \ does not change based on the module's inputs. Consider using a constant\
          \ container instead (e.g. for `list`, use a `tuple` instead. for `dict`,\
          \ use a `NamedTuple` instead). If you absolutely need this and know the\
          \ side effects, pass strict=False to trace() to allow this behavior."
        updatedAt: '2023-01-01T21:50:19.940Z'
      numEdits: 2
      reactions: []
    id: 63b1fe74f9ddaf1a16b44257
    type: comment
  author: Bluerider
  content: "Same here with a RX 580\n\nC:\\Users\\**\\AppData\\Local\\Programs\\Python\\\
    Python310\\lib\\site-packages\\diffusers\\models\\resnet.py:122: TracerWarning:\
    \ Converting a tensor to a Python boolean might cause the trace to be incorrect.\
    \ We can't record the data flow of Python values, so this value will be treated\
    \ as a constant in the future. This means that the trace might not generalize\
    \ to other inputs!\n  if hidden_states.shape[0] >= 64:\nTraceback (most recent\
    \ call last):\n  File \"C:\\r\\diffusers\\examples\\inference\\save_onnx.py\"\
    , line 66, in <module>\n    convert_to_onnx(pipe.unet, pipe.vae.post_quant_conv,\
    \ pipe.vae.decoder, text_encoder, height=512, width=512)\n  File \"C:\\r\\diffusers\\\
    examples\\inference\\save_onnx.py\", line 41, in convert_to_onnx\n    traced_model\
    \ = torch.jit.trace(unet, check_inputs[0], check_inputs=[check_inputs[1]], strict=True)\n\
    \  File \"C:\\Users\\**\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\\
    torch\\jit\\_trace.py\", line 759, in trace\n    return trace_module(\n  File\
    \ \"C:\\Users\\**\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\\
    torch\\jit\\_trace.py\", line 976, in trace_module\n    module._c._create_method_from_trace(\n\
    RuntimeError: Encountering a dict at the output of the tracer might cause the\
    \ trace to be incorrect, this is only valid if the container structure does not\
    \ change based on the module's inputs. Consider using a constant container instead\
    \ (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead).\
    \ If you absolutely need this and know the side effects, pass strict=False to\
    \ trace() to allow this behavior."
  created_at: 2023-01-01 21:43:16+00:00
  edited: true
  hidden: false
  id: 63b1fe74f9ddaf1a16b44257
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e20ca53173809cf9114ad696fdf15381.svg
      fullname: Anvar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: a6out
      type: user
    createdAt: '2023-01-02T00:08:05.000Z'
    data:
      edited: false
      editors:
      - a6out
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e20ca53173809cf9114ad696fdf15381.svg
          fullname: Anvar
          isHf: false
          isPro: false
          name: a6out
          type: user
        html: '<p>OH CMON!) rx 6700xt</p>

          <p>C:\Users*******\AppData\Local\Programs\Python\Python310\lib\site-packages\diffusers\models\resnet.py:122:
          TracerWarning: Converting a tensor to a Python boolean might cause the trace
          to be incorrect. We can''t record the data flow of Python values, so this
          value will be treated as a constant in the future. This means that the trace
          might not generalize to other inputs!<br>  if hidden_states.shape[0] &gt;=
          64:<br>Traceback (most recent call last):<br>  File "C:\Windows\System32\diffusers\examples\inference\save_onnx.py",
          line 66, in <br>    convert_to_onnx(pipe.unet, pipe.vae.post_quant_conv,
          pipe.vae.decoder, text_encoder, height=512, width=512)<br>  File "C:\Windows\System32\diffusers\examples\inference\save_onnx.py",
          line 41, in convert_to_onnx<br>    traced_model = torch.jit.trace(unet,
          check_inputs[0], check_inputs=[check_inputs[1]], strict=True)<br>  File
          "C:\Users\a6out\AppData\Roaming\Python\Python310\site-packages\torch\jit_trace.py",
          line 759, in trace<br>    return trace_module(<br>  File "C:\Users\a6out\AppData\Roaming\Python\Python310\site-packages\torch\jit_trace.py",
          line 976, in trace_module<br>    module._c._create_method_from_trace(<br>RuntimeError:
          Encountering a dict at the output of the tracer might cause the trace to
          be incorrect, this is only valid if the container structure does not change
          based on the module''s inputs. Consider using a constant container instead
          (e.g. for <code>list</code>, use a <code>tuple</code> instead. for <code>dict</code>,
          use a <code>NamedTuple</code> instead). If you absolutely need this and
          know the side effects, pass strict=False to trace() to allow this behavior.</p>

          '
        raw: "OH CMON!) rx 6700xt\n\nC:\\Users\\*******\\AppData\\Local\\Programs\\\
          Python\\Python310\\lib\\site-packages\\diffusers\\models\\resnet.py:122:\
          \ TracerWarning: Converting a tensor to a Python boolean might cause the\
          \ trace to be incorrect. We can't record the data flow of Python values,\
          \ so this value will be treated as a constant in the future. This means\
          \ that the trace might not generalize to other inputs!\n  if hidden_states.shape[0]\
          \ >= 64:\nTraceback (most recent call last):\n  File \"C:\\Windows\\System32\\\
          diffusers\\examples\\inference\\save_onnx.py\", line 66, in <module>\n \
          \   convert_to_onnx(pipe.unet, pipe.vae.post_quant_conv, pipe.vae.decoder,\
          \ text_encoder, height=512, width=512)\n  File \"C:\\Windows\\System32\\\
          diffusers\\examples\\inference\\save_onnx.py\", line 41, in convert_to_onnx\n\
          \    traced_model = torch.jit.trace(unet, check_inputs[0], check_inputs=[check_inputs[1]],\
          \ strict=True)\n  File \"C:\\Users\\a6out\\AppData\\Roaming\\Python\\Python310\\\
          site-packages\\torch\\jit\\_trace.py\", line 759, in trace\n    return trace_module(\n\
          \  File \"C:\\Users\\a6out\\AppData\\Roaming\\Python\\Python310\\site-packages\\\
          torch\\jit\\_trace.py\", line 976, in trace_module\n    module._c._create_method_from_trace(\n\
          RuntimeError: Encountering a dict at the output of the tracer might cause\
          \ the trace to be incorrect, this is only valid if the container structure\
          \ does not change based on the module's inputs. Consider using a constant\
          \ container instead (e.g. for `list`, use a `tuple` instead. for `dict`,\
          \ use a `NamedTuple` instead). If you absolutely need this and know the\
          \ side effects, pass strict=False to trace() to allow this behavior."
        updatedAt: '2023-01-02T00:08:05.026Z'
      numEdits: 0
      reactions: []
    id: 63b220651bc4bb9da21dfa28
    type: comment
  author: a6out
  content: "OH CMON!) rx 6700xt\n\nC:\\Users\\*******\\AppData\\Local\\Programs\\\
    Python\\Python310\\lib\\site-packages\\diffusers\\models\\resnet.py:122: TracerWarning:\
    \ Converting a tensor to a Python boolean might cause the trace to be incorrect.\
    \ We can't record the data flow of Python values, so this value will be treated\
    \ as a constant in the future. This means that the trace might not generalize\
    \ to other inputs!\n  if hidden_states.shape[0] >= 64:\nTraceback (most recent\
    \ call last):\n  File \"C:\\Windows\\System32\\diffusers\\examples\\inference\\\
    save_onnx.py\", line 66, in <module>\n    convert_to_onnx(pipe.unet, pipe.vae.post_quant_conv,\
    \ pipe.vae.decoder, text_encoder, height=512, width=512)\n  File \"C:\\Windows\\\
    System32\\diffusers\\examples\\inference\\save_onnx.py\", line 41, in convert_to_onnx\n\
    \    traced_model = torch.jit.trace(unet, check_inputs[0], check_inputs=[check_inputs[1]],\
    \ strict=True)\n  File \"C:\\Users\\a6out\\AppData\\Roaming\\Python\\Python310\\\
    site-packages\\torch\\jit\\_trace.py\", line 759, in trace\n    return trace_module(\n\
    \  File \"C:\\Users\\a6out\\AppData\\Roaming\\Python\\Python310\\site-packages\\\
    torch\\jit\\_trace.py\", line 976, in trace_module\n    module._c._create_method_from_trace(\n\
    RuntimeError: Encountering a dict at the output of the tracer might cause the\
    \ trace to be incorrect, this is only valid if the container structure does not\
    \ change based on the module's inputs. Consider using a constant container instead\
    \ (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead).\
    \ If you absolutely need this and know the side effects, pass strict=False to\
    \ trace() to allow this behavior."
  created_at: 2023-01-02 00:08:05+00:00
  edited: false
  hidden: false
  id: 63b220651bc4bb9da21dfa28
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7baf6b15b3151f232efbad50da424d95.svg
      fullname: Vlastimir Stankovic
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vlastimirs
      type: user
    createdAt: '2023-01-03T19:37:39.000Z'
    data:
      edited: false
      editors:
      - vlastimirs
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7baf6b15b3151f232efbad50da424d95.svg
          fullname: Vlastimir Stankovic
          isHf: false
          isPro: false
          name: vlastimirs
          type: user
        html: '<p>I had slightly more luck with this one :)</p>

          <p><a rel="nofollow" href="https://github.com/nod-ai/SHARK/blob/main/shark/examples/shark_inference/stable_diffusion/stable_diffusion_amd.md">https://github.com/nod-ai/SHARK/blob/main/shark/examples/shark_inference/stable_diffusion/stable_diffusion_amd.md</a></p>

          <p>Still in vacation, so not at my rig to go the fully Python way - but
          the exe does it''s magic, provided you install the right AMD drivers</p>

          '
        raw: 'I had slightly more luck with this one :)


          https://github.com/nod-ai/SHARK/blob/main/shark/examples/shark_inference/stable_diffusion/stable_diffusion_amd.md


          Still in vacation, so not at my rig to go the fully Python way - but the
          exe does it''s magic, provided you install the right AMD drivers'
        updatedAt: '2023-01-03T19:37:39.857Z'
      numEdits: 0
      reactions: []
    id: 63b484033e02c8e7cb74cd36
    type: comment
  author: vlastimirs
  content: 'I had slightly more luck with this one :)


    https://github.com/nod-ai/SHARK/blob/main/shark/examples/shark_inference/stable_diffusion/stable_diffusion_amd.md


    Still in vacation, so not at my rig to go the fully Python way - but the exe does
    it''s magic, provided you install the right AMD drivers'
  created_at: 2023-01-03 19:37:39+00:00
  edited: false
  hidden: false
  id: 63b484033e02c8e7cb74cd36
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0e912252d5964f87e654f21295136a10.svg
      fullname: Joe Biden
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pixeljunk
      type: user
    createdAt: '2023-01-10T14:37:39.000Z'
    data:
      edited: false
      editors:
      - Pixeljunk
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0e912252d5964f87e654f21295136a10.svg
          fullname: Joe Biden
          isHf: false
          isPro: false
          name: Pixeljunk
          type: user
        html: '<p>Same error here (RX 6800 XT)</p>

          <p>Traceback (most recent call last):<br>  File "C:\Diffusion\diffusers-dml\examples\inference\save_onnx.py",
          line 66, in <br>    convert_to_onnx(pipe.unet, pipe.vae.post_quant_conv,
          pipe.vae.decoder, text_encoder, height=512, width=512)<br>  File "C:\Diffusion\diffusers-dml\examples\inference\save_onnx.py",
          line 41, in convert_to_onnx<br>    traced_model = torch.jit.trace(unet,
          check_inputs[0], check_inputs=[check_inputs[1]], strict=True)<br>  File
          "C:\Diffusion\amd_venv\lib\site-packages\torch\jit_trace.py", line 759,
          in trace<br>    return trace_module(<br>  File "C:\Diffusion\amd_venv\lib\site-packages\torch\jit_trace.py",
          line 976, in trace_module<br>    module._c._create_method_from_trace(<br>RuntimeError:
          Encountering a dict at the output of the tracer might cause the trace to
          be incorrect, this is only valid if the container structure does not change
          based on the module''s inputs. Consider using a constant container instead
          (e.g. for <code>list</code>, use a <code>tuple</code> instead. for <code>dict</code>,
          use a <code>NamedTuple</code> instead). If you absolutely need this and
          know the side effects, pass strict=False to trace() to allow this behavior.</p>

          <p>Just joining the rest.</p>

          '
        raw: "Same error here (RX 6800 XT)\n\nTraceback (most recent call last):\n\
          \  File \"C:\\Diffusion\\diffusers-dml\\examples\\inference\\save_onnx.py\"\
          , line 66, in <module>\n    convert_to_onnx(pipe.unet, pipe.vae.post_quant_conv,\
          \ pipe.vae.decoder, text_encoder, height=512, width=512)\n  File \"C:\\\
          Diffusion\\diffusers-dml\\examples\\inference\\save_onnx.py\", line 41,\
          \ in convert_to_onnx\n    traced_model = torch.jit.trace(unet, check_inputs[0],\
          \ check_inputs=[check_inputs[1]], strict=True)\n  File \"C:\\Diffusion\\\
          amd_venv\\lib\\site-packages\\torch\\jit\\_trace.py\", line 759, in trace\n\
          \    return trace_module(\n  File \"C:\\Diffusion\\amd_venv\\lib\\site-packages\\\
          torch\\jit\\_trace.py\", line 976, in trace_module\n    module._c._create_method_from_trace(\n\
          RuntimeError: Encountering a dict at the output of the tracer might cause\
          \ the trace to be incorrect, this is only valid if the container structure\
          \ does not change based on the module's inputs. Consider using a constant\
          \ container instead (e.g. for `list`, use a `tuple` instead. for `dict`,\
          \ use a `NamedTuple` instead). If you absolutely need this and know the\
          \ side effects, pass strict=False to trace() to allow this behavior.\n\n\
          Just joining the rest."
        updatedAt: '2023-01-10T14:37:39.194Z'
      numEdits: 0
      reactions: []
    id: 63bd783376a5d68b122d51a3
    type: comment
  author: Pixeljunk
  content: "Same error here (RX 6800 XT)\n\nTraceback (most recent call last):\n \
    \ File \"C:\\Diffusion\\diffusers-dml\\examples\\inference\\save_onnx.py\", line\
    \ 66, in <module>\n    convert_to_onnx(pipe.unet, pipe.vae.post_quant_conv, pipe.vae.decoder,\
    \ text_encoder, height=512, width=512)\n  File \"C:\\Diffusion\\diffusers-dml\\\
    examples\\inference\\save_onnx.py\", line 41, in convert_to_onnx\n    traced_model\
    \ = torch.jit.trace(unet, check_inputs[0], check_inputs=[check_inputs[1]], strict=True)\n\
    \  File \"C:\\Diffusion\\amd_venv\\lib\\site-packages\\torch\\jit\\_trace.py\"\
    , line 759, in trace\n    return trace_module(\n  File \"C:\\Diffusion\\amd_venv\\\
    lib\\site-packages\\torch\\jit\\_trace.py\", line 976, in trace_module\n    module._c._create_method_from_trace(\n\
    RuntimeError: Encountering a dict at the output of the tracer might cause the\
    \ trace to be incorrect, this is only valid if the container structure does not\
    \ change based on the module's inputs. Consider using a constant container instead\
    \ (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead).\
    \ If you absolutely need this and know the side effects, pass strict=False to\
    \ trace() to allow this behavior.\n\nJust joining the rest."
  created_at: 2023-01-10 14:37:39+00:00
  edited: false
  hidden: false
  id: 63bd783376a5d68b122d51a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a178c312e12afc301903f372b83cac8.svg
      fullname: Mister Entity
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 656E746974790A
      type: user
    createdAt: '2023-01-27T17:45:31.000Z'
    data:
      edited: false
      editors:
      - 656E746974790A
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7a178c312e12afc301903f372b83cac8.svg
          fullname: Mister Entity
          isHf: false
          isPro: false
          name: 656E746974790A
          type: user
        html: '<blockquote>

          <p>Same here with a RX 580</p>

          </blockquote>

          <p>At my wits end! Also same here with Windows 10 and an RX 580. </p>

          <p>RuntimeError: Encountering a dict at the output of the tracer might cause
          the trace to be incorrect, this is only valid if the container structure
          does not change based on the module''s inputs. Consider using a constant
          container instead (e.g. for <code>list</code>, use a <code>tuple</code>
          instead. for <code>dict</code>, use a <code>NamedTuple</code> instead).
          If you absolutely need this and know the side effects, pass strict=False
          to trace() to allow this behavior.</p>

          '
        raw: "> Same here with a RX 580\n\n\nAt my wits end! Also same here with Windows\
          \ 10 and an RX 580. \n\nRuntimeError: Encountering a dict at the output\
          \ of the tracer might cause the trace to be incorrect, this is only valid\
          \ if the container structure does not change based on the module's inputs.\
          \ Consider using a constant container instead (e.g. for `list`, use a `tuple`\
          \ instead. for `dict`, use a `NamedTuple` instead). If you absolutely need\
          \ this and know the side effects, pass strict=False to trace() to allow\
          \ this behavior."
        updatedAt: '2023-01-27T17:45:31.435Z'
      numEdits: 0
      reactions: []
    id: 63d40dbb108305eda75ebc4b
    type: comment
  author: 656E746974790A
  content: "> Same here with a RX 580\n\n\nAt my wits end! Also same here with Windows\
    \ 10 and an RX 580. \n\nRuntimeError: Encountering a dict at the output of the\
    \ tracer might cause the trace to be incorrect, this is only valid if the container\
    \ structure does not change based on the module's inputs. Consider using a constant\
    \ container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a\
    \ `NamedTuple` instead). If you absolutely need this and know the side effects,\
    \ pass strict=False to trace() to allow this behavior."
  created_at: 2023-01-27 17:45:31+00:00
  edited: false
  hidden: false
  id: 63d40dbb108305eda75ebc4b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/718f811b1c2245891aa9a63e2fd7de0a.svg
      fullname: Mateo B
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Milor123
      type: user
    createdAt: '2023-02-10T15:41:48.000Z'
    data:
      edited: false
      editors:
      - Milor123
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/718f811b1c2245891aa9a63e2fd7de0a.svg
          fullname: Mateo B
          isHf: false
          isPro: false
          name: Milor123
          type: user
        html: '<p>Have the same problen with RX 6750 xt</p>

          '
        raw: Have the same problen with RX 6750 xt
        updatedAt: '2023-02-10T15:41:48.410Z'
      numEdits: 0
      reactions: []
    id: 63e665bc70fa0ed02a5551d8
    type: comment
  author: Milor123
  content: Have the same problen with RX 6750 xt
  created_at: 2023-02-10 15:41:48+00:00
  edited: false
  hidden: false
  id: 63e665bc70fa0ed02a5551d8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4cf05caec6a5ae4774177f49b5273b85.svg
      fullname: Ronnie D
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ronniediaz
      type: user
    createdAt: '2023-03-10T06:46:37.000Z'
    data:
      edited: true
      editors:
      - ronniediaz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4cf05caec6a5ae4774177f49b5273b85.svg
          fullname: Ronnie D
          isHf: false
          isPro: false
          name: ronniediaz
          type: user
        html: '<p>I had this same issue on RX 6800 XT and came across this guide from
          git user ''averad'' using SD 1.5 and worked successfully.<br><a rel="nofollow"
          href="https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674">https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674</a></p>

          <p>Note: I set protobuf version to 3.20.2 instead of 3.20.1 due to this
          error:<br>onnx 1.13.1 requires protobuf&lt;4,&gt;=3.20.2</p>

          '
        raw: 'I had this same issue on RX 6800 XT and came across this guide from
          git user ''averad'' using SD 1.5 and worked successfully.

          https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674


          Note: I set protobuf version to 3.20.2 instead of 3.20.1 due to this error:

          onnx 1.13.1 requires protobuf<4,>=3.20.2'
        updatedAt: '2023-03-10T06:50:15.053Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - BABIFIT
      - count: 1
        reaction: "\U0001F917"
        users:
        - BABIFIT
    id: 640ad24d7680fce13b8f57f9
    type: comment
  author: ronniediaz
  content: 'I had this same issue on RX 6800 XT and came across this guide from git
    user ''averad'' using SD 1.5 and worked successfully.

    https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674


    Note: I set protobuf version to 3.20.2 instead of 3.20.1 due to this error:

    onnx 1.13.1 requires protobuf<4,>=3.20.2'
  created_at: 2023-03-10 06:46:37+00:00
  edited: true
  hidden: false
  id: 640ad24d7680fce13b8f57f9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c5ac7d22f9b1feee090c85b70a245c01.svg
      fullname: JS
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BABIFIT
      type: user
    createdAt: '2023-03-22T14:39:55.000Z'
    data:
      edited: false
      editors:
      - BABIFIT
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c5ac7d22f9b1feee090c85b70a245c01.svg
          fullname: JS
          isHf: false
          isPro: false
          name: BABIFIT
          type: user
        html: '<p>Greetings everyone! Following ronniediaz''s instructions worked
          for me. Thank you so much, sir/ma''am!<br>(Copied here):<br>"I had this
          same issue on RX 6800 XT and came across this guide from git user ''averad''
          using SD 1.5 and worked successfully.<br><a rel="nofollow" href="https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674">https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674</a></p>

          <p>Note: I set protobuf version to 3.20.2 instead of 3.20.1 due to this
          error:<br>onnx 1.13.1 requires protobuf&lt;4,&gt;=3.20.2"</p>

          '
        raw: 'Greetings everyone! Following ronniediaz''s instructions worked for
          me. Thank you so much, sir/ma''am!

          (Copied here):

          "I had this same issue on RX 6800 XT and came across this guide from git
          user ''averad'' using SD 1.5 and worked successfully.

          https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674


          Note: I set protobuf version to 3.20.2 instead of 3.20.1 due to this error:

          onnx 1.13.1 requires protobuf<4,>=3.20.2"'
        updatedAt: '2023-03-22T14:39:55.162Z'
      numEdits: 0
      reactions: []
    id: 641b133b4723a2b0aa4a5b67
    type: comment
  author: BABIFIT
  content: 'Greetings everyone! Following ronniediaz''s instructions worked for me.
    Thank you so much, sir/ma''am!

    (Copied here):

    "I had this same issue on RX 6800 XT and came across this guide from git user
    ''averad'' using SD 1.5 and worked successfully.

    https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674


    Note: I set protobuf version to 3.20.2 instead of 3.20.1 due to this error:

    onnx 1.13.1 requires protobuf<4,>=3.20.2"'
  created_at: 2023-03-22 13:39:55+00:00
  edited: false
  hidden: false
  id: 641b133b4723a2b0aa4a5b67
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 164
repo_id: CompVis/stable-diffusion-v1-4
repo_type: model
status: open
target_branch: null
title: Having an issue with AMD GPU on Windows
