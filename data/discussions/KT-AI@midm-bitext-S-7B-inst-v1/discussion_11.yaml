!!python/object:huggingface_hub.community.DiscussionWithDetails
author: supark
conflicting_files: null
created_at: 2023-11-24 09:46:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1b05d74eeb05b5a5e3a510c7efdb1823.svg
      fullname: Sunghoon Park
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: supark
      type: user
    createdAt: '2023-11-24T09:46:16.000Z'
    data:
      edited: true
      editors:
      - supark
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8815608024597168
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1b05d74eeb05b5a5e3a510c7efdb1823.svg
          fullname: Sunghoon Park
          isHf: false
          isPro: false
          name: supark
          type: user
        html: '<p>Hello.</p>

          <p>I''m trying to fine-tune(peft) the <code>KT-AI/midm-bitext-S-7B-inst-v1</code>
          model.<br>When trying to train using the <code>AutoTokenizer</code> and
          <code>AutoModelForCausalLM</code> functions provided by the <code>Transformer</code>
          package, I encountered the following error message. </p>

          <ul>

          <li><code>Tokenizer class Midm_bitext_Tokenizer does not exist or is not
          currently imported</code></li>

          </ul>

          <p>I also attempted to invoke the tokenizer using the <code>Midm_bitext_Tokenizer</code>
          class included in <code>midm_bitext_tokenization.py</code>, but I still
          received the same error message. I''m wondering if there''s a way to address
          this issue.</p>

          '
        raw: "Hello.\n\nI'm trying to fine-tune(peft) the `KT-AI/midm-bitext-S-7B-inst-v1`\
          \ model. \nWhen trying to train using the `AutoTokenizer` and `AutoModelForCausalLM`\
          \ functions provided by the `Transformer` package, I encountered the following\
          \ error message. \n\n- `Tokenizer class Midm_bitext_Tokenizer does not exist\
          \ or is not currently imported`\n\nI also attempted to invoke the tokenizer\
          \ using the `Midm_bitext_Tokenizer` class included in `midm_bitext_tokenization.py`,\
          \ but I still received the same error message. I'm wondering if there's\
          \ a way to address this issue."
        updatedAt: '2023-11-24T09:47:22.174Z'
      numEdits: 1
      reactions: []
    id: 656070e847d95544efa09dde
    type: comment
  author: supark
  content: "Hello.\n\nI'm trying to fine-tune(peft) the `KT-AI/midm-bitext-S-7B-inst-v1`\
    \ model. \nWhen trying to train using the `AutoTokenizer` and `AutoModelForCausalLM`\
    \ functions provided by the `Transformer` package, I encountered the following\
    \ error message. \n\n- `Tokenizer class Midm_bitext_Tokenizer does not exist or\
    \ is not currently imported`\n\nI also attempted to invoke the tokenizer using\
    \ the `Midm_bitext_Tokenizer` class included in `midm_bitext_tokenization.py`,\
    \ but I still received the same error message. I'm wondering if there's a way\
    \ to address this issue."
  created_at: 2023-11-24 09:46:16+00:00
  edited: true
  hidden: false
  id: 656070e847d95544efa09dde
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eee110202c00f32afb01b21870af38c9.svg
      fullname: taehyeong_kim
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ktthkim
      type: user
    createdAt: '2023-11-28T01:16:45.000Z'
    data:
      edited: true
      editors:
      - ktthkim
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8223785758018494
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eee110202c00f32afb01b21870af38c9.svg
          fullname: taehyeong_kim
          isHf: false
          isPro: false
          name: ktthkim
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;supark&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/supark\">@<span class=\"\
          underline\">supark</span></a></span>\n\n\t</span></span><br>Could you share\
          \ your test code and the  transformers version?</p>\n"
        raw: "@supark \nCould you share your test code and the  transformers version?"
        updatedAt: '2023-11-28T01:17:01.583Z'
      numEdits: 1
      reactions: []
    id: 65653f7d96c2f44bd47c0e0f
    type: comment
  author: ktthkim
  content: "@supark \nCould you share your test code and the  transformers version?"
  created_at: 2023-11-28 01:16:45+00:00
  edited: true
  hidden: false
  id: 65653f7d96c2f44bd47c0e0f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1b05d74eeb05b5a5e3a510c7efdb1823.svg
      fullname: Sunghoon Park
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: supark
      type: user
    createdAt: '2023-11-29T04:48:46.000Z'
    data:
      edited: false
      editors:
      - supark
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9002667665481567
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1b05d74eeb05b5a5e3a510c7efdb1823.svg
          fullname: Sunghoon Park
          isHf: false
          isPro: false
          name: supark
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ktthkim&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ktthkim\">@<span class=\"\
          underline\">ktthkim</span></a></span>\n\n\t</span></span> </p>\n<p>Below\
          \ are the specific versions for testing configuration:</p>\n<p><code>Python\
          \ 3.10</code><br><code>Transformers==4.33.2</code></p>\n<p>The test code\
          \ itself is lengthy, but it is a standard codebase that you can easily find\
          \ on the web.</p>\n"
        raw: "@ktthkim \n\nBelow are the specific versions for testing configuration:\n\
          \n`Python 3.10`\n`Transformers==4.33.2`\n\nThe test code itself is lengthy,\
          \ but it is a standard codebase that you can easily find on the web."
        updatedAt: '2023-11-29T04:48:46.501Z'
      numEdits: 0
      reactions: []
    id: 6566c2aee7be83d4996b07b6
    type: comment
  author: supark
  content: "@ktthkim \n\nBelow are the specific versions for testing configuration:\n\
    \n`Python 3.10`\n`Transformers==4.33.2`\n\nThe test code itself is lengthy, but\
    \ it is a standard codebase that you can easily find on the web."
  created_at: 2023-11-29 04:48:46+00:00
  edited: false
  hidden: false
  id: 6566c2aee7be83d4996b07b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eee110202c00f32afb01b21870af38c9.svg
      fullname: taehyeong_kim
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ktthkim
      type: user
    createdAt: '2023-11-29T05:50:25.000Z'
    data:
      edited: false
      editors:
      - ktthkim
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9021061658859253
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eee110202c00f32afb01b21870af38c9.svg
          fullname: taehyeong_kim
          isHf: false
          isPro: false
          name: ktthkim
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;supark&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/supark\">@<span class=\"\
          underline\">supark</span></a></span>\n\n\t</span></span><br>I tested the\
          \ sample in the readme using transformers==4.33.2, and it worked well for\
          \ me.<br>Please make sure to check trust_remote_code=True when using from_pretrained</p>\n"
        raw: "@supark \nI tested the sample in the readme using transformers==4.33.2,\
          \ and it worked well for me.\nPlease make sure to check trust_remote_code=True\
          \ when using from_pretrained"
        updatedAt: '2023-11-29T05:50:25.921Z'
      numEdits: 0
      reactions: []
    id: 6566d121e320894e09076607
    type: comment
  author: ktthkim
  content: "@supark \nI tested the sample in the readme using transformers==4.33.2,\
    \ and it worked well for me.\nPlease make sure to check trust_remote_code=True\
    \ when using from_pretrained"
  created_at: 2023-11-29 05:50:25+00:00
  edited: false
  hidden: false
  id: 6566d121e320894e09076607
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1b05d74eeb05b5a5e3a510c7efdb1823.svg
      fullname: Sunghoon Park
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: supark
      type: user
    createdAt: '2023-11-29T07:21:42.000Z'
    data:
      edited: true
      editors:
      - supark
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9483254551887512
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1b05d74eeb05b5a5e3a510c7efdb1823.svg
          fullname: Sunghoon Park
          isHf: false
          isPro: false
          name: supark
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ktthkim&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ktthkim\">@<span class=\"\
          underline\">ktthkim</span></a></span>\n\n\t</span></span><br>There is no\
          \ issue with loading the model and tokenizer as you mentioned.<br>However,\
          \ when trying to fine-tune(QLoRa) using the <code>Trainer.train()</code>\
          \ provided by <code>Transformer</code>, the error mentioned above occurs.</p>\n"
        raw: "@ktthkim \nThere is no issue with loading the model and tokenizer as\
          \ you mentioned.\nHowever, when trying to fine-tune(QLoRa) using the `Trainer.train()`\
          \ provided by `Transformer`, the error mentioned above occurs."
        updatedAt: '2023-11-29T07:26:45.724Z'
      numEdits: 1
      reactions: []
    id: 6566e6863d526e3297e5afcc
    type: comment
  author: supark
  content: "@ktthkim \nThere is no issue with loading the model and tokenizer as you\
    \ mentioned.\nHowever, when trying to fine-tune(QLoRa) using the `Trainer.train()`\
    \ provided by `Transformer`, the error mentioned above occurs."
  created_at: 2023-11-29 07:21:42+00:00
  edited: true
  hidden: false
  id: 6566e6863d526e3297e5afcc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: KT-AI/midm-bitext-S-7B-inst-v1
repo_type: model
status: open
target_branch: null
title: Tokenizer class Midm_bitext_Tokenizer does not exist or is not currently imported
