!!python/object:huggingface_hub.community.DiscussionWithDetails
author: vishaal27
conflicting_files: null
created_at: 2023-08-24 04:14:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/308e98b9720521aa4e9c52a78dc95e56.svg
      fullname: Vishaal Udandarao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vishaal27
      type: user
    createdAt: '2023-08-24T05:14:27.000Z'
    data:
      edited: true
      editors:
      - vishaal27
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8307480812072754
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/308e98b9720521aa4e9c52a78dc95e56.svg
          fullname: Vishaal Udandarao
          isHf: false
          isPro: false
          name: vishaal27
          type: user
        html: '<p>Maybe this is something that is well known, but I had a few issues
          while running the model, and I just wanted to share my final environment
          settings that got it working on an NVIDIA A100-40GB GPU.</p>

          <pre><code class="language-bash">conda create --name ideficsenv python=3.8
          -y

          conda activate ideficsenv


          <span class="hljs-comment"># for idefics install specific transformers version</span>

          pip install transformers==4.32.0

          <span class="hljs-comment"># for A100 nodes, I had to setup torch specifically
          to use cu110+ compiles, idefics requires torch 2.0.0+</span>

          pip install torch==2.0.1+cu117 torchvision==0.15.2+cu117 -f https://download.pytorch.org/whl/torch_stable.html

          <span class="hljs-comment"># idefics also requires sentencepiece, protobuf,
          scipy, bitsandbytes and accelerate</span>

          pip install sentencepiece

          pip install protobuf

          pip install scipy bitsandbytes accelerate

          </code></pre>

          <p>With this setup, I was able to run the <a rel="nofollow" href="https://github.com/huggingface/notebooks/blob/main/examples/idefics/inference.py">example
          inference</a> script without any issues.</p>

          '
        raw: 'Maybe this is something that is well known, but I had a few issues while
          running the model, and I just wanted to share my final environment settings
          that got it working on an NVIDIA A100-40GB GPU.


          ```bash

          conda create --name ideficsenv python=3.8 -y

          conda activate ideficsenv


          # for idefics install specific transformers version

          pip install transformers==4.32.0

          # for A100 nodes, I had to setup torch specifically to use cu110+ compiles,
          idefics requires torch 2.0.0+

          pip install torch==2.0.1+cu117 torchvision==0.15.2+cu117 -f https://download.pytorch.org/whl/torch_stable.html

          # idefics also requires sentencepiece, protobuf, scipy, bitsandbytes and
          accelerate

          pip install sentencepiece

          pip install protobuf

          pip install scipy bitsandbytes accelerate

          ```


          With this setup, I was able to run the [example inference](https://github.com/huggingface/notebooks/blob/main/examples/idefics/inference.py)
          script without any issues.'
        updatedAt: '2023-08-24T15:06:20.331Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - VictorSanh
    id: 64e6e733336924eaf1a53510
    type: comment
  author: vishaal27
  content: 'Maybe this is something that is well known, but I had a few issues while
    running the model, and I just wanted to share my final environment settings that
    got it working on an NVIDIA A100-40GB GPU.


    ```bash

    conda create --name ideficsenv python=3.8 -y

    conda activate ideficsenv


    # for idefics install specific transformers version

    pip install transformers==4.32.0

    # for A100 nodes, I had to setup torch specifically to use cu110+ compiles, idefics
    requires torch 2.0.0+

    pip install torch==2.0.1+cu117 torchvision==0.15.2+cu117 -f https://download.pytorch.org/whl/torch_stable.html

    # idefics also requires sentencepiece, protobuf, scipy, bitsandbytes and accelerate

    pip install sentencepiece

    pip install protobuf

    pip install scipy bitsandbytes accelerate

    ```


    With this setup, I was able to run the [example inference](https://github.com/huggingface/notebooks/blob/main/examples/idefics/inference.py)
    script without any issues.'
  created_at: 2023-08-24 04:14:27+00:00
  edited: true
  hidden: false
  id: 64e6e733336924eaf1a53510
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: HuggingFaceM4/idefics-9b
repo_type: model
status: open
target_branch: null
title: Requirements for running the model
