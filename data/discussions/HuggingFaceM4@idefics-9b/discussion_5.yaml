!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dribnet
conflicting_files: null
created_at: 2023-08-24 08:49:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5d1f5d503cd3640552eb4cce327e3c2a.svg
      fullname: Tom White
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dribnet
      type: user
    createdAt: '2023-08-24T09:49:32.000Z'
    data:
      edited: false
      editors:
      - dribnet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9397953152656555
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5d1f5d503cd3640552eb4cce327e3c2a.svg
          fullname: Tom White
          isHf: false
          isPro: false
          name: dribnet
          type: user
        html: '<p>Thanks for this amazing project. I''m looking into replicating a
          subset of the evaluations shown on the model card. Is the code used to run
          these evals and generate these graphs available somewhere?</p>

          <p>I''m actually not interested in replicating the full eval suite, but
          thought it would be prudent when fine tuning to determine if this is hurting
          performance elsewhere. So my thought it to adopt some of the key evaluation
          metrics on a smaller subset of the datasets (eg: maybe VQA-v2 and ImageNet-1k)
          and run it before and after - or maybe even periodically during the fine
          tuning process.</p>

          '
        raw: "Thanks for this amazing project. I'm looking into replicating a subset\
          \ of the evaluations shown on the model card. Is the code used to run these\
          \ evals and generate these graphs available somewhere?\r\n\r\nI'm actually\
          \ not interested in replicating the full eval suite, but thought it would\
          \ be prudent when fine tuning to determine if this is hurting performance\
          \ elsewhere. So my thought it to adopt some of the key evaluation metrics\
          \ on a smaller subset of the datasets (eg: maybe VQA-v2 and ImageNet-1k)\
          \ and run it before and after - or maybe even periodically during the fine\
          \ tuning process."
        updatedAt: '2023-08-24T09:49:32.837Z'
      numEdits: 0
      reactions: []
    id: 64e727acc0cc3e95d1da005c
    type: comment
  author: dribnet
  content: "Thanks for this amazing project. I'm looking into replicating a subset\
    \ of the evaluations shown on the model card. Is the code used to run these evals\
    \ and generate these graphs available somewhere?\r\n\r\nI'm actually not interested\
    \ in replicating the full eval suite, but thought it would be prudent when fine\
    \ tuning to determine if this is hurting performance elsewhere. So my thought\
    \ it to adopt some of the key evaluation metrics on a smaller subset of the datasets\
    \ (eg: maybe VQA-v2 and ImageNet-1k) and run it before and after - or maybe even\
    \ periodically during the fine tuning process."
  created_at: 2023-08-24 08:49:32+00:00
  edited: false
  hidden: false
  id: 64e727acc0cc3e95d1da005c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
      fullname: Victor Sanh
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: true
      name: VictorSanh
      type: user
    createdAt: '2023-08-28T16:28:26.000Z'
    data:
      edited: false
      editors:
      - VictorSanh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9208952188491821
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
          fullname: Victor Sanh
          isHf: true
          isPro: true
          name: VictorSanh
          type: user
        html: '<p>Hi!<br>At the present moment, our codebase to train and evaluate
          is not public.<br>There are plans to make it public although the team needs
          to take a break ;)<br>Happy to help if you are reproducing the numbers independently
          of the codebase!<br>For vqa, we used the open-ended evaluation meaning that
          we let the model generate a free form text, and use that as generated answer.<br>For
          imagenet, we use rank evaluation meaning that we score all 1_000 possibilities
          via log-probability under the model, and chose as prediction the option
          with the highest score.</p>

          '
        raw: "Hi!\nAt the present moment, our codebase to train and evaluate is not\
          \ public.\nThere are plans to make it public although the team needs to\
          \ take a break ;) \nHappy to help if you are reproducing the numbers independently\
          \ of the codebase! \nFor vqa, we used the open-ended evaluation meaning\
          \ that we let the model generate a free form text, and use that as generated\
          \ answer.\nFor imagenet, we use rank evaluation meaning that we score all\
          \ 1_000 possibilities via log-probability under the model, and chose as\
          \ prediction the option with the highest score."
        updatedAt: '2023-08-28T16:28:26.969Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - dribnet
    id: 64eccb2a2f0bd58125f8e3db
    type: comment
  author: VictorSanh
  content: "Hi!\nAt the present moment, our codebase to train and evaluate is not\
    \ public.\nThere are plans to make it public although the team needs to take a\
    \ break ;) \nHappy to help if you are reproducing the numbers independently of\
    \ the codebase! \nFor vqa, we used the open-ended evaluation meaning that we let\
    \ the model generate a free form text, and use that as generated answer.\nFor\
    \ imagenet, we use rank evaluation meaning that we score all 1_000 possibilities\
    \ via log-probability under the model, and chose as prediction the option with\
    \ the highest score."
  created_at: 2023-08-28 15:28:26+00:00
  edited: false
  hidden: false
  id: 64eccb2a2f0bd58125f8e3db
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: HuggingFaceM4/idefics-9b
repo_type: model
status: open
target_branch: null
title: replicating evaluation?
