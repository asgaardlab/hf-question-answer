!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Yhyu13
conflicting_files: null
created_at: 2024-01-19 06:10:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2024-01-19T06:10:07.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.32925498485565186
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: "<p>Seems like it's an error on the Mixtral expert choosing, does any\
          \ one have the same issue? Just want to know if its is a known bug for this\
          \ model, or maybe a bug for the code?</p>\n<p>I am on textgen webui <a rel=\"\
          nofollow\" href=\"https://github.com/oobabooga/text-generation-webui/commit/d8c3a5bee814f09b0868474002105dcf21a3ff1a\"\
          >https://github.com/oobabooga/text-generation-webui/commit/d8c3a5bee814f09b0868474002105dcf21a3ff1a</a></p>\n\
          <p>Ubuntu 20.04<br>RTX3090<br>Nvidia 545.23.08</p>\n<pre><code>Traceback\
          \ (most recent call last):\n  File \"/home/hangyu5/Documents/Gitrepo-My/text-generation-webui/modules/callbacks.py\"\
          , line 61, in gentask\n    ret = self.mfunc(callback=_callback, *args, **self.kwargs)\n\
          \          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File\
          \ \"/home/hangyu5/Documents/Gitrepo-My/text-generation-webui/modules/text_generation.py\"\
          , line 376, in generate_with_callback\n    shared.model.generate(**kwargs)\n\
          \  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n    \
          \       ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/generation/utils.py\"\
          , line 1764, in generate\n    return self.sample(\n           ^^^^^^^^^^^^\n\
          \  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/generation/utils.py\"\
          , line 2861, in sample\n    outputs = self(\n              ^^^^^\n  File\
          \ \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = module._old_forward(*args, **kwargs)\n\
          \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
          , line 1222, in forward\n    outputs = self.model(\n              ^^^^^^^^^^^\n\
          \  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = module._old_forward(*args, **kwargs)\n\
          \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
          , line 1090, in forward\n    layer_outputs = decoder_layer(\n          \
          \          ^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = module._old_forward(*args, **kwargs)\n\
          \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
          , line 819, in forward\n    hidden_states, router_logits = self.block_sparse_moe(hidden_states)\n\
          \                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\n    output = module._old_forward(*args, **kwargs)\n\
          \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
          , line 736, in forward\n    idx, top_x = torch.where(expert_mask[expert_idx])\n\
          \                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA\
          \ error: an illegal memory access was encountered\nCUDA kernel errors might\
          \ be asynchronously reported at some other API call, so the stacktrace below\
          \ might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n\
          Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n</code></pre>\n"
        raw: "Seems like it's an error on the Mixtral expert choosing, does any one\
          \ have the same issue? Just want to know if its is a known bug for this\
          \ model, or maybe a bug for the code?\r\n\r\nI am on textgen webui https://github.com/oobabooga/text-generation-webui/commit/d8c3a5bee814f09b0868474002105dcf21a3ff1a\r\
          \n\r\nUbuntu 20.04\r\nRTX3090\r\nNvidia 545.23.08\r\n\r\n```\r\nTraceback\
          \ (most recent call last):\r\n  File \"/home/hangyu5/Documents/Gitrepo-My/text-generation-webui/modules/callbacks.py\"\
          , line 61, in gentask\r\n    ret = self.mfunc(callback=_callback, *args,\
          \ **self.kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/home/hangyu5/Documents/Gitrepo-My/text-generation-webui/modules/text_generation.py\"\
          , line 376, in generate_with_callback\r\n    shared.model.generate(**kwargs)\r\
          \n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n\
          \           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/generation/utils.py\"\
          , line 1764, in generate\r\n    return self.sample(\r\n           ^^^^^^^^^^^^\r\
          \n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/generation/utils.py\"\
          , line 2861, in sample\r\n    outputs = self(\r\n              ^^^^^\r\n\
          \  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
          , line 1222, in forward\r\n    outputs = self.model(\r\n              ^^^^^^^^^^^\r\
          \n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
          , line 1090, in forward\r\n    layer_outputs = decoder_layer(\r\n      \
          \              ^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
          , line 819, in forward\r\n    hidden_states, router_logits = self.block_sparse_moe(hidden_states)\r\
          \n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          /home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
          , line 736, in forward\r\n    idx, top_x = torch.where(expert_mask[expert_idx])\r\
          \n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nRuntimeError:\
          \ CUDA error: an illegal memory access was encountered\r\nCUDA kernel errors\
          \ might be asynchronously reported at some other API call, so the stacktrace\
          \ below might be incorrect.\r\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\r\
          \nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\r\n\
          ```"
        updatedAt: '2024-01-19T06:10:07.834Z'
      numEdits: 0
      reactions: []
    id: 65aa123fb68db4f26eb357d4
    type: comment
  author: Yhyu13
  content: "Seems like it's an error on the Mixtral expert choosing, does any one\
    \ have the same issue? Just want to know if its is a known bug for this model,\
    \ or maybe a bug for the code?\r\n\r\nI am on textgen webui https://github.com/oobabooga/text-generation-webui/commit/d8c3a5bee814f09b0868474002105dcf21a3ff1a\r\
    \n\r\nUbuntu 20.04\r\nRTX3090\r\nNvidia 545.23.08\r\n\r\n```\r\nTraceback (most\
    \ recent call last):\r\n  File \"/home/hangyu5/Documents/Gitrepo-My/text-generation-webui/modules/callbacks.py\"\
    , line 61, in gentask\r\n    ret = self.mfunc(callback=_callback, *args, **self.kwargs)\r\
    \n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
    /home/hangyu5/Documents/Gitrepo-My/text-generation-webui/modules/text_generation.py\"\
    , line 376, in generate_with_callback\r\n    shared.model.generate(**kwargs)\r\
    \n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n      \
    \     ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/generation/utils.py\"\
    , line 1764, in generate\r\n    return self.sample(\r\n           ^^^^^^^^^^^^\r\
    \n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/generation/utils.py\"\
    , line 2861, in sample\r\n    outputs = self(\r\n              ^^^^^\r\n  File\
    \ \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
    , line 1222, in forward\r\n    outputs = self.model(\r\n              ^^^^^^^^^^^\r\
    \n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
    , line 1090, in forward\r\n    layer_outputs = decoder_layer(\r\n            \
    \        ^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
    , line 819, in forward\r\n    hidden_states, router_logits = self.block_sparse_moe(hidden_states)\r\
    \n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\
    \  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/hangyu5/anaconda3/envs/textgen/lib/python3.11/site-packages/transformers/models/mixtral/modeling_mixtral.py\"\
    , line 736, in forward\r\n    idx, top_x = torch.where(expert_mask[expert_idx])\r\
    \n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nRuntimeError: CUDA\
    \ error: an illegal memory access was encountered\r\nCUDA kernel errors might\
    \ be asynchronously reported at some other API call, so the stacktrace below might\
    \ be incorrect.\r\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\r\n\
    Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\r\n```"
  created_at: 2024-01-19 06:10:07+00:00
  edited: false
  hidden: false
  id: 65aa123fb68db4f26eb357d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/83438dca274171c14ff397fd7d56dc4c.svg
      fullname: Suqin Zhang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: TomGrc
      type: user
    createdAt: '2024-01-19T07:09:29.000Z'
    data:
      edited: false
      editors:
      - TomGrc
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/83438dca274171c14ff397fd7d56dc4c.svg
          fullname: Suqin Zhang
          isHf: false
          isPro: false
          name: TomGrc
          type: user
        html: '<p>I believe it''s a bug in the code.</p>

          '
        raw: I believe it's a bug in the code.
        updatedAt: '2024-01-19T07:09:29.080Z'
      numEdits: 0
      reactions: []
    id: 65aa2029d6b10af91160c879
    type: comment
  author: TomGrc
  content: I believe it's a bug in the code.
  created_at: 2024-01-19 07:09:29+00:00
  edited: false
  hidden: false
  id: 65aa2029d6b10af91160c879
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TomGrc/FusionNet_7Bx2_MoE_14B
repo_type: model
status: open
target_branch: null
title: textgen webui CUDA memory error on clear cache
