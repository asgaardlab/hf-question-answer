!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ritvikshandilya
conflicting_files: null
created_at: 2023-09-23 06:14:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e9129733d1b0ca83cad7eea15ea3b467.svg
      fullname: ritvik shandilya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ritvikshandilya
      type: user
    createdAt: '2023-09-23T07:14:22.000Z'
    data:
      edited: false
      editors:
      - ritvikshandilya
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8965222835540771
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e9129733d1b0ca83cad7eea15ea3b467.svg
          fullname: ritvik shandilya
          isHf: false
          isPro: false
          name: ritvikshandilya
          type: user
        html: '<p>Hey, I was trying to quantize it by following your article <a rel="nofollow"
          href="https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html">https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html</a>
          but the tokenizer.model file is missing, can you help us how we can use
          your quantization tutorial (gguf) on  colab fine tuning files?</p>

          '
        raw: Hey, I was trying to quantize it by following your article https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html
          but the tokenizer.model file is missing, can you help us how we can use
          your quantization tutorial (gguf) on  colab fine tuning files?
        updatedAt: '2023-09-23T07:14:22.716Z'
      numEdits: 0
      reactions: []
    id: 650e904e9d93eec4a72b77a9
    type: comment
  author: ritvikshandilya
  content: Hey, I was trying to quantize it by following your article https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html
    but the tokenizer.model file is missing, can you help us how we can use your quantization
    tutorial (gguf) on  colab fine tuning files?
  created_at: 2023-09-23 06:14:22+00:00
  edited: false
  hidden: false
  id: 650e904e9d93eec4a72b77a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
      fullname: Maxime Labonne
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mlabonne
      type: user
    createdAt: '2023-09-23T10:30:13.000Z'
    data:
      edited: false
      editors:
      - mlabonne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8346012234687805
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
          fullname: Maxime Labonne
          isHf: false
          isPro: false
          name: mlabonne
          type: user
        html: '<p>This error happens because the model you want to quantize (llama-2-7b-meditext)
          doesn''t have a tokenizer in its repo. You can simply download the tokenizer
          files from Llama-2 (<a href="https://huggingface.co/meta-llama/Llama-2-7b-hf/tree/main">https://huggingface.co/meta-llama/Llama-2-7b-hf/tree/main</a>)
          and place them in your model''s folder.</p>

          '
        raw: This error happens because the model you want to quantize (llama-2-7b-meditext)
          doesn't have a tokenizer in its repo. You can simply download the tokenizer
          files from Llama-2 (https://huggingface.co/meta-llama/Llama-2-7b-hf/tree/main)
          and place them in your model's folder.
        updatedAt: '2023-09-23T10:30:13.914Z'
      numEdits: 0
      reactions: []
    id: 650ebe35c945dfc9387b3597
    type: comment
  author: mlabonne
  content: This error happens because the model you want to quantize (llama-2-7b-meditext)
    doesn't have a tokenizer in its repo. You can simply download the tokenizer files
    from Llama-2 (https://huggingface.co/meta-llama/Llama-2-7b-hf/tree/main) and place
    them in your model's folder.
  created_at: 2023-09-23 09:30:13+00:00
  edited: false
  hidden: false
  id: 650ebe35c945dfc9387b3597
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: mlabonne/codellama-2-7b
repo_type: model
status: open
target_branch: null
title: Quantizing this by following your article
