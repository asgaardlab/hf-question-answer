!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kopyl
conflicting_files: null
created_at: 2023-12-04 06:00:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d6a6d922028e8b447b87fca56c00c679.svg
      fullname: T
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kopyl
      type: user
    createdAt: '2023-12-04T06:00:21.000Z'
    data:
      edited: false
      editors:
      - kopyl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.671997606754303
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d6a6d922028e8b447b87fca56c00c679.svg
          fullname: T
          isHf: false
          isPro: false
          name: kopyl
          type: user
        html: "<p>I just fined tuned <a href=\"https://huggingface.co/lambdalabs/miniSD-diffusers\"\
          >https://huggingface.co/lambdalabs/miniSD-diffusers</a><br>which is a similar\
          \ model to this except with 256x256 resultion.</p>\n<p>The fine-tuning went\
          \ well, but when i use the same approach on this model, i quickly get zero\
          \ step loss at 100 steps. Do you know why? Here i my params:</p>\n<pre><code>!accelerate\
          \ launch --mixed_precision=\"fp16\" train_text_to_image.py \\\n  --pretrained_model_name_or_path=OFA-Sys/small-stable-diffusion-v0\
          \ \\\n  --use_ema \\\n  --resolution=512 \\\n  --train_batch_size=64 \\\n\
          \  --max_train_steps=1000000 \\\n  --checkpointing_steps=200 \\\n  --learning_rate=4e-7\
          \ \\\n  --max_grad_norm=1 \\\n  --lr_scheduler=\"constant\" \\\n  --lr_warmup_steps=0\
          \ \\\n  --noise_offset=0.05 \\\n</code></pre>\n<p>I tried these LR:</p>\n\
          <ul>\n<li>4e-7</li>\n<li>1e-5<br>-1e-6<br>and always get the zero loss</li>\n\
          </ul>\n<p><code>train_text_to_image.py</code> is <a rel=\"nofollow\" href=\"\
          https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py\"\
          >https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py</a></p>\n"
        raw: "I just fined tuned https://huggingface.co/lambdalabs/miniSD-diffusers\r\
          \nwhich is a similar model to this except with 256x256 resultion.\r\n\r\n\
          The fine-tuning went well, but when i use the same approach on this model,\
          \ i quickly get zero step loss at 100 steps. Do you know why? Here i my\
          \ params:\r\n\r\n```\r\n!accelerate launch --mixed_precision=\"fp16\" train_text_to_image.py\
          \ \\\r\n  --pretrained_model_name_or_path=OFA-Sys/small-stable-diffusion-v0\
          \ \\\r\n  --use_ema \\\r\n  --resolution=512 \\\r\n  --train_batch_size=64\
          \ \\\r\n  --max_train_steps=1000000 \\\r\n  --checkpointing_steps=200 \\\
          \r\n  --learning_rate=4e-7 \\\r\n  --max_grad_norm=1 \\\r\n  --lr_scheduler=\"\
          constant\" \\\r\n  --lr_warmup_steps=0 \\\r\n  --noise_offset=0.05 \\\r\n\
          ```\r\n\r\nI tried these LR:\r\n- 4e-7\r\n- 1e-5\r\n-1e-6\r\nand always\
          \ get the zero loss\r\n\r\n`train_text_to_image.py` is https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py"
        updatedAt: '2023-12-04T06:00:21.025Z'
      numEdits: 0
      reactions: []
    id: 656d6af5271c5c4e334238da
    type: comment
  author: kopyl
  content: "I just fined tuned https://huggingface.co/lambdalabs/miniSD-diffusers\r\
    \nwhich is a similar model to this except with 256x256 resultion.\r\n\r\nThe fine-tuning\
    \ went well, but when i use the same approach on this model, i quickly get zero\
    \ step loss at 100 steps. Do you know why? Here i my params:\r\n\r\n```\r\n!accelerate\
    \ launch --mixed_precision=\"fp16\" train_text_to_image.py \\\r\n  --pretrained_model_name_or_path=OFA-Sys/small-stable-diffusion-v0\
    \ \\\r\n  --use_ema \\\r\n  --resolution=512 \\\r\n  --train_batch_size=64 \\\r\
    \n  --max_train_steps=1000000 \\\r\n  --checkpointing_steps=200 \\\r\n  --learning_rate=4e-7\
    \ \\\r\n  --max_grad_norm=1 \\\r\n  --lr_scheduler=\"constant\" \\\r\n  --lr_warmup_steps=0\
    \ \\\r\n  --noise_offset=0.05 \\\r\n```\r\n\r\nI tried these LR:\r\n- 4e-7\r\n\
    - 1e-5\r\n-1e-6\r\nand always get the zero loss\r\n\r\n`train_text_to_image.py`\
    \ is https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py"
  created_at: 2023-12-04 06:00:21+00:00
  edited: false
  hidden: false
  id: 656d6af5271c5c4e334238da
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: OFA-Sys/small-stable-diffusion-v0
repo_type: model
status: open
target_branch: null
title: Nice model, but can't fine-tune
