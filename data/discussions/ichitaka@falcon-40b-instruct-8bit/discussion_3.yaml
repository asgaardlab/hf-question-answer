!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SaffalPoosh
conflicting_files: null
created_at: 2023-07-04 08:47:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652562749455-noauth.png?w=200&h=200&f=face
      fullname: Talha Yousuf
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SaffalPoosh
      type: user
    createdAt: '2023-07-04T09:47:36.000Z'
    data:
      edited: false
      editors:
      - SaffalPoosh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.966559648513794
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652562749455-noauth.png?w=200&h=200&f=face
          fullname: Talha Yousuf
          isHf: false
          isPro: false
          name: SaffalPoosh
          type: user
        html: '<p>I was also trying to quantize some 40B/30B LLM models  using bitsandbytes
          and AUTOGPTQ algorithm , with bits and bytes it was giving me errors, with
          layers, it would be extremely helpful if you can give insight into how did
          you manage to quantize this model? </p>

          <p>Also <code>model.save_pretrained()</code> after  <code>load_in_8bit=True</code>
          gives error that quantized model cannot be saved. How you pushed it here?</p>

          <p>thanks</p>

          '
        raw: "I was also trying to quantize some 40B/30B LLM models  using bitsandbytes\
          \ and AUTOGPTQ algorithm , with bits and bytes it was giving me errors,\
          \ with layers, it would be extremely helpful if you can give insight into\
          \ how did you manage to quantize this model? \r\n\r\nAlso `model.save_pretrained()`\
          \ after  `load_in_8bit=True` gives error that quantized model cannot be\
          \ saved. How you pushed it here?\r\n\r\nthanks"
        updatedAt: '2023-07-04T09:47:36.744Z'
      numEdits: 0
      reactions: []
    id: 64a3eab80924dcbf9392aa5a
    type: comment
  author: SaffalPoosh
  content: "I was also trying to quantize some 40B/30B LLM models  using bitsandbytes\
    \ and AUTOGPTQ algorithm , with bits and bytes it was giving me errors, with layers,\
    \ it would be extremely helpful if you can give insight into how did you manage\
    \ to quantize this model? \r\n\r\nAlso `model.save_pretrained()` after  `load_in_8bit=True`\
    \ gives error that quantized model cannot be saved. How you pushed it here?\r\n\
    \r\nthanks"
  created_at: 2023-07-04 08:47:36+00:00
  edited: false
  hidden: false
  id: 64a3eab80924dcbf9392aa5a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2704aa0f012d94f88c349c532eb403cb.svg
      fullname: T T
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ichitaka
      type: user
    createdAt: '2023-07-05T08:11:55.000Z'
    data:
      edited: false
      editors:
      - ichitaka
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.837149441242218
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2704aa0f012d94f88c349c532eb403cb.svg
          fullname: T T
          isHf: false
          isPro: false
          name: ichitaka
          type: user
        html: '<p>Not all models are able to be quantized using the bitsandbytes integration.
          If the model contains custom layers outside the standard huggingface transformers
          library, you will not be able to use the bitsandbytes route. What error
          are you facing when saving the model? </p>

          '
        raw: 'Not all models are able to be quantized using the bitsandbytes integration.
          If the model contains custom layers outside the standard huggingface transformers
          library, you will not be able to use the bitsandbytes route. What error
          are you facing when saving the model? '
        updatedAt: '2023-07-05T08:11:55.437Z'
      numEdits: 0
      reactions: []
    id: 64a525cb30f9a7f52d3fdca3
    type: comment
  author: ichitaka
  content: 'Not all models are able to be quantized using the bitsandbytes integration.
    If the model contains custom layers outside the standard huggingface transformers
    library, you will not be able to use the bitsandbytes route. What error are you
    facing when saving the model? '
  created_at: 2023-07-05 07:11:55+00:00
  edited: false
  hidden: false
  id: 64a525cb30f9a7f52d3fdca3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
      fullname: Michael O'Mahony
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: michaelomahony
      type: user
    createdAt: '2023-07-06T14:12:34.000Z'
    data:
      edited: false
      editors:
      - michaelomahony
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7035917043685913
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
          fullname: Michael O'Mahony
          isHf: false
          isPro: false
          name: michaelomahony
          type: user
        html: '<p>I also get an error when calling model.save_pretrained() with the
          8-bit falcon-7b-instruct model. This is the warning when it''s run:<br><code>/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:1709:
          UserWarning: You are calling </code>save_pretrained<code>to a 8-bit converted
          model you may likely encounter unexepected behaviors. If you want to save
          8-bit models, make sure to have</code>bitsandbytes&gt;0.37.2<code> installed.   warnings.warn(</code></p>

          <p>This is the error:<br>AttributeError                            Traceback
          (most recent call last)<br>File :1</p>

          <p>File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:1820,
          in PreTrainedModel.save_pretrained(self, save_directory, is_main_process,
          state_dict, save_function, push_to_hub, max_shard_size, safe_serialization,
          variant, **kwargs)<br>   1817 weights_name = SAFE_WEIGHTS_NAME if safe_serialization
          else WEIGHTS_NAME<br>   1818 weights_name = _add_variant(weights_name, variant)<br>-&gt;
          1820 shards, index = shard_checkpoint(state_dict, max_shard_size=max_shard_size,
          weights_name=weights_name)<br>   1822 # Clean the folder from a previous
          save<br>   1823 for filename in os.listdir(save_directory):</p>

          <p>File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:318,
          in shard_checkpoint(state_dict, max_shard_size, weights_name)<br>    315
          storage_id_to_block = {}<br>    317 for key, weight in state_dict.items():<br>--&gt;
          318     storage_id = id_tensor_storage(weight)<br>    320     # If a <code>weight</code>
          shares the same underlying storage as another tensor, we put <code>weight</code>
          in the same <code>block</code><br>    321     if storage_id in storage_id_to_block:</p>

          <p>File ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pytorch_utils.py:290,
          in id_tensor_storage(tensor)<br>    283 def id_tensor_storage(tensor: torch.Tensor)
          -&gt; Tuple[torch.device, int, int]:<br>    284     """<br>    285     Unique
          identifier to a tensor storage. Multiple different tensors can share the
          same underlying storage. For<br>    286     example, "meta" tensors all
          share the same storage, and thus their identifier will all be equal. This
          identifier is<br>    287     guaranteed to be unique and constant for this
          tensor''s storage during its lifetime. Two tensor storages with<br>    288     non-overlapping
          lifetimes may have the same id.<br>    289     """<br>--&gt; 290     return
          tensor.device, storage_ptr(tensor), storage_size(tensor)</p>

          <p><code>AttributeError: ''str'' object has no attribute ''device''</code></p>

          '
        raw: "I also get an error when calling model.save_pretrained() with the 8-bit\
          \ falcon-7b-instruct model. This is the warning when it's run:\n`/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:1709:\
          \ UserWarning: You are calling `save_pretrained` to a 8-bit converted model\
          \ you may likely encounter unexepected behaviors. If you want to save 8-bit\
          \ models, make sure to have `bitsandbytes>0.37.2` installed.\n  warnings.warn(`\n\
          \nThis is the error:\nAttributeError                            Traceback\
          \ (most recent call last)\nFile <timed eval>:1\n\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:1820,\
          \ in PreTrainedModel.save_pretrained(self, save_directory, is_main_process,\
          \ state_dict, save_function, push_to_hub, max_shard_size, safe_serialization,\
          \ variant, **kwargs)\n   1817 weights_name = SAFE_WEIGHTS_NAME if safe_serialization\
          \ else WEIGHTS_NAME\n   1818 weights_name = _add_variant(weights_name, variant)\n\
          -> 1820 shards, index = shard_checkpoint(state_dict, max_shard_size=max_shard_size,\
          \ weights_name=weights_name)\n   1822 # Clean the folder from a previous\
          \ save\n   1823 for filename in os.listdir(save_directory):\n\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:318,\
          \ in shard_checkpoint(state_dict, max_shard_size, weights_name)\n    315\
          \ storage_id_to_block = {}\n    317 for key, weight in state_dict.items():\n\
          --> 318     storage_id = id_tensor_storage(weight)\n    320     # If a `weight`\
          \ shares the same underlying storage as another tensor, we put `weight`\
          \ in the same `block`\n    321     if storage_id in storage_id_to_block:\n\
          \nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pytorch_utils.py:290,\
          \ in id_tensor_storage(tensor)\n    283 def id_tensor_storage(tensor: torch.Tensor)\
          \ -> Tuple[torch.device, int, int]:\n    284     \"\"\"\n    285     Unique\
          \ identifier to a tensor storage. Multiple different tensors can share the\
          \ same underlying storage. For\n    286     example, \"meta\" tensors all\
          \ share the same storage, and thus their identifier will all be equal. This\
          \ identifier is\n    287     guaranteed to be unique and constant for this\
          \ tensor's storage during its lifetime. Two tensor storages with\n    288\
          \     non-overlapping lifetimes may have the same id.\n    289     \"\"\"\
          \n--> 290     return tensor.device, storage_ptr(tensor), storage_size(tensor)\n\
          \n`AttributeError: 'str' object has no attribute 'device'`"
        updatedAt: '2023-07-06T14:12:34.490Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - SaffalPoosh
    id: 64a6cbd2b8689f49e8aaa4e4
    type: comment
  author: michaelomahony
  content: "I also get an error when calling model.save_pretrained() with the 8-bit\
    \ falcon-7b-instruct model. This is the warning when it's run:\n`/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:1709:\
    \ UserWarning: You are calling `save_pretrained` to a 8-bit converted model you\
    \ may likely encounter unexepected behaviors. If you want to save 8-bit models,\
    \ make sure to have `bitsandbytes>0.37.2` installed.\n  warnings.warn(`\n\nThis\
    \ is the error:\nAttributeError                            Traceback (most recent\
    \ call last)\nFile <timed eval>:1\n\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:1820,\
    \ in PreTrainedModel.save_pretrained(self, save_directory, is_main_process, state_dict,\
    \ save_function, push_to_hub, max_shard_size, safe_serialization, variant, **kwargs)\n\
    \   1817 weights_name = SAFE_WEIGHTS_NAME if safe_serialization else WEIGHTS_NAME\n\
    \   1818 weights_name = _add_variant(weights_name, variant)\n-> 1820 shards, index\
    \ = shard_checkpoint(state_dict, max_shard_size=max_shard_size, weights_name=weights_name)\n\
    \   1822 # Clean the folder from a previous save\n   1823 for filename in os.listdir(save_directory):\n\
    \nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_utils.py:318,\
    \ in shard_checkpoint(state_dict, max_shard_size, weights_name)\n    315 storage_id_to_block\
    \ = {}\n    317 for key, weight in state_dict.items():\n--> 318     storage_id\
    \ = id_tensor_storage(weight)\n    320     # If a `weight` shares the same underlying\
    \ storage as another tensor, we put `weight` in the same `block`\n    321    \
    \ if storage_id in storage_id_to_block:\n\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pytorch_utils.py:290,\
    \ in id_tensor_storage(tensor)\n    283 def id_tensor_storage(tensor: torch.Tensor)\
    \ -> Tuple[torch.device, int, int]:\n    284     \"\"\"\n    285     Unique identifier\
    \ to a tensor storage. Multiple different tensors can share the same underlying\
    \ storage. For\n    286     example, \"meta\" tensors all share the same storage,\
    \ and thus their identifier will all be equal. This identifier is\n    287   \
    \  guaranteed to be unique and constant for this tensor's storage during its lifetime.\
    \ Two tensor storages with\n    288     non-overlapping lifetimes may have the\
    \ same id.\n    289     \"\"\"\n--> 290     return tensor.device, storage_ptr(tensor),\
    \ storage_size(tensor)\n\n`AttributeError: 'str' object has no attribute 'device'`"
  created_at: 2023-07-06 13:12:34+00:00
  edited: false
  hidden: false
  id: 64a6cbd2b8689f49e8aaa4e4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2704aa0f012d94f88c349c532eb403cb.svg
      fullname: T T
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ichitaka
      type: user
    createdAt: '2023-07-06T14:21:15.000Z'
    data:
      edited: false
      editors:
      - ichitaka
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8172513842582703
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2704aa0f012d94f88c349c532eb403cb.svg
          fullname: T T
          isHf: false
          isPro: false
          name: ichitaka
          type: user
        html: '<p>Well, do you have the right bitsandbytes version?</p>

          '
        raw: Well, do you have the right bitsandbytes version?
        updatedAt: '2023-07-06T14:21:15.144Z'
      numEdits: 0
      reactions: []
    id: 64a6cddbcb25ce57a47b8570
    type: comment
  author: ichitaka
  content: Well, do you have the right bitsandbytes version?
  created_at: 2023-07-06 13:21:15+00:00
  edited: false
  hidden: false
  id: 64a6cddbcb25ce57a47b8570
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
      fullname: Michael O'Mahony
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: michaelomahony
      type: user
    createdAt: '2023-07-06T14:54:18.000Z'
    data:
      edited: false
      editors:
      - michaelomahony
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9714187383651733
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
          fullname: Michael O'Mahony
          isHf: false
          isPro: false
          name: michaelomahony
          type: user
        html: '<p>I have version 0.39.1</p>

          '
        raw: I have version 0.39.1
        updatedAt: '2023-07-06T14:54:18.124Z'
      numEdits: 0
      reactions: []
    id: 64a6d59aff16977feab9ff8c
    type: comment
  author: michaelomahony
  content: I have version 0.39.1
  created_at: 2023-07-06 13:54:18+00:00
  edited: false
  hidden: false
  id: 64a6d59aff16977feab9ff8c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2704aa0f012d94f88c349c532eb403cb.svg
      fullname: T T
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ichitaka
      type: user
    createdAt: '2023-07-06T15:04:52.000Z'
    data:
      edited: false
      editors:
      - ichitaka
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4938163757324219
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2704aa0f012d94f88c349c532eb403cb.svg
          fullname: T T
          isHf: false
          isPro: false
          name: ichitaka
          type: user
        html: '<p>Maybe try an older version. Huggingface documentation uses<br>bitsandbytes==0.38.0.post1</p>

          '
        raw: "Maybe try an older version. Huggingface documentation uses \nbitsandbytes==0.38.0.post1"
        updatedAt: '2023-07-06T15:04:52.994Z'
      numEdits: 0
      reactions: []
    id: 64a6d814bc33d16e6584d849
    type: comment
  author: ichitaka
  content: "Maybe try an older version. Huggingface documentation uses \nbitsandbytes==0.38.0.post1"
  created_at: 2023-07-06 14:04:52+00:00
  edited: false
  hidden: false
  id: 64a6d814bc33d16e6584d849
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
      fullname: Michael O'Mahony
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: michaelomahony
      type: user
    createdAt: '2023-07-06T15:05:42.000Z'
    data:
      edited: false
      editors:
      - michaelomahony
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9948187470436096
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
          fullname: Michael O'Mahony
          isHf: false
          isPro: false
          name: michaelomahony
          type: user
        html: '<p>Okay, I''ll try that. Thanks!</p>

          '
        raw: Okay, I'll try that. Thanks!
        updatedAt: '2023-07-06T15:05:42.097Z'
      numEdits: 0
      reactions: []
    id: 64a6d846849d2222ee1ff433
    type: comment
  author: michaelomahony
  content: Okay, I'll try that. Thanks!
  created_at: 2023-07-06 14:05:42+00:00
  edited: false
  hidden: false
  id: 64a6d846849d2222ee1ff433
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
      fullname: Michael O'Mahony
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: michaelomahony
      type: user
    createdAt: '2023-07-06T16:25:51.000Z'
    data:
      edited: false
      editors:
      - michaelomahony
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7271130084991455
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
          fullname: Michael O'Mahony
          isHf: false
          isPro: false
          name: michaelomahony
          type: user
        html: '<p>Yeah, setting bitsandbytes to version 0.38.0.post1 fixed my issue</p>

          '
        raw: Yeah, setting bitsandbytes to version 0.38.0.post1 fixed my issue
        updatedAt: '2023-07-06T16:25:51.888Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - SaffalPoosh
    id: 64a6eb0faa636af859786c70
    type: comment
  author: michaelomahony
  content: Yeah, setting bitsandbytes to version 0.38.0.post1 fixed my issue
  created_at: 2023-07-06 15:25:51+00:00
  edited: false
  hidden: false
  id: 64a6eb0faa636af859786c70
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/2704aa0f012d94f88c349c532eb403cb.svg
      fullname: T T
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ichitaka
      type: user
    createdAt: '2023-07-06T16:26:42.000Z'
    data:
      status: closed
    id: 64a6eb42c10593f0054dd72c
    type: status-change
  author: ichitaka
  created_at: 2023-07-06 15:26:42+00:00
  id: 64a6eb42c10593f0054dd72c
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: ichitaka/falcon-40b-instruct-8bit
repo_type: model
status: closed
target_branch: null
title: How  did you manage to quantize the model?
