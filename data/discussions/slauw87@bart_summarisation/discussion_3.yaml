!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pritish
conflicting_files: null
created_at: 2023-06-30 06:27:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62258acf8dc6b0b64f5e90f4/FlfLotuGE5KL-uzvAaQnb.png?w=200&h=200&f=face
      fullname: Pritish Mishra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pritish
      type: user
    createdAt: '2023-06-30T07:27:08.000Z'
    data:
      edited: false
      editors:
      - pritish
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6649872660636902
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62258acf8dc6b0b64f5e90f4/FlfLotuGE5KL-uzvAaQnb.png?w=200&h=200&f=face
          fullname: Pritish Mishra
          isHf: false
          isPro: false
          name: pritish
          type: user
        html: '<p>Whenever I run this line of code:</p>

          <pre><code>summarizer = pipeline("summarization", model="slauw87/bart-large-cnn-samsum")

          </code></pre>

          <p>I get this error:</p>

          <pre><code>OSError: slauw87/bart-large-cnn-samsum does not appear to have
          a file named config.json. Checkout ''https://huggingface.co/slauw87/bart-large-cnn-samsum/main''
          for available files.

          </code></pre>

          <p>Please Help!!!</p>

          '
        raw: "Whenever I run this line of code:\r\n\r\n```\r\nsummarizer = pipeline(\"\
          summarization\", model=\"slauw87/bart-large-cnn-samsum\")\r\n```\r\n\r\n\
          I get this error:\r\n\r\n```\r\nOSError: slauw87/bart-large-cnn-samsum does\
          \ not appear to have a file named config.json. Checkout 'https://huggingface.co/slauw87/bart-large-cnn-samsum/main'\
          \ for available files.\r\n```\r\n\r\nPlease Help!!!"
        updatedAt: '2023-06-30T07:27:08.439Z'
      numEdits: 0
      reactions: []
    id: 649e83cc2ccae3ea1f35d0d7
    type: comment
  author: pritish
  content: "Whenever I run this line of code:\r\n\r\n```\r\nsummarizer = pipeline(\"\
    summarization\", model=\"slauw87/bart-large-cnn-samsum\")\r\n```\r\n\r\nI get\
    \ this error:\r\n\r\n```\r\nOSError: slauw87/bart-large-cnn-samsum does not appear\
    \ to have a file named config.json. Checkout 'https://huggingface.co/slauw87/bart-large-cnn-samsum/main'\
    \ for available files.\r\n```\r\n\r\nPlease Help!!!"
  created_at: 2023-06-30 06:27:08+00:00
  edited: false
  hidden: false
  id: 649e83cc2ccae3ea1f35d0d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62258acf8dc6b0b64f5e90f4/FlfLotuGE5KL-uzvAaQnb.png?w=200&h=200&f=face
      fullname: Pritish Mishra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pritish
      type: user
    createdAt: '2023-07-01T07:05:39.000Z'
    data:
      edited: false
      editors:
      - pritish
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3641951084136963
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62258acf8dc6b0b64f5e90f4/FlfLotuGE5KL-uzvAaQnb.png?w=200&h=200&f=face
          fullname: Pritish Mishra
          isHf: false
          isPro: false
          name: pritish
          type: user
        html: "<p>I solved  this error. If you want to use this model try this code:</p>\n\
          <pre><code>from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\
          \n# load the tokenizer and summarizer\ntokenizer = AutoTokenizer.from_pretrained(\"\
          slauw87/bart_summarisation\")\nsummarizer = AutoModelForSeq2SeqLM.from_pretrained(\"\
          slauw87/bart_summarisation\")\n\n# use gpu\nsummarizer = summarizer.to('cuda')\n\
          \ndef summarizer(text, summary_max_length):\n    inputs = tokenizer(\n \
          \       text,\n        return_tensors='pt',\n        padding=True\n    )['input_ids'].to('cuda')\n\
          \n    summary_ids = summarizer.generate(\n        inputs, \n        max_length=summary_max_length,\n\
          \        length_penalty=3.0,\n        num_beams=2\n    )\n\n    summary\
          \ =  tokenizer.decode(\n                summary_ids[0] , \n            \
          \    skip_special_tokens=True, \n                clean_up_tokenization_spaces=False\n\
          \    )\n\n    return summary\n\noutput = summarizer(\"long text here\")\n\
          </code></pre>\n"
        raw: "I solved  this error. If you want to use this model try this code:\n\
          \n```\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n\
          # load the tokenizer and summarizer\ntokenizer = AutoTokenizer.from_pretrained(\"\
          slauw87/bart_summarisation\")\nsummarizer = AutoModelForSeq2SeqLM.from_pretrained(\"\
          slauw87/bart_summarisation\")\n\n# use gpu\nsummarizer = summarizer.to('cuda')\n\
          \ndef summarizer(text, summary_max_length):\n    inputs = tokenizer(\n \
          \       text,\n        return_tensors='pt',\n        padding=True\n    )['input_ids'].to('cuda')\n\
          \n    summary_ids = summarizer.generate(\n        inputs, \n        max_length=summary_max_length,\n\
          \        length_penalty=3.0,\n        num_beams=2\n    )\n\n    summary\
          \ =  tokenizer.decode(\n                summary_ids[0] , \n            \
          \    skip_special_tokens=True, \n                clean_up_tokenization_spaces=False\n\
          \    )\n\n    return summary\n\noutput = summarizer(\"long text here\")\n\
          ```"
        updatedAt: '2023-07-01T07:05:39.252Z'
      numEdits: 0
      reactions: []
    id: 649fd0439d0d8fabee72e7b7
    type: comment
  author: pritish
  content: "I solved  this error. If you want to use this model try this code:\n\n\
    ```\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# load the\
    \ tokenizer and summarizer\ntokenizer = AutoTokenizer.from_pretrained(\"slauw87/bart_summarisation\"\
    )\nsummarizer = AutoModelForSeq2SeqLM.from_pretrained(\"slauw87/bart_summarisation\"\
    )\n\n# use gpu\nsummarizer = summarizer.to('cuda')\n\ndef summarizer(text, summary_max_length):\n\
    \    inputs = tokenizer(\n        text,\n        return_tensors='pt',\n      \
    \  padding=True\n    )['input_ids'].to('cuda')\n\n    summary_ids = summarizer.generate(\n\
    \        inputs, \n        max_length=summary_max_length,\n        length_penalty=3.0,\n\
    \        num_beams=2\n    )\n\n    summary =  tokenizer.decode(\n            \
    \    summary_ids[0] , \n                skip_special_tokens=True, \n         \
    \       clean_up_tokenization_spaces=False\n    )\n\n    return summary\n\noutput\
    \ = summarizer(\"long text here\")\n```"
  created_at: 2023-07-01 06:05:39+00:00
  edited: false
  hidden: false
  id: 649fd0439d0d8fabee72e7b7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: slauw87/bart_summarisation
repo_type: model
status: open
target_branch: null
title: Error when loading model
