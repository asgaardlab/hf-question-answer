!!python/object:huggingface_hub.community.DiscussionWithDetails
author: staviq
conflicting_files: null
created_at: 2023-07-25 16:00:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9b794f0fe77bece69110fd634154f339.svg
      fullname: GST
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: staviq
      type: user
    createdAt: '2023-07-25T17:00:10.000Z'
    data:
      edited: false
      editors:
      - staviq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9194808602333069
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9b794f0fe77bece69110fd634154f339.svg
          fullname: GST
          isHf: false
          isPro: false
          name: staviq
          type: user
        html: '<p>Hi. There is a lot of confusing info floating around about prompt
          formats and llama2 ( from a beginner perspective at least)</p>

          <p>From what I understand, Llama2 was trained with a specific conversation
          "flow" format, utilising SYS/ INS tags, etc.</p>

          <p>The description of this model suggests a different "template".</p>

          <p>Does this mean, this particular model overrides the training of base
          llama2 model, and those SYS etc tags are not required ?</p>

          <p>Or does this mean, both "templates" will work, and llama2 template will
          "trigger" responses coming from the base model, and suggested here "###
          human:" etc prompts will trigger responses utilising what this particular
          model adds on top of base llama2 model ?</p>

          <p>Is it possible/necessary to use both of those prompt formats at the same
          time/interchangeably ?</p>

          <p>I''m trying to construct a UI that would allow for conversation with
          the AI as well as an imaginary character that AI will impersonate, in the
          same conversation, allowing the user to refer to either the AI or the character.</p>

          <p>So far, I''m getting stuck in a situation where the conversation gets
          off the rails and model starts to produce output incoherent with the conversation,
          talking to itself, spawning additional characters, or even worse, perceiving
          conversation template tags as a part of the conversation and inventing random
          keywords as if it''s a code snippet to be completed.</p>

          <p>I would greatly appreciate if anybody could clarify this "conversation
          template" situation.</p>

          '
        raw: "Hi. There is a lot of confusing info floating around about prompt formats\
          \ and llama2 ( from a beginner perspective at least)\r\n\r\nFrom what I\
          \ understand, Llama2 was trained with a specific conversation \"flow\" format,\
          \ utilising SYS/ INS tags, etc.\r\n\r\nThe description of this model suggests\
          \ a different \"template\".\r\n\r\nDoes this mean, this particular model\
          \ overrides the training of base llama2 model, and those SYS etc tags are\
          \ not required ?\r\n\r\nOr does this mean, both \"templates\" will work,\
          \ and llama2 template will \"trigger\" responses coming from the base model,\
          \ and suggested here \"### human:\" etc prompts will trigger responses utilising\
          \ what this particular model adds on top of base llama2 model ?\r\n\r\n\
          Is it possible/necessary to use both of those prompt formats at the same\
          \ time/interchangeably ?\r\n\r\nI'm trying to construct a UI that would\
          \ allow for conversation with the AI as well as an imaginary character that\
          \ AI will impersonate, in the same conversation, allowing the user to refer\
          \ to either the AI or the character.\r\n\r\nSo far, I'm getting stuck in\
          \ a situation where the conversation gets off the rails and model starts\
          \ to produce output incoherent with the conversation, talking to itself,\
          \ spawning additional characters, or even worse, perceiving conversation\
          \ template tags as a part of the conversation and inventing random keywords\
          \ as if it's a code snippet to be completed.\r\n\r\nI would greatly appreciate\
          \ if anybody could clarify this \"conversation template\" situation."
        updatedAt: '2023-07-25T17:00:10.171Z'
      numEdits: 0
      reactions: []
    id: 64bfff9aec07373c12848034
    type: comment
  author: staviq
  content: "Hi. There is a lot of confusing info floating around about prompt formats\
    \ and llama2 ( from a beginner perspective at least)\r\n\r\nFrom what I understand,\
    \ Llama2 was trained with a specific conversation \"flow\" format, utilising SYS/\
    \ INS tags, etc.\r\n\r\nThe description of this model suggests a different \"\
    template\".\r\n\r\nDoes this mean, this particular model overrides the training\
    \ of base llama2 model, and those SYS etc tags are not required ?\r\n\r\nOr does\
    \ this mean, both \"templates\" will work, and llama2 template will \"trigger\"\
    \ responses coming from the base model, and suggested here \"### human:\" etc\
    \ prompts will trigger responses utilising what this particular model adds on\
    \ top of base llama2 model ?\r\n\r\nIs it possible/necessary to use both of those\
    \ prompt formats at the same time/interchangeably ?\r\n\r\nI'm trying to construct\
    \ a UI that would allow for conversation with the AI as well as an imaginary character\
    \ that AI will impersonate, in the same conversation, allowing the user to refer\
    \ to either the AI or the character.\r\n\r\nSo far, I'm getting stuck in a situation\
    \ where the conversation gets off the rails and model starts to produce output\
    \ incoherent with the conversation, talking to itself, spawning additional characters,\
    \ or even worse, perceiving conversation template tags as a part of the conversation\
    \ and inventing random keywords as if it's a code snippet to be completed.\r\n\
    \r\nI would greatly appreciate if anybody could clarify this \"conversation template\"\
    \ situation."
  created_at: 2023-07-25 16:00:10+00:00
  edited: false
  hidden: false
  id: 64bfff9aec07373c12848034
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640356718818-61c47e9c71a107e9d80e33e3.jpeg?w=200&h=200&f=face
      fullname: Henky!!
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Henk717
      type: user
    createdAt: '2023-07-25T18:46:54.000Z'
    data:
      edited: false
      editors:
      - Henk717
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9648988246917725
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640356718818-61c47e9c71a107e9d80e33e3.jpeg?w=200&h=200&f=face
          fullname: Henky!!
          isHf: false
          isPro: false
          name: Henk717
          type: user
        html: '<p>Only the llama2 chat format was trained on that specific format,
          community tuners can pick their own they think is best.<br>So for each model
          check the model card for the most suitable format.</p>

          '
        raw: 'Only the llama2 chat format was trained on that specific format, community
          tuners can pick their own they think is best.

          So for each model check the model card for the most suitable format.'
        updatedAt: '2023-07-25T18:46:54.759Z'
      numEdits: 0
      reactions: []
    id: 64c0189ebf550559c6f5fa52
    type: comment
  author: Henk717
  content: 'Only the llama2 chat format was trained on that specific format, community
    tuners can pick their own they think is best.

    So for each model check the model card for the most suitable format.'
  created_at: 2023-07-25 17:46:54+00:00
  edited: false
  hidden: false
  id: 64c0189ebf550559c6f5fa52
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9b794f0fe77bece69110fd634154f339.svg
      fullname: GST
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: staviq
      type: user
    createdAt: '2023-07-25T18:50:25.000Z'
    data:
      edited: false
      editors:
      - staviq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.978736937046051
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9b794f0fe77bece69110fd634154f339.svg
          fullname: GST
          isHf: false
          isPro: false
          name: staviq
          type: user
        html: '<p>Yes I understand that, but I would like to understand if a tuned
          model adds its own format on top of the base format, or it replaces the
          base format completely with its own.</p>

          '
        raw: Yes I understand that, but I would like to understand if a tuned model
          adds its own format on top of the base format, or it replaces the base format
          completely with its own.
        updatedAt: '2023-07-25T18:50:25.566Z'
      numEdits: 0
      reactions: []
    id: 64c01971afdc3961089563d3
    type: comment
  author: staviq
  content: Yes I understand that, but I would like to understand if a tuned model
    adds its own format on top of the base format, or it replaces the base format
    completely with its own.
  created_at: 2023-07-25 17:50:25+00:00
  edited: false
  hidden: false
  id: 64c01971afdc3961089563d3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640356718818-61c47e9c71a107e9d80e33e3.jpeg?w=200&h=200&f=face
      fullname: Henky!!
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Henk717
      type: user
    createdAt: '2023-07-25T18:51:51.000Z'
    data:
      edited: false
      editors:
      - Henk717
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.986198365688324
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640356718818-61c47e9c71a107e9d80e33e3.jpeg?w=200&h=200&f=face
          fullname: Henky!!
          isHf: false
          isPro: false
          name: Henk717
          type: user
        html: '<p>The base model that typically is being used does not have this format,
          only the meta tuned chat version. So its not so much a matter of replacing
          as it is of just doing the same thing differently.</p>

          '
        raw: The base model that typically is being used does not have this format,
          only the meta tuned chat version. So its not so much a matter of replacing
          as it is of just doing the same thing differently.
        updatedAt: '2023-07-25T18:51:51.551Z'
      numEdits: 0
      reactions: []
    id: 64c019c75a8f5b0d13a607f0
    type: comment
  author: Henk717
  content: The base model that typically is being used does not have this format,
    only the meta tuned chat version. So its not so much a matter of replacing as
    it is of just doing the same thing differently.
  created_at: 2023-07-25 17:51:51+00:00
  edited: false
  hidden: false
  id: 64c019c75a8f5b0d13a607f0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9b794f0fe77bece69110fd634154f339.svg
      fullname: GST
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: staviq
      type: user
    createdAt: '2023-07-25T19:17:30.000Z'
    data:
      edited: false
      editors:
      - staviq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9557891488075256
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9b794f0fe77bece69110fd634154f339.svg
          fullname: GST
          isHf: false
          isPro: false
          name: staviq
          type: user
        html: '<p>Oh, so this model is based on "base" llama2, and only llama2-chat
          uses its weird prompt format, therefore this particular model achieves its
          "chatness" by imprinting its own specific format on a model that was "formatless"
          to begin with?</p>

          <p>Am I understanding this right ?</p>

          '
        raw: 'Oh, so this model is based on "base" llama2, and only llama2-chat uses
          its weird prompt format, therefore this particular model achieves its "chatness"
          by imprinting its own specific format on a model that was "formatless" to
          begin with?


          Am I understanding this right ?'
        updatedAt: '2023-07-25T19:17:30.406Z'
      numEdits: 0
      reactions: []
    id: 64c01fca0a4d02f37a8648b7
    type: comment
  author: staviq
  content: 'Oh, so this model is based on "base" llama2, and only llama2-chat uses
    its weird prompt format, therefore this particular model achieves its "chatness"
    by imprinting its own specific format on a model that was "formatless" to begin
    with?


    Am I understanding this right ?'
  created_at: 2023-07-25 18:17:30+00:00
  edited: false
  hidden: false
  id: 64c01fca0a4d02f37a8648b7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640356718818-61c47e9c71a107e9d80e33e3.jpeg?w=200&h=200&f=face
      fullname: Henky!!
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Henk717
      type: user
    createdAt: '2023-07-26T19:15:02.000Z'
    data:
      edited: false
      editors:
      - Henk717
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7104992866516113
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640356718818-61c47e9c71a107e9d80e33e3.jpeg?w=200&h=200&f=face
          fullname: Henky!!
          isHf: false
          isPro: false
          name: Henk717
          type: user
        html: '<p>Correct yes.</p>

          '
        raw: Correct yes.
        updatedAt: '2023-07-26T19:15:02.043Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - zoigo
        - rocklaw34
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - staviq
    id: 64c170b6c84cd12dd7964597
    type: comment
  author: Henk717
  content: Correct yes.
  created_at: 2023-07-26 18:15:02+00:00
  edited: false
  hidden: false
  id: 64c170b6c84cd12dd7964597
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9b794f0fe77bece69110fd634154f339.svg
      fullname: GST
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: staviq
      type: user
    createdAt: '2023-07-26T19:19:12.000Z'
    data:
      edited: false
      editors:
      - staviq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9947949051856995
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9b794f0fe77bece69110fd634154f339.svg
          fullname: GST
          isHf: false
          isPro: false
          name: staviq
          type: user
        html: '<p>Thank you very much for this clarification, it is very helpful.</p>

          '
        raw: Thank you very much for this clarification, it is very helpful.
        updatedAt: '2023-07-26T19:19:12.027Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - zoigo
    id: 64c171b0576884e0faaec008
    type: comment
  author: staviq
  content: Thank you very much for this clarification, it is very helpful.
  created_at: 2023-07-26 18:19:12+00:00
  edited: false
  hidden: false
  id: 64c171b0576884e0faaec008
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: NousResearch/Redmond-Puffin-13B-GGML
repo_type: model
status: open
target_branch: null
title: Kindly, please help me understand the conversation template format
