!!python/object:huggingface_hub.community.DiscussionWithDetails
author: guido1893
conflicting_files: null
created_at: 2023-10-30 12:54:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d3dfc868a6aa32a3930ce037e20ab58c.svg
      fullname: Guido Schulz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guido1893
      type: user
    createdAt: '2023-10-30T13:54:23.000Z'
    data:
      edited: true
      editors:
      - guido1893
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5541320443153381
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d3dfc868a6aa32a3930ce037e20ab58c.svg
          fullname: Guido Schulz
          isHf: false
          isPro: false
          name: guido1893
          type: user
        html: "<p>I'm using <code>T-Systems-onsite/cross-en-de-roberta-sentence-transformer</code>\
          \ as the embedding model for creating a <a rel=\"nofollow\" href=\"https://github.com/imartinez/privateGPT/blob/main/settings.yaml\"\
          >privateGPT chatbot</a>.</p>\n<p>My setup is </p>\n<div class=\"max-w-full\
          \ overflow-auto\">\n\t<table>\n\t\t<thead><tr>\n<th>privateGPT Setup</th>\n\
          <th>Used/Parameter</th>\n</tr>\n\n\t\t</thead><tbody><tr>\n<td>Hardware</td>\n\
          <td>Ubuntu Server with 48 CPUs</td>\n</tr>\n<tr>\n<td>Source Documents</td>\n\
          <td>One PDF, around 100pages</td>\n</tr>\n<tr>\n<td><code>llm_hf_repo_id</code></td>\n\
          <td><code>TheBloke/Leo-Mistral-Hessianai-7B-Chat-GGUF</code></td>\n</tr>\n\
          <tr>\n<td><code>llm_hf_model_file</code></td>\n<td><code>leo-mistral-hessianai-7b-chat.Q4_K_M.gguf</code></td>\n\
          </tr>\n<tr>\n<td><code>embedding_hf_model_name</code></td>\n<td><code>T-Systems-onsite/cross-en-de-roberta-sentence-transformer</code></td>\n\
          </tr>\n</tbody>\n\t</table>\n</div>\n<p>Now, my problem is: </p>\n<p>When\
          \ I ingest the <code>.pdf</code> file creating the embeddings, after around\
          \ 70% of the ingestion, I run into the following error:</p>\n<pre><code>\
          \ File \"/*****/.cache/pypoetry/virtualenvs/private-gpt-igPs2cci-py3.11/lib/python3.11/site-packages/torch/nn/functional.py\"\
          , line 2233, in embedding\n    return torch.embedding(weight, input, padding_idx,\
          \ scale_grad_by_freq, sparse)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          IndexError: index out of range in self\n</code></pre>\n<p>Does that mean\
          \ that <code>T-Systems-onsite/cross-en-de-roberta-sentence-transformer</code>\
          \ cannot handle long pdfs?<br>Or do I need to set some parameters/options?<br>Is\
          \ this a problem of <code>privateGPT</code> of <code>T-Systems-onsite/cross-en-de-roberta-sentence-transformer</code>?</p>\n"
        raw: "I'm using `T-Systems-onsite/cross-en-de-roberta-sentence-transformer`\
          \ as the embedding model for creating a [privateGPT chatbot](https://github.com/imartinez/privateGPT/blob/main/settings.yaml).\n\
          \nMy setup is \n\n| privateGPT Setup   | Used/Parameter                \
          \            |\n|--------------------|----------------------------------|\n\
          | Hardware           | Ubuntu Server with 48 CPUs                |\n| Source\
          \ Documents   | One PDF, around 100pages          | \n| `llm_hf_repo_id`\
          \   | `TheBloke/Leo-Mistral-Hessianai-7B-Chat-GGUF`  |\n| `llm_hf_model_file`|\
          \ `leo-mistral-hessianai-7b-chat.Q4_K_M.gguf`    |\n| `embedding_hf_model_name`\
          \ | `T-Systems-onsite/cross-en-de-roberta-sentence-transformer`  |\n\nNow,\
          \ my problem is: \n\nWhen I ingest the `.pdf` file creating the embeddings,\
          \ after around 70% of the ingestion, I run into the following error:\n\n\
          ```\n File \"/*****/.cache/pypoetry/virtualenvs/private-gpt-igPs2cci-py3.11/lib/python3.11/site-packages/torch/nn/functional.py\"\
          , line 2233, in embedding\n    return torch.embedding(weight, input, padding_idx,\
          \ scale_grad_by_freq, sparse)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          IndexError: index out of range in self\n```\n\nDoes that mean that `T-Systems-onsite/cross-en-de-roberta-sentence-transformer`\
          \ cannot handle long pdfs? \nOr do I need to set some parameters/options?\
          \ \nIs this a problem of `privateGPT` of `T-Systems-onsite/cross-en-de-roberta-sentence-transformer`?"
        updatedAt: '2023-10-30T13:57:08.113Z'
      numEdits: 1
      reactions: []
    id: 653fb58f62203e4bffe92822
    type: comment
  author: guido1893
  content: "I'm using `T-Systems-onsite/cross-en-de-roberta-sentence-transformer`\
    \ as the embedding model for creating a [privateGPT chatbot](https://github.com/imartinez/privateGPT/blob/main/settings.yaml).\n\
    \nMy setup is \n\n| privateGPT Setup   | Used/Parameter                      \
    \      |\n|--------------------|----------------------------------|\n| Hardware\
    \           | Ubuntu Server with 48 CPUs                |\n| Source Documents\
    \   | One PDF, around 100pages          | \n| `llm_hf_repo_id`   | `TheBloke/Leo-Mistral-Hessianai-7B-Chat-GGUF`\
    \  |\n| `llm_hf_model_file`| `leo-mistral-hessianai-7b-chat.Q4_K_M.gguf`    |\n\
    | `embedding_hf_model_name` | `T-Systems-onsite/cross-en-de-roberta-sentence-transformer`\
    \  |\n\nNow, my problem is: \n\nWhen I ingest the `.pdf` file creating the embeddings,\
    \ after around 70% of the ingestion, I run into the following error:\n\n```\n\
    \ File \"/*****/.cache/pypoetry/virtualenvs/private-gpt-igPs2cci-py3.11/lib/python3.11/site-packages/torch/nn/functional.py\"\
    , line 2233, in embedding\n    return torch.embedding(weight, input, padding_idx,\
    \ scale_grad_by_freq, sparse)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
    IndexError: index out of range in self\n```\n\nDoes that mean that `T-Systems-onsite/cross-en-de-roberta-sentence-transformer`\
    \ cannot handle long pdfs? \nOr do I need to set some parameters/options? \nIs\
    \ this a problem of `privateGPT` of `T-Systems-onsite/cross-en-de-roberta-sentence-transformer`?"
  created_at: 2023-10-30 12:54:23+00:00
  edited: true
  hidden: false
  id: 653fb58f62203e4bffe92822
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595445065015-noauth.png?w=200&h=200&f=face
      fullname: Philip May
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: PhilipMay
      type: user
    createdAt: '2023-12-07T18:34:17.000Z'
    data:
      edited: false
      editors:
      - PhilipMay
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8851004838943481
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595445065015-noauth.png?w=200&h=200&f=face
          fullname: Philip May
          isHf: false
          isPro: false
          name: PhilipMay
          type: user
        html: '<p>Can you please use Sentence Transformers to load this model and
          do some tests?<br>Code can be found here: <a rel="nofollow" href="https://www.sbert.net/docs/usage/semantic_textual_similarity.html">https://www.sbert.net/docs/usage/semantic_textual_similarity.html</a></p>

          <p>I guess this is an issue specific to privateGPT.</p>

          <p>Hope that helps. If you still have problems please give me code to to
          reproduce the error.</p>

          '
        raw: 'Can you please use Sentence Transformers to load this model and do some
          tests?

          Code can be found here: https://www.sbert.net/docs/usage/semantic_textual_similarity.html


          I guess this is an issue specific to privateGPT.


          Hope that helps. If you still have problems please give me code to to reproduce
          the error.'
        updatedAt: '2023-12-07T18:34:17.232Z'
      numEdits: 0
      reactions: []
    id: 657210297f2f590839ef1ce3
    type: comment
  author: PhilipMay
  content: 'Can you please use Sentence Transformers to load this model and do some
    tests?

    Code can be found here: https://www.sbert.net/docs/usage/semantic_textual_similarity.html


    I guess this is an issue specific to privateGPT.


    Hope that helps. If you still have problems please give me code to to reproduce
    the error.'
  created_at: 2023-12-07 18:34:17+00:00
  edited: false
  hidden: false
  id: 657210297f2f590839ef1ce3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: T-Systems-onsite/cross-en-de-roberta-sentence-transformer
repo_type: model
status: open
target_branch: null
title: '`IndexError: index out of range in self` when creating embeddings'
