!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lthamm
conflicting_files: null
created_at: 2023-06-28 11:12:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f125a29a1edbadf11a3ff8b0e054508d.svg
      fullname: Lennart Thamm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lthamm
      type: user
    createdAt: '2023-06-28T12:12:33.000Z'
    data:
      edited: false
      editors:
      - lthamm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9037010669708252
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f125a29a1edbadf11a3ff8b0e054508d.svg
          fullname: Lennart Thamm
          isHf: false
          isPro: false
          name: lthamm
          type: user
        html: "<p>I hope this not to be a question with a very obvious answer, but\
          \ how much context does this model actually use / been trained on?<br>RoBERTa\
          \ has a maximum context length of 512 tokens (minus some reserved tokens)\
          \ and when I load the model and check <code>model.max_seq_length</code>\
          \ it is indeed 512 tokens.</p>\n<p>However in the sentence_bert_config.json\
          \ I find </p>\n<pre><code>{\n  \"max_seq_length\": 128\n}\n</code></pre>\n\
          <p>Thank you for opensourcing this great model!</p>\n"
        raw: "I hope this not to be a question with a very obvious answer, but how\
          \ much context does this model actually use / been trained on?\r\nRoBERTa\
          \ has a maximum context length of 512 tokens (minus some reserved tokens)\
          \ and when I load the model and check `model.max_seq_length` it is indeed\
          \ 512 tokens.\r\n\r\nHowever in the sentence_bert_config.json I find \r\n\
          ```\r\n{\r\n  \"max_seq_length\": 128\r\n}\r\n```\r\n\r\nThank you for opensourcing\
          \ this great model!"
        updatedAt: '2023-06-28T12:12:33.990Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - PhilipMay
    id: 649c23b19e0f87ceedea1b7a
    type: comment
  author: lthamm
  content: "I hope this not to be a question with a very obvious answer, but how much\
    \ context does this model actually use / been trained on?\r\nRoBERTa has a maximum\
    \ context length of 512 tokens (minus some reserved tokens) and when I load the\
    \ model and check `model.max_seq_length` it is indeed 512 tokens.\r\n\r\nHowever\
    \ in the sentence_bert_config.json I find \r\n```\r\n{\r\n  \"max_seq_length\"\
    : 128\r\n}\r\n```\r\n\r\nThank you for opensourcing this great model!"
  created_at: 2023-06-28 11:12:33+00:00
  edited: false
  hidden: false
  id: 649c23b19e0f87ceedea1b7a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595445065015-noauth.png?w=200&h=200&f=face
      fullname: Philip May
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: PhilipMay
      type: user
    createdAt: '2023-06-28T17:48:25.000Z'
    data:
      edited: false
      editors:
      - PhilipMay
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9929191470146179
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595445065015-noauth.png?w=200&h=200&f=face
          fullname: Philip May
          isHf: false
          isPro: false
          name: PhilipMay
          type: user
        html: '<p>Yes. It is not the full 512. It was 128.</p>

          '
        raw: Yes. It is not the full 512. It was 128.
        updatedAt: '2023-06-28T17:48:25.554Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - lthamm
      - count: 1
        reaction: "\U0001F44D"
        users:
        - lthamm
    id: 649c726978fe1d064b05e722
    type: comment
  author: PhilipMay
  content: Yes. It is not the full 512. It was 128.
  created_at: 2023-06-28 16:48:25+00:00
  edited: false
  hidden: false
  id: 649c726978fe1d064b05e722
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595445065015-noauth.png?w=200&h=200&f=face
      fullname: Philip May
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: PhilipMay
      type: user
    createdAt: '2023-06-28T17:49:05.000Z'
    data:
      edited: false
      editors:
      - PhilipMay
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8947182893753052
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595445065015-noauth.png?w=200&h=200&f=face
          fullname: Philip May
          isHf: false
          isPro: false
          name: PhilipMay
          type: user
        html: '<p>Does this answer your question?<br>If yes - please close this again.</p>

          <p>Many thanks<br>Philip</p>

          '
        raw: 'Does this answer your question?

          If yes - please close this again.


          Many thanks

          Philip'
        updatedAt: '2023-06-28T17:49:05.547Z'
      numEdits: 0
      reactions: []
    id: 649c7291a74b6dbfe638818d
    type: comment
  author: PhilipMay
  content: 'Does this answer your question?

    If yes - please close this again.


    Many thanks

    Philip'
  created_at: 2023-06-28 16:49:05+00:00
  edited: false
  hidden: false
  id: 649c7291a74b6dbfe638818d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f125a29a1edbadf11a3ff8b0e054508d.svg
      fullname: Lennart Thamm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lthamm
      type: user
    createdAt: '2023-06-29T07:13:49.000Z'
    data:
      edited: false
      editors:
      - lthamm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9016438722610474
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f125a29a1edbadf11a3ff8b0e054508d.svg
          fullname: Lennart Thamm
          isHf: false
          isPro: false
          name: lthamm
          type: user
        html: '<p>This helps a lot! </p>

          <p>Just to be clear: What exactly happens when I pass in an input longer
          than 128 tokens?<br>As model.max_seq_length says 512, will it just work
          with the input but with worse quality?<br>Or will it actually truncate the
          input?</p>

          '
        raw: "This helps a lot! \n\nJust to be clear: What exactly happens when I\
          \ pass in an input longer than 128 tokens? \nAs model.max_seq_length says\
          \ 512, will it just work with the input but with worse quality?\nOr will\
          \ it actually truncate the input?"
        updatedAt: '2023-06-29T07:13:49.477Z'
      numEdits: 0
      reactions: []
    id: 649d2f2d1bafbcc83acd021d
    type: comment
  author: lthamm
  content: "This helps a lot! \n\nJust to be clear: What exactly happens when I pass\
    \ in an input longer than 128 tokens? \nAs model.max_seq_length says 512, will\
    \ it just work with the input but with worse quality?\nOr will it actually truncate\
    \ the input?"
  created_at: 2023-06-29 06:13:49+00:00
  edited: false
  hidden: false
  id: 649d2f2d1bafbcc83acd021d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595445065015-noauth.png?w=200&h=200&f=face
      fullname: Philip May
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: PhilipMay
      type: user
    createdAt: '2023-06-29T11:47:41.000Z'
    data:
      edited: false
      editors:
      - PhilipMay
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9980282783508301
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595445065015-noauth.png?w=200&h=200&f=face
          fullname: Philip May
          isHf: false
          isPro: false
          name: PhilipMay
          type: user
        html: '<p>I think it will not crash. It will also not truncate as far as I
          know.<br>My guess is that the quality is just degraded.</p>

          '
        raw: 'I think it will not crash. It will also not truncate as far as I know.

          My guess is that the quality is just degraded.'
        updatedAt: '2023-06-29T11:47:41.838Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - lthamm
    id: 649d6f5d8dbd641ddbba63b7
    type: comment
  author: PhilipMay
  content: 'I think it will not crash. It will also not truncate as far as I know.

    My guess is that the quality is just degraded.'
  created_at: 2023-06-29 10:47:41+00:00
  edited: false
  hidden: false
  id: 649d6f5d8dbd641ddbba63b7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f125a29a1edbadf11a3ff8b0e054508d.svg
      fullname: Lennart Thamm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lthamm
      type: user
    createdAt: '2023-06-29T12:39:52.000Z'
    data:
      edited: false
      editors:
      - lthamm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7999588847160339
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f125a29a1edbadf11a3ff8b0e054508d.svg
          fullname: Lennart Thamm
          isHf: false
          isPro: false
          name: lthamm
          type: user
        html: "<p>Thank you!<br>If anyone should come across this: While everything\
          \ between 128 and 512 tokens might or might not be truncated, everything\
          \ above 512 definitely will<br>(<a rel=\"nofollow\" href=\"https://github.com/UKPLab/sentence-transformers/issues/181\"\
          >https://github.com/UKPLab/sentence-transformers/issues/181</a>). </p>\n\
          <p>GOATransformers \U0001F410</p>\n"
        raw: "Thank you!\nIf anyone should come across this: While everything between\
          \ 128 and 512 tokens might or might not be truncated, everything above 512\
          \ definitely will\n(https://github.com/UKPLab/sentence-transformers/issues/181).\
          \ \n\nGOATransformers \U0001F410"
        updatedAt: '2023-06-29T12:39:52.773Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - PhilipMay
      relatedEventId: 649d7b98271b9b95f012a4c2
    id: 649d7b98271b9b95f012a4c1
    type: comment
  author: lthamm
  content: "Thank you!\nIf anyone should come across this: While everything between\
    \ 128 and 512 tokens might or might not be truncated, everything above 512 definitely\
    \ will\n(https://github.com/UKPLab/sentence-transformers/issues/181). \n\nGOATransformers\
    \ \U0001F410"
  created_at: 2023-06-29 11:39:52+00:00
  edited: false
  hidden: false
  id: 649d7b98271b9b95f012a4c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f125a29a1edbadf11a3ff8b0e054508d.svg
      fullname: Lennart Thamm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lthamm
      type: user
    createdAt: '2023-06-29T12:39:52.000Z'
    data:
      status: closed
    id: 649d7b98271b9b95f012a4c2
    type: status-change
  author: lthamm
  created_at: 2023-06-29 11:39:52+00:00
  id: 649d7b98271b9b95f012a4c2
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: T-Systems-onsite/cross-en-de-roberta-sentence-transformer
repo_type: model
status: closed
target_branch: null
title: Maximum context length actually used by the model
