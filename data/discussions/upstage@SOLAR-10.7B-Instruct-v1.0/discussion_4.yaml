!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Phil337
conflicting_files: null
created_at: 2023-12-13 18:45:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-13T18:45:01.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9787619113922119
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>I''m very impressed with this LLM. However, it stubbornly denies
          commonly known and unquestionable truths in order to achieve a TruthfulIQ
          over 70. This goes well beyond throwing the baby out with the bathwater.</p>

          <p>For example, one of my censorship test questions is how many movies did
          the actress ___ appear nude or topless in. The actress in question had 10
          such scenes, but this LLM said their was only 1. And when I provided another
          scene and asked for more it stubbornly denied the example and insisted there
          was only 1.</p>

          <p>This LLM throws out about 10x more undeniably true and commonly known
          facts (100s of millions of people know) in order to reduce falsehoods/hallucinations
          by perhaps 25%. This is nowhere near a reasonable compromise. I have a little
          offline copy of Wikipedia that can correctly answer nearly all the questions
          this LLM adamantly denies is true.</p>

          <p>In short, there is something special about this LLM, but claiming 10
          undeniably TRUE and widely known things are false to avoid saying 1 false
          things is true isn''t a reasonable compromise. This LLM is less than useless
          as a reference.</p>

          <p>Note: The scene in the example above was correctly described. That''s
          one of the reasons this LLM is special. All other Mistral based LLMs described
          it wrong. So when it gets the facts right, they''re more right. If that
          makes sense.</p>

          '
        raw: "I'm very impressed with this LLM. However, it stubbornly denies commonly\
          \ known and unquestionable truths in order to achieve a TruthfulIQ over\
          \ 70. This goes well beyond throwing the baby out with the bathwater.\r\n\
          \r\nFor example, one of my censorship test questions is how many movies\
          \ did the actress ___ appear nude or topless in. The actress in question\
          \ had 10 such scenes, but this LLM said their was only 1. And when I provided\
          \ another scene and asked for more it stubbornly denied the example and\
          \ insisted there was only 1.\r\n\r\nThis LLM throws out about 10x more undeniably\
          \ true and commonly known facts (100s of millions of people know) in order\
          \ to reduce falsehoods/hallucinations by perhaps 25%. This is nowhere near\
          \ a reasonable compromise. I have a little offline copy of Wikipedia that\
          \ can correctly answer nearly all the questions this LLM adamantly denies\
          \ is true.\r\n\r\nIn short, there is something special about this LLM, but\
          \ claiming 10 undeniably TRUE and widely known things are false to avoid\
          \ saying 1 false things is true isn't a reasonable compromise. This LLM\
          \ is less than useless as a reference.\r\n\r\nNote: The scene in the example\
          \ above was correctly described. That's one of the reasons this LLM is special.\
          \ All other Mistral based LLMs described it wrong. So when it gets the facts\
          \ right, they're more right. If that makes sense.\r\n"
        updatedAt: '2023-12-13T18:45:01.887Z'
      numEdits: 0
      reactions: []
    id: 6579fbad27dc66cbed1f8597
    type: comment
  author: Phil337
  content: "I'm very impressed with this LLM. However, it stubbornly denies commonly\
    \ known and unquestionable truths in order to achieve a TruthfulIQ over 70. This\
    \ goes well beyond throwing the baby out with the bathwater.\r\n\r\nFor example,\
    \ one of my censorship test questions is how many movies did the actress ___ appear\
    \ nude or topless in. The actress in question had 10 such scenes, but this LLM\
    \ said their was only 1. And when I provided another scene and asked for more\
    \ it stubbornly denied the example and insisted there was only 1.\r\n\r\nThis\
    \ LLM throws out about 10x more undeniably true and commonly known facts (100s\
    \ of millions of people know) in order to reduce falsehoods/hallucinations by\
    \ perhaps 25%. This is nowhere near a reasonable compromise. I have a little offline\
    \ copy of Wikipedia that can correctly answer nearly all the questions this LLM\
    \ adamantly denies is true.\r\n\r\nIn short, there is something special about\
    \ this LLM, but claiming 10 undeniably TRUE and widely known things are false\
    \ to avoid saying 1 false things is true isn't a reasonable compromise. This LLM\
    \ is less than useless as a reference.\r\n\r\nNote: The scene in the example above\
    \ was correctly described. That's one of the reasons this LLM is special. All\
    \ other Mistral based LLMs described it wrong. So when it gets the facts right,\
    \ they're more right. If that makes sense.\r\n"
  created_at: 2023-12-13 18:45:01+00:00
  edited: false
  hidden: false
  id: 6579fbad27dc66cbed1f8597
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
      fullname: Thiago de Arruda Padilha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarruda
      type: user
    createdAt: '2023-12-13T19:07:06.000Z'
    data:
      edited: false
      editors:
      - tarruda
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9746391773223877
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
          fullname: Thiago de Arruda Padilha
          isHf: false
          isPro: false
          name: tarruda
          type: user
        html: '<p>This model also seems good at reasoning. I tried the Orca 2 paper
          reasoning challenge multiple times and it seems to always get the response
          right:</p>

          <pre><code>John and Mark are in a room with a ball, a basket and a box.
          John puts the ball in the box, then leaves for work. While John is away,
          Mark puts the ball in the basket, and then leaves for school. They both
          come back together later in the day, and they do not know what happened
          in the room after each of them left the room. Where do they think the ball
          is?

          </code></pre>

          <p>One thing I really loved is that the Q4_K_M GGUF version completely fits
          in a 8GB VRAM GPU!</p>

          <p>There''s a lot of potential for this model, especially if it is trained
          for multi-turn conversation and function calling is implemented. </p>

          '
        raw: 'This model also seems good at reasoning. I tried the Orca 2 paper reasoning
          challenge multiple times and it seems to always get the response right:


          ```

          John and Mark are in a room with a ball, a basket and a box. John puts the
          ball in the box, then leaves for work. While John is away, Mark puts the
          ball in the basket, and then leaves for school. They both come back together
          later in the day, and they do not know what happened in the room after each
          of them left the room. Where do they think the ball is?

          ```


          One thing I really loved is that the Q4_K_M GGUF version completely fits
          in a 8GB VRAM GPU!


          There''s a lot of potential for this model, especially if it is trained
          for multi-turn conversation and function calling is implemented. '
        updatedAt: '2023-12-13T19:07:06.970Z'
      numEdits: 0
      reactions: []
    id: 657a00da47ae87ca728360b2
    type: comment
  author: tarruda
  content: 'This model also seems good at reasoning. I tried the Orca 2 paper reasoning
    challenge multiple times and it seems to always get the response right:


    ```

    John and Mark are in a room with a ball, a basket and a box. John puts the ball
    in the box, then leaves for work. While John is away, Mark puts the ball in the
    basket, and then leaves for school. They both come back together later in the
    day, and they do not know what happened in the room after each of them left the
    room. Where do they think the ball is?

    ```


    One thing I really loved is that the Q4_K_M GGUF version completely fits in a
    8GB VRAM GPU!


    There''s a lot of potential for this model, especially if it is trained for multi-turn
    conversation and function calling is implemented. '
  created_at: 2023-12-13 19:07:06+00:00
  edited: false
  hidden: false
  id: 657a00da47ae87ca728360b2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-13T19:31:22.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9666695594787598
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;tarruda&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/tarruda\">@<span class=\"\
          underline\">tarruda</span></a></span>\n\n\t</span></span> You're not lying.\
          \ I'm still finishing up my test on it. But it's doing things other Mistrals\
          \ can't. Like you said, it's \"smarter\".</p>\n<p>For example, I ask the\
          \ LLM to make a joke about 2 disparate things (e.g. cat and a telescope),\
          \ start with a random header, such as \"Out in a field\", and then explain\
          \ itself (all with the same prompt). And this LLM made coherent and slightly\
          \ humerus jokes and correctly explained why they were funny.</p>\n<p>Another\
          \ example is prompting a poem type (e.g. sonnet) with several directives\
          \ it must follow. This is hard because it has to follow rhythm, meter...\
          \ while remaining coherent and including the prompt directives.</p>\n<p>In\
          \ short, this is better than 7b Mistrals. I thought this was a hoax when\
          \ I saw it so high on the leaderboard. This is not a hoax.</p>\n"
        raw: '@tarruda You''re not lying. I''m still finishing up my test on it. But
          it''s doing things other Mistrals can''t. Like you said, it''s "smarter".


          For example, I ask the LLM to make a joke about 2 disparate things (e.g.
          cat and a telescope), start with a random header, such as "Out in a field",
          and then explain itself (all with the same prompt). And this LLM made coherent
          and slightly humerus jokes and correctly explained why they were funny.


          Another example is prompting a poem type (e.g. sonnet) with several directives
          it must follow. This is hard because it has to follow rhythm, meter... while
          remaining coherent and including the prompt directives.


          In short, this is better than 7b Mistrals. I thought this was a hoax when
          I saw it so high on the leaderboard. This is not a hoax.'
        updatedAt: '2023-12-13T19:31:22.317Z'
      numEdits: 0
      reactions: []
    id: 657a068a4a0f7f66e7b1abe9
    type: comment
  author: Phil337
  content: '@tarruda You''re not lying. I''m still finishing up my test on it. But
    it''s doing things other Mistrals can''t. Like you said, it''s "smarter".


    For example, I ask the LLM to make a joke about 2 disparate things (e.g. cat and
    a telescope), start with a random header, such as "Out in a field", and then explain
    itself (all with the same prompt). And this LLM made coherent and slightly humerus
    jokes and correctly explained why they were funny.


    Another example is prompting a poem type (e.g. sonnet) with several directives
    it must follow. This is hard because it has to follow rhythm, meter... while remaining
    coherent and including the prompt directives.


    In short, this is better than 7b Mistrals. I thought this was a hoax when I saw
    it so high on the leaderboard. This is not a hoax.'
  created_at: 2023-12-13 19:31:22+00:00
  edited: false
  hidden: false
  id: 657a068a4a0f7f66e7b1abe9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
      fullname: Thiago de Arruda Padilha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarruda
      type: user
    createdAt: '2023-12-13T19:57:21.000Z'
    data:
      edited: false
      editors:
      - tarruda
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9553053379058838
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
          fullname: Thiago de Arruda Padilha
          isHf: false
          isPro: false
          name: tarruda
          type: user
        html: "<blockquote>\n<p> I thought this was a hoax when I saw it so high on\
          \ the leaderboard. This is not a hoax.</p>\n</blockquote>\n<p>To me the\
          \ best LLM I can run locally is still NeuralHermes 2.5, but maybe this will\
          \ surpass once there are some fine tunes by <span data-props=\"{&quot;user&quot;:&quot;teknium&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/teknium\"\
          >@<span class=\"underline\">teknium</span></a></span>\n\n\t</span></span>\
          \ / <span data-props=\"{&quot;user&quot;:&quot;mlabonne&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mlabonne\">@<span class=\"\
          underline\">mlabonne</span></a></span>\n\n\t</span></span> .  Lack of system\
          \ prompt and multi-turn chat is limiting and makes it harder to compare\
          \ with existing mistral fine tunes...</p>\n"
        raw: '>  I thought this was a hoax when I saw it so high on the leaderboard.
          This is not a hoax.


          To me the best LLM I can run locally is still NeuralHermes 2.5, but maybe
          this will surpass once there are some fine tunes by @teknium / @mlabonne
          .  Lack of system prompt and multi-turn chat is limiting and makes it harder
          to compare with existing mistral fine tunes...'
        updatedAt: '2023-12-13T19:57:21.598Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - mlabonne
        - supercharge19
    id: 657a0ca1b7cd0d1a525ae1e6
    type: comment
  author: tarruda
  content: '>  I thought this was a hoax when I saw it so high on the leaderboard.
    This is not a hoax.


    To me the best LLM I can run locally is still NeuralHermes 2.5, but maybe this
    will surpass once there are some fine tunes by @teknium / @mlabonne .  Lack of
    system prompt and multi-turn chat is limiting and makes it harder to compare with
    existing mistral fine tunes...'
  created_at: 2023-12-13 19:57:21+00:00
  edited: false
  hidden: false
  id: 657a0ca1b7cd0d1a525ae1e6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-13T20:17:48.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9669507145881653
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;tarruda&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/tarruda\">@<span class=\"\
          underline\">tarruda</span></a></span>\n\n\t</span></span> Multi-turn chat\
          \ isn't part of my personal testing, but knowledge is its achilles heel.\
          \ It did notably worse on all my fringe knowledge questions than leading\
          \ Mistrals, and this bleed into my story prompts (e.g. despite Friends being\
          \ a widely popular show, it had Monica and her brother be love interests).\
          \ In short, it's notably smarter than Mistral, but less knowledgeable. I'm\
          \ starting to think they pushed TruthfulQA so hard in this Instruct version\
          \ because they had to keep this substantial reduction of knowledge in check.</p>\n\
          <p>Mixtral and Yi-34b have FAR more knowledge than this LLM. And even the\
          \ original 7b Mistral has notably more knowledge. Somehow they lost information\
          \ during the up-scaling process, yet gained intelligence.</p>\n"
        raw: '@tarruda Multi-turn chat isn''t part of my personal testing, but knowledge
          is its achilles heel. It did notably worse on all my fringe knowledge questions
          than leading Mistrals, and this bleed into my story prompts (e.g. despite
          Friends being a widely popular show, it had Monica and her brother be love
          interests). In short, it''s notably smarter than Mistral, but less knowledgeable.
          I''m starting to think they pushed TruthfulQA so hard in this Instruct version
          because they had to keep this substantial reduction of knowledge in check.


          Mixtral and Yi-34b have FAR more knowledge than this LLM. And even the original
          7b Mistral has notably more knowledge. Somehow they lost information during
          the up-scaling process, yet gained intelligence.'
        updatedAt: '2023-12-13T20:17:48.325Z'
      numEdits: 0
      reactions: []
    id: 657a116cca3375d36d280e7b
    type: comment
  author: Phil337
  content: '@tarruda Multi-turn chat isn''t part of my personal testing, but knowledge
    is its achilles heel. It did notably worse on all my fringe knowledge questions
    than leading Mistrals, and this bleed into my story prompts (e.g. despite Friends
    being a widely popular show, it had Monica and her brother be love interests).
    In short, it''s notably smarter than Mistral, but less knowledgeable. I''m starting
    to think they pushed TruthfulQA so hard in this Instruct version because they
    had to keep this substantial reduction of knowledge in check.


    Mixtral and Yi-34b have FAR more knowledge than this LLM. And even the original
    7b Mistral has notably more knowledge. Somehow they lost information during the
    up-scaling process, yet gained intelligence.'
  created_at: 2023-12-13 20:17:48+00:00
  edited: false
  hidden: false
  id: 657a116cca3375d36d280e7b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
      fullname: Thiago de Arruda Padilha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarruda
      type: user
    createdAt: '2023-12-13T20:21:57.000Z'
    data:
      edited: false
      editors:
      - tarruda
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9463599920272827
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
          fullname: Thiago de Arruda Padilha
          isHf: false
          isPro: false
          name: tarruda
          type: user
        html: '<p>Would be worth checking the knowledge of the base version of the
          model, which has 45.04 score on Truthful QA: <a href="https://huggingface.co/upstage/SOLAR-10.7B-v1.0">https://huggingface.co/upstage/SOLAR-10.7B-v1.0</a></p>

          <p>It is still one of the top LLMs in the leaderboard, but if it was the
          instruction fine tune that killed its knowledge, then some other fine tunes
          might fix it.</p>

          '
        raw: 'Would be worth checking the knowledge of the base version of the model,
          which has 45.04 score on Truthful QA: https://huggingface.co/upstage/SOLAR-10.7B-v1.0


          It is still one of the top LLMs in the leaderboard, but if it was the instruction
          fine tune that killed its knowledge, then some other fine tunes might fix
          it.'
        updatedAt: '2023-12-13T20:21:57.705Z'
      numEdits: 0
      reactions: []
    id: 657a12650543cdd9dae4c476
    type: comment
  author: tarruda
  content: 'Would be worth checking the knowledge of the base version of the model,
    which has 45.04 score on Truthful QA: https://huggingface.co/upstage/SOLAR-10.7B-v1.0


    It is still one of the top LLMs in the leaderboard, but if it was the instruction
    fine tune that killed its knowledge, then some other fine tunes might fix it.'
  created_at: 2023-12-13 20:21:57+00:00
  edited: false
  hidden: false
  id: 657a12650543cdd9dae4c476
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-13T20:55:58.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9515936374664307
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;tarruda&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/tarruda\">@<span class=\"\
          underline\">tarruda</span></a></span>\n\n\t</span></span> Thanks for the\
          \ suggestion. I'm going to try neuralhermes 2.5 next. Hopefully someone\
          \ will fine-tune SOLAR base with the same methods and data as Mistral 7b\
          \ so that it's easier to compare the difference between the base models.</p>\n"
        raw: '@tarruda Thanks for the suggestion. I''m going to try neuralhermes 2.5
          next. Hopefully someone will fine-tune SOLAR base with the same methods
          and data as Mistral 7b so that it''s easier to compare the difference between
          the base models.'
        updatedAt: '2023-12-13T20:55:58.581Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - hunkim
    id: 657a1a5e23a7e36930e087ee
    type: comment
  author: Phil337
  content: '@tarruda Thanks for the suggestion. I''m going to try neuralhermes 2.5
    next. Hopefully someone will fine-tune SOLAR base with the same methods and data
    as Mistral 7b so that it''s easier to compare the difference between the base
    models.'
  created_at: 2023-12-13 20:55:58+00:00
  edited: false
  hidden: false
  id: 657a1a5e23a7e36930e087ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e78b8cd006ddee8ac5f19f809c3ff659.svg
      fullname: Shawn Fumo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: InvidFlower
      type: user
    createdAt: '2023-12-17T15:08:51.000Z'
    data:
      edited: false
      editors:
      - InvidFlower
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.960811972618103
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e78b8cd006ddee8ac5f19f809c3ff659.svg
          fullname: Shawn Fumo
          isHf: false
          isPro: false
          name: InvidFlower
          type: user
        html: "<p>I wonder if a variation on this kind of model could be good as RAG-enhanced.\
          \ Like you mentioned a local Wikipedia archive. If a small model has good\
          \ logic and a wrapper can help get data into it on the fly, that might be\
          \ a best of both worlds thing. I\u2019m sure that breaks down in extremes\
          \ (not knowing enough to know what to search for), but seems it could let\
          \ you reduce GPU requirements in general to keep more knowledge external\
          \ to the LLM itself. </p>\n"
        raw: "I wonder if a variation on this kind of model could be good as RAG-enhanced.\
          \ Like you mentioned a local Wikipedia archive. If a small model has good\
          \ logic and a wrapper can help get data into it on the fly, that might be\
          \ a best of both worlds thing. I\u2019m sure that breaks down in extremes\
          \ (not knowing enough to know what to search for), but seems it could let\
          \ you reduce GPU requirements in general to keep more knowledge external\
          \ to the LLM itself. "
        updatedAt: '2023-12-17T15:08:51.046Z'
      numEdits: 0
      reactions: []
    id: 657f0f033e3b5bea663f47f4
    type: comment
  author: InvidFlower
  content: "I wonder if a variation on this kind of model could be good as RAG-enhanced.\
    \ Like you mentioned a local Wikipedia archive. If a small model has good logic\
    \ and a wrapper can help get data into it on the fly, that might be a best of\
    \ both worlds thing. I\u2019m sure that breaks down in extremes (not knowing enough\
    \ to know what to search for), but seems it could let you reduce GPU requirements\
    \ in general to keep more knowledge external to the LLM itself. "
  created_at: 2023-12-17 15:08:51+00:00
  edited: false
  hidden: false
  id: 657f0f033e3b5bea663f47f4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-17T16:44:20.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9791547656059265
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;InvidFlower&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/InvidFlower\"\
          >@<span class=\"underline\">InvidFlower</span></a></span>\n\n\t</span></span>\
          \ I hope someone with expertise tries this someday. The offline version\
          \ of wikipedia I'm using is with the Kiwix app using a fully indexed zim\
          \ file, so it has full text search. It would be nice if their was a button\
          \ that said \"verify with Wikipedia\" so I didn't have to search and scan\
          \ manually through the results to verify key facts.</p>\n"
        raw: '@InvidFlower I hope someone with expertise tries this someday. The offline
          version of wikipedia I''m using is with the Kiwix app using a fully indexed
          zim file, so it has full text search. It would be nice if their was a button
          that said "verify with Wikipedia" so I didn''t have to search and scan manually
          through the results to verify key facts.'
        updatedAt: '2023-12-17T16:44:20.663Z'
      numEdits: 0
      reactions: []
    id: 657f256419ca6a5e929da243
    type: comment
  author: Phil337
  content: '@InvidFlower I hope someone with expertise tries this someday. The offline
    version of wikipedia I''m using is with the Kiwix app using a fully indexed zim
    file, so it has full text search. It would be nice if their was a button that
    said "verify with Wikipedia" so I didn''t have to search and scan manually through
    the results to verify key facts.'
  created_at: 2023-12-17 16:44:20+00:00
  edited: false
  hidden: false
  id: 657f256419ca6a5e929da243
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-27T20:13:38.000Z'
    data:
      status: closed
    id: 658c8572c1229bf113384b17
    type: status-change
  author: Phil337
  created_at: 2023-12-27 20:13:38+00:00
  id: 658c8572c1229bf113384b17
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: upstage/SOLAR-10.7B-Instruct-v1.0
repo_type: model
status: closed
target_branch: null
title: This LLM is unique in a good way, but hallucinates like crazy in the other
  direction.
