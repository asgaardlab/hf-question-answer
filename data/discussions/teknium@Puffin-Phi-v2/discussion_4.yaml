!!python/object:huggingface_hub.community.DiscussionWithDetails
author: radames
conflicting_files: null
created_at: 2023-10-26 05:40:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648966381588-6064e095abd8d3692e3e2ed6.jpeg?w=200&h=200&f=face
      fullname: "Radam\xE9s Ajna"
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: radames
      type: user
    createdAt: '2023-10-26T06:40:33.000Z'
    data:
      edited: false
      editors:
      - radames
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8748031258583069
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648966381588-6064e095abd8d3692e3e2ed6.jpeg?w=200&h=200&f=face
          fullname: "Radam\xE9s Ajna"
          isHf: true
          isPro: false
          name: radames
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;teknium&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/teknium\">@<span class=\"\
          underline\">teknium</span></a></span>\n\n\t</span></span>,<br>We have been\
          \ working on a ML framework in Rust called <a rel=\"nofollow\" href=\"https://github.com/huggingface/candle\"\
          >Candle</a>. <span data-props=\"{&quot;user&quot;:&quot;lmz&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/lmz\">@<span class=\"\
          underline\">lmz</span></a></span>\n\n\t</span></span>, has implemented the\
          \ Phi architecture in the framework. With Puffin-Phi-v2 quantized model,\
          \ you can run it completely offline on your browser using Wasm. Candle makes\
          \ it easy target the build to Wasm.<br>Here is the demo:<br><a href=\"https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm\"\
          >https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm</a></p>\n"
        raw: "Hi @teknium,\r\nWe have been working on a ML framework in Rust called\
          \ [Candle](https://github.com/huggingface/candle). @lmz, has implemented\
          \ the Phi architecture in the framework. With Puffin-Phi-v2 quantized model,\
          \ you can run it completely offline on your browser using Wasm. Candle makes\
          \ it easy target the build to Wasm.\r\nHere is the demo: \r\nhttps://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm"
        updatedAt: '2023-10-26T06:40:33.051Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\u2764\uFE0F"
        users:
        - Felladrin
        - lmz
        - thijshakkenberg
        - teknium
        - bayang
        - fakezeta
    id: 653a09e1f940c8a035b453a4
    type: comment
  author: radames
  content: "Hi @teknium,\r\nWe have been working on a ML framework in Rust called\
    \ [Candle](https://github.com/huggingface/candle). @lmz, has implemented the Phi\
    \ architecture in the framework. With Puffin-Phi-v2 quantized model, you can run\
    \ it completely offline on your browser using Wasm. Candle makes it easy target\
    \ the build to Wasm.\r\nHere is the demo: \r\nhttps://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm"
  created_at: 2023-10-26 05:40:33+00:00
  edited: false
  hidden: false
  id: 653a09e1f940c8a035b453a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454aff9273f649830234978/cvVV08YHJpJx9xWVZqgVW.jpeg?w=200&h=200&f=face
      fullname: Victor Nogueira
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Felladrin
      type: user
    createdAt: '2023-10-26T07:54:19.000Z'
    data:
      edited: false
      editors:
      - Felladrin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9072265625
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6454aff9273f649830234978/cvVV08YHJpJx9xWVZqgVW.jpeg?w=200&h=200&f=face
          fullname: Victor Nogueira
          isHf: false
          isPro: false
          name: Felladrin
          type: user
        html: '<p>The responses are remarkably better when using Puffin-Phi-v2 compared
          to the base Phi! (Tested with Candle Wasm quantized)<br>Thank you for setting
          that up!</p>

          '
        raw: 'The responses are remarkably better when using Puffin-Phi-v2 compared
          to the base Phi! (Tested with Candle Wasm quantized)

          Thank you for setting that up!'
        updatedAt: '2023-10-26T07:54:19.652Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - lmz
        - teknium
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - radames
    id: 653a1b2b6da48e0d210a2c04
    type: comment
  author: Felladrin
  content: 'The responses are remarkably better when using Puffin-Phi-v2 compared
    to the base Phi! (Tested with Candle Wasm quantized)

    Thank you for setting that up!'
  created_at: 2023-10-26 06:54:19+00:00
  edited: false
  hidden: false
  id: 653a1b2b6da48e0d210a2c04
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: teknium/Puffin-Phi-v2
repo_type: model
status: open
target_branch: null
title: Puffin-Phi-v2  running on the browser with Wasm!!
