!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kc1818
conflicting_files: null
created_at: 2023-05-15 08:39:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69b4b70d8cafc96bdf46ba2ed6c4ddde.svg
      fullname: KC
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kc1818
      type: user
    createdAt: '2023-05-15T09:39:19.000Z'
    data:
      edited: false
      editors:
      - kc1818
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69b4b70d8cafc96bdf46ba2ed6c4ddde.svg
          fullname: KC
          isHf: false
          isPro: false
          name: kc1818
          type: user
        html: '<p>I tried running the given code sample -<br>from sagemaker.huggingface
          import HuggingFaceModel<br>import sagemaker</p>

          <p>role = sagemaker.get_execution_role()</p>

          <h1 id="hub-model-configuration-httpshuggingfacecomodels">Hub Model configuration.
          <a href="https://huggingface.co/models">https://huggingface.co/models</a></h1>

          <p>hub = {<br>    ''HF_MODEL_ID'':''vasista22/whisper-telugu-base'',<br>    ''HF_TASK'':''automatic-speech-recognition''<br>}</p>

          <h1 id="create-hugging-face-model-class">create Hugging Face Model Class</h1>

          <p>huggingface_model = HuggingFaceModel(<br>    transformers_version=''4.17.0'',<br>    pytorch_version=''1.10.2'',<br>    py_version=''py38'',<br>    env=hub,<br>    role=role,<br>)</p>

          <h1 id="deploy-model-to-sagemaker-inference">deploy model to SageMaker Inference</h1>

          <p>predictor = huggingface_model.deploy(<br>    initial_instance_count=1,
          # number of instances<br>    instance_type=''ml.m5.xlarge'' # ec2 instance
          type<br>)</p>

          <p>predictor.predict({<br>    ''inputs'': "Telugu.flac"<br>})</p>

          <p>and it fails with</p>

          <p>ModelError: An error occurred (ModelError) when calling the InvokeEndpoint
          operation: Received client error (400) from primary with message "{<br>  "code":
          400,<br>  "type": "InternalServerException",<br>  "message": "\u0027whisper\u0027"<br>}</p>

          '
        raw: "I tried running the given code sample - \r\nfrom sagemaker.huggingface\
          \ import HuggingFaceModel\r\nimport sagemaker\r\n\r\nrole = sagemaker.get_execution_role()\r\
          \n# Hub Model configuration. https://huggingface.co/models\r\nhub = {\r\n\
          \t'HF_MODEL_ID':'vasista22/whisper-telugu-base',\r\n\t'HF_TASK':'automatic-speech-recognition'\r\
          \n}\r\n\r\n# create Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\
          \n\ttransformers_version='4.17.0',\r\n\tpytorch_version='1.10.2',\r\n\t\
          py_version='py38',\r\n\tenv=hub,\r\n\trole=role, \r\n)\r\n\r\n# deploy model\
          \ to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\n\t\
          initial_instance_count=1, # number of instances\r\n\tinstance_type='ml.m5.xlarge'\
          \ # ec2 instance type\r\n)\r\n\r\npredictor.predict({\r\n\t'inputs': \"\
          Telugu.flac\"\r\n})\r\n\r\nand it fails with\r\n\r\nModelError: An error\
          \ occurred (ModelError) when calling the InvokeEndpoint operation: Received\
          \ client error (400) from primary with message \"{\r\n  \"code\": 400,\r\
          \n  \"type\": \"InternalServerException\",\r\n  \"message\": \"\\u0027whisper\\\
          u0027\"\r\n}\r\n\r\n"
        updatedAt: '2023-05-15T09:39:19.570Z'
      numEdits: 0
      reactions: []
    id: 6461fdc7681b2e19b6adabb6
    type: comment
  author: kc1818
  content: "I tried running the given code sample - \r\nfrom sagemaker.huggingface\
    \ import HuggingFaceModel\r\nimport sagemaker\r\n\r\nrole = sagemaker.get_execution_role()\r\
    \n# Hub Model configuration. https://huggingface.co/models\r\nhub = {\r\n\t'HF_MODEL_ID':'vasista22/whisper-telugu-base',\r\
    \n\t'HF_TASK':'automatic-speech-recognition'\r\n}\r\n\r\n# create Hugging Face\
    \ Model Class\r\nhuggingface_model = HuggingFaceModel(\r\n\ttransformers_version='4.17.0',\r\
    \n\tpytorch_version='1.10.2',\r\n\tpy_version='py38',\r\n\tenv=hub,\r\n\trole=role,\
    \ \r\n)\r\n\r\n# deploy model to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\
    \n\tinitial_instance_count=1, # number of instances\r\n\tinstance_type='ml.m5.xlarge'\
    \ # ec2 instance type\r\n)\r\n\r\npredictor.predict({\r\n\t'inputs': \"Telugu.flac\"\
    \r\n})\r\n\r\nand it fails with\r\n\r\nModelError: An error occurred (ModelError)\
    \ when calling the InvokeEndpoint operation: Received client error (400) from\
    \ primary with message \"{\r\n  \"code\": 400,\r\n  \"type\": \"InternalServerException\"\
    ,\r\n  \"message\": \"\\u0027whisper\\u0027\"\r\n}\r\n\r\n"
  created_at: 2023-05-15 08:39:19+00:00
  edited: false
  hidden: false
  id: 6461fdc7681b2e19b6adabb6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: vasista22/whisper-telugu-base
repo_type: model
status: open
target_branch: null
title: Fails to run in SageMaker
