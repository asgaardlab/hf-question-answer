!!python/object:huggingface_hub.community.DiscussionWithDetails
author: alexgenovese
conflicting_files: null
created_at: 2023-09-27 05:41:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c33c07f7d9edcc39e1c4a1723edb7539.svg
      fullname: Alex Genovese
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: alexgenovese
      type: user
    createdAt: '2023-09-27T06:41:59.000Z'
    data:
      edited: false
      editors:
      - alexgenovese
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9596700668334961
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c33c07f7d9edcc39e1c4a1723edb7539.svg
          fullname: Alex Genovese
          isHf: false
          isPro: true
          name: alexgenovese
          type: user
        html: '<p>Hello there, </p>

          <p>I really like your job. I want to ask you what was the training process
          to have this result. I suppose is based on a sort of manual tagging a subset
          of photos? </p>

          <p>I mean: </p>

          <ul>

          <li>50 Angle 1 photos with CLIP caption + TAG1 (...a1...) </li>

          <li>50 Angle 2 photos with CLIP caption + TAG2 (...a2...)</li>

          </ul>

          <p>Thank you for sharing it. </p>

          '
        raw: "Hello there, \r\n\r\nI really like your job. I want to ask you what\
          \ was the training process to have this result. I suppose is based on a\
          \ sort of manual tagging a subset of photos? \r\n\r\nI mean: \r\n- 50 Angle\
          \ 1 photos with CLIP caption + TAG1 (...a1...) \r\n- 50 Angle 2 photos with\
          \ CLIP caption + TAG2 (...a2...) \r\n\r\nThank you for sharing it. \r\n"
        updatedAt: '2023-09-27T06:41:59.035Z'
      numEdits: 0
      reactions: []
    id: 6513ceb7d06aa2cf17e38532
    type: comment
  author: alexgenovese
  content: "Hello there, \r\n\r\nI really like your job. I want to ask you what was\
    \ the training process to have this result. I suppose is based on a sort of manual\
    \ tagging a subset of photos? \r\n\r\nI mean: \r\n- 50 Angle 1 photos with CLIP\
    \ caption + TAG1 (...a1...) \r\n- 50 Angle 2 photos with CLIP caption + TAG2 (...a2...)\
    \ \r\n\r\nThank you for sharing it. \r\n"
  created_at: 2023-09-27 05:41:59+00:00
  edited: false
  hidden: false
  id: 6513ceb7d06aa2cf17e38532
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0e37f54dfe7d7c16318b2074fa9eb000.svg
      fullname: derp
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: doctorderp
      type: user
    createdAt: '2023-11-29T15:57:19.000Z'
    data:
      edited: false
      editors:
      - doctorderp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9764106869697571
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0e37f54dfe7d7c16318b2074fa9eb000.svg
          fullname: derp
          isHf: false
          isPro: false
          name: doctorderp
          type: user
        html: '<p>Sorry took a while to respond.  I haven''t been on in a while so
          just saw this message.  Training consisted of me gathering images of people
          in various camera shots and angles.  Then I sorted all of the images so
          that each group of images had only one camera angle and shot.  Then I made
          a hypernetwork for only that camera shot and angle.  Rince/repeat that process
          30 times to cover all shots and angles within 180 degrees.  So now I had
          30 hypernetworks.  I then created the most photoreal checkpoint model I
          could by merging over 20 different models and experimenting a lot along
          the way.  Then I made wildcards in helping to simplify the process of putting
          the whole together and labeling the camera shots depending on their angle
          and shot (Distance to subject).  Captioning was done manually.  I used a
          self imposed captioning schema to label every image in natural spoken English
          fashion for ease of use.  I made sure and described every image in great
          detail for maximum capability in flexibility during inference.  Anyways
          there was a lot of other stuff I did along the way, but I''ve rambled long
          enough.  This was a passion project that took a year and tens of thousands
          of images and way too much of my time and money lol... I learned a lot making
          Prometheus. </p>

          '
        raw: 'Sorry took a while to respond.  I haven''t been on in a while so just
          saw this message.  Training consisted of me gathering images of people in
          various camera shots and angles.  Then I sorted all of the images so that
          each group of images had only one camera angle and shot.  Then I made a
          hypernetwork for only that camera shot and angle.  Rince/repeat that process
          30 times to cover all shots and angles within 180 degrees.  So now I had
          30 hypernetworks.  I then created the most photoreal checkpoint model I
          could by merging over 20 different models and experimenting a lot along
          the way.  Then I made wildcards in helping to simplify the process of putting
          the whole together and labeling the camera shots depending on their angle
          and shot (Distance to subject).  Captioning was done manually.  I used a
          self imposed captioning schema to label every image in natural spoken English
          fashion for ease of use.  I made sure and described every image in great
          detail for maximum capability in flexibility during inference.  Anyways
          there was a lot of other stuff I did along the way, but I''ve rambled long
          enough.  This was a passion project that took a year and tens of thousands
          of images and way too much of my time and money lol... I learned a lot making
          Prometheus. '
        updatedAt: '2023-11-29T15:57:19.387Z'
      numEdits: 0
      reactions: []
    id: 65675f5f2f3ec92d7e4f68a6
    type: comment
  author: doctorderp
  content: 'Sorry took a while to respond.  I haven''t been on in a while so just
    saw this message.  Training consisted of me gathering images of people in various
    camera shots and angles.  Then I sorted all of the images so that each group of
    images had only one camera angle and shot.  Then I made a hypernetwork for only
    that camera shot and angle.  Rince/repeat that process 30 times to cover all shots
    and angles within 180 degrees.  So now I had 30 hypernetworks.  I then created
    the most photoreal checkpoint model I could by merging over 20 different models
    and experimenting a lot along the way.  Then I made wildcards in helping to simplify
    the process of putting the whole together and labeling the camera shots depending
    on their angle and shot (Distance to subject).  Captioning was done manually.  I
    used a self imposed captioning schema to label every image in natural spoken English
    fashion for ease of use.  I made sure and described every image in great detail
    for maximum capability in flexibility during inference.  Anyways there was a lot
    of other stuff I did along the way, but I''ve rambled long enough.  This was a
    passion project that took a year and tens of thousands of images and way too much
    of my time and money lol... I learned a lot making Prometheus. '
  created_at: 2023-11-29 15:57:19+00:00
  edited: false
  hidden: false
  id: 65675f5f2f3ec92d7e4f68a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c33c07f7d9edcc39e1c4a1723edb7539.svg
      fullname: Alex Genovese
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: alexgenovese
      type: user
    createdAt: '2023-11-30T07:39:03.000Z'
    data:
      edited: false
      editors:
      - alexgenovese
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.909535825252533
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c33c07f7d9edcc39e1c4a1723edb7539.svg
          fullname: Alex Genovese
          isHf: false
          isPro: true
          name: alexgenovese
          type: user
        html: '<p>No worries, thank you for sharing it</p>

          '
        raw: No worries, thank you for sharing it
        updatedAt: '2023-11-30T07:39:03.564Z'
      numEdits: 0
      reactions: []
    id: 65683c170e4b5ff9d54f2b0e
    type: comment
  author: alexgenovese
  content: No worries, thank you for sharing it
  created_at: 2023-11-30 07:39:03+00:00
  edited: false
  hidden: false
  id: 65683c170e4b5ff9d54f2b0e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: doctorderp/prometheus.safetensors
repo_type: model
status: open
target_branch: null
title: Training Info
