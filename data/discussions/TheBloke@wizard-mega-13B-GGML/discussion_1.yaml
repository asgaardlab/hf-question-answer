!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Jlonge4
conflicting_files: null
created_at: 2023-05-17 18:48:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dff9de481de8e493b916c91ab50f147b.svg
      fullname: Josh longenecker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jlonge4
      type: user
    createdAt: '2023-05-17T19:48:50.000Z'
    data:
      edited: false
      editors:
      - Jlonge4
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dff9de481de8e493b916c91ab50f147b.svg
          fullname: Josh longenecker
          isHf: false
          isPro: false
          name: Jlonge4
          type: user
        html: '<p>How to install this locally and use offline? Any references or videos
          would be great</p>

          '
        raw: How to install this locally and use offline? Any references or videos
          would be great
        updatedAt: '2023-05-17T19:48:50.728Z'
      numEdits: 0
      reactions: []
    id: 64652fa2e27766e8921a02ad
    type: comment
  author: Jlonge4
  content: How to install this locally and use offline? Any references or videos would
    be great
  created_at: 2023-05-17 18:48:50+00:00
  edited: false
  hidden: false
  id: 64652fa2e27766e8921a02ad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a7ac4351c4efb691f9eef3ecc7f0467b.svg
      fullname: Jeff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheStamp
      type: user
    createdAt: '2023-05-17T20:17:05.000Z'
    data:
      edited: false
      editors:
      - TheStamp
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a7ac4351c4efb691f9eef3ecc7f0467b.svg
          fullname: Jeff
          isHf: false
          isPro: false
          name: TheStamp
          type: user
        html: '<p><a rel="nofollow" href="https://www.youtube.com/watch?v=6-zYkPo1M68">https://www.youtube.com/watch?v=6-zYkPo1M68</a></p>

          '
        raw: https://www.youtube.com/watch?v=6-zYkPo1M68
        updatedAt: '2023-05-17T20:17:05.879Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Jlonge4
    id: 64653641a0748f9aa4c86075
    type: comment
  author: TheStamp
  content: https://www.youtube.com/watch?v=6-zYkPo1M68
  created_at: 2023-05-17 19:17:05+00:00
  edited: false
  hidden: false
  id: 64653641a0748f9aa4c86075
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a7ac4351c4efb691f9eef3ecc7f0467b.svg
      fullname: Jeff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheStamp
      type: user
    createdAt: '2023-05-17T20:19:23.000Z'
    data:
      edited: false
      editors:
      - TheStamp
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a7ac4351c4efb691f9eef3ecc7f0467b.svg
          fullname: Jeff
          isHf: false
          isPro: false
          name: TheStamp
          type: user
        html: '<p>this is actually the GGML version (my bad) - you should be able
          to use it with LLama.cpp <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp">https://github.com/ggerganov/llama.cpp</a></p>

          '
        raw: this is actually the GGML version (my bad) - you should be able to use
          it with LLama.cpp https://github.com/ggerganov/llama.cpp
        updatedAt: '2023-05-17T20:19:23.089Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mirek190
    id: 646536cba0748f9aa4c8676c
    type: comment
  author: TheStamp
  content: this is actually the GGML version (my bad) - you should be able to use
    it with LLama.cpp https://github.com/ggerganov/llama.cpp
  created_at: 2023-05-17 19:19:23+00:00
  edited: false
  hidden: false
  id: 646536cba0748f9aa4c8676c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dff9de481de8e493b916c91ab50f147b.svg
      fullname: Josh longenecker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jlonge4
      type: user
    createdAt: '2023-05-17T20:21:21.000Z'
    data:
      edited: false
      editors:
      - Jlonge4
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dff9de481de8e493b916c91ab50f147b.svg
          fullname: Josh longenecker
          isHf: false
          isPro: false
          name: Jlonge4
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheStamp&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheStamp\">@<span class=\"\
          underline\">TheStamp</span></a></span>\n\n\t</span></span> with llama.cpp,\
          \ as in I need both this model and llama.cpp locally? I\u2019m trying to\
          \ run it in code using langchain instead of openai. Sorry for the newbiness</p>\n"
        raw: "@TheStamp with llama.cpp, as in I need both this model and llama.cpp\
          \ locally? I\u2019m trying to run it in code using langchain instead of\
          \ openai. Sorry for the newbiness"
        updatedAt: '2023-05-17T20:21:21.336Z'
      numEdits: 0
      reactions: []
    id: 64653741e8e31202cb517368
    type: comment
  author: Jlonge4
  content: "@TheStamp with llama.cpp, as in I need both this model and llama.cpp locally?\
    \ I\u2019m trying to run it in code using langchain instead of openai. Sorry for\
    \ the newbiness"
  created_at: 2023-05-17 19:21:21+00:00
  edited: false
  hidden: false
  id: 64653741e8e31202cb517368
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-17T20:24:40.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Then you want llama-cpp-python, which are llama.cpp bindings for
          Python.  Allows you to load GGML files exactly the same as llama.cpp does,
          but easily accessible from code. </p>

          <p>It can then be used either direct from your own Python code, or via an
          OpenAI-compatible API which you can put LangChain at, or any other client.</p>

          <p><a rel="nofollow" href="https://github.com/abetlen/llama-cpp-python">https://github.com/abetlen/llama-cpp-python</a><br><a
          rel="nofollow" href="https://pypi.org/project/llama-cpp-python/">https://pypi.org/project/llama-cpp-python/</a></p>

          '
        raw: "Then you want llama-cpp-python, which are llama.cpp bindings for Python.\
          \  Allows you to load GGML files exactly the same as llama.cpp does, but\
          \ easily accessible from code. \n\nIt can then be used either direct from\
          \ your own Python code, or via an OpenAI-compatible API which you can put\
          \ LangChain at, or any other client.\n\nhttps://github.com/abetlen/llama-cpp-python\n\
          https://pypi.org/project/llama-cpp-python/"
        updatedAt: '2023-05-17T20:25:26.458Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jeffwadsworth
    id: 6465380886e668ad22e7135c
    type: comment
  author: TheBloke
  content: "Then you want llama-cpp-python, which are llama.cpp bindings for Python.\
    \  Allows you to load GGML files exactly the same as llama.cpp does, but easily\
    \ accessible from code. \n\nIt can then be used either direct from your own Python\
    \ code, or via an OpenAI-compatible API which you can put LangChain at, or any\
    \ other client.\n\nhttps://github.com/abetlen/llama-cpp-python\nhttps://pypi.org/project/llama-cpp-python/"
  created_at: 2023-05-17 19:24:40+00:00
  edited: true
  hidden: false
  id: 6465380886e668ad22e7135c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a97cfbaf6cd58ad8ad35cfd96cb87aa4.svg
      fullname: gkp
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gkp255
      type: user
    createdAt: '2023-05-17T22:23:25.000Z'
    data:
      edited: true
      editors:
      - gkp255
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a97cfbaf6cd58ad8ad35cfd96cb87aa4.svg
          fullname: gkp
          isHf: false
          isPro: false
          name: gkp255
          type: user
        html: '<p>you could use this: <a rel="nofollow" href="https://www.youtube.com/watch?v=aO5ZpFYHa0A&amp;t=1s">https://www.youtube.com/watch?v=aO5ZpFYHa0A&amp;t=1s</a></p>

          '
        raw: 'you could use this: https://www.youtube.com/watch?v=aO5ZpFYHa0A&t=1s'
        updatedAt: '2023-05-17T22:23:42.146Z'
      numEdits: 1
      reactions: []
    id: 646553dd86e668ad22e8af22
    type: comment
  author: gkp255
  content: 'you could use this: https://www.youtube.com/watch?v=aO5ZpFYHa0A&t=1s'
  created_at: 2023-05-17 21:23:25+00:00
  edited: true
  hidden: false
  id: 646553dd86e668ad22e8af22
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dff9de481de8e493b916c91ab50f147b.svg
      fullname: Josh longenecker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jlonge4
      type: user
    createdAt: '2023-05-18T18:42:40.000Z'
    data:
      edited: false
      editors:
      - Jlonge4
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dff9de481de8e493b916c91ab50f147b.svg
          fullname: Josh longenecker
          isHf: false
          isPro: false
          name: Jlonge4
          type: user
        html: '<p>Thanks everyone, goal accomplished</p>

          '
        raw: Thanks everyone, goal accomplished
        updatedAt: '2023-05-18T18:42:40.333Z'
      numEdits: 0
      reactions: []
    id: 646671a0119ad94383d3d4c2
    type: comment
  author: Jlonge4
  content: Thanks everyone, goal accomplished
  created_at: 2023-05-18 17:42:40+00:00
  edited: false
  hidden: false
  id: 646671a0119ad94383d3d4c2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/wizard-mega-13B-GGML
repo_type: model
status: open
target_branch: null
title: How to install this locally and use offline?
