!!python/object:huggingface_hub.community.DiscussionWithDetails
author: peterzhu
conflicting_files: null
created_at: 2023-07-27 15:07:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/579cfca74c8507c13cc657f0684ad0d8.svg
      fullname: peter zhu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: peterzhu
      type: user
    createdAt: '2023-07-27T16:07:27.000Z'
    data:
      edited: false
      editors:
      - peterzhu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.25634321570396423
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/579cfca74c8507c13cc657f0684ad0d8.svg
          fullname: peter zhu
          isHf: false
          isPro: false
          name: peterzhu
          type: user
        html: '<p>Traceback (most recent call last):<br>  File "F:\AI-RWKV\oobabooga_windows\text-generation-webui\server.py",
          line 68, in load_model_wrapper<br>    shared.model, shared.tokenizer = load_model(shared.model_name,
          loader)<br>  File "F:\AI-RWKV\oobabooga_windows\text-generation-webui\modules\models.py",
          line 78, in load_model<br>    output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>  File
          "F:\AI-RWKV\oobabooga_windows\text-generation-webui\modules\models.py",
          line 305, in ExLlama_HF_loader<br>    return ExllamaHF.from_pretrained(model_name)<br>  File
          "F:\AI-RWKV\oobabooga_windows\text-generation-webui\modules\exllama_hf.py",
          line 116, in from_pretrained<br>    return ExllamaHF(config)<br>  File "F:\AI-RWKV\oobabooga_windows\text-generation-webui\modules\exllama_hf.py",
          line 31, in <strong>init</strong><br>    self.ex_model = ExLlama(self.ex_config)<br>  File
          "F:\AI-RWKV\oobabooga_windows\installer_files\env\lib\site-packages\exllama\model.py",
          line 772, in <strong>init</strong><br>    layer = ExLlamaDecoderLayer(self.config,
          tensors, f"model.layers.{i}", i, sin, cos)<br>  File "F:\AI-RWKV\oobabooga_windows\installer_files\env\lib\site-packages\exllama\model.py",
          line 451, in <strong>init</strong><br>    self.self_attn = ExLlamaAttention(self.config,
          tensors, key + ".self_attn", sin, cos, self.index)<br>  File "F:\AI-RWKV\oobabooga_windows\installer_files\env\lib\site-packages\exllama\model.py",
          line 289, in <strong>init</strong><br>    self.q_proj = Ex4bitLinear(config,
          self.config.hidden_size, self.config.num_attention_heads * self.config.head_dim,
          False, tensors, key + ".q_proj")<br>  File "F:\AI-RWKV\oobabooga_windows\installer_files\env\lib\site-packages\exllama\model.py",
          line 126, in <strong>init</strong><br>    self.qweight = tensors[key + ".qweight"]<br>KeyError:
          ''model.layers.0.self_attn.q_proj.qweight''</p>

          '
        raw: "Traceback (most recent call last):\r\n  File \"F:\\AI-RWKV\\oobabooga_windows\\\
          text-generation-webui\\server.py\", line 68, in load_model_wrapper\r\n \
          \   shared.model, shared.tokenizer = load_model(shared.model_name, loader)\r\
          \n  File \"F:\\AI-RWKV\\oobabooga_windows\\text-generation-webui\\modules\\\
          models.py\", line 78, in load_model\r\n    output = load_func_map[loader](model_name)\r\
          \n  File \"F:\\AI-RWKV\\oobabooga_windows\\text-generation-webui\\modules\\\
          models.py\", line 305, in ExLlama_HF_loader\r\n    return ExllamaHF.from_pretrained(model_name)\r\
          \n  File \"F:\\AI-RWKV\\oobabooga_windows\\text-generation-webui\\modules\\\
          exllama_hf.py\", line 116, in from_pretrained\r\n    return ExllamaHF(config)\r\
          \n  File \"F:\\AI-RWKV\\oobabooga_windows\\text-generation-webui\\modules\\\
          exllama_hf.py\", line 31, in __init__\r\n    self.ex_model = ExLlama(self.ex_config)\r\
          \n  File \"F:\\AI-RWKV\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
          exllama\\model.py\", line 772, in __init__\r\n    layer = ExLlamaDecoderLayer(self.config,\
          \ tensors, f\"model.layers.{i}\", i, sin, cos)\r\n  File \"F:\\AI-RWKV\\\
          oobabooga_windows\\installer_files\\env\\lib\\site-packages\\exllama\\model.py\"\
          , line 451, in __init__\r\n    self.self_attn = ExLlamaAttention(self.config,\
          \ tensors, key + \".self_attn\", sin, cos, self.index)\r\n  File \"F:\\\
          AI-RWKV\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\exllama\\\
          model.py\", line 289, in __init__\r\n    self.q_proj = Ex4bitLinear(config,\
          \ self.config.hidden_size, self.config.num_attention_heads * self.config.head_dim,\
          \ False, tensors, key + \".q_proj\")\r\n  File \"F:\\AI-RWKV\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\exllama\\model.py\", line 126,\
          \ in __init__\r\n    self.qweight = tensors[key + \".qweight\"]\r\nKeyError:\
          \ 'model.layers.0.self_attn.q_proj.qweight'"
        updatedAt: '2023-07-27T16:07:27.523Z'
      numEdits: 0
      reactions: []
    id: 64c2963f9a861c5673384719
    type: comment
  author: peterzhu
  content: "Traceback (most recent call last):\r\n  File \"F:\\AI-RWKV\\oobabooga_windows\\\
    text-generation-webui\\server.py\", line 68, in load_model_wrapper\r\n    shared.model,\
    \ shared.tokenizer = load_model(shared.model_name, loader)\r\n  File \"F:\\AI-RWKV\\\
    oobabooga_windows\\text-generation-webui\\modules\\models.py\", line 78, in load_model\r\
    \n    output = load_func_map[loader](model_name)\r\n  File \"F:\\AI-RWKV\\oobabooga_windows\\\
    text-generation-webui\\modules\\models.py\", line 305, in ExLlama_HF_loader\r\n\
    \    return ExllamaHF.from_pretrained(model_name)\r\n  File \"F:\\AI-RWKV\\oobabooga_windows\\\
    text-generation-webui\\modules\\exllama_hf.py\", line 116, in from_pretrained\r\
    \n    return ExllamaHF(config)\r\n  File \"F:\\AI-RWKV\\oobabooga_windows\\text-generation-webui\\\
    modules\\exllama_hf.py\", line 31, in __init__\r\n    self.ex_model = ExLlama(self.ex_config)\r\
    \n  File \"F:\\AI-RWKV\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    exllama\\model.py\", line 772, in __init__\r\n    layer = ExLlamaDecoderLayer(self.config,\
    \ tensors, f\"model.layers.{i}\", i, sin, cos)\r\n  File \"F:\\AI-RWKV\\oobabooga_windows\\\
    installer_files\\env\\lib\\site-packages\\exllama\\model.py\", line 451, in __init__\r\
    \n    self.self_attn = ExLlamaAttention(self.config, tensors, key + \".self_attn\"\
    , sin, cos, self.index)\r\n  File \"F:\\AI-RWKV\\oobabooga_windows\\installer_files\\\
    env\\lib\\site-packages\\exllama\\model.py\", line 289, in __init__\r\n    self.q_proj\
    \ = Ex4bitLinear(config, self.config.hidden_size, self.config.num_attention_heads\
    \ * self.config.head_dim, False, tensors, key + \".q_proj\")\r\n  File \"F:\\\
    AI-RWKV\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\exllama\\\
    model.py\", line 126, in __init__\r\n    self.qweight = tensors[key + \".qweight\"\
    ]\r\nKeyError: 'model.layers.0.self_attn.q_proj.qweight'"
  created_at: 2023-07-27 15:07:27+00:00
  edited: false
  hidden: false
  id: 64c2963f9a861c5673384719
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61caeda441f9432649f03ab6/q7BrCmKdQkvVZ7mBdKdbQ.jpeg?w=200&h=200&f=face
      fullname: s3nh
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: s3nh
      type: user
    createdAt: '2023-07-27T16:27:07.000Z'
    data:
      edited: false
      editors:
      - s3nh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5682532787322998
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61caeda441f9432649f03ab6/q7BrCmKdQkvVZ7mBdKdbQ.jpeg?w=200&h=200&f=face
          fullname: s3nh
          isHf: false
          isPro: false
          name: s3nh
          type: user
        html: '<p>I am not fammiliar with text generation gui. Ill add simple snippet
          in readme.md.</p>

          '
        raw: I am not fammiliar with text generation gui. Ill add simple snippet in
          readme.md.
        updatedAt: '2023-07-27T16:27:07.013Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - songzhen
    id: 64c29adbc306e2648840c219
    type: comment
  author: s3nh
  content: I am not fammiliar with text generation gui. Ill add simple snippet in
    readme.md.
  created_at: 2023-07-27 15:27:07+00:00
  edited: false
  hidden: false
  id: 64c29adbc306e2648840c219
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61caeda441f9432649f03ab6/q7BrCmKdQkvVZ7mBdKdbQ.jpeg?w=200&h=200&f=face
      fullname: s3nh
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: s3nh
      type: user
    createdAt: '2023-07-27T16:27:45.000Z'
    data:
      edited: false
      editors:
      - s3nh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8759110569953918
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61caeda441f9432649f03ab6/q7BrCmKdQkvVZ7mBdKdbQ.jpeg?w=200&h=200&f=face
          fullname: s3nh
          isHf: false
          isPro: false
          name: s3nh
          type: user
        html: '<p>The most simple way to read pretrained GPTQ model is by using auto_gptq
          library</p>

          '
        raw: The most simple way to read pretrained GPTQ model is by using auto_gptq
          library
        updatedAt: '2023-07-27T16:27:45.632Z'
      numEdits: 0
      reactions: []
    id: 64c29b018f50849b102a281a
    type: comment
  author: s3nh
  content: The most simple way to read pretrained GPTQ model is by using auto_gptq
    library
  created_at: 2023-07-27 15:27:45+00:00
  edited: false
  hidden: false
  id: 64c29b018f50849b102a281a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/D6hvFF8-69JsXYA9vXdGq.png?w=200&h=200&f=face
      fullname: songzhen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: songzhen
      type: user
    createdAt: '2023-08-10T03:41:08.000Z'
    data:
      edited: false
      editors:
      - songzhen
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.8736169934272766
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/D6hvFF8-69JsXYA9vXdGq.png?w=200&h=200&f=face
          fullname: songzhen
          isHf: false
          isPro: false
          name: songzhen
          type: user
        html: "<p>\u5927\u4F6C\uFF0C\u53EF\u4EE5\u50CFthebloke\u90A3\u6837\u505A\u4E00\
          \u4E2A\u4E13\u95E8\u7ED9text-generation-webui\u7528\u7684\u5305\u5417\uFF1F\
          \u73B0\u5728\u5C31\u662F\u5374\u51E0\u4E2A\u6587\u4EF6\u6CA1\u6CD5\u52A0\
          \u8F7D\u6210\u529F\uFF0C\u591A\u8C22\u5566\uFF01</p>\n"
        raw: "\u5927\u4F6C\uFF0C\u53EF\u4EE5\u50CFthebloke\u90A3\u6837\u505A\u4E00\
          \u4E2A\u4E13\u95E8\u7ED9text-generation-webui\u7528\u7684\u5305\u5417\uFF1F\
          \u73B0\u5728\u5C31\u662F\u5374\u51E0\u4E2A\u6587\u4EF6\u6CA1\u6CD5\u52A0\
          \u8F7D\u6210\u529F\uFF0C\u591A\u8C22\u5566\uFF01"
        updatedAt: '2023-08-10T03:41:08.623Z'
      numEdits: 0
      reactions: []
    id: 64d45c549be1ed353bf674bf
    type: comment
  author: songzhen
  content: "\u5927\u4F6C\uFF0C\u53EF\u4EE5\u50CFthebloke\u90A3\u6837\u505A\u4E00\u4E2A\
    \u4E13\u95E8\u7ED9text-generation-webui\u7528\u7684\u5305\u5417\uFF1F\u73B0\u5728\
    \u5C31\u662F\u5374\u51E0\u4E2A\u6587\u4EF6\u6CA1\u6CD5\u52A0\u8F7D\u6210\u529F\
    \uFF0C\u591A\u8C22\u5566\uFF01"
  created_at: 2023-08-10 02:41:08+00:00
  edited: false
  hidden: false
  id: 64d45c549be1ed353bf674bf
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: s3nh/Baichuan-13B-Instruction-GPTQ
repo_type: model
status: open
target_branch: null
title: exllama can't load.
