!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ehartford
conflicting_files: null
created_at: 2024-01-10 00:31:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2024-01-10T00:31:57.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6444377303123474
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: "<p>I tried to run your exact same yaml file on a different 70b model,\
          \ and I got this:</p>\n<pre><code>  File \"/Users/eric/git/mergekit/mergekit/options.py\"\
          , line 58, in wrapper\n    f(*args, **kwargs)\n  File \"/Users/eric/git/mergekit/mergekit/scripts/run_yaml.py\"\
          , line 47, in main\n    run_merge(\n  File \"/Users/eric/git/mergekit/mergekit/merge.py\"\
          , line 110, in run_merge\n    exec.run(\n  File \"/Users/eric/git/mergekit/mergekit/graph.py\"\
          , line 254, in run\n    writer.save_tensor(ref.key, tensor, clone=clone_tensors)\n\
          \  File \"/Users/eric/git/mergekit/mergekit/io/tensor_writer.py\", line\
          \ 51, in save_tensor\n    self.flush_current_shard()\n  File \"/Users/eric/git/mergekit/mergekit/io/tensor_writer.py\"\
          , line 68, in flush_current_shard\n    safetensors.torch.save_file(\n  File\
          \ \"/Users/eric/miniconda3/envs/mergekit/lib/python3.11/site-packages/safetensors/torch.py\"\
          , line 281, in save_file\n    serialize_file(_flatten(tensors), filename,\
          \ metadata=metadata)\n                   ^^^^^^^^^^^^^^^^^\n  File \"/Users/eric/miniconda3/envs/mergekit/lib/python3.11/site-packages/safetensors/torch.py\"\
          , line 467, in _flatten\n    raise RuntimeError(\nRuntimeError:\n      \
          \      Some tensors share memory, this will lead to duplicate memory on\
          \ disk and potential differences when loading them again: [{'model.layers.20.input_layernorm.weight',\
          \ 'model.layers.10.input_layernorm.weight'}].\n            A potential way\
          \ to correctly save your model is to use `save_model`.\n            More\
          \ information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n\
          </code></pre>\n<p>Any idea what I did wrong?</p>\n"
        raw: "I tried to run your exact same yaml file on a different 70b model, and\
          \ I got this:\r\n\r\n```\r\n  File \"/Users/eric/git/mergekit/mergekit/options.py\"\
          , line 58, in wrapper\r\n    f(*args, **kwargs)\r\n  File \"/Users/eric/git/mergekit/mergekit/scripts/run_yaml.py\"\
          , line 47, in main\r\n    run_merge(\r\n  File \"/Users/eric/git/mergekit/mergekit/merge.py\"\
          , line 110, in run_merge\r\n    exec.run(\r\n  File \"/Users/eric/git/mergekit/mergekit/graph.py\"\
          , line 254, in run\r\n    writer.save_tensor(ref.key, tensor, clone=clone_tensors)\r\
          \n  File \"/Users/eric/git/mergekit/mergekit/io/tensor_writer.py\", line\
          \ 51, in save_tensor\r\n    self.flush_current_shard()\r\n  File \"/Users/eric/git/mergekit/mergekit/io/tensor_writer.py\"\
          , line 68, in flush_current_shard\r\n    safetensors.torch.save_file(\r\n\
          \  File \"/Users/eric/miniconda3/envs/mergekit/lib/python3.11/site-packages/safetensors/torch.py\"\
          , line 281, in save_file\r\n    serialize_file(_flatten(tensors), filename,\
          \ metadata=metadata)\r\n                   ^^^^^^^^^^^^^^^^^\r\n  File \"\
          /Users/eric/miniconda3/envs/mergekit/lib/python3.11/site-packages/safetensors/torch.py\"\
          , line 467, in _flatten\r\n    raise RuntimeError(\r\nRuntimeError:\r\n\
          \            Some tensors share memory, this will lead to duplicate memory\
          \ on disk and potential differences when loading them again: [{'model.layers.20.input_layernorm.weight',\
          \ 'model.layers.10.input_layernorm.weight'}].\r\n            A potential\
          \ way to correctly save your model is to use `save_model`.\r\n         \
          \   More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\r\
          \n```\r\n\r\nAny idea what I did wrong?"
        updatedAt: '2024-01-10T00:31:57.570Z'
      numEdits: 0
      reactions: []
    id: 659de57d04b93eb6db8e0f63
    type: comment
  author: ehartford
  content: "I tried to run your exact same yaml file on a different 70b model, and\
    \ I got this:\r\n\r\n```\r\n  File \"/Users/eric/git/mergekit/mergekit/options.py\"\
    , line 58, in wrapper\r\n    f(*args, **kwargs)\r\n  File \"/Users/eric/git/mergekit/mergekit/scripts/run_yaml.py\"\
    , line 47, in main\r\n    run_merge(\r\n  File \"/Users/eric/git/mergekit/mergekit/merge.py\"\
    , line 110, in run_merge\r\n    exec.run(\r\n  File \"/Users/eric/git/mergekit/mergekit/graph.py\"\
    , line 254, in run\r\n    writer.save_tensor(ref.key, tensor, clone=clone_tensors)\r\
    \n  File \"/Users/eric/git/mergekit/mergekit/io/tensor_writer.py\", line 51, in\
    \ save_tensor\r\n    self.flush_current_shard()\r\n  File \"/Users/eric/git/mergekit/mergekit/io/tensor_writer.py\"\
    , line 68, in flush_current_shard\r\n    safetensors.torch.save_file(\r\n  File\
    \ \"/Users/eric/miniconda3/envs/mergekit/lib/python3.11/site-packages/safetensors/torch.py\"\
    , line 281, in save_file\r\n    serialize_file(_flatten(tensors), filename, metadata=metadata)\r\
    \n                   ^^^^^^^^^^^^^^^^^\r\n  File \"/Users/eric/miniconda3/envs/mergekit/lib/python3.11/site-packages/safetensors/torch.py\"\
    , line 467, in _flatten\r\n    raise RuntimeError(\r\nRuntimeError:\r\n      \
    \      Some tensors share memory, this will lead to duplicate memory on disk and\
    \ potential differences when loading them again: [{'model.layers.20.input_layernorm.weight',\
    \ 'model.layers.10.input_layernorm.weight'}].\r\n            A potential way to\
    \ correctly save your model is to use `save_model`.\r\n            More information\
    \ at https://huggingface.co/docs/safetensors/torch_shared_tensors\r\n```\r\n\r\
    \nAny idea what I did wrong?"
  created_at: 2024-01-10 00:31:57+00:00
  edited: false
  hidden: false
  id: 659de57d04b93eb6db8e0f63
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2024-01-10T00:33:02.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.37663495540618896
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: "<pre><code>$ cat ~/models/Dolphin-120b/mergekit_config.yml \ndtype:\
          \ float16\nmerge_method: passthrough\nslices:\n- sources:\n  - layer_range:\
          \ [0, 20]\n    model: cognitivecomputations/dolphin-2.2-70b\n- sources:\n\
          \  - layer_range: [10, 30]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          - sources:\n  - layer_range: [20, 40]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          - sources:\n  - layer_range: [30, 50]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          - sources:\n  - layer_range: [40, 60]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          - sources:\n  - layer_range: [50, 70]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          - sources:\n  - layer_range: [60, 80]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          </code></pre>\n"
        raw: "```\n$ cat ~/models/Dolphin-120b/mergekit_config.yml \ndtype: float16\n\
          merge_method: passthrough\nslices:\n- sources:\n  - layer_range: [0, 20]\n\
          \    model: cognitivecomputations/dolphin-2.2-70b\n- sources:\n  - layer_range:\
          \ [10, 30]\n    model: cognitivecomputations/dolphin-2.2-70b\n- sources:\n\
          \  - layer_range: [20, 40]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          - sources:\n  - layer_range: [30, 50]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          - sources:\n  - layer_range: [40, 60]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          - sources:\n  - layer_range: [50, 70]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          - sources:\n  - layer_range: [60, 80]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
          ```"
        updatedAt: '2024-01-10T00:33:02.821Z'
      numEdits: 0
      reactions: []
    id: 659de5be10064f20ff2f8c14
    type: comment
  author: ehartford
  content: "```\n$ cat ~/models/Dolphin-120b/mergekit_config.yml \ndtype: float16\n\
    merge_method: passthrough\nslices:\n- sources:\n  - layer_range: [0, 20]\n   \
    \ model: cognitivecomputations/dolphin-2.2-70b\n- sources:\n  - layer_range: [10,\
    \ 30]\n    model: cognitivecomputations/dolphin-2.2-70b\n- sources:\n  - layer_range:\
    \ [20, 40]\n    model: cognitivecomputations/dolphin-2.2-70b\n- sources:\n  -\
    \ layer_range: [30, 50]\n    model: cognitivecomputations/dolphin-2.2-70b\n- sources:\n\
    \  - layer_range: [40, 60]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
    - sources:\n  - layer_range: [50, 70]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
    - sources:\n  - layer_range: [60, 80]\n    model: cognitivecomputations/dolphin-2.2-70b\n\
    ```"
  created_at: 2024-01-10 00:33:02+00:00
  edited: false
  hidden: false
  id: 659de5be10064f20ff2f8c14
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/311b7f466c5f282fe9f5e25e4431d813.svg
      fullname: John Smith
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nsfwthrowitaway69
      type: user
    createdAt: '2024-01-10T04:32:37.000Z'
    data:
      edited: false
      editors:
      - nsfwthrowitaway69
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8978978395462036
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/311b7f466c5f282fe9f5e25e4431d813.svg
          fullname: John Smith
          isHf: false
          isPro: false
          name: nsfwthrowitaway69
          type: user
        html: '<p>That''s strange, your yaml file looks fine. Are you running mergekit
          using the command line or Jupyter notebook?</p>

          '
        raw: That's strange, your yaml file looks fine. Are you running mergekit using
          the command line or Jupyter notebook?
        updatedAt: '2024-01-10T04:32:37.823Z'
      numEdits: 0
      reactions: []
    id: 659e1de5e5bc942b4b1d8a64
    type: comment
  author: nsfwthrowitaway69
  content: That's strange, your yaml file looks fine. Are you running mergekit using
    the command line or Jupyter notebook?
  created_at: 2024-01-10 04:32:37+00:00
  edited: false
  hidden: false
  id: 659e1de5e5bc942b4b1d8a64
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2024-01-10T05:24:24.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9878554940223694
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>Well I got past it by making two symlinks to the model directory
          and making it think I was pulling in 3 different models</p>

          '
        raw: Well I got past it by making two symlinks to the model directory and
          making it think I was pulling in 3 different models
        updatedAt: '2024-01-10T05:24:24.003Z'
      numEdits: 0
      reactions: []
      relatedEventId: 659e2a08e5bc942b4b1ff699
    id: 659e2a08e5bc942b4b1ff694
    type: comment
  author: ehartford
  content: Well I got past it by making two symlinks to the model directory and making
    it think I was pulling in 3 different models
  created_at: 2024-01-10 05:24:24+00:00
  edited: false
  hidden: false
  id: 659e2a08e5bc942b4b1ff694
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2024-01-10T05:24:24.000Z'
    data:
      status: closed
    id: 659e2a08e5bc942b4b1ff699
    type: status-change
  author: ehartford
  created_at: 2024-01-10 05:24:24+00:00
  id: 659e2a08e5bc942b4b1ff699
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: nsfwthrowitaway69/Venus-120b-v1.2
repo_type: model
status: closed
target_branch: null
title: error message
