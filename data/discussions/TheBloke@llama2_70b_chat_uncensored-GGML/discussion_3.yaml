!!python/object:huggingface_hub.community.DiscussionWithDetails
author: PyrroAiakid
conflicting_files: null
created_at: 2023-08-16 01:31:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b4aa587f8ad819add3a48530ee5e2673.svg
      fullname: Jhon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: PyrroAiakid
      type: user
    createdAt: '2023-08-16T02:31:51.000Z'
    data:
      edited: false
      editors:
      - PyrroAiakid
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8056671619415283
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b4aa587f8ad819add3a48530ee5e2673.svg
          fullname: Jhon
          isHf: false
          isPro: false
          name: PyrroAiakid
          type: user
        html: '<p>Forgive me if it''s something very simple, but when I load the modlo
          I get an error.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/649faf41b248aaaa2d1c1fb5/G-Bwzia2Kx8TSnxff9Hwu.png"><img
          alt="Captura de pantalla 2023-08-15 212926.png" src="https://cdn-uploads.huggingface.co/production/uploads/649faf41b248aaaa2d1c1fb5/G-Bwzia2Kx8TSnxff9Hwu.png"></a></p>

          <p>They say I have to put -gqa 8 but I don''t know how to do it.</p>

          '
        raw: "Forgive me if it's something very simple, but when I load the modlo\
          \ I get an error.\r\n\r\n![Captura de pantalla 2023-08-15 212926.png](https://cdn-uploads.huggingface.co/production/uploads/649faf41b248aaaa2d1c1fb5/G-Bwzia2Kx8TSnxff9Hwu.png)\r\
          \n\r\nThey say I have to put -gqa 8 but I don't know how to do it."
        updatedAt: '2023-08-16T02:31:51.494Z'
      numEdits: 0
      reactions: []
    id: 64dc35175f144aa29f17f210
    type: comment
  author: PyrroAiakid
  content: "Forgive me if it's something very simple, but when I load the modlo I\
    \ get an error.\r\n\r\n![Captura de pantalla 2023-08-15 212926.png](https://cdn-uploads.huggingface.co/production/uploads/649faf41b248aaaa2d1c1fb5/G-Bwzia2Kx8TSnxff9Hwu.png)\r\
    \n\r\nThey say I have to put -gqa 8 but I don't know how to do it."
  created_at: 2023-08-16 01:31:51+00:00
  edited: false
  hidden: false
  id: 64dc35175f144aa29f17f210
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/67a290e83b559a3393d70014583ac702.svg
      fullname: Wayne Kenney Jr.
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: waynekenney
      type: user
    createdAt: '2023-09-03T09:03:25.000Z'
    data:
      edited: false
      editors:
      - waynekenney
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9449394345283508
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/67a290e83b559a3393d70014583ac702.svg
          fullname: Wayne Kenney Jr.
          isHf: false
          isPro: false
          name: waynekenney
          type: user
        html: '<p>I''m running into issues loading this model too. Gotta love our
          super helpful community, right? </p>

          '
        raw: 'I''m running into issues loading this model too. Gotta love our super
          helpful community, right? '
        updatedAt: '2023-09-03T09:03:25.889Z'
      numEdits: 0
      reactions: []
    id: 64f44bddbdde14c82b95209f
    type: comment
  author: waynekenney
  content: 'I''m running into issues loading this model too. Gotta love our super
    helpful community, right? '
  created_at: 2023-09-03 08:03:25+00:00
  edited: false
  hidden: false
  id: 64f44bddbdde14c82b95209f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/0H4Hegmgi1BP09WpqWdaI.jpeg?w=200&h=200&f=face
      fullname: Tanaka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Flanua
      type: user
    createdAt: '2023-09-06T22:30:09.000Z'
    data:
      edited: false
      editors:
      - Flanua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.970585823059082
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/0H4Hegmgi1BP09WpqWdaI.jpeg?w=200&h=200&f=face
          fullname: Tanaka
          isHf: false
          isPro: false
          name: Flanua
          type: user
        html: '<p>Why context length is 2048? Is it was cut on half? Base Llama 2
          model have 4096 context length. If it''s indeed 2048 then it''s not the
          first time the model gets massacred like that.</p>

          '
        raw: Why context length is 2048? Is it was cut on half? Base Llama 2 model
          have 4096 context length. If it's indeed 2048 then it's not the first time
          the model gets massacred like that.
        updatedAt: '2023-09-06T22:30:09.286Z'
      numEdits: 0
      reactions: []
    id: 64f8fd71e7584abc626c94c5
    type: comment
  author: Flanua
  content: Why context length is 2048? Is it was cut on half? Base Llama 2 model have
    4096 context length. If it's indeed 2048 then it's not the first time the model
    gets massacred like that.
  created_at: 2023-09-06 21:30:09+00:00
  edited: false
  hidden: false
  id: 64f8fd71e7584abc626c94c5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662098610747-noauth.jpeg?w=200&h=200&f=face
      fullname: Akarshan Biswas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: akarshanbiswas
      type: user
    createdAt: '2023-09-07T04:28:28.000Z'
    data:
      edited: true
      editors:
      - akarshanbiswas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8096763491630554
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662098610747-noauth.jpeg?w=200&h=200&f=face
          fullname: Akarshan Biswas
          isHf: false
          isPro: false
          name: akarshanbiswas
          type: user
        html: '<p>It''s just the GQA which should be 8 in 70B models. IF you multiply
          1024 by 8 it will be 8192. Try adding -gqa 8 parameter or set gqa as 8.</p>

          '
        raw: It's just the GQA which should be 8 in 70B models. IF you multiply 1024
          by 8 it will be 8192. Try adding -gqa 8 parameter or set gqa as 8.
        updatedAt: '2023-09-07T04:29:04.422Z'
      numEdits: 1
      reactions: []
    id: 64f9516cfe57e7455aca7d4a
    type: comment
  author: akarshanbiswas
  content: It's just the GQA which should be 8 in 70B models. IF you multiply 1024
    by 8 it will be 8192. Try adding -gqa 8 parameter or set gqa as 8.
  created_at: 2023-09-07 03:28:28+00:00
  edited: true
  hidden: false
  id: 64f9516cfe57e7455aca7d4a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/llama2_70b_chat_uncensored-GGML
repo_type: model
status: open
target_branch: null
title: Loading the model
