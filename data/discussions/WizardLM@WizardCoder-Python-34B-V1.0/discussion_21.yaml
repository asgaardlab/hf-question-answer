!!python/object:huggingface_hub.community.DiscussionWithDetails
author: FrankWu
conflicting_files: null
created_at: 2023-09-05 09:25:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6b64c63c46ae98363c7c1e4c35a73112.svg
      fullname: Frank Wu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: FrankWu
      type: user
    createdAt: '2023-09-05T10:25:49.000Z'
    data:
      edited: false
      editors:
      - FrankWu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8803881406784058
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6b64c63c46ae98363c7c1e4c35a73112.svg
          fullname: Frank Wu
          isHf: false
          isPro: false
          name: FrankWu
          type: user
        html: "<p>I meet this issue \"RuntimeError: probability tensor contains either\
          \ inf, nan or element &lt; 0\"\uFF0Cmy gpu is V100. Is there anyone no why?</p>\n"
        raw: "I meet this issue \"RuntimeError: probability tensor contains either\
          \ inf, nan or element < 0\"\uFF0Cmy gpu is V100. Is there anyone no why?"
        updatedAt: '2023-09-05T10:25:49.347Z'
      numEdits: 0
      reactions: []
    id: 64f7022d365c61c6be75066d
    type: comment
  author: FrankWu
  content: "I meet this issue \"RuntimeError: probability tensor contains either inf,\
    \ nan or element < 0\"\uFF0Cmy gpu is V100. Is there anyone no why?"
  created_at: 2023-09-05 09:25:49+00:00
  edited: false
  hidden: false
  id: 64f7022d365c61c6be75066d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/24633b955436e638a18a186749f42530.svg
      fullname: iCSawyer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iCSawyer
      type: user
    createdAt: '2023-09-05T14:19:09.000Z'
    data:
      edited: false
      editors:
      - iCSawyer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9524495601654053
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/24633b955436e638a18a186749f42530.svg
          fullname: iCSawyer
          isHf: false
          isPro: false
          name: iCSawyer
          type: user
        html: '<p>I ran into this problem with 7B model. I have solved it by using
          bf16 precision and replacing <code>model.half()</code> with <code>model.bfloat16()</code>.
          Maybe you can try this.</p>

          '
        raw: I ran into this problem with 7B model. I have solved it by using bf16
          precision and replacing `model.half()` with `model.bfloat16()`. Maybe you
          can try this.
        updatedAt: '2023-09-05T14:19:09.223Z'
      numEdits: 0
      reactions: []
    id: 64f738dd783289f0c2351d31
    type: comment
  author: iCSawyer
  content: I ran into this problem with 7B model. I have solved it by using bf16 precision
    and replacing `model.half()` with `model.bfloat16()`. Maybe you can try this.
  created_at: 2023-09-05 13:19:09+00:00
  edited: false
  hidden: false
  id: 64f738dd783289f0c2351d31
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6b64c63c46ae98363c7c1e4c35a73112.svg
      fullname: Frank Wu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: FrankWu
      type: user
    createdAt: '2023-09-05T14:37:52.000Z'
    data:
      edited: false
      editors:
      - FrankWu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8397054076194763
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6b64c63c46ae98363c7c1e4c35a73112.svg
          fullname: Frank Wu
          isHf: false
          isPro: false
          name: FrankWu
          type: user
        html: "<p>aha\uFF0CV100 doesn't support bf16. It is said that fp16 usually\
          \  is ok to do inference.But i also found</p>\n<p><a rel=\"nofollow\" href=\"\
          https://cdn-uploads.huggingface.co/production/uploads/64706234cf0a68ad56a93f03/mqZPS-fls7CSnVC4I_INv.png\"\
          ><img alt=\"\u56FE\u7247.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64706234cf0a68ad56a93f03/mqZPS-fls7CSnVC4I_INv.png\"\
          ></a></p>\n<p>It seems that codellama is pretrained with bf16  <a rel=\"\
          nofollow\" href=\"https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf/blob/main/config.json\"\
          ><img alt=\"codellama\" src=\"https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf/blob/main/config.json\"\
          ></a></p>\n"
        raw: "aha\uFF0CV100 doesn't support bf16. It is said that fp16 usually  is\
          \ ok to do inference.But i also found\n\n![\u56FE\u7247.png](https://cdn-uploads.huggingface.co/production/uploads/64706234cf0a68ad56a93f03/mqZPS-fls7CSnVC4I_INv.png)\n\
          \nIt seems that codellama is pretrained with bf16  ![codellama](https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf/blob/main/config.json)"
        updatedAt: '2023-09-05T14:37:52.825Z'
      numEdits: 0
      reactions: []
    id: 64f73d4061afe1d3356af99f
    type: comment
  author: FrankWu
  content: "aha\uFF0CV100 doesn't support bf16. It is said that fp16 usually  is ok\
    \ to do inference.But i also found\n\n![\u56FE\u7247.png](https://cdn-uploads.huggingface.co/production/uploads/64706234cf0a68ad56a93f03/mqZPS-fls7CSnVC4I_INv.png)\n\
    \nIt seems that codellama is pretrained with bf16  ![codellama](https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf/blob/main/config.json)"
  created_at: 2023-09-05 13:37:52+00:00
  edited: false
  hidden: false
  id: 64f73d4061afe1d3356af99f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/24633b955436e638a18a186749f42530.svg
      fullname: iCSawyer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iCSawyer
      type: user
    createdAt: '2023-09-05T14:43:47.000Z'
    data:
      edited: true
      editors:
      - iCSawyer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9513600468635559
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/24633b955436e638a18a186749f42530.svg
          fullname: iCSawyer
          isHf: false
          isPro: false
          name: iCSawyer
          type: user
        html: "<p>haha, I found this solution </p>\n<blockquote>\n<p>I ran into this\
          \ problem with 7B model. I have solved it by using bf16 precision and replacing\
          \ <code>model.half()</code> with <code>model.bfloat16()</code>. Maybe you\
          \ can try this.</p>\n</blockquote>\n<p>using <code>llama</code> keyword\
          \ which is the foundation model \U0001F923 </p>\n<p>maybe you can try fp32\
          \ or 8/4bit</p>\n"
        raw: "haha, I found this solution \n> I ran into this problem with 7B model.\
          \ I have solved it by using bf16 precision and replacing `model.half()`\
          \ with `model.bfloat16()`. Maybe you can try this.\n\nusing `llama` keyword\
          \ which is the foundation model \U0001F923 \n\nmaybe you can try fp32 or\
          \ 8/4bit"
        updatedAt: '2023-09-05T14:43:58.553Z'
      numEdits: 1
      reactions: []
    id: 64f73ea3db38c520bd1af382
    type: comment
  author: iCSawyer
  content: "haha, I found this solution \n> I ran into this problem with 7B model.\
    \ I have solved it by using bf16 precision and replacing `model.half()` with `model.bfloat16()`.\
    \ Maybe you can try this.\n\nusing `llama` keyword which is the foundation model\
    \ \U0001F923 \n\nmaybe you can try fp32 or 8/4bit"
  created_at: 2023-09-05 13:43:47+00:00
  edited: true
  hidden: false
  id: 64f73ea3db38c520bd1af382
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6b64c63c46ae98363c7c1e4c35a73112.svg
      fullname: Frank Wu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: FrankWu
      type: user
    createdAt: '2023-09-06T02:15:30.000Z'
    data:
      edited: false
      editors:
      - FrankWu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8661038875579834
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6b64c63c46ae98363c7c1e4c35a73112.svg
          fullname: Frank Wu
          isHf: false
          isPro: false
          name: FrankWu
          type: user
        html: '<p>set load_8_bit or load_4_bit =True, it''s ok. But set torch_dtype=torch.float32
          is still NG. It''s very strange</p>

          '
        raw: set load_8_bit or load_4_bit =True, it's ok. But set torch_dtype=torch.float32
          is still NG. It's very strange
        updatedAt: '2023-09-06T02:15:30.276Z'
      numEdits: 0
      reactions: []
    id: 64f7e0c292c40ce4823f8ff0
    type: comment
  author: FrankWu
  content: set load_8_bit or load_4_bit =True, it's ok. But set torch_dtype=torch.float32
    is still NG. It's very strange
  created_at: 2023-09-06 01:15:30+00:00
  edited: false
  hidden: false
  id: 64f7e0c292c40ce4823f8ff0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6b64c63c46ae98363c7c1e4c35a73112.svg
      fullname: Frank Wu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: FrankWu
      type: user
    createdAt: '2023-09-06T13:09:40.000Z'
    data:
      edited: false
      editors:
      - FrankWu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8956440687179565
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6b64c63c46ae98363c7c1e4c35a73112.svg
          fullname: Frank Wu
          isHf: false
          isPro: false
          name: FrankWu
          type: user
        html: '<p>Maybe this is just Wizardcode issue, i try another codellama version
          ok</p>

          '
        raw: Maybe this is just Wizardcode issue, i try another codellama version
          ok
        updatedAt: '2023-09-06T13:09:40.905Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64f87a146389380c7782a5d9
    id: 64f87a146389380c7782a5d6
    type: comment
  author: FrankWu
  content: Maybe this is just Wizardcode issue, i try another codellama version ok
  created_at: 2023-09-06 12:09:40+00:00
  edited: false
  hidden: false
  id: 64f87a146389380c7782a5d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/6b64c63c46ae98363c7c1e4c35a73112.svg
      fullname: Frank Wu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: FrankWu
      type: user
    createdAt: '2023-09-06T13:09:40.000Z'
    data:
      status: closed
    id: 64f87a146389380c7782a5d9
    type: status-change
  author: FrankWu
  created_at: 2023-09-06 12:09:40+00:00
  id: 64f87a146389380c7782a5d9
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 21
repo_id: WizardLM/WizardCoder-Python-34B-V1.0
repo_type: model
status: closed
target_branch: null
title: 'RuntimeError: probability tensor contains either inf, nan or element < 0'
