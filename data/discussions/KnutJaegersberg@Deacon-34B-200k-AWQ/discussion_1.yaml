!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gaboukassm
conflicting_files: null
created_at: 2023-11-13 04:32:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/16811bbf3cd91342c06682173fcb84d0.svg
      fullname: George Abou Kassm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gaboukassm
      type: user
    createdAt: '2023-11-13T04:32:17.000Z'
    data:
      edited: false
      editors:
      - gaboukassm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9692626595497131
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/16811bbf3cd91342c06682173fcb84d0.svg
          fullname: George Abou Kassm
          isHf: false
          isPro: false
          name: gaboukassm
          type: user
        html: '<p>Hi,</p>

          <p>What kind of setup would be required to run your model ?<br>I am new
          to this and would appreciate your help .<br>I am planning on running this
          on a GPU setup but even using 4xRTX4090 or 2X A100 , the system kept going
          out of memory , so i was wondering what king of setup do i need to have
          for this to run efficiently ?</p>

          <p>Thank you</p>

          '
        raw: "Hi,\r\n\r\nWhat kind of setup would be required to run your model ?\
          \ \r\nI am new to this and would appreciate your help .\r\nI am planning\
          \ on running this on a GPU setup but even using 4xRTX4090 or 2X A100 , the\
          \ system kept going out of memory , so i was wondering what king of setup\
          \ do i need to have for this to run efficiently ?\r\n\r\nThank you"
        updatedAt: '2023-11-13T04:32:17.927Z'
      numEdits: 0
      reactions: []
    id: 6551a6d10f44a05d81f15777
    type: comment
  author: gaboukassm
  content: "Hi,\r\n\r\nWhat kind of setup would be required to run your model ? \r\
    \nI am new to this and would appreciate your help .\r\nI am planning on running\
    \ this on a GPU setup but even using 4xRTX4090 or 2X A100 , the system kept going\
    \ out of memory , so i was wondering what king of setup do i need to have for\
    \ this to run efficiently ?\r\n\r\nThank you"
  created_at: 2023-11-13 04:32:17+00:00
  edited: false
  hidden: false
  id: 6551a6d10f44a05d81f15777
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-13T07:46:54.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7953973412513733
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>It depends on the settings. 2 4090 should be more than enough for
          a lot of use cases.<br>Without fused attention, it''s 27 gb vram, will need
          some if if yo do stuff. </p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63732ebbbd81fae2b3aaf3fb/1cbqKp55WhN4BQD337E-n.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/63732ebbbd81fae2b3aaf3fb/1cbqKp55WhN4BQD337E-n.png"></a></p>

          <p>You can also let if have fused attention and just reduce the max_seq_length
          to something way smaller yet still useful</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63732ebbbd81fae2b3aaf3fb/JRi4sakPziGpmOFCBfcJS.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/63732ebbbd81fae2b3aaf3fb/JRi4sakPziGpmOFCBfcJS.png"></a></p>

          '
        raw: "It depends on the settings. 2 4090 should be more than enough for a\
          \ lot of use cases. \nWithout fused attention, it's 27 gb vram, will need\
          \ some if if yo do stuff. \n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63732ebbbd81fae2b3aaf3fb/1cbqKp55WhN4BQD337E-n.png)\n\
          \nYou can also let if have fused attention and just reduce the max_seq_length\
          \ to something way smaller yet still useful\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63732ebbbd81fae2b3aaf3fb/JRi4sakPziGpmOFCBfcJS.png)\n\
          \n"
        updatedAt: '2023-11-13T07:46:54.210Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - gaboukassm
      relatedEventId: 6551d46e0aa8eba4c27231b0
    id: 6551d46e0aa8eba4c27231ae
    type: comment
  author: KnutJaegersberg
  content: "It depends on the settings. 2 4090 should be more than enough for a lot\
    \ of use cases. \nWithout fused attention, it's 27 gb vram, will need some if\
    \ if yo do stuff. \n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63732ebbbd81fae2b3aaf3fb/1cbqKp55WhN4BQD337E-n.png)\n\
    \nYou can also let if have fused attention and just reduce the max_seq_length\
    \ to something way smaller yet still useful\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63732ebbbd81fae2b3aaf3fb/JRi4sakPziGpmOFCBfcJS.png)\n\
    \n"
  created_at: 2023-11-13 07:46:54+00:00
  edited: false
  hidden: false
  id: 6551d46e0aa8eba4c27231ae
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-13T07:46:54.000Z'
    data:
      status: closed
    id: 6551d46e0aa8eba4c27231b0
    type: status-change
  author: KnutJaegersberg
  created_at: 2023-11-13 07:46:54+00:00
  id: 6551d46e0aa8eba4c27231b0
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/16811bbf3cd91342c06682173fcb84d0.svg
      fullname: George Abou Kassm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gaboukassm
      type: user
    createdAt: '2023-11-16T03:34:48.000Z'
    data:
      status: open
    id: 65558dd8710bb1dad219e1c0
    type: status-change
  author: gaboukassm
  created_at: 2023-11-16 03:34:48+00:00
  id: 65558dd8710bb1dad219e1c0
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/16811bbf3cd91342c06682173fcb84d0.svg
      fullname: George Abou Kassm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gaboukassm
      type: user
    createdAt: '2023-11-16T03:35:28.000Z'
    data:
      edited: false
      editors:
      - gaboukassm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8511235117912292
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/16811bbf3cd91342c06682173fcb84d0.svg
          fullname: George Abou Kassm
          isHf: false
          isPro: false
          name: gaboukassm
          type: user
        html: '<p>Thank you so much for your reply and sorry for my silly question
          but what is this tool you''re using (not the nvtop) to load the module and
          specify sequence length etc ?</p>

          '
        raw: Thank you so much for your reply and sorry for my silly question but
          what is this tool you're using (not the nvtop) to load the module and specify
          sequence length etc ?
        updatedAt: '2023-11-16T03:35:28.345Z'
      numEdits: 0
      reactions: []
    id: 65558e00bcf02b4c4c698523
    type: comment
  author: gaboukassm
  content: Thank you so much for your reply and sorry for my silly question but what
    is this tool you're using (not the nvtop) to load the module and specify sequence
    length etc ?
  created_at: 2023-11-16 03:35:28+00:00
  edited: false
  hidden: false
  id: 65558e00bcf02b4c4c698523
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-16T06:08:29.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4957011342048645
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>It''s <a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui">https://github.com/oobabooga/text-generation-webui</a><br>These
          options are part of autoawq<br><a rel="nofollow" href="https://github.com/casper-hansen/AutoAWQ">https://github.com/casper-hansen/AutoAWQ</a><br>fuse_layers=True<br>max_new_tokens=seq_len</p>

          '
        raw: "It's https://github.com/oobabooga/text-generation-webui \nThese options\
          \ are part of autoawq \nhttps://github.com/casper-hansen/AutoAWQ\nfuse_layers=True\n\
          max_new_tokens=seq_len"
        updatedAt: '2023-11-16T06:08:29.863Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - gaboukassm
      relatedEventId: 6555b1dd7cca2ba493f7d6b8
    id: 6555b1dd7cca2ba493f7d6b5
    type: comment
  author: KnutJaegersberg
  content: "It's https://github.com/oobabooga/text-generation-webui \nThese options\
    \ are part of autoawq \nhttps://github.com/casper-hansen/AutoAWQ\nfuse_layers=True\n\
    max_new_tokens=seq_len"
  created_at: 2023-11-16 06:08:29+00:00
  edited: false
  hidden: false
  id: 6555b1dd7cca2ba493f7d6b5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-16T06:08:29.000Z'
    data:
      status: closed
    id: 6555b1dd7cca2ba493f7d6b8
    type: status-change
  author: KnutJaegersberg
  created_at: 2023-11-16 06:08:29+00:00
  id: 6555b1dd7cca2ba493f7d6b8
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: KnutJaegersberg/Deacon-34B-200k-AWQ
repo_type: model
status: closed
target_branch: null
title: System requirements
