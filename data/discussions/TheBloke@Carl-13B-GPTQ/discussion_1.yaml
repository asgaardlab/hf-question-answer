!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ajibawa-2023
conflicting_files: null
created_at: 2023-08-16 18:21:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-08-16T19:21:49.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9203271865844727
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Hello, Thank you for all the GGML &amp; GPTQ models of Carl &amp;
          Scarlett. I highly appreciate your work &amp; help. I will post more models
          very soon. Thanks!</p>

          '
        raw: Hello, Thank you for all the GGML & GPTQ models of Carl & Scarlett. I
          highly appreciate your work & help. I will post more models very soon. Thanks!
        updatedAt: '2023-08-16T19:21:49.264Z'
      numEdits: 0
      reactions: []
    id: 64dd21cd5f21fb7f85af0af0
    type: comment
  author: ajibawa-2023
  content: Hello, Thank you for all the GGML & GPTQ models of Carl & Scarlett. I highly
    appreciate your work & help. I will post more models very soon. Thanks!
  created_at: 2023-08-16 18:21:49+00:00
  edited: false
  hidden: false
  id: 64dd21cd5f21fb7f85af0af0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-16T19:28:25.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6843470335006714
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>You're very welcome! Thank you for the great new models.</p>\n<p>I\
          \ was going to message you actually, I wanted to let you know a couple of\
          \ things that would make it easier for people to download your models:</p>\n\
          <ol>\n<li>Firstly, your models are in float32. This makes it twice as large\
          \ to download</li>\n<li>Secondly, you output in a single pytorch_model.bin\
          \ which I imagine is why you then split it up using <code>split</code> -\
          \ because of the 50GB file limit?  That requires the extra <code>cat pytorch_model.bin-a*\
          \ &gt; pytorch_model.bin</code> step for people downloading, and also means\
          \ the model can never work automatically from Transformers.</li>\n</ol>\n\
          <ul>\n<li>Also, it's usually much quicker to load a model from multiple\
          \ shards than from one single pytorch_model.bin file. And it takes less\
          \ RAM to do so.</li>\n</ul>\n<p>Fortunately there's an easy way to fix both\
          \ problems in one.  Here's a little script I wrote:  <a rel=\"nofollow\"\
          \ href=\"https://gist.github.com/TheBloke/8934a51c5572b500c5217f42bfd055a8#file-reshard-py\"\
          >https://gist.github.com/TheBloke/8934a51c5572b500c5217f42bfd055a8#file-reshard-py</a></p>\n\
          <p>Run it like this:</p>\n<pre><code> python3 reshard.py --base_model_name_or_path\
          \ &lt;path to your model&gt; --output_dir &lt;path to output to&gt; --device\
          \ cpu --max_shard_size '8GiB' --dtype bfloat16\n</code></pre>\n<p>And it\
          \ will create a float16 model (or bfloat16 model with <code>--dtype bfloat16</code>,\
          \ which matches the format your models were in) split into chunks like this:</p>\n\
          <pre><code> [venv] tomj@2b8eac64e03a:/workspace/process/carl-33b \u1405\
          \ l source\ntotal 61G\ndrwxrwxrwx 2 tomj tomj 2.9M Aug 16 14:36 .\ndrwxrwxrwx\
          \ 5 tomj tomj 3.0M Aug 16 15:44 ..\n-rw-rw-rw- 1 tomj tomj 2.3K Aug 16 13:16\
          \ .gitattributes\n-rw-rw-rw- 1 tomj tomj 1.7K Aug 16 13:16 README.md\n-rw-rw-rw-\
          \ 1 tomj tomj  690 Aug 16 14:37 config.json\n-rw-rw-rw- 1 tomj tomj  137\
          \ Aug 16 13:52 generation_config.json\n-rw-rw-rw- 1 tomj tomj 8.0G Aug 16\
          \ 13:52 pytorch_model-00001-of-00008.bin\n-rw-rw-rw- 1 tomj tomj 8.0G Aug\
          \ 16 13:53 pytorch_model-00002-of-00008.bin\n-rw-rw-rw- 1 tomj tomj 8.0G\
          \ Aug 16 13:53 pytorch_model-00003-of-00008.bin\n-rw-rw-rw- 1 tomj tomj\
          \ 8.0G Aug 16 13:53 pytorch_model-00004-of-00008.bin\n-rw-rw-rw- 1 tomj\
          \ tomj 8.0G Aug 16 13:53 pytorch_model-00005-of-00008.bin\n-rw-rw-rw- 1\
          \ tomj tomj 8.0G Aug 16 13:54 pytorch_model-00006-of-00008.bin\n-rw-rw-rw-\
          \ 1 tomj tomj 8.0G Aug 16 13:54 pytorch_model-00007-of-00008.bin\n-rw-rw-rw-\
          \ 1 tomj tomj 4.9G Aug 16 13:54 pytorch_model-00008-of-00008.bin\n-rw-rw-rw-\
          \ 1 tomj tomj  44K Aug 16 13:54 pytorch_model.bin.index.json\n-rw-rw-rw-\
          \ 1 tomj tomj  435 Aug 16 13:54 special_tokens_map.json\n-rw-rw-rw- 1 tomj\
          \ tomj 1.8M Aug 16 13:54 tokenizer.json\n-rw-rw-rw- 1 tomj tomj 489K Aug\
          \ 16 13:54 tokenizer.model\n-rw-rw-rw- 1 tomj tomj  745 Aug 16 13:54 tokenizer_config.json\n\
          </code></pre>\n<p>Then you can upload that and won't have any 50GB problems,\
          \ and people can download it and use it immediately, including automatically\
          \ from Transformers code.  And it'll be in float16, not float32, so it only\
          \ requires half as much time to upload and download.</p>\n<p>I still have\
          \ the sharded files for Carl-33B and Scarlette-33B so if you like I could\
          \ PR the bf16 sharded version to your repos. Let me know if that'd be helpful.</p>\n\
          <p>Thanks again for the great models and looking forward to seeing more!\
          \  Feel free to ping me when they're up and I'll quantise them.</p>\n"
        raw: "You're very welcome! Thank you for the great new models.\n\nI was going\
          \ to message you actually, I wanted to let you know a couple of things that\
          \ would make it easier for people to download your models:\n\n1. Firstly,\
          \ your models are in float32. This makes it twice as large to download\n\
          2. Secondly, you output in a single pytorch_model.bin which I imagine is\
          \ why you then split it up using `split` - because of the 50GB file limit?\
          \  That requires the extra `cat pytorch_model.bin-a* > pytorch_model.bin`\
          \ step for people downloading, and also means the model can never work automatically\
          \ from Transformers.\n  - Also, it's usually much quicker to load a model\
          \ from multiple shards than from one single pytorch_model.bin file. And\
          \ it takes less RAM to do so.\n\nFortunately there's an easy way to fix\
          \ both problems in one.  Here's a little script I wrote:  https://gist.github.com/TheBloke/8934a51c5572b500c5217f42bfd055a8#file-reshard-py\n\
          \nRun it like this:\n```\n python3 reshard.py --base_model_name_or_path\
          \ <path to your model> --output_dir <path to output to> --device cpu --max_shard_size\
          \ '8GiB' --dtype bfloat16\n```\n\nAnd it will create a float16 model (or\
          \ bfloat16 model with `--dtype bfloat16`, which matches the format your\
          \ models were in) split into chunks like this:\n```\n [venv] tomj@2b8eac64e03a:/workspace/process/carl-33b\
          \ \u1405 l source\ntotal 61G\ndrwxrwxrwx 2 tomj tomj 2.9M Aug 16 14:36 .\n\
          drwxrwxrwx 5 tomj tomj 3.0M Aug 16 15:44 ..\n-rw-rw-rw- 1 tomj tomj 2.3K\
          \ Aug 16 13:16 .gitattributes\n-rw-rw-rw- 1 tomj tomj 1.7K Aug 16 13:16\
          \ README.md\n-rw-rw-rw- 1 tomj tomj  690 Aug 16 14:37 config.json\n-rw-rw-rw-\
          \ 1 tomj tomj  137 Aug 16 13:52 generation_config.json\n-rw-rw-rw- 1 tomj\
          \ tomj 8.0G Aug 16 13:52 pytorch_model-00001-of-00008.bin\n-rw-rw-rw- 1\
          \ tomj tomj 8.0G Aug 16 13:53 pytorch_model-00002-of-00008.bin\n-rw-rw-rw-\
          \ 1 tomj tomj 8.0G Aug 16 13:53 pytorch_model-00003-of-00008.bin\n-rw-rw-rw-\
          \ 1 tomj tomj 8.0G Aug 16 13:53 pytorch_model-00004-of-00008.bin\n-rw-rw-rw-\
          \ 1 tomj tomj 8.0G Aug 16 13:53 pytorch_model-00005-of-00008.bin\n-rw-rw-rw-\
          \ 1 tomj tomj 8.0G Aug 16 13:54 pytorch_model-00006-of-00008.bin\n-rw-rw-rw-\
          \ 1 tomj tomj 8.0G Aug 16 13:54 pytorch_model-00007-of-00008.bin\n-rw-rw-rw-\
          \ 1 tomj tomj 4.9G Aug 16 13:54 pytorch_model-00008-of-00008.bin\n-rw-rw-rw-\
          \ 1 tomj tomj  44K Aug 16 13:54 pytorch_model.bin.index.json\n-rw-rw-rw-\
          \ 1 tomj tomj  435 Aug 16 13:54 special_tokens_map.json\n-rw-rw-rw- 1 tomj\
          \ tomj 1.8M Aug 16 13:54 tokenizer.json\n-rw-rw-rw- 1 tomj tomj 489K Aug\
          \ 16 13:54 tokenizer.model\n-rw-rw-rw- 1 tomj tomj  745 Aug 16 13:54 tokenizer_config.json\n\
          ```\n\nThen you can upload that and won't have any 50GB problems, and people\
          \ can download it and use it immediately, including automatically from Transformers\
          \ code.  And it'll be in float16, not float32, so it only requires half\
          \ as much time to upload and download.\n\nI still have the sharded files\
          \ for Carl-33B and Scarlette-33B so if you like I could PR the bf16 sharded\
          \ version to your repos. Let me know if that'd be helpful.\n\nThanks again\
          \ for the great models and looking forward to seeing more!  Feel free to\
          \ ping me when they're up and I'll quantise them.\n\n"
        updatedAt: '2023-08-16T19:30:10.898Z'
      numEdits: 2
      reactions: []
    id: 64dd2359a4b9ebcd2b1a5598
    type: comment
  author: TheBloke
  content: "You're very welcome! Thank you for the great new models.\n\nI was going\
    \ to message you actually, I wanted to let you know a couple of things that would\
    \ make it easier for people to download your models:\n\n1. Firstly, your models\
    \ are in float32. This makes it twice as large to download\n2. Secondly, you output\
    \ in a single pytorch_model.bin which I imagine is why you then split it up using\
    \ `split` - because of the 50GB file limit?  That requires the extra `cat pytorch_model.bin-a*\
    \ > pytorch_model.bin` step for people downloading, and also means the model can\
    \ never work automatically from Transformers.\n  - Also, it's usually much quicker\
    \ to load a model from multiple shards than from one single pytorch_model.bin\
    \ file. And it takes less RAM to do so.\n\nFortunately there's an easy way to\
    \ fix both problems in one.  Here's a little script I wrote:  https://gist.github.com/TheBloke/8934a51c5572b500c5217f42bfd055a8#file-reshard-py\n\
    \nRun it like this:\n```\n python3 reshard.py --base_model_name_or_path <path\
    \ to your model> --output_dir <path to output to> --device cpu --max_shard_size\
    \ '8GiB' --dtype bfloat16\n```\n\nAnd it will create a float16 model (or bfloat16\
    \ model with `--dtype bfloat16`, which matches the format your models were in)\
    \ split into chunks like this:\n```\n [venv] tomj@2b8eac64e03a:/workspace/process/carl-33b\
    \ \u1405 l source\ntotal 61G\ndrwxrwxrwx 2 tomj tomj 2.9M Aug 16 14:36 .\ndrwxrwxrwx\
    \ 5 tomj tomj 3.0M Aug 16 15:44 ..\n-rw-rw-rw- 1 tomj tomj 2.3K Aug 16 13:16 .gitattributes\n\
    -rw-rw-rw- 1 tomj tomj 1.7K Aug 16 13:16 README.md\n-rw-rw-rw- 1 tomj tomj  690\
    \ Aug 16 14:37 config.json\n-rw-rw-rw- 1 tomj tomj  137 Aug 16 13:52 generation_config.json\n\
    -rw-rw-rw- 1 tomj tomj 8.0G Aug 16 13:52 pytorch_model-00001-of-00008.bin\n-rw-rw-rw-\
    \ 1 tomj tomj 8.0G Aug 16 13:53 pytorch_model-00002-of-00008.bin\n-rw-rw-rw- 1\
    \ tomj tomj 8.0G Aug 16 13:53 pytorch_model-00003-of-00008.bin\n-rw-rw-rw- 1 tomj\
    \ tomj 8.0G Aug 16 13:53 pytorch_model-00004-of-00008.bin\n-rw-rw-rw- 1 tomj tomj\
    \ 8.0G Aug 16 13:53 pytorch_model-00005-of-00008.bin\n-rw-rw-rw- 1 tomj tomj 8.0G\
    \ Aug 16 13:54 pytorch_model-00006-of-00008.bin\n-rw-rw-rw- 1 tomj tomj 8.0G Aug\
    \ 16 13:54 pytorch_model-00007-of-00008.bin\n-rw-rw-rw- 1 tomj tomj 4.9G Aug 16\
    \ 13:54 pytorch_model-00008-of-00008.bin\n-rw-rw-rw- 1 tomj tomj  44K Aug 16 13:54\
    \ pytorch_model.bin.index.json\n-rw-rw-rw- 1 tomj tomj  435 Aug 16 13:54 special_tokens_map.json\n\
    -rw-rw-rw- 1 tomj tomj 1.8M Aug 16 13:54 tokenizer.json\n-rw-rw-rw- 1 tomj tomj\
    \ 489K Aug 16 13:54 tokenizer.model\n-rw-rw-rw- 1 tomj tomj  745 Aug 16 13:54\
    \ tokenizer_config.json\n```\n\nThen you can upload that and won't have any 50GB\
    \ problems, and people can download it and use it immediately, including automatically\
    \ from Transformers code.  And it'll be in float16, not float32, so it only requires\
    \ half as much time to upload and download.\n\nI still have the sharded files\
    \ for Carl-33B and Scarlette-33B so if you like I could PR the bf16 sharded version\
    \ to your repos. Let me know if that'd be helpful.\n\nThanks again for the great\
    \ models and looking forward to seeing more!  Feel free to ping me when they're\
    \ up and I'll quantise them.\n\n"
  created_at: 2023-08-16 18:28:25+00:00
  edited: true
  hidden: false
  id: 64dd2359a4b9ebcd2b1a5598
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-08-16T19:35:23.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8938143849372864
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Thank you very much for making my &amp; other users life easy. I
          will use the script for sure!<br>You surely can PR the bf16 sharded version
          to my repos. That will be great!<br>Thank you!</p>

          '
        raw: "Thank you very much for making my & other users life easy. I will use\
          \ the script for sure! \nYou surely can PR the bf16 sharded version to my\
          \ repos. That will be great! \nThank you!"
        updatedAt: '2023-08-16T19:35:23.057Z'
      numEdits: 0
      reactions: []
    id: 64dd24fb77af4902fe5e0db8
    type: comment
  author: ajibawa-2023
  content: "Thank you very much for making my & other users life easy. I will use\
    \ the script for sure! \nYou surely can PR the bf16 sharded version to my repos.\
    \ That will be great! \nThank you!"
  created_at: 2023-08-16 18:35:23+00:00
  edited: false
  hidden: false
  id: 64dd24fb77af4902fe5e0db8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-09-01T18:54:24.000Z'
    data:
      edited: true
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9411717653274536
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Hello Bloke, sorry to bother you. Heartiest congratulations on winning
          the a16z grant! You guys deserve it! </p>

          '
        raw: "Hello Bloke, sorry to bother you. Heartiest congratulations on winning\
          \ the a16z grant! You guys deserve it! \n"
        updatedAt: '2023-09-14T18:59:11.160Z'
      numEdits: 1
      reactions: []
    id: 64f233605428b3903ef1c585
    type: comment
  author: ajibawa-2023
  content: "Hello Bloke, sorry to bother you. Heartiest congratulations on winning\
    \ the a16z grant! You guys deserve it! \n"
  created_at: 2023-09-01 17:54:24+00:00
  edited: true
  hidden: false
  id: 64f233605428b3903ef1c585
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-09-14T18:58:56.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7382751703262329
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Hello Bloke,<br> Can you do the GPTQ &amp; GGML for the following
          models:</p>

          <ol>

          <li><a href="https://huggingface.co/ajibawa-2023/Uncensored-Frank-7B">https://huggingface.co/ajibawa-2023/Uncensored-Frank-7B</a></li>

          <li><a href="https://huggingface.co/ajibawa-2023/Uncensored-Frank-13B">https://huggingface.co/ajibawa-2023/Uncensored-Frank-13B</a></li>

          <li><a href="https://huggingface.co/ajibawa-2023/Uncensored-Frank-33B">https://huggingface.co/ajibawa-2023/Uncensored-Frank-33B</a><br>Looking
          forward to hearing from you. Thank you very much for sharing the script
          and necessary instructions.</li>

          </ol>

          '
        raw: "Hello Bloke,\n Can you do the GPTQ & GGML for the following models:\n\
          1. https://huggingface.co/ajibawa-2023/Uncensored-Frank-7B\n2. https://huggingface.co/ajibawa-2023/Uncensored-Frank-13B\n\
          3. https://huggingface.co/ajibawa-2023/Uncensored-Frank-33B\nLooking forward\
          \ to hearing from you. Thank you very much for sharing the script and necessary\
          \ instructions.\n"
        updatedAt: '2023-09-14T18:58:56.718Z'
      numEdits: 0
      reactions: []
    id: 650357f0dcfe8fd06a626e35
    type: comment
  author: ajibawa-2023
  content: "Hello Bloke,\n Can you do the GPTQ & GGML for the following models:\n\
    1. https://huggingface.co/ajibawa-2023/Uncensored-Frank-7B\n2. https://huggingface.co/ajibawa-2023/Uncensored-Frank-13B\n\
    3. https://huggingface.co/ajibawa-2023/Uncensored-Frank-33B\nLooking forward to\
    \ hearing from you. Thank you very much for sharing the script and necessary instructions.\n"
  created_at: 2023-09-14 17:58:56+00:00
  edited: false
  hidden: false
  id: 650357f0dcfe8fd06a626e35
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-09-19T13:24:39.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9210924506187439
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Hello Bloke, Any luck with quantization of above models. I highly
          appreciate your work for open source community. Thank you!</p>

          '
        raw: Hello Bloke, Any luck with quantization of above models. I highly appreciate
          your work for open source community. Thank you!
        updatedAt: '2023-09-19T13:24:39.004Z'
      numEdits: 0
      reactions: []
    id: 6509a1171b3694179de1a641
    type: comment
  author: ajibawa-2023
  content: Hello Bloke, Any luck with quantization of above models. I highly appreciate
    your work for open source community. Thank you!
  created_at: 2023-09-19 12:24:39+00:00
  edited: false
  hidden: false
  id: 6509a1171b3694179de1a641
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-09-19T13:29:26.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9931843876838684
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Oh sorry, I didn''t see this.  I''ll add them to the queue and do
          them shortly, in GPTQ, GGUF and AWQ</p>

          '
        raw: Oh sorry, I didn't see this.  I'll add them to the queue and do them
          shortly, in GPTQ, GGUF and AWQ
        updatedAt: '2023-09-19T13:29:26.358Z'
      numEdits: 0
      reactions: []
    id: 6509a23661c4bb4636fbe881
    type: comment
  author: TheBloke
  content: Oh sorry, I didn't see this.  I'll add them to the queue and do them shortly,
    in GPTQ, GGUF and AWQ
  created_at: 2023-09-19 12:29:26+00:00
  edited: false
  hidden: false
  id: 6509a23661c4bb4636fbe881
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-09-19T13:34:13.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8606921434402466
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Surely, super thankful to you!</p>

          '
        raw: Surely, super thankful to you!
        updatedAt: '2023-09-19T13:34:13.611Z'
      numEdits: 0
      reactions: []
    id: 6509a355ad753305dec95515
    type: comment
  author: ajibawa-2023
  content: Surely, super thankful to you!
  created_at: 2023-09-19 12:34:13+00:00
  edited: false
  hidden: false
  id: 6509a355ad753305dec95515
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-09-19T23:29:37.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9790911078453064
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Models are starting to upload now</p>

          '
        raw: Models are starting to upload now
        updatedAt: '2023-09-19T23:29:37.623Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jlzhou
    id: 650a2ee16d2284f7325e6e9c
    type: comment
  author: TheBloke
  content: Models are starting to upload now
  created_at: 2023-09-19 22:29:37+00:00
  edited: false
  hidden: false
  id: 650a2ee16d2284f7325e6e9c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-09-20T16:27:44.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9844394326210022
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Thank you very much Bloke!</p>

          '
        raw: Thank you very much Bloke!
        updatedAt: '2023-09-20T16:27:44.466Z'
      numEdits: 0
      reactions: []
    id: 650b1d805510464e85949323
    type: comment
  author: ajibawa-2023
  content: Thank you very much Bloke!
  created_at: 2023-09-20 15:27:44+00:00
  edited: false
  hidden: false
  id: 650b1d805510464e85949323
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-10-10T14:01:25.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-10-11T07:11:41.474Z'
      numEdits: 0
      reactions: []
    id: 652559359e97bb9586d86da8
    type: comment
  author: ajibawa-2023
  content: This comment has been hidden
  created_at: 2023-10-10 13:01:25+00:00
  edited: true
  hidden: true
  id: 652559359e97bb9586d86da8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-10-30T20:10:27.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7369902729988098
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Hello Bloke,<br>   I hope you are doing great! Can you help me by
          quantizing my following new models:</p>

          <ol>

          <li>Uncensored-Jordan-7B :  <a href="https://huggingface.co/ajibawa-2023/Uncensored-Jordan-7B">https://huggingface.co/ajibawa-2023/Uncensored-Jordan-7B</a></li>

          <li>Uncensored-Jordan-13B : <a href="https://huggingface.co/ajibawa-2023/Uncensored-Jordan-13B">https://huggingface.co/ajibawa-2023/Uncensored-Jordan-13B</a></li>

          <li>Uncensored-Jordan-33B : <a href="https://huggingface.co/ajibawa-2023/Uncensored-Jordan-33B">https://huggingface.co/ajibawa-2023/Uncensored-Jordan-33B</a><br>Looking
          forward to hearing from you. Thank you for your relentless efforts. Hats
          off to you!</li>

          </ol>

          '
        raw: "Hello Bloke,\n   I hope you are doing great! Can you help me by quantizing\
          \ my following new models:\n1.  Uncensored-Jordan-7B :  https://huggingface.co/ajibawa-2023/Uncensored-Jordan-7B\n\
          2. Uncensored-Jordan-13B : https://huggingface.co/ajibawa-2023/Uncensored-Jordan-13B\n\
          3. Uncensored-Jordan-33B : https://huggingface.co/ajibawa-2023/Uncensored-Jordan-33B\n\
          Looking forward to hearing from you. Thank you for your relentless efforts.\
          \ Hats off to you!"
        updatedAt: '2023-10-30T20:10:27.215Z'
      numEdits: 0
      reactions: []
    id: 65400db3c81b3728f07f5b0a
    type: comment
  author: ajibawa-2023
  content: "Hello Bloke,\n   I hope you are doing great! Can you help me by quantizing\
    \ my following new models:\n1.  Uncensored-Jordan-7B :  https://huggingface.co/ajibawa-2023/Uncensored-Jordan-7B\n\
    2. Uncensored-Jordan-13B : https://huggingface.co/ajibawa-2023/Uncensored-Jordan-13B\n\
    3. Uncensored-Jordan-33B : https://huggingface.co/ajibawa-2023/Uncensored-Jordan-33B\n\
    Looking forward to hearing from you. Thank you for your relentless efforts. Hats\
    \ off to you!"
  created_at: 2023-10-30 19:10:27+00:00
  edited: false
  hidden: false
  id: 65400db3c81b3728f07f5b0a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-10-30T20:13:23.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9476564526557922
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yes of course, glad to. I''ll add them to the queue now</p>

          '
        raw: Yes of course, glad to. I'll add them to the queue now
        updatedAt: '2023-10-30T20:13:23.949Z'
      numEdits: 0
      reactions: []
    id: 65400e6349546d9536b2fd5b
    type: comment
  author: TheBloke
  content: Yes of course, glad to. I'll add them to the queue now
  created_at: 2023-10-30 19:13:23+00:00
  edited: false
  hidden: false
  id: 65400e6349546d9536b2fd5b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-10-30T20:13:57.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9786298274993896
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>By the way, is there a reason you''re still using Llama 1 for 7B?</p>

          '
        raw: By the way, is there a reason you're still using Llama 1 for 7B?
        updatedAt: '2023-10-30T20:15:41.493Z'
      numEdits: 1
      reactions: []
    id: 65400e85bd60d2bd19159631
    type: comment
  author: TheBloke
  content: By the way, is there a reason you're still using Llama 1 for 7B?
  created_at: 2023-10-30 19:13:57+00:00
  edited: true
  hidden: false
  id: 65400e85bd60d2bd19159631
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-10-30T20:32:42.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9756116271018982
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Thanks Bloke! It was trained before the release of Mistral. </p>

          '
        raw: 'Thanks Bloke! It was trained before the release of Mistral. '
        updatedAt: '2023-10-30T20:32:42.504Z'
      numEdits: 0
      reactions: []
    id: 654012eace1bab505370886e
    type: comment
  author: ajibawa-2023
  content: 'Thanks Bloke! It was trained before the release of Mistral. '
  created_at: 2023-10-30 19:32:42+00:00
  edited: false
  hidden: false
  id: 654012eace1bab505370886e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-10-31T00:12:24.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9786117672920227
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>These are all done</p>

          '
        raw: These are all done
        updatedAt: '2023-10-31T00:12:24.491Z'
      numEdits: 0
      reactions: []
    id: 65404668df8f1e9385d441e4
    type: comment
  author: TheBloke
  content: These are all done
  created_at: 2023-10-30 23:12:24+00:00
  edited: false
  hidden: false
  id: 65404668df8f1e9385d441e4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-10-31T05:30:30.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9952494502067566
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Thank you very much man! Kudos to you.</p>

          '
        raw: Thank you very much man! Kudos to you.
        updatedAt: '2023-10-31T05:30:30.605Z'
      numEdits: 0
      reactions: []
    id: 654090f6fcbd1aa00670a2a9
    type: comment
  author: ajibawa-2023
  content: Thank you very much man! Kudos to you.
  created_at: 2023-10-31 04:30:30+00:00
  edited: false
  hidden: false
  id: 654090f6fcbd1aa00670a2a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-11-13T18:46:55.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7597703337669373
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Hello Bloke,<br>   Trust you are doing great! Can you help me by
          quantizing my following new models:</p>

          <ol>

          <li>Python-Code-13B: <a href="https://huggingface.co/ajibawa-2023/Python-Code-13B">https://huggingface.co/ajibawa-2023/Python-Code-13B</a></li>

          <li>Python-Code-33B: <a href="https://huggingface.co/ajibawa-2023/Python-Code-33B">https://huggingface.co/ajibawa-2023/Python-Code-33B</a><br>Thanks
          for your guidance &amp; help. I highly appreciate your dedication towards
          OSS community.<br>Thank you!</li>

          </ol>

          '
        raw: "Hello Bloke,\n   Trust you are doing great! Can you help me by quantizing\
          \ my following new models:\n1. Python-Code-13B: https://huggingface.co/ajibawa-2023/Python-Code-13B\n\
          2. Python-Code-33B: https://huggingface.co/ajibawa-2023/Python-Code-33B\n\
          Thanks for your guidance & help. I highly appreciate your dedication towards\
          \ OSS community.\nThank you!"
        updatedAt: '2023-11-13T18:46:55.792Z'
      numEdits: 0
      reactions: []
    id: 65526f1fe5c209f56b756152
    type: comment
  author: ajibawa-2023
  content: "Hello Bloke,\n   Trust you are doing great! Can you help me by quantizing\
    \ my following new models:\n1. Python-Code-13B: https://huggingface.co/ajibawa-2023/Python-Code-13B\n\
    2. Python-Code-33B: https://huggingface.co/ajibawa-2023/Python-Code-33B\nThanks\
    \ for your guidance & help. I highly appreciate your dedication towards OSS community.\n\
    Thank you!"
  created_at: 2023-11-13 18:46:55+00:00
  edited: false
  hidden: false
  id: 65526f1fe5c209f56b756152
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-11-14T18:14:33.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7785970568656921
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Hello Bloke,<br> Looking forward to a positive response. Sorry,
          if I am troubling you.</p>

          '
        raw: "Hello Bloke,\n Looking forward to a positive response. Sorry, if I am\
          \ troubling you.\n"
        updatedAt: '2023-11-14T18:14:33.490Z'
      numEdits: 0
      reactions: []
    id: 6553b9097acfce2165319ccf
    type: comment
  author: ajibawa-2023
  content: "Hello Bloke,\n Looking forward to a positive response. Sorry, if I am\
    \ troubling you.\n"
  created_at: 2023-11-14 18:14:33+00:00
  edited: false
  hidden: false
  id: 6553b9097acfce2165319ccf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-14T18:15:54.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9596534967422485
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Oh sorry, I missed this.  My normal place for model requests is
          the #model-requests forum in my Discord.  So the best results to ensure
          I see it quickly is to post it there, and ping me there.</p>

          <p>I will add these to my queue now.  GGUFs and AWQs will come soon, GPTQs
          in a couple of hours</p>

          '
        raw: 'Oh sorry, I missed this.  My normal place for model requests is the
          #model-requests forum in my Discord.  So the best results to ensure I see
          it quickly is to post it there, and ping me there.


          I will add these to my queue now.  GGUFs and AWQs will come soon, GPTQs
          in a couple of hours'
        updatedAt: '2023-11-14T18:15:54.362Z'
      numEdits: 0
      reactions: []
    id: 6553b95a24601ffa6672c353
    type: comment
  author: TheBloke
  content: 'Oh sorry, I missed this.  My normal place for model requests is the #model-requests
    forum in my Discord.  So the best results to ensure I see it quickly is to post
    it there, and ping me there.


    I will add these to my queue now.  GGUFs and AWQs will come soon, GPTQs in a couple
    of hours'
  created_at: 2023-11-14 18:15:54+00:00
  edited: false
  hidden: false
  id: 6553b95a24601ffa6672c353
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-11-14T18:29:26.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9505854249000549
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Thank you Bloke! I am not on Discord but will join soon. Thank you.</p>

          '
        raw: Thank you Bloke! I am not on Discord but will join soon. Thank you.
        updatedAt: '2023-11-14T18:29:26.715Z'
      numEdits: 0
      reactions: []
    id: 6553bc868aca278b839e4ece
    type: comment
  author: ajibawa-2023
  content: Thank you Bloke! I am not on Discord but will join soon. Thank you.
  created_at: 2023-11-14 18:29:26+00:00
  edited: false
  hidden: false
  id: 6553bc868aca278b839e4ece
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-11-15T04:48:11.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9770655632019043
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Hello Bloke,<br>Thank you very much for quantized models. I am extremely
          thankful to you.</p>

          '
        raw: 'Hello Bloke,

          Thank you very much for quantized models. I am extremely thankful to you.'
        updatedAt: '2023-11-15T04:48:11.658Z'
      numEdits: 0
      reactions: []
    id: 65544d8b849e7971cb653ad7
    type: comment
  author: ajibawa-2023
  content: 'Hello Bloke,

    Thank you very much for quantized models. I am extremely thankful to you.'
  created_at: 2023-11-15 04:48:11+00:00
  edited: false
  hidden: false
  id: 65544d8b849e7971cb653ad7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
      fullname: Feynman Innovations
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ajibawa-2023
      type: user
    createdAt: '2023-11-30T16:34:35.000Z'
    data:
      edited: false
      editors:
      - ajibawa-2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8914854526519775
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64aea8ff67511bd3d965697b/Jxn52EmDF5RApJh8antxn.jpeg?w=200&h=200&f=face
          fullname: Feynman Innovations
          isHf: false
          isPro: false
          name: ajibawa-2023
          type: user
        html: '<p>Hello Bloke,<br>  How are you? Can you quantize my model: <a href="https://huggingface.co/ajibawa-2023/SlimOrca-13B">https://huggingface.co/ajibawa-2023/SlimOrca-13B</a><br>Thank
          you very much!  Happy Holidays to you.</p>

          '
        raw: "Hello Bloke,\n  How are you? Can you quantize my model: https://huggingface.co/ajibawa-2023/SlimOrca-13B\n\
          Thank you very much!  Happy Holidays to you."
        updatedAt: '2023-11-30T16:34:35.925Z'
      numEdits: 0
      reactions: []
    id: 6568b99bf730f5b7b7b1ea46
    type: comment
  author: ajibawa-2023
  content: "Hello Bloke,\n  How are you? Can you quantize my model: https://huggingface.co/ajibawa-2023/SlimOrca-13B\n\
    Thank you very much!  Happy Holidays to you."
  created_at: 2023-11-30 16:34:35+00:00
  edited: false
  hidden: false
  id: 6568b99bf730f5b7b7b1ea46
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Carl-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: Thank you very much!
