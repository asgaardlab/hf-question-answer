!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dranger003
conflicting_files: null
created_at: 2023-11-05 15:14:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4cd276aaa319b12d0beaf23c65630769.svg
      fullname: "DAN\u2122"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dranger003
      type: user
    createdAt: '2023-11-05T15:14:44.000Z'
    data:
      edited: false
      editors:
      - dranger003
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3267328143119812
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4cd276aaa319b12d0beaf23c65630769.svg
          fullname: "DAN\u2122"
          isHf: false
          isPro: false
          name: dranger003
          type: user
        html: "<p>Thanks for converting this model! Although I see some weird tokens\
          \ when running llama.cpp (compiled from master).</p>\n<pre><code>llm_load_print_meta:\
          \ general.name   = deepseek-ai_deepseek-coder-33b-instruct\nllm_load_print_meta:\
          \ BOS token = 32013 '&lt;\u2229\u255C\xA3begin\u0393\xFB\xFCof\u0393\xFB\
          \xFCsentence\u2229\u255C\xA3&gt;'\nllm_load_print_meta: EOS token = 32014\
          \ '&lt;\u2229\u255C\xA3end\u0393\xFB\xFCof\u0393\xFB\xFCsentence\u2229\u255C\
          \xA3&gt;'\nllm_load_print_meta: PAD token = 32014 '&lt;\u2229\u255C\xA3\
          end\u0393\xFB\xFCof\u0393\xFB\xFCsentence\u2229\u255C\xA3&gt;'\nllm_load_print_meta:\
          \ LF token  = 30 '?'\n</code></pre>\n"
        raw: "Thanks for converting this model! Although I see some weird tokens when\
          \ running llama.cpp (compiled from master).\r\n\r\n```\r\nllm_load_print_meta:\
          \ general.name   = deepseek-ai_deepseek-coder-33b-instruct\r\nllm_load_print_meta:\
          \ BOS token = 32013 '<\u2229\u255C\xA3begin\u0393\xFB\xFCof\u0393\xFB\xFC\
          sentence\u2229\u255C\xA3>'\r\nllm_load_print_meta: EOS token = 32014 '<\u2229\
          \u255C\xA3end\u0393\xFB\xFCof\u0393\xFB\xFCsentence\u2229\u255C\xA3>'\r\n\
          llm_load_print_meta: PAD token = 32014 '<\u2229\u255C\xA3end\u0393\xFB\xFC\
          of\u0393\xFB\xFCsentence\u2229\u255C\xA3>'\r\nllm_load_print_meta: LF token\
          \  = 30 '?'\r\n```"
        updatedAt: '2023-11-05T15:14:44.305Z'
      numEdits: 0
      reactions: []
    id: 6547b16408deaa0c9108cefd
    type: comment
  author: dranger003
  content: "Thanks for converting this model! Although I see some weird tokens when\
    \ running llama.cpp (compiled from master).\r\n\r\n```\r\nllm_load_print_meta:\
    \ general.name   = deepseek-ai_deepseek-coder-33b-instruct\r\nllm_load_print_meta:\
    \ BOS token = 32013 '<\u2229\u255C\xA3begin\u0393\xFB\xFCof\u0393\xFB\xFCsentence\u2229\
    \u255C\xA3>'\r\nllm_load_print_meta: EOS token = 32014 '<\u2229\u255C\xA3end\u0393\
    \xFB\xFCof\u0393\xFB\xFCsentence\u2229\u255C\xA3>'\r\nllm_load_print_meta: PAD\
    \ token = 32014 '<\u2229\u255C\xA3end\u0393\xFB\xFCof\u0393\xFB\xFCsentence\u2229\
    \u255C\xA3>'\r\nllm_load_print_meta: LF token  = 30 '?'\r\n```"
  created_at: 2023-11-05 15:14:44+00:00
  edited: false
  hidden: false
  id: 6547b16408deaa0c9108cefd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-05T15:19:13.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7151219844818115
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>Yeah it is weird, but that's exactly what's defined in tokenizer_config.json:</p>\n\
          <pre><code> [pytorch2] tomj@MC:/workspace/git/gguf-llama (master \u2718\
          )\u272D \u1405 grep -A5 -i eos /workspace/process/deepseek-ai_deepseek-coder-33b-instruct/source/tokenizer_config.json\
          \ | cat -\nve\n  \"add_eos_token\": false,$\n  \"bos_token\": {$\n    \"\
          __type\": \"AddedToken\",$\n    \"content\": \"&lt;M-oM-=M-^\\beginM-bM-^VM-^AofM-bM-^VM-^AsentenceM-oM-=M-^\\\
          &gt;\",$\n    \"lstrip\": false,$\n    \"normalized\": true,$\n--$\n  \"\
          eos_token\": {$\n    \"__type\": \"AddedToken\",$\n    \"content\": \"&lt;M-oM-=M-^\\\
          endM-bM-^VM-^AofM-bM-^VM-^AsentenceM-oM-=M-^\\&gt;\",$\n    \"lstrip\":\
          \ false,$\n    \"normalized\": true,$\n    \"rstrip\": false,$\n</code></pre>\n\
          <p>I don't know why they've used those weird chars, but this isn't a llama.cpp\
          \ issue; it's using the tokens as defined by the original model.</p>\n<p>FYI\
          \ I'm just about to re-make all the GGUFs after an update to the convert.py\
          \ I'm using, which affects special tokens.  It won't change this, but might\
          \ affect other aspects of special token usage.</p>\n"
        raw: "Yeah it is weird, but that's exactly what's defined in tokenizer_config.json:\n\
          ```\n [pytorch2] tomj@MC:/workspace/git/gguf-llama (master \u2718)\u272D\
          \ \u1405 grep -A5 -i eos /workspace/process/deepseek-ai_deepseek-coder-33b-instruct/source/tokenizer_config.json\
          \ | cat -\nve\n  \"add_eos_token\": false,$\n  \"bos_token\": {$\n    \"\
          __type\": \"AddedToken\",$\n    \"content\": \"<M-oM-=M-^\\beginM-bM-^VM-^AofM-bM-^VM-^AsentenceM-oM-=M-^\\\
          >\",$\n    \"lstrip\": false,$\n    \"normalized\": true,$\n--$\n  \"eos_token\"\
          : {$\n    \"__type\": \"AddedToken\",$\n    \"content\": \"<M-oM-=M-^\\\
          endM-bM-^VM-^AofM-bM-^VM-^AsentenceM-oM-=M-^\\>\",$\n    \"lstrip\": false,$\n\
          \    \"normalized\": true,$\n    \"rstrip\": false,$\n```\n\nI don't know\
          \ why they've used those weird chars, but this isn't a llama.cpp issue;\
          \ it's using the tokens as defined by the original model.\n\nFYI I'm just\
          \ about to re-make all the GGUFs after an update to the convert.py I'm using,\
          \ which affects special tokens.  It won't change this, but might affect\
          \ other aspects of special token usage."
        updatedAt: '2023-11-05T15:19:13.961Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - dranger003
        - mufeed
        - dzupin
    id: 6547b27144867327206bb236
    type: comment
  author: TheBloke
  content: "Yeah it is weird, but that's exactly what's defined in tokenizer_config.json:\n\
    ```\n [pytorch2] tomj@MC:/workspace/git/gguf-llama (master \u2718)\u272D \u1405\
    \ grep -A5 -i eos /workspace/process/deepseek-ai_deepseek-coder-33b-instruct/source/tokenizer_config.json\
    \ | cat -\nve\n  \"add_eos_token\": false,$\n  \"bos_token\": {$\n    \"__type\"\
    : \"AddedToken\",$\n    \"content\": \"<M-oM-=M-^\\beginM-bM-^VM-^AofM-bM-^VM-^AsentenceM-oM-=M-^\\\
    >\",$\n    \"lstrip\": false,$\n    \"normalized\": true,$\n--$\n  \"eos_token\"\
    : {$\n    \"__type\": \"AddedToken\",$\n    \"content\": \"<M-oM-=M-^\\endM-bM-^VM-^AofM-bM-^VM-^AsentenceM-oM-=M-^\\\
    >\",$\n    \"lstrip\": false,$\n    \"normalized\": true,$\n    \"rstrip\": false,$\n\
    ```\n\nI don't know why they've used those weird chars, but this isn't a llama.cpp\
    \ issue; it's using the tokens as defined by the original model.\n\nFYI I'm just\
    \ about to re-make all the GGUFs after an update to the convert.py I'm using,\
    \ which affects special tokens.  It won't change this, but might affect other\
    \ aspects of special token usage."
  created_at: 2023-11-05 15:19:13+00:00
  edited: false
  hidden: false
  id: 6547b27144867327206bb236
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/60dd41679856317c93a1ccfcccc82390.svg
      fullname: Jorrit
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JorritJ
      type: user
    createdAt: '2023-11-06T15:00:02.000Z'
    data:
      edited: false
      editors:
      - JorritJ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9641603231430054
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/60dd41679856317c93a1ccfcccc82390.svg
          fullname: Jorrit
          isHf: false
          isPro: false
          name: JorritJ
          type: user
        html: '<p>That weird combination of characters is probably to reduce the odds
          of them being present in random input.</p>

          <p>The output being garbled on dranger003''s run is just a console character
          set issue.</p>

          '
        raw: 'That weird combination of characters is probably to reduce the odds
          of them being present in random input.


          The output being garbled on dranger003''s run is just a console character
          set issue.'
        updatedAt: '2023-11-06T15:00:02.197Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - TheBloke
        - zoigo
    id: 6548ff7246ce83d797a14282
    type: comment
  author: JorritJ
  content: 'That weird combination of characters is probably to reduce the odds of
    them being present in random input.


    The output being garbled on dranger003''s run is just a console character set
    issue.'
  created_at: 2023-11-06 15:00:02+00:00
  edited: false
  hidden: false
  id: 6548ff7246ce83d797a14282
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/deepseek-coder-33B-instruct-GGUF
repo_type: model
status: open
target_branch: null
title: Weird tokens
