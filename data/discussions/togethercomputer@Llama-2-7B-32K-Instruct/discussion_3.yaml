!!python/object:huggingface_hub.community.DiscussionWithDetails
author: CUIGuy
conflicting_files: null
created_at: 2023-08-21 21:15:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af5e8947845d198701e452cd8a514cce.svg
      fullname: Xiaoyun Wu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CUIGuy
      type: user
    createdAt: '2023-08-21T22:15:22.000Z'
    data:
      edited: false
      editors:
      - CUIGuy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9760750532150269
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af5e8947845d198701e452cd8a514cce.svg
          fullname: Xiaoyun Wu
          isHf: false
          isPro: false
          name: CUIGuy
          type: user
        html: '<p>is it possible to have ggml version?</p>

          '
        raw: "is it possible to have ggml version?\r\n"
        updatedAt: '2023-08-21T22:15:22.088Z'
      numEdits: 0
      reactions: []
    id: 64e3e1fa623074ac85fe1d01
    type: comment
  author: CUIGuy
  content: "is it possible to have ggml version?\r\n"
  created_at: 2023-08-21 21:15:22+00:00
  edited: false
  hidden: false
  id: 64e3e1fa623074ac85fe1d01
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39cf3180fc0b02006a709a5ba9e3ae32.svg
      fullname: Pawel Kowalski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pbkowalski
      type: user
    createdAt: '2023-08-22T09:35:23.000Z'
    data:
      edited: false
      editors:
      - pbkowalski
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.803399920463562
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39cf3180fc0b02006a709a5ba9e3ae32.svg
          fullname: Pawel Kowalski
          isHf: false
          isPro: false
          name: pbkowalski
          type: user
        html: '<p>There is already one from TheBloke ( <a href="https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GGML">https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GGML</a>
          ), unfortunately it only outputs gibberish for me</p>

          '
        raw: There is already one from TheBloke ( https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GGML
          ), unfortunately it only outputs gibberish for me
        updatedAt: '2023-08-22T09:35:23.863Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mauriceweber
    id: 64e4815bd01e5d02d9b24012
    type: comment
  author: pbkowalski
  content: There is already one from TheBloke ( https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GGML
    ), unfortunately it only outputs gibberish for me
  created_at: 2023-08-22 08:35:23+00:00
  edited: false
  hidden: false
  id: 64e4815bd01e5d02d9b24012
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af5e8947845d198701e452cd8a514cce.svg
      fullname: Xiaoyun Wu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CUIGuy
      type: user
    createdAt: '2023-08-22T15:50:58.000Z'
    data:
      edited: true
      editors:
      - CUIGuy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7621304988861084
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af5e8947845d198701e452cd8a514cce.svg
          fullname: Xiaoyun Wu
          isHf: false
          isPro: false
          name: CUIGuy
          type: user
        html: "<blockquote>\n<p>There is already one from TheBloke ( <a href=\"https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GGML\"\
          >https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GGML</a> ), unfortunately\
          \ it only outputs gibberish for me</p>\n</blockquote>\n<p>what prompt are\
          \ you using? People say this use a different prompt then the original llama\
          \ chat prompt. <span data-props=\"{&quot;user&quot;:&quot;pbkowalski&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/pbkowalski\"\
          >@<span class=\"underline\">pbkowalski</span></a></span>\n\n\t</span></span>\
          \ </p>\n"
        raw: "> There is already one from TheBloke ( https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GGML\
          \ ), unfortunately it only outputs gibberish for me\n\nwhat prompt are you\
          \ using? People say this use a different prompt then the original llama\
          \ chat prompt. @pbkowalski \n"
        updatedAt: '2023-08-22T15:51:14.689Z'
      numEdits: 1
      reactions: []
    id: 64e4d962280de399ac73e9bf
    type: comment
  author: CUIGuy
  content: "> There is already one from TheBloke ( https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GGML\
    \ ), unfortunately it only outputs gibberish for me\n\nwhat prompt are you using?\
    \ People say this use a different prompt then the original llama chat prompt.\
    \ @pbkowalski \n"
  created_at: 2023-08-22 14:50:58+00:00
  edited: true
  hidden: false
  id: 64e4d962280de399ac73e9bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39cf3180fc0b02006a709a5ba9e3ae32.svg
      fullname: Pawel Kowalski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pbkowalski
      type: user
    createdAt: '2023-08-22T16:01:16.000Z'
    data:
      edited: false
      editors:
      - pbkowalski
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8852906227111816
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39cf3180fc0b02006a709a5ba9e3ae32.svg
          fullname: Pawel Kowalski
          isHf: false
          isPro: false
          name: pbkowalski
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;CUIGuy&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/CUIGuy\">@<span class=\"\
          underline\">CUIGuy</span></a></span>\n\n\t</span></span>  I've tried both\
          \ the variant specified [INST]...[\\INST] and others, but the output is\
          \ just symbols regardless</p>\n"
        raw: '@CUIGuy  I''ve tried both the variant specified [INST]...[\INST] and
          others, but the output is just symbols regardless'
        updatedAt: '2023-08-22T16:01:16.937Z'
      numEdits: 0
      reactions: []
    id: 64e4dbccd01e5d02d9be3d0e
    type: comment
  author: pbkowalski
  content: '@CUIGuy  I''ve tried both the variant specified [INST]...[\INST] and others,
    but the output is just symbols regardless'
  created_at: 2023-08-22 15:01:16+00:00
  edited: false
  hidden: false
  id: 64e4dbccd01e5d02d9be3d0e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af5e8947845d198701e452cd8a514cce.svg
      fullname: Xiaoyun Wu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CUIGuy
      type: user
    createdAt: '2023-08-22T16:19:52.000Z'
    data:
      edited: false
      editors:
      - CUIGuy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8702464699745178
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af5e8947845d198701e452cd8a514cce.svg
          fullname: Xiaoyun Wu
          isHf: false
          isPro: false
          name: CUIGuy
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;CUIGuy&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/CUIGuy\"\
          >@<span class=\"underline\">CUIGuy</span></a></span>\n\n\t</span></span>\
          \  I've tried both the variant specified [INST]...[\\INST] and others, but\
          \ the output is just symbols regardless</p>\n</blockquote>\n<p>got.</p>\n"
        raw: '> @CUIGuy  I''ve tried both the variant specified [INST]...[\INST] and
          others, but the output is just symbols regardless


          got.'
        updatedAt: '2023-08-22T16:19:52.497Z'
      numEdits: 0
      reactions: []
    id: 64e4e0289241845879606d45
    type: comment
  author: CUIGuy
  content: '> @CUIGuy  I''ve tried both the variant specified [INST]...[\INST] and
    others, but the output is just symbols regardless


    got.'
  created_at: 2023-08-22 15:19:52+00:00
  edited: false
  hidden: false
  id: 64e4e0289241845879606d45
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6329ee3dab49d487dd1439ec/vxGvdBK0XMZaCpc5dGOIa.jpeg?w=200&h=200&f=face
      fullname: Maurice Weber
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mauriceweber
      type: user
    createdAt: '2023-08-23T07:52:18.000Z'
    data:
      edited: false
      editors:
      - mauriceweber
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9281167984008789
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6329ee3dab49d487dd1439ec/vxGvdBK0XMZaCpc5dGOIa.jpeg?w=200&h=200&f=face
          fullname: Maurice Weber
          isHf: false
          isPro: false
          name: mauriceweber
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;pbkowalski&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/pbkowalski\">@<span class=\"\
          underline\">pbkowalski</span></a></span>\n\n\t</span></span> for which quantization\
          \ levels did you observe this ?</p>\n"
        raw: '@pbkowalski for which quantization levels did you observe this ?'
        updatedAt: '2023-08-23T07:52:18.488Z'
      numEdits: 0
      reactions: []
    id: 64e5bab20dc1e9ef6b433150
    type: comment
  author: mauriceweber
  content: '@pbkowalski for which quantization levels did you observe this ?'
  created_at: 2023-08-23 06:52:18+00:00
  edited: false
  hidden: false
  id: 64e5bab20dc1e9ef6b433150
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39cf3180fc0b02006a709a5ba9e3ae32.svg
      fullname: Pawel Kowalski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pbkowalski
      type: user
    createdAt: '2023-08-23T08:10:20.000Z'
    data:
      edited: true
      editors:
      - pbkowalski
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5020573735237122
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39cf3180fc0b02006a709a5ba9e3ae32.svg
          fullname: Pawel Kowalski
          isHf: false
          isPro: false
          name: pbkowalski
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mauriceweber&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/mauriceweber\"\
          >@<span class=\"underline\">mauriceweber</span></a></span>\n\n\t</span></span>\
          \ I've only tried  2_K, 4_0 and 4_1</p>\n<p>The output I get from 4_1:</p>\n\
          <p>'[INST]\\nWrite a poem about cats\\n[\\INST]\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n',</p>\n"
        raw: '@mauriceweber I''ve only tried  2_K, 4_0 and 4_1


          The output I get from 4_1:


          ''[INST]\nWrite a poem about cats\n[\\INST]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'','
        updatedAt: '2023-08-23T10:07:37.631Z'
      numEdits: 1
      reactions: []
    id: 64e5beec4af6c29a06b9e6ca
    type: comment
  author: pbkowalski
  content: '@mauriceweber I''ve only tried  2_K, 4_0 and 4_1


    The output I get from 4_1:


    ''[INST]\nWrite a poem about cats\n[\\INST]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'','
  created_at: 2023-08-23 07:10:20+00:00
  edited: true
  hidden: false
  id: 64e5beec4af6c29a06b9e6ca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/34c4e2742ea00a395a78b56cf94248b6.svg
      fullname: Manuel Pasieka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mapa17
      type: user
    createdAt: '2023-08-25T14:23:03.000Z'
    data:
      edited: true
      editors:
      - mapa17
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9489821195602417
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/34c4e2742ea00a395a78b56cf94248b6.svg
          fullname: Manuel Pasieka
          isHf: false
          isPro: false
          name: mapa17
          type: user
        html: '<p>I tried different prompts and as well only get long sequences of
          "\n". Could it be that something breaks in the tokenization of the input?<br>Can
          someone with access to the unquantized model verify if the token sequence
          for the following?</p>

          <pre><code>m.tokenize("[INST]\nWrite a poem about cats\n[/INST]\n\n".encode(''utf8''))

          [1, 29961, 25580, 29962, 13, 6113, 263, 26576, 1048, 274, 1446, 13, 29961,
          29914, 25580, 29962, 13, 13]

          </code></pre>

          '
        raw: 'I tried different prompts and as well only get long sequences of "\n".
          Could it be that something breaks in the tokenization of the input?

          Can someone with access to the unquantized model verify if the token sequence
          for the following?

          ```

          m.tokenize("[INST]\nWrite a poem about cats\n[/INST]\n\n".encode(''utf8''))

          [1, 29961, 25580, 29962, 13, 6113, 263, 26576, 1048, 274, 1446, 13, 29961,
          29914, 25580, 29962, 13, 13]

          ```'
        updatedAt: '2023-08-25T14:26:59.308Z'
      numEdits: 1
      reactions: []
    id: 64e8b94718bf99cdb29bf2a2
    type: comment
  author: mapa17
  content: 'I tried different prompts and as well only get long sequences of "\n".
    Could it be that something breaks in the tokenization of the input?

    Can someone with access to the unquantized model verify if the token sequence
    for the following?

    ```

    m.tokenize("[INST]\nWrite a poem about cats\n[/INST]\n\n".encode(''utf8''))

    [1, 29961, 25580, 29962, 13, 6113, 263, 26576, 1048, 274, 1446, 13, 29961, 29914,
    25580, 29962, 13, 13]

    ```'
  created_at: 2023-08-25 13:23:03+00:00
  edited: true
  hidden: false
  id: 64e8b94718bf99cdb29bf2a2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/313a9e2786513613725c10b7a1a01176.svg
      fullname: Andreas Rozek
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rozek
      type: user
    createdAt: '2023-08-31T09:23:37.000Z'
    data:
      edited: false
      editors:
      - rozek
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8702601790428162
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/313a9e2786513613725c10b7a1a01176.svg
          fullname: Andreas Rozek
          isHf: false
          isPro: false
          name: rozek
          type: user
        html: '<p>Based on my experiences, Q2...Q4 quantizations are too small for
          proper outputs - even when generating "useful" texts (rather than just newlines)
          these models hallucinate far too much. The Q8_0 quantization, however, works
          pretty well - and, when using <a rel="nofollow" href="https://github.com/rozek/llama.cpp">llama.cpp</a>,
          16GB RAM allow for context lengths up to 16k, 24GB RAM for lengths up to
          32k (tested on a Macbook Air 15" with 24GB unified RAM).</p>

          '
        raw: Based on my experiences, Q2...Q4 quantizations are too small for proper
          outputs - even when generating "useful" texts (rather than just newlines)
          these models hallucinate far too much. The Q8_0 quantization, however, works
          pretty well - and, when using [llama.cpp](https://github.com/rozek/llama.cpp),
          16GB RAM allow for context lengths up to 16k, 24GB RAM for lengths up to
          32k (tested on a Macbook Air 15" with 24GB unified RAM).
        updatedAt: '2023-08-31T09:23:37.042Z'
      numEdits: 0
      reactions: []
    id: 64f05c1984a6041b1b4f1409
    type: comment
  author: rozek
  content: Based on my experiences, Q2...Q4 quantizations are too small for proper
    outputs - even when generating "useful" texts (rather than just newlines) these
    models hallucinate far too much. The Q8_0 quantization, however, works pretty
    well - and, when using [llama.cpp](https://github.com/rozek/llama.cpp), 16GB RAM
    allow for context lengths up to 16k, 24GB RAM for lengths up to 32k (tested on
    a Macbook Air 15" with 24GB unified RAM).
  created_at: 2023-08-31 08:23:37+00:00
  edited: false
  hidden: false
  id: 64f05c1984a6041b1b4f1409
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: togethercomputer/Llama-2-7B-32K-Instruct
repo_type: model
status: open
target_branch: null
title: when will have a ggml version?
