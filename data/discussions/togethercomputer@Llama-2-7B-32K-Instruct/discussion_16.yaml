!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jwschrader
conflicting_files: null
created_at: 2023-12-31 03:37:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b870f77e8bbd1b8c763c16b86891ae89.svg
      fullname: schrader
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jwschrader
      type: user
    createdAt: '2023-12-31T03:37:37.000Z'
    data:
      edited: false
      editors:
      - jwschrader
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7982068061828613
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b870f77e8bbd1b8c763c16b86891ae89.svg
          fullname: schrader
          isHf: false
          isPro: false
          name: jwschrader
          type: user
        html: '<p>Hi folks,<br>Not sure if this is the best place to ask this question.  Please
          let me know if there is somewhere else.  I''ll also probably try your support/contact
          link.</p>

          <p>When I use the playground with this model, it works fine.</p>

          <p>I then copy the curl command that the playground generates and run that
          locally and it returns an empty text string for the answer.  Here is a sample
          response.  I''ve tried adjusting the <code>temperature</code>, <code>top_p</code>,
          <code>top_k</code>, <code>max_tokens</code>, <code>stream_tokens</code>
          and the prompt that I''m asking.</p>

          <pre><code>{"id":"83df4b8d3f94c39c-SEA","status":"finished","prompt":["[INST]  What
          is rain?  [/INST]  "],"model":"togethercomputer/Llama-2-7B-32K-Instruct","model_owner":"","num_returns":1,"args":{"model":"togethercomputer/Llama-2-7B-32K-Instruct","prompt":"[INST]  What
          is rain?  [/INST]  ","request_type":"language-model-inference","temperature":0.1,"top_p":0.1,"top_k":3,"max_tokens":1000,"stream_tokens":false,"stop":["[INST]","\n\n"],"negative_prompt":"","sessionKey":"906e58d5-91b6-4ec9-990e-315b47ec5184","update_at":"2023-12-31T03:00:29.376Z"},"subjobs":[],"output":{"usage":{"prompt_tokens":15,"completion_tokens":2,"total_tokens":17},"result_type":"language-model-inference","choices":[{"text":""}]}}%

          </code></pre>

          <p>This also happens when using the javascript code that is generated.  </p>

          <p>The generated curl command is working correctly for all other models
          that I have tried.</p>

          <p>Thanks for any guidance,<br>Jeremy</p>

          '
        raw: "Hi folks,\r\nNot sure if this is the best place to ask this question.\
          \  Please let me know if there is somewhere else.  I'll also probably try\
          \ your support/contact link.\r\n\r\nWhen I use the playground with this\
          \ model, it works fine.\r\n\r\nI then copy the curl command that the playground\
          \ generates and run that locally and it returns an empty text string for\
          \ the answer.  Here is a sample response.  I've tried adjusting the `temperature`,\
          \ `top_p`, `top_k`, `max_tokens`, `stream_tokens` and the prompt that I'm\
          \ asking.\r\n\r\n```\r\n{\"id\":\"83df4b8d3f94c39c-SEA\",\"status\":\"finished\"\
          ,\"prompt\":[\"[INST]  What is rain?  [/INST]  \"],\"model\":\"togethercomputer/Llama-2-7B-32K-Instruct\"\
          ,\"model_owner\":\"\",\"num_returns\":1,\"args\":{\"model\":\"togethercomputer/Llama-2-7B-32K-Instruct\"\
          ,\"prompt\":\"[INST]  What is rain?  [/INST]  \",\"request_type\":\"language-model-inference\"\
          ,\"temperature\":0.1,\"top_p\":0.1,\"top_k\":3,\"max_tokens\":1000,\"stream_tokens\"\
          :false,\"stop\":[\"[INST]\",\"\\n\\n\"],\"negative_prompt\":\"\",\"sessionKey\"\
          :\"906e58d5-91b6-4ec9-990e-315b47ec5184\",\"update_at\":\"2023-12-31T03:00:29.376Z\"\
          },\"subjobs\":[],\"output\":{\"usage\":{\"prompt_tokens\":15,\"completion_tokens\"\
          :2,\"total_tokens\":17},\"result_type\":\"language-model-inference\",\"\
          choices\":[{\"text\":\"\"}]}}%\r\n```\r\n\r\nThis also happens when using\
          \ the javascript code that is generated.  \r\n\r\nThe generated curl command\
          \ is working correctly for all other models that I have tried.\r\n\r\nThanks\
          \ for any guidance,\r\nJeremy\r\n"
        updatedAt: '2023-12-31T03:37:37.403Z'
      numEdits: 0
      reactions: []
    id: 6590e20189f1ff046389b3f1
    type: comment
  author: jwschrader
  content: "Hi folks,\r\nNot sure if this is the best place to ask this question.\
    \  Please let me know if there is somewhere else.  I'll also probably try your\
    \ support/contact link.\r\n\r\nWhen I use the playground with this model, it works\
    \ fine.\r\n\r\nI then copy the curl command that the playground generates and\
    \ run that locally and it returns an empty text string for the answer.  Here is\
    \ a sample response.  I've tried adjusting the `temperature`, `top_p`, `top_k`,\
    \ `max_tokens`, `stream_tokens` and the prompt that I'm asking.\r\n\r\n```\r\n\
    {\"id\":\"83df4b8d3f94c39c-SEA\",\"status\":\"finished\",\"prompt\":[\"[INST]\
    \  What is rain?  [/INST]  \"],\"model\":\"togethercomputer/Llama-2-7B-32K-Instruct\"\
    ,\"model_owner\":\"\",\"num_returns\":1,\"args\":{\"model\":\"togethercomputer/Llama-2-7B-32K-Instruct\"\
    ,\"prompt\":\"[INST]  What is rain?  [/INST]  \",\"request_type\":\"language-model-inference\"\
    ,\"temperature\":0.1,\"top_p\":0.1,\"top_k\":3,\"max_tokens\":1000,\"stream_tokens\"\
    :false,\"stop\":[\"[INST]\",\"\\n\\n\"],\"negative_prompt\":\"\",\"sessionKey\"\
    :\"906e58d5-91b6-4ec9-990e-315b47ec5184\",\"update_at\":\"2023-12-31T03:00:29.376Z\"\
    },\"subjobs\":[],\"output\":{\"usage\":{\"prompt_tokens\":15,\"completion_tokens\"\
    :2,\"total_tokens\":17},\"result_type\":\"language-model-inference\",\"choices\"\
    :[{\"text\":\"\"}]}}%\r\n```\r\n\r\nThis also happens when using the javascript\
    \ code that is generated.  \r\n\r\nThe generated curl command is working correctly\
    \ for all other models that I have tried.\r\n\r\nThanks for any guidance,\r\n\
    Jeremy\r\n"
  created_at: 2023-12-31 03:37:37+00:00
  edited: false
  hidden: false
  id: 6590e20189f1ff046389b3f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6440872be44f30a723256163/I-xsy2tuS-k51TB1YnRTt.jpeg?w=200&h=200&f=face
      fullname: OrangeTin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: orangetin
      type: user
    createdAt: '2024-01-05T12:25:22.000Z'
    data:
      edited: false
      editors:
      - orangetin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9854656457901001
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6440872be44f30a723256163/I-xsy2tuS-k51TB1YnRTt.jpeg?w=200&h=200&f=face
          fullname: OrangeTin
          isHf: false
          isPro: false
          name: orangetin
          type: user
        html: '<p>issue was fixed in the Playground! Please try again</p>

          '
        raw: issue was fixed in the Playground! Please try again
        updatedAt: '2024-01-05T12:25:22.337Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6597f5325fc65052a9fbe60c
    id: 6597f5325fc65052a9fbe60b
    type: comment
  author: orangetin
  content: issue was fixed in the Playground! Please try again
  created_at: 2024-01-05 12:25:22+00:00
  edited: false
  hidden: false
  id: 6597f5325fc65052a9fbe60b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6440872be44f30a723256163/I-xsy2tuS-k51TB1YnRTt.jpeg?w=200&h=200&f=face
      fullname: OrangeTin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: orangetin
      type: user
    createdAt: '2024-01-05T12:25:22.000Z'
    data:
      status: closed
    id: 6597f5325fc65052a9fbe60c
    type: status-change
  author: orangetin
  created_at: 2024-01-05 12:25:22+00:00
  id: 6597f5325fc65052a9fbe60c
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: togethercomputer/Llama-2-7B-32K-Instruct
repo_type: model
status: closed
target_branch: null
title: Empty response when using generated curl statement from API playground
