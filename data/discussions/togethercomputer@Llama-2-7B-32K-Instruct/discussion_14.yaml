!!python/object:huggingface_hub.community.DiscussionWithDetails
author: fwrefewrfwe
conflicting_files: null
created_at: 2023-10-22 10:54:39+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6b7b8ad958439177c7c05fe3f9f30955.svg
      fullname: wefewfwef
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fwrefewrfwe
      type: user
    createdAt: '2023-10-22T11:54:39.000Z'
    data:
      edited: false
      editors:
      - fwrefewrfwe
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.1855641007423401
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6b7b8ad958439177c7c05fe3f9f30955.svg
          fullname: wefewfwef
          isHf: false
          isPro: false
          name: fwrefewrfwe
          type: user
        html: '<p>Traceback (most recent call last):</p>

          <p>File "C:\Users\User\text-generation-webui\modules\ui_model_menu.py",
          line 201, in load_model_wrapper</p>

          <p>shared.model, shared.tokenizer = load_model(shared.model_name, loader)<br>File
          "C:\Users\User\text-generation-webui\modules\models.py", line 79, in load_model</p>

          <p>output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>File
          "C:\Users\User\text-generation-webui\modules\models.py", line 143, in huggingface_loader</p>

          <p>model = model.cuda()<br>File "C:\Users\User\anaconda3\envs\tg\lib\site-packages\transformers\modeling_utils.py",
          line 2168, in cuda</p>

          <p>return super().cuda(*args, **kwargs)<br>File "C:\Users\User\anaconda3\envs\tg\lib\site-packages\torch\nn\modules\module.py",
          line 918, in cuda</p>

          <p>return self._apply(lambda t: t.cuda(device))<br>File "C:\Users\User\anaconda3\envs\tg\lib\site-packages\torch\nn\modules\module.py",
          line 810, in _apply</p>

          <p>module._apply(fn)<br>File "C:\Users\User\anaconda3\envs\tg\lib\site-packages\torch\nn\modules\module.py",
          line 810, in _apply</p>

          <p>module._apply(fn)<br>File "C:\Users\User\anaconda3\envs\tg\lib\site-packages\torch\nn\modules\module.py",
          line 833, in _apply</p>

          <p>param_applied = fn(param)<br>File "C:\Users\User\anaconda3\envs\tg\lib\site-packages\torch\nn\modules\module.py",
          line 918, in</p>

          <p>return self.<em>apply(lambda t: t.cuda(device))<br>File "C:\Users\User\anaconda3\envs\tg\lib\site-packages\torch\cuda_init</em>.py",
          line 289, in _lazy_init</p>

          <p>raise AssertionError("Torch not compiled with CUDA enabled")<br>AssertionError:
          Torch not compiled with CUDA enabled</p>

          '
        raw: "Traceback (most recent call last):\r\n\r\nFile \"C:\\Users\\User\\text-generation-webui\\\
          modules\\ui_model_menu.py\", line 201, in load_model_wrapper\r\n\r\n\r\n\
          shared.model, shared.tokenizer = load_model(shared.model_name, loader)\r\
          \nFile \"C:\\Users\\User\\text-generation-webui\\modules\\models.py\", line\
          \ 79, in load_model\r\n\r\n\r\noutput = load_func_map[loader](model_name)\r\
          \nFile \"C:\\Users\\User\\text-generation-webui\\modules\\models.py\", line\
          \ 143, in huggingface_loader\r\n\r\n\r\nmodel = model.cuda()\r\nFile \"\
          C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\site-packages\\transformers\\\
          modeling_utils.py\", line 2168, in cuda\r\n\r\n\r\nreturn super().cuda(*args,\
          \ **kwargs)\r\nFile \"C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 918, in cuda\r\n\r\n\r\nreturn self._apply(lambda\
          \ t: t.cuda(device))\r\nFile \"C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\\
          site-packages\\torch\\nn\\modules\\module.py\", line 810, in _apply\r\n\r\
          \n\r\nmodule._apply(fn)\r\nFile \"C:\\Users\\User\\anaconda3\\envs\\tg\\\
          lib\\site-packages\\torch\\nn\\modules\\module.py\", line 810, in _apply\r\
          \n\r\n\r\nmodule._apply(fn)\r\nFile \"C:\\Users\\User\\anaconda3\\envs\\\
          tg\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 833, in _apply\r\
          \n\r\n\r\nparam_applied = fn(param)\r\nFile \"C:\\Users\\User\\anaconda3\\\
          envs\\tg\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 918,\
          \ in\r\n\r\n\r\nreturn self._apply(lambda t: t.cuda(device))\r\nFile \"\
          C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\site-packages\\torch\\cuda_init_.py\"\
          , line 289, in _lazy_init\r\n\r\n\r\nraise AssertionError(\"Torch not compiled\
          \ with CUDA enabled\")\r\nAssertionError: Torch not compiled with CUDA enabled"
        updatedAt: '2023-10-22T11:54:39.300Z'
      numEdits: 0
      reactions: []
    id: 65350d7f02d1ecd5457a9050
    type: comment
  author: fwrefewrfwe
  content: "Traceback (most recent call last):\r\n\r\nFile \"C:\\Users\\User\\text-generation-webui\\\
    modules\\ui_model_menu.py\", line 201, in load_model_wrapper\r\n\r\n\r\nshared.model,\
    \ shared.tokenizer = load_model(shared.model_name, loader)\r\nFile \"C:\\Users\\\
    User\\text-generation-webui\\modules\\models.py\", line 79, in load_model\r\n\r\
    \n\r\noutput = load_func_map[loader](model_name)\r\nFile \"C:\\Users\\User\\text-generation-webui\\\
    modules\\models.py\", line 143, in huggingface_loader\r\n\r\n\r\nmodel = model.cuda()\r\
    \nFile \"C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\site-packages\\transformers\\\
    modeling_utils.py\", line 2168, in cuda\r\n\r\n\r\nreturn super().cuda(*args,\
    \ **kwargs)\r\nFile \"C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\site-packages\\\
    torch\\nn\\modules\\module.py\", line 918, in cuda\r\n\r\n\r\nreturn self._apply(lambda\
    \ t: t.cuda(device))\r\nFile \"C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\site-packages\\\
    torch\\nn\\modules\\module.py\", line 810, in _apply\r\n\r\n\r\nmodule._apply(fn)\r\
    \nFile \"C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\site-packages\\torch\\nn\\\
    modules\\module.py\", line 810, in _apply\r\n\r\n\r\nmodule._apply(fn)\r\nFile\
    \ \"C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\site-packages\\torch\\nn\\modules\\\
    module.py\", line 833, in _apply\r\n\r\n\r\nparam_applied = fn(param)\r\nFile\
    \ \"C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\site-packages\\torch\\nn\\modules\\\
    module.py\", line 918, in\r\n\r\n\r\nreturn self._apply(lambda t: t.cuda(device))\r\
    \nFile \"C:\\Users\\User\\anaconda3\\envs\\tg\\lib\\site-packages\\torch\\cuda_init_.py\"\
    , line 289, in _lazy_init\r\n\r\n\r\nraise AssertionError(\"Torch not compiled\
    \ with CUDA enabled\")\r\nAssertionError: Torch not compiled with CUDA enabled"
  created_at: 2023-10-22 10:54:39+00:00
  edited: false
  hidden: false
  id: 65350d7f02d1ecd5457a9050
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 14
repo_id: togethercomputer/Llama-2-7B-32K-Instruct
repo_type: model
status: open
target_branch: null
title: Traceback (most recent call last)
