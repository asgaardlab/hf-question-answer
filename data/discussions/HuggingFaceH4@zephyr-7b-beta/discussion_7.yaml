!!python/object:huggingface_hub.community.DiscussionWithDetails
author: andreaKIM
conflicting_files: null
created_at: 2023-10-30 04:28:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d1f763ca61fb1f281f7ac24bdee8722f.svg
      fullname: DAEHEEKIM
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andreaKIM
      type: user
    createdAt: '2023-10-30T05:28:38.000Z'
    data:
      edited: false
      editors:
      - andreaKIM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6867760419845581
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d1f763ca61fb1f281f7ac24bdee8722f.svg
          fullname: DAEHEEKIM
          isHf: false
          isPro: false
          name: andreaKIM
          type: user
        html: '<p>Hello. Is there any proper formatting for fine tuning this model?<br>Can
          I use mistral model''s prompt or any recommended prompt format is available?</p>

          '
        raw: "Hello. Is there any proper formatting for fine tuning this model?\r\n\
          Can I use mistral model's prompt or any recommended prompt format is available?"
        updatedAt: '2023-10-30T05:28:38.522Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - JJhooww
        - tangawho
        - vtoth
        - Aiemu
        - usholanb
        - weixinchen
    id: 653f3f06dd4c516022ddac6e
    type: comment
  author: andreaKIM
  content: "Hello. Is there any proper formatting for fine tuning this model?\r\n\
    Can I use mistral model's prompt or any recommended prompt format is available?"
  created_at: 2023-10-30 04:28:38+00:00
  edited: false
  hidden: false
  id: 653f3f06dd4c516022ddac6e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/67da8840cbc35541e479deed0a854d45.svg
      fullname: Jhonata
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JJhooww
      type: user
    createdAt: '2023-10-31T06:12:12.000Z'
    data:
      edited: false
      editors:
      - JJhooww
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.564911425113678
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/67da8840cbc35541e479deed0a854d45.svg
          fullname: Jhonata
          isHf: false
          isPro: false
          name: JJhooww
          type: user
        html: '<p>I used the following prompt to fine-tune:<br>&lt;|system|&gt;\n
          {instruction} \n&lt;|user|&gt;\n{query}\n&lt;|assistant|&gt;\n{response}</p>

          <p>I had problems making the model stop generating content. So I found the
          solution in this link (<a rel="nofollow" href="https://medium.com/@parikshitsaikia1619/mistral-mastery-fine-tuning-fast-inference-guide-62e163198b06">https://medium.com/@parikshitsaikia1619/mistral-mastery-fine-tuning-fast-inference-guide-62e163198b06</a>)
          </p>

          <p>This change before starting the training solved my problem<br>tokenizer
          = AutoTokenizer.from_pretrained("HuggingFaceH4/zephyr-7b-beta")<br>#tokenizer.pad_token
          = tokenizer.eos_token</p>

          <p>tokenizer.pad_token = tokenizer.unk_token  &lt;----<br>tokenizer.padding_side
          = "right" &lt;----</p>

          '
        raw: "I used the following prompt to fine-tune:\n<|system|>\\n {instruction}\
          \ </s>\\n<|user|>\\n{query}</s>\\n<|assistant|>\\n{response}</s>\n\nI had\
          \ problems making the model stop generating content. So I found the solution\
          \ in this link (https://medium.com/@parikshitsaikia1619/mistral-mastery-fine-tuning-fast-inference-guide-62e163198b06)\
          \ \n\nThis change before starting the training solved my problem\ntokenizer\
          \ = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n#tokenizer.pad_token\
          \ = tokenizer.eos_token\n\ntokenizer.pad_token = tokenizer.unk_token  <----\n\
          tokenizer.padding_side = \"right\" <----\n"
        updatedAt: '2023-10-31T06:12:12.746Z'
      numEdits: 0
      reactions: []
    id: 65409abceddfff043544a98f
    type: comment
  author: JJhooww
  content: "I used the following prompt to fine-tune:\n<|system|>\\n {instruction}\
    \ </s>\\n<|user|>\\n{query}</s>\\n<|assistant|>\\n{response}</s>\n\nI had problems\
    \ making the model stop generating content. So I found the solution in this link\
    \ (https://medium.com/@parikshitsaikia1619/mistral-mastery-fine-tuning-fast-inference-guide-62e163198b06)\
    \ \n\nThis change before starting the training solved my problem\ntokenizer =\
    \ AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n#tokenizer.pad_token\
    \ = tokenizer.eos_token\n\ntokenizer.pad_token = tokenizer.unk_token  <----\n\
    tokenizer.padding_side = \"right\" <----\n"
  created_at: 2023-10-31 05:12:12+00:00
  edited: false
  hidden: false
  id: 65409abceddfff043544a98f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/698c8eb1b19ed7d4ba6bb4b4fefe19f5.svg
      fullname: Miguel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MigsN9
      type: user
    createdAt: '2023-10-31T11:27:03.000Z'
    data:
      edited: false
      editors:
      - MigsN9
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7804235816001892
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/698c8eb1b19ed7d4ba6bb4b4fefe19f5.svg
          fullname: Miguel
          isHf: false
          isPro: false
          name: MigsN9
          type: user
        html: '<p>Hi! Any limmits to the length of the inputs/outputs when finetunning?
          Like those limmits found in OpenAI models?</p>

          '
        raw: Hi! Any limmits to the length of the inputs/outputs when finetunning?
          Like those limmits found in OpenAI models?
        updatedAt: '2023-10-31T11:27:03.343Z'
      numEdits: 0
      reactions: []
    id: 6540e487cdc9c22e35bfad4e
    type: comment
  author: MigsN9
  content: Hi! Any limmits to the length of the inputs/outputs when finetunning? Like
    those limmits found in OpenAI models?
  created_at: 2023-10-31 10:27:03+00:00
  edited: false
  hidden: false
  id: 6540e487cdc9c22e35bfad4e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/67da8840cbc35541e479deed0a854d45.svg
      fullname: Jhonata
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JJhooww
      type: user
    createdAt: '2023-10-31T16:11:39.000Z'
    data:
      edited: true
      editors:
      - JJhooww
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9273515939712524
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/67da8840cbc35541e479deed0a854d45.svg
          fullname: Jhonata
          isHf: false
          isPro: false
          name: JJhooww
          type: user
        html: '<blockquote>

          <p>Hi! Any limmits to the length of the inputs/outputs when finetunning?
          Like those limmits found in OpenAI models?</p>

          </blockquote>

          <p>It''s my first major fine-tuning, so maybe something I say may not make
          sense, but when it comes to fine-tuning input, depending on the configuration,
          it needs to be multi-gpu, otherwise you''ll be limited. Already at the output
          I noticed that the more complete the fine adjustment... checkpoints, times,
          the more complete the fine adjustment the greater the output has been. But
          I repeat, this is my first major fine-tuning, because until now I was having
          a problem with the model not generating the eos_token</p>

          '
        raw: '> Hi! Any limmits to the length of the inputs/outputs when finetunning?
          Like those limmits found in OpenAI models?


          It''s my first major fine-tuning, so maybe something I say may not make
          sense, but when it comes to fine-tuning input, depending on the configuration,
          it needs to be multi-gpu, otherwise you''ll be limited. Already at the output
          I noticed that the more complete the fine adjustment... checkpoints, times,
          the more complete the fine adjustment the greater the output has been. But
          I repeat, this is my first major fine-tuning, because until now I was having
          a problem with the model not generating the eos_token'
        updatedAt: '2023-10-31T16:12:46.886Z'
      numEdits: 1
      reactions: []
    id: 6541273b32dcbb8663224fb7
    type: comment
  author: JJhooww
  content: '> Hi! Any limmits to the length of the inputs/outputs when finetunning?
    Like those limmits found in OpenAI models?


    It''s my first major fine-tuning, so maybe something I say may not make sense,
    but when it comes to fine-tuning input, depending on the configuration, it needs
    to be multi-gpu, otherwise you''ll be limited. Already at the output I noticed
    that the more complete the fine adjustment... checkpoints, times, the more complete
    the fine adjustment the greater the output has been. But I repeat, this is my
    first major fine-tuning, because until now I was having a problem with the model
    not generating the eos_token'
  created_at: 2023-10-31 15:11:39+00:00
  edited: true
  hidden: false
  id: 6541273b32dcbb8663224fb7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dbed75557bb804124f537221e67d39db.svg
      fullname: Hannah Bernstein
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hannahbernstein
      type: user
    createdAt: '2023-11-08T16:23:08.000Z'
    data:
      edited: false
      editors:
      - hannahbernstein
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6924006342887878
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dbed75557bb804124f537221e67d39db.svg
          fullname: Hannah Bernstein
          isHf: false
          isPro: false
          name: hannahbernstein
          type: user
        html: '<blockquote>

          <p>I used the following prompt to fine-tune:<br>&lt;|system|&gt;\n {instruction}
          \n&lt;|user|&gt;\n{query}\n&lt;|assistant|&gt;\n{response}</p>

          </blockquote>

          <p>What did your prepared dataset look like for finetuning? Was it a .csv
          file with a single column in this format?</p>

          '
        raw: '> I used the following prompt to fine-tune:

          > <|system|>\n {instruction} </s>\n<|user|>\n{query}</s>\n<|assistant|>\n{response}</s>


          What did your prepared dataset look like for finetuning? Was it a .csv file
          with a single column in this format?'
        updatedAt: '2023-11-08T16:23:08.676Z'
      numEdits: 0
      reactions: []
    id: 654bb5ec6b51714c2a514e7c
    type: comment
  author: hannahbernstein
  content: '> I used the following prompt to fine-tune:

    > <|system|>\n {instruction} </s>\n<|user|>\n{query}</s>\n<|assistant|>\n{response}</s>


    What did your prepared dataset look like for finetuning? Was it a .csv file with
    a single column in this format?'
  created_at: 2023-11-08 16:23:08+00:00
  edited: false
  hidden: false
  id: 654bb5ec6b51714c2a514e7c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/67da8840cbc35541e479deed0a854d45.svg
      fullname: Jhonata
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JJhooww
      type: user
    createdAt: '2023-11-08T16:50:11.000Z'
    data:
      edited: false
      editors:
      - JJhooww
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.20276296138763428
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/67da8840cbc35541e479deed0a854d45.svg
          fullname: Jhonata
          isHf: false
          isPro: false
          name: JJhooww
          type: user
        html: '<p>Yes, single column:<br>"text"<br>"&lt;|system|&gt;\n {instruction}
          \n&lt;|user|&gt;\n{query}\n&lt;|assistant|&gt;\n{response}"<br>"&lt;|system|&gt;\n
          {instruction} \n&lt;|user|&gt;\n{query}\n&lt;|assistant|&gt;\n{response}"</p>

          '
        raw: 'Yes, single column:

          "text"

          "<|system|>\n {instruction} \n<|user|>\n{query}\n<|assistant|>\n{response}"

          "<|system|>\n {instruction} \n<|user|>\n{query}\n<|assistant|>\n{response}"'
        updatedAt: '2023-11-08T16:50:11.851Z'
      numEdits: 0
      reactions: []
    id: 654bbc43eb360d17becbbfc2
    type: comment
  author: JJhooww
  content: 'Yes, single column:

    "text"

    "<|system|>\n {instruction} \n<|user|>\n{query}\n<|assistant|>\n{response}"

    "<|system|>\n {instruction} \n<|user|>\n{query}\n<|assistant|>\n{response}"'
  created_at: 2023-11-08 16:50:11+00:00
  edited: false
  hidden: false
  id: 654bbc43eb360d17becbbfc2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: HuggingFaceH4/zephyr-7b-beta
repo_type: model
status: open
target_branch: null
title: Dataset format for fine tuning
