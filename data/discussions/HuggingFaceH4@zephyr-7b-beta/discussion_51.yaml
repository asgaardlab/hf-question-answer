!!python/object:huggingface_hub.community.DiscussionWithDetails
author: allpunks
conflicting_files: null
created_at: 2024-01-07 15:38:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3b83fe4ca322936705fba3b211a15173.svg
      fullname: Bruno
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: allpunks
      type: user
    createdAt: '2024-01-07T15:38:51.000Z'
    data:
      edited: false
      editors:
      - allpunks
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9145407676696777
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3b83fe4ca322936705fba3b211a15173.svg
          fullname: Bruno
          isHf: false
          isPro: false
          name: allpunks
          type: user
        html: '<p>Hi ! I''m trying to run this model locally and gettign this bug:</p>

          <p>torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00
          MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of
          the allocated memory 12.57 GiB is allocated by PyTorch, and 241.53 MiB is
          reserved by PyTorch but unallocated. If reserved but unallocated memory
          is large try setting max_split_size_mb to avoid fragmentation.  See documentation
          for Memory Management and PYTORCH_CUDA_ALLOC_CONF</p>

          <p>I already tried to set this environment variable:<br>os.environ["PYTORCH_CUDA_ALLOC_CONF"]
          = "max_split_size_mb:256"</p>

          <p>but didn''t work.<br>There is any other configuration that i can set
          to make this model run on my computer ? thanks !</p>

          '
        raw: "Hi ! I'm trying to run this model locally and gettign this bug:\r\n\r\
          \ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00\
          \ MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of\
          \ the allocated memory 12.57 GiB is allocated by PyTorch, and 241.53 MiB\
          \ is reserved by PyTorch but unallocated. If reserved but unallocated memory\
          \ is large try setting max_split_size_mb to avoid fragmentation.  See documentation\
          \ for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\n\r\nI already tried\
          \ to set this environment variable: \r\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"\
          ] = \"max_split_size_mb:256\"\r\n\r\nbut didn't work. \r\nThere is any other\
          \ configuration that i can set to make this model run on my computer ? thanks\
          \ !"
        updatedAt: '2024-01-07T15:38:51.806Z'
      numEdits: 0
      reactions: []
    id: 659ac58b6d20ab21b07a74a6
    type: comment
  author: allpunks
  content: "Hi ! I'm trying to run this model locally and gettign this bug:\r\n\r\n\
    torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB.\
    \ GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated\
    \ memory 12.57 GiB is allocated by PyTorch, and 241.53 MiB is reserved by PyTorch\
    \ but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb\
    \ to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\
    \n\r\nI already tried to set this environment variable: \r\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"\
    ] = \"max_split_size_mb:256\"\r\n\r\nbut didn't work. \r\nThere is any other configuration\
    \ that i can set to make this model run on my computer ? thanks !"
  created_at: 2024-01-07 15:38:51+00:00
  edited: false
  hidden: false
  id: 659ac58b6d20ab21b07a74a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64e2ba1e93103b4537cb6fcd/iruFHnspBc-uy9judKdXe.png?w=200&h=200&f=face
      fullname: SpeedStar101
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SpeedStar101
      type: user
    createdAt: '2024-01-07T22:53:18.000Z'
    data:
      edited: true
      editors:
      - SpeedStar101
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8678706884384155
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64e2ba1e93103b4537cb6fcd/iruFHnspBc-uy9judKdXe.png?w=200&h=200&f=face
          fullname: SpeedStar101
          isHf: false
          isPro: false
          name: SpeedStar101
          type: user
        html: "<blockquote>\n<p>Hi ! I'm trying to run this model locally and gettign\
          \ this bug:</p>\n<p>torch.cuda.OutOfMemoryError: CUDA out of memory. Tried\
          \ to allocate 112.00 MiB. GPU 0 has a total capacty of 6.00 GiB of which\
          \ 0 bytes is free. Of the allocated memory 12.57 GiB is allocated by PyTorch,\
          \ and 241.53 MiB is reserved by PyTorch but unallocated. If reserved but\
          \ unallocated memory is large try setting max_split_size_mb to avoid fragmentation.\
          \  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF</p>\n\
          <p>I already tried to set this environment variable:<br>os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"\
          ] = \"max_split_size_mb:256\"</p>\n<p>but didn't work.<br>There is any other\
          \ configuration that i can set to make this model run on my computer ? thanks\
          \ !</p>\n</blockquote>\n<h2 id=\"check-available-gpu-memory\">Check Available\
          \ GPU Memory</h2>\n<p>Verify the available GPU memory. It\u2019s possible\
          \ something else is using your GPU memory.<br>Use:</p>\n<pre><code class=\"\
          language-bash\">nvidia-smi\n</code></pre>\n<h2 id=\"memory-cleanup\">Memory\
          \ Cleanup</h2>\n<p>Try explicitly releasing GPU memory using:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">import</span> torch\n\
          torch.cuda.empty_cache()\n</code></pre>\n<h2 id=\"limit-gpu-usage\">Limit\
          \ GPU Usage</h2>\n<p>You can try to limit the fraction of GPU memory PyTorch\
          \ by using :</p>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >import</span> torch\ntorch.cuda.set_per_process_memory_fraction(<span class=\"\
          hljs-number\">0.8</span>)  <span class=\"hljs-comment\"># Adjust the fraction\
          \ as needed</span>\n</code></pre>\n<h2 id=\"quantized-model\">Quantized\
          \ Model</h2>\n<p>You can try using a quantized version of this model, <strong>TheBloke</strong>\
          \ has <strong>GPTQ</strong>, and <strong>AWQ</strong> quantized models.\
          \ You could also try using <strong>bitsandbytes</strong> and load the model\
          \ in either 8 bit or 4 bit.</p>\n<h2 id=\"cpu-inference\">CPU Inference</h2>\n\
          <p>Your last option could be to set the model onto your CPU, obviously you\
          \ won\u2019t get to utilize your GPU to accelerate inference.</p>\n<p>If\
          \ you\u2019d like you could share your code and I could try to help you.\
          \ </p>\n"
        raw: "> Hi ! I'm trying to run this model locally and gettign this bug:\n\
          > \n> torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate\
          \ 112.00 MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is\
          \ free. Of the allocated memory 12.57 GiB is allocated by PyTorch, and 241.53\
          \ MiB is reserved by PyTorch but unallocated. If reserved but unallocated\
          \ memory is large try setting max_split_size_mb to avoid fragmentation.\
          \  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\
          > \n> I already tried to set this environment variable: \n> os.environ[\"\
          PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n> \n> but didn't\
          \ work. \n> There is any other configuration that i can set to make this\
          \ model run on my computer ? thanks !\n\n## Check Available GPU Memory\n\
          Verify the available GPU memory. It\u2019s possible something else is using\
          \ your GPU memory.\nUse:\n```bash\nnvidia-smi\n```\n\n## Memory Cleanup\n\
          Try explicitly releasing GPU memory using:\n```python\nimport torch\ntorch.cuda.empty_cache()\n\
          ```\n\n## Limit GPU Usage\nYou can try to limit the fraction of GPU memory\
          \ PyTorch by using :\n```python\nimport torch\ntorch.cuda.set_per_process_memory_fraction(0.8)\
          \  # Adjust the fraction as needed\n```\n\n## Quantized Model\nYou can try\
          \ using a quantized version of this model, **TheBloke** has **GPTQ**, and\
          \ **AWQ** quantized models. You could also try using **bitsandbytes** and\
          \ load the model in either 8 bit or 4 bit.\n\n## CPU Inference \nYour last\
          \ option could be to set the model onto your CPU, obviously you won\u2019\
          t get to utilize your GPU to accelerate inference.\n\n\nIf you\u2019d like\
          \ you could share your code and I could try to help you. \n"
        updatedAt: '2024-01-07T23:13:42.914Z'
      numEdits: 1
      reactions: []
    id: 659b2b5e351b28906369b13c
    type: comment
  author: SpeedStar101
  content: "> Hi ! I'm trying to run this model locally and gettign this bug:\n> \n\
    > torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB.\
    \ GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated\
    \ memory 12.57 GiB is allocated by PyTorch, and 241.53 MiB is reserved by PyTorch\
    \ but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb\
    \ to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\
    > \n> I already tried to set this environment variable: \n> os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"\
    ] = \"max_split_size_mb:256\"\n> \n> but didn't work. \n> There is any other configuration\
    \ that i can set to make this model run on my computer ? thanks !\n\n## Check\
    \ Available GPU Memory\nVerify the available GPU memory. It\u2019s possible something\
    \ else is using your GPU memory.\nUse:\n```bash\nnvidia-smi\n```\n\n## Memory\
    \ Cleanup\nTry explicitly releasing GPU memory using:\n```python\nimport torch\n\
    torch.cuda.empty_cache()\n```\n\n## Limit GPU Usage\nYou can try to limit the\
    \ fraction of GPU memory PyTorch by using :\n```python\nimport torch\ntorch.cuda.set_per_process_memory_fraction(0.8)\
    \  # Adjust the fraction as needed\n```\n\n## Quantized Model\nYou can try using\
    \ a quantized version of this model, **TheBloke** has **GPTQ**, and **AWQ** quantized\
    \ models. You could also try using **bitsandbytes** and load the model in either\
    \ 8 bit or 4 bit.\n\n## CPU Inference \nYour last option could be to set the model\
    \ onto your CPU, obviously you won\u2019t get to utilize your GPU to accelerate\
    \ inference.\n\n\nIf you\u2019d like you could share your code and I could try\
    \ to help you. \n"
  created_at: 2024-01-07 22:53:18+00:00
  edited: true
  hidden: false
  id: 659b2b5e351b28906369b13c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 51
repo_id: HuggingFaceH4/zephyr-7b-beta
repo_type: model
status: open
target_branch: null
title: getting CUDA out of memory
