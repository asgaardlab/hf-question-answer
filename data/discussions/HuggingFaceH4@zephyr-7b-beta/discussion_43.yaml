!!python/object:huggingface_hub.community.DiscussionWithDetails
author: YWDallas
conflicting_files: null
created_at: 2023-12-21 00:37:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5f9f1c967d01f14858587e86bc12ebb3.svg
      fullname: Yi Wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YWDallas
      type: user
    createdAt: '2023-12-21T00:37:59.000Z'
    data:
      edited: false
      editors:
      - YWDallas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5202062726020813
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5f9f1c967d01f14858587e86bc12ebb3.svg
          fullname: Yi Wang
          isHf: false
          isPro: false
          name: YWDallas
          type: user
        html: "<p>Unexpected exception formatting exception. Falling back to standard\
          \ exception<br>Traceback (most recent call last):<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\"\
          , line 3526, in run_code<br>    exec(code_obj, self.user_global_ns, self.user_ns)<br>\
          \  File \"/tmp/ipykernel_10963/2260344357.py\", line 30, in <br>    outputs\
          \ = pipe(prompt, max_new_tokens=1000, do_sample=True, temperature=0.001,\
          \ top_k=50, top_p=0.95)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\"\
          , line 208, in <strong>call</strong><br>    return super().<strong>call</strong>(text_inputs,\
          \ **kwargs)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/base.py\"\
          , line 1140, in <strong>call</strong><br>    return self.run_single(inputs,\
          \ preprocess_params, forward_params, postprocess_params)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/base.py\"\
          , line 1147, in run_single<br>    model_outputs = self.forward(model_inputs,\
          \ **forward_params)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/base.py\"\
          , line 1046, in forward<br>    model_outputs = self._forward(model_inputs,\
          \ **forward_params)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\"\
          , line 271, in _forward<br>    generated_sequence = self.model.generate(input_ids=input_ids,\
          \ attention_mask=attention_mask, **generate_kwargs)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context<br>    return func(*args, **kwargs)<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1777, in generate<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 2874, in sample<br>    next_token_scores = logits_processor(input_ids,\
          \ next_token_logits)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl<br>    return self._call_impl(*args,\
          \ **kwargs)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl<br>    return forward_call(*args, **kwargs)<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward<br>    output = module._old_forward(*args, **kwargs)<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 1055, in forward<br>    attention_mask=attention_mask,<br>  File\
          \ \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl<br>    return self._call_impl(*args,\
          \ **kwargs)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl<br>    return forward_call(*args, **kwargs)<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 940, in forward<br>    attention_mask=attention_mask,<br>  File \"\
          /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl<br>    return self._call_impl(*args,\
          \ **kwargs)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl<br>    return forward_call(*args, **kwargs)<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward<br>    output = module._old_forward(*args, **kwargs)<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 665, in forward<br>    attention_mask=attention_mask,<br>  File \"\
          /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl<br>    return self._call_impl(*args,\
          \ **kwargs)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl<br>    return forward_call(*args, **kwargs)<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward<br>    output = module._old_forward(*args, **kwargs)<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 300, in forward<br>    attn_weights = nn.functional.softmax(attn_weights,\
          \ dim=-1, dtype=torch.float32).to(query_states.dtype)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/functional.py\"\
          , line 1858, in softmax<br>    ret = input.softmax(dim, dtype=dtype)<br>torch.cuda.OutOfMemoryError:\
          \ CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacty\
          \ of 14.75 GiB of which 921.06 MiB is free. Including non-PyTorch memory,\
          \ this process has 13.85 GiB memory in use. Of the allocated memory 13.22\
          \ GiB is allocated by PyTorch, and 518.11 MiB is reserved by PyTorch but\
          \ unallocated. If reserved but unallocated memory is large try setting max_split_size_mb\
          \ to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF</p>\n\
          <p>During handling of the above exception, another exception occurred:</p>\n\
          <p>Traceback (most recent call last):<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\"\
          , line 2120, in showtraceback<br>    stb = self.InteractiveTB.structured_traceback(<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 1435, in structured_traceback<br>    return FormattedTB.structured_traceback(<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 1326, in structured_traceback<br>    return VerboseTB.structured_traceback(<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 1173, in structured_traceback<br>    formatted_exception = self.format_exception_as_a_whole(etype,\
          \ evalue, etb, number_of_lines_of_context,<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 1088, in format_exception_as_a_whole<br>    frames.append(self.format_record(record))<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 970, in format_record<br>    frame_info.lines, Colors, self.has_colors,\
          \ lvals<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 792, in lines<br>    return self._sd.lines<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/utils.py\"\
          , line 144, in cached_property_wrapper<br>    value = obj.<strong>dict</strong>[self.func.<strong>name</strong>]\
          \ = self.func(obj)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/core.py\"\
          , line 734, in lines<br>    pieces = self.included_pieces<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/utils.py\"\
          , line 144, in cached_property_wrapper<br>    value = obj.<strong>dict</strong>[self.func.<strong>name</strong>]\
          \ = self.func(obj)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/core.py\"\
          , line 681, in included_pieces<br>    pos = scope_pieces.index(self.executing_piece)<br>\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/utils.py\"\
          , line 144, in cached_property_wrapper<br>    value = obj.<strong>dict</strong>[self.func.<strong>name</strong>]\
          \ = self.func(obj)<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/core.py\"\
          , line 660, in executing_piece<br>    return only(<br>  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/executing/executing.py\"\
          , line 190, in only<br>    raise NotOneValueFound('Expected one value, found\
          \ 0')<br>executing.executing.NotOneValueFound: Expected one value, found\
          \ 0<br>\u200B</p>\n"
        raw: "Unexpected exception formatting exception. Falling back to standard\
          \ exception\r\nTraceback (most recent call last):\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\"\
          , line 3526, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\
          \n  File \"/tmp/ipykernel_10963/2260344357.py\", line 30, in <module>\r\n\
          \    outputs = pipe(prompt, max_new_tokens=1000, do_sample=True, temperature=0.001,\
          \ top_k=50, top_p=0.95)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\"\
          , line 208, in __call__\r\n    return super().__call__(text_inputs, **kwargs)\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/base.py\"\
          , line 1140, in __call__\r\n    return self.run_single(inputs, preprocess_params,\
          \ forward_params, postprocess_params)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/base.py\"\
          , line 1147, in run_single\r\n    model_outputs = self.forward(model_inputs,\
          \ **forward_params)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/base.py\"\
          , line 1046, in forward\r\n    model_outputs = self._forward(model_inputs,\
          \ **forward_params)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\"\
          , line 271, in _forward\r\n    generated_sequence = self.model.generate(input_ids=input_ids,\
          \ attention_mask=attention_mask, **generate_kwargs)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n\
          \  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1777, in generate\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 2874, in sample\r\n    next_token_scores = logits_processor(input_ids,\
          \ next_token_logits)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 1055, in forward\r\n    attention_mask=attention_mask,\r\n  File\
          \ \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 940, in forward\r\n    attention_mask=attention_mask,\r\n  File \"\
          /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 665, in forward\r\n    attention_mask=attention_mask,\r\n  File \"\
          /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/hooks.py\"\
          , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 300, in forward\r\n    attn_weights = nn.functional.softmax(attn_weights,\
          \ dim=-1, dtype=torch.float32).to(query_states.dtype)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/functional.py\"\
          , line 1858, in softmax\r\n    ret = input.softmax(dim, dtype=dtype)\r\n\
          torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.08\
          \ GiB. GPU 0 has a total capacty of 14.75 GiB of which 921.06 MiB is free.\
          \ Including non-PyTorch memory, this process has 13.85 GiB memory in use.\
          \ Of the allocated memory 13.22 GiB is allocated by PyTorch, and 518.11\
          \ MiB is reserved by PyTorch but unallocated. If reserved but unallocated\
          \ memory is large try setting max_split_size_mb to avoid fragmentation.\
          \  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\
          \n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nTraceback (most recent call last):\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\"\
          , line 2120, in showtraceback\r\n    stb = self.InteractiveTB.structured_traceback(\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 1435, in structured_traceback\r\n    return FormattedTB.structured_traceback(\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 1326, in structured_traceback\r\n    return VerboseTB.structured_traceback(\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 1173, in structured_traceback\r\n    formatted_exception = self.format_exception_as_a_whole(etype,\
          \ evalue, etb, number_of_lines_of_context,\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 1088, in format_exception_as_a_whole\r\n    frames.append(self.format_record(record))\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 970, in format_record\r\n    frame_info.lines, Colors, self.has_colors,\
          \ lvals\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
          , line 792, in lines\r\n    return self._sd.lines\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/utils.py\"\
          , line 144, in cached_property_wrapper\r\n    value = obj.__dict__[self.func.__name__]\
          \ = self.func(obj)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/core.py\"\
          , line 734, in lines\r\n    pieces = self.included_pieces\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/utils.py\"\
          , line 144, in cached_property_wrapper\r\n    value = obj.__dict__[self.func.__name__]\
          \ = self.func(obj)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/core.py\"\
          , line 681, in included_pieces\r\n    pos = scope_pieces.index(self.executing_piece)\r\
          \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/utils.py\"\
          , line 144, in cached_property_wrapper\r\n    value = obj.__dict__[self.func.__name__]\
          \ = self.func(obj)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/core.py\"\
          , line 660, in executing_piece\r\n    return only(\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/executing/executing.py\"\
          , line 190, in only\r\n    raise NotOneValueFound('Expected one value, found\
          \ 0')\r\nexecuting.executing.NotOneValueFound: Expected one value, found\
          \ 0\r\n\u200B"
        updatedAt: '2023-12-21T00:37:59.858Z'
      numEdits: 0
      reactions: []
    id: 658388e7cf92e8f35cd4fed8
    type: comment
  author: YWDallas
  content: "Unexpected exception formatting exception. Falling back to standard exception\r\
    \nTraceback (most recent call last):\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\"\
    , line 3526, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\
    \n  File \"/tmp/ipykernel_10963/2260344357.py\", line 30, in <module>\r\n    outputs\
    \ = pipe(prompt, max_new_tokens=1000, do_sample=True, temperature=0.001, top_k=50,\
    \ top_p=0.95)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\"\
    , line 208, in __call__\r\n    return super().__call__(text_inputs, **kwargs)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/base.py\"\
    , line 1140, in __call__\r\n    return self.run_single(inputs, preprocess_params,\
    \ forward_params, postprocess_params)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/base.py\"\
    , line 1147, in run_single\r\n    model_outputs = self.forward(model_inputs, **forward_params)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/base.py\"\
    , line 1046, in forward\r\n    model_outputs = self._forward(model_inputs, **forward_params)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\"\
    , line 271, in _forward\r\n    generated_sequence = self.model.generate(input_ids=input_ids,\
    \ attention_mask=attention_mask, **generate_kwargs)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File\
    \ \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 1777, in generate\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 2874, in sample\r\n    next_token_scores = logits_processor(input_ids,\
    \ next_token_logits)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 1055, in forward\r\n    attention_mask=attention_mask,\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 940, in forward\r\n    attention_mask=attention_mask,\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 665, in forward\r\n    attention_mask=attention_mask,\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/hooks.py\"\
    , line 165, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 300, in forward\r\n    attn_weights = nn.functional.softmax(attn_weights,\
    \ dim=-1, dtype=torch.float32).to(query_states.dtype)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/functional.py\"\
    , line 1858, in softmax\r\n    ret = input.softmax(dim, dtype=dtype)\r\ntorch.cuda.OutOfMemoryError:\
    \ CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacty of\
    \ 14.75 GiB of which 921.06 MiB is free. Including non-PyTorch memory, this process\
    \ has 13.85 GiB memory in use. Of the allocated memory 13.22 GiB is allocated\
    \ by PyTorch, and 518.11 MiB is reserved by PyTorch but unallocated. If reserved\
    \ but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.\
    \  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\n\r\n\
    During handling of the above exception, another exception occurred:\r\n\r\nTraceback\
    \ (most recent call last):\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\"\
    , line 2120, in showtraceback\r\n    stb = self.InteractiveTB.structured_traceback(\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
    , line 1435, in structured_traceback\r\n    return FormattedTB.structured_traceback(\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
    , line 1326, in structured_traceback\r\n    return VerboseTB.structured_traceback(\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
    , line 1173, in structured_traceback\r\n    formatted_exception = self.format_exception_as_a_whole(etype,\
    \ evalue, etb, number_of_lines_of_context,\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
    , line 1088, in format_exception_as_a_whole\r\n    frames.append(self.format_record(record))\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
    , line 970, in format_record\r\n    frame_info.lines, Colors, self.has_colors,\
    \ lvals\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/ultratb.py\"\
    , line 792, in lines\r\n    return self._sd.lines\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/utils.py\"\
    , line 144, in cached_property_wrapper\r\n    value = obj.__dict__[self.func.__name__]\
    \ = self.func(obj)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/core.py\"\
    , line 734, in lines\r\n    pieces = self.included_pieces\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/utils.py\"\
    , line 144, in cached_property_wrapper\r\n    value = obj.__dict__[self.func.__name__]\
    \ = self.func(obj)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/core.py\"\
    , line 681, in included_pieces\r\n    pos = scope_pieces.index(self.executing_piece)\r\
    \n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/utils.py\"\
    , line 144, in cached_property_wrapper\r\n    value = obj.__dict__[self.func.__name__]\
    \ = self.func(obj)\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/stack_data/core.py\"\
    , line 660, in executing_piece\r\n    return only(\r\n  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/executing/executing.py\"\
    , line 190, in only\r\n    raise NotOneValueFound('Expected one value, found 0')\r\
    \nexecuting.executing.NotOneValueFound: Expected one value, found 0\r\n\u200B"
  created_at: 2023-12-21 00:37:59+00:00
  edited: false
  hidden: false
  id: 658388e7cf92e8f35cd4fed8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 43
repo_id: HuggingFaceH4/zephyr-7b-beta
repo_type: model
status: open
target_branch: null
title: Error Message when the number of input tokens exceeds 2000. I am using ml.g4dn.8xlarge
  instance (128 GiB).
