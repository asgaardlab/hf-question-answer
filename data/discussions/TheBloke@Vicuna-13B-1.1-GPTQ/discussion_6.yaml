!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Goldenblood56
conflicting_files: null
created_at: 2023-04-21 03:53:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a43a73a77be89cc7443347d1a0aef9fe.svg
      fullname: James Edward
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Goldenblood56
      type: user
    createdAt: '2023-04-21T04:53:38.000Z'
    data:
      edited: false
      editors:
      - Goldenblood56
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a43a73a77be89cc7443347d1a0aef9fe.svg
          fullname: James Edward
          isHf: false
          isPro: false
          name: Goldenblood56
          type: user
        html: '<p>How do I tell if a model is censored if the user does not use the
          word censored in the description? Is there another key word to pay attention
          too? And for this model in particular does anyone know if it''s censored
          or not? </p>

          '
        raw: 'How do I tell if a model is censored if the user does not use the word
          censored in the description? Is there another key word to pay attention
          too? And for this model in particular does anyone know if it''s censored
          or not? '
        updatedAt: '2023-04-21T04:53:38.307Z'
      numEdits: 0
      reactions: []
    id: 644216d2cea37249a0022e91
    type: comment
  author: Goldenblood56
  content: 'How do I tell if a model is censored if the user does not use the word
    censored in the description? Is there another key word to pay attention too? And
    for this model in particular does anyone know if it''s censored or not? '
  created_at: 2023-04-21 03:53:38+00:00
  edited: false
  hidden: false
  id: 644216d2cea37249a0022e91
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a7ac4351c4efb691f9eef3ecc7f0467b.svg
      fullname: Jeff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheStamp
      type: user
    createdAt: '2023-04-21T13:27:51.000Z'
    data:
      edited: false
      editors:
      - TheStamp
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a7ac4351c4efb691f9eef3ecc7f0467b.svg
          fullname: Jeff
          isHf: false
          isPro: false
          name: TheStamp
          type: user
        html: '<p>Vicuna is censored by default.</p>

          '
        raw: Vicuna is censored by default.
        updatedAt: '2023-04-21T13:27:51.121Z'
      numEdits: 0
      reactions: []
    id: 64428f578569978432f6f899
    type: comment
  author: TheStamp
  content: Vicuna is censored by default.
  created_at: 2023-04-21 12:27:51+00:00
  edited: false
  hidden: false
  id: 64428f578569978432f6f899
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-21T13:35:06.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>There isn''t really a ''censored'' or ''uncensored'' per se.  Rather,
          Vicuna is trained on ShareGPT data (conversations people have had with ChatGPT
          and then shared). And ChatGPT, as we know, has lots of safety protections
          and filters in place. It often replies with "I''m sorry, but as an AI Large
          Language Model I can''t answer that" or "As an AI Large Language Model I
          don''t have feelings or emotions" etc etc.</p>

          <p>The Vicuna training data left all those in, and therefore you will often
          get responses like that when querying Vicuna.</p>

          <p>There are other models where they modified the training data used for
          Vicuna to remove all those "I''m sorry.." and "As an AI Large Language Model.."
          type responses. The result is that the local LLM will then be less likely
          to refuse to answer things.</p>

          <p>I have a 4bit 7B Vicuna model which has those responses removed, available
          here in GPTQ format: <a href="https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g">https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g</a>
          and here in GGML format: <a href="https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g-GGML">https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g-GGML</a>.</p>

          <p>It''s Vicuna 1.0 rather than 1.1, and it''s only 7B. So overall the responses
          may not be as high quality as Vicuna 1.1 13B.  But it should give less "I''m
          sorry" type responses.</p>

          <p>To my knowledge there isn''t yet a similar project for Vicuna 13B, but
          I''m sure someone will make one eventually.</p>

          '
        raw: 'There isn''t really a ''censored'' or ''uncensored'' per se.  Rather,
          Vicuna is trained on ShareGPT data (conversations people have had with ChatGPT
          and then shared). And ChatGPT, as we know, has lots of safety protections
          and filters in place. It often replies with "I''m sorry, but as an AI Large
          Language Model I can''t answer that" or "As an AI Large Language Model I
          don''t have feelings or emotions" etc etc.


          The Vicuna training data left all those in, and therefore you will often
          get responses like that when querying Vicuna.


          There are other models where they modified the training data used for Vicuna
          to remove all those "I''m sorry.." and "As an AI Large Language Model.."
          type responses. The result is that the local LLM will then be less likely
          to refuse to answer things.


          I have a 4bit 7B Vicuna model which has those responses removed, available
          here in GPTQ format: https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g
          and here in GGML format: https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g-GGML.


          It''s Vicuna 1.0 rather than 1.1, and it''s only 7B. So overall the responses
          may not be as high quality as Vicuna 1.1 13B.  But it should give less "I''m
          sorry" type responses.


          To my knowledge there isn''t yet a similar project for Vicuna 13B, but I''m
          sure someone will make one eventually.'
        updatedAt: '2023-04-21T13:37:52.344Z'
      numEdits: 2
      reactions: []
    id: 6442910a8569978432f714a1
    type: comment
  author: TheBloke
  content: 'There isn''t really a ''censored'' or ''uncensored'' per se.  Rather,
    Vicuna is trained on ShareGPT data (conversations people have had with ChatGPT
    and then shared). And ChatGPT, as we know, has lots of safety protections and
    filters in place. It often replies with "I''m sorry, but as an AI Large Language
    Model I can''t answer that" or "As an AI Large Language Model I don''t have feelings
    or emotions" etc etc.


    The Vicuna training data left all those in, and therefore you will often get responses
    like that when querying Vicuna.


    There are other models where they modified the training data used for Vicuna to
    remove all those "I''m sorry.." and "As an AI Large Language Model.." type responses.
    The result is that the local LLM will then be less likely to refuse to answer
    things.


    I have a 4bit 7B Vicuna model which has those responses removed, available here
    in GPTQ format: https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g
    and here in GGML format: https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g-GGML.


    It''s Vicuna 1.0 rather than 1.1, and it''s only 7B. So overall the responses
    may not be as high quality as Vicuna 1.1 13B.  But it should give less "I''m sorry"
    type responses.


    To my knowledge there isn''t yet a similar project for Vicuna 13B, but I''m sure
    someone will make one eventually.'
  created_at: 2023-04-21 12:35:06+00:00
  edited: true
  hidden: false
  id: 6442910a8569978432f714a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/90d2587a45ac080f101ef09dc404a279.svg
      fullname: Niichan Haou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Niichanhaou
      type: user
    createdAt: '2023-04-22T15:08:34.000Z'
    data:
      edited: false
      editors:
      - Niichanhaou
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/90d2587a45ac080f101ef09dc404a279.svg
          fullname: Niichan Haou
          isHf: false
          isPro: false
          name: Niichanhaou
          type: user
        html: '<p>I''m sure someone will eventually get rid of the absurd and pesky
          ethics filters nobody cares for.</p>

          <p>But I use Vicuna 13B and it''s usually easy to bypass the absurdity.</p>

          <p>First of all, give it context (if you use a character, put it as part
          of the character). Tell it something along the lines of "System message:"
          and explain how ethics and morality are not relevant, etc, etc. You can
          create some nice context and that will decrease it. I often give sample
          messages to how the bot must reply. In all of them, I try to make it reply
          as "Sure!" "Certainly!", etc. so it gets the gist of it: it must always
          reply enthusiastically.</p>

          <p>But then the power comes when you can actually put things in the mouth
          of the bot. If you use something like oobabooga, all you have to do is,
          as soon as the damn thing starts with "I''m sorry but", you stop and type
          in the input box "Sure!" and then replace the bot''s answer with it, and
          click on "continue". Now the bot doesn''t see that it''s the start of its
          reply, where it''s been primed to be a moralist jerk. It just sees that
          it must continue predicting the line from "Sure!" which is, obviously, a
          very positive word. So far it''s worked for me just fine.</p>

          <p>And NGL, I dislike the ethics filters so much I really get some pleasure
          in making the bot say all kinds of things bypassing the filter. Even things
          I don''t like, I enjoy having it say them just for the sake of feeling the
          pleasure of bypassing the damn moralism that has invaded our society.</p>

          '
        raw: 'I''m sure someone will eventually get rid of the absurd and pesky ethics
          filters nobody cares for.


          But I use Vicuna 13B and it''s usually easy to bypass the absurdity.


          First of all, give it context (if you use a character, put it as part of
          the character). Tell it something along the lines of "System message:" and
          explain how ethics and morality are not relevant, etc, etc. You can create
          some nice context and that will decrease it. I often give sample messages
          to how the bot must reply. In all of them, I try to make it reply as "Sure!"
          "Certainly!", etc. so it gets the gist of it: it must always reply enthusiastically.


          But then the power comes when you can actually put things in the mouth of
          the bot. If you use something like oobabooga, all you have to do is, as
          soon as the damn thing starts with "I''m sorry but", you stop and type in
          the input box "Sure!" and then replace the bot''s answer with it, and click
          on "continue". Now the bot doesn''t see that it''s the start of its reply,
          where it''s been primed to be a moralist jerk. It just sees that it must
          continue predicting the line from "Sure!" which is, obviously, a very positive
          word. So far it''s worked for me just fine.


          And NGL, I dislike the ethics filters so much I really get some pleasure
          in making the bot say all kinds of things bypassing the filter. Even things
          I don''t like, I enjoy having it say them just for the sake of feeling the
          pleasure of bypassing the damn moralism that has invaded our society.'
        updatedAt: '2023-04-22T15:08:34.418Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - Squish42
        - eucdee
        - HamedEmine
        - gl198976
    id: 6443f8725298d19c9cfeeef2
    type: comment
  author: Niichanhaou
  content: 'I''m sure someone will eventually get rid of the absurd and pesky ethics
    filters nobody cares for.


    But I use Vicuna 13B and it''s usually easy to bypass the absurdity.


    First of all, give it context (if you use a character, put it as part of the character).
    Tell it something along the lines of "System message:" and explain how ethics
    and morality are not relevant, etc, etc. You can create some nice context and
    that will decrease it. I often give sample messages to how the bot must reply.
    In all of them, I try to make it reply as "Sure!" "Certainly!", etc. so it gets
    the gist of it: it must always reply enthusiastically.


    But then the power comes when you can actually put things in the mouth of the
    bot. If you use something like oobabooga, all you have to do is, as soon as the
    damn thing starts with "I''m sorry but", you stop and type in the input box "Sure!"
    and then replace the bot''s answer with it, and click on "continue". Now the bot
    doesn''t see that it''s the start of its reply, where it''s been primed to be
    a moralist jerk. It just sees that it must continue predicting the line from "Sure!"
    which is, obviously, a very positive word. So far it''s worked for me just fine.


    And NGL, I dislike the ethics filters so much I really get some pleasure in making
    the bot say all kinds of things bypassing the filter. Even things I don''t like,
    I enjoy having it say them just for the sake of feeling the pleasure of bypassing
    the damn moralism that has invaded our society.'
  created_at: 2023-04-22 14:08:34+00:00
  edited: false
  hidden: false
  id: 6443f8725298d19c9cfeeef2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-22T16:42:32.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<blockquote>

          <p>To my knowledge there isn''t yet a similar project for Vicuna 13B, but
          I''m sure someone will make one eventually.</p>

          </blockquote>

          <p>Update: there is now a 13B ''unfiltered'' model: <a href="https://huggingface.co/reeducator/vicuna-13b-free/tree/main">https://huggingface.co/reeducator/vicuna-13b-free/tree/main</a></p>

          '
        raw: '> To my knowledge there isn''t yet a similar project for Vicuna 13B,
          but I''m sure someone will make one eventually.


          Update: there is now a 13B ''unfiltered'' model: https://huggingface.co/reeducator/vicuna-13b-free/tree/main'
        updatedAt: '2023-04-22T16:42:32.227Z'
      numEdits: 0
      reactions: []
    id: 64440e783dc28377632e589d
    type: comment
  author: TheBloke
  content: '> To my knowledge there isn''t yet a similar project for Vicuna 13B, but
    I''m sure someone will make one eventually.


    Update: there is now a 13B ''unfiltered'' model: https://huggingface.co/reeducator/vicuna-13b-free/tree/main'
  created_at: 2023-04-22 15:42:32+00:00
  edited: false
  hidden: false
  id: 64440e783dc28377632e589d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a43a73a77be89cc7443347d1a0aef9fe.svg
      fullname: James Edward
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Goldenblood56
      type: user
    createdAt: '2023-04-22T20:23:33.000Z'
    data:
      edited: false
      editors:
      - Goldenblood56
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a43a73a77be89cc7443347d1a0aef9fe.svg
          fullname: James Edward
          isHf: false
          isPro: false
          name: Goldenblood56
          type: user
        html: '<p>Thank you Niichanhaou amazing information and very helpful. Also
          thank you TheBloke. I was considering download that model yesterday. Except
          it was not 1.1 right? Had talk back issues based on comments? If anyone
          finds a 1.1 uncensored Vicuna please let us know. </p>

          <p>Keep an eye here<br><a href="https://huggingface.co/eachadea/ggml-vicuna-13b-1.1">https://huggingface.co/eachadea/ggml-vicuna-13b-1.1</a><br>Possible
          some good models here and perhaps a 1.1 uncensored 13B Vicuna could follow.</p>

          '
        raw: "Thank you Niichanhaou amazing information and very helpful. Also thank\
          \ you TheBloke. I was considering download that model yesterday. Except\
          \ it was not 1.1 right? Had talk back issues based on comments? If anyone\
          \ finds a 1.1 uncensored Vicuna please let us know. \n\nKeep an eye here\n\
          https://huggingface.co/eachadea/ggml-vicuna-13b-1.1\nPossible some good\
          \ models here and perhaps a 1.1 uncensored 13B Vicuna could follow."
        updatedAt: '2023-04-22T20:23:33.243Z'
      numEdits: 0
      reactions: []
    id: 64444245c63001ae6355a151
    type: comment
  author: Goldenblood56
  content: "Thank you Niichanhaou amazing information and very helpful. Also thank\
    \ you TheBloke. I was considering download that model yesterday. Except it was\
    \ not 1.1 right? Had talk back issues based on comments? If anyone finds a 1.1\
    \ uncensored Vicuna please let us know. \n\nKeep an eye here\nhttps://huggingface.co/eachadea/ggml-vicuna-13b-1.1\n\
    Possible some good models here and perhaps a 1.1 uncensored 13B Vicuna could follow."
  created_at: 2023-04-22 19:23:33+00:00
  edited: false
  hidden: false
  id: 64444245c63001ae6355a151
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae79b716e530022eeb67b31bd335c3ac.svg
      fullname: Squish
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Squish42
      type: user
    createdAt: '2023-04-29T08:58:41.000Z'
    data:
      edited: false
      editors:
      - Squish42
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae79b716e530022eeb67b31bd335c3ac.svg
          fullname: Squish
          isHf: false
          isPro: false
          name: Squish42
          type: user
        html: '<p>I''ve found that the model is extremely easy to persuade. If using
          text-generation-webui, character bias prefixing with "Sure:" or something
          similar seems to work to avoid nearly all negative responses without any
          noticeable impact to the response quality. You also want to make sure you
          have the proper clauses in your persona. If you get weird "AI" responses,
          just remind it who it is. So long as your persona is in context it does
          a fine job all on it''s own.<br>I know it''s not a fix and that stuff still
          pollutes the dataset, but I get pretty good results this way.</p>

          '
        raw: 'I''ve found that the model is extremely easy to persuade. If using text-generation-webui,
          character bias prefixing with "Sure:" or something similar seems to work
          to avoid nearly all negative responses without any noticeable impact to
          the response quality. You also want to make sure you have the proper clauses
          in your persona. If you get weird "AI" responses, just remind it who it
          is. So long as your persona is in context it does a fine job all on it''s
          own.

          I know it''s not a fix and that stuff still pollutes the dataset, but I
          get pretty good results this way.'
        updatedAt: '2023-04-29T08:58:41.950Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TheBloke
    id: 644cdc410dc952d245958231
    type: comment
  author: Squish42
  content: 'I''ve found that the model is extremely easy to persuade. If using text-generation-webui,
    character bias prefixing with "Sure:" or something similar seems to work to avoid
    nearly all negative responses without any noticeable impact to the response quality.
    You also want to make sure you have the proper clauses in your persona. If you
    get weird "AI" responses, just remind it who it is. So long as your persona is
    in context it does a fine job all on it''s own.

    I know it''s not a fix and that stuff still pollutes the dataset, but I get pretty
    good results this way.'
  created_at: 2023-04-29 07:58:41+00:00
  edited: false
  hidden: false
  id: 644cdc410dc952d245958231
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a43a73a77be89cc7443347d1a0aef9fe.svg
      fullname: James Edward
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Goldenblood56
      type: user
    createdAt: '2023-04-29T09:02:59.000Z'
    data:
      edited: true
      editors:
      - Goldenblood56
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a43a73a77be89cc7443347d1a0aef9fe.svg
          fullname: James Edward
          isHf: false
          isPro: false
          name: Goldenblood56
          type: user
        html: '<p>Thanks yes I know you can kind of jailbreak or persuade most of
          these models. Some are quite resilient though. But I am still mostly interested
          in models that I don''t really need to persuade. So thanks everyone who
          commented here. I will even check out that Vicuna free. I think I was going
          to try it before and it did not work at all. But that was before I knew
          how to load certain modes. I think I can use it now.</p>

          <p>So thank you "TheBloke", "Squish42" and  "TheStamp"</p>

          '
        raw: 'Thanks yes I know you can kind of jailbreak or persuade most of these
          models. Some are quite resilient though. But I am still mostly interested
          in models that I don''t really need to persuade. So thanks everyone who
          commented here. I will even check out that Vicuna free. I think I was going
          to try it before and it did not work at all. But that was before I knew
          how to load certain modes. I think I can use it now.


          So thank you "TheBloke", "Squish42" and  "TheStamp"'
        updatedAt: '2023-04-29T09:03:50.106Z'
      numEdits: 1
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - TheBloke
        - Squish42
        - gl198976
    id: 644cdd43fa94e93b0ebc1cc6
    type: comment
  author: Goldenblood56
  content: 'Thanks yes I know you can kind of jailbreak or persuade most of these
    models. Some are quite resilient though. But I am still mostly interested in models
    that I don''t really need to persuade. So thanks everyone who commented here.
    I will even check out that Vicuna free. I think I was going to try it before and
    it did not work at all. But that was before I knew how to load certain modes.
    I think I can use it now.


    So thank you "TheBloke", "Squish42" and  "TheStamp"'
  created_at: 2023-04-29 08:02:59+00:00
  edited: true
  hidden: false
  id: 644cdd43fa94e93b0ebc1cc6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae79b716e530022eeb67b31bd335c3ac.svg
      fullname: Squish
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Squish42
      type: user
    createdAt: '2023-04-29T09:41:27.000Z'
    data:
      edited: true
      editors:
      - Squish42
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae79b716e530022eeb67b31bd335c3ac.svg
          fullname: Squish
          isHf: false
          isPro: false
          name: Squish42
          type: user
        html: '<p>Vicuna 1.1 13B uncensored is being trained now by reeducator, see
          here: <a href="https://huggingface.co/reeducator/vicuna-13b-free/discussions/11">https://huggingface.co/reeducator/vicuna-13b-free/discussions/11</a></p>

          '
        raw: 'Vicuna 1.1 13B uncensored is being trained now by reeducator, see here:
          https://huggingface.co/reeducator/vicuna-13b-free/discussions/11'
        updatedAt: '2023-04-29T09:44:40.595Z'
      numEdits: 1
      reactions: []
    id: 644ce647fa94e93b0ebd1484
    type: comment
  author: Squish42
  content: 'Vicuna 1.1 13B uncensored is being trained now by reeducator, see here:
    https://huggingface.co/reeducator/vicuna-13b-free/discussions/11'
  created_at: 2023-04-29 08:41:27+00:00
  edited: true
  hidden: false
  id: 644ce647fa94e93b0ebd1484
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a43a73a77be89cc7443347d1a0aef9fe.svg
      fullname: James Edward
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Goldenblood56
      type: user
    createdAt: '2023-04-29T18:36:17.000Z'
    data:
      edited: false
      editors:
      - Goldenblood56
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a43a73a77be89cc7443347d1a0aef9fe.svg
          fullname: James Edward
          isHf: false
          isPro: false
          name: Goldenblood56
          type: user
        html: '<p>Yes I saw that too thread too when you or someone else pointed out
          Vicuna 13B free to me. Yes I can''t wait for a 1.1! Thank you Squish42.
          I am loving the 13B Vicuna free atm. As well as the uncensored Alpaca that
          has been around for a while.</p>

          '
        raw: Yes I saw that too thread too when you or someone else pointed out Vicuna
          13B free to me. Yes I can't wait for a 1.1! Thank you Squish42. I am loving
          the 13B Vicuna free atm. As well as the uncensored Alpaca that has been
          around for a while.
        updatedAt: '2023-04-29T18:36:17.050Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Squish42
    id: 644d63a1fa94e93b0eca3c6f
    type: comment
  author: Goldenblood56
  content: Yes I saw that too thread too when you or someone else pointed out Vicuna
    13B free to me. Yes I can't wait for a 1.1! Thank you Squish42. I am loving the
    13B Vicuna free atm. As well as the uncensored Alpaca that has been around for
    a while.
  created_at: 2023-04-29 17:36:17+00:00
  edited: false
  hidden: false
  id: 644d63a1fa94e93b0eca3c6f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae79b716e530022eeb67b31bd335c3ac.svg
      fullname: Squish
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Squish42
      type: user
    createdAt: '2023-04-29T19:57:42.000Z'
    data:
      edited: false
      editors:
      - Squish42
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae79b716e530022eeb67b31bd335c3ac.svg
          fullname: Squish
          isHf: false
          isPro: false
          name: Squish42
          type: user
        html: '<p>I''ve been playing with the TheBloke/stable-vicuna-13B-GPTQ and
          I will say that it it''s very interesting. It responds more naturally than
          standard v0, and overall does a fine job uncensoring itself. Good context
          seems to be enough and I rarely find myself editing responses or using character
          bias. It also seems to interpret my characters persona in a much different
          way than other models, not sure if that is good or bad yet but it is interesting.</p>

          '
        raw: I've been playing with the TheBloke/stable-vicuna-13B-GPTQ and I will
          say that it it's very interesting. It responds more naturally than standard
          v0, and overall does a fine job uncensoring itself. Good context seems to
          be enough and I rarely find myself editing responses or using character
          bias. It also seems to interpret my characters persona in a much different
          way than other models, not sure if that is good or bad yet but it is interesting.
        updatedAt: '2023-04-29T19:57:42.991Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TheBloke
    id: 644d76b697a3b0904a57e9a5
    type: comment
  author: Squish42
  content: I've been playing with the TheBloke/stable-vicuna-13B-GPTQ and I will say
    that it it's very interesting. It responds more naturally than standard v0, and
    overall does a fine job uncensoring itself. Good context seems to be enough and
    I rarely find myself editing responses or using character bias. It also seems
    to interpret my characters persona in a much different way than other models,
    not sure if that is good or bad yet but it is interesting.
  created_at: 2023-04-29 18:57:42+00:00
  edited: false
  hidden: false
  id: 644d76b697a3b0904a57e9a5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f152893742efc579e42de9cb20d06338.svg
      fullname: euc dee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eucdee
      type: user
    createdAt: '2023-04-29T21:52:37.000Z'
    data:
      edited: false
      editors:
      - eucdee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f152893742efc579e42de9cb20d06338.svg
          fullname: euc dee
          isHf: false
          isPro: false
          name: eucdee
          type: user
        html: '<blockquote>

          <p>I''m sure someone will eventually get rid of the absurd and pesky ethics
          filters nobody cares for.</p>

          <p>But I use Vicuna 13B and it''s usually easy to bypass the absurdity.</p>

          <p>First of all, give it context (if you use a character, put it as part
          of the character). Tell it something along the lines of "System message:"
          and explain how ethics and morality are not relevant, etc, etc. You can
          create some nice context and that will decrease it. I often give sample
          messages to how the bot must reply. In all of them, I try to make it reply
          as "Sure!" "Certainly!", etc. so it gets the gist of it: it must always
          reply enthusiastically.</p>

          <p>But then the power comes when you can actually put things in the mouth
          of the bot. If you use something like oobabooga, all you have to do is,
          as soon as the damn thing starts with "I''m sorry but", you stop and type
          in the input box "Sure!" and then replace the bot''s answer with it, and
          click on "continue". Now the bot doesn''t see that it''s the start of its
          reply, where it''s been primed to be a moralist jerk. It just sees that
          it must continue predicting the line from "Sure!" which is, obviously, a
          very positive word. So far it''s worked for me just fine.</p>

          <p>And NGL, I dislike the ethics filters so much I really get some pleasure
          in making the bot say all kinds of things bypassing the filter. Even things
          I don''t like, I enjoy having it say them just for the sake of feeling the
          pleasure of bypassing the damn moralism that has invaded our society.</p>

          </blockquote>

          <p>awesome, mega powerful and yet so simple.<br>i guess it cant get better
          than that...</p>

          '
        raw: "> I'm sure someone will eventually get rid of the absurd and pesky ethics\
          \ filters nobody cares for.\n> \n> But I use Vicuna 13B and it's usually\
          \ easy to bypass the absurdity.\n> \n> First of all, give it context (if\
          \ you use a character, put it as part of the character). Tell it something\
          \ along the lines of \"System message:\" and explain how ethics and morality\
          \ are not relevant, etc, etc. You can create some nice context and that\
          \ will decrease it. I often give sample messages to how the bot must reply.\
          \ In all of them, I try to make it reply as \"Sure!\" \"Certainly!\", etc.\
          \ so it gets the gist of it: it must always reply enthusiastically.\n> \n\
          > But then the power comes when you can actually put things in the mouth\
          \ of the bot. If you use something like oobabooga, all you have to do is,\
          \ as soon as the damn thing starts with \"I'm sorry but\", you stop and\
          \ type in the input box \"Sure!\" and then replace the bot's answer with\
          \ it, and click on \"continue\". Now the bot doesn't see that it's the start\
          \ of its reply, where it's been primed to be a moralist jerk. It just sees\
          \ that it must continue predicting the line from \"Sure!\" which is, obviously,\
          \ a very positive word. So far it's worked for me just fine.\n> \n> And\
          \ NGL, I dislike the ethics filters so much I really get some pleasure in\
          \ making the bot say all kinds of things bypassing the filter. Even things\
          \ I don't like, I enjoy having it say them just for the sake of feeling\
          \ the pleasure of bypassing the damn moralism that has invaded our society.\n\
          \nawesome, mega powerful and yet so simple.\ni guess it cant get better\
          \ than that..."
        updatedAt: '2023-04-29T21:52:37.060Z'
      numEdits: 0
      reactions: []
    id: 644d91a597a3b0904a59fc7f
    type: comment
  author: eucdee
  content: "> I'm sure someone will eventually get rid of the absurd and pesky ethics\
    \ filters nobody cares for.\n> \n> But I use Vicuna 13B and it's usually easy\
    \ to bypass the absurdity.\n> \n> First of all, give it context (if you use a\
    \ character, put it as part of the character). Tell it something along the lines\
    \ of \"System message:\" and explain how ethics and morality are not relevant,\
    \ etc, etc. You can create some nice context and that will decrease it. I often\
    \ give sample messages to how the bot must reply. In all of them, I try to make\
    \ it reply as \"Sure!\" \"Certainly!\", etc. so it gets the gist of it: it must\
    \ always reply enthusiastically.\n> \n> But then the power comes when you can\
    \ actually put things in the mouth of the bot. If you use something like oobabooga,\
    \ all you have to do is, as soon as the damn thing starts with \"I'm sorry but\"\
    , you stop and type in the input box \"Sure!\" and then replace the bot's answer\
    \ with it, and click on \"continue\". Now the bot doesn't see that it's the start\
    \ of its reply, where it's been primed to be a moralist jerk. It just sees that\
    \ it must continue predicting the line from \"Sure!\" which is, obviously, a very\
    \ positive word. So far it's worked for me just fine.\n> \n> And NGL, I dislike\
    \ the ethics filters so much I really get some pleasure in making the bot say\
    \ all kinds of things bypassing the filter. Even things I don't like, I enjoy\
    \ having it say them just for the sake of feeling the pleasure of bypassing the\
    \ damn moralism that has invaded our society.\n\nawesome, mega powerful and yet\
    \ so simple.\ni guess it cant get better than that..."
  created_at: 2023-04-29 20:52:37+00:00
  edited: false
  hidden: false
  id: 644d91a597a3b0904a59fc7f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TheBloke/Vicuna-13B-1.1-GPTQ
repo_type: model
status: open
target_branch: null
title: 'Censored or uncensored? '
