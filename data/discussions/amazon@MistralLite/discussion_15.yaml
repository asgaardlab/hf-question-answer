!!python/object:huggingface_hub.community.DiscussionWithDetails
author: apepkuss79
conflicting_files: null
created_at: 2023-12-03 02:53:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1134f882ff1d8246506cf6f8a204c56f.svg
      fullname: Sam Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: apepkuss79
      type: user
    createdAt: '2023-12-03T02:53:03.000Z'
    data:
      edited: false
      editors:
      - apepkuss79
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5935511589050293
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1134f882ff1d8246506cf6f8a204c56f.svg
          fullname: Sam Liu
          isHf: false
          isPro: false
          name: apepkuss79
          type: user
        html: '<p>According to the description in <code>Model card</code>, the prompt
          template is </p>

          <pre><code class="language-text">&lt;|prompter|&gt;{user_message}&lt;/s&gt;&lt;|assistant|&gt;

          </code></pre>

          <p>How about the prompt template for multi-turn conversations? Just concatenate
          the prompt templates one by one? looks like the example below?</p>

          <pre><code class="language-text">&lt;|prompter|&gt;{user_message_1}&lt;/s&gt;&lt;|assistant|&gt;{assistant_message_1}&lt;|prompter|&gt;{user_message_2}&lt;/s&gt;&lt;|assistant|&gt;

          </code></pre>

          '
        raw: "According to the description in `Model card`, the prompt template is\
          \ \r\n\r\n```text\r\n<|prompter|>{user_message}</s><|assistant|>\r\n```\r\
          \n\r\nHow about the prompt template for multi-turn conversations? Just concatenate\
          \ the prompt templates one by one? looks like the example below?\r\n\r\n\
          ```text\r\n<|prompter|>{user_message_1}</s><|assistant|>{assistant_message_1}<|prompter|>{user_message_2}</s><|assistant|>\r\
          \n```"
        updatedAt: '2023-12-03T02:53:03.225Z'
      numEdits: 0
      reactions: []
    id: 656bed8fadba74cd5e505091
    type: comment
  author: apepkuss79
  content: "According to the description in `Model card`, the prompt template is \r\
    \n\r\n```text\r\n<|prompter|>{user_message}</s><|assistant|>\r\n```\r\n\r\nHow\
    \ about the prompt template for multi-turn conversations? Just concatenate the\
    \ prompt templates one by one? looks like the example below?\r\n\r\n```text\r\n\
    <|prompter|>{user_message_1}</s><|assistant|>{assistant_message_1}<|prompter|>{user_message_2}</s><|assistant|>\r\
    \n```"
  created_at: 2023-12-03 02:53:03+00:00
  edited: false
  hidden: false
  id: 656bed8fadba74cd5e505091
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c5af9961560bf7b4108640e1c205234a.svg
      fullname: Yin Song
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: yinsong1986
      type: user
    createdAt: '2023-12-13T06:15:38.000Z'
    data:
      edited: false
      editors:
      - yinsong1986
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9282419085502625
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c5af9961560bf7b4108640e1c205234a.svg
          fullname: Yin Song
          isHf: false
          isPro: false
          name: yinsong1986
          type: user
        html: "<p>Yes <span data-props=\"{&quot;user&quot;:&quot;apepkuss79&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/apepkuss79\"\
          >@<span class=\"underline\">apepkuss79</span></a></span>\n\n\t</span></span>\
          \ , you can try that, but the fine tuned data didn't have such multiple\
          \ run conversation. So there is no guarantee it would be able to pick the\
          \ message history.</p>\n<p>You can try to use this <a rel=\"nofollow\" href=\"\
          https://python.langchain.com/docs/modules/memory/\">https://python.langchain.com/docs/modules/memory/</a>\
          \ to manage the conversation history here. Thank you!</p>\n"
        raw: 'Yes @apepkuss79 , you can try that, but the fine tuned data didn''t
          have such multiple run conversation. So there is no guarantee it would be
          able to pick the message history.


          You can try to use this https://python.langchain.com/docs/modules/memory/
          to manage the conversation history here. Thank you!

          '
        updatedAt: '2023-12-13T06:15:38.771Z'
      numEdits: 0
      reactions: []
    id: 65794c0a4d989b0a68c4d2f8
    type: comment
  author: yinsong1986
  content: 'Yes @apepkuss79 , you can try that, but the fine tuned data didn''t have
    such multiple run conversation. So there is no guarantee it would be able to pick
    the message history.


    You can try to use this https://python.langchain.com/docs/modules/memory/ to manage
    the conversation history here. Thank you!

    '
  created_at: 2023-12-13 06:15:38+00:00
  edited: false
  hidden: false
  id: 65794c0a4d989b0a68c4d2f8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: amazon/MistralLite
repo_type: model
status: open
target_branch: null
title: Prompt template for multi-turn conversations?
