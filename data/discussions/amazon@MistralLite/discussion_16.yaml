!!python/object:huggingface_hub.community.DiscussionWithDetails
author: drachs
conflicting_files: null
created_at: 2023-12-07 06:21:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9e2763e25cf9063bd0429fad43aade5f.svg
      fullname: David H
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: drachs
      type: user
    createdAt: '2023-12-07T06:21:28.000Z'
    data:
      edited: false
      editors:
      - drachs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9835466742515564
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9e2763e25cf9063bd0429fad43aade5f.svg
          fullname: David H
          isHf: false
          isPro: false
          name: drachs
          type: user
        html: '<p>Do I have to do anything special if I want to try to fine tune this
          as compared to a regular mistral fine tune?   I have a task that requires
          very long attention, 60-100k.  I have plenty of data to work with so I thought
          I''d try a LORA based fine tune and see what happens.</p>

          '
        raw: Do I have to do anything special if I want to try to fine tune this as
          compared to a regular mistral fine tune?   I have a task that requires very
          long attention, 60-100k.  I have plenty of data to work with so I thought
          I'd try a LORA based fine tune and see what happens.
        updatedAt: '2023-12-07T06:21:28.424Z'
      numEdits: 0
      reactions: []
    id: 65716468c8018fe64096ea39
    type: comment
  author: drachs
  content: Do I have to do anything special if I want to try to fine tune this as
    compared to a regular mistral fine tune?   I have a task that requires very long
    attention, 60-100k.  I have plenty of data to work with so I thought I'd try a
    LORA based fine tune and see what happens.
  created_at: 2023-12-07 06:21:28+00:00
  edited: false
  hidden: false
  id: 65716468c8018fe64096ea39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c5af9961560bf7b4108640e1c205234a.svg
      fullname: Yin Song
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: yinsong1986
      type: user
    createdAt: '2023-12-13T06:17:58.000Z'
    data:
      edited: false
      editors:
      - yinsong1986
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9048976898193359
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c5af9961560bf7b4108640e1c205234a.svg
          fullname: Yin Song
          isHf: false
          isPro: false
          name: yinsong1986
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;drachs&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/drachs\">@<span class=\"\
          underline\">drachs</span></a></span>\n\n\t</span></span> </p>\n<p>I think\
          \ it is better to set to <code>sliding_window</code>to 100k in the model\
          \ config for your fine tuning. Thank you! If possible, please share with\
          \ us how it goes.</p>\n"
        raw: "@drachs \n\nI think it is better to set to `sliding_window`to 100k in\
          \ the model config for your fine tuning. Thank you! If possible, please\
          \ share with us how it goes."
        updatedAt: '2023-12-13T06:17:58.850Z'
      numEdits: 0
      reactions: []
    id: 65794c96a415f6989a50f152
    type: comment
  author: yinsong1986
  content: "@drachs \n\nI think it is better to set to `sliding_window`to 100k in\
    \ the model config for your fine tuning. Thank you! If possible, please share\
    \ with us how it goes."
  created_at: 2023-12-13 06:17:58+00:00
  edited: false
  hidden: false
  id: 65794c96a415f6989a50f152
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: amazon/MistralLite
repo_type: model
status: open
target_branch: null
title: Fine Tuning
