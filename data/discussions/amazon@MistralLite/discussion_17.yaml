!!python/object:huggingface_hub.community.DiscussionWithDetails
author: soumodeep-semut
conflicting_files: null
created_at: 2023-12-27 05:51:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e9b6931e977ad7ca62573a291d841952.svg
      fullname: Soumodeep Sen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: soumodeep-semut
      type: user
    createdAt: '2023-12-27T05:51:52.000Z'
    data:
      edited: false
      editors:
      - soumodeep-semut
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.47380802035331726
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e9b6931e977ad7ca62573a291d841952.svg
          fullname: Soumodeep Sen
          isHf: false
          isPro: false
          name: soumodeep-semut
          type: user
        html: "<p>Just a month ago, I used this model and finetuned it for some works\
          \ but it is not working and giving the below error.</p>\n<pre><code>Traceback\
          \ (most recent call last):\n  File \"/opt/conda/bin/text-generation-server\"\
          , line 8, in &lt;module&gt;\n    sys.exit(app())\n  File \"/opt/conda/lib/python3.9/site-packages/typer/main.py\"\
          , line 311, in __call__\n    return get_command(self)(*args, **kwargs)\n\
          \  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line 1157,\
          \ in __call__\n    return self.main(*args, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/typer/core.py\"\
          , line 778, in main\n    return _main(\n  File \"/opt/conda/lib/python3.9/site-packages/typer/core.py\"\
          , line 216, in _main\n    rv = self.invoke(ctx)\n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\"\
          , line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n\
          \  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line 1434,\
          \ in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File\
          \ \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line 783, in\
          \ invoke\n    return __callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/typer/main.py\"\
          , line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n\
          \  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
          , line 83, in serve\n    server.serve(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 207, in serve\n    asyncio.run(\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
          , line 44, in run\n    return loop.run_until_complete(main)\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
          , line 634, in run_until_complete\n    self.run_forever()\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
          , line 601, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
          , line 1905, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.9/asyncio/events.py\"\
          , line 80, in _run\n    self._context.run(self._callback, *self._args)\n\
          &gt; File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 159, in serve_inner\n    model = get_model(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 252, in get_model\n    return FlashMistral(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_mistral.py\"\
          , line 312, in __init__\n    SLIDING_WINDOW_BLOCKS = math.ceil(config.sliding_window\
          \ / BLOCK_SIZE)\nTypeError: unsupported operand type(s) for /: 'NoneType'\
          \ and 'int'\n\n2023-12-27T05:49:01.354948Z ERROR shard-manager: text_generation_launcher:\
          \ Shard complete standard error output:\n\nTraceback (most recent call last):\n\
          \n  File \"/opt/conda/bin/text-generation-server\", line 8, in &lt;module&gt;\n\
          \    sys.exit(app())\n\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
          , line 83, in serve\n    server.serve(\n\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 207, in serve\n    asyncio.run(\n\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
          , line 44, in run\n    return loop.run_until_complete(main)\n\n  File \"\
          /opt/conda/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\n\
          \    return future.result()\n\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 159, in serve_inner\n    model = get_model(\n\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 252, in get_model\n    return FlashMistral(\n\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_mistral.py\"\
          , line 312, in __init__\n    SLIDING_WINDOW_BLOCKS = math.ceil(config.sliding_window\
          \ / BLOCK_SIZE)\n\nTypeError: unsupported operand type(s) for /: 'NoneType'\
          \ and 'int'\n rank=0\nError: ShardCannotStart\n2023-12-27T05:49:01.453825Z\
          \ ERROR text_generation_launcher: Shard 0 failed to start\n2023-12-27T05:49:01.453846Z\
          \  INFO text_generation_launcher: Shutting down shards\n</code></pre>\n"
        raw: "Just a month ago, I used this model and finetuned it for some works\
          \ but it is not working and giving the below error.\r\n```\r\nTraceback\
          \ (most recent call last):\r\n  File \"/opt/conda/bin/text-generation-server\"\
          , line 8, in <module>\r\n    sys.exit(app())\r\n  File \"/opt/conda/lib/python3.9/site-packages/typer/main.py\"\
          , line 311, in __call__\r\n    return get_command(self)(*args, **kwargs)\r\
          \n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line\
          \ 1157, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\
          /opt/conda/lib/python3.9/site-packages/typer/core.py\", line 778, in main\r\
          \n    return _main(\r\n  File \"/opt/conda/lib/python3.9/site-packages/typer/core.py\"\
          , line 216, in _main\r\n    rv = self.invoke(ctx)\r\n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\"\
          , line 1688, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\
          \n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line\
          \ 1434, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\
          \n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line\
          \ 783, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"\
          /opt/conda/lib/python3.9/site-packages/typer/main.py\", line 683, in wrapper\r\
          \n    return callback(**use_params)  # type: ignore\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
          , line 83, in serve\r\n    server.serve(\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 207, in serve\r\n    asyncio.run(\r\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
          , line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File\
          \ \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 634, in run_until_complete\r\
          \n    self.run_forever()\r\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
          , line 601, in run_forever\r\n    self._run_once()\r\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
          , line 1905, in _run_once\r\n    handle._run()\r\n  File \"/opt/conda/lib/python3.9/asyncio/events.py\"\
          , line 80, in _run\r\n    self._context.run(self._callback, *self._args)\r\
          \n> File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 159, in serve_inner\r\n    model = get_model(\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 252, in get_model\r\n    return FlashMistral(\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_mistral.py\"\
          , line 312, in __init__\r\n    SLIDING_WINDOW_BLOCKS = math.ceil(config.sliding_window\
          \ / BLOCK_SIZE)\r\nTypeError: unsupported operand type(s) for /: 'NoneType'\
          \ and 'int'\r\n\r\n2023-12-27T05:49:01.354948Z ERROR shard-manager: text_generation_launcher:\
          \ Shard complete standard error output:\r\n\r\nTraceback (most recent call\
          \ last):\r\n\r\n  File \"/opt/conda/bin/text-generation-server\", line 8,\
          \ in <module>\r\n    sys.exit(app())\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
          , line 83, in serve\r\n    server.serve(\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 207, in serve\r\n    asyncio.run(\r\n\r\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
          , line 44, in run\r\n    return loop.run_until_complete(main)\r\n\r\n  File\
          \ \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\r\
          \n    return future.result()\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 159, in serve_inner\r\n    model = get_model(\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 252, in get_model\r\n    return FlashMistral(\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_mistral.py\"\
          , line 312, in __init__\r\n    SLIDING_WINDOW_BLOCKS = math.ceil(config.sliding_window\
          \ / BLOCK_SIZE)\r\n\r\nTypeError: unsupported operand type(s) for /: 'NoneType'\
          \ and 'int'\r\n rank=0\r\nError: ShardCannotStart\r\n2023-12-27T05:49:01.453825Z\
          \ ERROR text_generation_launcher: Shard 0 failed to start\r\n2023-12-27T05:49:01.453846Z\
          \  INFO text_generation_launcher: Shutting down shards\r\n```"
        updatedAt: '2023-12-27T05:51:52.330Z'
      numEdits: 0
      reactions: []
    id: 658bbb787549e4e07e79fadd
    type: comment
  author: soumodeep-semut
  content: "Just a month ago, I used this model and finetuned it for some works but\
    \ it is not working and giving the below error.\r\n```\r\nTraceback (most recent\
    \ call last):\r\n  File \"/opt/conda/bin/text-generation-server\", line 8, in\
    \ <module>\r\n    sys.exit(app())\r\n  File \"/opt/conda/lib/python3.9/site-packages/typer/main.py\"\
    , line 311, in __call__\r\n    return get_command(self)(*args, **kwargs)\r\n \
    \ File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line 1157, in\
    \ __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.9/site-packages/typer/core.py\"\
    , line 778, in main\r\n    return _main(\r\n  File \"/opt/conda/lib/python3.9/site-packages/typer/core.py\"\
    , line 216, in _main\r\n    rv = self.invoke(ctx)\r\n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\"\
    , line 1688, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\
    \n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line 1434,\
    \ in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\
    /opt/conda/lib/python3.9/site-packages/click/core.py\", line 783, in invoke\r\n\
    \    return __callback(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.9/site-packages/typer/main.py\"\
    , line 683, in wrapper\r\n    return callback(**use_params)  # type: ignore\r\n\
    \  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
    , line 83, in serve\r\n    server.serve(\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
    , line 207, in serve\r\n    asyncio.run(\r\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
    , line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
    , line 634, in run_until_complete\r\n    self.run_forever()\r\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
    , line 601, in run_forever\r\n    self._run_once()\r\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
    , line 1905, in _run_once\r\n    handle._run()\r\n  File \"/opt/conda/lib/python3.9/asyncio/events.py\"\
    , line 80, in _run\r\n    self._context.run(self._callback, *self._args)\r\n>\
    \ File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
    , line 159, in serve_inner\r\n    model = get_model(\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
    , line 252, in get_model\r\n    return FlashMistral(\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_mistral.py\"\
    , line 312, in __init__\r\n    SLIDING_WINDOW_BLOCKS = math.ceil(config.sliding_window\
    \ / BLOCK_SIZE)\r\nTypeError: unsupported operand type(s) for /: 'NoneType' and\
    \ 'int'\r\n\r\n2023-12-27T05:49:01.354948Z ERROR shard-manager: text_generation_launcher:\
    \ Shard complete standard error output:\r\n\r\nTraceback (most recent call last):\r\
    \n\r\n  File \"/opt/conda/bin/text-generation-server\", line 8, in <module>\r\n\
    \    sys.exit(app())\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
    , line 83, in serve\r\n    server.serve(\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
    , line 207, in serve\r\n    asyncio.run(\r\n\r\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
    , line 44, in run\r\n    return loop.run_until_complete(main)\r\n\r\n  File \"\
    /opt/conda/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\r\
    \n    return future.result()\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
    , line 159, in serve_inner\r\n    model = get_model(\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
    , line 252, in get_model\r\n    return FlashMistral(\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_mistral.py\"\
    , line 312, in __init__\r\n    SLIDING_WINDOW_BLOCKS = math.ceil(config.sliding_window\
    \ / BLOCK_SIZE)\r\n\r\nTypeError: unsupported operand type(s) for /: 'NoneType'\
    \ and 'int'\r\n rank=0\r\nError: ShardCannotStart\r\n2023-12-27T05:49:01.453825Z\
    \ ERROR text_generation_launcher: Shard 0 failed to start\r\n2023-12-27T05:49:01.453846Z\
    \  INFO text_generation_launcher: Shutting down shards\r\n```"
  created_at: 2023-12-27 05:51:52+00:00
  edited: false
  hidden: false
  id: 658bbb787549e4e07e79fadd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f931ce9cb4adff3057609dd165453975.svg
      fullname: Mihail Chirobocea
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mihailch
      type: user
    createdAt: '2023-12-28T13:43:52.000Z'
    data:
      edited: false
      editors:
      - mihailch
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7958862781524658
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f931ce9cb4adff3057609dd165453975.svg
          fullname: Mihail Chirobocea
          isHf: false
          isPro: false
          name: mihailch
          type: user
        html: '<p>The problem seam to be related with the last commit that changed
          the "sliding_window" to null inside the config. You can try to set it back
          to 16384 in your cached config file (it should be a path like this ~/models--amazon--MistralLite/snapshots).</p>

          '
        raw: The problem seam to be related with the last commit that changed the
          "sliding_window" to null inside the config. You can try to set it back to
          16384 in your cached config file (it should be a path like this ~/models--amazon--MistralLite/snapshots).
        updatedAt: '2023-12-28T13:43:52.595Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - dorike
    id: 658d7b9879c9c9b95f5e3d7d
    type: comment
  author: mihailch
  content: The problem seam to be related with the last commit that changed the "sliding_window"
    to null inside the config. You can try to set it back to 16384 in your cached
    config file (it should be a path like this ~/models--amazon--MistralLite/snapshots).
  created_at: 2023-12-28 13:43:52+00:00
  edited: false
  hidden: false
  id: 658d7b9879c9c9b95f5e3d7d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/73743366a937da9829b637576004bd9c.svg
      fullname: Vinayak Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dorike
      type: user
    createdAt: '2024-01-03T13:09:06.000Z'
    data:
      edited: true
      editors:
      - dorike
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.510930597782135
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/73743366a937da9829b637576004bd9c.svg
          fullname: Vinayak Sharma
          isHf: false
          isPro: false
          name: dorike
          type: user
        html: "<p>I am facing the same issue.<br><span data-props=\"{&quot;user&quot;:&quot;mihailch&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/mihailch\"\
          >@<span class=\"underline\">mihailch</span></a></span>\n\n\t</span></span>\
          \ Can you please explain how I can set 'sliding_window\" if I'm using below\
          \ method to use tgi?</p>\n<p>hub = {<br>    'HF_MODEL_ID':'amazon/MistralLite',<br>\
          \    'SM_NUM_GPUS': json.dumps(1)<br>}</p>\n<p>huggingface_model = HuggingFaceModel(<br>image_uri=get_huggingface_llm_image_uri(\"\
          huggingface\",version=\"1.1.0\"),<br>    env=hub,<br>    role=role,<br>)</p>\n\
          <p>predictor = huggingface_model.deploy(<br>    initial_instance_count=1,<br>\
          \    instance_type=\"ml.g5.2xlarge\",<br>    container_startup_health_check_timeout=300,<br>\
          \  )\n  </p>\n"
        raw: "I am facing the same issue.\n@mihailch Can you please explain how I\
          \ can set 'sliding_window\" if I'm using below method to use tgi?\n\nhub\
          \ = {\n    'HF_MODEL_ID':'amazon/MistralLite',\n    'SM_NUM_GPUS': json.dumps(1)\n\
          }\n\nhuggingface_model = HuggingFaceModel(\nimage_uri=get_huggingface_llm_image_uri(\"\
          huggingface\",version=\"1.1.0\"),\n    env=hub,\n    role=role, \n)\n\n\
          predictor = huggingface_model.deploy(\n    initial_instance_count=1,\n \
          \   instance_type=\"ml.g5.2xlarge\",\n    container_startup_health_check_timeout=300,\n\
          \  )\n  "
        updatedAt: '2024-01-03T13:09:55.260Z'
      numEdits: 3
      reactions: []
    id: 65955c72e589f84445db3e7b
    type: comment
  author: dorike
  content: "I am facing the same issue.\n@mihailch Can you please explain how I can\
    \ set 'sliding_window\" if I'm using below method to use tgi?\n\nhub = {\n   \
    \ 'HF_MODEL_ID':'amazon/MistralLite',\n    'SM_NUM_GPUS': json.dumps(1)\n}\n\n\
    huggingface_model = HuggingFaceModel(\nimage_uri=get_huggingface_llm_image_uri(\"\
    huggingface\",version=\"1.1.0\"),\n    env=hub,\n    role=role, \n)\n\npredictor\
    \ = huggingface_model.deploy(\n    initial_instance_count=1,\n    instance_type=\"\
    ml.g5.2xlarge\",\n    container_startup_health_check_timeout=300,\n  )\n  "
  created_at: 2024-01-03 13:09:06+00:00
  edited: true
  hidden: false
  id: 65955c72e589f84445db3e7b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/73743366a937da9829b637576004bd9c.svg
      fullname: Vinayak Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dorike
      type: user
    createdAt: '2024-01-03T13:17:00.000Z'
    data:
      edited: false
      editors:
      - dorike
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9277471303939819
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/73743366a937da9829b637576004bd9c.svg
          fullname: Vinayak Sharma
          isHf: false
          isPro: false
          name: dorike
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;yinsong1986&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/yinsong1986\"\
          >@<span class=\"underline\">yinsong1986</span></a></span>\n\n\t</span></span><br>Your\
          \ last commit in config file for 'sliding_window' is causing the issue with\
          \ Sagemaker endpoint and with Sagemaker SDK.<br>Can you please suggest any\
          \ solution?<br>Thanks in advance.</p>\n"
        raw: "@yinsong1986 \nYour last commit in config file for 'sliding_window'\
          \ is causing the issue with Sagemaker endpoint and with Sagemaker SDK.\n\
          Can you please suggest any solution?\nThanks in advance."
        updatedAt: '2024-01-03T13:17:00.741Z'
      numEdits: 0
      reactions: []
    id: 65955e4cc7023f8f800ee725
    type: comment
  author: dorike
  content: "@yinsong1986 \nYour last commit in config file for 'sliding_window' is\
    \ causing the issue with Sagemaker endpoint and with Sagemaker SDK.\nCan you please\
    \ suggest any solution?\nThanks in advance."
  created_at: 2024-01-03 13:17:00+00:00
  edited: false
  hidden: false
  id: 65955e4cc7023f8f800ee725
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f258ee558ab7383e0a38c2d7a653b062.svg
      fullname: Chen Wu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: chenwuml
      type: user
    createdAt: '2024-01-03T13:37:29.000Z'
    data:
      edited: false
      editors:
      - chenwuml
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5296353101730347
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f258ee558ab7383e0a38c2d7a653b062.svg
          fullname: Chen Wu
          isHf: false
          isPro: false
          name: chenwuml
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;dorike&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/dorike\">@<span class=\"\
          underline\">dorike</span></a></span>\n\n\t</span></span><br>Does this temp\
          \ solution work? basically use the previous revision for the time being.</p>\n\
          <pre><code class=\"language-python\">hub = {\n<span class=\"hljs-string\"\
          >'HF_MODEL_ID'</span>:<span class=\"hljs-string\">'amazon/MistralLite'</span>,\n\
          <span class=\"hljs-string\">'SM_NUM_GPUS'</span>: json.dumps(<span class=\"\
          hljs-number\">1</span>),\n<span class=\"hljs-string\">'HF_MODEL_REVISION'</span>:<span\
          \ class=\"hljs-string\">'23486089ab7ba741b34adc69ab7555885f8abe71'</span>\n\
          }\n</code></pre>\n"
        raw: "@dorike \nDoes this temp solution work? basically use the previous revision\
          \ for the time being.\n```python\nhub = {\n'HF_MODEL_ID':'amazon/MistralLite',\n\
          'SM_NUM_GPUS': json.dumps(1),\n'HF_MODEL_REVISION':'23486089ab7ba741b34adc69ab7555885f8abe71'\n\
          }\n```"
        updatedAt: '2024-01-03T13:37:29.063Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - dorike
    id: 6595631901261599c6d101ed
    type: comment
  author: chenwuml
  content: "@dorike \nDoes this temp solution work? basically use the previous revision\
    \ for the time being.\n```python\nhub = {\n'HF_MODEL_ID':'amazon/MistralLite',\n\
    'SM_NUM_GPUS': json.dumps(1),\n'HF_MODEL_REVISION':'23486089ab7ba741b34adc69ab7555885f8abe71'\n\
    }\n```"
  created_at: 2024-01-03 13:37:29+00:00
  edited: false
  hidden: false
  id: 6595631901261599c6d101ed
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/73743366a937da9829b637576004bd9c.svg
      fullname: Vinayak Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dorike
      type: user
    createdAt: '2024-01-03T14:10:34.000Z'
    data:
      edited: true
      editors:
      - dorike
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7572832107543945
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/73743366a937da9829b637576004bd9c.svg
          fullname: Vinayak Sharma
          isHf: false
          isPro: false
          name: dorike
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;dorike&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/dorike\"\
          >@<span class=\"underline\">dorike</span></a></span>\n\n\t</span></span><br>Does\
          \ this temp solution work? basically use the previous revision for the time\
          \ being.</p>\n<pre><code class=\"language-python\">hub = {\n<span class=\"\
          hljs-string\">'HF_MODEL_ID'</span>:<span class=\"hljs-string\">'amazon/MistralLite'</span>,\n\
          <span class=\"hljs-string\">'SM_NUM_GPUS'</span>: json.dumps(<span class=\"\
          hljs-number\">1</span>),\n<span class=\"hljs-string\">'HF_MODEL_REVISION'</span>:<span\
          \ class=\"hljs-string\">'23486089ab7ba741b34adc69ab7555885f8abe71'</span>\n\
          }\n</code></pre>\n<p><span data-props=\"{&quot;user&quot;:&quot;chenwuml&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/chenwuml\"\
          >@<span class=\"underline\">chenwuml</span></a></span>\n\n\t</span></span><br>Yup\
          \ this actually worked. Thanks<br>I learned something new today.</p>\n</blockquote>\n\
          <p>Thanks again.</p>\n"
        raw: "> @dorike \n> Does this temp solution work? basically use the previous\
          \ revision for the time being.\n> ```python\n> hub = {\n> 'HF_MODEL_ID':'amazon/MistralLite',\n\
          > 'SM_NUM_GPUS': json.dumps(1),\n> 'HF_MODEL_REVISION':'23486089ab7ba741b34adc69ab7555885f8abe71'\n\
          > }\n> ```\n@chenwuml \nYup this actually worked. Thanks \nI learned something\
          \ new today.\n\nThanks again."
        updatedAt: '2024-01-03T14:11:10.981Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - chenwuml
    id: 65956ada2fb5530bae565e26
    type: comment
  author: dorike
  content: "> @dorike \n> Does this temp solution work? basically use the previous\
    \ revision for the time being.\n> ```python\n> hub = {\n> 'HF_MODEL_ID':'amazon/MistralLite',\n\
    > 'SM_NUM_GPUS': json.dumps(1),\n> 'HF_MODEL_REVISION':'23486089ab7ba741b34adc69ab7555885f8abe71'\n\
    > }\n> ```\n@chenwuml \nYup this actually worked. Thanks \nI learned something\
    \ new today.\n\nThanks again."
  created_at: 2024-01-03 14:10:34+00:00
  edited: true
  hidden: false
  id: 65956ada2fb5530bae565e26
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 17
repo_id: amazon/MistralLite
repo_type: model
status: open
target_branch: null
title: MistralLite is not running on Text Generation Inference
