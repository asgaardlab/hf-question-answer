!!python/object:huggingface_hub.community.DiscussionWithDetails
author: treksis
conflicting_files: null
created_at: 2023-10-10 20:35:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674672951716-63268e321069e50203a86671.jpeg?w=200&h=200&f=face
      fullname: Ho woo Jang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: treksis
      type: user
    createdAt: '2023-10-10T21:35:38.000Z'
    data:
      edited: true
      editors:
      - treksis
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5627791881561279
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674672951716-63268e321069e50203a86671.jpeg?w=200&h=200&f=face
          fullname: Ho woo Jang
          isHf: false
          isPro: false
          name: treksis
          type: user
        html: "<p>Hi,</p>\n<p>I tried to use codeformer .fp16 version with the script\
          \ that is on the repo that you used to convert the onnx model.</p>\n<p><a\
          \ rel=\"nofollow\" href=\"https://github.com/harisreedhar/Face-Upscalers-ONNX\"\
          >https://github.com/harisreedhar/Face-Upscalers-ONNX</a></p>\n<p>example.py</p>\n\
          <pre><code>import os\nimport cv2\nimport numpy as np\n\nfrom GPEN.GPEN import\
          \ GPEN\nfrom GFPGAN.GFPGAN import GFPGAN\nfrom Codeformer.Codeformer import\
          \ CodeFormer\nfrom Restoreformer.Restoreformer import RestoreFormer\n\n\
          #codeformer = CodeFormer(model_path=\"codeformer.onnx\", device=\"cpu\"\
          )\ncodeformer = CodeFormer(model_path=\"codeformer.fp16.onnx\", device=\"\
          cpu\")\n\nimage_directory = \"./test_images\"\n\nenhanced_images = []\n\n\
          for filename in os.listdir(image_directory):\n    if filename.lower().endswith(('.jpg',\
          \ '.png')):\n        image_path = os.path.join(image_directory, filename)\n\
          \        img = cv2.imread(image_path)\n\n        hstacked = np.hstack([\n\
          \            cv2.resize(img, (512,512)),\n            codeformer.enhance(img),\n\
          \        ])\n\n    enhanced_images.append(hstacked)\n\ncv2.imwrite(\"output2.jpg\"\
          , np.vstack(enhanced_images))\n</code></pre>\n<p>and I'm getting this error.</p>\n\
          <pre><code>onnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument:\
          \ [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type.\
          \ Actual: (tensor(float)) , expected: (tensor(float16)) \n</code></pre>\n\
          <p>I tried changing preprocess function into np.float16, still I'm not able\
          \ to inference it. If you succesfully made inference, would you mind to\
          \ share the code?</p>\n<p>Codeformer/Codeformer.py</p>\n<pre><code>def preprocess(self,\
          \ img, w):\n    img = cv2.resize(img, self.resolution, interpolation=cv2.INTER_LINEAR)\n\
          \    img = img.astype(np.float16)[:,:,::-1] / 255.0  # Convert to float16\n\
          \    img = img.transpose((2, 0, 1))\n    img = (img - 0.5) / 0.5\n    img\
          \ = np.expand_dims(img, axis=0).astype(np.float16)  # Convert to float16\n\
          \    w = np.array([w], dtype=np.float16)  # Convert to float16\n    return\
          \ img, w\n</code></pre>\n<p>Thank you</p>\n"
        raw: "Hi,\n\nI tried to use codeformer .fp16 version with the script that\
          \ is on the repo that you used to convert the onnx model.\n\nhttps://github.com/harisreedhar/Face-Upscalers-ONNX\n\
          \nexample.py\n```\nimport os\nimport cv2\nimport numpy as np\n\nfrom GPEN.GPEN\
          \ import GPEN\nfrom GFPGAN.GFPGAN import GFPGAN\nfrom Codeformer.Codeformer\
          \ import CodeFormer\nfrom Restoreformer.Restoreformer import RestoreFormer\n\
          \n#codeformer = CodeFormer(model_path=\"codeformer.onnx\", device=\"cpu\"\
          )\ncodeformer = CodeFormer(model_path=\"codeformer.fp16.onnx\", device=\"\
          cpu\")\n\nimage_directory = \"./test_images\"\n\nenhanced_images = []\n\n\
          for filename in os.listdir(image_directory):\n    if filename.lower().endswith(('.jpg',\
          \ '.png')):\n        image_path = os.path.join(image_directory, filename)\n\
          \        img = cv2.imread(image_path)\n\n        hstacked = np.hstack([\n\
          \            cv2.resize(img, (512,512)),\n            codeformer.enhance(img),\n\
          \        ])\n\n    enhanced_images.append(hstacked)\n\ncv2.imwrite(\"output2.jpg\"\
          , np.vstack(enhanced_images))\n```\n\nand I'm getting this error.\n\n```\n\
          onnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError]\
          \ : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual: (tensor(float))\
          \ , expected: (tensor(float16)) \n```\n\nI tried changing preprocess function\
          \ into np.float16, still I'm not able to inference it. If you succesfully\
          \ made inference, would you mind to share the code?\n\nCodeformer/Codeformer.py\n\
          ```    \ndef preprocess(self, img, w):\n    img = cv2.resize(img, self.resolution,\
          \ interpolation=cv2.INTER_LINEAR)\n    img = img.astype(np.float16)[:,:,::-1]\
          \ / 255.0  # Convert to float16\n    img = img.transpose((2, 0, 1))\n  \
          \  img = (img - 0.5) / 0.5\n    img = np.expand_dims(img, axis=0).astype(np.float16)\
          \  # Convert to float16\n    w = np.array([w], dtype=np.float16)  # Convert\
          \ to float16\n    return img, w\n```\n\nThank you"
        updatedAt: '2023-10-10T21:36:26.639Z'
      numEdits: 1
      reactions: []
    id: 6525c3aabda6113c955faca8
    type: comment
  author: treksis
  content: "Hi,\n\nI tried to use codeformer .fp16 version with the script that is\
    \ on the repo that you used to convert the onnx model.\n\nhttps://github.com/harisreedhar/Face-Upscalers-ONNX\n\
    \nexample.py\n```\nimport os\nimport cv2\nimport numpy as np\n\nfrom GPEN.GPEN\
    \ import GPEN\nfrom GFPGAN.GFPGAN import GFPGAN\nfrom Codeformer.Codeformer import\
    \ CodeFormer\nfrom Restoreformer.Restoreformer import RestoreFormer\n\n#codeformer\
    \ = CodeFormer(model_path=\"codeformer.onnx\", device=\"cpu\")\ncodeformer = CodeFormer(model_path=\"\
    codeformer.fp16.onnx\", device=\"cpu\")\n\nimage_directory = \"./test_images\"\
    \n\nenhanced_images = []\n\nfor filename in os.listdir(image_directory):\n   \
    \ if filename.lower().endswith(('.jpg', '.png')):\n        image_path = os.path.join(image_directory,\
    \ filename)\n        img = cv2.imread(image_path)\n\n        hstacked = np.hstack([\n\
    \            cv2.resize(img, (512,512)),\n            codeformer.enhance(img),\n\
    \        ])\n\n    enhanced_images.append(hstacked)\n\ncv2.imwrite(\"output2.jpg\"\
    , np.vstack(enhanced_images))\n```\n\nand I'm getting this error.\n\n```\nonnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument:\
    \ [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual:\
    \ (tensor(float)) , expected: (tensor(float16)) \n```\n\nI tried changing preprocess\
    \ function into np.float16, still I'm not able to inference it. If you succesfully\
    \ made inference, would you mind to share the code?\n\nCodeformer/Codeformer.py\n\
    ```    \ndef preprocess(self, img, w):\n    img = cv2.resize(img, self.resolution,\
    \ interpolation=cv2.INTER_LINEAR)\n    img = img.astype(np.float16)[:,:,::-1]\
    \ / 255.0  # Convert to float16\n    img = img.transpose((2, 0, 1))\n    img =\
    \ (img - 0.5) / 0.5\n    img = np.expand_dims(img, axis=0).astype(np.float16)\
    \  # Convert to float16\n    w = np.array([w], dtype=np.float16)  # Convert to\
    \ float16\n    return img, w\n```\n\nThank you"
  created_at: 2023-10-10 20:35:38+00:00
  edited: true
  hidden: false
  id: 6525c3aabda6113c955faca8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674672951716-63268e321069e50203a86671.jpeg?w=200&h=200&f=face
      fullname: Ho woo Jang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: treksis
      type: user
    createdAt: '2023-10-10T21:51:17.000Z'
    data:
      edited: true
      editors:
      - treksis
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.22416694462299347
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674672951716-63268e321069e50203a86671.jpeg?w=200&h=200&f=face
          fullname: Ho woo Jang
          isHf: false
          isPro: false
          name: treksis
          type: user
        html: "<p>Fixed.</p>\n<pre><code>\ndef preprocess(self, img, w):\n       \
          \ img = cv2.resize(img, self.resolution, interpolation=cv2.INTER_LINEAR)\n\
          \        img = img.astype(np.float32)[:,:,::-1] / 255.0\n        img = img.transpose((2,\
          \ 0, 1))\n        img = (img - 0.5) / 0.5\n        img = np.expand_dims(img,\
          \ axis=0).astype(np.float16) #only this one to changed.\n        w = np.array([w],\
          \ dtype=np.double)\n        return img, w\n</code></pre>\n"
        raw: "Fixed.\n\n```  \n\ndef preprocess(self, img, w):\n        img = cv2.resize(img,\
          \ self.resolution, interpolation=cv2.INTER_LINEAR)\n        img = img.astype(np.float32)[:,:,::-1]\
          \ / 255.0\n        img = img.transpose((2, 0, 1))\n        img = (img -\
          \ 0.5) / 0.5\n        img = np.expand_dims(img, axis=0).astype(np.float16)\
          \ #only this one to changed.\n        w = np.array([w], dtype=np.double)\n\
          \        return img, w\n```"
        updatedAt: '2023-10-10T21:51:48.205Z'
      numEdits: 3
      reactions: []
      relatedEventId: 6525c755774dcb9103663f53
    id: 6525c755774dcb9103663f4f
    type: comment
  author: treksis
  content: "Fixed.\n\n```  \n\ndef preprocess(self, img, w):\n        img = cv2.resize(img,\
    \ self.resolution, interpolation=cv2.INTER_LINEAR)\n        img = img.astype(np.float32)[:,:,::-1]\
    \ / 255.0\n        img = img.transpose((2, 0, 1))\n        img = (img - 0.5) /\
    \ 0.5\n        img = np.expand_dims(img, axis=0).astype(np.float16) #only this\
    \ one to changed.\n        w = np.array([w], dtype=np.double)\n        return\
    \ img, w\n```"
  created_at: 2023-10-10 20:51:17+00:00
  edited: true
  hidden: false
  id: 6525c755774dcb9103663f4f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674672951716-63268e321069e50203a86671.jpeg?w=200&h=200&f=face
      fullname: Ho woo Jang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: treksis
      type: user
    createdAt: '2023-10-10T21:51:17.000Z'
    data:
      status: closed
    id: 6525c755774dcb9103663f53
    type: status-change
  author: treksis
  created_at: 2023-10-10 20:51:17+00:00
  id: 6525c755774dcb9103663f53
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: netrunner-exe/Face-Upscalers-onnx
repo_type: model
status: closed
target_branch: null
title: Hi, do you succesfully make inference with .fp16?
