!!python/object:huggingface_hub.community.DiscussionWithDetails
author: qhkm
conflicting_files: null
created_at: 2023-10-19 16:01:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b1ea0542119d7103de60a6a39ea21502.svg
      fullname: qhkm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: qhkm
      type: user
    createdAt: '2023-10-19T17:01:56.000Z'
    data:
      edited: false
      editors:
      - qhkm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9822293519973755
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b1ea0542119d7103de60a6a39ea21502.svg
          fullname: qhkm
          isHf: false
          isPro: false
          name: qhkm
          type: user
        html: '<p>Hi there! This is super cool! Saw it on twitter and was amazed by
          the performance as compared to sentence embedding. Would love to be able
          to use this in llama cpp so would need to convert to gguf to be able to
          use it. Do you have any idea how to do that? Thanks!</p>

          '
        raw: Hi there! This is super cool! Saw it on twitter and was amazed by the
          performance as compared to sentence embedding. Would love to be able to
          use this in llama cpp so would need to convert to gguf to be able to use
          it. Do you have any idea how to do that? Thanks!
        updatedAt: '2023-10-19T17:01:56.273Z'
      numEdits: 0
      reactions: []
    id: 65316104cdc25730d4a6aa74
    type: comment
  author: qhkm
  content: Hi there! This is super cool! Saw it on twitter and was amazed by the performance
    as compared to sentence embedding. Would love to be able to use this in llama
    cpp so would need to convert to gguf to be able to use it. Do you have any idea
    how to do that? Thanks!
  created_at: 2023-10-19 16:01:56+00:00
  edited: false
  hidden: false
  id: 65316104cdc25730d4a6aa74
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fbdc193a07ef87e2e3388180b5eee723.svg
      fullname: Benjamin Anderson
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: andersonbcdefg
      type: user
    createdAt: '2023-10-27T16:20:41.000Z'
    data:
      edited: false
      editors:
      - andersonbcdefg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9538739919662476
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fbdc193a07ef87e2e3388180b5eee723.svg
          fullname: Benjamin Anderson
          isHf: false
          isPro: false
          name: andersonbcdefg
          type: user
        html: '<p>I would not recommend using this with Llama.cpp. It''s a BERT model,
          so I looked into BERT.cpp but I don''t really see the benefits of that over
          ONNX. I provided ONNX checkpoints so you should just use those. Many of
          the benefits of using Llama.cpp are more relevant to text generation, not
          so much for embeddings. </p>

          '
        raw: 'I would not recommend using this with Llama.cpp. It''s a BERT model,
          so I looked into BERT.cpp but I don''t really see the benefits of that over
          ONNX. I provided ONNX checkpoints so you should just use those. Many of
          the benefits of using Llama.cpp are more relevant to text generation, not
          so much for embeddings. '
        updatedAt: '2023-10-27T16:20:41.760Z'
      numEdits: 0
      reactions: []
    id: 653be359953b0158d6c3706a
    type: comment
  author: andersonbcdefg
  content: 'I would not recommend using this with Llama.cpp. It''s a BERT model, so
    I looked into BERT.cpp but I don''t really see the benefits of that over ONNX.
    I provided ONNX checkpoints so you should just use those. Many of the benefits
    of using Llama.cpp are more relevant to text generation, not so much for embeddings. '
  created_at: 2023-10-27 15:20:41+00:00
  edited: false
  hidden: false
  id: 653be359953b0158d6c3706a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TaylorAI/gte-tiny
repo_type: model
status: open
target_branch: null
title: Do you have guide to convert this to GGUF/GGML format?
