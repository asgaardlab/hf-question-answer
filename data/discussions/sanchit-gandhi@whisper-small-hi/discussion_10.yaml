!!python/object:huggingface_hub.community.DiscussionWithDetails
author: 5amuel
conflicting_files: null
created_at: 2023-01-30 13:56:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/25048fb67e089f0b3e17e90459b399f6.svg
      fullname: Samuel Maurer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 5amuel
      type: user
    createdAt: '2023-01-30T13:56:51.000Z'
    data:
      edited: false
      editors:
      - 5amuel
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/25048fb67e089f0b3e17e90459b399f6.svg
          fullname: Samuel Maurer
          isHf: false
          isPro: false
          name: 5amuel
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ ,<br>i tried to reproduce your hindi fine-tuning from <a href=\"https://huggingface.co/blog/fine-tune-whisper\"\
          >https://huggingface.co/blog/fine-tune-whisper</a> with the exact same code\
          \ as you, but somehow i don't get the same performance.<br>I'm not sure\
          \ what causes the different results? maybe you can lead me in the right\
          \ direction? the link below contains the script i'm running:</p>\n<p><a\
          \ rel=\"nofollow\" href=\"https://pastebin.com/wz4dyiEA\">https://pastebin.com/wz4dyiEA</a></p>\n\
          <p>My results:</p>\n<div class=\"max-w-full overflow-auto\">\n\t<table>\n\
          \t\t<thead><tr>\n<th align=\"center\">Training Loss</th>\n<th align=\"center\"\
          >Epoch</th>\n<th align=\"center\">Step</th>\n<th align=\"center\">Validation\
          \ Loss</th>\n<th align=\"center\">Wer</th>\n</tr>\n\n\t\t</thead><tbody><tr>\n\
          <td align=\"center\">0.0885</td>\n<td align=\"center\">2.44</td>\n<td align=\"\
          center\">1000</td>\n<td align=\"center\">0.2941</td>\n<td align=\"center\"\
          >34.8684</td>\n</tr>\n<tr>\n<td align=\"center\">0.0222</td>\n<td align=\"\
          center\">4.89</td>\n<td align=\"center\">2000</td>\n<td align=\"center\"\
          >0.3481</td>\n<td align=\"center\">37.2894</td>\n</tr>\n<tr>\n<td align=\"\
          center\">0.0023</td>\n<td align=\"center\">7.33</td>\n<td align=\"center\"\
          >3000</td>\n<td align=\"center\">0.4163</td>\n<td align=\"center\">61.7286</td>\n\
          </tr>\n<tr>\n<td align=\"center\">0.0004</td>\n<td align=\"center\">9.78</td>\n\
          <td align=\"center\">4000</td>\n<td align=\"center\">0.4440</td>\n<td align=\"\
          center\">79.7511</td>\n</tr>\n<tr>\n<td align=\"center\">0.0002</td>\n<td\
          \ align=\"center\">12.22</td>\n<td align=\"center\">5000</td>\n<td align=\"\
          center\">0.4595</td>\n<td align=\"center\">82.5277</td>\n</tr>\n</tbody>\n\
          \t</table>\n</div>\n<p>Transformers 4.26.0.dev0<br>Pytorch 1.13.1+cu117<br>Datasets\
          \ 2.8.0<br>Tokenizer 0.13.2</p>\n"
        raw: "Hey @sanchit-gandhi ,\r\ni tried to reproduce your hindi fine-tuning\
          \ from https://huggingface.co/blog/fine-tune-whisper with the exact same\
          \ code as you, but somehow i don't get the same performance.\r\nI'm not\
          \ sure what causes the different results? maybe you can lead me in the right\
          \ direction? the link below contains the script i'm running:\r\n\r\nhttps://pastebin.com/wz4dyiEA\r\
          \n\r\nMy results:\r\n| Training Loss | Epoch | Step | Validation Loss |\
          \ Wer     |\r\n|:-------------:|:-----:|:----:|:---------------:|:-------:|\r\
          \n| 0.0885        | 2.44  | 1000 | 0.2941          | 34.8684 |\r\n| 0.0222\
          \        | 4.89  | 2000 | 0.3481          | 37.2894 |\r\n| 0.0023      \
          \  | 7.33  | 3000 | 0.4163          | 61.7286 |\r\n| 0.0004        | 9.78\
          \  | 4000 | 0.4440          | 79.7511 |\r\n| 0.0002        | 12.22 | 5000\
          \ | 0.4595          | 82.5277 |\r\n\r\nTransformers 4.26.0.dev0\r\nPytorch\
          \ 1.13.1+cu117\r\nDatasets 2.8.0\r\nTokenizer 0.13.2"
        updatedAt: '2023-01-30T13:56:51.092Z'
      numEdits: 0
      reactions: []
    id: 63d7cca307cd1aa3c49b485a
    type: comment
  author: 5amuel
  content: "Hey @sanchit-gandhi ,\r\ni tried to reproduce your hindi fine-tuning from\
    \ https://huggingface.co/blog/fine-tune-whisper with the exact same code as you,\
    \ but somehow i don't get the same performance.\r\nI'm not sure what causes the\
    \ different results? maybe you can lead me in the right direction? the link below\
    \ contains the script i'm running:\r\n\r\nhttps://pastebin.com/wz4dyiEA\r\n\r\n\
    My results:\r\n| Training Loss | Epoch | Step | Validation Loss | Wer     |\r\n\
    |:-------------:|:-----:|:----:|:---------------:|:-------:|\r\n| 0.0885     \
    \   | 2.44  | 1000 | 0.2941          | 34.8684 |\r\n| 0.0222        | 4.89  |\
    \ 2000 | 0.3481          | 37.2894 |\r\n| 0.0023        | 7.33  | 3000 | 0.4163\
    \          | 61.7286 |\r\n| 0.0004        | 9.78  | 4000 | 0.4440          | 79.7511\
    \ |\r\n| 0.0002        | 12.22 | 5000 | 0.4595          | 82.5277 |\r\n\r\nTransformers\
    \ 4.26.0.dev0\r\nPytorch 1.13.1+cu117\r\nDatasets 2.8.0\r\nTokenizer 0.13.2"
  created_at: 2023-01-30 13:56:51+00:00
  edited: false
  hidden: false
  id: 63d7cca307cd1aa3c49b485a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-02-10T12:53:58.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;5amuel&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/5amuel\">@<span class=\"\
          underline\">5amuel</span></a></span>\n\n\t</span></span>! Sorry for the\
          \ late reply! That's super weird, it should be possible to get identical\
          \ results if you run the examples script start to finish. Let me re-run\
          \ training and get back to you with my results</p>\n"
        raw: Hey @5amuel! Sorry for the late reply! That's super weird, it should
          be possible to get identical results if you run the examples script start
          to finish. Let me re-run training and get back to you with my results
        updatedAt: '2023-02-10T12:53:58.415Z'
      numEdits: 0
      reactions: []
    id: 63e63e6663037c7d960d970d
    type: comment
  author: sanchit-gandhi
  content: Hey @5amuel! Sorry for the late reply! That's super weird, it should be
    possible to get identical results if you run the examples script start to finish.
    Let me re-run training and get back to you with my results
  created_at: 2023-02-10 12:53:58+00:00
  edited: false
  hidden: false
  id: 63e63e6663037c7d960d970d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-02-23T09:48:06.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;5amuel&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/5amuel\">@<span class=\"\
          underline\">5amuel</span></a></span>\n\n\t</span></span>! I re-ran training\
          \ with transformers installed from <code>main</code> and the default training\
          \ arguments: <a rel=\"nofollow\" href=\"https://wandb.ai/sanchit-gandhi/huggingface/runs/7ojjc1py/overview?workspace=user-sanchit-gandhi\"\
          >https://wandb.ai/sanchit-gandhi/huggingface/runs/7ojjc1py/overview?workspace=user-sanchit-gandhi</a></p>\n\
          <p>You can see from these logs that the results I got were identical to\
          \ those in the blog post:<br><a rel=\"nofollow\" href=\"https://wandb.ai/sanchit-gandhi/huggingface/runs/7ojjc1py?workspace=\"\
          >https://wandb.ai/sanchit-gandhi/huggingface/runs/7ojjc1py?workspace=</a></p>\n\
          <p>=&gt; this suggests to me everything is in order!</p>\n"
        raw: 'Hey @5amuel! I re-ran training with transformers installed from `main`
          and the default training arguments: https://wandb.ai/sanchit-gandhi/huggingface/runs/7ojjc1py/overview?workspace=user-sanchit-gandhi


          You can see from these logs that the results I got were identical to those
          in the blog post:

          https://wandb.ai/sanchit-gandhi/huggingface/runs/7ojjc1py?workspace=


          => this suggests to me everything is in order!'
        updatedAt: '2023-02-23T09:48:06.603Z'
      numEdits: 0
      reactions: []
    id: 63f736561cb66f416c697b74
    type: comment
  author: sanchit-gandhi
  content: 'Hey @5amuel! I re-ran training with transformers installed from `main`
    and the default training arguments: https://wandb.ai/sanchit-gandhi/huggingface/runs/7ojjc1py/overview?workspace=user-sanchit-gandhi


    You can see from these logs that the results I got were identical to those in
    the blog post:

    https://wandb.ai/sanchit-gandhi/huggingface/runs/7ojjc1py?workspace=


    => this suggests to me everything is in order!'
  created_at: 2023-02-23 09:48:06+00:00
  edited: false
  hidden: false
  id: 63f736561cb66f416c697b74
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: sanchit-gandhi/whisper-small-hi
repo_type: model
status: open
target_branch: null
title: Reproducing Hindi fine-tuning
