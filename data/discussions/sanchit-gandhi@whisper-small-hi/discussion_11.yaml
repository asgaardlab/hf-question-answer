!!python/object:huggingface_hub.community.DiscussionWithDetails
author: taqwa92
conflicting_files: null
created_at: 2023-02-09 10:51:39+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c4f7c29d63b94580a183e346624f3384.svg
      fullname: taqwa mohamed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: taqwa92
      type: user
    createdAt: '2023-02-09T10:51:39.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/c4f7c29d63b94580a183e346624f3384.svg
          fullname: taqwa mohamed
          isHf: false
          isPro: false
          name: taqwa92
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-02-09T18:47:24.504Z'
      numEdits: 0
      reactions: []
    id: 63e4d03bd6278c161be5b5e4
    type: comment
  author: taqwa92
  content: This comment has been hidden
  created_at: 2023-02-09 10:51:39+00:00
  edited: true
  hidden: true
  id: 63e4d03bd6278c161be5b5e4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c4f7c29d63b94580a183e346624f3384.svg
      fullname: taqwa mohamed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: taqwa92
      type: user
    createdAt: '2023-02-09T10:59:49.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/c4f7c29d63b94580a183e346624f3384.svg
          fullname: taqwa mohamed
          isHf: false
          isPro: false
          name: taqwa92
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-02-09T18:47:37.223Z'
      numEdits: 0
      reactions: []
    id: 63e4d225d69072437ec0e4fa
    type: comment
  author: taqwa92
  content: This comment has been hidden
  created_at: 2023-02-09 10:59:49+00:00
  edited: true
  hidden: true
  id: 63e4d225d69072437ec0e4fa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-02-10T14:31:02.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;taqwa92&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/taqwa92\"\
          >@<span class=\"underline\">taqwa92</span></a></span>\n\n\t</span></span>\
          \ </p>\n<p>The issue is with your target label sequences. Some of the label\
          \ sequences have a length that exceeds the model\u2019s maximum generation\
          \ length. These must be very long sequences, as the maximum generation length\
          \ is 448. This is the longest sequence the model is configured to handle\
          \ (<code>model.config.max_length</code>).</p>\n<p>We've got two options\
          \ here:</p>\n<ol>\n<li>Filter any label sequences longer than max length</li>\n\
          <li>Increase the models' max length</li>\n</ol>\n<p>What we can do is compute\
          \ the labels length of each target sequence:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >prepare_dataset</span>(<span class=\"hljs-params\">batch</span>):\n   \
          \ <span class=\"hljs-comment\"># load and resample audio data from 48 to\
          \ 16kHz</span>\n    audio = batch[<span class=\"hljs-string\">\"audio\"\
          </span>]\n\n    <span class=\"hljs-comment\"># compute input length</span>\n\
          \    batch[<span class=\"hljs-string\">\"input_length\"</span>] = <span\
          \ class=\"hljs-built_in\">len</span>(batch[<span class=\"hljs-string\">\"\
          audio\"</span>])\n\n    <span class=\"hljs-comment\"># compute log-Mel input\
          \ features from input audio array </span>\n    batch[<span class=\"hljs-string\"\
          >\"input_features\"</span>] = feature_extractor(audio[<span class=\"hljs-string\"\
          >\"array\"</span>], sampling_rate=audio[<span class=\"hljs-string\">\"sampling_rate\"\
          </span>]).input_features[<span class=\"hljs-number\">0</span>]\n\n    <span\
          \ class=\"hljs-comment\"># encode target text to label ids </span>\n   \
          \ batch[<span class=\"hljs-string\">\"labels\"</span>] = tokenizer(batch[<span\
          \ class=\"hljs-string\">\"sentence\"</span>]).input_ids\n\n    <span class=\"\
          hljs-comment\"># compute labels length</span>\n    batch[<span class=\"\
          hljs-string\">\"labels_length\"</span>] = <span class=\"hljs-built_in\"\
          >len</span>(batch[<span class=\"hljs-string\">\"labels\"</span>])\n    <span\
          \ class=\"hljs-keyword\">return</span> batch\n</code></pre>\n<p>And then\
          \ filter those that exceed the models maximum length:</p>\n<pre><code class=\"\
          language-python\">MAX_DURATION_IN_SECONDS = <span class=\"hljs-number\"\
          >30.0</span>\nmax_input_length = MAX_DURATION_IN_SECONDS * <span class=\"\
          hljs-number\">16000</span>\n\n<span class=\"hljs-keyword\">def</span> <span\
          \ class=\"hljs-title function_\">filter_inputs</span>(<span class=\"hljs-params\"\
          >input_length</span>):\n    <span class=\"hljs-string\">\"\"\"Filter inputs\
          \ with zero input length or longer than 30s\"\"\"</span>\n    <span class=\"\
          hljs-keyword\">return</span> <span class=\"hljs-number\">0</span> &lt; input_length\
          \ &lt; max_input_length\n\nmax_label_length = model.config.max_length\n\n\
          <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >filter_labels</span>(<span class=\"hljs-params\">labels_length</span>):\n\
          \    <span class=\"hljs-string\">\"\"\"Filter label sequences longer than\
          \ max length (448)\"\"\"</span>\n    <span class=\"hljs-keyword\">return</span>\
          \ labels_length &lt; max_label_length\n</code></pre>\n<p>You can then apply\
          \ the <code>prepare_dataset</code> function and the two new filter functions\
          \ to your dataset <code>common_voice</code> as follows:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-comment\"># pre-process</span>\n\
          common_voice = common_voice.<span class=\"hljs-built_in\">map</span>(prepare_dataset,\
          \ remove_columns= my_dataset.column_names[<span class=\"hljs-string\">\"\
          train\"</span>])\n<span class=\"hljs-comment\"># filter by audio length</span>\n\
          common_voice = common_voice.<span class=\"hljs-built_in\">filter</span>(filter_inputs,\
          \ input_columns=[<span class=\"hljs-string\">\"input_length\"</span>], remove_columns=[<span\
          \ class=\"hljs-string\">\"input_length\"</span>]\n<span class=\"hljs-comment\"\
          ># filter by label length</span>\ncommon_voice = common_voice.<span class=\"\
          hljs-built_in\">filter</span>(filter_labels, input_columns=[<span class=\"\
          hljs-string\">\"labels_length\"</span>], remove_columns=[<span class=\"\
          hljs-string\">\"labels_length\"</span>])\n</code></pre>\n<p>That should\
          \ pre-process the dataset and remove any label sequences that are too long\
          \ for the model.</p>\n<p>Alternatively, we can change the model\u2019s max\
          \ length to any value we want:</p>\n<pre><code class=\"language-python\"\
          >model.config.max_length = <span class=\"hljs-number\">500</span>\n</code></pre>\n\
          <p>This will update the max length to 500 tokens. Make sure to do this before\
          \ you filter for it to take effect:</p>\n<pre><code class=\"language-python\"\
          >max_label_length  = model.config.max_length = <span class=\"hljs-number\"\
          >500</span>\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\
          \ function_\">filter_labels</span>(<span class=\"hljs-params\">labels_length</span>):\n\
          \    <span class=\"hljs-string\">\"\"\"Filter label sequences longer than\
          \ the new max length (500)\"\"\"</span>\n    <span class=\"hljs-keyword\"\
          >return</span> labels_length &lt; max_label_length\n</code></pre>\n<p>Hope\
          \ that helps!</p>\n"
        raw: "Hey @taqwa92 \n\nThe issue is with your target label sequences. Some\
          \ of the label sequences have a length that exceeds the model\u2019s maximum\
          \ generation length. These must be very long sequences, as the maximum generation\
          \ length is 448. This is the longest sequence the model is configured to\
          \ handle (`model.config.max_length`).\n\nWe've got two options here:\n1.\
          \ Filter any label sequences longer than max length\n2. Increase the models'\
          \ max length\n\nWhat we can do is compute the labels length of each target\
          \ sequence:\n\n```python\ndef prepare_dataset(batch):\n    # load and resample\
          \ audio data from 48 to 16kHz\n    audio = batch[\"audio\"]\n\n    # compute\
          \ input length\n    batch[\"input_length\"] = len(batch[\"audio\"])\n\n\
          \    # compute log-Mel input features from input audio array \n    batch[\"\
          input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"\
          sampling_rate\"]).input_features[0]\n\n    # encode target text to label\
          \ ids \n    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n\
          \n    # compute labels length\n    batch[\"labels_length\"] = len(batch[\"\
          labels\"])\n    return batch\n```\n\nAnd then filter those that exceed the\
          \ models maximum length:\n\n```python\nMAX_DURATION_IN_SECONDS = 30.0\n\
          max_input_length = MAX_DURATION_IN_SECONDS * 16000\n\ndef filter_inputs(input_length):\n\
          \    \"\"\"Filter inputs with zero input length or longer than 30s\"\"\"\
          \n    return 0 < input_length < max_input_length\n\nmax_label_length = model.config.max_length\n\
          \ndef filter_labels(labels_length):\n    \"\"\"Filter label sequences longer\
          \ than max length (448)\"\"\"\n    return labels_length < max_label_length\n\
          ```\n\nYou can then apply the `prepare_dataset` function and the two new\
          \ filter functions to your dataset `common_voice` as follows:\n```python\n\
          # pre-process\ncommon_voice = common_voice.map(prepare_dataset, remove_columns=\
          \ my_dataset.column_names[\"train\"])\n# filter by audio length\ncommon_voice\
          \ = common_voice.filter(filter_inputs, input_columns=[\"input_length\"],\
          \ remove_columns=[\"input_length\"]\n# filter by label length\ncommon_voice\
          \ = common_voice.filter(filter_labels, input_columns=[\"labels_length\"\
          ], remove_columns=[\"labels_length\"])\n```\n\nThat should pre-process the\
          \ dataset and remove any label sequences that are too long for the model.\n\
          \nAlternatively, we can change the model\u2019s max length to any value\
          \ we want:\n\n```python\nmodel.config.max_length = 500\n```\n\nThis will\
          \ update the max length to 500 tokens. Make sure to do this before you filter\
          \ for it to take effect:\n```python\nmax_label_length  = model.config.max_length\
          \ = 500\n\ndef filter_labels(labels_length):\n    \"\"\"Filter label sequences\
          \ longer than the new max length (500)\"\"\"\n    return labels_length <\
          \ max_label_length\n```\n\nHope that helps!"
        updatedAt: '2023-02-10T14:31:02.978Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - bouim
    id: 63e6552663037c7d9610c199
    type: comment
  author: sanchit-gandhi
  content: "Hey @taqwa92 \n\nThe issue is with your target label sequences. Some of\
    \ the label sequences have a length that exceeds the model\u2019s maximum generation\
    \ length. These must be very long sequences, as the maximum generation length\
    \ is 448. This is the longest sequence the model is configured to handle (`model.config.max_length`).\n\
    \nWe've got two options here:\n1. Filter any label sequences longer than max length\n\
    2. Increase the models' max length\n\nWhat we can do is compute the labels length\
    \ of each target sequence:\n\n```python\ndef prepare_dataset(batch):\n    # load\
    \ and resample audio data from 48 to 16kHz\n    audio = batch[\"audio\"]\n\n \
    \   # compute input length\n    batch[\"input_length\"] = len(batch[\"audio\"\
    ])\n\n    # compute log-Mel input features from input audio array \n    batch[\"\
    input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"\
    sampling_rate\"]).input_features[0]\n\n    # encode target text to label ids \n\
    \    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n\n    # compute\
    \ labels length\n    batch[\"labels_length\"] = len(batch[\"labels\"])\n    return\
    \ batch\n```\n\nAnd then filter those that exceed the models maximum length:\n\
    \n```python\nMAX_DURATION_IN_SECONDS = 30.0\nmax_input_length = MAX_DURATION_IN_SECONDS\
    \ * 16000\n\ndef filter_inputs(input_length):\n    \"\"\"Filter inputs with zero\
    \ input length or longer than 30s\"\"\"\n    return 0 < input_length < max_input_length\n\
    \nmax_label_length = model.config.max_length\n\ndef filter_labels(labels_length):\n\
    \    \"\"\"Filter label sequences longer than max length (448)\"\"\"\n    return\
    \ labels_length < max_label_length\n```\n\nYou can then apply the `prepare_dataset`\
    \ function and the two new filter functions to your dataset `common_voice` as\
    \ follows:\n```python\n# pre-process\ncommon_voice = common_voice.map(prepare_dataset,\
    \ remove_columns= my_dataset.column_names[\"train\"])\n# filter by audio length\n\
    common_voice = common_voice.filter(filter_inputs, input_columns=[\"input_length\"\
    ], remove_columns=[\"input_length\"]\n# filter by label length\ncommon_voice =\
    \ common_voice.filter(filter_labels, input_columns=[\"labels_length\"], remove_columns=[\"\
    labels_length\"])\n```\n\nThat should pre-process the dataset and remove any label\
    \ sequences that are too long for the model.\n\nAlternatively, we can change the\
    \ model\u2019s max length to any value we want:\n\n```python\nmodel.config.max_length\
    \ = 500\n```\n\nThis will update the max length to 500 tokens. Make sure to do\
    \ this before you filter for it to take effect:\n```python\nmax_label_length \
    \ = model.config.max_length = 500\n\ndef filter_labels(labels_length):\n    \"\
    \"\"Filter label sequences longer than the new max length (500)\"\"\"\n    return\
    \ labels_length < max_label_length\n```\n\nHope that helps!"
  created_at: 2023-02-10 14:31:02+00:00
  edited: false
  hidden: false
  id: 63e6552663037c7d9610c199
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c4f7c29d63b94580a183e346624f3384.svg
      fullname: taqwa mohamed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: taqwa92
      type: user
    createdAt: '2023-02-10T17:46:07.000Z'
    data:
      edited: false
      editors:
      - taqwa92
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c4f7c29d63b94580a183e346624f3384.svg
          fullname: taqwa mohamed
          isHf: false
          isPro: false
          name: taqwa92
          type: user
        html: "<p>alot of thanks for you prof <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ , it really helps me</p>\n"
        raw: alot of thanks for you prof @sanchit-gandhi , it really helps me
        updatedAt: '2023-02-10T17:46:07.385Z'
      numEdits: 0
      reactions: []
    id: 63e682df70fa0ed02a5b3ce5
    type: comment
  author: taqwa92
  content: alot of thanks for you prof @sanchit-gandhi , it really helps me
  created_at: 2023-02-10 17:46:07+00:00
  edited: false
  hidden: false
  id: 63e682df70fa0ed02a5b3ce5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: sanchit-gandhi/whisper-small-hi
repo_type: model
status: open
target_branch: null
title: Size mismatch error during train
