!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TNTOutburst
conflicting_files: null
created_at: 2023-12-04 22:00:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/854e541c5d4ce3b0bdd2ee96b2916a61.svg
      fullname: Christopher
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TNTOutburst
      type: user
    createdAt: '2023-12-04T22:00:05.000Z'
    data:
      edited: false
      editors:
      - TNTOutburst
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9402115941047668
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/854e541c5d4ce3b0bdd2ee96b2916a61.svg
          fullname: Christopher
          isHf: false
          isPro: false
          name: TNTOutburst
          type: user
        html: '<p>Hello, I noticed that tigerbot-70b-chat-v2 had much higher ARC and
          TruthfulQA scores than other llama2-70b finetunes. I was wondering if there
          could have been a contamination issue with this version?<br><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</a></p>

          '
        raw: "Hello, I noticed that tigerbot-70b-chat-v2 had much higher ARC and TruthfulQA\
          \ scores than other llama2-70b finetunes. I was wondering if there could\
          \ have been a contamination issue with this version?\r\nhttps://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"
        updatedAt: '2023-12-04T22:00:05.399Z'
      numEdits: 0
      reactions: []
    id: 656e4be5c94d150e5dd46a61
    type: comment
  author: TNTOutburst
  content: "Hello, I noticed that tigerbot-70b-chat-v2 had much higher ARC and TruthfulQA\
    \ scores than other llama2-70b finetunes. I was wondering if there could have\
    \ been a contamination issue with this version?\r\nhttps://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"
  created_at: 2023-12-04 22:00:05+00:00
  edited: false
  hidden: false
  id: 656e4be5c94d150e5dd46a61
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619266745847-607838a98794cdeedcb7b04d.jpeg?w=200&h=200&f=face
      fullname: Ye Chen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: yechen
      type: user
    createdAt: '2023-12-05T01:20:24.000Z'
    data:
      edited: false
      editors:
      - yechen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8984857201576233
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619266745847-607838a98794cdeedcb7b04d.jpeg?w=200&h=200&f=face
          fullname: Ye Chen
          isHf: false
          isPro: false
          name: yechen
          type: user
        html: '<p>Hi Christopher,</p>

          <p>Thanks for your interests and comments. We did not use any test data
          in our training pipeline, as we use the model as our official chat product,
          and usually benchmark data distribution is very different from real user
          behavior. But during training, we use a sample of train and valid split
          data for fast evaluation. Also, we use annotated real user prompts for iterative
          alignments. Our initial check did not find data leakage. We will further
          investigation, but you raise a good observation, we probably will remove
          the fast evaluation and check into the real user data for leakage in our
          later versions.</p>

          <p>As a reference, this version is not a direct fine-tune from llama-2,
          instead its a fine-tune and rlhf chat model from our own base model: tigerbot-70b-base-v1.
          This base model was continual pretrained from llama-2 on 300B token data
          for three months on a 500x a100 cluster. the pretrain data is unsupervised
          text, and this base model can perform quite well already (avg 65 in hf leaderboard).
          we checked its evaluation results also on opencampass (<a rel="nofollow"
          href="https://opencompass.org.cn/model-detail/TigerBot-70B-Base-V1">https://opencompass.org.cn/model-detail/TigerBot-70B-Base-V1</a>),
          the arc score already 82-87. the variance from hf is likely due to the evaluation
          scripts prompting difference, but this suggest it''s less likely data leakage
          during fine-tuning.</p>

          <p>as a side note, our model got evaluated on opencampass: <a rel="nofollow"
          href="https://opencompass.org.cn/leaderboard-llm">https://opencompass.org.cn/leaderboard-llm</a>  (from
          a Chinese national lab who evaluated on about 40 benchmarks) and clib: <a
          rel="nofollow" href="https://github.com/jeinlee1991/chinese-llm-benchmark">https://github.com/jeinlee1991/chinese-llm-benchmark#%E5%8E%9F%E5%A7%8B%E8%AF%84%E6%B5%8B%E6%95%B0%E6%8D%AE</a>
          (crowdsourced), and performed quite well. </p>

          <p>Nevertheless, thanks for your observations and raising the issue, we
          surely will put more efforts to avoid data contamination.</p>

          '
        raw: "Hi Christopher,\n\nThanks for your interests and comments. We did not\
          \ use any test data in our training pipeline, as we use the model as our\
          \ official chat product, and usually benchmark data distribution is very\
          \ different from real user behavior. But during training, we use a sample\
          \ of train and valid split data for fast evaluation. Also, we use annotated\
          \ real user prompts for iterative alignments. Our initial check did not\
          \ find data leakage. We will further investigation, but you raise a good\
          \ observation, we probably will remove the fast evaluation and check into\
          \ the real user data for leakage in our later versions.\n\nAs a reference,\
          \ this version is not a direct fine-tune from llama-2, instead its a fine-tune\
          \ and rlhf chat model from our own base model: tigerbot-70b-base-v1. This\
          \ base model was continual pretrained from llama-2 on 300B token data for\
          \ three months on a 500x a100 cluster. the pretrain data is unsupervised\
          \ text, and this base model can perform quite well already (avg 65 in hf\
          \ leaderboard). we checked its evaluation results also on opencampass (https://opencompass.org.cn/model-detail/TigerBot-70B-Base-V1),\
          \ the arc score already 82-87. the variance from hf is likely due to the\
          \ evaluation scripts prompting difference, but this suggest it's less likely\
          \ data leakage during fine-tuning.\n\nas a side note, our model got evaluated\
          \ on opencampass: https://opencompass.org.cn/leaderboard-llm  (from a Chinese\
          \ national lab who evaluated on about 40 benchmarks) and clib: [https://github.com/jeinlee1991/chinese-llm-benchmark#%E5%8E%9F%E5%A7%8B%E8%AF%84%E6%B5%8B%E6%95%B0%E6%8D%AE](https://github.com/jeinlee1991/chinese-llm-benchmark)\
          \ (crowdsourced), and performed quite well. \n\nNevertheless, thanks for\
          \ your observations and raising the issue, we surely will put more efforts\
          \ to avoid data contamination.\n\n"
        updatedAt: '2023-12-05T01:20:24.729Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - PapersAnon
    id: 656e7ad8a00ad2dc33e8e6d2
    type: comment
  author: yechen
  content: "Hi Christopher,\n\nThanks for your interests and comments. We did not\
    \ use any test data in our training pipeline, as we use the model as our official\
    \ chat product, and usually benchmark data distribution is very different from\
    \ real user behavior. But during training, we use a sample of train and valid\
    \ split data for fast evaluation. Also, we use annotated real user prompts for\
    \ iterative alignments. Our initial check did not find data leakage. We will further\
    \ investigation, but you raise a good observation, we probably will remove the\
    \ fast evaluation and check into the real user data for leakage in our later versions.\n\
    \nAs a reference, this version is not a direct fine-tune from llama-2, instead\
    \ its a fine-tune and rlhf chat model from our own base model: tigerbot-70b-base-v1.\
    \ This base model was continual pretrained from llama-2 on 300B token data for\
    \ three months on a 500x a100 cluster. the pretrain data is unsupervised text,\
    \ and this base model can perform quite well already (avg 65 in hf leaderboard).\
    \ we checked its evaluation results also on opencampass (https://opencompass.org.cn/model-detail/TigerBot-70B-Base-V1),\
    \ the arc score already 82-87. the variance from hf is likely due to the evaluation\
    \ scripts prompting difference, but this suggest it's less likely data leakage\
    \ during fine-tuning.\n\nas a side note, our model got evaluated on opencampass:\
    \ https://opencompass.org.cn/leaderboard-llm  (from a Chinese national lab who\
    \ evaluated on about 40 benchmarks) and clib: [https://github.com/jeinlee1991/chinese-llm-benchmark#%E5%8E%9F%E5%A7%8B%E8%AF%84%E6%B5%8B%E6%95%B0%E6%8D%AE](https://github.com/jeinlee1991/chinese-llm-benchmark)\
    \ (crowdsourced), and performed quite well. \n\nNevertheless, thanks for your\
    \ observations and raising the issue, we surely will put more efforts to avoid\
    \ data contamination.\n\n"
  created_at: 2023-12-05 01:20:24+00:00
  edited: false
  hidden: false
  id: 656e7ad8a00ad2dc33e8e6d2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6439638f7245b3b7f4527529/g5eWATQmf5WaKp7Se0HkQ.jpeg?w=200&h=200&f=face
      fullname: Dahyun Kim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: killawhale2
      type: user
    createdAt: '2023-12-05T13:44:16.000Z'
    data:
      edited: false
      editors:
      - killawhale2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9650623202323914
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6439638f7245b3b7f4527529/g5eWATQmf5WaKp7Se0HkQ.jpeg?w=200&h=200&f=face
          fullname: Dahyun Kim
          isHf: false
          isPro: false
          name: killawhale2
          type: user
        html: '<p>It''s not Arc or Truthful but I noticed that the SFT dataset (<a
          href="https://huggingface.co/datasets/TigerResearch/sft_en">https://huggingface.co/datasets/TigerResearch/sft_en</a>)  shared
          by the developers of this model contains GSM8K train data as well.<br>If
          the SFT dataset that is currently shared was used during the fine-tuning
          stage of the released TigerBot chat models, won''t it have contamination
          with the GSM8K task?</p>

          '
        raw: "It's not Arc or Truthful but I noticed that the SFT dataset (https://huggingface.co/datasets/TigerResearch/sft_en)\
          \  shared by the developers of this model contains GSM8K train data as well.\
          \ \nIf the SFT dataset that is currently shared was used during the fine-tuning\
          \ stage of the released TigerBot chat models, won't it have contamination\
          \ with the GSM8K task?"
        updatedAt: '2023-12-05T13:44:16.159Z'
      numEdits: 0
      reactions: []
    id: 656f2930a0ef947593ec8ea1
    type: comment
  author: killawhale2
  content: "It's not Arc or Truthful but I noticed that the SFT dataset (https://huggingface.co/datasets/TigerResearch/sft_en)\
    \  shared by the developers of this model contains GSM8K train data as well. \n\
    If the SFT dataset that is currently shared was used during the fine-tuning stage\
    \ of the released TigerBot chat models, won't it have contamination with the GSM8K\
    \ task?"
  created_at: 2023-12-05 13:44:16+00:00
  edited: false
  hidden: false
  id: 656f2930a0ef947593ec8ea1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619266745847-607838a98794cdeedcb7b04d.jpeg?w=200&h=200&f=face
      fullname: Ye Chen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: yechen
      type: user
    createdAt: '2023-12-05T13:56:28.000Z'
    data:
      edited: false
      editors:
      - yechen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9871553182601929
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619266745847-607838a98794cdeedcb7b04d.jpeg?w=200&h=200&f=face
          fullname: Ye Chen
          isHf: false
          isPro: false
          name: yechen
          type: user
        html: '<p>HI killawhale2,</p>

          <p>Thanks for raising this. That data was uploaded five months ago as an
          example, our latest iterations have moved away from that data. Also, our
          production process has dedup step to filter out any overlap with evaluation
          data to avoid overfitting. anyway, we will clean that upload and maybe upload
          an more fresh sample. thanks.</p>

          '
        raw: 'HI killawhale2,


          Thanks for raising this. That data was uploaded five months ago as an example,
          our latest iterations have moved away from that data. Also, our production
          process has dedup step to filter out any overlap with evaluation data to
          avoid overfitting. anyway, we will clean that upload and maybe upload an
          more fresh sample. thanks.'
        updatedAt: '2023-12-05T13:56:28.334Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - killawhale2
        - vivicai
    id: 656f2c0c5273668d5b931d68
    type: comment
  author: yechen
  content: 'HI killawhale2,


    Thanks for raising this. That data was uploaded five months ago as an example,
    our latest iterations have moved away from that data. Also, our production process
    has dedup step to filter out any overlap with evaluation data to avoid overfitting.
    anyway, we will clean that upload and maybe upload an more fresh sample. thanks.'
  created_at: 2023-12-05 13:56:28+00:00
  edited: false
  hidden: false
  id: 656f2c0c5273668d5b931d68
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619266745847-607838a98794cdeedcb7b04d.jpeg?w=200&h=200&f=face
      fullname: Ye Chen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: yechen
      type: user
    createdAt: '2023-12-05T14:11:11.000Z'
    data:
      status: closed
    id: 656f2f7f0492a9d6355ad90c
    type: status-change
  author: yechen
  created_at: 2023-12-05 14:11:11+00:00
  id: 656f2f7f0492a9d6355ad90c
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TigerResearch/tigerbot-70b-chat-v2
repo_type: model
status: closed
target_branch: null
title: High ARC and TruthfulQA scores
