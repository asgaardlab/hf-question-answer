!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hsuyab
conflicting_files: null
created_at: 2023-04-20 08:49:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f75788572c021be584f4c097016cbcab.svg
      fullname: Ayush Bihani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hsuyab
      type: user
    createdAt: '2023-04-20T09:49:56.000Z'
    data:
      edited: false
      editors:
      - hsuyab
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f75788572c021be584f4c097016cbcab.svg
          fullname: Ayush Bihani
          isHf: false
          isPro: false
          name: hsuyab
          type: user
        html: "<p>Hi I am getting this error when I am trying to fine-tune gpt-j-6b\
          \ on custom data? Any one has any idea on this?<br>This happens when I call\
          \ my <code>trainer.train()</code> to fine-tune the model</p>\n<pre><code>---------------------------------------------------------------------------\n\
          ValueError                                Traceback (most recent call last)\n\
          /tmp/ipykernel_7169/3756176484.py in \n     46 \n     47 # Fine-tune the\
          \ model\n---&gt; 48 trainer.train()\n\n/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\
          \ in train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\n\
          \   1631             self._inner_training_loop, self._train_batch_size,\
          \ args.auto_find_batch_size\n   1632         )\n-&gt; 1633         return\
          \ inner_training_loop(\n   1634             args=args,\n   1635        \
          \     resume_from_checkpoint=resume_from_checkpoint,\n\n/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\
          \ in _inner_training_loop(self, batch_size, args, resume_from_checkpoint,\
          \ trial, ignore_keys_for_eval)\n   1933                                \
          \ xm.all_reduce(\"sum\", gradients, scale=1.0 / xm.xrt_world_size())\n \
          \  1934                             # AMP: gradients need unscaling\n-&gt;\
          \ 1935                             self.scaler.unscale_(self.optimizer)\n\
          \   1936 \n   1937                         if is_sagemaker_mp_enabled()\
          \ and args.fp16:\n\n/opt/conda/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\
          \ in unscale_(self, optimizer)\n    282         found_inf = torch.full((1,),\
          \ 0.0, dtype=torch.float32, device=self._scale.device)\n    283 \n--&gt;\
          \ 284         optimizer_state[\"found_inf_per_device\"] = self._unscale_grads_(optimizer,\
          \ inv_scale, found_inf, False)\n    285         optimizer_state[\"stage\"\
          ] = OptState.UNSCALED\n    286 \n\n/opt/conda/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\
          \ in _unscale_grads_(self, optimizer, inv_scale, found_inf, allow_fp16)\n\
          \    210                         continue\n    211                     if\
          \ (not allow_fp16) and param.grad.dtype == torch.float16:\n--&gt; 212  \
          \                       raise ValueError(\"Attempting to unscale FP16 gradients.\"\
          )\n    213                     if param.grad.is_sparse:\n    214       \
          \                  # is_coalesced() == False means the sparse grad has values\
          \ with duplicate indices.\n\nValueError: Attempting to unscale FP16 gradients.\n\
          </code></pre>\n"
        raw: "Hi I am getting this error when I am trying to fine-tune gpt-j-6b on\
          \ custom data? Any one has any idea on this?\r\nThis happens when I call\
          \ my `trainer.train()` to fine-tune the model\r\n```\r\n---------------------------------------------------------------------------\r\
          \nValueError                                Traceback (most recent call\
          \ last)\r\n/tmp/ipykernel_7169/3756176484.py in \r\n     46 \r\n     47\
          \ # Fine-tune the model\r\n---> 48 trainer.train()\r\n\r\n/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\
          \ in train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\r\
          \n   1631             self._inner_training_loop, self._train_batch_size,\
          \ args.auto_find_batch_size\r\n   1632         )\r\n-> 1633         return\
          \ inner_training_loop(\r\n   1634             args=args,\r\n   1635    \
          \         resume_from_checkpoint=resume_from_checkpoint,\r\n\r\n/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\
          \ in _inner_training_loop(self, batch_size, args, resume_from_checkpoint,\
          \ trial, ignore_keys_for_eval)\r\n   1933                              \
          \   xm.all_reduce(\"sum\", gradients, scale=1.0 / xm.xrt_world_size())\r\
          \n   1934                             # AMP: gradients need unscaling\r\n\
          -> 1935                             self.scaler.unscale_(self.optimizer)\r\
          \n   1936 \r\n   1937                         if is_sagemaker_mp_enabled()\
          \ and args.fp16:\r\n\r\n/opt/conda/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\
          \ in unscale_(self, optimizer)\r\n    282         found_inf = torch.full((1,),\
          \ 0.0, dtype=torch.float32, device=self._scale.device)\r\n    283 \r\n-->\
          \ 284         optimizer_state[\"found_inf_per_device\"] = self._unscale_grads_(optimizer,\
          \ inv_scale, found_inf, False)\r\n    285         optimizer_state[\"stage\"\
          ] = OptState.UNSCALED\r\n    286 \r\n\r\n/opt/conda/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\
          \ in _unscale_grads_(self, optimizer, inv_scale, found_inf, allow_fp16)\r\
          \n    210                         continue\r\n    211                  \
          \   if (not allow_fp16) and param.grad.dtype == torch.float16:\r\n--> 212\
          \                         raise ValueError(\"Attempting to unscale FP16\
          \ gradients.\")\r\n    213                     if param.grad.is_sparse:\r\
          \n    214                         # is_coalesced() == False means the sparse\
          \ grad has values with duplicate indices.\r\n\r\nValueError: Attempting\
          \ to unscale FP16 gradients.\r\n```"
        updatedAt: '2023-04-20T09:49:56.501Z'
      numEdits: 0
      reactions: []
    id: 64410ac4ad24e9b2cfbafc48
    type: comment
  author: hsuyab
  content: "Hi I am getting this error when I am trying to fine-tune gpt-j-6b on custom\
    \ data? Any one has any idea on this?\r\nThis happens when I call my `trainer.train()`\
    \ to fine-tune the model\r\n```\r\n---------------------------------------------------------------------------\r\
    \nValueError                                Traceback (most recent call last)\r\
    \n/tmp/ipykernel_7169/3756176484.py in \r\n     46 \r\n     47 # Fine-tune the\
    \ model\r\n---> 48 trainer.train()\r\n\r\n/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\
    \ in train(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\r\
    \n   1631             self._inner_training_loop, self._train_batch_size, args.auto_find_batch_size\r\
    \n   1632         )\r\n-> 1633         return inner_training_loop(\r\n   1634\
    \             args=args,\r\n   1635             resume_from_checkpoint=resume_from_checkpoint,\r\
    \n\r\n/opt/conda/lib/python3.8/site-packages/transformers/trainer.py in _inner_training_loop(self,\
    \ batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\r\n \
    \  1933                                 xm.all_reduce(\"sum\", gradients, scale=1.0\
    \ / xm.xrt_world_size())\r\n   1934                             # AMP: gradients\
    \ need unscaling\r\n-> 1935                             self.scaler.unscale_(self.optimizer)\r\
    \n   1936 \r\n   1937                         if is_sagemaker_mp_enabled() and\
    \ args.fp16:\r\n\r\n/opt/conda/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\
    \ in unscale_(self, optimizer)\r\n    282         found_inf = torch.full((1,),\
    \ 0.0, dtype=torch.float32, device=self._scale.device)\r\n    283 \r\n--> 284\
    \         optimizer_state[\"found_inf_per_device\"] = self._unscale_grads_(optimizer,\
    \ inv_scale, found_inf, False)\r\n    285         optimizer_state[\"stage\"] =\
    \ OptState.UNSCALED\r\n    286 \r\n\r\n/opt/conda/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\
    \ in _unscale_grads_(self, optimizer, inv_scale, found_inf, allow_fp16)\r\n  \
    \  210                         continue\r\n    211                     if (not\
    \ allow_fp16) and param.grad.dtype == torch.float16:\r\n--> 212              \
    \           raise ValueError(\"Attempting to unscale FP16 gradients.\")\r\n  \
    \  213                     if param.grad.is_sparse:\r\n    214               \
    \          # is_coalesced() == False means the sparse grad has values with duplicate\
    \ indices.\r\n\r\nValueError: Attempting to unscale FP16 gradients.\r\n```"
  created_at: 2023-04-20 08:49:56+00:00
  edited: false
  hidden: false
  id: 64410ac4ad24e9b2cfbafc48
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 26
repo_id: EleutherAI/gpt-j-6b
repo_type: model
status: open
target_branch: null
title: 'ValueError: Attempting to unscale FP16 gradients.'
