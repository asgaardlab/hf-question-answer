!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BastiNi
conflicting_files: null
created_at: 2022-10-28 13:27:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9f04f1f6873097cfe9372b386f2927cc.svg
      fullname: Sebastian Nichtern
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BastiNi
      type: user
    createdAt: '2022-10-28T14:27:00.000Z'
    data:
      edited: true
      editors:
      - BastiNi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9f04f1f6873097cfe9372b386f2927cc.svg
          fullname: Sebastian Nichtern
          isHf: false
          isPro: false
          name: BastiNi
          type: user
        html: '<p>I tried to run the model on my local laptop, but I keep getting
          the following error on inference:</p>

          <p><code>RuntimeError: "LayerNormKernelImpl" not implemented for ''Half''</code></p>

          <p>I''m loading the model using</p>

          <p><code>model =  GPTJForCausalLM.from_pretrained("EleutherAI/gpt-j-6B",
          revision="float16", torch_dtype=torch.float16, low_cpu_mem_usage=True)</code></p>

          <p>I tried several PyTorch and hugging face versions, including the ones
          from <a rel="nofollow" href="https://github.com/philschmid/amazon-sagemaker-gpt-j-sample">this</a>
          repo (torch==1.9.1, transformers==4.12.3).</p>

          <p>Maybe the model is not supporting CPU inference?</p>

          '
        raw: 'I tried to run the model on my local laptop, but I keep getting the
          following error on inference:


          `RuntimeError: "LayerNormKernelImpl" not implemented for ''Half''`


          I''m loading the model using


          `model =  GPTJForCausalLM.from_pretrained("EleutherAI/gpt-j-6B", revision="float16",
          torch_dtype=torch.float16, low_cpu_mem_usage=True)`


          I tried several PyTorch and hugging face versions, including the ones from
          [this](https://github.com/philschmid/amazon-sagemaker-gpt-j-sample) repo
          (torch==1.9.1, transformers==4.12.3).


          Maybe the model is not supporting CPU inference?'
        updatedAt: '2022-10-28T14:27:33.730Z'
      numEdits: 1
      reactions: []
    id: 635be6b4dc371b8f910322d1
    type: comment
  author: BastiNi
  content: 'I tried to run the model on my local laptop, but I keep getting the following
    error on inference:


    `RuntimeError: "LayerNormKernelImpl" not implemented for ''Half''`


    I''m loading the model using


    `model =  GPTJForCausalLM.from_pretrained("EleutherAI/gpt-j-6B", revision="float16",
    torch_dtype=torch.float16, low_cpu_mem_usage=True)`


    I tried several PyTorch and hugging face versions, including the ones from [this](https://github.com/philschmid/amazon-sagemaker-gpt-j-sample)
    repo (torch==1.9.1, transformers==4.12.3).


    Maybe the model is not supporting CPU inference?'
  created_at: 2022-10-28 13:27:00+00:00
  edited: true
  hidden: false
  id: 635be6b4dc371b8f910322d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7e361e249d836a9ac01d111c6347e23a.svg
      fullname: Nora Belrose
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: norabelrose
      type: user
    createdAt: '2022-10-28T18:23:29.000Z'
    data:
      edited: false
      editors:
      - norabelrose
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7e361e249d836a9ac01d111c6347e23a.svg
          fullname: Nora Belrose
          isHf: false
          isPro: false
          name: norabelrose
          type: user
        html: '<p>Try using the float32 version if you want to do CPU inference</p>

          '
        raw: Try using the float32 version if you want to do CPU inference
        updatedAt: '2022-10-28T18:23:29.920Z'
      numEdits: 0
      reactions: []
    id: 635c1e21ca038892de0668b8
    type: comment
  author: norabelrose
  content: Try using the float32 version if you want to do CPU inference
  created_at: 2022-10-28 17:23:29+00:00
  edited: false
  hidden: false
  id: 635c1e21ca038892de0668b8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60347d3660e3dd96631c9093/B3fuZer5N04tZIAYrLnz4.jpeg?w=200&h=200&f=face
      fullname: Stella Biderman
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: stellaathena
      type: user
    createdAt: '2022-12-08T01:39:32.000Z'
    data:
      status: closed
    id: 639140542e1b430e96ce0b43
    type: status-change
  author: stellaathena
  created_at: 2022-12-08 01:39:32+00:00
  id: 639140542e1b430e96ce0b43
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: EleutherAI/gpt-j-6b
repo_type: model
status: closed
target_branch: null
title: Can it run on CPU?
