!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tanishq3232
conflicting_files: null
created_at: 2023-04-11 08:27:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0e3698f02bb081d7047207e190d1dbb4.svg
      fullname: Tanishq
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tanishq3232
      type: user
    createdAt: '2023-04-11T09:27:50.000Z'
    data:
      edited: false
      editors:
      - Tanishq3232
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0e3698f02bb081d7047207e190d1dbb4.svg
          fullname: Tanishq
          isHf: false
          isPro: false
          name: Tanishq3232
          type: user
        html: '<p>tokenizer = transformers.AutoTokenizer.from_pretrained("EleutherAI/gpt-j-6B")<br>gives
          an error saying </p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64254dc1daa3502ee356543a/vDehgjUfsPW1kWy1KaNmJ.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64254dc1daa3502ee356543a/vDehgjUfsPW1kWy1KaNmJ.png"></a></p>

          <p>full error:<br>Distant resource does not have an ETag, we won''t be able
          to reliably ensure reproducibility.</p>

          <hr>

          <p>OSError                                   Traceback (most recent call
          last)<br>File ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/configuration_utils.py:566,
          in PretrainedConfig.get_config_dict(cls, pretrained_model_name_or_path,
          **kwargs)<br>    564 try:<br>    565     # Load from URL or cache if already
          cached<br>--&gt; 566     resolved_config_file = cached_path(<br>    567         config_file,<br>    568         cache_dir=cache_dir,<br>    569         force_download=force_download,<br>    570         proxies=proxies,<br>    571         resume_download=resume_download,<br>    572         local_files_only=local_files_only,<br>    573         use_auth_token=use_auth_token,<br>    574         user_agent=user_agent,<br>    575     )<br>    576     #
          Load config dict</p>

          <p>File ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/file_utils.py:1625,
          in cached_path(url_or_filename, cache_dir, force_download, proxies, resume_download,
          user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)<br>   1623
          if is_remote_url(url_or_filename):<br>   1624     # URL, so get it from
          the cache (downloading if necessary)<br>-&gt; 1625     output_path = get_from_cache(<br>   1626         url_or_filename,<br>   1627         cache_dir=cache_dir,<br>   1628         force_download=force_download,<br>   1629         proxies=proxies,<br>   1630         resume_download=resume_download,<br>   1631         user_agent=user_agent,<br>   1632         use_auth_token=use_auth_token,<br>   1633         local_files_only=local_files_only,<br>   1634     )<br>   1635
          elif os.path.exists(url_or_filename):<br>   1636     # File, and it exists.</p>

          <p>File ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/file_utils.py:1803,
          in get_from_cache(url, cache_dir, force_download, proxies, etag_timeout,
          resume_download, user_agent, use_auth_token, local_files_only)<br>   1802
          if etag is None:<br>-&gt; 1803     raise OSError(<br>   1804         "Distant
          resource does not have an ETag, we won''t be able to reliably ensure reproducibility."<br>   1805     )<br>   1806
          # In case of a redirect,<br>   1807 # save an extra redirect on the request.get
          call,<br>   1808 # and ensure we download the exact atomic version even
          if it changed<br>   1809 # between the HEAD and the GET (unlikely, but hey).</p>

          <p>OSError: Distant resource does not have an ETag, we won''t be able to
          reliably ensure reproducibility.</p>

          <p>During handling of the above exception, another exception occurred:</p>

          <p>OSError                                   Traceback (most recent call
          last)<br>Cell In[3], line 3<br>      1 from transformers import AutoTokenizer,
          AutoModelForCausalLM<br>----&gt; 3 tokenizer = AutoTokenizer.from_pretrained("EleutherAI/gpt-j-6B")</p>

          <p>File ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:487,
          in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,
          **kwargs)<br>    485 if config_tokenizer_class is None:<br>    486     if
          not isinstance(config, PretrainedConfig):<br>--&gt; 487         config =
          AutoConfig.from_pretrained(<br>    488             pretrained_model_name_or_path,
          trust_remote_code=trust_remote_code, **kwargs<br>    489         )<br>    490     config_tokenizer_class
          = config.tokenizer_class<br>    491     if hasattr(config, "auto_map") and
          "AutoTokenizer" in config.auto_map:</p>

          <p>File ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:580,
          in AutoConfig.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)<br>    578
          kwargs["name_or_path"] = pretrained_model_name_or_path<br>    579 trust_remote_code
          = kwargs.pop("trust_remote_code", False)<br>--&gt; 580 config_dict, _ =
          PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)<br>    581
          if "auto_map" in config_dict and "AutoConfig" in config_dict["auto_map"]:<br>    582     if
          not trust_remote_code:</p>

          <p>File ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/configuration_utils.py:591,
          in PretrainedConfig.get_config_dict(cls, pretrained_model_name_or_path,
          **kwargs)<br>    588     if revision is not None:<br>    589         msg
          += f"- or ''{revision}'' is a valid git identifier (branch name, a tag name,
          or a commit id) that exists for this model name as listed on its model page
          on ''<a href="https://huggingface.co/models''%5Cn%5Cn&quot;">https://huggingface.co/models''\n\n"</a><br>--&gt;
          591     raise EnvironmentError(msg)<br>    593 except (json.JSONDecodeError,
          UnicodeDecodeError):<br>    594     msg = (<br>    595         f"Couldn''t
          reach server at ''{config_file}'' to download configuration file or "<br>    596         "configuration
          file is not a valid JSON file. "<br>    597         f"Please check network
          or file content here: {resolved_config_file}."<br>    598     )</p>

          <p>OSError: Can''t load config for ''EleutherAI/gpt-j-6B''. Make sure that:</p>

          <ul>

          <li><p>''EleutherAI/gpt-j-6B'' is a correct model identifier listed on ''<a
          href="https://huggingface.co/models''">https://huggingface.co/models''</a><br>(make
          sure ''EleutherAI/gpt-j-6B'' is not a path to a local directory with something
          else, in that case)</p>

          </li>

          <li><p>or ''EleutherAI/gpt-j-6B'' is the correct path to a directory containing
          a config.json file</p>

          </li>

          </ul>

          '
        raw: "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\"\
          )\r\ngives an error saying \r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64254dc1daa3502ee356543a/vDehgjUfsPW1kWy1KaNmJ.png)\r\
          \n\r\n\r\nfull error:\r\nDistant resource does not have an ETag, we won't\
          \ be able to reliably ensure reproducibility.\r\n\r\n---------------------------------------------------------------------------\r\
          \nOSError                                   Traceback (most recent call\
          \ last)\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/configuration_utils.py:566,\
          \ in PretrainedConfig.get_config_dict(cls, pretrained_model_name_or_path,\
          \ **kwargs)\r\n    564 try:\r\n    565     # Load from URL or cache if already\
          \ cached\r\n--> 566     resolved_config_file = cached_path(\r\n    567 \
          \        config_file,\r\n    568         cache_dir=cache_dir,\r\n    569\
          \         force_download=force_download,\r\n    570         proxies=proxies,\r\
          \n    571         resume_download=resume_download,\r\n    572         local_files_only=local_files_only,\r\
          \n    573         use_auth_token=use_auth_token,\r\n    574         user_agent=user_agent,\r\
          \n    575     )\r\n    576     # Load config dict\r\n\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/file_utils.py:1625,\
          \ in cached_path(url_or_filename, cache_dir, force_download, proxies, resume_download,\
          \ user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\r\
          \n   1623 if is_remote_url(url_or_filename):\r\n   1624     # URL, so get\
          \ it from the cache (downloading if necessary)\r\n-> 1625     output_path\
          \ = get_from_cache(\r\n   1626         url_or_filename,\r\n   1627     \
          \    cache_dir=cache_dir,\r\n   1628         force_download=force_download,\r\
          \n   1629         proxies=proxies,\r\n   1630         resume_download=resume_download,\r\
          \n   1631         user_agent=user_agent,\r\n   1632         use_auth_token=use_auth_token,\r\
          \n   1633         local_files_only=local_files_only,\r\n   1634     )\r\n\
          \   1635 elif os.path.exists(url_or_filename):\r\n   1636     # File, and\
          \ it exists.\r\n\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/file_utils.py:1803,\
          \ in get_from_cache(url, cache_dir, force_download, proxies, etag_timeout,\
          \ resume_download, user_agent, use_auth_token, local_files_only)\r\n   1802\
          \ if etag is None:\r\n-> 1803     raise OSError(\r\n   1804         \"Distant\
          \ resource does not have an ETag, we won't be able to reliably ensure reproducibility.\"\
          \r\n   1805     )\r\n   1806 # In case of a redirect,\r\n   1807 # save\
          \ an extra redirect on the request.get call,\r\n   1808 # and ensure we\
          \ download the exact atomic version even if it changed\r\n   1809 # between\
          \ the HEAD and the GET (unlikely, but hey).\r\n\r\nOSError: Distant resource\
          \ does not have an ETag, we won't be able to reliably ensure reproducibility.\r\
          \n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nOSError                                   Traceback (most recent call\
          \ last)\r\nCell In[3], line 3\r\n      1 from transformers import AutoTokenizer,\
          \ AutoModelForCausalLM\r\n----> 3 tokenizer = AutoTokenizer.from_pretrained(\"\
          EleutherAI/gpt-j-6B\")\r\n\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:487,\
          \ in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,\
          \ **kwargs)\r\n    485 if config_tokenizer_class is None:\r\n    486   \
          \  if not isinstance(config, PretrainedConfig):\r\n--> 487         config\
          \ = AutoConfig.from_pretrained(\r\n    488             pretrained_model_name_or_path,\
          \ trust_remote_code=trust_remote_code, **kwargs\r\n    489         )\r\n\
          \    490     config_tokenizer_class = config.tokenizer_class\r\n    491\
          \     if hasattr(config, \"auto_map\") and \"AutoTokenizer\" in config.auto_map:\r\
          \n\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:580,\
          \ in AutoConfig.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\
          \n    578 kwargs[\"name_or_path\"] = pretrained_model_name_or_path\r\n \
          \   579 trust_remote_code = kwargs.pop(\"trust_remote_code\", False)\r\n\
          --> 580 config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path,\
          \ **kwargs)\r\n    581 if \"auto_map\" in config_dict and \"AutoConfig\"\
          \ in config_dict[\"auto_map\"]:\r\n    582     if not trust_remote_code:\r\
          \n\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/configuration_utils.py:591,\
          \ in PretrainedConfig.get_config_dict(cls, pretrained_model_name_or_path,\
          \ **kwargs)\r\n    588     if revision is not None:\r\n    589         msg\
          \ += f\"- or '{revision}' is a valid git identifier (branch name, a tag\
          \ name, or a commit id) that exists for this model name as listed on its\
          \ model page on 'https://huggingface.co/models'\\n\\n\"\r\n--> 591     raise\
          \ EnvironmentError(msg)\r\n    593 except (json.JSONDecodeError, UnicodeDecodeError):\r\
          \n    594     msg = (\r\n    595         f\"Couldn't reach server at '{config_file}'\
          \ to download configuration file or \"\r\n    596         \"configuration\
          \ file is not a valid JSON file. \"\r\n    597         f\"Please check network\
          \ or file content here: {resolved_config_file}.\"\r\n    598     )\r\n\r\
          \nOSError: Can't load config for 'EleutherAI/gpt-j-6B'. Make sure that:\r\
          \n\r\n- 'EleutherAI/gpt-j-6B' is a correct model identifier listed on 'https://huggingface.co/models'\r\
          \n  (make sure 'EleutherAI/gpt-j-6B' is not a path to a local directory\
          \ with something else, in that case)\r\n\r\n- or 'EleutherAI/gpt-j-6B' is\
          \ the correct path to a directory containing a config.json file\r\n\r\n"
        updatedAt: '2023-04-11T09:27:50.575Z'
      numEdits: 0
      reactions: []
    id: 643528167d013020da3ae9b9
    type: comment
  author: Tanishq3232
  content: "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\"\
    )\r\ngives an error saying \r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64254dc1daa3502ee356543a/vDehgjUfsPW1kWy1KaNmJ.png)\r\
    \n\r\n\r\nfull error:\r\nDistant resource does not have an ETag, we won't be able\
    \ to reliably ensure reproducibility.\r\n\r\n---------------------------------------------------------------------------\r\
    \nOSError                                   Traceback (most recent call last)\r\
    \nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/configuration_utils.py:566,\
    \ in PretrainedConfig.get_config_dict(cls, pretrained_model_name_or_path, **kwargs)\r\
    \n    564 try:\r\n    565     # Load from URL or cache if already cached\r\n-->\
    \ 566     resolved_config_file = cached_path(\r\n    567         config_file,\r\
    \n    568         cache_dir=cache_dir,\r\n    569         force_download=force_download,\r\
    \n    570         proxies=proxies,\r\n    571         resume_download=resume_download,\r\
    \n    572         local_files_only=local_files_only,\r\n    573         use_auth_token=use_auth_token,\r\
    \n    574         user_agent=user_agent,\r\n    575     )\r\n    576     # Load\
    \ config dict\r\n\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/file_utils.py:1625,\
    \ in cached_path(url_or_filename, cache_dir, force_download, proxies, resume_download,\
    \ user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\r\
    \n   1623 if is_remote_url(url_or_filename):\r\n   1624     # URL, so get it from\
    \ the cache (downloading if necessary)\r\n-> 1625     output_path = get_from_cache(\r\
    \n   1626         url_or_filename,\r\n   1627         cache_dir=cache_dir,\r\n\
    \   1628         force_download=force_download,\r\n   1629         proxies=proxies,\r\
    \n   1630         resume_download=resume_download,\r\n   1631         user_agent=user_agent,\r\
    \n   1632         use_auth_token=use_auth_token,\r\n   1633         local_files_only=local_files_only,\r\
    \n   1634     )\r\n   1635 elif os.path.exists(url_or_filename):\r\n   1636  \
    \   # File, and it exists.\r\n\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/file_utils.py:1803,\
    \ in get_from_cache(url, cache_dir, force_download, proxies, etag_timeout, resume_download,\
    \ user_agent, use_auth_token, local_files_only)\r\n   1802 if etag is None:\r\n\
    -> 1803     raise OSError(\r\n   1804         \"Distant resource does not have\
    \ an ETag, we won't be able to reliably ensure reproducibility.\"\r\n   1805 \
    \    )\r\n   1806 # In case of a redirect,\r\n   1807 # save an extra redirect\
    \ on the request.get call,\r\n   1808 # and ensure we download the exact atomic\
    \ version even if it changed\r\n   1809 # between the HEAD and the GET (unlikely,\
    \ but hey).\r\n\r\nOSError: Distant resource does not have an ETag, we won't be\
    \ able to reliably ensure reproducibility.\r\n\r\nDuring handling of the above\
    \ exception, another exception occurred:\r\n\r\nOSError                      \
    \             Traceback (most recent call last)\r\nCell In[3], line 3\r\n    \
    \  1 from transformers import AutoTokenizer, AutoModelForCausalLM\r\n----> 3 tokenizer\
    \ = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\r\n\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:487,\
    \ in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,\
    \ **kwargs)\r\n    485 if config_tokenizer_class is None:\r\n    486     if not\
    \ isinstance(config, PretrainedConfig):\r\n--> 487         config = AutoConfig.from_pretrained(\r\
    \n    488             pretrained_model_name_or_path, trust_remote_code=trust_remote_code,\
    \ **kwargs\r\n    489         )\r\n    490     config_tokenizer_class = config.tokenizer_class\r\
    \n    491     if hasattr(config, \"auto_map\") and \"AutoTokenizer\" in config.auto_map:\r\
    \n\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:580,\
    \ in AutoConfig.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\
    \n    578 kwargs[\"name_or_path\"] = pretrained_model_name_or_path\r\n    579\
    \ trust_remote_code = kwargs.pop(\"trust_remote_code\", False)\r\n--> 580 config_dict,\
    \ _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\r\
    \n    581 if \"auto_map\" in config_dict and \"AutoConfig\" in config_dict[\"\
    auto_map\"]:\r\n    582     if not trust_remote_code:\r\n\r\nFile ~/venvs/stgTenderTagging/lib/python3.9/site-packages/transformers/configuration_utils.py:591,\
    \ in PretrainedConfig.get_config_dict(cls, pretrained_model_name_or_path, **kwargs)\r\
    \n    588     if revision is not None:\r\n    589         msg += f\"- or '{revision}'\
    \ is a valid git identifier (branch name, a tag name, or a commit id) that exists\
    \ for this model name as listed on its model page on 'https://huggingface.co/models'\\\
    n\\n\"\r\n--> 591     raise EnvironmentError(msg)\r\n    593 except (json.JSONDecodeError,\
    \ UnicodeDecodeError):\r\n    594     msg = (\r\n    595         f\"Couldn't reach\
    \ server at '{config_file}' to download configuration file or \"\r\n    596  \
    \       \"configuration file is not a valid JSON file. \"\r\n    597         f\"\
    Please check network or file content here: {resolved_config_file}.\"\r\n    598\
    \     )\r\n\r\nOSError: Can't load config for 'EleutherAI/gpt-j-6B'. Make sure\
    \ that:\r\n\r\n- 'EleutherAI/gpt-j-6B' is a correct model identifier listed on\
    \ 'https://huggingface.co/models'\r\n  (make sure 'EleutherAI/gpt-j-6B' is not\
    \ a path to a local directory with something else, in that case)\r\n\r\n- or 'EleutherAI/gpt-j-6B'\
    \ is the correct path to a directory containing a config.json file\r\n\r\n"
  created_at: 2023-04-11 08:27:50+00:00
  edited: false
  hidden: false
  id: 643528167d013020da3ae9b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/58bb4033cb1e5e9e0742f42961edc743.svg
      fullname: John Cook
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: johncookds
      type: user
    createdAt: '2023-04-11T16:57:13.000Z'
    data:
      edited: true
      editors:
      - johncookds
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/58bb4033cb1e5e9e0742f42961edc743.svg
          fullname: John Cook
          isHf: false
          isPro: false
          name: johncookds
          type: user
        html: '<p>I''ve had the same issue occur, been unable to find a fix.</p>

          <p>(Edit: This has now been solved for me)</p>

          '
        raw: 'I''ve had the same issue occur, been unable to find a fix.


          (Edit: This has now been solved for me)'
        updatedAt: '2023-04-18T18:22:12.227Z'
      numEdits: 3
      reactions: []
    id: 6435916987604914ba35dd2d
    type: comment
  author: johncookds
  content: 'I''ve had the same issue occur, been unable to find a fix.


    (Edit: This has now been solved for me)'
  created_at: 2023-04-11 15:57:13+00:00
  edited: true
  hidden: false
  id: 6435916987604914ba35dd2d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/585955aaa4c3e4386a8b4fb54ac380c7.svg
      fullname: Aryan GD Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: resz
      type: user
    createdAt: '2023-04-18T21:34:13.000Z'
    data:
      edited: false
      editors:
      - resz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/585955aaa4c3e4386a8b4fb54ac380c7.svg
          fullname: Aryan GD Singh
          isHf: false
          isPro: false
          name: resz
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;johncookds&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/johncookds\">@<span class=\"\
          underline\">johncookds</span></a></span>\n\n\t</span></span>  how were you\
          \ able  to solve the problem? I am running into the same issue</p>\n"
        raw: '@johncookds  how were you able  to solve the problem? I am running into
          the same issue'
        updatedAt: '2023-04-18T21:34:13.207Z'
      numEdits: 0
      reactions: []
    id: 643f0cd546c418c9c6838f23
    type: comment
  author: resz
  content: '@johncookds  how were you able  to solve the problem? I am running into
    the same issue'
  created_at: 2023-04-18 20:34:13+00:00
  edited: false
  hidden: false
  id: 643f0cd546c418c9c6838f23
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/58bb4033cb1e5e9e0742f42961edc743.svg
      fullname: John Cook
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: johncookds
      type: user
    createdAt: '2023-04-26T15:07:07.000Z'
    data:
      edited: false
      editors:
      - johncookds
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/58bb4033cb1e5e9e0742f42961edc743.svg
          fullname: John Cook
          isHf: false
          isPro: false
          name: johncookds
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;resz&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/resz\">@<span class=\"\
          underline\">resz</span></a></span>\n\n\t</span></span> I believe it was\
          \ a network connection issue for me that lasted a while. I originally suspected\
          \ it was something to do with the huggingface space files but do not believe\
          \ it actually was. After a few days the issue cleared up so there's a chance\
          \ something was done on the HF side but I expect it was a network issue</p>\n"
        raw: '@resz I believe it was a network connection issue for me that lasted
          a while. I originally suspected it was something to do with the huggingface
          space files but do not believe it actually was. After a few days the issue
          cleared up so there''s a chance something was done on the HF side but I
          expect it was a network issue'
        updatedAt: '2023-04-26T15:07:07.253Z'
      numEdits: 0
      reactions: []
    id: 64493e1ba281f51a62aac757
    type: comment
  author: johncookds
  content: '@resz I believe it was a network connection issue for me that lasted a
    while. I originally suspected it was something to do with the huggingface space
    files but do not believe it actually was. After a few days the issue cleared up
    so there''s a chance something was done on the HF side but I expect it was a network
    issue'
  created_at: 2023-04-26 14:07:07+00:00
  edited: false
  hidden: false
  id: 64493e1ba281f51a62aac757
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e3da2b42209d042af57a1eadee203f10.svg
      fullname: cem kaya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hunterTR
      type: user
    createdAt: '2023-06-03T01:31:11.000Z'
    data:
      edited: true
      editors:
      - hunterTR
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9632050395011902
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e3da2b42209d042af57a1eadee203f10.svg
          fullname: cem kaya
          isHf: false
          isPro: false
          name: hunterTR
          type: user
        html: '<p>I was getting this with transformers version 4.13, it is solved
          for me after upgrading.</p>

          '
        raw: I was getting this with transformers version 4.13, it is solved for me
          after upgrading.
        updatedAt: '2023-06-03T01:31:46.498Z'
      numEdits: 2
      reactions: []
    id: 647a97df42abe2774763b8f7
    type: comment
  author: hunterTR
  content: I was getting this with transformers version 4.13, it is solved for me
    after upgrading.
  created_at: 2023-06-03 00:31:11+00:00
  edited: true
  hidden: false
  id: 647a97df42abe2774763b8f7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bec786dce49bf8ea8eece23b6473f817.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Haonan
      type: user
    createdAt: '2023-09-04T11:29:25.000Z'
    data:
      edited: true
      editors:
      - Haonan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6578461527824402
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bec786dce49bf8ea8eece23b6473f817.svg
          fullname: Liu
          isHf: false
          isPro: false
          name: Haonan
          type: user
        html: '<p>I fixed it by using the model EleutherAI/gpt-j-6b instead of EleutherAI/gpt-j-6B
          so it is small b not B</p>

          '
        raw: I fixed it by using the model EleutherAI/gpt-j-6b instead of EleutherAI/gpt-j-6B
          so it is small b not B
        updatedAt: '2023-09-04T11:29:47.016Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - avirupc11
        - ye997
    id: 64f5bf959eaf9d8fb74cc3b2
    type: comment
  author: Haonan
  content: I fixed it by using the model EleutherAI/gpt-j-6b instead of EleutherAI/gpt-j-6B
    so it is small b not B
  created_at: 2023-09-04 10:29:25+00:00
  edited: true
  hidden: false
  id: 64f5bf959eaf9d8fb74cc3b2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 23
repo_id: EleutherAI/gpt-j-6b
repo_type: model
status: open
target_branch: null
title: Tokenizer loading issue
