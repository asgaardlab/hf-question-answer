!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wizbe
conflicting_files: null
created_at: 2022-11-18 14:27:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668504314445-noauth.png?w=200&h=200&f=face
      fullname: Yong Li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wizbe
      type: user
    createdAt: '2022-11-18T14:27:29.000Z'
    data:
      edited: false
      editors:
      - wizbe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668504314445-noauth.png?w=200&h=200&f=face
          fullname: Yong Li
          isHf: false
          isPro: false
          name: wizbe
          type: user
        html: "<p>test.py, the same as in the introduction:</p>\n<h1 id=\"pip-install-githttpsgithubcomhuggingfaceaccelerate\"\
          >!pip install git+<a rel=\"nofollow\" href=\"https://github.com/huggingface/accelerate\"\
          >https://github.com/huggingface/accelerate</a></h1>\n<p>from diffusers import\
          \ StableDiffusionPipeline<br>import torch<br>torch.backends.cudnn.benchmark\
          \ = True<br>pipe = StableDiffusionPipeline.from_pretrained(\"IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1\"\
          , torch_dtype=torch.float16)<br>pipe.to('cuda')</p>\n<p>prompt = '\u5C0F\
          \u6865\u6D41\u6C34\u4EBA\u5BB6\uFF0CVan Gogh style'<br>image = pipe(prompt,\
          \ guidance_scale=10.0).images[0]<br>image.save(\"\u5C0F\u6865.png\")</p>\n\
          <p>Running from a python enviroment that runs Taiyi webui, but here is the\
          \ result:</p>\n<p>Fetching 22 files: 100%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22/22 [00:00&lt;00:00,\
          \ 24289.20it/s]<br>Traceback (most recent call last):<br>  File \"/home/liyong/t.py\"\
          , line 9, in <br>    image = pipe(prompt, guidance_scale=10.0).images[0]<br>\
          \  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context<br>    return func(*args, **kwargs)<br> \
          \ File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\"\
          , line 182, in <strong>call</strong><br>    text_embeddings = self.text_encoder(text_input.input_ids.to(self.device))[0]<br>\
          \  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl<br>    return forward_call(*input, **kwargs)<br>\
          \  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
          , line 722, in forward<br>    return self.text_model(<br>  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl<br>    return forward_call(*input, **kwargs)<br>\
          \  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
          , line 643, in forward<br>    encoder_outputs = self.encoder(<br>  File\
          \ \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl<br>    return forward_call(*input, **kwargs)<br>\
          \  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
          , line 574, in forward<br>    layer_outputs = encoder_layer(<br>  File \"\
          /home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl<br>    return forward_call(*input, **kwargs)<br>\
          \  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
          , line 317, in forward<br>    hidden_states, attn_weights = self.self_attn(<br>\
          \  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl<br>    return forward_call(*input, **kwargs)<br>\
          \  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
          , line 257, in forward<br>    attn_output = torch.bmm(attn_probs, value_states)<br>RuntimeError:\
          \ expected scalar type Half but found Float</p>\n<p>What's wrong?</p>\n"
        raw: "test.py, the same as in the introduction:\r\n# !pip install git+https://github.com/huggingface/accelerate\r\
          \nfrom diffusers import StableDiffusionPipeline\r\nimport torch\r\ntorch.backends.cudnn.benchmark\
          \ = True\r\npipe = StableDiffusionPipeline.from_pretrained(\"IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1\"\
          , torch_dtype=torch.float16)\r\npipe.to('cuda')\r\n\r\nprompt = '\u5C0F\u6865\
          \u6D41\u6C34\u4EBA\u5BB6\uFF0CVan Gogh style'\r\nimage = pipe(prompt, guidance_scale=10.0).images[0]\r\
          \nimage.save(\"\u5C0F\u6865.png\")\r\n\r\nRunning from a python enviroment\
          \ that runs Taiyi webui, but here is the result:\r\n\r\n\r\nFetching 22\
          \ files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588| 22/22 [00:00<00:00, 24289.20it/s]\r\nTraceback (most\
          \ recent call last):\r\n  File \"/home/liyong/t.py\", line 9, in <module>\r\
          \n    image = pipe(prompt, guidance_scale=10.0).images[0]\r\n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n \
          \ File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\"\
          , line 182, in __call__\r\n    text_embeddings = self.text_encoder(text_input.input_ids.to(self.device))[0]\r\
          \n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
          , line 722, in forward\r\n    return self.text_model(\r\n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
          , line 643, in forward\r\n    encoder_outputs = self.encoder(\r\n  File\
          \ \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
          , line 574, in forward\r\n    layer_outputs = encoder_layer(\r\n  File \"\
          /home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
          , line 317, in forward\r\n    hidden_states, attn_weights = self.self_attn(\r\
          \n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
          , line 257, in forward\r\n    attn_output = torch.bmm(attn_probs, value_states)\r\
          \nRuntimeError: expected scalar type Half but found Float\r\n\r\nWhat's\
          \ wrong?"
        updatedAt: '2022-11-18T14:27:29.228Z'
      numEdits: 0
      reactions: []
    id: 63779651dd61cb2fa30fcd35
    type: comment
  author: wizbe
  content: "test.py, the same as in the introduction:\r\n# !pip install git+https://github.com/huggingface/accelerate\r\
    \nfrom diffusers import StableDiffusionPipeline\r\nimport torch\r\ntorch.backends.cudnn.benchmark\
    \ = True\r\npipe = StableDiffusionPipeline.from_pretrained(\"IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1\"\
    , torch_dtype=torch.float16)\r\npipe.to('cuda')\r\n\r\nprompt = '\u5C0F\u6865\u6D41\
    \u6C34\u4EBA\u5BB6\uFF0CVan Gogh style'\r\nimage = pipe(prompt, guidance_scale=10.0).images[0]\r\
    \nimage.save(\"\u5C0F\u6865.png\")\r\n\r\nRunning from a python enviroment that\
    \ runs Taiyi webui, but here is the result:\r\n\r\n\r\nFetching 22 files: 100%|\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588| 22/22 [00:00<00:00, 24289.20it/s]\r\nTraceback (most\
    \ recent call last):\r\n  File \"/home/liyong/t.py\", line 9, in <module>\r\n\
    \    image = pipe(prompt, guidance_scale=10.0).images[0]\r\n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/autograd/grad_mode.py\"\
    , line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"\
    /home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\"\
    , line 182, in __call__\r\n    text_embeddings = self.text_encoder(text_input.input_ids.to(self.device))[0]\r\
    \n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
    , line 722, in forward\r\n    return self.text_model(\r\n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
    , line 643, in forward\r\n    encoder_outputs = self.encoder(\r\n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
    , line 574, in forward\r\n    layer_outputs = encoder_layer(\r\n  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
    , line 317, in forward\r\n    hidden_states, attn_weights = self.self_attn(\r\n\
    \  File \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/liyong/taiyi-stable-diffusion-webui/venv/lib64/python3.9/site-packages/transformers/models/clip/modeling_clip.py\"\
    , line 257, in forward\r\n    attn_output = torch.bmm(attn_probs, value_states)\r\
    \nRuntimeError: expected scalar type Half but found Float\r\n\r\nWhat's wrong?"
  created_at: 2022-11-18 14:27:29+00:00
  edited: false
  hidden: false
  id: 63779651dd61cb2fa30fcd35
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/50a8a429ce03dfcdd9ccede1426a1079.svg
      fullname: xiayuli
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: xiayu
      type: user
    createdAt: '2022-11-19T03:32:46.000Z'
    data:
      edited: false
      editors:
      - xiayu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/50a8a429ce03dfcdd9ccede1426a1079.svg
          fullname: xiayuli
          isHf: false
          isPro: false
          name: xiayu
          type: user
        html: '<p>Maybe you can try to upgrade your environment.<br>Here is some version
          suggestion:<br>transformers:  4.24.0<br>diffusers:  0.7.2</p>

          '
        raw: 'Maybe you can try to upgrade your environment.

          Here is some version suggestion:

          transformers:  4.24.0

          diffusers:  0.7.2'
        updatedAt: '2022-11-19T03:32:46.186Z'
      numEdits: 0
      reactions: []
    id: 63784e5eea2a9a0283b405df
    type: comment
  author: xiayu
  content: 'Maybe you can try to upgrade your environment.

    Here is some version suggestion:

    transformers:  4.24.0

    diffusers:  0.7.2'
  created_at: 2022-11-19 03:32:46+00:00
  edited: false
  hidden: false
  id: 63784e5eea2a9a0283b405df
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1
repo_type: model
status: open
target_branch: null
title: Script error
