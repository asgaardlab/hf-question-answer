!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Muhammadreza
conflicting_files: null
created_at: 2023-12-28 10:01:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e719af1e2b75f1956ea9c7bc3de6fcad.svg
      fullname: Haghiri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Muhammadreza
      type: user
    createdAt: '2023-12-28T10:01:49.000Z'
    data:
      edited: false
      editors:
      - Muhammadreza
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.968981146812439
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e719af1e2b75f1956ea9c7bc3de6fcad.svg
          fullname: Haghiri
          isHf: false
          isPro: false
          name: Muhammadreza
          type: user
        html: '<p>Well since your model is based on Mistral, I have a few questions:</p>

          <ol>

          <li>Have you taken the 7B model and trimmed the fat to get this? Or this
          is a coded model from scratch?</li>

          <li>What steps are necessary in order to train this model?</li>

          <li>What hardware do you recommend for training the model?</li>

          </ol>

          <p>Thanks. </p>

          '
        raw: "Well since your model is based on Mistral, I have a few questions:\r\
          \n\r\n1. Have you taken the 7B model and trimmed the fat to get this? Or\
          \ this is a coded model from scratch?\r\n2. What steps are necessary in\
          \ order to train this model?\r\n3. What hardware do you recommend for training\
          \ the model?\r\n\r\nThanks. "
        updatedAt: '2023-12-28T10:01:49.256Z'
      numEdits: 0
      reactions: []
    id: 658d478dc8217618ed7ab99f
    type: comment
  author: Muhammadreza
  content: "Well since your model is based on Mistral, I have a few questions:\r\n\
    \r\n1. Have you taken the 7B model and trimmed the fat to get this? Or this is\
    \ a coded model from scratch?\r\n2. What steps are necessary in order to train\
    \ this model?\r\n3. What hardware do you recommend for training the model?\r\n\
    \r\nThanks. "
  created_at: 2023-12-28 10:01:49+00:00
  edited: false
  hidden: false
  id: 658d478dc8217618ed7ab99f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e54f0eae9d3f10acb95cb9/VAyk05hqB3OZWXEZW-B0q.png?w=200&h=200&f=face
      fullname: mrfakename
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mrfakename
      type: user
    createdAt: '2023-12-28T16:02:42.000Z'
    data:
      edited: false
      editors:
      - mrfakename
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9389928579330444
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e54f0eae9d3f10acb95cb9/VAyk05hqB3OZWXEZW-B0q.png?w=200&h=200&f=face
          fullname: mrfakename
          isHf: false
          isPro: false
          name: mrfakename
          type: user
        html: '<p>Hi,<br>Thank you for your interest.<br>I basically trimmed most
          of the layers from Mistral to get this model.<br>If you''d like to train
          a completely new model, I''d look into <a rel="nofollow" href="https://github.com/princeton-nlp/LLM-Shearing">LLM
          Shearing</a>. If you''d like to finetune this model, I''d recommend using
          <a rel="nofollow" href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl</a>
          and perhaps The Pile or Falcon RefinedWeb.<br>As for the hardware, this
          can fit on many GPUs since it''s really small. You could use a 3090 or 4090,
          or for faster training H100s.<br>However, if you''re looking for a good
          pre-trained model that does not require any further finetuning, I''d recommend
          <a href="https://huggingface.co/TinyLlama">TinyLlama</a>.<br>I hope this
          helps!</p>

          '
        raw: 'Hi,

          Thank you for your interest.

          I basically trimmed most of the layers from Mistral to get this model.

          If you''d like to train a completely new model, I''d look into [LLM Shearing](https://github.com/princeton-nlp/LLM-Shearing).
          If you''d like to finetune this model, I''d recommend using [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)
          and perhaps The Pile or Falcon RefinedWeb.

          As for the hardware, this can fit on many GPUs since it''s really small.
          You could use a 3090 or 4090, or for faster training H100s.

          However, if you''re looking for a good pre-trained model that does not require
          any further finetuning, I''d recommend [TinyLlama](https://huggingface.co/TinyLlama).

          I hope this helps!'
        updatedAt: '2023-12-28T16:02:42.566Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Muhammadreza
    id: 658d9c228dd94e1b5eaa742b
    type: comment
  author: mrfakename
  content: 'Hi,

    Thank you for your interest.

    I basically trimmed most of the layers from Mistral to get this model.

    If you''d like to train a completely new model, I''d look into [LLM Shearing](https://github.com/princeton-nlp/LLM-Shearing).
    If you''d like to finetune this model, I''d recommend using [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)
    and perhaps The Pile or Falcon RefinedWeb.

    As for the hardware, this can fit on many GPUs since it''s really small. You could
    use a 3090 or 4090, or for faster training H100s.

    However, if you''re looking for a good pre-trained model that does not require
    any further finetuning, I''d recommend [TinyLlama](https://huggingface.co/TinyLlama).

    I hope this helps!'
  created_at: 2023-12-28 16:02:42+00:00
  edited: false
  hidden: false
  id: 658d9c228dd94e1b5eaa742b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e719af1e2b75f1956ea9c7bc3de6fcad.svg
      fullname: Haghiri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Muhammadreza
      type: user
    createdAt: '2023-12-28T17:21:37.000Z'
    data:
      edited: false
      editors:
      - Muhammadreza
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9559190273284912
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e719af1e2b75f1956ea9c7bc3de6fcad.svg
          fullname: Haghiri
          isHf: false
          isPro: false
          name: Muhammadreza
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;mrfakename&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/mrfakename\"\
          >@<span class=\"underline\">mrfakename</span></a></span>\n\n\t</span></span>!\
          \ For now, I'm more interested in <em>trimming</em> the model. Is there\
          \ any document or guide on that?<br>We have our own 7B model, based on mistral\
          \ and trained for our own language. I guess it could be nice if we can make\
          \ it small as well!</p>\n"
        raw: "Thanks @mrfakename! For now, I'm more interested in _trimming_ the model.\
          \ Is there any document or guide on that? \nWe have our own 7B model, based\
          \ on mistral and trained for our own language. I guess it could be nice\
          \ if we can make it small as well!"
        updatedAt: '2023-12-28T17:21:37.642Z'
      numEdits: 0
      reactions: []
    id: 658daea137e81e9f9ff5df9f
    type: comment
  author: Muhammadreza
  content: "Thanks @mrfakename! For now, I'm more interested in _trimming_ the model.\
    \ Is there any document or guide on that? \nWe have our own 7B model, based on\
    \ mistral and trained for our own language. I guess it could be nice if we can\
    \ make it small as well!"
  created_at: 2023-12-28 17:21:37+00:00
  edited: false
  hidden: false
  id: 658daea137e81e9f9ff5df9f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e54f0eae9d3f10acb95cb9/VAyk05hqB3OZWXEZW-B0q.png?w=200&h=200&f=face
      fullname: mrfakename
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mrfakename
      type: user
    createdAt: '2023-12-28T18:37:17.000Z'
    data:
      edited: false
      editors:
      - mrfakename
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9427307844161987
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e54f0eae9d3f10acb95cb9/VAyk05hqB3OZWXEZW-B0q.png?w=200&h=200&f=face
          fullname: mrfakename
          isHf: false
          isPro: false
          name: mrfakename
          type: user
        html: "<p>Hi,<br>Unfortunately there\u2019s no good way to trim a pre trained\
          \ model (as far as I know). Personally, my best guess would be to use LLM\
          \ Shearing, however this method requires further pretraining.<br>However,\
          \ if you just want a model that can run on weaker hardware, I\u2019d recommend\
          \ quantization using bitsandbytes or llama.cpp.</p>\n"
        raw: "Hi,\nUnfortunately there\u2019s no good way to trim a pre trained model\
          \ (as far as I know). Personally, my best guess would be to use LLM Shearing,\
          \ however this method requires further pretraining. \nHowever, if you just\
          \ want a model that can run on weaker hardware, I\u2019d recommend quantization\
          \ using bitsandbytes or llama.cpp."
        updatedAt: '2023-12-28T18:37:17.984Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Muhammadreza
    id: 658dc05d3533188375c96a1d
    type: comment
  author: mrfakename
  content: "Hi,\nUnfortunately there\u2019s no good way to trim a pre trained model\
    \ (as far as I know). Personally, my best guess would be to use LLM Shearing,\
    \ however this method requires further pretraining. \nHowever, if you just want\
    \ a model that can run on weaker hardware, I\u2019d recommend quantization using\
    \ bitsandbytes or llama.cpp."
  created_at: 2023-12-28 18:37:17+00:00
  edited: false
  hidden: false
  id: 658dc05d3533188375c96a1d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: lmlab/lmlab-mistral-1b-untrained
repo_type: model
status: open
target_branch: null
title: Training guide/requirements
