!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ralphsch
conflicting_files: null
created_at: 2023-05-11 10:04:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f338db4e1ce3745408f55506ea18974d.svg
      fullname: Ralph
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ralphsch
      type: user
    createdAt: '2023-05-11T11:04:09.000Z'
    data:
      edited: true
      editors:
      - ralphsch
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f338db4e1ce3745408f55506ea18974d.svg
          fullname: Ralph
          isHf: false
          isPro: false
          name: ralphsch
          type: user
        html: "<p>Thanks for this work, I am currently trying it out in combination\
          \ with the llama-index (gpt-index) project to generate responses based on\
          \ company data.<br>I am aware that  this is a first \"alpha\" version and\
          \ honestly, it generates impressive and correct responses about half the\
          \ time.</p>\n<p>However, sometimes the model will return the correct response,\
          \ but then instead of stopping, it continues and \"leaks\" an instruction-answer\
          \ pair from (I guess) the training data such as below:</p>\n<pre><code>&lt;correct\
          \ answer here&gt;   &lt;|endoftext|&gt;### Anweisung:\nWhat is the difference\
          \ between a cat and a dog?\n\n### Antwort:\nThe difference between a cat\
          \ and a dog is that cats are independent, independent, and independent,\
          \ \nwhile dogs are more companion-like, more companion-like, and more companion-like.\n\
          Cats are more independent, while dogs are more companion-    like. Cats\
          \ are more independent, while dogs are more com\n</code></pre>\n<p>It seems\
          \ as if this happens especially if the correct answer was rather short.<br>I\
          \ configured it to generate a maximum of 256 new tokens.</p>\n<p>Do you\
          \ have any pointers whether I am doing something wrong or whether it is\
          \ just a current limitation of the model?</p>\n<p>Thanks in advance and\
          \ keep up the good work :)</p>\n"
        raw: "Thanks for this work, I am currently trying it out in combination with\
          \ the llama-index (gpt-index) project to generate responses based on company\
          \ data.\nI am aware that  this is a first \"alpha\" version and honestly,\
          \ it generates impressive and correct responses about half the time.\n\n\
          However, sometimes the model will return the correct response, but then\
          \ instead of stopping, it continues and \"leaks\" an instruction-answer\
          \ pair from (I guess) the training data such as below:\n\n    <correct answer\
          \ here>   <|endoftext|>### Anweisung:\n    What is the difference between\
          \ a cat and a dog?\n\n    ### Antwort:\n    The difference between a cat\
          \ and a dog is that cats are independent, independent, and independent,\
          \ \n    while dogs are more companion-like, more companion-like, and more\
          \ companion-like.\n    Cats are more independent, while dogs are more companion-\
          \    like. Cats are more independent, while dogs are more com\n\nIt seems\
          \ as if this happens especially if the correct answer was rather short.\n\
          I configured it to generate a maximum of 256 new tokens.\n\nDo you have\
          \ any pointers whether I am doing something wrong or whether it is just\
          \ a current limitation of the model?\n\nThanks in advance and keep up the\
          \ good work :)"
        updatedAt: '2023-05-11T11:04:36.337Z'
      numEdits: 2
      reactions: []
    id: 645ccba903fc86c46b3d1979
    type: comment
  author: ralphsch
  content: "Thanks for this work, I am currently trying it out in combination with\
    \ the llama-index (gpt-index) project to generate responses based on company data.\n\
    I am aware that  this is a first \"alpha\" version and honestly, it generates\
    \ impressive and correct responses about half the time.\n\nHowever, sometimes\
    \ the model will return the correct response, but then instead of stopping, it\
    \ continues and \"leaks\" an instruction-answer pair from (I guess) the training\
    \ data such as below:\n\n    <correct answer here>   <|endoftext|>### Anweisung:\n\
    \    What is the difference between a cat and a dog?\n\n    ### Antwort:\n   \
    \ The difference between a cat and a dog is that cats are independent, independent,\
    \ and independent, \n    while dogs are more companion-like, more companion-like,\
    \ and more companion-like.\n    Cats are more independent, while dogs are more\
    \ companion-    like. Cats are more independent, while dogs are more com\n\nIt\
    \ seems as if this happens especially if the correct answer was rather short.\n\
    I configured it to generate a maximum of 256 new tokens.\n\nDo you have any pointers\
    \ whether I am doing something wrong or whether it is just a current limitation\
    \ of the model?\n\nThanks in advance and keep up the good work :)"
  created_at: 2023-05-11 10:04:09+00:00
  edited: true
  hidden: false
  id: 645ccba903fc86c46b3d1979
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: philschmid/instruct-igel-001
repo_type: model
status: open
target_branch: null
title: Model "leaks" parts of training data
