!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jafi96
conflicting_files: null
created_at: 2023-06-14 11:04:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/583d00063eceb46e298c0b91933c06e9.svg
      fullname: Jacob Fidorra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jafi96
      type: user
    createdAt: '2023-06-14T12:04:23.000Z'
    data:
      edited: true
      editors:
      - jafi96
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7957043051719666
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/583d00063eceb46e298c0b91933c06e9.svg
          fullname: Jacob Fidorra
          isHf: false
          isPro: false
          name: jafi96
          type: user
        html: '<p>I unsuccessfully tried multiple ways to deploy this model on Sagemaker.
          The new default deployment example via the HuggingFace Image works for the
          Falcon-7b (14GB) model on a g4dn.2xlarge instance (T4 GPU) just fine. When
          I use the igel (13GB) my instance fails to create, even if I increase the
          startup-timeout to 3600 seconds.</p>

          <p>I found similar behaviour when using another deployment image like described
          here (<a rel="nofollow" href="https://aws.amazon.com/de/blogs/machine-learning/deploy-bloom-176b-and-opt-30b-on-amazon-sagemaker-with-large-model-inference-deep-learning-containers-and-deepspeed/">https://aws.amazon.com/de/blogs/machine-learning/deploy-bloom-176b-and-opt-30b-on-amazon-sagemaker-with-large-model-inference-deep-learning-containers-and-deepspeed/</a>)</p>

          <p>Is someone facing similar problems when deploying this model?</p>

          <p>Thank you! </p>

          '
        raw: 'I unsuccessfully tried multiple ways to deploy this model on Sagemaker.
          The new default deployment example via the HuggingFace Image works for the
          Falcon-7b (14GB) model on a g4dn.2xlarge instance (T4 GPU) just fine. When
          I use the igel (13GB) my instance fails to create, even if I increase the
          startup-timeout to 3600 seconds.


          I found similar behaviour when using another deployment image like described
          here (https://aws.amazon.com/de/blogs/machine-learning/deploy-bloom-176b-and-opt-30b-on-amazon-sagemaker-with-large-model-inference-deep-learning-containers-and-deepspeed/)


          Is someone facing similar problems when deploying this model?


          Thank you! '
        updatedAt: '2023-06-14T12:11:07.869Z'
      numEdits: 3
      reactions: []
    id: 6489acc7208ff0a875853697
    type: comment
  author: jafi96
  content: 'I unsuccessfully tried multiple ways to deploy this model on Sagemaker.
    The new default deployment example via the HuggingFace Image works for the Falcon-7b
    (14GB) model on a g4dn.2xlarge instance (T4 GPU) just fine. When I use the igel
    (13GB) my instance fails to create, even if I increase the startup-timeout to
    3600 seconds.


    I found similar behaviour when using another deployment image like described here
    (https://aws.amazon.com/de/blogs/machine-learning/deploy-bloom-176b-and-opt-30b-on-amazon-sagemaker-with-large-model-inference-deep-learning-containers-and-deepspeed/)


    Is someone facing similar problems when deploying this model?


    Thank you! '
  created_at: 2023-06-14 11:04:23+00:00
  edited: true
  hidden: false
  id: 6489acc7208ff0a875853697
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60b473d729d165cd0a344292/GuA16oYkOXt0EW8mgVzUk.png?w=200&h=200&f=face
      fullname: Chris Lemke
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chrislemke
      type: user
    createdAt: '2023-07-18T17:53:44.000Z'
    data:
      edited: false
      editors:
      - chrislemke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7898942828178406
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60b473d729d165cd0a344292/GuA16oYkOXt0EW8mgVzUk.png?w=200&h=200&f=face
          fullname: Chris Lemke
          isHf: false
          isPro: false
          name: chrislemke
          type: user
        html: '<p>Not sure if it is still relevant. I used this notebook, made some
          renaming and minor changes and it works quite well:</p>

          <p><a rel="nofollow" href="https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/llm-workshop/lab10-falcon-40b-and-7b/falcon-7b-accelerate.ipynb">https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/llm-workshop/lab10-falcon-40b-and-7b/falcon-7b-accelerate.ipynb</a></p>

          '
        raw: 'Not sure if it is still relevant. I used this notebook, made some renaming
          and minor changes and it works quite well:


          https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/llm-workshop/lab10-falcon-40b-and-7b/falcon-7b-accelerate.ipynb'
        updatedAt: '2023-07-18T17:53:44.794Z'
      numEdits: 0
      reactions: []
    id: 64b6d1a807660173c7a29ff0
    type: comment
  author: chrislemke
  content: 'Not sure if it is still relevant. I used this notebook, made some renaming
    and minor changes and it works quite well:


    https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/llm-workshop/lab10-falcon-40b-and-7b/falcon-7b-accelerate.ipynb'
  created_at: 2023-07-18 16:53:44+00:00
  edited: false
  hidden: false
  id: 64b6d1a807660173c7a29ff0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/583d00063eceb46e298c0b91933c06e9.svg
      fullname: Jacob Fidorra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jafi96
      type: user
    createdAt: '2023-07-19T06:51:11.000Z'
    data:
      edited: true
      editors:
      - jafi96
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8613168597221375
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/583d00063eceb46e298c0b91933c06e9.svg
          fullname: Jacob Fidorra
          isHf: false
          isPro: false
          name: jafi96
          type: user
        html: '<p>Thanks for your answer!<br>I solved the problem two days ago :)</p>

          <p>The problem was caused by my use of the g4dn instance instead of the
          g5 instance. The official HuggingFace-SageMaker deployment image uses custom
          CUDA Kernels optimized for A100 GPUs (g5 instance) by default. When using
          the g4dn (that has a different GPU) this causes <code>CUDA error: no kernel
          image is available for execution on the device</code>.<br>The solution was
          to disable the custom Kernels in the HuggingFaceModel config by setting
          <code>''DISABLE_CUSTOM_KERNELS'':''true''</code></p>

          <p>Hope this helps anybody who wants to deploy BLOOM models on g4dn instances.</p>

          '
        raw: "Thanks for your answer!\nI solved the problem two days ago :)\n\nThe\
          \ problem was caused by my use of the g4dn instance instead of the g5 instance.\
          \ The official HuggingFace-SageMaker deployment image uses custom CUDA Kernels\
          \ optimized for A100 GPUs (g5 instance) by default. When using the g4dn\
          \ (that has a different GPU) this causes ``CUDA error: no kernel image is\
          \ available for execution on the device``. \nThe solution was to disable\
          \ the custom Kernels in the HuggingFaceModel config by setting ``'DISABLE_CUSTOM_KERNELS':'true'``\n\
          \nHope this helps anybody who wants to deploy BLOOM models on g4dn instances."
        updatedAt: '2023-07-19T06:55:30.227Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - chrislemke
    id: 64b787df88b86014d7ee23d4
    type: comment
  author: jafi96
  content: "Thanks for your answer!\nI solved the problem two days ago :)\n\nThe problem\
    \ was caused by my use of the g4dn instance instead of the g5 instance. The official\
    \ HuggingFace-SageMaker deployment image uses custom CUDA Kernels optimized for\
    \ A100 GPUs (g5 instance) by default. When using the g4dn (that has a different\
    \ GPU) this causes ``CUDA error: no kernel image is available for execution on\
    \ the device``. \nThe solution was to disable the custom Kernels in the HuggingFaceModel\
    \ config by setting ``'DISABLE_CUSTOM_KERNELS':'true'``\n\nHope this helps anybody\
    \ who wants to deploy BLOOM models on g4dn instances."
  created_at: 2023-07-19 05:51:11+00:00
  edited: true
  hidden: false
  id: 64b787df88b86014d7ee23d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/583d00063eceb46e298c0b91933c06e9.svg
      fullname: Jacob Fidorra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jafi96
      type: user
    createdAt: '2023-07-19T06:57:52.000Z'
    data:
      from: SageMaker Deployment does not work
      to: SageMaker Deployment does not work on g4dn instance
    id: 64b7897045f3511db2061bf0
    type: title-change
  author: jafi96
  created_at: 2023-07-19 05:57:52+00:00
  id: 64b7897045f3511db2061bf0
  new_title: SageMaker Deployment does not work on g4dn instance
  old_title: SageMaker Deployment does not work
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/583d00063eceb46e298c0b91933c06e9.svg
      fullname: Jacob Fidorra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jafi96
      type: user
    createdAt: '2023-07-19T08:55:00.000Z'
    data:
      status: closed
    id: 64b7a4e490154e1f1d015c26
    type: status-change
  author: jafi96
  created_at: 2023-07-19 07:55:00+00:00
  id: 64b7a4e490154e1f1d015c26
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: philschmid/instruct-igel-001
repo_type: model
status: closed
target_branch: null
title: SageMaker Deployment does not work on g4dn instance
