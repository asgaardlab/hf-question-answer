!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Fuji081
conflicting_files: null
created_at: 2023-09-19 09:17:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1fc2828c9ae5e38db8434f56fe38fa1b.svg
      fullname: Fujimoto
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Fuji081
      type: user
    createdAt: '2023-09-19T10:17:44.000Z'
    data:
      edited: false
      editors:
      - Fuji081
      hidden: false
      identifiedLanguage:
        language: ja
        probability: 0.9207187294960022
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1fc2828c9ae5e38db8434f56fe38fa1b.svg
          fullname: Fujimoto
          isHf: false
          isPro: false
          name: Fuji081
          type: user
        html: "<p>\u30D5\u30A1\u30A4\u30F3\u30C1\u30E5\u30FC\u30CB\u30F3\u30B0\u3057\
          \u3066google chrome\u306E\u4E2D\u306B\u30E2\u30C7\u30EB\u3092\u4FDD\u5B58\
          \u3057\u3001chatGPT\u306B\u66F8\u304B\u305B\u305F\u4EE5\u4E0B\u306E\u30B3\
          \u30FC\u30C9\u3067\u6587\u5B57\u8D77\u3053\u3057\u3092\u3057\u3088\u3046\
          \u3068\u3057\u307E\u3057\u305F\u3002\u3059\u308B\u3068\u30A8\u30E9\u30FC\
          \u30E1\u30C3\u30BB\u30FC\u30B8\u304C\u51FA\u307E\u3057\u305F\u3002vcab.json\u306E\
          \u30D5\u30A1\u30A4\u30EB\u306B\u554F\u984C\u304C\u3042\u308B\u601D\u3044\
          \u516C\u5F0F\u30B5\u30A4\u30C8\u304B\u3089\u5B66\u7FD2\u5143\u306EWhisper-small\u306E\
          \u30DA\u30FC\u30B8\u304B\u3089vcab\u30D5\u30A1\u30A4\u30EB\u3092\u518D\u30C0\
          \u30A6\u30F3\u30ED\u30FC\u30C9\u3057\u3066\u30B3\u30FC\u30C9\u3092\u518D\
          \u5B9F\u884C\u3057\u307E\u3057\u305F\u304C\u3001\u89E3\u6D88\u3055\u308C\
          \u307E\u305B\u3093\u3067\u3057\u305F\u3002\u8AB0\u304B\u52A9\u3051\u3066\
          ...</p>\n<p>import torch<br>from transformers import AutoTokenizer, AutoModelForSeq2SeqLM<br>import\
          \ torchaudio<br>from IPython.display import Audio<br>from transformers import\
          \ WhisperForConditionalGeneration, WhisperProcessor<br>from transformers\
          \ import WhisperTokenizer</p>\n<h1 id=\"\u30E2\u30C7\u30EB\u3068\u30C8\u30FC\
          \u30AF\u30CA\u30A4\u30B6\u30FC\u3092\u30ED\u30FC\u30C9\">\u30E2\u30C7\u30EB\
          \u3068\u30C8\u30FC\u30AF\u30CA\u30A4\u30B6\u30FC\u3092\u30ED\u30FC\u30C9\
          </h1>\n<p>model_dir = \"/content/drive/MyDrive/\u5352\u696D\u7814\u7A76\
          /model3\"  # \u4FDD\u5B58\u3057\u305F\u30E2\u30C7\u30EB\u3068\u30C8\u30FC\
          \u30AF\u30CA\u30A4\u30B6\u30FC\u306E\u30C7\u30A3\u30EC\u30AF\u30C8\u30EA\
          \u30D1\u30B9<br>model = WhisperForConditionalGeneration.from_pretrained(model_dir)</p>\n\
          <p>tokenizer = WhisperTokenizer.from_pretrained(model_dir)</p>\n<h1 id=\"\
          \u97F3\u58F0\u30D5\u30A1\u30A4\u30EB\u306E\u8AAD\u307F\u8FBC\u307F\">\u97F3\
          \u58F0\u30D5\u30A1\u30A4\u30EB\u306E\u8AAD\u307F\u8FBC\u307F</h1>\n<p>audio_file\
          \ = \"/content/out_288_1.wav\"  # \u97F3\u58F0\u30D5\u30A1\u30A4\u30EB\u306E\
          \u30D1\u30B9<br>waveform, sample_rate = torchaudio.load(audio_file)</p>\n\
          <h1 id=\"\u97F3\u58F0\u3092\u30C6\u30AD\u30B9\u30C8\u306B\u5909\u63DB\"\
          >\u97F3\u58F0\u3092\u30C6\u30AD\u30B9\u30C8\u306B\u5909\u63DB</h1>\n<p>input_text\
          \ = \"\u6587\u5B57\u8D77\u3053\u3057\u3057\u3066\u304F\u3060\u3055\u3044\
          \u3002\"  # \u97F3\u58F0\u306E\u5185\u5BB9\u306B\u95A2\u3059\u308B\u30C6\
          \u30AD\u30B9\u30C8<br>input_ids = tokenizer.encode(input_text, return_tensors=\"\
          pt\")<br>with torch.no_grad():<br>    generated_ids = model.generate(input_ids)<br>transcription\
          \ = tokenizer.decode(generated_ids[0], skip_special_tokens=True)</p>\n"
        raw: "\u30D5\u30A1\u30A4\u30F3\u30C1\u30E5\u30FC\u30CB\u30F3\u30B0\u3057\u3066\
          google chrome\u306E\u4E2D\u306B\u30E2\u30C7\u30EB\u3092\u4FDD\u5B58\u3057\
          \u3001chatGPT\u306B\u66F8\u304B\u305B\u305F\u4EE5\u4E0B\u306E\u30B3\u30FC\
          \u30C9\u3067\u6587\u5B57\u8D77\u3053\u3057\u3092\u3057\u3088\u3046\u3068\
          \u3057\u307E\u3057\u305F\u3002\u3059\u308B\u3068\u30A8\u30E9\u30FC\u30E1\
          \u30C3\u30BB\u30FC\u30B8\u304C\u51FA\u307E\u3057\u305F\u3002vcab.json\u306E\
          \u30D5\u30A1\u30A4\u30EB\u306B\u554F\u984C\u304C\u3042\u308B\u601D\u3044\
          \u516C\u5F0F\u30B5\u30A4\u30C8\u304B\u3089\u5B66\u7FD2\u5143\u306EWhisper-small\u306E\
          \u30DA\u30FC\u30B8\u304B\u3089vcab\u30D5\u30A1\u30A4\u30EB\u3092\u518D\u30C0\
          \u30A6\u30F3\u30ED\u30FC\u30C9\u3057\u3066\u30B3\u30FC\u30C9\u3092\u518D\
          \u5B9F\u884C\u3057\u307E\u3057\u305F\u304C\u3001\u89E3\u6D88\u3055\u308C\
          \u307E\u305B\u3093\u3067\u3057\u305F\u3002\u8AB0\u304B\u52A9\u3051\u3066\
          ...\r\n\r\nimport torch\r\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\r\
          \nimport torchaudio\r\nfrom IPython.display import Audio\r\nfrom transformers\
          \ import WhisperForConditionalGeneration, WhisperProcessor\r\nfrom transformers\
          \ import WhisperTokenizer\r\n\r\n# \u30E2\u30C7\u30EB\u3068\u30C8\u30FC\u30AF\
          \u30CA\u30A4\u30B6\u30FC\u3092\u30ED\u30FC\u30C9\r\nmodel_dir = \"/content/drive/MyDrive/\u5352\
          \u696D\u7814\u7A76/model3\"  # \u4FDD\u5B58\u3057\u305F\u30E2\u30C7\u30EB\
          \u3068\u30C8\u30FC\u30AF\u30CA\u30A4\u30B6\u30FC\u306E\u30C7\u30A3\u30EC\
          \u30AF\u30C8\u30EA\u30D1\u30B9\r\nmodel = WhisperForConditionalGeneration.from_pretrained(model_dir)\r\
          \n\r\ntokenizer = WhisperTokenizer.from_pretrained(model_dir)\r\n\r\n# \u97F3\
          \u58F0\u30D5\u30A1\u30A4\u30EB\u306E\u8AAD\u307F\u8FBC\u307F\r\naudio_file\
          \ = \"/content/out_288_1.wav\"  # \u97F3\u58F0\u30D5\u30A1\u30A4\u30EB\u306E\
          \u30D1\u30B9\r\nwaveform, sample_rate = torchaudio.load(audio_file)\r\n\r\
          \n# \u97F3\u58F0\u3092\u30C6\u30AD\u30B9\u30C8\u306B\u5909\u63DB\r\ninput_text\
          \ = \"\u6587\u5B57\u8D77\u3053\u3057\u3057\u3066\u304F\u3060\u3055\u3044\
          \u3002\"  # \u97F3\u58F0\u306E\u5185\u5BB9\u306B\u95A2\u3059\u308B\u30C6\
          \u30AD\u30B9\u30C8\r\ninput_ids = tokenizer.encode(input_text, return_tensors=\"\
          pt\")\r\nwith torch.no_grad():\r\n    generated_ids = model.generate(input_ids)\r\
          \ntranscription = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\r\
          \n\r\n"
        updatedAt: '2023-09-19T10:17:44.229Z'
      numEdits: 0
      reactions: []
    id: 650975481aece923f2e9f10b
    type: comment
  author: Fuji081
  content: "\u30D5\u30A1\u30A4\u30F3\u30C1\u30E5\u30FC\u30CB\u30F3\u30B0\u3057\u3066\
    google chrome\u306E\u4E2D\u306B\u30E2\u30C7\u30EB\u3092\u4FDD\u5B58\u3057\u3001\
    chatGPT\u306B\u66F8\u304B\u305B\u305F\u4EE5\u4E0B\u306E\u30B3\u30FC\u30C9\u3067\
    \u6587\u5B57\u8D77\u3053\u3057\u3092\u3057\u3088\u3046\u3068\u3057\u307E\u3057\
    \u305F\u3002\u3059\u308B\u3068\u30A8\u30E9\u30FC\u30E1\u30C3\u30BB\u30FC\u30B8\
    \u304C\u51FA\u307E\u3057\u305F\u3002vcab.json\u306E\u30D5\u30A1\u30A4\u30EB\u306B\
    \u554F\u984C\u304C\u3042\u308B\u601D\u3044\u516C\u5F0F\u30B5\u30A4\u30C8\u304B\
    \u3089\u5B66\u7FD2\u5143\u306EWhisper-small\u306E\u30DA\u30FC\u30B8\u304B\u3089\
    vcab\u30D5\u30A1\u30A4\u30EB\u3092\u518D\u30C0\u30A6\u30F3\u30ED\u30FC\u30C9\u3057\
    \u3066\u30B3\u30FC\u30C9\u3092\u518D\u5B9F\u884C\u3057\u307E\u3057\u305F\u304C\
    \u3001\u89E3\u6D88\u3055\u308C\u307E\u305B\u3093\u3067\u3057\u305F\u3002\u8AB0\
    \u304B\u52A9\u3051\u3066...\r\n\r\nimport torch\r\nfrom transformers import AutoTokenizer,\
    \ AutoModelForSeq2SeqLM\r\nimport torchaudio\r\nfrom IPython.display import Audio\r\
    \nfrom transformers import WhisperForConditionalGeneration, WhisperProcessor\r\
    \nfrom transformers import WhisperTokenizer\r\n\r\n# \u30E2\u30C7\u30EB\u3068\u30C8\
    \u30FC\u30AF\u30CA\u30A4\u30B6\u30FC\u3092\u30ED\u30FC\u30C9\r\nmodel_dir = \"\
    /content/drive/MyDrive/\u5352\u696D\u7814\u7A76/model3\"  # \u4FDD\u5B58\u3057\
    \u305F\u30E2\u30C7\u30EB\u3068\u30C8\u30FC\u30AF\u30CA\u30A4\u30B6\u30FC\u306E\
    \u30C7\u30A3\u30EC\u30AF\u30C8\u30EA\u30D1\u30B9\r\nmodel = WhisperForConditionalGeneration.from_pretrained(model_dir)\r\
    \n\r\ntokenizer = WhisperTokenizer.from_pretrained(model_dir)\r\n\r\n# \u97F3\u58F0\
    \u30D5\u30A1\u30A4\u30EB\u306E\u8AAD\u307F\u8FBC\u307F\r\naudio_file = \"/content/out_288_1.wav\"\
    \  # \u97F3\u58F0\u30D5\u30A1\u30A4\u30EB\u306E\u30D1\u30B9\r\nwaveform, sample_rate\
    \ = torchaudio.load(audio_file)\r\n\r\n# \u97F3\u58F0\u3092\u30C6\u30AD\u30B9\u30C8\
    \u306B\u5909\u63DB\r\ninput_text = \"\u6587\u5B57\u8D77\u3053\u3057\u3057\u3066\
    \u304F\u3060\u3055\u3044\u3002\"  # \u97F3\u58F0\u306E\u5185\u5BB9\u306B\u95A2\
    \u3059\u308B\u30C6\u30AD\u30B9\u30C8\r\ninput_ids = tokenizer.encode(input_text,\
    \ return_tensors=\"pt\")\r\nwith torch.no_grad():\r\n    generated_ids = model.generate(input_ids)\r\
    \ntranscription = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\r\
    \n\r\n"
  created_at: 2023-09-19 09:17:44+00:00
  edited: false
  hidden: false
  id: 650975481aece923f2e9f10b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Fuji081/model2
repo_type: model
status: open
target_branch: null
title: 'ValueError: Non-consecutive added token ''<|endoftext|>'' found. Should have
  index 50258 but has index 50257 in saved vocabulary.'
