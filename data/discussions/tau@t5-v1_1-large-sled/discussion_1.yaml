!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ljhwild
conflicting_files: null
created_at: 2023-08-27 10:30:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aa8e2e38e07d1fa0d2dc611723bc8f4c.svg
      fullname: "\u0141ael Al-Halawani"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ljhwild
      type: user
    createdAt: '2023-08-27T11:30:56.000Z'
    data:
      edited: false
      editors:
      - ljhwild
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6212608814239502
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aa8e2e38e07d1fa0d2dc611723bc8f4c.svg
          fullname: "\u0141ael Al-Halawani"
          isHf: false
          isPro: false
          name: ljhwild
          type: user
        html: '<p>Thanks for amazing research and publications!<br>I was reading the
          paper and it appears SLED allows to use any pretrained encoder-decoder model.<br>if
          <strong>name</strong> == ''<strong>main</strong>'':<br>    # Load the model
          and tokenizer for Bart-base-SLED<br>    bart_base_sled_model = AutoModel.from_pretrained(''tau/bart-base-sled'')<br>    tokenizer
          = AutoTokenizer.from_pretrained(''tau/bart-base-sled'')<br>    bart_base_sled_model.eval()</p>

          <p>In the code examples we''re using bart_base_sled_model, how do you create
          these models?</p>

          '
        raw: "Thanks for amazing research and publications!\r\nI was reading the paper\
          \ and it appears SLED allows to use any pretrained encoder-decoder model.\
          \ \r\nif __name__ == '__main__':\r\n    # Load the model and tokenizer for\
          \ Bart-base-SLED\r\n    bart_base_sled_model = AutoModel.from_pretrained('tau/bart-base-sled')\r\
          \n    tokenizer = AutoTokenizer.from_pretrained('tau/bart-base-sled')\r\n\
          \    bart_base_sled_model.eval()\r\n\r\nIn the code examples we're using\
          \ bart_base_sled_model, how do you create these models?"
        updatedAt: '2023-08-27T11:30:56.828Z'
      numEdits: 0
      reactions: []
    id: 64eb33f001df1b139e802cfe
    type: comment
  author: ljhwild
  content: "Thanks for amazing research and publications!\r\nI was reading the paper\
    \ and it appears SLED allows to use any pretrained encoder-decoder model. \r\n\
    if __name__ == '__main__':\r\n    # Load the model and tokenizer for Bart-base-SLED\r\
    \n    bart_base_sled_model = AutoModel.from_pretrained('tau/bart-base-sled')\r\
    \n    tokenizer = AutoTokenizer.from_pretrained('tau/bart-base-sled')\r\n    bart_base_sled_model.eval()\r\
    \n\r\nIn the code examples we're using bart_base_sled_model, how do you create\
    \ these models?"
  created_at: 2023-08-27 10:30:56+00:00
  edited: false
  hidden: false
  id: 64eb33f001df1b139e802cfe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/610b7f53b1d06c607ab4436d/Bqw7fIsjpuukFP11S-awA.jpeg?w=200&h=200&f=face
      fullname: Maor
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Mivg
      type: user
    createdAt: '2023-08-29T07:09:27.000Z'
    data:
      edited: false
      editors:
      - Mivg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9189452528953552
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/610b7f53b1d06c607ab4436d/Bqw7fIsjpuukFP11S-awA.jpeg?w=200&h=200&f=face
          fullname: Maor
          isHf: false
          isPro: false
          name: Mivg
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;ljhwild&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ljhwild\">@<span class=\"\
          underline\">ljhwild</span></a></span>\n\n\t</span></span><br>Thanks for\
          \ your kind words!<br>Indeed, you can use any encoder-decoder model with\
          \ SLED (though some custom models may require some minor tweaking to expose\
          \ the required methods in the same interface BART and t5 do for example).\
          \ The usage is simply by listing the name of the model/tokenizer so that\
          \ SLED can load it. If it's already on GitHub then great, but you can also\
          \ work with local config files if needed. You're absolutely right that I\
          \ need to update the README here to make it clearer. Take a look at the\
          \ repo <a rel=\"nofollow\" href=\"https://github.com/mivg/sled\">https://github.com/mivg/sled</a>\
          \ for details how to use your own model, and open an issue there if you\
          \ need any help and I'll try to assist you.</p>\n"
        raw: "Hi @ljhwild \nThanks for your kind words!\nIndeed, you can use any encoder-decoder\
          \ model with SLED (though some custom models may require some minor tweaking\
          \ to expose the required methods in the same interface BART and t5 do for\
          \ example). The usage is simply by listing the name of the model/tokenizer\
          \ so that SLED can load it. If it's already on GitHub then great, but you\
          \ can also work with local config files if needed. You're absolutely right\
          \ that I need to update the README here to make it clearer. Take a look\
          \ at the repo https://github.com/mivg/sled for details how to use your own\
          \ model, and open an issue there if you need any help and I'll try to assist\
          \ you.\n"
        updatedAt: '2023-08-29T07:09:27.065Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - ljhwild
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ljhwild
    id: 64ed99a784cc47a8b503ba5a
    type: comment
  author: Mivg
  content: "Hi @ljhwild \nThanks for your kind words!\nIndeed, you can use any encoder-decoder\
    \ model with SLED (though some custom models may require some minor tweaking to\
    \ expose the required methods in the same interface BART and t5 do for example).\
    \ The usage is simply by listing the name of the model/tokenizer so that SLED\
    \ can load it. If it's already on GitHub then great, but you can also work with\
    \ local config files if needed. You're absolutely right that I need to update\
    \ the README here to make it clearer. Take a look at the repo https://github.com/mivg/sled\
    \ for details how to use your own model, and open an issue there if you need any\
    \ help and I'll try to assist you.\n"
  created_at: 2023-08-29 06:09:27+00:00
  edited: false
  hidden: false
  id: 64ed99a784cc47a8b503ba5a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: tau/t5-v1_1-large-sled
repo_type: model
status: open
target_branch: null
title: Can I hot swap for any encoder/decoder model?
