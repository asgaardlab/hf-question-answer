!!python/object:huggingface_hub.community.DiscussionWithDetails
author: logvinata
conflicting_files: null
created_at: 2023-06-07 09:03:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2230ebfd38dc9c593585ce10050a12cf.svg
      fullname: Nataliya Logvina
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: logvinata
      type: user
    createdAt: '2023-06-07T10:03:42.000Z'
    data:
      edited: true
      editors:
      - logvinata
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9784351587295532
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2230ebfd38dc9c593585ce10050a12cf.svg
          fullname: Nataliya Logvina
          isHf: false
          isPro: false
          name: logvinata
          type: user
        html: '<p>Hello!<br>I  was just going through your thesis report to find some
          details about the model and saw that you did some additional distillation
          for promoter identification. So, I got curious about the version of the
          model you''ve got on Hugging Face - is it the one with the extra distillation
          step or without it?<br> Thanks for your help!<br>P.S. And the next immediate
          question - what tokenizer should I use with the model? <code>tokenizer =
          AutoTokenizer.from_pretrained(''Peltarion/dnabert-distilbert'')</code> returns
          an error:  <code>stat: path should be string, bytes, os.PathLike or integer,
          not NoneType</code>. From the error stack I get it so that there is no tokenizer
          with such name in the hub.</p>

          '
        raw: "Hello!\nI  was just going through your thesis report to find some details\
          \ about the model and saw that you did some additional distillation for\
          \ promoter identification. So, I got curious about the version of the model\
          \ you've got on Hugging Face - is it the one with the extra distillation\
          \ step or without it?\n Thanks for your help!\nP.S. And the next immediate\
          \ question - what tokenizer should I use with the model? `tokenizer = AutoTokenizer.from_pretrained('Peltarion/dnabert-distilbert')`\
          \ returns an error:  `stat: path should be string, bytes, os.PathLike or\
          \ integer, not NoneType`. From the error stack I get it so that there is\
          \ no tokenizer with such name in the hub."
        updatedAt: '2023-06-07T10:42:43.725Z'
      numEdits: 1
      reactions: []
    id: 648055fe3fb124fc984aeb31
    type: comment
  author: logvinata
  content: "Hello!\nI  was just going through your thesis report to find some details\
    \ about the model and saw that you did some additional distillation for promoter\
    \ identification. So, I got curious about the version of the model you've got\
    \ on Hugging Face - is it the one with the extra distillation step or without\
    \ it?\n Thanks for your help!\nP.S. And the next immediate question - what tokenizer\
    \ should I use with the model? `tokenizer = AutoTokenizer.from_pretrained('Peltarion/dnabert-distilbert')`\
    \ returns an error:  `stat: path should be string, bytes, os.PathLike or integer,\
    \ not NoneType`. From the error stack I get it so that there is no tokenizer with\
    \ such name in the hub."
  created_at: 2023-06-07 09:03:42+00:00
  edited: true
  hidden: false
  id: 648055fe3fb124fc984aeb31
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a6d9e6b6aa501fa5c4b3ba965f1ac486.svg
      fullname: "Joana Pal\xE9s Huix"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: joanaapa
      type: user
    createdAt: '2023-06-09T09:41:10.000Z'
    data:
      edited: true
      editors:
      - joanaapa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.81644606590271
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a6d9e6b6aa501fa5c4b3ba965f1ac486.svg
          fullname: "Joana Pal\xE9s Huix"
          isHf: false
          isPro: false
          name: joanaapa
          type: user
        html: "<p>Hello! </p>\n<p>It's the one without the additional distillation\
          \ step, as this extra step was used when finetuning the model for promoter\
          \ identification.<br>For the tokenizer, you need to use a specific one build\
          \ to handle DNA data. You can find how to use the models in my github repo\
          \ \u201D<a rel=\"nofollow\" href=\"https://github.com/joanaapa/Distillation-DNABERT-Promoter&quot;\"\
          >https://github.com/joanaapa/Distillation-DNABERT-Promoter\"</a>. The DNA\
          \ tokenizer you can find in <code>/src/transformers/tokenization_DNA.py</code>.</p>\n\
          <p>Let me know if you have any more questions!</p>\n"
        raw: "Hello! \n\nIt's the one without the additional distillation step, as\
          \ this extra step was used when finetuning the model for promoter identification.\n\
          For the tokenizer, you need to use a specific one build to handle DNA data.\
          \ You can find how to use the models in my github repo \u201Dhttps://github.com/joanaapa/Distillation-DNABERT-Promoter\"\
          . The DNA tokenizer you can find in `/src/transformers/tokenization_DNA.py`.\n\
          \nLet me know if you have any more questions!"
        updatedAt: '2023-06-09T09:41:31.690Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - logvinata
    id: 6482f3b67e165f4007d4d890
    type: comment
  author: joanaapa
  content: "Hello! \n\nIt's the one without the additional distillation step, as this\
    \ extra step was used when finetuning the model for promoter identification.\n\
    For the tokenizer, you need to use a specific one build to handle DNA data. You\
    \ can find how to use the models in my github repo \u201Dhttps://github.com/joanaapa/Distillation-DNABERT-Promoter\"\
    . The DNA tokenizer you can find in `/src/transformers/tokenization_DNA.py`.\n\
    \nLet me know if you have any more questions!"
  created_at: 2023-06-09 08:41:10+00:00
  edited: true
  hidden: false
  id: 6482f3b67e165f4007d4d890
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Peltarion/dnabert-distilbert
repo_type: model
status: open
target_branch: null
title: Promoters Distillation
