!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Jason571
conflicting_files: null
created_at: 2023-12-14 03:45:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0b27ff879524aed13e9e0940557190c7.svg
      fullname: yang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jason571
      type: user
    createdAt: '2023-12-14T03:45:15.000Z'
    data:
      edited: false
      editors:
      - Jason571
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4557586908340454
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0b27ff879524aed13e9e0940557190c7.svg
          fullname: yang
          isHf: false
          isPro: false
          name: Jason571
          type: user
        html: '<p>When I generate text<br>TypeError: bad operand type for unary -:
          ''NoneType''<br> File "/mnt/p/home/flyang/text-generation-webui/modules/callbacks.py",
          line 57, in gentask<br>    ret = self.mfunc(callback=_callback, *args, **self.kwargs)<br>  File
          "/mnt/p/home/flyang/text-generation-webui/modules/text_generation.py", line
          351, in generate_with_callback<br>    shared.model.generate(**kwargs)<br>  File
          "/home/flyang/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py",
          line 115, in decorate_context<br>    return func(*args, **kwargs)<br>  File
          "/home/flyang/.local/lib/python3.10/site-packages/transformers/generation/utils.py",
          line 1652, in generate<br>    return self.sample(<br>  File "/home/flyang/.local/lib/python3.10/site-packages/transformers/generation/utils.py",
          line 2734, in sample<br>    outputs = self(<br>  File "/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>    return self._call_impl(*args, **kwargs)<br>  File
          "/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py",
          line 1045, in forward<br>    outputs = self.model(<br>  File "/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>    return self._call_impl(*args, **kwargs)<br>  File
          "/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py",
          line 888, in forward<br>    attention_mask = self._prepare_decoder_attention_mask(<br>  File
          "/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py",
          line 796, in _prepare_decoder_attention_mask<br>    combined_attention_mask
          = _make_sliding_window_causal_mask(<br>  File "/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py",
          line 88, in _make_sliding_window_causal_mask<br>    mask = torch.triu(mask,
          diagonal=-sliding_window)<br>TypeError: bad operand type for unary -: ''NoneType''</p>

          '
        raw: "When I generate text\r\nTypeError: bad operand type for unary -: 'NoneType'\
          \ \r\n File \"/mnt/p/home/flyang/text-generation-webui/modules/callbacks.py\"\
          , line 57, in gentask\r\n    ret = self.mfunc(callback=_callback, *args,\
          \ **self.kwargs)\r\n  File \"/mnt/p/home/flyang/text-generation-webui/modules/text_generation.py\"\
          , line 351, in generate_with_callback\r\n    shared.model.generate(**kwargs)\r\
          \n  File \"/home/flyang/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n\
          \  File \"/home/flyang/.local/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1652, in generate\r\n    return self.sample(\r\n  File \"/home/flyang/.local/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 2734, in sample\r\n    outputs = self(\r\n  File \"/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n  File \"/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 1045, in forward\r\n    outputs = self.model(\r\n  File \"/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args,\
          \ **kwargs)\r\n  File \"/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 888, in forward\r\n    attention_mask = self._prepare_decoder_attention_mask(\r\
          \n  File \"/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 796, in _prepare_decoder_attention_mask\r\n    combined_attention_mask\
          \ = _make_sliding_window_causal_mask(\r\n  File \"/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 88, in _make_sliding_window_causal_mask\r\n    mask = torch.triu(mask,\
          \ diagonal=-sliding_window)\r\nTypeError: bad operand type for unary -:\
          \ 'NoneType'"
        updatedAt: '2023-12-14T03:45:15.846Z'
      numEdits: 0
      reactions: []
    id: 657a7a4b186ecaba79efb33d
    type: comment
  author: Jason571
  content: "When I generate text\r\nTypeError: bad operand type for unary -: 'NoneType'\
    \ \r\n File \"/mnt/p/home/flyang/text-generation-webui/modules/callbacks.py\"\
    , line 57, in gentask\r\n    ret = self.mfunc(callback=_callback, *args, **self.kwargs)\r\
    \n  File \"/mnt/p/home/flyang/text-generation-webui/modules/text_generation.py\"\
    , line 351, in generate_with_callback\r\n    shared.model.generate(**kwargs)\r\
    \n  File \"/home/flyang/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File\
    \ \"/home/flyang/.local/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 1652, in generate\r\n    return self.sample(\r\n  File \"/home/flyang/.local/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 2734, in sample\r\n    outputs = self(\r\n  File \"/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n  File \"/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 1045, in forward\r\n    outputs = self.model(\r\n  File \"/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\
    \n  File \"/home/flyang/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 888, in forward\r\n    attention_mask = self._prepare_decoder_attention_mask(\r\
    \n  File \"/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 796, in _prepare_decoder_attention_mask\r\n    combined_attention_mask\
    \ = _make_sliding_window_causal_mask(\r\n  File \"/home/flyang/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 88, in _make_sliding_window_causal_mask\r\n    mask = torch.triu(mask,\
    \ diagonal=-sliding_window)\r\nTypeError: bad operand type for unary -: 'NoneType'"
  created_at: 2023-12-14 03:45:15+00:00
  edited: false
  hidden: false
  id: 657a7a4b186ecaba79efb33d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f4dd436182662398a477161957d11096.svg
      fullname: Gu Wenyi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guwenyi
      type: user
    createdAt: '2023-12-14T06:40:50.000Z'
    data:
      edited: false
      editors:
      - guwenyi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.45136386156082153
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f4dd436182662398a477161957d11096.svg
          fullname: Gu Wenyi
          isHf: false
          isPro: false
          name: guwenyi
          type: user
        html: '<p>I got a same error:</p>

          <p>User: hi<br>Assistant: Exception in thread Thread-3 (generate):<br>Traceback
          (most recent call last):<br>  File "/root/miniconda3/envs/llama_factory/lib/python3.10/threading.py",
          line 1016, in _bootstrap_inner<br>    self.run()<br>  File "/root/miniconda3/envs/llama_factory/lib/python3.10/threading.py",
          line 953, in run<br>    self._target(*self._args, **self._kwargs)<br>  File
          "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/utils/_contextlib.py",
          line 115, in decorate_context<br>    return func(*args, **kwargs)<br>  File
          "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/generation/utils.py",
          line 1652, in generate<br>    return self.sample(<br>  File "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/generation/utils.py",
          line 2734, in sample<br>    outputs = self(<br>  File "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>    return self._call_impl(*args, **kwargs)<br>  File
          "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py",
          line 1045, in forward<br>    outputs = self.model(<br>  File "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>    return self._call_impl(*args, **kwargs)<br>  File
          "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py",
          line 888, in forward<br>    attention_mask = self._prepare_decoder_attention_mask(<br>  File
          "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py",
          line 796, in _prepare_decoder_attention_mask<br>    combined_attention_mask
          = _make_sliding_window_causal_mask(<br>  File "/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py",
          line 88, in _make_sliding_window_causal_mask<br>    mask = torch.triu(mask,
          diagonal=-sliding_window)<br>TypeError: bad operand type for unary -: ''NoneType''</p>

          '
        raw: "I got a same error:\n\nUser: hi\nAssistant: Exception in thread Thread-3\
          \ (generate):\nTraceback (most recent call last):\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/threading.py\"\
          , line 1016, in _bootstrap_inner\n    self.run()\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/threading.py\"\
          , line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File\
          \ \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1652, in generate\n    return self.sample(\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 2734, in sample\n    outputs = self(\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 1045, in forward\n    outputs = self.model(\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
          \  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 888, in forward\n    attention_mask = self._prepare_decoder_attention_mask(\n\
          \  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 796, in _prepare_decoder_attention_mask\n    combined_attention_mask\
          \ = _make_sliding_window_causal_mask(\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
          , line 88, in _make_sliding_window_causal_mask\n    mask = torch.triu(mask,\
          \ diagonal=-sliding_window)\nTypeError: bad operand type for unary -: 'NoneType'"
        updatedAt: '2023-12-14T06:40:50.702Z'
      numEdits: 0
      reactions: []
    id: 657aa372893b13b8f437144a
    type: comment
  author: guwenyi
  content: "I got a same error:\n\nUser: hi\nAssistant: Exception in thread Thread-3\
    \ (generate):\nTraceback (most recent call last):\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/threading.py\"\
    , line 1016, in _bootstrap_inner\n    self.run()\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/threading.py\"\
    , line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 1652, in generate\n    return self.sample(\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 2734, in sample\n    outputs = self(\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
    \  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 1045, in forward\n    outputs = self.model(\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n\
    \  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 888, in forward\n    attention_mask = self._prepare_decoder_attention_mask(\n\
    \  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 796, in _prepare_decoder_attention_mask\n    combined_attention_mask =\
    \ _make_sliding_window_causal_mask(\n  File \"/root/miniconda3/envs/llama_factory/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\"\
    , line 88, in _make_sliding_window_causal_mask\n    mask = torch.triu(mask, diagonal=-sliding_window)\n\
    TypeError: bad operand type for unary -: 'NoneType'"
  created_at: 2023-12-14 06:40:50+00:00
  edited: false
  hidden: false
  id: 657aa372893b13b8f437144a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-12-14T12:09:56.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.731676459312439
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: '<p>hi everyone,<br>can you update the transformers package? <code>pip
          install -U transformers</code></p>

          '
        raw: 'hi everyone,

          can you update the transformers package? `pip install -U transformers`'
        updatedAt: '2023-12-14T12:09:56.222Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - epignatelli
        - Jason571
    id: 657af0946b314373ed393308
    type: comment
  author: ybelkada
  content: 'hi everyone,

    can you update the transformers package? `pip install -U transformers`'
  created_at: 2023-12-14 12:09:56+00:00
  edited: false
  hidden: false
  id: 657af0946b314373ed393308
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a4cae175448775d9505f8d47eefe5fe1.svg
      fullname: Eduardo Pignatelli
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: epignatelli
      type: user
    createdAt: '2023-12-14T17:06:20.000Z'
    data:
      edited: false
      editors:
      - epignatelli
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9802708625793457
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a4cae175448775d9505f8d47eefe5fe1.svg
          fullname: Eduardo Pignatelli
          isHf: false
          isPro: false
          name: epignatelli
          type: user
        html: '<p>Upgrading to a newer version of <code>transformers</code> worked
          for me.</p>

          '
        raw: Upgrading to a newer version of `transformers` worked for me.
        updatedAt: '2023-12-14T17:06:20.036Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F91D"
        users:
        - ybelkada
        - Jason571
      - count: 1
        reaction: "\U0001F44D"
        users:
        - veeravignesh
    id: 657b360c538666d04cb12905
    type: comment
  author: epignatelli
  content: Upgrading to a newer version of `transformers` worked for me.
  created_at: 2023-12-14 17:06:20+00:00
  edited: false
  hidden: false
  id: 657b360c538666d04cb12905
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c21bbffd5837de2123c21e88169c8351.svg
      fullname: Kuo Liao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MagiaSN
      type: user
    createdAt: '2024-01-03T12:31:16.000Z'
    data:
      edited: false
      editors:
      - MagiaSN
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8593592047691345
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c21bbffd5837de2123c21e88169c8351.svg
          fullname: Kuo Liao
          isHf: false
          isPro: false
          name: MagiaSN
          type: user
        html: '<p>An alternative is to change <code>sliding_window</code> in <code>config.json</code>
          from <code>null</code> to something like <code>4096</code>, if you can not
          update your <code>transformers</code> just like me.</p>

          '
        raw: An alternative is to change `sliding_window` in `config.json` from `null`
          to something like `4096`, if you can not update your `transformers` just
          like me.
        updatedAt: '2024-01-03T12:31:16.516Z'
      numEdits: 0
      reactions: []
    id: 65955394dab38426101eb592
    type: comment
  author: MagiaSN
  content: An alternative is to change `sliding_window` in `config.json` from `null`
    to something like `4096`, if you can not update your `transformers` just like
    me.
  created_at: 2024-01-03 12:31:16+00:00
  edited: false
  hidden: false
  id: 65955394dab38426101eb592
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: mistralai/Mistral-7B-Instruct-v0.2
repo_type: model
status: open
target_branch: null
title: 'TypeError: bad operand type for unary -: ''NoneType'''
