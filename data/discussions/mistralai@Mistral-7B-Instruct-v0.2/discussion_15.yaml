!!python/object:huggingface_hub.community.DiscussionWithDetails
author: asmittal
conflicting_files: null
created_at: 2023-12-13 08:03:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/249a95ae8910ccde4ff41f85fba0b84e.svg
      fullname: Ashish Mittal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: asmittal
      type: user
    createdAt: '2023-12-13T08:03:18.000Z'
    data:
      edited: false
      editors:
      - asmittal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4353393316268921
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/249a95ae8910ccde4ff41f85fba0b84e.svg
          fullname: Ashish Mittal
          isHf: false
          isPro: false
          name: asmittal
          type: user
        html: "<p>Has anyone tried using stopping criteria in Mistral 0.2 its not\
          \ stopping generation on the token provided in the stopping criteria.<br>I'm\
          \ using this piece of code<br>class StoppingCriteriaSub(StoppingCriteria):</p>\n\
          <pre><code>def __init__(self, stops = [], encounters=1):\n    super().__init__()\n\
          \    self.stops = [stop.to(\"cuda\") for stop in stops]\n\ndef __call__(self,\
          \ input_ids: torch.LongTensor, scores: torch.FloatTensor):\n    for stop\
          \ in self.stops:\n        if torch.all((stop == input_ids[0][-len(stop):])).item():\n\
          \            return True\n\n    return False\n</code></pre>\n<p>stop_word\
          \ = \"\\n\"<br>stop_word_ids = tokenizer(stop_word, return_tensors='pt')['input_ids']<br>stopping_criteria\
          \ = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_word_ids)])</p>\n\
          <p>It should stop generating at \"\\n\" but that's not working. Any thoughts?<br>output\
          \ = model.generate(<br>        input_ids=model_inputs['input_ids'], attention_mask=model_inputs['attention_mask'],<br>\
          \        max_new_tokens=max_tokens,<br>        num_beams=1,<br>        early_stopping=True,<br>\
          \        temperature=temperature,<br>        stopping_criteria=stopping_criteria)</p>\n"
        raw: "Has anyone tried using stopping criteria in Mistral 0.2 its not stopping\
          \ generation on the token provided in the stopping criteria.\r\nI'm using\
          \ this piece of code\r\nclass StoppingCriteriaSub(StoppingCriteria):\r\n\
          \r\n    def __init__(self, stops = [], encounters=1):\r\n        super().__init__()\r\
          \n        self.stops = [stop.to(\"cuda\") for stop in stops]\r\n\r\n   \
          \ def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\r\
          \n        for stop in self.stops:\r\n            if torch.all((stop == input_ids[0][-len(stop):])).item():\r\
          \n                return True\r\n\r\n        return False\r\n\r\n\r\nstop_word\
          \ = \"\\n\"\r\nstop_word_ids = tokenizer(stop_word, return_tensors='pt')['input_ids']\r\
          \nstopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_word_ids)])\r\
          \n\r\nIt should stop generating at \"\\n\" but that's not working. Any thoughts?\r\
          \noutput = model.generate(\r\n        input_ids=model_inputs['input_ids'],\
          \ attention_mask=model_inputs['attention_mask'],\r\n        max_new_tokens=max_tokens,\r\
          \n        num_beams=1,\r\n        early_stopping=True,\r\n        temperature=temperature,\r\
          \n        stopping_criteria=stopping_criteria)"
        updatedAt: '2023-12-13T08:03:18.598Z'
      numEdits: 0
      reactions: []
    id: 65796546528e89e35f7a3242
    type: comment
  author: asmittal
  content: "Has anyone tried using stopping criteria in Mistral 0.2 its not stopping\
    \ generation on the token provided in the stopping criteria.\r\nI'm using this\
    \ piece of code\r\nclass StoppingCriteriaSub(StoppingCriteria):\r\n\r\n    def\
    \ __init__(self, stops = [], encounters=1):\r\n        super().__init__()\r\n\
    \        self.stops = [stop.to(\"cuda\") for stop in stops]\r\n\r\n    def __call__(self,\
    \ input_ids: torch.LongTensor, scores: torch.FloatTensor):\r\n        for stop\
    \ in self.stops:\r\n            if torch.all((stop == input_ids[0][-len(stop):])).item():\r\
    \n                return True\r\n\r\n        return False\r\n\r\n\r\nstop_word\
    \ = \"\\n\"\r\nstop_word_ids = tokenizer(stop_word, return_tensors='pt')['input_ids']\r\
    \nstopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_word_ids)])\r\
    \n\r\nIt should stop generating at \"\\n\" but that's not working. Any thoughts?\r\
    \noutput = model.generate(\r\n        input_ids=model_inputs['input_ids'], attention_mask=model_inputs['attention_mask'],\r\
    \n        max_new_tokens=max_tokens,\r\n        num_beams=1,\r\n        early_stopping=True,\r\
    \n        temperature=temperature,\r\n        stopping_criteria=stopping_criteria)"
  created_at: 2023-12-13 08:03:18+00:00
  edited: false
  hidden: false
  id: 65796546528e89e35f7a3242
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-13T08:52:32.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8423675894737244
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Make sure you check which token is the one that is generate, and
          which token you are using as a stop token. the <code>\n</code> token that
          is given by  <code>tokenizer(stop_word, return_tensors=''pt'')[''input_ids'']</code>
          is not the same as <code> tokenizer.convert_tokens_to_ids(stop_word)</code>
          because the tokenizer always adds a prefix space. </p>

          '
        raw: 'Make sure you check which token is the one that is generate, and which
          token you are using as a stop token. the `\n` token that is given by  `tokenizer(stop_word,
          return_tensors=''pt'')[''input_ids'']` is not the same as ` tokenizer.convert_tokens_to_ids(stop_word)`
          because the tokenizer always adds a prefix space. '
        updatedAt: '2023-12-13T08:52:32.084Z'
      numEdits: 0
      reactions: []
    id: 657970d09fae206bdfe7248f
    type: comment
  author: ArthurZ
  content: 'Make sure you check which token is the one that is generate, and which
    token you are using as a stop token. the `\n` token that is given by  `tokenizer(stop_word,
    return_tensors=''pt'')[''input_ids'']` is not the same as ` tokenizer.convert_tokens_to_ids(stop_word)`
    because the tokenizer always adds a prefix space. '
  created_at: 2023-12-13 08:52:32+00:00
  edited: false
  hidden: false
  id: 657970d09fae206bdfe7248f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/249a95ae8910ccde4ff41f85fba0b84e.svg
      fullname: Ashish Mittal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: asmittal
      type: user
    createdAt: '2023-12-13T10:27:29.000Z'
    data:
      edited: false
      editors:
      - asmittal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8172659873962402
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/249a95ae8910ccde4ff41f85fba0b84e.svg
          fullname: Ashish Mittal
          isHf: false
          isPro: false
          name: asmittal
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ArthurZ&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ArthurZ\">@<span class=\"\
          underline\">ArthurZ</span></a></span>\n\n\t</span></span> But this same\
          \ code works with Falcon7b Instruct model</p>\n"
        raw: '@ArthurZ But this same code works with Falcon7b Instruct model'
        updatedAt: '2023-12-13T10:27:29.221Z'
      numEdits: 0
      reactions: []
    id: 65798711479c85a20f6a71b7
    type: comment
  author: asmittal
  content: '@ArthurZ But this same code works with Falcon7b Instruct model'
  created_at: 2023-12-13 10:27:29+00:00
  edited: false
  hidden: false
  id: 65798711479c85a20f6a71b7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/249a95ae8910ccde4ff41f85fba0b84e.svg
      fullname: Ashish Mittal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: asmittal
      type: user
    createdAt: '2023-12-13T11:03:18.000Z'
    data:
      edited: false
      editors:
      - asmittal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6755384206771851
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/249a95ae8910ccde4ff41f85fba0b84e.svg
          fullname: Ashish Mittal
          isHf: false
          isPro: false
          name: asmittal
          type: user
        html: '<p>tokenizer.convert_tokens_to_ids(stop_word) this just gives zero
          as output for every token</p>

          '
        raw: tokenizer.convert_tokens_to_ids(stop_word) this just gives zero as output
          for every token
        updatedAt: '2023-12-13T11:03:18.016Z'
      numEdits: 0
      reactions: []
    id: 65798f768ee8830a31db0074
    type: comment
  author: asmittal
  content: tokenizer.convert_tokens_to_ids(stop_word) this just gives zero as output
    for every token
  created_at: 2023-12-13 11:03:18+00:00
  edited: false
  hidden: false
  id: 65798f768ee8830a31db0074
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: mistralai/Mistral-7B-Instruct-v0.2
repo_type: model
status: open
target_branch: null
title: Stopping Criteria Not Working
