!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jgsmcmahon
conflicting_files: null
created_at: 2023-12-12 20:35:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6363dff12e11f41bc8198114/ij92iaoWH9Xb4MOcauMe4.png?w=200&h=200&f=face
      fullname: Jason McMahon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jgsmcmahon
      type: user
    createdAt: '2023-12-12T20:35:23.000Z'
    data:
      edited: false
      editors:
      - jgsmcmahon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9069467186927795
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6363dff12e11f41bc8198114/ij92iaoWH9Xb4MOcauMe4.png?w=200&h=200&f=face
          fullname: Jason McMahon
          isHf: false
          isPro: false
          name: jgsmcmahon
          type: user
        html: '<p>MSG appears at Inference : The attention mask and the pad token
          id were not set. As a consequence, you may observe unexpected behavior.
          Please pass your input''s <code>attention_mask</code> to obtain reliable
          results. Setting <code>pad_token_id</code> to <code>eos_token_id</code>:2
          for open-end generation.</p>

          <p>Please let me know what I need to do to get past this issue ? Many thanks
          :-) </p>

          '
        raw: "MSG appears at Inference : The attention mask and the pad token id were\
          \ not set. As a consequence, you may observe unexpected behavior. Please\
          \ pass your input's `attention_mask` to obtain reliable results. Setting\
          \ `pad_token_id` to `eos_token_id`:2 for open-end generation.\r\n\r\nPlease\
          \ let me know what I need to do to get past this issue ? Many thanks :-) "
        updatedAt: '2023-12-12T20:35:23.956Z'
      numEdits: 0
      reactions: []
    id: 6578c40b491d8cc576eb0f94
    type: comment
  author: jgsmcmahon
  content: "MSG appears at Inference : The attention mask and the pad token id were\
    \ not set. As a consequence, you may observe unexpected behavior. Please pass\
    \ your input's `attention_mask` to obtain reliable results. Setting `pad_token_id`\
    \ to `eos_token_id`:2 for open-end generation.\r\n\r\nPlease let me know what\
    \ I need to do to get past this issue ? Many thanks :-) "
  created_at: 2023-12-12 20:35:23+00:00
  edited: false
  hidden: false
  id: 6578c40b491d8cc576eb0f94
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-13T09:05:28.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4174345135688782
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Just pass the full inputs from the tokenizer. <code>inputs = tokenizer(["Hey
          how are you?"], [''Good''], padding = True)</code> will return the attention
          mask. But if there is no padding token you should specify <code>tokenizer.pad_token
          = tokenizer.eos_token</code></p>

          '
        raw: Just pass the full inputs from the tokenizer. `inputs = tokenizer(["Hey
          how are you?"], ['Good'], padding = True)` will return the attention mask.
          But if there is no padding token you should specify `tokenizer.pad_token
          = tokenizer.eos_token`
        updatedAt: '2023-12-13T09:05:28.308Z'
      numEdits: 0
      reactions: []
    id: 657973d8ee33d547ae0043ee
    type: comment
  author: ArthurZ
  content: Just pass the full inputs from the tokenizer. `inputs = tokenizer(["Hey
    how are you?"], ['Good'], padding = True)` will return the attention mask. But
    if there is no padding token you should specify `tokenizer.pad_token = tokenizer.eos_token`
  created_at: 2023-12-13 09:05:28+00:00
  edited: false
  hidden: false
  id: 657973d8ee33d547ae0043ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6363dff12e11f41bc8198114/ij92iaoWH9Xb4MOcauMe4.png?w=200&h=200&f=face
      fullname: Jason McMahon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jgsmcmahon
      type: user
    createdAt: '2023-12-14T13:36:21.000Z'
    data:
      edited: false
      editors:
      - jgsmcmahon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9120744466781616
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6363dff12e11f41bc8198114/ij92iaoWH9Xb4MOcauMe4.png?w=200&h=200&f=face
          fullname: Jason McMahon
          isHf: false
          isPro: false
          name: jgsmcmahon
          type: user
        html: '<p>Ok thanks will try this :-)  </p>

          '
        raw: 'Ok thanks will try this :-)  '
        updatedAt: '2023-12-14T13:36:21.898Z'
      numEdits: 0
      reactions: []
    id: 657b04d5fcba5f698c009738
    type: comment
  author: jgsmcmahon
  content: 'Ok thanks will try this :-)  '
  created_at: 2023-12-14 13:36:21+00:00
  edited: false
  hidden: false
  id: 657b04d5fcba5f698c009738
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6e6bf3f9c41a409c5d8bdfcb4e16723d.svg
      fullname: John Barnes
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jabarne6
      type: user
    createdAt: '2023-12-17T18:23:07.000Z'
    data:
      edited: false
      editors:
      - jabarne6
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.34687429666519165
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6e6bf3f9c41a409c5d8bdfcb4e16723d.svg
          fullname: John Barnes
          isHf: false
          isPro: false
          name: jabarne6
          type: user
        html: "<p>Add this after loading in the tokenizer from pretrained:</p>\n<pre><code>if\
          \ tokenizer.pad_token is None:\n            tokenizer.pad_token = tokenizer.eos_token\n\
          </code></pre>\n<p>And then change the generate line to this:</p>\n<pre><code>generated_ids\
          \ = model.generate(model_inputs, pad_token_id=tokenizer.pad_token_id, max_new_tokens=2000,\
          \ do_sample=True)\n</code></pre>\n"
        raw: "Add this after loading in the tokenizer from pretrained:\n\n```\nif\
          \ tokenizer.pad_token is None:\n            tokenizer.pad_token = tokenizer.eos_token\n\
          ```\n\nAnd then change the generate line to this:\n```\ngenerated_ids =\
          \ model.generate(model_inputs, pad_token_id=tokenizer.pad_token_id, max_new_tokens=2000,\
          \ do_sample=True)\n```\n"
        updatedAt: '2023-12-17T18:23:07.394Z'
      numEdits: 0
      reactions: []
    id: 657f3c8ba575d54a1e90540d
    type: comment
  author: jabarne6
  content: "Add this after loading in the tokenizer from pretrained:\n\n```\nif tokenizer.pad_token\
    \ is None:\n            tokenizer.pad_token = tokenizer.eos_token\n```\n\nAnd\
    \ then change the generate line to this:\n```\ngenerated_ids = model.generate(model_inputs,\
    \ pad_token_id=tokenizer.pad_token_id, max_new_tokens=2000, do_sample=True)\n\
    ```\n"
  created_at: 2023-12-17 18:23:07+00:00
  edited: false
  hidden: false
  id: 657f3c8ba575d54a1e90540d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: mistralai/Mistral-7B-Instruct-v0.2
repo_type: model
status: open
target_branch: null
title: How to set the attention mask  for  inference ?
