!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yardenhoch
conflicting_files: null
created_at: 2023-12-20 08:43:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dccba59060ce07efab212454077a9bc0.svg
      fullname: Yarden Hochenberg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yardenhoch
      type: user
    createdAt: '2023-12-20T08:43:41.000Z'
    data:
      edited: false
      editors:
      - yardenhoch
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9235733151435852
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dccba59060ce07efab212454077a9bc0.svg
          fullname: Yarden Hochenberg
          isHf: false
          isPro: false
          name: yardenhoch
          type: user
        html: '<p>Hello,</p>

          <p>I''m currently working on fine-tuning the Mistral-7B-Instruct-v0.2 model
          and I have a question regarding the use of [INST] tokens in the prompts.</p>

          <p>In my project, I''m using a custom prompt structure that includes an
          instruction followed by a "HUMAN: " and "AI: " format. This differs from
          the one provided in the instruction format, which uses the [INST] and [/INST]
          tokens.</p>

          <p>Given this, I''m curious about the motivation behind adding [INST] to
          the prompt. Is it a must to use these tokens even if my prompts are structured
          differently? As I''m doing fine-tuning for the model, I''m wondering if
          it''s still necessary to add the [INST] tokens or if there''s a way to adapt
          this to my custom prompt structure.</p>

          <p>Thank you in advance for your guidance.</p>

          '
        raw: "Hello,\r\n\r\nI'm currently working on fine-tuning the Mistral-7B-Instruct-v0.2\
          \ model and I have a question regarding the use of [INST] tokens in the\
          \ prompts.\r\n\r\nIn my project, I'm using a custom prompt structure that\
          \ includes an instruction followed by a \"HUMAN: <question>\" and \"AI:\
          \ <response>\" format. This differs from the one provided in the instruction\
          \ format, which uses the [INST] and [/INST] tokens.\r\n\r\nGiven this, I'm\
          \ curious about the motivation behind adding [INST] to the prompt. Is it\
          \ a must to use these tokens even if my prompts are structured differently?\
          \ As I'm doing fine-tuning for the model, I'm wondering if it's still necessary\
          \ to add the [INST] tokens or if there's a way to adapt this to my custom\
          \ prompt structure.\r\n\r\nThank you in advance for your guidance."
        updatedAt: '2023-12-20T08:43:41.707Z'
      numEdits: 0
      reactions: []
    id: 6582a93dc9ead70193cd8571
    type: comment
  author: yardenhoch
  content: "Hello,\r\n\r\nI'm currently working on fine-tuning the Mistral-7B-Instruct-v0.2\
    \ model and I have a question regarding the use of [INST] tokens in the prompts.\r\
    \n\r\nIn my project, I'm using a custom prompt structure that includes an instruction\
    \ followed by a \"HUMAN: <question>\" and \"AI: <response>\" format. This differs\
    \ from the one provided in the instruction format, which uses the [INST] and [/INST]\
    \ tokens.\r\n\r\nGiven this, I'm curious about the motivation behind adding [INST]\
    \ to the prompt. Is it a must to use these tokens even if my prompts are structured\
    \ differently? As I'm doing fine-tuning for the model, I'm wondering if it's still\
    \ necessary to add the [INST] tokens or if there's a way to adapt this to my custom\
    \ prompt structure.\r\n\r\nThank you in advance for your guidance."
  created_at: 2023-12-20 08:43:41+00:00
  edited: false
  hidden: false
  id: 6582a93dc9ead70193cd8571
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 26
repo_id: mistralai/Mistral-7B-Instruct-v0.2
repo_type: model
status: open
target_branch: null
title: Use of [INST] Tokens in Fine-Tuning with Custom Prompt Structure
