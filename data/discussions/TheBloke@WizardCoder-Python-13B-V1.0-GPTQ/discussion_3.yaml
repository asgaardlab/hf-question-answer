!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Rohith1016
conflicting_files: null
created_at: 2023-11-09 12:22:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/214f490ef5705cde7a1f68df55d65388.svg
      fullname: RohithVaddeti
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Rohith1016
      type: user
    createdAt: '2023-11-09T12:22:54.000Z'
    data:
      edited: false
      editors:
      - Rohith1016
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4086764454841614
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/214f490ef5705cde7a1f68df55d65388.svg
          fullname: RohithVaddeti
          isHf: false
          isPro: false
          name: Rohith1016
          type: user
        html: '<p>Getting Error while downloading the Model<br>ImportError: libcudart.so.12:
          cannot open shared object file: No such file or directory</p>

          <hr>

          <p>ImportError                               Traceback (most recent call
          last)<br> in &lt;cell line: 6&gt;()<br>      4 # To use a different branch,
          change revision<br>      5 # For example: revision="main"<br>----&gt; 6
          model = AutoModelForCausalLM.from_pretrained(model_name_or_path,<br>      7                                              device_map="auto",<br>      8                                              trust_remote_code=False,</p>

          <p>6 frames<br>/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py
          in <br>     12<br>     13 try:<br>---&gt; 14     from exllama_kernels import
          make_q4, q4_matmul<br>     15 except ImportError:<br>     16     logger.error(''exllama_kernels
          not installed.'')</p>

          <p>ImportError: libcudart.so.12: cannot open shared object file: No such
          file or directory</p>

          <hr>

          '
        raw: "Getting Error while downloading the Model\r\nImportError: libcudart.so.12:\
          \ cannot open shared object file: No such file or directory\r\n\r\n---------------------------------------------------------------------------\r\
          \nImportError                               Traceback (most recent call\
          \ last)\r\n<ipython-input-2-b8b2c049a025> in <cell line: 6>()\r\n      4\
          \ # To use a different branch, change revision\r\n      5 # For example:\
          \ revision=\"main\"\r\n----> 6 model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\r\
          \n      7                                              device_map=\"auto\"\
          ,\r\n      8                                              trust_remote_code=False,\r\
          \n\r\n6 frames\r\n/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py\
          \ in <module>\r\n     12 \r\n     13 try:\r\n---> 14     from exllama_kernels\
          \ import make_q4, q4_matmul\r\n     15 except ImportError:\r\n     16  \
          \   logger.error('exllama_kernels not installed.')\r\n\r\nImportError: libcudart.so.12:\
          \ cannot open shared object file: No such file or directory\r\n\r\n---------------------------------------------------------------------------"
        updatedAt: '2023-11-09T12:22:54.896Z'
      numEdits: 0
      reactions: []
    id: 654ccf1e5cf343edfe6f4a91
    type: comment
  author: Rohith1016
  content: "Getting Error while downloading the Model\r\nImportError: libcudart.so.12:\
    \ cannot open shared object file: No such file or directory\r\n\r\n---------------------------------------------------------------------------\r\
    \nImportError                               Traceback (most recent call last)\r\
    \n<ipython-input-2-b8b2c049a025> in <cell line: 6>()\r\n      4 # To use a different\
    \ branch, change revision\r\n      5 # For example: revision=\"main\"\r\n---->\
    \ 6 model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\r\n     \
    \ 7                                              device_map=\"auto\",\r\n    \
    \  8                                              trust_remote_code=False,\r\n\
    \r\n6 frames\r\n/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/qlinear/qlinear_exllama.py\
    \ in <module>\r\n     12 \r\n     13 try:\r\n---> 14     from exllama_kernels\
    \ import make_q4, q4_matmul\r\n     15 except ImportError:\r\n     16     logger.error('exllama_kernels\
    \ not installed.')\r\n\r\nImportError: libcudart.so.12: cannot open shared object\
    \ file: No such file or directory\r\n\r\n---------------------------------------------------------------------------"
  created_at: 2023-11-09 12:22:54+00:00
  edited: false
  hidden: false
  id: 654ccf1e5cf343edfe6f4a91
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-09T12:24:13.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7735685110092163
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>The default pre-built wheels for 0.5.0 now use PyTorch 2.1 and CUDA
          12.1.</p>

          <p>If you have CUDA 11.8, you can install AutoGPTQ for PyTorch 2.1 and CUDA
          11.8 with:</p>

          <pre><code>pip3 uninstall -y auto-gptq

          pip3 install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/

          </code></pre>

          <p>But you''ll still need PyTorch 2.1.  If you want to use PyTorch 2.0.1,
          then you can either build AutoGPTQ 0.5.0 from source, or downgrade to AutoGPTQ
          0.4.2.</p>

          '
        raw: 'The default pre-built wheels for 0.5.0 now use PyTorch 2.1 and CUDA
          12.1.


          If you have CUDA 11.8, you can install AutoGPTQ for PyTorch 2.1 and CUDA
          11.8 with:


          ```

          pip3 uninstall -y auto-gptq

          pip3 install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/

          ```


          But you''ll still need PyTorch 2.1.  If you want to use PyTorch 2.0.1, then
          you can either build AutoGPTQ 0.5.0 from source, or downgrade to AutoGPTQ
          0.4.2.'
        updatedAt: '2023-11-09T12:25:42.063Z'
      numEdits: 2
      reactions: []
    id: 654ccf6d1026dadbc9fd5bc3
    type: comment
  author: TheBloke
  content: 'The default pre-built wheels for 0.5.0 now use PyTorch 2.1 and CUDA 12.1.


    If you have CUDA 11.8, you can install AutoGPTQ for PyTorch 2.1 and CUDA 11.8
    with:


    ```

    pip3 uninstall -y auto-gptq

    pip3 install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/

    ```


    But you''ll still need PyTorch 2.1.  If you want to use PyTorch 2.0.1, then you
    can either build AutoGPTQ 0.5.0 from source, or downgrade to AutoGPTQ 0.4.2.'
  created_at: 2023-11-09 12:24:13+00:00
  edited: true
  hidden: false
  id: 654ccf6d1026dadbc9fd5bc3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/214f490ef5705cde7a1f68df55d65388.svg
      fullname: RohithVaddeti
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Rohith1016
      type: user
    createdAt: '2023-11-09T13:05:37.000Z'
    data:
      edited: true
      editors:
      - Rohith1016
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3784717917442322
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/214f490ef5705cde7a1f68df55d65388.svg
          fullname: RohithVaddeti
          isHf: false
          isPro: false
          name: Rohith1016
          type: user
        html: '<p>Thank You for Your Response .</p>

          '
        raw: Thank You for Your Response .
        updatedAt: '2023-11-09T13:15:48.391Z'
      numEdits: 2
      reactions: []
    id: 654cd9211ed5dca1fb4caa60
    type: comment
  author: Rohith1016
  content: Thank You for Your Response .
  created_at: 2023-11-09 13:05:37+00:00
  edited: true
  hidden: false
  id: 654cd9211ed5dca1fb4caa60
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/WizardCoder-Python-13B-V1.0-GPTQ
repo_type: model
status: open
target_branch: null
title: 'ImportError: libcudart.so.12: cannot open shared object file: No such file
  or directory'
