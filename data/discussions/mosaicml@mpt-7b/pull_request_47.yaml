!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abhi-mosaic
conflicting_files: []
created_at: 2023-06-02 04:02:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-02T04:52:59.000Z'
    data:
      oid: 9e929f5c88820b2445ba3cc8a81ace3c33118c80
      parents:
      - 053e1a33a6e7043aefaa3f5d13c48269a5511cff
      subject: init
    id: 647975ab0000000000000000
    type: commit
  author: abhi-mosaic
  created_at: 2023-06-02 03:52:59+00:00
  id: 647975ab0000000000000000
  oid: 9e929f5c88820b2445ba3cc8a81ace3c33118c80
  summary: init
  type: commit
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-02T04:58:16.000Z'
    data:
      oid: b72c1cd182a352b74aca998c6cbda109bdee0e3d
      parents:
      - 9e929f5c88820b2445ba3cc8a81ace3c33118c80
      subject: add requirements.txt
    id: 647976e80000000000000000
    type: commit
  author: abhi-mosaic
  created_at: 2023-06-02 03:58:16+00:00
  id: 647976e80000000000000000
  oid: b72c1cd182a352b74aca998c6cbda109bdee0e3d
  summary: add requirements.txt
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-02T05:02:27.000Z'
    data:
      edited: true
      editors:
      - abhi-mosaic
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
          fullname: Abhi Venigalla
          isHf: false
          isPro: false
          name: abhi-mosaic
          type: user
        html: '<p>This PR adds updates from the LLM Foundry repo as of 06/01/2023.</p>

          <p>These include:</p>

          <ul>

          <li><code>device_map</code> support for multiple GPUs</li>

          <li>faster inference thanks to a refactor of the KV cacheing</li>

          <li>bugfix for returning the last hidden_state</li>

          <li>support for <code>output_attentions</code> when using <code>attn_impl:
          torch</code></li>

          <li>a <code>requirements.txt</code> file to make it easier to know what
          you need to install for MPT</li>

          <li>updated README instructions for fast GPU initialization</li>

          </ul>

          '
        raw: 'This PR adds updates from the LLM Foundry repo as of 06/01/2023.


          These include:


          * `device_map` support for multiple GPUs

          * faster inference thanks to a refactor of the KV cacheing

          * bugfix for returning the last hidden_state

          * support for `output_attentions` when using `attn_impl: torch`

          * a `requirements.txt` file to make it easier to know what you need to install
          for MPT

          * updated README instructions for fast GPU initialization'
        updatedAt: '2023-06-02T05:37:31.727Z'
      numEdits: 4
      reactions: []
    id: 647977e3ba447930a600c259
    type: comment
  author: abhi-mosaic
  content: 'This PR adds updates from the LLM Foundry repo as of 06/01/2023.


    These include:


    * `device_map` support for multiple GPUs

    * faster inference thanks to a refactor of the KV cacheing

    * bugfix for returning the last hidden_state

    * support for `output_attentions` when using `attn_impl: torch`

    * a `requirements.txt` file to make it easier to know what you need to install
    for MPT

    * updated README instructions for fast GPU initialization'
  created_at: 2023-06-02 04:02:27+00:00
  edited: true
  hidden: false
  id: 647977e3ba447930a600c259
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-02T05:28:37.000Z'
    data:
      oid: 1975e8d36a2cf623e5f36c51146c9615633cf447
      parents:
      - b72c1cd182a352b74aca998c6cbda109bdee0e3d
      subject: update README
    id: 64797e050000000000000000
    type: commit
  author: abhi-mosaic
  created_at: 2023-06-02 04:28:37+00:00
  id: 64797e050000000000000000
  oid: 1975e8d36a2cf623e5f36c51146c9615633cf447
  summary: update README
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-02T05:31:23.000Z'
    data:
      status: open
    id: 64797eab8c0a0bb3b1fb2e52
    type: status-change
  author: abhi-mosaic
  created_at: 2023-06-02 04:31:23+00:00
  id: 64797eab8c0a0bb3b1fb2e52
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676407968549-63dd38e5a8877129a15a12c5.png?w=200&h=200&f=face
      fullname: Jacob Portes
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jacobfulano
      type: user
    createdAt: '2023-06-02T23:37:46.000Z'
    data:
      edited: true
      editors:
      - jacobfulano
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5898665189743042
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676407968549-63dd38e5a8877129a15a12c5.png?w=200&h=200&f=face
          fullname: Jacob Portes
          isHf: false
          isPro: false
          name: jacobfulano
          type: user
        html: "<p>Confirming that this seems to play nicely with <code>load_in_8bit=True</code>\
          \ on google colab with higher system RAM (&gt;13GB) than the standard tier</p>\n\
          <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer\n\
          \nmodel_name = 'mosaicml/mpt-7b'\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    model_name, \n    load_in_8bit=True,\n    device_map=\"auto\",\n  \
          \  trust_remote_code=True,\n    revision=\"pr/47\"\n)\n</code></pre>\n<p><a\
          \ rel=\"nofollow\" href=\"https://colab.research.google.com/drive/1-1n2UvrU47UOcWGlgeIuhi2Vi0u7OW5F?usp=sharing\"\
          >https://colab.research.google.com/drive/1-1n2UvrU47UOcWGlgeIuhi2Vi0u7OW5F?usp=sharing</a></p>\n"
        raw: "Confirming that this seems to play nicely with `load_in_8bit=True` on\
          \ google colab with higher system RAM (>13GB) than the standard tier\n\n\
          ```\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name\
          \ = 'mosaicml/mpt-7b'\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    model_name, \n    load_in_8bit=True,\n    device_map=\"auto\",\n  \
          \  trust_remote_code=True,\n    revision=\"pr/47\"\n)\n```\n\nhttps://colab.research.google.com/drive/1-1n2UvrU47UOcWGlgeIuhi2Vi0u7OW5F?usp=sharing"
        updatedAt: '2023-06-02T23:38:54.630Z'
      numEdits: 2
      reactions: []
    id: 647a7d4ac7367455fda13298
    type: comment
  author: jacobfulano
  content: "Confirming that this seems to play nicely with `load_in_8bit=True` on\
    \ google colab with higher system RAM (>13GB) than the standard tier\n\n```\n\
    from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = 'mosaicml/mpt-7b'\n\
    \nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name, \n    load_in_8bit=True,\n\
    \    device_map=\"auto\",\n    trust_remote_code=True,\n    revision=\"pr/47\"\
    \n)\n```\n\nhttps://colab.research.google.com/drive/1-1n2UvrU47UOcWGlgeIuhi2Vi0u7OW5F?usp=sharing"
  created_at: 2023-06-02 22:37:46+00:00
  edited: true
  hidden: false
  id: 647a7d4ac7367455fda13298
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-02T23:45:00.000Z'
    data:
      status: merged
    id: 647a7efc822b7e8ccbdbf2cc
    type: status-change
  author: abhi-mosaic
  created_at: 2023-06-02 22:45:00+00:00
  id: 647a7efc822b7e8ccbdbf2cc
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 68e1a8e0ebb9b30f3c45c1ef6195980f29063ae2
num: 47
repo_id: mosaicml/mpt-7b
repo_type: model
status: merged
target_branch: refs/heads/main
title: LLM Foundry Updates 06-01-2023
