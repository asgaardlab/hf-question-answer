!!python/object:huggingface_hub.community.DiscussionWithDetails
author: RonanMcGovern
conflicting_files: null
created_at: 2023-07-14 08:31:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-07-14T09:31:30.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9318981170654297
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>I''ve been trying to get this to run on google collab pro (crashes
          due to memory), kaggle (trouble importing).</p>

          <p>Sagemaker seems to load if I use a large general purpose instance (8
          cores, 64 GB), but is really slow to start generating tokens.</p>

          <p>Could someone recommend a config and instance type for sagemaker, for
          this 7B and also 30B. Appreciate further if there is a different recc if
          I start increasing sequence length.</p>

          '
        raw: "I've been trying to get this to run on google collab pro (crashes due\
          \ to memory), kaggle (trouble importing).\r\n\r\nSagemaker seems to load\
          \ if I use a large general purpose instance (8 cores, 64 GB), but is really\
          \ slow to start generating tokens.\r\n\r\nCould someone recommend a config\
          \ and instance type for sagemaker, for this 7B and also 30B. Appreciate\
          \ further if there is a different recc if I start increasing sequence length."
        updatedAt: '2023-07-14T09:31:30.788Z'
      numEdits: 0
      reactions: []
    id: 64b115f2102ed6e7aeb10d07
    type: comment
  author: RonanMcGovern
  content: "I've been trying to get this to run on google collab pro (crashes due\
    \ to memory), kaggle (trouble importing).\r\n\r\nSagemaker seems to load if I\
    \ use a large general purpose instance (8 cores, 64 GB), but is really slow to\
    \ start generating tokens.\r\n\r\nCould someone recommend a config and instance\
    \ type for sagemaker, for this 7B and also 30B. Appreciate further if there is\
    \ a different recc if I start increasing sequence length."
  created_at: 2023-07-14 08:31:30+00:00
  edited: false
  hidden: false
  id: 64b115f2102ed6e7aeb10d07
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-07-19T12:14:31.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5999284386634827
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>Related answer here: <a rel="nofollow" href="https://discuss.huggingface.co/t/recommend-an-instance-for-mpt-7b-and-mpt-30b-inference/46722/2">https://discuss.huggingface.co/t/recommend-an-instance-for-mpt-7b-and-mpt-30b-inference/46722/2</a></p>

          <p>So closing this</p>

          '
        raw: 'Related answer here: https://discuss.huggingface.co/t/recommend-an-instance-for-mpt-7b-and-mpt-30b-inference/46722/2


          So closing this'
        updatedAt: '2023-07-19T12:14:31.437Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64b7d3a79ebb7e6c7de46333
    id: 64b7d3a79ebb7e6c7de46331
    type: comment
  author: RonanMcGovern
  content: 'Related answer here: https://discuss.huggingface.co/t/recommend-an-instance-for-mpt-7b-and-mpt-30b-inference/46722/2


    So closing this'
  created_at: 2023-07-19 11:14:31+00:00
  edited: false
  hidden: false
  id: 64b7d3a79ebb7e6c7de46331
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-07-19T12:14:31.000Z'
    data:
      status: closed
    id: 64b7d3a79ebb7e6c7de46333
    type: status-change
  author: RonanMcGovern
  created_at: 2023-07-19 11:14:31+00:00
  id: 64b7d3a79ebb7e6c7de46333
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 78
repo_id: mosaicml/mpt-7b
repo_type: model
status: closed
target_branch: null
title: Sagemaker Recommended Config and Instances
