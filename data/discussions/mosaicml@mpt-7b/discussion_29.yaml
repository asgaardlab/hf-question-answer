!!python/object:huggingface_hub.community.DiscussionWithDetails
author: airtable
conflicting_files: null
created_at: 2023-05-19 01:51:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/62ec05a0857bc02b8d060e2c71b8eb53.svg
      fullname: Air Table
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: airtable
      type: user
    createdAt: '2023-05-19T02:51:22.000Z'
    data:
      edited: false
      editors:
      - airtable
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/62ec05a0857bc02b8d060e2c71b8eb53.svg
          fullname: Air Table
          isHf: false
          isPro: false
          name: airtable
          type: user
        html: '<p>Hi there</p>

          <p>I previously used dolly-v2-3b and dolly-v2-7b to try and generate long
          text but it kept regenerating the same text over and over.</p>

          <p>My scenario is that I need to find relevant documents using FAISS vector
          search where k=10/k=20 etc and expect model to generate similar documents
          using Prompt with data given in the prompt.</p>

          <p>Can I use MPT-7b to generate this type of document with long context
          on a single GPU Azure cloud instance?</p>

          <p>VM Size<br>Standard_NC6 (6 cores, 56 GB RAM, 380 GB disk) With Nvidia
          K80 GPU</p>

          '
        raw: "Hi there\r\n\r\nI previously used dolly-v2-3b and dolly-v2-7b to try\
          \ and generate long text but it kept regenerating the same text over and\
          \ over.\r\n\r\nMy scenario is that I need to find relevant documents using\
          \ FAISS vector search where k=10/k=20 etc and expect model to generate similar\
          \ documents using Prompt with data given in the prompt.\r\n\r\nCan I use\
          \ MPT-7b to generate this type of document with long context on a single\
          \ GPU Azure cloud instance?\r\n\r\nVM Size\r\nStandard_NC6 (6 cores, 56\
          \ GB RAM, 380 GB disk) With Nvidia K80 GPU"
        updatedAt: '2023-05-19T02:51:22.946Z'
      numEdits: 0
      reactions: []
    id: 6466e42ae291c33d58875768
    type: comment
  author: airtable
  content: "Hi there\r\n\r\nI previously used dolly-v2-3b and dolly-v2-7b to try and\
    \ generate long text but it kept regenerating the same text over and over.\r\n\
    \r\nMy scenario is that I need to find relevant documents using FAISS vector search\
    \ where k=10/k=20 etc and expect model to generate similar documents using Prompt\
    \ with data given in the prompt.\r\n\r\nCan I use MPT-7b to generate this type\
    \ of document with long context on a single GPU Azure cloud instance?\r\n\r\n\
    VM Size\r\nStandard_NC6 (6 cores, 56 GB RAM, 380 GB disk) With Nvidia K80 GPU"
  created_at: 2023-05-19 01:51:22+00:00
  edited: false
  hidden: false
  id: 6466e42ae291c33d58875768
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
      fullname: Sam Havens
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sam-mosaic
      type: user
    createdAt: '2023-05-23T05:04:06.000Z'
    data:
      edited: false
      editors:
      - sam-mosaic
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
          fullname: Sam Havens
          isHf: false
          isPro: false
          name: sam-mosaic
          type: user
        html: '<p>The model should fit onto a k80. You''ll need to use standard torch
          attention. If you instantiate the model with <code>max_seq_len=4096</code>
          you should be able to get sequences twice as long as the dolly models you
          were trying.</p>

          <p>Depending on the type of documents this could work? Really depends how
          similar the task is to pretraining data.</p>

          <p>If you get repetitive output, try searching for a good <code>no_repeat_ngram_size</code>
          (somewhere between 3-9) and <code>repetition_penalty</code>(somewhere between
          1.01 and 1.2), as well as increasing the temperature.</p>

          '
        raw: 'The model should fit onto a k80. You''ll need to use standard torch
          attention. If you instantiate the model with `max_seq_len=4096` you should
          be able to get sequences twice as long as the dolly models you were trying.


          Depending on the type of documents this could work? Really depends how similar
          the task is to pretraining data.


          If you get repetitive output, try searching for a good `no_repeat_ngram_size`
          (somewhere between 3-9) and `repetition_penalty`(somewhere between 1.01
          and 1.2), as well as increasing the temperature.'
        updatedAt: '2023-05-23T05:04:06.150Z'
      numEdits: 0
      reactions: []
      relatedEventId: 646c4946ed228272134c2d61
    id: 646c4946ed228272134c2d60
    type: comment
  author: sam-mosaic
  content: 'The model should fit onto a k80. You''ll need to use standard torch attention.
    If you instantiate the model with `max_seq_len=4096` you should be able to get
    sequences twice as long as the dolly models you were trying.


    Depending on the type of documents this could work? Really depends how similar
    the task is to pretraining data.


    If you get repetitive output, try searching for a good `no_repeat_ngram_size`
    (somewhere between 3-9) and `repetition_penalty`(somewhere between 1.01 and 1.2),
    as well as increasing the temperature.'
  created_at: 2023-05-23 04:04:06+00:00
  edited: false
  hidden: false
  id: 646c4946ed228272134c2d60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
      fullname: Sam Havens
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sam-mosaic
      type: user
    createdAt: '2023-05-23T05:04:06.000Z'
    data:
      status: closed
    id: 646c4946ed228272134c2d61
    type: status-change
  author: sam-mosaic
  created_at: 2023-05-23 04:04:06+00:00
  id: 646c4946ed228272134c2d61
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/62ec05a0857bc02b8d060e2c71b8eb53.svg
      fullname: Air Table
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: airtable
      type: user
    createdAt: '2023-05-24T04:11:11.000Z'
    data:
      edited: false
      editors:
      - airtable
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/62ec05a0857bc02b8d060e2c71b8eb53.svg
          fullname: Air Table
          isHf: false
          isPro: false
          name: airtable
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;sam-mosaic&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sam-mosaic\"\
          >@<span class=\"underline\">sam-mosaic</span></a></span>\n\n\t</span></span>,\
          \ appreciate your response, I will try to see how to configure these settings\
          \ and try again</p>\n"
        raw: Thanks @sam-mosaic, appreciate your response, I will try to see how to
          configure these settings and try again
        updatedAt: '2023-05-24T04:11:11.544Z'
      numEdits: 0
      reactions: []
      relatedEventId: 646d8e5f2abe5323fe2b1b49
    id: 646d8e5f2abe5323fe2b1b48
    type: comment
  author: airtable
  content: Thanks @sam-mosaic, appreciate your response, I will try to see how to
    configure these settings and try again
  created_at: 2023-05-24 03:11:11+00:00
  edited: false
  hidden: false
  id: 646d8e5f2abe5323fe2b1b48
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/62ec05a0857bc02b8d060e2c71b8eb53.svg
      fullname: Air Table
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: airtable
      type: user
    createdAt: '2023-05-24T04:11:11.000Z'
    data:
      status: open
    id: 646d8e5f2abe5323fe2b1b49
    type: status-change
  author: airtable
  created_at: 2023-05-24 03:11:11+00:00
  id: 646d8e5f2abe5323fe2b1b49
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-03T01:29:32.000Z'
    data:
      edited: false
      editors:
      - abhi-mosaic
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9929845929145813
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
          fullname: Abhi Venigalla
          isHf: false
          isPro: false
          name: abhi-mosaic
          type: user
        html: '<p>Closing for now as this issue has gone stale</p>

          '
        raw: Closing for now as this issue has gone stale
        updatedAt: '2023-06-03T01:29:32.887Z'
      numEdits: 0
      reactions: []
      relatedEventId: 647a977cc7367455fda47270
    id: 647a977cc7367455fda47268
    type: comment
  author: abhi-mosaic
  content: Closing for now as this issue has gone stale
  created_at: 2023-06-03 00:29:32+00:00
  edited: false
  hidden: false
  id: 647a977cc7367455fda47268
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-03T01:29:32.000Z'
    data:
      status: closed
    id: 647a977cc7367455fda47270
    type: status-change
  author: abhi-mosaic
  created_at: 2023-06-03 00:29:32+00:00
  id: 647a977cc7367455fda47270
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 29
repo_id: mosaicml/mpt-7b
repo_type: model
status: closed
target_branch: null
title: Running on single Nvidia K80 GPU with large context to generate long output
