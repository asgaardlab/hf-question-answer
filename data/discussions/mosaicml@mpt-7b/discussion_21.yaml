!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TheronSnow
conflicting_files: null
created_at: 2023-05-15 15:12:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/84970aff649b51800f785ead40278d73.svg
      fullname: Christian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheronSnow
      type: user
    createdAt: '2023-05-15T16:12:08.000Z'
    data:
      edited: false
      editors:
      - TheronSnow
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/84970aff649b51800f785ead40278d73.svg
          fullname: Christian
          isHf: false
          isPro: false
          name: TheronSnow
          type: user
        html: '<p>Hello, I would like to use this model, however I am new to this
          and I do not know if I would be able to use the model with an i7-1165G7
          2.80 GHz with 16 GB RAM in total. Thanks for your time.</p>

          '
        raw: Hello, I would like to use this model, however I am new to this and I
          do not know if I would be able to use the model with an i7-1165G7 2.80 GHz
          with 16 GB RAM in total. Thanks for your time.
        updatedAt: '2023-05-15T16:12:08.434Z'
      numEdits: 0
      reactions: []
    id: 646259d88bd7025ebe82aa9b
    type: comment
  author: TheronSnow
  content: Hello, I would like to use this model, however I am new to this and I do
    not know if I would be able to use the model with an i7-1165G7 2.80 GHz with 16
    GB RAM in total. Thanks for your time.
  created_at: 2023-05-15 15:12:08+00:00
  edited: false
  hidden: false
  id: 646259d88bd7025ebe82aa9b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/84970aff649b51800f785ead40278d73.svg
      fullname: Christian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheronSnow
      type: user
    createdAt: '2023-05-15T16:29:40.000Z'
    data:
      status: closed
    id: 64625df4904bbc4cf2e024e1
    type: status-change
  author: TheronSnow
  created_at: 2023-05-15 15:29:40+00:00
  id: 64625df4904bbc4cf2e024e1
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/84970aff649b51800f785ead40278d73.svg
      fullname: Christian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheronSnow
      type: user
    createdAt: '2023-05-15T16:29:44.000Z'
    data:
      status: open
    id: 64625df8cce92c7d882cf88b
    type: status-change
  author: TheronSnow
  created_at: 2023-05-15 15:29:44+00:00
  id: 64625df8cce92c7d882cf88b
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
      fullname: Sam Havens
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sam-mosaic
      type: user
    createdAt: '2023-05-23T05:20:23.000Z'
    data:
      edited: false
      editors:
      - sam-mosaic
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
          fullname: Sam Havens
          isHf: false
          isPro: false
          name: sam-mosaic
          type: user
        html: '<p>You can use transformer models on CPUs, but they tend to be quite
          slow. You likely want to look at projects like GGML and llama.cpp. Optimizing
          for CPU is a focus of those projects, unlike us. </p>

          <p>This is not an endorsement, as I haven''t tested it, but this is the
          type of project you''d look for: <a href="https://huggingface.co/TheBloke/MPT-7B-Instruct-GGML">https://huggingface.co/TheBloke/MPT-7B-Instruct-GGML</a></p>

          '
        raw: "You can use transformer models on CPUs, but they tend to be quite slow.\
          \ You likely want to look at projects like GGML and llama.cpp. Optimizing\
          \ for CPU is a focus of those projects, unlike us. \n\nThis is not an endorsement,\
          \ as I haven't tested it, but this is the type of project you'd look for:\
          \ https://huggingface.co/TheBloke/MPT-7B-Instruct-GGML"
        updatedAt: '2023-05-23T05:20:23.829Z'
      numEdits: 0
      reactions: []
      relatedEventId: 646c4d17f85ebf65c54decfa
    id: 646c4d17f85ebf65c54decf9
    type: comment
  author: sam-mosaic
  content: "You can use transformer models on CPUs, but they tend to be quite slow.\
    \ You likely want to look at projects like GGML and llama.cpp. Optimizing for\
    \ CPU is a focus of those projects, unlike us. \n\nThis is not an endorsement,\
    \ as I haven't tested it, but this is the type of project you'd look for: https://huggingface.co/TheBloke/MPT-7B-Instruct-GGML"
  created_at: 2023-05-23 04:20:23+00:00
  edited: false
  hidden: false
  id: 646c4d17f85ebf65c54decf9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
      fullname: Sam Havens
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sam-mosaic
      type: user
    createdAt: '2023-05-23T05:20:23.000Z'
    data:
      status: closed
    id: 646c4d17f85ebf65c54decfa
    type: status-change
  author: sam-mosaic
  created_at: 2023-05-23 04:20:23+00:00
  id: 646c4d17f85ebf65c54decfa
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 21
repo_id: mosaicml/mpt-7b
repo_type: model
status: closed
target_branch: null
title: How do I enable cpu support?
