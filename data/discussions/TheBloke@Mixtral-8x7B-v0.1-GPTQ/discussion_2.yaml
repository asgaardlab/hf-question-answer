!!python/object:huggingface_hub.community.DiscussionWithDetails
author: luv2261
conflicting_files: null
created_at: 2023-12-13 08:44:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69d620f04240376e3b1d23321f96f3c4.svg
      fullname: Luv Bansal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luv2261
      type: user
    createdAt: '2023-12-13T08:44:12.000Z'
    data:
      edited: false
      editors:
      - luv2261
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5635672211647034
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69d620f04240376e3b1d23321f96f3c4.svg
          fullname: Luv Bansal
          isHf: false
          isPro: false
          name: luv2261
          type: user
        html: '<p>TypeError: mixtral isn''t supported yet.</p>

          <p>At:<br>  /opt/conda/envs/condaenv/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py(232):
          check_and_get_model_type<br>  /opt/conda/envs/condaenv/lib/python3.8/site-packages/auto_gptq/modeling/auto.py(98):
          from_quantized<br>  /app/mixtral-8x7B-v0.1-GPTQ/1/model.py(56): initialize</p>

          <p>I followed instructions from <a href="https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GPTQ#python-code-example-inference-from-this-gptq-model">https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GPTQ#python-code-example-inference-from-this-gptq-model</a>
          (I tried installations from wheel and from source).<br>Is mixtral not runnable
          with autoGPTQ yet?</p>

          '
        raw: "TypeError: mixtral isn't supported yet.\r\n\r\nAt:\r\n  /opt/conda/envs/condaenv/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py(232):\
          \ check_and_get_model_type\r\n  /opt/conda/envs/condaenv/lib/python3.8/site-packages/auto_gptq/modeling/auto.py(98):\
          \ from_quantized\r\n  /app/mixtral-8x7B-v0.1-GPTQ/1/model.py(56): initialize\r\
          \n\r\nI followed instructions from https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GPTQ#python-code-example-inference-from-this-gptq-model\
          \ (I tried installations from wheel and from source).\r\nIs mixtral not\
          \ runnable with autoGPTQ yet?\r\n\r\n"
        updatedAt: '2023-12-13T08:44:12.588Z'
      numEdits: 0
      reactions: []
    id: 65796edcd2ae45dee13cce85
    type: comment
  author: luv2261
  content: "TypeError: mixtral isn't supported yet.\r\n\r\nAt:\r\n  /opt/conda/envs/condaenv/lib/python3.8/site-packages/auto_gptq/modeling/_utils.py(232):\
    \ check_and_get_model_type\r\n  /opt/conda/envs/condaenv/lib/python3.8/site-packages/auto_gptq/modeling/auto.py(98):\
    \ from_quantized\r\n  /app/mixtral-8x7B-v0.1-GPTQ/1/model.py(56): initialize\r\
    \n\r\nI followed instructions from https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GPTQ#python-code-example-inference-from-this-gptq-model\
    \ (I tried installations from wheel and from source).\r\nIs mixtral not runnable\
    \ with autoGPTQ yet?\r\n\r\n"
  created_at: 2023-12-13 08:44:12+00:00
  edited: false
  hidden: false
  id: 65796edcd2ae45dee13cce85
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-12-13T09:13:18.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7835215926170349
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<p>Only mistral''s name is supported, you need to change the code <a
          rel="nofollow" href="https://github.com/PanQiWei/AutoGPTQ/blob/main/auto_gptq/modeling/_const.py">https://github.com/PanQiWei/AutoGPTQ/blob/main/auto_gptq/modeling/_const.py</a></p>

          <p>or maybe rename to mistral?</p>

          '
        raw: 'Only mistral''s name is supported, you need to change the code https://github.com/PanQiWei/AutoGPTQ/blob/main/auto_gptq/modeling/_const.py


          or maybe rename to mistral?'
        updatedAt: '2023-12-13T09:13:18.776Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - luv2261
    id: 657975ae8628ec00e9221970
    type: comment
  author: Yhyu13
  content: 'Only mistral''s name is supported, you need to change the code https://github.com/PanQiWei/AutoGPTQ/blob/main/auto_gptq/modeling/_const.py


    or maybe rename to mistral?'
  created_at: 2023-12-13 09:13:18+00:00
  edited: false
  hidden: false
  id: 657975ae8628ec00e9221970
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69d620f04240376e3b1d23321f96f3c4.svg
      fullname: Luv Bansal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luv2261
      type: user
    createdAt: '2023-12-13T09:49:09.000Z'
    data:
      edited: true
      editors:
      - luv2261
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.865780234336853
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69d620f04240376e3b1d23321f96f3c4.svg
          fullname: Luv Bansal
          isHf: false
          isPro: false
          name: luv2261
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;Yhyu13&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Yhyu13\"\
          >@<span class=\"underline\">Yhyu13</span></a></span>\n\n\t</span></span>\
          \ , I renamed mixtral to mistral in config.json and its working but now\
          \ I'm getting </p>\n<pre><code class=\"language-plaintext\">CUDA extension\
          \ not installed.\nCUDA extension not installed.\nCUDA kernels for auto_gptq\
          \ are not installed, this will result in very slow inference speed. This\
          \ may because:\n1. You disabled CUDA extensions compilation by setting BUILD_CUDA_EXT=0\
          \ when install auto_gptq from source.\n2. You are using pytorch without\
          \ CUDA support.\n3. CUDA and nvcc are not installed in your device.\n</code></pre>\n\
          <p>I have CUDA installed</p>\n"
        raw: "Thanks @Yhyu13 , I renamed mixtral to mistral in config.json and its\
          \ working but now I'm getting \n```plaintext\nCUDA extension not installed.\n\
          CUDA extension not installed.\nCUDA kernels for auto_gptq are not installed,\
          \ this will result in very slow inference speed. This may because:\n1. You\
          \ disabled CUDA extensions compilation by setting BUILD_CUDA_EXT=0 when\
          \ install auto_gptq from source.\n2. You are using pytorch without CUDA\
          \ support.\n3. CUDA and nvcc are not installed in your device.\n```\nI have\
          \ CUDA installed\n"
        updatedAt: '2023-12-13T09:51:10.800Z'
      numEdits: 1
      reactions: []
    id: 65797e156db22fc06cdcd893
    type: comment
  author: luv2261
  content: "Thanks @Yhyu13 , I renamed mixtral to mistral in config.json and its working\
    \ but now I'm getting \n```plaintext\nCUDA extension not installed.\nCUDA extension\
    \ not installed.\nCUDA kernels for auto_gptq are not installed, this will result\
    \ in very slow inference speed. This may because:\n1. You disabled CUDA extensions\
    \ compilation by setting BUILD_CUDA_EXT=0 when install auto_gptq from source.\n\
    2. You are using pytorch without CUDA support.\n3. CUDA and nvcc are not installed\
    \ in your device.\n```\nI have CUDA installed\n"
  created_at: 2023-12-13 09:49:09+00:00
  edited: true
  hidden: false
  id: 65797e156db22fc06cdcd893
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/Mixtral-8x7B-v0.1-GPTQ
repo_type: model
status: open
target_branch: null
title: 'TypeError: mixtral isn''t supported yet.'
