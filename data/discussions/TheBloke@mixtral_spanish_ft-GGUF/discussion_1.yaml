!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Esj-DL
conflicting_files: null
created_at: 2024-01-10 18:45:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2be939efbc35d7ea051a6eece79f8354.svg
      fullname: Einstein Vladimir Segundo Jimenez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Esj-DL
      type: user
    createdAt: '2024-01-10T18:45:26.000Z'
    data:
      edited: true
      editors:
      - Esj-DL
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5945034027099609
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2be939efbc35d7ea051a6eece79f8354.svg
          fullname: Einstein Vladimir Segundo Jimenez
          isHf: false
          isPro: false
          name: Esj-DL
          type: user
        html: '<p>Hi, I''m getting an error when I run.<br>Model : mixtral_spanish_ft.Q5_K_M.gguf<br>llm
          = LlamaCPP(<br>    model_path=pathMixtral,<br>    messages_to_prompt=messages_to_prompt,<br>    completion_to_prompt=completion_to_prompt,<br>    verbose=False,<br>)</p>

          <p>""""""""""""""""""<br>.....<br>llm_load_print_meta: BOS token        =
          1 ''<s>''<br>llm_load_print_meta: EOS token        = 2 ''</s>''<br>llm_load_print_meta:
          UNK token        = 0 ''''<br>llm_load_print_meta: PAD token        = 2 ''''<br>llm_load_print_meta:
          LF token         = 13 ''&lt;0x0A&gt;''<br>llm_load_tensors: ggml ctx size       =    0.38
          MiB<br>error loading model: create_tensor: tensor ''token_embd.weight''
          has wrong shape; expected  4096, 32002, got  4096, 32000,     1,     1<br>llama_load_model_from_file:
          failed to load model<br>""""""""""""""""""</p>

          <p>I found the same case in:<br><a href="https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/discussions/1">https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/discussions/1</a></p>

          <p>This problem is due to quantization or how can it be solved, thanks in
          advance.</p>

          '
        raw: "Hi, I'm getting an error when I run. \nModel : mixtral_spanish_ft.Q5_K_M.gguf\n\
          llm = LlamaCPP(\n    model_path=pathMixtral,\n    messages_to_prompt=messages_to_prompt,\n\
          \    completion_to_prompt=completion_to_prompt,\n    verbose=False,\n)\n\
          \n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n.....\nllm_load_print_meta: BOS\
          \ token        = 1 '<s>'\nllm_load_print_meta: EOS token        = 2 '</s>'\n\
          llm_load_print_meta: UNK token        = 0 '<unk>'\nllm_load_print_meta:\
          \ PAD token        = 2 '</s>'\nllm_load_print_meta: LF token         = 13\
          \ '<0x0A>'\nllm_load_tensors: ggml ctx size       =    0.38 MiB\nerror loading\
          \ model: create_tensor: tensor 'token_embd.weight' has wrong shape; expected\
          \  4096, 32002, got  4096, 32000,     1,     1\nllama_load_model_from_file:\
          \ failed to load model\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nI found\
          \ the same case in:\nhttps://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/discussions/1\n\
          \nThis problem is due to quantization or how can it be solved, thanks in\
          \ advance."
        updatedAt: '2024-01-10T18:53:32.324Z'
      numEdits: 2
      reactions: []
    id: 659ee5c681f61dd7400497be
    type: comment
  author: Esj-DL
  content: "Hi, I'm getting an error when I run. \nModel : mixtral_spanish_ft.Q5_K_M.gguf\n\
    llm = LlamaCPP(\n    model_path=pathMixtral,\n    messages_to_prompt=messages_to_prompt,\n\
    \    completion_to_prompt=completion_to_prompt,\n    verbose=False,\n)\n\n\"\"\
    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n.....\nllm_load_print_meta: BOS token      \
    \  = 1 '<s>'\nllm_load_print_meta: EOS token        = 2 '</s>'\nllm_load_print_meta:\
    \ UNK token        = 0 '<unk>'\nllm_load_print_meta: PAD token        = 2 '</s>'\n\
    llm_load_print_meta: LF token         = 13 '<0x0A>'\nllm_load_tensors: ggml ctx\
    \ size       =    0.38 MiB\nerror loading model: create_tensor: tensor 'token_embd.weight'\
    \ has wrong shape; expected  4096, 32002, got  4096, 32000,     1,     1\nllama_load_model_from_file:\
    \ failed to load model\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nI found the same\
    \ case in:\nhttps://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/discussions/1\n\
    \nThis problem is due to quantization or how can it be solved, thanks in advance."
  created_at: 2024-01-10 18:45:26+00:00
  edited: true
  hidden: false
  id: 659ee5c681f61dd7400497be
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb736b4e4e38ee185e3da89d72bfdc6d.svg
      fullname: Erick
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: elhe26
      type: user
    createdAt: '2024-01-20T14:15:17.000Z'
    data:
      edited: false
      editors:
      - elhe26
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.911777138710022
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb736b4e4e38ee185e3da89d72bfdc6d.svg
          fullname: Erick
          isHf: false
          isPro: false
          name: elhe26
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>,\
          \ any clues on how to solve this? Thanks for everything!</p>\n"
        raw: Hi @TheBloke, any clues on how to solve this? Thanks for everything!
        updatedAt: '2024-01-20T14:15:17.211Z'
      numEdits: 0
      reactions: []
    id: 65abd575043d53781a30267f
    type: comment
  author: elhe26
  content: Hi @TheBloke, any clues on how to solve this? Thanks for everything!
  created_at: 2024-01-20 14:15:17+00:00
  edited: false
  hidden: false
  id: 65abd575043d53781a30267f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/mixtral_spanish_ft-GGUF
repo_type: model
status: open
target_branch: null
title: tensor 'token_embd.weight' has wrong shape
