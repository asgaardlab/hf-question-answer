!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Neptuno
conflicting_files: null
created_at: 2024-01-13 17:05:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/da8acf1250f060187001a12a854ab24b.svg
      fullname: Games
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Neptuno
      type: user
    createdAt: '2024-01-13T17:05:51.000Z'
    data:
      edited: false
      editors:
      - Neptuno
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3110387325286865
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/da8acf1250f060187001a12a854ab24b.svg
          fullname: Games
          isHf: false
          isPro: false
          name: Neptuno
          type: user
        html: '<p>I got this error when trying to load the model, which is sad, because
          it seems to be the only one in Spanish based on Mixtral :/</p>

          <hr>

          <p>Traceback (most recent call last):<br>  File "R:\IA\text-generation-webui\modules\ui_model_menu.py",
          line 213, in load_model_wrapper<br>    shared.model, shared.tokenizer =
          load_model(selected_model, loader)<br>                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "R:\IA\text-generation-webui\modules\models.py", line 87, in load_model<br>    output
          = load_func_map<a rel="nofollow" href="model_name">loader</a><br>             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "R:\IA\text-generation-webui\modules\models.py", line 250, in llamacpp_loader<br>    model,
          tokenizer = LlamaCppModel.from_pretrained(model_file)<br>                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "R:\IA\text-generation-webui\modules\llamacpp_model.py", line 101, in from_pretrained<br>    result.model
          = Llama(**params)<br>                   ^^^^^^^^^^^^^^^<br>  File "R:\IA\text-generation-webui\installer_files\env\Lib\site-packages\llama_cpp_cuda_tensorcores\llama.py",
          line 962, in <strong>init</strong><br>    self._n_vocab = self.n_vocab()<br>                    ^^^^^^^^^^^^^^<br>  File
          "R:\IA\text-generation-webui\installer_files\env\Lib\site-packages\llama_cpp_cuda_tensorcores\llama.py",
          line 2274, in n_vocab<br>    return self._model.n_vocab()<br>           ^^^^^^^^^^^^^^^^^^^^^<br>  File
          "R:\IA\text-generation-webui\installer_files\env\Lib\site-packages\llama_cpp_cuda_tensorcores\llama.py",
          line 251, in n_vocab<br>    assert self.model is not None<br>           ^^^^^^^^^^^^^^^^^^^^^^<br>AssertionError</p>

          <p>Exception ignored in: &lt;function LlamaCppModel.__del__ at 0x0000021257DFBCE0&gt;<br>Traceback
          (most recent call last):<br>  File "R:\IA\text-generation-webui\modules\llamacpp_model.py",
          line 58, in <strong>del</strong><br>    del self.model<br>        ^^^^^^^^^^<br>AttributeError:
          ''LlamaCppModel'' object has no attribute ''model''</p>

          <hr>

          '
        raw: "I got this error when trying to load the model, which is sad, because\
          \ it seems to be the only one in Spanish based on Mixtral :/\r\n\r\n--------------------------------------------------------------------------------------------------------------\r\
          \n\r\nTraceback (most recent call last):\r\n  File \"R:\\IA\\text-generation-webui\\\
          modules\\ui_model_menu.py\", line 213, in load_model_wrapper\r\n    shared.model,\
          \ shared.tokenizer = load_model(selected_model, loader)\r\n            \
          \                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
          R:\\IA\\text-generation-webui\\modules\\models.py\", line 87, in load_model\r\
          \n    output = load_func_map[loader](model_name)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"R:\\IA\\text-generation-webui\\modules\\models.py\", line 250,\
          \ in llamacpp_loader\r\n    model, tokenizer = LlamaCppModel.from_pretrained(model_file)\r\
          \n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n \
          \ File \"R:\\IA\\text-generation-webui\\modules\\llamacpp_model.py\", line\
          \ 101, in from_pretrained\r\n    result.model = Llama(**params)\r\n    \
          \               ^^^^^^^^^^^^^^^\r\n  File \"R:\\IA\\text-generation-webui\\\
          installer_files\\env\\Lib\\site-packages\\llama_cpp_cuda_tensorcores\\llama.py\"\
          , line 962, in __init__\r\n    self._n_vocab = self.n_vocab()\r\n      \
          \              ^^^^^^^^^^^^^^\r\n  File \"R:\\IA\\text-generation-webui\\\
          installer_files\\env\\Lib\\site-packages\\llama_cpp_cuda_tensorcores\\llama.py\"\
          , line 2274, in n_vocab\r\n    return self._model.n_vocab()\r\n        \
          \   ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"R:\\IA\\text-generation-webui\\installer_files\\\
          env\\Lib\\site-packages\\llama_cpp_cuda_tensorcores\\llama.py\", line 251,\
          \ in n_vocab\r\n    assert self.model is not None\r\n           ^^^^^^^^^^^^^^^^^^^^^^\r\
          \nAssertionError\r\n\r\nException ignored in: <function LlamaCppModel.__del__\
          \ at 0x0000021257DFBCE0>\r\nTraceback (most recent call last):\r\n  File\
          \ \"R:\\IA\\text-generation-webui\\modules\\llamacpp_model.py\", line 58,\
          \ in __del__\r\n    del self.model\r\n        ^^^^^^^^^^\r\nAttributeError:\
          \ 'LlamaCppModel' object has no attribute 'model'\r\n\r\n--------------------------------------------------------------------------------------------------------------"
        updatedAt: '2024-01-13T17:05:51.068Z'
      numEdits: 0
      reactions: []
    id: 65a2c2efc8a09bd5e8f16631
    type: comment
  author: Neptuno
  content: "I got this error when trying to load the model, which is sad, because\
    \ it seems to be the only one in Spanish based on Mixtral :/\r\n\r\n--------------------------------------------------------------------------------------------------------------\r\
    \n\r\nTraceback (most recent call last):\r\n  File \"R:\\IA\\text-generation-webui\\\
    modules\\ui_model_menu.py\", line 213, in load_model_wrapper\r\n    shared.model,\
    \ shared.tokenizer = load_model(selected_model, loader)\r\n                  \
    \                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"R:\\IA\\text-generation-webui\\\
    modules\\models.py\", line 87, in load_model\r\n    output = load_func_map[loader](model_name)\r\
    \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"R:\\IA\\text-generation-webui\\\
    modules\\models.py\", line 250, in llamacpp_loader\r\n    model, tokenizer = LlamaCppModel.from_pretrained(model_file)\r\
    \n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\
    R:\\IA\\text-generation-webui\\modules\\llamacpp_model.py\", line 101, in from_pretrained\r\
    \n    result.model = Llama(**params)\r\n                   ^^^^^^^^^^^^^^^\r\n\
    \  File \"R:\\IA\\text-generation-webui\\installer_files\\env\\Lib\\site-packages\\\
    llama_cpp_cuda_tensorcores\\llama.py\", line 962, in __init__\r\n    self._n_vocab\
    \ = self.n_vocab()\r\n                    ^^^^^^^^^^^^^^\r\n  File \"R:\\IA\\\
    text-generation-webui\\installer_files\\env\\Lib\\site-packages\\llama_cpp_cuda_tensorcores\\\
    llama.py\", line 2274, in n_vocab\r\n    return self._model.n_vocab()\r\n    \
    \       ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"R:\\IA\\text-generation-webui\\installer_files\\\
    env\\Lib\\site-packages\\llama_cpp_cuda_tensorcores\\llama.py\", line 251, in\
    \ n_vocab\r\n    assert self.model is not None\r\n           ^^^^^^^^^^^^^^^^^^^^^^\r\
    \nAssertionError\r\n\r\nException ignored in: <function LlamaCppModel.__del__\
    \ at 0x0000021257DFBCE0>\r\nTraceback (most recent call last):\r\n  File \"R:\\\
    IA\\text-generation-webui\\modules\\llamacpp_model.py\", line 58, in __del__\r\
    \n    del self.model\r\n        ^^^^^^^^^^\r\nAttributeError: 'LlamaCppModel'\
    \ object has no attribute 'model'\r\n\r\n--------------------------------------------------------------------------------------------------------------"
  created_at: 2024-01-13 17:05:51+00:00
  edited: false
  hidden: false
  id: 65a2c2efc8a09bd5e8f16631
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb736b4e4e38ee185e3da89d72bfdc6d.svg
      fullname: Erick
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: elhe26
      type: user
    createdAt: '2024-01-20T14:14:15.000Z'
    data:
      edited: false
      editors:
      - elhe26
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3182256817817688
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb736b4e4e38ee185e3da89d72bfdc6d.svg
          fullname: Erick
          isHf: false
          isPro: false
          name: elhe26
          type: user
        html: '<p>Getting same error.</p>

          '
        raw: Getting same error.
        updatedAt: '2024-01-20T14:14:15.539Z'
      numEdits: 0
      reactions: []
    id: 65abd537d2adc31ee3425988
    type: comment
  author: elhe26
  content: Getting same error.
  created_at: 2024-01-20 14:14:15+00:00
  edited: false
  hidden: false
  id: 65abd537d2adc31ee3425988
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/mixtral_spanish_ft-GGUF
repo_type: model
status: open
target_branch: null
title: 'AttributeError: ''LlamaCppModel'' object has no attribute ''model'''
