!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abrehmaaan
conflicting_files: null
created_at: 2023-10-06 05:16:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/60cd54c69021e9ff6b4d5664bb672c49.svg
      fullname: Abdul Rehman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abrehmaaan
      type: user
    createdAt: '2023-10-06T06:16:52.000Z'
    data:
      edited: false
      editors:
      - abrehmaaan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.76969975233078
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/60cd54c69021e9ff6b4d5664bb672c49.svg
          fullname: Abdul Rehman
          isHf: false
          isPro: false
          name: abrehmaaan
          type: user
        html: '<p>I have an Amazon EC2 instance having these specs:</p>

          <p>Instance Size: g5.2xlarge<br>GPU: 1<br>GPU Memory (GiB): 24<br>vCPUs:
          8<br>Memory (GiB): 32<br>Instance Storage (GB): 1 x 450 NVMe SSD<br>Network
          Bandwidth (Gbps): Up to 10<br>EBS Bandwidth (Gbps): Up to 3.5</p>

          <p>Can I run this Llama-2-7B-GPTQ version on it? Does the model require
          more specs? Are there any other open-source LLMs that can be used in these
          specifications?</p>

          '
        raw: "I have an Amazon EC2 instance having these specs:\r\n\r\nInstance Size:\
          \ g5.2xlarge\r\nGPU: 1\r\nGPU Memory (GiB): 24\r\nvCPUs: 8\r\nMemory (GiB):\
          \ 32\r\nInstance Storage (GB): 1 x 450 NVMe SSD\r\nNetwork Bandwidth (Gbps):\
          \ Up to 10\r\nEBS Bandwidth (Gbps): Up to 3.5\r\n\r\nCan I run this Llama-2-7B-GPTQ\
          \ version on it? Does the model require more specs? Are there any other\
          \ open-source LLMs that can be used in these specifications?"
        updatedAt: '2023-10-06T06:16:52.350Z'
      numEdits: 0
      reactions: []
    id: 651fa654128d26b399dfd35f
    type: comment
  author: abrehmaaan
  content: "I have an Amazon EC2 instance having these specs:\r\n\r\nInstance Size:\
    \ g5.2xlarge\r\nGPU: 1\r\nGPU Memory (GiB): 24\r\nvCPUs: 8\r\nMemory (GiB): 32\r\
    \nInstance Storage (GB): 1 x 450 NVMe SSD\r\nNetwork Bandwidth (Gbps): Up to 10\r\
    \nEBS Bandwidth (Gbps): Up to 3.5\r\n\r\nCan I run this Llama-2-7B-GPTQ version\
    \ on it? Does the model require more specs? Are there any other open-source LLMs\
    \ that can be used in these specifications?"
  created_at: 2023-10-06 05:16:52+00:00
  edited: false
  hidden: false
  id: 651fa654128d26b399dfd35f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/60cd54c69021e9ff6b4d5664bb672c49.svg
      fullname: Abdul Rehman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abrehmaaan
      type: user
    createdAt: '2023-10-06T06:17:08.000Z'
    data:
      edited: false
      editors:
      - abrehmaaan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8597272634506226
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/60cd54c69021e9ff6b4d5664bb672c49.svg
          fullname: Abdul Rehman
          isHf: false
          isPro: false
          name: abrehmaaan
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> Please reply</p>\n"
        raw: '@TheBloke Please reply'
        updatedAt: '2023-10-06T06:17:08.864Z'
      numEdits: 0
      reactions: []
    id: 651fa664372c0f3dc701d909
    type: comment
  author: abrehmaaan
  content: '@TheBloke Please reply'
  created_at: 2023-10-06 05:17:08+00:00
  edited: false
  hidden: false
  id: 651fa664372c0f3dc701d909
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2023-10-06T16:38:09.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9937681555747986
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: '<p>Yes definitely. You could probably run a 13b gptq model as well.</p>

          '
        raw: Yes definitely. You could probably run a 13b gptq model as well.
        updatedAt: '2023-10-06T16:38:09.662Z'
      numEdits: 0
      reactions: []
    id: 652037f1b903b175b096cfbc
    type: comment
  author: YaTharThShaRma999
  content: Yes definitely. You could probably run a 13b gptq model as well.
  created_at: 2023-10-06 15:38:09+00:00
  edited: false
  hidden: false
  id: 652037f1b903b175b096cfbc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: TheBloke/Llama-2-7B-GPTQ
repo_type: model
status: open
target_branch: null
title: GPU Requirement
