!!python/object:huggingface_hub.community.DiscussionWithDetails
author: umiuni
conflicting_files: null
created_at: 2023-09-03 08:00:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/32144813a0590fbed64444cfbda424b7.svg
      fullname: Admin UmiUni
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: umiuni
      type: user
    createdAt: '2023-09-03T09:00:30.000Z'
    data:
      edited: true
      editors:
      - umiuni
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6095332503318787
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/32144813a0590fbed64444cfbda424b7.svg
          fullname: Admin UmiUni
          isHf: false
          isPro: false
          name: umiuni
          type: user
        html: "<pre><code>import torch\nfrom auto_gptq import AutoGPTQForCausalLM\n\
          from transformers import AutoTokenizer\n\n# Load the AutoGPTQForCausalLM\
          \ model and tokenizer\nmodel_name_or_path = \"/scratch/yerong/.cache/pyllama/Llama-2-7B-GPTQ\"\
          \nmodel = AutoGPTQForCausalLM.from_quantized(model_name_or_path, model_basename=\"\
          model\", inject_fused_attention=False, use_safetensors=True, trust_remote_code=False,\
          \ device=\"cuda:0\", use_triton=False, quantize_config=None)\ntokenizer\
          \ = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n\n\
          # Set the padding token to be equal to the end of sequence token (eos_token)\n\
          tokenizer.pad_token = tokenizer.eos_token\n\n# Set the device (CPU or GPU)\n\
          # device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# model.to(device)\n\
          \n# Define a list of prompts (text) for batch generation\nsentence = \"\
          Elon Musk is a South African-born Canadian-American business magnate, investor\
          \ and inventor. He is the founder, CEO, and chief engineer/designer of SpaceX;\
          \ co-founder, CEO, and product architect\",\n\n# sentences = [\n#     \"\
          Elon Musk is a South African-born Canadian-American business magnate, investor\
          \ and inventor. He is the founder, CEO, and chief engineer/designer of SpaceX;\
          \ co-founder, CEO, and product architect\",\n#     # \"Prompt 2: Bill Gates\
          \ dropped out of Harvard\",\n#     # \"Prompt 3: Another prompt to generate\
          \ text.\",\n#     # \"Prompt 4: Yet another prompt for AutoGPT.\",\n#  \
          \   # \"Prompt 5: A fifth prompt to see what it generates.\",\n#     # \"\
          Prompt 6: AutoGPT can generate text creatively.\",\n#     # \"Prompt 7:\
          \ Let's test another prompt.\",\n#     # \"Prompt 8: The final prompt for\
          \ this batch.\",\n# ]\n\ninput_ids = tokenizer(sentence, return_tensors='pt',\
          \ truncation=True, padding=\"max_length\", max_length=512).input_ids.cuda()\n\
          # input_ids = tokenizer(sentences, return_tensors='pt', truncation=True,\
          \ padding=\"max_length\", max_length=512).input_ids.cuda()\n\nwith torch.no_grad():\n\
          \    outputs = model.generate(\n        input_ids=input_ids,\n        max_new_tokens=256,\n\
          \        do_sample=True,\n        top_p=0.9,\n        temperature=float(0.01),\n\
          \        top_k=40\n    )\n\n# print(tokenizer.batch_decode(outputs[:, input_ids.shape[1]:],\
          \ max_new_tokens=256, skip_special_tokens=True))\nprint(tokenizer.batch_decode(outputs,\
          \ max_new_tokens=256, skip_special_tokens=True))\n</code></pre>\n<pre><code>skip\
          \ module injection for FusedLlamaMLPForQuantizedModel not support integrate\
          \ without triton yet.                                                  \
          \          \n['nobody nobody nobody nobody\\n everybody nobody nobody nobody\
          \ nobody nobody nobody nobody\\n nobody\\n nobody\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\n\\n\\n\\n\\n\\n._\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n nobody\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n']\n['Elon Musk is a South African-born Canadian-American business\
          \ magnate, investor and inventor. He is the founder, CEO, and chief engineer/designer\
          \ of SpaceX; co-founder, CEO, and product architect nobody nobody nobody\
          \ nobody\\n everybody nobody nobody nobody nobody nobody nobody nobody\\\
          n nobody\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n._\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n</code></pre>\n<p><a rel=\"\
          nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/64a63d485f93bfafa746183e/4LJfCARsiiIJWl372LOnT.jpeg\"\
          ><img alt=\"screenshot.jpg\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64a63d485f93bfafa746183e/4LJfCARsiiIJWl372LOnT.jpeg\"\
          ></a></p>\n"
        raw: "```\nimport torch\nfrom auto_gptq import AutoGPTQForCausalLM\nfrom transformers\
          \ import AutoTokenizer\n\n# Load the AutoGPTQForCausalLM model and tokenizer\n\
          model_name_or_path = \"/scratch/yerong/.cache/pyllama/Llama-2-7B-GPTQ\"\n\
          model = AutoGPTQForCausalLM.from_quantized(model_name_or_path, model_basename=\"\
          model\", inject_fused_attention=False, use_safetensors=True, trust_remote_code=False,\
          \ device=\"cuda:0\", use_triton=False, quantize_config=None)\ntokenizer\
          \ = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n\n\
          # Set the padding token to be equal to the end of sequence token (eos_token)\n\
          tokenizer.pad_token = tokenizer.eos_token\n\n# Set the device (CPU or GPU)\n\
          # device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# model.to(device)\n\
          \n# Define a list of prompts (text) for batch generation\nsentence = \"\
          Elon Musk is a South African-born Canadian-American business magnate, investor\
          \ and inventor. He is the founder, CEO, and chief engineer/designer of SpaceX;\
          \ co-founder, CEO, and product architect\",\n\n# sentences = [\n#     \"\
          Elon Musk is a South African-born Canadian-American business magnate, investor\
          \ and inventor. He is the founder, CEO, and chief engineer/designer of SpaceX;\
          \ co-founder, CEO, and product architect\",\n#     # \"Prompt 2: Bill Gates\
          \ dropped out of Harvard\",\n#     # \"Prompt 3: Another prompt to generate\
          \ text.\",\n#     # \"Prompt 4: Yet another prompt for AutoGPT.\",\n#  \
          \   # \"Prompt 5: A fifth prompt to see what it generates.\",\n#     # \"\
          Prompt 6: AutoGPT can generate text creatively.\",\n#     # \"Prompt 7:\
          \ Let's test another prompt.\",\n#     # \"Prompt 8: The final prompt for\
          \ this batch.\",\n# ]\n\ninput_ids = tokenizer(sentence, return_tensors='pt',\
          \ truncation=True, padding=\"max_length\", max_length=512).input_ids.cuda()\n\
          # input_ids = tokenizer(sentences, return_tensors='pt', truncation=True,\
          \ padding=\"max_length\", max_length=512).input_ids.cuda()\n\nwith torch.no_grad():\n\
          \    outputs = model.generate(\n        input_ids=input_ids,\n        max_new_tokens=256,\n\
          \        do_sample=True,\n        top_p=0.9,\n        temperature=float(0.01),\n\
          \        top_k=40\n    )\n\n# print(tokenizer.batch_decode(outputs[:, input_ids.shape[1]:],\
          \ max_new_tokens=256, skip_special_tokens=True))\nprint(tokenizer.batch_decode(outputs,\
          \ max_new_tokens=256, skip_special_tokens=True))\n```\n\n```\nskip module\
          \ injection for FusedLlamaMLPForQuantizedModel not support integrate without\
          \ triton yet.                                                          \
          \  \n['nobody nobody nobody nobody\\n everybody nobody nobody nobody nobody\
          \ nobody nobody nobody\\n nobody\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\n\\n\\n\\n\\n\\n._\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n nobody\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n']\n['Elon Musk is a South African-born Canadian-American business magnate,\
          \ investor and inventor. He is the founder, CEO, and chief engineer/designer\
          \ of SpaceX; co-founder, CEO, and product architect nobody nobody nobody\
          \ nobody\\n everybody nobody nobody nobody nobody nobody nobody nobody\\\
          n nobody\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n._\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
          n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n\n```\n\n\n\n![screenshot.jpg](https://cdn-uploads.huggingface.co/production/uploads/64a63d485f93bfafa746183e/4LJfCARsiiIJWl372LOnT.jpeg)\n"
        updatedAt: '2023-09-03T09:00:46.914Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - yravindranath
    id: 64f44b2edf8497802cf0e5c9
    type: comment
  author: umiuni
  content: "```\nimport torch\nfrom auto_gptq import AutoGPTQForCausalLM\nfrom transformers\
    \ import AutoTokenizer\n\n# Load the AutoGPTQForCausalLM model and tokenizer\n\
    model_name_or_path = \"/scratch/yerong/.cache/pyllama/Llama-2-7B-GPTQ\"\nmodel\
    \ = AutoGPTQForCausalLM.from_quantized(model_name_or_path, model_basename=\"model\"\
    , inject_fused_attention=False, use_safetensors=True, trust_remote_code=False,\
    \ device=\"cuda:0\", use_triton=False, quantize_config=None)\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path,\
    \ use_fast=True)\n\n# Set the padding token to be equal to the end of sequence\
    \ token (eos_token)\ntokenizer.pad_token = tokenizer.eos_token\n\n# Set the device\
    \ (CPU or GPU)\n# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\
    # model.to(device)\n\n# Define a list of prompts (text) for batch generation\n\
    sentence = \"Elon Musk is a South African-born Canadian-American business magnate,\
    \ investor and inventor. He is the founder, CEO, and chief engineer/designer of\
    \ SpaceX; co-founder, CEO, and product architect\",\n\n# sentences = [\n#    \
    \ \"Elon Musk is a South African-born Canadian-American business magnate, investor\
    \ and inventor. He is the founder, CEO, and chief engineer/designer of SpaceX;\
    \ co-founder, CEO, and product architect\",\n#     # \"Prompt 2: Bill Gates dropped\
    \ out of Harvard\",\n#     # \"Prompt 3: Another prompt to generate text.\",\n\
    #     # \"Prompt 4: Yet another prompt for AutoGPT.\",\n#     # \"Prompt 5: A\
    \ fifth prompt to see what it generates.\",\n#     # \"Prompt 6: AutoGPT can generate\
    \ text creatively.\",\n#     # \"Prompt 7: Let's test another prompt.\",\n#  \
    \   # \"Prompt 8: The final prompt for this batch.\",\n# ]\n\ninput_ids = tokenizer(sentence,\
    \ return_tensors='pt', truncation=True, padding=\"max_length\", max_length=512).input_ids.cuda()\n\
    # input_ids = tokenizer(sentences, return_tensors='pt', truncation=True, padding=\"\
    max_length\", max_length=512).input_ids.cuda()\n\nwith torch.no_grad():\n    outputs\
    \ = model.generate(\n        input_ids=input_ids,\n        max_new_tokens=256,\n\
    \        do_sample=True,\n        top_p=0.9,\n        temperature=float(0.01),\n\
    \        top_k=40\n    )\n\n# print(tokenizer.batch_decode(outputs[:, input_ids.shape[1]:],\
    \ max_new_tokens=256, skip_special_tokens=True))\nprint(tokenizer.batch_decode(outputs,\
    \ max_new_tokens=256, skip_special_tokens=True))\n```\n\n```\nskip module injection\
    \ for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\
    \                                                            \n['nobody nobody\
    \ nobody nobody\\n everybody nobody nobody nobody nobody nobody nobody nobody\\\
    n nobody\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\n\\n\\n\\n\\n\\n._\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n nobody\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n\
    ['Elon Musk is a South African-born Canadian-American business magnate, investor\
    \ and inventor. He is the founder, CEO, and chief engineer/designer of SpaceX;\
    \ co-founder, CEO, and product architect nobody nobody nobody nobody\\n everybody\
    \ nobody nobody nobody nobody nobody nobody nobody\\n nobody\\n nobody\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n._\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n nobody\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\\
    n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n\n```\n\n\n\n![screenshot.jpg](https://cdn-uploads.huggingface.co/production/uploads/64a63d485f93bfafa746183e/4LJfCARsiiIJWl372LOnT.jpeg)\n"
  created_at: 2023-09-03 08:00:30+00:00
  edited: true
  hidden: false
  id: 64f44b2edf8497802cf0e5c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/734f388412406ccdd0e572c7246ca90c.svg
      fullname: Ryan Shrott
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rshrott
      type: user
    createdAt: '2023-09-08T22:49:56.000Z'
    data:
      edited: false
      editors:
      - rshrott
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9754126071929932
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/734f388412406ccdd0e572c7246ca90c.svg
          fullname: Ryan Shrott
          isHf: false
          isPro: false
          name: rshrott
          type: user
        html: '<p>I saw something similar, and solve the issue by setting temperature
          to 0. </p>

          '
        raw: 'I saw something similar, and solve the issue by setting temperature
          to 0. '
        updatedAt: '2023-09-08T22:49:56.511Z'
      numEdits: 0
      reactions: []
    id: 64fba514b8d50cebd6431039
    type: comment
  author: rshrott
  content: 'I saw something similar, and solve the issue by setting temperature to
    0. '
  created_at: 2023-09-08 21:49:56+00:00
  edited: false
  hidden: false
  id: 64fba514b8d50cebd6431039
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: TheBloke/Llama-2-7B-GPTQ
repo_type: model
status: open
target_branch: null
title: output Nonsense compared to llama.cpp
