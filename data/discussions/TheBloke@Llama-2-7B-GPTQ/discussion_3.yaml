!!python/object:huggingface_hub.community.DiscussionWithDetails
author: EYan0208
conflicting_files: null
created_at: 2023-08-01 02:33:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0a5ba4dde948265d17591d7217b6dcb.svg
      fullname: Y
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: EYan0208
      type: user
    createdAt: '2023-08-01T03:33:07.000Z'
    data:
      edited: false
      editors:
      - EYan0208
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9610430598258972
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0a5ba4dde948265d17591d7217b6dcb.svg
          fullname: Y
          isHf: false
          isPro: false
          name: EYan0208
          type: user
        html: '<p>So I have cloned the main branch and I am trying to run the sample
          code in the description but some warnings which are shown below popped out:</p>

          <p>CUDA extension not installed.<br>The model weights are not tied. Please
          use the <code>tie_weights</code> method before using the <code>infer_auto_device</code>
          function.<br>The safetensors archive passed at ./Llama-2-7B-GPTQ\gptq_model-4bit-128g.safetensors
          does not contain metadata. Make sure to save your model with the <code>save_pretrained</code>
          method. Defaulting to ''pt'' metadata.<br>skip module injection for FusedLlamaMLPForQuantizedModel
          not support integrate without triton yet.</p>

          <p>Even though output is generated eventually, it is really slow and the
          result is undesired:</p>

          <p>nobody can tell me about AI<br>I''m not sure what you mean by "tell me
          about AI".<br>I''m not sure what you mean by "tell me about AI". I''m not
          sure what you mean by "tell me about AI". I''m not sure what you mean by
          "tell me about AI". I''m not sure what you mean by "tell me about AI". I''m
          not sure what you mean by "tell me about AI". I''m not sure what you mean
          by "tell me about AI". I''m not sure what you mean by "tell me about AI".
          I''m not sure what you mean by "tell me about AI". I''m not sure what you
          mean by "tell me about AI". I''m not sure what you mean by "tell me about
          AI". I''m not sure what you mean by "tell me about AI". I''m not sure what
          you mean by "tell me about AI". I''m not sure what you mean by "tell me
          about AI". I''m not sure what you mean by "tell me about AI". I''m not sure
          what you mean by "tell me about AI". I''m not sure what you mean by "tell
          me about AI". I''m not sure what you mean by "tell me about AI". I''m not
          sure what you mean by "tell me about AI". I''m not sure what you mean by
          "tell me about AI". I''m not sure what you mean by "tell me about AI". I''m
          not sure what you mean by "tell me about AI". I''m not sure what you mean
          by "tell me about AI". I''m not sure what you mean by "tell me about AI".
          I''m not sure what you mean by "tell me about AI". I''m not sure what you
          mean by "tell me about AI". I''m not sure what you mean by "tell me about
          AI". I''m not sure what you mean by "tell me about AI". I''m not sure what
          you mean by "tell me about AI". I''m not sure what you mean by "</p>

          <p>I wonder if it is the problem related to the warnings...</p>

          '
        raw: "So I have cloned the main branch and I am trying to run the sample code\
          \ in the description but some warnings which are shown below popped out:\r\
          \n\r\nCUDA extension not installed.\r\nThe model weights are not tied. Please\
          \ use the `tie_weights` method before using the `infer_auto_device` function.\r\
          \nThe safetensors archive passed at ./Llama-2-7B-GPTQ\\gptq_model-4bit-128g.safetensors\
          \ does not contain metadata. Make sure to save your model with the `save_pretrained`\
          \ method. Defaulting to 'pt' metadata.\r\nskip module injection for FusedLlamaMLPForQuantizedModel\
          \ not support integrate without triton yet.\r\n\r\nEven though output is\
          \ generated eventually, it is really slow and the result is undesired:\r\
          \n\r\nnobody can tell me about AI\r\nI'm not sure what you mean by \"tell\
          \ me about AI\".\r\nI'm not sure what you mean by \"tell me about AI\".\
          \ I'm not sure what you mean by \"tell me about AI\". I'm not sure what\
          \ you mean by \"tell me about AI\". I'm not sure what you mean by \"tell\
          \ me about AI\". I'm not sure what you mean by \"tell me about AI\". I'm\
          \ not sure what you mean by \"tell me about AI\". I'm not sure what you\
          \ mean by \"tell me about AI\". I'm not sure what you mean by \"tell me\
          \ about AI\". I'm not sure what you mean by \"tell me about AI\". I'm not\
          \ sure what you mean by \"tell me about AI\". I'm not sure what you mean\
          \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about\
          \ AI\". I'm not sure what you mean by \"tell me about AI\". I'm not sure\
          \ what you mean by \"tell me about AI\". I'm not sure what you mean by \"\
          tell me about AI\". I'm not sure what you mean by \"tell me about AI\".\
          \ I'm not sure what you mean by \"tell me about AI\". I'm not sure what\
          \ you mean by \"tell me about AI\". I'm not sure what you mean by \"tell\
          \ me about AI\". I'm not sure what you mean by \"tell me about AI\". I'm\
          \ not sure what you mean by \"tell me about AI\". I'm not sure what you\
          \ mean by \"tell me about AI\". I'm not sure what you mean by \"tell me\
          \ about AI\". I'm not sure what you mean by \"tell me about AI\". I'm not\
          \ sure what you mean by \"tell me about AI\". I'm not sure what you mean\
          \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about\
          \ AI\". I'm not sure what you mean by \"tell me about AI\". I'm not sure\
          \ what you mean by \"\r\n\r\nI wonder if it is the problem related to the\
          \ warnings..."
        updatedAt: '2023-08-01T03:33:07.793Z'
      numEdits: 0
      reactions: []
    id: 64c87cf30b2ba05b2f4ce22c
    type: comment
  author: EYan0208
  content: "So I have cloned the main branch and I am trying to run the sample code\
    \ in the description but some warnings which are shown below popped out:\r\n\r\
    \nCUDA extension not installed.\r\nThe model weights are not tied. Please use\
    \ the `tie_weights` method before using the `infer_auto_device` function.\r\n\
    The safetensors archive passed at ./Llama-2-7B-GPTQ\\gptq_model-4bit-128g.safetensors\
    \ does not contain metadata. Make sure to save your model with the `save_pretrained`\
    \ method. Defaulting to 'pt' metadata.\r\nskip module injection for FusedLlamaMLPForQuantizedModel\
    \ not support integrate without triton yet.\r\n\r\nEven though output is generated\
    \ eventually, it is really slow and the result is undesired:\r\n\r\nnobody can\
    \ tell me about AI\r\nI'm not sure what you mean by \"tell me about AI\".\r\n\
    I'm not sure what you mean by \"tell me about AI\". I'm not sure what you mean\
    \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about AI\"\
    . I'm not sure what you mean by \"tell me about AI\". I'm not sure what you mean\
    \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about AI\"\
    . I'm not sure what you mean by \"tell me about AI\". I'm not sure what you mean\
    \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about AI\"\
    . I'm not sure what you mean by \"tell me about AI\". I'm not sure what you mean\
    \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about AI\"\
    . I'm not sure what you mean by \"tell me about AI\". I'm not sure what you mean\
    \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about AI\"\
    . I'm not sure what you mean by \"tell me about AI\". I'm not sure what you mean\
    \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about AI\"\
    . I'm not sure what you mean by \"tell me about AI\". I'm not sure what you mean\
    \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about AI\"\
    . I'm not sure what you mean by \"tell me about AI\". I'm not sure what you mean\
    \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about AI\"\
    . I'm not sure what you mean by \"tell me about AI\". I'm not sure what you mean\
    \ by \"tell me about AI\". I'm not sure what you mean by \"tell me about AI\"\
    . I'm not sure what you mean by \"tell me about AI\". I'm not sure what you mean\
    \ by \"\r\n\r\nI wonder if it is the problem related to the warnings..."
  created_at: 2023-08-01 02:33:07+00:00
  edited: false
  hidden: false
  id: 64c87cf30b2ba05b2f4ce22c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/Llama-2-7B-GPTQ
repo_type: model
status: open
target_branch: null
title: Couples of warnings popping out
