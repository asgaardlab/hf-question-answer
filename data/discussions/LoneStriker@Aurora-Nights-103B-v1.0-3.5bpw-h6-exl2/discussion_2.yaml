!!python/object:huggingface_hub.community.DiscussionWithDetails
author: coffeedean
conflicting_files: null
created_at: 2023-12-29 06:10:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4ebf07f28dd5b7b42a9c97836a81a992.svg
      fullname: Gabriel B
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: coffeedean
      type: user
    createdAt: '2023-12-29T06:10:19.000Z'
    data:
      edited: false
      editors:
      - coffeedean
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.948150098323822
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4ebf07f28dd5b7b42a9c97836a81a992.svg
          fullname: Gabriel B
          isHf: false
          isPro: false
          name: coffeedean
          type: user
        html: '<p>Hello, </p>

          <p>I''ve been using your 5.0bpw exl2 model of the previous 103b model from
          sophosympatheia, Rogue-Rose-103b-v0.2-5.0bpw-h6-exl2-2. It has been performing
          really well. Now I''ve been testing Aurora-Nights-103B-v1.0 using the Q5
          GGUF from TheBloke, and I''m really impressed with its output, but I''ve
          always had huge issues with tk/s performance using GGUF. And your exl2 models
          are always so good, fast, and easy to use.</p>

          <p>Do you have any plans for an Aurora-Nights-103B-v1.0-5.0bpw-h6-exl2?
          I''m not sure if there''s enough demand, not sure how many people used Rogue-Rose-103b-v0.2-5.0bpw-h6-exl2-2,
          but I did, and love it. </p>

          <p>Thanks!</p>

          '
        raw: "Hello, \r\n\r\nI've been using your 5.0bpw exl2 model of the previous\
          \ 103b model from sophosympatheia, Rogue-Rose-103b-v0.2-5.0bpw-h6-exl2-2.\
          \ It has been performing really well. Now I've been testing Aurora-Nights-103B-v1.0\
          \ using the Q5 GGUF from TheBloke, and I'm really impressed with its output,\
          \ but I've always had huge issues with tk/s performance using GGUF. And\
          \ your exl2 models are always so good, fast, and easy to use.\r\n\r\nDo\
          \ you have any plans for an Aurora-Nights-103B-v1.0-5.0bpw-h6-exl2? I'm\
          \ not sure if there's enough demand, not sure how many people used Rogue-Rose-103b-v0.2-5.0bpw-h6-exl2-2,\
          \ but I did, and love it. \r\n\r\nThanks!\r\n\r\n"
        updatedAt: '2023-12-29T06:10:19.974Z'
      numEdits: 0
      reactions: []
    id: 658e62cb35c41262d6286e92
    type: comment
  author: coffeedean
  content: "Hello, \r\n\r\nI've been using your 5.0bpw exl2 model of the previous\
    \ 103b model from sophosympatheia, Rogue-Rose-103b-v0.2-5.0bpw-h6-exl2-2. It has\
    \ been performing really well. Now I've been testing Aurora-Nights-103B-v1.0 using\
    \ the Q5 GGUF from TheBloke, and I'm really impressed with its output, but I've\
    \ always had huge issues with tk/s performance using GGUF. And your exl2 models\
    \ are always so good, fast, and easy to use.\r\n\r\nDo you have any plans for\
    \ an Aurora-Nights-103B-v1.0-5.0bpw-h6-exl2? I'm not sure if there's enough demand,\
    \ not sure how many people used Rogue-Rose-103b-v0.2-5.0bpw-h6-exl2-2, but I did,\
    \ and love it. \r\n\r\nThanks!\r\n\r\n"
  created_at: 2023-12-29 06:10:19+00:00
  edited: false
  hidden: false
  id: 658e62cb35c41262d6286e92
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-12-29T09:16:21.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.971485435962677
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>I can add it to the list when doing 103B models. Very few people
          have 48 GB VRAM, let alone more than 48 GB to run something like this at
          5.0bpw (I''ll be able to test these locally as well shortly after I shuffle
          my GPUs around.)</p>

          '
        raw: I can add it to the list when doing 103B models. Very few people have
          48 GB VRAM, let alone more than 48 GB to run something like this at 5.0bpw
          (I'll be able to test these locally as well shortly after I shuffle my GPUs
          around.)
        updatedAt: '2023-12-29T09:16:21.051Z'
      numEdits: 0
      reactions: []
    id: 658e8e65cdc0c4099b015c6a
    type: comment
  author: LoneStriker
  content: I can add it to the list when doing 103B models. Very few people have 48
    GB VRAM, let alone more than 48 GB to run something like this at 5.0bpw (I'll
    be able to test these locally as well shortly after I shuffle my GPUs around.)
  created_at: 2023-12-29 09:16:21+00:00
  edited: false
  hidden: false
  id: 658e8e65cdc0c4099b015c6a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4ebf07f28dd5b7b42a9c97836a81a992.svg
      fullname: Gabriel B
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: coffeedean
      type: user
    createdAt: '2023-12-29T14:13:23.000Z'
    data:
      edited: false
      editors:
      - coffeedean
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9482477307319641
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4ebf07f28dd5b7b42a9c97836a81a992.svg
          fullname: Gabriel B
          isHf: false
          isPro: false
          name: coffeedean
          type: user
        html: '<p>Thank you so much, I appreciate it! Yes, the only way I run those
          big models at higher quants is using something like Runpod. But it does
          make a noticeable difference in output quality, at least it for me did for
          Rogue Rose. </p>

          '
        raw: 'Thank you so much, I appreciate it! Yes, the only way I run those big
          models at higher quants is using something like Runpod. But it does make
          a noticeable difference in output quality, at least it for me did for Rogue
          Rose. '
        updatedAt: '2023-12-29T14:13:23.669Z'
      numEdits: 0
      reactions: []
    id: 658ed403bea632dc944a3e9a
    type: comment
  author: coffeedean
  content: 'Thank you so much, I appreciate it! Yes, the only way I run those big
    models at higher quants is using something like Runpod. But it does make a noticeable
    difference in output quality, at least it for me did for Rogue Rose. '
  created_at: 2023-12-29 14:13:23+00:00
  edited: false
  hidden: false
  id: 658ed403bea632dc944a3e9a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-12-29T14:54:57.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5908392667770386
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>It''s up here: <a href="https://huggingface.co/LoneStriker/Aurora-Nights-103B-v1.0-5.0bpw-h6-exl2">https://huggingface.co/LoneStriker/Aurora-Nights-103B-v1.0-5.0bpw-h6-exl2</a></p>

          '
        raw: 'It''s up here: https://huggingface.co/LoneStriker/Aurora-Nights-103B-v1.0-5.0bpw-h6-exl2'
        updatedAt: '2023-12-29T14:54:57.815Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - coffeedean
    id: 658eddc11adf6d577e51adf9
    type: comment
  author: LoneStriker
  content: 'It''s up here: https://huggingface.co/LoneStriker/Aurora-Nights-103B-v1.0-5.0bpw-h6-exl2'
  created_at: 2023-12-29 14:54:57+00:00
  edited: false
  hidden: false
  id: 658eddc11adf6d577e51adf9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4ebf07f28dd5b7b42a9c97836a81a992.svg
      fullname: Gabriel B
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: coffeedean
      type: user
    createdAt: '2023-12-29T16:33:47.000Z'
    data:
      edited: false
      editors:
      - coffeedean
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9829778671264648
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4ebf07f28dd5b7b42a9c97836a81a992.svg
          fullname: Gabriel B
          isHf: false
          isPro: false
          name: coffeedean
          type: user
        html: '<p>Thank you! You''re awesome. I''m testing it right now and it''s
          working very well. Thanks again!</p>

          '
        raw: Thank you! You're awesome. I'm testing it right now and it's working
          very well. Thanks again!
        updatedAt: '2023-12-29T16:33:47.940Z'
      numEdits: 0
      reactions: []
      relatedEventId: 658ef4ec16227c7a2df18e5a
    id: 658ef4eb16227c7a2df18e50
    type: comment
  author: coffeedean
  content: Thank you! You're awesome. I'm testing it right now and it's working very
    well. Thanks again!
  created_at: 2023-12-29 16:33:47+00:00
  edited: false
  hidden: false
  id: 658ef4eb16227c7a2df18e50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/4ebf07f28dd5b7b42a9c97836a81a992.svg
      fullname: Gabriel B
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: coffeedean
      type: user
    createdAt: '2023-12-29T16:33:48.000Z'
    data:
      status: closed
    id: 658ef4ec16227c7a2df18e5a
    type: status-change
  author: coffeedean
  created_at: 2023-12-29 16:33:48+00:00
  id: 658ef4ec16227c7a2df18e5a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: LoneStriker/Aurora-Nights-103B-v1.0-3.5bpw-h6-exl2
repo_type: model
status: closed
target_branch: null
title: 5.0bpw exl2?
