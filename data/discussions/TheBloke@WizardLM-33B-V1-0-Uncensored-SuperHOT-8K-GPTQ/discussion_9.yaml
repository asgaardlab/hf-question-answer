!!python/object:huggingface_hub.community.DiscussionWithDetails
author: PieDev
conflicting_files: null
created_at: 2023-09-18 02:59:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/89ebe1d65b6af36bcd570a4c347b040f.svg
      fullname: PieDev
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: PieDev
      type: user
    createdAt: '2023-09-18T03:59:22.000Z'
    data:
      edited: false
      editors:
      - PieDev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6217554807662964
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/89ebe1d65b6af36bcd570a4c347b040f.svg
          fullname: PieDev
          isHf: false
          isPro: false
          name: PieDev
          type: user
        html: '<p>Oobabooga seems to be unable to run the model properly as shown
          below:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64dfab85e8b6f3f3baa44508/7PwCelJENEcgtEAAX5nE_.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64dfab85e8b6f3f3baa44508/7PwCelJENEcgtEAAX5nE_.png"></a></p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64dfab85e8b6f3f3baa44508/MoDDxu756PDp-Zzu0HeRR.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64dfab85e8b6f3f3baa44508/MoDDxu756PDp-Zzu0HeRR.png"></a></p>

          '
        raw: "Oobabooga seems to be unable to run the model properly as shown below:\r\
          \n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64dfab85e8b6f3f3baa44508/7PwCelJENEcgtEAAX5nE_.png)\r\
          \n\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64dfab85e8b6f3f3baa44508/MoDDxu756PDp-Zzu0HeRR.png)\r\
          \n"
        updatedAt: '2023-09-18T03:59:22.718Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - IronicKeyboard
    id: 6507cb1a0c87331947b16bf0
    type: comment
  author: PieDev
  content: "Oobabooga seems to be unable to run the model properly as shown below:\r\
    \n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64dfab85e8b6f3f3baa44508/7PwCelJENEcgtEAAX5nE_.png)\r\
    \n\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64dfab85e8b6f3f3baa44508/MoDDxu756PDp-Zzu0HeRR.png)\r\
    \n"
  created_at: 2023-09-18 02:59:22+00:00
  edited: false
  hidden: false
  id: 6507cb1a0c87331947b16bf0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/46fac6fae7aabbc82ec2a58c410c4028.svg
      fullname: Ironic Keyboard
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: IronicKeyboard
      type: user
    createdAt: '2023-09-23T15:45:34.000Z'
    data:
      edited: true
      editors:
      - IronicKeyboard
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9744482636451721
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/46fac6fae7aabbc82ec2a58c410c4028.svg
          fullname: Ironic Keyboard
          isHf: false
          isPro: false
          name: IronicKeyboard
          type: user
        html: '<p>I''m getting the same issue as of this post. Been playing around
          with different settings, but haven''t been able to improve things much.</p>

          <p>Been running this on runpod with the latest image, on a single L40</p>

          <p>Edit note:<br>Solved the problem by ensure these instructions were properly
          followed:<br><code>To use the increased context, set the Loader to ExLlama,
          set max_seq_len to 8192 or 4096, and set compress_pos_emb to 4 for 8192
          context, or to 2 for 4096 context.</code></p>

          '
        raw: 'I''m getting the same issue as of this post. Been playing around with
          different settings, but haven''t been able to improve things much.


          Been running this on runpod with the latest image, on a single L40


          Edit note:

          Solved the problem by ensure these instructions were properly followed:

          `To use the increased context, set the Loader to ExLlama, set max_seq_len
          to 8192 or 4096, and set compress_pos_emb to 4 for 8192 context, or to 2
          for 4096 context.`



          '
        updatedAt: '2023-09-23T15:50:38.069Z'
      numEdits: 1
      reactions: []
    id: 650f081e6620b0c57e320525
    type: comment
  author: IronicKeyboard
  content: 'I''m getting the same issue as of this post. Been playing around with
    different settings, but haven''t been able to improve things much.


    Been running this on runpod with the latest image, on a single L40


    Edit note:

    Solved the problem by ensure these instructions were properly followed:

    `To use the increased context, set the Loader to ExLlama, set max_seq_len to 8192
    or 4096, and set compress_pos_emb to 4 for 8192 context, or to 2 for 4096 context.`



    '
  created_at: 2023-09-23 14:45:34+00:00
  edited: true
  hidden: false
  id: 650f081e6620b0c57e320525
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: TheBloke/WizardLM-33B-V1-0-Uncensored-SuperHOT-8K-GPTQ
repo_type: model
status: open
target_branch: null
title: Oobabooga Chat Errors
