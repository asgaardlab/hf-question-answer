!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rombodawg
conflicting_files: null
created_at: 2023-07-05 01:36:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2023-07-05T02:36:12.000Z'
    data:
      edited: true
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6514515280723572
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: '<p>Here are the flags to run simultaneously with gpu and cpu. You can
          change pre_layer to whatever amount you want to load onto your gpu, and
          max_seq_len to however many tokens you want your model to generate at max,
          make sure its either 2048, 4096, 6144 or 8192 and make sure compress_pos_emb
          matches at 1,2,3 and 4</p>

          <p>python server.py --chat --model TheBloke_WizardLM-33B-V1-0-Uncensored-SuperHOT-8K-GPTQ
          --pre_layer 8 --loader exllama_HF --compress_pos_emb 4 --max_seq_len 8192
          --trust-remote-code</p>

          '
        raw: 'Here are the flags to run simultaneously with gpu and cpu. You can change
          pre_layer to whatever amount you want to load onto your gpu, and max_seq_len
          to however many tokens you want your model to generate at max, make sure
          its either 2048, 4096, 6144 or 8192 and make sure compress_pos_emb matches
          at 1,2,3 and 4


          python server.py --chat --model TheBloke_WizardLM-33B-V1-0-Uncensored-SuperHOT-8K-GPTQ
          --pre_layer 8 --loader exllama_HF --compress_pos_emb 4 --max_seq_len 8192
          --trust-remote-code'
        updatedAt: '2023-07-05T02:36:36.581Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - TheBloke
        - artur454324372662
    id: 64a4d71cdc0544712a6c28f7
    type: comment
  author: rombodawg
  content: 'Here are the flags to run simultaneously with gpu and cpu. You can change
    pre_layer to whatever amount you want to load onto your gpu, and max_seq_len to
    however many tokens you want your model to generate at max, make sure its either
    2048, 4096, 6144 or 8192 and make sure compress_pos_emb matches at 1,2,3 and 4


    python server.py --chat --model TheBloke_WizardLM-33B-V1-0-Uncensored-SuperHOT-8K-GPTQ
    --pre_layer 8 --loader exllama_HF --compress_pos_emb 4 --max_seq_len 8192 --trust-remote-code'
  created_at: 2023-07-05 01:36:12+00:00
  edited: true
  hidden: false
  id: 64a4d71cdc0544712a6c28f7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-07T12:47:14.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9666979312896729
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Cool, thanks for posting.</p>

          <p>What is performance like when CPU offloading?</p>

          '
        raw: 'Cool, thanks for posting.


          What is performance like when CPU offloading?'
        updatedAt: '2023-07-07T12:47:14.752Z'
      numEdits: 0
      reactions: []
    id: 64a809520f4bad61a44bd5d7
    type: comment
  author: TheBloke
  content: 'Cool, thanks for posting.


    What is performance like when CPU offloading?'
  created_at: 2023-07-07 11:47:14+00:00
  edited: false
  hidden: false
  id: 64a809520f4bad61a44bd5d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2023-07-07T21:52:54.000Z'
    data:
      edited: true
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8534708023071289
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: '<p>With this particular model i get 4 tokens a second with 10gb filled
          ni vram and 20 gb filled in system ram. However I am running XMP profile
          1 on my 64gb ram oc''d to 3600mz. And my evga xc3 ultra 3080 is overclocked
          with a memory OC of +400 and a gpu OC of +100. That does boost the performance
          a bit. Full specs bellow:</p>

          <p>Evga Rtx 3080 xc3 ultra 10gb vram<br>Ryzen 5600x CPU<br>64gb 3200mhz
          ram (OC to 3600mzhz)<br>msi b550 pro vhd wifi motherboard<br>750w powersupply</p>

          '
        raw: 'With this particular model i get 4 tokens a second with 10gb filled
          ni vram and 20 gb filled in system ram. However I am running XMP profile
          1 on my 64gb ram oc''d to 3600mz. And my evga xc3 ultra 3080 is overclocked
          with a memory OC of +400 and a gpu OC of +100. That does boost the performance
          a bit. Full specs bellow:


          Evga Rtx 3080 xc3 ultra 10gb vram

          Ryzen 5600x CPU

          64gb 3200mhz ram (OC to 3600mzhz)

          msi b550 pro vhd wifi motherboard

          750w powersupply'
        updatedAt: '2023-07-07T21:56:07.916Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TheBloke
    id: 64a889365a69e2ca88877bc2
    type: comment
  author: rombodawg
  content: 'With this particular model i get 4 tokens a second with 10gb filled ni
    vram and 20 gb filled in system ram. However I am running XMP profile 1 on my
    64gb ram oc''d to 3600mz. And my evga xc3 ultra 3080 is overclocked with a memory
    OC of +400 and a gpu OC of +100. That does boost the performance a bit. Full specs
    bellow:


    Evga Rtx 3080 xc3 ultra 10gb vram

    Ryzen 5600x CPU

    64gb 3200mhz ram (OC to 3600mzhz)

    msi b550 pro vhd wifi motherboard

    750w powersupply'
  created_at: 2023-07-07 20:52:54+00:00
  edited: true
  hidden: false
  id: 64a889365a69e2ca88877bc2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2023-07-07T21:55:48.000Z'
    data:
      edited: false
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.970167338848114
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: '<p>I should note that that 4 tk/s is the speed it starts at, it slows
          down to 2 tk/s after its running for a little while. </p>

          '
        raw: 'I should note that that 4 tk/s is the speed it starts at, it slows down
          to 2 tk/s after its running for a little while. '
        updatedAt: '2023-07-07T21:55:48.563Z'
      numEdits: 0
      reactions: []
    id: 64a889e4d14398e270888a28
    type: comment
  author: rombodawg
  content: 'I should note that that 4 tk/s is the speed it starts at, it slows down
    to 2 tk/s after its running for a little while. '
  created_at: 2023-07-07 20:55:48+00:00
  edited: false
  hidden: false
  id: 64a889e4d14398e270888a28
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-07T22:05:38.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9463945031166077
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>OK, so not unusable.  But pretty slow, and I would expect GGML to
          be faster. </p>

          <p>Have you tried KoboldCpp instead, with CUDA acceleration and partial
          GPU offloading?  It means you can''t use text-generation-webui, but KoboldCpp
          is quite a good GUI as well.</p>

          '
        raw: "OK, so not unusable.  But pretty slow, and I would expect GGML to be\
          \ faster. \n\nHave you tried KoboldCpp instead, with CUDA acceleration and\
          \ partial GPU offloading?  It means you can't use text-generation-webui,\
          \ but KoboldCpp is quite a good GUI as well."
        updatedAt: '2023-07-07T22:05:38.619Z'
      numEdits: 0
      reactions: []
    id: 64a88c32c5a0593b307e9b52
    type: comment
  author: TheBloke
  content: "OK, so not unusable.  But pretty slow, and I would expect GGML to be faster.\
    \ \n\nHave you tried KoboldCpp instead, with CUDA acceleration and partial GPU\
    \ offloading?  It means you can't use text-generation-webui, but KoboldCpp is\
    \ quite a good GUI as well."
  created_at: 2023-07-07 21:05:38+00:00
  edited: false
  hidden: false
  id: 64a88c32c5a0593b307e9b52
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2023-07-07T22:08:35.000Z'
    data:
      edited: false
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8984142541885376
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: '<p>Yea I have used koboldcpp, but I cant get over how these models
          require the "Start reply with" feature that oobagooba has to do anything
          right sometimes. They just plain dont follow instructions correctly a lot
          of the time unless you force them to. So that tends to be mostly why i avoid
          koboldcpp, not because i dont like it, but because the models suck and require
          alot of extra guidance </p>

          '
        raw: 'Yea I have used koboldcpp, but I cant get over how these models require
          the "Start reply with" feature that oobagooba has to do anything right sometimes.
          They just plain dont follow instructions correctly a lot of the time unless
          you force them to. So that tends to be mostly why i avoid koboldcpp, not
          because i dont like it, but because the models suck and require alot of
          extra guidance '
        updatedAt: '2023-07-07T22:08:35.683Z'
      numEdits: 0
      reactions: []
    id: 64a88ce331f620201dbf6a91
    type: comment
  author: rombodawg
  content: 'Yea I have used koboldcpp, but I cant get over how these models require
    the "Start reply with" feature that oobagooba has to do anything right sometimes.
    They just plain dont follow instructions correctly a lot of the time unless you
    force them to. So that tends to be mostly why i avoid koboldcpp, not because i
    dont like it, but because the models suck and require alot of extra guidance '
  created_at: 2023-07-07 21:08:35+00:00
  edited: false
  hidden: false
  id: 64a88ce331f620201dbf6a91
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TheBloke/WizardLM-33B-V1-0-Uncensored-SuperHOT-8K-GPTQ
repo_type: model
status: open
target_branch: null
title: Use these flags to run this model and any model thats GPTQ split between gpu
  and cpu if you dont have enough vram
