!!python/object:huggingface_hub.community.DiscussionWithDetails
author: msmilauer
conflicting_files: null
created_at: 2023-07-18 11:00:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/82c18e4dc975c711a3cfd3ce8799b1d6.svg
      fullname: Michael Smilauer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: msmilauer
      type: user
    createdAt: '2023-07-18T12:00:27.000Z'
    data:
      edited: false
      editors:
      - msmilauer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9183021783828735
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/82c18e4dc975c711a3cfd3ce8799b1d6.svg
          fullname: Michael Smilauer
          isHf: false
          isPro: false
          name: msmilauer
          type: user
        html: '<p>Hi, is this model available in 4-bit quantization?<br>Is this model
          suitable for multi-turn discussion?<br>Sorry for the noob questions.</p>

          '
        raw: "Hi, is this model available in 4-bit quantization?\r\nIs this model\
          \ suitable for multi-turn discussion?\r\nSorry for the noob questions."
        updatedAt: '2023-07-18T12:00:27.315Z'
      numEdits: 0
      reactions: []
    id: 64b67edbfdad8ff872a6183a
    type: comment
  author: msmilauer
  content: "Hi, is this model available in 4-bit quantization?\r\nIs this model suitable\
    \ for multi-turn discussion?\r\nSorry for the noob questions."
  created_at: 2023-07-18 11:00:27+00:00
  edited: false
  hidden: false
  id: 64b67edbfdad8ff872a6183a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-18T12:34:50.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6028082966804504
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yes, linked in the README :)</p>

          <h2 id="other-repositories-available">Other repositories available</h2>

          <ul>

          <li><a href="https://huggingface.co/Aeala/VicUnlocked-alpaca-65b-4bit">4-bit
          GPTQ models for GPU inference</a></li>

          <li><a href="https://huggingface.co/TheBloke/VicUnlocked-alpaca-65B-QLoRA-GGML">4-bit,
          5-bit, and 8-bit GGML models for CPU+GPU inference</a></li>

          <li><a href="https://huggingface.co/TheBloke/VicUnlocked-alpaca-65B-QLoRA-fp16">Original
          unquantised fp16 model in HF format</a></li>

          </ul>

          '
        raw: 'Yes, linked in the README :)


          ## Other repositories available


          * [4-bit GPTQ models for GPU inference](https://huggingface.co/Aeala/VicUnlocked-alpaca-65b-4bit)

          * [4-bit, 5-bit, and 8-bit GGML models for CPU+GPU inference](https://huggingface.co/TheBloke/VicUnlocked-alpaca-65B-QLoRA-GGML)

          * [Original unquantised fp16 model in HF format](https://huggingface.co/TheBloke/VicUnlocked-alpaca-65B-QLoRA-fp16)

          '
        updatedAt: '2023-07-18T12:34:50.623Z'
      numEdits: 0
      reactions: []
    id: 64b686eac67700d8a328215c
    type: comment
  author: TheBloke
  content: 'Yes, linked in the README :)


    ## Other repositories available


    * [4-bit GPTQ models for GPU inference](https://huggingface.co/Aeala/VicUnlocked-alpaca-65b-4bit)

    * [4-bit, 5-bit, and 8-bit GGML models for CPU+GPU inference](https://huggingface.co/TheBloke/VicUnlocked-alpaca-65B-QLoRA-GGML)

    * [Original unquantised fp16 model in HF format](https://huggingface.co/TheBloke/VicUnlocked-alpaca-65B-QLoRA-fp16)

    '
  created_at: 2023-07-18 11:34:50+00:00
  edited: false
  hidden: false
  id: 64b686eac67700d8a328215c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/VicUnlocked-alpaca-65B-QLoRA-fp16
repo_type: model
status: open
target_branch: null
title: 4-bit quantization
