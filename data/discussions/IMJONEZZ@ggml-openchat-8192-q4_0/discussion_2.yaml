!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Hoioi
conflicting_files: null
created_at: 2023-07-07 13:23:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d380e709fe0e95f8bb1684e961549013.svg
      fullname: Hut hiu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hoioi
      type: user
    createdAt: '2023-07-07T14:23:37.000Z'
    data:
      edited: false
      editors:
      - Hoioi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.61579430103302
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d380e709fe0e95f8bb1684e961549013.svg
          fullname: Hut hiu
          isHf: false
          isPro: false
          name: Hoioi
          type: user
        html: '<p>Can i use these ggml files with gpt4all or koboldcpp? </p>

          '
        raw: 'Can i use these ggml files with gpt4all or koboldcpp? '
        updatedAt: '2023-07-07T14:23:37.531Z'
      numEdits: 0
      reactions: []
    id: 64a81fe997d4408e93a27ad0
    type: comment
  author: Hoioi
  content: 'Can i use these ggml files with gpt4all or koboldcpp? '
  created_at: 2023-07-07 13:23:37+00:00
  edited: false
  hidden: false
  id: 64a81fe997d4408e93a27ad0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1627516866400-noauth.jpeg?w=200&h=200&f=face
      fullname: Christopher Brousseau
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: IMJONEZZ
      type: user
    createdAt: '2023-07-07T14:36:07.000Z'
    data:
      edited: false
      editors:
      - IMJONEZZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8241256475448608
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1627516866400-noauth.jpeg?w=200&h=200&f=face
          fullname: Christopher Brousseau
          isHf: false
          isPro: false
          name: IMJONEZZ
          type: user
        html: "<p>You can use these with anything compatible with the newer version\
          \ of llama.cpp, so yes to GPT4All, and idk for koboldcpp I haven\u2019t\
          \ used that. </p>\n"
        raw: "You can use these with anything compatible with the newer version of\
          \ llama.cpp, so yes to GPT4All, and idk for koboldcpp I haven\u2019t used\
          \ that. "
        updatedAt: '2023-07-07T14:36:07.403Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Hoioi
    id: 64a822d74a119b9cc67d7fcd
    type: comment
  author: IMJONEZZ
  content: "You can use these with anything compatible with the newer version of llama.cpp,\
    \ so yes to GPT4All, and idk for koboldcpp I haven\u2019t used that. "
  created_at: 2023-07-07 13:36:07+00:00
  edited: false
  hidden: false
  id: 64a822d74a119b9cc67d7fcd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d380e709fe0e95f8bb1684e961549013.svg
      fullname: Hut hiu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hoioi
      type: user
    createdAt: '2023-07-07T17:26:35.000Z'
    data:
      edited: false
      editors:
      - Hoioi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9912391901016235
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d380e709fe0e95f8bb1684e961549013.svg
          fullname: Hut hiu
          isHf: false
          isPro: false
          name: Hoioi
          type: user
        html: '<p>That''s nice. I was waiting for the q5_K_M version and since it
          wasn''t being uploaded, I would like to know is it possible that you release
          the q6_k version too? Actually q6_k has more accuracy than q5 versions and
          of course it uses more RAM. </p>

          '
        raw: 'That''s nice. I was waiting for the q5_K_M version and since it wasn''t
          being uploaded, I would like to know is it possible that you release the
          q6_k version too? Actually q6_k has more accuracy than q5 versions and of
          course it uses more RAM. '
        updatedAt: '2023-07-07T17:26:35.202Z'
      numEdits: 0
      reactions: []
    id: 64a84acbc5a0593b30771ee7
    type: comment
  author: Hoioi
  content: 'That''s nice. I was waiting for the q5_K_M version and since it wasn''t
    being uploaded, I would like to know is it possible that you release the q6_k
    version too? Actually q6_k has more accuracy than q5 versions and of course it
    uses more RAM. '
  created_at: 2023-07-07 16:26:35+00:00
  edited: false
  hidden: false
  id: 64a84acbc5a0593b30771ee7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1627516866400-noauth.jpeg?w=200&h=200&f=face
      fullname: Christopher Brousseau
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: IMJONEZZ
      type: user
    createdAt: '2023-07-09T00:50:51.000Z'
    data:
      edited: false
      editors:
      - IMJONEZZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9551102519035339
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1627516866400-noauth.jpeg?w=200&h=200&f=face
          fullname: Christopher Brousseau
          isHf: false
          isPro: false
          name: IMJONEZZ
          type: user
        html: '<p>q5_K_M quantization is incompatible with this model, currently,
          I''m looking into a way to hack it together because the naming schema is
          wrong. I can try for q6_k, yes.</p>

          '
        raw: q5_K_M quantization is incompatible with this model, currently, I'm looking
          into a way to hack it together because the naming schema is wrong. I can
          try for q6_k, yes.
        updatedAt: '2023-07-09T00:50:51.398Z'
      numEdits: 0
      reactions: []
    id: 64aa046be368492ab8e889fa
    type: comment
  author: IMJONEZZ
  content: q5_K_M quantization is incompatible with this model, currently, I'm looking
    into a way to hack it together because the naming schema is wrong. I can try for
    q6_k, yes.
  created_at: 2023-07-08 23:50:51+00:00
  edited: false
  hidden: false
  id: 64aa046be368492ab8e889fa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d380e709fe0e95f8bb1684e961549013.svg
      fullname: Hut hiu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hoioi
      type: user
    createdAt: '2023-07-09T00:54:06.000Z'
    data:
      edited: false
      editors:
      - Hoioi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7815008163452148
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d380e709fe0e95f8bb1684e961549013.svg
          fullname: Hut hiu
          isHf: false
          isPro: false
          name: Hoioi
          type: user
        html: '<p>If the vocabulary size of the model is 32001,both q5_K_M and q6_k
          are not possible to be generated. Is the vocabulary size 32001?</p>

          '
        raw: If the vocabulary size of the model is 32001,both q5_K_M and q6_k are
          not possible to be generated. Is the vocabulary size 32001?
        updatedAt: '2023-07-09T00:54:06.452Z'
      numEdits: 0
      reactions: []
    id: 64aa052eeaf3ada4ec76316e
    type: comment
  author: Hoioi
  content: If the vocabulary size of the model is 32001,both q5_K_M and q6_k are not
    possible to be generated. Is the vocabulary size 32001?
  created_at: 2023-07-08 23:54:06+00:00
  edited: false
  hidden: false
  id: 64aa052eeaf3ada4ec76316e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/d380e709fe0e95f8bb1684e961549013.svg
      fullname: Hut hiu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hoioi
      type: user
    createdAt: '2023-07-10T18:38:05.000Z'
    data:
      status: closed
    id: 64ac500d6864362a7eefeed2
    type: status-change
  author: Hoioi
  created_at: 2023-07-10 17:38:05+00:00
  id: 64ac500d6864362a7eefeed2
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: IMJONEZZ/ggml-openchat-8192-q4_0
repo_type: model
status: closed
target_branch: null
title: 'Are the GGML files gpt4all compatible? '
