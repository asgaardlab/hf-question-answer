!!python/object:huggingface_hub.community.DiscussionWithDetails
author: polax
conflicting_files: null
created_at: 2023-04-29 10:51:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
      fullname: tomi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: polax
      type: user
    createdAt: '2023-04-29T11:51:53.000Z'
    data:
      edited: false
      editors:
      - polax
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
          fullname: tomi
          isHf: false
          isPro: false
          name: polax
          type: user
        html: '<p>I installed the following models into the proper folder but can
          t make it work. control_v2p_sd15_mediapipe_face.safetensor+yaml (for Stable
          Diffusion 1.5)<br> It doesn t generate annotator result.<br>I am using google
          colab. the last ben. SD 1,5<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6330296016eecf0872907ddd/vSuOiGA3Gm6otnpQSzH8H.jpeg"><img
          alt="controlnetface.jpg" src="https://cdn-uploads.huggingface.co/production/uploads/6330296016eecf0872907ddd/vSuOiGA3Gm6otnpQSzH8H.jpeg"></a></p>

          '
        raw: "\r\nI installed the following models into the proper folder but can\
          \ t make it work. control_v2p_sd15_mediapipe_face.safetensor+yaml (for Stable\
          \ Diffusion 1.5)\r\n It doesn t generate annotator result.\r\nI am using\
          \ google colab. the last ben. SD 1,5\r\n![controlnetface.jpg](https://cdn-uploads.huggingface.co/production/uploads/6330296016eecf0872907ddd/vSuOiGA3Gm6otnpQSzH8H.jpeg)\r\
          \n"
        updatedAt: '2023-04-29T11:51:53.524Z'
      numEdits: 0
      reactions: []
    id: 644d04d95c1b4e14d0bf42c7
    type: comment
  author: polax
  content: "\r\nI installed the following models into the proper folder but can t\
    \ make it work. control_v2p_sd15_mediapipe_face.safetensor+yaml (for Stable Diffusion\
    \ 1.5)\r\n It doesn t generate annotator result.\r\nI am using google colab. the\
    \ last ben. SD 1,5\r\n![controlnetface.jpg](https://cdn-uploads.huggingface.co/production/uploads/6330296016eecf0872907ddd/vSuOiGA3Gm6otnpQSzH8H.jpeg)\r\
    \n"
  created_at: 2023-04-29 10:51:53+00:00
  edited: false
  hidden: false
  id: 644d04d95c1b4e14d0bf42c7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
      fullname: tomi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: polax
      type: user
    createdAt: '2023-04-29T13:10:33.000Z'
    data:
      edited: false
      editors:
      - polax
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
          fullname: tomi
          isHf: false
          isPro: false
          name: polax
          type: user
        html: '<p>-&gt; error: No module named ''mediapipe''<br>Loading model from
          cache: control_v2p_sd15_mediapipe_face [9c7784a9] Loading preprocessor:
          mediapipe_face preprocessor resolution = 512 Error running process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py
          Traceback (most recent call last): File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py",
          line 417, in process script.process(p, *script_args) File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py",
          line 1134, in process detected_map, is_image = preprocessor(input_image,
          res=preprocessor_resolution, thr_a=unit.threshold_a, thr_b=unit.threshold_b)
          File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/processor.py",
          line 111, in mediapipe_face from annotator.mediapipe_face import apply_mediapipe_face
          File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/<strong>init</strong>.py",
          line 1, in  from .mediapipe_face_common import generate_annotation File
          "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/mediapipe_face_common.py",
          line 3, in  import mediapipe as mp ModuleNotFoundError: No module named
          ''mediapipe'' 100% 30/30 [00:06&lt;00:00, 4.50it/s] 100% 30/30 [00:06&lt;00:00,
          4.50it/s] 100% 30/30 [00:06&lt;00:00, 4.46it/s] Loading weights [92970aa785]
          from /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.safetensors
          Applying xformers cross attention optimization. Weights loaded in 11.2s
          (load weights from disk: 9.8s, apply weights to model: 0.7s, move model
          to device: 0.7s). Loading model: control_v2p_sd15_mediapipe_face [9c7784a9]
          Loaded state_dict from [/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_v2p_sd15_mediapipe_face.safetensors]
          Loading config: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_v2p_sd15_mediapipe_face.yaml
          ControlNet model control_v2p_sd15_mediapipe_face [9c7784a9] loaded. Loading
          preprocessor: mediapipe_face preprocessor resolution = 704 Error running
          process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py
          Traceback (most recent call last): File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py",
          line 417, in process script.process(p, *script_args) File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py",
          line 1134, in process detected_map, is_image = preprocessor(input_image,
          res=preprocessor_resolution, thr_a=unit.threshold_a, thr_b=unit.threshold_b)
          File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/processor.py",
          line 111, in mediapipe_face from annotator.mediapipe_face import apply_mediapipe_face
          File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/__init__.py",
          line 1, in  from .mediapipe_face_common import generate_annotation File
          "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/mediapipe_face_common.py",
          line 3, in  import mediapipe as mp ModuleNotFoundError: No module named
          ''mediapipe'' 100% 30/30 [00:07&lt;00:00, 3.95it/s] 100% 30/30 [00:06&lt;00:00,
          4.67it/s] 100% 30/30 [00:06&lt;00:00, 4.62it/s] Loading model from cache:
          control_v2p_sd15_mediapipe_face [9c7784a9] Loading preprocessor: mediapipe_face
          preprocessor resolution = 704 Error running process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py
          Traceback (most recent call last): File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py",
          line 417, in process script.process(p, *script_args) File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py",
          line 1134, in process detected_map, is_image = preprocessor(input_image,
          res=preprocessor_resolution, thr_a=unit.threshold_a, thr_b=unit.threshold_b)
          File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/processor.py",
          line 111, in mediapipe_face from annotator.mediapipe_face import apply_mediapipe_face
          File "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/__init__.py",
          line 1, in  from .mediapipe_face_common import generate_annotation File
          "/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/mediapipe_face_common.py",
          line 3, in  import mediapipe as mp ModuleNotFoundError: No module named
          ''mediapipe''</p>

          '
        raw: "-> error: No module named 'mediapipe' \nLoading model from cache: control_v2p_sd15_mediapipe_face\
          \ [9c7784a9] Loading preprocessor: mediapipe_face preprocessor resolution\
          \ = 512 Error running process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\
          \ Traceback (most recent call last): File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\"\
          , line 417, in process script.process(p, *script_args) File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\"\
          , line 1134, in process detected_map, is_image = preprocessor(input_image,\
          \ res=preprocessor_resolution, thr_a=unit.threshold_a, thr_b=unit.threshold_b)\
          \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/processor.py\"\
          , line 111, in mediapipe_face from annotator.mediapipe_face import apply_mediapipe_face\
          \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/__init__.py\"\
          , line 1, in <module> from .mediapipe_face_common import generate_annotation\
          \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/mediapipe_face_common.py\"\
          , line 3, in <module> import mediapipe as mp ModuleNotFoundError: No module\
          \ named 'mediapipe' 100% 30/30 [00:06<00:00, 4.50it/s] 100% 30/30 [00:06<00:00,\
          \ 4.50it/s] 100% 30/30 [00:06<00:00, 4.46it/s] Loading weights [92970aa785]\
          \ from /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.safetensors\
          \ Applying xformers cross attention optimization. Weights loaded in 11.2s\
          \ (load weights from disk: 9.8s, apply weights to model: 0.7s, move model\
          \ to device: 0.7s). Loading model: control_v2p_sd15_mediapipe_face [9c7784a9]\
          \ Loaded state_dict from [/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_v2p_sd15_mediapipe_face.safetensors]\
          \ Loading config: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_v2p_sd15_mediapipe_face.yaml\
          \ ControlNet model control_v2p_sd15_mediapipe_face [9c7784a9] loaded. Loading\
          \ preprocessor: mediapipe_face preprocessor resolution = 704 Error running\
          \ process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\
          \ Traceback (most recent call last): File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\"\
          , line 417, in process script.process(p, *script_args) File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\"\
          , line 1134, in process detected_map, is_image = preprocessor(input_image,\
          \ res=preprocessor_resolution, thr_a=unit.threshold_a, thr_b=unit.threshold_b)\
          \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/processor.py\"\
          , line 111, in mediapipe_face from annotator.mediapipe_face import apply_mediapipe_face\
          \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/__init__.py\"\
          , line 1, in <module> from .mediapipe_face_common import generate_annotation\
          \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/mediapipe_face_common.py\"\
          , line 3, in <module> import mediapipe as mp ModuleNotFoundError: No module\
          \ named 'mediapipe' 100% 30/30 [00:07<00:00, 3.95it/s] 100% 30/30 [00:06<00:00,\
          \ 4.67it/s] 100% 30/30 [00:06<00:00, 4.62it/s] Loading model from cache:\
          \ control_v2p_sd15_mediapipe_face [9c7784a9] Loading preprocessor: mediapipe_face\
          \ preprocessor resolution = 704 Error running process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\
          \ Traceback (most recent call last): File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\"\
          , line 417, in process script.process(p, *script_args) File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\"\
          , line 1134, in process detected_map, is_image = preprocessor(input_image,\
          \ res=preprocessor_resolution, thr_a=unit.threshold_a, thr_b=unit.threshold_b)\
          \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/processor.py\"\
          , line 111, in mediapipe_face from annotator.mediapipe_face import apply_mediapipe_face\
          \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/__init__.py\"\
          , line 1, in <module> from .mediapipe_face_common import generate_annotation\
          \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/mediapipe_face_common.py\"\
          , line 3, in <module> import mediapipe as mp ModuleNotFoundError: No module\
          \ named 'mediapipe'"
        updatedAt: '2023-04-29T13:10:33.467Z'
      numEdits: 0
      reactions: []
    id: 644d1749fa94e93b0ec292c1
    type: comment
  author: polax
  content: "-> error: No module named 'mediapipe' \nLoading model from cache: control_v2p_sd15_mediapipe_face\
    \ [9c7784a9] Loading preprocessor: mediapipe_face preprocessor resolution = 512\
    \ Error running process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\
    \ Traceback (most recent call last): File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\"\
    , line 417, in process script.process(p, *script_args) File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\"\
    , line 1134, in process detected_map, is_image = preprocessor(input_image, res=preprocessor_resolution,\
    \ thr_a=unit.threshold_a, thr_b=unit.threshold_b) File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/processor.py\"\
    , line 111, in mediapipe_face from annotator.mediapipe_face import apply_mediapipe_face\
    \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/__init__.py\"\
    , line 1, in <module> from .mediapipe_face_common import generate_annotation File\
    \ \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/mediapipe_face_common.py\"\
    , line 3, in <module> import mediapipe as mp ModuleNotFoundError: No module named\
    \ 'mediapipe' 100% 30/30 [00:06<00:00, 4.50it/s] 100% 30/30 [00:06<00:00, 4.50it/s]\
    \ 100% 30/30 [00:06<00:00, 4.46it/s] Loading weights [92970aa785] from /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.safetensors\
    \ Applying xformers cross attention optimization. Weights loaded in 11.2s (load\
    \ weights from disk: 9.8s, apply weights to model: 0.7s, move model to device:\
    \ 0.7s). Loading model: control_v2p_sd15_mediapipe_face [9c7784a9] Loaded state_dict\
    \ from [/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_v2p_sd15_mediapipe_face.safetensors]\
    \ Loading config: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_v2p_sd15_mediapipe_face.yaml\
    \ ControlNet model control_v2p_sd15_mediapipe_face [9c7784a9] loaded. Loading\
    \ preprocessor: mediapipe_face preprocessor resolution = 704 Error running process:\
    \ /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\
    \ Traceback (most recent call last): File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\"\
    , line 417, in process script.process(p, *script_args) File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\"\
    , line 1134, in process detected_map, is_image = preprocessor(input_image, res=preprocessor_resolution,\
    \ thr_a=unit.threshold_a, thr_b=unit.threshold_b) File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/processor.py\"\
    , line 111, in mediapipe_face from annotator.mediapipe_face import apply_mediapipe_face\
    \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/__init__.py\"\
    , line 1, in <module> from .mediapipe_face_common import generate_annotation File\
    \ \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/mediapipe_face_common.py\"\
    , line 3, in <module> import mediapipe as mp ModuleNotFoundError: No module named\
    \ 'mediapipe' 100% 30/30 [00:07<00:00, 3.95it/s] 100% 30/30 [00:06<00:00, 4.67it/s]\
    \ 100% 30/30 [00:06<00:00, 4.62it/s] Loading model from cache: control_v2p_sd15_mediapipe_face\
    \ [9c7784a9] Loading preprocessor: mediapipe_face preprocessor resolution = 704\
    \ Error running process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\
    \ Traceback (most recent call last): File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\"\
    , line 417, in process script.process(p, *script_args) File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\"\
    , line 1134, in process detected_map, is_image = preprocessor(input_image, res=preprocessor_resolution,\
    \ thr_a=unit.threshold_a, thr_b=unit.threshold_b) File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/processor.py\"\
    , line 111, in mediapipe_face from annotator.mediapipe_face import apply_mediapipe_face\
    \ File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/__init__.py\"\
    , line 1, in <module> from .mediapipe_face_common import generate_annotation File\
    \ \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/mediapipe_face/mediapipe_face_common.py\"\
    , line 3, in <module> import mediapipe as mp ModuleNotFoundError: No module named\
    \ 'mediapipe'"
  created_at: 2023-04-29 12:10:33+00:00
  edited: false
  hidden: false
  id: 644d1749fa94e93b0ec292c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60a86aec17722074ec658f7e/JuDJOux1TT2ApTKGJXDpr.jpeg?w=200&h=200&f=face
      fullname: Joseph Catrambone
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JosephCatrambone
      type: user
    createdAt: '2023-05-01T16:46:27.000Z'
    data:
      edited: false
      editors:
      - JosephCatrambone
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60a86aec17722074ec658f7e/JuDJOux1TT2ApTKGJXDpr.jpeg?w=200&h=200&f=face
          fullname: Joseph Catrambone
          isHf: false
          isPro: false
          name: JosephCatrambone
          type: user
        html: '<p><code>error: No module named ''mediapipe''</code> means that mediapipe
          was either not found or not installed.  If you run ''pip install mediapipe''
          it should resolve the issue.</p>

          '
        raw: '`error: No module named ''mediapipe''` means that mediapipe was either
          not found or not installed.  If you run ''pip install mediapipe'' it should
          resolve the issue.'
        updatedAt: '2023-05-01T16:46:27.135Z'
      numEdits: 0
      reactions: []
    id: 644fece328774bd665daab4c
    type: comment
  author: JosephCatrambone
  content: '`error: No module named ''mediapipe''` means that mediapipe was either
    not found or not installed.  If you run ''pip install mediapipe'' it should resolve
    the issue.'
  created_at: 2023-05-01 15:46:27+00:00
  edited: false
  hidden: false
  id: 644fece328774bd665daab4c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4df1d8d8a299223f7254cc91b49f1a39.svg
      fullname: CQ king
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vikiiing
      type: user
    createdAt: '2023-05-01T17:28:18.000Z'
    data:
      edited: true
      editors:
      - Vikiiing
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4df1d8d8a299223f7254cc91b49f1a39.svg
          fullname: CQ king
          isHf: false
          isPro: false
          name: Vikiiing
          type: user
        html: '<p>the same issue,I use the controlnet V1.1.125, I  have  install mediapipe</p>

          <p>Loading model: control_v11f1e_sd15_tile_fp16 [3b860298]<br>Loaded state_dict
          from [E:\AI\sd-webui-aki-v4\sd-webui-aki-v4\extensions\sd-webui-controlnet\models\control_v11f1e_sd15_tile_fp16.safetensors]<br>Loading
          config: E:\AI\sd-webui-aki-v4\sd-webui-aki-v4\extensions\sd-webui-controlnet\models\control_v11f1e_sd15_tile.yaml<br>ControlNet
          model control_v11f1e_sd15_tile_fp16 [3b860298] loaded.<br>Loading preprocessor:
          tile_resample<br>preprocessor resolution = 64</p>

          <p>![P9~QU53GDFQU]<a rel="nofollow" href="mailto:U5GMM@35SX.png">U5GMM@35SX.png</a>](<a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63102c84236215d0b711f83f/oplW_UVAIBdmy9SZVqQJp.png">https://cdn-uploads.huggingface.co/production/uploads/63102c84236215d0b711f83f/oplW_UVAIBdmy9SZVqQJp.png</a>)</p>

          '
        raw: 'the same issue,I use the controlnet V1.1.125, I  have  install mediapipe


          Loading model: control_v11f1e_sd15_tile_fp16 [3b860298]

          Loaded state_dict from [E:\AI\sd-webui-aki-v4\sd-webui-aki-v4\extensions\sd-webui-controlnet\models\control_v11f1e_sd15_tile_fp16.safetensors]

          Loading config: E:\AI\sd-webui-aki-v4\sd-webui-aki-v4\extensions\sd-webui-controlnet\models\control_v11f1e_sd15_tile.yaml

          ControlNet model control_v11f1e_sd15_tile_fp16 [3b860298] loaded.

          Loading preprocessor: tile_resample

          preprocessor resolution = 64


          ![P9~QU53GDFQU]U5GMM@35SX.png](https://cdn-uploads.huggingface.co/production/uploads/63102c84236215d0b711f83f/oplW_UVAIBdmy9SZVqQJp.png)'
        updatedAt: '2023-05-01T17:39:42.129Z'
      numEdits: 4
      reactions: []
    id: 644ff6b220ba3e3e4bed7900
    type: comment
  author: Vikiiing
  content: 'the same issue,I use the controlnet V1.1.125, I  have  install mediapipe


    Loading model: control_v11f1e_sd15_tile_fp16 [3b860298]

    Loaded state_dict from [E:\AI\sd-webui-aki-v4\sd-webui-aki-v4\extensions\sd-webui-controlnet\models\control_v11f1e_sd15_tile_fp16.safetensors]

    Loading config: E:\AI\sd-webui-aki-v4\sd-webui-aki-v4\extensions\sd-webui-controlnet\models\control_v11f1e_sd15_tile.yaml

    ControlNet model control_v11f1e_sd15_tile_fp16 [3b860298] loaded.

    Loading preprocessor: tile_resample

    preprocessor resolution = 64


    ![P9~QU53GDFQU]U5GMM@35SX.png](https://cdn-uploads.huggingface.co/production/uploads/63102c84236215d0b711f83f/oplW_UVAIBdmy9SZVqQJp.png)'
  created_at: 2023-05-01 16:28:18+00:00
  edited: true
  hidden: false
  id: 644ff6b220ba3e3e4bed7900
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60a86aec17722074ec658f7e/JuDJOux1TT2ApTKGJXDpr.jpeg?w=200&h=200&f=face
      fullname: Joseph Catrambone
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JosephCatrambone
      type: user
    createdAt: '2023-05-01T19:13:32.000Z'
    data:
      edited: false
      editors:
      - JosephCatrambone
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60a86aec17722074ec658f7e/JuDJOux1TT2ApTKGJXDpr.jpeg?w=200&h=200&f=face
          fullname: Joseph Catrambone
          isHf: false
          isPro: false
          name: JosephCatrambone
          type: user
        html: '<p>If mediapipe is installed, it is possible that a face isn''t recognized
          by mediapipe.  (In the case of polax above, mediapipe is almost certainly
          not installed.)  Mediapipe is made to detect real photos, not to detect
          anime or drawings.  :(  Sadly it does not work well when detecting face
          drawings.  Try with a real photo as the driver instead of an illustration.</p>

          '
        raw: If mediapipe is installed, it is possible that a face isn't recognized
          by mediapipe.  (In the case of polax above, mediapipe is almost certainly
          not installed.)  Mediapipe is made to detect real photos, not to detect
          anime or drawings.  :(  Sadly it does not work well when detecting face
          drawings.  Try with a real photo as the driver instead of an illustration.
        updatedAt: '2023-05-01T19:13:32.726Z'
      numEdits: 0
      reactions: []
    id: 64500f5c577838187e0082a1
    type: comment
  author: JosephCatrambone
  content: If mediapipe is installed, it is possible that a face isn't recognized
    by mediapipe.  (In the case of polax above, mediapipe is almost certainly not
    installed.)  Mediapipe is made to detect real photos, not to detect anime or drawings.  :(  Sadly
    it does not work well when detecting face drawings.  Try with a real photo as
    the driver instead of an illustration.
  created_at: 2023-05-01 18:13:32+00:00
  edited: false
  hidden: false
  id: 64500f5c577838187e0082a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
      fullname: tomi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: polax
      type: user
    createdAt: '2023-05-01T20:36:16.000Z'
    data:
      edited: false
      editors:
      - polax
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
          fullname: tomi
          isHf: false
          isPro: false
          name: polax
          type: user
        html: '<blockquote>

          <p>If mediapipe is installed, it is possible that a face isn''t recognized
          by mediapipe.  (In the case of polax above, mediapipe is almost certainly
          not installed.)  Mediapipe is made to detect real photos, not to detect
          anime or drawings.  :(  Sadly it does not work well when detecting face
          drawings.  Try with a real photo as the driver instead of an illustration.</p>

          </blockquote>

          <p>thanks. it solved the problem</p>

          '
        raw: '> If mediapipe is installed, it is possible that a face isn''t recognized
          by mediapipe.  (In the case of polax above, mediapipe is almost certainly
          not installed.)  Mediapipe is made to detect real photos, not to detect
          anime or drawings.  :(  Sadly it does not work well when detecting face
          drawings.  Try with a real photo as the driver instead of an illustration.


          thanks. it solved the problem'
        updatedAt: '2023-05-01T20:36:16.469Z'
      numEdits: 0
      reactions: []
    id: 645022c0d5f7dafcfa68236d
    type: comment
  author: polax
  content: '> If mediapipe is installed, it is possible that a face isn''t recognized
    by mediapipe.  (In the case of polax above, mediapipe is almost certainly not
    installed.)  Mediapipe is made to detect real photos, not to detect anime or drawings.  :(  Sadly
    it does not work well when detecting face drawings.  Try with a real photo as
    the driver instead of an illustration.


    thanks. it solved the problem'
  created_at: 2023-05-01 19:36:16+00:00
  edited: false
  hidden: false
  id: 645022c0d5f7dafcfa68236d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
      fullname: tomi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: polax
      type: user
    createdAt: '2023-05-01T20:37:22.000Z'
    data:
      edited: false
      editors:
      - polax
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
          fullname: tomi
          isHf: false
          isPro: false
          name: polax
          type: user
        html: '<p>for large picture with people with small faces on images. it doesn
          t seem to work. any tips ?</p>

          '
        raw: for large picture with people with small faces on images. it doesn t
          seem to work. any tips ?
        updatedAt: '2023-05-01T20:37:22.810Z'
      numEdits: 0
      reactions: []
    id: 6450230220ba3e3e4bf11795
    type: comment
  author: polax
  content: for large picture with people with small faces on images. it doesn t seem
    to work. any tips ?
  created_at: 2023-05-01 19:37:22+00:00
  edited: false
  hidden: false
  id: 6450230220ba3e3e4bf11795
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60a86aec17722074ec658f7e/JuDJOux1TT2ApTKGJXDpr.jpeg?w=200&h=200&f=face
      fullname: Joseph Catrambone
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JosephCatrambone
      type: user
    createdAt: '2023-05-02T16:47:10.000Z'
    data:
      edited: false
      editors:
      - JosephCatrambone
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60a86aec17722074ec658f7e/JuDJOux1TT2ApTKGJXDpr.jpeg?w=200&h=200&f=face
          fullname: Joseph Catrambone
          isHf: false
          isPro: false
          name: JosephCatrambone
          type: user
        html: '<p>I think there''s a limit to how small the faces can be in an image.  When
          we were doing training we didn''t get much detail for faces that had fewer
          than 64 pixels; there just was''t enough information in them.  If you can
          crop the image to 512 by 512 that would be ideal.  Perhaps it''s worth trying
          a content-aware resize to preserve the faces while reducing the image?  Or
          you can try to produce the face annotation directly and disable the annotator.</p>

          '
        raw: I think there's a limit to how small the faces can be in an image.  When
          we were doing training we didn't get much detail for faces that had fewer
          than 64 pixels; there just was't enough information in them.  If you can
          crop the image to 512 by 512 that would be ideal.  Perhaps it's worth trying
          a content-aware resize to preserve the faces while reducing the image?  Or
          you can try to produce the face annotation directly and disable the annotator.
        updatedAt: '2023-05-02T16:47:10.314Z'
      numEdits: 0
      reactions: []
    id: 64513e8e41f3c769b90feb5b
    type: comment
  author: JosephCatrambone
  content: I think there's a limit to how small the faces can be in an image.  When
    we were doing training we didn't get much detail for faces that had fewer than
    64 pixels; there just was't enough information in them.  If you can crop the image
    to 512 by 512 that would be ideal.  Perhaps it's worth trying a content-aware
    resize to preserve the faces while reducing the image?  Or you can try to produce
    the face annotation directly and disable the annotator.
  created_at: 2023-05-02 15:47:10+00:00
  edited: false
  hidden: false
  id: 64513e8e41f3c769b90feb5b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
      fullname: tomi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: polax
      type: user
    createdAt: '2023-05-02T19:56:09.000Z'
    data:
      edited: false
      editors:
      - polax
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
          fullname: tomi
          isHf: false
          isPro: false
          name: polax
          type: user
        html: '<p>here it is an example. the less small example. still not working
          for thoses faces.<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6330296016eecf0872907ddd/FLIIr--VAwYOOikHwO5U6.jpeg"><img
          alt="bath.jpg" src="https://cdn-uploads.huggingface.co/production/uploads/6330296016eecf0872907ddd/FLIIr--VAwYOOikHwO5U6.jpeg"></a></p>

          '
        raw: 'here it is an example. the less small example. still not working for
          thoses faces.

          ![bath.jpg](https://cdn-uploads.huggingface.co/production/uploads/6330296016eecf0872907ddd/FLIIr--VAwYOOikHwO5U6.jpeg)'
        updatedAt: '2023-05-02T19:56:09.996Z'
      numEdits: 0
      reactions: []
    id: 64516ad9b3f75261a7dbc426
    type: comment
  author: polax
  content: 'here it is an example. the less small example. still not working for thoses
    faces.

    ![bath.jpg](https://cdn-uploads.huggingface.co/production/uploads/6330296016eecf0872907ddd/FLIIr--VAwYOOikHwO5U6.jpeg)'
  created_at: 2023-05-02 18:56:09+00:00
  edited: false
  hidden: false
  id: 64516ad9b3f75261a7dbc426
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
      fullname: tomi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: polax
      type: user
    createdAt: '2023-05-02T19:57:49.000Z'
    data:
      edited: false
      editors:
      - polax
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
          fullname: tomi
          isHf: false
          isPro: false
          name: polax
          type: user
        html: '<p>what do you mean by this "trying a content-aware resize to preserve
          the faces while reducing the image"<br>how can I produce face annotation
          directly?</p>

          '
        raw: "what do you mean by this \"trying a content-aware resize to preserve\
          \ the faces while reducing the image\" \nhow can I produce face annotation\
          \ directly?"
        updatedAt: '2023-05-02T19:57:49.815Z'
      numEdits: 0
      reactions: []
    id: 64516b3db3f75261a7dbd48e
    type: comment
  author: polax
  content: "what do you mean by this \"trying a content-aware resize to preserve the\
    \ faces while reducing the image\" \nhow can I produce face annotation directly?"
  created_at: 2023-05-02 18:57:49+00:00
  edited: false
  hidden: false
  id: 64516b3db3f75261a7dbd48e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60a86aec17722074ec658f7e/JuDJOux1TT2ApTKGJXDpr.jpeg?w=200&h=200&f=face
      fullname: Joseph Catrambone
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JosephCatrambone
      type: user
    createdAt: '2023-05-03T21:11:15.000Z'
    data:
      edited: false
      editors:
      - JosephCatrambone
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60a86aec17722074ec658f7e/JuDJOux1TT2ApTKGJXDpr.jpeg?w=200&h=200&f=face
          fullname: Joseph Catrambone
          isHf: false
          isPro: false
          name: JosephCatrambone
          type: user
        html: '<p>It is possible to use an image editing program to copy/paste recognized
          faces into any configuration that you desire.  For example: toyxyz has done
          something like this: <a rel="nofollow" href="https://twitter.com/toyxyz3/status/1644356993342386176">https://twitter.com/toyxyz3/status/1644356993342386176</a></p>

          <p>Before that, though, I would recommend increasing "max faces" from 1
          to 3, as there are three faces in that picture.  I would also decrease "min
          face confidence" to make it more likely that a face will be detected.  (Note:
          this might cause things that are <em>not</em> faces to be detected.)</p>

          '
        raw: 'It is possible to use an image editing program to copy/paste recognized
          faces into any configuration that you desire.  For example: toyxyz has done
          something like this: https://twitter.com/toyxyz3/status/1644356993342386176


          Before that, though, I would recommend increasing "max faces" from 1 to
          3, as there are three faces in that picture.  I would also decrease "min
          face confidence" to make it more likely that a face will be detected.  (Note:
          this might cause things that are _not_ faces to be detected.)'
        updatedAt: '2023-05-03T21:11:15.673Z'
      numEdits: 0
      reactions: []
    id: 6452cdf33a794b2d9b16edc6
    type: comment
  author: JosephCatrambone
  content: 'It is possible to use an image editing program to copy/paste recognized
    faces into any configuration that you desire.  For example: toyxyz has done something
    like this: https://twitter.com/toyxyz3/status/1644356993342386176


    Before that, though, I would recommend increasing "max faces" from 1 to 3, as
    there are three faces in that picture.  I would also decrease "min face confidence"
    to make it more likely that a face will be detected.  (Note: this might cause
    things that are _not_ faces to be detected.)'
  created_at: 2023-05-03 20:11:15+00:00
  edited: false
  hidden: false
  id: 6452cdf33a794b2d9b16edc6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
      fullname: tomi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: polax
      type: user
    createdAt: '2023-05-06T13:15:25.000Z'
    data:
      edited: false
      editors:
      - polax
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a87c62e32d3fba50cfa646b154b7916b.svg
          fullname: tomi
          isHf: false
          isPro: false
          name: polax
          type: user
        html: '<p>thanks but you can t go further than 2 for the max faces. if you
          create your own annotation with photoshop for example. does it work?</p>

          '
        raw: thanks but you can t go further than 2 for the max faces. if you create
          your own annotation with photoshop for example. does it work?
        updatedAt: '2023-05-06T13:15:25.792Z'
      numEdits: 0
      reactions: []
    id: 645652ed03625871eb741461
    type: comment
  author: polax
  content: thanks but you can t go further than 2 for the max faces. if you create
    your own annotation with photoshop for example. does it work?
  created_at: 2023-05-06 12:15:25+00:00
  edited: false
  hidden: false
  id: 645652ed03625871eb741461
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60a86aec17722074ec658f7e/JuDJOux1TT2ApTKGJXDpr.jpeg?w=200&h=200&f=face
      fullname: Joseph Catrambone
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JosephCatrambone
      type: user
    createdAt: '2023-05-08T19:44:17.000Z'
    data:
      edited: false
      editors:
      - JosephCatrambone
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60a86aec17722074ec658f7e/JuDJOux1TT2ApTKGJXDpr.jpeg?w=200&h=200&f=face
          fullname: Joseph Catrambone
          isHf: false
          isPro: false
          name: JosephCatrambone
          type: user
        html: '<p>It should be possible to go up to ten for the max faces.</p>

          <p>I''ve been able to create annotations manually in an image editor, yes.</p>

          '
        raw: 'It should be possible to go up to ten for the max faces.


          I''ve been able to create annotations manually in an image editor, yes.'
        updatedAt: '2023-05-08T19:44:17.046Z'
      numEdits: 0
      reactions: []
    id: 6459511139e6aea69cc3f988
    type: comment
  author: JosephCatrambone
  content: 'It should be possible to go up to ten for the max faces.


    I''ve been able to create annotations manually in an image editor, yes.'
  created_at: 2023-05-08 18:44:17+00:00
  edited: false
  hidden: false
  id: 6459511139e6aea69cc3f988
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 21
repo_id: CrucibleAI/ControlNetMediaPipeFace
repo_type: model
status: open
target_branch: null
title: No annotator result
