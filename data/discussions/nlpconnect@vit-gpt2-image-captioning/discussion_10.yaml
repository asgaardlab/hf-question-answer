!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SRDdev
conflicting_files: null
created_at: 2022-12-18 08:06:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62600854000b49a547738c98/j_xVztYnc0sI-A0xd98k6.png?w=200&h=200&f=face
      fullname: Shreyas Dixit
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SRDdev
      type: user
    createdAt: '2022-12-18T08:06:45.000Z'
    data:
      edited: false
      editors:
      - SRDdev
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62600854000b49a547738c98/j_xVztYnc0sI-A0xd98k6.png?w=200&h=200&f=face
          fullname: Shreyas Dixit
          isHf: false
          isPro: false
          name: SRDdev
          type: user
        html: '<p>I am a student learning to use transformers on huggingface.</p>

          <ul>

          <li><p>I am facing an issue in creating a Hosted Inference API , as the
          pipeline gives an error of "Unidentified feature_extractor" while building
          the pipeline. So to fix this issue I manually made changes in <code>preprocessor_config.json</code>
          as it was containing <b>"image_processor_type": "ViTImageProcessor" </b>.<br>I
          crosschecked with your file and it shows <b>"feature_extractor": "ViTFeatureExtractor"
          </b>.<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1671350797413-62600854000b49a547738c98.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1671350797413-62600854000b49a547738c98.png"></a></p>

          </li>

          <li><p>Another issue is if I manually change the file and the pipeline is
          built then while calling the pipeline  <b><code>"captioner("image.jpg")"</code></b>
          , it throws an error saying <code>preprocess_fn() got an unexpected keyword
          argument ''images''</code><br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1671350774062-62600854000b49a547738c98.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1671350774062-62600854000b49a547738c98.png"></a></p>

          </li>

          </ul>

          <p>I am quite new to Pytorch and Huggingface, it would be a great help if
          you could help me with this issue.</p>

          <p>Thank you </p>

          '
        raw: "I am a student learning to use transformers on huggingface.\r\n- I am\
          \ facing an issue in creating a Hosted Inference API , as the pipeline gives\
          \ an error of \"Unidentified feature_extractor\" while building the pipeline.\
          \ So to fix this issue I manually made changes in `preprocessor_config.json`\
          \ as it was containing <b>\"image_processor_type\": \"ViTImageProcessor\"\
          \ </b>. \r\nI crosschecked with your file and it shows <b>\"feature_extractor\"\
          : \"ViTFeatureExtractor\" </b>. \r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1671350797413-62600854000b49a547738c98.png)\r\
          \n\r\n\r\n- Another issue is if I manually change the file and the pipeline\
          \ is built then while calling the pipeline  <b>`\"captioner(\"image.jpg\"\
          )\"`</b> , it throws an error saying `preprocess_fn() got an unexpected\
          \ keyword argument 'images'`\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1671350774062-62600854000b49a547738c98.png)\r\
          \n\r\nI am quite new to Pytorch and Huggingface, it would be a great help\
          \ if you could help me with this issue.\r\n\r\nThank you "
        updatedAt: '2022-12-18T08:06:45.364Z'
      numEdits: 0
      reactions: []
    id: 639eca15beb95d698dd12d80
    type: comment
  author: SRDdev
  content: "I am a student learning to use transformers on huggingface.\r\n- I am\
    \ facing an issue in creating a Hosted Inference API , as the pipeline gives an\
    \ error of \"Unidentified feature_extractor\" while building the pipeline. So\
    \ to fix this issue I manually made changes in `preprocessor_config.json` as it\
    \ was containing <b>\"image_processor_type\": \"ViTImageProcessor\" </b>. \r\n\
    I crosschecked with your file and it shows <b>\"feature_extractor\": \"ViTFeatureExtractor\"\
    \ </b>. \r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1671350797413-62600854000b49a547738c98.png)\r\
    \n\r\n\r\n- Another issue is if I manually change the file and the pipeline is\
    \ built then while calling the pipeline  <b>`\"captioner(\"image.jpg\")\"`</b>\
    \ , it throws an error saying `preprocess_fn() got an unexpected keyword argument\
    \ 'images'`\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1671350774062-62600854000b49a547738c98.png)\r\
    \n\r\nI am quite new to Pytorch and Huggingface, it would be a great help if you\
    \ could help me with this issue.\r\n\r\nThank you "
  created_at: 2022-12-18 08:06:45+00:00
  edited: false
  hidden: false
  id: 639eca15beb95d698dd12d80
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1599133184264-noauth.jpeg?w=200&h=200&f=face
      fullname: Ankur Singh
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ankur310794
      type: user
    createdAt: '2022-12-18T09:56:32.000Z'
    data:
      edited: false
      editors:
      - ankur310794
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1599133184264-noauth.jpeg?w=200&h=200&f=face
          fullname: Ankur Singh
          isHf: false
          isPro: false
          name: ankur310794
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;SRDdev&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/SRDdev\">@<span class=\"\
          underline\">SRDdev</span></a></span>\n\n\t</span></span> </p>\n<ol>\n<li>I\
          \ have checked this, I am also getting same error, this is because of hugging\
          \ face is changing the feature extractor with image processor, you may see\
          \ <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/blob/7032e0203262ebb2ebf55da8d2e01f873973e835/src/transformers/models/vit/feature_extraction_vit.py#L29\"\
          >https://github.com/huggingface/transformers/blob/7032e0203262ebb2ebf55da8d2e01f873973e835/src/transformers/models/vit/feature_extraction_vit.py#L29</a><br>I\
          \ feel there is an error in package that why we are getting this.</li>\n\
          </ol>\n<p>Solution would be for now just change \"feature_extractor_type\"\
          : \"ViTFeatureExtractor\", as you already did and able to load.</p>\n<ol\
          \ start=\"2\">\n<li>For the 2nd issue I am not getting any error in inferencing\
          \ with pipeline. Feels like again it is a package version problem.</li>\n\
          </ol>\n"
        raw: "@SRDdev \n\n1. I have checked this, I am also getting same error, this\
          \ is because of hugging face is changing the feature extractor with image\
          \ processor, you may see https://github.com/huggingface/transformers/blob/7032e0203262ebb2ebf55da8d2e01f873973e835/src/transformers/models/vit/feature_extraction_vit.py#L29\n\
          I feel there is an error in package that why we are getting this. \n\nSolution\
          \ would be for now just change \"feature_extractor_type\": \"ViTFeatureExtractor\"\
          , as you already did and able to load.\n\n2. For the 2nd issue I am not\
          \ getting any error in inferencing with pipeline. Feels like again it is\
          \ a package version problem."
        updatedAt: '2022-12-18T09:56:32.219Z'
      numEdits: 0
      reactions: []
    id: 639ee3d09f1f2baab2eb593d
    type: comment
  author: ankur310794
  content: "@SRDdev \n\n1. I have checked this, I am also getting same error, this\
    \ is because of hugging face is changing the feature extractor with image processor,\
    \ you may see https://github.com/huggingface/transformers/blob/7032e0203262ebb2ebf55da8d2e01f873973e835/src/transformers/models/vit/feature_extraction_vit.py#L29\n\
    I feel there is an error in package that why we are getting this. \n\nSolution\
    \ would be for now just change \"feature_extractor_type\": \"ViTFeatureExtractor\"\
    , as you already did and able to load.\n\n2. For the 2nd issue I am not getting\
    \ any error in inferencing with pipeline. Feels like again it is a package version\
    \ problem."
  created_at: 2022-12-18 09:56:32+00:00
  edited: false
  hidden: false
  id: 639ee3d09f1f2baab2eb593d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62600854000b49a547738c98/j_xVztYnc0sI-A0xd98k6.png?w=200&h=200&f=face
      fullname: Shreyas Dixit
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SRDdev
      type: user
    createdAt: '2022-12-18T10:00:21.000Z'
    data:
      edited: false
      editors:
      - SRDdev
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62600854000b49a547738c98/j_xVztYnc0sI-A0xd98k6.png?w=200&h=200&f=face
          fullname: Shreyas Dixit
          isHf: false
          isPro: false
          name: SRDdev
          type: user
        html: '<p>Can I load a previous version of the pipeline package and solve
          this issue?</p>

          '
        raw: Can I load a previous version of the pipeline package and solve this
          issue?
        updatedAt: '2022-12-18T10:00:21.280Z'
      numEdits: 0
      reactions: []
    id: 639ee4b5beb95d698dd3316b
    type: comment
  author: SRDdev
  content: Can I load a previous version of the pipeline package and solve this issue?
  created_at: 2022-12-18 10:00:21+00:00
  edited: false
  hidden: false
  id: 639ee4b5beb95d698dd3316b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62600854000b49a547738c98/j_xVztYnc0sI-A0xd98k6.png?w=200&h=200&f=face
      fullname: Shreyas Dixit
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SRDdev
      type: user
    createdAt: '2022-12-18T11:50:18.000Z'
    data:
      edited: false
      editors:
      - SRDdev
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62600854000b49a547738c98/j_xVztYnc0sI-A0xd98k6.png?w=200&h=200&f=face
          fullname: Shreyas Dixit
          isHf: false
          isPro: false
          name: SRDdev
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1671364133513-62600854000b49a547738c98.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1671364133513-62600854000b49a547738c98.png"></a><br>The
          pipeline issue is resolved but the Generated sentence is not yet accurate
          is it only because I have trained on the demo dataset of ydshieh/coco_dataset_script<br>Or
          there might be some issue ?</p>

          '
        raw: '![image.png](https://cdn-uploads.huggingface.co/production/uploads/1671364133513-62600854000b49a547738c98.png)

          The pipeline issue is resolved but the Generated sentence is not yet accurate
          is it only because I have trained on the demo dataset of ydshieh/coco_dataset_script

          Or there might be some issue ?'
        updatedAt: '2022-12-18T11:50:18.845Z'
      numEdits: 0
      reactions: []
    id: 639efe7abeb95d698dd52b9f
    type: comment
  author: SRDdev
  content: '![image.png](https://cdn-uploads.huggingface.co/production/uploads/1671364133513-62600854000b49a547738c98.png)

    The pipeline issue is resolved but the Generated sentence is not yet accurate
    is it only because I have trained on the demo dataset of ydshieh/coco_dataset_script

    Or there might be some issue ?'
  created_at: 2022-12-18 11:50:18+00:00
  edited: false
  hidden: false
  id: 639efe7abeb95d698dd52b9f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1599133184264-noauth.jpeg?w=200&h=200&f=face
      fullname: Ankur Singh
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ankur310794
      type: user
    createdAt: '2022-12-18T14:36:34.000Z'
    data:
      edited: false
      editors:
      - ankur310794
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1599133184264-noauth.jpeg?w=200&h=200&f=face
          fullname: Ankur Singh
          isHf: false
          isPro: false
          name: ankur310794
          type: user
        html: '<p>yes right, it is very small set.<br>You need to train on larger
          set.</p>

          '
        raw: "yes right, it is very small set. \nYou need to train on larger set."
        updatedAt: '2022-12-18T14:36:34.010Z'
      numEdits: 0
      reactions: []
    id: 639f25729f1f2baab2f0b0d7
    type: comment
  author: ankur310794
  content: "yes right, it is very small set. \nYou need to train on larger set."
  created_at: 2022-12-18 14:36:34+00:00
  edited: false
  hidden: false
  id: 639f25729f1f2baab2f0b0d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62600854000b49a547738c98/j_xVztYnc0sI-A0xd98k6.png?w=200&h=200&f=face
      fullname: Shreyas Dixit
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SRDdev
      type: user
    createdAt: '2022-12-18T14:38:45.000Z'
    data:
      edited: false
      editors:
      - SRDdev
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62600854000b49a547738c98/j_xVztYnc0sI-A0xd98k6.png?w=200&h=200&f=face
          fullname: Shreyas Dixit
          isHf: false
          isPro: false
          name: SRDdev
          type: user
        html: "<p>Thank you so much!<br>I had this issue for a week and today I got\
          \ it solved!<br>Thanks again \U0001F64F\U0001F3FB</p>\n"
        raw: "Thank you so much!\nI had this issue for a week and today I got it solved!\n\
          Thanks again \U0001F64F\U0001F3FB"
        updatedAt: '2022-12-18T14:38:45.517Z'
      numEdits: 0
      reactions: []
      relatedEventId: 639f25f50d679f53943392f6
    id: 639f25f50d679f53943392f5
    type: comment
  author: SRDdev
  content: "Thank you so much!\nI had this issue for a week and today I got it solved!\n\
    Thanks again \U0001F64F\U0001F3FB"
  created_at: 2022-12-18 14:38:45+00:00
  edited: false
  hidden: false
  id: 639f25f50d679f53943392f5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62600854000b49a547738c98/j_xVztYnc0sI-A0xd98k6.png?w=200&h=200&f=face
      fullname: Shreyas Dixit
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SRDdev
      type: user
    createdAt: '2022-12-18T14:38:45.000Z'
    data:
      status: closed
    id: 639f25f50d679f53943392f6
    type: status-change
  author: SRDdev
  created_at: 2022-12-18 14:38:45+00:00
  id: 639f25f50d679f53943392f6
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1599133184264-noauth.jpeg?w=200&h=200&f=face
      fullname: Ankur Singh
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ankur310794
      type: user
    createdAt: '2022-12-19T13:04:06.000Z'
    data:
      edited: false
      editors:
      - ankur310794
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1599133184264-noauth.jpeg?w=200&h=200&f=face
          fullname: Ankur Singh
          isHf: false
          isPro: false
          name: ankur310794
          type: user
        html: "<h1 id=\"to-train-on-a-large-set-you-can-use-a-torch-data-iterator\"\
          >To train on a large set, you can use a torch data iterator.</h1>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">import</span> torch\n\
          <span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\"\
          >import</span> Image\n<span class=\"hljs-keyword\">class</span> <span class=\"\
          hljs-title class_\">ImageCapatioingDataset</span>(torch.utils.data.Dataset):\n\
          \    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >__init__</span>(<span class=\"hljs-params\">self, ds, ds_type, max_target_length</span>):\n\
          \        self.ds = ds\n        self.max_target_length = max_target_length\n\
          \        self.ds_type = ds_type\n\n    <span class=\"hljs-keyword\">def</span>\
          \ <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"\
          hljs-params\">self, idx</span>):\n        image_path = self.ds[self.ds_type][<span\
          \ class=\"hljs-string\">'image_path'</span>][idx]\n        caption = self.ds[self.ds_type][<span\
          \ class=\"hljs-string\">'caption'</span>][idx]\n        model_inputs = <span\
          \ class=\"hljs-built_in\">dict</span>()\n        model_inputs[<span class=\"\
          hljs-string\">'labels'</span>] = self.tokenization_fn(caption, self.max_target_length)\n\
          \        model_inputs[<span class=\"hljs-string\">'pixel_values'</span>]\
          \ = self.feature_extraction_fn(image_path)\n        <span class=\"hljs-keyword\"\
          >return</span> model_inputs\n\n    <span class=\"hljs-keyword\">def</span>\
          \ <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\"\
          >self</span>):\n        <span class=\"hljs-keyword\">return</span> <span\
          \ class=\"hljs-built_in\">len</span>(self.ds[self.ds_type])\n    \n    <span\
          \ class=\"hljs-comment\"># text preprocessing step</span>\n    <span class=\"\
          hljs-keyword\">def</span> <span class=\"hljs-title function_\">tokenization_fn</span>(<span\
          \ class=\"hljs-params\">self, caption, max_target_length</span>):\n    \
          \    <span class=\"hljs-string\">\"\"\"Run tokenization on caption.\"\"\"\
          </span>\n        labels = tokenizer(caption, \n                        \
          \  padding=<span class=\"hljs-string\">\"max_length\"</span>, \n       \
          \                   max_length=max_target_length).input_ids\n\n        <span\
          \ class=\"hljs-keyword\">return</span> labels\n    \n    <span class=\"\
          hljs-comment\"># image preprocessing step</span>\n    <span class=\"hljs-keyword\"\
          >def</span> <span class=\"hljs-title function_\">feature_extraction_fn</span>(<span\
          \ class=\"hljs-params\">self, image_path</span>):\n        <span class=\"\
          hljs-string\">\"\"\"</span>\n<span class=\"hljs-string\">        Run feature\
          \ extraction on images</span>\n<span class=\"hljs-string\">        If `check_image`\
          \ is `True`, the examples that fails during `Image.open()` will be caught\
          \ and discarded.</span>\n<span class=\"hljs-string\">        Otherwise,\
          \ an exception will be thrown.</span>\n<span class=\"hljs-string\">    \
          \    \"\"\"</span>\n        image = Image.<span class=\"hljs-built_in\"\
          >open</span>(image_path)\n\n        encoder_inputs = feature_extractor(images=image,\
          \ return_tensors=<span class=\"hljs-string\">\"np\"</span>)\n\n        <span\
          \ class=\"hljs-keyword\">return</span> encoder_inputs.pixel_values[<span\
          \ class=\"hljs-number\">0</span>]\n\n\ntrain_ds = ImageCapatioingDataset(ds,\
          \ <span class=\"hljs-string\">'train'</span>, <span class=\"hljs-number\"\
          >64</span>)\neval_ds = ImageCapatioingDataset(ds, <span class=\"hljs-string\"\
          >'validation'</span>, <span class=\"hljs-number\">64</span>)\n\n\n<span\
          \ class=\"hljs-comment\"># instantiate trainer</span>\ntrainer = Seq2SeqTrainer(\n\
          \    model=model,\n    tokenizer=feature_extractor,\n    args=training_args,\n\
          \    compute_metrics=compute_metrics,\n    train_dataset=train_ds,\n   \
          \ eval_dataset=eval_ds,\n    data_collator=default_data_collator,\n)\n</code></pre>\n"
        raw: "# To train on a large set, you can use a torch data iterator.\n```python\n\
          import torch\nfrom PIL import Image\nclass ImageCapatioingDataset(torch.utils.data.Dataset):\n\
          \    def __init__(self, ds, ds_type, max_target_length):\n        self.ds\
          \ = ds\n        self.max_target_length = max_target_length\n        self.ds_type\
          \ = ds_type\n\n    def __getitem__(self, idx):\n        image_path = self.ds[self.ds_type]['image_path'][idx]\n\
          \        caption = self.ds[self.ds_type]['caption'][idx]\n        model_inputs\
          \ = dict()\n        model_inputs['labels'] = self.tokenization_fn(caption,\
          \ self.max_target_length)\n        model_inputs['pixel_values'] = self.feature_extraction_fn(image_path)\n\
          \        return model_inputs\n\n    def __len__(self):\n        return len(self.ds[self.ds_type])\n\
          \    \n    # text preprocessing step\n    def tokenization_fn(self, caption,\
          \ max_target_length):\n        \"\"\"Run tokenization on caption.\"\"\"\n\
          \        labels = tokenizer(caption, \n                          padding=\"\
          max_length\", \n                          max_length=max_target_length).input_ids\n\
          \n        return labels\n    \n    # image preprocessing step\n    def feature_extraction_fn(self,\
          \ image_path):\n        \"\"\"\n        Run feature extraction on images\n\
          \        If `check_image` is `True`, the examples that fails during `Image.open()`\
          \ will be caught and discarded.\n        Otherwise, an exception will be\
          \ thrown.\n        \"\"\"\n        image = Image.open(image_path)\n\n  \
          \      encoder_inputs = feature_extractor(images=image, return_tensors=\"\
          np\")\n\n        return encoder_inputs.pixel_values[0]\n\n\ntrain_ds = ImageCapatioingDataset(ds,\
          \ 'train', 64)\neval_ds = ImageCapatioingDataset(ds, 'validation', 64)\n\
          \n\n# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n\
          \    tokenizer=feature_extractor,\n    args=training_args,\n    compute_metrics=compute_metrics,\n\
          \    train_dataset=train_ds,\n    eval_dataset=eval_ds,\n    data_collator=default_data_collator,\n\
          )\n```"
        updatedAt: '2022-12-19T13:04:06.619Z'
      numEdits: 0
      reactions: []
    id: 63a061466b087d7413c2aa8b
    type: comment
  author: ankur310794
  content: "# To train on a large set, you can use a torch data iterator.\n```python\n\
    import torch\nfrom PIL import Image\nclass ImageCapatioingDataset(torch.utils.data.Dataset):\n\
    \    def __init__(self, ds, ds_type, max_target_length):\n        self.ds = ds\n\
    \        self.max_target_length = max_target_length\n        self.ds_type = ds_type\n\
    \n    def __getitem__(self, idx):\n        image_path = self.ds[self.ds_type]['image_path'][idx]\n\
    \        caption = self.ds[self.ds_type]['caption'][idx]\n        model_inputs\
    \ = dict()\n        model_inputs['labels'] = self.tokenization_fn(caption, self.max_target_length)\n\
    \        model_inputs['pixel_values'] = self.feature_extraction_fn(image_path)\n\
    \        return model_inputs\n\n    def __len__(self):\n        return len(self.ds[self.ds_type])\n\
    \    \n    # text preprocessing step\n    def tokenization_fn(self, caption, max_target_length):\n\
    \        \"\"\"Run tokenization on caption.\"\"\"\n        labels = tokenizer(caption,\
    \ \n                          padding=\"max_length\", \n                     \
    \     max_length=max_target_length).input_ids\n\n        return labels\n    \n\
    \    # image preprocessing step\n    def feature_extraction_fn(self, image_path):\n\
    \        \"\"\"\n        Run feature extraction on images\n        If `check_image`\
    \ is `True`, the examples that fails during `Image.open()` will be caught and\
    \ discarded.\n        Otherwise, an exception will be thrown.\n        \"\"\"\n\
    \        image = Image.open(image_path)\n\n        encoder_inputs = feature_extractor(images=image,\
    \ return_tensors=\"np\")\n\n        return encoder_inputs.pixel_values[0]\n\n\n\
    train_ds = ImageCapatioingDataset(ds, 'train', 64)\neval_ds = ImageCapatioingDataset(ds,\
    \ 'validation', 64)\n\n\n# instantiate trainer\ntrainer = Seq2SeqTrainer(\n  \
    \  model=model,\n    tokenizer=feature_extractor,\n    args=training_args,\n \
    \   compute_metrics=compute_metrics,\n    train_dataset=train_ds,\n    eval_dataset=eval_ds,\n\
    \    data_collator=default_data_collator,\n)\n```"
  created_at: 2022-12-19 13:04:06+00:00
  edited: false
  hidden: false
  id: 63a061466b087d7413c2aa8b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: nlpconnect/vit-gpt2-image-captioning
repo_type: model
status: closed
target_branch: null
title: Inference Issue
