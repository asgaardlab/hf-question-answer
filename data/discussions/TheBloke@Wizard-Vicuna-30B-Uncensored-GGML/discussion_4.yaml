!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Flanua
conflicting_files: null
created_at: 2023-06-19 23:31:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/0H4Hegmgi1BP09WpqWdaI.jpeg?w=200&h=200&f=face
      fullname: Tanaka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Flanua
      type: user
    createdAt: '2023-06-20T00:31:52.000Z'
    data:
      edited: true
      editors:
      - Flanua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9783467054367065
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/0H4Hegmgi1BP09WpqWdaI.jpeg?w=200&h=200&f=face
          fullname: Tanaka
          isHf: false
          isPro: false
          name: Flanua
          type: user
        html: '<p>This model is very good at conversations and very good at reasoning
          probably because it''s 30B parameters compared to my old lama model of 13B
          parameters even though it''s bad at coding compared to lama 13B but that''s
          because of  datasets and the way it was trained most probably.</p>

          <p>P.S:  Wizard-Vicuna-30B can read the text from pictures almost immediately
          compared to Lama 13B model. Lama 13B.. model was unable to read the text
          from pics correctly at all.<br>Wish to have a Wizard-Vicuna-65B parameters
          model or even higher.<br>And wish to have a higher max context limit from
          2048 tokens to at least 4048 and I''m not sure if Wizard-Vicuna-30B has
          a higher limit than 2048 though.</p>

          <p>Thanks for sharing this model.</p>

          '
        raw: "This model is very good at conversations and very good at reasoning\
          \ probably because it's 30B parameters compared to my old lama model of\
          \ 13B parameters even though it's bad at coding compared to lama 13B but\
          \ that's because of  datasets and the way it was trained most probably.\n\
          \nP.S:  Wizard-Vicuna-30B can read the text from pictures almost immediately\
          \ compared to Lama 13B model. Lama 13B.. model was unable to read the text\
          \ from pics correctly at all. \nWish to have a Wizard-Vicuna-65B parameters\
          \ model or even higher. \nAnd wish to have a higher max context limit from\
          \ 2048 tokens to at least 4048 and I'm not sure if Wizard-Vicuna-30B has\
          \ a higher limit than 2048 though.\n\nThanks for sharing this model."
        updatedAt: '2023-06-20T00:43:42.782Z'
      numEdits: 9
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - CeeGee
        - Flanua
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - CeeGee
        - Flanua
    id: 6490f378d0aa14078ddd14b5
    type: comment
  author: Flanua
  content: "This model is very good at conversations and very good at reasoning probably\
    \ because it's 30B parameters compared to my old lama model of 13B parameters\
    \ even though it's bad at coding compared to lama 13B but that's because of  datasets\
    \ and the way it was trained most probably.\n\nP.S:  Wizard-Vicuna-30B can read\
    \ the text from pictures almost immediately compared to Lama 13B model. Lama 13B..\
    \ model was unable to read the text from pics correctly at all. \nWish to have\
    \ a Wizard-Vicuna-65B parameters model or even higher. \nAnd wish to have a higher\
    \ max context limit from 2048 tokens to at least 4048 and I'm not sure if Wizard-Vicuna-30B\
    \ has a higher limit than 2048 though.\n\nThanks for sharing this model."
  created_at: 2023-06-19 23:31:52+00:00
  edited: true
  hidden: false
  id: 6490f378d0aa14078ddd14b5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/Wizard-Vicuna-30B-Uncensored-GGML
repo_type: model
status: open
target_branch: null
title: So far my favorite model. Thanks for sharing!
