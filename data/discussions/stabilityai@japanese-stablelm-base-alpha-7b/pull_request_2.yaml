!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mkshing
conflicting_files: []
created_at: 2023-08-10 05:14:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c2e7747a42b2edc5d2ccf7/5GdUBW1HYEy17orItOqfV.png?w=200&h=200&f=face
      fullname: Makoto Shing
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mkshing
      type: user
    createdAt: '2023-08-10T06:14:07.000Z'
    data:
      edited: true
      editors:
      - mkshing
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c2e7747a42b2edc5d2ccf7/5GdUBW1HYEy17orItOqfV.png?w=200&h=200&f=face
          fullname: Makoto Shing
          isHf: false
          isPro: false
          name: mkshing
          type: user
        html: '<p>This PR enables to use this model with Colab Free plan by int8 quantization.<br>Here''s
          the link to the demo in colab. </p>

          <p><a rel="nofollow" href="https://colab.research.google.com/github/mkshing/notebooks/blob/main/stabilityai_japanese_stablelm_alpha_7b.ipynb">https://colab.research.google.com/github/mkshing/notebooks/blob/main/stabilityai_japanese_stablelm_alpha_7b.ipynb</a></p>

          '
        raw: "This PR enables to use this model with Colab Free plan by int8 quantization.\
          \ \nHere's the link to the demo in colab. \n\nhttps://colab.research.google.com/github/mkshing/notebooks/blob/main/stabilityai_japanese_stablelm_alpha_7b.ipynb"
        updatedAt: '2023-08-10T06:45:07.615Z'
      numEdits: 1
      reactions: []
    id: 64d4802fc7a6981f474b8fbe
    type: comment
  author: mkshing
  content: "This PR enables to use this model with Colab Free plan by int8 quantization.\
    \ \nHere's the link to the demo in colab. \n\nhttps://colab.research.google.com/github/mkshing/notebooks/blob/main/stabilityai_japanese_stablelm_alpha_7b.ipynb"
  created_at: 2023-08-10 05:14:07+00:00
  edited: true
  hidden: false
  id: 64d4802fc7a6981f474b8fbe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    createdAt: '2023-08-10T06:46:36.000Z'
    data:
      oid: 74641c1115224a526b2a4c551b6547ca66951846
      parents:
      - dbf6070080f90fc5093e6ff69b22c83bdbead66f
      subject: add int8
    id: 64d487cc0000000000000000
    type: commit
  author: deleted
  created_at: 2023-08-10 05:46:36+00:00
  id: 64d487cc0000000000000000
  oid: 74641c1115224a526b2a4c551b6547ca66951846
  summary: add int8
  type: commit
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    createdAt: '2023-08-10T06:53:56.000Z'
    data:
      oid: 5a6026af892d9b54514e3094c2efcbff24d4739b
      parents:
      - 74641c1115224a526b2a4c551b6547ca66951846
      subject: add fp16
    id: 64d489840000000000000000
    type: commit
  author: deleted
  created_at: 2023-08-10 05:53:56+00:00
  id: 64d489840000000000000000
  oid: 5a6026af892d9b54514e3094c2efcbff24d4739b
  summary: add fp16
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c2e7747a42b2edc5d2ccf7/5GdUBW1HYEy17orItOqfV.png?w=200&h=200&f=face
      fullname: Makoto Shing
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mkshing
      type: user
    createdAt: '2023-08-10T07:03:05.000Z'
    data:
      status: open
    id: 64d48ba986d4554eb9d9b08f
    type: status-change
  author: mkshing
  created_at: 2023-08-10 06:03:05+00:00
  id: 64d48ba986d4554eb9d9b08f
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1626334352388-5e1494d0fcf41d740b69967a.jpeg?w=200&h=200&f=face
      fullname: Meng Lee
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: leemeng
      type: user
    createdAt: '2023-08-10T07:14:17.000Z'
    data:
      edited: false
      editors:
      - leemeng
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7668890953063965
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1626334352388-5e1494d0fcf41d740b69967a.jpeg?w=200&h=200&f=face
          fullname: Meng Lee
          isHf: false
          isPro: false
          name: leemeng
          type: user
        html: "<p>Generally LGTM! by the way, if we don't include <code>variant=\"\
          int8\"</code> in the <code>from_pretrained</code>, it will just load the\
          \ original fp32 version, is that correct?</p>\n<pre><code class=\"language-python\"\
          >model = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>,\n    variant=<span class=\"hljs-string\"\
          >\"int8\"</span>,\n    low_cpu_mem_usage=<span class=\"hljs-literal\">True</span>,\n\
          \    load_in_8bit=<span class=\"hljs-literal\">True</span>,\n)\n</code></pre>\n"
        raw: "Generally LGTM! by the way, if we don't include `variant=\"int8\"` in\
          \ the `from_pretrained`, it will just load the original fp32 version, is\
          \ that correct?\n\n```python\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    model_id,\n    trust_remote_code=True,\n    variant=\"int8\",\n   \
          \ low_cpu_mem_usage=True,\n    load_in_8bit=True,\n)\n```"
        updatedAt: '2023-08-10T07:14:17.884Z'
      numEdits: 0
      reactions: []
    id: 64d48e49bb654cb81e195840
    type: comment
  author: leemeng
  content: "Generally LGTM! by the way, if we don't include `variant=\"int8\"` in\
    \ the `from_pretrained`, it will just load the original fp32 version, is that\
    \ correct?\n\n```python\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n\
    \    trust_remote_code=True,\n    variant=\"int8\",\n    low_cpu_mem_usage=True,\n\
    \    load_in_8bit=True,\n)\n```"
  created_at: 2023-08-10 06:14:17+00:00
  edited: false
  hidden: false
  id: 64d48e49bb654cb81e195840
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c2e7747a42b2edc5d2ccf7/5GdUBW1HYEy17orItOqfV.png?w=200&h=200&f=face
      fullname: Makoto Shing
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mkshing
      type: user
    createdAt: '2023-08-10T07:15:59.000Z'
    data:
      edited: true
      editors:
      - mkshing
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6111014485359192
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c2e7747a42b2edc5d2ccf7/5GdUBW1HYEy17orItOqfV.png?w=200&h=200&f=face
          fullname: Makoto Shing
          isHf: false
          isPro: false
          name: mkshing
          type: user
        html: "<p>Exactly!<br>So, if I'm correct, it loads fp32 weights first and\
          \ convert to int8 in this case.</p>\n<pre><code class=\"language-diff\"\
          >\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n\
          <span class=\"hljs-deletion\">-   variant=\"int8\",</span>\n    low_cpu_mem_usage=True,\n\
          \    load_in_8bit=True,\n)\n</code></pre>\n"
        raw: "Exactly! \nSo, if I'm correct, it loads fp32 weights first and convert\
          \ to int8 in this case.\n```diff\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    model_id,\n    trust_remote_code=True,\n-   variant=\"int8\",\n   \
          \ low_cpu_mem_usage=True,\n    load_in_8bit=True,\n)\n```"
        updatedAt: '2023-08-10T07:17:24.224Z'
      numEdits: 1
      reactions: []
    id: 64d48eafe385bc62fb7bec23
    type: comment
  author: mkshing
  content: "Exactly! \nSo, if I'm correct, it loads fp32 weights first and convert\
    \ to int8 in this case.\n```diff\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\
    \    model_id,\n    trust_remote_code=True,\n-   variant=\"int8\",\n    low_cpu_mem_usage=True,\n\
    \    load_in_8bit=True,\n)\n```"
  created_at: 2023-08-10 06:15:59+00:00
  edited: true
  hidden: false
  id: 64d48eafe385bc62fb7bec23
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1626334352388-5e1494d0fcf41d740b69967a.jpeg?w=200&h=200&f=face
      fullname: Meng Lee
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: leemeng
      type: user
    createdAt: '2023-08-10T07:20:53.000Z'
    data:
      edited: false
      editors:
      - leemeng
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9703320860862732
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1626334352388-5e1494d0fcf41d740b69967a.jpeg?w=200&h=200&f=face
          fullname: Meng Lee
          isHf: false
          isPro: false
          name: leemeng
          type: user
        html: '<p>nice! let''s merge this. By the way, do you want to also include
          the <code>variant</code> as a colab dropdown (with default use <code>int8</code>)
          like <code>model_id</code> so people can be aware of that? </p>

          '
        raw: 'nice! let''s merge this. By the way, do you want to also include the
          `variant` as a colab dropdown (with default use `int8`) like `model_id`
          so people can be aware of that? '
        updatedAt: '2023-08-10T07:20:53.767Z'
      numEdits: 0
      reactions: []
    id: 64d48fd5760d672909f9a92d
    type: comment
  author: leemeng
  content: 'nice! let''s merge this. By the way, do you want to also include the `variant`
    as a colab dropdown (with default use `int8`) like `model_id` so people can be
    aware of that? '
  created_at: 2023-08-10 06:20:53+00:00
  edited: false
  hidden: false
  id: 64d48fd5760d672909f9a92d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1626334352388-5e1494d0fcf41d740b69967a.jpeg?w=200&h=200&f=face
      fullname: Meng Lee
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: leemeng
      type: user
    createdAt: '2023-08-10T07:25:12.000Z'
    data:
      status: merged
    id: 64d490d81e302dba63e8ed94
    type: status-change
  author: leemeng
  created_at: 2023-08-10 06:25:12+00:00
  id: 64d490d81e302dba63e8ed94
  new_status: merged
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c2e7747a42b2edc5d2ccf7/5GdUBW1HYEy17orItOqfV.png?w=200&h=200&f=face
      fullname: Makoto Shing
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mkshing
      type: user
    createdAt: '2023-08-10T07:25:21.000Z'
    data:
      edited: false
      editors:
      - mkshing
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.936502993106842
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c2e7747a42b2edc5d2ccf7/5GdUBW1HYEy17orItOqfV.png?w=200&h=200&f=face
          fullname: Makoto Shing
          isHf: false
          isPro: false
          name: mkshing
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;leemeng&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/leemeng\">@<span class=\"\
          underline\">leemeng</span></a></span>\n\n\t</span></span> sure! I will add\
          \ some comments that only int8 works in colab free. </p>\n"
        raw: '@leemeng sure! I will add some comments that only int8 works in colab
          free. '
        updatedAt: '2023-08-10T07:25:21.176Z'
      numEdits: 0
      reactions: []
    id: 64d490e1113932b24034882e
    type: comment
  author: mkshing
  content: '@leemeng sure! I will add some comments that only int8 works in colab
    free. '
  created_at: 2023-08-10 06:25:21+00:00
  edited: false
  hidden: false
  id: 64d490e1113932b24034882e
  type: comment
is_pull_request: true
merge_commit_oid: c5c38b135e7c4df43d225cf54269327adfc0d4bc
num: 2
repo_id: stabilityai/japanese-stablelm-base-alpha-7b
repo_type: model
status: merged
target_branch: refs/heads/main
title: Add fp16/int8 weights
