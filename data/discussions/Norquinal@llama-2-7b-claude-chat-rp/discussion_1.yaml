!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sdranju
conflicting_files: null
created_at: 2023-08-25 05:22:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/51a8fecfd7d35ca6ad4bcbdb7cf1442e.svg
      fullname: Shamsuddoha Ranju
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sdranju
      type: user
    createdAt: '2023-08-25T06:22:29.000Z'
    data:
      edited: false
      editors:
      - sdranju
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8939937353134155
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/51a8fecfd7d35ca6ad4bcbdb7cf1442e.svg
          fullname: Shamsuddoha Ranju
          isHf: false
          isPro: false
          name: sdranju
          type: user
        html: '<p>Thrown during validation:<br><code>do_sample</code> is set to <code>False</code>.
          However, <code>temperature</code> is set to <code>0.9</code> -- this flag
          is only used in sample-based generation modes.<br>You should set <code>do_sample=True</code>
          or unset <code>temperature</code>.</p>

          '
        raw: "Thrown during validation:\r\n`do_sample` is set to `False`. However,\
          \ `temperature` is set to `0.9` -- this flag is only used in sample-based\
          \ generation modes. \r\nYou should set `do_sample=True` or unset `temperature`.\r\
          \n"
        updatedAt: '2023-08-25T06:22:29.754Z'
      numEdits: 0
      reactions: []
    id: 64e848a5d021ea7dfaae705c
    type: comment
  author: sdranju
  content: "Thrown during validation:\r\n`do_sample` is set to `False`. However, `temperature`\
    \ is set to `0.9` -- this flag is only used in sample-based generation modes.\
    \ \r\nYou should set `do_sample=True` or unset `temperature`.\r\n"
  created_at: 2023-08-25 05:22:29+00:00
  edited: false
  hidden: false
  id: 64e848a5d021ea7dfaae705c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae1d0445cb3b03e81ea983c9dc3cd831.svg
      fullname: Andy B. Norquinal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Norquinal
      type: user
    createdAt: '2023-08-25T07:43:32.000Z'
    data:
      edited: false
      editors:
      - Norquinal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9685949683189392
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae1d0445cb3b03e81ea983c9dc3cd831.svg
          fullname: Andy B. Norquinal
          isHf: false
          isPro: false
          name: Norquinal
          type: user
        html: '<p>Oh, yeah you can go ahead and remove "temperature" and "top_p" for
          that matter from the generation_config. I don''t believe it''s a big deal,
          it was just something that was added automatically. If it''s causingissues
          with safetensors conversion then I will go ahead and update the file later.</p>

          '
        raw: Oh, yeah you can go ahead and remove "temperature" and "top_p" for that
          matter from the generation_config. I don't believe it's a big deal, it was
          just something that was added automatically. If it's causingissues with
          safetensors conversion then I will go ahead and update the file later.
        updatedAt: '2023-08-25T07:43:32.339Z'
      numEdits: 0
      reactions: []
    id: 64e85ba464e7b5f642e5ccdd
    type: comment
  author: Norquinal
  content: Oh, yeah you can go ahead and remove "temperature" and "top_p" for that
    matter from the generation_config. I don't believe it's a big deal, it was just
    something that was added automatically. If it's causingissues with safetensors
    conversion then I will go ahead and update the file later.
  created_at: 2023-08-25 06:43:32+00:00
  edited: false
  hidden: false
  id: 64e85ba464e7b5f642e5ccdd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Norquinal/llama-2-7b-claude-chat-rp
repo_type: model
status: open
target_branch: null
title: Getting error during safetensors conversion
