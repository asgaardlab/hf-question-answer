!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Teo155
conflicting_files: null
created_at: 2023-01-25 08:26:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ba0441483a288a50b40a02d6ff7509f1.svg
      fullname: Matteo Schifano
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Teo155
      type: user
    createdAt: '2023-01-25T08:26:18.000Z'
    data:
      edited: false
      editors:
      - Teo155
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ba0441483a288a50b40a02d6ff7509f1.svg
          fullname: Matteo Schifano
          isHf: false
          isPro: false
          name: Teo155
          type: user
        html: "<p>hello everyone i would like to ask what is the maximum number of\
          \ classes predictable by this model and more importantly what is the confidence\
          \ with which it predicts the Italian language? however having a very high\
          \ number of classes in the order of hundreds what advice could you give\
          \ me? is it the case to do fine tune for such a high number of classes?\
          \ if so how can i do it?</p>\n<p>thank you all!!\U0001F917</p>\n"
        raw: "\r\nhello everyone i would like to ask what is the maximum number of\
          \ classes predictable by this model and more importantly what is the confidence\
          \ with which it predicts the Italian language? however having a very high\
          \ number of classes in the order of hundreds what advice could you give\
          \ me? is it the case to do fine tune for such a high number of classes?\
          \ if so how can i do it?\r\n\r\nthank you all!!\U0001F917"
        updatedAt: '2023-01-25T08:26:18.146Z'
      numEdits: 0
      reactions: []
    id: 63d0e7aaf7f31a66a2ca15cf
    type: comment
  author: Teo155
  content: "\r\nhello everyone i would like to ask what is the maximum number of classes\
    \ predictable by this model and more importantly what is the confidence with which\
    \ it predicts the Italian language? however having a very high number of classes\
    \ in the order of hundreds what advice could you give me? is it the case to do\
    \ fine tune for such a high number of classes? if so how can i do it?\r\n\r\n\
    thank you all!!\U0001F917"
  created_at: 2023-01-25 08:26:18+00:00
  edited: false
  hidden: false
  id: 63d0e7aaf7f31a66a2ca15cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2023-01-25T13:43:45.000Z'
    data:
      edited: false
      editors:
      - MoritzLaurer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
          fullname: Moritz Laurer
          isHf: true
          isPro: false
          name: MoritzLaurer
          type: user
        html: '<p>Technically, there is no limit for the classes you can predict with
          NLI zero-shooting. Performance will, however, decrease as you add more classes.
          Hard to give a concrete number, because it strongly depends on the complexity
          of your classes. So hundreds of classes works, but will not perform very
          well (that''s quite a lot for any classifier). </p>

          <p>Regarding Italian: Italian was both in the pre-training corpus of mDeBERTa
          as well as the NLI fine-tuning corpus, so performance on Italian should
          be good. </p>

          <p>Fine-tuning an NLI model for other tasks than NLI takes some experience.
          I''d recommend you look into the Hugging Face course for the fundamentals.
          Then you can find more details in this paper and also in the google colab
          notebook in footnote 2: <a rel="nofollow" href="https://osf.io/xc39s">https://osf.io/xc39s</a></p>

          '
        raw: "Technically, there is no limit for the classes you can predict with\
          \ NLI zero-shooting. Performance will, however, decrease as you add more\
          \ classes. Hard to give a concrete number, because it strongly depends on\
          \ the complexity of your classes. So hundreds of classes works, but will\
          \ not perform very well (that's quite a lot for any classifier). \n\nRegarding\
          \ Italian: Italian was both in the pre-training corpus of mDeBERTa as well\
          \ as the NLI fine-tuning corpus, so performance on Italian should be good.\
          \ \n\nFine-tuning an NLI model for other tasks than NLI takes some experience.\
          \ I'd recommend you look into the Hugging Face course for the fundamentals.\
          \ Then you can find more details in this paper and also in the google colab\
          \ notebook in footnote 2: https://osf.io/xc39s"
        updatedAt: '2023-01-25T13:43:45.007Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Teo155
    id: 63d1321162f0de677d85bb01
    type: comment
  author: MoritzLaurer
  content: "Technically, there is no limit for the classes you can predict with NLI\
    \ zero-shooting. Performance will, however, decrease as you add more classes.\
    \ Hard to give a concrete number, because it strongly depends on the complexity\
    \ of your classes. So hundreds of classes works, but will not perform very well\
    \ (that's quite a lot for any classifier). \n\nRegarding Italian: Italian was\
    \ both in the pre-training corpus of mDeBERTa as well as the NLI fine-tuning corpus,\
    \ so performance on Italian should be good. \n\nFine-tuning an NLI model for other\
    \ tasks than NLI takes some experience. I'd recommend you look into the Hugging\
    \ Face course for the fundamentals. Then you can find more details in this paper\
    \ and also in the google colab notebook in footnote 2: https://osf.io/xc39s"
  created_at: 2023-01-25 13:43:45+00:00
  edited: false
  hidden: false
  id: 63d1321162f0de677d85bb01
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2023-02-08T21:06:49.000Z'
    data:
      status: closed
    id: 63e40ee9a6002a8f78edde34
    type: status-change
  author: MoritzLaurer
  created_at: 2023-02-08 21:06:49+00:00
  id: 63e40ee9a6002a8f78edde34
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7
repo_type: model
status: closed
target_branch: null
title: "What is the maximum number of predictable classes and how to do fine tune?\U0001F917"
