!!python/object:huggingface_hub.community.DiscussionWithDetails
author: 3r1c
conflicting_files: null
created_at: 2023-02-03 16:01:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/73fbc2404ae4ef58d6d8cb3a52e5296d.svg
      fullname: Rudolph
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 3r1c
      type: user
    createdAt: '2023-02-03T16:01:33.000Z'
    data:
      edited: true
      editors:
      - 3r1c
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/73fbc2404ae4ef58d6d8cb3a52e5296d.svg
          fullname: Rudolph
          isHf: false
          isPro: false
          name: 3r1c
          type: user
        html: "<p>In my dataset I only have 2 labels: \"entailment\" or \"contradiction\"\
          . So I want to change the num_labels to 2 and then fine_tune the model like:\
          \ </p>\n<pre><code>    id2label = {0: \"entailment\", 1: \"contradiction\"\
          }\n    config = AutoConfig.from_pretrained(args.model_name_or_path)  \n\
          \    tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\n\
          \    config.num_labels=2\n    config.id2label = id2label,\n    model = AutoModelForSequenceClassification.from_pretrained(\n\
          \        args.model_name_or_path,\n        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n\
          \        config=config, \n        ignore_mismatched_sizes=True,\n    )\n\
          </code></pre>\n<p>Unfortunately the model returns during training only one\
          \ logit and uses Mean Squared Error loss I think. Do you have an idea how\
          \ I can change the models num_labels to two so I get two logits?</p>\n"
        raw: "In my dataset I only have 2 labels: \"entailment\" or \"contradiction\"\
          . So I want to change the num_labels to 2 and then fine_tune the model like:\
          \ \n\n        id2label = {0: \"entailment\", 1: \"contradiction\"}\n   \
          \     config = AutoConfig.from_pretrained(args.model_name_or_path)  \n \
          \       tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\n\
          \        config.num_labels=2\n        config.id2label = id2label,\n    \
          \    model = AutoModelForSequenceClassification.from_pretrained(\n     \
          \       args.model_name_or_path,\n            from_tf=bool(\".ckpt\" in\
          \ args.model_name_or_path),\n            config=config, \n            ignore_mismatched_sizes=True,\n\
          \        )\n\nUnfortunately the model returns during training only one logit\
          \ and uses Mean Squared Error loss I think. Do you have an idea how I can\
          \ change the models num_labels to two so I get two logits?"
        updatedAt: '2023-02-03T16:02:15.425Z'
      numEdits: 2
      reactions: []
    id: 63dd2fddf3711148252581f0
    type: comment
  author: 3r1c
  content: "In my dataset I only have 2 labels: \"entailment\" or \"contradiction\"\
    . So I want to change the num_labels to 2 and then fine_tune the model like: \n\
    \n        id2label = {0: \"entailment\", 1: \"contradiction\"}\n        config\
    \ = AutoConfig.from_pretrained(args.model_name_or_path)  \n        tokenizer =\
    \ AutoTokenizer.from_pretrained(args.model_name_or_path)\n        config.num_labels=2\n\
    \        config.id2label = id2label,\n        model = AutoModelForSequenceClassification.from_pretrained(\n\
    \            args.model_name_or_path,\n            from_tf=bool(\".ckpt\" in args.model_name_or_path),\n\
    \            config=config, \n            ignore_mismatched_sizes=True,\n    \
    \    )\n\nUnfortunately the model returns during training only one logit and uses\
    \ Mean Squared Error loss I think. Do you have an idea how I can change the models\
    \ num_labels to two so I get two logits?"
  created_at: 2023-02-03 16:01:33+00:00
  edited: true
  hidden: false
  id: 63dd2fddf3711148252581f0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2023-02-09T07:58:54.000Z'
    data:
      edited: false
      editors:
      - MoritzLaurer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
          fullname: Moritz Laurer
          isHf: true
          isPro: false
          name: MoritzLaurer
          type: user
        html: "<p>This is how I load the models in my scripts: </p>\n<pre><code>label2id\
          \ = {\"entailment\": 0, \"not_entailment\": 1}\nid2label = {0: \"entailment\"\
          , 1: \"not_entailment\"}\nmodel_name = \"microsoft/mdeberta-v3-base\" \n\
          tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, model_max_length=512)\
          \  # model_max_length=512\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name,\
          \ label2id=label2id, id2label=id2label).to(device) \n</code></pre>\n<p>(I\
          \ had used the <code>num_labels=3</code> flag when loading the model in\
          \ the past, but that doesn't seem to be necessary)</p>\n"
        raw: "This is how I load the models in my scripts: \n\n```\nlabel2id = {\"\
          entailment\": 0, \"not_entailment\": 1}\nid2label = {0: \"entailment\",\
          \ 1: \"not_entailment\"}\nmodel_name = \"microsoft/mdeberta-v3-base\" \n\
          tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, model_max_length=512)\
          \  # model_max_length=512\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name,\
          \ label2id=label2id, id2label=id2label).to(device) \n```\n(I had used the\
          \ `num_labels=3` flag when loading the model in the past, but that doesn't\
          \ seem to be necessary)"
        updatedAt: '2023-02-09T07:58:54.413Z'
      numEdits: 0
      reactions: []
    id: 63e4a7bea26ec2301f03d35b
    type: comment
  author: MoritzLaurer
  content: "This is how I load the models in my scripts: \n\n```\nlabel2id = {\"entailment\"\
    : 0, \"not_entailment\": 1}\nid2label = {0: \"entailment\", 1: \"not_entailment\"\
    }\nmodel_name = \"microsoft/mdeberta-v3-base\" \ntokenizer = AutoTokenizer.from_pretrained(model_name,\
    \ use_fast=True, model_max_length=512)  # model_max_length=512\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name,\
    \ label2id=label2id, id2label=id2label).to(device) \n```\n(I had used the `num_labels=3`\
    \ flag when loading the model in the past, but that doesn't seem to be necessary)"
  created_at: 2023-02-09 07:58:54+00:00
  edited: false
  hidden: false
  id: 63e4a7bea26ec2301f03d35b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7
repo_type: model
status: open
target_branch: null
title: changing to num_labels 2
