!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Aryanne
conflicting_files: null
created_at: 2023-07-10 15:01:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
      fullname: Aryanne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aryanne
      type: user
    createdAt: '2023-07-10T16:01:49.000Z'
    data:
      edited: false
      editors:
      - Aryanne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.888047993183136
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
          fullname: Aryanne
          isHf: false
          isPro: false
          name: Aryanne
          type: user
        html: '<p>Can you quantize conceptofmind/LLongMA-3b and conceptofmind/Flan-Open-Llama-3b,
          I can''t find it anywhere, and with k-quants too? </p>

          '
        raw: 'Can you quantize conceptofmind/LLongMA-3b and conceptofmind/Flan-Open-Llama-3b,
          I can''t find it anywhere, and with k-quants too? '
        updatedAt: '2023-07-10T16:01:49.497Z'
      numEdits: 0
      reactions: []
    id: 64ac2b6d94ae6b609d13ad54
    type: comment
  author: Aryanne
  content: 'Can you quantize conceptofmind/LLongMA-3b and conceptofmind/Flan-Open-Llama-3b,
    I can''t find it anywhere, and with k-quants too? '
  created_at: 2023-07-10 15:01:49+00:00
  edited: false
  hidden: false
  id: 64ac2b6d94ae6b609d13ad54
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6461e6d29ca00a1b9af42a8f4549cd63.svg
      fullname: Henri Vasserman
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: SlyEcho
      type: user
    createdAt: '2023-07-13T11:10:07.000Z'
    data:
      edited: false
      editors:
      - SlyEcho
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9615345001220703
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6461e6d29ca00a1b9af42a8f4549cd63.svg
          fullname: Henri Vasserman
          isHf: false
          isPro: false
          name: SlyEcho
          type: user
        html: '<p>I don''t really see what the origin or license is for those models.</p>

          <p>But otherwise, is there something difficult in converting these models
          to ggml? I think it should be possible to use the tools included in llama.cpp
          right now without any hacking patching (which was not true when I first
          uploaded the 3B models).</p>

          <p>K quants for 3B models is problematic right now because they require
          a special build of llama.cpp to work.</p>

          '
        raw: 'I don''t really see what the origin or license is for those models.


          But otherwise, is there something difficult in converting these models to
          ggml? I think it should be possible to use the tools included in llama.cpp
          right now without any hacking patching (which was not true when I first
          uploaded the 3B models).


          K quants for 3B models is problematic right now because they require a special
          build of llama.cpp to work.'
        updatedAt: '2023-07-13T11:10:07.296Z'
      numEdits: 0
      reactions: []
    id: 64afdb8f8be88034605ef155
    type: comment
  author: SlyEcho
  content: 'I don''t really see what the origin or license is for those models.


    But otherwise, is there something difficult in converting these models to ggml?
    I think it should be possible to use the tools included in llama.cpp right now
    without any hacking patching (which was not true when I first uploaded the 3B
    models).


    K quants for 3B models is problematic right now because they require a special
    build of llama.cpp to work.'
  created_at: 2023-07-13 10:10:07+00:00
  edited: false
  hidden: false
  id: 64afdb8f8be88034605ef155
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
      fullname: Aryanne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aryanne
      type: user
    createdAt: '2023-07-13T13:08:13.000Z'
    data:
      edited: false
      editors:
      - Aryanne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7934608459472656
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
          fullname: Aryanne
          isHf: false
          isPro: false
          name: Aryanne
          type: user
        html: "<p>I found more info on:<br><a rel=\"nofollow\" href=\"https://twitter.com/EnricoShippole/status/1672274141255180288?t=iDgpZy2ggF3xt9I4TlhTug&amp;s=19\"\
          >https://twitter.com/EnricoShippole/status/1672274141255180288?t=iDgpZy2ggF3xt9I4TlhTug&amp;s=19</a></p>\n\
          <p>I asked you cause I don't any computer available at the moment to quantize\
          \ and Idk how too. Thanks for answering \U0001F917</p>\n"
        raw: "I found more info on:\nhttps://twitter.com/EnricoShippole/status/1672274141255180288?t=iDgpZy2ggF3xt9I4TlhTug&s=19\n\
          \nI asked you cause I don't any computer available at the moment to quantize\
          \ and Idk how too. Thanks for answering \U0001F917"
        updatedAt: '2023-07-13T13:08:13.771Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - SlyEcho
        - Aryanne
    id: 64aff73d94ca7626fe00b53e
    type: comment
  author: Aryanne
  content: "I found more info on:\nhttps://twitter.com/EnricoShippole/status/1672274141255180288?t=iDgpZy2ggF3xt9I4TlhTug&s=19\n\
    \nI asked you cause I don't any computer available at the moment to quantize and\
    \ Idk how too. Thanks for answering \U0001F917"
  created_at: 2023-07-13 12:08:13+00:00
  edited: false
  hidden: false
  id: 64aff73d94ca7626fe00b53e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
      fullname: Aryanne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aryanne
      type: user
    createdAt: '2023-07-13T20:06:40.000Z'
    data:
      edited: false
      editors:
      - Aryanne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9180284738540649
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
          fullname: Aryanne
          isHf: false
          isPro: false
          name: Aryanne
          type: user
        html: '<p>I think it would be possible to quantize with k quants The Bloke
          did with <a href="https://huggingface.co/TheBloke/Flan-OpenLlama-7B-GGML">https://huggingface.co/TheBloke/Flan-OpenLlama-7B-GGML</a></p>

          '
        raw: I think it would be possible to quantize with k quants The Bloke did
          with https://huggingface.co/TheBloke/Flan-OpenLlama-7B-GGML
        updatedAt: '2023-07-13T20:06:40.040Z'
      numEdits: 0
      reactions: []
    id: 64b059507ac2da5cef913a22
    type: comment
  author: Aryanne
  content: I think it would be possible to quantize with k quants The Bloke did with
    https://huggingface.co/TheBloke/Flan-OpenLlama-7B-GGML
  created_at: 2023-07-13 19:06:40+00:00
  edited: false
  hidden: false
  id: 64b059507ac2da5cef913a22
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6461e6d29ca00a1b9af42a8f4549cd63.svg
      fullname: Henri Vasserman
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: SlyEcho
      type: user
    createdAt: '2023-07-13T20:14:30.000Z'
    data:
      edited: false
      editors:
      - SlyEcho
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9485524296760559
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6461e6d29ca00a1b9af42a8f4549cd63.svg
          fullname: Henri Vasserman
          isHf: false
          isPro: false
          name: SlyEcho
          type: user
        html: '<p>K quants are not supported well for 3B models. You have to basically
          compile a custom version of llama.cpp but it will probably be extremely
          hard for you to do.</p>

          <p>I will try to add the models, though.</p>

          '
        raw: 'K quants are not supported well for 3B models. You have to basically
          compile a custom version of llama.cpp but it will probably be extremely
          hard for you to do.


          I will try to add the models, though.'
        updatedAt: '2023-07-13T20:14:30.031Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Aryanne
    id: 64b05b26821ccdcd946b935f
    type: comment
  author: SlyEcho
  content: 'K quants are not supported well for 3B models. You have to basically compile
    a custom version of llama.cpp but it will probably be extremely hard for you to
    do.


    I will try to add the models, though.'
  created_at: 2023-07-13 19:14:30+00:00
  edited: false
  hidden: false
  id: 64b05b26821ccdcd946b935f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6461e6d29ca00a1b9af42a8f4549cd63.svg
      fullname: Henri Vasserman
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: SlyEcho
      type: user
    createdAt: '2023-07-13T23:11:57.000Z'
    data:
      edited: false
      editors:
      - SlyEcho
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8528422117233276
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6461e6d29ca00a1b9af42a8f4549cd63.svg
          fullname: Henri Vasserman
          isHf: false
          isPro: false
          name: SlyEcho
          type: user
        html: '<p>Alright, here they are:</p>

          <ul>

          <li><a href="https://huggingface.co/SlyEcho/Flan-Open-Llama-3b-ggml">Flan-Open-Llama-3b-ggml</a></li>

          <li><a href="https://huggingface.co/SlyEcho/LLongMA-3b-ggml">LLongMA-3b-ggml</a></li>

          </ul>

          <p>I did manage to get LLongMA-3b working with the 8K context but I needed
          apply patches from Github as it is not merged yet.<br>Not sure how helpful
          it is for you.</p>

          '
        raw: 'Alright, here they are:


          - [Flan-Open-Llama-3b-ggml](https://huggingface.co/SlyEcho/Flan-Open-Llama-3b-ggml)

          - [LLongMA-3b-ggml](https://huggingface.co/SlyEcho/LLongMA-3b-ggml)


          I did manage to get LLongMA-3b working with the 8K context but I needed
          apply patches from Github as it is not merged yet.

          Not sure how helpful it is for you.'
        updatedAt: '2023-07-13T23:11:57.872Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Aryanne
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Aryanne
      relatedEventId: 64b084bd14b3c5479ee34536
    id: 64b084bd14b3c5479ee34535
    type: comment
  author: SlyEcho
  content: 'Alright, here they are:


    - [Flan-Open-Llama-3b-ggml](https://huggingface.co/SlyEcho/Flan-Open-Llama-3b-ggml)

    - [LLongMA-3b-ggml](https://huggingface.co/SlyEcho/LLongMA-3b-ggml)


    I did manage to get LLongMA-3b working with the 8K context but I needed apply
    patches from Github as it is not merged yet.

    Not sure how helpful it is for you.'
  created_at: 2023-07-13 22:11:57+00:00
  edited: false
  hidden: false
  id: 64b084bd14b3c5479ee34535
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/6461e6d29ca00a1b9af42a8f4549cd63.svg
      fullname: Henri Vasserman
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: SlyEcho
      type: user
    createdAt: '2023-07-13T23:11:57.000Z'
    data:
      status: closed
    id: 64b084bd14b3c5479ee34536
    type: status-change
  author: SlyEcho
  created_at: 2023-07-13 22:11:57+00:00
  id: 64b084bd14b3c5479ee34536
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
      fullname: Aryanne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aryanne
      type: user
    createdAt: '2023-07-13T23:16:34.000Z'
    data:
      edited: false
      editors:
      - Aryanne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8690445423126221
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
          fullname: Aryanne
          isHf: false
          isPro: false
          name: Aryanne
          type: user
        html: "<p>Thanks\U0001F64C, I'm going to test on koboldcpp</p>\n"
        raw: "Thanks\U0001F64C, I'm going to test on koboldcpp"
        updatedAt: '2023-07-13T23:16:34.397Z'
      numEdits: 0
      reactions: []
    id: 64b085d2fdafb9210d7e6e61
    type: comment
  author: Aryanne
  content: "Thanks\U0001F64C, I'm going to test on koboldcpp"
  created_at: 2023-07-13 22:16:34+00:00
  edited: false
  hidden: false
  id: 64b085d2fdafb9210d7e6e61
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
      fullname: Aryanne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aryanne
      type: user
    createdAt: '2023-07-22T04:27:39.000Z'
    data:
      edited: false
      editors:
      - Aryanne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.717253565788269
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
          fullname: Aryanne
          isHf: false
          isPro: false
          name: Aryanne
          type: user
        html: '<p>all worked perfectly, thanks, if you can convert this too <a href="https://huggingface.co/syzymon/long_llama_3b">https://huggingface.co/syzymon/long_llama_3b</a></p>

          '
        raw: all worked perfectly, thanks, if you can convert this too https://huggingface.co/syzymon/long_llama_3b
        updatedAt: '2023-07-22T04:27:39.990Z'
      numEdits: 0
      reactions: []
    id: 64bb5abb2e66dc7b8b8fe250
    type: comment
  author: Aryanne
  content: all worked perfectly, thanks, if you can convert this too https://huggingface.co/syzymon/long_llama_3b
  created_at: 2023-07-22 03:27:39+00:00
  edited: false
  hidden: false
  id: 64bb5abb2e66dc7b8b8fe250
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6461e6d29ca00a1b9af42a8f4549cd63.svg
      fullname: Henri Vasserman
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: SlyEcho
      type: user
    createdAt: '2023-07-23T19:15:29.000Z'
    data:
      edited: false
      editors:
      - SlyEcho
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9508125185966492
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6461e6d29ca00a1b9af42a8f4549cd63.svg
          fullname: Henri Vasserman
          isHf: false
          isPro: false
          name: SlyEcho
          type: user
        html: '<p>That model would only work with 2048 tokens in the current llama.cpp
          code, so I don''t see the point right now.</p>

          <p>Maybe later.</p>

          '
        raw: 'That model would only work with 2048 tokens in the current llama.cpp
          code, so I don''t see the point right now.


          Maybe later.'
        updatedAt: '2023-07-23T19:15:29.821Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Aryanne
    id: 64bd7c5186e7fb5b8a68fc1e
    type: comment
  author: SlyEcho
  content: 'That model would only work with 2048 tokens in the current llama.cpp code,
    so I don''t see the point right now.


    Maybe later.'
  created_at: 2023-07-23 18:15:29+00:00
  edited: false
  hidden: false
  id: 64bd7c5186e7fb5b8a68fc1e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: SlyEcho/open_llama_7b_v2_ggml
repo_type: model
status: closed
target_branch: null
title: Please
