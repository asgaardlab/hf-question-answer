!!python/object:huggingface_hub.community.DiscussionWithDetails
author: practical-dreamer
conflicting_files: null
created_at: 2023-08-30 21:14:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642e4fbda0b65dce1f875e90/o08Ni4hSRiqyoBy6MEg-a.jpeg?w=200&h=200&f=face
      fullname: practical-dreamer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: practical-dreamer
      type: user
    createdAt: '2023-08-30T22:14:26.000Z'
    data:
      edited: true
      editors:
      - practical-dreamer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8888587355613708
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642e4fbda0b65dce1f875e90/o08Ni4hSRiqyoBy6MEg-a.jpeg?w=200&h=200&f=face
          fullname: practical-dreamer
          isHf: false
          isPro: false
          name: practical-dreamer
          type: user
        html: '<p>I''ve been reading your prompt instructions and analyzing your dataset
          and would like to ask a couple questions to ensure my instruction template
          is configured correctly for use with ooba''s textgenui. My questions are
          specific to two-party multi-turn character roleplay.</p>

          <ol>

          <li>What pre-prompt was given when training this model? (the string that
          wraps around the "instruction" and "response" values in the dataset)</li>

          </ol>

          <ul>

          <li>For example one of Alpaca''s preprompts were defined as</li>

          </ul>

          <pre><code>Below is an instruction that describes a task. Write a response
          that appropriately completes the request.


          ### Instruction:

          {instruction}


          ### Response:

          {output}

          </code></pre>

          <p>Was the "instruction" value wrapped with "BEGIN INSTRUCTION", "END INSTRUCTION"
          before sending to .train()?<br>2. Do you recommend we contextualize the
          conversation between "USER:" and "ASSISTANT:"?</p>

          <ul>

          <li>Based on line 4974 and 4614 of expert_createive.jsonl it looks like
          the turn template might do best if we prefance our character names with
          "USER: " and "ASSISTANT: "</li>

          <li>For instance on line 4614 of expert_createive.jsonl I see</li>

          </ul>

          <pre><code>USER: Let''s dive into the topic.

          ASSISTANT: Nathaniel: Taking a moment to admire the...

          </code></pre>

          <ul>

          <li>Meaning the turn template that might work best here would be something
          like:<br><code>USER: &lt;|user|&gt; &lt;|user-message|&gt;\nASSISTANT: &lt;|bot|&gt;
          &lt;|bot-message|&gt;\n</code></li>

          </ul>

          <ol start="3">

          <li>Would you recommend wrapping the character cards with "BEGINCONTEXT"
          and "ENDCONTEXT"?</li>

          </ol>

          <p>It seems like you use a diverse blend of instruction prompt formats so
          it may not make as much a difference I just want to make sure I''m inferencing
          with whatever format you recommend.</p>

          '
        raw: "I've been reading your prompt instructions and analyzing your dataset\
          \ and would like to ask a couple questions to ensure my instruction template\
          \ is configured correctly for use with ooba's textgenui. My questions are\
          \ specific to two-party multi-turn character roleplay.\n\n1. What pre-prompt\
          \ was given when training this model? (the string that wraps around the\
          \ \"instruction\" and \"response\" values in the dataset)\n- For example\
          \ one of Alpaca's preprompts were defined as\n```\nBelow is an instruction\
          \ that describes a task. Write a response that appropriately completes the\
          \ request.\n\n### Instruction:\n{instruction}\n\n### Response:\n{output}\n\
          ```\nWas the \"instruction\" value wrapped with \"BEGIN INSTRUCTION\", \"\
          END INSTRUCTION\" before sending to .train()?\n2. Do you recommend we contextualize\
          \ the conversation between \"USER:\" and \"ASSISTANT:\"?\n-  Based on line\
          \ 4974 and 4614 of expert_createive.jsonl it looks like the turn template\
          \ might do best if we prefance our character names with \"USER: \" and \"\
          ASSISTANT: \"\n- For instance on line 4614 of expert_createive.jsonl I see\
          \ \n```\nUSER: Let's dive into the topic.\nASSISTANT: Nathaniel: Taking\
          \ a moment to admire the...\n```\n- Meaning the turn template that might\
          \ work best here would be something like:\n`USER: <|user|> <|user-message|>\\\
          nASSISTANT: <|bot|> <|bot-message|>\\n`\n3. Would you recommend wrapping\
          \ the character cards with \"BEGINCONTEXT\" and \"ENDCONTEXT\"?\n\nIt seems\
          \ like you use a diverse blend of instruction prompt formats so it may not\
          \ make as much a difference I just want to make sure I'm inferencing with\
          \ whatever format you recommend."
        updatedAt: '2023-08-30T22:16:58.457Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ricofix
    id: 64efbf4282c6eea604b5ec04
    type: comment
  author: practical-dreamer
  content: "I've been reading your prompt instructions and analyzing your dataset\
    \ and would like to ask a couple questions to ensure my instruction template is\
    \ configured correctly for use with ooba's textgenui. My questions are specific\
    \ to two-party multi-turn character roleplay.\n\n1. What pre-prompt was given\
    \ when training this model? (the string that wraps around the \"instruction\"\
    \ and \"response\" values in the dataset)\n- For example one of Alpaca's preprompts\
    \ were defined as\n```\nBelow is an instruction that describes a task. Write a\
    \ response that appropriately completes the request.\n\n### Instruction:\n{instruction}\n\
    \n### Response:\n{output}\n```\nWas the \"instruction\" value wrapped with \"\
    BEGIN INSTRUCTION\", \"END INSTRUCTION\" before sending to .train()?\n2. Do you\
    \ recommend we contextualize the conversation between \"USER:\" and \"ASSISTANT:\"\
    ?\n-  Based on line 4974 and 4614 of expert_createive.jsonl it looks like the\
    \ turn template might do best if we prefance our character names with \"USER:\
    \ \" and \"ASSISTANT: \"\n- For instance on line 4614 of expert_createive.jsonl\
    \ I see \n```\nUSER: Let's dive into the topic.\nASSISTANT: Nathaniel: Taking\
    \ a moment to admire the...\n```\n- Meaning the turn template that might work\
    \ best here would be something like:\n`USER: <|user|> <|user-message|>\\nASSISTANT:\
    \ <|bot|> <|bot-message|>\\n`\n3. Would you recommend wrapping the character cards\
    \ with \"BEGINCONTEXT\" and \"ENDCONTEXT\"?\n\nIt seems like you use a diverse\
    \ blend of instruction prompt formats so it may not make as much a difference\
    \ I just want to make sure I'm inferencing with whatever format you recommend."
  created_at: 2023-08-30 21:14:26+00:00
  edited: true
  hidden: false
  id: 64efbf4282c6eea604b5ec04
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6453dafca647b92069ac541a/QkUleoJtHHdTkqtW54QIG.jpeg?w=200&h=200&f=face
      fullname: Jon Durbin
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: jondurbin
      type: user
    createdAt: '2023-08-30T23:09:40.000Z'
    data:
      edited: false
      editors:
      - jondurbin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9554811716079712
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6453dafca647b92069ac541a/QkUleoJtHHdTkqtW54QIG.jpeg?w=200&h=200&f=face
          fullname: Jon Durbin
          isHf: false
          isPro: true
          name: jondurbin
          type: user
        html: "<p>I would experiment with a many settings to see what works best,\
          \ but most of the training data has a format similar to the following:</p>\n\
          <pre><code>This is a chat between 2 characters: [name of your character]\
          \ and USER\n\n[name of character]: [description of the character, personality\
          \ traits, backstory, speaking style, etc.]\n\n[name of user]: [description\
          \ of user]\n\nUSER is also known as [your name], and must be referred to\
          \ with that name.\n\nSetting for the chat:\n[describe the setting where\
          \ the chat takes place]\nEnd of setting.\nUSER: Start the conversation.\n\
          ASSISTANT: \n</code></pre>\n<p>Be sure to add a single space after <code>ASSISTANT:\
          \ </code> The code used to fine-tune the model random selected newline or\
          \ space before 'ASSISTANT: ', so you may wish to try both to see whether\
          \ a newline helps or hurts performance.</p>\n<p>I would also ensure you\
          \ add a stopping criteria on \"USER:\" and \"ASSISTANT:\" to ensure it doesn't\
          \ try continuing the chat on it's own without user input.</p>\n<p>Other's\
          \ have actually had better results with alpaca style instructions than the\
          \ USER/ASSISTANT prompt format (with previous versions of the model).  I'm\
          \ not sure how much it really matters, if the model wasn't too overfit,\
          \ but I haven't had a chance to test the model much yet.</p>\n"
        raw: "I would experiment with a many settings to see what works best, but\
          \ most of the training data has a format similar to the following:\n\n```\n\
          This is a chat between 2 characters: [name of your character] and USER\n\
          \n[name of character]: [description of the character, personality traits,\
          \ backstory, speaking style, etc.]\n\n[name of user]: [description of user]\n\
          \nUSER is also known as [your name], and must be referred to with that name.\n\
          \nSetting for the chat:\n[describe the setting where the chat takes place]\n\
          End of setting.\nUSER: Start the conversation.\nASSISTANT: \n```\n\nBe sure\
          \ to add a single space after `ASSISTANT: ` The code used to fine-tune the\
          \ model random selected newline or space before 'ASSISTANT: ', so you may\
          \ wish to try both to see whether a newline helps or hurts performance.\n\
          \nI would also ensure you add a stopping criteria on \"USER:\" and \"ASSISTANT:\"\
          \ to ensure it doesn't try continuing the chat on it's own without user\
          \ input.\n\nOther's have actually had better results with alpaca style instructions\
          \ than the USER/ASSISTANT prompt format (with previous versions of the model).\
          \  I'm not sure how much it really matters, if the model wasn't too overfit,\
          \ but I haven't had a chance to test the model much yet."
        updatedAt: '2023-08-30T23:09:40.185Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - ricofix
    id: 64efcc340af6d9bfbc96d3f2
    type: comment
  author: jondurbin
  content: "I would experiment with a many settings to see what works best, but most\
    \ of the training data has a format similar to the following:\n\n```\nThis is\
    \ a chat between 2 characters: [name of your character] and USER\n\n[name of character]:\
    \ [description of the character, personality traits, backstory, speaking style,\
    \ etc.]\n\n[name of user]: [description of user]\n\nUSER is also known as [your\
    \ name], and must be referred to with that name.\n\nSetting for the chat:\n[describe\
    \ the setting where the chat takes place]\nEnd of setting.\nUSER: Start the conversation.\n\
    ASSISTANT: \n```\n\nBe sure to add a single space after `ASSISTANT: ` The code\
    \ used to fine-tune the model random selected newline or space before 'ASSISTANT:\
    \ ', so you may wish to try both to see whether a newline helps or hurts performance.\n\
    \nI would also ensure you add a stopping criteria on \"USER:\" and \"ASSISTANT:\"\
    \ to ensure it doesn't try continuing the chat on it's own without user input.\n\
    \nOther's have actually had better results with alpaca style instructions than\
    \ the USER/ASSISTANT prompt format (with previous versions of the model).  I'm\
    \ not sure how much it really matters, if the model wasn't too overfit, but I\
    \ haven't had a chance to test the model much yet."
  created_at: 2023-08-30 22:09:40+00:00
  edited: false
  hidden: false
  id: 64efcc340af6d9bfbc96d3f2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: jondurbin/airoboros-l2-70b-2.1-creative
repo_type: model
status: open
target_branch: null
title: Character Roleplay Prompt Format and Turn Template
