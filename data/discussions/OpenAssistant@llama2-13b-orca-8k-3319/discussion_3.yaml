!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gsaivinay
conflicting_files: null
created_at: 2023-07-25 13:40:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
      fullname: SVG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gsaivinay
      type: user
    createdAt: '2023-07-25T14:40:32.000Z'
    data:
      edited: false
      editors:
      - gsaivinay
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.913519024848938
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
          fullname: SVG
          isHf: false
          isPro: false
          name: gsaivinay
          type: user
        html: "<p>Thanks for this model with 8k context \U0001F92F</p>\n<blockquote>\n\
          <p>base model: meta-llama/Llama-2-7b</p>\n</blockquote>\n<p>is this a typo\
          \ in Readme?</p>\n<p>Also I'd like to ask few things:</p>\n<ul>\n<li>Is\
          \ this model trained with any coding data? given that it has 8k context,\
          \ it'll be excellent use case for coding assistant.</li>\n<li>Is there any\
          \ prompt format for this model to answer questions based on context? for\
          \ example using it for document chat using vector db.</li>\n<li>did you\
          \ happen to benchmark this model? while I can wait for open llm leaderboard,\
          \ it may take few days for this model to be evaluated in the leaderboard.</li>\n\
          </ul>\n"
        raw: "Thanks for this model with 8k context \U0001F92F\r\n\r\n> base model:\
          \ meta-llama/Llama-2-7b\r\n\r\nis this a typo in Readme?\r\n\r\n\r\nAlso\
          \ I'd like to ask few things:\r\n- Is this model trained with any coding\
          \ data? given that it has 8k context, it'll be excellent use case for coding\
          \ assistant.\r\n- Is there any prompt format for this model to answer questions\
          \ based on context? for example using it for document chat using vector\
          \ db.\r\n- did you happen to benchmark this model? while I can wait for\
          \ open llm leaderboard, it may take few days for this model to be evaluated\
          \ in the leaderboard."
        updatedAt: '2023-07-25T14:40:32.193Z'
      numEdits: 0
      reactions: []
    id: 64bfdee0d824ac47a13957b0
    type: comment
  author: gsaivinay
  content: "Thanks for this model with 8k context \U0001F92F\r\n\r\n> base model:\
    \ meta-llama/Llama-2-7b\r\n\r\nis this a typo in Readme?\r\n\r\n\r\nAlso I'd like\
    \ to ask few things:\r\n- Is this model trained with any coding data? given that\
    \ it has 8k context, it'll be excellent use case for coding assistant.\r\n- Is\
    \ there any prompt format for this model to answer questions based on context?\
    \ for example using it for document chat using vector db.\r\n- did you happen\
    \ to benchmark this model? while I can wait for open llm leaderboard, it may take\
    \ few days for this model to be evaluated in the leaderboard."
  created_at: 2023-07-25 13:40:32+00:00
  edited: false
  hidden: false
  id: 64bfdee0d824ac47a13957b0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b888106cf60e8c3d00dc86/lNCiIc424q60PC2D33vxN.jpeg?w=200&h=200&f=face
      fullname: "Andreas K\xF6pf"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: andreaskoepf
      type: user
    createdAt: '2023-07-25T21:00:32.000Z'
    data:
      edited: false
      editors:
      - andreaskoepf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8921236395835876
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b888106cf60e8c3d00dc86/lNCiIc424q60PC2D33vxN.jpeg?w=200&h=200&f=face
          fullname: "Andreas K\xF6pf"
          isHf: false
          isPro: false
          name: andreaskoepf
          type: user
        html: '<blockquote>

          <p>base model: "meta-llama/Llama-2-7b" -  is this a typo in Readme?</p>

          </blockquote>

          <p>Yes .. good catch, it is of course based on Llama-2-13b, should be fixed
          now!</p>

          <blockquote>

          <p>Is this model trained with any coding data? given that it has 8k context,
          it''ll be excellent use case for coding assistant.</p>

          </blockquote>

          <p>From benchmarks we know that it is currently not performing well in coding
          tasks. We are further fine-tuning the model with more code related instruction
          data.</p>

          <blockquote>

          <p>Is there any prompt format for this model to answer questions based on
          context? for example using it for document chat using vector db.</p>

          </blockquote>

          <p>No, the context would probably best  be placed in the <code>&lt;|prompter|&gt;</code>
          message.</p>

          <blockquote>

          <p>did you happen to benchmark this model? while I can wait for open llm
          leaderboard, it may take few days for this model to be evaluated in the
          leaderboard.</p>

          </blockquote>

          <p>Some benchmark results can be found here: <a rel="nofollow" href="https://tju01.github.io/ilm-eval/#?branch=oa-orca">https://tju01.github.io/ilm-eval/#?branch=oa-orca</a>
          </p>

          '
        raw: "> base model: \"meta-llama/Llama-2-7b\" -  is this a typo in Readme?\n\
          \nYes .. good catch, it is of course based on Llama-2-13b, should be fixed\
          \ now!\n\n\n  > Is this model trained with any coding data? given that it\
          \ has 8k context, it'll be excellent use case for coding assistant.\n\n\
          From benchmarks we know that it is currently not performing well in coding\
          \ tasks. We are further fine-tuning the model with more code related instruction\
          \ data.\n\n   > Is there any prompt format for this model to answer questions\
          \ based on context? for example using it for document chat using vector\
          \ db.\n\nNo, the context would probably best  be placed in the `<|prompter|>`\
          \ message.\n\n   >did you happen to benchmark this model? while I can wait\
          \ for open llm leaderboard, it may take few days for this model to be evaluated\
          \ in the leaderboard.\n\nSome benchmark results can be found here: https://tju01.github.io/ilm-eval/#?branch=oa-orca "
        updatedAt: '2023-07-25T21:00:32.547Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - gsaivinay
    id: 64c037f036db3901adc2b97f
    type: comment
  author: andreaskoepf
  content: "> base model: \"meta-llama/Llama-2-7b\" -  is this a typo in Readme?\n\
    \nYes .. good catch, it is of course based on Llama-2-13b, should be fixed now!\n\
    \n\n  > Is this model trained with any coding data? given that it has 8k context,\
    \ it'll be excellent use case for coding assistant.\n\nFrom benchmarks we know\
    \ that it is currently not performing well in coding tasks. We are further fine-tuning\
    \ the model with more code related instruction data.\n\n   > Is there any prompt\
    \ format for this model to answer questions based on context? for example using\
    \ it for document chat using vector db.\n\nNo, the context would probably best\
    \  be placed in the `<|prompter|>` message.\n\n   >did you happen to benchmark\
    \ this model? while I can wait for open llm leaderboard, it may take few days\
    \ for this model to be evaluated in the leaderboard.\n\nSome benchmark results\
    \ can be found here: https://tju01.github.io/ilm-eval/#?branch=oa-orca "
  created_at: 2023-07-25 20:00:32+00:00
  edited: false
  hidden: false
  id: 64c037f036db3901adc2b97f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
      fullname: SVG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gsaivinay
      type: user
    createdAt: '2023-07-26T07:59:59.000Z'
    data:
      status: closed
    id: 64c0d27fb85ee9e4222c5bfd
    type: status-change
  author: gsaivinay
  created_at: 2023-07-26 06:59:59+00:00
  id: 64c0d27fb85ee9e4222c5bfd
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
      fullname: SVG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gsaivinay
      type: user
    createdAt: '2023-07-26T11:23:23.000Z'
    data:
      edited: false
      editors:
      - gsaivinay
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5449746251106262
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ad4bb6fe31efe3634e349f59d6d57b79.svg
          fullname: SVG
          isHf: false
          isPro: false
          name: gsaivinay
          type: user
        html: '<p>evaluation available now</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/639a21281791d1f367cfde4c/lgzJINKmr5CYSnl7mSkaH.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/639a21281791d1f367cfde4c/lgzJINKmr5CYSnl7mSkaH.png"></a></p>

          '
        raw: 'evaluation available now



          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/639a21281791d1f367cfde4c/lgzJINKmr5CYSnl7mSkaH.png)

          '
        updatedAt: '2023-07-26T11:23:23.349Z'
      numEdits: 0
      reactions: []
    id: 64c1022ba73ac49b2c1db5d1
    type: comment
  author: gsaivinay
  content: 'evaluation available now



    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/639a21281791d1f367cfde4c/lgzJINKmr5CYSnl7mSkaH.png)

    '
  created_at: 2023-07-26 10:23:23+00:00
  edited: false
  hidden: false
  id: 64c1022ba73ac49b2c1db5d1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: OpenAssistant/llama2-13b-orca-8k-3319
repo_type: model
status: closed
target_branch: null
title: Awesome, thanks
