!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ecorro
conflicting_files: null
created_at: 2023-06-22 21:16:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1c1feb032c94a864355c667b5596c4f2.svg
      fullname: Enrique Corro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ecorro
      type: user
    createdAt: '2023-06-22T22:16:01.000Z'
    data:
      edited: true
      editors:
      - ecorro
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8407046794891357
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1c1feb032c94a864355c667b5596c4f2.svg
          fullname: Enrique Corro
          isHf: false
          isPro: false
          name: ecorro
          type: user
        html: '<p>I''m trying to fine tune it with another instruct dataset and want
          to do it using bfp16 instead of 4-bit QLoRA. Can anyone please point me
          to an appropriate lora_config  setup? Particularly the ''target_modules''
          prameter.</p>

          '
        raw: I'm trying to fine tune it with another instruct dataset and want to
          do it using bfp16 instead of 4-bit QLoRA. Can anyone please point me to
          an appropriate lora_config  setup? Particularly the 'target_modules' prameter.
        updatedAt: '2023-06-22T22:31:56.051Z'
      numEdits: 1
      reactions: []
    id: 6494c821139e3f738a7287c3
    type: comment
  author: ecorro
  content: I'm trying to fine tune it with another instruct dataset and want to do
    it using bfp16 instead of 4-bit QLoRA. Can anyone please point me to an appropriate
    lora_config  setup? Particularly the 'target_modules' prameter.
  created_at: 2023-06-22 21:16:01+00:00
  edited: true
  hidden: false
  id: 6494c821139e3f738a7287c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/1c1feb032c94a864355c667b5596c4f2.svg
      fullname: Enrique Corro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ecorro
      type: user
    createdAt: '2023-06-23T19:20:18.000Z'
    data:
      status: closed
    id: 6495f07222f657d37bf4671e
    type: status-change
  author: ecorro
  created_at: 2023-06-23 18:20:18+00:00
  id: 6495f07222f657d37bf4671e
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1c1feb032c94a864355c667b5596c4f2.svg
      fullname: Enrique Corro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ecorro
      type: user
    createdAt: '2023-06-23T19:21:43.000Z'
    data:
      edited: false
      editors:
      - ecorro
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7159087657928467
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1c1feb032c94a864355c667b5596c4f2.svg
          fullname: Enrique Corro
          isHf: false
          isPro: false
          name: ecorro
          type: user
        html: '<p>Here the answer to my question <a rel="nofollow" href="https://gist.github.com/pacman100/1731b41f7a90a87b457e8c5415ff1c14">https://gist.github.com/pacman100/1731b41f7a90a87b457e8c5415ff1c14</a>
          </p>

          '
        raw: 'Here the answer to my question https://gist.github.com/pacman100/1731b41f7a90a87b457e8c5415ff1c14 '
        updatedAt: '2023-06-23T19:21:43.019Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6495f0c72ec29bb1a7615f09
    id: 6495f0c72ec29bb1a7615f08
    type: comment
  author: ecorro
  content: 'Here the answer to my question https://gist.github.com/pacman100/1731b41f7a90a87b457e8c5415ff1c14 '
  created_at: 2023-06-23 18:21:43+00:00
  edited: false
  hidden: false
  id: 6495f0c72ec29bb1a7615f08
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/1c1feb032c94a864355c667b5596c4f2.svg
      fullname: Enrique Corro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ecorro
      type: user
    createdAt: '2023-06-23T19:21:43.000Z'
    data:
      status: open
    id: 6495f0c72ec29bb1a7615f09
    type: status-change
  author: ecorro
  created_at: 2023-06-23 18:21:43+00:00
  id: 6495f0c72ec29bb1a7615f09
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/1c1feb032c94a864355c667b5596c4f2.svg
      fullname: Enrique Corro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ecorro
      type: user
    createdAt: '2023-06-23T19:21:57.000Z'
    data:
      status: closed
    id: 6495f0d538e398e724271118
    type: status-change
  author: ecorro
  created_at: 2023-06-23 18:21:57+00:00
  id: 6495f0d538e398e724271118
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 42
repo_id: tiiuae/falcon-7b-instruct
repo_type: model
status: closed
target_branch: null
title: What was the lora_config used to create this fine-tuned version of falcon-7b?
