!!python/object:huggingface_hub.community.DiscussionWithDetails
author: patti-j
conflicting_files: null
created_at: 2023-06-18 21:33:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1edcd0edf763e5dd977a0e802232c013.svg
      fullname: Patti Jorgensen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patti-j
      type: user
    createdAt: '2023-06-18T22:33:43.000Z'
    data:
      edited: false
      editors:
      - patti-j
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.15229558944702148
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1edcd0edf763e5dd977a0e802232c013.svg
          fullname: Patti Jorgensen
          isHf: false
          isPro: false
          name: patti-j
          type: user
        html: "<p>\u256D\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent\
          \ call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256E<br>\u2502\
          \ in :8                                                                \
          \                    \u2502<br>\u2502                                  \
          \                                                                \u2502\
          <br>\u2502    5 #model = \"tiiuae/falcon-7b-instruct\"                 \
          \                                       \u2502<br>\u2502    6 model = AutoModelForCausalLM.from_pretrained(\"\
          tiiuae/falcon-7b\", trust_remote_code=True)    \u2502<br>\u2502    7   \
          \                                                                      \
          \                    \u2502<br>\u2502 \u2771  8 tokenizer = AutoTokenizer.from_pretrained(model)\
          \                                            \u2502<br>\u2502    9 pipeline\
          \ = transformers.pipeline(                                             \
          \              \u2502<br>\u2502   10 \u2502   \"text-generation\",     \
          \                                                                 \u2502\
          <br>\u2502   11 \u2502   model=model,                                  \
          \                                          \u2502<br>\u2502            \
          \                                                                      \
          \                \u2502<br>\u2502 C:\\Users\\PattiJorgensen\\AppData\\Roaming\\\
          Python\\Python311\\site-packages\\transformers\\models\\auto\\ \u2502<br>\u2502\
          \ tokenization_auto.py:642 in from_pretrained                          \
          \                            \u2502<br>\u2502                          \
          \                                                                      \
          \  \u2502<br>\u2502   639 \u2502   \u2502   \u2502   return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *input   \u2502<br>\u2502   640 \u2502   \u2502                      \
          \                                                                \u2502\
          <br>\u2502   641 \u2502   \u2502   # Next, let's try to use the tokenizer_config\
          \ file to get the tokenizer class.     \u2502<br>\u2502 \u2771 642 \u2502\
          \   \u2502   tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path,\
          \ **kwargs)   \u2502<br>\u2502   643 \u2502   \u2502   if \"_commit_hash\"\
          \ in tokenizer_config:                                             \u2502\
          <br>\u2502   644 \u2502   \u2502   \u2502   kwargs[\"_commit_hash\"] = tokenizer_config[\"\
          _commit_hash\"]                      \u2502<br>\u2502   645 \u2502   \u2502\
          \   config_tokenizer_class = tokenizer_config.get(\"tokenizer_class\") \
          \                  \u2502<br>\u2502                                    \
          \                                                              \u2502<br>\u2502\
          \ C:\\Users\\PattiJorgensen\\AppData\\Roaming\\Python\\Python311\\site-packages\\\
          transformers\\models\\auto\\ \u2502<br>\u2502 tokenization_auto.py:486 in\
          \ get_tokenizer_config                                                 \u2502\
          <br>\u2502                                                             \
          \                                     \u2502<br>\u2502   483 \u2502   tokenizer_config\
          \ = get_tokenizer_config(\"tokenizer-test\")                           \
          \   \u2502<br>\u2502   484 \u2502   ```\"\"\"                          \
          \                                                       \u2502<br>\u2502\
          \   485 \u2502   commit_hash = kwargs.get(\"<em>commit_hash\", None)   \
          \                                      \u2502<br>\u2502 \u2771 486 \u2502\
          \   resolved_config_file = cached_file(                                \
          \                    \u2502<br>\u2502   487 \u2502   \u2502   pretrained_model_name_or_path,\
          \                                                     \u2502<br>\u2502 \
          \  488 \u2502   \u2502   TOKENIZER_CONFIG_FILE,                        \
          \                                     \u2502<br>\u2502   489 \u2502   \u2502\
          \   cache_dir=cache_dir,                                               \
          \                \u2502<br>\u2502                                      \
          \                                                            \u2502<br>\u2502\
          \ C:\\Users\\PattiJorgensen\\AppData\\Roaming\\Python\\Python311\\site-packages\\\
          transformers\\utils\\hub.py \u2502<br>\u2502 :409 in cached_file       \
          \                                                                      \
          \ \u2502<br>\u2502                                                     \
          \                                             \u2502<br>\u2502    406 \u2502\
          \   user_agent = http_user_agent(user_agent)                           \
          \                   \u2502<br>\u2502    407 \u2502   try:              \
          \                                                                    \u2502\
          <br>\u2502    408 \u2502   \u2502   # Load from URL or cache if already\
          \ cached                                        \u2502<br>\u2502 \u2771\
          \  409 \u2502   \u2502   resolved_file = hf_hub_download(              \
          \                                    \u2502<br>\u2502    410 \u2502   \u2502\
          \   \u2502   path_or_repo_id,                                          \
          \                    \u2502<br>\u2502    411 \u2502   \u2502   \u2502  \
          \ filename,                                                            \
          \         \u2502<br>\u2502    412 \u2502   \u2502   \u2502   subfolder=None\
          \ if len(subfolder) == 0 else subfolder,                         \u2502\
          <br>\u2502                                                             \
          \                                     \u2502<br>\u2502 c:\\Python311\\Lib\\\
          site-packages\\huggingface_hub\\utils_validators.py:110 in <em>inner_fn\
          \             \u2502<br>\u2502                                         \
          \                                                         \u2502<br>\u2502\
          \   107 \u2502   \u2502   \u2502   kwargs.items(),  # Kwargs values    \
          \                                           \u2502<br>\u2502   108 \u2502\
          \   \u2502   ):                                                        \
          \                         \u2502<br>\u2502   109 \u2502   \u2502   \u2502\
          \   if arg_name in [\"repo_id\", \"from_id\", \"to_id\"]:              \
          \                  \u2502<br>\u2502 \u2771 110 \u2502   \u2502   \u2502\
          \   \u2502   validate_repo_id(arg_value)                               \
          \                 \u2502<br>\u2502   111 \u2502   \u2502   \u2502      \
          \                                                                      \
          \      \u2502<br>\u2502   112 \u2502   \u2502   \u2502   elif arg_name ==\
          \ \"token\" and arg_value is not None:                            \u2502\
          <br>\u2502   113 \u2502   \u2502   \u2502   \u2502   has_token = True  \
          \                                                         \u2502<br>\u2502\
          \                                                                      \
          \                            \u2502<br>\u2502 c:\\Python311\\Lib\\site-packages\\\
          huggingface_hub\\utils_validators.py:164 in validate_repo_id      \u2502\
          <br>\u2502                                                             \
          \                                     \u2502<br>\u2502   161 \u2502   \u2502\
          \   )                                                                  \
          \                \u2502<br>\u2502   162 \u2502                         \
          \                                                                 \u2502\
          <br>\u2502   163 \u2502   if not REPO_ID_REGEX.match(repo_id):         \
          \                                          \u2502<br>\u2502 \u2771 164 \u2502\
          \   \u2502   raise HFValidationError(                                  \
          \                         \u2502<br>\u2502   165 \u2502   \u2502   \u2502\
          \   \"Repo id must use alphanumeric chars or '-', '</em>', '.', '--' and\
          \ '..' are\"      \u2502<br>\u2502   166 \u2502   \u2502   \u2502   \" forbidden,\
          \ '-' and '.' cannot start or end the name, max length is 96:\"      \u2502\
          <br>\u2502   167 \u2502   \u2502   \u2502   f\" '{repo_id}'.\"         \
          \                                                      \u2502<br>\u2570\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u256F<br>HFValidationError: Repo id must use alphanumeric chars or\
          \ '-', '</em>', '.', '--' and '..' are forbidden, '-' and '.'<br>cannot\
          \ start or end the name, max length is 96: 'RWForCausalLM(<br>  (transformer):\
          \ RWModel(<br>    (word_embeddings): Embedding(65024, 4544)<br>    (h):\
          \ ModuleList(<br>      (0-31): 32 x DecoderLayer(<br>        (input_layernorm):\
          \ LayerNorm((4544,), eps=1e-05, elementwise_affine=True)<br>        (self_attention):\
          \ Attention(<br>          (maybe_rotary): RotaryEmbedding()<br>        \
          \  (query_key_value): Linear(in_features=4544, out_features=4672, bias=False)<br>\
          \          (dense): Linear(in_features=4544, out_features=4544, bias=False)<br>\
          \          (attention_dropout): Dropout(p=0.0, inplace=False)<br>      \
          \  )<br>        (mlp): MLP(<br>          (dense_h_to_4h): Linear(in_features=4544,\
          \ out_features=18176, bias=False)<br>          (act): GELU(approximate='none')<br>\
          \          (dense_4h_to_h): Linear(in_features=18176, out_features=4544,\
          \ bias=False)<br>        )<br>      )<br>    )<br>    (ln_f): LayerNorm((4544,),\
          \ eps=1e-05, elementwise_affine=True)<br>  )<br>  (lm_head): Linear(in_features=4544,\
          \ out_features=65024, bias=False)<br>)'.</p>\n"
        raw: "\r\n\u256D\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent\
          \ call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256E\r\n\u2502\
          \ in <module>:8                                                        \
          \                            \u2502\r\n\u2502                          \
          \                                                                      \
          \  \u2502\r\n\u2502    5 #model = \"tiiuae/falcon-7b-instruct\"        \
          \                                                \u2502\r\n\u2502    6 model\
          \ = AutoModelForCausalLM.from_pretrained(\"tiiuae/falcon-7b\", trust_remote_code=True)\
          \    \u2502\r\n\u2502    7                                             \
          \                                                \u2502\r\n\u2502 \u2771\
          \  8 tokenizer = AutoTokenizer.from_pretrained(model)                  \
          \                          \u2502\r\n\u2502    9 pipeline = transformers.pipeline(\
          \                                                           \u2502\r\n\u2502\
          \   10 \u2502   \"text-generation\",                                   \
          \                                   \u2502\r\n\u2502   11 \u2502   model=model,\
          \                                                                      \
          \      \u2502\r\n\u2502                                                \
          \                                                  \u2502\r\n\u2502 C:\\\
          Users\\PattiJorgensen\\AppData\\Roaming\\Python\\Python311\\site-packages\\\
          transformers\\models\\auto\\ \u2502\r\n\u2502 tokenization_auto.py:642 in\
          \ from_pretrained                                                      \u2502\
          \r\n\u2502                                                             \
          \                                     \u2502\r\n\u2502   639 \u2502   \u2502\
          \   \u2502   return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *input   \u2502\r\n\u2502   640 \u2502   \u2502                      \
          \                                                                \u2502\r\
          \n\u2502   641 \u2502   \u2502   # Next, let's try to use the tokenizer_config\
          \ file to get the tokenizer class.     \u2502\r\n\u2502 \u2771 642 \u2502\
          \   \u2502   tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path,\
          \ **kwargs)   \u2502\r\n\u2502   643 \u2502   \u2502   if \"_commit_hash\"\
          \ in tokenizer_config:                                             \u2502\
          \r\n\u2502   644 \u2502   \u2502   \u2502   kwargs[\"_commit_hash\"] = tokenizer_config[\"\
          _commit_hash\"]                      \u2502\r\n\u2502   645 \u2502   \u2502\
          \   config_tokenizer_class = tokenizer_config.get(\"tokenizer_class\") \
          \                  \u2502\r\n\u2502                                    \
          \                                                              \u2502\r\n\
          \u2502 C:\\Users\\PattiJorgensen\\AppData\\Roaming\\Python\\Python311\\\
          site-packages\\transformers\\models\\auto\\ \u2502\r\n\u2502 tokenization_auto.py:486\
          \ in get_tokenizer_config                                              \
          \   \u2502\r\n\u2502                                                   \
          \                                               \u2502\r\n\u2502   483 \u2502\
          \   tokenizer_config = get_tokenizer_config(\"tokenizer-test\")        \
          \                      \u2502\r\n\u2502   484 \u2502   ```\"\"\"       \
          \                                                                      \
          \    \u2502\r\n\u2502   485 \u2502   commit_hash = kwargs.get(\"_commit_hash\"\
          , None)                                         \u2502\r\n\u2502 \u2771\
          \ 486 \u2502   resolved_config_file = cached_file(                     \
          \                               \u2502\r\n\u2502   487 \u2502   \u2502 \
          \  pretrained_model_name_or_path,                                      \
          \               \u2502\r\n\u2502   488 \u2502   \u2502   TOKENIZER_CONFIG_FILE,\
          \                                                             \u2502\r\n\
          \u2502   489 \u2502   \u2502   cache_dir=cache_dir,                    \
          \                                           \u2502\r\n\u2502           \
          \                                                                      \
          \                 \u2502\r\n\u2502 C:\\Users\\PattiJorgensen\\AppData\\\
          Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py \u2502\
          \r\n\u2502 :409 in cached_file                                         \
          \                                     \u2502\r\n\u2502                 \
          \                                                                      \
          \           \u2502\r\n\u2502    406 \u2502   user_agent = http_user_agent(user_agent)\
          \                                              \u2502\r\n\u2502    407 \u2502\
          \   try:                                                               \
          \                   \u2502\r\n\u2502    408 \u2502   \u2502   # Load from\
          \ URL or cache if already cached                                       \
          \ \u2502\r\n\u2502 \u2771  409 \u2502   \u2502   resolved_file = hf_hub_download(\
          \                                                  \u2502\r\n\u2502    410\
          \ \u2502   \u2502   \u2502   path_or_repo_id,                          \
          \                                    \u2502\r\n\u2502    411 \u2502   \u2502\
          \   \u2502   filename,                                                 \
          \                    \u2502\r\n\u2502    412 \u2502   \u2502   \u2502  \
          \ subfolder=None if len(subfolder) == 0 else subfolder,                \
          \         \u2502\r\n\u2502                                             \
          \                                                     \u2502\r\n\u2502 c:\\\
          Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:110\
          \ in _inner_fn             \u2502\r\n\u2502                            \
          \                                                                      \u2502\
          \r\n\u2502   107 \u2502   \u2502   \u2502   kwargs.items(),  # Kwargs values\
          \                                               \u2502\r\n\u2502   108 \u2502\
          \   \u2502   ):                                                        \
          \                         \u2502\r\n\u2502   109 \u2502   \u2502   \u2502\
          \   if arg_name in [\"repo_id\", \"from_id\", \"to_id\"]:              \
          \                  \u2502\r\n\u2502 \u2771 110 \u2502   \u2502   \u2502\
          \   \u2502   validate_repo_id(arg_value)                               \
          \                 \u2502\r\n\u2502   111 \u2502   \u2502   \u2502      \
          \                                                                      \
          \      \u2502\r\n\u2502   112 \u2502   \u2502   \u2502   elif arg_name ==\
          \ \"token\" and arg_value is not None:                            \u2502\
          \r\n\u2502   113 \u2502   \u2502   \u2502   \u2502   has_token = True  \
          \                                                         \u2502\r\n\u2502\
          \                                                                      \
          \                            \u2502\r\n\u2502 c:\\Python311\\Lib\\site-packages\\\
          huggingface_hub\\utils\\_validators.py:164 in validate_repo_id      \u2502\
          \r\n\u2502                                                             \
          \                                     \u2502\r\n\u2502   161 \u2502   \u2502\
          \   )                                                                  \
          \                \u2502\r\n\u2502   162 \u2502                         \
          \                                                                 \u2502\
          \r\n\u2502   163 \u2502   if not REPO_ID_REGEX.match(repo_id):         \
          \                                          \u2502\r\n\u2502 \u2771 164 \u2502\
          \   \u2502   raise HFValidationError(                                  \
          \                         \u2502\r\n\u2502   165 \u2502   \u2502   \u2502\
          \   \"Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..'\
          \ are\"      \u2502\r\n\u2502   166 \u2502   \u2502   \u2502   \" forbidden,\
          \ '-' and '.' cannot start or end the name, max length is 96:\"      \u2502\
          \r\n\u2502   167 \u2502   \u2502   \u2502   f\" '{repo_id}'.\"         \
          \                                                      \u2502\r\n\u2570\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u256F\r\nHFValidationError: Repo id must use alphanumeric chars or\
          \ '-', '_', '.', '--' and '..' are forbidden, '-' and '.' \r\ncannot start\
          \ or end the name, max length is 96: 'RWForCausalLM(\r\n  (transformer):\
          \ RWModel(\r\n    (word_embeddings): Embedding(65024, 4544)\r\n    (h):\
          \ ModuleList(\r\n      (0-31): 32 x DecoderLayer(\r\n        (input_layernorm):\
          \ LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\r\n        (self_attention):\
          \ Attention(\r\n          (maybe_rotary): RotaryEmbedding()\r\n        \
          \  (query_key_value): Linear(in_features=4544, out_features=4672, bias=False)\r\
          \n          (dense): Linear(in_features=4544, out_features=4544, bias=False)\r\
          \n          (attention_dropout): Dropout(p=0.0, inplace=False)\r\n     \
          \   )\r\n        (mlp): MLP(\r\n          (dense_h_to_4h): Linear(in_features=4544,\
          \ out_features=18176, bias=False)\r\n          (act): GELU(approximate='none')\r\
          \n          (dense_4h_to_h): Linear(in_features=18176, out_features=4544,\
          \ bias=False)\r\n        )\r\n      )\r\n    )\r\n    (ln_f): LayerNorm((4544,),\
          \ eps=1e-05, elementwise_affine=True)\r\n  )\r\n  (lm_head): Linear(in_features=4544,\
          \ out_features=65024, bias=False)\r\n)'."
        updatedAt: '2023-06-18T22:33:43.711Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - cr00
    id: 648f8647e8a1900eb6317460
    type: comment
  author: patti-j
  content: "\r\n\u256D\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last)\
    \ \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u256E\r\n\u2502 in <module>:8           \
    \                                                                         \u2502\
    \r\n\u2502                                                                   \
    \                               \u2502\r\n\u2502    5 #model = \"tiiuae/falcon-7b-instruct\"\
    \                                                        \u2502\r\n\u2502    6\
    \ model = AutoModelForCausalLM.from_pretrained(\"tiiuae/falcon-7b\", trust_remote_code=True)\
    \    \u2502\r\n\u2502    7                                                   \
    \                                          \u2502\r\n\u2502 \u2771  8 tokenizer\
    \ = AutoTokenizer.from_pretrained(model)                                     \
    \       \u2502\r\n\u2502    9 pipeline = transformers.pipeline(              \
    \                                             \u2502\r\n\u2502   10 \u2502   \"\
    text-generation\",                                                           \
    \           \u2502\r\n\u2502   11 \u2502   model=model,                      \
    \                                                      \u2502\r\n\u2502      \
    \                                                                            \
    \                \u2502\r\n\u2502 C:\\Users\\PattiJorgensen\\AppData\\Roaming\\\
    Python\\Python311\\site-packages\\transformers\\models\\auto\\ \u2502\r\n\u2502\
    \ tokenization_auto.py:642 in from_pretrained                                \
    \                      \u2502\r\n\u2502                                      \
    \                                                            \u2502\r\n\u2502\
    \   639 \u2502   \u2502   \u2502   return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
    \ *input   \u2502\r\n\u2502   640 \u2502   \u2502                            \
    \                                                          \u2502\r\n\u2502  \
    \ 641 \u2502   \u2502   # Next, let's try to use the tokenizer_config file to\
    \ get the tokenizer class.     \u2502\r\n\u2502 \u2771 642 \u2502   \u2502   tokenizer_config\
    \ = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)   \u2502\r\n\
    \u2502   643 \u2502   \u2502   if \"_commit_hash\" in tokenizer_config:      \
    \                                       \u2502\r\n\u2502   644 \u2502   \u2502\
    \   \u2502   kwargs[\"_commit_hash\"] = tokenizer_config[\"_commit_hash\"]   \
    \                   \u2502\r\n\u2502   645 \u2502   \u2502   config_tokenizer_class\
    \ = tokenizer_config.get(\"tokenizer_class\")                   \u2502\r\n\u2502\
    \                                                                            \
    \                      \u2502\r\n\u2502 C:\\Users\\PattiJorgensen\\AppData\\Roaming\\\
    Python\\Python311\\site-packages\\transformers\\models\\auto\\ \u2502\r\n\u2502\
    \ tokenization_auto.py:486 in get_tokenizer_config                           \
    \                      \u2502\r\n\u2502                                      \
    \                                                            \u2502\r\n\u2502\
    \   483 \u2502   tokenizer_config = get_tokenizer_config(\"tokenizer-test\") \
    \                             \u2502\r\n\u2502   484 \u2502   ```\"\"\"      \
    \                                                                           \u2502\
    \r\n\u2502   485 \u2502   commit_hash = kwargs.get(\"_commit_hash\", None)   \
    \                                      \u2502\r\n\u2502 \u2771 486 \u2502   resolved_config_file\
    \ = cached_file(                                                    \u2502\r\n\
    \u2502   487 \u2502   \u2502   pretrained_model_name_or_path,                \
    \                                     \u2502\r\n\u2502   488 \u2502   \u2502 \
    \  TOKENIZER_CONFIG_FILE,                                                    \
    \         \u2502\r\n\u2502   489 \u2502   \u2502   cache_dir=cache_dir,      \
    \                                                         \u2502\r\n\u2502   \
    \                                                                            \
    \                   \u2502\r\n\u2502 C:\\Users\\PattiJorgensen\\AppData\\Roaming\\\
    Python\\Python311\\site-packages\\transformers\\utils\\hub.py \u2502\r\n\u2502\
    \ :409 in cached_file                                                        \
    \                      \u2502\r\n\u2502                                      \
    \                                                            \u2502\r\n\u2502\
    \    406 \u2502   user_agent = http_user_agent(user_agent)                   \
    \                           \u2502\r\n\u2502    407 \u2502   try:            \
    \                                                                      \u2502\r\
    \n\u2502    408 \u2502   \u2502   # Load from URL or cache if already cached \
    \                                       \u2502\r\n\u2502 \u2771  409 \u2502  \
    \ \u2502   resolved_file = hf_hub_download(                                  \
    \                \u2502\r\n\u2502    410 \u2502   \u2502   \u2502   path_or_repo_id,\
    \                                                              \u2502\r\n\u2502\
    \    411 \u2502   \u2502   \u2502   filename,                                \
    \                                     \u2502\r\n\u2502    412 \u2502   \u2502\
    \   \u2502   subfolder=None if len(subfolder) == 0 else subfolder,           \
    \              \u2502\r\n\u2502                                              \
    \                                                    \u2502\r\n\u2502 c:\\Python311\\\
    Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:110 in _inner_fn  \
    \           \u2502\r\n\u2502                                                 \
    \                                                 \u2502\r\n\u2502   107 \u2502\
    \   \u2502   \u2502   kwargs.items(),  # Kwargs values                       \
    \                        \u2502\r\n\u2502   108 \u2502   \u2502   ):         \
    \                                                                        \u2502\
    \r\n\u2502   109 \u2502   \u2502   \u2502   if arg_name in [\"repo_id\", \"from_id\"\
    , \"to_id\"]:                                \u2502\r\n\u2502 \u2771 110 \u2502\
    \   \u2502   \u2502   \u2502   validate_repo_id(arg_value)                   \
    \                             \u2502\r\n\u2502   111 \u2502   \u2502   \u2502\
    \                                                                            \
    \      \u2502\r\n\u2502   112 \u2502   \u2502   \u2502   elif arg_name == \"token\"\
    \ and arg_value is not None:                            \u2502\r\n\u2502   113\
    \ \u2502   \u2502   \u2502   \u2502   has_token = True                       \
    \                                    \u2502\r\n\u2502                        \
    \                                                                          \u2502\
    \r\n\u2502 c:\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:164\
    \ in validate_repo_id      \u2502\r\n\u2502                                  \
    \                                                                \u2502\r\n\u2502\
    \   161 \u2502   \u2502   )                                                  \
    \                                \u2502\r\n\u2502   162 \u2502               \
    \                                                                           \u2502\
    \r\n\u2502   163 \u2502   if not REPO_ID_REGEX.match(repo_id):               \
    \                                    \u2502\r\n\u2502 \u2771 164 \u2502   \u2502\
    \   raise HFValidationError(                                                 \
    \          \u2502\r\n\u2502   165 \u2502   \u2502   \u2502   \"Repo id must use\
    \ alphanumeric chars or '-', '_', '.', '--' and '..' are\"      \u2502\r\n\u2502\
    \   166 \u2502   \u2502   \u2502   \" forbidden, '-' and '.' cannot start or end\
    \ the name, max length is 96:\"      \u2502\r\n\u2502   167 \u2502   \u2502  \
    \ \u2502   f\" '{repo_id}'.\"                                                \
    \               \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256F\
    \r\nHFValidationError: Repo id must use alphanumeric chars or '-', '_', '.', '--'\
    \ and '..' are forbidden, '-' and '.' \r\ncannot start or end the name, max length\
    \ is 96: 'RWForCausalLM(\r\n  (transformer): RWModel(\r\n    (word_embeddings):\
    \ Embedding(65024, 4544)\r\n    (h): ModuleList(\r\n      (0-31): 32 x DecoderLayer(\r\
    \n        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\r\
    \n        (self_attention): Attention(\r\n          (maybe_rotary): RotaryEmbedding()\r\
    \n          (query_key_value): Linear(in_features=4544, out_features=4672, bias=False)\r\
    \n          (dense): Linear(in_features=4544, out_features=4544, bias=False)\r\
    \n          (attention_dropout): Dropout(p=0.0, inplace=False)\r\n        )\r\n\
    \        (mlp): MLP(\r\n          (dense_h_to_4h): Linear(in_features=4544, out_features=18176,\
    \ bias=False)\r\n          (act): GELU(approximate='none')\r\n          (dense_4h_to_h):\
    \ Linear(in_features=18176, out_features=4544, bias=False)\r\n        )\r\n  \
    \    )\r\n    )\r\n    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\r\
    \n  )\r\n  (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\r\
    \n)'."
  created_at: 2023-06-18 21:33:43+00:00
  edited: false
  hidden: false
  id: 648f8647e8a1900eb6317460
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/o8Ulf7Tan062ifN8nXZIN.png?w=200&h=200&f=face
      fullname: jimbo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cr00
      type: user
    createdAt: '2023-06-26T14:35:24.000Z'
    data:
      edited: false
      editors:
      - cr00
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9761658906936646
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/o8Ulf7Tan062ifN8nXZIN.png?w=200&h=200&f=face
          fullname: jimbo
          isHf: false
          isPro: false
          name: cr00
          type: user
        html: '<p>same, but I don''t know where in the pipeline there is any repo
          id</p>

          '
        raw: same, but I don't know where in the pipeline there is any repo id
        updatedAt: '2023-06-26T14:35:24.737Z'
      numEdits: 0
      reactions: []
    id: 6499a22c47ce9764a43c6ae7
    type: comment
  author: cr00
  content: same, but I don't know where in the pipeline there is any repo id
  created_at: 2023-06-26 13:35:24+00:00
  edited: false
  hidden: false
  id: 6499a22c47ce9764a43c6ae7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1edcd0edf763e5dd977a0e802232c013.svg
      fullname: Patti Jorgensen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patti-j
      type: user
    createdAt: '2023-06-26T17:38:22.000Z'
    data:
      edited: false
      editors:
      - patti-j
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9746952652931213
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1edcd0edf763e5dd977a0e802232c013.svg
          fullname: Patti Jorgensen
          isHf: false
          isPro: false
          name: patti-j
          type: user
        html: '<p>I traced it back to the README file, of all things. HF appears to
          be validating README files. I was going to report it but haven''t had a
          chance yet. In the meantime I altered my version of HF validation python
          file to omit this record.</p>

          '
        raw: I traced it back to the README file, of all things. HF appears to be
          validating README files. I was going to report it but haven't had a chance
          yet. In the meantime I altered my version of HF validation python file to
          omit this record.
        updatedAt: '2023-06-26T17:38:22.963Z'
      numEdits: 0
      reactions: []
    id: 6499cd0e7674f057d5b772bf
    type: comment
  author: patti-j
  content: I traced it back to the README file, of all things. HF appears to be validating
    README files. I was going to report it but haven't had a chance yet. In the meantime
    I altered my version of HF validation python file to omit this record.
  created_at: 2023-06-26 16:38:22+00:00
  edited: false
  hidden: false
  id: 6499cd0e7674f057d5b772bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/o8Ulf7Tan062ifN8nXZIN.png?w=200&h=200&f=face
      fullname: jimbo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cr00
      type: user
    createdAt: '2023-06-26T18:25:18.000Z'
    data:
      edited: false
      editors:
      - cr00
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9278224110603333
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/o8Ulf7Tan062ifN8nXZIN.png?w=200&h=200&f=face
          fullname: jimbo
          isHf: false
          isPro: false
          name: cr00
          type: user
        html: '<p>do you remember the name of the file you edited? thanks</p>

          '
        raw: do you remember the name of the file you edited? thanks
        updatedAt: '2023-06-26T18:25:18.938Z'
      numEdits: 0
      reactions: []
    id: 6499d80e6558dafec6a59286
    type: comment
  author: cr00
  content: do you remember the name of the file you edited? thanks
  created_at: 2023-06-26 17:25:18+00:00
  edited: false
  hidden: false
  id: 6499d80e6558dafec6a59286
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1edcd0edf763e5dd977a0e802232c013.svg
      fullname: Patti Jorgensen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patti-j
      type: user
    createdAt: '2023-06-26T20:01:46.000Z'
    data:
      edited: true
      editors:
      - patti-j
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7244487404823303
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1edcd0edf763e5dd977a0e802232c013.svg
          fullname: Patti Jorgensen
          isHf: false
          isPro: false
          name: patti-j
          type: user
        html: '<p>Yes, it''s validate.py in the<br>C:\Python311\Lib\site-packages\huggingface_hub\utils_validators.py
          </p>

          <p>This is the offending snippet:<br>if not REPO_ID_REGEX.match(repo_id):<br>        raise
          HFValidationError(<br>            "Repo id must use alphanumeric chars or
          ''-'', ''_'', ''.'', ''--'' and ''..'' are"<br>            " forbidden,
          ''-'' and ''.'' cannot start or end the name, max length is 96:"<br>            f"
          ''{repo_id}''."<br>        )</p>

          <p>I just did a quick-and-dirty to bypass this passage if repo_id = ''RWModel(''</p>

          <p>Ideally, we should put a bit of code at the top, or better yet in the
          calling script, to exclude README.md files from validation.</p>

          '
        raw: "Yes, it's validate.py in the \nC:\\Python311\\Lib\\site-packages\\huggingface_hub\\\
          utils\\_validators.py \n\nThis is the offending snippet:\nif not REPO_ID_REGEX.match(repo_id):\n\
          \        raise HFValidationError(\n            \"Repo id must use alphanumeric\
          \ chars or '-', '_', '.', '--' and '..' are\"\n            \" forbidden,\
          \ '-' and '.' cannot start or end the name, max length is 96:\"\n      \
          \      f\" '{repo_id}'.\"\n        )\n\nI just did a quick-and-dirty to\
          \ bypass this passage if repo_id = 'RWModel('\n\nIdeally, we should put\
          \ a bit of code at the top, or better yet in the calling script, to exclude\
          \ README.md files from validation."
        updatedAt: '2023-06-26T20:03:50.574Z'
      numEdits: 1
      reactions: []
    id: 6499eeaa23dc99ea547d8e16
    type: comment
  author: patti-j
  content: "Yes, it's validate.py in the \nC:\\Python311\\Lib\\site-packages\\huggingface_hub\\\
    utils\\_validators.py \n\nThis is the offending snippet:\nif not REPO_ID_REGEX.match(repo_id):\n\
    \        raise HFValidationError(\n            \"Repo id must use alphanumeric\
    \ chars or '-', '_', '.', '--' and '..' are\"\n            \" forbidden, '-' and\
    \ '.' cannot start or end the name, max length is 96:\"\n            f\" '{repo_id}'.\"\
    \n        )\n\nI just did a quick-and-dirty to bypass this passage if repo_id\
    \ = 'RWModel('\n\nIdeally, we should put a bit of code at the top, or better yet\
    \ in the calling script, to exclude README.md files from validation."
  created_at: 2023-06-26 19:01:46+00:00
  edited: true
  hidden: false
  id: 6499eeaa23dc99ea547d8e16
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/1edcd0edf763e5dd977a0e802232c013.svg
      fullname: Patti Jorgensen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patti-j
      type: user
    createdAt: '2023-06-27T12:05:48.000Z'
    data:
      from: Repo ID HFValidationError in tokenizer_config file
      to: Repo ID HFValidationError
    id: 649ad09c29269784cce97501
    type: title-change
  author: patti-j
  created_at: 2023-06-27 11:05:48+00:00
  id: 649ad09c29269784cce97501
  new_title: Repo ID HFValidationError
  old_title: Repo ID HFValidationError in tokenizer_config file
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/1edcd0edf763e5dd977a0e802232c013.svg
      fullname: Patti Jorgensen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patti-j
      type: user
    createdAt: '2023-06-27T12:06:50.000Z'
    data:
      from: Repo ID HFValidationError
      to: Repo ID HFValidationError for RWModel(
    id: 649ad0da3f1045a93f658ef8
    type: title-change
  author: patti-j
  created_at: 2023-06-27 11:06:50+00:00
  id: 649ad0da3f1045a93f658ef8
  new_title: Repo ID HFValidationError for RWModel(
  old_title: Repo ID HFValidationError
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19af38dc05560dbeae7b38ab43e4a01e.svg
      fullname: Karthik Bala
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Karthik1611
      type: user
    createdAt: '2023-06-28T09:02:57.000Z'
    data:
      edited: false
      editors:
      - Karthik1611
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8990656137466431
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19af38dc05560dbeae7b38ab43e4a01e.svg
          fullname: Karthik Bala
          isHf: false
          isPro: false
          name: Karthik1611
          type: user
        html: '<p>I got the same error and what worked for me was this. Instead of
          passing in the model variable add the model path in tokenizer.</p>

          <p>tokenizer = AutoTokenizer.from_pretrained("tiiuae/falcon-7b-instruct")</p>

          '
        raw: 'I got the same error and what worked for me was this. Instead of passing
          in the model variable add the model path in tokenizer.


          tokenizer = AutoTokenizer.from_pretrained("tiiuae/falcon-7b-instruct")'
        updatedAt: '2023-06-28T09:02:57.041Z'
      numEdits: 0
      reactions: []
    id: 649bf74155a3fb0d7da37390
    type: comment
  author: Karthik1611
  content: 'I got the same error and what worked for me was this. Instead of passing
    in the model variable add the model path in tokenizer.


    tokenizer = AutoTokenizer.from_pretrained("tiiuae/falcon-7b-instruct")'
  created_at: 2023-06-28 08:02:57+00:00
  edited: false
  hidden: false
  id: 649bf74155a3fb0d7da37390
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/o8Ulf7Tan062ifN8nXZIN.png?w=200&h=200&f=face
      fullname: jimbo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cr00
      type: user
    createdAt: '2023-06-30T03:17:15.000Z'
    data:
      edited: false
      editors:
      - cr00
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6757928133010864
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/o8Ulf7Tan062ifN8nXZIN.png?w=200&h=200&f=face
          fullname: jimbo
          isHf: false
          isPro: false
          name: cr00
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Karthik1611&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Karthik1611\"\
          >@<span class=\"underline\">Karthik1611</span></a></span>\n\n\t</span></span>\
          \ what did you do for this line: model=AutoModelForCausalLM.from_pretrained(model,\
          \ trust_remote_code=True)</p>\n"
        raw: '@Karthik1611 what did you do for this line: model=AutoModelForCausalLM.from_pretrained(model,
          trust_remote_code=True)

          '
        updatedAt: '2023-06-30T03:17:15.848Z'
      numEdits: 0
      reactions: []
    id: 649e493be0854d2c5dffaf56
    type: comment
  author: cr00
  content: '@Karthik1611 what did you do for this line: model=AutoModelForCausalLM.from_pretrained(model,
    trust_remote_code=True)

    '
  created_at: 2023-06-30 02:17:15+00:00
  edited: false
  hidden: false
  id: 649e493be0854d2c5dffaf56
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19af38dc05560dbeae7b38ab43e4a01e.svg
      fullname: Karthik Bala
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Karthik1611
      type: user
    createdAt: '2023-06-30T09:01:10.000Z'
    data:
      edited: false
      editors:
      - Karthik1611
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8436574339866638
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19af38dc05560dbeae7b38ab43e4a01e.svg
          fullname: Karthik Bala
          isHf: false
          isPro: false
          name: Karthik1611
          type: user
        html: '<p>Same as tokenizer, I passed the model path directly instead of the
          model variable.</p>

          '
        raw: Same as tokenizer, I passed the model path directly instead of the model
          variable.
        updatedAt: '2023-06-30T09:01:10.582Z'
      numEdits: 0
      reactions: []
    id: 649e99d6e685e40238b4191d
    type: comment
  author: Karthik1611
  content: Same as tokenizer, I passed the model path directly instead of the model
    variable.
  created_at: 2023-06-30 08:01:10+00:00
  edited: false
  hidden: false
  id: 649e99d6e685e40238b4191d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 35
repo_id: tiiuae/falcon-7b-instruct
repo_type: model
status: open
target_branch: null
title: Repo ID HFValidationError for RWModel(
