!!python/object:huggingface_hub.community.DiscussionWithDetails
author: its-eric-liu
conflicting_files: null
created_at: 2023-09-08 20:08:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6092f7205f7ae77c35e3a7143f4ff726.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: its-eric-liu
      type: user
    createdAt: '2023-09-08T21:08:54.000Z'
    data:
      edited: false
      editors:
      - its-eric-liu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.717873752117157
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6092f7205f7ae77c35e3a7143f4ff726.svg
          fullname: Liu
          isHf: false
          isPro: false
          name: its-eric-liu
          type: user
        html: '<p>Looking for information on the hardware requirement to run falcon
          models:  7B, 40B, 180B.</p>

          '
        raw: "Looking for information on the hardware requirement to run falcon models:\
          \  7B, 40B, 180B.\r\n\r\n"
        updatedAt: '2023-09-08T21:08:54.934Z'
      numEdits: 0
      reactions: []
    id: 64fb8d66304b8cb412bfb6d5
    type: comment
  author: its-eric-liu
  content: "Looking for information on the hardware requirement to run falcon models:\
    \  7B, 40B, 180B.\r\n\r\n"
  created_at: 2023-09-08 20:08:54+00:00
  edited: false
  hidden: false
  id: 64fb8d66304b8cb412bfb6d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6502a4bd3767e3952ce21a33/FUcLRWvdY4D2em7wEVGz5.jpeg?w=200&h=200&f=face
      fullname: caldwell
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: myron1
      type: user
    createdAt: '2023-09-15T13:44:45.000Z'
    data:
      edited: false
      editors:
      - myron1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.33811527490615845
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6502a4bd3767e3952ce21a33/FUcLRWvdY4D2em7wEVGz5.jpeg?w=200&h=200&f=face
          fullname: caldwell
          isHf: false
          isPro: false
          name: myron1
          type: user
        html: '<p>Hello</p>

          '
        raw: 'Hello

          '
        updatedAt: '2023-09-15T13:44:45.284Z'
      numEdits: 0
      reactions: []
    id: 65045fcd20543350f712301b
    type: comment
  author: myron1
  content: 'Hello

    '
  created_at: 2023-09-15 12:44:45+00:00
  edited: false
  hidden: false
  id: 65045fcd20543350f712301b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2742dd80992b240cba9172a74612a485.svg
      fullname: Matt Eaton
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fatnypantzer
      type: user
    createdAt: '2023-11-11T12:41:00.000Z'
    data:
      edited: false
      editors:
      - fatnypantzer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9720609188079834
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2742dd80992b240cba9172a74612a485.svg
          fullname: Matt Eaton
          isHf: false
          isPro: false
          name: fatnypantzer
          type: user
        html: '<p>7b-instruct I''ve trained with 9-36gb vram, currently trying 7b.</p>

          <p>40b is ~96gb vram, from what i''ve read there was someone who had trained
          40b-instruct using something different to Lora with 48gb vRam, however,
          even then there seems to be more involved with the GPU configuration.</p>

          <p>if anyone has more concrete details on the hardware requirements.</p>

          <p>I''ve come across quite a few links that i''ll post when i find them
          again.</p>

          <p>Resources:<br><a rel="nofollow" href="https://www.reddit.com/r/LocalLLaMA/comments/13wutj4/getting_falcon_40b_to_work/">https://www.reddit.com/r/LocalLLaMA/comments/13wutj4/getting_falcon_40b_to_work/</a><br><a
          href="https://huggingface.co/TheBloke/falcon-40b-instruct-GPTQ/discussions">https://huggingface.co/TheBloke/falcon-40b-instruct-GPTQ/discussions</a></p>

          '
        raw: "7b-instruct I've trained with 9-36gb vram, currently trying 7b.\n\n\
          40b is ~96gb vram, from what i've read there was someone who had trained\
          \ 40b-instruct using something different to Lora with 48gb vRam, however,\
          \ even then there seems to be more involved with the GPU configuration.\n\
          \nif anyone has more concrete details on the hardware requirements.\n\n\
          I've come across quite a few links that i'll post when i find them again.\n\
          \nResources: \nhttps://www.reddit.com/r/LocalLLaMA/comments/13wutj4/getting_falcon_40b_to_work/\n\
          https://huggingface.co/TheBloke/falcon-40b-instruct-GPTQ/discussions"
        updatedAt: '2023-11-11T12:41:00.841Z'
      numEdits: 0
      reactions: []
    id: 654f765c5491c57ee9a513ae
    type: comment
  author: fatnypantzer
  content: "7b-instruct I've trained with 9-36gb vram, currently trying 7b.\n\n40b\
    \ is ~96gb vram, from what i've read there was someone who had trained 40b-instruct\
    \ using something different to Lora with 48gb vRam, however, even then there seems\
    \ to be more involved with the GPU configuration.\n\nif anyone has more concrete\
    \ details on the hardware requirements.\n\nI've come across quite a few links\
    \ that i'll post when i find them again.\n\nResources: \nhttps://www.reddit.com/r/LocalLLaMA/comments/13wutj4/getting_falcon_40b_to_work/\n\
    https://huggingface.co/TheBloke/falcon-40b-instruct-GPTQ/discussions"
  created_at: 2023-11-11 12:41:00+00:00
  edited: false
  hidden: false
  id: 654f765c5491c57ee9a513ae
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 83
repo_id: tiiuae/falcon-7b-instruct
repo_type: model
status: open
target_branch: null
title: 'Hardware requirements on falcon models: 7B, 40B, 180B'
