!!python/object:huggingface_hub.community.DiscussionWithDetails
author: DanCher
conflicting_files: null
created_at: 2023-07-31 13:02:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6b96beed80dc883c732e10c2be7accda.svg
      fullname: Dan Cherneavsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DanCher
      type: user
    createdAt: '2023-07-31T14:02:09.000Z'
    data:
      edited: false
      editors:
      - DanCher
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6245349645614624
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6b96beed80dc883c732e10c2be7accda.svg
          fullname: Dan Cherneavsky
          isHf: false
          isPro: false
          name: DanCher
          type: user
        html: "<p>Hi!</p>\n<p>I'm following an example from here: <a rel=\"nofollow\"\
          \ href=\"https://ashukumar27.medium.com/the-agents-of-ai-1402548e9b8c\"\
          >https://ashukumar27.medium.com/the-agents-of-ai-1402548e9b8c</a><br>(similar\
          \ to stuff I've seen in other places as well, including the official Langchain\
          \ documentation)</p>\n<p>Here's my code:</p>\n<pre><code>import transformers\n\
          from langchain.agents import create_csv_agent\nfrom langchain.llms import\
          \ HuggingFacePipeline\n\nmodel_local_path = \"falcon-7b-instruct\"\n\ntokenizer\
          \ = transformers.AutoTokenizer.from_pretrained(model_local_path)\n\npipeline\
          \ = transformers.pipeline(\n    \"text-generation\",\n    model=model_local_path,\n\
          \    tokenizer=tokenizer,\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n\
          \    device_map=\"auto\",\n    max_new_tokens=500\n)\n\nlocal_llm = HuggingFacePipeline(pipeline=pipeline)\n\
          \nagent = create_csv_agent(\n    local_llm,\n    \"/path/to/train.csv\"\
          ,\n    verbose=True,\n    # agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n\
          )\n\nres = agent.run(\"how many rows are there?\")\nprint(res)\n</code></pre>\n\
          <p>Instead of getting something similar to what can be seen in the example,\
          \ I'm getting this:</p>\n<p>Loading checkpoint shards: 100%|\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:08&lt;00:00, \
          \ 4.22s/it]<br>The model 'RWForCausalLM' is not supported for text-generation.\
          \ Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder',\
          \ 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM',\
          \ 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM',\
          \ 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel',\
          \ 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM',\
          \ 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM',\
          \ 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM',\
          \ 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM',\
          \ 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel',\
          \ 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM',\
          \ 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM',\
          \ 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM',\
          \ 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel',\
          \ 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM',\
          \ 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel',\
          \ 'XmodForCausalLM'].</p>\n<blockquote>\n<p>Entering new AgentExecutor chain...<br>.../venv/lib/python3.9/site-packages/transformers/generation/utils.py:1259:\
          \ UserWarning: You have modified the pretrained model configuration to control\
          \ generation. This is a deprecated strategy to control generation and will\
          \ be removed soon, in a future version. Please use a generation configuration\
          \ file (see <a href=\"https://huggingface.co/docs/transformers/main_classes/text_generation\"\
          >https://huggingface.co/docs/transformers/main_classes/text_generation</a>)<br>\
          \  warnings.warn(<br>Setting <code>pad_token_id</code> to <code>eos_token_id</code>:11\
          \ for open-end generation.<br>Thought: you should always think about what\
          \ to do<br>Action: the action to take, should be one of [python_repl_ast]<br>Action\
          \ Input: the input to the action<br>Observation: the action to take, should\
          \ be one of [python_repl_ast] is not a valid tool, try another one.<br>Thought:Setting\
          \ <code>pad_token_id</code> to <code>eos_token_id</code>:11 for open-end\
          \ generation.<br> I now know the final answer<br>Final Answer: the final\
          \ answer to the original input question</p>\n</blockquote>\n<p>The number\
          \ of rows in the dataframe is <code>df.count()</code>. You can use this\
          \ to get the number of rows in the dataframe.</p>\n<blockquote>\n<p>Finished\
          \ chain.<br>the final answer to the original input question</p>\n</blockquote>\n\
          <p>The number of rows in the dataframe is <code>df.count()</code>. You can\
          \ use this to get the number of rows in the dataframe.</p>\n<p>Process finished\
          \ with exit code 0</p>\n<p>I have no idea why this is behaving like this.\
          \ Any help would be appreciated! thanks.</p>\n"
        raw: "Hi!\r\n\r\nI'm following an example from here: https://ashukumar27.medium.com/the-agents-of-ai-1402548e9b8c\r\
          \n(similar to stuff I've seen in other places as well, including the official\
          \ Langchain documentation)\r\n\r\n\r\nHere's my code:\r\n\r\n\r\n    import\
          \ transformers\r\n    from langchain.agents import create_csv_agent\r\n\
          \    from langchain.llms import HuggingFacePipeline\r\n\r\n    model_local_path\
          \ = \"falcon-7b-instruct\"\r\n\r\n    tokenizer = transformers.AutoTokenizer.from_pretrained(model_local_path)\r\
          \n\r\n    pipeline = transformers.pipeline(\r\n        \"text-generation\"\
          ,\r\n        model=model_local_path,\r\n        tokenizer=tokenizer,\r\n\
          \        torch_dtype=torch.bfloat16,\r\n        trust_remote_code=True,\r\
          \n        device_map=\"auto\",\r\n        max_new_tokens=500\r\n    )\r\n\
          \r\n    local_llm = HuggingFacePipeline(pipeline=pipeline)\r\n\r\n    agent\
          \ = create_csv_agent(\r\n        local_llm,\r\n        \"/path/to/train.csv\"\
          ,\r\n        verbose=True,\r\n        # agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\r\
          \n    )\r\n\r\n    res = agent.run(\"how many rows are there?\")\r\n   \
          \ print(res)\r\n\r\n\r\nInstead of getting something similar to what can\
          \ be seen in the example, I'm getting this:\r\n\r\nLoading checkpoint shards:\
          \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2\
          \ [00:08<00:00,  4.22s/it]\r\nThe model 'RWForCausalLM' is not supported\
          \ for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel',\
          \ 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM',\
          \ 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM',\
          \ 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM',\
          \ 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM',\
          \ 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM',\
          \ 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM',\
          \ 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM',\
          \ 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM',\
          \ 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM',\
          \ 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead',\
          \ 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM',\
          \ 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM',\
          \ 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel',\
          \ 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM',\
          \ 'XLNetLMHeadModel', 'XmodForCausalLM'].\r\n\r\n\r\n> Entering new AgentExecutor\
          \ chain...\r\n.../venv/lib/python3.9/site-packages/transformers/generation/utils.py:1259:\
          \ UserWarning: You have modified the pretrained model configuration to control\
          \ generation. This is a deprecated strategy to control generation and will\
          \ be removed soon, in a future version. Please use a generation configuration\
          \ file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\r\
          \n  warnings.warn(\r\nSetting `pad_token_id` to `eos_token_id`:11 for open-end\
          \ generation.\r\nThought: you should always think about what to do\r\nAction:\
          \ the action to take, should be one of [python_repl_ast]\r\nAction Input:\
          \ the input to the action\r\nObservation: the action to take, should be\
          \ one of [python_repl_ast] is not a valid tool, try another one.\r\nThought:Setting\
          \ `pad_token_id` to `eos_token_id`:11 for open-end generation.\r\n I now\
          \ know the final answer\r\nFinal Answer: the final answer to the original\
          \ input question\r\n\r\n\r\nThe number of rows in the dataframe is `df.count()`.\
          \ You can use this to get the number of rows in the dataframe.\r\n\r\n>\
          \ Finished chain.\r\nthe final answer to the original input question\r\n\
          \r\n\r\nThe number of rows in the dataframe is `df.count()`. You can use\
          \ this to get the number of rows in the dataframe.\r\n\r\nProcess finished\
          \ with exit code 0\r\n\r\n\r\nI have no idea why this is behaving like this.\
          \ Any help would be appreciated! thanks.\r\n"
        updatedAt: '2023-07-31T14:02:09.019Z'
      numEdits: 0
      reactions: []
    id: 64c7bee10d3d1b209dff5cca
    type: comment
  author: DanCher
  content: "Hi!\r\n\r\nI'm following an example from here: https://ashukumar27.medium.com/the-agents-of-ai-1402548e9b8c\r\
    \n(similar to stuff I've seen in other places as well, including the official\
    \ Langchain documentation)\r\n\r\n\r\nHere's my code:\r\n\r\n\r\n    import transformers\r\
    \n    from langchain.agents import create_csv_agent\r\n    from langchain.llms\
    \ import HuggingFacePipeline\r\n\r\n    model_local_path = \"falcon-7b-instruct\"\
    \r\n\r\n    tokenizer = transformers.AutoTokenizer.from_pretrained(model_local_path)\r\
    \n\r\n    pipeline = transformers.pipeline(\r\n        \"text-generation\",\r\n\
    \        model=model_local_path,\r\n        tokenizer=tokenizer,\r\n        torch_dtype=torch.bfloat16,\r\
    \n        trust_remote_code=True,\r\n        device_map=\"auto\",\r\n        max_new_tokens=500\r\
    \n    )\r\n\r\n    local_llm = HuggingFacePipeline(pipeline=pipeline)\r\n\r\n\
    \    agent = create_csv_agent(\r\n        local_llm,\r\n        \"/path/to/train.csv\"\
    ,\r\n        verbose=True,\r\n        # agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\r\
    \n    )\r\n\r\n    res = agent.run(\"how many rows are there?\")\r\n    print(res)\r\
    \n\r\n\r\nInstead of getting something similar to what can be seen in the example,\
    \ I'm getting this:\r\n\r\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:08<00:00,  4.22s/it]\r\nThe model\
    \ 'RWForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM',\
    \ 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM',\
    \ 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM',\
    \ 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM',\
    \ 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM',\
    \ 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM',\
    \ 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM',\
    \ 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM',\
    \ 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel',\
    \ 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM',\
    \ 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM',\
    \ 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM',\
    \ 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM',\
    \ 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM',\
    \ 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\r\n\r\n\r\
    \n> Entering new AgentExecutor chain...\r\n.../venv/lib/python3.9/site-packages/transformers/generation/utils.py:1259:\
    \ UserWarning: You have modified the pretrained model configuration to control\
    \ generation. This is a deprecated strategy to control generation and will be\
    \ removed soon, in a future version. Please use a generation configuration file\
    \ (see https://huggingface.co/docs/transformers/main_classes/text_generation)\r\
    \n  warnings.warn(\r\nSetting `pad_token_id` to `eos_token_id`:11 for open-end\
    \ generation.\r\nThought: you should always think about what to do\r\nAction:\
    \ the action to take, should be one of [python_repl_ast]\r\nAction Input: the\
    \ input to the action\r\nObservation: the action to take, should be one of [python_repl_ast]\
    \ is not a valid tool, try another one.\r\nThought:Setting `pad_token_id` to `eos_token_id`:11\
    \ for open-end generation.\r\n I now know the final answer\r\nFinal Answer: the\
    \ final answer to the original input question\r\n\r\n\r\nThe number of rows in\
    \ the dataframe is `df.count()`. You can use this to get the number of rows in\
    \ the dataframe.\r\n\r\n> Finished chain.\r\nthe final answer to the original\
    \ input question\r\n\r\n\r\nThe number of rows in the dataframe is `df.count()`.\
    \ You can use this to get the number of rows in the dataframe.\r\n\r\nProcess\
    \ finished with exit code 0\r\n\r\n\r\nI have no idea why this is behaving like\
    \ this. Any help would be appreciated! thanks.\r\n"
  created_at: 2023-07-31 13:02:09+00:00
  edited: false
  hidden: false
  id: 64c7bee10d3d1b209dff5cca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/909ebb668d83115a73cd3798f9e2dce6.svg
      fullname: Akash Patel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: akashpatel
      type: user
    createdAt: '2023-11-01T06:52:02.000Z'
    data:
      edited: false
      editors:
      - akashpatel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8435930013656616
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/909ebb668d83115a73cd3798f9e2dce6.svg
          fullname: Akash Patel
          isHf: false
          isPro: false
          name: akashpatel
          type: user
        html: '<p>I want to use csv agent with mistral model. Please update if you
          have any relevant information. </p>

          '
        raw: 'I want to use csv agent with mistral model. Please update if you have
          any relevant information. '
        updatedAt: '2023-11-01T06:52:02.681Z'
      numEdits: 0
      reactions: []
    id: 6541f592f096c4b9ea06d2a5
    type: comment
  author: akashpatel
  content: 'I want to use csv agent with mistral model. Please update if you have
    any relevant information. '
  created_at: 2023-11-01 05:52:02+00:00
  edited: false
  hidden: false
  id: 6541f592f096c4b9ea06d2a5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aa7f73922b5519680bc0d3d7b1ff2096.svg
      fullname: matej gazda
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: codermato
      type: user
    createdAt: '2023-11-19T19:20:53.000Z'
    data:
      edited: false
      editors:
      - codermato
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9825796484947205
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aa7f73922b5519680bc0d3d7b1ff2096.svg
          fullname: matej gazda
          isHf: false
          isPro: false
          name: codermato
          type: user
        html: '<p>Have you figured what was wrong? Similar thing is happening to me
          with arxiv and llamav2.</p>

          '
        raw: 'Have you figured what was wrong? Similar thing is happening to me with
          arxiv and llamav2.

          '
        updatedAt: '2023-11-19T19:20:53.704Z'
      numEdits: 0
      reactions: []
    id: 655a60156412aaeed6790f61
    type: comment
  author: codermato
  content: 'Have you figured what was wrong? Similar thing is happening to me with
    arxiv and llamav2.

    '
  created_at: 2023-11-19 19:20:53+00:00
  edited: false
  hidden: false
  id: 655a60156412aaeed6790f61
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 71
repo_id: tiiuae/falcon-7b-instruct
repo_type: model
status: open
target_branch: null
title: integration issue with Langchain csv agent
