!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tolgaakar
conflicting_files: null
created_at: 2023-06-21 13:22:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/ojjz9-jjsyYCaT1tHLFPQ.jpeg?w=200&h=200&f=face
      fullname: Tolga Akar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tolgaakar
      type: user
    createdAt: '2023-06-21T14:22:04.000Z'
    data:
      edited: true
      editors:
      - tolgaakar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9648572206497192
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/ojjz9-jjsyYCaT1tHLFPQ.jpeg?w=200&h=200&f=face
          fullname: Tolga Akar
          isHf: false
          isPro: false
          name: tolgaakar
          type: user
        html: '<p>I have been playing around with both unquantized and 8-bit versions.
          Mostly I use the prompt in the example, but I tried other alternatives as
          well. For some reason, the generated response frequently ends with ''User''
          in a new line, as can also be seen in the example. Does anyone else have
          the same problem? </p>

          <p>QUESTION&lt;&lt;: How can I go from Berlin to Paris?</p>

          <p>ANSWER&lt;&lt;: You can take a train from Berlin to Paris. There are
          several high speed train options, including the DB Eurostar and TGV train,
          that can get you to Paris in a matter of hours or a day depending on which
          option you choose.<br>User  </p>

          '
        raw: "I have been playing around with both unquantized and 8-bit versions.\
          \ Mostly I use the prompt in the example, but I tried other alternatives\
          \ as well. For some reason, the generated response frequently ends with\
          \ 'User' in a new line, as can also be seen in the example. Does anyone\
          \ else have the same problem? \n\nQUESTION<<: How can I go from Berlin to\
          \ Paris?\n\nANSWER<<: You can take a train from Berlin to Paris. There are\
          \ several high speed train options, including the DB Eurostar and TGV train,\
          \ that can get you to Paris in a matter of hours or a day depending on which\
          \ option you choose.\nUser  \n"
        updatedAt: '2023-06-21T14:22:53.333Z'
      numEdits: 3
      reactions: []
    id: 6493078c533303bd3fc6f3c3
    type: comment
  author: tolgaakar
  content: "I have been playing around with both unquantized and 8-bit versions. Mostly\
    \ I use the prompt in the example, but I tried other alternatives as well. For\
    \ some reason, the generated response frequently ends with 'User' in a new line,\
    \ as can also be seen in the example. Does anyone else have the same problem?\
    \ \n\nQUESTION<<: How can I go from Berlin to Paris?\n\nANSWER<<: You can take\
    \ a train from Berlin to Paris. There are several high speed train options, including\
    \ the DB Eurostar and TGV train, that can get you to Paris in a matter of hours\
    \ or a day depending on which option you choose.\nUser  \n"
  created_at: 2023-06-21 13:22:04+00:00
  edited: true
  hidden: false
  id: 6493078c533303bd3fc6f3c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4a2f8644aba2be301db22766f2cca2e2.svg
      fullname: Dolev Artzi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dartzi
      type: user
    createdAt: '2023-06-22T17:02:06.000Z'
    data:
      edited: false
      editors:
      - dartzi
      hidden: false
      identifiedLanguage:
        language: it
        probability: 0.9861560463905334
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4a2f8644aba2be301db22766f2cca2e2.svg
          fullname: Dolev Artzi
          isHf: false
          isPro: false
          name: dartzi
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2023-06-22T17:02:06.602Z'
      numEdits: 0
      reactions: []
    id: 64947e8ed9a2c408f16f7f2e
    type: comment
  author: dartzi
  content: '+1'
  created_at: 2023-06-22 16:02:06+00:00
  edited: false
  hidden: false
  id: 64947e8ed9a2c408f16f7f2e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674225232524-6327bbf0bfc72a1d59ce6377.png?w=200&h=200&f=face
      fullname: Eamonn Tweedy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: etweedy
      type: user
    createdAt: '2023-07-02T16:13:21.000Z'
    data:
      edited: false
      editors:
      - etweedy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9575438499450684
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674225232524-6327bbf0bfc72a1d59ce6377.png?w=200&h=200&f=face
          fullname: Eamonn Tweedy
          isHf: false
          isPro: false
          name: etweedy
          type: user
        html: '<p>I''ve frequently seen the same behavior from this model.  I''ve
          been using this model with langchain, and my solution has been to pass in
          ''User'' or ''\nUser'' as a stop token to my chain''s predict method.  This
          is sort of a hack, which manually removes suffixes in your provided stop
          list from the end of the response before storing it (or adding it to chain
          memory, if using).</p>

          '
        raw: I've frequently seen the same behavior from this model.  I've been using
          this model with langchain, and my solution has been to pass in 'User' or
          '\nUser' as a stop token to my chain's predict method.  This is sort of
          a hack, which manually removes suffixes in your provided stop list from
          the end of the response before storing it (or adding it to chain memory,
          if using).
        updatedAt: '2023-07-02T16:13:21.403Z'
      numEdits: 0
      reactions: []
    id: 64a1a221a1a76b1d01639705
    type: comment
  author: etweedy
  content: I've frequently seen the same behavior from this model.  I've been using
    this model with langchain, and my solution has been to pass in 'User' or '\nUser'
    as a stop token to my chain's predict method.  This is sort of a hack, which manually
    removes suffixes in your provided stop list from the end of the response before
    storing it (or adding it to chain memory, if using).
  created_at: 2023-07-02 15:13:21+00:00
  edited: false
  hidden: false
  id: 64a1a221a1a76b1d01639705
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3c7c3f7ac36c64b5802ec6cc59171317.svg
      fullname: Francesco Dighera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: f-dig
      type: user
    createdAt: '2023-07-13T09:25:41.000Z'
    data:
      edited: false
      editors:
      - f-dig
      hidden: false
      identifiedLanguage:
        language: it
        probability: 0.9861560463905334
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3c7c3f7ac36c64b5802ec6cc59171317.svg
          fullname: Francesco Dighera
          isHf: false
          isPro: false
          name: f-dig
          type: user
        html: '<p>+1</p>

          '
        raw: '+1

          '
        updatedAt: '2023-07-13T09:25:41.196Z'
      numEdits: 0
      reactions: []
    id: 64afc315058a74ea9121bace
    type: comment
  author: f-dig
  content: '+1

    '
  created_at: 2023-07-13 08:25:41+00:00
  edited: false
  hidden: false
  id: 64afc315058a74ea9121bace
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19899f5f39c86456515a21bf4afafe90.svg
      fullname: Sam Edwards
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: samdwar
      type: user
    createdAt: '2023-08-18T13:12:17.000Z'
    data:
      edited: true
      editors:
      - samdwar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9673326015472412
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19899f5f39c86456515a21bf4afafe90.svg
          fullname: Sam Edwards
          isHf: false
          isPro: false
          name: samdwar
          type: user
        html: '<p>Having same issue, it seems the issue is with the Auto inference
          code. It is detecting correct stop token and stopping, but instead of omitting
          that token from output it is including it. I tested number of Falcon models
          and they all have same problem when using with TGI</p>

          '
        raw: Having same issue, it seems the issue is with the Auto inference code.
          It is detecting correct stop token and stopping, but instead of omitting
          that token from output it is including it. I tested number of Falcon models
          and they all have same problem when using with TGI
        updatedAt: '2023-08-18T13:13:29.548Z'
      numEdits: 1
      reactions: []
    id: 64df6e31e437d02ce6bd0ba3
    type: comment
  author: samdwar
  content: Having same issue, it seems the issue is with the Auto inference code.
    It is detecting correct stop token and stopping, but instead of omitting that
    token from output it is including it. I tested number of Falcon models and they
    all have same problem when using with TGI
  created_at: 2023-08-18 12:12:17+00:00
  edited: true
  hidden: false
  id: 64df6e31e437d02ce6bd0ba3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 40
repo_id: tiiuae/falcon-7b-instruct
repo_type: model
status: open
target_branch: null
title: Generated text frequently ends with 'User'
