!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Rick458
conflicting_files: null
created_at: 2023-06-23 04:48:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1644391889370-620292ea9dab2e6e083d031f.jpeg?w=200&h=200&f=face
      fullname: Kunal Bhadra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Rick458
      type: user
    createdAt: '2023-06-23T05:48:32.000Z'
    data:
      edited: false
      editors:
      - Rick458
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.758374035358429
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1644391889370-620292ea9dab2e6e083d031f.jpeg?w=200&h=200&f=face
          fullname: Kunal Bhadra
          isHf: false
          isPro: false
          name: Rick458
          type: user
        html: '<p>In QA, I am trying to make the llm answer questions in one word
          only. However, it gives the answer, and then proceeds to give a 1-2 sentence
          reasoning. Can anyone suggest any methods to only get the one-word answer
          no matter what?<br>My config:<br>pipe = pipeline(<br>    "text-generation",<br>    model=model,<br>    tokenizer=tokenizer,<br>    torch_dtype=torch.bfloat16,<br>    use_auth_token=False,<br>    trust_remote_code=True,<br>    device="cuda:1",<br>    temperature=0.5,<br>    min_length=100,<br>    max_new_tokens=150,<br>    num_return_sequences=1<br>)</p>

          '
        raw: "In QA, I am trying to make the llm answer questions in one word only.\
          \ However, it gives the answer, and then proceeds to give a 1-2 sentence\
          \ reasoning. Can anyone suggest any methods to only get the one-word answer\
          \ no matter what?\r\nMy config:\r\npipe = pipeline(\r\n    \"text-generation\"\
          ,\r\n    model=model,\r\n    tokenizer=tokenizer,\r\n    torch_dtype=torch.bfloat16,\r\
          \n    use_auth_token=False,\r\n    trust_remote_code=True,\r\n    device=\"\
          cuda:1\",\r\n    temperature=0.5,\r\n    min_length=100,\r\n    max_new_tokens=150,\r\
          \n    num_return_sequences=1\r\n)"
        updatedAt: '2023-06-23T05:48:32.086Z'
      numEdits: 0
      reactions: []
    id: 6495323095ca60af5c7f4e25
    type: comment
  author: Rick458
  content: "In QA, I am trying to make the llm answer questions in one word only.\
    \ However, it gives the answer, and then proceeds to give a 1-2 sentence reasoning.\
    \ Can anyone suggest any methods to only get the one-word answer no matter what?\r\
    \nMy config:\r\npipe = pipeline(\r\n    \"text-generation\",\r\n    model=model,\r\
    \n    tokenizer=tokenizer,\r\n    torch_dtype=torch.bfloat16,\r\n    use_auth_token=False,\r\
    \n    trust_remote_code=True,\r\n    device=\"cuda:1\",\r\n    temperature=0.5,\r\
    \n    min_length=100,\r\n    max_new_tokens=150,\r\n    num_return_sequences=1\r\
    \n)"
  created_at: 2023-06-23 04:48:32+00:00
  edited: false
  hidden: false
  id: 6495323095ca60af5c7f4e25
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
      fullname: Michael O'Mahony
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: michaelomahony
      type: user
    createdAt: '2023-06-30T10:18:20.000Z'
    data:
      edited: false
      editors:
      - michaelomahony
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4842902719974518
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
          fullname: Michael O'Mahony
          isHf: false
          isPro: false
          name: michaelomahony
          type: user
        html: '<p>Set max_new_tokens = 1</p>

          '
        raw: Set max_new_tokens = 1
        updatedAt: '2023-06-30T10:18:20.331Z'
      numEdits: 0
      reactions: []
    id: 649eabecf9134a06ed26ba78
    type: comment
  author: michaelomahony
  content: Set max_new_tokens = 1
  created_at: 2023-06-30 09:18:20+00:00
  edited: false
  hidden: false
  id: 649eabecf9134a06ed26ba78
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 43
repo_id: tiiuae/falcon-7b-instruct
repo_type: model
status: open
target_branch: null
title: Output formatting not enforceable
