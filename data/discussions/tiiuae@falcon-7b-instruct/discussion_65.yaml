!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yyjhao
conflicting_files: null
created_at: 2023-07-17 20:05:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b7edbfd71c5d31c5e1ad476ffcc6d82f.svg
      fullname: Yujian Yao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yyjhao
      type: user
    createdAt: '2023-07-17T21:05:06.000Z'
    data:
      edited: false
      editors:
      - yyjhao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9273784160614014
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b7edbfd71c5d31c5e1ad476ffcc6d82f.svg
          fullname: Yujian Yao
          isHf: false
          isPro: false
          name: yyjhao
          type: user
        html: '<p>Sorry if this is a noob question:</p>

          <p>I was able to drag in the mlpackage folder into my Xcode project and
          have it generate a class. I then do</p>

          <pre><code>let model = try! falcon_7b_64_float32()

          </code></pre>

          <p>and I noticed that the model has a ''prediction'' function, but that
          takes in a <code>falcon_7b_64_float32Input</code> type. It looks like the
          return type of that function is another special type as well. How do I convert
          from a string to input and from the output to another string text?</p>

          '
        raw: "Sorry if this is a noob question:\r\n\r\nI was able to drag in the mlpackage\
          \ folder into my Xcode project and have it generate a class. I then do\r\
          \n\r\n```\r\nlet model = try! falcon_7b_64_float32()\r\n```\r\n\r\nand I\
          \ noticed that the model has a 'prediction' function, but that takes in\
          \ a `falcon_7b_64_float32Input` type. It looks like the return type of that\
          \ function is another special type as well. How do I convert from a string\
          \ to input and from the output to another string text?"
        updatedAt: '2023-07-17T21:05:06.553Z'
      numEdits: 0
      reactions: []
    id: 64b5ad02b84198afd5d32f67
    type: comment
  author: yyjhao
  content: "Sorry if this is a noob question:\r\n\r\nI was able to drag in the mlpackage\
    \ folder into my Xcode project and have it generate a class. I then do\r\n\r\n\
    ```\r\nlet model = try! falcon_7b_64_float32()\r\n```\r\n\r\nand I noticed that\
    \ the model has a 'prediction' function, but that takes in a `falcon_7b_64_float32Input`\
    \ type. It looks like the return type of that function is another special type\
    \ as well. How do I convert from a string to input and from the output to another\
    \ string text?"
  created_at: 2023-07-17 20:05:06+00:00
  edited: false
  hidden: false
  id: 64b5ad02b84198afd5d32f67
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5fdf0e1f3adb479cf5aa796c9ed772b4.svg
      fullname: William Martin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: anomalus
      type: user
    createdAt: '2023-07-18T20:38:14.000Z'
    data:
      edited: false
      editors:
      - anomalus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8105202317237854
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5fdf0e1f3adb479cf5aa796c9ed772b4.svg
          fullname: William Martin
          isHf: false
          isPro: false
          name: anomalus
          type: user
        html: '<p>I''m curious as well! It''d be great to have the code from the <a
          href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/147_falcon/falcon-7b.mp4">demo
          shown in the video</a>, so we can tinker.</p>

          <p>I may be overthinking this, but I suspect it involves passing the String
          to a <a rel="nofollow" href="https://developer.apple.com/documentation/naturallanguage/tokenizing_natural_language_text">tokenizer</a>
          built for this particular model, similar to these <a rel="nofollow" href="https://github.com/huggingface/swift-coreml-transformers/">Swift
          CoreML transformers</a>.</p>

          '
        raw: 'I''m curious as well! It''d be great to have the code from the [demo
          shown in the video](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/147_falcon/falcon-7b.mp4),
          so we can tinker.


          I may be overthinking this, but I suspect it involves passing the String
          to a [tokenizer](https://developer.apple.com/documentation/naturallanguage/tokenizing_natural_language_text)
          built for this particular model, similar to these [Swift CoreML transformers](https://github.com/huggingface/swift-coreml-transformers/).'
        updatedAt: '2023-07-18T20:38:14.841Z'
      numEdits: 0
      reactions: []
    id: 64b6f8361a4d97b5d7ec0abd
    type: comment
  author: anomalus
  content: 'I''m curious as well! It''d be great to have the code from the [demo shown
    in the video](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/147_falcon/falcon-7b.mp4),
    so we can tinker.


    I may be overthinking this, but I suspect it involves passing the String to a
    [tokenizer](https://developer.apple.com/documentation/naturallanguage/tokenizing_natural_language_text)
    built for this particular model, similar to these [Swift CoreML transformers](https://github.com/huggingface/swift-coreml-transformers/).'
  created_at: 2023-07-18 19:38:14+00:00
  edited: false
  hidden: false
  id: 64b6f8361a4d97b5d7ec0abd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
      fullname: Pedro Cuenca
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pcuenq
      type: user
    createdAt: '2023-07-19T07:10:32.000Z'
    data:
      edited: false
      editors:
      - pcuenq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8490346670150757
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg?w=200&h=200&f=face
          fullname: Pedro Cuenca
          isHf: true
          isPro: false
          name: pcuenq
          type: user
        html: "<p>You are right <span data-props=\"{&quot;user&quot;:&quot;anomalus&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/anomalus\"\
          >@<span class=\"underline\">anomalus</span></a></span>\n\n\t</span></span>:\
          \ you need to tokenize the text, and then process the outputs to create\
          \ the output sequence. The model only returns information about the probability\
          \ of the next token in the sequence, so you need to call it multiple times\
          \ to get the output.</p>\n<p>We intend to publish everything soon.</p>\n"
        raw: 'You are right @anomalus: you need to tokenize the text, and then process
          the outputs to create the output sequence. The model only returns information
          about the probability of the next token in the sequence, so you need to
          call it multiple times to get the output.


          We intend to publish everything soon.'
        updatedAt: '2023-07-19T07:10:32.580Z'
      numEdits: 0
      reactions: []
    id: 64b78c6862b2914fd56b9421
    type: comment
  author: pcuenq
  content: 'You are right @anomalus: you need to tokenize the text, and then process
    the outputs to create the output sequence. The model only returns information
    about the probability of the next token in the sequence, so you need to call it
    multiple times to get the output.


    We intend to publish everything soon.'
  created_at: 2023-07-19 06:10:32+00:00
  edited: false
  hidden: false
  id: 64b78c6862b2914fd56b9421
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5fdf0e1f3adb479cf5aa796c9ed772b4.svg
      fullname: William Martin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: anomalus
      type: user
    createdAt: '2023-07-19T19:10:34.000Z'
    data:
      edited: false
      editors:
      - anomalus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5395971536636353
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5fdf0e1f3adb479cf5aa796c9ed772b4.svg
          fullname: William Martin
          isHf: false
          isPro: false
          name: anomalus
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;pcuenq&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/pcuenq\">@<span class=\"\
          underline\">pcuenq</span></a></span>\n\n\t</span></span> Fantastic. Looking\
          \ forward to it!</p>\n"
        raw: '@pcuenq Fantastic. Looking forward to it!'
        updatedAt: '2023-07-19T19:10:34.733Z'
      numEdits: 0
      reactions: []
    id: 64b8352a35c815492d1ac760
    type: comment
  author: anomalus
  content: '@pcuenq Fantastic. Looking forward to it!'
  created_at: 2023-07-19 18:10:34+00:00
  edited: false
  hidden: false
  id: 64b8352a35c815492d1ac760
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d07f7f28c0b324ae75ca30fe6f915a39.svg
      fullname: Jason Fehr
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jayfehr
      type: user
    createdAt: '2023-08-05T20:56:39.000Z'
    data:
      edited: false
      editors:
      - jayfehr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8671686053276062
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d07f7f28c0b324ae75ca30fe6f915a39.svg
          fullname: Jason Fehr
          isHf: false
          isPro: false
          name: jayfehr
          type: user
        html: "<blockquote>\n<p>You are right <span data-props=\"{&quot;user&quot;:&quot;anomalus&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/anomalus\"\
          >@<span class=\"underline\">anomalus</span></a></span>\n\n\t</span></span>:\
          \ you need to tokenize the text, and then process the outputs to create\
          \ the output sequence. The model only returns information about the probability\
          \ of the next token in the sequence, so you need to call it multiple times\
          \ to get the output.</p>\n<p>We intend to publish everything soon.</p>\n\
          </blockquote>\n<p>Would you be able to provide quick sample code to run\
          \ this the mlpackage? </p>\n"
        raw: "> You are right @anomalus: you need to tokenize the text, and then process\
          \ the outputs to create the output sequence. The model only returns information\
          \ about the probability of the next token in the sequence, so you need to\
          \ call it multiple times to get the output.\n> \n> We intend to publish\
          \ everything soon.\n\nWould you be able to provide quick sample code to\
          \ run this the mlpackage? "
        updatedAt: '2023-08-05T20:56:39.829Z'
      numEdits: 0
      reactions: []
    id: 64ceb7876f107411da80e9b3
    type: comment
  author: jayfehr
  content: "> You are right @anomalus: you need to tokenize the text, and then process\
    \ the outputs to create the output sequence. The model only returns information\
    \ about the probability of the next token in the sequence, so you need to call\
    \ it multiple times to get the output.\n> \n> We intend to publish everything\
    \ soon.\n\nWould you be able to provide quick sample code to run this the mlpackage? "
  created_at: 2023-08-05 19:56:39+00:00
  edited: false
  hidden: false
  id: 64ceb7876f107411da80e9b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5fdf0e1f3adb479cf5aa796c9ed772b4.svg
      fullname: William Martin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: anomalus
      type: user
    createdAt: '2023-08-16T12:29:25.000Z'
    data:
      edited: false
      editors:
      - anomalus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.868744432926178
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5fdf0e1f3adb479cf5aa796c9ed772b4.svg
          fullname: William Martin
          isHf: false
          isPro: false
          name: anomalus
          type: user
        html: "<p>Posting this here: <a href=\"https://huggingface.co/blog/swift-coreml-llm\"\
          >https://huggingface.co/blog/swift-coreml-llm</a></p>\n<p>Thanks <span data-props=\"\
          {&quot;user&quot;:&quot;pcuenq&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/pcuenq\">@<span class=\"underline\">pcuenq</span></a></span>\n\
          \n\t</span></span>! The only part I'm curious about is using Falcon 7b with\
          \ Swift Chat is unusably slow. It takes maybe 5 minutes per word. I have\
          \ a Macbook Pro M1 Max with 32GB of RAM, but SwiftChat uses 55GB+ of RAM\
          \ on a simple run. Any advice on how to navigate this?</p>\n"
        raw: 'Posting this here: https://huggingface.co/blog/swift-coreml-llm


          Thanks @pcuenq! The only part I''m curious about is using Falcon 7b with
          Swift Chat is unusably slow. It takes maybe 5 minutes per word. I have a
          Macbook Pro M1 Max with 32GB of RAM, but SwiftChat uses 55GB+ of RAM on
          a simple run. Any advice on how to navigate this?'
        updatedAt: '2023-08-16T12:29:25.402Z'
      numEdits: 0
      reactions: []
    id: 64dcc125109476ce9ac56589
    type: comment
  author: anomalus
  content: 'Posting this here: https://huggingface.co/blog/swift-coreml-llm


    Thanks @pcuenq! The only part I''m curious about is using Falcon 7b with Swift
    Chat is unusably slow. It takes maybe 5 minutes per word. I have a Macbook Pro
    M1 Max with 32GB of RAM, but SwiftChat uses 55GB+ of RAM on a simple run. Any
    advice on how to navigate this?'
  created_at: 2023-08-16 11:29:25+00:00
  edited: false
  hidden: false
  id: 64dcc125109476ce9ac56589
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 65
repo_id: tiiuae/falcon-7b-instruct
repo_type: model
status: open
target_branch: null
title: How to use the CoreML model?
