!!python/object:huggingface_hub.community.DiscussionWithDetails
author: veilsidebr
conflicting_files: null
created_at: 2023-05-28 07:26:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e61484e235e0b27e494331d4ac996a07.svg
      fullname: Sammuel Moretto
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: veilsidebr
      type: user
    createdAt: '2023-05-28T08:26:52.000Z'
    data:
      edited: false
      editors:
      - veilsidebr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e61484e235e0b27e494331d4ac996a07.svg
          fullname: Sammuel Moretto
          isHf: false
          isPro: false
          name: veilsidebr
          type: user
        html: "<p>Hi there! Using the 7b instruct model, i used the code provided\
          \ in model card, saved as main.py and when i run it, i keep receiving this\
          \ error after 3-5 mins processing, any ideas of what may be wrong?</p>\n\
          <p> C:\\Users\\veilsidebr/.cache\\huggingface\\modules\\transformers_modules\\\
          tiiuae\\falcon-7b-instruct\\b6 \u2502<br>\u2502 efaea5d78e4313145bda4d688675414a76fc22\\\
          modelling_RW.py:478 in _convert_to_rw_cache               \u2502<br>\u2502\
          \                                                                      \
          \                            \u2502<br>\u2502    475 \u2502   def _convert_to_rw_cache(\
          \                                                             \u2502<br>\u2502\
          \    476 \u2502   \u2502   past_key_value: Tuple[Tuple[torch.Tensor, torch.Tensor]]\
          \                          \u2502<br>\u2502    477 \u2502   ) -&gt; Tuple[Tuple[torch.Tensor,\
          \ torch.Tensor]]:                                        \u2502<br>\u2502\
          \ \u2771  478 \u2502   \u2502   batch_size, num_heads, head_dim, seq_length\
          \ = past_key_value[0][0].shape          \u2502<br>\u2502    479 \u2502 \
          \  \u2502   batch_size_times_num_heads = batch_size * num_heads        \
          \                       \u2502<br>\u2502    480 \u2502   \u2502   # key:\
          \  [batch_size, num_heads, head_dim, seq_length] -&gt; [batch_size * num_heads\
          \  \u2502<br>\u2502    481 \u2502   \u2502   # value: [batch_size, num_heads,\
          \ seq_length, head_dim] -&gt; [batch_size * num_head  \u2502<br>\u2570\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u256F<br>ValueError: not enough values to unpack (expected 4, got\
          \ 3)<br>PS C:\\Models\\Falcon-7B&gt; </p>\n"
        raw: "Hi there! Using the 7b instruct model, i used the code provided in model\
          \ card, saved as main.py and when i run it, i keep receiving this error\
          \ after 3-5 mins processing, any ideas of what may be wrong?\r\n\r\n C:\\\
          Users\\veilsidebr/.cache\\huggingface\\modules\\transformers_modules\\tiiuae\\\
          falcon-7b-instruct\\b6 \u2502\r\n\u2502 efaea5d78e4313145bda4d688675414a76fc22\\\
          modelling_RW.py:478 in _convert_to_rw_cache               \u2502\r\n\u2502\
          \                                                                      \
          \                            \u2502\r\n\u2502    475 \u2502   def _convert_to_rw_cache(\
          \                                                             \u2502\r\n\
          \u2502    476 \u2502   \u2502   past_key_value: Tuple[Tuple[torch.Tensor,\
          \ torch.Tensor]]                          \u2502\r\n\u2502    477 \u2502\
          \   ) -> Tuple[Tuple[torch.Tensor, torch.Tensor]]:                     \
          \                   \u2502\r\n\u2502 \u2771  478 \u2502   \u2502   batch_size,\
          \ num_heads, head_dim, seq_length = past_key_value[0][0].shape         \
          \ \u2502\r\n\u2502    479 \u2502   \u2502   batch_size_times_num_heads =\
          \ batch_size * num_heads                               \u2502\r\n\u2502\
          \    480 \u2502   \u2502   # key:  [batch_size, num_heads, head_dim, seq_length]\
          \ -> [batch_size * num_heads  \u2502\r\n\u2502    481 \u2502   \u2502  \
          \ # value: [batch_size, num_heads, seq_length, head_dim] -> [batch_size\
          \ * num_head  \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256F\r\nValueError: not enough\
          \ values to unpack (expected 4, got 3)\r\nPS C:\\Models\\Falcon-7B> "
        updatedAt: '2023-05-28T08:26:52.274Z'
      numEdits: 0
      reactions: []
    id: 6473104cd9e9598973c76908
    type: comment
  author: veilsidebr
  content: "Hi there! Using the 7b instruct model, i used the code provided in model\
    \ card, saved as main.py and when i run it, i keep receiving this error after\
    \ 3-5 mins processing, any ideas of what may be wrong?\r\n\r\n C:\\Users\\veilsidebr/.cache\\\
    huggingface\\modules\\transformers_modules\\tiiuae\\falcon-7b-instruct\\b6 \u2502\
    \r\n\u2502 efaea5d78e4313145bda4d688675414a76fc22\\modelling_RW.py:478 in _convert_to_rw_cache\
    \               \u2502\r\n\u2502                                             \
    \                                                     \u2502\r\n\u2502    475\
    \ \u2502   def _convert_to_rw_cache(                                         \
    \                    \u2502\r\n\u2502    476 \u2502   \u2502   past_key_value:\
    \ Tuple[Tuple[torch.Tensor, torch.Tensor]]                          \u2502\r\n\
    \u2502    477 \u2502   ) -> Tuple[Tuple[torch.Tensor, torch.Tensor]]:        \
    \                                \u2502\r\n\u2502 \u2771  478 \u2502   \u2502\
    \   batch_size, num_heads, head_dim, seq_length = past_key_value[0][0].shape \
    \         \u2502\r\n\u2502    479 \u2502   \u2502   batch_size_times_num_heads\
    \ = batch_size * num_heads                               \u2502\r\n\u2502    480\
    \ \u2502   \u2502   # key:  [batch_size, num_heads, head_dim, seq_length] -> [batch_size\
    \ * num_heads  \u2502\r\n\u2502    481 \u2502   \u2502   # value: [batch_size,\
    \ num_heads, seq_length, head_dim] -> [batch_size * num_head  \u2502\r\n\u2570\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256F\r\nValueError: not enough values\
    \ to unpack (expected 4, got 3)\r\nPS C:\\Models\\Falcon-7B> "
  created_at: 2023-05-28 07:26:52+00:00
  edited: false
  hidden: false
  id: 6473104cd9e9598973c76908
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7b178c35f2187eb7b602d755e2c74ad3.svg
      fullname: Tanmey Rawal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: taurasAI
      type: user
    createdAt: '2023-06-28T08:56:58.000Z'
    data:
      edited: false
      editors:
      - taurasAI
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9466067552566528
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7b178c35f2187eb7b602d755e2c74ad3.svg
          fullname: Tanmey Rawal
          isHf: false
          isPro: false
          name: taurasAI
          type: user
        html: '<p>Try upgrading package from transformers to latest version<br>I upgraded
          transformers to 4.30.2 and this issues is resolved<br>P.S torch=2.0.1</p>

          '
        raw: 'Try upgrading package from transformers to latest version

          I upgraded transformers to 4.30.2 and this issues is resolved

          P.S torch=2.0.1'
        updatedAt: '2023-06-28T08:56:58.790Z'
      numEdits: 0
      reactions: []
    id: 649bf5da3178e4123665ed16
    type: comment
  author: taurasAI
  content: 'Try upgrading package from transformers to latest version

    I upgraded transformers to 4.30.2 and this issues is resolved

    P.S torch=2.0.1'
  created_at: 2023-06-28 07:56:58+00:00
  edited: false
  hidden: false
  id: 649bf5da3178e4123665ed16
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: tiiuae/falcon-7b-instruct
repo_type: model
status: open
target_branch: null
title: 'ValueError: not enough values to unpack (expected 4, got 3)'
