!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BigArt
conflicting_files: null
created_at: 2023-06-14 10:31:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/391897020377a3ea48c20d8fc009589d.svg
      fullname: Artemiy Marchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BigArt
      type: user
    createdAt: '2023-06-14T11:31:19.000Z'
    data:
      edited: false
      editors:
      - BigArt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9739727973937988
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/391897020377a3ea48c20d8fc009589d.svg
          fullname: Artemiy Marchenko
          isHf: false
          isPro: false
          name: BigArt
          type: user
        html: '<p>In 40B and 7B model cards it is said that this model is optimised
          for inference. But it is one of the most slow models among 7B ones. May
          be I am doing something wrong, or don''t have required libraries, but the
          use example code is producing very slow results on A100 or RTX8000. Is it
          common problem or am I doing something wrong?</p>

          '
        raw: In 40B and 7B model cards it is said that this model is optimised for
          inference. But it is one of the most slow models among 7B ones. May be I
          am doing something wrong, or don't have required libraries, but the use
          example code is producing very slow results on A100 or RTX8000. Is it common
          problem or am I doing something wrong?
        updatedAt: '2023-06-14T11:31:19.156Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - rustamg
        - ChrisJFarr
    id: 6489a5078de3f9d810b19404
    type: comment
  author: BigArt
  content: In 40B and 7B model cards it is said that this model is optimised for inference.
    But it is one of the most slow models among 7B ones. May be I am doing something
    wrong, or don't have required libraries, but the use example code is producing
    very slow results on A100 or RTX8000. Is it common problem or am I doing something
    wrong?
  created_at: 2023-06-14 10:31:19+00:00
  edited: false
  hidden: false
  id: 6489a5078de3f9d810b19404
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/67ef48f109eb8feac9750886f896e947.svg
      fullname: Paton Wong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patonw
      type: user
    createdAt: '2023-06-14T22:22:58.000Z'
    data:
      edited: false
      editors:
      - patonw
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9395479559898376
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/67ef48f109eb8feac9750886f896e947.svg
          fullname: Paton Wong
          isHf: false
          isPro: false
          name: patonw
          type: user
        html: '<p>Slow for me also, on a RTX3090. Orders of magnitude slower than
          other 7B models I''ve tried.<br>After warming up, other models summarize
          an article in 2 to 10 seconds. Falcon takes about 2 minutes for the same
          article.<br>I double checked that it''s using the GPU and tried running
          a quantized version, but still slow.</p>

          '
        raw: 'Slow for me also, on a RTX3090. Orders of magnitude slower than other
          7B models I''ve tried.

          After warming up, other models summarize an article in 2 to 10 seconds.
          Falcon takes about 2 minutes for the same article.

          I double checked that it''s using the GPU and tried running a quantized
          version, but still slow.'
        updatedAt: '2023-06-14T22:22:58.225Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - rustamg
        - michaelomahony
        - yuchenlin
      - count: 2
        reaction: "\U0001F92F"
        users:
        - pdakin
        - yuchenlin
    id: 648a3dc2314cf5e628cc778a
    type: comment
  author: patonw
  content: 'Slow for me also, on a RTX3090. Orders of magnitude slower than other
    7B models I''ve tried.

    After warming up, other models summarize an article in 2 to 10 seconds. Falcon
    takes about 2 minutes for the same article.

    I double checked that it''s using the GPU and tried running a quantized version,
    but still slow.'
  created_at: 2023-06-14 21:22:58+00:00
  edited: false
  hidden: false
  id: 648a3dc2314cf5e628cc778a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/71d6b53ba2eea94e2bd3f0459c54601d.svg
      fullname: Sven Heyer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sven00
      type: user
    createdAt: '2023-06-16T07:40:17.000Z'
    data:
      edited: false
      editors:
      - Sven00
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.846413791179657
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/71d6b53ba2eea94e2bd3f0459c54601d.svg
          fullname: Sven Heyer
          isHf: false
          isPro: false
          name: Sven00
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;patonw&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/patonw\">@<span class=\"\
          underline\">patonw</span></a></span>\n\n\t</span></span> can you please\
          \ let me know  which prompt/parameter you are using for summarization task?\
          \ i'm struggling with 7 B models to get a more or less stable and factual\
          \ correct summary. thank you</p>\n"
        raw: '@patonw can you please let me know  which prompt/parameter you are using
          for summarization task? i''m struggling with 7 B models to get a more or
          less stable and factual correct summary. thank you'
        updatedAt: '2023-06-16T07:40:17.510Z'
      numEdits: 0
      reactions: []
    id: 648c11e1f11318e0a45067ef
    type: comment
  author: Sven00
  content: '@patonw can you please let me know  which prompt/parameter you are using
    for summarization task? i''m struggling with 7 B models to get a more or less
    stable and factual correct summary. thank you'
  created_at: 2023-06-16 06:40:17+00:00
  edited: false
  hidden: false
  id: 648c11e1f11318e0a45067ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/PwaTO6BJYQ1Yjv6q4R2pL.jpeg?w=200&h=200&f=face
      fullname: Hlib Avietisov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HAvietisov
      type: user
    createdAt: '2023-06-17T11:11:21.000Z'
    data:
      edited: false
      editors:
      - HAvietisov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.935612142086029
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/PwaTO6BJYQ1Yjv6q4R2pL.jpeg?w=200&h=200&f=face
          fullname: Hlib Avietisov
          isHf: false
          isPro: false
          name: HAvietisov
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;patonw&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/patonw\">@<span class=\"\
          underline\">patonw</span></a></span>\n\n\t</span></span> aren't quantized\
          \ models always slow in comparison to models in float16?</p>\n"
        raw: '@patonw aren''t quantized models always slow in comparison to models
          in float16?'
        updatedAt: '2023-06-17T11:11:21.203Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - rustamg
    id: 648d94d9b7dab2d0ac43b205
    type: comment
  author: HAvietisov
  content: '@patonw aren''t quantized models always slow in comparison to models in
    float16?'
  created_at: 2023-06-17 10:11:21+00:00
  edited: false
  hidden: false
  id: 648d94d9b7dab2d0ac43b205
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8deea47badcda32596986c846872533f.svg
      fullname: sam wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: treeguard
      type: user
    createdAt: '2023-06-19T04:17:01.000Z'
    data:
      edited: false
      editors:
      - treeguard
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9985256791114807
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8deea47badcda32596986c846872533f.svg
          fullname: sam wang
          isHf: false
          isPro: false
          name: treeguard
          type: user
        html: '<p>It''s really slow for me also</p>

          '
        raw: It's really slow for me also
        updatedAt: '2023-06-19T04:17:01.119Z'
      numEdits: 0
      reactions: []
    id: 648fd6bd81a3fcd67498d572
    type: comment
  author: treeguard
  content: It's really slow for me also
  created_at: 2023-06-19 03:17:01+00:00
  edited: false
  hidden: false
  id: 648fd6bd81a3fcd67498d572
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/67ef48f109eb8feac9750886f896e947.svg
      fullname: Paton Wong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patonw
      type: user
    createdAt: '2023-06-19T19:09:13.000Z'
    data:
      edited: false
      editors:
      - patonw
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9379518628120422
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/67ef48f109eb8feac9750886f896e947.svg
          fullname: Paton Wong
          isHf: false
          isPro: false
          name: patonw
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Sven00&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Sven00\">@<span class=\"\
          underline\">Sven00</span></a></span>\n\n\t</span></span> I didn't any official\
          \ examples for summarization prompts either, but through trial and error\
          \ I found this works fairly well:  </p>\n<pre><code>INSTRUCTIONS:\nYou are\
          \ a political analyst for a national newspaper.\nOnly refer to the provided\
          \ text and no other sources.\nSummarize 5 key facts from the following text\
          \ as a numbered list.\n\nTEXT:\n###\n{text}\n###\n\nSUMMARY:\n</code></pre>\n\
          <p>However, the model neither numbers items or counts correctly</p>\n<p><span\
          \ data-props=\"{&quot;user&quot;:&quot;HAvietisov&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/HAvietisov\">@<span class=\"\
          underline\">HAvietisov</span></a></span>\n\n\t</span></span> Running quantized\
          \ is slightly faster for this model on my hardware at least, but not by\
          \ much.</p>\n"
        raw: "@Sven00 I didn't any official examples for summarization prompts either,\
          \ but through trial and error I found this works fairly well:  \n```\nINSTRUCTIONS:\n\
          You are a political analyst for a national newspaper.\nOnly refer to the\
          \ provided text and no other sources.\nSummarize 5 key facts from the following\
          \ text as a numbered list.\n\nTEXT:\n###\n{text}\n###\n\nSUMMARY:\n```\n\
          \nHowever, the model neither numbers items or counts correctly\n\n@HAvietisov\
          \ Running quantized is slightly faster for this model on my hardware at\
          \ least, but not by much."
        updatedAt: '2023-06-19T19:09:13.881Z'
      numEdits: 0
      reactions: []
    id: 6490a7d9af458feda9630018
    type: comment
  author: patonw
  content: "@Sven00 I didn't any official examples for summarization prompts either,\
    \ but through trial and error I found this works fairly well:  \n```\nINSTRUCTIONS:\n\
    You are a political analyst for a national newspaper.\nOnly refer to the provided\
    \ text and no other sources.\nSummarize 5 key facts from the following text as\
    \ a numbered list.\n\nTEXT:\n###\n{text}\n###\n\nSUMMARY:\n```\n\nHowever, the\
    \ model neither numbers items or counts correctly\n\n@HAvietisov Running quantized\
    \ is slightly faster for this model on my hardware at least, but not by much."
  created_at: 2023-06-19 18:09:13+00:00
  edited: false
  hidden: false
  id: 6490a7d9af458feda9630018
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/PwaTO6BJYQ1Yjv6q4R2pL.jpeg?w=200&h=200&f=face
      fullname: Hlib Avietisov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HAvietisov
      type: user
    createdAt: '2023-06-19T19:16:09.000Z'
    data:
      edited: true
      editors:
      - HAvietisov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7870623469352722
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/PwaTO6BJYQ1Yjv6q4R2pL.jpeg?w=200&h=200&f=face
          fullname: Hlib Avietisov
          isHf: false
          isPro: false
          name: HAvietisov
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;patonw&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/patonw\">@<span class=\"\
          underline\">patonw</span></a></span>\n\n\t</span></span> what hardware you\
          \ use and what quantization method?<br>I run int8 quantization via bitsandbytes,\
          \ with dequantization to float16 on single rtx 3090</p>\n"
        raw: '@patonw what hardware you use and what quantization method?

          I run int8 quantization via bitsandbytes, with dequantization to float16
          on single rtx 3090'
        updatedAt: '2023-06-19T19:16:23.632Z'
      numEdits: 1
      reactions: []
    id: 6490a979ed034b1864d1d81e
    type: comment
  author: HAvietisov
  content: '@patonw what hardware you use and what quantization method?

    I run int8 quantization via bitsandbytes, with dequantization to float16 on single
    rtx 3090'
  created_at: 2023-06-19 18:16:09+00:00
  edited: true
  hidden: false
  id: 6490a979ed034b1864d1d81e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/56ce9fe9559760f3127c5c32e2bfff46.svg
      fullname: Rustam Galljamov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rustamg
      type: user
    createdAt: '2023-06-21T11:42:36.000Z'
    data:
      edited: true
      editors:
      - rustamg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6928930282592773
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/56ce9fe9559760f3127c5c32e2bfff46.svg
          fullname: Rustam Galljamov
          isHf: false
          isPro: false
          name: rustamg
          type: user
        html: '<p>Changing <code>torch_dtype=torch.bfloat16</code> to <code>torch_dtype=torch.float16</code>
          in the <a href="https://huggingface.co/tiiuae/falcon-7b-instruct#how-to-get-started-with-the-model">Getting
          Started code snippet</a> (removing the "b" before "float") led to a significant
          speedup on a 16GB vRAM NC4as-v3 machine in databricks running the falcon-7b-instruct
          model. Hope this helps others, too.</p>

          '
        raw: Changing ``torch_dtype=torch.bfloat16`` to ``torch_dtype=torch.float16``
          in the [Getting Started code snippet](https://huggingface.co/tiiuae/falcon-7b-instruct#how-to-get-started-with-the-model)
          (removing the "b" before "float") led to a significant speedup on a 16GB
          vRAM NC4as-v3 machine in databricks running the falcon-7b-instruct model.
          Hope this helps others, too.
        updatedAt: '2023-06-21T11:47:34.932Z'
      numEdits: 2
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - vipulad
        - HAvietisov
        - yuchenlin
    id: 6492e22c36fcb188daa52794
    type: comment
  author: rustamg
  content: Changing ``torch_dtype=torch.bfloat16`` to ``torch_dtype=torch.float16``
    in the [Getting Started code snippet](https://huggingface.co/tiiuae/falcon-7b-instruct#how-to-get-started-with-the-model)
    (removing the "b" before "float") led to a significant speedup on a 16GB vRAM
    NC4as-v3 machine in databricks running the falcon-7b-instruct model. Hope this
    helps others, too.
  created_at: 2023-06-21 10:42:36+00:00
  edited: true
  hidden: false
  id: 6492e22c36fcb188daa52794
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
      fullname: Michael O'Mahony
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: michaelomahony
      type: user
    createdAt: '2023-07-10T09:33:24.000Z'
    data:
      edited: false
      editors:
      - michaelomahony
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9692665934562683
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31d4056d85425d918f8c326c4e022dff.svg
          fullname: Michael O'Mahony
          isHf: false
          isPro: false
          name: michaelomahony
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;rustamg&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/rustamg\">@<span class=\"\
          underline\">rustamg</span></a></span>\n\n\t</span></span> thanks for sharing!\
          \ Any idea how much of a drop in accuracy this could cause?</p>\n"
        raw: '@rustamg thanks for sharing! Any idea how much of a drop in accuracy
          this could cause?

          '
        updatedAt: '2023-07-10T09:33:24.259Z'
      numEdits: 0
      reactions: []
    id: 64abd0648cac7b871a893704
    type: comment
  author: michaelomahony
  content: '@rustamg thanks for sharing! Any idea how much of a drop in accuracy this
    could cause?

    '
  created_at: 2023-07-10 08:33:24+00:00
  edited: false
  hidden: false
  id: 64abd0648cac7b871a893704
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/796f5e27b219f72f174c2ad34a7fb774.svg
      fullname: Jenny loves coding
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jenny2020
      type: user
    createdAt: '2023-09-01T05:40:37.000Z'
    data:
      edited: true
      editors:
      - Jenny2020
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9066556692123413
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/796f5e27b219f72f174c2ad34a7fb774.svg
          fullname: Jenny loves coding
          isHf: false
          isPro: false
          name: Jenny2020
          type: user
        html: '<p>usually How long it takes for warmup steps finish for fully finetune?
          </p>

          '
        raw: 'usually How long it takes for warmup steps finish for fully finetune? '
        updatedAt: '2023-09-01T05:41:35.552Z'
      numEdits: 1
      reactions: []
    id: 64f17955d0546fc2416720ef
    type: comment
  author: Jenny2020
  content: 'usually How long it takes for warmup steps finish for fully finetune? '
  created_at: 2023-09-01 04:40:37+00:00
  edited: true
  hidden: false
  id: 64f17955d0546fc2416720ef
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 33
repo_id: tiiuae/falcon-7b-instruct
repo_type: model
status: open
target_branch: null
title: Slow inference
