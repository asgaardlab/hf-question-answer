!!python/object:huggingface_hub.community.DiscussionWithDetails
author: HR1777
conflicting_files: null
created_at: 2023-06-23 07:51:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
      fullname: H R
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HR1777
      type: user
    createdAt: '2023-06-23T08:51:51.000Z'
    data:
      edited: false
      editors:
      - HR1777
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9517186880111694
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
          fullname: H R
          isHf: false
          isPro: false
          name: HR1777
          type: user
        html: '<p>I would like to use this model using GPT4All and id like to know
          does GPT4All (windows version) already support mpt-30b-chat? Do you have
          any other alternative to run this model on Windows OS? I would like to use
          this same model not the quantized versions (GGML) . What is your suggestion
          for running it on Windows?</p>

          '
        raw: I would like to use this model using GPT4All and id like to know does
          GPT4All (windows version) already support mpt-30b-chat? Do you have any
          other alternative to run this model on Windows OS? I would like to use this
          same model not the quantized versions (GGML) . What is your suggestion for
          running it on Windows?
        updatedAt: '2023-06-23T08:51:51.517Z'
      numEdits: 0
      reactions: []
    id: 64955d27f2b8c25a2a3fda2f
    type: comment
  author: HR1777
  content: I would like to use this model using GPT4All and id like to know does GPT4All
    (windows version) already support mpt-30b-chat? Do you have any other alternative
    to run this model on Windows OS? I would like to use this same model not the quantized
    versions (GGML) . What is your suggestion for running it on Windows?
  created_at: 2023-06-23 07:51:51+00:00
  edited: false
  hidden: false
  id: 64955d27f2b8c25a2a3fda2f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eca3e86d4fb4e79fc3b88ec4d6576e24.svg
      fullname: Jacek
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: beoswindvip
      type: user
    createdAt: '2023-06-27T22:27:00.000Z'
    data:
      edited: true
      editors:
      - beoswindvip
      hidden: false
      identifiedLanguage:
        language: es
        probability: 0.875447690486908
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eca3e86d4fb4e79fc3b88ec4d6576e24.svg
          fullname: Jacek
          isHf: false
          isPro: false
          name: beoswindvip
          type: user
        html: '<p>No -  MPT-30B-CHAT files are almost 60 GB so it''s not possible
          run it with small RAM</p>

          '
        raw: No -  MPT-30B-CHAT files are almost 60 GB so it's not possible run it
          with small RAM
        updatedAt: '2023-06-27T22:27:42.319Z'
      numEdits: 1
      reactions: []
    id: 649b62348302704b3c30e2fd
    type: comment
  author: beoswindvip
  content: No -  MPT-30B-CHAT files are almost 60 GB so it's not possible run it with
    small RAM
  created_at: 2023-06-27 21:27:00+00:00
  edited: true
  hidden: false
  id: 649b62348302704b3c30e2fd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
      fullname: H R
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HR1777
      type: user
    createdAt: '2023-06-29T07:26:00.000Z'
    data:
      edited: false
      editors:
      - HR1777
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9862707257270813
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
          fullname: H R
          isHf: false
          isPro: false
          name: HR1777
          type: user
        html: '<p>Thank you so much for your reply. </p>

          '
        raw: 'Thank you so much for your reply. '
        updatedAt: '2023-06-29T07:26:00.092Z'
      numEdits: 0
      reactions: []
      relatedEventId: 649d320878fe1d064b1911a4
    id: 649d320878fe1d064b1911a2
    type: comment
  author: HR1777
  content: 'Thank you so much for your reply. '
  created_at: 2023-06-29 06:26:00+00:00
  edited: false
  hidden: false
  id: 649d320878fe1d064b1911a2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
      fullname: H R
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HR1777
      type: user
    createdAt: '2023-06-29T07:26:00.000Z'
    data:
      status: closed
    id: 649d320878fe1d064b1911a4
    type: status-change
  author: HR1777
  created_at: 2023-06-29 06:26:00+00:00
  id: 649d320878fe1d064b1911a4
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: mosaicml/mpt-30b-chat
repo_type: model
status: closed
target_branch: null
title: Does the GPT4All (windows version) already support mpt-30b-chat?
