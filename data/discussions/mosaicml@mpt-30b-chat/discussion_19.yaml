!!python/object:huggingface_hub.community.DiscussionWithDetails
author: fuliu2023
conflicting_files: null
created_at: 2023-08-25 06:24:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/81e77f378de0d67c870fc560f6446e3c.svg
      fullname: guangwei she
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fuliu2023
      type: user
    createdAt: '2023-08-25T07:24:14.000Z'
    data:
      edited: false
      editors:
      - fuliu2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6299524903297424
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/81e77f378de0d67c870fc560f6446e3c.svg
          fullname: guangwei she
          isHf: false
          isPro: false
          name: fuliu2023
          type: user
        html: "<p>config.init_device how to use all gpu\u3002I config config.init_device\
          \ = 'cuda:0',it report error\uFF1Atorch.cuda.OutOfMemoryError: CUDA out\
          \ of memory. Tried to allocate 98.00 MiB (GPU 0; 15.77 GiB total capacity;\
          \ 14.74 GiB already allocated; 86.88 MiB free; 14.75 GiB reserved in total\
          \ by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting\
          \ max_split_size_mb to avoid fragmentation.  See documentation for Memory\
          \ Management and PYTORCH_CUDA_ALLOC_CON</p>\n"
        raw: "config.init_device how to use all gpu\u3002I config config.init_device\
          \ = 'cuda:0',it report error\uFF1Atorch.cuda.OutOfMemoryError: CUDA out\
          \ of memory. Tried to allocate 98.00 MiB (GPU 0; 15.77 GiB total capacity;\
          \ 14.74 GiB already allocated; 86.88 MiB free; 14.75 GiB reserved in total\
          \ by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb\
          \ to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CON"
        updatedAt: '2023-08-25T07:24:14.260Z'
      numEdits: 0
      reactions: []
    id: 64e8571ef2f5545edaf8b839
    type: comment
  author: fuliu2023
  content: "config.init_device how to use all gpu\u3002I config config.init_device\
    \ = 'cuda:0',it report error\uFF1Atorch.cuda.OutOfMemoryError: CUDA out of memory.\
    \ Tried to allocate 98.00 MiB (GPU 0; 15.77 GiB total capacity; 14.74 GiB already\
    \ allocated; 86.88 MiB free; 14.75 GiB reserved in total by PyTorch) If reserved\
    \ memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.\
    \  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CON"
  created_at: 2023-08-25 06:24:14+00:00
  edited: false
  hidden: false
  id: 64e8571ef2f5545edaf8b839
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: mosaicml/mpt-30b-chat
repo_type: model
status: open
target_branch: null
title: How to use all gpu?
