!!python/object:huggingface_hub.community.DiscussionWithDetails
author: habsanero
conflicting_files: null
created_at: 2024-01-09 08:17:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43e420e4f447f3c5cee387d165a4f84b.svg
      fullname: Hab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: habsanero
      type: user
    createdAt: '2024-01-09T08:17:53.000Z'
    data:
      edited: false
      editors:
      - habsanero
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8905792236328125
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43e420e4f447f3c5cee387d165a4f84b.svg
          fullname: Hab
          isHf: false
          isPro: false
          name: habsanero
          type: user
        html: "<p>I'm having trouble getting this to run. I've downloaded the weights\
          \ from hugging face and the create_model() function finds them ok. But it\
          \ runs into issues after that.  I'm on an M1 Mac Pro with 32GB of RAM.</p>\n\
          <p>Here is my output using the the example file, with a small modification\
          \ to get it to compile (weights_path needed to be changed to weights):</p>\n\
          <pre><code>Loading weights from ../models/e5-mistral-7b-instruct/weights.npz\n\
          [WARNING] Missing keys in weights file: output.weight\n[WARNING] Missing\
          \ key output.weight in weights file\nYou're using a LlamaTokenizerFast tokenizer.\
          \ Please note that with a fast tokenizer, using the `__call__` method is\
          \ faster than using a method to encode the text followed by a call to the\
          \ `pad` method to get a padded encoding.\n/opt/homebrew/lib/python3.11/site-packages/numpy/linalg/linalg.py:2583:\
          \ RuntimeWarning: overflow encountered in reduce\n  return sqrt(add.reduce(s,\
          \ axis=axis, keepdims=keepdims))\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n\
          </code></pre>\n"
        raw: "I'm having trouble getting this to run. I've downloaded the weights\
          \ from hugging face and the create_model() function finds them ok. But it\
          \ runs into issues after that.  I'm on an M1 Mac Pro with 32GB of RAM.\r\
          \n\r\nHere is my output using the the example file, with a small modification\
          \ to get it to compile (weights_path needed to be changed to weights):\r\
          \n\r\n```\r\nLoading weights from ../models/e5-mistral-7b-instruct/weights.npz\r\
          \n[WARNING] Missing keys in weights file: output.weight\r\n[WARNING] Missing\
          \ key output.weight in weights file\r\nYou're using a LlamaTokenizerFast\
          \ tokenizer. Please note that with a fast tokenizer, using the `__call__`\
          \ method is faster than using a method to encode the text followed by a\
          \ call to the `pad` method to get a padded encoding.\r\n/opt/homebrew/lib/python3.11/site-packages/numpy/linalg/linalg.py:2583:\
          \ RuntimeWarning: overflow encountered in reduce\r\n  return sqrt(add.reduce(s,\
          \ axis=axis, keepdims=keepdims))\r\n[[0. 0. 0.]\r\n [0. 0. 0.]\r\n [0. 0.\
          \ 0.]]\r\n```"
        updatedAt: '2024-01-09T08:17:53.407Z'
      numEdits: 0
      reactions: []
    id: 659d013128c62716458846c4
    type: comment
  author: habsanero
  content: "I'm having trouble getting this to run. I've downloaded the weights from\
    \ hugging face and the create_model() function finds them ok. But it runs into\
    \ issues after that.  I'm on an M1 Mac Pro with 32GB of RAM.\r\n\r\nHere is my\
    \ output using the the example file, with a small modification to get it to compile\
    \ (weights_path needed to be changed to weights):\r\n\r\n```\r\nLoading weights\
    \ from ../models/e5-mistral-7b-instruct/weights.npz\r\n[WARNING] Missing keys\
    \ in weights file: output.weight\r\n[WARNING] Missing key output.weight in weights\
    \ file\r\nYou're using a LlamaTokenizerFast tokenizer. Please note that with a\
    \ fast tokenizer, using the `__call__` method is faster than using a method to\
    \ encode the text followed by a call to the `pad` method to get a padded encoding.\r\
    \n/opt/homebrew/lib/python3.11/site-packages/numpy/linalg/linalg.py:2583: RuntimeWarning:\
    \ overflow encountered in reduce\r\n  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\r\
    \n[[0. 0. 0.]\r\n [0. 0. 0.]\r\n [0. 0. 0.]]\r\n```"
  created_at: 2024-01-09 08:17:53+00:00
  edited: false
  hidden: false
  id: 659d013128c62716458846c4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/649d381f5a5d6d6a143f0b7e/219Dut7IFzOl--GvsZ4bS.png?w=200&h=200&f=face
      fullname: Riccardo Musmeci
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: riccardomusmeci
      type: user
    createdAt: '2024-01-09T09:07:49.000Z'
    data:
      edited: false
      editors:
      - riccardomusmeci
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7906621694564819
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/649d381f5a5d6d6a143f0b7e/219Dut7IFzOl--GvsZ4bS.png?w=200&h=200&f=face
          fullname: Riccardo Musmeci
          isHf: false
          isPro: false
          name: riccardomusmeci
          type: user
        html: '<p>What''s the input?</p>

          '
        raw: What's the input?
        updatedAt: '2024-01-09T09:07:49.612Z'
      numEdits: 0
      reactions: []
    id: 659d0ce52f26ff2d02902feb
    type: comment
  author: riccardomusmeci
  content: What's the input?
  created_at: 2024-01-09 09:07:49+00:00
  edited: false
  hidden: false
  id: 659d0ce52f26ff2d02902feb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43e420e4f447f3c5cee387d165a4f84b.svg
      fullname: Hab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: habsanero
      type: user
    createdAt: '2024-01-09T19:10:37.000Z'
    data:
      edited: false
      editors:
      - habsanero
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9889475703239441
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43e420e4f447f3c5cee387d165a4f84b.svg
          fullname: Hab
          isHf: false
          isPro: false
          name: habsanero
          type: user
        html: '<p>I was verbatim running the example in the README. I saved that out
          to a .py file and ran it. </p>

          '
        raw: 'I was verbatim running the example in the README. I saved that out to
          a .py file and ran it. '
        updatedAt: '2024-01-09T19:10:37.318Z'
      numEdits: 0
      reactions: []
    id: 659d9a2d18dc7360290d8c31
    type: comment
  author: habsanero
  content: 'I was verbatim running the example in the README. I saved that out to
    a .py file and ran it. '
  created_at: 2024-01-09 19:10:37+00:00
  edited: false
  hidden: false
  id: 659d9a2d18dc7360290d8c31
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43e420e4f447f3c5cee387d165a4f84b.svg
      fullname: Hab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: habsanero
      type: user
    createdAt: '2024-01-09T20:12:25.000Z'
    data:
      edited: false
      editors:
      - habsanero
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9628653526306152
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43e420e4f447f3c5cee387d165a4f84b.svg
          fullname: Hab
          isHf: false
          isPro: false
          name: habsanero
          type: user
        html: '<p>I think the example is incomplete/incorrect currently. For example,
          it doesn''t use the last_token_pool method provided by the e5-mistral-7b-instruct
          team, which grabs only the last tensor to get the most useful embedding.
          It also doesn''t seem to use the attention mask for anything, which is an
          important step.</p>

          '
        raw: 'I think the example is incomplete/incorrect currently. For example,
          it doesn''t use the last_token_pool method provided by the e5-mistral-7b-instruct
          team, which grabs only the last tensor to get the most useful embedding.
          It also doesn''t seem to use the attention mask for anything, which is an
          important step.

          '
        updatedAt: '2024-01-09T20:12:25.488Z'
      numEdits: 0
      reactions: []
    id: 659da8a915506e9719a32220
    type: comment
  author: habsanero
  content: 'I think the example is incomplete/incorrect currently. For example, it
    doesn''t use the last_token_pool method provided by the e5-mistral-7b-instruct
    team, which grabs only the last tensor to get the most useful embedding. It also
    doesn''t seem to use the attention mask for anything, which is an important step.

    '
  created_at: 2024-01-09 20:12:25+00:00
  edited: false
  hidden: false
  id: 659da8a915506e9719a32220
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/649d381f5a5d6d6a143f0b7e/219Dut7IFzOl--GvsZ4bS.png?w=200&h=200&f=face
      fullname: Riccardo Musmeci
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: riccardomusmeci
      type: user
    createdAt: '2024-01-10T06:35:04.000Z'
    data:
      edited: false
      editors:
      - riccardomusmeci
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9678090810775757
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/649d381f5a5d6d6a143f0b7e/219Dut7IFzOl--GvsZ4bS.png?w=200&h=200&f=face
          fullname: Riccardo Musmeci
          isHf: false
          isPro: false
          name: riccardomusmeci
          type: user
        html: '<p> My initial idea was to give a grasp of what you can do. Coming
          back soon with a fix.  Thanks for the comment &lt;3 </p>

          '
        raw: ' My initial idea was to give a grasp of what you can do. Coming back
          soon with a fix.  Thanks for the comment <3 '
        updatedAt: '2024-01-10T06:35:04.982Z'
      numEdits: 0
      reactions: []
    id: 659e3a9804b93eb6dba3c23b
    type: comment
  author: riccardomusmeci
  content: ' My initial idea was to give a grasp of what you can do. Coming back soon
    with a fix.  Thanks for the comment <3 '
  created_at: 2024-01-10 06:35:04+00:00
  edited: false
  hidden: false
  id: 659e3a9804b93eb6dba3c23b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/66071cb9b1cb4bae3c0acc2d4ca55450.svg
      fullname: paul maksimovich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: paulmaksimovich
      type: user
    createdAt: '2024-01-12T04:20:51.000Z'
    data:
      edited: true
      editors:
      - paulmaksimovich
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6214539408683777
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/66071cb9b1cb4bae3c0acc2d4ca55450.svg
          fullname: paul maksimovich
          isHf: false
          isPro: false
          name: paulmaksimovich
          type: user
        html: "<p>As a fyi, I have some success with:</p>\n<pre><code>from mlx_llm.model\
          \ import create_model\nfrom transformers import AutoTokenizer\nimport mlx.core\
          \ as mx\n\nmodel = create_model(\"e5-mistral-7b-instruct\")\ntokenizer =\
          \ AutoTokenizer.from_pretrained('intfloat/e5-mistral-7b-instruct')\ntext\
          \ = [\"I like to play basketball\", \"I like to play tennis\"]\ntokens =\
          \ tokenizer(text)\nx = mx.array(tokens[\"input_ids\"])\nembeds = model.embed(x)\n\
          print(embeds)\n</code></pre>\n<p>Still need to do the whole mlx_llm install\
          \ of course. </p>\n<p>The output I see:</p>\n<pre><code>Loading weights\
          \ from /Users/xxxxx/.cache/huggingface/hub/models--mlx-community--e5-mistral-7b-instruct-mlx/snapshots/22ac7676256b54fc97423032f2d9f26e9a8a92ea/weights.npz\n\
          [WARNING] Missing keys in weights file: output.weight\n[WARNING] Missing\
          \ key output.weight in weights file\narray([[[-1.72168, 0.583008, -1.65137,\
          \ ..., 0.221558, -2.03125, 2.67578],\n        [-1.22266, -0.729004, -0.797363,\
          \ ..., 3.53711, -4.75, 2.02148],\n        [-0.523438, -0.513672, -0.918457,\
          \ ..., 0.196411, 2.79297, -2.21094],\n        [0.465332, 0.130127, 2.82422,\
          \ ..., -5.42969, 0.048645, -2.75195],\n        [3.10547, 1.83008, -1.22461,\
          \ ..., -1.96582, -1.21875, 9.67188],\n        [-1.2168, -2.43164, 0.737793,\
          \ ..., 0.120483, 0.842773, 8.5625]],\n       [[-1.72168, 0.583008, -1.65137,\
          \ ..., 0.221558, -2.03125, 2.67578],\n        [-1.22266, -0.729004, -0.797363,\
          \ ..., 3.53711, -4.75, 2.02148],\n        [-0.523438, -0.513672, -0.918457,\
          \ ..., 0.196411, 2.79297, -2.21094],\n        [0.465332, 0.130127, 2.82422,\
          \ ..., -5.42969, 0.048645, -2.75195],\n        [3.10547, 1.83008, -1.22461,\
          \ ..., -1.96582, -1.21875, 9.67188],\n        [-1.24805, 5.57812, -1.57715,\
          \ ..., 3.67188, 4.06641, 6.41016]]], dtype=float16)\n\nProcess finished\
          \ with exit code 0\n</code></pre>\n<p>^ shape <code>[2,6,4096]</code><br>Although\
          \ clearly missing weights/output sounds alarming.<br>Any tips?</p>\n"
        raw: "As a fyi, I have some success with:\n```\nfrom mlx_llm.model import\
          \ create_model\nfrom transformers import AutoTokenizer\nimport mlx.core\
          \ as mx\n\nmodel = create_model(\"e5-mistral-7b-instruct\")\ntokenizer =\
          \ AutoTokenizer.from_pretrained('intfloat/e5-mistral-7b-instruct')\ntext\
          \ = [\"I like to play basketball\", \"I like to play tennis\"]\ntokens =\
          \ tokenizer(text)\nx = mx.array(tokens[\"input_ids\"])\nembeds = model.embed(x)\n\
          print(embeds)\n```\n\nStill need to do the whole mlx_llm install of course.\
          \ \n\nThe output I see:\n```\nLoading weights from /Users/xxxxx/.cache/huggingface/hub/models--mlx-community--e5-mistral-7b-instruct-mlx/snapshots/22ac7676256b54fc97423032f2d9f26e9a8a92ea/weights.npz\n\
          [WARNING] Missing keys in weights file: output.weight\n[WARNING] Missing\
          \ key output.weight in weights file\narray([[[-1.72168, 0.583008, -1.65137,\
          \ ..., 0.221558, -2.03125, 2.67578],\n        [-1.22266, -0.729004, -0.797363,\
          \ ..., 3.53711, -4.75, 2.02148],\n        [-0.523438, -0.513672, -0.918457,\
          \ ..., 0.196411, 2.79297, -2.21094],\n        [0.465332, 0.130127, 2.82422,\
          \ ..., -5.42969, 0.048645, -2.75195],\n        [3.10547, 1.83008, -1.22461,\
          \ ..., -1.96582, -1.21875, 9.67188],\n        [-1.2168, -2.43164, 0.737793,\
          \ ..., 0.120483, 0.842773, 8.5625]],\n       [[-1.72168, 0.583008, -1.65137,\
          \ ..., 0.221558, -2.03125, 2.67578],\n        [-1.22266, -0.729004, -0.797363,\
          \ ..., 3.53711, -4.75, 2.02148],\n        [-0.523438, -0.513672, -0.918457,\
          \ ..., 0.196411, 2.79297, -2.21094],\n        [0.465332, 0.130127, 2.82422,\
          \ ..., -5.42969, 0.048645, -2.75195],\n        [3.10547, 1.83008, -1.22461,\
          \ ..., -1.96582, -1.21875, 9.67188],\n        [-1.24805, 5.57812, -1.57715,\
          \ ..., 3.67188, 4.06641, 6.41016]]], dtype=float16)\n\nProcess finished\
          \ with exit code 0\n```\n^ shape `[2,6,4096]`\nAlthough clearly missing\
          \ weights/output sounds alarming.\nAny tips?\n"
        updatedAt: '2024-01-12T05:35:02.110Z'
      numEdits: 1
      reactions: []
    id: 65a0be23628cd4ce2f3747ba
    type: comment
  author: paulmaksimovich
  content: "As a fyi, I have some success with:\n```\nfrom mlx_llm.model import create_model\n\
    from transformers import AutoTokenizer\nimport mlx.core as mx\n\nmodel = create_model(\"\
    e5-mistral-7b-instruct\")\ntokenizer = AutoTokenizer.from_pretrained('intfloat/e5-mistral-7b-instruct')\n\
    text = [\"I like to play basketball\", \"I like to play tennis\"]\ntokens = tokenizer(text)\n\
    x = mx.array(tokens[\"input_ids\"])\nembeds = model.embed(x)\nprint(embeds)\n\
    ```\n\nStill need to do the whole mlx_llm install of course. \n\nThe output I\
    \ see:\n```\nLoading weights from /Users/xxxxx/.cache/huggingface/hub/models--mlx-community--e5-mistral-7b-instruct-mlx/snapshots/22ac7676256b54fc97423032f2d9f26e9a8a92ea/weights.npz\n\
    [WARNING] Missing keys in weights file: output.weight\n[WARNING] Missing key output.weight\
    \ in weights file\narray([[[-1.72168, 0.583008, -1.65137, ..., 0.221558, -2.03125,\
    \ 2.67578],\n        [-1.22266, -0.729004, -0.797363, ..., 3.53711, -4.75, 2.02148],\n\
    \        [-0.523438, -0.513672, -0.918457, ..., 0.196411, 2.79297, -2.21094],\n\
    \        [0.465332, 0.130127, 2.82422, ..., -5.42969, 0.048645, -2.75195],\n \
    \       [3.10547, 1.83008, -1.22461, ..., -1.96582, -1.21875, 9.67188],\n    \
    \    [-1.2168, -2.43164, 0.737793, ..., 0.120483, 0.842773, 8.5625]],\n      \
    \ [[-1.72168, 0.583008, -1.65137, ..., 0.221558, -2.03125, 2.67578],\n       \
    \ [-1.22266, -0.729004, -0.797363, ..., 3.53711, -4.75, 2.02148],\n        [-0.523438,\
    \ -0.513672, -0.918457, ..., 0.196411, 2.79297, -2.21094],\n        [0.465332,\
    \ 0.130127, 2.82422, ..., -5.42969, 0.048645, -2.75195],\n        [3.10547, 1.83008,\
    \ -1.22461, ..., -1.96582, -1.21875, 9.67188],\n        [-1.24805, 5.57812, -1.57715,\
    \ ..., 3.67188, 4.06641, 6.41016]]], dtype=float16)\n\nProcess finished with exit\
    \ code 0\n```\n^ shape `[2,6,4096]`\nAlthough clearly missing weights/output sounds\
    \ alarming.\nAny tips?\n"
  created_at: 2024-01-12 04:20:51+00:00
  edited: true
  hidden: false
  id: 65a0be23628cd4ce2f3747ba
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/649d381f5a5d6d6a143f0b7e/219Dut7IFzOl--GvsZ4bS.png?w=200&h=200&f=face
      fullname: Riccardo Musmeci
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: riccardomusmeci
      type: user
    createdAt: '2024-01-12T17:38:40.000Z'
    data:
      edited: false
      editors:
      - riccardomusmeci
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9501741528511047
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/649d381f5a5d6d6a143f0b7e/219Dut7IFzOl--GvsZ4bS.png?w=200&h=200&f=face
          fullname: Riccardo Musmeci
          isHf: false
          isPro: false
          name: riccardomusmeci
          type: user
        html: '<p>The missing weights and outputs is not alarming. This is an embedding
          model that does not have the head layers used to predict the next tokens
          usually. Here you want to stop before the generation and extract the embeddings.</p>

          '
        raw: The missing weights and outputs is not alarming. This is an embedding
          model that does not have the head layers used to predict the next tokens
          usually. Here you want to stop before the generation and extract the embeddings.
        updatedAt: '2024-01-12T17:38:40.092Z'
      numEdits: 0
      reactions: []
    id: 65a179204e2e55a1287585b9
    type: comment
  author: riccardomusmeci
  content: The missing weights and outputs is not alarming. This is an embedding model
    that does not have the head layers used to predict the next tokens usually. Here
    you want to stop before the generation and extract the embeddings.
  created_at: 2024-01-12 17:38:40+00:00
  edited: false
  hidden: false
  id: 65a179204e2e55a1287585b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/649d381f5a5d6d6a143f0b7e/219Dut7IFzOl--GvsZ4bS.png?w=200&h=200&f=face
      fullname: Riccardo Musmeci
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: riccardomusmeci
      type: user
    createdAt: '2024-01-12T18:33:09.000Z'
    data:
      edited: true
      editors:
      - riccardomusmeci
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8769955635070801
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/649d381f5a5d6d6a143f0b7e/219Dut7IFzOl--GvsZ4bS.png?w=200&h=200&f=face
          fullname: Riccardo Musmeci
          isHf: false
          isPro: false
          name: riccardomusmeci
          type: user
        html: "<blockquote>\n<p>I'm having trouble getting this to run. I've downloaded\
          \ the weights from hugging face and the create_model() function finds them\
          \ ok. But it runs into issues after that.  I'm on an M1 Mac Pro with 32GB\
          \ of RAM.</p>\n<p>Here is my output using the the example file, with a small\
          \ modification to get it to compile (weights_path needed to be changed to\
          \ weights):</p>\n<pre><code>Loading weights from ../models/e5-mistral-7b-instruct/weights.npz\n\
          [WARNING] Missing keys in weights file: output.weight\n[WARNING] Missing\
          \ key output.weight in weights file\nYou're using a LlamaTokenizerFast tokenizer.\
          \ Please note that with a fast tokenizer, using the `__call__` method is\
          \ faster than using a method to encode the text followed by a call to the\
          \ `pad` method to get a padded encoding.\n/opt/homebrew/lib/python3.11/site-packages/numpy/linalg/linalg.py:2583:\
          \ RuntimeWarning: overflow encountered in reduce\n  return sqrt(add.reduce(s,\
          \ axis=axis, keepdims=keepdims))\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n\
          </code></pre>\n</blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;habsanero&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/habsanero\"\
          >@<span class=\"underline\">habsanero</span></a></span>\n\n\t</span></span>\
          \ found where the problem is. You must call model.embed(x, norm=False)</p>\n\
          <p>Actually, I will change how the method works in the future since norm=True\
          \ is the default and generates wrong embeddings.</p>\n"
        raw: "\n> I'm having trouble getting this to run. I've downloaded the weights\
          \ from hugging face and the create_model() function finds them ok. But it\
          \ runs into issues after that.  I'm on an M1 Mac Pro with 32GB of RAM.\n\
          > \n> Here is my output using the the example file, with a small modification\
          \ to get it to compile (weights_path needed to be changed to weights):\n\
          > \n> ```\n> Loading weights from ../models/e5-mistral-7b-instruct/weights.npz\n\
          > [WARNING] Missing keys in weights file: output.weight\n> [WARNING] Missing\
          \ key output.weight in weights file\n> You're using a LlamaTokenizerFast\
          \ tokenizer. Please note that with a fast tokenizer, using the `__call__`\
          \ method is faster than using a method to encode the text followed by a\
          \ call to the `pad` method to get a padded encoding.\n> /opt/homebrew/lib/python3.11/site-packages/numpy/linalg/linalg.py:2583:\
          \ RuntimeWarning: overflow encountered in reduce\n>   return sqrt(add.reduce(s,\
          \ axis=axis, keepdims=keepdims))\n> [[0. 0. 0.]\n>  [0. 0. 0.]\n>  [0. 0.\
          \ 0.]]\n> ```\n\n@habsanero found where the problem is. You must call model.embed(x,\
          \ norm=False)\n\nActually, I will change how the method works in the future\
          \ since norm=True is the default and generates wrong embeddings.\n"
        updatedAt: '2024-01-12T18:33:38.501Z'
      numEdits: 1
      reactions: []
      relatedEventId: 65a185e6d46a3b5c6e3e524e
    id: 65a185e5d46a3b5c6e3e5248
    type: comment
  author: riccardomusmeci
  content: "\n> I'm having trouble getting this to run. I've downloaded the weights\
    \ from hugging face and the create_model() function finds them ok. But it runs\
    \ into issues after that.  I'm on an M1 Mac Pro with 32GB of RAM.\n> \n> Here\
    \ is my output using the the example file, with a small modification to get it\
    \ to compile (weights_path needed to be changed to weights):\n> \n> ```\n> Loading\
    \ weights from ../models/e5-mistral-7b-instruct/weights.npz\n> [WARNING] Missing\
    \ keys in weights file: output.weight\n> [WARNING] Missing key output.weight in\
    \ weights file\n> You're using a LlamaTokenizerFast tokenizer. Please note that\
    \ with a fast tokenizer, using the `__call__` method is faster than using a method\
    \ to encode the text followed by a call to the `pad` method to get a padded encoding.\n\
    > /opt/homebrew/lib/python3.11/site-packages/numpy/linalg/linalg.py:2583: RuntimeWarning:\
    \ overflow encountered in reduce\n>   return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n\
    > [[0. 0. 0.]\n>  [0. 0. 0.]\n>  [0. 0. 0.]]\n> ```\n\n@habsanero found where\
    \ the problem is. You must call model.embed(x, norm=False)\n\nActually, I will\
    \ change how the method works in the future since norm=True is the default and\
    \ generates wrong embeddings.\n"
  created_at: 2024-01-12 18:33:09+00:00
  edited: true
  hidden: false
  id: 65a185e5d46a3b5c6e3e5248
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/649d381f5a5d6d6a143f0b7e/219Dut7IFzOl--GvsZ4bS.png?w=200&h=200&f=face
      fullname: Riccardo Musmeci
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: riccardomusmeci
      type: user
    createdAt: '2024-01-12T18:33:10.000Z'
    data:
      status: closed
    id: 65a185e6d46a3b5c6e3e524e
    type: status-change
  author: riccardomusmeci
  created_at: 2024-01-12 18:33:10+00:00
  id: 65a185e6d46a3b5c6e3e524e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: mlx-community/e5-mistral-7b-instruct-mlx
repo_type: model
status: closed
target_branch: null
title: Incomplete example?
