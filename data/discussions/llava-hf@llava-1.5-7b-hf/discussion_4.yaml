!!python/object:huggingface_hub.community.DiscussionWithDetails
author: PerRing
conflicting_files: null
created_at: 2023-12-09 14:56:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae00fde99b95fcc3a95aae8a558eb049.svg
      fullname: HanYoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: PerRing
      type: user
    createdAt: '2023-12-09T14:56:02.000Z'
    data:
      edited: false
      editors:
      - PerRing
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4678831696510315
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae00fde99b95fcc3a95aae8a558eb049.svg
          fullname: HanYoo
          isHf: false
          isPro: false
          name: PerRing
          type: user
        html: "<pre><code>---&gt; 12 outputs = pipe(image, prompt=prompt, generate_kwargs={\"\
          max_new_tokens\": 200})\n     13 print(outputs)\n\nFile /data/MLP/hgyoo/.hg/lib/python3.10/site-packages/transformers/pipelines/image_to_text.py:111,\
          \ in ImageToTextPipeline.__call__(self, images, **kwargs)\n     83 def __call__(self,\
          \ images: Union[str, List[str], \"Image.Image\", List[\"Image.Image\"]],\
          \ **kwargs):\n     84     \"\"\"\n     85     Assign labels to the image(s)\
          \ passed as inputs.\n     86 \n   (...)\n    109         - **generated_text**\
          \ (`str`) -- The generated text.\n    110     \"\"\"\n--&gt; 111     return\
          \ super().__call__(images, **kwargs)\n\nFile /data/MLP/hgyoo/.hg/lib/python3.10/site-packages/transformers/pipelines/base.py:1140,\
          \ in Pipeline.__call__(self, inputs, num_workers, batch_size, *args, **kwargs)\n\
          \   1132     return next(\n   1133         iter(\n   1134             self.get_iterator(\n\
          \   (...)\n   1137         )\n   1138     )\n...\n--&gt; 136     expanded_attn_mask\
          \ = causal_4d_mask.masked_fill(expanded_attn_mask.bool(), torch.finfo(dtype).min)\n\
          \    138 # expanded_attn_mask + causal_4d_mask can cause some overflow\n\
          \    139 expanded_4d_mask = expanded_attn_mask\n\nRuntimeError: The size\
          \ of tensor a (616) must match the size of tensor b (1231) at non-singleton\
          \ dimension 3\n</code></pre>\n<p>I ran the Using Pipeline code exactly as\
          \ it is in the README, but I'm getting a dimension error.<br>Additionally,\
          \ there is a typo (import request -&gt; import requests)</p>\n"
        raw: "```\r\n---> 12 outputs = pipe(image, prompt=prompt, generate_kwargs={\"\
          max_new_tokens\": 200})\r\n     13 print(outputs)\r\n\r\nFile /data/MLP/hgyoo/.hg/lib/python3.10/site-packages/transformers/pipelines/image_to_text.py:111,\
          \ in ImageToTextPipeline.__call__(self, images, **kwargs)\r\n     83 def\
          \ __call__(self, images: Union[str, List[str], \"Image.Image\", List[\"\
          Image.Image\"]], **kwargs):\r\n     84     \"\"\"\r\n     85     Assign\
          \ labels to the image(s) passed as inputs.\r\n     86 \r\n   (...)\r\n \
          \   109         - **generated_text** (`str`) -- The generated text.\r\n\
          \    110     \"\"\"\r\n--> 111     return super().__call__(images, **kwargs)\r\
          \n\r\nFile /data/MLP/hgyoo/.hg/lib/python3.10/site-packages/transformers/pipelines/base.py:1140,\
          \ in Pipeline.__call__(self, inputs, num_workers, batch_size, *args, **kwargs)\r\
          \n   1132     return next(\r\n   1133         iter(\r\n   1134         \
          \    self.get_iterator(\r\n   (...)\r\n   1137         )\r\n   1138    \
          \ )\r\n...\r\n--> 136     expanded_attn_mask = causal_4d_mask.masked_fill(expanded_attn_mask.bool(),\
          \ torch.finfo(dtype).min)\r\n    138 # expanded_attn_mask + causal_4d_mask\
          \ can cause some overflow\r\n    139 expanded_4d_mask = expanded_attn_mask\r\
          \n\r\nRuntimeError: The size of tensor a (616) must match the size of tensor\
          \ b (1231) at non-singleton dimension 3\r\n```\r\nI ran the Using Pipeline\
          \ code exactly as it is in the README, but I'm getting a dimension error.\
          \ \r\nAdditionally, there is a typo (import request -> import requests)"
        updatedAt: '2023-12-09T14:56:02.945Z'
      numEdits: 0
      reactions: []
    id: 657480028b44ef012b2f6e00
    type: comment
  author: PerRing
  content: "```\r\n---> 12 outputs = pipe(image, prompt=prompt, generate_kwargs={\"\
    max_new_tokens\": 200})\r\n     13 print(outputs)\r\n\r\nFile /data/MLP/hgyoo/.hg/lib/python3.10/site-packages/transformers/pipelines/image_to_text.py:111,\
    \ in ImageToTextPipeline.__call__(self, images, **kwargs)\r\n     83 def __call__(self,\
    \ images: Union[str, List[str], \"Image.Image\", List[\"Image.Image\"]], **kwargs):\r\
    \n     84     \"\"\"\r\n     85     Assign labels to the image(s) passed as inputs.\r\
    \n     86 \r\n   (...)\r\n    109         - **generated_text** (`str`) -- The\
    \ generated text.\r\n    110     \"\"\"\r\n--> 111     return super().__call__(images,\
    \ **kwargs)\r\n\r\nFile /data/MLP/hgyoo/.hg/lib/python3.10/site-packages/transformers/pipelines/base.py:1140,\
    \ in Pipeline.__call__(self, inputs, num_workers, batch_size, *args, **kwargs)\r\
    \n   1132     return next(\r\n   1133         iter(\r\n   1134             self.get_iterator(\r\
    \n   (...)\r\n   1137         )\r\n   1138     )\r\n...\r\n--> 136     expanded_attn_mask\
    \ = causal_4d_mask.masked_fill(expanded_attn_mask.bool(), torch.finfo(dtype).min)\r\
    \n    138 # expanded_attn_mask + causal_4d_mask can cause some overflow\r\n  \
    \  139 expanded_4d_mask = expanded_attn_mask\r\n\r\nRuntimeError: The size of\
    \ tensor a (616) must match the size of tensor b (1231) at non-singleton dimension\
    \ 3\r\n```\r\nI ran the Using Pipeline code exactly as it is in the README, but\
    \ I'm getting a dimension error. \r\nAdditionally, there is a typo (import request\
    \ -> import requests)"
  created_at: 2023-12-09 14:56:02+00:00
  edited: false
  hidden: false
  id: 657480028b44ef012b2f6e00
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-12-09T15:38:23.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9088812470436096
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: '<p>It has been recently fixed in transformers main can you try:</p>

          <pre><code class="language-bash">pip install -U git+https://github.com/huggingface/transformers.git

          </code></pre>

          <p>For the typo : thanks for noticing! I will update it</p>

          '
        raw: 'It has been recently fixed in transformers main can you try:


          ```bash

          pip install -U git+https://github.com/huggingface/transformers.git

          ```


          For the typo : thanks for noticing! I will update it'
        updatedAt: '2023-12-09T15:38:23.596Z'
      numEdits: 0
      reactions: []
    id: 657489ef05e573071546079c
    type: comment
  author: ybelkada
  content: 'It has been recently fixed in transformers main can you try:


    ```bash

    pip install -U git+https://github.com/huggingface/transformers.git

    ```


    For the typo : thanks for noticing! I will update it'
  created_at: 2023-12-09 15:38:23+00:00
  edited: false
  hidden: false
  id: 657489ef05e573071546079c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae00fde99b95fcc3a95aae8a558eb049.svg
      fullname: HanYoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: PerRing
      type: user
    createdAt: '2023-12-09T15:56:51.000Z'
    data:
      edited: false
      editors:
      - PerRing
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8416974544525146
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae00fde99b95fcc3a95aae8a558eb049.svg
          fullname: HanYoo
          isHf: false
          isPro: false
          name: PerRing
          type: user
        html: '<p>I just updated Transformers ( 4.36.0.dev0) with your code, but it
          still doesn''t work. Is this not the latest version?<br>+) there is no ''processor=AutoProcessor.from_pretrained(model_id)''
          in Using pure transformers:</p>

          '
        raw: 'I just updated Transformers ( 4.36.0.dev0) with your code, but it still
          doesn''t work. Is this not the latest version?

          +) there is no ''processor=AutoProcessor.from_pretrained(model_id)'' in
          Using pure transformers:'
        updatedAt: '2023-12-09T15:56:51.832Z'
      numEdits: 0
      reactions: []
    id: 65748e437068a85089469764
    type: comment
  author: PerRing
  content: 'I just updated Transformers ( 4.36.0.dev0) with your code, but it still
    doesn''t work. Is this not the latest version?

    +) there is no ''processor=AutoProcessor.from_pretrained(model_id)'' in Using
    pure transformers:'
  created_at: 2023-12-09 15:56:51+00:00
  edited: false
  hidden: false
  id: 65748e437068a85089469764
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-12-09T16:12:00.000Z'
    data:
      edited: true
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9599428176879883
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;PerRing&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/PerRing\">@<span class=\"\
          underline\">PerRing</span></a></span>\n\n\t</span></span> !<br>Nice catch\
          \ !<br>You might need to re-start the kernel in case you are using Gcolab,\
          \ we just tried it and it seems to work fine: <a href=\"https://huggingface.co/llava-hf/llava-1.5-7b-hf/discussions/2#65748c1a244aefdfc48fbd83\"\
          >https://huggingface.co/llava-hf/llava-1.5-7b-hf/discussions/2#65748c1a244aefdfc48fbd83</a></p>\n"
        raw: "Hi @PerRing ! \nNice catch ! \nYou might need to re-start the kernel\
          \ in case you are using Gcolab, we just tried it and it seems to work fine:\
          \ https://huggingface.co/llava-hf/llava-1.5-7b-hf/discussions/2#65748c1a244aefdfc48fbd83"
        updatedAt: '2023-12-09T16:14:21.980Z'
      numEdits: 1
      reactions: []
    id: 657491d088805b3ba1d54812
    type: comment
  author: ybelkada
  content: "Hi @PerRing ! \nNice catch ! \nYou might need to re-start the kernel in\
    \ case you are using Gcolab, we just tried it and it seems to work fine: https://huggingface.co/llava-hf/llava-1.5-7b-hf/discussions/2#65748c1a244aefdfc48fbd83"
  created_at: 2023-12-09 16:12:00+00:00
  edited: true
  hidden: false
  id: 657491d088805b3ba1d54812
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae00fde99b95fcc3a95aae8a558eb049.svg
      fullname: HanYoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: PerRing
      type: user
    createdAt: '2023-12-09T16:55:46.000Z'
    data:
      edited: false
      editors:
      - PerRing
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8819854259490967
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae00fde99b95fcc3a95aae8a558eb049.svg
          fullname: HanYoo
          isHf: false
          isPro: false
          name: PerRing
          type: user
        html: '<p>it works after I create new environment.</p>

          '
        raw: it works after I create new environment.
        updatedAt: '2023-12-09T16:55:46.067Z'
      numEdits: 0
      reactions: []
    id: 65749c129fe27c093d69b444
    type: comment
  author: PerRing
  content: it works after I create new environment.
  created_at: 2023-12-09 16:55:46+00:00
  edited: false
  hidden: false
  id: 65749c129fe27c093d69b444
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ae00fde99b95fcc3a95aae8a558eb049.svg
      fullname: HanYoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: PerRing
      type: user
    createdAt: '2023-12-09T16:55:51.000Z'
    data:
      status: closed
    id: 65749c17412ee70185bc9c1f
    type: status-change
  author: PerRing
  created_at: 2023-12-09 16:55:51+00:00
  id: 65749c17412ee70185bc9c1f
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: llava-hf/llava-1.5-7b-hf
repo_type: model
status: closed
target_branch: null
title: '"Using pipeline:" in the README doesn''t work.(+ there is typo)'
