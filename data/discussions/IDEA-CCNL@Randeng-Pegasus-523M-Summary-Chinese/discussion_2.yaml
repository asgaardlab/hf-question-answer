!!python/object:huggingface_hub.community.DiscussionWithDetails
author: candog
conflicting_files: null
created_at: 2023-03-22 11:11:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5b8c63c96a0955ccd3d3eb3f18f7f9b0.svg
      fullname: wu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: candog
      type: user
    createdAt: '2023-03-22T12:11:05.000Z'
    data:
      edited: false
      editors:
      - candog
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5b8c63c96a0955ccd3d3eb3f18f7f9b0.svg
          fullname: wu
          isHf: false
          isPro: false
          name: candog
          type: user
        html: "<p>where i test \"\u4F7F\u7528 Usage\"  on colab, i get follow error</p>\n\
          <p>ModuleNotFoundError                       Traceback (most recent call\
          \ last)<br> in <br>      6 # 2. cd Fengshenbang-LM/fengshen/examples/pegasus/<br>\
          \      7 # and then you will see the tokenizers_pegasus.py and data_utils.py\
          \ which are needed by pegasus model<br>----&gt; 8 from tokenizers_pegasus\
          \ import PegasusTokenizer<br>      9<br>     10 model = PegasusForConditionalGeneration.from_pretrained(\"\
          IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\")</p>\n<p>/content/Fengshenbang-LM/fengshen/examples/pegasus/Fengshenbang-LM/fengshen/examples/pegasus/Fengshenbang-LM/fengshen/examples/pegasus/tokenizers_pegasus.py\
          \ in <br>----&gt; 1 from fengshen.examples.pegasus.data_utils import (<br>\
          \      2     _is_control,<br>      3     _is_punctuation,<br>      4   \
          \  _is_whitespace,<br>      5     _is_chinese_char)</p>\n<p>ModuleNotFoundError:\
          \ No module named 'fengshen'</p>\n<p>here is my code<br>!pip install transformers<br>!git\
          \ clone <a rel=\"nofollow\" href=\"https://github.com/IDEA-CCNL/Fengshenbang-LM\"\
          >https://github.com/IDEA-CCNL/Fengshenbang-LM</a><br>%cd Fengshenbang-LM/fengshen/examples/pegasus/<br>%ls\
          \ -l</p>\n<p>from transformers import PegasusForConditionalGeneration</p>\n\
          <h1 id=\"need-to-download-tokenizers_pegasuspy-and-other-python-script-from-fengshenbang-lm-github-repo-in-advance\"\
          >Need to download tokenizers_pegasus.py and other Python script from Fengshenbang-LM\
          \ github repo in advance,</h1>\n<h1 id=\"or-you-can-download-tokenizers_pegasuspy-and-data_utilspy-in-httpshuggingfacecoidea-ccnlrandeng_pegasus_523mtreemain\"\
          >or you can download tokenizers_pegasus.py and data_utils.py in <a href=\"\
          https://huggingface.co/IDEA-CCNL/Randeng_Pegasus_523M/tree/main\">https://huggingface.co/IDEA-CCNL/Randeng_Pegasus_523M/tree/main</a></h1>\n\
          <h1 id=\"strongly-recommend-you-git-clone-the-fengshenbang-lm-repo\">Strongly\
          \ recommend you git clone the Fengshenbang-LM repo:</h1>\n<h1 id=\"1-git-clone-httpsgithubcomidea-ccnlfengshenbang-lm\"\
          >1. git clone <a rel=\"nofollow\" href=\"https://github.com/IDEA-CCNL/Fengshenbang-LM\"\
          >https://github.com/IDEA-CCNL/Fengshenbang-LM</a></h1>\n<h1 id=\"2-cd-fengshenbang-lmfengshenexamplespegasus\"\
          >2. cd Fengshenbang-LM/fengshen/examples/pegasus/</h1>\n<h1 id=\"and-then-you-will-see-the-tokenizers_pegasuspy-and-data_utilspy-which-are-needed-by-pegasus-model\"\
          >and then you will see the tokenizers_pegasus.py and data_utils.py which\
          \ are needed by pegasus model</h1>\n<p>from tokenizers_pegasus import PegasusTokenizer</p>\n\
          <p>model = PegasusForConditionalGeneration.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\"\
          )<br>tokenizer = PegasusTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\"\
          )</p>\n<p>text = \"\u636E\u5FAE\u4FE1\u516C\u4F17\u53F7\u201C\u754C\u9762\
          \u201D\u62A5\u9053\uFF0C4\u65E5\u4E0A\u534810\u70B9\u5DE6\u53F3\uFF0C\u4E2D\
          \u56FD\u53D1\u6539\u59D4\u53CD\u5784\u65AD\u8C03\u67E5\u5C0F\u7EC4\u7A81\
          \u51FB\u67E5\u8BBF\u5954\u9A70\u4E0A\u6D77\u529E\u4E8B\u5904\uFF0C\u8C03\
          \u53D6\u6570\u636E\u6750\u6599\uFF0C\u5E76\u5BF9\u591A\u540D\u5954\u9A70\
          \u9AD8\u7BA1\u8FDB\u884C\u4E86\u7EA6\u8C08\u3002\u622A\u6B62\u6628\u65E5\
          \u665A9\u70B9\uFF0C\u5305\u62EC\u5317\u4EAC\u6885\u8D5B\u5FB7\u65AF-\u5954\
          \u9A70\u9500\u552E\u670D\u52A1\u6709\u9650\u516C\u53F8\u4E1C\u533A\u603B\
          \u7ECF\u7406\u5728\u5185\u7684\u591A\u540D\u7BA1\u7406\u4EBA\u5458\u4ECD\
          \u7559\u5728\u4E0A\u6D77\u529E\u516C\u5BA4\u5185\"<br>inputs = tokenizer(text,\
          \ max_length=1024, return_tensors=\"pt\")</p>\n<h1 id=\"generate-summary\"\
          >Generate Summary</h1>\n<p>summary_ids = model.generate(inputs[\"input_ids\"\
          ])<br>tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]</p>\n\
          <h1 id=\"model-output-\u53CD\u5784\u65AD\u8C03\u67E5\u5C0F\u7EC4\u7A81\u51FB\
          \u67E5\u8BBF\u5954\u9A70\u4E0A\u6D77\u529E\u4E8B\u5904\uFF0C\u5BF9\u591A\
          \u540D\u5954\u9A70\u9AD8\u7BA1\u8FDB\u884C\u7EA6\u8C08\">model Output: \u53CD\
          \u5784\u65AD\u8C03\u67E5\u5C0F\u7EC4\u7A81\u51FB\u67E5\u8BBF\u5954\u9A70\
          \u4E0A\u6D77\u529E\u4E8B\u5904\uFF0C\u5BF9\u591A\u540D\u5954\u9A70\u9AD8\
          \u7BA1\u8FDB\u884C\u7EA6\u8C08</h1>\n"
        raw: "where i test \"\u4F7F\u7528 Usage\"  on colab, i get follow error\r\n\
          \r\nModuleNotFoundError                       Traceback (most recent call\
          \ last)\r\n<ipython-input-14-b708ed12b150> in <module>\r\n      6 # 2. cd\
          \ Fengshenbang-LM/fengshen/examples/pegasus/\r\n      7 # and then you will\
          \ see the tokenizers_pegasus.py and data_utils.py which are needed by pegasus\
          \ model\r\n----> 8 from tokenizers_pegasus import PegasusTokenizer\r\n \
          \     9 \r\n     10 model = PegasusForConditionalGeneration.from_pretrained(\"\
          IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\")\r\n\r\n/content/Fengshenbang-LM/fengshen/examples/pegasus/Fengshenbang-LM/fengshen/examples/pegasus/Fengshenbang-LM/fengshen/examples/pegasus/tokenizers_pegasus.py\
          \ in <module>\r\n----> 1 from fengshen.examples.pegasus.data_utils import\
          \ (\r\n      2     _is_control,\r\n      3     _is_punctuation,\r\n    \
          \  4     _is_whitespace,\r\n      5     _is_chinese_char)\r\n\r\nModuleNotFoundError:\
          \ No module named 'fengshen'\r\n\r\nhere is my code\r\n!pip install transformers\r\
          \n!git clone https://github.com/IDEA-CCNL/Fengshenbang-LM\r\n%cd Fengshenbang-LM/fengshen/examples/pegasus/\r\
          \n%ls -l\r\n\r\nfrom transformers import PegasusForConditionalGeneration\r\
          \n# Need to download tokenizers_pegasus.py and other Python script from\
          \ Fengshenbang-LM github repo in advance,\r\n# or you can download tokenizers_pegasus.py\
          \ and data_utils.py in https://huggingface.co/IDEA-CCNL/Randeng_Pegasus_523M/tree/main\r\
          \n# Strongly recommend you git clone the Fengshenbang-LM repo:\r\n# 1. git\
          \ clone https://github.com/IDEA-CCNL/Fengshenbang-LM\r\n# 2. cd Fengshenbang-LM/fengshen/examples/pegasus/\r\
          \n# and then you will see the tokenizers_pegasus.py and data_utils.py which\
          \ are needed by pegasus model\r\nfrom tokenizers_pegasus import PegasusTokenizer\r\
          \n\r\nmodel = PegasusForConditionalGeneration.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\"\
          )\r\ntokenizer = PegasusTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\"\
          )\r\n\r\ntext = \"\u636E\u5FAE\u4FE1\u516C\u4F17\u53F7\u201C\u754C\u9762\
          \u201D\u62A5\u9053\uFF0C4\u65E5\u4E0A\u534810\u70B9\u5DE6\u53F3\uFF0C\u4E2D\
          \u56FD\u53D1\u6539\u59D4\u53CD\u5784\u65AD\u8C03\u67E5\u5C0F\u7EC4\u7A81\
          \u51FB\u67E5\u8BBF\u5954\u9A70\u4E0A\u6D77\u529E\u4E8B\u5904\uFF0C\u8C03\
          \u53D6\u6570\u636E\u6750\u6599\uFF0C\u5E76\u5BF9\u591A\u540D\u5954\u9A70\
          \u9AD8\u7BA1\u8FDB\u884C\u4E86\u7EA6\u8C08\u3002\u622A\u6B62\u6628\u65E5\
          \u665A9\u70B9\uFF0C\u5305\u62EC\u5317\u4EAC\u6885\u8D5B\u5FB7\u65AF-\u5954\
          \u9A70\u9500\u552E\u670D\u52A1\u6709\u9650\u516C\u53F8\u4E1C\u533A\u603B\
          \u7ECF\u7406\u5728\u5185\u7684\u591A\u540D\u7BA1\u7406\u4EBA\u5458\u4ECD\
          \u7559\u5728\u4E0A\u6D77\u529E\u516C\u5BA4\u5185\"\r\ninputs = tokenizer(text,\
          \ max_length=1024, return_tensors=\"pt\")\r\n\r\n# Generate Summary\r\n\
          summary_ids = model.generate(inputs[\"input_ids\"])\r\ntokenizer.batch_decode(summary_ids,\
          \ skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\r\n\r\
          \n# model Output: \u53CD\u5784\u65AD\u8C03\u67E5\u5C0F\u7EC4\u7A81\u51FB\
          \u67E5\u8BBF\u5954\u9A70\u4E0A\u6D77\u529E\u4E8B\u5904\uFF0C\u5BF9\u591A\
          \u540D\u5954\u9A70\u9AD8\u7BA1\u8FDB\u884C\u7EA6\u8C08"
        updatedAt: '2023-03-22T12:11:05.398Z'
      numEdits: 0
      reactions: []
    id: 641af059ec5b871c0bcb90b6
    type: comment
  author: candog
  content: "where i test \"\u4F7F\u7528 Usage\"  on colab, i get follow error\r\n\r\
    \nModuleNotFoundError                       Traceback (most recent call last)\r\
    \n<ipython-input-14-b708ed12b150> in <module>\r\n      6 # 2. cd Fengshenbang-LM/fengshen/examples/pegasus/\r\
    \n      7 # and then you will see the tokenizers_pegasus.py and data_utils.py\
    \ which are needed by pegasus model\r\n----> 8 from tokenizers_pegasus import\
    \ PegasusTokenizer\r\n      9 \r\n     10 model = PegasusForConditionalGeneration.from_pretrained(\"\
    IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\")\r\n\r\n/content/Fengshenbang-LM/fengshen/examples/pegasus/Fengshenbang-LM/fengshen/examples/pegasus/Fengshenbang-LM/fengshen/examples/pegasus/tokenizers_pegasus.py\
    \ in <module>\r\n----> 1 from fengshen.examples.pegasus.data_utils import (\r\n\
    \      2     _is_control,\r\n      3     _is_punctuation,\r\n      4     _is_whitespace,\r\
    \n      5     _is_chinese_char)\r\n\r\nModuleNotFoundError: No module named 'fengshen'\r\
    \n\r\nhere is my code\r\n!pip install transformers\r\n!git clone https://github.com/IDEA-CCNL/Fengshenbang-LM\r\
    \n%cd Fengshenbang-LM/fengshen/examples/pegasus/\r\n%ls -l\r\n\r\nfrom transformers\
    \ import PegasusForConditionalGeneration\r\n# Need to download tokenizers_pegasus.py\
    \ and other Python script from Fengshenbang-LM github repo in advance,\r\n# or\
    \ you can download tokenizers_pegasus.py and data_utils.py in https://huggingface.co/IDEA-CCNL/Randeng_Pegasus_523M/tree/main\r\
    \n# Strongly recommend you git clone the Fengshenbang-LM repo:\r\n# 1. git clone\
    \ https://github.com/IDEA-CCNL/Fengshenbang-LM\r\n# 2. cd Fengshenbang-LM/fengshen/examples/pegasus/\r\
    \n# and then you will see the tokenizers_pegasus.py and data_utils.py which are\
    \ needed by pegasus model\r\nfrom tokenizers_pegasus import PegasusTokenizer\r\
    \n\r\nmodel = PegasusForConditionalGeneration.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\"\
    )\r\ntokenizer = PegasusTokenizer.from_pretrained(\"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese\"\
    )\r\n\r\ntext = \"\u636E\u5FAE\u4FE1\u516C\u4F17\u53F7\u201C\u754C\u9762\u201D\
    \u62A5\u9053\uFF0C4\u65E5\u4E0A\u534810\u70B9\u5DE6\u53F3\uFF0C\u4E2D\u56FD\u53D1\
    \u6539\u59D4\u53CD\u5784\u65AD\u8C03\u67E5\u5C0F\u7EC4\u7A81\u51FB\u67E5\u8BBF\
    \u5954\u9A70\u4E0A\u6D77\u529E\u4E8B\u5904\uFF0C\u8C03\u53D6\u6570\u636E\u6750\
    \u6599\uFF0C\u5E76\u5BF9\u591A\u540D\u5954\u9A70\u9AD8\u7BA1\u8FDB\u884C\u4E86\
    \u7EA6\u8C08\u3002\u622A\u6B62\u6628\u65E5\u665A9\u70B9\uFF0C\u5305\u62EC\u5317\
    \u4EAC\u6885\u8D5B\u5FB7\u65AF-\u5954\u9A70\u9500\u552E\u670D\u52A1\u6709\u9650\
    \u516C\u53F8\u4E1C\u533A\u603B\u7ECF\u7406\u5728\u5185\u7684\u591A\u540D\u7BA1\
    \u7406\u4EBA\u5458\u4ECD\u7559\u5728\u4E0A\u6D77\u529E\u516C\u5BA4\u5185\"\r\n\
    inputs = tokenizer(text, max_length=1024, return_tensors=\"pt\")\r\n\r\n# Generate\
    \ Summary\r\nsummary_ids = model.generate(inputs[\"input_ids\"])\r\ntokenizer.batch_decode(summary_ids,\
    \ skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\r\n\r\n# model\
    \ Output: \u53CD\u5784\u65AD\u8C03\u67E5\u5C0F\u7EC4\u7A81\u51FB\u67E5\u8BBF\u5954\
    \u9A70\u4E0A\u6D77\u529E\u4E8B\u5904\uFF0C\u5BF9\u591A\u540D\u5954\u9A70\u9AD8\
    \u7BA1\u8FDB\u884C\u7EA6\u8C08"
  created_at: 2023-03-22 11:11:05+00:00
  edited: false
  hidden: false
  id: 641af059ec5b871c0bcb90b6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese
repo_type: model
status: open
target_branch: null
title: "the \"\u4F7F\u7528 Usage\" does not work"
