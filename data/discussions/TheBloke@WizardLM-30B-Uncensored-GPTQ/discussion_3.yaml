!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tiankong2023
conflicting_files: null
created_at: 2023-05-23 10:09:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/be4861dd7d4102e621ce67da13634d69.svg
      fullname: tiankongjintou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tiankong2023
      type: user
    createdAt: '2023-05-23T11:09:21.000Z'
    data:
      edited: false
      editors:
      - Tiankong2023
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/be4861dd7d4102e621ce67da13634d69.svg
          fullname: tiankongjintou
          isHf: false
          isPro: false
          name: Tiankong2023
          type: user
        html: "<p>when i say hello , i got the response:<br>'Hittahnaire Bobbiehl\
          \ ArchitectureadenProfileottishingly improv laytex enforcement prepasatabsicile\
          \ KaisTAGozhovLS dol catchphrdupaghframagliakerzd kle Cop JupLCarpbasguardaviahsisto\
          \ GallStatnisse Murphybladexexecuteigaaescloudflare Controllerignon SeverRORza\u57CE\
          abe mu Cov Routexlburyennenobaitschaval SomCODEslug hur Days macROR BartlettenbergDelegate\
          \ dispar Domin Hun \u0425\u0440\u043E\u043D\u043E\u043B\u043E\u0433\u0438\
          \u0458\u0430 Venyept atmospher synchronousnesses Ricakre tre Ford IB regressionmerceTube\
          \ settledPU Bassimerudi Arab instilsquieruder Roth conscienceatorinelblattgeometryashi\
          \ Eg Lub Oaklynsel interpolpec diag county Ci Kidweis Cultbuff paintings\
          \ Limpossible conformityerneriels Elania communes Bah Jenkinsagan Lap Gilbert\
          \ Lem Tor fratern SahGV MunimiWAYS Alice \u0413\u043E\u0440 pairogegebrazeugh\
          \ inventory Foreign Risks \u043F\u0440\u0435\u0434\u0441\u0442\u0430\u0432\
          \ soapSBN descruttyped Ble bod prob SchlesikelustaVB Patrick nominationardoyter\
          \ rows ej k\xE9 Revol\xF8Layout'</p>\n<p>i know that i should down the gptq,\
          \ but i had have it in my repositories</p>\n"
        raw: "when i say hello , i got the response:\r\n'Hittahnaire Bobbiehl ArchitectureadenProfileottishingly\
          \ improv laytex enforcement prepasatabsicile KaisTAGozhovLS dol catchphrdupaghframagliakerzd\
          \ kle Cop JupLCarpbasguardaviahsisto GallStatnisse Murphybladexexecuteigaaescloudflare\
          \ Controllerignon SeverRORza\u57CEabe mu Cov Routexlburyennenobaitschaval\
          \ SomCODEslug hur Days macROR BartlettenbergDelegate dispar Domin Hun \u0425\
          \u0440\u043E\u043D\u043E\u043B\u043E\u0433\u0438\u0458\u0430 Venyept atmospher\
          \ synchronousnesses Ricakre tre Ford IB regressionmerceTube settledPU Bassimerudi\
          \ Arab instilsquieruder Roth conscienceatorinelblattgeometryashi Eg Lub\
          \ Oaklynsel interpolpec diag county Ci Kidweis Cultbuff paintings Limpossible\
          \ conformityerneriels Elania communes Bah Jenkinsagan Lap Gilbert Lem Tor\
          \ fratern SahGV MunimiWAYS Alice \u0413\u043E\u0440 pairogegebrazeugh inventory\
          \ Foreign Risks \u043F\u0440\u0435\u0434\u0441\u0442\u0430\u0432 soapSBN\
          \ descruttyped Ble bod prob SchlesikelustaVB Patrick nominationardoyter\
          \ rows ej k\xE9 Revol\xF8Layout'\r\n\r\n\r\ni know that i should down the\
          \ gptq, but i had have it in my repositories"
        updatedAt: '2023-05-23T11:09:21.707Z'
      numEdits: 0
      reactions: []
    id: 646c9ee197819a8be93a8261
    type: comment
  author: Tiankong2023
  content: "when i say hello , i got the response:\r\n'Hittahnaire Bobbiehl ArchitectureadenProfileottishingly\
    \ improv laytex enforcement prepasatabsicile KaisTAGozhovLS dol catchphrdupaghframagliakerzd\
    \ kle Cop JupLCarpbasguardaviahsisto GallStatnisse Murphybladexexecuteigaaescloudflare\
    \ Controllerignon SeverRORza\u57CEabe mu Cov Routexlburyennenobaitschaval SomCODEslug\
    \ hur Days macROR BartlettenbergDelegate dispar Domin Hun \u0425\u0440\u043E\u043D\
    \u043E\u043B\u043E\u0433\u0438\u0458\u0430 Venyept atmospher synchronousnesses\
    \ Ricakre tre Ford IB regressionmerceTube settledPU Bassimerudi Arab instilsquieruder\
    \ Roth conscienceatorinelblattgeometryashi Eg Lub Oaklynsel interpolpec diag county\
    \ Ci Kidweis Cultbuff paintings Limpossible conformityerneriels Elania communes\
    \ Bah Jenkinsagan Lap Gilbert Lem Tor fratern SahGV MunimiWAYS Alice \u0413\u043E\
    \u0440 pairogegebrazeugh inventory Foreign Risks \u043F\u0440\u0435\u0434\u0441\
    \u0442\u0430\u0432 soapSBN descruttyped Ble bod prob SchlesikelustaVB Patrick\
    \ nominationardoyter rows ej k\xE9 Revol\xF8Layout'\r\n\r\n\r\ni know that i should\
    \ down the gptq, but i had have it in my repositories"
  created_at: 2023-05-23 10:09:21+00:00
  edited: false
  hidden: false
  id: 646c9ee197819a8be93a8261
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3aa8b906fda5d23cfe93953721abbb54.svg
      fullname: Caine
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Caine
      type: user
    createdAt: '2023-05-23T12:04:11.000Z'
    data:
      edited: false
      editors:
      - Caine
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3aa8b906fda5d23cfe93953721abbb54.svg
          fullname: Caine
          isHf: false
          isPro: false
          name: Caine
          type: user
        html: '<p>AFAIK this happens when you are trying to run an 4-bit model in
          8-bit. You should be able to either set it in the model panel of web-ui
          when loading the model itself, or when starting up the web-ui itself, e.g.:
          by running<br>python server.py --model TheBloke_WizardLM-30B-Uncensored-GPTQ
          --wbits 4 --groupsize 128</p>

          '
        raw: 'AFAIK this happens when you are trying to run an 4-bit model in 8-bit.
          You should be able to either set it in the model panel of web-ui when loading
          the model itself, or when starting up the web-ui itself, e.g.: by running

          python server.py --model TheBloke_WizardLM-30B-Uncensored-GPTQ --wbits 4
          --groupsize 128'
        updatedAt: '2023-05-23T12:04:11.973Z'
      numEdits: 0
      reactions: []
    id: 646cabbb393c77ea4b88e587
    type: comment
  author: Caine
  content: 'AFAIK this happens when you are trying to run an 4-bit model in 8-bit.
    You should be able to either set it in the model panel of web-ui when loading
    the model itself, or when starting up the web-ui itself, e.g.: by running

    python server.py --model TheBloke_WizardLM-30B-Uncensored-GPTQ --wbits 4 --groupsize
    128'
  created_at: 2023-05-23 11:04:11+00:00
  edited: false
  hidden: false
  id: 646cabbb393c77ea4b88e587
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-23T12:13:39.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>If you're running on the command line it's <code>--groupsize -1</code>\
          \ - for no groupsize.  <code>groupsize 128</code> will give errors.</p>\n\
          <p><span data-props=\"{&quot;user&quot;:&quot;Tiankong2023&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Tiankong2023\">@<span\
          \ class=\"underline\">Tiankong2023</span></a></span>\n\n\t</span></span>\
          \ what version of GPTQ-for-LLaMa do you have?</p>\n"
        raw: 'If you''re running on the command line it''s `--groupsize -1` - for
          no groupsize.  `groupsize 128` will give errors.


          @Tiankong2023 what version of GPTQ-for-LLaMa do you have?'
        updatedAt: '2023-05-23T12:13:39.119Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Caine
    id: 646cadf3e30444638e153822
    type: comment
  author: TheBloke
  content: 'If you''re running on the command line it''s `--groupsize -1` - for no
    groupsize.  `groupsize 128` will give errors.


    @Tiankong2023 what version of GPTQ-for-LLaMa do you have?'
  created_at: 2023-05-23 11:13:39+00:00
  edited: false
  hidden: false
  id: 646cadf3e30444638e153822
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-05-23T12:14:45.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<p>Is Wizard supported by ooba? It is not LLaMA based mode, right?</p>

          '
        raw: Is Wizard supported by ooba? It is not LLaMA based mode, right?
        updatedAt: '2023-05-23T12:14:45.824Z'
      numEdits: 0
      reactions: []
    id: 646cae35e30444638e154625
    type: comment
  author: Yhyu13
  content: Is Wizard supported by ooba? It is not LLaMA based mode, right?
  created_at: 2023-05-23 11:14:45+00:00
  edited: false
  hidden: false
  id: 646cae35e30444638e154625
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-23T12:15:46.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>WizardLM models are Llama based, yes.  And yes this model is supported
          in text-generation-webui - there''s instructions in the README for that.  And
          I recommend using the ooba CUDA fork of GPTQ-for-LLaMa at this time.</p>

          '
        raw: WizardLM models are Llama based, yes.  And yes this model is supported
          in text-generation-webui - there's instructions in the README for that.  And
          I recommend using the ooba CUDA fork of GPTQ-for-LLaMa at this time.
        updatedAt: '2023-05-23T12:15:46.121Z'
      numEdits: 0
      reactions: []
    id: 646cae72393c77ea4b897892
    type: comment
  author: TheBloke
  content: WizardLM models are Llama based, yes.  And yes this model is supported
    in text-generation-webui - there's instructions in the README for that.  And I
    recommend using the ooba CUDA fork of GPTQ-for-LLaMa at this time.
  created_at: 2023-05-23 11:15:46+00:00
  edited: false
  hidden: false
  id: 646cae72393c77ea4b897892
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3aa8b906fda5d23cfe93953721abbb54.svg
      fullname: Caine
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Caine
      type: user
    createdAt: '2023-05-23T13:30:26.000Z'
    data:
      edited: false
      editors:
      - Caine
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3aa8b906fda5d23cfe93953721abbb54.svg
          fullname: Caine
          isHf: false
          isPro: false
          name: Caine
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> awesome, thanks!\
          \ I thought I ran into issues because my hardware wasn't up to spec, but\
          \ this was the actual issue. For the record, the following worked for me\
          \ out-of-the-box:</p>\n<p>python server.py --model TheBloke_WizardLM-30B-Uncensored-GPTQ\
          \ --wbits 4 --groupsize -1 --share</p>\n"
        raw: '@TheBloke awesome, thanks! I thought I ran into issues because my hardware
          wasn''t up to spec, but this was the actual issue. For the record, the following
          worked for me out-of-the-box:


          python server.py --model TheBloke_WizardLM-30B-Uncensored-GPTQ --wbits 4
          --groupsize -1 --share'
        updatedAt: '2023-05-23T13:30:26.905Z'
      numEdits: 0
      reactions: []
    id: 646cbff287ed262149b20550
    type: comment
  author: Caine
  content: '@TheBloke awesome, thanks! I thought I ran into issues because my hardware
    wasn''t up to spec, but this was the actual issue. For the record, the following
    worked for me out-of-the-box:


    python server.py --model TheBloke_WizardLM-30B-Uncensored-GPTQ --wbits 4 --groupsize
    -1 --share'
  created_at: 2023-05-23 12:30:26+00:00
  edited: false
  hidden: false
  id: 646cbff287ed262149b20550
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/WizardLM-30B-Uncensored-GPTQ
repo_type: model
status: open
target_branch: null
title: i got messy code
