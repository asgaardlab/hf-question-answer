!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ilnurshams
conflicting_files: null
created_at: 2023-05-25 12:36:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aeb28ba60e2961c979bf0787bc90e40c.svg
      fullname: ilnurshams
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilnurshams
      type: user
    createdAt: '2023-05-25T13:36:42.000Z'
    data:
      edited: false
      editors:
      - ilnurshams
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aeb28ba60e2961c979bf0787bc90e40c.svg
          fullname: ilnurshams
          isHf: false
          isPro: false
          name: ilnurshams
          type: user
        html: '<p>Help needed!</p>

          <p>When I start via oobabooga_windows start.bat, it gives me the following
          error:</p>

          <p>bin C:\Users\Admin\Desktop\oobabooga_windows\installer_files\env\lib\site-packages\bitsandbytes\libbitsandbytes_cuda117.dll<br>INFO:Loading
          TheBloke_WizardLM-30B-Uncensored-GPTQ...<br>Traceback (most recent call
          last):<br>  File "C:\Users\Admin\Desktop\oobabooga_windows\text-generation-webui\server.py",
          line 1081, in <br>    shared.model, shared.tokenizer = load_model(shared.model_name)<br>  File
          "C:\Users\Admin\Desktop\oobabooga_windows\text-generation-webui\modules\models.py",
          line 95, in load_model<br>    output = load_func(model_name)<br>  File "C:\Users\Admin\Desktop\oobabooga_windows\text-generation-webui\modules\models.py",
          line 153, in huggingface_loader<br>    model = LoaderClass.from_pretrained(Path(f"{shared.args.model_dir}/{model_name}"),
          low_cpu_mem_usage=True, torch_dtype=torch.bfloat16 if shared.args.bf16 else
          torch.float16, trust_remote_code=shared.args.trust_remote_code)<br>  File
          "C:\Users\Admin\Desktop\oobabooga_windows\installer_files\env\lib\site-packages\transformers\models\auto\auto_factory.py",
          line 472, in from_pretrained<br>    return model_class.from_pretrained(<br>  File
          "C:\Users\Admin\Desktop\oobabooga_windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 2406, in from_pretrained<br>    raise EnvironmentError(<br>OSError:
          Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or
          flax_model.msgpack found in directory models\TheBloke_WizardLM-30B-Uncensored-GPTQ.</p>

          <p>Done!<br>Press any key to continue . . .<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/LVoNn_UuOtpwtemww_J9a.png"><img
          alt="Screenshot 2023-05-25 163428.png" src="https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/LVoNn_UuOtpwtemww_J9a.png"></a></p>

          '
        raw: "Help needed!\r\n\r\nWhen I start via oobabooga_windows start.bat, it\
          \ gives me the following error:\r\n\r\nbin C:\\Users\\Admin\\Desktop\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll\r\
          \nINFO:Loading TheBloke_WizardLM-30B-Uncensored-GPTQ...\r\nTraceback (most\
          \ recent call last):\r\n  File \"C:\\Users\\Admin\\Desktop\\oobabooga_windows\\\
          text-generation-webui\\server.py\", line 1081, in <module>\r\n    shared.model,\
          \ shared.tokenizer = load_model(shared.model_name)\r\n  File \"C:\\Users\\\
          Admin\\Desktop\\oobabooga_windows\\text-generation-webui\\modules\\models.py\"\
          , line 95, in load_model\r\n    output = load_func(model_name)\r\n  File\
          \ \"C:\\Users\\Admin\\Desktop\\oobabooga_windows\\text-generation-webui\\\
          modules\\models.py\", line 153, in huggingface_loader\r\n    model = LoaderClass.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
          \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\r\
          \n  File \"C:\\Users\\Admin\\Desktop\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\",\
          \ line 472, in from_pretrained\r\n    return model_class.from_pretrained(\r\
          \n  File \"C:\\Users\\Admin\\Desktop\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\modeling_utils.py\", line 2406, in\
          \ from_pretrained\r\n    raise EnvironmentError(\r\nOSError: Error no file\
          \ named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models\\TheBloke_WizardLM-30B-Uncensored-GPTQ.\r\n\r\
          \nDone!\r\nPress any key to continue . . .\r\n![Screenshot 2023-05-25 163428.png](https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/LVoNn_UuOtpwtemww_J9a.png)\r\
          \n"
        updatedAt: '2023-05-25T13:36:42.036Z'
      numEdits: 0
      reactions: []
    id: 646f646a041e48e1c4726fee
    type: comment
  author: ilnurshams
  content: "Help needed!\r\n\r\nWhen I start via oobabooga_windows start.bat, it gives\
    \ me the following error:\r\n\r\nbin C:\\Users\\Admin\\Desktop\\oobabooga_windows\\\
    installer_files\\env\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll\r\
    \nINFO:Loading TheBloke_WizardLM-30B-Uncensored-GPTQ...\r\nTraceback (most recent\
    \ call last):\r\n  File \"C:\\Users\\Admin\\Desktop\\oobabooga_windows\\text-generation-webui\\\
    server.py\", line 1081, in <module>\r\n    shared.model, shared.tokenizer = load_model(shared.model_name)\r\
    \n  File \"C:\\Users\\Admin\\Desktop\\oobabooga_windows\\text-generation-webui\\\
    modules\\models.py\", line 95, in load_model\r\n    output = load_func(model_name)\r\
    \n  File \"C:\\Users\\Admin\\Desktop\\oobabooga_windows\\text-generation-webui\\\
    modules\\models.py\", line 153, in huggingface_loader\r\n    model = LoaderClass.from_pretrained(Path(f\"\
    {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
    \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\r\
    \n  File \"C:\\Users\\Admin\\Desktop\\oobabooga_windows\\installer_files\\env\\\
    lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 472, in\
    \ from_pretrained\r\n    return model_class.from_pretrained(\r\n  File \"C:\\\
    Users\\Admin\\Desktop\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\modeling_utils.py\", line 2406, in from_pretrained\r\n    raise\
    \ EnvironmentError(\r\nOSError: Error no file named pytorch_model.bin, tf_model.h5,\
    \ model.ckpt.index or flax_model.msgpack found in directory models\\TheBloke_WizardLM-30B-Uncensored-GPTQ.\r\
    \n\r\nDone!\r\nPress any key to continue . . .\r\n![Screenshot 2023-05-25 163428.png](https://cdn-uploads.huggingface.co/production/uploads/6468e2d1188ca2e6bc591896/LVoNn_UuOtpwtemww_J9a.png)\r\
    \n"
  created_at: 2023-05-25 12:36:42+00:00
  edited: false
  hidden: false
  id: 646f646a041e48e1c4726fee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a7ac4351c4efb691f9eef3ecc7f0467b.svg
      fullname: Jeff
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheStamp
      type: user
    createdAt: '2023-05-25T14:27:59.000Z'
    data:
      edited: false
      editors:
      - TheStamp
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a7ac4351c4efb691f9eef3ecc7f0467b.svg
          fullname: Jeff
          isHf: false
          isPro: false
          name: TheStamp
          type: user
        html: '<p>it''s complaining that it can''t find a proper model in the folder.</p>

          <p>switch to a model that you know works, then use the built-in model downloader
          to download the model you want.</p>

          '
        raw: 'it''s complaining that it can''t find a proper model in the folder.


          switch to a model that you know works, then use the built-in model downloader
          to download the model you want.'
        updatedAt: '2023-05-25T14:27:59.817Z'
      numEdits: 0
      reactions: []
    id: 646f706fbc42f4b0022e46ac
    type: comment
  author: TheStamp
  content: 'it''s complaining that it can''t find a proper model in the folder.


    switch to a model that you know works, then use the built-in model downloader
    to download the model you want.'
  created_at: 2023-05-25 13:27:59+00:00
  edited: false
  hidden: false
  id: 646f706fbc42f4b0022e46ac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bc303770417db89dea04196dc6e00c81.svg
      fullname: Guru Prakash
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guruprk
      type: user
    createdAt: '2023-05-26T06:03:30.000Z'
    data:
      edited: false
      editors:
      - guruprk
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bc303770417db89dea04196dc6e00c81.svg
          fullname: Guru Prakash
          isHf: false
          isPro: false
          name: guruprk
          type: user
        html: '<p>i downloaded the model using the built in model downloader. still
          getting the same error</p>

          '
        raw: i downloaded the model using the built in model downloader. still getting
          the same error
        updatedAt: '2023-05-26T06:03:30.114Z'
      numEdits: 0
      reactions: []
    id: 64704bb21f0e7ee7fb144858
    type: comment
  author: guruprk
  content: i downloaded the model using the built in model downloader. still getting
    the same error
  created_at: 2023-05-26 05:03:30+00:00
  edited: false
  hidden: false
  id: 64704bb21f0e7ee7fb144858
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-26T08:04:55.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>This error happens when you''ve not set GPTQ parameters for the
          model. Please see the README.</p>

          '
        raw: This error happens when you've not set GPTQ parameters for the model.
          Please see the README.
        updatedAt: '2023-05-26T08:04:55.644Z'
      numEdits: 0
      reactions: []
    id: 647068271f0e7ee7fb1646b9
    type: comment
  author: TheBloke
  content: This error happens when you've not set GPTQ parameters for the model. Please
    see the README.
  created_at: 2023-05-26 07:04:55+00:00
  edited: false
  hidden: false
  id: 647068271f0e7ee7fb1646b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bc303770417db89dea04196dc6e00c81.svg
      fullname: Guru Prakash
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guruprk
      type: user
    createdAt: '2023-05-26T08:43:16.000Z'
    data:
      edited: false
      editors:
      - guruprk
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bc303770417db89dea04196dc6e00c81.svg
          fullname: Guru Prakash
          isHf: false
          isPro: false
          name: guruprk
          type: user
        html: '<p>Update: i was trying to deploy this model on runpod''s oobabooga
          ui image. that image does not have the latest version of text-gen-ui, which
          is the reason for this error, at least on my side. not sure about OP</p>

          '
        raw: 'Update: i was trying to deploy this model on runpod''s oobabooga ui
          image. that image does not have the latest version of text-gen-ui, which
          is the reason for this error, at least on my side. not sure about OP'
        updatedAt: '2023-05-26T08:43:16.010Z'
      numEdits: 0
      reactions: []
    id: 64707124806c7d87fa12cf09
    type: comment
  author: guruprk
  content: 'Update: i was trying to deploy this model on runpod''s oobabooga ui image.
    that image does not have the latest version of text-gen-ui, which is the reason
    for this error, at least on my side. not sure about OP'
  created_at: 2023-05-26 07:43:16+00:00
  edited: false
  hidden: false
  id: 64707124806c7d87fa12cf09
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-26T08:48:17.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Ah yeah, in fact the Runpod text-gen-ui template doesn''t support
          GPTQ at all I think.</p>

          <p>I have a Runpod template which supports GPTQ, GGML with GPU acceleration,
          and which always uses the latest version of text-generation-webui : <a rel="nofollow"
          href="https://runpod.io/gsc?template=qk29nkmbfr&amp;ref=eexqfacd">https://runpod.io/gsc?template=qk29nkmbfr&amp;ref=eexqfacd</a></p>

          '
        raw: 'Ah yeah, in fact the Runpod text-gen-ui template doesn''t support GPTQ
          at all I think.


          I have a Runpod template which supports GPTQ, GGML with GPU acceleration,
          and which always uses the latest version of text-generation-webui : https://runpod.io/gsc?template=qk29nkmbfr&ref=eexqfacd'
        updatedAt: '2023-05-26T08:55:01.203Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - guruprk
    id: 64707251806c7d87fa12e34a
    type: comment
  author: TheBloke
  content: 'Ah yeah, in fact the Runpod text-gen-ui template doesn''t support GPTQ
    at all I think.


    I have a Runpod template which supports GPTQ, GGML with GPU acceleration, and
    which always uses the latest version of text-generation-webui : https://runpod.io/gsc?template=qk29nkmbfr&ref=eexqfacd'
  created_at: 2023-05-26 07:48:17+00:00
  edited: true
  hidden: false
  id: 64707251806c7d87fa12e34a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bc303770417db89dea04196dc6e00c81.svg
      fullname: Guru Prakash
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guruprk
      type: user
    createdAt: '2023-05-26T09:08:25.000Z'
    data:
      edited: false
      editors:
      - guruprk
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bc303770417db89dea04196dc6e00c81.svg
          fullname: Guru Prakash
          isHf: false
          isPro: false
          name: guruprk
          type: user
        html: '<p>Dude thats sick! Thanks!</p>

          '
        raw: Dude thats sick! Thanks!
        updatedAt: '2023-05-26T09:08:25.975Z'
      numEdits: 0
      reactions: []
    id: 64707709806c7d87fa133a3f
    type: comment
  author: guruprk
  content: Dude thats sick! Thanks!
  created_at: 2023-05-26 08:08:25+00:00
  edited: false
  hidden: false
  id: 64707709806c7d87fa133a3f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
      fullname: Rafa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rafa9
      type: user
    createdAt: '2023-05-26T10:41:17.000Z'
    data:
      edited: true
      editors:
      - rafa9
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
          fullname: Rafa
          isHf: false
          isPro: false
          name: rafa9
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> I tried with\
          \ your template on runpod and it still shows similar error on oobagooba\
          \ UI: </p>\n<pre><code>File \u201C/root/text-generation-webui/server.py\u201D\
          , line 71, in load_model_wrapper\nshared.model, shared.tokenizer = load_model(shared.model_name)\n\
          File \u201C/root/text-generation-webui/modules/models.py\u201D, line 95,\
          \ in load_model\noutput = load_func(model_name)\nFile \u201C/root/text-generation-webui/modules/models.py\u201D\
          , line 153, in huggingface_loader\nmodel = LoaderClass.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
          \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\n\
          File \u201C/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u201D\
          , line 471, in from_pretrained\nreturn model_class.from_pretrained(\nFile\
          \ \u201C/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u201D\
          , line 2405, in from_pretrained\nraise EnvironmentError(\nOSError: Error\
          \ no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models/TheBloke_WizardLM-30B-Uncensored-GPTQ.\n</code></pre>\n"
        raw: "@TheBloke I tried with your template on runpod and it still shows similar\
          \ error on oobagooba UI: \n```\nFile \u201C/root/text-generation-webui/server.py\u201D\
          , line 71, in load_model_wrapper\nshared.model, shared.tokenizer = load_model(shared.model_name)\n\
          File \u201C/root/text-generation-webui/modules/models.py\u201D, line 95,\
          \ in load_model\noutput = load_func(model_name)\nFile \u201C/root/text-generation-webui/modules/models.py\u201D\
          , line 153, in huggingface_loader\nmodel = LoaderClass.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
          \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\n\
          File \u201C/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u201D\
          , line 471, in from_pretrained\nreturn model_class.from_pretrained(\nFile\
          \ \u201C/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u201D\
          , line 2405, in from_pretrained\nraise EnvironmentError(\nOSError: Error\
          \ no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models/TheBloke_WizardLM-30B-Uncensored-GPTQ.\n```"
        updatedAt: '2023-05-26T10:41:45.084Z'
      numEdits: 1
      reactions: []
    id: 64708ccd1f0e7ee7fb18c696
    type: comment
  author: rafa9
  content: "@TheBloke I tried with your template on runpod and it still shows similar\
    \ error on oobagooba UI: \n```\nFile \u201C/root/text-generation-webui/server.py\u201D\
    , line 71, in load_model_wrapper\nshared.model, shared.tokenizer = load_model(shared.model_name)\n\
    File \u201C/root/text-generation-webui/modules/models.py\u201D, line 95, in load_model\n\
    output = load_func(model_name)\nFile \u201C/root/text-generation-webui/modules/models.py\u201D\
    , line 153, in huggingface_loader\nmodel = LoaderClass.from_pretrained(Path(f\"\
    {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
    \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\n\
    File \u201C/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u201D\
    , line 471, in from_pretrained\nreturn model_class.from_pretrained(\nFile \u201C\
    /usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u201D,\
    \ line 2405, in from_pretrained\nraise EnvironmentError(\nOSError: Error no file\
    \ named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
    \ found in directory models/TheBloke_WizardLM-30B-Uncensored-GPTQ.\n```"
  created_at: 2023-05-26 09:41:17+00:00
  edited: true
  hidden: false
  id: 64708ccd1f0e7ee7fb18c696
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-26T10:43:40.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>This happens because you didn''t set the GPTQ parameters. Please
          follow the instructions in the README - they''re in both the README for
          this model, and the README for the Runpod template.</p>

          <p>Make sure to set the GPTQ params and then "Save settings for this model"
          and "reload this model"</p>

          <p>Fairly soon I will update the template to use AutoGPTQ and then you won''t
          need to set GPTQ parameters manually.  But for now you still do.</p>

          '
        raw: 'This happens because you didn''t set the GPTQ parameters. Please follow
          the instructions in the README - they''re in both the README for this model,
          and the README for the Runpod template.


          Make sure to set the GPTQ params and then "Save settings for this model"
          and "reload this model"


          Fairly soon I will update the template to use AutoGPTQ and then you won''t
          need to set GPTQ parameters manually.  But for now you still do.'
        updatedAt: '2023-05-26T10:43:40.112Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - rafa9
    id: 64708d5c3df93fddece02815
    type: comment
  author: TheBloke
  content: 'This happens because you didn''t set the GPTQ parameters. Please follow
    the instructions in the README - they''re in both the README for this model, and
    the README for the Runpod template.


    Make sure to set the GPTQ params and then "Save settings for this model" and "reload
    this model"


    Fairly soon I will update the template to use AutoGPTQ and then you won''t need
    to set GPTQ parameters manually.  But for now you still do.'
  created_at: 2023-05-26 09:43:40+00:00
  edited: false
  hidden: false
  id: 64708d5c3df93fddece02815
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
      fullname: Rafa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rafa9
      type: user
    createdAt: '2023-05-26T10:45:37.000Z'
    data:
      edited: false
      editors:
      - rafa9
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
          fullname: Rafa
          isHf: false
          isPro: false
          name: rafa9
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> Thank you! is\
          \ there a way to create an API endpoint and make http request instead of\
          \ using the UI?</p>\n"
        raw: '@TheBloke Thank you! is there a way to create an API endpoint and make
          http request instead of using the UI?'
        updatedAt: '2023-05-26T10:45:37.402Z'
      numEdits: 0
      reactions: []
    id: 64708dd19fe78d69a8ae6fa3
    type: comment
  author: rafa9
  content: '@TheBloke Thank you! is there a way to create an API endpoint and make
    http request instead of using the UI?'
  created_at: 2023-05-26 09:45:37+00:00
  edited: false
  hidden: false
  id: 64708dd19fe78d69a8ae6fa3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-26T10:46:58.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah I made a template for that too!</p>

          <p><a rel="nofollow" href="https://runpod.io/gsc?template=f1pf20op0z&amp;ref=eexqfacd">https://runpod.io/gsc?template=f1pf20op0z&amp;ref=eexqfacd</a></p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/SiuDGAVwHE6tSavGqRzzB.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/SiuDGAVwHE6tSavGqRzzB.png"></a></p>

          <p>It''s using the same container as "One-Click UI" so it should work exactly
          the same. The difference is it opens the API port so you can access remotely,
          and I included some instructions on using it in the README shown above</p>

          '
        raw: 'Yeah I made a template for that too!


          https://runpod.io/gsc?template=f1pf20op0z&ref=eexqfacd


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/SiuDGAVwHE6tSavGqRzzB.png)


          It''s using the same container as "One-Click UI" so it should work exactly
          the same. The difference is it opens the API port so you can access remotely,
          and I included some instructions on using it in the README shown above'
        updatedAt: '2023-05-26T10:46:58.163Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - rafa9
    id: 64708e229fe78d69a8ae75a7
    type: comment
  author: TheBloke
  content: 'Yeah I made a template for that too!


    https://runpod.io/gsc?template=f1pf20op0z&ref=eexqfacd


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/SiuDGAVwHE6tSavGqRzzB.png)


    It''s using the same container as "One-Click UI" so it should work exactly the
    same. The difference is it opens the API port so you can access remotely, and
    I included some instructions on using it in the README shown above'
  created_at: 2023-05-26 09:46:58+00:00
  edited: false
  hidden: false
  id: 64708e229fe78d69a8ae75a7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
      fullname: Rafa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rafa9
      type: user
    createdAt: '2023-05-26T10:51:21.000Z'
    data:
      edited: false
      editors:
      - rafa9
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
          fullname: Rafa
          isHf: false
          isPro: false
          name: rafa9
          type: user
        html: '<p>The GOAT! TYSM</p>

          '
        raw: The GOAT! TYSM
        updatedAt: '2023-05-26T10:51:21.819Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - TheBloke
    id: 64708f299fe78d69a8ae85b9
    type: comment
  author: rafa9
  content: The GOAT! TYSM
  created_at: 2023-05-26 09:51:21+00:00
  edited: false
  hidden: false
  id: 64708f299fe78d69a8ae85b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
      fullname: Rafa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rafa9
      type: user
    createdAt: '2023-05-27T17:16:07.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/04b2b2e284c9479a4e4a1ab6df5f526c.svg
          fullname: Rafa
          isHf: false
          isPro: false
          name: rafa9
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-05-27T17:38:17.974Z'
      numEdits: 0
      reactions: []
    id: 64723ad7c27f74a0eba73036
    type: comment
  author: rafa9
  content: This comment has been hidden
  created_at: 2023-05-27 16:16:07+00:00
  edited: true
  hidden: true
  id: 64723ad7c27f74a0eba73036
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/aeb28ba60e2961c979bf0787bc90e40c.svg
      fullname: ilnurshams
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilnurshams
      type: user
    createdAt: '2023-05-27T18:48:38.000Z'
    data:
      status: closed
    id: 647250865afd6a6965895c39
    type: status-change
  author: ilnurshams
  created_at: 2023-05-27 17:48:38+00:00
  id: 647250865afd6a6965895c39
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: TheBloke/WizardLM-30B-Uncensored-GPTQ
repo_type: model
status: closed
target_branch: null
title: 'Error on start - raise EnvironmentError( OSError: Error no file named pytorch_model.bin,
  tf_model.h5, model.ckpt.index or flax_model.msgpack'
