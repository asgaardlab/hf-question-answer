!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Delta36652
conflicting_files: null
created_at: 2023-05-16 16:42:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4677ae94058f95d01935153de2a23e.svg
      fullname: Delta36652
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delta36652
      type: user
    createdAt: '2023-05-16T17:42:58.000Z'
    data:
      edited: false
      editors:
      - Delta36652
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4677ae94058f95d01935153de2a23e.svg
          fullname: Delta36652
          isHf: false
          isPro: false
          name: Delta36652
          type: user
        html: '<p>llama.cpp now includes GPU offloading support, but it requires for
          model file to be represented in new GGML file format.</p>

          '
        raw: llama.cpp now includes GPU offloading support, but it requires for model
          file to be represented in new GGML file format.
        updatedAt: '2023-05-16T17:42:58.679Z'
      numEdits: 0
      reactions: []
    id: 6463c0a228fafa56c3f15746
    type: comment
  author: Delta36652
  content: llama.cpp now includes GPU offloading support, but it requires for model
    file to be represented in new GGML file format.
  created_at: 2023-05-16 16:42:58+00:00
  edited: false
  hidden: false
  id: 6463c0a228fafa56c3f15746
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bd6d702643cd5875d6a43e3369945ac5.svg
      fullname: Metal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: MetaIX
      type: user
    createdAt: '2023-05-18T15:42:48.000Z'
    data:
      edited: false
      editors:
      - MetaIX
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bd6d702643cd5875d6a43e3369945ac5.svg
          fullname: Metal
          isHf: false
          isPro: false
          name: MetaIX
          type: user
        html: '<p>Updating today</p>

          '
        raw: Updating today
        updatedAt: '2023-05-18T15:42:48.779Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - Sunija
        - b-t
    id: 646647783b99ed9970fba40f
    type: comment
  author: MetaIX
  content: Updating today
  created_at: 2023-05-18 14:42:48+00:00
  edited: false
  hidden: false
  id: 646647783b99ed9970fba40f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/42b26a17a6c107a1a47671b6eeb06416.svg
      fullname: Bertram Truong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: b-t
      type: user
    createdAt: '2023-05-19T05:40:57.000Z'
    data:
      edited: false
      editors:
      - b-t
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/42b26a17a6c107a1a47671b6eeb06416.svg
          fullname: Bertram Truong
          isHf: false
          isPro: false
          name: b-t
          type: user
        html: '<p>Can''t wait!</p>

          '
        raw: Can't wait!
        updatedAt: '2023-05-19T05:40:57.104Z'
      numEdits: 0
      reactions: []
    id: 64670be9e65dce8e43358f08
    type: comment
  author: b-t
  content: Can't wait!
  created_at: 2023-05-19 04:40:57+00:00
  edited: false
  hidden: false
  id: 64670be9e65dce8e43358f08
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-21T22:42:38.000Z'
    data:
      edited: false
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8812722563743591
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: '<p>Second this. Please convert to GGML3 with the new K  Quants.</p>

          '
        raw: Second this. Please convert to GGML3 with the new K  Quants.
        updatedAt: '2023-06-21T22:42:38.585Z'
      numEdits: 0
      reactions: []
    id: 64937cde89fefd775ac32df8
    type: comment
  author: vdruts
  content: Second this. Please convert to GGML3 with the new K  Quants.
  created_at: 2023-06-21 21:42:38+00:00
  edited: false
  hidden: false
  id: 64937cde89fefd775ac32df8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-23T21:08:29.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9714987874031067
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I tried to do k-quants for this model myself the other day because
          I was asked to, but it''s not currently possible.</p>

          <p>There''s currently an issue that prevents making k-quants with certain
          models, models which feature tensors that aren''t divisible by 256.  </p>

          <p>That affects two types of Llama models:</p>

          <ul>

          <li>Ones that had a vocab size of 32001 instead of 32000 (because of the
          addition of a PAD token - which I think was an early hack which got copied
          even where it''s not needed)</li>

          <li>Models based on OpenAssistant which have a vocab of 32016 tokens.</li>

          </ul>

          <p>This model is an example of the latter, so it won''t be possible to make
          k-quants until this is resolved: <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/issues/1919#issuecomment-1599484900">https://github.com/ggerganov/llama.cpp/issues/1919#issuecomment-1599484900</a></p>

          '
        raw: "I tried to do k-quants for this model myself the other day because I\
          \ was asked to, but it's not currently possible.\n\nThere's currently an\
          \ issue that prevents making k-quants with certain models, models which\
          \ feature tensors that aren't divisible by 256.  \n\nThat affects two types\
          \ of Llama models:\n- Ones that had a vocab size of 32001 instead of 32000\
          \ (because of the addition of a PAD token - which I think was an early hack\
          \ which got copied even where it's not needed)\n- Models based on OpenAssistant\
          \ which have a vocab of 32016 tokens.  \n\nThis model is an example of the\
          \ latter, so it won't be possible to make k-quants until this is resolved:\
          \ https://github.com/ggerganov/llama.cpp/issues/1919#issuecomment-1599484900"
        updatedAt: '2023-06-23T21:09:13.353Z'
      numEdits: 1
      reactions: []
    id: 649609cd5d127f28d613551a
    type: comment
  author: TheBloke
  content: "I tried to do k-quants for this model myself the other day because I was\
    \ asked to, but it's not currently possible.\n\nThere's currently an issue that\
    \ prevents making k-quants with certain models, models which feature tensors that\
    \ aren't divisible by 256.  \n\nThat affects two types of Llama models:\n- Ones\
    \ that had a vocab size of 32001 instead of 32000 (because of the addition of\
    \ a PAD token - which I think was an early hack which got copied even where it's\
    \ not needed)\n- Models based on OpenAssistant which have a vocab of 32016 tokens.\
    \  \n\nThis model is an example of the latter, so it won't be possible to make\
    \ k-quants until this is resolved: https://github.com/ggerganov/llama.cpp/issues/1919#issuecomment-1599484900"
  created_at: 2023-06-23 20:08:29+00:00
  edited: true
  hidden: false
  id: 649609cd5d127f28d613551a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: MetaIX/GPT4-X-Alpasta-30b-4bit
repo_type: model
status: open
target_branch: null
title: Please reconvert to new GGML format
