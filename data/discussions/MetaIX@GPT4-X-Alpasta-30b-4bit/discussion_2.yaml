!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tonight223
conflicting_files: null
created_at: 2023-04-30 08:07:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637f083e2438d7485b8eb942/gO1NL5pquqQS-uGVQ4Sjc.png?w=200&h=200&f=face
      fullname: T-ML
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tonight223
      type: user
    createdAt: '2023-04-30T09:07:41.000Z'
    data:
      edited: false
      editors:
      - Tonight223
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637f083e2438d7485b8eb942/gO1NL5pquqQS-uGVQ4Sjc.png?w=200&h=200&f=face
          fullname: T-ML
          isHf: false
          isPro: false
          name: Tonight223
          type: user
        html: '<p>I find this model working pretty well with different tasks(except
          for math and coding) and wonder how many tokens it can handle once? </p>

          '
        raw: 'I find this model working pretty well with different tasks(except for
          math and coding) and wonder how many tokens it can handle once? '
        updatedAt: '2023-04-30T09:07:41.786Z'
      numEdits: 0
      reactions: []
    id: 644e2fddd6001776ed74f91a
    type: comment
  author: Tonight223
  content: 'I find this model working pretty well with different tasks(except for
    math and coding) and wonder how many tokens it can handle once? '
  created_at: 2023-04-30 08:07:41+00:00
  edited: false
  hidden: false
  id: 644e2fddd6001776ed74f91a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-04-30T11:27:37.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<p>@Amantuer How bad is this model on math or coding? I am just about
          to run some evaluation CoT on 30B models</p>

          '
        raw: '@Amantuer How bad is this model on math or coding? I am just about to
          run some evaluation CoT on 30B models'
        updatedAt: '2023-04-30T11:27:37.719Z'
      numEdits: 0
      reactions: []
    id: 644e50a9ddf20748b053b4cf
    type: comment
  author: Yhyu13
  content: '@Amantuer How bad is this model on math or coding? I am just about to
    run some evaluation CoT on 30B models'
  created_at: 2023-04-30 10:27:37+00:00
  edited: false
  hidden: false
  id: 644e50a9ddf20748b053b4cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637f083e2438d7485b8eb942/gO1NL5pquqQS-uGVQ4Sjc.png?w=200&h=200&f=face
      fullname: T-ML
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tonight223
      type: user
    createdAt: '2023-04-30T13:15:12.000Z'
    data:
      edited: false
      editors:
      - Tonight223
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637f083e2438d7485b8eb942/gO1NL5pquqQS-uGVQ4Sjc.png?w=200&h=200&f=face
          fullname: T-ML
          isHf: false
          isPro: false
          name: Tonight223
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Yhyu13&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Yhyu13\">@<span class=\"\
          underline\">Yhyu13</span></a></span>\n\n\t</span></span> you could try to\
          \ ask what is 15 * 5 and add 5 minus 2, or write a snake game in python,\
          \ you will know what I mean. Models in this scale are all weak at math and\
          \ coding. Even GPT-3.5 also make mistakes sometimes,  at present only GPT-4\
          \ can say is capable of math and coding I think.</p>\n"
        raw: '@Yhyu13 you could try to ask what is 15 * 5 and add 5 minus 2, or write
          a snake game in python, you will know what I mean. Models in this scale
          are all weak at math and coding. Even GPT-3.5 also make mistakes sometimes,  at
          present only GPT-4 can say is capable of math and coding I think.'
        updatedAt: '2023-04-30T13:15:12.082Z'
      numEdits: 0
      reactions: []
    id: 644e69e0a00f4b11d39123d7
    type: comment
  author: Tonight223
  content: '@Yhyu13 you could try to ask what is 15 * 5 and add 5 minus 2, or write
    a snake game in python, you will know what I mean. Models in this scale are all
    weak at math and coding. Even GPT-3.5 also make mistakes sometimes,  at present
    only GPT-4 can say is capable of math and coding I think.'
  created_at: 2023-04-30 12:15:12+00:00
  edited: false
  hidden: false
  id: 644e69e0a00f4b11d39123d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5e620df8104e8fe6eedb1049e43d2068.svg
      fullname: Austin Szelkowski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: asresearch7428
      type: user
    createdAt: '2023-05-01T23:12:02.000Z'
    data:
      edited: true
      editors:
      - asresearch7428
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5e620df8104e8fe6eedb1049e43d2068.svg
          fullname: Austin Szelkowski
          isHf: false
          isPro: false
          name: asresearch7428
          type: user
        html: '<p>I don''t know the details of this particular model, but I think
          it''s  Llama based, so it probably has a 2048 token limit between prompt
          and completion. Someone correct me if I''m wrong.</p>

          <p>Does depend on the length of fine tuning prompt/completion pairs too,
          as to how well it should perform at different token counts. Some models
          have an absolute limit of "x" tokens, but if fine-tuned on shorter pairs,
          they could perform poorly closer to the limit. My guess, given the fine
          tuning dataset, it''s probably good up to 2048 tokens.</p>

          <p>Hope this helps the OP, and whoever else is wondering.</p>

          '
        raw: 'I don''t know the details of this particular model, but I think it''s  Llama
          based, so it probably has a 2048 token limit between prompt and completion.
          Someone correct me if I''m wrong.


          Does depend on the length of fine tuning prompt/completion pairs too, as
          to how well it should perform at different token counts. Some models have
          an absolute limit of "x" tokens, but if fine-tuned on shorter pairs, they
          could perform poorly closer to the limit. My guess, given the fine tuning
          dataset, it''s probably good up to 2048 tokens.


          Hope this helps the OP, and whoever else is wondering.'
        updatedAt: '2023-05-01T23:15:42.578Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Tonight223
    id: 64504742577838187e05008c
    type: comment
  author: asresearch7428
  content: 'I don''t know the details of this particular model, but I think it''s  Llama
    based, so it probably has a 2048 token limit between prompt and completion. Someone
    correct me if I''m wrong.


    Does depend on the length of fine tuning prompt/completion pairs too, as to how
    well it should perform at different token counts. Some models have an absolute
    limit of "x" tokens, but if fine-tuned on shorter pairs, they could perform poorly
    closer to the limit. My guess, given the fine tuning dataset, it''s probably good
    up to 2048 tokens.


    Hope this helps the OP, and whoever else is wondering.'
  created_at: 2023-05-01 22:12:02+00:00
  edited: true
  hidden: false
  id: 64504742577838187e05008c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: MetaIX/GPT4-X-Alpasta-30b-4bit
repo_type: model
status: open
target_branch: null
title: How many tokens can this model handle?
