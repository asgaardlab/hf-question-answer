!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Arya123456
conflicting_files: null
created_at: 2023-05-28 14:20:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/22d45a930f4e9c9c0d573cdd20765f0f.svg
      fullname: Stark
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Arya123456
      type: user
    createdAt: '2023-05-28T15:20:00.000Z'
    data:
      edited: false
      editors:
      - Arya123456
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/22d45a930f4e9c9c0d573cdd20765f0f.svg
          fullname: Stark
          isHf: false
          isPro: false
          name: Arya123456
          type: user
        html: '<p>I am a beginner at this and was wondering which of these files is
          to be used in the Oobabooga WebUI? Or do I need all of them? Thanks for
          your help :)</p>

          <p> gpt4-x-alpasta-30b-128g-4bit.safetensors</p>

          <p>gpt4-x-alpasta-30b-4bit.safetensors</p>

          <p>gpt4-x-alpasta-30b-ggml-q4_1.bin</p>

          <p>gpt4-x-alpasta-30b-ggml-q5_0.bin</p>

          <p>gpt4-x-alpasta-30b-ggml-q5_1.bin</p>

          '
        raw: "I am a beginner at this and was wondering which of these files is to\
          \ be used in the Oobabooga WebUI? Or do I need all of them? Thanks for your\
          \ help :)\r\n\r\n gpt4-x-alpasta-30b-128g-4bit.safetensors\r\n\r\ngpt4-x-alpasta-30b-4bit.safetensors\r\
          \n\r\ngpt4-x-alpasta-30b-ggml-q4_1.bin\r\n\r\ngpt4-x-alpasta-30b-ggml-q5_0.bin\r\
          \n\r\ngpt4-x-alpasta-30b-ggml-q5_1.bin\r\n\r\n"
        updatedAt: '2023-05-28T15:20:00.788Z'
      numEdits: 0
      reactions: []
    id: 647371208b7a55cfa91e2491
    type: comment
  author: Arya123456
  content: "I am a beginner at this and was wondering which of these files is to be\
    \ used in the Oobabooga WebUI? Or do I need all of them? Thanks for your help\
    \ :)\r\n\r\n gpt4-x-alpasta-30b-128g-4bit.safetensors\r\n\r\ngpt4-x-alpasta-30b-4bit.safetensors\r\
    \n\r\ngpt4-x-alpasta-30b-ggml-q4_1.bin\r\n\r\ngpt4-x-alpasta-30b-ggml-q5_0.bin\r\
    \n\r\ngpt4-x-alpasta-30b-ggml-q5_1.bin\r\n\r\n"
  created_at: 2023-05-28 14:20:00+00:00
  edited: false
  hidden: false
  id: 647371208b7a55cfa91e2491
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/550e36f3104051a9f97622a1ec5c8c50.svg
      fullname: Lance
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: clevnumb
      type: user
    createdAt: '2023-05-28T22:05:05.000Z'
    data:
      edited: false
      editors:
      - clevnumb
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/550e36f3104051a9f97622a1ec5c8c50.svg
          fullname: Lance
          isHf: false
          isPro: false
          name: clevnumb
          type: user
        html: '<p>I think you use the highest one your card/VRAM can support. 5_1
          would be the best for the BINS, but if you can use the safetensor without
          the 128g in it that would be ideal, as it won''t exceed your VRAM is how
          I understand it.</p>

          '
        raw: I think you use the highest one your card/VRAM can support. 5_1 would
          be the best for the BINS, but if you can use the safetensor without the
          128g in it that would be ideal, as it won't exceed your VRAM is how I understand
          it.
        updatedAt: '2023-05-28T22:05:05.459Z'
      numEdits: 0
      reactions: []
    id: 6473d011352c94a20ddc06e1
    type: comment
  author: clevnumb
  content: I think you use the highest one your card/VRAM can support. 5_1 would be
    the best for the BINS, but if you can use the safetensor without the 128g in it
    that would be ideal, as it won't exceed your VRAM is how I understand it.
  created_at: 2023-05-28 21:05:05+00:00
  edited: false
  hidden: false
  id: 6473d011352c94a20ddc06e1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/22d45a930f4e9c9c0d573cdd20765f0f.svg
      fullname: Stark
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Arya123456
      type: user
    createdAt: '2023-05-30T21:48:05.000Z'
    data:
      edited: false
      editors:
      - Arya123456
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/22d45a930f4e9c9c0d573cdd20765f0f.svg
          fullname: Stark
          isHf: false
          isPro: false
          name: Arya123456
          type: user
        html: '<p>Thank you Clevnumb!</p>

          '
        raw: Thank you Clevnumb!
        updatedAt: '2023-05-30T21:48:05.772Z'
      numEdits: 0
      reactions: []
    id: 64766f15cfe9d995bf406eb7
    type: comment
  author: Arya123456
  content: Thank you Clevnumb!
  created_at: 2023-05-30 20:48:05+00:00
  edited: false
  hidden: false
  id: 64766f15cfe9d995bf406eb7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: MetaIX/GPT4-X-Alpasta-30b-4bit
repo_type: model
status: open
target_branch: null
title: What are the different files for?
