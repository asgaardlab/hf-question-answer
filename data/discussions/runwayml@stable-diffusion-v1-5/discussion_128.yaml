!!python/object:huggingface_hub.community.DiscussionWithDetails
author: HiddenGalaxy
conflicting_files: null
created_at: 2023-05-10 02:54:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/273f6e6c9b5bc356d04e4d8cc5d13beb.svg
      fullname: FSY
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HiddenGalaxy
      type: user
    createdAt: '2023-05-10T03:54:32.000Z'
    data:
      edited: false
      editors:
      - HiddenGalaxy
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/273f6e6c9b5bc356d04e4d8cc5d13beb.svg
          fullname: FSY
          isHf: false
          isPro: false
          name: HiddenGalaxy
          type: user
        html: '<p>I have a question, during the training of diffusion, if it is a
          conditional input, (for example, an image generation model that combines
          text) it seems that the crossattention in the network does not use the window
          attention similar to the swing transformer structure, but directly uses
          the global attention. Considering that the size of the input image is 512*512,
          is this the reason why diffusion is so difficult to train?<br>But it does
          not seem good to change the global attention to window attention, because
          the text controls the generation of the whole image, not based on the window.<br>I
          don''t know if my understanding is correct or not, I hope for your answers.</p>

          '
        raw: "I have a question, during the training of diffusion, if it is a conditional\
          \ input, (for example, an image generation model that combines text) it\
          \ seems that the crossattention in the network does not use the window attention\
          \ similar to the swing transformer structure, but directly uses the global\
          \ attention. Considering that the size of the input image is 512*512, is\
          \ this the reason why diffusion is so difficult to train?\r\nBut it does\
          \ not seem good to change the global attention to window attention, because\
          \ the text controls the generation of the whole image, not based on the\
          \ window.\r\nI don't know if my understanding is correct or not, I hope\
          \ for your answers."
        updatedAt: '2023-05-10T03:54:32.090Z'
      numEdits: 0
      reactions: []
    id: 645b157856d647d77d74feb4
    type: comment
  author: HiddenGalaxy
  content: "I have a question, during the training of diffusion, if it is a conditional\
    \ input, (for example, an image generation model that combines text) it seems\
    \ that the crossattention in the network does not use the window attention similar\
    \ to the swing transformer structure, but directly uses the global attention.\
    \ Considering that the size of the input image is 512*512, is this the reason\
    \ why diffusion is so difficult to train?\r\nBut it does not seem good to change\
    \ the global attention to window attention, because the text controls the generation\
    \ of the whole image, not based on the window.\r\nI don't know if my understanding\
    \ is correct or not, I hope for your answers."
  created_at: 2023-05-10 02:54:32+00:00
  edited: false
  hidden: false
  id: 645b157856d647d77d74feb4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 128
repo_id: runwayml/stable-diffusion-v1-5
repo_type: model
status: open
target_branch: null
title: training of diffusion
