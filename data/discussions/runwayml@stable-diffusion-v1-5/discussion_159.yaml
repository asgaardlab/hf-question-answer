!!python/object:huggingface_hub.community.DiscussionWithDetails
author: eplo
conflicting_files: null
created_at: 2023-07-24 11:57:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2e9df4be8870d8cb7e8709debabd9b44.svg
      fullname: pl-2
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eplo
      type: user
    createdAt: '2023-07-24T12:57:18.000Z'
    data:
      edited: false
      editors:
      - eplo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7084684371948242
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2e9df4be8870d8cb7e8709debabd9b44.svg
          fullname: pl-2
          isHf: false
          isPro: false
          name: eplo
          type: user
        html: '<p>Why do I get a square of the purest grey instead of any images?</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64bd64c79a69e8da48cf37b8/CgTDUxt4A5Y4d_7VQQZA4.png"><img
          alt="astronaut_rides_horse.png" src="https://cdn-uploads.huggingface.co/production/uploads/64bd64c79a69e8da48cf37b8/CgTDUxt4A5Y4d_7VQQZA4.png"></a></p>

          <p>I''m using a Radeon 5700 with 8GB on Ubuntu 22.04. Drivers courtesy of
          <code>amdgpu-install_5.6.50600-1_all.deb</code>, <code>pytorch</code> courtesy
          of <code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.2</code></p>

          <p>Variables added:</p>

          <pre><code>export HSA_OVERRIDE_GFX_VERSION=10.3.0

          </code></pre>

          <p>I ran some model (waifu-diffusion?) once last night but it took ages
          and was on CPU because I forget the <code>pipe.to("cuda")</code> line.</p>

          '
        raw: "Why do I get a square of the purest grey instead of any images?\r\n\r\
          \n![astronaut_rides_horse.png](https://cdn-uploads.huggingface.co/production/uploads/64bd64c79a69e8da48cf37b8/CgTDUxt4A5Y4d_7VQQZA4.png)\r\
          \n\r\nI'm using a Radeon 5700 with 8GB on Ubuntu 22.04. Drivers courtesy\
          \ of `amdgpu-install_5.6.50600-1_all.deb`, `pytorch` courtesy of `pip3 install\
          \ torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.2`\r\
          \n\r\nVariables added:\r\n\r\n```\r\nexport HSA_OVERRIDE_GFX_VERSION=10.3.0\r\
          \n```\r\n\r\nI ran some model (waifu-diffusion?) once last night but it\
          \ took ages and was on CPU because I forget the `pipe.to(\"cuda\")` line.\r\
          \n"
        updatedAt: '2023-07-24T12:57:18.087Z'
      numEdits: 0
      reactions: []
    id: 64be752ef8f28a19b0ea8956
    type: comment
  author: eplo
  content: "Why do I get a square of the purest grey instead of any images?\r\n\r\n\
    ![astronaut_rides_horse.png](https://cdn-uploads.huggingface.co/production/uploads/64bd64c79a69e8da48cf37b8/CgTDUxt4A5Y4d_7VQQZA4.png)\r\
    \n\r\nI'm using a Radeon 5700 with 8GB on Ubuntu 22.04. Drivers courtesy of `amdgpu-install_5.6.50600-1_all.deb`,\
    \ `pytorch` courtesy of `pip3 install torch torchvision torchaudio --index-url\
    \ https://download.pytorch.org/whl/rocm5.2`\r\n\r\nVariables added:\r\n\r\n```\r\
    \nexport HSA_OVERRIDE_GFX_VERSION=10.3.0\r\n```\r\n\r\nI ran some model (waifu-diffusion?)\
    \ once last night but it took ages and was on CPU because I forget the `pipe.to(\"\
    cuda\")` line.\r\n"
  created_at: 2023-07-24 11:57:18+00:00
  edited: false
  hidden: false
  id: 64be752ef8f28a19b0ea8956
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2e9df4be8870d8cb7e8709debabd9b44.svg
      fullname: pl-2
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eplo
      type: user
    createdAt: '2023-07-26T15:02:44.000Z'
    data:
      edited: false
      editors:
      - eplo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6711268424987793
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2e9df4be8870d8cb7e8709debabd9b44.svg
          fullname: pl-2
          isHf: false
          isPro: false
          name: eplo
          type: user
        html: "<p>Deleting <code> torch_dtype=torch.float16</code> solves this, but\
          \ introduces other challenges to VRAM conservation which I'm giving the\
          \ simplest, dumbest, possible solution for here:</p>\n<pre><code class=\"\
          language-python\"><span class=\"hljs-keyword\">from</span> diffusers <span\
          \ class=\"hljs-keyword\">import</span> StableDiffusionPipeline\n<span class=\"\
          hljs-keyword\">import</span> torch\n\nmodel_id = <span class=\"hljs-string\"\
          >\"runwayml/stable-diffusion-v1-5\"</span>\npipe = StableDiffusionPipeline.from_pretrained(model_id)\n\
          pipe = pipe.to(<span class=\"hljs-string\">\"cuda\"</span>)\n\nprompt =\
          \ <span class=\"hljs-string\">\"a photo of an astronaut riding a horse on\
          \ mars\"</span>\nimage = pipe(prompt, width=<span class=\"hljs-number\"\
          >400</span>, height=<span class=\"hljs-number\">400</span>).images[<span\
          \ class=\"hljs-number\">0</span>]  \n    \nimage.save(<span class=\"hljs-string\"\
          >\"astronaut_rides_horse.png\"</span>)\n</code></pre>\n<p>From here I can\
          \ play with options to get the image size back up.</p>\n"
        raw: "Deleting ` torch_dtype=torch.float16` solves this, but introduces other\
          \ challenges to VRAM conservation which I'm giving the simplest, dumbest,\
          \ possible solution for here:\n\n```python\nfrom diffusers import StableDiffusionPipeline\n\
          import torch\n\nmodel_id = \"runwayml/stable-diffusion-v1-5\"\npipe = StableDiffusionPipeline.from_pretrained(model_id)\n\
          pipe = pipe.to(\"cuda\")\n\nprompt = \"a photo of an astronaut riding a\
          \ horse on mars\"\nimage = pipe(prompt, width=400, height=400).images[0]\
          \  \n    \nimage.save(\"astronaut_rides_horse.png\")\n```\n\nFrom here I\
          \ can play with options to get the image size back up."
        updatedAt: '2023-07-26T15:02:44.065Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64c135942b37de867c2af987
    id: 64c135942b37de867c2af986
    type: comment
  author: eplo
  content: "Deleting ` torch_dtype=torch.float16` solves this, but introduces other\
    \ challenges to VRAM conservation which I'm giving the simplest, dumbest, possible\
    \ solution for here:\n\n```python\nfrom diffusers import StableDiffusionPipeline\n\
    import torch\n\nmodel_id = \"runwayml/stable-diffusion-v1-5\"\npipe = StableDiffusionPipeline.from_pretrained(model_id)\n\
    pipe = pipe.to(\"cuda\")\n\nprompt = \"a photo of an astronaut riding a horse\
    \ on mars\"\nimage = pipe(prompt, width=400, height=400).images[0]  \n    \nimage.save(\"\
    astronaut_rides_horse.png\")\n```\n\nFrom here I can play with options to get\
    \ the image size back up."
  created_at: 2023-07-26 14:02:44+00:00
  edited: false
  hidden: false
  id: 64c135942b37de867c2af986
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/2e9df4be8870d8cb7e8709debabd9b44.svg
      fullname: pl-2
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eplo
      type: user
    createdAt: '2023-07-26T15:02:44.000Z'
    data:
      status: closed
    id: 64c135942b37de867c2af987
    type: status-change
  author: eplo
  created_at: 2023-07-26 14:02:44+00:00
  id: 64c135942b37de867c2af987
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 159
repo_id: runwayml/stable-diffusion-v1-5
repo_type: model
status: closed
target_branch: null
title: Radeon 5700 produces uniformly grey squares
