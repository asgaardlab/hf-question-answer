!!python/object:huggingface_hub.community.DiscussionWithDetails
author: siriously
conflicting_files: null
created_at: 2022-11-29 13:15:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86e584c131de94fc369015a1e2ef4c51.svg
      fullname: Siri Mira
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: siriously
      type: user
    createdAt: '2022-11-29T13:15:00.000Z'
    data:
      edited: false
      editors:
      - siriously
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86e584c131de94fc369015a1e2ef4c51.svg
          fullname: Siri Mira
          isHf: false
          isPro: false
          name: siriously
          type: user
        html: "<p>When using this colab: <a rel=\"nofollow\" href=\"https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb\"\
          >https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb</a><br>when\
          \ I get to the training step, I get the error \" Can't load tokenizer for\
          \ '/content/stable-diffusion-v1-5'. \"<br>Why is this occuring?</p>\n<p>Here's\
          \ the full error:</p>\n<pre><code>Traceback (most recent call last):\n \
          \ File \"/content/diffusers/examples/dreambooth/train_dreambooth.py\", line\
          \ 795, in &lt;module&gt;\n    main()\n  File \"/content/diffusers/examples/dreambooth/train_dreambooth.py\"\
          , line 472, in main\n    tokenizer = CLIPTokenizer.from_pretrained(args.pretrained_model_name_or_path,\
          \ subfolder=\"tokenizer\")\n  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\"\
          , line 1760, in from_pretrained\n    f\"Can't load tokenizer for '{pretrained_model_name_or_path}'.\
          \ If you were trying to load it from \"\nOSError: Can't load tokenizer for\
          \ '/content/stable-diffusion-v1-5'. If you were trying to load it from 'https://huggingface.co/models',\
          \ make sure you don't have a local directory with the same name. Otherwise,\
          \ make sure '/content/stable-diffusion-v1-5' is the correct path to a directory\
          \ containing all relevant files for a CLIPTokenizer tokenizer.\nTraceback\
          \ (most recent call last):\n  File \"/usr/local/bin/accelerate\", line 8,\
          \ in &lt;module&gt;\n    sys.exit(main())\n  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/accelerate_cli.py\"\
          , line 43, in main\n    args.func(args)\n  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/launch.py\"\
          , line 837, in launch_command\n    simple_launcher(args)\n  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/launch.py\"\
          , line 354, in simple_launcher\n    raise subprocess.CalledProcessError(returncode=process.returncode,\
          \ cmd=cmd)\nsubprocess.CalledProcessError: Command '['/usr/bin/python3',\
          \ '/content/diffusers/examples/dreambooth/train_dreambooth.py', '--image_captions_filename',\
          \ '--train_text_encoder', '--save_starting_step=500', '--stop_text_encoder_training=3000',\
          \ '--save_n_steps=0', '--Session_dir=/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/newSesh',\
          \ '--pretrained_model_name_or_path=/content/stable-diffusion-v1-5', '--instance_data_dir=/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/newSesh/instance_images',\
          \ '--output_dir=/content/models/newSesh', '--instance_prompt=', '--seed=949403',\
          \ '--resolution=512', '--mixed_precision=fp16', '--train_batch_size=1',\
          \ '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--use_8bit_adam',\
          \ '--learning_rate=2e-6', '--lr_scheduler=polynomial', '--lr_warmup_steps=0',\
          \ '--max_train_steps=3000']' returned non-zero exit status 1.\n</code></pre>\n"
        raw: "When using this colab: https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb\r\
          \nwhen I get to the training step, I get the error \" Can't load tokenizer\
          \ for '/content/stable-diffusion-v1-5'. \"\r\nWhy is this occuring?\r\n\r\
          \nHere's the full error:\r\n```\r\nTraceback (most recent call last):\r\n\
          \  File \"/content/diffusers/examples/dreambooth/train_dreambooth.py\",\
          \ line 795, in <module>\r\n    main()\r\n  File \"/content/diffusers/examples/dreambooth/train_dreambooth.py\"\
          , line 472, in main\r\n    tokenizer = CLIPTokenizer.from_pretrained(args.pretrained_model_name_or_path,\
          \ subfolder=\"tokenizer\")\r\n  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\"\
          , line 1760, in from_pretrained\r\n    f\"Can't load tokenizer for '{pretrained_model_name_or_path}'.\
          \ If you were trying to load it from \"\r\nOSError: Can't load tokenizer\
          \ for '/content/stable-diffusion-v1-5'. If you were trying to load it from\
          \ 'https://huggingface.co/models', make sure you don't have a local directory\
          \ with the same name. Otherwise, make sure '/content/stable-diffusion-v1-5'\
          \ is the correct path to a directory containing all relevant files for a\
          \ CLIPTokenizer tokenizer.\r\nTraceback (most recent call last):\r\n  File\
          \ \"/usr/local/bin/accelerate\", line 8, in <module>\r\n    sys.exit(main())\r\
          \n  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/accelerate_cli.py\"\
          , line 43, in main\r\n    args.func(args)\r\n  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/launch.py\"\
          , line 837, in launch_command\r\n    simple_launcher(args)\r\n  File \"\
          /usr/local/lib/python3.7/dist-packages/accelerate/commands/launch.py\",\
          \ line 354, in simple_launcher\r\n    raise subprocess.CalledProcessError(returncode=process.returncode,\
          \ cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/usr/bin/python3',\
          \ '/content/diffusers/examples/dreambooth/train_dreambooth.py', '--image_captions_filename',\
          \ '--train_text_encoder', '--save_starting_step=500', '--stop_text_encoder_training=3000',\
          \ '--save_n_steps=0', '--Session_dir=/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/newSesh',\
          \ '--pretrained_model_name_or_path=/content/stable-diffusion-v1-5', '--instance_data_dir=/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/newSesh/instance_images',\
          \ '--output_dir=/content/models/newSesh', '--instance_prompt=', '--seed=949403',\
          \ '--resolution=512', '--mixed_precision=fp16', '--train_batch_size=1',\
          \ '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--use_8bit_adam',\
          \ '--learning_rate=2e-6', '--lr_scheduler=polynomial', '--lr_warmup_steps=0',\
          \ '--max_train_steps=3000']' returned non-zero exit status 1.\r\n```"
        updatedAt: '2022-11-29T13:15:00.155Z'
      numEdits: 0
      reactions: []
    id: 638605d4988cb440e7ce95fb
    type: comment
  author: siriously
  content: "When using this colab: https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb\r\
    \nwhen I get to the training step, I get the error \" Can't load tokenizer for\
    \ '/content/stable-diffusion-v1-5'. \"\r\nWhy is this occuring?\r\n\r\nHere's\
    \ the full error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/content/diffusers/examples/dreambooth/train_dreambooth.py\"\
    , line 795, in <module>\r\n    main()\r\n  File \"/content/diffusers/examples/dreambooth/train_dreambooth.py\"\
    , line 472, in main\r\n    tokenizer = CLIPTokenizer.from_pretrained(args.pretrained_model_name_or_path,\
    \ subfolder=\"tokenizer\")\r\n  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\"\
    , line 1760, in from_pretrained\r\n    f\"Can't load tokenizer for '{pretrained_model_name_or_path}'.\
    \ If you were trying to load it from \"\r\nOSError: Can't load tokenizer for '/content/stable-diffusion-v1-5'.\
    \ If you were trying to load it from 'https://huggingface.co/models', make sure\
    \ you don't have a local directory with the same name. Otherwise, make sure '/content/stable-diffusion-v1-5'\
    \ is the correct path to a directory containing all relevant files for a CLIPTokenizer\
    \ tokenizer.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/accelerate\"\
    , line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/accelerate_cli.py\"\
    , line 43, in main\r\n    args.func(args)\r\n  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/launch.py\"\
    , line 837, in launch_command\r\n    simple_launcher(args)\r\n  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/launch.py\"\
    , line 354, in simple_launcher\r\n    raise subprocess.CalledProcessError(returncode=process.returncode,\
    \ cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/usr/bin/python3', '/content/diffusers/examples/dreambooth/train_dreambooth.py',\
    \ '--image_captions_filename', '--train_text_encoder', '--save_starting_step=500',\
    \ '--stop_text_encoder_training=3000', '--save_n_steps=0', '--Session_dir=/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/newSesh',\
    \ '--pretrained_model_name_or_path=/content/stable-diffusion-v1-5', '--instance_data_dir=/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/newSesh/instance_images',\
    \ '--output_dir=/content/models/newSesh', '--instance_prompt=', '--seed=949403',\
    \ '--resolution=512', '--mixed_precision=fp16', '--train_batch_size=1', '--gradient_accumulation_steps=1',\
    \ '--gradient_checkpointing', '--use_8bit_adam', '--learning_rate=2e-6', '--lr_scheduler=polynomial',\
    \ '--lr_warmup_steps=0', '--max_train_steps=3000']' returned non-zero exit status\
    \ 1.\r\n```"
  created_at: 2022-11-29 13:15:00+00:00
  edited: false
  hidden: false
  id: 638605d4988cb440e7ce95fb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 31
repo_id: runwayml/stable-diffusion-v1-5
repo_type: model
status: open
target_branch: null
title: Tokenizer error
