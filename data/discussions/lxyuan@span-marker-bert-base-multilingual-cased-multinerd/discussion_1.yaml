!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tomaarsen
conflicting_files: null
created_at: 2023-08-14 08:00:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
      fullname: Tom Aarsen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomaarsen
      type: user
    createdAt: '2023-08-14T09:00:37.000Z'
    data:
      edited: false
      editors:
      - tomaarsen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6121119260787964
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
          fullname: Tom Aarsen
          isHf: true
          isPro: false
          name: tomaarsen
          type: user
        html: "<p>Hello! This is looking great, your F1 seems higher than my version\
          \ \U0001F389<br>I computed some per-language metrics for you. Here's the\
          \ script:</p>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n\
          <span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> TrainingArguments\n\n<span class=\"hljs-keyword\">from</span>\
          \ span_marker <span class=\"hljs-keyword\">import</span> SpanMarkerModel,\
          \ Trainer\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\
          \ function_\">main</span>() -&gt; <span class=\"hljs-literal\">None</span>:\n\
          \    model_name = <span class=\"hljs-string\">\"lxyuan/span-marker-bert-base-multilingual-cased-multinerd\"\
          </span>\n    model = SpanMarkerModel.from_pretrained(model_name).cuda()\n\
          \n    <span class=\"hljs-comment\"># Prepare the \U0001F917 transformers\
          \ training arguments</span>\n    args = TrainingArguments(\n        output_dir=<span\
          \ class=\"hljs-string\">\"results\"</span>,\n        per_device_eval_batch_size=<span\
          \ class=\"hljs-number\">32</span>,\n        bf16=<span class=\"hljs-literal\"\
          >True</span>,\n        dataloader_num_workers=<span class=\"hljs-number\"\
          >2</span>,\n        report_to=<span class=\"hljs-string\">\"none\"</span>,\n\
          \    )\n\n    <span class=\"hljs-comment\"># Initialize the trainer using\
          \ our model, training args &amp; dataset, and train</span>\n    trainer\
          \ = Trainer(\n        model=model,\n        args=args,\n    )\n\n    dataset\
          \ = <span class=\"hljs-string\">\"Babelscape/multinerd\"</span>\n    languages\
          \ = [<span class=\"hljs-string\">\"de\"</span>, <span class=\"hljs-string\"\
          >\"en\"</span>, <span class=\"hljs-string\">\"es\"</span>, <span class=\"\
          hljs-string\">\"fr\"</span>, <span class=\"hljs-string\">\"it\"</span>,\
          \ <span class=\"hljs-string\">\"nl\"</span>, <span class=\"hljs-string\"\
          >\"pl\"</span>, <span class=\"hljs-string\">\"pt\"</span>, <span class=\"\
          hljs-string\">\"ru\"</span>, <span class=\"hljs-string\">\"zh\"</span>]\n\
          \    test_dataset = load_dataset(dataset, split=<span class=\"hljs-string\"\
          >\"test\"</span>)\n    <span class=\"hljs-keyword\">for</span> lang <span\
          \ class=\"hljs-keyword\">in</span> languages:\n        split_test_dataset\
          \ = test_dataset.<span class=\"hljs-built_in\">filter</span>(<span class=\"\
          hljs-keyword\">lambda</span> sample: sample[<span class=\"hljs-string\"\
          >\"lang\"</span>] == lang)\n        <span class=\"hljs-comment\"># Compute\
          \ &amp; save the metrics on the test set</span>\n        metrics = trainer.evaluate(split_test_dataset,\
          \ metric_key_prefix=<span class=\"hljs-string\">f\"test_<span class=\"hljs-subst\"\
          >{lang}</span>\"</span>)\n        trainer.save_metrics(<span class=\"hljs-string\"\
          >f\"test_<span class=\"hljs-subst\">{lang}</span>\"</span>, metrics)\n\n\
          <span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\"\
          >\"__main__\"</span>:\n    main()\n</code></pre>\n<p>This resulted in some\
          \ files, including an <code>all_results.json</code> file. When formatted\
          \ nicely, that becomes:</p>\n<div class=\"max-w-full overflow-auto\">\n\t\
          <table>\n\t\t<thead><tr>\n<th><strong>Language</strong></th>\n<th><strong>Precision</strong></th>\n\
          <th><strong>Recall</strong></th>\n<th><strong>F1</strong></th>\n</tr>\n\n\
          \t\t</thead><tbody><tr>\n<td><strong>all</strong></td>\n<td>92.42</td>\n\
          <td>92.81</td>\n<td><strong>92.61</strong></td>\n</tr>\n<tr>\n<td><strong>de</strong></td>\n\
          <td>95.03</td>\n<td>95.07</td>\n<td><strong>95.05</strong></td>\n</tr>\n\
          <tr>\n<td><strong>en</strong></td>\n<td>95.00</td>\n<td>95.40</td>\n<td><strong>95.20</strong></td>\n\
          </tr>\n<tr>\n<td><strong>es</strong></td>\n<td>92.05</td>\n<td>91.37</td>\n\
          <td><strong>91.71</strong></td>\n</tr>\n<tr>\n<td><strong>fr</strong></td>\n\
          <td>92.37</td>\n<td>91.41</td>\n<td><strong>91.89</strong></td>\n</tr>\n\
          <tr>\n<td><strong>it</strong></td>\n<td>91.45</td>\n<td>93.15</td>\n<td><strong>92.29</strong></td>\n\
          </tr>\n<tr>\n<td><strong>nl</strong></td>\n<td>93.85</td>\n<td>92.98</td>\n\
          <td><strong>93.41</strong></td>\n</tr>\n<tr>\n<td><strong>pl</strong></td>\n\
          <td>93.13</td>\n<td>92.66</td>\n<td><strong>92.89</strong></td>\n</tr>\n\
          <tr>\n<td><strong>pt</strong></td>\n<td>93.60</td>\n<td>92.50</td>\n<td><strong>93.05</strong></td>\n\
          </tr>\n<tr>\n<td><strong>ru</strong></td>\n<td>93.25</td>\n<td>93.32</td>\n\
          <td><strong>93.29</strong></td>\n</tr>\n<tr>\n<td><strong>zh</strong></td>\n\
          <td>89.47</td>\n<td>88.40</td>\n<td><strong>88.93</strong></td>\n</tr>\n\
          </tbody>\n\t</table>\n</div>\n<p>For reference, your model performs better\
          \ in this test for all languages except French, Italian and Russian. Notably,\
          \ your model is much better (~2 F1) on Chinese. Here's the markdown version\
          \ so you can copy paste it into your README if you want:</p>\n<pre><code>|\
          \ **Language** | **Precision** | **Recall** | **F1**     |\n|--------------|---------------|------------|------------|\n\
          | **all**      | 92.42         | 92.81      | **92.61**  |\n| **de**   \
          \    | 95.03         | 95.07      | **95.05**  |\n| **en**       | 95.00\
          \         | 95.40      | **95.20**  |\n| **es**       | 92.05         |\
          \ 91.37      | **91.71**  |\n| **fr**       | 92.37         | 91.41    \
          \  | **91.89**  | \n| **it**       | 91.45         | 93.15      | **92.29**\
          \  | \n| **nl**       | 93.85         | 92.98      | **93.41**  |\n| **pl**\
          \       | 93.13         | 92.66      | **92.89**  |\n| **pt**       | 93.60\
          \         | 92.50      | **93.05**  |\n| **ru**       | 93.25         |\
          \ 93.32      | **93.29**  | \n| **zh**       | 89.47         | 88.40   \
          \   | **88.93**  |\n</code></pre>\n<p>Perhaps in a future iteration of SpanMarker,\
          \ I can automatically generate F1 scores per entity class. I think it would\
          \ be valuable to learn what performances make up the 92.61 F1. After all,\
          \ the 92.61 tells you nothing about how good the model can detect e.g. foods.</p>\n\
          <p>I'll add a link to this model at the bottom of my mBERT model!</p>\n\
          <ul>\n<li>Tom Aarsen</li>\n</ul>\n"
        raw: "Hello! This is looking great, your F1 seems higher than my version \U0001F389\
          \r\nI computed some per-language metrics for you. Here's the script:\r\n\
          ```python\r\nfrom datasets import load_dataset\r\nfrom transformers import\
          \ TrainingArguments\r\n\r\nfrom span_marker import SpanMarkerModel, Trainer\r\
          \n\r\ndef main() -> None:\r\n    model_name = \"lxyuan/span-marker-bert-base-multilingual-cased-multinerd\"\
          \r\n    model = SpanMarkerModel.from_pretrained(model_name).cuda()\r\n\r\
          \n    # Prepare the \U0001F917 transformers training arguments\r\n    args\
          \ = TrainingArguments(\r\n        output_dir=\"results\",\r\n        per_device_eval_batch_size=32,\r\
          \n        bf16=True,\r\n        dataloader_num_workers=2,\r\n        report_to=\"\
          none\",\r\n    )\r\n\r\n    # Initialize the trainer using our model, training\
          \ args & dataset, and train\r\n    trainer = Trainer(\r\n        model=model,\r\
          \n        args=args,\r\n    )\r\n\r\n    dataset = \"Babelscape/multinerd\"\
          \r\n    languages = [\"de\", \"en\", \"es\", \"fr\", \"it\", \"nl\", \"\
          pl\", \"pt\", \"ru\", \"zh\"]\r\n    test_dataset = load_dataset(dataset,\
          \ split=\"test\")\r\n    for lang in languages:\r\n        split_test_dataset\
          \ = test_dataset.filter(lambda sample: sample[\"lang\"] == lang)\r\n   \
          \     # Compute & save the metrics on the test set\r\n        metrics =\
          \ trainer.evaluate(split_test_dataset, metric_key_prefix=f\"test_{lang}\"\
          )\r\n        trainer.save_metrics(f\"test_{lang}\", metrics)\r\n\r\nif __name__\
          \ == \"__main__\":\r\n    main()\r\n```\r\n\r\nThis resulted in some files,\
          \ including an `all_results.json` file. When formatted nicely, that becomes:\r\
          \n\r\n| **Language** | **Precision** | **Recall** | **F1**     |\r\n|--------------|---------------|------------|------------|\r\
          \n| **all**      | 92.42         | 92.81      | **92.61**  |\r\n| **de**\
          \       | 95.03         | 95.07      | **95.05**  |\r\n| **en**       |\
          \ 95.00         | 95.40      | **95.20**  |\r\n| **es**       | 92.05  \
          \       | 91.37      | **91.71**  |\r\n| **fr**       | 92.37         |\
          \ 91.41      | **91.89**  | \r\n| **it**       | 91.45         | 93.15 \
          \     | **92.29**  | \r\n| **nl**       | 93.85         | 92.98      | **93.41**\
          \  |\r\n| **pl**       | 93.13         | 92.66      | **92.89**  |\r\n|\
          \ **pt**       | 93.60         | 92.50      | **93.05**  |\r\n| **ru** \
          \      | 93.25         | 93.32      | **93.29**  | \r\n| **zh**       |\
          \ 89.47         | 88.40      | **88.93**  |\r\n\r\nFor reference, your model\
          \ performs better in this test for all languages except French, Italian\
          \ and Russian. Notably, your model is much better (~2 F1) on Chinese. Here's\
          \ the markdown version so you can copy paste it into your README if you\
          \ want:\r\n```\r\n| **Language** | **Precision** | **Recall** | **F1** \
          \    |\r\n|--------------|---------------|------------|------------|\r\n\
          | **all**      | 92.42         | 92.81      | **92.61**  |\r\n| **de** \
          \      | 95.03         | 95.07      | **95.05**  |\r\n| **en**       | 95.00\
          \         | 95.40      | **95.20**  |\r\n| **es**       | 92.05        \
          \ | 91.37      | **91.71**  |\r\n| **fr**       | 92.37         | 91.41\
          \      | **91.89**  | \r\n| **it**       | 91.45         | 93.15      |\
          \ **92.29**  | \r\n| **nl**       | 93.85         | 92.98      | **93.41**\
          \  |\r\n| **pl**       | 93.13         | 92.66      | **92.89**  |\r\n|\
          \ **pt**       | 93.60         | 92.50      | **93.05**  |\r\n| **ru** \
          \      | 93.25         | 93.32      | **93.29**  | \r\n| **zh**       |\
          \ 89.47         | 88.40      | **88.93**  |\r\n```\r\n\r\nPerhaps in a future\
          \ iteration of SpanMarker, I can automatically generate F1 scores per entity\
          \ class. I think it would be valuable to learn what performances make up\
          \ the 92.61 F1. After all, the 92.61 tells you nothing about how good the\
          \ model can detect e.g. foods.\r\n\r\nI'll add a link to this model at the\
          \ bottom of my mBERT model!\r\n\r\n- Tom Aarsen"
        updatedAt: '2023-08-14T09:00:37.968Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - lxyuan
    id: 64d9ed35b4099a766b4225bc
    type: comment
  author: tomaarsen
  content: "Hello! This is looking great, your F1 seems higher than my version \U0001F389\
    \r\nI computed some per-language metrics for you. Here's the script:\r\n```python\r\
    \nfrom datasets import load_dataset\r\nfrom transformers import TrainingArguments\r\
    \n\r\nfrom span_marker import SpanMarkerModel, Trainer\r\n\r\ndef main() -> None:\r\
    \n    model_name = \"lxyuan/span-marker-bert-base-multilingual-cased-multinerd\"\
    \r\n    model = SpanMarkerModel.from_pretrained(model_name).cuda()\r\n\r\n   \
    \ # Prepare the \U0001F917 transformers training arguments\r\n    args = TrainingArguments(\r\
    \n        output_dir=\"results\",\r\n        per_device_eval_batch_size=32,\r\n\
    \        bf16=True,\r\n        dataloader_num_workers=2,\r\n        report_to=\"\
    none\",\r\n    )\r\n\r\n    # Initialize the trainer using our model, training\
    \ args & dataset, and train\r\n    trainer = Trainer(\r\n        model=model,\r\
    \n        args=args,\r\n    )\r\n\r\n    dataset = \"Babelscape/multinerd\"\r\n\
    \    languages = [\"de\", \"en\", \"es\", \"fr\", \"it\", \"nl\", \"pl\", \"pt\"\
    , \"ru\", \"zh\"]\r\n    test_dataset = load_dataset(dataset, split=\"test\")\r\
    \n    for lang in languages:\r\n        split_test_dataset = test_dataset.filter(lambda\
    \ sample: sample[\"lang\"] == lang)\r\n        # Compute & save the metrics on\
    \ the test set\r\n        metrics = trainer.evaluate(split_test_dataset, metric_key_prefix=f\"\
    test_{lang}\")\r\n        trainer.save_metrics(f\"test_{lang}\", metrics)\r\n\r\
    \nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nThis resulted in some\
    \ files, including an `all_results.json` file. When formatted nicely, that becomes:\r\
    \n\r\n| **Language** | **Precision** | **Recall** | **F1**     |\r\n|--------------|---------------|------------|------------|\r\
    \n| **all**      | 92.42         | 92.81      | **92.61**  |\r\n| **de**     \
    \  | 95.03         | 95.07      | **95.05**  |\r\n| **en**       | 95.00     \
    \    | 95.40      | **95.20**  |\r\n| **es**       | 92.05         | 91.37   \
    \   | **91.71**  |\r\n| **fr**       | 92.37         | 91.41      | **91.89**\
    \  | \r\n| **it**       | 91.45         | 93.15      | **92.29**  | \r\n| **nl**\
    \       | 93.85         | 92.98      | **93.41**  |\r\n| **pl**       | 93.13\
    \         | 92.66      | **92.89**  |\r\n| **pt**       | 93.60         | 92.50\
    \      | **93.05**  |\r\n| **ru**       | 93.25         | 93.32      | **93.29**\
    \  | \r\n| **zh**       | 89.47         | 88.40      | **88.93**  |\r\n\r\nFor\
    \ reference, your model performs better in this test for all languages except\
    \ French, Italian and Russian. Notably, your model is much better (~2 F1) on Chinese.\
    \ Here's the markdown version so you can copy paste it into your README if you\
    \ want:\r\n```\r\n| **Language** | **Precision** | **Recall** | **F1**     |\r\
    \n|--------------|---------------|------------|------------|\r\n| **all**    \
    \  | 92.42         | 92.81      | **92.61**  |\r\n| **de**       | 95.03     \
    \    | 95.07      | **95.05**  |\r\n| **en**       | 95.00         | 95.40   \
    \   | **95.20**  |\r\n| **es**       | 92.05         | 91.37      | **91.71**\
    \  |\r\n| **fr**       | 92.37         | 91.41      | **91.89**  | \r\n| **it**\
    \       | 91.45         | 93.15      | **92.29**  | \r\n| **nl**       | 93.85\
    \         | 92.98      | **93.41**  |\r\n| **pl**       | 93.13         | 92.66\
    \      | **92.89**  |\r\n| **pt**       | 93.60         | 92.50      | **93.05**\
    \  |\r\n| **ru**       | 93.25         | 93.32      | **93.29**  | \r\n| **zh**\
    \       | 89.47         | 88.40      | **88.93**  |\r\n```\r\n\r\nPerhaps in a\
    \ future iteration of SpanMarker, I can automatically generate F1 scores per entity\
    \ class. I think it would be valuable to learn what performances make up the 92.61\
    \ F1. After all, the 92.61 tells you nothing about how good the model can detect\
    \ e.g. foods.\r\n\r\nI'll add a link to this model at the bottom of my mBERT model!\r\
    \n\r\n- Tom Aarsen"
  created_at: 2023-08-14 08:00:37+00:00
  edited: false
  hidden: false
  id: 64d9ed35b4099a766b4225bc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
      fullname: Tom Aarsen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomaarsen
      type: user
    createdAt: '2023-08-14T09:03:42.000Z'
    data:
      edited: false
      editors:
      - tomaarsen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.884343147277832
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
          fullname: Tom Aarsen
          isHf: true
          isPro: false
          name: tomaarsen
          type: user
        html: '<p>Unrelated, but I wonder if a uncased encoder (e.g. <a href="https://huggingface.co/bert-base-multilingual-uncased">bert-base-multilingual-uncased</a>)
          would perform better for entities that are often times not capitalized,
          like foods.</p>

          '
        raw: Unrelated, but I wonder if a uncased encoder (e.g. [bert-base-multilingual-uncased](https://huggingface.co/bert-base-multilingual-uncased))
          would perform better for entities that are often times not capitalized,
          like foods.
        updatedAt: '2023-08-14T09:03:42.708Z'
      numEdits: 0
      reactions: []
    id: 64d9edee8f84a7738ddf1d4f
    type: comment
  author: tomaarsen
  content: Unrelated, but I wonder if a uncased encoder (e.g. [bert-base-multilingual-uncased](https://huggingface.co/bert-base-multilingual-uncased))
    would perform better for entities that are often times not capitalized, like foods.
  created_at: 2023-08-14 08:03:42+00:00
  edited: false
  hidden: false
  id: 64d9edee8f84a7738ddf1d4f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-08-14T09:17:51.000Z'
    data:
      edited: false
      editors:
      - lxyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9402531385421753
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
          fullname: Lik Xun Yuan
          isHf: false
          isPro: false
          name: lxyuan
          type: user
        html: '<p>Hi Tom,</p>

          <p>Thanks for the evaluation script and the results in markdown format.<br>I
          will include them in my model card later.</p>

          '
        raw: "Hi Tom,\n\nThanks for the evaluation script and the results in markdown\
          \ format. \nI will include them in my model card later."
        updatedAt: '2023-08-14T09:17:51.525Z'
      numEdits: 0
      reactions: []
    id: 64d9f13fcbd2eba1e63449cf
    type: comment
  author: lxyuan
  content: "Hi Tom,\n\nThanks for the evaluation script and the results in markdown\
    \ format. \nI will include them in my model card later."
  created_at: 2023-08-14 08:17:51+00:00
  edited: false
  hidden: false
  id: 64d9f13fcbd2eba1e63449cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-08-14T09:20:23.000Z'
    data:
      edited: false
      editors:
      - lxyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8570787906646729
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
          fullname: Lik Xun Yuan
          isHf: false
          isPro: false
          name: lxyuan
          type: user
        html: '<blockquote>

          <p>Unrelated, but I wonder if a uncased encoder (e.g. <a href="https://huggingface.co/bert-base-multilingual-uncased">bert-base-multilingual-uncased</a>)
          would perform better for entities that are often times not capitalized,
          like foods.</p>

          </blockquote>

          <p>Interesting observation! Happy to run another experiment using <code>bert-base-multilingual-uncased</code>
          and compare the results. I will definitely ping you again when I complete
          the training.</p>

          '
        raw: '> Unrelated, but I wonder if a uncased encoder (e.g. [bert-base-multilingual-uncased](https://huggingface.co/bert-base-multilingual-uncased))
          would perform better for entities that are often times not capitalized,
          like foods.


          Interesting observation! Happy to run another experiment using `bert-base-multilingual-uncased`
          and compare the results. I will definitely ping you again when I complete
          the training.

          '
        updatedAt: '2023-08-14T09:20:23.869Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - tomaarsen
    id: 64d9f1d7887f55fb6e74369d
    type: comment
  author: lxyuan
  content: '> Unrelated, but I wonder if a uncased encoder (e.g. [bert-base-multilingual-uncased](https://huggingface.co/bert-base-multilingual-uncased))
    would perform better for entities that are often times not capitalized, like foods.


    Interesting observation! Happy to run another experiment using `bert-base-multilingual-uncased`
    and compare the results. I will definitely ping you again when I complete the
    training.

    '
  created_at: 2023-08-14 08:20:23+00:00
  edited: false
  hidden: false
  id: 64d9f1d7887f55fb6e74369d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
      fullname: Tom Aarsen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomaarsen
      type: user
    createdAt: '2023-08-14T09:35:40.000Z'
    data:
      edited: false
      editors:
      - tomaarsen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7871655225753784
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
          fullname: Tom Aarsen
          isHf: true
          isPro: false
          name: tomaarsen
          type: user
        html: "<p>That would be awesome!</p>\n<p>I'm running some tests now regarding\
          \ per-entity class metrics. Here's the results:</p>\n<div class=\"max-w-full\
          \ overflow-auto\">\n\t<table>\n\t\t<thead><tr>\n<th><strong>Language</strong></th>\n\
          <th><strong>PER</strong></th>\n<th><strong>ORG</strong></th>\n<th><strong>LOC</strong></th>\n\
          <th><strong>ANIM</strong></th>\n<th><strong>BIO</strong></th>\n<th><strong>CEL</strong></th>\n\
          <th><strong>DIS</strong></th>\n<th><strong>EVE</strong></th>\n<th><strong>FOOD</strong></th>\n\
          <th><strong>INST</strong></th>\n<th><strong>MEDIA</strong></th>\n<th><strong>PLANT</strong></th>\n\
          <th><strong>MYTH</strong></th>\n<th><strong>TIME</strong></th>\n<th><strong>VEHI</strong></th>\n\
          </tr>\n\n\t\t</thead><tbody><tr>\n<td><strong>en</strong></td>\n<td>99.49\
          \ (10530)</td>\n<td>98.31 (6616)</td>\n<td>99.47 (24046)</td>\n<td>76.26\
          \ (3208)</td>\n<td>77.78 (16)</td>\n<td>79.07 (82)</td>\n<td>79.15 (1514)</td>\n\
          <td>97.32 (704)</td>\n<td>68.02 (1132)</td>\n<td>78.58 (24)</td>\n<td>97.93\
          \ (916)</td>\n<td>69.69 (1788)</td>\n<td>86.15 (64)</td>\n<td>85.61 (578)</td>\n\
          <td>86.67 (64)</td>\n</tr>\n<tr>\n<td><strong>zh</strong></td>\n<td>79.71\
          \ (4174)</td>\n<td>61.66 (1926)</td>\n<td>78.79 (3850)</td>\n<td>96.56 (7918)</td>\n\
          <td>71.56 (110)</td>\n<td>83.40 (92)</td>\n<td>78.95 (40)</td>\n<td>84.66\
          \ (1696)</td>\n<td>81.93 (738)</td>\n<td>83.82 (502)</td>\n<td>93.17 (23902)</td>\n\
          <td>86.93 (1682)</td>\n<td>85.40 (780)</td>\n<td>76.12 (152)</td>\n<td>75.61\
          \ (98)</td>\n</tr>\n</tbody>\n\t</table>\n</div>\n<p>The first value is\
          \ the F1, and the second value is the number of entities that were used\
          \ to calculate that F1. I mention it because some entity classes only have\
          \ e.g. 24 entities in the test set. I think the differences are quite fascinating.\
          \ For example the performance of person, organization and locations are\
          \ much better in English, while the Chinese model seems super good at animals\
          \ for some reason.</p>\n"
        raw: 'That would be awesome!


          I''m running some tests now regarding per-entity class metrics. Here''s
          the results:

          | **Language** | **PER** | **ORG** | **LOC** | **ANIM** | **BIO** | **CEL**
          | **DIS** | **EVE** | **FOOD** | **INST** | **MEDIA** | **PLANT** | **MYTH**
          | **TIME** | **VEHI** |

          |-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|

          | **en** | 99.49 (10530) | 98.31 (6616) | 99.47 (24046) | 76.26 (3208) |
          77.78 (16) | 79.07 (82) | 79.15 (1514) | 97.32 (704) | 68.02 (1132) | 78.58
          (24) | 97.93 (916) | 69.69 (1788) | 86.15 (64) | 85.61 (578) | 86.67 (64)
          |

          | **zh** | 79.71 (4174) | 61.66 (1926) | 78.79 (3850) | 96.56 (7918) | 71.56
          (110) | 83.40 (92) | 78.95 (40) | 84.66 (1696) | 81.93 (738) | 83.82 (502)
          | 93.17 (23902) | 86.93 (1682) | 85.40 (780) | 76.12 (152) | 75.61 (98)
          |


          The first value is the F1, and the second value is the number of entities
          that were used to calculate that F1. I mention it because some entity classes
          only have e.g. 24 entities in the test set. I think the differences are
          quite fascinating. For example the performance of person, organization and
          locations are much better in English, while the Chinese model seems super
          good at animals for some reason.'
        updatedAt: '2023-08-14T09:35:40.624Z'
      numEdits: 0
      reactions: []
    id: 64d9f56c52acbd45d36944f6
    type: comment
  author: tomaarsen
  content: 'That would be awesome!


    I''m running some tests now regarding per-entity class metrics. Here''s the results:

    | **Language** | **PER** | **ORG** | **LOC** | **ANIM** | **BIO** | **CEL** |
    **DIS** | **EVE** | **FOOD** | **INST** | **MEDIA** | **PLANT** | **MYTH** | **TIME**
    | **VEHI** |

    |-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|

    | **en** | 99.49 (10530) | 98.31 (6616) | 99.47 (24046) | 76.26 (3208) | 77.78
    (16) | 79.07 (82) | 79.15 (1514) | 97.32 (704) | 68.02 (1132) | 78.58 (24) | 97.93
    (916) | 69.69 (1788) | 86.15 (64) | 85.61 (578) | 86.67 (64) |

    | **zh** | 79.71 (4174) | 61.66 (1926) | 78.79 (3850) | 96.56 (7918) | 71.56 (110)
    | 83.40 (92) | 78.95 (40) | 84.66 (1696) | 81.93 (738) | 83.82 (502) | 93.17 (23902)
    | 86.93 (1682) | 85.40 (780) | 76.12 (152) | 75.61 (98) |


    The first value is the F1, and the second value is the number of entities that
    were used to calculate that F1. I mention it because some entity classes only
    have e.g. 24 entities in the test set. I think the differences are quite fascinating.
    For example the performance of person, organization and locations are much better
    in English, while the Chinese model seems super good at animals for some reason.'
  created_at: 2023-08-14 08:35:40+00:00
  edited: false
  hidden: false
  id: 64d9f56c52acbd45d36944f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-08-14T10:51:08.000Z'
    data:
      edited: false
      editors:
      - lxyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6969634294509888
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
          fullname: Lik Xun Yuan
          isHf: false
          isPro: false
          name: lxyuan
          type: user
        html: "<p>Intuitively, I would look at the number of unique animal entities\
          \ in the Chinese test split and see if we have something interesting.</p>\n\
          <p>Additionally, I quickly glanced through the training and test split on\
          \ the Hugging Face dataset hub. I noticed there are some duplications, and\
          \ a common pattern is that animal entity samples commonly begin with \"\
          redirect # .\" For instance, if you select the train split and click on\
          \ the last page, you will see: </p>\n<pre><code>[ \"R\", \"E\", \"D\", \"\
          I\", \"R\", \"E\", \"C\", \"T\", \"#\", \"\u73B3\", \"\u7441\" ]\t [ 0,\
          \ 0, 0, 0, 0, 0, 0, 0, 0, 7, 8 ] \"zh\"\n[ \"R\", \"E\", \"D\", \"I\", \"\
          R\", \"E\", \"C\", \"T\", \"#\", \"\u73B3\", \"\u7441\" ]\t[ 0, 0, 0, 0,\
          \ 0, 0, 0, 0, 0, 7, 8 ]\t\"zh\"\n[ \"R\", \"E\", \"D\", \"I\", \"R\", \"\
          E\", \"C\", \"T\", \"#\", \"\u73B3\", \"\u7441\" ]\t[ 0, 0, 0, 0, 0, 0,\
          \ 0, 0, 0, 7, 8 ]\t\"zh\"\n[ \"R\", \"E\", \"D\", \"I\", \"R\", \"E\", \"\
          C\", \"T\", \"#\", \"\u73B3\", \"\u7441\" ]\t[ 0, 0, 0, 0, 0, 0, 0, 0, 0,\
          \ 7, 8 ]\t\"zh\"\n</code></pre>\n"
        raw: "Intuitively, I would look at the number of unique animal entities in\
          \ the Chinese test split and see if we have something interesting.\n\nAdditionally,\
          \ I quickly glanced through the training and test split on the Hugging Face\
          \ dataset hub. I noticed there are some duplications, and a common pattern\
          \ is that animal entity samples commonly begin with \"redirect # <animal>.\"\
          \ For instance, if you select the train split and click on the last page,\
          \ you will see: \n```\n[ \"R\", \"E\", \"D\", \"I\", \"R\", \"E\", \"C\"\
          , \"T\", \"#\", \"\u73B3\", \"\u7441\" ]\t [ 0, 0, 0, 0, 0, 0, 0, 0, 0,\
          \ 7, 8 ] \"zh\"\n[ \"R\", \"E\", \"D\", \"I\", \"R\", \"E\", \"C\", \"T\"\
          , \"#\", \"\u73B3\", \"\u7441\" ]\t[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8 ]\t\
          \"zh\"\n[ \"R\", \"E\", \"D\", \"I\", \"R\", \"E\", \"C\", \"T\", \"#\"\
          , \"\u73B3\", \"\u7441\" ]\t[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8 ]\t\"zh\"\n\
          [ \"R\", \"E\", \"D\", \"I\", \"R\", \"E\", \"C\", \"T\", \"#\", \"\u73B3\
          \", \"\u7441\" ]\t[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8 ]\t\"zh\"\n```"
        updatedAt: '2023-08-14T10:51:08.804Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - tomaarsen
    id: 64da071cff83b3386a15c178
    type: comment
  author: lxyuan
  content: "Intuitively, I would look at the number of unique animal entities in the\
    \ Chinese test split and see if we have something interesting.\n\nAdditionally,\
    \ I quickly glanced through the training and test split on the Hugging Face dataset\
    \ hub. I noticed there are some duplications, and a common pattern is that animal\
    \ entity samples commonly begin with \"redirect # <animal>.\" For instance, if\
    \ you select the train split and click on the last page, you will see: \n```\n\
    [ \"R\", \"E\", \"D\", \"I\", \"R\", \"E\", \"C\", \"T\", \"#\", \"\u73B3\", \"\
    \u7441\" ]\t [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8 ] \"zh\"\n[ \"R\", \"E\", \"D\"\
    , \"I\", \"R\", \"E\", \"C\", \"T\", \"#\", \"\u73B3\", \"\u7441\" ]\t[ 0, 0,\
    \ 0, 0, 0, 0, 0, 0, 0, 7, 8 ]\t\"zh\"\n[ \"R\", \"E\", \"D\", \"I\", \"R\", \"\
    E\", \"C\", \"T\", \"#\", \"\u73B3\", \"\u7441\" ]\t[ 0, 0, 0, 0, 0, 0, 0, 0,\
    \ 0, 7, 8 ]\t\"zh\"\n[ \"R\", \"E\", \"D\", \"I\", \"R\", \"E\", \"C\", \"T\"\
    , \"#\", \"\u73B3\", \"\u7441\" ]\t[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8 ]\t\"zh\"\
    \n```"
  created_at: 2023-08-14 09:51:08+00:00
  edited: false
  hidden: false
  id: 64da071cff83b3386a15c178
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
      fullname: Tom Aarsen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomaarsen
      type: user
    createdAt: '2023-08-14T11:03:29.000Z'
    data:
      edited: false
      editors:
      - tomaarsen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9311779737472534
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
          fullname: Tom Aarsen
          isHf: true
          isPro: false
          name: tomaarsen
          type: user
        html: '<p>Ooh, you''re right. That might unfairly skew the F1 of the Chinese
          model.<br>I see some other quirks here too, like lowercase "redirect" and
          some cases of None. I can notify the dataset author with this information.<br>Well
          spotted</p>

          '
        raw: 'Ooh, you''re right. That might unfairly skew the F1 of the Chinese model.

          I see some other quirks here too, like lowercase "redirect" and some cases
          of None. I can notify the dataset author with this information.

          Well spotted'
        updatedAt: '2023-08-14T11:03:29.579Z'
      numEdits: 0
      reactions: []
    id: 64da0a0196f0f217e4ff409d
    type: comment
  author: tomaarsen
  content: 'Ooh, you''re right. That might unfairly skew the F1 of the Chinese model.

    I see some other quirks here too, like lowercase "redirect" and some cases of
    None. I can notify the dataset author with this information.

    Well spotted'
  created_at: 2023-08-14 10:03:29+00:00
  edited: false
  hidden: false
  id: 64da0a0196f0f217e4ff409d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-08-16T09:54:45.000Z'
    data:
      edited: false
      editors:
      - lxyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8327208161354065
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
          fullname: Lik Xun Yuan
          isHf: false
          isPro: false
          name: lxyuan
          type: user
        html: "<blockquote>\n<p>Unrelated, but I wonder if a uncased encoder (e.g.\
          \ <a href=\"https://huggingface.co/bert-base-multilingual-uncased\">bert-base-multilingual-uncased</a>)\
          \ would perform better for entities that are often times not capitalized,\
          \ like foods.</p>\n</blockquote>\n<blockquote>\n<p>Interesting observation!\
          \ Happy to run another experiment using <code>bert-base-multilingual-uncased</code>\
          \ and compare the results. I will definitely ping you again when I complete\
          \ the training.</p>\n</blockquote>\n<p>The finetuned version of  <code>bert-base-multilingual-uncased</code>\
          \ on the <code>Babelscape/multinerd</code> dataset is ready and we got some\
          \ interesting findings as well.</p>\n<p>Link: <a href=\"https://huggingface.co/lxyuan/span-marker-bert-base-multilingual-uncased-multinerd\"\
          >https://huggingface.co/lxyuan/span-marker-bert-base-multilingual-uncased-multinerd</a></p>\n\
          <p>CC: <span data-props=\"{&quot;user&quot;:&quot;tomaarsen&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/tomaarsen\">@<span class=\"\
          underline\">tomaarsen</span></a></span>\n\n\t</span></span>  </p>\n"
        raw: "> Unrelated, but I wonder if a uncased encoder (e.g. [bert-base-multilingual-uncased](https://huggingface.co/bert-base-multilingual-uncased))\
          \ would perform better for entities that are often times not capitalized,\
          \ like foods.\n\n> Interesting observation! Happy to run another experiment\
          \ using `bert-base-multilingual-uncased` and compare the results. I will\
          \ definitely ping you again when I complete the training.\n\nThe finetuned\
          \ version of  `bert-base-multilingual-uncased` on the `Babelscape/multinerd`\
          \ dataset is ready and we got some interesting findings as well.\n\nLink:\
          \ https://huggingface.co/lxyuan/span-marker-bert-base-multilingual-uncased-multinerd\n\
          \nCC: @tomaarsen  \n\n"
        updatedAt: '2023-08-16T09:54:45.870Z'
      numEdits: 0
      reactions: []
    id: 64dc9ce580e316d0b795821e
    type: comment
  author: lxyuan
  content: "> Unrelated, but I wonder if a uncased encoder (e.g. [bert-base-multilingual-uncased](https://huggingface.co/bert-base-multilingual-uncased))\
    \ would perform better for entities that are often times not capitalized, like\
    \ foods.\n\n> Interesting observation! Happy to run another experiment using `bert-base-multilingual-uncased`\
    \ and compare the results. I will definitely ping you again when I complete the\
    \ training.\n\nThe finetuned version of  `bert-base-multilingual-uncased` on the\
    \ `Babelscape/multinerd` dataset is ready and we got some interesting findings\
    \ as well.\n\nLink: https://huggingface.co/lxyuan/span-marker-bert-base-multilingual-uncased-multinerd\n\
    \nCC: @tomaarsen  \n\n"
  created_at: 2023-08-16 08:54:45+00:00
  edited: false
  hidden: false
  id: 64dc9ce580e316d0b795821e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
      fullname: Tom Aarsen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomaarsen
      type: user
    createdAt: '2023-08-16T10:37:45.000Z'
    data:
      edited: false
      editors:
      - tomaarsen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9288238286972046
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
          fullname: Tom Aarsen
          isHf: true
          isPro: false
          name: tomaarsen
          type: user
        html: '<p>Very interesting behaviour indeed. I do tend to see that a cased
          model outperforms the uncased variant slightly, although users tend to prefer
          uncased versions as it works on both lowercase and uppercase text. I tried
          out your model for a bit and it seems quite strong, although I do agree
          that none of the models do great on food or plants. I think this might be
          caused by the dataset?</p>

          <p>As you can see, lowercase text works  very well:<br><a rel="nofollow"
          href="https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/8_IgEfLROMKT2NaXRSQMj.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/8_IgEfLROMKT2NaXRSQMj.png"></a></p>

          <p>If I use that same text in this cased model, then it doesn''t even find
          any entities:<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/DyLTlggn8BtNzwDpywuD1.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/DyLTlggn8BtNzwDpywuD1.png"></a></p>

          <p>(For reference, both models work perfectly with capitalized text)</p>

          <hr>

          <p>At this point I have the following recommendations:</p>

          <ol>

          <li>Cross-reference the models at the top of the model cards.</li>

          <li>Add examples for the Hosted Inference API widget. We want to show people
          that the model is awesome, but people won''t really be able to come up with
          difficult examples quickly. The examples help with that.</li>

          </ol>

          <p>I can make PRs for these.</p>

          '
        raw: 'Very interesting behaviour indeed. I do tend to see that a cased model
          outperforms the uncased variant slightly, although users tend to prefer
          uncased versions as it works on both lowercase and uppercase text. I tried
          out your model for a bit and it seems quite strong, although I do agree
          that none of the models do great on food or plants. I think this might be
          caused by the dataset?


          As you can see, lowercase text works  very well:

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/8_IgEfLROMKT2NaXRSQMj.png)


          If I use that same text in this cased model, then it doesn''t even find
          any entities:

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/DyLTlggn8BtNzwDpywuD1.png)


          (For reference, both models work perfectly with capitalized text)


          ---


          At this point I have the following recommendations:

          1. Cross-reference the models at the top of the model cards.

          2. Add examples for the Hosted Inference API widget. We want to show people
          that the model is awesome, but people won''t really be able to come up with
          difficult examples quickly. The examples help with that.


          I can make PRs for these.'
        updatedAt: '2023-08-16T10:37:45.873Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - lxyuan
    id: 64dca6f909563e71e2112052
    type: comment
  author: tomaarsen
  content: 'Very interesting behaviour indeed. I do tend to see that a cased model
    outperforms the uncased variant slightly, although users tend to prefer uncased
    versions as it works on both lowercase and uppercase text. I tried out your model
    for a bit and it seems quite strong, although I do agree that none of the models
    do great on food or plants. I think this might be caused by the dataset?


    As you can see, lowercase text works  very well:

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/8_IgEfLROMKT2NaXRSQMj.png)


    If I use that same text in this cased model, then it doesn''t even find any entities:

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/DyLTlggn8BtNzwDpywuD1.png)


    (For reference, both models work perfectly with capitalized text)


    ---


    At this point I have the following recommendations:

    1. Cross-reference the models at the top of the model cards.

    2. Add examples for the Hosted Inference API widget. We want to show people that
    the model is awesome, but people won''t really be able to come up with difficult
    examples quickly. The examples help with that.


    I can make PRs for these.'
  created_at: 2023-08-16 09:37:45+00:00
  edited: false
  hidden: false
  id: 64dca6f909563e71e2112052
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-08-16T10:59:34.000Z'
    data:
      edited: false
      editors:
      - lxyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9681456089019775
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
          fullname: Lik Xun Yuan
          isHf: false
          isPro: false
          name: lxyuan
          type: user
        html: '<blockquote>

          <p>although I do agree that none of the models do great on food or plants.
          I think this might be caused by the dataset?</p>

          </blockquote>

          <p>Agree. The dataset (i.e., type of sentence and sentence quality) will
          have a huge impact on model performance for different entities.</p>

          <p>Thanks for submitting all the PRs and your training scripts. </p>

          '
        raw: '> although I do agree that none of the models do great on food or plants.
          I think this might be caused by the dataset?


          Agree. The dataset (i.e., type of sentence and sentence quality) will have
          a huge impact on model performance for different entities.


          Thanks for submitting all the PRs and your training scripts. '
        updatedAt: '2023-08-16T10:59:34.261Z'
      numEdits: 0
      reactions: []
    id: 64dcac16a4b9ebcd2b05e6c6
    type: comment
  author: lxyuan
  content: '> although I do agree that none of the models do great on food or plants.
    I think this might be caused by the dataset?


    Agree. The dataset (i.e., type of sentence and sentence quality) will have a huge
    impact on model performance for different entities.


    Thanks for submitting all the PRs and your training scripts. '
  created_at: 2023-08-16 09:59:34+00:00
  edited: false
  hidden: false
  id: 64dcac16a4b9ebcd2b05e6c6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
      fullname: Tom Aarsen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomaarsen
      type: user
    createdAt: '2023-08-16T11:07:16.000Z'
    data:
      edited: false
      editors:
      - tomaarsen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9824654459953308
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
          fullname: Tom Aarsen
          isHf: true
          isPro: false
          name: tomaarsen
          type: user
        html: '<p>Indeed. I''ve noticed it with my models trained on data from Arxiv
          papers: they don''t work as well on informal text.<br>Is it okay if I share
          this model on my LinkedIn over the next few days? It''s totally okay if
          you''d rather that I don''t :)</p>

          '
        raw: "Indeed. I've noticed it with my models trained on data from Arxiv papers:\
          \ they don't work as well on informal text. \nIs it okay if I share this\
          \ model on my LinkedIn over the next few days? It's totally okay if you'd\
          \ rather that I don't :)"
        updatedAt: '2023-08-16T11:07:16.338Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - lxyuan
    id: 64dcade44e2c7863c30568dc
    type: comment
  author: tomaarsen
  content: "Indeed. I've noticed it with my models trained on data from Arxiv papers:\
    \ they don't work as well on informal text. \nIs it okay if I share this model\
    \ on my LinkedIn over the next few days? It's totally okay if you'd rather that\
    \ I don't :)"
  created_at: 2023-08-16 10:07:16+00:00
  edited: false
  hidden: false
  id: 64dcade44e2c7863c30568dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-08-16T11:21:46.000Z'
    data:
      edited: false
      editors:
      - lxyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9127373695373535
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
          fullname: Lik Xun Yuan
          isHf: false
          isPro: false
          name: lxyuan
          type: user
        html: '<p>Sure, go ahead! Happy to be mentioned on LinkedIn.</p>

          '
        raw: Sure, go ahead! Happy to be mentioned on LinkedIn.
        updatedAt: '2023-08-16T11:21:46.551Z'
      numEdits: 0
      reactions: []
    id: 64dcb14a5e16f5b12b2708b3
    type: comment
  author: lxyuan
  content: Sure, go ahead! Happy to be mentioned on LinkedIn.
  created_at: 2023-08-16 10:21:46+00:00
  edited: false
  hidden: false
  id: 64dcb14a5e16f5b12b2708b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-08-28T15:41:01.000Z'
    data:
      status: closed
    id: 64ecc00d8a351f5b738bdd7d
    type: status-change
  author: lxyuan
  created_at: 2023-08-28 14:41:01+00:00
  id: 64ecc00d8a351f5b738bdd7d
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: lxyuan/span-marker-bert-base-multilingual-cased-multinerd
repo_type: model
status: closed
target_branch: null
title: Metrics per language
