!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TahaKhan
conflicting_files: null
created_at: 2023-07-17 11:42:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/424af21246412264a05094927ef6052f.svg
      fullname: Muhammad Taha Khan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TahaKhan
      type: user
    createdAt: '2023-07-17T12:42:08.000Z'
    data:
      edited: false
      editors:
      - TahaKhan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9378806352615356
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/424af21246412264a05094927ef6052f.svg
          fullname: Muhammad Taha Khan
          isHf: false
          isPro: false
          name: TahaKhan
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;nmitchko&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nmitchko\"\
          >@<span class=\"underline\">nmitchko</span></a></span>\n\n\t</span></span>\
          \ ,</p>\n<p>I am a data science beginner and would like to achieve something\
          \ similar on a dataset I have:<br>I want to fine-tune guanaco on a specific\
          \ product and technical documentation.<br>In order to do so, I am preparing\
          \ a strategy to create, and/or collect high quality dataset for fine tuning.\
          \ </p>\n<p>For this purpose, I am looking to learn from experiences of people\
          \ who have already done so and I found you while looking for people with\
          \ experience of fine tuning guanaco.</p>\n<p>I wanted to ask if you will\
          \ be willing to share some examples from your dataset that you used in your\
          \ fine tuning?<br>Would it be possible for you to please share some examples\
          \ from each category of your dataset? </p>\n<p>I will be happy to get any\
          \ other insights that you would like to share. </p>\n<p>Looking forward\
          \ to your response. :) </p>\n<p>Best,<br>Taha. </p>\n"
        raw: "Hello @nmitchko ,\r\n\r\nI am a data science beginner and would like\
          \ to achieve something similar on a dataset I have:\r\nI want to fine-tune\
          \ guanaco on a specific product and technical documentation.\r\nIn order\
          \ to do so, I am preparing a strategy to create, and/or collect high quality\
          \ dataset for fine tuning. \r\n\r\nFor this purpose, I am looking to learn\
          \ from experiences of people who have already done so and I found you while\
          \ looking for people with experience of fine tuning guanaco.\r\n\r\nI wanted\
          \ to ask if you will be willing to share some examples from your dataset\
          \ that you used in your fine tuning? \r\nWould it be possible for you to\
          \ please share some examples from each category of your dataset? \r\n\r\n\
          I will be happy to get any other insights that you would like to share.\
          \ \r\n\r\nLooking forward to your response. :) \r\n\r\nBest,\r\nTaha. "
        updatedAt: '2023-07-17T12:42:08.362Z'
      numEdits: 0
      reactions: []
    id: 64b537200a54158d66427980
    type: comment
  author: TahaKhan
  content: "Hello @nmitchko ,\r\n\r\nI am a data science beginner and would like to\
    \ achieve something similar on a dataset I have:\r\nI want to fine-tune guanaco\
    \ on a specific product and technical documentation.\r\nIn order to do so, I am\
    \ preparing a strategy to create, and/or collect high quality dataset for fine\
    \ tuning. \r\n\r\nFor this purpose, I am looking to learn from experiences of\
    \ people who have already done so and I found you while looking for people with\
    \ experience of fine tuning guanaco.\r\n\r\nI wanted to ask if you will be willing\
    \ to share some examples from your dataset that you used in your fine tuning?\
    \ \r\nWould it be possible for you to please share some examples from each category\
    \ of your dataset? \r\n\r\nI will be happy to get any other insights that you\
    \ would like to share. \r\n\r\nLooking forward to your response. :) \r\n\r\nBest,\r\
    \nTaha. "
  created_at: 2023-07-17 11:42:08+00:00
  edited: false
  hidden: false
  id: 64b537200a54158d66427980
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/72660963812ee19b654fb3111cb7e5ad.svg
      fullname: Nicholai
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nmitchko
      type: user
    createdAt: '2023-07-20T19:14:04.000Z'
    data:
      edited: false
      editors:
      - nmitchko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.804631769657135
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/72660963812ee19b654fb3111cb7e5ad.svg
          fullname: Nicholai
          isHf: false
          isPro: false
          name: nmitchko
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;TahaKhan&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TahaKhan\"\
          >@<span class=\"underline\">TahaKhan</span></a></span>\n\n\t</span></span>\
          \ </p>\n<p>Firstly, I fine-tune using <a rel=\"nofollow\" href=\"https://github.com/artidoro/qlora\"\
          >Qlora</a>. This let's me create a lora with limited hw through 4-bit inference\
          \ and full-precision LoRAs.</p>\n<p>As for datasets, you can use <a rel=\"\
          nofollow\" href=\"https://github.com/LAION-AI/Open-Assistant\">OpenAssistant</a>\
          \ to create a high quality dataset for your task. </p>\n<p>On product documentation,\
          \ you shouldn't finetune a model on your first go, instead, try using a\
          \ context database first, and test the results against the base model. If\
          \ that has limitations, then explore creating a finetuned model.</p>\n<p>Here\
          \ is an example of using a model without finetuning on PDF documentation.\
          \ <a href=\"https://huggingface.co/spaces/Logspace/Langflow\">LangFlow</a>\
          \ is a great way to test this out. See the \"PDF Loader\" Flow.</p>\n"
        raw: "Hi @TahaKhan \n\nFirstly, I fine-tune using [Qlora](https://github.com/artidoro/qlora).\
          \ This let's me create a lora with limited hw through 4-bit inference and\
          \ full-precision LoRAs.\n\nAs for datasets, you can use [OpenAssistant](https://github.com/LAION-AI/Open-Assistant)\
          \ to create a high quality dataset for your task. \n\nOn product documentation,\
          \ you shouldn't finetune a model on your first go, instead, try using a\
          \ context database first, and test the results against the base model. If\
          \ that has limitations, then explore creating a finetuned model.\n\nHere\
          \ is an example of using a model without finetuning on PDF documentation.\
          \ [LangFlow](https://huggingface.co/spaces/Logspace/Langflow) is a great\
          \ way to test this out. See the \"PDF Loader\" Flow."
        updatedAt: '2023-07-20T19:14:04.505Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - TahaKhan
    id: 64b9877c0b24527e9c2325d4
    type: comment
  author: nmitchko
  content: "Hi @TahaKhan \n\nFirstly, I fine-tune using [Qlora](https://github.com/artidoro/qlora).\
    \ This let's me create a lora with limited hw through 4-bit inference and full-precision\
    \ LoRAs.\n\nAs for datasets, you can use [OpenAssistant](https://github.com/LAION-AI/Open-Assistant)\
    \ to create a high quality dataset for your task. \n\nOn product documentation,\
    \ you shouldn't finetune a model on your first go, instead, try using a context\
    \ database first, and test the results against the base model. If that has limitations,\
    \ then explore creating a finetuned model.\n\nHere is an example of using a model\
    \ without finetuning on PDF documentation. [LangFlow](https://huggingface.co/spaces/Logspace/Langflow)\
    \ is a great way to test this out. See the \"PDF Loader\" Flow."
  created_at: 2023-07-20 18:14:04+00:00
  edited: false
  hidden: false
  id: 64b9877c0b24527e9c2325d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/72660963812ee19b654fb3111cb7e5ad.svg
      fullname: Nicholai
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nmitchko
      type: user
    createdAt: '2023-07-20T19:27:03.000Z'
    data:
      edited: false
      editors:
      - nmitchko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8428298830986023
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/72660963812ee19b654fb3111cb7e5ad.svg
          fullname: Nicholai
          isHf: false
          isPro: false
          name: nmitchko
          type: user
        html: "<p>As for the dataset format, here is what the input data looks like:</p>\n\
          <p><code>medconcat.json</code></p>\n<pre><code class=\"language-json\"><span\
          \ class=\"hljs-punctuation\">[</span>\n    <span class=\"hljs-punctuation\"\
          >{</span><span class=\"hljs-attr\">\"instruction\"</span><span class=\"\
          hljs-punctuation\">:</span> <span class=\"hljs-string\">\"Answer this question\
          \ truthfully\"</span><span class=\"hljs-punctuation\">,</span> \n     <span\
          \ class=\"hljs-attr\">\"input\"</span><span class=\"hljs-punctuation\">:</span>\
          \ <span class=\"hljs-string\">\"What to expect if I have Varicose veins\
          \  (Outlook/Prognosis)?\"</span><span class=\"hljs-punctuation\">,</span>\
          \ \n     <span class=\"hljs-attr\">\"output\"</span><span class=\"hljs-punctuation\"\
          >:</span> <span class=\"hljs-string\">\"Varicose veins tend to get worse\
          \ over time. You can ease discomfort and slow varicose vein progression\
          \ with self care.\"</span><span class=\"hljs-punctuation\">}</span><span\
          \ class=\"hljs-punctuation\">,</span>\n    <span class=\"hljs-punctuation\"\
          >{</span> <span class=\"hljs-attr\">\"instruction\"</span><span class=\"\
          hljs-punctuation\">:</span> <span class=\"hljs-string\">\"....\"</span>\
          \ ...\n<span class=\"hljs-punctuation\">]</span>\n</code></pre>\n<p>During\
          \ each training pass, each item in the dataset gets parsed into the <a rel=\"\
          nofollow\" href=\"https://github.com/tatsu-lab/stanford_alpaca#data-release\"\
          >alpaca instruction format</a>:</p>\n<pre><code class=\"language-python\"\
          >instruction = <span class=\"hljs-string\">f\"\"\"Below is an instruction\
          \ that describes a task, paired with an input that provides further context.\
          \ Write a response that appropriately completes the request.</span>\n<span\
          \ class=\"hljs-string\"></span>\n<span class=\"hljs-string\">### Instruction:</span>\n\
          <span class=\"hljs-string\"><span class=\"hljs-subst\">{instruction}</span></span>\n\
          <span class=\"hljs-string\"></span>\n<span class=\"hljs-string\">### Input:</span>\n\
          <span class=\"hljs-string\"><span class=\"hljs-subst\">{<span class=\"hljs-built_in\"\
          >input</span>}</span></span>\n<span class=\"hljs-string\"></span>\n<span\
          \ class=\"hljs-string\">### Response:\"\"\"</span>\n</code></pre>\n<p>and\
          \ the training target is that the next tokens are equal to the <code>{output}</code>\
          \ for each instruction tuned</p>\n"
        raw: "As for the dataset format, here is what the input data looks like:\n\
          \n`medconcat.json`\n```json\n[\n    {\"instruction\": \"Answer this question\
          \ truthfully\", \n     \"input\": \"What to expect if I have Varicose veins\
          \  (Outlook/Prognosis)?\", \n     \"output\": \"Varicose veins tend to get\
          \ worse over time. You can ease discomfort and slow varicose vein progression\
          \ with self care.\"},\n    { \"instruction\": \"....\" ...\n]\n```\n\nDuring\
          \ each training pass, each item in the dataset gets parsed into the [alpaca\
          \ instruction format](https://github.com/tatsu-lab/stanford_alpaca#data-release):\n\
          \n```python\ninstruction = f\"\"\"Below is an instruction that describes\
          \ a task, paired with an input that provides further context. Write a response\
          \ that appropriately completes the request.\n\n### Instruction:\n{instruction}\n\
          \n### Input:\n{input}\n\n### Response:\"\"\"\n```\n\nand the training target\
          \ is that the next tokens are equal to the `{output}` for each instruction\
          \ tuned"
        updatedAt: '2023-07-20T19:27:03.326Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - TahaKhan
    id: 64b98a870b24527e9c238698
    type: comment
  author: nmitchko
  content: "As for the dataset format, here is what the input data looks like:\n\n\
    `medconcat.json`\n```json\n[\n    {\"instruction\": \"Answer this question truthfully\"\
    , \n     \"input\": \"What to expect if I have Varicose veins  (Outlook/Prognosis)?\"\
    , \n     \"output\": \"Varicose veins tend to get worse over time. You can ease\
    \ discomfort and slow varicose vein progression with self care.\"},\n    { \"\
    instruction\": \"....\" ...\n]\n```\n\nDuring each training pass, each item in\
    \ the dataset gets parsed into the [alpaca instruction format](https://github.com/tatsu-lab/stanford_alpaca#data-release):\n\
    \n```python\ninstruction = f\"\"\"Below is an instruction that describes a task,\
    \ paired with an input that provides further context. Write a response that appropriately\
    \ completes the request.\n\n### Instruction:\n{instruction}\n\n### Input:\n{input}\n\
    \n### Response:\"\"\"\n```\n\nand the training target is that the next tokens\
    \ are equal to the `{output}` for each instruction tuned"
  created_at: 2023-07-20 18:27:03+00:00
  edited: false
  hidden: false
  id: 64b98a870b24527e9c238698
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/424af21246412264a05094927ef6052f.svg
      fullname: Muhammad Taha Khan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TahaKhan
      type: user
    createdAt: '2023-07-20T19:37:37.000Z'
    data:
      edited: true
      editors:
      - TahaKhan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9113695621490479
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/424af21246412264a05094927ef6052f.svg
          fullname: Muhammad Taha Khan
          isHf: false
          isPro: false
          name: TahaKhan
          type: user
        html: "<p>Thank you <span data-props=\"{&quot;user&quot;:&quot;nmitchko&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nmitchko\"\
          >@<span class=\"underline\">nmitchko</span></a></span>\n\n\t</span></span>\
          \ for your insights, and your advices. </p>\n<p>Please bear with me on a\
          \ seemingly dumb question: </p>\n<ul>\n<li>Why can I not use guanaco itself\
          \ to create a high quality dataset? You proposed using OpenAssistant, there\
          \ must be some wisdom behind it. Can you please tell me what that is? :D</li>\n\
          </ul>\n<p>Again, I thank you very much!  </p>\n"
        raw: "Thank you @nmitchko for your insights, and your advices. \n\nPlease\
          \ bear with me on a seemingly dumb question: \n- Why can I not use guanaco\
          \ itself to create a high quality dataset? You proposed using OpenAssistant,\
          \ there must be some wisdom behind it. Can you please tell me what that\
          \ is? :D \n\nAgain, I thank you very much!  "
        updatedAt: '2023-07-20T19:46:30.621Z'
      numEdits: 3
      reactions: []
    id: 64b98d01b7af2cf5150bd66c
    type: comment
  author: TahaKhan
  content: "Thank you @nmitchko for your insights, and your advices. \n\nPlease bear\
    \ with me on a seemingly dumb question: \n- Why can I not use guanaco itself to\
    \ create a high quality dataset? You proposed using OpenAssistant, there must\
    \ be some wisdom behind it. Can you please tell me what that is? :D \n\nAgain,\
    \ I thank you very much!  "
  created_at: 2023-07-20 18:37:37+00:00
  edited: true
  hidden: false
  id: 64b98d01b7af2cf5150bd66c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/72660963812ee19b654fb3111cb7e5ad.svg
      fullname: Nicholai
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nmitchko
      type: user
    createdAt: '2023-07-21T02:41:29.000Z'
    data:
      edited: false
      editors:
      - nmitchko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8985303044319153
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/72660963812ee19b654fb3111cb7e5ad.svg
          fullname: Nicholai
          isHf: false
          isPro: false
          name: nmitchko
          type: user
        html: '<p>While you may think an AI model can autoencode your data for you,
          human input learning creates a much better dataset than just using guanaco
          alone.</p>

          '
        raw: While you may think an AI model can autoencode your data for you, human
          input learning creates a much better dataset than just using guanaco alone.
        updatedAt: '2023-07-21T02:41:29.305Z'
      numEdits: 0
      reactions: []
    id: 64b9f059b3bd26c44b0d99f1
    type: comment
  author: nmitchko
  content: While you may think an AI model can autoencode your data for you, human
    input learning creates a much better dataset than just using guanaco alone.
  created_at: 2023-07-21 01:41:29+00:00
  edited: false
  hidden: false
  id: 64b9f059b3bd26c44b0d99f1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: nmitchko/medguanaco-lora-65b-GPTQ
repo_type: model
status: open
target_branch: null
title: Insights on dataset
