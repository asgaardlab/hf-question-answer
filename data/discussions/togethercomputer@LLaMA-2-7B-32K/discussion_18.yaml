!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MathewOpt
conflicting_files: null
created_at: 2023-08-15 22:00:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c9ba2e8bf38437dcec6da17b28bf73b5.svg
      fullname: Mathew S
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MathewOpt
      type: user
    createdAt: '2023-08-15T23:00:41.000Z'
    data:
      edited: false
      editors:
      - MathewOpt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9549614191055298
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c9ba2e8bf38437dcec6da17b28bf73b5.svg
          fullname: Mathew S
          isHf: false
          isPro: false
          name: MathewOpt
          type: user
        html: '<p>Is "togethercomputer/LLaMA-2-7B-32K" already trained for answering
          questions from long text? I see that it was fine-tuned on "20% Natural Instructions
          (NI), 20% Public Pool of Prompts (P3)". Please confirm. I tried the model
          as it is for question-answering using one of the samples in the Long Data
          Collections dataset, but it doesn''t seem to answer correctly.</p>

          '
        raw: "Is \"togethercomputer/LLaMA-2-7B-32K\" already trained for answering\
          \ questions from long text? I see that it was fine-tuned on \"20% Natural\
          \ Instructions (NI), 20% Public Pool of Prompts (P3)\". Please confirm.\
          \ I tried the model as it is for question-answering using one of the samples\
          \ in the Long Data Collections dataset, but it doesn't seem to answer correctly.\r\
          \n\r\n"
        updatedAt: '2023-08-15T23:00:41.368Z'
      numEdits: 0
      reactions: []
    id: 64dc0399e7bc8544f9b10555
    type: comment
  author: MathewOpt
  content: "Is \"togethercomputer/LLaMA-2-7B-32K\" already trained for answering questions\
    \ from long text? I see that it was fine-tuned on \"20% Natural Instructions (NI),\
    \ 20% Public Pool of Prompts (P3)\". Please confirm. I tried the model as it is\
    \ for question-answering using one of the samples in the Long Data Collections\
    \ dataset, but it doesn't seem to answer correctly.\r\n\r\n"
  created_at: 2023-08-15 22:00:41+00:00
  edited: false
  hidden: false
  id: 64dc0399e7bc8544f9b10555
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/c9ba2e8bf38437dcec6da17b28bf73b5.svg
      fullname: Mathew S
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MathewOpt
      type: user
    createdAt: '2023-08-15T23:02:52.000Z'
    data:
      from: Is "togethercomputer/LLaMA-2-7B-32K" already fine-tuned for answering
        questions from long text?
      to: Is LLaMA-2-7B-32K  already fine-tuned for answering questions from long
        text?
    id: 64dc041c7f749b6e3469fdfd
    type: title-change
  author: MathewOpt
  created_at: 2023-08-15 22:02:52+00:00
  id: 64dc041c7f749b6e3469fdfd
  new_title: Is LLaMA-2-7B-32K  already fine-tuned for answering questions from long
    text?
  old_title: Is "togethercomputer/LLaMA-2-7B-32K" already fine-tuned for answering
    questions from long text?
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/277ff242cf15b380b80bdabfc0cfa030.svg
      fullname: Ce Zhang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: zhangce
      type: user
    createdAt: '2023-08-18T17:00:18.000Z'
    data:
      edited: true
      editors:
      - zhangce
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7525715231895447
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/277ff242cf15b380b80bdabfc0cfa030.svg
          fullname: Ce Zhang
          isHf: false
          isPro: false
          name: zhangce
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;MathewOpt&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/MathewOpt\">@<span class=\"\
          underline\">MathewOpt</span></a></span>\n\n\t</span></span> We now have\
          \ an instruct version that is fine-tunned on QA <a href=\"https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct\"\
          >https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct</a></p>\n\
          <p>More details here: <a rel=\"nofollow\" href=\"https://together.ai/blog/llama-2-7b-32k-instruct\"\
          >https://together.ai/blog/llama-2-7b-32k-instruct</a></p>\n<p>Let us know\
          \ if this works!</p>\n"
        raw: '@MathewOpt We now have an instruct version that is fine-tunned on QA
          https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct


          More details here: https://together.ai/blog/llama-2-7b-32k-instruct


          Let us know if this works!'
        updatedAt: '2023-08-18T17:00:47.615Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MathewOpt
    id: 64dfa3a2c1691b57781db0aa
    type: comment
  author: zhangce
  content: '@MathewOpt We now have an instruct version that is fine-tunned on QA https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct


    More details here: https://together.ai/blog/llama-2-7b-32k-instruct


    Let us know if this works!'
  created_at: 2023-08-18 16:00:18+00:00
  edited: true
  hidden: false
  id: 64dfa3a2c1691b57781db0aa
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: togethercomputer/LLaMA-2-7B-32K
repo_type: model
status: open
target_branch: null
title: Is LLaMA-2-7B-32K  already fine-tuned for answering questions from long text?
