!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AndyLLama
conflicting_files: null
created_at: 2023-10-19 05:26:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a312fb3f668f4e918a739862bfe96b59.svg
      fullname: Andy Davies
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AndyLLama
      type: user
    createdAt: '2023-10-19T06:26:38.000Z'
    data:
      edited: false
      editors:
      - AndyLLama
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6772068738937378
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a312fb3f668f4e918a739862bfe96b59.svg
          fullname: Andy Davies
          isHf: false
          isPro: false
          name: AndyLLama
          type: user
        html: "<p>Hi,<br>I'm new to LLM and trying to install but having great difficulty.<br>Ubuntu\
          \ 22.04 with Nvidia 4080 card.<br>running nvidia-smi I have cuda 12.0 installed\
          \ and driver 525.125.06<br>When I try to run the README.md steps:<br>pip\
          \ install transformers==4.31.0<br>pip install sentencepiece<br>pip install\
          \ ninja<br>pip install flash-attn --no-build-isolation<br>pip install git+<a\
          \ rel=\"nofollow\" href=\"https://github.com/HazyResearch/flash-attention.git#subdirectory\"\
          >https://github.com/HazyResearch/flash-attention.git#subdirectory</a> =csrc/rotary<br>Everything\
          \ works except the last step where I get:<br>  Running command git submodule\
          \ update --init --recursive -q<br>  Preparing metadata (setup.py) ... error<br>\
          \  error: subprocess-exited-with-error</p>\n<p>  \xD7 python setup.py egg_info\
          \ did not run successfully.<br>  \u2502 exit code: 1<br>  \u2570\u2500&gt;\
          \ [28 lines of output]<br>      /home/ai/.local/lib/python3.10/site-packages/torch/cuda/<strong>init</strong>.py:107:\
          \ UserWarning: CUDA initialization: CUDA unknown error - this may be due\
          \ to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES\
          \ after program start. Setting the available devices to be zero. (Triggered\
          \ internally at ../c10/cuda/CUDAFunctions.cpp:109.)<br>        return torch._C._cuda_getDeviceCount()\
          \ &gt; 0<br>      No CUDA runtime is found, using CUDA_HOME='/opt/cuda/bin'<br>\
          \      Traceback (most recent call last):<br>        File \"\", line 2,\
          \ in <br>        File \"\", line 34, in <br>        File \"/tmp/pip-req-build-7w_ksy4l/csrc/rotary/setup.py\"\
          , line 74, in <br>          _, bare_metal_version = get_cuda_bare_metal_version(CUDA_HOME)<br>\
          \        File \"/tmp/pip-req-build-7w_ksy4l/csrc/rotary/setup.py\", line\
          \ 17, in get_cuda_bare_metal_version<br>          raw_output = subprocess.check_output([cuda_dir\
          \ + \"/bin/nvcc\", \"-V\"], universal_newlines=True)<br>        File \"\
          /usr/lib/python3.10/subprocess.py\", line 421, in check_output<br>     \
          \     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,<br>\
          \        File \"/usr/lib/python3.10/subprocess.py\", line 503, in run<br>\
          \          with Popen(*popenargs, **kwargs) as process:<br>        File\
          \ \"/usr/lib/python3.10/subprocess.py\", line 971, in <strong>init</strong><br>\
          \          self._execute_child(args, executable, preexec_fn, close_fds,<br>\
          \        File \"/usr/lib/python3.10/subprocess.py\", line 1863, in _execute_child<br>\
          \          raise child_exception_type(errno_num, err_msg, err_filename)<br>\
          \      FileNotFoundError: [Errno 2] No such file or directory: '/opt/cuda/bin/bin/nvcc'</p>\n\
          <pre><code>  Warning: Torch did not find available GPUs on this system.\n\
          \   If your intention is to cross-compile, this is not an error.\n  By default,\
          \ Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n\
          \  Volta (compute capability 7.0), Turing (compute capability 7.5),\n  and,\
          \ if the CUDA version is &gt;= 11.0, Ampere (compute capability 8.0).\n\
          \  If you wish to cross-compile for a single specific architecture,\n  export\
          \ TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n\
          \n  [end of output]\n</code></pre>\n<p>  note: This error originates from\
          \ a subprocess, and is likely not a problem with pip.<br>error: metadata-generation-failed</p>\n\
          <p>\xD7 Encountered error while generating package metadata.<br>\u2570\u2500\
          &gt; See above for output.</p>\n<p>note: This is an issue with the package\
          \ mentioned above, not pip.<br>hint: See above for details.</p>\n<p>Not\
          \ sure how to fix the above I've been going in circle trying different versions\
          \ of software/installing/uninstalling for over a week with no luck.</p>\n\
          <p>Thanks for any help.</p>\n"
        raw: "Hi,\r\nI'm new to LLM and trying to install but having great difficulty.\r\
          \nUbuntu 22.04 with Nvidia 4080 card.  \r\nrunning nvidia-smi I have cuda\
          \ 12.0 installed and driver 525.125.06\r\nWhen I try to run the README.md\
          \ steps:\r\npip install transformers==4.31.0\r\npip install sentencepiece\r\
          \npip install ninja\r\npip install flash-attn --no-build-isolation\r\npip\
          \ install git+https://github.com/HazyResearch/flash-attention.git#subdirectory\
          \ =csrc/rotary\r\nEverything works except the last step where I get:\r\n\
          \  Running command git submodule update --init --recursive -q\r\n  Preparing\
          \ metadata (setup.py) ... error\r\n  error: subprocess-exited-with-error\r\
          \n\r\n  \xD7 python setup.py egg_info did not run successfully.\r\n  \u2502\
          \ exit code: 1\r\n  \u2570\u2500> [28 lines of output]\r\n      /home/ai/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:107:\
          \ UserWarning: CUDA initialization: CUDA unknown error - this may be due\
          \ to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES\
          \ after program start. Setting the available devices to be zero. (Triggered\
          \ internally at ../c10/cuda/CUDAFunctions.cpp:109.)\r\n        return torch._C._cuda_getDeviceCount()\
          \ > 0\r\n      No CUDA runtime is found, using CUDA_HOME='/opt/cuda/bin'\r\
          \n      Traceback (most recent call last):\r\n        File \"<string>\"\
          , line 2, in <module>\r\n        File \"<pip-setuptools-caller>\", line\
          \ 34, in <module>\r\n        File \"/tmp/pip-req-build-7w_ksy4l/csrc/rotary/setup.py\"\
          , line 74, in <module>\r\n          _, bare_metal_version = get_cuda_bare_metal_version(CUDA_HOME)\r\
          \n        File \"/tmp/pip-req-build-7w_ksy4l/csrc/rotary/setup.py\", line\
          \ 17, in get_cuda_bare_metal_version\r\n          raw_output = subprocess.check_output([cuda_dir\
          \ + \"/bin/nvcc\", \"-V\"], universal_newlines=True)\r\n        File \"\
          /usr/lib/python3.10/subprocess.py\", line 421, in check_output\r\n     \
          \     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\r\
          \n        File \"/usr/lib/python3.10/subprocess.py\", line 503, in run\r\
          \n          with Popen(*popenargs, **kwargs) as process:\r\n        File\
          \ \"/usr/lib/python3.10/subprocess.py\", line 971, in __init__\r\n     \
          \     self._execute_child(args, executable, preexec_fn, close_fds,\r\n \
          \       File \"/usr/lib/python3.10/subprocess.py\", line 1863, in _execute_child\r\
          \n          raise child_exception_type(errno_num, err_msg, err_filename)\r\
          \n      FileNotFoundError: [Errno 2] No such file or directory: '/opt/cuda/bin/bin/nvcc'\r\
          \n\r\n      Warning: Torch did not find available GPUs on this system.\r\
          \n       If your intention is to cross-compile, this is not an error.\r\n\
          \      By default, Apex will cross-compile for Pascal (compute capabilities\
          \ 6.0, 6.1, 6.2),\r\n      Volta (compute capability 7.0), Turing (compute\
          \ capability 7.5),\r\n      and, if the CUDA version is >= 11.0, Ampere\
          \ (compute capability 8.0).\r\n      If you wish to cross-compile for a\
          \ single specific architecture,\r\n      export TORCH_CUDA_ARCH_LIST=\"\
          compute capability\" before running setup.py.\r\n\r\n      [end of output]\r\
          \n\r\n  note: This error originates from a subprocess, and is likely not\
          \ a problem with pip.\r\nerror: metadata-generation-failed\r\n\r\n\xD7 Encountered\
          \ error while generating package metadata.\r\n\u2570\u2500> See above for\
          \ output.\r\n\r\nnote: This is an issue with the package mentioned above,\
          \ not pip.\r\nhint: See above for details.\r\n\r\nNot sure how to fix the\
          \ above I've been going in circle trying different versions of software/installing/uninstalling\
          \ for over a week with no luck.\r\n\r\nThanks for any help.\r\n"
        updatedAt: '2023-10-19T06:26:38.324Z'
      numEdits: 0
      reactions: []
    id: 6530cc1eb50285938b66642d
    type: comment
  author: AndyLLama
  content: "Hi,\r\nI'm new to LLM and trying to install but having great difficulty.\r\
    \nUbuntu 22.04 with Nvidia 4080 card.  \r\nrunning nvidia-smi I have cuda 12.0\
    \ installed and driver 525.125.06\r\nWhen I try to run the README.md steps:\r\n\
    pip install transformers==4.31.0\r\npip install sentencepiece\r\npip install ninja\r\
    \npip install flash-attn --no-build-isolation\r\npip install git+https://github.com/HazyResearch/flash-attention.git#subdirectory\
    \ =csrc/rotary\r\nEverything works except the last step where I get:\r\n  Running\
    \ command git submodule update --init --recursive -q\r\n  Preparing metadata (setup.py)\
    \ ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  \xD7 python setup.py\
    \ egg_info did not run successfully.\r\n  \u2502 exit code: 1\r\n  \u2570\u2500\
    > [28 lines of output]\r\n      /home/ai/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:107:\
    \ UserWarning: CUDA initialization: CUDA unknown error - this may be due to an\
    \ incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES\
    \ after program start. Setting the available devices to be zero. (Triggered internally\
    \ at ../c10/cuda/CUDAFunctions.cpp:109.)\r\n        return torch._C._cuda_getDeviceCount()\
    \ > 0\r\n      No CUDA runtime is found, using CUDA_HOME='/opt/cuda/bin'\r\n \
    \     Traceback (most recent call last):\r\n        File \"<string>\", line 2,\
    \ in <module>\r\n        File \"<pip-setuptools-caller>\", line 34, in <module>\r\
    \n        File \"/tmp/pip-req-build-7w_ksy4l/csrc/rotary/setup.py\", line 74,\
    \ in <module>\r\n          _, bare_metal_version = get_cuda_bare_metal_version(CUDA_HOME)\r\
    \n        File \"/tmp/pip-req-build-7w_ksy4l/csrc/rotary/setup.py\", line 17,\
    \ in get_cuda_bare_metal_version\r\n          raw_output = subprocess.check_output([cuda_dir\
    \ + \"/bin/nvcc\", \"-V\"], universal_newlines=True)\r\n        File \"/usr/lib/python3.10/subprocess.py\"\
    , line 421, in check_output\r\n          return run(*popenargs, stdout=PIPE, timeout=timeout,\
    \ check=True,\r\n        File \"/usr/lib/python3.10/subprocess.py\", line 503,\
    \ in run\r\n          with Popen(*popenargs, **kwargs) as process:\r\n       \
    \ File \"/usr/lib/python3.10/subprocess.py\", line 971, in __init__\r\n      \
    \    self._execute_child(args, executable, preexec_fn, close_fds,\r\n        File\
    \ \"/usr/lib/python3.10/subprocess.py\", line 1863, in _execute_child\r\n    \
    \      raise child_exception_type(errno_num, err_msg, err_filename)\r\n      FileNotFoundError:\
    \ [Errno 2] No such file or directory: '/opt/cuda/bin/bin/nvcc'\r\n\r\n      Warning:\
    \ Torch did not find available GPUs on this system.\r\n       If your intention\
    \ is to cross-compile, this is not an error.\r\n      By default, Apex will cross-compile\
    \ for Pascal (compute capabilities 6.0, 6.1, 6.2),\r\n      Volta (compute capability\
    \ 7.0), Turing (compute capability 7.5),\r\n      and, if the CUDA version is\
    \ >= 11.0, Ampere (compute capability 8.0).\r\n      If you wish to cross-compile\
    \ for a single specific architecture,\r\n      export TORCH_CUDA_ARCH_LIST=\"\
    compute capability\" before running setup.py.\r\n\r\n      [end of output]\r\n\
    \r\n  note: This error originates from a subprocess, and is likely not a problem\
    \ with pip.\r\nerror: metadata-generation-failed\r\n\r\n\xD7 Encountered error\
    \ while generating package metadata.\r\n\u2570\u2500> See above for output.\r\n\
    \r\nnote: This is an issue with the package mentioned above, not pip.\r\nhint:\
    \ See above for details.\r\n\r\nNot sure how to fix the above I've been going\
    \ in circle trying different versions of software/installing/uninstalling for\
    \ over a week with no luck.\r\n\r\nThanks for any help.\r\n"
  created_at: 2023-10-19 05:26:38+00:00
  edited: false
  hidden: false
  id: 6530cc1eb50285938b66642d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/a312fb3f668f4e918a739862bfe96b59.svg
      fullname: Andy Davies
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AndyLLama
      type: user
    createdAt: '2024-01-12T19:28:34.000Z'
    data:
      status: closed
    id: 65a192e2d13926ca4bd682ef
    type: status-change
  author: AndyLLama
  created_at: 2024-01-12 19:28:34+00:00
  id: 65a192e2d13926ca4bd682ef
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 31
repo_id: togethercomputer/LLaMA-2-7B-32K
repo_type: model
status: closed
target_branch: null
title: New to LLM Need help with versions of software
