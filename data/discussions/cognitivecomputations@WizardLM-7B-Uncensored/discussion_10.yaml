!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Henk717
conflicting_files: null
created_at: 2023-05-09 22:17:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640356718818-61c47e9c71a107e9d80e33e3.jpeg?w=200&h=200&f=face
      fullname: Henky!!
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Henk717
      type: user
    createdAt: '2023-05-09T23:17:22.000Z'
    data:
      edited: false
      editors:
      - Henk717
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640356718818-61c47e9c71a107e9d80e33e3.jpeg?w=200&h=200&f=face
          fullname: Henky!!
          isHf: false
          isPro: false
          name: Henk717
          type: user
        html: '<p>When experimenting the model I noticed the model is very confident
          in its choices, its not as bad as some other models I have seen but it is
          usually near 100% confident.<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/61c47e9c71a107e9d80e33e3/WnSEAY-U6kwq_EHzAp7EH.png"><img
          alt="overtraining.png" src="https://cdn-uploads.huggingface.co/production/uploads/61c47e9c71a107e9d80e33e3/WnSEAY-U6kwq_EHzAp7EH.png"></a><br>In
          this example on the KoboldAI sample story, you see that it was near 100%
          confident that "with a quick flick" was correct while other plausible follow-up
          words had been possible.</p>

          <p>This is an snippet of llama-7b on the same sample story.<br><a rel="nofollow"
          href="https://cdn-uploads.huggingface.co/production/uploads/61c47e9c71a107e9d80e33e3/6hlhAXKKpfb-MXnwC3F3w.png"><img
          alt="llama-7b.png" src="https://cdn-uploads.huggingface.co/production/uploads/61c47e9c71a107e9d80e33e3/6hlhAXKKpfb-MXnwC3F3w.png"></a></p>

          <p>As you can see these confidence scores are much lower allowing for more
          varied output.<br>From experience we found that models that behave over
          confident the learning rate or other parameters were to high, you might
          be able to get higher quality results from your future revisions if you
          tone then down a bit.</p>

          '
        raw: "When experimenting the model I noticed the model is very confident in\
          \ its choices, its not as bad as some other models I have seen but it is\
          \ usually near 100% confident.\r\n![overtraining.png](https://cdn-uploads.huggingface.co/production/uploads/61c47e9c71a107e9d80e33e3/WnSEAY-U6kwq_EHzAp7EH.png)\r\
          \nIn this example on the KoboldAI sample story, you see that it was near\
          \ 100% confident that \"with a quick flick\" was correct while other plausible\
          \ follow-up words had been possible.\r\n\r\nThis is an snippet of llama-7b\
          \ on the same sample story.\r\n![llama-7b.png](https://cdn-uploads.huggingface.co/production/uploads/61c47e9c71a107e9d80e33e3/6hlhAXKKpfb-MXnwC3F3w.png)\r\
          \n\r\nAs you can see these confidence scores are much lower allowing for\
          \ more varied output.\r\nFrom experience we found that models that behave\
          \ over confident the learning rate or other parameters were to high, you\
          \ might be able to get higher quality results from your future revisions\
          \ if you tone then down a bit."
        updatedAt: '2023-05-09T23:17:22.748Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - wolfram
        - rogerleger
        - rain5
        - gl198976
        - FabianKarl
    id: 645ad4825e6871b4b2d684f1
    type: comment
  author: Henk717
  content: "When experimenting the model I noticed the model is very confident in\
    \ its choices, its not as bad as some other models I have seen but it is usually\
    \ near 100% confident.\r\n![overtraining.png](https://cdn-uploads.huggingface.co/production/uploads/61c47e9c71a107e9d80e33e3/WnSEAY-U6kwq_EHzAp7EH.png)\r\
    \nIn this example on the KoboldAI sample story, you see that it was near 100%\
    \ confident that \"with a quick flick\" was correct while other plausible follow-up\
    \ words had been possible.\r\n\r\nThis is an snippet of llama-7b on the same sample\
    \ story.\r\n![llama-7b.png](https://cdn-uploads.huggingface.co/production/uploads/61c47e9c71a107e9d80e33e3/6hlhAXKKpfb-MXnwC3F3w.png)\r\
    \n\r\nAs you can see these confidence scores are much lower allowing for more\
    \ varied output.\r\nFrom experience we found that models that behave over confident\
    \ the learning rate or other parameters were to high, you might be able to get\
    \ higher quality results from your future revisions if you tone then down a bit."
  created_at: 2023-05-09 22:17:22+00:00
  edited: false
  hidden: false
  id: 645ad4825e6871b4b2d684f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-05-10T02:54:37.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>This is great feedback!  Thank you!</p>

          '
        raw: This is great feedback!  Thank you!
        updatedAt: '2023-05-10T02:54:37.350Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - rogerleger
        - rain5
        - FabianKarl
    id: 645b076ddbf60d373367d9da
    type: comment
  author: ehartford
  content: This is great feedback!  Thank you!
  created_at: 2023-05-10 01:54:37+00:00
  edited: false
  hidden: false
  id: 645b076ddbf60d373367d9da
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: cognitivecomputations/WizardLM-7B-Uncensored
repo_type: model
status: open
target_branch: null
title: Possible sign of overtraining
