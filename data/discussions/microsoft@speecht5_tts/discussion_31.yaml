!!python/object:huggingface_hub.community.DiscussionWithDetails
author: thunder-007
conflicting_files: null
created_at: 2023-12-21 11:53:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644917e381c086e0a4220980/N6HVolVy9_sW7390E-hMg.jpeg?w=200&h=200&f=face
      fullname: Harsha Vardhan V
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thunder-007
      type: user
    createdAt: '2023-12-21T11:53:27.000Z'
    data:
      edited: false
      editors:
      - thunder-007
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5235587954521179
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644917e381c086e0a4220980/N6HVolVy9_sW7390E-hMg.jpeg?w=200&h=200&f=face
          fullname: Harsha Vardhan V
          isHf: false
          isPro: false
          name: thunder-007
          type: user
        html: '<pre><code>from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech,
          SpeechT5HifiGan

          from datasets import load_dataset

          import torch

          import soundfile as sf

          from datasets import load_dataset


          processor = SpeechT5Processor.from_pretrained("microsoft/speecht5_tts")

          model = SpeechT5ForTextToSpeech.from_pretrained("microsoft/speecht5_tts")

          vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")


          inputs = processor(text="Hello, my dog is cute.", return_tensors="pt")


          # embeddings_dataset = load_dataset("Matthijs/cmu-arctic-xvectors", split="validation")

          # speaker_embeddings = torch.tensor(embeddings_dataset[7306]["xvector"]).unsqueeze(0)


          speech = model.generate_speech(inputs["input_ids"], vocoder=vocoder)#, speaker_embeddings,)


          sf.write("speech.wav", speech.numpy(), samplerate=16000)

          </code></pre>

          <p>I think gonna give the output from a llm to this model when the llm yeild
          the text in real time how can we make this read in real time?</p>

          '
        raw: "```\r\nfrom transformers import SpeechT5Processor, SpeechT5ForTextToSpeech,\
          \ SpeechT5HifiGan\r\nfrom datasets import load_dataset\r\nimport torch\r\
          \nimport soundfile as sf\r\nfrom datasets import load_dataset\r\n\r\nprocessor\
          \ = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\r\nmodel\
          \ = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\r\
          \nvocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\"\
          )\r\n\r\ninputs = processor(text=\"Hello, my dog is cute.\", return_tensors=\"\
          pt\")\r\n\r\n# embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\"\
          , split=\"validation\")\r\n# speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"\
          xvector\"]).unsqueeze(0)\r\n\r\nspeech = model.generate_speech(inputs[\"\
          input_ids\"], vocoder=vocoder)#, speaker_embeddings,)\r\n\r\nsf.write(\"\
          speech.wav\", speech.numpy(), samplerate=16000)\r\n```\r\nI think gonna\
          \ give the output from a llm to this model when the llm yeild the text in\
          \ real time how can we make this read in real time?"
        updatedAt: '2023-12-21T11:53:27.661Z'
      numEdits: 0
      reactions: []
    id: 6584273783a9e1460c7b531e
    type: comment
  author: thunder-007
  content: "```\r\nfrom transformers import SpeechT5Processor, SpeechT5ForTextToSpeech,\
    \ SpeechT5HifiGan\r\nfrom datasets import load_dataset\r\nimport torch\r\nimport\
    \ soundfile as sf\r\nfrom datasets import load_dataset\r\n\r\nprocessor = SpeechT5Processor.from_pretrained(\"\
    microsoft/speecht5_tts\")\r\nmodel = SpeechT5ForTextToSpeech.from_pretrained(\"\
    microsoft/speecht5_tts\")\r\nvocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\"\
    )\r\n\r\ninputs = processor(text=\"Hello, my dog is cute.\", return_tensors=\"\
    pt\")\r\n\r\n# embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\"\
    , split=\"validation\")\r\n# speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"\
    xvector\"]).unsqueeze(0)\r\n\r\nspeech = model.generate_speech(inputs[\"input_ids\"\
    ], vocoder=vocoder)#, speaker_embeddings,)\r\n\r\nsf.write(\"speech.wav\", speech.numpy(),\
    \ samplerate=16000)\r\n```\r\nI think gonna give the output from a llm to this\
    \ model when the llm yeild the text in real time how can we make this read in\
    \ real time?"
  created_at: 2023-12-21 11:53:27+00:00
  edited: false
  hidden: false
  id: 6584273783a9e1460c7b531e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 31
repo_id: microsoft/speecht5_tts
repo_type: model
status: open
target_branch: null
title: How can I pass the result to microphone
