!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Delcos
conflicting_files: null
created_at: 2023-12-26 23:11:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
      fullname: Devon M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delcos
      type: user
    createdAt: '2023-12-26T23:11:29.000Z'
    data:
      edited: false
      editors:
      - Delcos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.36188027262687683
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
          fullname: Devon M
          isHf: false
          isPro: false
          name: Delcos
          type: user
        html: '<p>Why llama 1? Why not 2 or mistral? </p>

          '
        raw: 'Why llama 1? Why not 2 or mistral? '
        updatedAt: '2023-12-26T23:11:29.622Z'
      numEdits: 0
      reactions: []
    id: 658b5da17f1e21412cb4f173
    type: comment
  author: Delcos
  content: 'Why llama 1? Why not 2 or mistral? '
  created_at: 2023-12-26 23:11:29+00:00
  edited: false
  hidden: false
  id: 658b5da17f1e21412cb4f173
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/650801ced5578ef7e20b33d4/oLptSnKMecbu62EgglmO6.png?w=200&h=200&f=face
      fullname: AdaptLLM
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: AdaptLLM
      type: user
    createdAt: '2023-12-27T01:55:17.000Z'
    data:
      edited: true
      editors:
      - AdaptLLM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9113093018531799
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/650801ced5578ef7e20b33d4/oLptSnKMecbu62EgglmO6.png?w=200&h=200&f=face
          fullname: AdaptLLM
          isHf: false
          isPro: false
          name: AdaptLLM
          type: user
        html: '<p>Hi, thanks for your attention! This is mainly for research purpose.
          Our research, started at about April, way before LLaMA-2 and Mistral came
          into the scene. Back then we utilized LLaMA-1-7B for our investigations.
          As our work progressed, we conducted experiments on LLaMA-1-13B to assess
          the generalizability of our method to larger models. You may refer to our
          chat model at <a href="https://huggingface.co/AdaptLLM/finance-chat">AdaptLLM/finance-chat</a>
          to see the effectiveness of our method on LLaMA-2-Chat. And of course Mistral
          is part of our future plans, so please stay tuned!</p>

          '
        raw: Hi, thanks for your attention! This is mainly for research purpose. Our
          research, started at about April, way before LLaMA-2 and Mistral came into
          the scene. Back then we utilized LLaMA-1-7B for our investigations. As our
          work progressed, we conducted experiments on LLaMA-1-13B to assess the generalizability
          of our method to larger models. You may refer to our chat model at [AdaptLLM/finance-chat](https://huggingface.co/AdaptLLM/finance-chat)
          to see the effectiveness of our method on LLaMA-2-Chat. And of course Mistral
          is part of our future plans, so please stay tuned!
        updatedAt: '2023-12-28T02:12:54.766Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - Delcos
        - HFFAN123
    id: 658b84058a8a1413609eb18d
    type: comment
  author: AdaptLLM
  content: Hi, thanks for your attention! This is mainly for research purpose. Our
    research, started at about April, way before LLaMA-2 and Mistral came into the
    scene. Back then we utilized LLaMA-1-7B for our investigations. As our work progressed,
    we conducted experiments on LLaMA-1-13B to assess the generalizability of our
    method to larger models. You may refer to our chat model at [AdaptLLM/finance-chat](https://huggingface.co/AdaptLLM/finance-chat)
    to see the effectiveness of our method on LLaMA-2-Chat. And of course Mistral
    is part of our future plans, so please stay tuned!
  created_at: 2023-12-27 01:55:17+00:00
  edited: true
  hidden: false
  id: 658b84058a8a1413609eb18d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: AdaptLLM/finance-LLM-13B
repo_type: model
status: open
target_branch: null
title: Good idea but why llama 1?
