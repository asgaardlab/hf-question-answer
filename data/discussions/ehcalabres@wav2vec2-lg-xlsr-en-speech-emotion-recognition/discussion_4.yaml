!!python/object:huggingface_hub.community.DiscussionWithDetails
author: coder151516
conflicting_files: null
created_at: 2023-07-10 15:39:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3a5c9800fbbf67b9e6b56c6753ae0ff4.svg
      fullname: David Gormley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: coder151516
      type: user
    createdAt: '2023-07-10T16:39:31.000Z'
    data:
      edited: true
      editors:
      - coder151516
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9238093495368958
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3a5c9800fbbf67b9e6b56c6753ae0ff4.svg
          fullname: David Gormley
          isHf: false
          isPro: false
          name: coder151516
          type: user
        html: '<p>I am running the model in my on jupyter notebook as well as in the
          hosted inference API and I can''t get the model to accurately classify audio.
          I input audio that is clearly positive (tone and content) and it fails to
          converge (see photo). What am I doing wrong? (For context the audio is about
          7 seconds long - perhaps that is an issue?)<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6495e7c438e398e72425ed2a/LqwBv9SUaoq8hvfQZbYbC.png"><img
          alt="Screen Shot 2023-07-10 at 9.39.12 AM.png" src="https://cdn-uploads.huggingface.co/production/uploads/6495e7c438e398e72425ed2a/LqwBv9SUaoq8hvfQZbYbC.png"></a></p>

          '
        raw: 'I am running the model in my on jupyter notebook as well as in the hosted
          inference API and I can''t get the model to accurately classify audio. I
          input audio that is clearly positive (tone and content) and it fails to
          converge (see photo). What am I doing wrong? (For context the audio is about
          7 seconds long - perhaps that is an issue?)

          ![Screen Shot 2023-07-10 at 9.39.12 AM.png](https://cdn-uploads.huggingface.co/production/uploads/6495e7c438e398e72425ed2a/LqwBv9SUaoq8hvfQZbYbC.png)

          '
        updatedAt: '2023-07-10T16:39:58.727Z'
      numEdits: 1
      reactions: []
    id: 64ac34433f1cdf3a8e504019
    type: comment
  author: coder151516
  content: 'I am running the model in my on jupyter notebook as well as in the hosted
    inference API and I can''t get the model to accurately classify audio. I input
    audio that is clearly positive (tone and content) and it fails to converge (see
    photo). What am I doing wrong? (For context the audio is about 7 seconds long
    - perhaps that is an issue?)

    ![Screen Shot 2023-07-10 at 9.39.12 AM.png](https://cdn-uploads.huggingface.co/production/uploads/6495e7c438e398e72425ed2a/LqwBv9SUaoq8hvfQZbYbC.png)

    '
  created_at: 2023-07-10 15:39:31+00:00
  edited: true
  hidden: false
  id: 64ac34433f1cdf3a8e504019
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
repo_type: model
status: open
target_branch: null
title: I can't seem to get the model to work - what am I doing wrong?
