!!python/object:huggingface_hub.community.DiscussionWithDetails
author: risau
conflicting_files: null
created_at: 2022-09-20 16:10:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c46f1d78fa9e5960420a2e5744bb4db5.svg
      fullname: Risa U
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: risau
      type: user
    createdAt: '2022-09-20T17:10:56.000Z'
    data:
      edited: false
      editors:
      - risau
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c46f1d78fa9e5960420a2e5744bb4db5.svg
          fullname: Risa U
          isHf: false
          isPro: false
          name: risau
          type: user
        html: '<p>Hi! I am not sure how to use the model. Trying to use <code>pipeline</code>
          but </p>

          <pre><code>from transformers import AutoProcessor, AutoModelForAudioClassification

          processor = AutoProcessor.from_pretrained("ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition")

          </code></pre>

          <p>gives error:<br><code>OSError: Can''t load tokenizer for ''ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition''.
          If you were trying to load it from ''https://huggingface.co/models'', make
          sure you don''t have a local directory with the same name. Otherwise, make
          sure ''ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition'' is the
          correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer
          tokenizer.</code></p>

          '
        raw: "Hi! I am not sure how to use the model. Trying to use `pipeline` but\
          \ \r\n```\r\nfrom transformers import AutoProcessor, AutoModelForAudioClassification\r\
          \nprocessor = AutoProcessor.from_pretrained(\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\
          )\r\n```\r\ngives error: \r\n`OSError: Can't load tokenizer for 'ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition'.\
          \ If you were trying to load it from 'https://huggingface.co/models', make\
          \ sure you don't have a local directory with the same name. Otherwise, make\
          \ sure 'ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition' is the\
          \ correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer\
          \ tokenizer.`"
        updatedAt: '2022-09-20T17:10:56.088Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - marcmaxmeister
        - RustemShaimarus
        - Geometrein
    id: 6329f4205f2ff1958cfe9510
    type: comment
  author: risau
  content: "Hi! I am not sure how to use the model. Trying to use `pipeline` but \r\
    \n```\r\nfrom transformers import AutoProcessor, AutoModelForAudioClassification\r\
    \nprocessor = AutoProcessor.from_pretrained(\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\
    )\r\n```\r\ngives error: \r\n`OSError: Can't load tokenizer for 'ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition'.\
    \ If you were trying to load it from 'https://huggingface.co/models', make sure\
    \ you don't have a local directory with the same name. Otherwise, make sure 'ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition'\
    \ is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer\
    \ tokenizer.`"
  created_at: 2022-09-20 16:10:56+00:00
  edited: false
  hidden: false
  id: 6329f4205f2ff1958cfe9510
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663171480350-6321fb29e4399dd61398e931.png?w=200&h=200&f=face
      fullname: Marc Maxmeister
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marcmaxmeister
      type: user
    createdAt: '2022-10-26T16:18:36.000Z'
    data:
      edited: false
      editors:
      - marcmaxmeister
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663171480350-6321fb29e4399dd61398e931.png?w=200&h=200&f=face
          fullname: Marc Maxmeister
          isHf: false
          isPro: false
          name: marcmaxmeister
          type: user
        html: '<p>I too am confused. I''ve used many other huggingface models and
          this one needs a working example of applying the pretrained model to a local
          audio file.</p>

          '
        raw: I too am confused. I've used many other huggingface models and this one
          needs a working example of applying the pretrained model to a local audio
          file.
        updatedAt: '2022-10-26T16:18:36.652Z'
      numEdits: 0
      reactions: []
    id: 63595ddc6a6195408084b48e
    type: comment
  author: marcmaxmeister
  content: I too am confused. I've used many other huggingface models and this one
    needs a working example of applying the pretrained model to a local audio file.
  created_at: 2022-10-26 15:18:36+00:00
  edited: false
  hidden: false
  id: 63595ddc6a6195408084b48e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663171480350-6321fb29e4399dd61398e931.png?w=200&h=200&f=face
      fullname: Marc Maxmeister
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marcmaxmeister
      type: user
    createdAt: '2022-10-26T17:46:12.000Z'
    data:
      edited: false
      editors:
      - marcmaxmeister
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663171480350-6321fb29e4399dd61398e931.png?w=200&h=200&f=face
          fullname: Marc Maxmeister
          isHf: false
          isPro: false
          name: marcmaxmeister
          type: user
        html: "<p>So I hacked around with this model all morning and here is a script\
          \ of how I THINK it is supposed to work. I don't feel confident that every\
          \ step is accurate, but since the source doesn't seem to be available on\
          \ github and there's no public example, this is a start. Hopefully the author\
          \ or someone else will correct my work and we'll all be better off. I can't\
          \ believe this is the most downloaded audio-emotion model on huggingface\
          \ at the moment. (Though \"downloads\" include all the people who try the\
          \ online demo too).</p>\n<p>(Honorable mention to github copilot, that filled\
          \ in some of the code for where documentation was lacking!)</p>\n<pre><code>import\
          \ torch\nfrom transformers import AutoProcessor, AutoModelForAudioClassification,\
          \ Wav2Vec2FeatureExtractor\nimport numpy as np\nfrom pydub import AudioSegment\n\
          \n# https://github.com/ehcalabres/EMOVoice\n# the preprocessor was derived\
          \ from https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english\n\
          # processor1 = AutoProcessor.from_pretrained(\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\
          )\n# ^^^ no preload model available for this model (above), but the `feature_extractor`\
          \ works in place\nmodel1 = AutoModelForAudioClassification.from_pretrained(\"\
          ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\")\nfeature_extractor\
          \ = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\"\
          )\n\ndef predict_emotion(audio_file):\n    if not audio_file:\n        #\
          \ I fetched some samples with known emotions from here: https://www.fesliyanstudios.com/royalty-free-sound-effects-download/poeple-crying-252\n\
          \        audio_file = 'mp3/dude-crying.mp3'\n    sound = AudioSegment.from_file(audio_file)\n\
          \    sound = sound.set_frame_rate(16000)\n    sound_array = np.array(sound.get_array_of_samples())\n\
          \    # this model is VERY SLOW, so best to pass in small sections that contain\
          \ \n    # emotional words from the transcript. like 10s or less.\n    #\
          \ how to make sub-chunk  -- this was necessary even with very short audio\
          \ files \n    # test = torch.tensor(input.input_values.float()[:, :100000])\n\
          \n    input = feature_extractor(\n        raw_speech=sound_array,\n    \
          \    sampling_rate=16000,\n        padding=True,\n        return_tensors=\"\
          pt\")\n\n    result = model1.forward(input.input_values.float())\n    #\
          \ making sense of the result \n    id2label = {\n        \"0\": \"angry\"\
          ,\n        \"1\": \"calm\",\n        \"2\": \"disgust\",\n        \"3\"\
          : \"fearful\",\n        \"4\": \"happy\",\n        \"5\": \"neutral\",\n\
          \        \"6\": \"sad\",\n        \"7\": \"surprised\"\n    }\n    interp\
          \ = dict(zip(id2label.values(), list(round(float(i),4) for i in result[0][0])))\n\
          \    return interp\n</code></pre>\n<p>{'angry': 0.0389, 'calm': 0.0323,\
          \ 'disgust': -0.0222, 'fearful': -0.1644, 'happy': -0.0891, 'neutral': 0.0672,\
          \ 'sad': 0.0889, 'surprised': 0.053}</p>\n<p>(the sample was of a dude crying,\
          \ and \"sad\" is the highest scoring match, so it worked)</p>\n"
        raw: "So I hacked around with this model all morning and here is a script\
          \ of how I THINK it is supposed to work. I don't feel confident that every\
          \ step is accurate, but since the source doesn't seem to be available on\
          \ github and there's no public example, this is a start. Hopefully the author\
          \ or someone else will correct my work and we'll all be better off. I can't\
          \ believe this is the most downloaded audio-emotion model on huggingface\
          \ at the moment. (Though \"downloads\" include all the people who try the\
          \ online demo too).\n\n(Honorable mention to github copilot, that filled\
          \ in some of the code for where documentation was lacking!)\n\n```\nimport\
          \ torch\nfrom transformers import AutoProcessor, AutoModelForAudioClassification,\
          \ Wav2Vec2FeatureExtractor\nimport numpy as np\nfrom pydub import AudioSegment\n\
          \n# https://github.com/ehcalabres/EMOVoice\n# the preprocessor was derived\
          \ from https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english\n\
          # processor1 = AutoProcessor.from_pretrained(\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\
          )\n# ^^^ no preload model available for this model (above), but the `feature_extractor`\
          \ works in place\nmodel1 = AutoModelForAudioClassification.from_pretrained(\"\
          ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\")\nfeature_extractor\
          \ = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\"\
          )\n\ndef predict_emotion(audio_file):\n    if not audio_file:\n        #\
          \ I fetched some samples with known emotions from here: https://www.fesliyanstudios.com/royalty-free-sound-effects-download/poeple-crying-252\n\
          \        audio_file = 'mp3/dude-crying.mp3'\n    sound = AudioSegment.from_file(audio_file)\n\
          \    sound = sound.set_frame_rate(16000)\n    sound_array = np.array(sound.get_array_of_samples())\n\
          \    # this model is VERY SLOW, so best to pass in small sections that contain\
          \ \n    # emotional words from the transcript. like 10s or less.\n    #\
          \ how to make sub-chunk  -- this was necessary even with very short audio\
          \ files \n    # test = torch.tensor(input.input_values.float()[:, :100000])\n\
          \n    input = feature_extractor(\n        raw_speech=sound_array,\n    \
          \    sampling_rate=16000,\n        padding=True,\n        return_tensors=\"\
          pt\")\n\n    result = model1.forward(input.input_values.float())\n    #\
          \ making sense of the result \n    id2label = {\n        \"0\": \"angry\"\
          ,\n        \"1\": \"calm\",\n        \"2\": \"disgust\",\n        \"3\"\
          : \"fearful\",\n        \"4\": \"happy\",\n        \"5\": \"neutral\",\n\
          \        \"6\": \"sad\",\n        \"7\": \"surprised\"\n    }\n    interp\
          \ = dict(zip(id2label.values(), list(round(float(i),4) for i in result[0][0])))\n\
          \    return interp\n```\n\n{'angry': 0.0389, 'calm': 0.0323, 'disgust':\
          \ -0.0222, 'fearful': -0.1644, 'happy': -0.0891, 'neutral': 0.0672, 'sad':\
          \ 0.0889, 'surprised': 0.053}\n\n(the sample was of a dude crying, and \"\
          sad\" is the highest scoring match, so it worked)"
        updatedAt: '2022-10-26T17:46:12.460Z'
      numEdits: 0
      reactions:
      - count: 7
        reaction: "\u2764\uFE0F"
        users:
        - Cierveh
        - dlituiev
        - money4
        - scyeo
        - Geometrein
        - Saahil97
        - TechDing
    id: 6359726460e2f140f44bdc2f
    type: comment
  author: marcmaxmeister
  content: "So I hacked around with this model all morning and here is a script of\
    \ how I THINK it is supposed to work. I don't feel confident that every step is\
    \ accurate, but since the source doesn't seem to be available on github and there's\
    \ no public example, this is a start. Hopefully the author or someone else will\
    \ correct my work and we'll all be better off. I can't believe this is the most\
    \ downloaded audio-emotion model on huggingface at the moment. (Though \"downloads\"\
    \ include all the people who try the online demo too).\n\n(Honorable mention to\
    \ github copilot, that filled in some of the code for where documentation was\
    \ lacking!)\n\n```\nimport torch\nfrom transformers import AutoProcessor, AutoModelForAudioClassification,\
    \ Wav2Vec2FeatureExtractor\nimport numpy as np\nfrom pydub import AudioSegment\n\
    \n# https://github.com/ehcalabres/EMOVoice\n# the preprocessor was derived from\
    \ https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english\n# processor1\
    \ = AutoProcessor.from_pretrained(\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\
    )\n# ^^^ no preload model available for this model (above), but the `feature_extractor`\
    \ works in place\nmodel1 = AutoModelForAudioClassification.from_pretrained(\"\
    ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\")\nfeature_extractor\
    \ = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\"\
    )\n\ndef predict_emotion(audio_file):\n    if not audio_file:\n        # I fetched\
    \ some samples with known emotions from here: https://www.fesliyanstudios.com/royalty-free-sound-effects-download/poeple-crying-252\n\
    \        audio_file = 'mp3/dude-crying.mp3'\n    sound = AudioSegment.from_file(audio_file)\n\
    \    sound = sound.set_frame_rate(16000)\n    sound_array = np.array(sound.get_array_of_samples())\n\
    \    # this model is VERY SLOW, so best to pass in small sections that contain\
    \ \n    # emotional words from the transcript. like 10s or less.\n    # how to\
    \ make sub-chunk  -- this was necessary even with very short audio files \n  \
    \  # test = torch.tensor(input.input_values.float()[:, :100000])\n\n    input\
    \ = feature_extractor(\n        raw_speech=sound_array,\n        sampling_rate=16000,\n\
    \        padding=True,\n        return_tensors=\"pt\")\n\n    result = model1.forward(input.input_values.float())\n\
    \    # making sense of the result \n    id2label = {\n        \"0\": \"angry\"\
    ,\n        \"1\": \"calm\",\n        \"2\": \"disgust\",\n        \"3\": \"fearful\"\
    ,\n        \"4\": \"happy\",\n        \"5\": \"neutral\",\n        \"6\": \"sad\"\
    ,\n        \"7\": \"surprised\"\n    }\n    interp = dict(zip(id2label.values(),\
    \ list(round(float(i),4) for i in result[0][0])))\n    return interp\n```\n\n\
    {'angry': 0.0389, 'calm': 0.0323, 'disgust': -0.0222, 'fearful': -0.1644, 'happy':\
    \ -0.0891, 'neutral': 0.0672, 'sad': 0.0889, 'surprised': 0.053}\n\n(the sample\
    \ was of a dude crying, and \"sad\" is the highest scoring match, so it worked)"
  created_at: 2022-10-26 16:46:12+00:00
  edited: false
  hidden: false
  id: 6359726460e2f140f44bdc2f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663171480350-6321fb29e4399dd61398e931.png?w=200&h=200&f=face
      fullname: Marc Maxmeister
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marcmaxmeister
      type: user
    createdAt: '2022-10-26T17:51:18.000Z'
    data:
      edited: false
      editors:
      - marcmaxmeister
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663171480350-6321fb29e4399dd61398e931.png?w=200&h=200&f=face
          fullname: Marc Maxmeister
          isHf: false
          isPro: false
          name: marcmaxmeister
          type: user
        html: '<p>My audio test file. Seems to be an actor, not an authentically sad
          person, but the classifier should still pick up the signals.</p>

          <p><audio src="https://cdn-uploads.huggingface.co/production/uploads/1666806645707-6321fb29e4399dd61398e931.wav"
          controls=""></audio></p>

          '
        raw: 'My audio test file. Seems to be an actor, not an authentically sad person,
          but the classifier should still pick up the signals.


          <audio controls src="https://cdn-uploads.huggingface.co/production/uploads/1666806645707-6321fb29e4399dd61398e931.wav"></audio>'
        updatedAt: '2022-10-26T17:51:18.271Z'
      numEdits: 0
      reactions: []
    id: 635973966805fab09b0a4732
    type: comment
  author: marcmaxmeister
  content: 'My audio test file. Seems to be an actor, not an authentically sad person,
    but the classifier should still pick up the signals.


    <audio controls src="https://cdn-uploads.huggingface.co/production/uploads/1666806645707-6321fb29e4399dd61398e931.wav"></audio>'
  created_at: 2022-10-26 16:51:18+00:00
  edited: false
  hidden: false
  id: 635973966805fab09b0a4732
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a860abd7bad8c56a246fa30536e36ff.svg
      fullname: Giuseppe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: keyswordart
      type: user
    createdAt: '2022-11-30T21:05:12.000Z'
    data:
      edited: false
      editors:
      - keyswordart
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7a860abd7bad8c56a246fa30536e36ff.svg
          fullname: Giuseppe
          isHf: false
          isPro: false
          name: keyswordart
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;marcmaxmeister&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/marcmaxmeister\"\
          >@<span class=\"underline\">marcmaxmeister</span></a></span>\n\n\t</span></span><br>When\
          \ I try your code with the sample \"dude crying\" I get totally different\
          \ results:<br>{'angry': -0.0665,<br> 'calm': 0.1155,<br> 'disgust': 0.0035,<br>\
          \ 'fearful': 0.0059,<br> 'happy': -0.061,<br> 'neutral': -0.08,<br> 'sad':\
          \ -0.0665,<br> 'surprised': 0.009}</p>\n<p>can you try again and see if\
          \ you get my results or still the good results with sad beeing the biggest\
          \ one?</p>\n"
        raw: "Hello @marcmaxmeister \nWhen I try your code with the sample \"dude\
          \ crying\" I get totally different results:\n{'angry': -0.0665,\n 'calm':\
          \ 0.1155,\n 'disgust': 0.0035,\n 'fearful': 0.0059,\n 'happy': -0.061,\n\
          \ 'neutral': -0.08,\n 'sad': -0.0665,\n 'surprised': 0.009}\n\ncan you try\
          \ again and see if you get my results or still the good results with sad\
          \ beeing the biggest one?"
        updatedAt: '2022-11-30T21:05:12.154Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - marcmaxmeister
    id: 6387c588ad6d6d6e93543615
    type: comment
  author: keyswordart
  content: "Hello @marcmaxmeister \nWhen I try your code with the sample \"dude crying\"\
    \ I get totally different results:\n{'angry': -0.0665,\n 'calm': 0.1155,\n 'disgust':\
    \ 0.0035,\n 'fearful': 0.0059,\n 'happy': -0.061,\n 'neutral': -0.08,\n 'sad':\
    \ -0.0665,\n 'surprised': 0.009}\n\ncan you try again and see if you get my results\
    \ or still the good results with sad beeing the biggest one?"
  created_at: 2022-11-30 21:05:12+00:00
  edited: false
  hidden: false
  id: 6387c588ad6d6d6e93543615
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663171480350-6321fb29e4399dd61398e931.png?w=200&h=200&f=face
      fullname: Marc Maxmeister
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marcmaxmeister
      type: user
    createdAt: '2022-12-13T15:17:12.000Z'
    data:
      edited: false
      editors:
      - marcmaxmeister
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663171480350-6321fb29e4399dd61398e931.png?w=200&h=200&f=face
          fullname: Marc Maxmeister
          isHf: false
          isPro: false
          name: marcmaxmeister
          type: user
        html: '<p>Sure. I copied the code from this page and reran it on my local
          copy of <code>dude-crying.mp3</code> as well as a downloaded copy of the
          WAV file, just in case the site modified the bitrate or something. Got the
          same result each time, but they did not match my previous run or your test
          run. Image attached.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1670944572626-6321fb29e4399dd61398e931.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1670944572626-6321fb29e4399dd61398e931.png"></a></p>

          '
        raw: 'Sure. I copied the code from this page and reran it on my local copy
          of `dude-crying.mp3` as well as a downloaded copy of the WAV file, just
          in case the site modified the bitrate or something. Got the same result
          each time, but they did not match my previous run or your test run. Image
          attached.


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1670944572626-6321fb29e4399dd61398e931.png)'
        updatedAt: '2022-12-13T15:17:12.299Z'
      numEdits: 0
      reactions: []
    id: 63989778118937178eab6fd1
    type: comment
  author: marcmaxmeister
  content: 'Sure. I copied the code from this page and reran it on my local copy of
    `dude-crying.mp3` as well as a downloaded copy of the WAV file, just in case the
    site modified the bitrate or something. Got the same result each time, but they
    did not match my previous run or your test run. Image attached.


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1670944572626-6321fb29e4399dd61398e931.png)'
  created_at: 2022-12-13 15:17:12+00:00
  edited: false
  hidden: false
  id: 63989778118937178eab6fd1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665539282451-62f85e7104de855c35e55e75.png?w=200&h=200&f=face
      fullname: HJ.Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HJChen
      type: user
    createdAt: '2023-03-18T14:05:52.000Z'
    data:
      edited: true
      editors:
      - HJChen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665539282451-62f85e7104de855c35e55e75.png?w=200&h=200&f=face
          fullname: HJ.Chen
          isHf: false
          isPro: false
          name: HJChen
          type: user
        html: '<p>Anyone notice the warnings when loading the pretrained model?</p>

          <pre><code>Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          were not used when initializing Wav2Vec2ForSequenceClassification: [''classifier.output.bias'',
          ''classifier.dense.weight'', ''classifier.dense.bias'', ''classifier.output.weight'']

          - This IS expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model trained on another task or with another architecture
          (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining
          model).

          - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model that you expect to be exactly identical (initializing
          a BertForSequenceClassification model from a BertForSequenceClassification
          model).

          Some weights of Wav2Vec2ForSequenceClassification were not initialized from
          the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          and are newly initialized: [''projector.bias'', ''classifier.bias'', ''projector.weight'',
          ''classifier.weight'']

          You should probably TRAIN this model on a down-stream task to be able to
          use it for predictions and inference.

          </code></pre>

          <p>Does it mean the model is actually outputting random predictions?</p>

          '
        raw: 'Anyone notice the warnings when loading the pretrained model?

          ```

          Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          were not used when initializing Wav2Vec2ForSequenceClassification: [''classifier.output.bias'',
          ''classifier.dense.weight'', ''classifier.dense.bias'', ''classifier.output.weight'']

          - This IS expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model trained on another task or with another architecture
          (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining
          model).

          - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model that you expect to be exactly identical (initializing
          a BertForSequenceClassification model from a BertForSequenceClassification
          model).

          Some weights of Wav2Vec2ForSequenceClassification were not initialized from
          the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          and are newly initialized: [''projector.bias'', ''classifier.bias'', ''projector.weight'',
          ''classifier.weight'']

          You should probably TRAIN this model on a down-stream task to be able to
          use it for predictions and inference.

          ```


          Does it mean the model is actually outputting random predictions?'
        updatedAt: '2023-05-09T13:01:48.754Z'
      numEdits: 1
      reactions: []
    id: 6415c540c2d99a3c553d0658
    type: comment
  author: HJChen
  content: 'Anyone notice the warnings when loading the pretrained model?

    ```

    Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
    were not used when initializing Wav2Vec2ForSequenceClassification: [''classifier.output.bias'',
    ''classifier.dense.weight'', ''classifier.dense.bias'', ''classifier.output.weight'']

    - This IS expected if you are initializing Wav2Vec2ForSequenceClassification from
    the checkpoint of a model trained on another task or with another architecture
    (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining
    model).

    - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification
    from the checkpoint of a model that you expect to be exactly identical (initializing
    a BertForSequenceClassification model from a BertForSequenceClassification model).

    Some weights of Wav2Vec2ForSequenceClassification were not initialized from the
    model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
    and are newly initialized: [''projector.bias'', ''classifier.bias'', ''projector.weight'',
    ''classifier.weight'']

    You should probably TRAIN this model on a down-stream task to be able to use it
    for predictions and inference.

    ```


    Does it mean the model is actually outputting random predictions?'
  created_at: 2023-03-18 13:05:52+00:00
  edited: true
  hidden: false
  id: 6415c540c2d99a3c553d0658
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fc8e45bc7c37ad27bb8b3aed730606fb.svg
      fullname: tt dang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: huttersadan
      type: user
    createdAt: '2023-04-14T12:05:46.000Z'
    data:
      edited: false
      editors:
      - huttersadan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fc8e45bc7c37ad27bb8b3aed730606fb.svg
          fullname: tt dang
          isHf: false
          isPro: false
          name: huttersadan
          type: user
        html: '<blockquote>

          <p>Anyone notice the warnings when loading the pretrained model?</p>

          <pre><code>Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          were not used when initializing Wav2Vec2ForSequenceClassification: [''classifier.output.bias'',
          ''classifier.dense.weight'', ''classifier.dense.bias'', ''classifier.output.weight'']

          - This IS expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model trained on another task or with another architecture
          (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining
          model).

          - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model that you expect to be exactly identical (initializing
          a BertForSequenceClassification model from a BertForSequenceClassification
          model).

          Some weights of Wav2Vec2ForSequenceClassification were not initialized from
          the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          and are newly initialized: [''projector.bias'', ''classifier.bias'', ''projector.weight'',
          ''classifier.weight'']

          You should probably TRAIN this model on a down-stream task to be able to
          use it for predictions and inference.

          </code></pre>

          <p>Does it mean the model is accurately outputting random predictions?</p>

          </blockquote>

          <p>I met this issue too. Did you solve this problem?</p>

          '
        raw: "> Anyone notice the warnings when loading the pretrained model?\n> ```\n\
          > Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
          \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
          > - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
          \ from the checkpoint of a model trained on another task or with another\
          \ architecture (e.g. initializing a BertForSequenceClassification model\
          \ from a BertForPreTraining model).\n> - This IS NOT expected if you are\
          \ initializing Wav2Vec2ForSequenceClassification from the checkpoint of\
          \ a model that you expect to be exactly identical (initializing a BertForSequenceClassification\
          \ model from a BertForSequenceClassification model).\n> Some weights of\
          \ Wav2Vec2ForSequenceClassification were not initialized from the model\
          \ checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
          \ 'classifier.weight']\n> You should probably TRAIN this model on a down-stream\
          \ task to be able to use it for predictions and inference.\n> ```\n> \n\
          > Does it mean the model is accurately outputting random predictions?\n\n\
          I met this issue too. Did you solve this problem?"
        updatedAt: '2023-04-14T12:05:46.059Z'
      numEdits: 0
      reactions: []
    id: 6439419a9f49f6e6ee22411c
    type: comment
  author: huttersadan
  content: "> Anyone notice the warnings when loading the pretrained model?\n> ```\n\
    > Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
    \ were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
    \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
    > - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
    \ from the checkpoint of a model trained on another task or with another architecture\
    \ (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining\
    \ model).\n> - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification\
    \ from the checkpoint of a model that you expect to be exactly identical (initializing\
    \ a BertForSequenceClassification model from a BertForSequenceClassification model).\n\
    > Some weights of Wav2Vec2ForSequenceClassification were not initialized from\
    \ the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
    \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
    \ 'classifier.weight']\n> You should probably TRAIN this model on a down-stream\
    \ task to be able to use it for predictions and inference.\n> ```\n> \n> Does\
    \ it mean the model is accurately outputting random predictions?\n\nI met this\
    \ issue too. Did you solve this problem?"
  created_at: 2023-04-14 11:05:46+00:00
  edited: false
  hidden: false
  id: 6439419a9f49f6e6ee22411c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665539282451-62f85e7104de855c35e55e75.png?w=200&h=200&f=face
      fullname: HJ.Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HJChen
      type: user
    createdAt: '2023-05-09T13:04:19.000Z'
    data:
      edited: false
      editors:
      - HJChen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665539282451-62f85e7104de855c35e55e75.png?w=200&h=200&f=face
          fullname: HJ.Chen
          isHf: false
          isPro: false
          name: HJChen
          type: user
        html: '<blockquote>

          <blockquote>

          <p>Anyone notice the warnings when loading the pretrained model?</p>

          <pre><code>Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          were not used when initializing Wav2Vec2ForSequenceClassification: [''classifier.output.bias'',
          ''classifier.dense.weight'', ''classifier.dense.bias'', ''classifier.output.weight'']

          - This IS expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model trained on another task or with another architecture
          (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining
          model).

          - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model that you expect to be exactly identical (initializing
          a BertForSequenceClassification model from a BertForSequenceClassification
          model).

          Some weights of Wav2Vec2ForSequenceClassification were not initialized from
          the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          and are newly initialized: [''projector.bias'', ''classifier.bias'', ''projector.weight'',
          ''classifier.weight'']

          You should probably TRAIN this model on a down-stream task to be able to
          use it for predictions and inference.

          </code></pre>

          <p>Does it mean the model is accurately outputting random predictions?</p>

          </blockquote>

          <p>I met this issue too. Did you solve this problem?</p>

          </blockquote>

          <p>Well, I guess I solved it. I noticed that the reason for the mismatch
          is the name of that layer. I manually set the random initialed layer''s
          value.</p>

          '
        raw: "> > Anyone notice the warnings when loading the pretrained model?\n\
          > > ```\n> > Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
          \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
          > > - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
          \ from the checkpoint of a model trained on another task or with another\
          \ architecture (e.g. initializing a BertForSequenceClassification model\
          \ from a BertForPreTraining model).\n> > - This IS NOT expected if you are\
          \ initializing Wav2Vec2ForSequenceClassification from the checkpoint of\
          \ a model that you expect to be exactly identical (initializing a BertForSequenceClassification\
          \ model from a BertForSequenceClassification model).\n> > Some weights of\
          \ Wav2Vec2ForSequenceClassification were not initialized from the model\
          \ checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
          \ 'classifier.weight']\n> > You should probably TRAIN this model on a down-stream\
          \ task to be able to use it for predictions and inference.\n> > ```\n> >\
          \ \n> > Does it mean the model is accurately outputting random predictions?\n\
          > \n> I met this issue too. Did you solve this problem?\n\nWell, I guess\
          \ I solved it. I noticed that the reason for the mismatch is the name of\
          \ that layer. I manually set the random initialed layer's value."
        updatedAt: '2023-05-09T13:04:19.472Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F917"
        users:
        - Zkli
        - HJChen
    id: 645a44d37a9cc041197ae98a
    type: comment
  author: HJChen
  content: "> > Anyone notice the warnings when loading the pretrained model?\n> >\
    \ ```\n> > Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
    \ were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
    \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
    > > - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
    \ from the checkpoint of a model trained on another task or with another architecture\
    \ (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining\
    \ model).\n> > - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification\
    \ from the checkpoint of a model that you expect to be exactly identical (initializing\
    \ a BertForSequenceClassification model from a BertForSequenceClassification model).\n\
    > > Some weights of Wav2Vec2ForSequenceClassification were not initialized from\
    \ the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
    \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
    \ 'classifier.weight']\n> > You should probably TRAIN this model on a down-stream\
    \ task to be able to use it for predictions and inference.\n> > ```\n> > \n> >\
    \ Does it mean the model is accurately outputting random predictions?\n> \n> I\
    \ met this issue too. Did you solve this problem?\n\nWell, I guess I solved it.\
    \ I noticed that the reason for the mismatch is the name of that layer. I manually\
    \ set the random initialed layer's value."
  created_at: 2023-05-09 12:04:19+00:00
  edited: false
  hidden: false
  id: 645a44d37a9cc041197ae98a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/171dc46396c443601336fcc36c480011.svg
      fullname: Luis Otte
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luis-otte
      type: user
    createdAt: '2023-05-18T05:01:13.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/171dc46396c443601336fcc36c480011.svg
          fullname: Luis Otte
          isHf: false
          isPro: false
          name: luis-otte
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-05-18T05:15:08.897Z'
      numEdits: 0
      reactions: []
    id: 6465b11986e668ad22ede6c1
    type: comment
  author: luis-otte
  content: This comment has been hidden
  created_at: 2023-05-18 04:01:13+00:00
  edited: true
  hidden: true
  id: 6465b11986e668ad22ede6c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69854a41558693d8a5295bb6581aa9a9.svg
      fullname: Abdul Qader Alafeefi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: qadoor
      type: user
    createdAt: '2023-05-31T08:57:41.000Z'
    data:
      edited: false
      editors:
      - qadoor
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69854a41558693d8a5295bb6581aa9a9.svg
          fullname: Abdul Qader Alafeefi
          isHf: false
          isPro: false
          name: qadoor
          type: user
        html: '<blockquote>

          <blockquote>

          <blockquote>

          <p>Anyone notice the warnings when loading the pretrained model?</p>

          <pre><code>Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          were not used when initializing Wav2Vec2ForSequenceClassification: [''classifier.output.bias'',
          ''classifier.dense.weight'', ''classifier.dense.bias'', ''classifier.output.weight'']

          - This IS expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model trained on another task or with another architecture
          (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining
          model).

          - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model that you expect to be exactly identical (initializing
          a BertForSequenceClassification model from a BertForSequenceClassification
          model).

          Some weights of Wav2Vec2ForSequenceClassification were not initialized from
          the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          and are newly initialized: [''projector.bias'', ''classifier.bias'', ''projector.weight'',
          ''classifier.weight'']

          You should probably TRAIN this model on a down-stream task to be able to
          use it for predictions and inference.

          </code></pre>

          <p>Does it mean the model is accurately outputting random predictions?</p>

          </blockquote>

          <p>I met this issue too. Did you solve this problem?</p>

          </blockquote>

          <p>Well, I guess I solved it. I noticed that the reason for the mismatch
          is the name of that layer. I manually set the random initialed layer''s
          value.</p>

          </blockquote>

          <p>How did you set the random initialed layer''s value manually?</p>

          '
        raw: "> > > Anyone notice the warnings when loading the pretrained model?\n\
          > > > ```\n> > > Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
          \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
          > > > - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
          \ from the checkpoint of a model trained on another task or with another\
          \ architecture (e.g. initializing a BertForSequenceClassification model\
          \ from a BertForPreTraining model).\n> > > - This IS NOT expected if you\
          \ are initializing Wav2Vec2ForSequenceClassification from the checkpoint\
          \ of a model that you expect to be exactly identical (initializing a BertForSequenceClassification\
          \ model from a BertForSequenceClassification model).\n> > > Some weights\
          \ of Wav2Vec2ForSequenceClassification were not initialized from the model\
          \ checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
          \ 'classifier.weight']\n> > > You should probably TRAIN this model on a\
          \ down-stream task to be able to use it for predictions and inference.\n\
          > > > ```\n> > > \n> > > Does it mean the model is accurately outputting\
          \ random predictions?\n> > \n> > I met this issue too. Did you solve this\
          \ problem?\n> \n> Well, I guess I solved it. I noticed that the reason for\
          \ the mismatch is the name of that layer. I manually set the random initialed\
          \ layer's value.\n\nHow did you set the random initialed layer's value manually?"
        updatedAt: '2023-05-31T08:57:41.400Z'
      numEdits: 0
      reactions: []
    id: 64770c0540c99df876005323
    type: comment
  author: qadoor
  content: "> > > Anyone notice the warnings when loading the pretrained model?\n\
    > > > ```\n> > > Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
    \ were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
    \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
    > > > - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
    \ from the checkpoint of a model trained on another task or with another architecture\
    \ (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining\
    \ model).\n> > > - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification\
    \ from the checkpoint of a model that you expect to be exactly identical (initializing\
    \ a BertForSequenceClassification model from a BertForSequenceClassification model).\n\
    > > > Some weights of Wav2Vec2ForSequenceClassification were not initialized from\
    \ the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
    \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
    \ 'classifier.weight']\n> > > You should probably TRAIN this model on a down-stream\
    \ task to be able to use it for predictions and inference.\n> > > ```\n> > > \n\
    > > > Does it mean the model is accurately outputting random predictions?\n> >\
    \ \n> > I met this issue too. Did you solve this problem?\n> \n> Well, I guess\
    \ I solved it. I noticed that the reason for the mismatch is the name of that\
    \ layer. I manually set the random initialed layer's value.\n\nHow did you set\
    \ the random initialed layer's value manually?"
  created_at: 2023-05-31 07:57:41+00:00
  edited: false
  hidden: false
  id: 64770c0540c99df876005323
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5c3082fe8549890ad1b3f326854127c1.svg
      fullname: Zekai Li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Zkli
      type: user
    createdAt: '2023-06-05T08:21:48.000Z'
    data:
      edited: false
      editors:
      - Zkli
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8073862195014954
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5c3082fe8549890ad1b3f326854127c1.svg
          fullname: Zekai Li
          isHf: false
          isPro: false
          name: Zkli
          type: user
        html: '<blockquote>

          <blockquote>

          <blockquote>

          <p>Anyone notice the warnings when loading the pretrained model?</p>

          <pre><code>Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          were not used when initializing Wav2Vec2ForSequenceClassification: [''classifier.output.bias'',
          ''classifier.dense.weight'', ''classifier.dense.bias'', ''classifier.output.weight'']

          - This IS expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model trained on another task or with another architecture
          (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining
          model).

          - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification
          from the checkpoint of a model that you expect to be exactly identical (initializing
          a BertForSequenceClassification model from a BertForSequenceClassification
          model).

          Some weights of Wav2Vec2ForSequenceClassification were not initialized from
          the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
          and are newly initialized: [''projector.bias'', ''classifier.bias'', ''projector.weight'',
          ''classifier.weight'']

          You should probably TRAIN this model on a down-stream task to be able to
          use it for predictions and inference.

          </code></pre>

          <p>Does it mean the model is accurately outputting random predictions?</p>

          </blockquote>

          <p>I met this issue too. Did you solve this problem?</p>

          </blockquote>

          <p>Well, I guess I solved it. I noticed that the reason for the mismatch
          is the name of that layer. I manually set the random initialed layer''s
          value.</p>

          </blockquote>

          <p>I have the same question. How did you set that?</p>

          '
        raw: "> > > Anyone notice the warnings when loading the pretrained model?\n\
          > > > ```\n> > > Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
          \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
          > > > - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
          \ from the checkpoint of a model trained on another task or with another\
          \ architecture (e.g. initializing a BertForSequenceClassification model\
          \ from a BertForPreTraining model).\n> > > - This IS NOT expected if you\
          \ are initializing Wav2Vec2ForSequenceClassification from the checkpoint\
          \ of a model that you expect to be exactly identical (initializing a BertForSequenceClassification\
          \ model from a BertForSequenceClassification model).\n> > > Some weights\
          \ of Wav2Vec2ForSequenceClassification were not initialized from the model\
          \ checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
          \ 'classifier.weight']\n> > > You should probably TRAIN this model on a\
          \ down-stream task to be able to use it for predictions and inference.\n\
          > > > ```\n> > > \n> > > Does it mean the model is accurately outputting\
          \ random predictions?\n> > \n> > I met this issue too. Did you solve this\
          \ problem?\n> \n> Well, I guess I solved it. I noticed that the reason for\
          \ the mismatch is the name of that layer. I manually set the random initialed\
          \ layer's value.\n\nI have the same question. How did you set that?"
        updatedAt: '2023-06-05T08:21:48.276Z'
      numEdits: 0
      reactions: []
    id: 647d9b1c32c471a7fa806184
    type: comment
  author: Zkli
  content: "> > > Anyone notice the warnings when loading the pretrained model?\n\
    > > > ```\n> > > Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
    \ were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
    \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
    > > > - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
    \ from the checkpoint of a model trained on another task or with another architecture\
    \ (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining\
    \ model).\n> > > - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification\
    \ from the checkpoint of a model that you expect to be exactly identical (initializing\
    \ a BertForSequenceClassification model from a BertForSequenceClassification model).\n\
    > > > Some weights of Wav2Vec2ForSequenceClassification were not initialized from\
    \ the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
    \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
    \ 'classifier.weight']\n> > > You should probably TRAIN this model on a down-stream\
    \ task to be able to use it for predictions and inference.\n> > > ```\n> > > \n\
    > > > Does it mean the model is accurately outputting random predictions?\n> >\
    \ \n> > I met this issue too. Did you solve this problem?\n> \n> Well, I guess\
    \ I solved it. I noticed that the reason for the mismatch is the name of that\
    \ layer. I manually set the random initialed layer's value.\n\nI have the same\
    \ question. How did you set that?"
  created_at: 2023-06-05 07:21:48+00:00
  edited: false
  hidden: false
  id: 647d9b1c32c471a7fa806184
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665539282451-62f85e7104de855c35e55e75.png?w=200&h=200&f=face
      fullname: HJ.Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HJChen
      type: user
    createdAt: '2023-06-08T13:58:23.000Z'
    data:
      edited: true
      editors:
      - HJChen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6894683241844177
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665539282451-62f85e7104de855c35e55e75.png?w=200&h=200&f=face
          fullname: HJ.Chen
          isHf: false
          isPro: false
          name: HJChen
          type: user
        html: "<p>!!! This is how I did, plz let me know if it works on your data\
          \ !!! <span data-props=\"{&quot;user&quot;:&quot;Zkli&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Zkli\">@<span class=\"\
          underline\">Zkli</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;qadoor&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/qadoor\">@<span class=\"underline\">qadoor</span></a></span>\n\
          \n\t</span></span> <span data-props=\"{&quot;user&quot;:&quot;huttersadan&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/huttersadan\"\
          >@<span class=\"underline\">huttersadan</span></a></span>\n\n\t</span></span>\
          \ </p>\n<pre><code class=\"language-python\">model = AutoModelForAudioClassification.from_pretrained(<span\
          \ class=\"hljs-string\">\"wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\
          </span>) \n\nmodel.projector = nn.Linear(<span class=\"hljs-number\">1024</span>,\
          \ <span class=\"hljs-number\">1024</span>, bias=<span class=\"hljs-literal\"\
          >True</span>)\nmodel.classifier = nn.Linear(<span class=\"hljs-number\"\
          >1024</span>, <span class=\"hljs-number\">8</span>, bias=<span class=\"\
          hljs-literal\">True</span>)\n\ntorch_state_dict = torch.load(<span class=\"\
          hljs-string\">'/content/wav2vec2-lg-xlsr-en-speech-emotion-recognition/pytorch_model.bin'</span>,\
          \ map_location=torch.device(<span class=\"hljs-string\">'cpu'</span>))\n\
          \nmodel.projector.weight.data = torch_state_dict[<span class=\"hljs-string\"\
          >'classifier.dense.weight'</span>]\nmodel.projector.bias.data = torch_state_dict[<span\
          \ class=\"hljs-string\">'classifier.dense.bias'</span>]\n\nmodel.classifier.weight.data\
          \ = torch_state_dict[<span class=\"hljs-string\">'classifier.output.weight'</span>]\n\
          model.classifier.bias.data = torch_state_dict[<span class=\"hljs-string\"\
          >'classifier.output.bias'</span>]\n</code></pre>\n<blockquote>\n<blockquote>\n\
          <blockquote>\n<p>Anyone notice the warnings when loading the pretrained\
          \ model?</p>\n<pre><code>Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
          \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
          - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
          \ from the checkpoint of a model trained on another task or with another\
          \ architecture (e.g. initializing a BertForSequenceClassification model\
          \ from a BertForPreTraining model).\n- This IS NOT expected if you are initializing\
          \ Wav2Vec2ForSequenceClassification from the checkpoint of a model that\
          \ you expect to be exactly identical (initializing a BertForSequenceClassification\
          \ model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2ForSequenceClassification\
          \ were not initialized from the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
          \ 'classifier.weight']\nYou should probably TRAIN this model on a down-stream\
          \ task to be able to use it for predictions and inference.\n</code></pre>\n\
          <p>Does it mean the model is accurately outputting random predictions?</p>\n\
          </blockquote>\n<p>I met this issue too. Did you solve this problem?</p>\n\
          </blockquote>\n<p>Well, I guess I solved it. I noticed that the reason for\
          \ the mismatch is the name of that layer. I manually set the random initialed\
          \ layer's value.</p>\n</blockquote>\n"
        raw: "!!! This is how I did, plz let me know if it works on your data !!!\
          \ @Zkli @qadoor @huttersadan \n```python\nmodel = AutoModelForAudioClassification.from_pretrained(\"\
          wav2vec2-lg-xlsr-en-speech-emotion-recognition\") \n\nmodel.projector =\
          \ nn.Linear(1024, 1024, bias=True)\nmodel.classifier = nn.Linear(1024, 8,\
          \ bias=True)\n\ntorch_state_dict = torch.load('/content/wav2vec2-lg-xlsr-en-speech-emotion-recognition/pytorch_model.bin',\
          \ map_location=torch.device('cpu'))\n\nmodel.projector.weight.data = torch_state_dict['classifier.dense.weight']\n\
          model.projector.bias.data = torch_state_dict['classifier.dense.bias']\n\n\
          model.classifier.weight.data = torch_state_dict['classifier.output.weight']\n\
          model.classifier.bias.data = torch_state_dict['classifier.output.bias']\n\
          ```\n> > > Anyone notice the warnings when loading the pretrained model?\n\
          > > > ```\n> > > Some weights of the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ were not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
          \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
          > > > - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
          \ from the checkpoint of a model trained on another task or with another\
          \ architecture (e.g. initializing a BertForSequenceClassification model\
          \ from a BertForPreTraining model).\n> > > - This IS NOT expected if you\
          \ are initializing Wav2Vec2ForSequenceClassification from the checkpoint\
          \ of a model that you expect to be exactly identical (initializing a BertForSequenceClassification\
          \ model from a BertForSequenceClassification model).\n> > > Some weights\
          \ of Wav2Vec2ForSequenceClassification were not initialized from the model\
          \ checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
          \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
          \ 'classifier.weight']\n> > > You should probably TRAIN this model on a\
          \ down-stream task to be able to use it for predictions and inference.\n\
          > > > ```\n> > > \n> > > Does it mean the model is accurately outputting\
          \ random predictions?\n> > \n> > I met this issue too. Did you solve this\
          \ problem?\n> \n> Well, I guess I solved it. I noticed that the reason for\
          \ the mismatch is the name of that layer. I manually set the random initialed\
          \ layer's value."
        updatedAt: '2023-06-08T14:01:27.139Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - money4
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - marcmaxmeister
    id: 6481de7f15c5dc529069760f
    type: comment
  author: HJChen
  content: "!!! This is how I did, plz let me know if it works on your data !!! @Zkli\
    \ @qadoor @huttersadan \n```python\nmodel = AutoModelForAudioClassification.from_pretrained(\"\
    wav2vec2-lg-xlsr-en-speech-emotion-recognition\") \n\nmodel.projector = nn.Linear(1024,\
    \ 1024, bias=True)\nmodel.classifier = nn.Linear(1024, 8, bias=True)\n\ntorch_state_dict\
    \ = torch.load('/content/wav2vec2-lg-xlsr-en-speech-emotion-recognition/pytorch_model.bin',\
    \ map_location=torch.device('cpu'))\n\nmodel.projector.weight.data = torch_state_dict['classifier.dense.weight']\n\
    model.projector.bias.data = torch_state_dict['classifier.dense.bias']\n\nmodel.classifier.weight.data\
    \ = torch_state_dict['classifier.output.weight']\nmodel.classifier.bias.data =\
    \ torch_state_dict['classifier.output.bias']\n```\n> > > Anyone notice the warnings\
    \ when loading the pretrained model?\n> > > ```\n> > > Some weights of the model\
    \ checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition were\
    \ not used when initializing Wav2Vec2ForSequenceClassification: ['classifier.output.bias',\
    \ 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.output.weight']\n\
    > > > - This IS expected if you are initializing Wav2Vec2ForSequenceClassification\
    \ from the checkpoint of a model trained on another task or with another architecture\
    \ (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining\
    \ model).\n> > > - This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification\
    \ from the checkpoint of a model that you expect to be exactly identical (initializing\
    \ a BertForSequenceClassification model from a BertForSequenceClassification model).\n\
    > > > Some weights of Wav2Vec2ForSequenceClassification were not initialized from\
    \ the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\
    \ and are newly initialized: ['projector.bias', 'classifier.bias', 'projector.weight',\
    \ 'classifier.weight']\n> > > You should probably TRAIN this model on a down-stream\
    \ task to be able to use it for predictions and inference.\n> > > ```\n> > > \n\
    > > > Does it mean the model is accurately outputting random predictions?\n> >\
    \ \n> > I met this issue too. Did you solve this problem?\n> \n> Well, I guess\
    \ I solved it. I noticed that the reason for the mismatch is the name of that\
    \ layer. I manually set the random initialed layer's value."
  created_at: 2023-06-08 12:58:23+00:00
  edited: true
  hidden: false
  id: 6481de7f15c5dc529069760f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/55db693edfbb2ad3742d941c56fd6843.svg
      fullname: "Ant\xF3nio Carlos Pinto Oliveira"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aoliveira
      type: user
    createdAt: '2023-11-24T12:02:17.000Z'
    data:
      edited: true
      editors:
      - aoliveira
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8186014890670776
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/55db693edfbb2ad3742d941c56fd6843.svg
          fullname: "Ant\xF3nio Carlos Pinto Oliveira"
          isHf: false
          isPro: false
          name: aoliveira
          type: user
        html: '<p>I was able to use the pipeline (from transformers) giving the feature
          extractor and the model, but I only get the five top scored classes. Is
          there a way to get all eight?</p>

          <p>[Edit: I have to add <code>return_all_scores=True</code> when instantiating
          the pipeline.]</p>

          '
        raw: 'I was able to use the pipeline (from transformers) giving the feature
          extractor and the model, but I only get the five top scored classes. Is
          there a way to get all eight?


          [Edit: I have to add `return_all_scores=True` when instantiating the pipeline.]'
        updatedAt: '2023-11-28T12:24:46.939Z'
      numEdits: 1
      reactions: []
    id: 656090c9462e5ebcbfcdabb1
    type: comment
  author: aoliveira
  content: 'I was able to use the pipeline (from transformers) giving the feature
    extractor and the model, but I only get the five top scored classes. Is there
    a way to get all eight?


    [Edit: I have to add `return_all_scores=True` when instantiating the pipeline.]'
  created_at: 2023-11-24 12:02:17+00:00
  edited: true
  hidden: false
  id: 656090c9462e5ebcbfcdabb1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition
repo_type: model
status: open
target_branch: null
title: How to run pre-trained model on local audio file?
