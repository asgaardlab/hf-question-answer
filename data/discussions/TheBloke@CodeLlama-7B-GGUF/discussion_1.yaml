!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lmz
conflicting_files: null
created_at: 2023-08-25 12:59:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
      fullname: Laurent Mazare
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lmz
      type: user
    createdAt: '2023-08-25T13:59:07.000Z'
    data:
      edited: false
      editors:
      - lmz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9633495807647705
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
          fullname: Laurent Mazare
          isHf: false
          isPro: false
          name: lmz
          type: user
        html: '<p>Hey,<br>First thanks for all the hard work providing these quantized
          models in such a timely fashion, that''s super helpful!<br>I noticed that
          you have some mention in the model card on "clients and libraries that are
          known to support GGUF" so just wanted to mention that our rust library <a
          rel="nofollow" href="https://github.com/huggingface/candle">candle</a> now
          also supports using GGUF files. We even have in our examples an equivalent
          of llama.cpp that actually uses your weight files :) So would be great if
          it can be added to your list. No worries if you want to keep the list small
          and/or for libraries that you know well, feel free to close this issue if
          that''s the case.</p>

          '
        raw: "Hey,\r\nFirst thanks for all the hard work providing these quantized\
          \ models in such a timely fashion, that's super helpful!\r\nI noticed that\
          \ you have some mention in the model card on \"clients and libraries that\
          \ are known to support GGUF\" so just wanted to mention that our rust library\
          \ [candle](https://github.com/huggingface/candle) now also supports using\
          \ GGUF files. We even have in our examples an equivalent of llama.cpp that\
          \ actually uses your weight files :) So would be great if it can be added\
          \ to your list. No worries if you want to keep the list small and/or for\
          \ libraries that you know well, feel free to close this issue if that's\
          \ the case."
        updatedAt: '2023-08-25T13:59:07.880Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jlzhou
    id: 64e8b3ab0150435eaf7d4841
    type: comment
  author: lmz
  content: "Hey,\r\nFirst thanks for all the hard work providing these quantized models\
    \ in such a timely fashion, that's super helpful!\r\nI noticed that you have some\
    \ mention in the model card on \"clients and libraries that are known to support\
    \ GGUF\" so just wanted to mention that our rust library [candle](https://github.com/huggingface/candle)\
    \ now also supports using GGUF files. We even have in our examples an equivalent\
    \ of llama.cpp that actually uses your weight files :) So would be great if it\
    \ can be added to your list. No worries if you want to keep the list small and/or\
    \ for libraries that you know well, feel free to close this issue if that's the\
    \ case."
  created_at: 2023-08-25 12:59:07+00:00
  edited: false
  hidden: false
  id: 64e8b3ab0150435eaf7d4841
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-25T15:25:49.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9407773613929749
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Thanks for letting me know! I have added it to my GGUF template.</p>

          <ul>

          <li><a rel="nofollow" href="https://github.com/huggingface/candle">candle</a>,
          added GGUF support on August 22nd. Candle is a Rust ML framework with a
          focus on performance, including GPU support, and ease of use.</li>

          </ul>

          '
        raw: 'Thanks for letting me know! I have added it to my GGUF template.


          * [candle](https://github.com/huggingface/candle), added GGUF support on
          August 22nd. Candle is a Rust ML framework with a focus on performance,
          including GPU support, and ease of use.'
        updatedAt: '2023-08-25T15:25:49.129Z'
      numEdits: 0
      reactions: []
    id: 64e8c7fd24abf6be052219ab
    type: comment
  author: TheBloke
  content: 'Thanks for letting me know! I have added it to my GGUF template.


    * [candle](https://github.com/huggingface/candle), added GGUF support on August
    22nd. Candle is a Rust ML framework with a focus on performance, including GPU
    support, and ease of use.'
  created_at: 2023-08-25 14:25:49+00:00
  edited: false
  hidden: false
  id: 64e8c7fd24abf6be052219ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
      fullname: Laurent Mazare
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lmz
      type: user
    createdAt: '2023-08-25T15:36:06.000Z'
    data:
      edited: false
      editors:
      - lmz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8514842987060547
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
          fullname: Laurent Mazare
          isHf: false
          isPro: false
          name: lmz
          type: user
        html: '<p>Great, thanks a lot!</p>

          '
        raw: Great, thanks a lot!
        updatedAt: '2023-08-25T15:36:06.664Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64e8ca66f2f5545eda096697
    id: 64e8ca66f2f5545eda096695
    type: comment
  author: lmz
  content: Great, thanks a lot!
  created_at: 2023-08-25 14:36:06+00:00
  edited: false
  hidden: false
  id: 64e8ca66f2f5545eda096695
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
      fullname: Laurent Mazare
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lmz
      type: user
    createdAt: '2023-08-25T15:36:06.000Z'
    data:
      status: closed
    id: 64e8ca66f2f5545eda096697
    type: status-change
  author: lmz
  created_at: 2023-08-25 14:36:06+00:00
  id: 64e8ca66f2f5545eda096697
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/CodeLlama-7B-GGUF
repo_type: model
status: closed
target_branch: null
title: Another library supporting GGUF
