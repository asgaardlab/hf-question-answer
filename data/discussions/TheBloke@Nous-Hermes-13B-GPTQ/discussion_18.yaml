!!python/object:huggingface_hub.community.DiscussionWithDetails
author: synapse
conflicting_files: null
created_at: 2024-01-19 09:49:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624970855793-60bf781464e3c84de301c998.jpeg?w=200&h=200&f=face
      fullname: "Jos\xE9 Egas-L\xF3pez"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: synapse
      type: user
    createdAt: '2024-01-19T09:49:12.000Z'
    data:
      edited: false
      editors:
      - synapse
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5349609851837158
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624970855793-60bf781464e3c84de301c998.jpeg?w=200&h=200&f=face
          fullname: "Jos\xE9 Egas-L\xF3pez"
          isHf: false
          isPro: false
          name: synapse
          type: user
        html: "<p>I am getting the error:<br><code>FileNotFoundError: Could not find\
          \ model in TheBloke/Nous-Hermes-13B-GPTQ</code></p>\n<p>Am I missing something\
          \ in my code below (running on collab)?:</p>\n<pre><code>model_name_or_path\
          \ = \"TheBloke/Nous-Hermes-13B-GPTQ\"\nmodel_basename = \"nous-hermes-13b-GPTQ-4bit-128g.no-act.order\"\
          \n\nuse_triton = False\n\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path,\
          \ use_fast=True)\n\nmodel = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n\
          \        model_basename=model_basename,\n        use_safetensors=True,\n\
          \        trust_remote_code=True,\n        device=\"cuda:0\",\n        use_triton=use_triton,\n\
          \        quantize_config=None)\n</code></pre>\n"
        raw: "I am getting the error:\r\n`FileNotFoundError: Could not find model\
          \ in TheBloke/Nous-Hermes-13B-GPTQ`\r\n\r\nAm I missing something in my\
          \ code below (running on collab)?:\r\n```\r\nmodel_name_or_path = \"TheBloke/Nous-Hermes-13B-GPTQ\"\
          \r\nmodel_basename = \"nous-hermes-13b-GPTQ-4bit-128g.no-act.order\"\r\n\
          \r\nuse_triton = False\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path,\
          \ use_fast=True)\r\n\r\nmodel = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\r\
          \n        model_basename=model_basename,\r\n        use_safetensors=True,\r\
          \n        trust_remote_code=True,\r\n        device=\"cuda:0\",\r\n    \
          \    use_triton=use_triton,\r\n        quantize_config=None)\r\n```"
        updatedAt: '2024-01-19T09:49:13.002Z'
      numEdits: 0
      reactions: []
    id: 65aa459871c5d01a282d8cc0
    type: comment
  author: synapse
  content: "I am getting the error:\r\n`FileNotFoundError: Could not find model in\
    \ TheBloke/Nous-Hermes-13B-GPTQ`\r\n\r\nAm I missing something in my code below\
    \ (running on collab)?:\r\n```\r\nmodel_name_or_path = \"TheBloke/Nous-Hermes-13B-GPTQ\"\
    \r\nmodel_basename = \"nous-hermes-13b-GPTQ-4bit-128g.no-act.order\"\r\n\r\nuse_triton\
    \ = False\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path,\
    \ use_fast=True)\r\n\r\nmodel = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\r\
    \n        model_basename=model_basename,\r\n        use_safetensors=True,\r\n\
    \        trust_remote_code=True,\r\n        device=\"cuda:0\",\r\n        use_triton=use_triton,\r\
    \n        quantize_config=None)\r\n```"
  created_at: 2024-01-19 09:49:12+00:00
  edited: false
  hidden: false
  id: 65aa459871c5d01a282d8cc0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: TheBloke/Nous-Hermes-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: 'FileNotFoundError: Could not find model in TheBloke/Nous-Hermes-13B-GPTQ'
