!!python/object:huggingface_hub.community.DiscussionWithDetails
author: versae
conflicting_files: null
created_at: 2023-09-18 11:14:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593016943046-noauth.jpeg?w=200&h=200&f=face
      fullname: Javier de la Rosa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: versae
      type: user
    createdAt: '2023-09-18T12:14:15.000Z'
    data:
      edited: false
      editors:
      - versae
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.25733885169029236
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593016943046-noauth.jpeg?w=200&h=200&f=face
          fullname: Javier de la Rosa
          isHf: false
          isPro: false
          name: versae
          type: user
        html: '<p>The documentation says the text model is XLM Roberta, but when I
          compare the token ids of the HF tokenizer and the OpenCLIP tokenizer I get
          very different results.</p>

          <pre><code class="language-python"><span class="hljs-keyword">import</span>
          numpy <span class="hljs-keyword">as</span> np

          <span class="hljs-keyword">import</span> open_clip

          <span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span>
          AutoTokenizer

          roberta = AutoTokenizer.from_pretrained(<span class="hljs-string">"xlm-roberta-base"</span>)

          tokenizer = open_clip.get_tokenizer(<span class="hljs-string">''ViT-B-32''</span>)

          np.array(roberta.encode(<span class="hljs-string">"A dog"</span>, padding=<span
          class="hljs-string">"max_length"</span>, max_length=<span class="hljs-number">77</span>))

          <span class="hljs-comment">#&nbsp;array([    0,    62, 10269,     2,     1,     1,     1,     1,     1,</span>

          <span class="hljs-comment">#&nbsp;           1,     1,     1,     1,     1,     1,     1,     1,     1,</span>

          <span class="hljs-comment">#&nbsp;           1,     1,     1,     1,     1,     1,     1,     1,     1,</span>

          <span class="hljs-comment">#&nbsp;           1,     1,     1,     1,     1,     1,     1,     1,     1,</span>

          <span class="hljs-comment">#&nbsp;           1,     1,     1,     1,     1,     1,     1,     1,     1,</span>

          <span class="hljs-comment">#&nbsp;           1,     1,     1,     1,     1,     1,     1,     1,     1,</span>

          <span class="hljs-comment">#&nbsp;           1,     1,     1,     1,     1,     1,     1,     1,     1,</span>

          <span class="hljs-comment">#&nbsp;           1,     1,     1,     1,     1,     1,     1,     1,     1,</span>

          <span class="hljs-comment">#&nbsp;           1,     1,     1,     1,     1])</span>


          tokenizer(<span class="hljs-string">"A dog"</span>)[<span class="hljs-number">0</span>]

          <span class="hljs-comment">#&nbsp;tensor([49406,   320,  1929, 49407,     0,     0,     0,     0,     0,     0,</span>

          <span class="hljs-comment">#&nbsp;            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>

          <span class="hljs-comment">#&nbsp;            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>

          <span class="hljs-comment">#&nbsp;            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>

          <span class="hljs-comment">#&nbsp;            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>

          <span class="hljs-comment">#&nbsp;            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>

          <span class="hljs-comment">#&nbsp;            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,</span>

          <span class="hljs-comment">#&nbsp;            0,     0,     0,     0,     0,     0,     0])</span>

          </code></pre>

          '
        raw: "The documentation says the text model is XLM Roberta, but when I compare\
          \ the token ids of the HF tokenizer and the OpenCLIP tokenizer I get very\
          \ different results.\r\n\r\n```python\r\nimport numpy as np\r\nimport open_clip\r\
          \nfrom transformers import AutoTokenizer\r\nroberta = AutoTokenizer.from_pretrained(\"\
          xlm-roberta-base\")\r\ntokenizer = open_clip.get_tokenizer('ViT-B-32')\r\
          \nnp.array(roberta.encode(\"A dog\", padding=\"max_length\", max_length=77))\r\
          \n#\_array([    0,    62, 10269,     2,     1,     1,     1,     1,    \
          \ 1,\r\n#\_           1,     1,     1,     1,     1,     1,     1,     1,\
          \     1,\r\n#\_           1,     1,     1,     1,     1,     1,     1, \
          \    1,     1,\r\n#\_           1,     1,     1,     1,     1,     1,  \
          \   1,     1,     1,\r\n#\_           1,     1,     1,     1,     1,   \
          \  1,     1,     1,     1,\r\n#\_           1,     1,     1,     1,    \
          \ 1,     1,     1,     1,     1,\r\n#\_           1,     1,     1,     1,\
          \     1,     1,     1,     1,     1,\r\n#\_           1,     1,     1, \
          \    1,     1,     1,     1,     1,     1,\r\n#\_           1,     1,  \
          \   1,     1,     1])\r\n\r\ntokenizer(\"A dog\")[0]\r\n#\_tensor([49406,\
          \   320,  1929, 49407,     0,     0,     0,     0,     0,     0,\r\n#\_\
          \            0,     0,     0,     0,     0,     0,     0,     0,     0,\
          \     0,\r\n#\_            0,     0,     0,     0,     0,     0,     0,\
          \     0,     0,     0,\r\n#\_            0,     0,     0,     0,     0,\
          \     0,     0,     0,     0,     0,\r\n#\_            0,     0,     0,\
          \     0,     0,     0,     0,     0,     0,     0,\r\n#\_            0,\
          \     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n#\_\
          \            0,     0,     0,     0,     0,     0,     0,     0,     0,\
          \     0,\r\n#\_            0,     0,     0,     0,     0,     0,     0])\r\
          \n```"
        updatedAt: '2023-09-18T12:14:15.767Z'
      numEdits: 0
      reactions: []
    id: 65083f17a226ecc608027fd4
    type: comment
  author: versae
  content: "The documentation says the text model is XLM Roberta, but when I compare\
    \ the token ids of the HF tokenizer and the OpenCLIP tokenizer I get very different\
    \ results.\r\n\r\n```python\r\nimport numpy as np\r\nimport open_clip\r\nfrom\
    \ transformers import AutoTokenizer\r\nroberta = AutoTokenizer.from_pretrained(\"\
    xlm-roberta-base\")\r\ntokenizer = open_clip.get_tokenizer('ViT-B-32')\r\nnp.array(roberta.encode(\"\
    A dog\", padding=\"max_length\", max_length=77))\r\n#\_array([    0,    62, 10269,\
    \     2,     1,     1,     1,     1,     1,\r\n#\_           1,     1,     1,\
    \     1,     1,     1,     1,     1,     1,\r\n#\_           1,     1,     1,\
    \     1,     1,     1,     1,     1,     1,\r\n#\_           1,     1,     1,\
    \     1,     1,     1,     1,     1,     1,\r\n#\_           1,     1,     1,\
    \     1,     1,     1,     1,     1,     1,\r\n#\_           1,     1,     1,\
    \     1,     1,     1,     1,     1,     1,\r\n#\_           1,     1,     1,\
    \     1,     1,     1,     1,     1,     1,\r\n#\_           1,     1,     1,\
    \     1,     1,     1,     1,     1,     1,\r\n#\_           1,     1,     1,\
    \     1,     1])\r\n\r\ntokenizer(\"A dog\")[0]\r\n#\_tensor([49406,   320,  1929,\
    \ 49407,     0,     0,     0,     0,     0,     0,\r\n#\_            0,     0,\
    \     0,     0,     0,     0,     0,     0,     0,     0,\r\n#\_            0,\
    \     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n#\_      \
    \      0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\n#\_\
    \            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\r\
    \n#\_            0,     0,     0,     0,     0,     0,     0,     0,     0,  \
    \   0,\r\n#\_            0,     0,     0,     0,     0,     0,     0,     0, \
    \    0,     0,\r\n#\_            0,     0,     0,     0,     0,     0,     0])\r\
    \n```"
  created_at: 2023-09-18 11:14:15+00:00
  edited: false
  hidden: false
  id: 65083f17a226ecc608027fd4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593016943046-noauth.jpeg?w=200&h=200&f=face
      fullname: Javier de la Rosa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: versae
      type: user
    createdAt: '2023-09-18T12:21:59.000Z'
    data:
      edited: false
      editors:
      - versae
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.1424938440322876
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593016943046-noauth.jpeg?w=200&h=200&f=face
          fullname: Javier de la Rosa
          isHf: false
          isPro: false
          name: versae
          type: user
        html: "<p>Oops, nevermind. The right model to use in OpenCLIP was <code>xlm-roberta-base-ViT-B-32</code>:</p>\n\
          <pre><code class=\"language-python\">In [<span class=\"hljs-number\">79</span>]:\
          \ tokenizer = open_clip.get_tokenizer(<span class=\"hljs-string\">'xlm-roberta-base-ViT-B-32'</span>)\n\
          \nIn [<span class=\"hljs-number\">80</span>]: tokenizer(<span class=\"hljs-string\"\
          >\"A dog\"</span>)[<span class=\"hljs-number\">0</span>]\nOut[<span class=\"\
          hljs-number\">80</span>]: \ntensor([    <span class=\"hljs-number\">0</span>,\
          \    <span class=\"hljs-number\">62</span>, <span class=\"hljs-number\"\
          >10269</span>,     <span class=\"hljs-number\">2</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,\n            <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\n\
          \            <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,\n            <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,\n            <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,\n            <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,\n            <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,\n            <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>])\n\nIn [<span class=\"hljs-number\">81</span>]:\
          \ np.array(roberta.encode(<span class=\"hljs-string\">\"A dog\"</span>,\
          \ padding=<span class=\"hljs-string\">\"max_length\"</span>, max_length=<span\
          \ class=\"hljs-number\">77</span>))\nOut[<span class=\"hljs-number\">81</span>]:\
          \ \narray([    <span class=\"hljs-number\">0</span>,    <span class=\"hljs-number\"\
          >62</span>, <span class=\"hljs-number\">10269</span>,     <span class=\"\
          hljs-number\">2</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,\n           <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,\n           <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,\n           <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,\n           <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\n    \
          \       <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,\n           <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,\n           <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,     <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,\
          \     <span class=\"hljs-number\">1</span>,\n           <span class=\"hljs-number\"\
          >1</span>,     <span class=\"hljs-number\">1</span>,     <span class=\"\
          hljs-number\">1</span>,     <span class=\"hljs-number\">1</span>,     <span\
          \ class=\"hljs-number\">1</span>])\n</code></pre>\n"
        raw: "Oops, nevermind. The right model to use in OpenCLIP was `xlm-roberta-base-ViT-B-32`:\n\
          \n```python\nIn [79]: tokenizer = open_clip.get_tokenizer('xlm-roberta-base-ViT-B-32')\n\
          \nIn [80]: tokenizer(\"A dog\")[0]\nOut[80]: \ntensor([    0,    62, 10269,\
          \     2,     1,     1,     1,     1,     1,     1,\n            1,     1,\
          \     1,     1,     1,     1,     1,     1,     1,     1,\n            1,\
          \     1,     1,     1,     1,     1,     1,     1,     1,     1,\n     \
          \       1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n\
          \            1,     1,     1,     1,     1,     1,     1,     1,     1,\
          \     1,\n            1,     1,     1,     1,     1,     1,     1,     1,\
          \     1,     1,\n            1,     1,     1,     1,     1,     1,     1,\
          \     1,     1,     1,\n            1,     1,     1,     1,     1,     1,\
          \     1])\n\nIn [81]: np.array(roberta.encode(\"A dog\", padding=\"max_length\"\
          , max_length=77))\nOut[81]: \narray([    0,    62, 10269,     2,     1,\
          \     1,     1,     1,     1,\n           1,     1,     1,     1,     1,\
          \     1,     1,     1,     1,\n           1,     1,     1,     1,     1,\
          \     1,     1,     1,     1,\n           1,     1,     1,     1,     1,\
          \     1,     1,     1,     1,\n           1,     1,     1,     1,     1,\
          \     1,     1,     1,     1,\n           1,     1,     1,     1,     1,\
          \     1,     1,     1,     1,\n           1,     1,     1,     1,     1,\
          \     1,     1,     1,     1,\n           1,     1,     1,     1,     1,\
          \     1,     1,     1,     1,\n           1,     1,     1,     1,     1])\n\
          \n```"
        updatedAt: '2023-09-18T12:21:59.933Z'
      numEdits: 0
      reactions: []
      relatedEventId: 650840e7eac45ee2e43b3af6
    id: 650840e7eac45ee2e43b3af3
    type: comment
  author: versae
  content: "Oops, nevermind. The right model to use in OpenCLIP was `xlm-roberta-base-ViT-B-32`:\n\
    \n```python\nIn [79]: tokenizer = open_clip.get_tokenizer('xlm-roberta-base-ViT-B-32')\n\
    \nIn [80]: tokenizer(\"A dog\")[0]\nOut[80]: \ntensor([    0,    62, 10269,  \
    \   2,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,\
    \     1,     1,     1,     1,     1,     1,     1,\n            1,     1,    \
    \ 1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1, \
    \    1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,\
    \     1,     1,     1,     1,     1,     1,     1,     1,\n            1,    \
    \ 1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1, \
    \    1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,\
    \     1,     1,     1,     1,     1,     1])\n\nIn [81]: np.array(roberta.encode(\"\
    A dog\", padding=\"max_length\", max_length=77))\nOut[81]: \narray([    0,   \
    \ 62, 10269,     2,     1,     1,     1,     1,     1,\n           1,     1, \
    \    1,     1,     1,     1,     1,     1,     1,\n           1,     1,     1,\
    \     1,     1,     1,     1,     1,     1,\n           1,     1,     1,     1,\
    \     1,     1,     1,     1,     1,\n           1,     1,     1,     1,     1,\
    \     1,     1,     1,     1,\n           1,     1,     1,     1,     1,     1,\
    \     1,     1,     1,\n           1,     1,     1,     1,     1,     1,     1,\
    \     1,     1,\n           1,     1,     1,     1,     1,     1,     1,     1,\
    \     1,\n           1,     1,     1,     1,     1])\n\n```"
  created_at: 2023-09-18 11:21:59+00:00
  edited: false
  hidden: false
  id: 650840e7eac45ee2e43b3af3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593016943046-noauth.jpeg?w=200&h=200&f=face
      fullname: Javier de la Rosa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: versae
      type: user
    createdAt: '2023-09-18T12:21:59.000Z'
    data:
      status: closed
    id: 650840e7eac45ee2e43b3af6
    type: status-change
  author: versae
  created_at: 2023-09-18 11:21:59+00:00
  id: 650840e7eac45ee2e43b3af6
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: laion/CLIP-ViT-B-32-xlm-roberta-base-laion5B-s13B-b90k
repo_type: model
status: closed
target_branch: null
title: Is there a HF equivalent tokenizer?
