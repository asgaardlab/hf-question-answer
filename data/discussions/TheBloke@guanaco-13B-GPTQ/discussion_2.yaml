!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Nayyer
conflicting_files: null
created_at: 2024-01-11 14:51:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2a4ed66cd7fa8770eb3a8fefb14ff9da.svg
      fullname: Nayyer Shahzad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nayyer
      type: user
    createdAt: '2024-01-11T14:51:29.000Z'
    data:
      edited: false
      editors:
      - Nayyer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.273644357919693
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2a4ed66cd7fa8770eb3a8fefb14ff9da.svg
          fullname: Nayyer Shahzad
          isHf: false
          isPro: false
          name: Nayyer
          type: user
        html: '<p>18:42:18-071089 INFO     Loading TheBloke_guanaco-13B-GPTQ<br>18:42:18-073766
          ERROR    Failed to load the model.<br>Traceback (most recent call last):<br>  File
          "/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/ui_model_menu.py",
          line 213, in load_model_wrapper<br>    shared.model, shared.tokenizer =
          load_model(selected_model, loader)<br>                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/models.py",
          line 87, in load_model<br>    output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/models.py",
          line 366, in GPTQ_loader<br>    import modules.GPTQ_loader<br>  File "/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/GPTQ_loader.py",
          line 9, in <br>    from gptq_for_llama import llama_inference_offload<br>ModuleNotFoundError:
          No module named ''gptq_for_llama''</p>

          '
        raw: "18:42:18-071089 INFO     Loading TheBloke_guanaco-13B-GPTQ         \
          \                                                                      \
          \                         \r\n18:42:18-073766 ERROR    Failed to load the\
          \ model.                                                               \
          \                                                 \r\nTraceback (most recent\
          \ call last):\r\n  File \"/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/ui_model_menu.py\"\
          , line 213, in load_model_wrapper\r\n    shared.model, shared.tokenizer\
          \ = load_model(selected_model, loader)\r\n                             \
          \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/models.py\"\
          , line 87, in load_model\r\n    output = load_func_map[loader](model_name)\r\
          \n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/models.py\"\
          , line 366, in GPTQ_loader\r\n    import modules.GPTQ_loader\r\n  File \"\
          /Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/GPTQ_loader.py\"\
          , line 9, in <module>\r\n    from gptq_for_llama import llama_inference_offload\r\
          \nModuleNotFoundError: No module named 'gptq_for_llama'"
        updatedAt: '2024-01-11T14:51:29.072Z'
      numEdits: 0
      reactions: []
    id: 65a0007151e699b22a295f1e
    type: comment
  author: Nayyer
  content: "18:42:18-071089 INFO     Loading TheBloke_guanaco-13B-GPTQ           \
    \                                                                            \
    \                 \r\n18:42:18-073766 ERROR    Failed to load the model.     \
    \                                                                            \
    \                               \r\nTraceback (most recent call last):\r\n  File\
    \ \"/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/ui_model_menu.py\"\
    , line 213, in load_model_wrapper\r\n    shared.model, shared.tokenizer = load_model(selected_model,\
    \ loader)\r\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/models.py\"\
    , line 87, in load_model\r\n    output = load_func_map[loader](model_name)\r\n\
    \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/models.py\"\
    , line 366, in GPTQ_loader\r\n    import modules.GPTQ_loader\r\n  File \"/Users/nayyershahzad/PycharmProjects/textgenwebui/pythonProject/text-generation-webui/modules/GPTQ_loader.py\"\
    , line 9, in <module>\r\n    from gptq_for_llama import llama_inference_offload\r\
    \nModuleNotFoundError: No module named 'gptq_for_llama'"
  created_at: 2024-01-11 14:51:29+00:00
  edited: false
  hidden: false
  id: 65a0007151e699b22a295f1e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/guanaco-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: Not able to load the model. Getting following errors.
