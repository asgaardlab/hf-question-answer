!!python/object:huggingface_hub.community.DiscussionWithDetails
author: daxijiu
conflicting_files: null
created_at: 2023-08-22 02:49:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a7617a5457515045e920c2b1c8a6f782.svg
      fullname: zhangchi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: daxijiu
      type: user
    createdAt: '2023-08-22T03:49:31.000Z'
    data:
      edited: false
      editors:
      - daxijiu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9800114035606384
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a7617a5457515045e920c2b1c8a6f782.svg
          fullname: zhangchi
          isHf: false
          isPro: false
          name: daxijiu
          type: user
        html: '<p>as title<br>It doesn''t find anywhere how to train the refiner model.
          Maybe it should be trained in conjunction with the base model, and there
          are probably some tricks that need to be shared.</p>

          '
        raw: "as title\r\nIt doesn't find anywhere how to train the refiner model.\
          \ Maybe it should be trained in conjunction with the base model, and there\
          \ are probably some tricks that need to be shared."
        updatedAt: '2023-08-22T03:49:31.603Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - SLAPaper
        - wangxingjun778
    id: 64e4304b7e7b923a5358505e
    type: comment
  author: daxijiu
  content: "as title\r\nIt doesn't find anywhere how to train the refiner model. Maybe\
    \ it should be trained in conjunction with the base model, and there are probably\
    \ some tricks that need to be shared."
  created_at: 2023-08-22 02:49:31+00:00
  edited: false
  hidden: false
  id: 64e4304b7e7b923a5358505e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/79490cc54495ad8eee3530b204a4e490.svg
      fullname: Marc DeMory
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marcdemory
      type: user
    createdAt: '2023-09-02T18:23:21.000Z'
    data:
      edited: false
      editors:
      - marcdemory
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.864170491695404
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/79490cc54495ad8eee3530b204a4e490.svg
          fullname: Marc DeMory
          isHf: false
          isPro: false
          name: marcdemory
          type: user
        html: '<p>I am also interested in this. I can see from the documentation that
          the SDXL Img2Img pipeline linked below that the pipeline inherits the load_lora_weights
          method:<br><a href="https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLImg2ImgPipeline">https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLImg2ImgPipeline</a></p>

          <p>However, when I take LoRA weights that I got from Dreambooth LoRA training
          on the base SDXL, and try to use them in load_lora_weights on the SDXL Img2Img
          pipeline, I get an error.</p>

          <p>Additionally, if I train the text encoders when creating LoRA for base
          SDXL, if I pass those text encoders to SDXL Img2Img when creating it, should
          I expect that to have an effect?</p>

          '
        raw: 'I am also interested in this. I can see from the documentation that
          the SDXL Img2Img pipeline linked below that the pipeline inherits the load_lora_weights
          method:

          https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLImg2ImgPipeline


          However, when I take LoRA weights that I got from Dreambooth LoRA training
          on the base SDXL, and try to use them in load_lora_weights on the SDXL Img2Img
          pipeline, I get an error.


          Additionally, if I train the text encoders when creating LoRA for base SDXL,
          if I pass those text encoders to SDXL Img2Img when creating it, should I
          expect that to have an effect?'
        updatedAt: '2023-09-02T18:23:21.561Z'
      numEdits: 0
      reactions: []
    id: 64f37d99ff0d2e595c64da7e
    type: comment
  author: marcdemory
  content: 'I am also interested in this. I can see from the documentation that the
    SDXL Img2Img pipeline linked below that the pipeline inherits the load_lora_weights
    method:

    https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLImg2ImgPipeline


    However, when I take LoRA weights that I got from Dreambooth LoRA training on
    the base SDXL, and try to use them in load_lora_weights on the SDXL Img2Img pipeline,
    I get an error.


    Additionally, if I train the text encoders when creating LoRA for base SDXL, if
    I pass those text encoders to SDXL Img2Img when creating it, should I expect that
    to have an effect?'
  created_at: 2023-09-02 17:23:21+00:00
  edited: false
  hidden: false
  id: 64f37d99ff0d2e595c64da7e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2bdfc8c78faed7b0eda20885deb1aeb9.svg
      fullname: RobbyGordon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RobbyGordon56
      type: user
    createdAt: '2023-09-15T00:43:10.000Z'
    data:
      edited: false
      editors:
      - RobbyGordon56
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9722644686698914
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2bdfc8c78faed7b0eda20885deb1aeb9.svg
          fullname: RobbyGordon
          isHf: false
          isPro: false
          name: RobbyGordon56
          type: user
        html: '<p>Third nod here, if anyone has some information on refiner training
          please let us know. there is very little working information as it stands
          as people attempt using old v2.1 methods on XL - that do not work haha.
          Thanks!</p>

          '
        raw: 'Third nod here, if anyone has some information on refiner training please
          let us know. there is very little working information as it stands as people
          attempt using old v2.1 methods on XL - that do not work haha. Thanks!

          '
        updatedAt: '2023-09-15T00:43:10.657Z'
      numEdits: 0
      reactions: []
    id: 6503a89e694f6b620fcd217a
    type: comment
  author: RobbyGordon56
  content: 'Third nod here, if anyone has some information on refiner training please
    let us know. there is very little working information as it stands as people attempt
    using old v2.1 methods on XL - that do not work haha. Thanks!

    '
  created_at: 2023-09-14 23:43:10+00:00
  edited: false
  hidden: false
  id: 6503a89e694f6b620fcd217a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/79490cc54495ad8eee3530b204a4e490.svg
      fullname: Marc DeMory
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marcdemory
      type: user
    createdAt: '2023-09-15T01:47:35.000Z'
    data:
      edited: false
      editors:
      - marcdemory
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9154033064842224
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/79490cc54495ad8eee3530b204a4e490.svg
          fullname: Marc DeMory
          isHf: false
          isPro: false
          name: marcdemory
          type: user
        html: '<p>When you look into the SDXL training script, when you enable the
          text encoder training it trains both text encoders. </p>

          <p>The refiner uses the same model text encoders, so once you instantiate
          a pipeline for the base model, you can reference those same text encoders
          when instantiating the refiner pipeline. </p>

          <p>Does this have an effect? Not a great one. I have a Lora of myself -
          after passing the trained encoder to the refiner I feel like it still removes
          my identity because the UNET does not know me, but maybe slightly less so?
          </p>

          <p>I have not seen any additional information about fine-tuning the refiner
          yet either. </p>

          '
        raw: "When you look into the SDXL training script, when you enable the text\
          \ encoder training it trains both text encoders. \n\nThe refiner uses the\
          \ same model text encoders, so once you instantiate a pipeline for the base\
          \ model, you can reference those same text encoders when instantiating the\
          \ refiner pipeline. \n\nDoes this have an effect? Not a great one. I have\
          \ a Lora of myself - after passing the trained encoder to the refiner I\
          \ feel like it still removes my identity because the UNET does not know\
          \ me, but maybe slightly less so? \n\nI have not seen any additional information\
          \ about fine-tuning the refiner yet either. "
        updatedAt: '2023-09-15T01:47:35.536Z'
      numEdits: 0
      reactions: []
    id: 6503b7b724964747c8d1d084
    type: comment
  author: marcdemory
  content: "When you look into the SDXL training script, when you enable the text\
    \ encoder training it trains both text encoders. \n\nThe refiner uses the same\
    \ model text encoders, so once you instantiate a pipeline for the base model,\
    \ you can reference those same text encoders when instantiating the refiner pipeline.\
    \ \n\nDoes this have an effect? Not a great one. I have a Lora of myself - after\
    \ passing the trained encoder to the refiner I feel like it still removes my identity\
    \ because the UNET does not know me, but maybe slightly less so? \n\nI have not\
    \ seen any additional information about fine-tuning the refiner yet either. "
  created_at: 2023-09-15 00:47:35+00:00
  edited: false
  hidden: false
  id: 6503b7b724964747c8d1d084
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2bdfc8c78faed7b0eda20885deb1aeb9.svg
      fullname: RobbyGordon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RobbyGordon56
      type: user
    createdAt: '2023-09-15T19:10:15.000Z'
    data:
      edited: false
      editors:
      - RobbyGordon56
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9163488149642944
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2bdfc8c78faed7b0eda20885deb1aeb9.svg
          fullname: RobbyGordon
          isHf: false
          isPro: false
          name: RobbyGordon56
          type: user
        html: '<p>I''ve been fooling around and I think we need proper support for
          the refiners. </p>

          <p>The info from toolkit states they model components are: UNET-XL-Refiner,
          VAE-v1-SD, CLIP-XL-Refiner.</p>

          <p>I tried merging and blending but failed horribly. there is a mismatch
          error "The size of tensor a (384) must match the size of tensor b (320)
          at non-singleton dimension 0"  </p>

          <p>So unless someone figures out how to train them directly, the older stuff
          cannot match with the newer (probably because it''s 512 trained, not 1024
          base)</p>

          '
        raw: "I've been fooling around and I think we need proper support for the\
          \ refiners. \n\nThe info from toolkit states they model components are:\
          \ UNET-XL-Refiner, VAE-v1-SD, CLIP-XL-Refiner.\n\nI tried merging and blending\
          \ but failed horribly. there is a mismatch error \"The size of tensor a\
          \ (384) must match the size of tensor b (320) at non-singleton dimension\
          \ 0\"  \n\nSo unless someone figures out how to train them directly, the\
          \ older stuff cannot match with the newer (probably because it's 512 trained,\
          \ not 1024 base)\n\n"
        updatedAt: '2023-09-15T19:10:15.916Z'
      numEdits: 0
      reactions: []
    id: 6504ac17f92b9687cec81a13
    type: comment
  author: RobbyGordon56
  content: "I've been fooling around and I think we need proper support for the refiners.\
    \ \n\nThe info from toolkit states they model components are: UNET-XL-Refiner,\
    \ VAE-v1-SD, CLIP-XL-Refiner.\n\nI tried merging and blending but failed horribly.\
    \ there is a mismatch error \"The size of tensor a (384) must match the size of\
    \ tensor b (320) at non-singleton dimension 0\"  \n\nSo unless someone figures\
    \ out how to train them directly, the older stuff cannot match with the newer\
    \ (probably because it's 512 trained, not 1024 base)\n\n"
  created_at: 2023-09-15 18:10:15+00:00
  edited: false
  hidden: false
  id: 6504ac17f92b9687cec81a13
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/79490cc54495ad8eee3530b204a4e490.svg
      fullname: Marc DeMory
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marcdemory
      type: user
    createdAt: '2023-09-15T20:08:56.000Z'
    data:
      edited: false
      editors:
      - marcdemory
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9806826710700989
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/79490cc54495ad8eee3530b204a4e490.svg
          fullname: Marc DeMory
          isHf: false
          isPro: false
          name: marcdemory
          type: user
        html: '<p>Agreed. Only the UNET should need to be fine-tuned, and the trained
          text encoders can be reused from the base model. </p>

          <p>That being said, the refiner is made to be used in ensemble of expert
          denoisers - where I received an already partially denoised image and completes
          only the last 20% or so of denoising. </p>

          <p>I would imagine this would have to be replicated during training as well
          to get the best results. It sounds complicated, and probably the reason
          no one has a method to fine tune the refiner just yet. </p>

          '
        raw: "Agreed. Only the UNET should need to be fine-tuned, and the trained\
          \ text encoders can be reused from the base model. \n\nThat being said,\
          \ the refiner is made to be used in ensemble of expert denoisers - where\
          \ I received an already partially denoised image and completes only the\
          \ last 20% or so of denoising. \n\nI would imagine this would have to be\
          \ replicated during training as well to get the best results. It sounds\
          \ complicated, and probably the reason no one has a method to fine tune\
          \ the refiner just yet. "
        updatedAt: '2023-09-15T20:08:56.606Z'
      numEdits: 0
      reactions: []
    id: 6504b9d8d5578ef7e2ac3012
    type: comment
  author: marcdemory
  content: "Agreed. Only the UNET should need to be fine-tuned, and the trained text\
    \ encoders can be reused from the base model. \n\nThat being said, the refiner\
    \ is made to be used in ensemble of expert denoisers - where I received an already\
    \ partially denoised image and completes only the last 20% or so of denoising.\
    \ \n\nI would imagine this would have to be replicated during training as well\
    \ to get the best results. It sounds complicated, and probably the reason no one\
    \ has a method to fine tune the refiner just yet. "
  created_at: 2023-09-15 19:08:56+00:00
  edited: false
  hidden: false
  id: 6504b9d8d5578ef7e2ac3012
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8b1026db2af01c0098ad5c6e3b4597c2.svg
      fullname: Doe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: diegodoe
      type: user
    createdAt: '2023-12-26T20:54:05.000Z'
    data:
      edited: false
      editors:
      - diegodoe
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8404783606529236
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8b1026db2af01c0098ad5c6e3b4597c2.svg
          fullname: Doe
          isHf: false
          isPro: false
          name: diegodoe
          type: user
        html: '<p>The refiner model modules look quite similar to the base model.
          Would a tweak to the text_to_image_lora_sdxl.py script by removing the first
          text encoder module and changing the scheduler to only do 200 timesteps
          do something in this direction?</p>

          '
        raw: The refiner model modules look quite similar to the base model. Would
          a tweak to the text_to_image_lora_sdxl.py script by removing the first text
          encoder module and changing the scheduler to only do 200 timesteps do something
          in this direction?
        updatedAt: '2023-12-26T20:54:05.151Z'
      numEdits: 0
      reactions: []
    id: 658b3d6d4dd2ca8497c9479e
    type: comment
  author: diegodoe
  content: The refiner model modules look quite similar to the base model. Would a
    tweak to the text_to_image_lora_sdxl.py script by removing the first text encoder
    module and changing the scheduler to only do 200 timesteps do something in this
    direction?
  created_at: 2023-12-26 20:54:05+00:00
  edited: false
  hidden: false
  id: 658b3d6d4dd2ca8497c9479e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: stabilityai/stable-diffusion-xl-refiner-1.0
repo_type: model
status: open
target_branch: null
title: "how to finetune \u201Crefiner\u201D model, or training lora for \"refiener\"\
  ?"
