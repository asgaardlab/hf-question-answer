!!python/object:huggingface_hub.community.DiscussionWithDetails
author: maazmehmood22
conflicting_files: null
created_at: 2023-08-14 12:04:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2b119ee9fd5118678e5af6ae38884546.svg
      fullname: pierre
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: maazmehmood22
      type: user
    createdAt: '2023-08-14T13:04:58.000Z'
    data:
      edited: false
      editors:
      - maazmehmood22
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.44085317850112915
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2b119ee9fd5118678e5af6ae38884546.svg
          fullname: pierre
          isHf: false
          isPro: false
          name: maazmehmood22
          type: user
        html: "<p>Hello I get an error when I try to deploy this model to HF inference\
          \ endpoint, the GPU used was a NVIDIA A10G<br>here are the logs:</p>\n<pre><code>f69dd45546p69p\
          \ 2023-08-14T12:59:16.442Z  INFO | Ignore regex pattern for files, which\
          \ are not downloaded: tf*, flax*, rust*, *onnx, *safetensors, *mlmodel,\
          \ *tflite, *tar.gz, *ckpt\nf69dd45546p69p 2023-08-14T12:59:16.442Z  INFO\
          \ | Start loading image artifacts from huggingface.co\nf69dd45546p69p 2023-08-14T12:59:16.442Z\
          \  INFO | Used configuration:\nf69dd45546p69p 2023-08-14T12:59:16.442Z \
          \ INFO | Repository ID: stabilityai/stable-diffusion-xl-refiner-1.0\nf69dd45546p69p\
          \ 2023-08-14T12:59:16.442Z  INFO | Repository Revision: <a href=\"/stabilityai/stable-diffusion-xl-refiner-1.0/commit/93b080bbdc8efbeb862e29e15316cff53f9bef86\"\
          >93b080bbdc8efbeb862e29e15316cff53f9bef86</a>\nf69dd45546p69p 2023-08-14T12:59:22.261Z\
          \ 2023-08-14 12:59:22,261 | INFO | No custom pipeline found at /repository/handler.py\n\
          f69dd45546p69p 2023-08-14T12:59:22.261Z 2023-08-14 12:59:22,261 | INFO |\
          \ Using device GPU\nf69dd45546p69p 2023-08-14T12:59:22.261Z 2023-08-14 12:59:22,261\
          \ | INFO | Initializing model from directory:/repository\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.302Z \nLoading pipeline components...:   0%|     \
          \     | 0/5 [00:00&lt;?, ?it/s]\nLoading pipeline components...:  20%|\u2588\
          \u2588        | 1/5 [00:00&lt;00:00, 25.04it/s]\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \ Application startup failed. Exiting.\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     model_file = _get_model_file(\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     self.pipeline = get_pipeline(model_dir=model_dir, task=task)\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z     loaded_sub_model = load_sub_model(\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 682, in startup\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"\
          /opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line 584,\
          \ in __aenter__\nf69dd45546p69p 2023-08-14T12:59:22.305Z \nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z     self.pipeline = AutoPipelineForText2Image.from_pretrained(model_dir,\
          \ torch_dtype=dtype, device_map=device_map)\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     await self._router.startup()\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     raise EnvironmentError(\nf69dd45546p69p 2023-08-14T12:59:22.305Z \
          \  File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 468, in load_sub_model\nf69dd45546p69p 2023-08-14T12:59:22.305Z \
          \    hf_pipeline = get_diffusers_pipeline(task=task, model_dir=model_dir,\
          \ device=device, **kwargs)\nf69dd45546p69p 2023-08-14T12:59:22.305Z    \
          \ await handler()\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
          , line 26, in __init__\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"\
          /opt/conda/lib/python3.9/site-packages/diffusers/utils/hub_utils.py\", line\
          \ 275, in _get_model_file\nf69dd45546p69p 2023-08-14T12:59:22.305Z     pipeline\
          \ = DIFFUSERS_TASKS[task](model_dir=model_dir, device=device)\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z     loaded_sub_model = load_method(os.path.join(cached_folder,\
          \ name), **loading_kwargs)\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File\
          \ \"/app/webservice_starlette.py\", line 57, in some_startup_task\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z     return HuggingFaceHandler(model_dir=model_dir,\
          \ task=task)\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 45, in get_inference_handler_either_custom_or_default_handler\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 705, in lifespan\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File\
          \ \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
          , line 311, in from_pretrained\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     async with self.lifespan_context(app) as maybe_state:\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z Traceback (most recent call last):\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z OSError: Error no file named diffusion_pytorch_model.bin\
          \ found in directory /repository/vae.\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     return text_2_image_cls.from_pretrained(pretrained_model_or_path,\
          \ **kwargs)\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
          , line 62, in get_diffusers_pipeline\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
          , line 576, in from_pretrained\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \   File \"/app/huggingface_inference_toolkit/utils.py\", line 259, in get_pipeline\n\
          f69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 17, in __init__\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"\
          /opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 1069, in from_pretrained\nf69dd45546p69p 2023-08-14T12:59:25.306Z\
          \ 2023-08-14 12:59:25,306 | INFO | Initializing model from directory:/repository\n\
          f69dd45546p69p 2023-08-14T12:59:25.306Z 2023-08-14 12:59:25,306 | INFO |\
          \ No custom pipeline found at /repository/handler.py\nf69dd45546p69p 2023-08-14T12:59:25.306Z\
          \ 2023-08-14 12:59:25,306 | INFO | Using device GPU\nf69dd45546p69p 2023-08-14T12:59:25.307Z\
          \ \nLoading pipeline components...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\n\
          Loading pipeline components...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\n\
          f69dd45546p69p 2023-08-14T12:59:25.308Z     async with self.lifespan_context(app)\
          \ as maybe_state:\nf69dd45546p69p 2023-08-14T12:59:25.308Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 682, in startup\nf69dd45546p69p 2023-08-14T12:59:25.308Z Traceback\
          \ (most recent call last):\nf69dd45546p69p 2023-08-14T12:59:25.308Z   File\
          \ \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line\
          \ 705, in lifespan\nf69dd45546p69p 2023-08-14T12:59:25.308Z     return HuggingFaceHandler(model_dir=model_dir,\
          \ task=task)\nf69dd45546p69p 2023-08-14T12:59:25.308Z     inference_handler\
          \ = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\nf69dd45546p69p 2023-08-14T12:59:25.308Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 45, in get_inference_handler_either_custom_or_default_handler\nf69dd45546p69p\
          \ 2023-08-14T12:59:25.308Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 584, in __aenter__\nf69dd45546p69p 2023-08-14T12:59:25.308Z     await\
          \ self._router.startup()\nf69dd45546p69p 2023-08-14T12:59:25.308Z   File\
          \ \"/app/webservice_starlette.py\", line 57, in some_startup_task\nf69dd45546p69p\
          \ 2023-08-14T12:59:25.308Z     await handler()\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/utils/hub_utils.py\"\
          , line 275, in _get_model_file\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/app/huggingface_inference_toolkit/utils.py\", line 259, in get_pipeline\n\
          f69dd45546p69p 2023-08-14T12:59:25.309Z Application startup failed. Exiting.\n\
          f69dd45546p69p 2023-08-14T12:59:25.309Z     raise EnvironmentError(\nf69dd45546p69p\
          \ 2023-08-14T12:59:25.309Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
          , line 62, in get_diffusers_pipeline\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
          , line 576, in from_pretrained\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 1069, in from_pretrained\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/app/huggingface_inference_toolkit/handler.py\", line 17, in\
          \ __init__\nf69dd45546p69p 2023-08-14T12:59:25.309Z     pipeline = DIFFUSERS_TASKS[task](model_dir=model_dir,\
          \ device=device)\nf69dd45546p69p 2023-08-14T12:59:25.309Z     self.pipeline\
          \ = get_pipeline(model_dir=model_dir, task=task)\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \     model_file = _get_model_file(\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \     loaded_sub_model = load_sub_model(\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
          , line 311, in from_pretrained\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\", line\
          \ 26, in __init__\nf69dd45546p69p 2023-08-14T12:59:25.309Z \nf69dd45546p69p\
          \ 2023-08-14T12:59:25.309Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 468, in load_sub_model\nf69dd45546p69p 2023-08-14T12:59:25.309Z \
          \    return text_2_image_cls.from_pretrained(pretrained_model_or_path, **kwargs)\n\
          f69dd45546p69p 2023-08-14T12:59:25.309Z     self.pipeline = AutoPipelineForText2Image.from_pretrained(model_dir,\
          \ torch_dtype=dtype, device_map=device_map)\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \     loaded_sub_model = load_method(os.path.join(cached_folder, name),\
          \ **loading_kwargs)\nf69dd45546p69p 2023-08-14T12:59:25.309Z     hf_pipeline\
          \ = get_diffusers_pipeline(task=task, model_dir=model_dir, device=device,\
          \ **kwargs)\nf69dd45546p69p 2023-08-14T12:59:25.309Z OSError: Error no file\
          \ named diffusion_pytorch_model.bin found in directory /repository/unet.\n\
          f69dd45546p69p 2023-08-14T12:59:42.845Z 2023-08-14 12:59:42,845 | INFO |\
          \ Initializing model from directory:/repository\nf69dd45546p69p 2023-08-14T12:59:42.845Z\
          \ 2023-08-14 12:59:42,845 | INFO | No custom pipeline found at /repository/handler.py\n\
          f69dd45546p69p 2023-08-14T12:59:42.845Z 2023-08-14 12:59:42,845 | INFO |\
          \ Using device GPU\nf69dd45546p69p 2023-08-14T12:59:42.900Z \nLoading pipeline\
          \ components...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\nLoading pipeline\
          \ components...:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:00, 18.51it/s]\n\
          f69dd45546p69p 2023-08-14T12:59:42.902Z \nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
          , line 2474, in from_pretrained\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \     return text_2_image_cls.from_pretrained(pretrained_model_or_path,\
          \ **kwargs)\nf69dd45546p69p 2023-08-14T12:59:42.902Z     self.pipeline =\
          \ AutoPipelineForText2Image.from_pretrained(model_dir, torch_dtype=dtype,\
          \ device_map=device_map)\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File\
          \ \"/app/huggingface_inference_toolkit/diffusers_utils.py\", line 62, in\
          \ get_diffusers_pipeline\nf69dd45546p69p 2023-08-14T12:59:42.902Z     self.pipeline\
          \ = get_pipeline(model_dir=model_dir, task=task)\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \   File \"/app/webservice_starlette.py\", line 57, in some_startup_task\n\
          f69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 705, in lifespan\nf69dd45546p69p 2023-08-14T12:59:42.902Z     raise\
          \ EnvironmentError(\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
          , line 26, in __init__\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"\
          /app/huggingface_inference_toolkit/utils.py\", line 259, in get_pipeline\n\
          f69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 45, in get_inference_handler_either_custom_or_default_handler\nf69dd45546p69p\
          \ 2023-08-14T12:59:42.902Z     await handler()\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \ Traceback (most recent call last):\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 1069, in from_pretrained\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
          , line 311, in from_pretrained\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \     pipeline = DIFFUSERS_TASKS[task](model_dir=model_dir, device=device)\n\
          f69dd45546p69p 2023-08-14T12:59:42.902Z     hf_pipeline = get_diffusers_pipeline(task=task,\
          \ model_dir=model_dir, device=device, **kwargs)\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \     return HuggingFaceHandler(model_dir=model_dir, task=task)\nf69dd45546p69p\
          \ 2023-08-14T12:59:42.902Z     inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\nf69dd45546p69p 2023-08-14T12:59:42.902Z     await self._router.startup()\n\
          f69dd45546p69p 2023-08-14T12:59:42.902Z OSError: Error no file named pytorch_model.bin,\
          \ tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory\
          \ /repository/text_encoder_2.\nf69dd45546p69p 2023-08-14T12:59:42.902Z \
          \    loaded_sub_model = load_method(os.path.join(cached_folder, name), **loading_kwargs)\n\
          f69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 468, in load_sub_model\nf69dd45546p69p 2023-08-14T12:59:42.902Z \
          \    loaded_sub_model = load_sub_model(\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \   File \"/app/huggingface_inference_toolkit/handler.py\", line 17, in\
          \ __init__\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 682, in startup\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"\
          /opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line 584,\
          \ in __aenter__\nf69dd45546p69p 2023-08-14T12:59:42.902Z     async with\
          \ self.lifespan_context(app) as maybe_state:\nf69dd45546p69p 2023-08-14T12:59:42.905Z\
          \ Application startup failed. Exiting.\nf69dd45546p69p 2023-08-14T13:00:09.893Z\
          \ 2023-08-14 13:00:09,893 | INFO | No custom pipeline found at /repository/handler.py\n\
          f69dd45546p69p 2023-08-14T13:00:09.893Z 2023-08-14 13:00:09,893 | INFO |\
          \ Initializing model from directory:/repository\nf69dd45546p69p 2023-08-14T13:00:09.893Z\
          \ 2023-08-14 13:00:09,893 | INFO | Using device GPU\nf69dd45546p69p 2023-08-14T13:00:09.944Z\
          \ \nLoading pipeline components...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\n\
          Loading pipeline components...:  20%|\u2588\u2588        | 1/5 [00:00&lt;00:00,\
          \ 20.27it/s]\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 468, in load_sub_model\nf69dd45546p69p 2023-08-14T13:00:09.945Z \
          \    loaded_sub_model = load_sub_model(\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
          , line 311, in from_pretrained\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\", line\
          \ 62, in get_diffusers_pipeline\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     hf_pipeline = get_diffusers_pipeline(task=task, model_dir=model_dir,\
          \ device=device, **kwargs)\nf69dd45546p69p 2023-08-14T13:00:09.945Z    \
          \ inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\nf69dd45546p69p 2023-08-14T13:00:09.945Z     await self._router.startup()\n\
          f69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/utils/hub_utils.py\"\
          , line 275, in _get_model_file\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
          , line 576, in from_pretrained\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     return text_2_image_cls.from_pretrained(pretrained_model_or_path,\
          \ **kwargs)\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/app/huggingface_inference_toolkit/utils.py\"\
          , line 259, in get_pipeline\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File\
          \ \"/app/huggingface_inference_toolkit/handler.py\", line 17, in __init__\n\
          f69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 45, in get_inference_handler_either_custom_or_default_handler\nf69dd45546p69p\
          \ 2023-08-14T13:00:09.945Z     async with self.lifespan_context(app) as\
          \ maybe_state:\nf69dd45546p69p 2023-08-14T13:00:09.945Z     model_file =\
          \ _get_model_file(\nf69dd45546p69p 2023-08-14T13:00:09.945Z     loaded_sub_model\
          \ = load_method(os.path.join(cached_folder, name), **loading_kwargs)\nf69dd45546p69p\
          \ 2023-08-14T13:00:09.945Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
          , line 26, in __init__\nf69dd45546p69p 2023-08-14T13:00:09.945Z     pipeline\
          \ = DIFFUSERS_TASKS[task](model_dir=model_dir, device=device)\nf69dd45546p69p\
          \ 2023-08-14T13:00:09.945Z     self.pipeline = get_pipeline(model_dir=model_dir,\
          \ task=task)\nf69dd45546p69p 2023-08-14T13:00:09.945Z     await handler()\n\
          f69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 682, in startup\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"\
          /opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line 584,\
          \ in __aenter__\nf69dd45546p69p 2023-08-14T13:00:09.945Z Traceback (most\
          \ recent call last):\nf69dd45546p69p 2023-08-14T13:00:09.945Z \nf69dd45546p69p\
          \ 2023-08-14T13:00:09.945Z OSError: Error no file named diffusion_pytorch_model.bin\
          \ found in directory /repository/vae.\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     raise EnvironmentError(\nf69dd45546p69p 2023-08-14T13:00:09.945Z \
          \  File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 1069, in from_pretrained\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     self.pipeline = AutoPipelineForText2Image.from_pretrained(model_dir,\
          \ torch_dtype=dtype, device_map=device_map)\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     return HuggingFaceHandler(model_dir=model_dir, task=task)\nf69dd45546p69p\
          \ 2023-08-14T13:00:09.945Z   File \"/app/webservice_starlette.py\", line\
          \ 57, in some_startup_task\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File\
          \ \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line\
          \ 705, in lifespan\nf69dd45546p69p 2023-08-14T13:00:09.948Z Application\
          \ startup failed. Exiting.\n</code></pre>\n"
        raw: "Hello I get an error when I try to deploy this model to HF inference\
          \ endpoint, the GPU used was a NVIDIA A10G\r\nhere are the logs:\r\n```\r\
          \nf69dd45546p69p 2023-08-14T12:59:16.442Z  INFO | Ignore regex pattern for\
          \ files, which are not downloaded: tf*, flax*, rust*, *onnx, *safetensors,\
          \ *mlmodel, *tflite, *tar.gz, *ckpt\r\nf69dd45546p69p 2023-08-14T12:59:16.442Z\
          \  INFO | Start loading image artifacts from huggingface.co\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:16.442Z  INFO | Used configuration:\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:16.442Z  INFO | Repository ID: stabilityai/stable-diffusion-xl-refiner-1.0\r\
          \nf69dd45546p69p 2023-08-14T12:59:16.442Z  INFO | Repository Revision: 93b080bbdc8efbeb862e29e15316cff53f9bef86\r\
          \nf69dd45546p69p 2023-08-14T12:59:22.261Z 2023-08-14 12:59:22,261 | INFO\
          \ | No custom pipeline found at /repository/handler.py\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.261Z 2023-08-14 12:59:22,261 | INFO | Using device\
          \ GPU\r\nf69dd45546p69p 2023-08-14T12:59:22.261Z 2023-08-14 12:59:22,261\
          \ | INFO | Initializing model from directory:/repository\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.302Z \r\nLoading pipeline components...:   0%|   \
          \       | 0/5 [00:00<?, ?it/s]\r\nLoading pipeline components...:  20%|\u2588\
          \u2588        | 1/5 [00:00<00:00, 25.04it/s]\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \ Application startup failed. Exiting.\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     model_file = _get_model_file(\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     self.pipeline = get_pipeline(model_dir=model_dir, task=task)\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z     loaded_sub_model = load_sub_model(\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 682, in startup\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File\
          \ \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line\
          \ 584, in __aenter__\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z \r\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z     self.pipeline = AutoPipelineForText2Image.from_pretrained(model_dir,\
          \ torch_dtype=dtype, device_map=device_map)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     await self._router.startup()\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     raise EnvironmentError(\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 468, in load_sub_model\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     hf_pipeline = get_diffusers_pipeline(task=task, model_dir=model_dir,\
          \ device=device, **kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z  \
          \   await handler()\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"\
          /app/huggingface_inference_toolkit/diffusers_utils.py\", line 26, in __init__\r\
          \nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/utils/hub_utils.py\"\
          , line 275, in _get_model_file\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     pipeline = DIFFUSERS_TASKS[task](model_dir=model_dir, device=device)\r\
          \nf69dd45546p69p 2023-08-14T12:59:22.305Z     loaded_sub_model = load_method(os.path.join(cached_folder,\
          \ name), **loading_kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z  \
          \ File \"/app/webservice_starlette.py\", line 57, in some_startup_task\r\
          \nf69dd45546p69p 2023-08-14T12:59:22.305Z     return HuggingFaceHandler(model_dir=model_dir,\
          \ task=task)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 45, in get_inference_handler_either_custom_or_default_handler\r\n\
          f69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 705, in lifespan\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File\
          \ \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
          , line 311, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     async with self.lifespan_context(app) as maybe_state:\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z Traceback (most recent call last):\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:22.305Z OSError: Error no file named diffusion_pytorch_model.bin\
          \ found in directory /repository/vae.\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     return text_2_image_cls.from_pretrained(pretrained_model_or_path,\
          \ **kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
          , line 62, in get_diffusers_pipeline\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \     inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
          , line 576, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
          \   File \"/app/huggingface_inference_toolkit/utils.py\", line 259, in get_pipeline\r\
          \nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 17, in __init__\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File\
          \ \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 1069, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:25.306Z\
          \ 2023-08-14 12:59:25,306 | INFO | Initializing model from directory:/repository\r\
          \nf69dd45546p69p 2023-08-14T12:59:25.306Z 2023-08-14 12:59:25,306 | INFO\
          \ | No custom pipeline found at /repository/handler.py\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:25.306Z 2023-08-14 12:59:25,306 | INFO | Using device\
          \ GPU\r\nf69dd45546p69p 2023-08-14T12:59:25.307Z \r\nLoading pipeline components...:\
          \   0%|          | 0/5 [00:00<?, ?it/s]\r\nLoading pipeline components...:\
          \   0%|          | 0/5 [00:00<?, ?it/s]\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z\
          \     async with self.lifespan_context(app) as maybe_state:\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:25.308Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 682, in startup\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z Traceback\
          \ (most recent call last):\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z  \
          \ File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\",\
          \ line 705, in lifespan\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z     return\
          \ HuggingFaceHandler(model_dir=model_dir, task=task)\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z\
          \     inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 45, in get_inference_handler_either_custom_or_default_handler\r\n\
          f69dd45546p69p 2023-08-14T12:59:25.308Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 584, in __aenter__\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z   \
          \  await self._router.startup()\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z\
          \   File \"/app/webservice_starlette.py\", line 57, in some_startup_task\r\
          \nf69dd45546p69p 2023-08-14T12:59:25.308Z     await handler()\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:25.309Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/utils/hub_utils.py\"\
          , line 275, in _get_model_file\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/app/huggingface_inference_toolkit/utils.py\", line 259, in get_pipeline\r\
          \nf69dd45546p69p 2023-08-14T12:59:25.309Z Application startup failed. Exiting.\r\
          \nf69dd45546p69p 2023-08-14T12:59:25.309Z     raise EnvironmentError(\r\n\
          f69dd45546p69p 2023-08-14T12:59:25.309Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
          , line 62, in get_diffusers_pipeline\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
          , line 576, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 1069, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/app/huggingface_inference_toolkit/handler.py\", line 17, in\
          \ __init__\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z     pipeline = DIFFUSERS_TASKS[task](model_dir=model_dir,\
          \ device=device)\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z     self.pipeline\
          \ = get_pipeline(model_dir=model_dir, task=task)\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \     model_file = _get_model_file(\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \     loaded_sub_model = load_sub_model(\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
          , line 311, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\", line\
          \ 26, in __init__\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z \r\nf69dd45546p69p\
          \ 2023-08-14T12:59:25.309Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 468, in load_sub_model\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \     return text_2_image_cls.from_pretrained(pretrained_model_or_path,\
          \ **kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z     self.pipeline\
          \ = AutoPipelineForText2Image.from_pretrained(model_dir, torch_dtype=dtype,\
          \ device_map=device_map)\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z    \
          \ loaded_sub_model = load_method(os.path.join(cached_folder, name), **loading_kwargs)\r\
          \nf69dd45546p69p 2023-08-14T12:59:25.309Z     hf_pipeline = get_diffusers_pipeline(task=task,\
          \ model_dir=model_dir, device=device, **kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
          \ OSError: Error no file named diffusion_pytorch_model.bin found in directory\
          \ /repository/unet.\r\nf69dd45546p69p 2023-08-14T12:59:42.845Z 2023-08-14\
          \ 12:59:42,845 | INFO | Initializing model from directory:/repository\r\n\
          f69dd45546p69p 2023-08-14T12:59:42.845Z 2023-08-14 12:59:42,845 | INFO |\
          \ No custom pipeline found at /repository/handler.py\r\nf69dd45546p69p 2023-08-14T12:59:42.845Z\
          \ 2023-08-14 12:59:42,845 | INFO | Using device GPU\r\nf69dd45546p69p 2023-08-14T12:59:42.900Z\
          \ \r\nLoading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]\r\
          \nLoading pipeline components...:  20%|\u2588\u2588        | 1/5 [00:00<00:00,\
          \ 18.51it/s]\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z \r\nf69dd45546p69p\
          \ 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
          , line 2474, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \     return text_2_image_cls.from_pretrained(pretrained_model_or_path,\
          \ **kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z     self.pipeline\
          \ = AutoPipelineForText2Image.from_pretrained(model_dir, torch_dtype=dtype,\
          \ device_map=device_map)\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File\
          \ \"/app/huggingface_inference_toolkit/diffusers_utils.py\", line 62, in\
          \ get_diffusers_pipeline\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z    \
          \ self.pipeline = get_pipeline(model_dir=model_dir, task=task)\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:42.902Z   File \"/app/webservice_starlette.py\", line\
          \ 57, in some_startup_task\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z  \
          \ File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\",\
          \ line 705, in lifespan\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z     raise\
          \ EnvironmentError(\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"\
          /app/huggingface_inference_toolkit/diffusers_utils.py\", line 26, in __init__\r\
          \nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/app/huggingface_inference_toolkit/utils.py\"\
          , line 259, in get_pipeline\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z \
          \  File \"/app/huggingface_inference_toolkit/handler.py\", line 45, in get_inference_handler_either_custom_or_default_handler\r\
          \nf69dd45546p69p 2023-08-14T12:59:42.902Z     await handler()\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:42.902Z Traceback (most recent call last):\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 1069, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
          , line 311, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \     pipeline = DIFFUSERS_TASKS[task](model_dir=model_dir, device=device)\r\
          \nf69dd45546p69p 2023-08-14T12:59:42.902Z     hf_pipeline = get_diffusers_pipeline(task=task,\
          \ model_dir=model_dir, device=device, **kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \     return HuggingFaceHandler(model_dir=model_dir, task=task)\r\nf69dd45546p69p\
          \ 2023-08-14T12:59:42.902Z     inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z     await self._router.startup()\r\
          \nf69dd45546p69p 2023-08-14T12:59:42.902Z OSError: Error no file named pytorch_model.bin,\
          \ tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory\
          \ /repository/text_encoder_2.\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \     loaded_sub_model = load_method(os.path.join(cached_folder, name),\
          \ **loading_kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"\
          /opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 468, in load_sub_model\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \     loaded_sub_model = load_sub_model(\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
          \   File \"/app/huggingface_inference_toolkit/handler.py\", line 17, in\
          \ __init__\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 682, in startup\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File\
          \ \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line\
          \ 584, in __aenter__\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z     async\
          \ with self.lifespan_context(app) as maybe_state:\r\nf69dd45546p69p 2023-08-14T12:59:42.905Z\
          \ Application startup failed. Exiting.\r\nf69dd45546p69p 2023-08-14T13:00:09.893Z\
          \ 2023-08-14 13:00:09,893 | INFO | No custom pipeline found at /repository/handler.py\r\
          \nf69dd45546p69p 2023-08-14T13:00:09.893Z 2023-08-14 13:00:09,893 | INFO\
          \ | Initializing model from directory:/repository\r\nf69dd45546p69p 2023-08-14T13:00:09.893Z\
          \ 2023-08-14 13:00:09,893 | INFO | Using device GPU\r\nf69dd45546p69p 2023-08-14T13:00:09.944Z\
          \ \r\nLoading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]\r\
          \nLoading pipeline components...:  20%|\u2588\u2588        | 1/5 [00:00<00:00,\
          \ 20.27it/s]\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 468, in load_sub_model\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     loaded_sub_model = load_sub_model(\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
          , line 311, in from_pretrained\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\", line\
          \ 62, in get_diffusers_pipeline\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     hf_pipeline = get_diffusers_pipeline(task=task, model_dir=model_dir,\
          \ device=device, **kwargs)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z  \
          \   inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z     await self._router.startup()\r\
          \nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/utils/hub_utils.py\"\
          , line 275, in _get_model_file\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
          , line 576, in from_pretrained\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     return text_2_image_cls.from_pretrained(pretrained_model_or_path,\
          \ **kwargs)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/app/huggingface_inference_toolkit/utils.py\"\
          , line 259, in get_pipeline\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z \
          \  File \"/app/huggingface_inference_toolkit/handler.py\", line 17, in __init__\r\
          \nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 45, in get_inference_handler_either_custom_or_default_handler\r\n\
          f69dd45546p69p 2023-08-14T13:00:09.945Z     async with self.lifespan_context(app)\
          \ as maybe_state:\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z     model_file\
          \ = _get_model_file(\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z     loaded_sub_model\
          \ = load_method(os.path.join(cached_folder, name), **loading_kwargs)\r\n\
          f69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
          , line 26, in __init__\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z     pipeline\
          \ = DIFFUSERS_TASKS[task](model_dir=model_dir, device=device)\r\nf69dd45546p69p\
          \ 2023-08-14T13:00:09.945Z     self.pipeline = get_pipeline(model_dir=model_dir,\
          \ task=task)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z     await handler()\r\
          \nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 682, in startup\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File\
          \ \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line\
          \ 584, in __aenter__\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z Traceback\
          \ (most recent call last):\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z \r\
          \nf69dd45546p69p 2023-08-14T13:00:09.945Z OSError: Error no file named diffusion_pytorch_model.bin\
          \ found in directory /repository/vae.\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     raise EnvironmentError(\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
          , line 1069, in from_pretrained\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     self.pipeline = AutoPipelineForText2Image.from_pretrained(model_dir,\
          \ torch_dtype=dtype, device_map=device_map)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
          \     return HuggingFaceHandler(model_dir=model_dir, task=task)\r\nf69dd45546p69p\
          \ 2023-08-14T13:00:09.945Z   File \"/app/webservice_starlette.py\", line\
          \ 57, in some_startup_task\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z  \
          \ File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\",\
          \ line 705, in lifespan\r\nf69dd45546p69p 2023-08-14T13:00:09.948Z Application\
          \ startup failed. Exiting.\r\n```"
        updatedAt: '2023-08-14T13:04:58.381Z'
      numEdits: 0
      reactions: []
    id: 64da267a3764a5137e516aa8
    type: comment
  author: maazmehmood22
  content: "Hello I get an error when I try to deploy this model to HF inference endpoint,\
    \ the GPU used was a NVIDIA A10G\r\nhere are the logs:\r\n```\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:16.442Z  INFO | Ignore regex pattern for files, which are not\
    \ downloaded: tf*, flax*, rust*, *onnx, *safetensors, *mlmodel, *tflite, *tar.gz,\
    \ *ckpt\r\nf69dd45546p69p 2023-08-14T12:59:16.442Z  INFO | Start loading image\
    \ artifacts from huggingface.co\r\nf69dd45546p69p 2023-08-14T12:59:16.442Z  INFO\
    \ | Used configuration:\r\nf69dd45546p69p 2023-08-14T12:59:16.442Z  INFO | Repository\
    \ ID: stabilityai/stable-diffusion-xl-refiner-1.0\r\nf69dd45546p69p 2023-08-14T12:59:16.442Z\
    \  INFO | Repository Revision: 93b080bbdc8efbeb862e29e15316cff53f9bef86\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:22.261Z 2023-08-14 12:59:22,261 | INFO | No custom pipeline\
    \ found at /repository/handler.py\r\nf69dd45546p69p 2023-08-14T12:59:22.261Z 2023-08-14\
    \ 12:59:22,261 | INFO | Using device GPU\r\nf69dd45546p69p 2023-08-14T12:59:22.261Z\
    \ 2023-08-14 12:59:22,261 | INFO | Initializing model from directory:/repository\r\
    \nf69dd45546p69p 2023-08-14T12:59:22.302Z \r\nLoading pipeline components...:\
    \   0%|          | 0/5 [00:00<?, ?it/s]\r\nLoading pipeline components...:  20%|\u2588\
    \u2588        | 1/5 [00:00<00:00, 25.04it/s]\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
    \ Application startup failed. Exiting.\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
    \     model_file = _get_model_file(\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
    \     self.pipeline = get_pipeline(model_dir=model_dir, task=task)\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:22.305Z     loaded_sub_model = load_sub_model(\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 682, in startup\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 584, in __aenter__\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z \r\nf69dd45546p69p\
    \ 2023-08-14T12:59:22.305Z     self.pipeline = AutoPipelineForText2Image.from_pretrained(model_dir,\
    \ torch_dtype=dtype, device_map=device_map)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
    \     await self._router.startup()\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
    \     raise EnvironmentError(\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File\
    \ \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
    , line 468, in load_sub_model\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z     hf_pipeline\
    \ = get_diffusers_pipeline(task=task, model_dir=model_dir, device=device, **kwargs)\r\
    \nf69dd45546p69p 2023-08-14T12:59:22.305Z     await handler()\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
    , line 26, in __init__\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/utils/hub_utils.py\"\
    , line 275, in _get_model_file\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z    \
    \ pipeline = DIFFUSERS_TASKS[task](model_dir=model_dir, device=device)\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:22.305Z     loaded_sub_model = load_method(os.path.join(cached_folder,\
    \ name), **loading_kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"\
    /app/webservice_starlette.py\", line 57, in some_startup_task\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:22.305Z     return HuggingFaceHandler(model_dir=model_dir,\
    \ task=task)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 45, in get_inference_handler_either_custom_or_default_handler\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 705, in lifespan\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
    , line 311, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z    \
    \ async with self.lifespan_context(app) as maybe_state:\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
    \ Traceback (most recent call last):\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
    \ OSError: Error no file named diffusion_pytorch_model.bin found in directory\
    \ /repository/vae.\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z     return text_2_image_cls.from_pretrained(pretrained_model_or_path,\
    \ **kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
    , line 62, in get_diffusers_pipeline\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z\
    \     inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
    \ task=HF_TASK)\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
    , line 576, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File\
    \ \"/app/huggingface_inference_toolkit/utils.py\", line 259, in get_pipeline\r\
    \nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 17, in __init__\r\nf69dd45546p69p 2023-08-14T12:59:22.305Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
    , line 1069, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:25.306Z 2023-08-14\
    \ 12:59:25,306 | INFO | Initializing model from directory:/repository\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:25.306Z 2023-08-14 12:59:25,306 | INFO | No custom pipeline\
    \ found at /repository/handler.py\r\nf69dd45546p69p 2023-08-14T12:59:25.306Z 2023-08-14\
    \ 12:59:25,306 | INFO | Using device GPU\r\nf69dd45546p69p 2023-08-14T12:59:25.307Z\
    \ \r\nLoading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]\r\n\
    Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:25.308Z     async with self.lifespan_context(app) as maybe_state:\r\
    \nf69dd45546p69p 2023-08-14T12:59:25.308Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 682, in startup\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z Traceback (most\
    \ recent call last):\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 705, in lifespan\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z     return\
    \ HuggingFaceHandler(model_dir=model_dir, task=task)\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z\
    \     inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
    \ task=HF_TASK)\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 45, in get_inference_handler_either_custom_or_default_handler\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:25.308Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 584, in __aenter__\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z     await\
    \ self._router.startup()\r\nf69dd45546p69p 2023-08-14T12:59:25.308Z   File \"\
    /app/webservice_starlette.py\", line 57, in some_startup_task\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:25.308Z     await handler()\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
    \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/utils/hub_utils.py\"\
    , line 275, in _get_model_file\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z   File\
    \ \"/app/huggingface_inference_toolkit/utils.py\", line 259, in get_pipeline\r\
    \nf69dd45546p69p 2023-08-14T12:59:25.309Z Application startup failed. Exiting.\r\
    \nf69dd45546p69p 2023-08-14T12:59:25.309Z     raise EnvironmentError(\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:25.309Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
    , line 62, in get_diffusers_pipeline\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
    \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
    , line 576, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z   File\
    \ \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
    , line 1069, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z   File\
    \ \"/app/huggingface_inference_toolkit/handler.py\", line 17, in __init__\r\n\
    f69dd45546p69p 2023-08-14T12:59:25.309Z     pipeline = DIFFUSERS_TASKS[task](model_dir=model_dir,\
    \ device=device)\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z     self.pipeline\
    \ = get_pipeline(model_dir=model_dir, task=task)\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
    \     model_file = _get_model_file(\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
    \     loaded_sub_model = load_sub_model(\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
    \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
    , line 311, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z   File\
    \ \"/app/huggingface_inference_toolkit/diffusers_utils.py\", line 26, in __init__\r\
    \nf69dd45546p69p 2023-08-14T12:59:25.309Z \r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
    \   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
    , line 468, in load_sub_model\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z     return\
    \ text_2_image_cls.from_pretrained(pretrained_model_or_path, **kwargs)\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:25.309Z     self.pipeline = AutoPipelineForText2Image.from_pretrained(model_dir,\
    \ torch_dtype=dtype, device_map=device_map)\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
    \     loaded_sub_model = load_method(os.path.join(cached_folder, name), **loading_kwargs)\r\
    \nf69dd45546p69p 2023-08-14T12:59:25.309Z     hf_pipeline = get_diffusers_pipeline(task=task,\
    \ model_dir=model_dir, device=device, **kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:25.309Z\
    \ OSError: Error no file named diffusion_pytorch_model.bin found in directory\
    \ /repository/unet.\r\nf69dd45546p69p 2023-08-14T12:59:42.845Z 2023-08-14 12:59:42,845\
    \ | INFO | Initializing model from directory:/repository\r\nf69dd45546p69p 2023-08-14T12:59:42.845Z\
    \ 2023-08-14 12:59:42,845 | INFO | No custom pipeline found at /repository/handler.py\r\
    \nf69dd45546p69p 2023-08-14T12:59:42.845Z 2023-08-14 12:59:42,845 | INFO | Using\
    \ device GPU\r\nf69dd45546p69p 2023-08-14T12:59:42.900Z \r\nLoading pipeline components...:\
    \   0%|          | 0/5 [00:00<?, ?it/s]\r\nLoading pipeline components...:  20%|\u2588\
    \u2588        | 1/5 [00:00<00:00, 18.51it/s]\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
    \ \r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
    , line 2474, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   \
    \  return text_2_image_cls.from_pretrained(pretrained_model_or_path, **kwargs)\r\
    \nf69dd45546p69p 2023-08-14T12:59:42.902Z     self.pipeline = AutoPipelineForText2Image.from_pretrained(model_dir,\
    \ torch_dtype=dtype, device_map=device_map)\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
    \   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\", line 62, in\
    \ get_diffusers_pipeline\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z     self.pipeline\
    \ = get_pipeline(model_dir=model_dir, task=task)\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
    \   File \"/app/webservice_starlette.py\", line 57, in some_startup_task\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 705, in lifespan\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z     raise EnvironmentError(\r\
    \nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/app/huggingface_inference_toolkit/diffusers_utils.py\"\
    , line 26, in __init__\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/app/huggingface_inference_toolkit/utils.py\"\
    , line 259, in get_pipeline\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File\
    \ \"/app/huggingface_inference_toolkit/handler.py\", line 45, in get_inference_handler_either_custom_or_default_handler\r\
    \nf69dd45546p69p 2023-08-14T12:59:42.902Z     await handler()\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:42.902Z Traceback (most recent call last):\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
    , line 1069, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File\
    \ \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
    , line 311, in from_pretrained\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z    \
    \ pipeline = DIFFUSERS_TASKS[task](model_dir=model_dir, device=device)\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:42.902Z     hf_pipeline = get_diffusers_pipeline(task=task,\
    \ model_dir=model_dir, device=device, **kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z\
    \     return HuggingFaceHandler(model_dir=model_dir, task=task)\r\nf69dd45546p69p\
    \ 2023-08-14T12:59:42.902Z     inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
    \ task=HF_TASK)\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z     await self._router.startup()\r\
    \nf69dd45546p69p 2023-08-14T12:59:42.902Z OSError: Error no file named pytorch_model.bin,\
    \ tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /repository/text_encoder_2.\r\
    \nf69dd45546p69p 2023-08-14T12:59:42.902Z     loaded_sub_model = load_method(os.path.join(cached_folder,\
    \ name), **loading_kwargs)\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"\
    /opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
    , line 468, in load_sub_model\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z     loaded_sub_model\
    \ = load_sub_model(\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 17, in __init__\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 682, in startup\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 584, in __aenter__\r\nf69dd45546p69p 2023-08-14T12:59:42.902Z     async\
    \ with self.lifespan_context(app) as maybe_state:\r\nf69dd45546p69p 2023-08-14T12:59:42.905Z\
    \ Application startup failed. Exiting.\r\nf69dd45546p69p 2023-08-14T13:00:09.893Z\
    \ 2023-08-14 13:00:09,893 | INFO | No custom pipeline found at /repository/handler.py\r\
    \nf69dd45546p69p 2023-08-14T13:00:09.893Z 2023-08-14 13:00:09,893 | INFO | Initializing\
    \ model from directory:/repository\r\nf69dd45546p69p 2023-08-14T13:00:09.893Z\
    \ 2023-08-14 13:00:09,893 | INFO | Using device GPU\r\nf69dd45546p69p 2023-08-14T13:00:09.944Z\
    \ \r\nLoading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]\r\n\
    Loading pipeline components...:  20%|\u2588\u2588        | 1/5 [00:00<00:00, 20.27it/s]\r\
    \nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
    , line 468, in load_sub_model\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z     loaded_sub_model\
    \ = load_sub_model(\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/auto_pipeline.py\"\
    , line 311, in from_pretrained\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File\
    \ \"/app/huggingface_inference_toolkit/diffusers_utils.py\", line 62, in get_diffusers_pipeline\r\
    \nf69dd45546p69p 2023-08-14T13:00:09.945Z     hf_pipeline = get_diffusers_pipeline(task=task,\
    \ model_dir=model_dir, device=device, **kwargs)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
    \     inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
    \ task=HF_TASK)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z     await self._router.startup()\r\
    \nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/diffusers/utils/hub_utils.py\"\
    , line 275, in _get_model_file\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File\
    \ \"/opt/conda/lib/python3.9/site-packages/diffusers/models/modeling_utils.py\"\
    , line 576, in from_pretrained\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z    \
    \ return text_2_image_cls.from_pretrained(pretrained_model_or_path, **kwargs)\r\
    \nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/app/huggingface_inference_toolkit/utils.py\"\
    , line 259, in get_pipeline\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File\
    \ \"/app/huggingface_inference_toolkit/handler.py\", line 17, in __init__\r\n\
    f69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 45, in get_inference_handler_either_custom_or_default_handler\r\nf69dd45546p69p\
    \ 2023-08-14T13:00:09.945Z     async with self.lifespan_context(app) as maybe_state:\r\
    \nf69dd45546p69p 2023-08-14T13:00:09.945Z     model_file = _get_model_file(\r\n\
    f69dd45546p69p 2023-08-14T13:00:09.945Z     loaded_sub_model = load_method(os.path.join(cached_folder,\
    \ name), **loading_kwargs)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"\
    /app/huggingface_inference_toolkit/diffusers_utils.py\", line 26, in __init__\r\
    \nf69dd45546p69p 2023-08-14T13:00:09.945Z     pipeline = DIFFUSERS_TASKS[task](model_dir=model_dir,\
    \ device=device)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z     self.pipeline\
    \ = get_pipeline(model_dir=model_dir, task=task)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
    \     await handler()\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 682, in startup\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 584, in __aenter__\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z Traceback\
    \ (most recent call last):\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z \r\nf69dd45546p69p\
    \ 2023-08-14T13:00:09.945Z OSError: Error no file named diffusion_pytorch_model.bin\
    \ found in directory /repository/vae.\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
    \     raise EnvironmentError(\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   File\
    \ \"/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\"\
    , line 1069, in from_pretrained\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z   \
    \  self.pipeline = AutoPipelineForText2Image.from_pretrained(model_dir, torch_dtype=dtype,\
    \ device_map=device_map)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z     return\
    \ HuggingFaceHandler(model_dir=model_dir, task=task)\r\nf69dd45546p69p 2023-08-14T13:00:09.945Z\
    \   File \"/app/webservice_starlette.py\", line 57, in some_startup_task\r\nf69dd45546p69p\
    \ 2023-08-14T13:00:09.945Z   File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 705, in lifespan\r\nf69dd45546p69p 2023-08-14T13:00:09.948Z Application\
    \ startup failed. Exiting.\r\n```"
  created_at: 2023-08-14 12:04:58+00:00
  edited: false
  hidden: false
  id: 64da267a3764a5137e516aa8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f7a38cab02389697664e61f668f4cbe0.svg
      fullname: Shapira
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MichaelShapira
      type: user
    createdAt: '2023-08-15T19:22:51.000Z'
    data:
      edited: false
      editors:
      - MichaelShapira
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5320956110954285
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f7a38cab02389697664e61f668f4cbe0.svg
          fullname: Shapira
          isHf: false
          isPro: false
          name: MichaelShapira
          type: user
        html: '<p>Have the same error when deploying to Sagemaker</p>

          <p>Error no file named pytorch_model.bin, tf_model.h5</p>

          '
        raw: 'Have the same error when deploying to Sagemaker


          Error no file named pytorch_model.bin, tf_model.h5'
        updatedAt: '2023-08-15T19:22:51.147Z'
      numEdits: 0
      reactions: []
    id: 64dbd08b322a5774e0b308ff
    type: comment
  author: MichaelShapira
  content: 'Have the same error when deploying to Sagemaker


    Error no file named pytorch_model.bin, tf_model.h5'
  created_at: 2023-08-15 18:22:51+00:00
  edited: false
  hidden: false
  id: 64dbd08b322a5774e0b308ff
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e75199a64c9d9819bbae76/OWNWG7X-e9TWnl59Nm3NH.jpeg?w=200&h=200&f=face
      fullname: "D\u01B0\u01A1ng Quang T\xF9ng"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tungdq
      type: user
    createdAt: '2023-08-23T03:31:56.000Z'
    data:
      edited: false
      editors:
      - tungdq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8960940837860107
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e75199a64c9d9819bbae76/OWNWG7X-e9TWnl59Nm3NH.jpeg?w=200&h=200&f=face
          fullname: "D\u01B0\u01A1ng Quang T\xF9ng"
          isHf: false
          isPro: false
          name: tungdq
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;maazmehmood22&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/maazmehmood22\"\
          >@<span class=\"underline\">maazmehmood22</span></a></span>\n\n\t</span></span>\
          \ hello, have you successfully infer endpoint?</p>\n"
        raw: '@maazmehmood22 hello, have you successfully infer endpoint?'
        updatedAt: '2023-08-23T03:31:56.747Z'
      numEdits: 0
      reactions: []
    id: 64e57dac94aa06903215b190
    type: comment
  author: tungdq
  content: '@maazmehmood22 hello, have you successfully infer endpoint?'
  created_at: 2023-08-23 02:31:56+00:00
  edited: false
  hidden: false
  id: 64e57dac94aa06903215b190
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 17
repo_id: stabilityai/stable-diffusion-xl-refiner-1.0
repo_type: model
status: open
target_branch: null
title: error when deploying to huggingface inference endpoint
