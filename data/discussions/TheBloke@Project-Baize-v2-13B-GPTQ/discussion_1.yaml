!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Nicopara
conflicting_files: null
created_at: 2023-05-24 12:08:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a0e893f40edfc28592a63dc34dffdfe.svg
      fullname: nico radu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicopara
      type: user
    createdAt: '2023-05-24T13:08:31.000Z'
    data:
      edited: false
      editors:
      - Nicopara
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7a0e893f40edfc28592a63dc34dffdfe.svg
          fullname: nico radu
          isHf: false
          isPro: false
          name: Nicopara
          type: user
        html: "<p>Traceback (most recent call last): File \u201Cserver.py\u201D, line\
          \ 70, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name)\
          \ File \u201C/home/rocminsanity/Desktop/machinelearning/text-generation-webui-main/modules/models.py\u201D\
          , line 103, in load_model tokenizer = load_tokenizer(model_name, model)\
          \ File \u201C/home/rocminsanity/Desktop/machinelearning/text-generation-webui-main/modules/models.py\u201D\
          , line 128, in load_tokenizer tokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}/\"), clean_up_tokenization_spaces=True)\
          \ File \u201C/home/rocminsanity/miniconda3/envs/py3k/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u201D\
          , line 1796, in from_pretrained raise EnvironmentError( OSError: Can\u2019\
          t load tokenizer for \u2018models/baize-v2-13b-GPTQ\u2019. If you were trying\
          \ to load it from \u2018<a href=\"https://huggingface.co/models%E2%80%99\"\
          >https://huggingface.co/models\u2019</a>, make sure you don\u2019t have\
          \ a local directory with the same name. Otherwise, make sure \u2018models/baize-v2-13b-GPTQ\u2019\
          \ is the correct path to a directory containing all relevant files for a\
          \ LlamaTokenizer tokenizer.</p>\n"
        raw: "Traceback (most recent call last): File \u201Cserver.py\u201D, line\
          \ 70, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name)\
          \ File \u201C/home/rocminsanity/Desktop/machinelearning/text-generation-webui-main/modules/models.py\u201D\
          , line 103, in load_model tokenizer = load_tokenizer(model_name, model)\
          \ File \u201C/home/rocminsanity/Desktop/machinelearning/text-generation-webui-main/modules/models.py\u201D\
          , line 128, in load_tokenizer tokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}/\"), clean_up_tokenization_spaces=True)\
          \ File \u201C/home/rocminsanity/miniconda3/envs/py3k/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u201D\
          , line 1796, in from_pretrained raise EnvironmentError( OSError: Can\u2019\
          t load tokenizer for \u2018models/baize-v2-13b-GPTQ\u2019. If you were trying\
          \ to load it from \u2018https://huggingface.co/models\u2019, make sure you\
          \ don\u2019t have a local directory with the same name. Otherwise, make\
          \ sure \u2018models/baize-v2-13b-GPTQ\u2019 is the correct path to a directory\
          \ containing all relevant files for a LlamaTokenizer tokenizer."
        updatedAt: '2023-05-24T13:08:31.069Z'
      numEdits: 0
      reactions: []
    id: 646e0c4f2fd5a8eb8c525325
    type: comment
  author: Nicopara
  content: "Traceback (most recent call last): File \u201Cserver.py\u201D, line 70,\
    \ in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name)\
    \ File \u201C/home/rocminsanity/Desktop/machinelearning/text-generation-webui-main/modules/models.py\u201D\
    , line 103, in load_model tokenizer = load_tokenizer(model_name, model) File \u201C\
    /home/rocminsanity/Desktop/machinelearning/text-generation-webui-main/modules/models.py\u201D\
    , line 128, in load_tokenizer tokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
    {shared.args.model_dir}/{model_name}/\"), clean_up_tokenization_spaces=True) File\
    \ \u201C/home/rocminsanity/miniconda3/envs/py3k/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u201D\
    , line 1796, in from_pretrained raise EnvironmentError( OSError: Can\u2019t load\
    \ tokenizer for \u2018models/baize-v2-13b-GPTQ\u2019. If you were trying to load\
    \ it from \u2018https://huggingface.co/models\u2019, make sure you don\u2019t\
    \ have a local directory with the same name. Otherwise, make sure \u2018models/baize-v2-13b-GPTQ\u2019\
    \ is the correct path to a directory containing all relevant files for a LlamaTokenizer\
    \ tokenizer."
  created_at: 2023-05-24 12:08:31+00:00
  edited: false
  hidden: false
  id: 646e0c4f2fd5a8eb8c525325
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-24T13:11:28.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>One moment, I am checking</p>

          '
        raw: One moment, I am checking
        updatedAt: '2023-05-24T13:11:28.445Z'
      numEdits: 0
      reactions: []
    id: 646e0d0040e741b1913c2810
    type: comment
  author: TheBloke
  content: One moment, I am checking
  created_at: 2023-05-24 12:11:28+00:00
  edited: false
  hidden: false
  id: 646e0d0040e741b1913c2810
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-24T13:15:05.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I just double checked in ooba and had no problems at all, following
          the instructions in the README.</p>

          <p>Please try the ooba model download again in case you are missing some
          files. It won''t re-download any file unless it''s corrupted or missing.</p>

          '
        raw: 'I just double checked in ooba and had no problems at all, following
          the instructions in the README.


          Please try the ooba model download again in case you are missing some files.
          It won''t re-download any file unless it''s corrupted or missing.'
        updatedAt: '2023-05-24T13:15:05.028Z'
      numEdits: 0
      reactions: []
    id: 646e0dd99105e2cc56a1161b
    type: comment
  author: TheBloke
  content: 'I just double checked in ooba and had no problems at all, following the
    instructions in the README.


    Please try the ooba model download again in case you are missing some files. It
    won''t re-download any file unless it''s corrupted or missing.'
  created_at: 2023-05-24 12:15:05+00:00
  edited: false
  hidden: false
  id: 646e0dd99105e2cc56a1161b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-24T13:16:04.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Oh, looking at the log again I think you probably downloaded manually?
          Otherwise the folder should be called <code>models/TheBloke_Project-Baize-v2-13B-GPTQ</code>
          - so yeah you must have missed some files or something.  Or you started
          to download while I was still uploading, not sure.</p>

          <p>Anyway, repeat download and make sure all files are present.</p>

          '
        raw: 'Oh, looking at the log again I think you probably downloaded manually?
          Otherwise the folder should be called `models/TheBloke_Project-Baize-v2-13B-GPTQ`
          - so yeah you must have missed some files or something.  Or you started
          to download while I was still uploading, not sure.


          Anyway, repeat download and make sure all files are present.'
        updatedAt: '2023-05-24T13:16:04.097Z'
      numEdits: 0
      reactions: []
    id: 646e0e144bbb6117ee330491
    type: comment
  author: TheBloke
  content: 'Oh, looking at the log again I think you probably downloaded manually?
    Otherwise the folder should be called `models/TheBloke_Project-Baize-v2-13B-GPTQ`
    - so yeah you must have missed some files or something.  Or you started to download
    while I was still uploading, not sure.


    Anyway, repeat download and make sure all files are present.'
  created_at: 2023-05-24 12:16:04+00:00
  edited: false
  hidden: false
  id: 646e0e144bbb6117ee330491
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a0e893f40edfc28592a63dc34dffdfe.svg
      fullname: nico radu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicopara
      type: user
    createdAt: '2023-05-24T13:18:26.000Z'
    data:
      edited: false
      editors:
      - Nicopara
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7a0e893f40edfc28592a63dc34dffdfe.svg
          fullname: nico radu
          isHf: false
          isPro: false
          name: Nicopara
          type: user
        html: '<p>I downloaded using git clone, but It didn''t catch all files. Thank
          you.</p>

          '
        raw: I downloaded using git clone, but It didn't catch all files. Thank you.
        updatedAt: '2023-05-24T13:18:26.304Z'
      numEdits: 0
      reactions: []
      relatedEventId: 646e0ea25c3c0df5aef7b951
    id: 646e0ea25c3c0df5aef7b950
    type: comment
  author: Nicopara
  content: I downloaded using git clone, but It didn't catch all files. Thank you.
  created_at: 2023-05-24 12:18:26+00:00
  edited: false
  hidden: false
  id: 646e0ea25c3c0df5aef7b950
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/7a0e893f40edfc28592a63dc34dffdfe.svg
      fullname: nico radu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicopara
      type: user
    createdAt: '2023-05-24T13:18:26.000Z'
    data:
      status: closed
    id: 646e0ea25c3c0df5aef7b951
    type: status-change
  author: Nicopara
  created_at: 2023-05-24 12:18:26+00:00
  id: 646e0ea25c3c0df5aef7b951
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-24T13:25:28.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>No worries. For the future, I recommend using the text-generation-webui
          downloader, which downloads over HTTP.  You can either use it from the text-gen
          UI (bottom of Models page), or on the command line like this:</p>

          <pre><code>mkdir models

          python /path/to/text-generation-webui/download-model.py  TheBloke/Project-Baize-v2-13B-GPTQ  --thread
          2

          </code></pre>

          <p>When you use <code>git clone</code>, it stores every file twice, taking
          longer to complete and using double the disk space.  Also it doesn''t give
          very useful progress indication, like the true download speed in MB/s.</p>

          <p>I find it much quicker and easier to use than git.</p>

          '
        raw: 'No worries. For the future, I recommend using the text-generation-webui
          downloader, which downloads over HTTP.  You can either use it from the text-gen
          UI (bottom of Models page), or on the command line like this:

          ```

          mkdir models

          python /path/to/text-generation-webui/download-model.py  TheBloke/Project-Baize-v2-13B-GPTQ  --thread
          2

          ```


          When you use `git clone`, it stores every file twice, taking longer to complete
          and using double the disk space.  Also it doesn''t give very useful progress
          indication, like the true download speed in MB/s.


          I find it much quicker and easier to use than git.'
        updatedAt: '2023-05-24T13:25:49.929Z'
      numEdits: 1
      reactions: []
    id: 646e10489e252f776e417346
    type: comment
  author: TheBloke
  content: 'No worries. For the future, I recommend using the text-generation-webui
    downloader, which downloads over HTTP.  You can either use it from the text-gen
    UI (bottom of Models page), or on the command line like this:

    ```

    mkdir models

    python /path/to/text-generation-webui/download-model.py  TheBloke/Project-Baize-v2-13B-GPTQ  --thread
    2

    ```


    When you use `git clone`, it stores every file twice, taking longer to complete
    and using double the disk space.  Also it doesn''t give very useful progress indication,
    like the true download speed in MB/s.


    I find it much quicker and easier to use than git.'
  created_at: 2023-05-24 12:25:28+00:00
  edited: true
  hidden: false
  id: 646e10489e252f776e417346
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Project-Baize-v2-13B-GPTQ
repo_type: model
status: closed
target_branch: null
title: Can't load the model on ooba
