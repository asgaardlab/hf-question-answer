!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aldennX
conflicting_files: null
created_at: 2023-08-06 09:38:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5300a80e7f03a5ae00ede64d11492d9c.svg
      fullname: aldenn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aldennX
      type: user
    createdAt: '2023-08-06T10:38:36.000Z'
    data:
      edited: false
      editors:
      - aldennX
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.24009597301483154
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5300a80e7f03a5ae00ede64d11492d9c.svg
          fullname: aldenn
          isHf: false
          isPro: false
          name: aldennX
          type: user
        html: '<p>Traceback (most recent call last):<br>  File "C:\Users\Administrator\text-generation-webui\server.py",
          line 68, in load_model_wrapper<br>    shared.model, shared.tokenizer = load_model(shared.model_name,
          loader)<br>  File "C:\Users\Administrator\text-generation-webui\modules\models.py",
          line 78, in load_model<br>    output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>  File
          "C:\Users\Administrator\text-generation-webui\modules\models.py", line 232,
          in llamacpp_loader<br>    from modules.llamacpp_model import LlamaCppModel<br>  File
          "C:\Users\Administrator\text-generation-webui\modules\llamacpp_model.py",
          line 11, in <br>    import llama_cpp<br>  File "C:\Users\Administrator.conda\envs\textgen\lib\site-packages\llama_cpp_<em>init</em>_.py",
          line 1, in <br>    from .llama_cpp import *<br>  File "C:\Users\Administrator.conda\envs\textgen\lib\site-packages\llama_cpp\llama_cpp.py",
          line 1292, in <br>    llama_backend_init(c_bool(False))<br>  File "C:\Users\Administrator.conda\envs\textgen\lib\site-packages\llama_cpp\llama_cpp.py",
          line 403, in llama_backend_init<br>    return _lib.llama_backend_init(numa)<br>OSError:
          [WinError -1073741795] Windows Error 0xc000001d</p>

          '
        raw: "Traceback (most recent call last):\r\n  File \"C:\\Users\\Administrator\\\
          text-generation-webui\\server.py\", line 68, in load_model_wrapper\r\n \
          \   shared.model, shared.tokenizer = load_model(shared.model_name, loader)\r\
          \n  File \"C:\\Users\\Administrator\\text-generation-webui\\modules\\models.py\"\
          , line 78, in load_model\r\n    output = load_func_map[loader](model_name)\r\
          \n  File \"C:\\Users\\Administrator\\text-generation-webui\\modules\\models.py\"\
          , line 232, in llamacpp_loader\r\n    from modules.llamacpp_model import\
          \ LlamaCppModel\r\n  File \"C:\\Users\\Administrator\\text-generation-webui\\\
          modules\\llamacpp_model.py\", line 11, in <module>\r\n    import llama_cpp\r\
          \n  File \"C:\\Users\\Administrator\\.conda\\envs\\textgen\\lib\\site-packages\\\
          llama_cpp\\__init__.py\", line 1, in <module>\r\n    from .llama_cpp import\
          \ *\r\n  File \"C:\\Users\\Administrator\\.conda\\envs\\textgen\\lib\\site-packages\\\
          llama_cpp\\llama_cpp.py\", line 1292, in <module>\r\n    llama_backend_init(c_bool(False))\r\
          \n  File \"C:\\Users\\Administrator\\.conda\\envs\\textgen\\lib\\site-packages\\\
          llama_cpp\\llama_cpp.py\", line 403, in llama_backend_init\r\n    return\
          \ _lib.llama_backend_init(numa)\r\nOSError: [WinError -1073741795] Windows\
          \ Error 0xc000001d"
        updatedAt: '2023-08-06T10:38:36.483Z'
      numEdits: 0
      reactions: []
    id: 64cf782c995a0b5d595c45dd
    type: comment
  author: aldennX
  content: "Traceback (most recent call last):\r\n  File \"C:\\Users\\Administrator\\\
    text-generation-webui\\server.py\", line 68, in load_model_wrapper\r\n    shared.model,\
    \ shared.tokenizer = load_model(shared.model_name, loader)\r\n  File \"C:\\Users\\\
    Administrator\\text-generation-webui\\modules\\models.py\", line 78, in load_model\r\
    \n    output = load_func_map[loader](model_name)\r\n  File \"C:\\Users\\Administrator\\\
    text-generation-webui\\modules\\models.py\", line 232, in llamacpp_loader\r\n\
    \    from modules.llamacpp_model import LlamaCppModel\r\n  File \"C:\\Users\\\
    Administrator\\text-generation-webui\\modules\\llamacpp_model.py\", line 11, in\
    \ <module>\r\n    import llama_cpp\r\n  File \"C:\\Users\\Administrator\\.conda\\\
    envs\\textgen\\lib\\site-packages\\llama_cpp\\__init__.py\", line 1, in <module>\r\
    \n    from .llama_cpp import *\r\n  File \"C:\\Users\\Administrator\\.conda\\\
    envs\\textgen\\lib\\site-packages\\llama_cpp\\llama_cpp.py\", line 1292, in <module>\r\
    \n    llama_backend_init(c_bool(False))\r\n  File \"C:\\Users\\Administrator\\\
    .conda\\envs\\textgen\\lib\\site-packages\\llama_cpp\\llama_cpp.py\", line 403,\
    \ in llama_backend_init\r\n    return _lib.llama_backend_init(numa)\r\nOSError:\
    \ [WinError -1073741795] Windows Error 0xc000001d"
  created_at: 2023-08-06 09:38:36+00:00
  edited: false
  hidden: false
  id: 64cf782c995a0b5d595c45dd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61caeda441f9432649f03ab6/q7BrCmKdQkvVZ7mBdKdbQ.jpeg?w=200&h=200&f=face
      fullname: s3nh
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: s3nh
      type: user
    createdAt: '2023-08-06T13:03:21.000Z'
    data:
      edited: false
      editors:
      - s3nh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8805201053619385
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61caeda441f9432649f03ab6/q7BrCmKdQkvVZ7mBdKdbQ.jpeg?w=200&h=200&f=face
          fullname: s3nh
          isHf: false
          isPro: false
          name: s3nh
          type: user
        html: '<p>Hello, thank you for your message. I am not familiar with Text UIs
          and its compability, functionality, but  I built a simple space which allow
          to interract with a model, so you can try it out here.<br><a href="https://huggingface.co/spaces/s3nh/s3nh-chinese-alpaca-2-7b-GGML">https://huggingface.co/spaces/s3nh/s3nh-chinese-alpaca-2-7b-GGML</a></p>

          <p>All best,<br>Damian</p>

          '
        raw: "Hello, thank you for your message. I am not familiar with Text UIs and\
          \ its compability, functionality, but  I built a simple space which allow\
          \ to interract with a model, so you can try it out here. \nhttps://huggingface.co/spaces/s3nh/s3nh-chinese-alpaca-2-7b-GGML\n\
          \nAll best, \nDamian"
        updatedAt: '2023-08-06T13:03:21.382Z'
      numEdits: 0
      reactions: []
    id: 64cf9a19d1fda042b5560744
    type: comment
  author: s3nh
  content: "Hello, thank you for your message. I am not familiar with Text UIs and\
    \ its compability, functionality, but  I built a simple space which allow to interract\
    \ with a model, so you can try it out here. \nhttps://huggingface.co/spaces/s3nh/s3nh-chinese-alpaca-2-7b-GGML\n\
    \nAll best, \nDamian"
  created_at: 2023-08-06 12:03:21+00:00
  edited: false
  hidden: false
  id: 64cf9a19d1fda042b5560744
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5300a80e7f03a5ae00ede64d11492d9c.svg
      fullname: aldenn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aldennX
      type: user
    createdAt: '2023-08-07T10:25:26.000Z'
    data:
      edited: false
      editors:
      - aldennX
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8884689807891846
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5300a80e7f03a5ae00ede64d11492d9c.svg
          fullname: aldenn
          isHf: false
          isPro: false
          name: aldennX
          type: user
        html: '<p>I have successfully started, how to use text-generation-webui  for
          secondary training?</p>

          '
        raw: I have successfully started, how to use text-generation-webui  for secondary
          training?
        updatedAt: '2023-08-07T10:25:26.207Z'
      numEdits: 0
      reactions: []
    id: 64d0c696abc3308f053f7a7b
    type: comment
  author: aldennX
  content: I have successfully started, how to use text-generation-webui  for secondary
    training?
  created_at: 2023-08-07 09:25:26+00:00
  edited: false
  hidden: false
  id: 64d0c696abc3308f053f7a7b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/5300a80e7f03a5ae00ede64d11492d9c.svg
      fullname: aldenn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aldennX
      type: user
    createdAt: '2023-08-08T05:02:27.000Z'
    data:
      status: closed
    id: 64d1cc6373174cecdffae239
    type: status-change
  author: aldennX
  created_at: 2023-08-08 04:02:27+00:00
  id: 64d1cc6373174cecdffae239
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: s3nh/chinese-alpaca-2-7b-GGML
repo_type: model
status: closed
target_branch: null
title: "\u9009\u62E9\u6A21\u677F\u540E\u62A5\u9519!"
