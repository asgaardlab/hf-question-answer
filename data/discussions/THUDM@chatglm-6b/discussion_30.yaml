!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zxjyes
conflicting_files: null
created_at: 2023-04-07 01:52:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/44e07f5603c8dd547b73b76c563eb1bf.svg
      fullname: Zhang Xiaojun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zxjyes
      type: user
    createdAt: '2023-04-07T02:52:41.000Z'
    data:
      edited: false
      editors:
      - zxjyes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/44e07f5603c8dd547b73b76c563eb1bf.svg
          fullname: Zhang Xiaojun
          isHf: false
          isPro: false
          name: zxjyes
          type: user
        html: "<p>Explicitly passing a <code>revision</code> is encouraged when loading\
          \ a model with custom code to ensure no malicious code has been contributed\
          \ in a newer revision.<br>/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/io/image.py:13:\
          \ UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so:\
          \ cannot open shared object file: No such file or directory<br>  warn(f\"\
          Failed to load image Python extension: {e}\")<br>Explicitly passing a <code>revision</code>\
          \ is encouraged when loading a configuration with custom code to ensure\
          \ no malicious code has been contributed in a newer revision.<br>Explicitly\
          \ passing a <code>revision</code> is encouraged when loading a model with\
          \ custom code to ensure no malicious code has been contributed in a newer\
          \ revision.<br>Loading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588| 8/8 [00:09&lt;00:00,  1.14s/it]<br>Traceback (most recent\
          \ call last):<br>  File \"/home/zhangxj/gitspace/ChatGLM-6B/cli_demo.py\"\
          , line 7, in <br>    model = AutoModel.from_pretrained(\"/home/zhangxj/models/chatgpt6b\"\
          , trust_remote_code=True).half().quantize(4).cuda()<br>  File \"/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 466, in from_pretrained<br>    return model_class.from_pretrained(<br>\
          \  File \"/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
          , line 2646, in from_pretrained<br>    ) = cls._load_pretrained_model(<br>\
          \  File \"/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
          , line 3019, in _load_pretrained_model<br>    raise RuntimeError(f\"Error(s)\
          \ in loading state_dict for {model.<strong>class</strong>.<strong>name</strong>}:\\\
          n\\t{error_msg}\")<br>RuntimeError: Error(s) in loading state_dict for ChatGLMForConditionalGeneration:<br>\
          \    size mismatch for transformer.word_embeddings.weight: copying a param\
          \ with shape torch.Size([150528, 4096]) from checkpoint, the shape in current\
          \ model is torch.Size([130528, 4096]).<br>    size mismatch for lm_head.weight:\
          \ copying a param with shape torch.Size([150528, 4096]) from checkpoint,\
          \ the shape in current model is torch.Size([130528, 4096]).<br>    You may\
          \ consider adding <code>ignore_mismatched_sizes=True</code> in the model\
          \ <code>from_pretrained</code> method.</p>\n"
        raw: "Explicitly passing a `revision` is encouraged when loading a model with\
          \ custom code to ensure no malicious code has been contributed in a newer\
          \ revision.\r\n/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/io/image.py:13:\
          \ UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so:\
          \ cannot open shared object file: No such file or directory\r\n  warn(f\"\
          Failed to load image Python extension: {e}\")\r\nExplicitly passing a `revision`\
          \ is encouraged when loading a configuration with custom code to ensure\
          \ no malicious code has been contributed in a newer revision.\r\nExplicitly\
          \ passing a `revision` is encouraged when loading a model with custom code\
          \ to ensure no malicious code has been contributed in a newer revision.\r\
          \nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          | 8/8 [00:09<00:00,  1.14s/it]\r\nTraceback (most recent call last):\r\n\
          \  File \"/home/zhangxj/gitspace/ChatGLM-6B/cli_demo.py\", line 7, in <module>\r\
          \n    model = AutoModel.from_pretrained(\"/home/zhangxj/models/chatgpt6b\"\
          , trust_remote_code=True).half().quantize(4).cuda()\r\n  File \"/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 466, in from_pretrained\r\n    return model_class.from_pretrained(\r\
          \n  File \"/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
          , line 2646, in from_pretrained\r\n    ) = cls._load_pretrained_model(\r\
          \n  File \"/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
          , line 3019, in _load_pretrained_model\r\n    raise RuntimeError(f\"Error(s)\
          \ in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\
          )\r\nRuntimeError: Error(s) in loading state_dict for ChatGLMForConditionalGeneration:\r\
          \n\tsize mismatch for transformer.word_embeddings.weight: copying a param\
          \ with shape torch.Size([150528, 4096]) from checkpoint, the shape in current\
          \ model is torch.Size([130528, 4096]).\r\n\tsize mismatch for lm_head.weight:\
          \ copying a param with shape torch.Size([150528, 4096]) from checkpoint,\
          \ the shape in current model is torch.Size([130528, 4096]).\r\n\tYou may\
          \ consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained`\
          \ method.\r\n"
        updatedAt: '2023-04-07T02:52:41.657Z'
      numEdits: 0
      reactions: []
    id: 642f8579c953ca48ccd2e121
    type: comment
  author: zxjyes
  content: "Explicitly passing a `revision` is encouraged when loading a model with\
    \ custom code to ensure no malicious code has been contributed in a newer revision.\r\
    \n/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/io/image.py:13:\
    \ UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot\
    \ open shared object file: No such file or directory\r\n  warn(f\"Failed to load\
    \ image Python extension: {e}\")\r\nExplicitly passing a `revision` is encouraged\
    \ when loading a configuration with custom code to ensure no malicious code has\
    \ been contributed in a newer revision.\r\nExplicitly passing a `revision` is\
    \ encouraged when loading a model with custom code to ensure no malicious code\
    \ has been contributed in a newer revision.\r\nLoading checkpoint shards: 100%|\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8\
    \ [00:09<00:00,  1.14s/it]\r\nTraceback (most recent call last):\r\n  File \"\
    /home/zhangxj/gitspace/ChatGLM-6B/cli_demo.py\", line 7, in <module>\r\n    model\
    \ = AutoModel.from_pretrained(\"/home/zhangxj/models/chatgpt6b\", trust_remote_code=True).half().quantize(4).cuda()\r\
    \n  File \"/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\"\
    , line 466, in from_pretrained\r\n    return model_class.from_pretrained(\r\n\
    \  File \"/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
    , line 2646, in from_pretrained\r\n    ) = cls._load_pretrained_model(\r\n  File\
    \ \"/home/zhangxj/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/modeling_utils.py\"\
    , line 3019, in _load_pretrained_model\r\n    raise RuntimeError(f\"Error(s) in\
    \ loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\")\r\nRuntimeError:\
    \ Error(s) in loading state_dict for ChatGLMForConditionalGeneration:\r\n\tsize\
    \ mismatch for transformer.word_embeddings.weight: copying a param with shape\
    \ torch.Size([150528, 4096]) from checkpoint, the shape in current model is torch.Size([130528,\
    \ 4096]).\r\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([150528,\
    \ 4096]) from checkpoint, the shape in current model is torch.Size([130528, 4096]).\r\
    \n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained`\
    \ method.\r\n"
  created_at: 2023-04-07 01:52:41+00:00
  edited: false
  hidden: false
  id: 642f8579c953ca48ccd2e121
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661157784937-63033dc4e1e7f0e03a5e1a31.jpeg?w=200&h=200&f=face
      fullname: Zhengxiao Du
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: zxdu20
      type: user
    createdAt: '2023-04-08T02:55:10.000Z'
    data:
      edited: false
      editors:
      - zxdu20
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661157784937-63033dc4e1e7f0e03a5e1a31.jpeg?w=200&h=200&f=face
          fullname: Zhengxiao Du
          isHf: false
          isPro: false
          name: zxdu20
          type: user
        html: "<p>\u9700\u8981\u66F4\u65B0\u4E00\u4E0Bpytorch_model-00001-of-00008.bin\u548C\
          pytorch_model-00008-of-00008.bin</p>\n"
        raw: "\u9700\u8981\u66F4\u65B0\u4E00\u4E0Bpytorch_model-00001-of-00008.bin\u548C\
          pytorch_model-00008-of-00008.bin"
        updatedAt: '2023-04-08T02:55:10.358Z'
      numEdits: 0
      reactions: []
    id: 6430d78ea94b32637082578f
    type: comment
  author: zxdu20
  content: "\u9700\u8981\u66F4\u65B0\u4E00\u4E0Bpytorch_model-00001-of-00008.bin\u548C\
    pytorch_model-00008-of-00008.bin"
  created_at: 2023-04-08 01:55:10+00:00
  edited: false
  hidden: false
  id: 6430d78ea94b32637082578f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/44e07f5603c8dd547b73b76c563eb1bf.svg
      fullname: Zhang Xiaojun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zxjyes
      type: user
    createdAt: '2023-04-08T07:41:15.000Z'
    data:
      status: closed
    id: 64311a9bb62bdfa25c08e448
    type: status-change
  author: zxjyes
  created_at: 2023-04-08 06:41:15+00:00
  id: 64311a9bb62bdfa25c08e448
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 30
repo_id: THUDM/chatglm-6b
repo_type: model
status: closed
target_branch: null
title: "\u8FD9\u4E2A\u95EE\u9898\u6709\u4EBA\u9047\u5230\u8FC7\u5417\uFF1F\u8BF7\u95EE\
  \u4E00\u4E0B\u5982\u4F55\u89E3\u51B3\uFF0C\u6628\u5929\u8FD0\u884C\u7684\u597D\u597D\
  \u7684\uFF0C\u4ECA\u5929\u4E0D\u77E5\u9053\u4E3A\u5565\u7A81\u7136\u7EF4\u5EA6\u4E0D\
  \u5BF9\u5E94\u4E86"
