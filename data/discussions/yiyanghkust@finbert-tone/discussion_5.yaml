!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rushdishams
conflicting_files: null
created_at: 2022-09-22 13:51:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bd5dcb2b8998cd76d69aceef7bc61915.svg
      fullname: Rushdi Shams
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rushdishams
      type: user
    createdAt: '2022-09-22T14:51:24.000Z'
    data:
      edited: false
      editors:
      - rushdishams
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bd5dcb2b8998cd76d69aceef7bc61915.svg
          fullname: Rushdi Shams
          isHf: false
          isPro: false
          name: rushdishams
          type: user
        html: '<p>I am using finbert-tone from SageMaker notebooks to get text sentiments.
          The text are large in size. I am doing a batch transform, so I have "parameters":{"truncate":true}
          for each line inside json objects. But I am getting "Asking to truncate
          to max_length but no maximum length is provided and the model has no predefined
          maximum length. Default to no truncation." I found that the project has
          no tokenizer config file. How can I use the model with large texts without
          having a preprocess step to limit the token numbers of the texts? Thank
          you.</p>

          '
        raw: I am using finbert-tone from SageMaker notebooks to get text sentiments.
          The text are large in size. I am doing a batch transform, so I have "parameters":{"truncate":true}
          for each line inside json objects. But I am getting "Asking to truncate
          to max_length but no maximum length is provided and the model has no predefined
          maximum length. Default to no truncation." I found that the project has
          no tokenizer config file. How can I use the model with large texts without
          having a preprocess step to limit the token numbers of the texts? Thank
          you.
        updatedAt: '2022-09-22T14:51:24.779Z'
      numEdits: 0
      reactions: []
    id: 632c766c1d303f5f9acede71
    type: comment
  author: rushdishams
  content: I am using finbert-tone from SageMaker notebooks to get text sentiments.
    The text are large in size. I am doing a batch transform, so I have "parameters":{"truncate":true}
    for each line inside json objects. But I am getting "Asking to truncate to max_length
    but no maximum length is provided and the model has no predefined maximum length.
    Default to no truncation." I found that the project has no tokenizer config file.
    How can I use the model with large texts without having a preprocess step to limit
    the token numbers of the texts? Thank you.
  created_at: 2022-09-22 13:51:24+00:00
  edited: false
  hidden: false
  id: 632c766c1d303f5f9acede71
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ebb50dae79a934abfcad88686d342ec.svg
      fullname: lap yudabhay
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abbababaab
      type: user
    createdAt: '2023-07-27T10:18:03.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/6ebb50dae79a934abfcad88686d342ec.svg
          fullname: lap yudabhay
          isHf: false
          isPro: false
          name: abbababaab
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-07-27T10:18:15.211Z'
      numEdits: 0
      reactions: []
    id: 64c2445bec3c6181352e244f
    type: comment
  author: abbababaab
  content: This comment has been hidden
  created_at: 2023-07-27 09:18:03+00:00
  edited: true
  hidden: true
  id: 64c2445bec3c6181352e244f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: yiyanghkust/finbert-tone
repo_type: model
status: open
target_branch: null
title: Tokenizer Config File
