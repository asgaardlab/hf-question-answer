!!python/object:huggingface_hub.community.DiscussionWithDetails
author: RedXeol
conflicting_files: null
created_at: 2023-05-10 02:59:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/ZEcpodY84sXwqlXnD0QI1.jpeg?w=200&h=200&f=face
      fullname: ReDXeoL
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RedXeol
      type: user
    createdAt: '2023-05-10T03:59:46.000Z'
    data:
      edited: false
      editors:
      - RedXeol
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/ZEcpodY84sXwqlXnD0QI1.jpeg?w=200&h=200&f=face
          fullname: ReDXeoL
          isHf: false
          isPro: false
          name: RedXeol
          type: user
        html: "<p>El modelo es incre\xEDble; sin duda, en mi opini\xF3n, es el mejor\
          \ hasta el momento en espa\xF1ol. Su coherencia y cohesi\xF3n textual superan\
          \ a los modelos de c\xF3digo abierto m\xE1s grandes en ingl\xE9s. As\xED\
          \ que, ante todo, \xA1MUCHAS GRACIAS! Es maravilloso y un sue\xF1o hecho\
          \ realidad tener algo en nuestro idioma.</p>\n<p>Ahora bien, expresado mi\
          \ entusiasmo por el modelo Bertin, me gustar\xEDa saber si es posible, mediante\
          \ alg\xFAn m\xE9todo como Lora o quiz\xE1s un entrenamiento completo, censurar\
          \ al modelo utilizando un conjunto de datos o algo similar, para evitar\
          \ temas delicados como discriminaci\xF3n, pol\xEDtica conflictiva, religi\xF3\
          n, odio, contenido para adultos (NSFW), contenido sexual, violencia gr\xE1\
          fica, lenguaje ofensivo, racismo, homofobia, xenofobia, machismo, acoso\
          \ u otros temas que puedan resultar hirientes o inapropiados. A veces, el\
          \ modelo a\xFAn falla y puede decir cosas descabelladas como \"ama a Adolf\
          \ Hitler y es su dictador favorito\" XD.</p>\n<p>Si creo una lista de palabras\
          \ inapropiadas y le explico al modelo porque son malas... para luego entrenarlo\
          \ con  Lora y el PEFT de Hugging Face, \xBFcrees que servir\xE1 de algo?\
          \ \xBFO es bastante dif\xEDcil lograrlo con un m\xE9todo tan modesto y requiere\
          \ mayor capacidad computacional?<br>disculpa mi falta de experiencia, soy\
          \ un novato entusiasta en el mundo de los LLMs. muchas gracias</p>\n"
        raw: "El modelo es incre\xEDble; sin duda, en mi opini\xF3n, es el mejor hasta\
          \ el momento en espa\xF1ol. Su coherencia y cohesi\xF3n textual superan\
          \ a los modelos de c\xF3digo abierto m\xE1s grandes en ingl\xE9s. As\xED\
          \ que, ante todo, \xA1MUCHAS GRACIAS! Es maravilloso y un sue\xF1o hecho\
          \ realidad tener algo en nuestro idioma.\r\n\r\nAhora bien, expresado mi\
          \ entusiasmo por el modelo Bertin, me gustar\xEDa saber si es posible, mediante\
          \ alg\xFAn m\xE9todo como Lora o quiz\xE1s un entrenamiento completo, censurar\
          \ al modelo utilizando un conjunto de datos o algo similar, para evitar\
          \ temas delicados como discriminaci\xF3n, pol\xEDtica conflictiva, religi\xF3\
          n, odio, contenido para adultos (NSFW), contenido sexual, violencia gr\xE1\
          fica, lenguaje ofensivo, racismo, homofobia, xenofobia, machismo, acoso\
          \ u otros temas que puedan resultar hirientes o inapropiados. A veces, el\
          \ modelo a\xFAn falla y puede decir cosas descabelladas como \"ama a Adolf\
          \ Hitler y es su dictador favorito\" XD.\r\n\r\nSi creo una lista de palabras\
          \ inapropiadas y le explico al modelo porque son malas... para luego entrenarlo\
          \ con  Lora y el PEFT de Hugging Face, \xBFcrees que servir\xE1 de algo?\
          \ \xBFO es bastante dif\xEDcil lograrlo con un m\xE9todo tan modesto y requiere\
          \ mayor capacidad computacional?\r\ndisculpa mi falta de experiencia, soy\
          \ un novato entusiasta en el mundo de los LLMs. muchas gracias\r\n"
        updatedAt: '2023-05-10T03:59:46.280Z'
      numEdits: 0
      reactions: []
    id: 645b16b25196a37266168414
    type: comment
  author: RedXeol
  content: "El modelo es incre\xEDble; sin duda, en mi opini\xF3n, es el mejor hasta\
    \ el momento en espa\xF1ol. Su coherencia y cohesi\xF3n textual superan a los\
    \ modelos de c\xF3digo abierto m\xE1s grandes en ingl\xE9s. As\xED que, ante todo,\
    \ \xA1MUCHAS GRACIAS! Es maravilloso y un sue\xF1o hecho realidad tener algo en\
    \ nuestro idioma.\r\n\r\nAhora bien, expresado mi entusiasmo por el modelo Bertin,\
    \ me gustar\xEDa saber si es posible, mediante alg\xFAn m\xE9todo como Lora o\
    \ quiz\xE1s un entrenamiento completo, censurar al modelo utilizando un conjunto\
    \ de datos o algo similar, para evitar temas delicados como discriminaci\xF3n,\
    \ pol\xEDtica conflictiva, religi\xF3n, odio, contenido para adultos (NSFW), contenido\
    \ sexual, violencia gr\xE1fica, lenguaje ofensivo, racismo, homofobia, xenofobia,\
    \ machismo, acoso u otros temas que puedan resultar hirientes o inapropiados.\
    \ A veces, el modelo a\xFAn falla y puede decir cosas descabelladas como \"ama\
    \ a Adolf Hitler y es su dictador favorito\" XD.\r\n\r\nSi creo una lista de palabras\
    \ inapropiadas y le explico al modelo porque son malas... para luego entrenarlo\
    \ con  Lora y el PEFT de Hugging Face, \xBFcrees que servir\xE1 de algo? \xBF\
    O es bastante dif\xEDcil lograrlo con un m\xE9todo tan modesto y requiere mayor\
    \ capacidad computacional?\r\ndisculpa mi falta de experiencia, soy un novato\
    \ entusiasta en el mundo de los LLMs. muchas gracias\r\n"
  created_at: 2023-05-10 02:59:46+00:00
  edited: false
  hidden: false
  id: 645b16b25196a37266168414
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593016943046-noauth.jpeg?w=200&h=200&f=face
      fullname: Javier de la Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: versae
      type: user
    createdAt: '2023-05-10T10:07:37.000Z'
    data:
      edited: true
      editors:
      - versae
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593016943046-noauth.jpeg?w=200&h=200&f=face
          fullname: Javier de la Rosa
          isHf: false
          isPro: false
          name: versae
          type: user
        html: "<p>Vaya, \xA1muchas gracias!</p>\n<p>Por supuesto. De hecho <span data-props=\"\
          {&quot;user&quot;:&quot;mrm8488&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/mrm8488\">@<span class=\"underline\">mrm8488</span></a></span>\n\
          \n\t</span></span>, tambi\xE9n parte de BERTIN Project, escribi\xF3 no hace\
          \ mucho un <a rel=\"nofollow\" href=\"https://colab.research.google.com/drive/1KyasizgnWFeHU-KXO1-k53yCCBBtFE9i?usp=sharing\"\
          >Notebook para crear LoRA adapters usando PEFT sobre BERTIN-GPT-J-6B</a>.\
          \ En su ejemplo se a\xF1aden tokens especiales, pero ese paso no es estrictamente\
          \ necesario.</p>\n<p>El tema del alignment es delicado. Los datos para entrenar\
          \ los modelos BERTIN no han sido extensivamente revisados para eliminar\
          \ contenido ofensivo. Pero s\xED que se pueden entrenar, incluso este modelo\
          \ basado en Alpaca, si consigues un dataset de alignment para que los modelos\
          \ aprendan a no decir seg\xFAn qu\xE9 cosas. Con los datos adecuados se\
          \ puede probar a crear un adapter y deber\xEDa funcionar.</p>\n"
        raw: "Vaya, \xA1muchas gracias!\n\nPor supuesto. De hecho @mrm8488, tambi\xE9\
          n parte de BERTIN Project, escribi\xF3 no hace mucho un [Notebook para crear\
          \ LoRA adapters usando PEFT sobre BERTIN-GPT-J-6B](https://colab.research.google.com/drive/1KyasizgnWFeHU-KXO1-k53yCCBBtFE9i?usp=sharing).\
          \ En su ejemplo se a\xF1aden tokens especiales, pero ese paso no es estrictamente\
          \ necesario.\n\nEl tema del alignment es delicado. Los datos para entrenar\
          \ los modelos BERTIN no han sido extensivamente revisados para eliminar\
          \ contenido ofensivo. Pero s\xED que se pueden entrenar, incluso este modelo\
          \ basado en Alpaca, si consigues un dataset de alignment para que los modelos\
          \ aprendan a no decir seg\xFAn qu\xE9 cosas. Con los datos adecuados se\
          \ puede probar a crear un adapter y deber\xEDa funcionar."
        updatedAt: '2023-05-11T07:33:40.781Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - RedXeol
    id: 645b6ce9c971fbab741d7543
    type: comment
  author: versae
  content: "Vaya, \xA1muchas gracias!\n\nPor supuesto. De hecho @mrm8488, tambi\xE9\
    n parte de BERTIN Project, escribi\xF3 no hace mucho un [Notebook para crear LoRA\
    \ adapters usando PEFT sobre BERTIN-GPT-J-6B](https://colab.research.google.com/drive/1KyasizgnWFeHU-KXO1-k53yCCBBtFE9i?usp=sharing).\
    \ En su ejemplo se a\xF1aden tokens especiales, pero ese paso no es estrictamente\
    \ necesario.\n\nEl tema del alignment es delicado. Los datos para entrenar los\
    \ modelos BERTIN no han sido extensivamente revisados para eliminar contenido\
    \ ofensivo. Pero s\xED que se pueden entrenar, incluso este modelo basado en Alpaca,\
    \ si consigues un dataset de alignment para que los modelos aprendan a no decir\
    \ seg\xFAn qu\xE9 cosas. Con los datos adecuados se puede probar a crear un adapter\
    \ y deber\xEDa funcionar."
  created_at: 2023-05-10 09:07:37+00:00
  edited: true
  hidden: false
  id: 645b6ce9c971fbab741d7543
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593016943046-noauth.jpeg?w=200&h=200&f=face
      fullname: Javier de la Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: versae
      type: user
    createdAt: '2023-10-04T14:02:13.000Z'
    data:
      status: closed
    id: 651d70651c3092526818f014
    type: status-change
  author: versae
  created_at: 2023-10-04 13:02:13+00:00
  id: 651d70651c3092526818f014
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: bertin-project/bertin-gpt-j-6B-alpaca
repo_type: model
status: closed
target_branch: null
title: "\xBFPregunta peque\xF1a?"
