!!python/object:huggingface_hub.community.DiscussionWithDetails
author: chrisgru
conflicting_files: null
created_at: 2023-11-14 13:10:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f151d6f5cec5b8ee9721c6d70b4f1815.svg
      fullname: Cristian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chrisgru
      type: user
    createdAt: '2023-11-14T13:10:44.000Z'
    data:
      edited: true
      editors:
      - chrisgru
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7501594424247742
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f151d6f5cec5b8ee9721c6d70b4f1815.svg
          fullname: Cristian
          isHf: false
          isPro: false
          name: chrisgru
          type: user
        html: '<p>Hi,<br>first thank you for everything!<br>I have a question since
          I''m experimenting and debugging a lot.<br>Do you also see double eos tokens
          being added to the data when training ?<br>You can check using:<br>python
          -m axolotl.cli.train your_config.yml --prepare_ds_only --debug --debug_text_only
          --debug_num_examples 2</p>

          <p>For a simple dataset, I have this (eos \n eos again):<br>&lt;|im_start|&gt;user<br>Bonjour!&lt;|im_end|&gt;</p>

          <p>&lt;|im_start|&gt;assistant<br>Bonjour!&lt;|im_end|&gt;</p>

          <p>&lt;|im_end|&gt;&lt;|im_start|&gt;user<br>Salutations!&lt;|im_end|&gt;</p>

          <p>&lt;|im_start|&gt;assistant<br>Salutations!&lt;|im_end|&gt;</p>

          <p>&lt;|im_end|&gt;</p>

          <p>The dataset is like this:<br>{"conversations"[{"from": "human", "value":
          "Bonjour!"},{"from": "gpt","value": "Bonjour!"}]}<br>{"conversations"[{"from":
          "human", "value": "Salutations!"},{"from": "gpt","value": "Salutations!"}]}</p>

          <p>I assume since these are 2 eos tokens separated by \n, it doesn''t matter
          for performance in the end, but I just wanted to run this by you.</p>

          '
        raw: 'Hi,

          first thank you for everything!

          I have a question since I''m experimenting and debugging a lot.

          Do you also see double eos tokens being added to the data when training
          ?

          You can check using:

          python -m axolotl.cli.train your_config.yml --prepare_ds_only --debug --debug_text_only
          --debug_num_examples 2


          For a simple dataset, I have this (eos \n eos again):

          <|im_start|>user

          Bonjour!<|im_end|>


          <|im_start|>assistant

          Bonjour!<|im_end|>


          <|im_end|><|im_start|>user

          Salutations!<|im_end|>


          <|im_start|>assistant

          Salutations!<|im_end|>


          <|im_end|>


          The dataset is like this:

          {"conversations"[{"from": "human", "value": "Bonjour!"},{"from": "gpt","value":
          "Bonjour!"}]}

          {"conversations"[{"from": "human", "value": "Salutations!"},{"from": "gpt","value":
          "Salutations!"}]}


          I assume since these are 2 eos tokens separated by \n, it doesn''t matter
          for performance in the end, but I just wanted to run this by you.'
        updatedAt: '2023-11-14T13:11:09.092Z'
      numEdits: 1
      reactions: []
    id: 655371d4140fc44a74d963d0
    type: comment
  author: chrisgru
  content: 'Hi,

    first thank you for everything!

    I have a question since I''m experimenting and debugging a lot.

    Do you also see double eos tokens being added to the data when training ?

    You can check using:

    python -m axolotl.cli.train your_config.yml --prepare_ds_only --debug --debug_text_only
    --debug_num_examples 2


    For a simple dataset, I have this (eos \n eos again):

    <|im_start|>user

    Bonjour!<|im_end|>


    <|im_start|>assistant

    Bonjour!<|im_end|>


    <|im_end|><|im_start|>user

    Salutations!<|im_end|>


    <|im_start|>assistant

    Salutations!<|im_end|>


    <|im_end|>


    The dataset is like this:

    {"conversations"[{"from": "human", "value": "Bonjour!"},{"from": "gpt","value":
    "Bonjour!"}]}

    {"conversations"[{"from": "human", "value": "Salutations!"},{"from": "gpt","value":
    "Salutations!"}]}


    I assume since these are 2 eos tokens separated by \n, it doesn''t matter for
    performance in the end, but I just wanted to run this by you.'
  created_at: 2023-11-14 13:10:44+00:00
  edited: true
  hidden: false
  id: 655371d4140fc44a74d963d0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-11-15T06:06:09.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9927679300308228
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>this is really interesting.  I will examine this.</p>

          '
        raw: this is really interesting.  I will examine this.
        updatedAt: '2023-11-15T06:06:09.540Z'
      numEdits: 0
      reactions: []
    id: 65545fd13d8030de3544d5fb
    type: comment
  author: ehartford
  content: this is really interesting.  I will examine this.
  created_at: 2023-11-15 06:06:09+00:00
  edited: false
  hidden: false
  id: 65545fd13d8030de3544d5fb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f151d6f5cec5b8ee9721c6d70b4f1815.svg
      fullname: Cristian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chrisgru
      type: user
    createdAt: '2023-11-15T07:10:59.000Z'
    data:
      status: closed
    id: 65546f03d13e8d851dde5706
    type: status-change
  author: chrisgru
  created_at: 2023-11-15 07:10:59+00:00
  id: 65546f03d13e8d851dde5706
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f151d6f5cec5b8ee9721c6d70b4f1815.svg
      fullname: Cristian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chrisgru
      type: user
    createdAt: '2023-11-15T07:11:05.000Z'
    data:
      status: open
    id: 65546f09d13e8d851dde57c8
    type: status-change
  author: chrisgru
  created_at: 2023-11-15 07:11:05+00:00
  id: 65546f09d13e8d851dde57c8
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63037b895c70c21d0ea80b0e/myu35DuQn9io_HhxNLYR4.png?w=200&h=200&f=face
      fullname: Pooodle Shmith
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: Tom9000
      type: user
    createdAt: '2023-11-15T20:30:16.000Z'
    data:
      edited: true
      editors:
      - Tom9000
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9802584052085876
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63037b895c70c21d0ea80b0e/myu35DuQn9io_HhxNLYR4.png?w=200&h=200&f=face
          fullname: Pooodle Shmith
          isHf: false
          isPro: true
          name: Tom9000
          type: user
        html: '<p>I''ve spent half day trying and failing to figure out, why the moment
          I loaded this model, my obbabooga web ui broke completely, couldn''t follow
          ChatML format anymore.<br>The main problem, wasn''t just this this model,
          every other ChatML model stopped functioning no matter what I tried (short
          of complete webui purge and reinstall), but it was working flawlessly with
          every ChatML model all day until I attempted loading this one.<br>Still
          think it''s largely due to some bugs in web ui, it usually is ridden with
          those, but maybe some issues with tokenizer issues had some play too.<br>I''m
          re-downloading bloke''s quants once more to test.</p>

          '
        raw: 'I''ve spent half day trying and failing to figure out, why the moment
          I loaded this model, my obbabooga web ui broke completely, couldn''t follow
          ChatML format anymore.

          The main problem, wasn''t just this this model, every other ChatML model
          stopped functioning no matter what I tried (short of complete webui purge
          and reinstall), but it was working flawlessly with every ChatML model all
          day until I attempted loading this one.

          Still think it''s largely due to some bugs in web ui, it usually is ridden
          with those, but maybe some issues with tokenizer issues had some play too.

          I''m re-downloading bloke''s quants once more to test.'
        updatedAt: '2023-11-15T20:30:45.067Z'
      numEdits: 1
      reactions: []
    id: 65552a5841c144eefeba4fa4
    type: comment
  author: Tom9000
  content: 'I''ve spent half day trying and failing to figure out, why the moment
    I loaded this model, my obbabooga web ui broke completely, couldn''t follow ChatML
    format anymore.

    The main problem, wasn''t just this this model, every other ChatML model stopped
    functioning no matter what I tried (short of complete webui purge and reinstall),
    but it was working flawlessly with every ChatML model all day until I attempted
    loading this one.

    Still think it''s largely due to some bugs in web ui, it usually is ridden with
    those, but maybe some issues with tokenizer issues had some play too.

    I''m re-downloading bloke''s quants once more to test.'
  created_at: 2023-11-15 20:30:16+00:00
  edited: true
  hidden: false
  id: 65552a5841c144eefeba4fa4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f151d6f5cec5b8ee9721c6d70b4f1815.svg
      fullname: Cristian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chrisgru
      type: user
    createdAt: '2023-11-16T05:50:27.000Z'
    data:
      edited: true
      editors:
      - chrisgru
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.872201144695282
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f151d6f5cec5b8ee9721c6d70b4f1815.svg
          fullname: Cristian
          isHf: false
          isPro: false
          name: chrisgru
          type: user
        html: '<p>the 2 eos tokens that appear here should not bother Ooba. Test the
          model in another way if you can.<br>The 2 eos tokens are added:</p>

          <ol>

          <li>First as a separator: <a rel="nofollow" href="https://github.com/lm-sys/FastChat/blob/main/fastchat/conversation.py#L163">https://github.com/lm-sys/FastChat/blob/main/fastchat/conversation.py#L163</a><br>ret
          += role + "\n" + message + self.sep + "\n"</li>

          <li>axolotl adds another eos:<br><a rel="nofollow" href="https://github.com/OpenAccess-AI-Collective/axolotl/blob/1a6309c8a633a6fe17b2ffebbbc0353565f376e5/src/axolotl/prompt_tokenizers.py#L392">https://github.com/OpenAccess-AI-Collective/axolotl/blob/1a6309c8a633a6fe17b2ffebbbc0353565f376e5/src/axolotl/prompt_tokenizers.py#L392</a></li>

          </ol>

          <p>;;this should be the assistant response, should end with an eos token<br>.....<br>res
          = self._tokenize(<br>                        turn,<br>                        add_eos_token=True,<br>                        strip_bos_token=True,<br>                    )</p>

          <p>And as such we have at the end of each conversation:<br>&lt;|im_end|&gt;\n&lt;|im_end|&gt;</p>

          '
        raw: "the 2 eos tokens that appear here should not bother Ooba. Test the model\
          \ in another way if you can.\nThe 2 eos tokens are added:\n1. First as a\
          \ separator: https://github.com/lm-sys/FastChat/blob/main/fastchat/conversation.py#L163\
          \   \nret += role + \"\\n\" + message + self.sep + \"\\n\"\n2. axolotl adds\
          \ another eos: \nhttps://github.com/OpenAccess-AI-Collective/axolotl/blob/1a6309c8a633a6fe17b2ffebbbc0353565f376e5/src/axolotl/prompt_tokenizers.py#L392\n\
          \n;;this should be the assistant response, should end with an eos token\n\
          .....\nres = self._tokenize(\n                        turn,\n          \
          \              add_eos_token=True,\n                        strip_bos_token=True,\n\
          \                    )\n\nAnd as such we have at the end of each conversation:\n\
          <|im_end|>\\n<|im_end|>\n"
        updatedAt: '2023-11-16T05:57:02.026Z'
      numEdits: 2
      reactions: []
    id: 6555ada389fd41f8aff80f30
    type: comment
  author: chrisgru
  content: "the 2 eos tokens that appear here should not bother Ooba. Test the model\
    \ in another way if you can.\nThe 2 eos tokens are added:\n1. First as a separator:\
    \ https://github.com/lm-sys/FastChat/blob/main/fastchat/conversation.py#L163 \
    \  \nret += role + \"\\n\" + message + self.sep + \"\\n\"\n2. axolotl adds another\
    \ eos: \nhttps://github.com/OpenAccess-AI-Collective/axolotl/blob/1a6309c8a633a6fe17b2ffebbbc0353565f376e5/src/axolotl/prompt_tokenizers.py#L392\n\
    \n;;this should be the assistant response, should end with an eos token\n.....\n\
    res = self._tokenize(\n                        turn,\n                       \
    \ add_eos_token=True,\n                        strip_bos_token=True,\n       \
    \             )\n\nAnd as such we have at the end of each conversation:\n<|im_end|>\\\
    n<|im_end|>\n"
  created_at: 2023-11-16 05:50:27+00:00
  edited: true
  hidden: false
  id: 6555ada389fd41f8aff80f30
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-11-18T00:41:57.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9871447086334229
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>is there something I need to change?</p>

          '
        raw: is there something I need to change?
        updatedAt: '2023-11-18T00:41:57.161Z'
      numEdits: 0
      reactions: []
    id: 65580855efc0fb7bed5a0236
    type: comment
  author: ehartford
  content: is there something I need to change?
  created_at: 2023-11-18 00:41:57+00:00
  edited: false
  hidden: false
  id: 65580855efc0fb7bed5a0236
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-11-18T00:42:35.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8859800100326538
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>when I train dolphin 3.0 I can modify the axolotl config to train
          it differently</p>

          '
        raw: when I train dolphin 3.0 I can modify the axolotl config to train it
          differently
        updatedAt: '2023-11-18T00:42:35.990Z'
      numEdits: 0
      reactions: []
    id: 6558087b43c6fb21e473086d
    type: comment
  author: ehartford
  content: when I train dolphin 3.0 I can modify the axolotl config to train it differently
  created_at: 2023-11-18 00:42:35+00:00
  edited: false
  hidden: false
  id: 6558087b43c6fb21e473086d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f151d6f5cec5b8ee9721c6d70b4f1815.svg
      fullname: Cristian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chrisgru
      type: user
    createdAt: '2023-11-18T13:14:05.000Z'
    data:
      edited: true
      editors:
      - chrisgru
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8890061974525452
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f151d6f5cec5b8ee9721c6d70b4f1815.svg
          fullname: Cristian
          isHf: false
          isPro: false
          name: chrisgru
          type: user
        html: '<p>Hi Eric,</p>

          <p>There is not much we can change at this point. I mean, we can submit
          a PR to axolotl and change the above self._tokenize(...) to set add_eos_token
          to False. (Will this affect other templates that use the ShareGPTPromptTokenizingStrategy
          class ? maybe, that is why it needs a bit of attention. I''ll try but time
          is limited on my side, that is why no PR as of yet from me)<br>We also need
          to create a new FastChat conversation class to remove the \n at the end,
          like this:</p>

          <p>register_conv_template(<br>    Conversation(<br>        name="chatml2",<br>        system_template="&lt;|im_start|&gt;system\n{system_message}",<br>        system_message="You
          are a helpful assistant.",<br>        roles=["&lt;|im_start|&gt;user", "&lt;|im_start|&gt;assistant"],<br>        sep_style=SeparatorStyle.CHATML,<br>        sep="&lt;|im_end|&gt;"<br>    )<br>)</p>

          <p>// The original chatml conversation has   sep="&lt;|im_end|&gt;\n" and
          as such FastChat and Axolotl both added a \n at the end.</p>

          <p>Once this is done, the template will be correct. All this happens because
          multi turn conversation was not used that much previously and I guess people
          did not notice.<br>This may or may not affect the current trained Dolphin
          model. My not yet so expert opinion is that it affects it a little bit.</p>

          '
        raw: "Hi Eric,\n\nThere is not much we can change at this point. I mean, we\
          \ can submit a PR to axolotl and change the above self._tokenize(...) to\
          \ set add_eos_token to False. (Will this affect other templates that use\
          \ the ShareGPTPromptTokenizingStrategy class ? maybe, that is why it needs\
          \ a bit of attention. I'll try but time is limited on my side, that is why\
          \ no PR as of yet from me)\nWe also need to create a new FastChat conversation\
          \ class to remove the \\n at the end, like this:\n\nregister_conv_template(\n\
          \    Conversation(\n        name=\"chatml2\",\n        system_template=\"\
          <|im_start|>system\\n{system_message}\",\n        system_message=\"You are\
          \ a helpful assistant.\",\n        roles=[\"<|im_start|>user\", \"<|im_start|>assistant\"\
          ],\n        sep_style=SeparatorStyle.CHATML,\n        sep=\"<|im_end|>\"\
          \n    )\n)\n\n// The original chatml conversation has   sep=\"<|im_end|>\\\
          n\" and as such FastChat and Axolotl both added a \\n at the end.\n\nOnce\
          \ this is done, the template will be correct. All this happens because multi\
          \ turn conversation was not used that much previously and I guess people\
          \ did not notice.\nThis may or may not affect the current trained Dolphin\
          \ model. My not yet so expert opinion is that it affects it a little bit."
        updatedAt: '2023-11-18T13:14:50.334Z'
      numEdits: 1
      reactions: []
    id: 6558b89d30ad83ad6b281cd9
    type: comment
  author: chrisgru
  content: "Hi Eric,\n\nThere is not much we can change at this point. I mean, we\
    \ can submit a PR to axolotl and change the above self._tokenize(...) to set add_eos_token\
    \ to False. (Will this affect other templates that use the ShareGPTPromptTokenizingStrategy\
    \ class ? maybe, that is why it needs a bit of attention. I'll try but time is\
    \ limited on my side, that is why no PR as of yet from me)\nWe also need to create\
    \ a new FastChat conversation class to remove the \\n at the end, like this:\n\
    \nregister_conv_template(\n    Conversation(\n        name=\"chatml2\",\n    \
    \    system_template=\"<|im_start|>system\\n{system_message}\",\n        system_message=\"\
    You are a helpful assistant.\",\n        roles=[\"<|im_start|>user\", \"<|im_start|>assistant\"\
    ],\n        sep_style=SeparatorStyle.CHATML,\n        sep=\"<|im_end|>\"\n   \
    \ )\n)\n\n// The original chatml conversation has   sep=\"<|im_end|>\\n\" and\
    \ as such FastChat and Axolotl both added a \\n at the end.\n\nOnce this is done,\
    \ the template will be correct. All this happens because multi turn conversation\
    \ was not used that much previously and I guess people did not notice.\nThis may\
    \ or may not affect the current trained Dolphin model. My not yet so expert opinion\
    \ is that it affects it a little bit."
  created_at: 2023-11-18 13:14:05+00:00
  edited: true
  hidden: false
  id: 6558b89d30ad83ad6b281cd9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: cognitivecomputations/dolphin-2_2-yi-34b
repo_type: model
status: open
target_branch: null
title: Dataset question regarding eos
