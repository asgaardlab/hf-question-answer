!!python/object:huggingface_hub.community.DiscussionWithDetails
author: afmck
conflicting_files: null
created_at: 2023-10-30 12:09:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666128776959-6079e94c88160e14e4e2e4b1.jpeg?w=200&h=200&f=face
      fullname: Alex McKinney
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: afmck
      type: user
    createdAt: '2023-10-30T13:09:04.000Z'
    data:
      edited: false
      editors:
      - afmck
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5703620314598083
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666128776959-6079e94c88160e14e4e2e4b1.jpeg?w=200&h=200&f=face
          fullname: Alex McKinney
          isHf: false
          isPro: false
          name: afmck
          type: user
        html: "<p>Trying to load the model currently fails:</p>\n<pre><code>In [6]:\
          \ model = CLIPModel.from_pretrained(\"LanguageBind/LanguageBind_Audio\"\
          )\nYou are using a model of type LanguageBindAudio to instantiate a model\
          \ of type clip. This is not supported for all configurations of models and\
          \ can yield errors.\n---------------------------------------------------------------------------\n\
          RuntimeError                              Traceback (most recent call last)\n\
          Cell In[6], line 1\n----&gt; 1 model = CLIPModel.from_pretrained(\"LanguageBind/LanguageBind_Audio\"\
          )\n\nFile /..../miniconda3/envs/LanguageBind/lib/python3.9/site-packages/transformers/modeling_utils.py:2881,\
          \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *model_args, **kwargs)\n   2871     if dtype_orig is not None:\n   2872\
          \         torch.set_default_dtype(dtype_orig)\n   2874     (\n   2875  \
          \       model,\n   2876         missing_keys,\n   2877         unexpected_keys,\n\
          \   2878         mismatched_keys,\n   2879         offload_index,\n   2880\
          \         error_msgs,\n-&gt; 2881     ) = cls._load_pretrained_model(\n\
          \   2882         model,\n   2883         state_dict,\n   2884         loaded_state_dict_keys,\
          \  # XXX: rename?\n   2885         resolved_archive_file,\n   2886     \
          \    pretrained_model_name_or_path,\n   2887         ignore_mismatched_sizes=ignore_mismatched_sizes,\n\
          \   2888         sharded_metadata=sharded_metadata,\n   2889         _fast_init=_fast_init,\n\
          \   2890         low_cpu_mem_usage=low_cpu_mem_usage,\n   2891         device_map=device_map,\n\
          \   2892         offload_folder=offload_folder,\n   2893         offload_state_dict=offload_state_dict,\n\
          \   2894         dtype=torch_dtype,\n   2895         is_quantized=(load_in_8bit\
          \ or load_in_4bit),\n   2896         keep_in_fp32_modules=keep_in_fp32_modules,\n\
          \   2897     )\n   2899 model.is_loaded_in_4bit = load_in_4bit\n   2900\
          \ model.is_loaded_in_8bit = load_in_8bit\n\nFile /..../miniconda3/envs/LanguageBind/lib/python3.9/site-packages/transformers/modeling_utils.py:3278,\
          \ in PreTrainedModel._load_pretrained_model(cls, model, state_dict, loaded_keys,\
          \ resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes,\
          \ sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder,\
          \ offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\n   3274\
          \     if \"size mismatch\" in error_msg:\n   3275         error_msg += (\n\
          \   3276             \"\\n\\tYou may consider adding `ignore_mismatched_sizes=True`\
          \ in the model `from_pretrained` method.\"\n   3277         )\n-&gt; 3278\
          \     raise RuntimeError(f\"Error(s) in loading state_dict for {model.__class__.__name__}:\\\
          n\\t{error_msg}\")\n   3280 if is_quantized:\n   3281     unexpected_keys\
          \ = [elem for elem in unexpected_keys if \"SCB\" not in elem]\n\nRuntimeError:\
          \ Error(s) in loading state_dict for CLIPModel:\n        size mismatch for\
          \ vision_model.embeddings.position_ids: copying a param with shape torch.Size([1,\
          \ 577]) from checkpoint, the shape in current model is torch.Size([1, 257]).\n\
          \        size mismatch for vision_model.embeddings.position_embedding.weight:\
          \ copying a param with shape torch.Size([577, 1024]) from checkpoint, the\
          \ shape in current model is torch.Size([257, 1024]).\n        You may consider\
          \ adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\n\
          </code></pre>\n<p>Running with <code>ignore_mismatched_sizes</code> succeeds\
          \ but many weights not being used or being freshly initialised. This is\
          \ likely not correct.</p>\n<p>It would be nice if we could instantiate the\
          \ model using <code>from_pretrained</code> without error.</p>\n<p>Thanks~</p>\n"
        raw: "Trying to load the model currently fails:\r\n```\r\nIn [6]: model =\
          \ CLIPModel.from_pretrained(\"LanguageBind/LanguageBind_Audio\")\r\nYou\
          \ are using a model of type LanguageBindAudio to instantiate a model of\
          \ type clip. This is not supported for all configurations of models and\
          \ can yield errors.\r\n---------------------------------------------------------------------------\r\
          \nRuntimeError                              Traceback (most recent call\
          \ last)\r\nCell In[6], line 1\r\n----> 1 model = CLIPModel.from_pretrained(\"\
          LanguageBind/LanguageBind_Audio\")\r\n\r\nFile /..../miniconda3/envs/LanguageBind/lib/python3.9/site-packages/transformers/modeling_utils.py:2881,\
          \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *model_args, **kwargs)\r\n   2871     if dtype_orig is not None:\r\n \
          \  2872         torch.set_default_dtype(dtype_orig)\r\n   2874     (\r\n\
          \   2875         model,\r\n   2876         missing_keys,\r\n   2877    \
          \     unexpected_keys,\r\n   2878         mismatched_keys,\r\n   2879  \
          \       offload_index,\r\n   2880         error_msgs,\r\n-> 2881     ) =\
          \ cls._load_pretrained_model(\r\n   2882         model,\r\n   2883     \
          \    state_dict,\r\n   2884         loaded_state_dict_keys,  # XXX: rename?\r\
          \n   2885         resolved_archive_file,\r\n   2886         pretrained_model_name_or_path,\r\
          \n   2887         ignore_mismatched_sizes=ignore_mismatched_sizes,\r\n \
          \  2888         sharded_metadata=sharded_metadata,\r\n   2889         _fast_init=_fast_init,\r\
          \n   2890         low_cpu_mem_usage=low_cpu_mem_usage,\r\n   2891      \
          \   device_map=device_map,\r\n   2892         offload_folder=offload_folder,\r\
          \n   2893         offload_state_dict=offload_state_dict,\r\n   2894    \
          \     dtype=torch_dtype,\r\n   2895         is_quantized=(load_in_8bit or\
          \ load_in_4bit),\r\n   2896         keep_in_fp32_modules=keep_in_fp32_modules,\r\
          \n   2897     )\r\n   2899 model.is_loaded_in_4bit = load_in_4bit\r\n  \
          \ 2900 model.is_loaded_in_8bit = load_in_8bit\r\n\r\nFile /..../miniconda3/envs/LanguageBind/lib/python3.9/site-packages/transformers/modeling_utils.py:3278,\
          \ in PreTrainedModel._load_pretrained_model(cls, model, state_dict, loaded_keys,\
          \ resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes,\
          \ sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder,\
          \ offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\r\n   3274\
          \     if \"size mismatch\" in error_msg:\r\n   3275         error_msg +=\
          \ (\r\n   3276             \"\\n\\tYou may consider adding `ignore_mismatched_sizes=True`\
          \ in the model `from_pretrained` method.\"\r\n   3277         )\r\n-> 3278\
          \     raise RuntimeError(f\"Error(s) in loading state_dict for {model.__class__.__name__}:\\\
          n\\t{error_msg}\")\r\n   3280 if is_quantized:\r\n   3281     unexpected_keys\
          \ = [elem for elem in unexpected_keys if \"SCB\" not in elem]\r\n\r\nRuntimeError:\
          \ Error(s) in loading state_dict for CLIPModel:\r\n        size mismatch\
          \ for vision_model.embeddings.position_ids: copying a param with shape torch.Size([1,\
          \ 577]) from checkpoint, the shape in current model is torch.Size([1, 257]).\r\
          \n        size mismatch for vision_model.embeddings.position_embedding.weight:\
          \ copying a param with shape torch.Size([577, 1024]) from checkpoint, the\
          \ shape in current model is torch.Size([257, 1024]).\r\n        You may\
          \ consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained`\
          \ method.\r\n```\r\n\r\nRunning with `ignore_mismatched_sizes` succeeds\
          \ but many weights not being used or being freshly initialised. This is\
          \ likely not correct.\r\n\r\nIt would be nice if we could instantiate the\
          \ model using `from_pretrained` without error.\r\n\r\nThanks~"
        updatedAt: '2023-10-30T13:09:04.027Z'
      numEdits: 0
      reactions: []
    id: 653faaf0f0ae890814896241
    type: comment
  author: afmck
  content: "Trying to load the model currently fails:\r\n```\r\nIn [6]: model = CLIPModel.from_pretrained(\"\
    LanguageBind/LanguageBind_Audio\")\r\nYou are using a model of type LanguageBindAudio\
    \ to instantiate a model of type clip. This is not supported for all configurations\
    \ of models and can yield errors.\r\n---------------------------------------------------------------------------\r\
    \nRuntimeError                              Traceback (most recent call last)\r\
    \nCell In[6], line 1\r\n----> 1 model = CLIPModel.from_pretrained(\"LanguageBind/LanguageBind_Audio\"\
    )\r\n\r\nFile /..../miniconda3/envs/LanguageBind/lib/python3.9/site-packages/transformers/modeling_utils.py:2881,\
    \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, *model_args,\
    \ **kwargs)\r\n   2871     if dtype_orig is not None:\r\n   2872         torch.set_default_dtype(dtype_orig)\r\
    \n   2874     (\r\n   2875         model,\r\n   2876         missing_keys,\r\n\
    \   2877         unexpected_keys,\r\n   2878         mismatched_keys,\r\n   2879\
    \         offload_index,\r\n   2880         error_msgs,\r\n-> 2881     ) = cls._load_pretrained_model(\r\
    \n   2882         model,\r\n   2883         state_dict,\r\n   2884         loaded_state_dict_keys,\
    \  # XXX: rename?\r\n   2885         resolved_archive_file,\r\n   2886       \
    \  pretrained_model_name_or_path,\r\n   2887         ignore_mismatched_sizes=ignore_mismatched_sizes,\r\
    \n   2888         sharded_metadata=sharded_metadata,\r\n   2889         _fast_init=_fast_init,\r\
    \n   2890         low_cpu_mem_usage=low_cpu_mem_usage,\r\n   2891         device_map=device_map,\r\
    \n   2892         offload_folder=offload_folder,\r\n   2893         offload_state_dict=offload_state_dict,\r\
    \n   2894         dtype=torch_dtype,\r\n   2895         is_quantized=(load_in_8bit\
    \ or load_in_4bit),\r\n   2896         keep_in_fp32_modules=keep_in_fp32_modules,\r\
    \n   2897     )\r\n   2899 model.is_loaded_in_4bit = load_in_4bit\r\n   2900 model.is_loaded_in_8bit\
    \ = load_in_8bit\r\n\r\nFile /..../miniconda3/envs/LanguageBind/lib/python3.9/site-packages/transformers/modeling_utils.py:3278,\
    \ in PreTrainedModel._load_pretrained_model(cls, model, state_dict, loaded_keys,\
    \ resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes,\
    \ sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder,\
    \ offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\r\n   3274  \
    \   if \"size mismatch\" in error_msg:\r\n   3275         error_msg += (\r\n \
    \  3276             \"\\n\\tYou may consider adding `ignore_mismatched_sizes=True`\
    \ in the model `from_pretrained` method.\"\r\n   3277         )\r\n-> 3278   \
    \  raise RuntimeError(f\"Error(s) in loading state_dict for {model.__class__.__name__}:\\\
    n\\t{error_msg}\")\r\n   3280 if is_quantized:\r\n   3281     unexpected_keys\
    \ = [elem for elem in unexpected_keys if \"SCB\" not in elem]\r\n\r\nRuntimeError:\
    \ Error(s) in loading state_dict for CLIPModel:\r\n        size mismatch for vision_model.embeddings.position_ids:\
    \ copying a param with shape torch.Size([1, 577]) from checkpoint, the shape in\
    \ current model is torch.Size([1, 257]).\r\n        size mismatch for vision_model.embeddings.position_embedding.weight:\
    \ copying a param with shape torch.Size([577, 1024]) from checkpoint, the shape\
    \ in current model is torch.Size([257, 1024]).\r\n        You may consider adding\
    \ `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\r\n```\r\
    \n\r\nRunning with `ignore_mismatched_sizes` succeeds but many weights not being\
    \ used or being freshly initialised. This is likely not correct.\r\n\r\nIt would\
    \ be nice if we could instantiate the model using `from_pretrained` without error.\r\
    \n\r\nThanks~"
  created_at: 2023-10-30 12:09:04+00:00
  edited: false
  hidden: false
  id: 653faaf0f0ae890814896241
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0527137d7cb649a96e9856940cf21a5.svg
      fullname: linbin
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LanguageBind
      type: user
    createdAt: '2023-10-31T10:53:18.000Z'
    data:
      edited: true
      editors:
      - LanguageBind
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7488909363746643
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0527137d7cb649a96e9856940cf21a5.svg
          fullname: linbin
          isHf: false
          isPro: false
          name: LanguageBind
          type: user
        html: '<p>You can try by following <a rel="nofollow" href="https://github.com/PKU-YuanGroup/LanguageBind#different-branches-for-x-language-task">this</a>.<br>Feel
          free to tell me if it run or not.</p>

          '
        raw: 'You can try by following [this](https://github.com/PKU-YuanGroup/LanguageBind#different-branches-for-x-language-task).

          Feel free to tell me if it run or not.'
        updatedAt: '2023-10-31T10:56:41.313Z'
      numEdits: 3
      reactions: []
      relatedEventId: 6540dc9e1579bd6b098ac1f9
    id: 6540dc9e1579bd6b098ac1f8
    type: comment
  author: LanguageBind
  content: 'You can try by following [this](https://github.com/PKU-YuanGroup/LanguageBind#different-branches-for-x-language-task).

    Feel free to tell me if it run or not.'
  created_at: 2023-10-31 09:53:18+00:00
  edited: true
  hidden: false
  id: 6540dc9e1579bd6b098ac1f8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/e0527137d7cb649a96e9856940cf21a5.svg
      fullname: linbin
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LanguageBind
      type: user
    createdAt: '2023-10-31T10:53:18.000Z'
    data:
      status: closed
    id: 6540dc9e1579bd6b098ac1f9
    type: status-change
  author: LanguageBind
  created_at: 2023-10-31 09:53:18+00:00
  id: 6540dc9e1579bd6b098ac1f9
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666128776959-6079e94c88160e14e4e2e4b1.jpeg?w=200&h=200&f=face
      fullname: Alex McKinney
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: afmck
      type: user
    createdAt: '2023-11-01T11:18:24.000Z'
    data:
      edited: false
      editors:
      - afmck
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9385380744934082
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666128776959-6079e94c88160e14e4e2e4b1.jpeg?w=200&h=200&f=face
          fullname: Alex McKinney
          isHf: false
          isPro: false
          name: afmck
          type: user
        html: '<p>Yes that works, but the config in this repo indicates that the weights
          and config should be usable by <code>CLIPModel</code>. Is this not the case?</p>

          '
        raw: Yes that works, but the config in this repo indicates that the weights
          and config should be usable by `CLIPModel`. Is this not the case?
        updatedAt: '2023-11-01T11:18:24.599Z'
      numEdits: 0
      reactions: []
      relatedEventId: 654234006dcda08a6dd7b47b
    id: 654234006dcda08a6dd7b478
    type: comment
  author: afmck
  content: Yes that works, but the config in this repo indicates that the weights
    and config should be usable by `CLIPModel`. Is this not the case?
  created_at: 2023-11-01 10:18:24+00:00
  edited: false
  hidden: false
  id: 654234006dcda08a6dd7b478
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666128776959-6079e94c88160e14e4e2e4b1.jpeg?w=200&h=200&f=face
      fullname: Alex McKinney
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: afmck
      type: user
    createdAt: '2023-11-01T11:18:24.000Z'
    data:
      status: open
    id: 654234006dcda08a6dd7b47b
    type: status-change
  author: afmck
  created_at: 2023-11-01 10:18:24+00:00
  id: 654234006dcda08a6dd7b47b
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0527137d7cb649a96e9856940cf21a5.svg
      fullname: linbin
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LanguageBind
      type: user
    createdAt: '2023-11-01T11:50:12.000Z'
    data:
      edited: false
      editors:
      - LanguageBind
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9385268092155457
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0527137d7cb649a96e9856940cf21a5.svg
          fullname: linbin
          isHf: false
          isPro: false
          name: LanguageBind
          type: user
        html: '<blockquote>

          <p>Yes that works, but the config in this repo indicates that the weights
          and config should be usable by <code>CLIPModel</code>. Is this not the case?</p>

          </blockquote>

          <p>That''s typo. We will release a stronger audio model and fix it.</p>

          '
        raw: '> Yes that works, but the config in this repo indicates that the weights
          and config should be usable by `CLIPModel`. Is this not the case?


          That''s typo. We will release a stronger audio model and fix it.'
        updatedAt: '2023-11-01T11:50:12.208Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - afmck
    id: 65423b74b0170e9607032b65
    type: comment
  author: LanguageBind
  content: '> Yes that works, but the config in this repo indicates that the weights
    and config should be usable by `CLIPModel`. Is this not the case?


    That''s typo. We will release a stronger audio model and fix it.'
  created_at: 2023-11-01 10:50:12+00:00
  edited: false
  hidden: false
  id: 65423b74b0170e9607032b65
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666128776959-6079e94c88160e14e4e2e4b1.jpeg?w=200&h=200&f=face
      fullname: Alex McKinney
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: afmck
      type: user
    createdAt: '2023-11-01T13:00:53.000Z'
    data:
      edited: false
      editors:
      - afmck
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9124757647514343
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666128776959-6079e94c88160e14e4e2e4b1.jpeg?w=200&h=200&f=face
          fullname: Alex McKinney
          isHf: false
          isPro: false
          name: afmck
          type: user
        html: '<p>Nice thanks, could you share more details about this stronger model?</p>

          '
        raw: Nice thanks, could you share more details about this stronger model?
        updatedAt: '2023-11-01T13:00:53.173Z'
      numEdits: 0
      reactions: []
    id: 65424c0555ded3e093add35c
    type: comment
  author: afmck
  content: Nice thanks, could you share more details about this stronger model?
  created_at: 2023-11-01 12:00:53+00:00
  edited: false
  hidden: false
  id: 65424c0555ded3e093add35c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0527137d7cb649a96e9856940cf21a5.svg
      fullname: linbin
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LanguageBind
      type: user
    createdAt: '2023-11-04T05:38:55.000Z'
    data:
      edited: false
      editors:
      - LanguageBind
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9059945344924927
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0527137d7cb649a96e9856940cf21a5.svg
          fullname: linbin
          isHf: false
          isPro: false
          name: LanguageBind
          type: user
        html: '<blockquote>

          <p>Nice thanks, could you share more details about this stronger model?</p>

          </blockquote>

          <p>We have released the stronger model, the results can be found <a rel="nofollow"
          href="https://github.com/PKU-YuanGroup/LanguageBind/tree/main#multiple-modalities">here</a>.<br>The
          checkpoint also has updated!</p>

          '
        raw: '> Nice thanks, could you share more details about this stronger model?


          We have released the stronger model, the results can be found [here](https://github.com/PKU-YuanGroup/LanguageBind/tree/main#multiple-modalities).

          The checkpoint also has updated!'
        updatedAt: '2023-11-04T05:38:55.739Z'
      numEdits: 0
      reactions: []
    id: 6545d8efc6dadd513ff1b4fd
    type: comment
  author: LanguageBind
  content: '> Nice thanks, could you share more details about this stronger model?


    We have released the stronger model, the results can be found [here](https://github.com/PKU-YuanGroup/LanguageBind/tree/main#multiple-modalities).

    The checkpoint also has updated!'
  created_at: 2023-11-04 04:38:55+00:00
  edited: false
  hidden: false
  id: 6545d8efc6dadd513ff1b4fd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: LanguageBind/LanguageBind_Audio
repo_type: model
status: open
target_branch: null
title: Cannot instantiate using `from_pretrained`
