!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ede-CH
conflicting_files: null
created_at: 2023-06-05 10:04:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f3c28ccfdcd612d4afb104439f41dc3d.svg
      fullname: Bourn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ede-CH
      type: user
    createdAt: '2023-06-05T11:04:42.000Z'
    data:
      edited: false
      editors:
      - Ede-CH
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9216851592063904
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f3c28ccfdcd612d4afb104439f41dc3d.svg
          fullname: Bourn
          isHf: false
          isPro: false
          name: Ede-CH
          type: user
        html: '<p>Can you provide the script of splitting original tensors into 8
          shards?</p>

          '
        raw: Can you provide the script of splitting original tensors into 8 shards?
        updatedAt: '2023-06-05T11:04:42.965Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - RobertKe
    id: 647dc14ae4d52fe0e01c46fe
    type: comment
  author: Ede-CH
  content: Can you provide the script of splitting original tensors into 8 shards?
  created_at: 2023-06-05 10:04:42+00:00
  edited: false
  hidden: false
  id: 647dc14ae4d52fe0e01c46fe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3c8589b68a942b4afd54df2ae4b96336.svg
      fullname: Tingchen Fu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TingchenFu
      type: user
    createdAt: '2023-06-19T14:26:59.000Z'
    data:
      edited: false
      editors:
      - TingchenFu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6766712069511414
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3c8589b68a942b4afd54df2ae4b96336.svg
          fullname: Tingchen Fu
          isHf: false
          isPro: false
          name: TingchenFu
          type: user
        html: '<p>If you want to perform inference, you can directly assign mp_size
          = 8 as a parameter of deepspeed.init_inference().</p>

          '
        raw: If you want to perform inference, you can directly assign mp_size = 8
          as a parameter of deepspeed.init_inference().
        updatedAt: '2023-06-19T14:26:59.455Z'
      numEdits: 0
      reactions: []
    id: 649065b3231a197da75d05a6
    type: comment
  author: TingchenFu
  content: If you want to perform inference, you can directly assign mp_size = 8 as
    a parameter of deepspeed.init_inference().
  created_at: 2023-06-19 13:26:59+00:00
  edited: false
  hidden: false
  id: 649065b3231a197da75d05a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f3c28ccfdcd612d4afb104439f41dc3d.svg
      fullname: Bourn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ede-CH
      type: user
    createdAt: '2023-07-04T07:13:15.000Z'
    data:
      edited: false
      editors:
      - Ede-CH
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9676087498664856
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f3c28ccfdcd612d4afb104439f41dc3d.svg
          fullname: Bourn
          isHf: false
          isPro: false
          name: Ede-CH
          type: user
        html: '<p>Thanks for your reply! According to my understanding, this parameter
          divides the model weights into eight parts based on tensor parallelism (TP)
          after loading the model weights. However, since the model weights have not
          been previously sharded based on TP, the loading time can be quite long.
          In the weight files provided by you, each file only saves a portion of the
          matrix, allowing for direct loading. Could you please provide the script
          for pre-sharding the weights?</p>

          '
        raw: Thanks for your reply! According to my understanding, this parameter
          divides the model weights into eight parts based on tensor parallelism (TP)
          after loading the model weights. However, since the model weights have not
          been previously sharded based on TP, the loading time can be quite long.
          In the weight files provided by you, each file only saves a portion of the
          matrix, allowing for direct loading. Could you please provide the script
          for pre-sharding the weights?
        updatedAt: '2023-07-04T07:13:15.440Z'
      numEdits: 0
      reactions: []
    id: 64a3c68b67abe0e3d35d8946
    type: comment
  author: Ede-CH
  content: Thanks for your reply! According to my understanding, this parameter divides
    the model weights into eight parts based on tensor parallelism (TP) after loading
    the model weights. However, since the model weights have not been previously sharded
    based on TP, the loading time can be quite long. In the weight files provided
    by you, each file only saves a portion of the matrix, allowing for direct loading.
    Could you please provide the script for pre-sharding the weights?
  created_at: 2023-07-04 06:13:15+00:00
  edited: false
  hidden: false
  id: 64a3c68b67abe0e3d35d8946
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: microsoft/bloom-deepspeed-inference-fp16
repo_type: model
status: open
target_branch: null
title: How to split tensors to x shards?
