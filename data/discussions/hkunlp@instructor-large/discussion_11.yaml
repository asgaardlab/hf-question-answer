!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rasharab
conflicting_files: null
created_at: 2023-06-28 22:10:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ce8e4c34cac01be15adcd62bad957996.svg
      fullname: Rashin Ramazanarab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rasharab
      type: user
    createdAt: '2023-06-28T23:10:48.000Z'
    data:
      edited: false
      editors:
      - rasharab
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8598231673240662
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ce8e4c34cac01be15adcd62bad957996.svg
          fullname: Rashin Ramazanarab
          isHf: false
          isPro: false
          name: rasharab
          type: user
        html: '<p>Can someone tell me what the maximum input token size for the instructor
          model?<br>I know for ada, I believe it''s 8k.</p>

          '
        raw: "Can someone tell me what the maximum input token size for the instructor\
          \ model?\r\nI know for ada, I believe it's 8k."
        updatedAt: '2023-06-28T23:10:48.759Z'
      numEdits: 0
      reactions: []
    id: 649cbdf85bfecefaf1859e00
    type: comment
  author: rasharab
  content: "Can someone tell me what the maximum input token size for the instructor\
    \ model?\r\nI know for ada, I believe it's 8k."
  created_at: 2023-06-28 22:10:48+00:00
  edited: false
  hidden: false
  id: 649cbdf85bfecefaf1859e00
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b7d0a895e669bcd1303c4716b5401c36.svg
      fullname: Hongjin SU
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: multi-train
      type: user
    createdAt: '2023-07-02T12:53:59.000Z'
    data:
      edited: false
      editors:
      - multi-train
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6265053749084473
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b7d0a895e669bcd1303c4716b5401c36.svg
          fullname: Hongjin SU
          isHf: false
          isPro: false
          name: multi-train
          type: user
        html: '<p>The default maximum length for the INSTRUCTOR model is 512.</p>

          '
        raw: The default maximum length for the INSTRUCTOR model is 512.
        updatedAt: '2023-07-02T12:53:59.078Z'
      numEdits: 0
      reactions: []
    id: 64a173674d55bc91b1c50db8
    type: comment
  author: multi-train
  content: The default maximum length for the INSTRUCTOR model is 512.
  created_at: 2023-07-02 11:53:59+00:00
  edited: false
  hidden: false
  id: 64a173674d55bc91b1c50db8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63cb7b071b705cc951ea5b82/_fQ7Z7brwF7fXcoADvY88.jpeg?w=200&h=200&f=face
      fullname: LeMoussel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LeMoussel
      type: user
    createdAt: '2023-07-13T09:04:18.000Z'
    data:
      edited: true
      editors:
      - LeMoussel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7893929481506348
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63cb7b071b705cc951ea5b82/_fQ7Z7brwF7fXcoADvY88.jpeg?w=200&h=200&f=face
          fullname: LeMoussel
          isHf: false
          isPro: false
          name: LeMoussel
          type: user
        html: '<pre><code class="language-python"><span class="hljs-keyword">from</span>
          InstructorEmbedding <span class="hljs-keyword">import</span> INSTRUCTOR

          model = INSTRUCTOR(<span class="hljs-string">''hkunlp/instructor-large''</span>)

          sentence = <span class="hljs-string">"3D ActionSLAM: wearable person tracking
          in multi-floor environments"</span>

          instruction = <span class="hljs-string">"Represent the Science title:"</span>

          embeddings = model.encode([[instruction,sentence]])

          <span class="hljs-built_in">print</span>(embeddings)

          </code></pre>

          <p>Does this mean that the maximum length of <code>sentence</code>must not
          exceed 512 characters?<br>If so, should <code>sentence</code>be cut for
          every 512 tokens chunk ?</p>

          '
        raw: '```python

          from InstructorEmbedding import INSTRUCTOR

          model = INSTRUCTOR(''hkunlp/instructor-large'')

          sentence = "3D ActionSLAM: wearable person tracking in multi-floor environments"

          instruction = "Represent the Science title:"

          embeddings = model.encode([[instruction,sentence]])

          print(embeddings)

          ```

          Does this mean that the maximum length of `sentence`must not exceed 512
          characters?

          If so, should `sentence`be cut for every 512 tokens chunk ?

          '
        updatedAt: '2023-08-08T08:30:16.139Z'
      numEdits: 1
      reactions: []
    id: 64afbe125e0cf007b1a93f56
    type: comment
  author: LeMoussel
  content: '```python

    from InstructorEmbedding import INSTRUCTOR

    model = INSTRUCTOR(''hkunlp/instructor-large'')

    sentence = "3D ActionSLAM: wearable person tracking in multi-floor environments"

    instruction = "Represent the Science title:"

    embeddings = model.encode([[instruction,sentence]])

    print(embeddings)

    ```

    Does this mean that the maximum length of `sentence`must not exceed 512 characters?

    If so, should `sentence`be cut for every 512 tokens chunk ?

    '
  created_at: 2023-07-13 08:04:18+00:00
  edited: true
  hidden: false
  id: 64afbe125e0cf007b1a93f56
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b7d0a895e669bcd1303c4716b5401c36.svg
      fullname: Hongjin SU
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: multi-train
      type: user
    createdAt: '2023-07-22T10:31:39.000Z'
    data:
      edited: false
      editors:
      - multi-train
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9469751119613647
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b7d0a895e669bcd1303c4716b5401c36.svg
          fullname: Hongjin SU
          isHf: false
          isPro: false
          name: multi-train
          type: user
        html: '<p>Yes, it is recommended that the maximum length is under 512, and
          you can split texts into chunks for long documents</p>

          '
        raw: Yes, it is recommended that the maximum length is under 512, and you
          can split texts into chunks for long documents
        updatedAt: '2023-07-22T10:31:39.859Z'
      numEdits: 0
      reactions: []
    id: 64bbb00bae436c8813e97f54
    type: comment
  author: multi-train
  content: Yes, it is recommended that the maximum length is under 512, and you can
    split texts into chunks for long documents
  created_at: 2023-07-22 09:31:39+00:00
  edited: false
  hidden: false
  id: 64bbb00bae436c8813e97f54
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a36afadc530a6936e9e336a729f7ecf3.svg
      fullname: Jon Watte
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jwatte
      type: user
    createdAt: '2023-07-27T15:44:05.000Z'
    data:
      edited: false
      editors:
      - jwatte
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9744215607643127
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a36afadc530a6936e9e336a729f7ecf3.svg
          fullname: Jon Watte
          isHf: false
          isPro: false
          name: jwatte
          type: user
        html: '<p>512 is "tokens" not "characters," right?</p>

          '
        raw: 512 is "tokens" not "characters," right?
        updatedAt: '2023-07-27T15:44:05.021Z'
      numEdits: 0
      reactions: []
    id: 64c290c5c306e264883f0fd2
    type: comment
  author: jwatte
  content: 512 is "tokens" not "characters," right?
  created_at: 2023-07-27 14:44:05+00:00
  edited: false
  hidden: false
  id: 64c290c5c306e264883f0fd2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63cb7b071b705cc951ea5b82/_fQ7Z7brwF7fXcoADvY88.jpeg?w=200&h=200&f=face
      fullname: LeMoussel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LeMoussel
      type: user
    createdAt: '2023-08-08T08:29:51.000Z'
    data:
      edited: false
      editors:
      - LeMoussel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7308841943740845
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63cb7b071b705cc951ea5b82/_fQ7Z7brwF7fXcoADvY88.jpeg?w=200&h=200&f=face
          fullname: LeMoussel
          isHf: false
          isPro: false
          name: LeMoussel
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;jwatte&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jwatte\">@<span class=\"\
          underline\">jwatte</span></a></span>\n\n\t</span></span> Yes!</p>\n<p>Language\
          \ models have a token limit. You should not exceed the token limit.<br>You\
          \ can split your text into chunks. It is therefore a good idea to count\
          \ the number of tokens.<br>See:  <a rel=\"nofollow\" href=\"https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/split_by_token\"\
          >LangChain - Split by tokens</a></p>\n"
        raw: "@jwatte Yes!\n\nLanguage models have a token limit. You should not exceed\
          \ the token limit. \nYou can split your text into chunks. It is therefore\
          \ a good idea to count the number of tokens. \nSee:  [LangChain - Split\
          \ by tokens](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/split_by_token)"
        updatedAt: '2023-08-08T08:29:51.188Z'
      numEdits: 0
      reactions: []
    id: 64d1fcff228324a28b1dda81
    type: comment
  author: LeMoussel
  content: "@jwatte Yes!\n\nLanguage models have a token limit. You should not exceed\
    \ the token limit. \nYou can split your text into chunks. It is therefore a good\
    \ idea to count the number of tokens. \nSee:  [LangChain - Split by tokens](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/split_by_token)"
  created_at: 2023-08-08 07:29:51+00:00
  edited: false
  hidden: false
  id: 64d1fcff228324a28b1dda81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3e0c7cb70858d40b5cb63286a1138661.svg
      fullname: "Oskari Nihtil\xE4"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: oskarini
      type: user
    createdAt: '2023-11-04T14:11:37.000Z'
    data:
      edited: true
      editors:
      - oskarini
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9024209976196289
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3e0c7cb70858d40b5cb63286a1138661.svg
          fullname: "Oskari Nihtil\xE4"
          isHf: false
          isPro: false
          name: oskarini
          type: user
        html: '<p>Hello!</p>

          <p>If I want to create one embedding for a longer document, what is the
          proposed way to do it? </p>

          <p>Would it be to embed multiple chunks of 512 tokens and then take the
          average of the resulting embedding vectors?</p>

          '
        raw: "Hello!\n \nIf I want to create one embedding for a longer document,\
          \ what is the proposed way to do it? \n\nWould it be to embed multiple chunks\
          \ of 512 tokens and then take the average of the resulting embedding vectors?"
        updatedAt: '2023-11-04T15:15:24.153Z'
      numEdits: 1
      reactions: []
    id: 65465119a877ee9a50e30b9c
    type: comment
  author: oskarini
  content: "Hello!\n \nIf I want to create one embedding for a longer document, what\
    \ is the proposed way to do it? \n\nWould it be to embed multiple chunks of 512\
    \ tokens and then take the average of the resulting embedding vectors?"
  created_at: 2023-11-04 13:11:37+00:00
  edited: true
  hidden: false
  id: 65465119a877ee9a50e30b9c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63cb7b071b705cc951ea5b82/_fQ7Z7brwF7fXcoADvY88.jpeg?w=200&h=200&f=face
      fullname: LeMoussel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LeMoussel
      type: user
    createdAt: '2024-01-14T07:40:08.000Z'
    data:
      edited: false
      editors:
      - LeMoussel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.41981273889541626
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63cb7b071b705cc951ea5b82/_fQ7Z7brwF7fXcoADvY88.jpeg?w=200&h=200&f=face
          fullname: LeMoussel
          isHf: false
          isPro: false
          name: LeMoussel
          type: user
        html: '<p>See <a rel="nofollow" href="https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5">Evaluating
          the Ideal Chunk Size for a RAG System using LlamaIndex</a>.<br>This blog
          post explains the steps to determine the best fragment size using LlamaIndex''s
          <code>Response Evaluation</code> module.</p>

          '
        raw: "See [Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex](https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5).\
          \ \nThis blog post explains the steps to determine the best fragment size\
          \ using LlamaIndex's `Response Evaluation` module.\n"
        updatedAt: '2024-01-14T07:40:08.670Z'
      numEdits: 0
      reactions: []
    id: 65a38fd8895d1eca731653aa
    type: comment
  author: LeMoussel
  content: "See [Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex](https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5).\
    \ \nThis blog post explains the steps to determine the best fragment size using\
    \ LlamaIndex's `Response Evaluation` module.\n"
  created_at: 2024-01-14 07:40:08+00:00
  edited: false
  hidden: false
  id: 65a38fd8895d1eca731653aa
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: hkunlp/instructor-large
repo_type: model
status: open
target_branch: null
title: Maximum token size?
