!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nlpdev3
conflicting_files: null
created_at: 2023-06-29 23:21:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d043030a81fe1b6e0b7092030f0725a.svg
      fullname: TT
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nlpdev3
      type: user
    createdAt: '2023-06-30T00:21:59.000Z'
    data:
      edited: false
      editors:
      - nlpdev3
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8592132329940796
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d043030a81fe1b6e0b7092030f0725a.svg
          fullname: TT
          isHf: false
          isPro: false
          name: nlpdev3
          type: user
        html: '<p>How to finetune with multiple GPUs? </p>

          '
        raw: 'How to finetune with multiple GPUs? '
        updatedAt: '2023-06-30T00:21:59.066Z'
      numEdits: 0
      reactions: []
    id: 649e20270068a3930ec397d2
    type: comment
  author: nlpdev3
  content: 'How to finetune with multiple GPUs? '
  created_at: 2023-06-29 23:21:59+00:00
  edited: false
  hidden: false
  id: 649e20270068a3930ec397d2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b7d0a895e669bcd1303c4716b5401c36.svg
      fullname: Hongjin SU
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: multi-train
      type: user
    createdAt: '2023-07-02T12:52:41.000Z'
    data:
      edited: false
      editors:
      - multi-train
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4975428879261017
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b7d0a895e669bcd1303c4716b5401c36.svg
          fullname: Hongjin SU
          isHf: false
          isPro: false
          name: multi-train
          type: user
        html: '<p>Hi, Thanks a lot for your interests in the INSTRUCTOR!</p>

          <p>The following script should use all the available GPUs to finetune models:</p>

          <pre><code>python train.py --model_name_or_path sentence-transformers/gtr-t5-large
          --output_dir {output_directory} --cache_dir {cache_directory} --max_source_length
          512 --num_train_epochs 10 --save_steps 500 --cl_temperature 0.01 --warmup_ratio
          0.1 --learning_rate 2e-5 --overwrite_output_dir

          </code></pre>

          <p>You may also specify the GPUs by using CUDA_VISIBLE_DEVICE=GPU_ids.</p>

          <p>For more details, you may refer to <a rel="nofollow" href="https://github.com/HKUNLP/instructor-embedding#train-instructor">training
          instructions</a></p>

          '
        raw: 'Hi, Thanks a lot for your interests in the INSTRUCTOR!


          The following script should use all the available GPUs to finetune models:

          ```

          python train.py --model_name_or_path sentence-transformers/gtr-t5-large
          --output_dir {output_directory} --cache_dir {cache_directory} --max_source_length
          512 --num_train_epochs 10 --save_steps 500 --cl_temperature 0.01 --warmup_ratio
          0.1 --learning_rate 2e-5 --overwrite_output_dir

          ```

          You may also specify the GPUs by using CUDA_VISIBLE_DEVICE=GPU_ids.


          For more details, you may refer to [training instructions](https://github.com/HKUNLP/instructor-embedding#train-instructor)'
        updatedAt: '2023-07-02T12:52:41.038Z'
      numEdits: 0
      reactions: []
    id: 64a17319ca9d12304c10d20e
    type: comment
  author: multi-train
  content: 'Hi, Thanks a lot for your interests in the INSTRUCTOR!


    The following script should use all the available GPUs to finetune models:

    ```

    python train.py --model_name_or_path sentence-transformers/gtr-t5-large --output_dir
    {output_directory} --cache_dir {cache_directory} --max_source_length 512 --num_train_epochs
    10 --save_steps 500 --cl_temperature 0.01 --warmup_ratio 0.1 --learning_rate 2e-5
    --overwrite_output_dir

    ```

    You may also specify the GPUs by using CUDA_VISIBLE_DEVICE=GPU_ids.


    For more details, you may refer to [training instructions](https://github.com/HKUNLP/instructor-embedding#train-instructor)'
  created_at: 2023-07-02 11:52:41+00:00
  edited: false
  hidden: false
  id: 64a17319ca9d12304c10d20e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/4d043030a81fe1b6e0b7092030f0725a.svg
      fullname: TT
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nlpdev3
      type: user
    createdAt: '2023-07-03T04:48:58.000Z'
    data:
      status: closed
    id: 64a2533adcecd07271433d0c
    type: status-change
  author: nlpdev3
  created_at: 2023-07-03 03:48:58+00:00
  id: 64a2533adcecd07271433d0c
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: hkunlp/instructor-large
repo_type: model
status: closed
target_branch: null
title: How to finetune with multiple GPUs
