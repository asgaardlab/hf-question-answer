!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Luning-Yang
conflicting_files: null
created_at: 2023-05-01 15:42:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dd0a8bcaba2affc145c148f75125fb48.svg
      fullname: Luning Yang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Luning-Yang
      type: user
    createdAt: '2023-05-01T16:42:50.000Z'
    data:
      edited: false
      editors:
      - Luning-Yang
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dd0a8bcaba2affc145c148f75125fb48.svg
          fullname: Luning Yang
          isHf: false
          isPro: false
          name: Luning-Yang
          type: user
        html: '<p>I''m try to encode a massive amount of data using instructor. Here
          is what I did:</p>

          <pre><code>import torch

          from transformers import AutoTokenizer

          from InstructorEmbedding import INSTRUCTOR


          device = torch.device(''cuda'' if torch.cuda.is_available() else ''cpu'')


          model = INSTRUCTOR(''hkunlp/instructor-large'').to(device)

          tokenizer = AutoTokenizer.from_pretrained(''hkunlp/instructor-large'')

          </code></pre>

          <p>However, I don''t know how to properly convert the input data into tensors
          in order to use GPU for encoding. Could you elaborate on this?</p>

          '
        raw: "I'm try to encode a massive amount of data using instructor. Here is\
          \ what I did:\r\n```\r\nimport torch\r\nfrom transformers import AutoTokenizer\r\
          \nfrom InstructorEmbedding import INSTRUCTOR\r\n\r\ndevice = torch.device('cuda'\
          \ if torch.cuda.is_available() else 'cpu')\r\n\r\nmodel = INSTRUCTOR('hkunlp/instructor-large').to(device)\r\
          \ntokenizer = AutoTokenizer.from_pretrained('hkunlp/instructor-large')\r\
          \n```\r\nHowever, I don't know how to properly convert the input data into\
          \ tensors in order to use GPU for encoding. Could you elaborate on this?"
        updatedAt: '2023-05-01T16:42:50.854Z'
      numEdits: 0
      reactions: []
    id: 644fec0a55932790bc84fac0
    type: comment
  author: Luning-Yang
  content: "I'm try to encode a massive amount of data using instructor. Here is what\
    \ I did:\r\n```\r\nimport torch\r\nfrom transformers import AutoTokenizer\r\n\
    from InstructorEmbedding import INSTRUCTOR\r\n\r\ndevice = torch.device('cuda'\
    \ if torch.cuda.is_available() else 'cpu')\r\n\r\nmodel = INSTRUCTOR('hkunlp/instructor-large').to(device)\r\
    \ntokenizer = AutoTokenizer.from_pretrained('hkunlp/instructor-large')\r\n```\r\
    \nHowever, I don't know how to properly convert the input data into tensors in\
    \ order to use GPU for encoding. Could you elaborate on this?"
  created_at: 2023-05-01 15:42:50+00:00
  edited: false
  hidden: false
  id: 644fec0a55932790bc84fac0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b7d0a895e669bcd1303c4716b5401c36.svg
      fullname: Hongjin SU
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: multi-train
      type: user
    createdAt: '2023-05-16T11:20:05.000Z'
    data:
      edited: false
      editors:
      - multi-train
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b7d0a895e669bcd1303c4716b5401c36.svg
          fullname: Hongjin SU
          isHf: false
          isPro: false
          name: multi-train
          type: user
        html: '<p>Hi, Thanks a lot for your interest in the INSTRUCTOR model!</p>

          <p>You may need to move both models and encoding texts to the GPU.</p>

          <p>Feel free to add any questions or comments!</p>

          '
        raw: 'Hi, Thanks a lot for your interest in the INSTRUCTOR model!


          You may need to move both models and encoding texts to the GPU.


          Feel free to add any questions or comments!'
        updatedAt: '2023-05-16T11:20:05.836Z'
      numEdits: 0
      reactions: []
    id: 646366e5c758f942090a97a4
    type: comment
  author: multi-train
  content: 'Hi, Thanks a lot for your interest in the INSTRUCTOR model!


    You may need to move both models and encoding texts to the GPU.


    Feel free to add any questions or comments!'
  created_at: 2023-05-16 10:20:05+00:00
  edited: false
  hidden: false
  id: 646366e5c758f942090a97a4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: hkunlp/instructor-large
repo_type: model
status: open
target_branch: null
title: Doing the encoding using GPU
