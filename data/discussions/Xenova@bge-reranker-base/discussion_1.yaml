!!python/object:huggingface_hub.community.DiscussionWithDetails
author: brunnolou
conflicting_files: null
created_at: 2023-10-24 11:21:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/65256343a9f5b404762da984/d2af1wi3ej385qN5Q18P6.png?w=200&h=200&f=face
      fullname: Bruno
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brunnolou
      type: user
    createdAt: '2023-10-24T12:21:28.000Z'
    data:
      edited: false
      editors:
      - brunnolou
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7057400941848755
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/65256343a9f5b404762da984/d2af1wi3ej385qN5Q18P6.png?w=200&h=200&f=face
          fullname: Bruno
          isHf: false
          isPro: false
          name: brunnolou
          type: user
        html: "<pre><code class=\"language-ts\"><span class=\"hljs-comment\">// npm\
          \ i <span data-props=\"{&quot;user&quot;:&quot;xenova&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/xenova\">@<span class=\"\
          underline\">xenova</span></a></span>\n\n\t</span></span>/transformers</span>\n\
          <span class=\"hljs-keyword\">import</span> { pipeline } <span class=\"hljs-keyword\"\
          >from</span> <span class=\"hljs-string\">'@xenova/transformers'</span>;\n\
          \n<span class=\"hljs-comment\">// Allocate pipeline</span>\n<span class=\"\
          hljs-keyword\">const</span> reranker = <span class=\"hljs-keyword\">await</span>\
          \ <span class=\"hljs-title function_\">pipeline</span>(<span class=\"hljs-string\"\
          >'text-classification'</span>, <span class=\"hljs-string\">'Xenova/bge-reranker-base'</span>);\n\
          </code></pre>\n<p>I've tried: </p>\n<pre><code class=\"language-ts\"><span\
          \ class=\"hljs-keyword\">const</span> score = <span class=\"hljs-keyword\"\
          >await</span> <span class=\"hljs-title function_\">rerank</span>([\n  <span\
          \ class=\"hljs-string\">\"I love you. I like you\"</span>,\n  <span class=\"\
          hljs-string\">\"I love you\\n\\nI like you\"</span>,\n  <span class=\"hljs-string\"\
          >\"&lt;s&gt;I love you&lt;/s&gt;&lt;s&gt;I like you&lt;/s&gt;\"</span>,\n\
          \  <span class=\"hljs-string\">\"I love you&lt;/s&gt;I like you\"</span>,\n\
          ]);\n</code></pre>\n<p>And array pairs throw an error.</p>\n<pre><code class=\"\
          language-js\"><span class=\"hljs-keyword\">const</span> score = <span class=\"\
          hljs-keyword\">await</span> <span class=\"hljs-title function_\">rerank</span>([\n\
          \  [<span class=\"hljs-string\">\"I love you&lt;/s&gt;I like you\"</span>,\
          \ <span class=\"hljs-string\">\"Banana&lt;/s&gt;I like you\"</span>], <span\
          \ class=\"hljs-comment\">// &lt;- throw an error</span>\n]);\n</code></pre>\n\
          <p>The results are always the same: <code>{ \"label\": \"LABEL_0\", \"score\"\
          : 1 }</code>.</p>\n<p>All the examples above returns different results from\
          \ the <a href=\"https://huggingface.co/BAAI/bge-reranker-base?text=I+love+you%0A+like+you\"\
          >Hosted inference API</a></p>\n"
        raw: "```ts\r\n// npm i @xenova/transformers\r\nimport { pipeline } from '@xenova/transformers';\r\
          \n\r\n// Allocate pipeline\r\nconst reranker = await pipeline('text-classification',\
          \ 'Xenova/bge-reranker-base');\r\n```\r\nI've tried: \r\n```ts\r\nconst\
          \ score = await rerank([\r\n  \"I love you. I like you\",\r\n  \"I love\
          \ you\\n\\nI like you\",\r\n  \"<s>I love you</s><s>I like you</s>\",\r\n\
          \  \"I love you</s>I like you\",\r\n]);\r\n```\r\n\r\nAnd array pairs throw\
          \ an error.\r\n```js\r\nconst score = await rerank([\r\n  [\"I love you</s>I\
          \ like you\", \"Banana</s>I like you\"], // <- throw an error\r\n]);\r\n\
          ```\r\n\r\nThe results are always the same: `{ \"label\": \"LABEL_0\", \"\
          score\": 1 }`.\r\n\r\n\r\nAll the examples above returns different results\
          \ from the [Hosted inference API](https://huggingface.co/BAAI/bge-reranker-base?text=I+love+you%0A+like+you)"
        updatedAt: '2023-10-24T12:21:28.399Z'
      numEdits: 0
      reactions: []
    id: 6537b6c84e82cb275da56344
    type: comment
  author: brunnolou
  content: "```ts\r\n// npm i @xenova/transformers\r\nimport { pipeline } from '@xenova/transformers';\r\
    \n\r\n// Allocate pipeline\r\nconst reranker = await pipeline('text-classification',\
    \ 'Xenova/bge-reranker-base');\r\n```\r\nI've tried: \r\n```ts\r\nconst score\
    \ = await rerank([\r\n  \"I love you. I like you\",\r\n  \"I love you\\n\\nI like\
    \ you\",\r\n  \"<s>I love you</s><s>I like you</s>\",\r\n  \"I love you</s>I like\
    \ you\",\r\n]);\r\n```\r\n\r\nAnd array pairs throw an error.\r\n```js\r\nconst\
    \ score = await rerank([\r\n  [\"I love you</s>I like you\", \"Banana</s>I like\
    \ you\"], // <- throw an error\r\n]);\r\n```\r\n\r\nThe results are always the\
    \ same: `{ \"label\": \"LABEL_0\", \"score\": 1 }`.\r\n\r\n\r\nAll the examples\
    \ above returns different results from the [Hosted inference API](https://huggingface.co/BAAI/bge-reranker-base?text=I+love+you%0A+like+you)"
  created_at: 2023-10-24 11:21:28+00:00
  edited: false
  hidden: false
  id: 6537b6c84e82cb275da56344
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png?w=200&h=200&f=face
      fullname: Joshua
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Xenova
      type: user
    createdAt: '2023-10-24T17:03:56.000Z'
    data:
      edited: false
      editors:
      - Xenova
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5479015707969666
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png?w=200&h=200&f=face
          fullname: Joshua
          isHf: true
          isPro: false
          name: Xenova
          type: user
        html: "<p>Hi there! You can use it in the same way as shown in the <a href=\"\
          https://huggingface.co/BAAI/bge-reranker-base?text=I+love+you%0A+like+you#using-huggingface-transformers-1\"\
          >README</a>, just with minor syntax differences:</p>\n<h3 id=\"python-original\"\
          >Python (original)</h3>\n<pre><code class=\"language-py\"><span class=\"\
          hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\">from</span>\
          \ transformers <span class=\"hljs-keyword\">import</span> AutoModelForSequenceClassification,\
          \ AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(<span class=\"\
          hljs-string\">'BAAI/bge-reranker-base'</span>)\nmodel = AutoModelForSequenceClassification.from_pretrained(<span\
          \ class=\"hljs-string\">'BAAI/bge-reranker-base'</span>)\nmodel.<span class=\"\
          hljs-built_in\">eval</span>()\n\npairs = [[<span class=\"hljs-string\">'what\
          \ is panda?'</span>, <span class=\"hljs-string\">'hi'</span>], [<span class=\"\
          hljs-string\">'what is panda?'</span>, <span class=\"hljs-string\">'The\
          \ giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or\
          \ simply panda, is a bear species endemic to China.'</span>]]\n<span class=\"\
          hljs-keyword\">with</span> torch.no_grad():\n    inputs = tokenizer(pairs,\
          \ padding=<span class=\"hljs-literal\">True</span>, truncation=<span class=\"\
          hljs-literal\">True</span>, return_tensors=<span class=\"hljs-string\">'pt'</span>,\
          \ max_length=<span class=\"hljs-number\">512</span>)\n    scores = model(**inputs,\
          \ return_dict=<span class=\"hljs-literal\">True</span>).logits.view(-<span\
          \ class=\"hljs-number\">1</span>, ).<span class=\"hljs-built_in\">float</span>()\n\
          \    <span class=\"hljs-built_in\">print</span>(scores)\n</code></pre>\n\
          <p>outputs <code>[-8.1544,  6.1821]</code></p>\n<h3 id=\"javascript-ours\"\
          >JavaScript (ours)</h3>\n<pre><code class=\"language-js\"><span class=\"\
          hljs-keyword\">import</span> { <span class=\"hljs-title class_\">AutoModelForSequenceClassification</span>,\
          \ <span class=\"hljs-title class_\">AutoTokenizer</span> } <span class=\"\
          hljs-keyword\">from</span> <span class=\"hljs-string\">'@xenova/transformers'</span>;\n\
          \n<span class=\"hljs-keyword\">let</span> tokenizer = <span class=\"hljs-keyword\"\
          >await</span> <span class=\"hljs-title class_\">AutoTokenizer</span>.<span\
          \ class=\"hljs-title function_\">from_pretrained</span>(<span class=\"hljs-string\"\
          >'Xenova/bge-reranker-base'</span>)\n<span class=\"hljs-keyword\">let</span>\
          \ model = <span class=\"hljs-keyword\">await</span> <span class=\"hljs-title\
          \ class_\">AutoModelForSequenceClassification</span>.<span class=\"hljs-title\
          \ function_\">from_pretrained</span>(<span class=\"hljs-string\">'Xenova/bge-reranker-base'</span>,\
          \ { <span class=\"hljs-attr\">quantized</span>: <span class=\"hljs-literal\"\
          >false</span> })\n\n<span class=\"hljs-keyword\">let</span> texts = [<span\
          \ class=\"hljs-string\">'what is panda?'</span>, <span class=\"hljs-string\"\
          >'what is panda?'</span>];\n<span class=\"hljs-keyword\">let</span> pairs\
          \ = [<span class=\"hljs-string\">'hi'</span>, <span class=\"hljs-string\"\
          >'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear\
          \ or simply panda, is a bear species endemic to China.'</span>]\n\n<span\
          \ class=\"hljs-keyword\">let</span> inputs = <span class=\"hljs-title function_\"\
          >tokenizer</span>(texts, { <span class=\"hljs-attr\">text_pair</span>: pairs,\
          \ <span class=\"hljs-attr\">padding</span>: <span class=\"hljs-literal\"\
          >true</span>, <span class=\"hljs-attr\">truncation</span>: <span class=\"\
          hljs-literal\">true</span> })\n\n<span class=\"hljs-keyword\">let</span>\
          \ scores = <span class=\"hljs-keyword\">await</span> <span class=\"hljs-title\
          \ function_\">model</span>(inputs)\n<span class=\"hljs-variable language_\"\
          >console</span>.<span class=\"hljs-title function_\">log</span>(scores.<span\
          \ class=\"hljs-property\">logits</span>.<span class=\"hljs-property\">data</span>)\n\
          </code></pre>\n<p>outputs <code>[ -8.154397964477539, 6.182114601135254\
          \ ]</code></p>\n"
        raw: "Hi there! You can use it in the same way as shown in the [README](https://huggingface.co/BAAI/bge-reranker-base?text=I+love+you%0A+like+you#using-huggingface-transformers-1),\
          \ just with minor syntax differences:\n\n### Python (original)\n```py\n\
          import torch\nfrom transformers import AutoModelForSequenceClassification,\
          \ AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-base')\n\
          model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-base')\n\
          model.eval()\n\npairs = [['what is panda?', 'hi'], ['what is panda?', 'The\
          \ giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or\
          \ simply panda, is a bear species endemic to China.']]\nwith torch.no_grad():\n\
          \    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt',\
          \ max_length=512)\n    scores = model(**inputs, return_dict=True).logits.view(-1,\
          \ ).float()\n    print(scores)\n```\n\noutputs `[-8.1544,  6.1821]`\n\n\
          ### JavaScript (ours)\n```js\nimport { AutoModelForSequenceClassification,\
          \ AutoTokenizer } from '@xenova/transformers';\n\nlet tokenizer = await\
          \ AutoTokenizer.from_pretrained('Xenova/bge-reranker-base')\nlet model =\
          \ await AutoModelForSequenceClassification.from_pretrained('Xenova/bge-reranker-base',\
          \ { quantized: false })\n\nlet texts = ['what is panda?', 'what is panda?'];\n\
          let pairs = ['hi', 'The giant panda (Ailuropoda melanoleuca), sometimes\
          \ called a panda bear or simply panda, is a bear species endemic to China.']\n\
          \nlet inputs = tokenizer(texts, { text_pair: pairs, padding: true, truncation:\
          \ true })\n\nlet scores = await model(inputs)\nconsole.log(scores.logits.data)\n\
          ```\noutputs `[ -8.154397964477539, 6.182114601135254 ]`"
        updatedAt: '2023-10-24T17:03:56.647Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - brunnolou
    id: 6537f8fcffe3e0513106a1fa
    type: comment
  author: Xenova
  content: "Hi there! You can use it in the same way as shown in the [README](https://huggingface.co/BAAI/bge-reranker-base?text=I+love+you%0A+like+you#using-huggingface-transformers-1),\
    \ just with minor syntax differences:\n\n### Python (original)\n```py\nimport\
    \ torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\
    \ntokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-base')\nmodel =\
    \ AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-base')\n\
    model.eval()\n\npairs = [['what is panda?', 'hi'], ['what is panda?', 'The giant\
    \ panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda,\
    \ is a bear species endemic to China.']]\nwith torch.no_grad():\n    inputs =\
    \ tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n\
    \    scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n  \
    \  print(scores)\n```\n\noutputs `[-8.1544,  6.1821]`\n\n### JavaScript (ours)\n\
    ```js\nimport { AutoModelForSequenceClassification, AutoTokenizer } from '@xenova/transformers';\n\
    \nlet tokenizer = await AutoTokenizer.from_pretrained('Xenova/bge-reranker-base')\n\
    let model = await AutoModelForSequenceClassification.from_pretrained('Xenova/bge-reranker-base',\
    \ { quantized: false })\n\nlet texts = ['what is panda?', 'what is panda?'];\n\
    let pairs = ['hi', 'The giant panda (Ailuropoda melanoleuca), sometimes called\
    \ a panda bear or simply panda, is a bear species endemic to China.']\n\nlet inputs\
    \ = tokenizer(texts, { text_pair: pairs, padding: true, truncation: true })\n\n\
    let scores = await model(inputs)\nconsole.log(scores.logits.data)\n```\noutputs\
    \ `[ -8.154397964477539, 6.182114601135254 ]`"
  created_at: 2023-10-24 16:03:56+00:00
  edited: false
  hidden: false
  id: 6537f8fcffe3e0513106a1fa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png?w=200&h=200&f=face
      fullname: Joshua
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Xenova
      type: user
    createdAt: '2023-10-24T17:06:28.000Z'
    data:
      edited: true
      editors:
      - Xenova
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8754786252975464
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png?w=200&h=200&f=face
          fullname: Joshua
          isHf: true
          isPro: false
          name: Xenova
          type: user
        html: '<p>The main difference is the way texts are passed into the tokenizer...
          which is unfortunately is due to limitations of how JavaScript handles optional
          positional and keyword arguments. For this reason, we require the users
          to separate the inputs into two parallel arrays.</p>

          <p>Moreover, we use the unquantized model (<code>quantized: false</code>),
          but you can use the quantized version by removing  this additional parameter
          (the output is also still pretty good: <code>[ -7.527967929840088, 6.233025550842285
          ]</code>).</p>

          '
        raw: 'The main difference is the way texts are passed into the tokenizer...
          which is unfortunately is due to limitations of how JavaScript handles optional
          positional and keyword arguments. For this reason, we require the users
          to separate the inputs into two parallel arrays.


          Moreover, we use the unquantized model (`quantized: false`), but you can
          use the quantized version by removing  this additional parameter (the output
          is also still pretty good: `[ -7.527967929840088, 6.233025550842285 ]`).'
        updatedAt: '2023-10-24T17:16:59.432Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - brunnolou
    id: 6537f994613fe158bd3afe7c
    type: comment
  author: Xenova
  content: 'The main difference is the way texts are passed into the tokenizer...
    which is unfortunately is due to limitations of how JavaScript handles optional
    positional and keyword arguments. For this reason, we require the users to separate
    the inputs into two parallel arrays.


    Moreover, we use the unquantized model (`quantized: false`), but you can use the
    quantized version by removing  this additional parameter (the output is also still
    pretty good: `[ -7.527967929840088, 6.233025550842285 ]`).'
  created_at: 2023-10-24 16:06:28+00:00
  edited: true
  hidden: false
  id: 6537f994613fe158bd3afe7c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Xenova/bge-reranker-base
repo_type: model
status: open
target_branch: null
title: How to use this reranker?
