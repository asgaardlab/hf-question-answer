!!python/object:huggingface_hub.community.DiscussionWithDetails
author: maddes8cht
conflicting_files: null
created_at: 2023-11-03 19:44:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64314d56dd466752c73bce33/Hny4H26P7Zg0PbET-iYH-.jpeg?w=200&h=200&f=face
      fullname: Mathias Bachmann
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: maddes8cht
      type: user
    createdAt: '2023-11-03T20:44:46.000Z'
    data:
      edited: false
      editors:
      - maddes8cht
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7507007122039795
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64314d56dd466752c73bce33/Hny4H26P7Zg0PbET-iYH-.jpeg?w=200&h=200&f=face
          fullname: Mathias Bachmann
          isHf: false
          isPro: false
          name: maddes8cht
          type: user
        html: '<p>Since the ggml format is now somewhat outdated, I would like to
          point out that a complete set of gguf quantized versions of <a href="https://huggingface.co/maddes8cht/gorilla-llm-gorilla-mpt-7b-hf-v0-gguf">Gorilla-mpt
          is available</a>.</p>

          <p>There is also a corresponding set of <a href="https://huggingface.co/maddes8cht/gorilla-llm-gorilla-falcon-7b-hf-v0-gguf">Gorilla-Falcon
          gguf</a>  files at <a href="https://huggingface.co/maddes8cht">maddes8cht
          on Huggingface</a> </p>

          '
        raw: "Since the ggml format is now somewhat outdated, I would like to point\
          \ out that a complete set of gguf quantized versions of [Gorilla-mpt is\
          \ available](https://huggingface.co/maddes8cht/gorilla-llm-gorilla-mpt-7b-hf-v0-gguf).\r\
          \n\r\nThere is also a corresponding set of [Gorilla-Falcon gguf](https://huggingface.co/maddes8cht/gorilla-llm-gorilla-falcon-7b-hf-v0-gguf)\
          \  files at [maddes8cht on Huggingface](https://huggingface.co/maddes8cht) "
        updatedAt: '2023-11-03T20:44:46.370Z'
      numEdits: 0
      reactions: []
    id: 65455bbeaf7c27330dde2645
    type: comment
  author: maddes8cht
  content: "Since the ggml format is now somewhat outdated, I would like to point\
    \ out that a complete set of gguf quantized versions of [Gorilla-mpt is available](https://huggingface.co/maddes8cht/gorilla-llm-gorilla-mpt-7b-hf-v0-gguf).\r\
    \n\r\nThere is also a corresponding set of [Gorilla-Falcon gguf](https://huggingface.co/maddes8cht/gorilla-llm-gorilla-falcon-7b-hf-v0-gguf)\
    \  files at [maddes8cht on Huggingface](https://huggingface.co/maddes8cht) "
  created_at: 2023-11-03 19:44:46+00:00
  edited: false
  hidden: false
  id: 65455bbeaf7c27330dde2645
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: gorilla-llm/gorilla-mpt-7b-hf-v0-ggml
repo_type: model
status: open
target_branch: null
title: Up to date .gguf versions of Gorilla mpt and Gorilla Falcon available
