!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dualblades
conflicting_files: null
created_at: 2023-08-24 16:57:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e7663a38b9ea7fb9045167cf7dcf91d.svg
      fullname: Akshay B
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dualblades
      type: user
    createdAt: '2023-08-24T17:57:24.000Z'
    data:
      edited: false
      editors:
      - dualblades
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4649316668510437
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e7663a38b9ea7fb9045167cf7dcf91d.svg
          fullname: Akshay B
          isHf: false
          isPro: false
          name: dualblades
          type: user
        html: "<p>Kernel specifications:</p>\n<pre><code>Image: Data Science 3.0\n\
          Kernel: Python 3\nInstance type: ml.t3.medium\nStart-up script: No script\n\
          </code></pre>\n<p>This is my exact notebook code, copied from the \"Deploy\"\
          \ button on this page:</p>\n<pre><code>import sagemaker\nfrom sagemaker.huggingface\
          \ import HuggingFaceModel\n\nrole = sagemaker.get_execution_role()\n\n#\
          \ Hub Model configuration. https://huggingface.co/models\nhub = {\n    'HF_MODEL_ID':'HuggingFaceM4/idefics-80b',\n\
          \    'HF_TASK':'text-generation'\n}\n\n# create Hugging Face Model Class\n\
          huggingface_model = HuggingFaceModel(\n    transformers_version='4.26.0',\n\
          \    pytorch_version='1.13.1',\n    py_version='py39',\n    env=hub,\n \
          \   role=role, \n)\n\n# deploy model to SageMaker Inference\npredictor =\
          \ huggingface_model.deploy(\n    initial_instance_count=1, # number of instances\n\
          \    instance_type='ml.m5.xlarge' # ec2 instance type\n)\n\ndata = {\n \"\
          inputs\": \"Can you please let us know more details about your \"\n}\npredictor.predict(data)\n\
          </code></pre>\n<p>I am able to deploy the model and I can see the endpoint.\
          \ However, running the <code>predict</code> method always throws this error:</p>\n\
          <pre><code>ModelError                                Traceback (most recent\
          \ call last)\nCell In[17], line 1\n----&gt; 1 predictor.predict(data)\n\n\
          File /opt/conda/lib/python3.10/site-packages/sagemaker/base_predictor.py:185,\
          \ in Predictor.predict(self, data, initial_args, target_model, target_variant,\
          \ inference_id, custom_attributes)\n    138 \"\"\"Return the inference from\
          \ the specified endpoint.\n    139 \n    140 Args:\n   (...)\n    174  \
          \       as is.\n    175 \"\"\"\n    177 request_args = self._create_request_args(\n\
          \    178     data,\n    179     initial_args,\n   (...)\n    183     custom_attributes,\n\
          \    184 )\n--&gt; 185 response = self.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**request_args)\n\
          \    186 return self._handle_response(response)\n\nFile /opt/conda/lib/python3.10/site-packages/botocore/client.py:535,\
          \ in ClientCreator._create_api_method.&lt;locals&gt;._api_call(self, *args,\
          \ **kwargs)\n    531     raise TypeError(\n    532         f\"{py_operation_name}()\
          \ only accepts keyword arguments.\"\n    533     )\n    534 # The \"self\"\
          \ in this scope is referring to the BaseClient.\n--&gt; 535 return self._make_api_call(operation_name,\
          \ kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/botocore/client.py:980,\
          \ in BaseClient._make_api_call(self, operation_name, api_params)\n    978\
          \     error_code = parsed_response.get(\"Error\", {}).get(\"Code\")\n  \
          \  979     error_class = self.exceptions.from_code(error_code)\n--&gt; 980\
          \     raise error_class(parsed_response, operation_name)\n    981 else:\n\
          \    982     return parsed_response\n\nModelError: An error occurred (ModelError)\
          \ when calling the InvokeEndpoint operation: Received client error (400)\
          \ from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\"\
          ,\n  \"message\": \"\\u0027idefics\\u0027\"\n}\n\".\n</code></pre>\n<p>What\
          \ can I do to fix this issue and properly invoke the endpoint?</p>\n"
        raw: "Kernel specifications:\r\n```\r\nImage: Data Science 3.0\r\nKernel:\
          \ Python 3\r\nInstance type: ml.t3.medium\r\nStart-up script: No script\r\
          \n```\r\n\r\nThis is my exact notebook code, copied from the \"Deploy\"\
          \ button on this page:\r\n```\r\nimport sagemaker\r\nfrom sagemaker.huggingface\
          \ import HuggingFaceModel\r\n\r\nrole = sagemaker.get_execution_role()\r\
          \n\r\n# Hub Model configuration. https://huggingface.co/models\r\nhub =\
          \ {\r\n\t'HF_MODEL_ID':'HuggingFaceM4/idefics-80b',\r\n\t'HF_TASK':'text-generation'\r\
          \n}\r\n\r\n# create Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\
          \n\ttransformers_version='4.26.0',\r\n\tpytorch_version='1.13.1',\r\n\t\
          py_version='py39',\r\n\tenv=hub,\r\n\trole=role, \r\n)\r\n\r\n# deploy model\
          \ to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\n\t\
          initial_instance_count=1, # number of instances\r\n\tinstance_type='ml.m5.xlarge'\
          \ # ec2 instance type\r\n)\r\n\r\ndata = {\r\n \"inputs\": \"Can you please\
          \ let us know more details about your \"\r\n}\r\npredictor.predict(data)\r\
          \n```\r\n\r\nI am able to deploy the model and I can see the endpoint. However,\
          \ running the `predict` method always throws this error:\r\n```\r\nModelError\
          \                                Traceback (most recent call last)\r\nCell\
          \ In[17], line 1\r\n----> 1 predictor.predict(data)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/sagemaker/base_predictor.py:185,\
          \ in Predictor.predict(self, data, initial_args, target_model, target_variant,\
          \ inference_id, custom_attributes)\r\n    138 \"\"\"Return the inference\
          \ from the specified endpoint.\r\n    139 \r\n    140 Args:\r\n   (...)\r\
          \n    174         as is.\r\n    175 \"\"\"\r\n    177 request_args = self._create_request_args(\r\
          \n    178     data,\r\n    179     initial_args,\r\n   (...)\r\n    183\
          \     custom_attributes,\r\n    184 )\r\n--> 185 response = self.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**request_args)\r\
          \n    186 return self._handle_response(response)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/botocore/client.py:535,\
          \ in ClientCreator._create_api_method.<locals>._api_call(self, *args, **kwargs)\r\
          \n    531     raise TypeError(\r\n    532         f\"{py_operation_name}()\
          \ only accepts keyword arguments.\"\r\n    533     )\r\n    534 # The \"\
          self\" in this scope is referring to the BaseClient.\r\n--> 535 return self._make_api_call(operation_name,\
          \ kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/botocore/client.py:980,\
          \ in BaseClient._make_api_call(self, operation_name, api_params)\r\n   \
          \ 978     error_code = parsed_response.get(\"Error\", {}).get(\"Code\")\r\
          \n    979     error_class = self.exceptions.from_code(error_code)\r\n-->\
          \ 980     raise error_class(parsed_response, operation_name)\r\n    981\
          \ else:\r\n    982     return parsed_response\r\n\r\nModelError: An error\
          \ occurred (ModelError) when calling the InvokeEndpoint operation: Received\
          \ client error (400) from primary with message \"{\r\n  \"code\": 400,\r\
          \n  \"type\": \"InternalServerException\",\r\n  \"message\": \"\\u0027idefics\\\
          u0027\"\r\n}\r\n\".\r\n```\r\n\r\nWhat can I do to fix this issue and properly\
          \ invoke the endpoint?"
        updatedAt: '2023-08-24T17:57:24.900Z'
      numEdits: 0
      reactions: []
    id: 64e79a04ccfe005d2b1c64ec
    type: comment
  author: dualblades
  content: "Kernel specifications:\r\n```\r\nImage: Data Science 3.0\r\nKernel: Python\
    \ 3\r\nInstance type: ml.t3.medium\r\nStart-up script: No script\r\n```\r\n\r\n\
    This is my exact notebook code, copied from the \"Deploy\" button on this page:\r\
    \n```\r\nimport sagemaker\r\nfrom sagemaker.huggingface import HuggingFaceModel\r\
    \n\r\nrole = sagemaker.get_execution_role()\r\n\r\n# Hub Model configuration.\
    \ https://huggingface.co/models\r\nhub = {\r\n\t'HF_MODEL_ID':'HuggingFaceM4/idefics-80b',\r\
    \n\t'HF_TASK':'text-generation'\r\n}\r\n\r\n# create Hugging Face Model Class\r\
    \nhuggingface_model = HuggingFaceModel(\r\n\ttransformers_version='4.26.0',\r\n\
    \tpytorch_version='1.13.1',\r\n\tpy_version='py39',\r\n\tenv=hub,\r\n\trole=role,\
    \ \r\n)\r\n\r\n# deploy model to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\
    \n\tinitial_instance_count=1, # number of instances\r\n\tinstance_type='ml.m5.xlarge'\
    \ # ec2 instance type\r\n)\r\n\r\ndata = {\r\n \"inputs\": \"Can you please let\
    \ us know more details about your \"\r\n}\r\npredictor.predict(data)\r\n```\r\n\
    \r\nI am able to deploy the model and I can see the endpoint. However, running\
    \ the `predict` method always throws this error:\r\n```\r\nModelError        \
    \                        Traceback (most recent call last)\r\nCell In[17], line\
    \ 1\r\n----> 1 predictor.predict(data)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/sagemaker/base_predictor.py:185,\
    \ in Predictor.predict(self, data, initial_args, target_model, target_variant,\
    \ inference_id, custom_attributes)\r\n    138 \"\"\"Return the inference from\
    \ the specified endpoint.\r\n    139 \r\n    140 Args:\r\n   (...)\r\n    174\
    \         as is.\r\n    175 \"\"\"\r\n    177 request_args = self._create_request_args(\r\
    \n    178     data,\r\n    179     initial_args,\r\n   (...)\r\n    183     custom_attributes,\r\
    \n    184 )\r\n--> 185 response = self.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**request_args)\r\
    \n    186 return self._handle_response(response)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/botocore/client.py:535,\
    \ in ClientCreator._create_api_method.<locals>._api_call(self, *args, **kwargs)\r\
    \n    531     raise TypeError(\r\n    532         f\"{py_operation_name}() only\
    \ accepts keyword arguments.\"\r\n    533     )\r\n    534 # The \"self\" in this\
    \ scope is referring to the BaseClient.\r\n--> 535 return self._make_api_call(operation_name,\
    \ kwargs)\r\n\r\nFile /opt/conda/lib/python3.10/site-packages/botocore/client.py:980,\
    \ in BaseClient._make_api_call(self, operation_name, api_params)\r\n    978  \
    \   error_code = parsed_response.get(\"Error\", {}).get(\"Code\")\r\n    979 \
    \    error_class = self.exceptions.from_code(error_code)\r\n--> 980     raise\
    \ error_class(parsed_response, operation_name)\r\n    981 else:\r\n    982   \
    \  return parsed_response\r\n\r\nModelError: An error occurred (ModelError) when\
    \ calling the InvokeEndpoint operation: Received client error (400) from primary\
    \ with message \"{\r\n  \"code\": 400,\r\n  \"type\": \"InternalServerException\"\
    ,\r\n  \"message\": \"\\u0027idefics\\u0027\"\r\n}\r\n\".\r\n```\r\n\r\nWhat can\
    \ I do to fix this issue and properly invoke the endpoint?"
  created_at: 2023-08-24 16:57:24+00:00
  edited: false
  hidden: false
  id: 64e79a04ccfe005d2b1c64ec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
      fullname: Victor Sanh
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: true
      name: VictorSanh
      type: user
    createdAt: '2023-08-28T16:21:51.000Z'
    data:
      edited: false
      editors:
      - VictorSanh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9865033626556396
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
          fullname: Victor Sanh
          isHf: true
          isPro: true
          name: VictorSanh
          type: user
        html: "<p>Hi,<br>I am not familiar with the SM part, at a quick glance, i\
          \ would say that you need to update your transformers version. idefics was\
          \ released as part of the 4.32.0 release (and some tiny details were fixed\
          \ in 4.32.1 too).<br>if it doesn't entirely solve your problem, perhaps\
          \ <span data-props=\"{&quot;user&quot;:&quot;philschmid&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/philschmid\">@<span class=\"\
          underline\">philschmid</span></a></span>\n\n\t</span></span> knows?</p>\n"
        raw: 'Hi,

          I am not familiar with the SM part, at a quick glance, i would say that
          you need to update your transformers version. idefics was released as part
          of the 4.32.0 release (and some tiny details were fixed in 4.32.1 too).

          if it doesn''t entirely solve your problem, perhaps @philschmid knows?'
        updatedAt: '2023-08-28T16:21:51.636Z'
      numEdits: 0
      reactions: []
    id: 64ecc99f266afc1d935add5f
    type: comment
  author: VictorSanh
  content: 'Hi,

    I am not familiar with the SM part, at a quick glance, i would say that you need
    to update your transformers version. idefics was released as part of the 4.32.0
    release (and some tiny details were fixed in 4.32.1 too).

    if it doesn''t entirely solve your problem, perhaps @philschmid knows?'
  created_at: 2023-08-28 15:21:51+00:00
  edited: false
  hidden: false
  id: 64ecc99f266afc1d935add5f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e7663a38b9ea7fb9045167cf7dcf91d.svg
      fullname: Akshay B
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dualblades
      type: user
    createdAt: '2023-08-28T17:18:23.000Z'
    data:
      edited: false
      editors:
      - dualblades
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8351606726646423
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e7663a38b9ea7fb9045167cf7dcf91d.svg
          fullname: Akshay B
          isHf: false
          isPro: false
          name: dualblades
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;VictorSanh&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/VictorSanh\"\
          >@<span class=\"underline\">VictorSanh</span></a></span>\n\n\t</span></span>,\
          \ thank you for the suggestion. Unfortunately, 4.32.0 is not supported yet.\
          \ I upgraded my SageMaker SDK using the command in the screenshot, but still\
          \ no luck.<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6425e88c85f26ab94af1aac6/ZkAQr9QzRcZ_pV7yPXHyG.png\"\
          ><img alt=\"Screenshot 2023-08-28 at 10.17.09 AM.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6425e88c85f26ab94af1aac6/ZkAQr9QzRcZ_pV7yPXHyG.png\"\
          ></a></p>\n<p>This seems like a concerning issue if the model simply cannot\
          \ be run on SageMaker.</p>\n"
        raw: 'Hi @VictorSanh, thank you for the suggestion. Unfortunately, 4.32.0
          is not supported yet. I upgraded my SageMaker SDK using the command in the
          screenshot, but still no luck.

          ![Screenshot 2023-08-28 at 10.17.09 AM.png](https://cdn-uploads.huggingface.co/production/uploads/6425e88c85f26ab94af1aac6/ZkAQr9QzRcZ_pV7yPXHyG.png)


          This seems like a concerning issue if the model simply cannot be run on
          SageMaker.'
        updatedAt: '2023-08-28T17:18:23.397Z'
      numEdits: 0
      reactions: []
    id: 64ecd6dfd51cc52a60c163fb
    type: comment
  author: dualblades
  content: 'Hi @VictorSanh, thank you for the suggestion. Unfortunately, 4.32.0 is
    not supported yet. I upgraded my SageMaker SDK using the command in the screenshot,
    but still no luck.

    ![Screenshot 2023-08-28 at 10.17.09 AM.png](https://cdn-uploads.huggingface.co/production/uploads/6425e88c85f26ab94af1aac6/ZkAQr9QzRcZ_pV7yPXHyG.png)


    This seems like a concerning issue if the model simply cannot be run on SageMaker.'
  created_at: 2023-08-28 16:18:23+00:00
  edited: false
  hidden: false
  id: 64ecd6dfd51cc52a60c163fb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
      fullname: Victor Sanh
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: true
      name: VictorSanh
      type: user
    createdAt: '2023-08-28T17:48:41.000Z'
    data:
      edited: false
      editors:
      - VictorSanh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7320680022239685
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
          fullname: Victor Sanh
          isHf: true
          isPro: true
          name: VictorSanh
          type: user
        html: "<p>Got it! i will let <span data-props=\"{&quot;user&quot;:&quot;philschmid&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/philschmid\"\
          >@<span class=\"underline\">philschmid</span></a></span>\n\n\t</span></span>\
          \ advise</p>\n"
        raw: Got it! i will let @philschmid advise
        updatedAt: '2023-08-28T17:48:41.034Z'
      numEdits: 0
      reactions: []
    id: 64ecddf9961565b467809a1d
    type: comment
  author: VictorSanh
  content: Got it! i will let @philschmid advise
  created_at: 2023-08-28 16:48:41+00:00
  edited: false
  hidden: false
  id: 64ecddf9961565b467809a1d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e7663a38b9ea7fb9045167cf7dcf91d.svg
      fullname: Akshay B
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dualblades
      type: user
    createdAt: '2023-08-29T18:33:53.000Z'
    data:
      edited: false
      editors:
      - dualblades
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8161270022392273
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e7663a38b9ea7fb9045167cf7dcf91d.svg
          fullname: Akshay B
          isHf: false
          isPro: false
          name: dualblades
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;philschmid&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/philschmid\">@<span class=\"\
          underline\">philschmid</span></a></span>\n\n\t</span></span> Any update\
          \ here? Are we able to run idefics on SageMaker?</p>\n"
        raw: '@philschmid Any update here? Are we able to run idefics on SageMaker?'
        updatedAt: '2023-08-29T18:33:53.872Z'
      numEdits: 0
      reactions: []
    id: 64ee3a11d679ae3f90fa4ea5
    type: comment
  author: dualblades
  content: '@philschmid Any update here? Are we able to run idefics on SageMaker?'
  created_at: 2023-08-29 17:33:53+00:00
  edited: false
  hidden: false
  id: 64ee3a11d679ae3f90fa4ea5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png?w=200&h=200&f=face
      fullname: Philipp Schmid
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: philschmid
      type: user
    createdAt: '2023-08-30T06:11:07.000Z'
    data:
      edited: false
      editors:
      - philschmid
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8741822838783264
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png?w=200&h=200&f=face
          fullname: Philipp Schmid
          isHf: true
          isPro: false
          name: philschmid
          type: user
        html: '<p>You can customize the transformers with providing a <code>requirements.txt</code>
          and manually update until we have a new container. But this being said a
          <code>m5</code> instance is not enough to run a 80B parameter model neither
          would the task <code>text-generation</code> be correct. </p>

          '
        raw: "You can customize the transformers with providing a `requirements.txt`\
          \ and manually update until we have a new container. But this being said\
          \ a `m5` instance is not enough to run a 80B parameter model neither would\
          \ the task `text-generation` be correct. \n"
        updatedAt: '2023-08-30T06:11:07.992Z'
      numEdits: 0
      reactions: []
    id: 64eedd7b51bfada02a68d80b
    type: comment
  author: philschmid
  content: "You can customize the transformers with providing a `requirements.txt`\
    \ and manually update until we have a new container. But this being said a `m5`\
    \ instance is not enough to run a 80B parameter model neither would the task `text-generation`\
    \ be correct. \n"
  created_at: 2023-08-30 05:11:07+00:00
  edited: false
  hidden: false
  id: 64eedd7b51bfada02a68d80b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e7663a38b9ea7fb9045167cf7dcf91d.svg
      fullname: Akshay B
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dualblades
      type: user
    createdAt: '2023-08-30T19:28:43.000Z'
    data:
      edited: false
      editors:
      - dualblades
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7542663812637329
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e7663a38b9ea7fb9045167cf7dcf91d.svg
          fullname: Akshay B
          isHf: false
          isPro: false
          name: dualblades
          type: user
        html: '<p>If that''s the case, I''m confused why the "Deploy with SageMaker"
          provides those configurations. Could you please update these configurations?<br><a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6425e88c85f26ab94af1aac6/qaEM4BuT4WrYcDXDAXjCa.png"><img
          alt="Screenshot 2023-08-30 at 12.27.52 PM.png" src="https://cdn-uploads.huggingface.co/production/uploads/6425e88c85f26ab94af1aac6/qaEM4BuT4WrYcDXDAXjCa.png"></a></p>

          '
        raw: 'If that''s the case, I''m confused why the "Deploy with SageMaker" provides
          those configurations. Could you please update these configurations?

          ![Screenshot 2023-08-30 at 12.27.52 PM.png](https://cdn-uploads.huggingface.co/production/uploads/6425e88c85f26ab94af1aac6/qaEM4BuT4WrYcDXDAXjCa.png)

          '
        updatedAt: '2023-08-30T19:28:43.947Z'
      numEdits: 0
      reactions: []
    id: 64ef986bd2bab867b1af953e
    type: comment
  author: dualblades
  content: 'If that''s the case, I''m confused why the "Deploy with SageMaker" provides
    those configurations. Could you please update these configurations?

    ![Screenshot 2023-08-30 at 12.27.52 PM.png](https://cdn-uploads.huggingface.co/production/uploads/6425e88c85f26ab94af1aac6/qaEM4BuT4WrYcDXDAXjCa.png)

    '
  created_at: 2023-08-30 18:28:43+00:00
  edited: false
  hidden: false
  id: 64ef986bd2bab867b1af953e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png?w=200&h=200&f=face
      fullname: Philipp Schmid
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: philschmid
      type: user
    createdAt: '2023-10-12T14:19:29.000Z'
    data:
      edited: true
      editors:
      - philschmid
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6385021209716797
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png?w=200&h=200&f=face
          fullname: Philipp Schmid
          isHf: true
          isPro: false
          name: philschmid
          type: user
        html: '<p>Here is an example on how to dpeloy it. <a rel="nofollow" href="https://www.philschmid.de/sagemaker-idefics">https://www.philschmid.de/sagemaker-idefics</a></p>

          '
        raw: Here is an example on how to dpeloy it. https://www.philschmid.de/sagemaker-idefics
        updatedAt: '2023-10-12T14:19:45.133Z'
      numEdits: 1
      reactions: []
    id: 65280071819cfe9085225e80
    type: comment
  author: philschmid
  content: Here is an example on how to dpeloy it. https://www.philschmid.de/sagemaker-idefics
  created_at: 2023-10-12 13:19:29+00:00
  edited: true
  hidden: false
  id: 65280071819cfe9085225e80
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: HuggingFaceM4/idefics-80b
repo_type: model
status: open
target_branch: null
title: Unable to deploy to SageMaker via Studio notebook
