!!python/object:huggingface_hub.community.DiscussionWithDetails
author: shayan012
conflicting_files: null
created_at: 2023-06-07 12:31:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bb55df10a6446d6aafd8c6cb78d1d5f3.svg
      fullname: Shayan Duering
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shayan012
      type: user
    createdAt: '2023-06-07T13:31:15.000Z'
    data:
      edited: false
      editors:
      - shayan012
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.43521448969841003
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bb55df10a6446d6aafd8c6cb78d1d5f3.svg
          fullname: Shayan Duering
          isHf: false
          isPro: false
          name: shayan012
          type: user
        html: "<p>I'm using text-generation-webui, when I try to load this model I\
          \ get the following error in the bottom right:</p>\n<p>Traceback (most recent\
          \ call last): File \u201CC:\\Users\\user\\oobabooga_windows\\text-generation-webui\\\
          server.py\u201D, line 69, in load_model_wrapper shared.model, shared.tokenizer\
          \ = load_model(shared.model_name) File \u201CC:\\Users\\user\\oobabooga_windows\\\
          text-generation-webui\\modules\\models.py\u201D, line 94, in load_model\
          \ output = load_func(model_name) File \u201CC:\\Users\\user\\oobabooga_windows\\\
          text-generation-webui\\modules\\models.py\u201D, line 296, in AutoGPTQ_loader\
          \ return modules.AutoGPTQ_loader.load_quantized(model_name) File \u201C\
          C:\\Users\\user\\oobabooga_windows\\text-generation-webui\\modules\\AutoGPTQ_loader.py\u201D\
          , line 53, in load_quantized model = AutoGPTQForCausalLM.from_quantized(path_to_model,\
          \ **params) File \u201CC:\\Users\\user\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\auto_gptq\\modeling\\auto.py\u201D, line 82, in\
          \ from_quantized return quant_func( File \u201CC:\\Users\\user\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\auto_gptq\\modeling_base.py\u201D\
          , line 650, in from_quantized quantize_config = BaseQuantizeConfig.from_pretrained(model_name_or_path,\
          \ **kwargs) File \u201CC:\\Users\\user\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\auto_gptq\\modeling_base.py\u201D, line 90, in\
          \ from_pretrained return cls(**json.load(f)) File \u201CC:\\Users\\user\\\
          oobabooga_windows\\installer_files\\env\\lib\\json_init_.py\u201D, line\
          \ 293, in load return loads(fp.read(), File \u201CC:\\Users\\user\\oobabooga_windows\\\
          installer_files\\env\\lib\\json_init_.py\u201D, line 346, in loads return\
          \ _default_decoder.decode(s) File \u201CC:\\Users\\user\\oobabooga_windows\\\
          installer_files\\env\\lib\\json\\decoder.py\u201D, line 337, in decode obj,\
          \ end = self.raw_decode(s, idx=_w(s, 0).end()) File \u201CC:\\Users\\user\\\
          oobabooga_windows\\installer_files\\env\\lib\\json\\decoder.py\u201D, line\
          \ 355, in raw_decode raise JSONDecodeError(\u201CExpecting value\u201D,\
          \ s, err.value) from None json.decoder.JSONDecodeError: Expecting value:\
          \ line 9 column 27 (char 181)</p>\n<p>There's no error displayed in the\
          \ console and when I try to run some inference I get this error in the console:</p>\n\
          <p>ERROR:No model is loaded! Select one in the Model tab.</p>\n"
        raw: "I'm using text-generation-webui, when I try to load this model I get\
          \ the following error in the bottom right:\r\n\r\nTraceback (most recent\
          \ call last): File \u201CC:\\Users\\user\\oobabooga_windows\\text-generation-webui\\\
          server.py\u201D, line 69, in load_model_wrapper shared.model, shared.tokenizer\
          \ = load_model(shared.model_name) File \u201CC:\\Users\\user\\oobabooga_windows\\\
          text-generation-webui\\modules\\models.py\u201D, line 94, in load_model\
          \ output = load_func(model_name) File \u201CC:\\Users\\user\\oobabooga_windows\\\
          text-generation-webui\\modules\\models.py\u201D, line 296, in AutoGPTQ_loader\
          \ return modules.AutoGPTQ_loader.load_quantized(model_name) File \u201C\
          C:\\Users\\user\\oobabooga_windows\\text-generation-webui\\modules\\AutoGPTQ_loader.py\u201D\
          , line 53, in load_quantized model = AutoGPTQForCausalLM.from_quantized(path_to_model,\
          \ **params) File \u201CC:\\Users\\user\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\auto_gptq\\modeling\\auto.py\u201D, line 82, in\
          \ from_quantized return quant_func( File \u201CC:\\Users\\user\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\auto_gptq\\modeling_base.py\u201D\
          , line 650, in from_quantized quantize_config = BaseQuantizeConfig.from_pretrained(model_name_or_path,\
          \ **kwargs) File \u201CC:\\Users\\user\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\auto_gptq\\modeling_base.py\u201D, line 90, in\
          \ from_pretrained return cls(**json.load(f)) File \u201CC:\\Users\\user\\\
          oobabooga_windows\\installer_files\\env\\lib\\json_init_.py\u201D, line\
          \ 293, in load return loads(fp.read(), File \u201CC:\\Users\\user\\oobabooga_windows\\\
          installer_files\\env\\lib\\json_init_.py\u201D, line 346, in loads return\
          \ _default_decoder.decode(s) File \u201CC:\\Users\\user\\oobabooga_windows\\\
          installer_files\\env\\lib\\json\\decoder.py\u201D, line 337, in decode obj,\
          \ end = self.raw_decode(s, idx=_w(s, 0).end()) File \u201CC:\\Users\\user\\\
          oobabooga_windows\\installer_files\\env\\lib\\json\\decoder.py\u201D, line\
          \ 355, in raw_decode raise JSONDecodeError(\u201CExpecting value\u201D,\
          \ s, err.value) from None json.decoder.JSONDecodeError: Expecting value:\
          \ line 9 column 27 (char 181)\r\n\r\nThere's no error displayed in the console\
          \ and when I try to run some inference I get this error in the console:\r\
          \n\r\nERROR:No model is loaded! Select one in the Model tab."
        updatedAt: '2023-06-07T13:31:15.096Z'
      numEdits: 0
      reactions: []
    id: 648086a3f5be39206aef8413
    type: comment
  author: shayan012
  content: "I'm using text-generation-webui, when I try to load this model I get the\
    \ following error in the bottom right:\r\n\r\nTraceback (most recent call last):\
    \ File \u201CC:\\Users\\user\\oobabooga_windows\\text-generation-webui\\server.py\u201D\
    , line 69, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name)\
    \ File \u201CC:\\Users\\user\\oobabooga_windows\\text-generation-webui\\modules\\\
    models.py\u201D, line 94, in load_model output = load_func(model_name) File \u201C\
    C:\\Users\\user\\oobabooga_windows\\text-generation-webui\\modules\\models.py\u201D\
    , line 296, in AutoGPTQ_loader return modules.AutoGPTQ_loader.load_quantized(model_name)\
    \ File \u201CC:\\Users\\user\\oobabooga_windows\\text-generation-webui\\modules\\\
    AutoGPTQ_loader.py\u201D, line 53, in load_quantized model = AutoGPTQForCausalLM.from_quantized(path_to_model,\
    \ **params) File \u201CC:\\Users\\user\\oobabooga_windows\\installer_files\\env\\\
    lib\\site-packages\\auto_gptq\\modeling\\auto.py\u201D, line 82, in from_quantized\
    \ return quant_func( File \u201CC:\\Users\\user\\oobabooga_windows\\installer_files\\\
    env\\lib\\site-packages\\auto_gptq\\modeling_base.py\u201D, line 650, in from_quantized\
    \ quantize_config = BaseQuantizeConfig.from_pretrained(model_name_or_path, **kwargs)\
    \ File \u201CC:\\Users\\user\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    auto_gptq\\modeling_base.py\u201D, line 90, in from_pretrained return cls(**json.load(f))\
    \ File \u201CC:\\Users\\user\\oobabooga_windows\\installer_files\\env\\lib\\json_init_.py\u201D\
    , line 293, in load return loads(fp.read(), File \u201CC:\\Users\\user\\oobabooga_windows\\\
    installer_files\\env\\lib\\json_init_.py\u201D, line 346, in loads return _default_decoder.decode(s)\
    \ File \u201CC:\\Users\\user\\oobabooga_windows\\installer_files\\env\\lib\\json\\\
    decoder.py\u201D, line 337, in decode obj, end = self.raw_decode(s, idx=_w(s,\
    \ 0).end()) File \u201CC:\\Users\\user\\oobabooga_windows\\installer_files\\env\\\
    lib\\json\\decoder.py\u201D, line 355, in raw_decode raise JSONDecodeError(\u201C\
    Expecting value\u201D, s, err.value) from None json.decoder.JSONDecodeError: Expecting\
    \ value: line 9 column 27 (char 181)\r\n\r\nThere's no error displayed in the\
    \ console and when I try to run some inference I get this error in the console:\r\
    \n\r\nERROR:No model is loaded! Select one in the Model tab."
  created_at: 2023-06-07 12:31:15+00:00
  edited: false
  hidden: false
  id: 648086a3f5be39206aef8413
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-07T13:33:12.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9378277063369751
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Can you try deleting the file <code>quantize_config.json</code>
          in your models folder, and re-downloading it from this repo.  Then try again
          and report back.</p>

          '
        raw: Can you try deleting the file `quantize_config.json` in your models folder,
          and re-downloading it from this repo.  Then try again and report back.
        updatedAt: '2023-06-07T13:33:12.523Z'
      numEdits: 0
      reactions: []
    id: 64808718e1421e205fd82c8c
    type: comment
  author: TheBloke
  content: Can you try deleting the file `quantize_config.json` in your models folder,
    and re-downloading it from this repo.  Then try again and report back.
  created_at: 2023-06-07 12:33:12+00:00
  edited: false
  hidden: false
  id: 64808718e1421e205fd82c8c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bb55df10a6446d6aafd8c6cb78d1d5f3.svg
      fullname: Shayan Duering
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shayan012
      type: user
    createdAt: '2023-06-07T13:44:31.000Z'
    data:
      edited: false
      editors:
      - shayan012
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.32777273654937744
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bb55df10a6446d6aafd8c6cb78d1d5f3.svg
          fullname: Shayan Duering
          isHf: false
          isPro: false
          name: shayan012
          type: user
        html: "<p>Now I'm getting this error:</p>\n<p>oobabooga_windows\\installer_files\\\
          env\\lib\\json\\decoder.py\u201D, line 355, in raw_decode raise JSONDecodeError(\u201C\
          Expecting value\u201D, s, err.value) from None json.decoder.JSONDecodeError:\
          \ Expecting value: line 8 column 25 (char 149)</p>\n"
        raw: "Now I'm getting this error:\n\noobabooga_windows\\installer_files\\\
          env\\lib\\json\\decoder.py\u201D, line 355, in raw_decode raise JSONDecodeError(\u201C\
          Expecting value\u201D, s, err.value) from None json.decoder.JSONDecodeError:\
          \ Expecting value: line 8 column 25 (char 149)"
        updatedAt: '2023-06-07T13:44:31.931Z'
      numEdits: 0
      reactions: []
    id: 648089bf9aafd41918a8aa91
    type: comment
  author: shayan012
  content: "Now I'm getting this error:\n\noobabooga_windows\\installer_files\\env\\\
    lib\\json\\decoder.py\u201D, line 355, in raw_decode raise JSONDecodeError(\u201C\
    Expecting value\u201D, s, err.value) from None json.decoder.JSONDecodeError: Expecting\
    \ value: line 8 column 25 (char 149)"
  created_at: 2023-06-07 12:44:31+00:00
  edited: false
  hidden: false
  id: 648089bf9aafd41918a8aa91
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-07T13:55:57.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9256840348243713
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>OK download it again and this will definitely fix it.  Sorry for
          the troubles.</p>

          '
        raw: OK download it again and this will definitely fix it.  Sorry for the
          troubles.
        updatedAt: '2023-06-07T13:55:57.869Z'
      numEdits: 0
      reactions: []
    id: 64808c6d40facadc556dcee9
    type: comment
  author: TheBloke
  content: OK download it again and this will definitely fix it.  Sorry for the troubles.
  created_at: 2023-06-07 12:55:57+00:00
  edited: false
  hidden: false
  id: 64808c6d40facadc556dcee9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bb55df10a6446d6aafd8c6cb78d1d5f3.svg
      fullname: Shayan Duering
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shayan012
      type: user
    createdAt: '2023-06-07T21:50:51.000Z'
    data:
      edited: false
      editors:
      - shayan012
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9649170637130737
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bb55df10a6446d6aafd8c6cb78d1d5f3.svg
          fullname: Shayan Duering
          isHf: false
          isPro: false
          name: shayan012
          type: user
        html: '<p>Yeah it works now. Thank you so much for the quick support!</p>

          '
        raw: Yeah it works now. Thank you so much for the quick support!
        updatedAt: '2023-06-07T21:50:51.702Z'
      numEdits: 0
      reactions: []
    id: 6480fbbbbb25a636c9e3439b
    type: comment
  author: shayan012
  content: Yeah it works now. Thank you so much for the quick support!
  created_at: 2023-06-07 20:50:51+00:00
  edited: false
  hidden: false
  id: 6480fbbbbb25a636c9e3439b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/bb55df10a6446d6aafd8c6cb78d1d5f3.svg
      fullname: Shayan Duering
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shayan012
      type: user
    createdAt: '2023-06-07T21:50:56.000Z'
    data:
      status: closed
    id: 6480fbc040facadc55756a43
    type: status-change
  author: shayan012
  created_at: 2023-06-07 20:50:56+00:00
  id: 6480fbc040facadc55756a43
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/guanaco-7B-GPTQ
repo_type: model
status: closed
target_branch: null
title: JSONDecodeError  when loading model
