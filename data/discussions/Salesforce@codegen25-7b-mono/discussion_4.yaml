!!python/object:huggingface_hub.community.DiscussionWithDetails
author: NEDIX
conflicting_files: null
created_at: 2023-11-20 20:39:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d4715c3e0f8040834f0382a412a419cc.svg
      fullname: Hans van der Woude
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NEDIX
      type: user
    createdAt: '2023-11-20T20:39:40.000Z'
    data:
      edited: false
      editors:
      - NEDIX
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8670560121536255
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d4715c3e0f8040834f0382a412a419cc.svg
          fullname: Hans van der Woude
          isHf: false
          isPro: false
          name: NEDIX
          type: user
        html: '<p>Seeing that this project has moved to Llama2 architecture, I have
          been attempting to convert this model to LLAMA GGML format.</p>

          <p>I am currently at a dead end because of inoperable implementations of
          <code>get_vocab</code> and <code>save_vocabulary</code> methods in <code>tokenization_codegen25.py</code>.
          When attempting to invoke the <code>get_vocab</code> method the issue is
          that some of the vocabulary uses a different encoding from the defined <code>utf-8</code>.</p>

          <p>These could be solutions:<br>a. Change <code>tokenization_codegen25.py
          line 169</code> encoding from <code>utf-8</code> to <code>latin-1</code><br>b.
          With the next version of this model filter non utf-8 characters from the
          vocabulary</p>

          '
        raw: "Seeing that this project has moved to Llama2 architecture, I have been\
          \ attempting to convert this model to LLAMA GGML format.\r\n\r\nI am currently\
          \ at a dead end because of inoperable implementations of `get_vocab` and\
          \ `save_vocabulary` methods in `tokenization_codegen25.py`. When attempting\
          \ to invoke the `get_vocab` method the issue is that some of the vocabulary\
          \ uses a different encoding from the defined `utf-8`.\r\n\r\nThese could\
          \ be solutions:\r\na. Change `tokenization_codegen25.py line 169` encoding\
          \ from `utf-8` to `latin-1`\r\nb. With the next version of this model filter\
          \ non utf-8 characters from the vocabulary"
        updatedAt: '2023-11-20T20:39:40.477Z'
      numEdits: 0
      reactions: []
    id: 655bc40ca6a120a5c2ead5a3
    type: comment
  author: NEDIX
  content: "Seeing that this project has moved to Llama2 architecture, I have been\
    \ attempting to convert this model to LLAMA GGML format.\r\n\r\nI am currently\
    \ at a dead end because of inoperable implementations of `get_vocab` and `save_vocabulary`\
    \ methods in `tokenization_codegen25.py`. When attempting to invoke the `get_vocab`\
    \ method the issue is that some of the vocabulary uses a different encoding from\
    \ the defined `utf-8`.\r\n\r\nThese could be solutions:\r\na. Change `tokenization_codegen25.py\
    \ line 169` encoding from `utf-8` to `latin-1`\r\nb. With the next version of\
    \ this model filter non utf-8 characters from the vocabulary"
  created_at: 2023-11-20 20:39:40+00:00
  edited: false
  hidden: false
  id: 655bc40ca6a120a5c2ead5a3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: Salesforce/codegen25-7b-mono
repo_type: model
status: open
target_branch: null
title: Vocabulary
