!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yueyueyushi
conflicting_files: null
created_at: 2023-08-06 01:18:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/95a900cac51858cec399e3a4eee2d37f.svg
      fullname: "\u9648\u8DC3"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yueyueyushi
      type: user
    createdAt: '2023-08-06T02:18:09.000Z'
    data:
      edited: false
      editors:
      - yueyueyushi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6003615856170654
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/95a900cac51858cec399e3a4eee2d37f.svg
          fullname: "\u9648\u8DC3"
          isHf: false
          isPro: false
          name: yueyueyushi
          type: user
        html: "<p>Every time I load the codegen25-7b-mono locally, whether through\
          \ checkpoint or directly downloading the corresponding files required for\
          \ codegen25 model weights and inference online in the huggingface, I encounter\
          \ issues with the title. I confirm that I have installed all the required\
          \ dependencies and can run codegen-350m-mono locally using a V100, 32G memory\
          \ GPU<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/kYRR8de9lMIp86aMTXN1V.png\"\
          ><img alt=\"\u5FAE\u4FE1\u622A\u56FE_20230806101708.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/kYRR8de9lMIp86aMTXN1V.png\"\
          ></a></p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/-AroZiekQMDwD4hlc28Jx.png\"\
          ><img alt=\"\u5FAE\u4FE1\u622A\u56FE_20230806101546.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/-AroZiekQMDwD4hlc28Jx.png\"\
          ></a></p>\n"
        raw: "Every time I load the codegen25-7b-mono locally, whether through checkpoint\
          \ or directly downloading the corresponding files required for codegen25\
          \ model weights and inference online in the huggingface, I encounter issues\
          \ with the title. I confirm that I have installed all the required dependencies\
          \ and can run codegen-350m-mono locally using a V100, 32G memory GPU\r\n\
          ![\u5FAE\u4FE1\u622A\u56FE_20230806101708.png](https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/kYRR8de9lMIp86aMTXN1V.png)\r\
          \n\r\n\r\n![\u5FAE\u4FE1\u622A\u56FE_20230806101546.png](https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/-AroZiekQMDwD4hlc28Jx.png)\r\
          \n\r\n\r\n\r\n"
        updatedAt: '2023-08-06T02:18:09.119Z'
      numEdits: 0
      reactions: []
    id: 64cf02e11ed6649d70706570
    type: comment
  author: yueyueyushi
  content: "Every time I load the codegen25-7b-mono locally, whether through checkpoint\
    \ or directly downloading the corresponding files required for codegen25 model\
    \ weights and inference online in the huggingface, I encounter issues with the\
    \ title. I confirm that I have installed all the required dependencies and can\
    \ run codegen-350m-mono locally using a V100, 32G memory GPU\r\n![\u5FAE\u4FE1\
    \u622A\u56FE_20230806101708.png](https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/kYRR8de9lMIp86aMTXN1V.png)\r\
    \n\r\n\r\n![\u5FAE\u4FE1\u622A\u56FE_20230806101546.png](https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/-AroZiekQMDwD4hlc28Jx.png)\r\
    \n\r\n\r\n\r\n"
  created_at: 2023-08-06 01:18:09+00:00
  edited: false
  hidden: false
  id: 64cf02e11ed6649d70706570
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/95a900cac51858cec399e3a4eee2d37f.svg
      fullname: "\u9648\u8DC3"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yueyueyushi
      type: user
    createdAt: '2023-08-06T08:38:23.000Z'
    data:
      edited: true
      editors:
      - yueyueyushi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9408292174339294
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/95a900cac51858cec399e3a4eee2d37f.svg
          fullname: "\u9648\u8DC3"
          isHf: false
          isPro: false
          name: yueyueyushi
          type: user
        html: "<p>40G memory is not enough. 10G Virtual memory needs to be set to\
          \ solve the problem of loading shards 0%&amp;killed. But I encountered a\
          \ new problem: during the inference process, the GPU was not used at all,\
          \ and there were no programs executing in the NVidia-smi process<br><a rel=\"\
          nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/7FUpR5ssmfdCXavdIYBKP.png\"\
          ><img alt=\"\u5FAE\u4FE1\u622A\u56FE_20230806163959.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/7FUpR5ssmfdCXavdIYBKP.png\"\
          ></a></p>\n"
        raw: "40G memory is not enough. 10G Virtual memory needs to be set to solve\
          \ the problem of loading shards 0%&killed. But I encountered a new problem:\
          \ during the inference process, the GPU was not used at all, and there were\
          \ no programs executing in the NVidia-smi process\n![\u5FAE\u4FE1\u622A\u56FE\
          _20230806163959.png](https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/7FUpR5ssmfdCXavdIYBKP.png)\n"
        updatedAt: '2023-08-06T08:47:21.903Z'
      numEdits: 2
      reactions: []
    id: 64cf5bffe9cac0020b8def88
    type: comment
  author: yueyueyushi
  content: "40G memory is not enough. 10G Virtual memory needs to be set to solve\
    \ the problem of loading shards 0%&killed. But I encountered a new problem: during\
    \ the inference process, the GPU was not used at all, and there were no programs\
    \ executing in the NVidia-smi process\n![\u5FAE\u4FE1\u622A\u56FE_20230806163959.png](https://cdn-uploads.huggingface.co/production/uploads/649bfe6c1b049ced4520efe5/7FUpR5ssmfdCXavdIYBKP.png)\n"
  created_at: 2023-08-06 07:38:23+00:00
  edited: true
  hidden: false
  id: 64cf5bffe9cac0020b8def88
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Salesforce/codegen25-7b-mono
repo_type: model
status: open
target_branch: null
title: 'Loading checkpoint shards:   0%   Killed'
