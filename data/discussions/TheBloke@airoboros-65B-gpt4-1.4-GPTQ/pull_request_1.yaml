!!python/object:huggingface_hub.community.DiscussionWithDetails
author: linuxcl4
conflicting_files: []
created_at: 2023-07-14 18:41:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d23a2961bb2ad6d1784ca5735a303a2b.svg
      fullname: Chris Lefever
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: linuxcl4
      type: user
    createdAt: '2023-07-14T19:41:03.000Z'
    data:
      edited: false
      editors:
      - linuxcl4
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9223372936248779
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d23a2961bb2ad6d1784ca5735a303a2b.svg
          fullname: Chris Lefever
          isHf: false
          isPro: false
          name: linuxcl4
          type: user
        html: '<p>I noticed the values in <code>quantize_config.json</code> don''t
          match the settings listed for the main branch in the model table in the
          README. After pulling the latest changes from main, I get CUDA illegal memory
          access errors during generation. These changes allow me to run the model
          again.</p>

          <p>The only other model I checked was <code>guanaco-65B-GPTQ</code>, but
          it seems like it might be in a similar situation.</p>

          '
        raw: 'I noticed the values in `quantize_config.json` don''t match the settings
          listed for the main branch in the model table in the README. After pulling
          the latest changes from main, I get CUDA illegal memory access errors during
          generation. These changes allow me to run the model again.


          The only other model I checked was `guanaco-65B-GPTQ`, but it seems like
          it might be in a similar situation.'
        updatedAt: '2023-07-14T19:41:03.620Z'
      numEdits: 0
      reactions: []
    id: 64b1a4cfa8aae48db5400a56
    type: comment
  author: linuxcl4
  content: 'I noticed the values in `quantize_config.json` don''t match the settings
    listed for the main branch in the model table in the README. After pulling the
    latest changes from main, I get CUDA illegal memory access errors during generation.
    These changes allow me to run the model again.


    The only other model I checked was `guanaco-65B-GPTQ`, but it seems like it might
    be in a similar situation.'
  created_at: 2023-07-14 18:41:03+00:00
  edited: false
  hidden: false
  id: 64b1a4cfa8aae48db5400a56
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/d23a2961bb2ad6d1784ca5735a303a2b.svg
      fullname: Chris Lefever
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: linuxcl4
      type: user
    createdAt: '2023-07-14T19:41:04.000Z'
    data:
      oid: a1ca82e13bb66b7bb3d9dddb363302357f67e131
      parents:
      - 25f896a284da8e59c89c97fb487d7cd2bf061843
      subject: Fix values in quantize_config.json
    id: 64b1a4d00000000000000000
    type: commit
  author: linuxcl4
  created_at: 2023-07-14 18:41:04+00:00
  id: 64b1a4d00000000000000000
  oid: a1ca82e13bb66b7bb3d9dddb363302357f67e131
  summary: Fix values in quantize_config.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-14T20:32:27.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.961418092250824
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Thank you!</p>

          <p>I had a config error when adding the new quants to this repo and Guanaco
          and Robin 65B, that uploaded the wrong format to main.  I removed the dupe
          files but forgot to fix this.</p>

          '
        raw: 'Thank you!


          I had a config error when adding the new quants to this repo and Guanaco
          and Robin 65B, that uploaded the wrong format to main.  I removed the dupe
          files but forgot to fix this.'
        updatedAt: '2023-07-14T20:32:27.445Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64b1b0db9df48bad814c112b
    id: 64b1b0db9df48bad814c1127
    type: comment
  author: TheBloke
  content: 'Thank you!


    I had a config error when adding the new quants to this repo and Guanaco and Robin
    65B, that uploaded the wrong format to main.  I removed the dupe files but forgot
    to fix this.'
  created_at: 2023-07-14 19:32:27+00:00
  edited: false
  hidden: false
  id: 64b1b0db9df48bad814c1127
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-14T20:32:27.000Z'
    data:
      status: merged
    id: 64b1b0db9df48bad814c112b
    type: status-change
  author: TheBloke
  created_at: 2023-07-14 19:32:27+00:00
  id: 64b1b0db9df48bad814c112b
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 32c9e98cc60666d29a33d56f4227701e285a1d61
num: 1
repo_id: TheBloke/airoboros-65B-gpt4-1.4-GPTQ
repo_type: model
status: merged
target_branch: refs/heads/main
title: Fix values in quantize_config.json
