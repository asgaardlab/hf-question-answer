!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ChuckMcSneed
conflicting_files: null
created_at: 2024-01-22 13:08:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4VOzArmrRaX_DUTxGmm59.jpeg?w=200&h=200&f=face
      fullname: Charles McSneed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ChuckMcSneed
      type: user
    createdAt: '2024-01-22T13:08:44.000Z'
    data:
      edited: false
      editors:
      - ChuckMcSneed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8893871307373047
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4VOzArmrRaX_DUTxGmm59.jpeg?w=200&h=200&f=face
          fullname: Charles McSneed
          isHf: false
          isPro: false
          name: ChuckMcSneed
          type: user
        html: '<p>Nice model, definitely an upgrade.<br>Compared to 0.1, 0.5 has:</p>

          <ul>

          <li>Far less GPTisms</li>

          <li>Much stronger bias towards roleplay(both a plus and a minus, on empty
          context it doesn''t like to answer questions very much, tends to drift into
          roleplay)</li>

          <li>Stricter adherence to prompt format(in 0.1 I could get away with using
          Alpaca format, here I have to use LLama chat)</li>

          <li>Stricter adherence to system prompt, here it actually feels like it
          matters</li>

          </ul>

          <p>Sadly, it still loses minor details deeper into the context.<br>Keep
          up the good work!</p>

          '
        raw: "Nice model, definitely an upgrade.\r\nCompared to 0.1, 0.5 has:\r\n\
          - Far less GPTisms\r\n- Much stronger bias towards roleplay(both a plus\
          \ and a minus, on empty context it doesn't like to answer questions very\
          \ much, tends to drift into roleplay)\r\n- Stricter adherence to prompt\
          \ format(in 0.1 I could get away with using Alpaca format, here I have to\
          \ use LLama chat)\r\n- Stricter adherence to system prompt, here it actually\
          \ feels like it matters\r\n\r\nSadly, it still loses minor details deeper\
          \ into the context.\r\nKeep up the good work!"
        updatedAt: '2024-01-22T13:08:44.881Z'
      numEdits: 0
      reactions: []
    id: 65ae68dc1216d50327a86ad0
    type: comment
  author: ChuckMcSneed
  content: "Nice model, definitely an upgrade.\r\nCompared to 0.1, 0.5 has:\r\n- Far\
    \ less GPTisms\r\n- Much stronger bias towards roleplay(both a plus and a minus,\
    \ on empty context it doesn't like to answer questions very much, tends to drift\
    \ into roleplay)\r\n- Stricter adherence to prompt format(in 0.1 I could get away\
    \ with using Alpaca format, here I have to use LLama chat)\r\n- Stricter adherence\
    \ to system prompt, here it actually feels like it matters\r\n\r\nSadly, it still\
    \ loses minor details deeper into the context.\r\nKeep up the good work!"
  created_at: 2024-01-22 13:08:44+00:00
  edited: false
  hidden: false
  id: 65ae68dc1216d50327a86ad0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/636d6fceb1079bc9b2475e7e/VefNYYXAg4xfwSEF-xL1Y.png?w=200&h=200&f=face
      fullname: Grimulkan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: grimulkan
      type: user
    createdAt: '2024-01-22T16:17:39.000Z'
    data:
      edited: true
      editors:
      - grimulkan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9645874500274658
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/636d6fceb1079bc9b2475e7e/VefNYYXAg4xfwSEF-xL1Y.png?w=200&h=200&f=face
          fullname: Grimulkan
          isHf: false
          isPro: false
          name: grimulkan
          type: user
        html: '<p>Thanks for the feedback &amp; encouragement!</p>

          <p>Some thoughts:</p>

          <ul>

          <li>I tried to include more RP, but turns out it isn''t great for that either
          (not as good as story-telling), and as you noticed, it reduced the default
          chat/query capability. You can counter this by explaining the context in
          the first prompt (or remind the AI what the task is every time you ask).
          In v1, I''ll probably try to stick all this in the system prompt so people
          can choose what sort of mode they want, and try Meta''s Ghost Attention
          trick to get the model to pay attention to the system prompt more.</li>

          <li>Stricter adherence to the prompt format is a necessary thing IMO. It
          means there is a lot of training and it is working (assuming you don''t
          want a model that talks like base Llama). IMO, finding better performance
          on different prompts is a sign that the model was not trained for the application
          it is being used for (which could be inevitable when merging). Same for
          needing to use higher temperatures. As the model improves, I''d like to
          see people being able to use lower temperature (or Mirostat Tau) and relying
          on prompts to get the creativity they want.</li>

          <li>I can objectively measure the loss of minor details over longer contexts,
          and it is slightly worse than v0.1. The reduction in chatGPTisms came from
          mildly overfitting on the story-writing data, but that also reduced long-context
          capability. Strangely, I have working CPs that have great long-context detail
          preservation (better than v0.5 at least), so for v1, I''m experimenting
          on ways to preserve both.</li>

          </ul>

          '
        raw: "Thanks for the feedback & encouragement!\n\nSome thoughts:\n - I tried\
          \ to include more RP, but turns out it isn't great for that either (not\
          \ as good as story-telling), and as you noticed, it reduced the default\
          \ chat/query capability. You can counter this by explaining the context\
          \ in the first prompt (or remind the AI what the task is every time you\
          \ ask). In v1, I'll probably try to stick all this in the system prompt\
          \ so people can choose what sort of mode they want, and try Meta's Ghost\
          \ Attention trick to get the model to pay attention to the system prompt\
          \ more.\n - Stricter adherence to the prompt format is a necessary thing\
          \ IMO. It means there is a lot of training and it is working (assuming you\
          \ don't want a model that talks like base Llama). IMO, finding better performance\
          \ on different prompts is a sign that the model was not trained for the\
          \ application it is being used for (which could be inevitable when merging).\
          \ Same for needing to use higher temperatures. As the model improves, I'd\
          \ like to see people being able to use lower temperature (or Mirostat Tau)\
          \ and relying on prompts to get the creativity they want.\n - I can objectively\
          \ measure the loss of minor details over longer contexts, and it is slightly\
          \ worse than v0.1. The reduction in chatGPTisms came from mildly overfitting\
          \ on the story-writing data, but that also reduced long-context capability.\
          \ Strangely, I have working CPs that have great long-context detail preservation\
          \ (better than v0.5 at least), so for v1, I'm experimenting on ways to preserve\
          \ both.\n"
        updatedAt: '2024-01-22T16:19:41.553Z'
      numEdits: 2
      reactions: []
    id: 65ae9523c5a0d0c82f85cc4f
    type: comment
  author: grimulkan
  content: "Thanks for the feedback & encouragement!\n\nSome thoughts:\n - I tried\
    \ to include more RP, but turns out it isn't great for that either (not as good\
    \ as story-telling), and as you noticed, it reduced the default chat/query capability.\
    \ You can counter this by explaining the context in the first prompt (or remind\
    \ the AI what the task is every time you ask). In v1, I'll probably try to stick\
    \ all this in the system prompt so people can choose what sort of mode they want,\
    \ and try Meta's Ghost Attention trick to get the model to pay attention to the\
    \ system prompt more.\n - Stricter adherence to the prompt format is a necessary\
    \ thing IMO. It means there is a lot of training and it is working (assuming you\
    \ don't want a model that talks like base Llama). IMO, finding better performance\
    \ on different prompts is a sign that the model was not trained for the application\
    \ it is being used for (which could be inevitable when merging). Same for needing\
    \ to use higher temperatures. As the model improves, I'd like to see people being\
    \ able to use lower temperature (or Mirostat Tau) and relying on prompts to get\
    \ the creativity they want.\n - I can objectively measure the loss of minor details\
    \ over longer contexts, and it is slightly worse than v0.1. The reduction in chatGPTisms\
    \ came from mildly overfitting on the story-writing data, but that also reduced\
    \ long-context capability. Strangely, I have working CPs that have great long-context\
    \ detail preservation (better than v0.5 at least), so for v1, I'm experimenting\
    \ on ways to preserve both.\n"
  created_at: 2024-01-22 16:17:39+00:00
  edited: true
  hidden: false
  id: 65ae9523c5a0d0c82f85cc4f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4VOzArmrRaX_DUTxGmm59.jpeg?w=200&h=200&f=face
      fullname: Charles McSneed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ChuckMcSneed
      type: user
    createdAt: '2024-01-23T04:43:17.000Z'
    data:
      edited: false
      editors:
      - ChuckMcSneed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9780215620994568
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4VOzArmrRaX_DUTxGmm59.jpeg?w=200&h=200&f=face
          fullname: Charles McSneed
          isHf: false
          isPro: false
          name: ChuckMcSneed
          type: user
        html: '<p>I''d rather have a model that talks like ChatGPT, but remembers
          every minor detail, than a model that forgets about what happened 10 messages
          ago, but has a great, organic writing style.</p>

          '
        raw: I'd rather have a model that talks like ChatGPT, but remembers every
          minor detail, than a model that forgets about what happened 10 messages
          ago, but has a great, organic writing style.
        updatedAt: '2024-01-23T04:43:17.543Z'
      numEdits: 0
      reactions: []
    id: 65af43e566ad44e2d5bc2dee
    type: comment
  author: ChuckMcSneed
  content: I'd rather have a model that talks like ChatGPT, but remembers every minor
    detail, than a model that forgets about what happened 10 messages ago, but has
    a great, organic writing style.
  created_at: 2024-01-23 04:43:17+00:00
  edited: false
  hidden: false
  id: 65af43e566ad44e2d5bc2dee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/636d6fceb1079bc9b2475e7e/VefNYYXAg4xfwSEF-xL1Y.png?w=200&h=200&f=face
      fullname: Grimulkan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: grimulkan
      type: user
    createdAt: '2024-01-23T16:53:13.000Z'
    data:
      edited: true
      editors:
      - grimulkan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.987424373626709
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/636d6fceb1079bc9b2475e7e/VefNYYXAg4xfwSEF-xL1Y.png?w=200&h=200&f=face
          fullname: Grimulkan
          isHf: false
          isPro: false
          name: grimulkan
          type: user
        html: '<p>I kinda went away from that and wanted the different style and lack
          of censorship, because I already have ChatGPT for the rest... It''s not
          just a style of writing, but also a form of intelligence as it needs to
          embellish and expand on your instructions in creative ways.</p>

          <p>It could just be I''m trying to do too much in 70B, and really I should
          be making a story-writing model, an RP model and an analyzing "work" model
          (that could sound like ChatGPT, assuming that''s what you meant). Let''s
          see... EDIT: Or maybe you meant an RP or story-writing model that can write
          like ChatGPT (IMO, badly), but nevertheless keeps context? That might actually
          be a bit easier to train.</p>

          <p>I''d still rather try to do it all in one model.</p>

          '
        raw: 'I kinda went away from that and wanted the different style and lack
          of censorship, because I already have ChatGPT for the rest... It''s not
          just a style of writing, but also a form of intelligence as it needs to
          embellish and expand on your instructions in creative ways.


          It could just be I''m trying to do too much in 70B, and really I should
          be making a story-writing model, an RP model and an analyzing "work" model
          (that could sound like ChatGPT, assuming that''s what you meant). Let''s
          see... EDIT: Or maybe you meant an RP or story-writing model that can write
          like ChatGPT (IMO, badly), but nevertheless keeps context? That might actually
          be a bit easier to train.


          I''d still rather try to do it all in one model.'
        updatedAt: '2024-01-23T16:55:20.249Z'
      numEdits: 1
      reactions: []
    id: 65afeef9dfa67a6de9ff0893
    type: comment
  author: grimulkan
  content: 'I kinda went away from that and wanted the different style and lack of
    censorship, because I already have ChatGPT for the rest... It''s not just a style
    of writing, but also a form of intelligence as it needs to embellish and expand
    on your instructions in creative ways.


    It could just be I''m trying to do too much in 70B, and really I should be making
    a story-writing model, an RP model and an analyzing "work" model (that could sound
    like ChatGPT, assuming that''s what you meant). Let''s see... EDIT: Or maybe you
    meant an RP or story-writing model that can write like ChatGPT (IMO, badly), but
    nevertheless keeps context? That might actually be a bit easier to train.


    I''d still rather try to do it all in one model.'
  created_at: 2024-01-23 16:53:13+00:00
  edited: true
  hidden: false
  id: 65afeef9dfa67a6de9ff0893
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4VOzArmrRaX_DUTxGmm59.jpeg?w=200&h=200&f=face
      fullname: Charles McSneed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ChuckMcSneed
      type: user
    createdAt: '2024-01-24T09:48:22.000Z'
    data:
      edited: false
      editors:
      - ChuckMcSneed
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9765767455101013
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4VOzArmrRaX_DUTxGmm59.jpeg?w=200&h=200&f=face
          fullname: Charles McSneed
          isHf: false
          isPro: false
          name: ChuckMcSneed
          type: user
        html: '<p>I did mean that it is better to have a model that has a shitty writing
          style(ChatGPT), but keeps context. So, keeping track of things should be
          the priority, beautiful writing style can come later.</p>

          '
        raw: I did mean that it is better to have a model that has a shitty writing
          style(ChatGPT), but keeps context. So, keeping track of things should be
          the priority, beautiful writing style can come later.
        updatedAt: '2024-01-24T09:48:22.281Z'
      numEdits: 0
      reactions: []
    id: 65b0dce6be8efb3dd37e3b3f
    type: comment
  author: ChuckMcSneed
  content: I did mean that it is better to have a model that has a shitty writing
    style(ChatGPT), but keeps context. So, keeping track of things should be the priority,
    beautiful writing style can come later.
  created_at: 2024-01-24 09:48:22+00:00
  edited: false
  hidden: false
  id: 65b0dce6be8efb3dd37e3b3f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: grimulkan/aurelian-v0.5-70b-rope8-32K-fp16
repo_type: model
status: open
target_branch: null
title: Comparison with 0.1
