!!python/object:huggingface_hub.community.DiscussionWithDetails
author: iyodev
conflicting_files: null
created_at: 2023-11-03 21:08:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fb1a4788644c17db80c4cd0663765005.svg
      fullname: Iyo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iyodev
      type: user
    createdAt: '2023-11-03T22:08:49.000Z'
    data:
      edited: false
      editors:
      - iyodev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9054931998252869
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fb1a4788644c17db80c4cd0663765005.svg
          fullname: Iyo
          isHf: false
          isPro: false
          name: iyodev
          type: user
        html: '<p>Looking for an easy way to spool up briefly for testing! Could also
          be another deployment method.</p>

          '
        raw: Looking for an easy way to spool up briefly for testing! Could also be
          another deployment method.
        updatedAt: '2023-11-03T22:08:49.504Z'
      numEdits: 0
      reactions: []
    id: 65456f715cd5692b3a7c5a5d
    type: comment
  author: iyodev
  content: Looking for an easy way to spool up briefly for testing! Could also be
    another deployment method.
  created_at: 2023-11-03 21:08:49+00:00
  edited: false
  hidden: false
  id: 65456f715cd5692b3a7c5a5d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-11-04T12:30:40.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8350836038589478
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: "<p>Howdy <span data-props=\"{&quot;user&quot;:&quot;iyodev&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/iyodev\"\
          >@<span class=\"underline\">iyodev</span></a></span>\n\n\t</span></span>\
          \ :</p>\n<p>A) I've just enabled hosted inference.</p>\n<ul>\n<li>Will only\
          \ work with an access token (and if you've paid and gotten access - which\
          \ you have, I believe!)</li>\n<li>The free inference won't work because\
          \ the model is larger than 10 GB in size.</li>\n</ul>\n<p>B) Deploying on\
          \ runpod is probably an easy option. You can try <a rel=\"nofollow\" href=\"\
          https://runpod.io/gsc?template=81gbh0y9um&amp;ref=jmfkcdio\">this template</a>.\
          \ Make sure to read the ReadMe and use an access token.</p>\n"
        raw: 'Howdy @iyodev :


          A) I''ve just enabled hosted inference.

          - Will only work with an access token (and if you''ve paid and gotten access
          - which you have, I believe!)

          - The free inference won''t work because the model is larger than 10 GB
          in size.


          B) Deploying on runpod is probably an easy option. You can try [this template](https://runpod.io/gsc?template=81gbh0y9um&ref=jmfkcdio).
          Make sure to read the ReadMe and use an access token.

          '
        updatedAt: '2023-11-04T12:30:40.048Z'
      numEdits: 0
      reactions: []
    id: 654639708db75bfe5d46df12
    type: comment
  author: RonanMcGovern
  content: 'Howdy @iyodev :


    A) I''ve just enabled hosted inference.

    - Will only work with an access token (and if you''ve paid and gotten access -
    which you have, I believe!)

    - The free inference won''t work because the model is larger than 10 GB in size.


    B) Deploying on runpod is probably an easy option. You can try [this template](https://runpod.io/gsc?template=81gbh0y9um&ref=jmfkcdio).
    Make sure to read the ReadMe and use an access token.

    '
  created_at: 2023-11-04 11:30:40+00:00
  edited: false
  hidden: false
  id: 654639708db75bfe5d46df12
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fb1a4788644c17db80c4cd0663765005.svg
      fullname: Iyo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iyodev
      type: user
    createdAt: '2023-11-06T17:03:06.000Z'
    data:
      edited: true
      editors:
      - iyodev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9299987554550171
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fb1a4788644c17db80c4cd0663765005.svg
          fullname: Iyo
          isHf: false
          isPro: false
          name: iyodev
          type: user
        html: '<p>Thanks Ronan! Do you happen to have an example of how to use the
          hosted inference for this large of a model? Or do you mean I should create
          an inference endpoint?</p>

          '
        raw: Thanks Ronan! Do you happen to have an example of how to use the hosted
          inference for this large of a model? Or do you mean I should create an inference
          endpoint?
        updatedAt: '2023-11-06T17:06:35.466Z'
      numEdits: 2
      reactions: []
    id: 65491c4a1bb891a5a4f23b9a
    type: comment
  author: iyodev
  content: Thanks Ronan! Do you happen to have an example of how to use the hosted
    inference for this large of a model? Or do you mean I should create an inference
    endpoint?
  created_at: 2023-11-06 17:03:06+00:00
  edited: true
  hidden: false
  id: 65491c4a1bb891a5a4f23b9a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-11-07T10:34:03.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9455443024635315
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>Yeah the hosted inference won''t work for models bigger than 10
          GB . I think it maybe works if you have a HuggingFace paid plan, but I''m
          not sure.</p>

          <p>Yes, create an inference endpoint, or deploy using runpod.</p>

          '
        raw: 'Yeah the hosted inference won''t work for models bigger than 10 GB .
          I think it maybe works if you have a HuggingFace paid plan, but I''m not
          sure.


          Yes, create an inference endpoint, or deploy using runpod.'
        updatedAt: '2023-11-07T10:34:03.798Z'
      numEdits: 0
      reactions: []
    id: 654a129b55ecd2d37ab2a685
    type: comment
  author: RonanMcGovern
  content: 'Yeah the hosted inference won''t work for models bigger than 10 GB . I
    think it maybe works if you have a HuggingFace paid plan, but I''m not sure.


    Yes, create an inference endpoint, or deploy using runpod.'
  created_at: 2023-11-07 10:34:03+00:00
  edited: false
  hidden: false
  id: 654a129b55ecd2d37ab2a685
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fb1a4788644c17db80c4cd0663765005.svg
      fullname: Iyo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iyodev
      type: user
    createdAt: '2023-11-09T17:52:10.000Z'
    data:
      edited: false
      editors:
      - iyodev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8050064444541931
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fb1a4788644c17db80c4cd0663765005.svg
          fullname: Iyo
          isHf: false
          isPro: false
          name: iyodev
          type: user
        html: '<p>Thank you, the inference endpoint is working for me. Do you happen
          to know if any frameworks like langchain, llamaindex, litellm, etc already
          have the necessary formatting for function calling baked in?</p>

          '
        raw: Thank you, the inference endpoint is working for me. Do you happen to
          know if any frameworks like langchain, llamaindex, litellm, etc already
          have the necessary formatting for function calling baked in?
        updatedAt: '2023-11-09T17:52:10.565Z'
      numEdits: 0
      reactions: []
    id: 654d1c4a1e6216cb2d834bea
    type: comment
  author: iyodev
  content: Thank you, the inference endpoint is working for me. Do you happen to know
    if any frameworks like langchain, llamaindex, litellm, etc already have the necessary
    formatting for function calling baked in?
  created_at: 2023-11-09 17:52:10+00:00
  edited: false
  hidden: false
  id: 654d1c4a1e6216cb2d834bea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-11-09T17:55:47.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9229100942611694
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: "<p>unfortunately, I don't know <span data-props=\"{&quot;user&quot;:&quot;iyodev&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/iyodev\"\
          >@<span class=\"underline\">iyodev</span></a></span>\n\n\t</span></span>\
          \ , but appreciate you keeping me posted if you gain any insights. Any learnings\
          \ can inform a v3 for function calling.</p>\n"
        raw: unfortunately, I don't know @iyodev , but appreciate you keeping me posted
          if you gain any insights. Any learnings can inform a v3 for function calling.
        updatedAt: '2023-11-09T17:55:47.674Z'
      numEdits: 0
      reactions: []
    id: 654d1d23c9916525ebd8313e
    type: comment
  author: RonanMcGovern
  content: unfortunately, I don't know @iyodev , but appreciate you keeping me posted
    if you gain any insights. Any learnings can inform a v3 for function calling.
  created_at: 2023-11-09 17:55:47+00:00
  edited: false
  hidden: false
  id: 654d1d23c9916525ebd8313e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-11-16T10:44:00.000Z'
    data:
      status: closed
    id: 6555f270d4f86c8cbfec3af7
    type: status-change
  author: RonanMcGovern
  created_at: 2023-11-16 10:44:00+00:00
  id: 6555f270d4f86c8cbfec3af7
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Trelis/CodeLlama-34b-Instruct-hf-function-calling-v2
repo_type: model
status: closed
target_branch: null
title: Is there a way to deploy using a Hugging Face inference endpoint?
