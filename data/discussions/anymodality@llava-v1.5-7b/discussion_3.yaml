!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MetaSkills
conflicting_files: null
created_at: 2023-11-01 10:06:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1uhbC02C61vRVZ6boso6w.jpeg?w=200&h=200&f=face
      fullname: Ken Collins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MetaSkills
      type: user
    createdAt: '2023-11-01T11:06:20.000Z'
    data:
      edited: false
      editors:
      - MetaSkills
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9672497510910034
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1uhbC02C61vRVZ6boso6w.jpeg?w=200&h=200&f=face
          fullname: Ken Collins
          isHf: false
          isPro: false
          name: MetaSkills
          type: user
        html: '<p>This might showcase my ignorance on how much the SageMaker tools
          are doing with the Deep Learning Containers. But thought I would ask.</p>

          '
        raw: This might showcase my ignorance on how much the SageMaker tools are
          doing with the Deep Learning Containers. But thought I would ask.
        updatedAt: '2023-11-01T11:06:20.445Z'
      numEdits: 0
      reactions: []
    id: 6542312c3550a043ff7a09e0
    type: comment
  author: MetaSkills
  content: This might showcase my ignorance on how much the SageMaker tools are doing
    with the Deep Learning Containers. But thought I would ask.
  created_at: 2023-11-01 10:06:20+00:00
  edited: false
  hidden: false
  id: 6542312c3550a043ff7a09e0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5c97adf2ca56230f0c3766606a7d05bb.svg
      fullname: Tom Gou
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: liltom-eth
      type: user
    createdAt: '2023-11-04T00:10:37.000Z'
    data:
      edited: false
      editors:
      - liltom-eth
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8200539350509644
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5c97adf2ca56230f0c3766606a7d05bb.svg
          fullname: Tom Gou
          isHf: false
          isPro: false
          name: liltom-eth
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;MetaSkills&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/MetaSkills\">@<span class=\"\
          underline\">MetaSkills</span></a></span>\n\n\t</span></span> Yeah, the deployment\
          \ happens on a GPU when GPU instance is specified. The SageMaker gives users\
          \ pre-built Pytorch Deep Learning Containers and we customize the container\
          \ with some package defined in <code>requirements.txt</code>, and use <code>inference.py</code>\
          \ to define the endpoint interface.<br>Is that your question?</p>\n"
        raw: '@MetaSkills Yeah, the deployment happens on a GPU when GPU instance
          is specified. The SageMaker gives users pre-built Pytorch Deep Learning
          Containers and we customize the container with some package defined in `requirements.txt`,
          and use `inference.py` to define the endpoint interface.

          Is that your question?'
        updatedAt: '2023-11-04T00:10:37.509Z'
      numEdits: 0
      reactions: []
    id: 65458bfde3486f8a5e6a2815
    type: comment
  author: liltom-eth
  content: '@MetaSkills Yeah, the deployment happens on a GPU when GPU instance is
    specified. The SageMaker gives users pre-built Pytorch Deep Learning Containers
    and we customize the container with some package defined in `requirements.txt`,
    and use `inference.py` to define the endpoint interface.

    Is that your question?'
  created_at: 2023-11-03 23:10:37+00:00
  edited: false
  hidden: false
  id: 65458bfde3486f8a5e6a2815
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1uhbC02C61vRVZ6boso6w.jpeg?w=200&h=200&f=face
      fullname: Ken Collins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MetaSkills
      type: user
    createdAt: '2023-11-04T12:21:48.000Z'
    data:
      edited: false
      editors:
      - MetaSkills
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9507313966751099
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1uhbC02C61vRVZ6boso6w.jpeg?w=200&h=200&f=face
          fullname: Ken Collins
          isHf: false
          isPro: false
          name: MetaSkills
          type: user
        html: '<p>Thanks, but not really. </p>

          <p>Was more or less thinking about the machine running the deployment. I
          never spun up SageMaker to play with the Notebook because I could never
          get LFS working with any SageMaker setup. Yum not working, etc, etc. </p>

          <p>So, I ended up pulling apart the notebook into little bash scripts and
          running them from a Python Devcontainer locally, in my M2 Mac. And everything
          works. But the whole python code for the SageMaker deploy is still a mystery
          to me in how the final DLC is built and where that happens. My guess is
          remotely someplace in the pipeline. Hence the question. Totally something
          I can keep digging and learn myself too. </p>

          '
        raw: "Thanks, but not really. \n\nWas more or less thinking about the machine\
          \ running the deployment. I never spun up SageMaker to play with the Notebook\
          \ because I could never get LFS working with any SageMaker setup. Yum not\
          \ working, etc, etc. \n\nSo, I ended up pulling apart the notebook into\
          \ little bash scripts and running them from a Python Devcontainer locally,\
          \ in my M2 Mac. And everything works. But the whole python code for the\
          \ SageMaker deploy is still a mystery to me in how the final DLC is built\
          \ and where that happens. My guess is remotely someplace in the pipeline.\
          \ Hence the question. Totally something I can keep digging and learn myself\
          \ too. "
        updatedAt: '2023-11-04T12:21:48.523Z'
      numEdits: 0
      reactions: []
    id: 6546375c28b7019eae06f06d
    type: comment
  author: MetaSkills
  content: "Thanks, but not really. \n\nWas more or less thinking about the machine\
    \ running the deployment. I never spun up SageMaker to play with the Notebook\
    \ because I could never get LFS working with any SageMaker setup. Yum not working,\
    \ etc, etc. \n\nSo, I ended up pulling apart the notebook into little bash scripts\
    \ and running them from a Python Devcontainer locally, in my M2 Mac. And everything\
    \ works. But the whole python code for the SageMaker deploy is still a mystery\
    \ to me in how the final DLC is built and where that happens. My guess is remotely\
    \ someplace in the pipeline. Hence the question. Totally something I can keep\
    \ digging and learn myself too. "
  created_at: 2023-11-04 11:21:48+00:00
  edited: false
  hidden: false
  id: 6546375c28b7019eae06f06d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/1uhbC02C61vRVZ6boso6w.jpeg?w=200&h=200&f=face
      fullname: Ken Collins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MetaSkills
      type: user
    createdAt: '2023-11-04T12:22:57.000Z'
    data:
      from: Should Deploy Happen on a GPU?
      to: "Should Deploy Happen o\u0336n\u0336 from a GPU?"
    id: 654637a1b8ac1a89ffc45adb
    type: title-change
  author: MetaSkills
  created_at: 2023-11-04 11:22:57+00:00
  id: 654637a1b8ac1a89ffc45adb
  new_title: "Should Deploy Happen o\u0336n\u0336 from a GPU?"
  old_title: Should Deploy Happen on a GPU?
  type: title-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: anymodality/llava-v1.5-7b
repo_type: model
status: open
target_branch: null
title: "Should Deploy Happen o\u0336n\u0336 from a GPU?"
