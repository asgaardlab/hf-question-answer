!!python/object:huggingface_hub.community.DiscussionWithDetails
author: irenedea
conflicting_files: []
created_at: 2024-01-19 17:30:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/21a9a778ee5350a1e620d2bd848ee581.svg
      fullname: Irene Dea
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: irenedea
      type: user
    createdAt: '2024-01-19T17:30:19.000Z'
    data:
      edited: true
      editors:
      - irenedea
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/21a9a778ee5350a1e620d2bd848ee581.svg
          fullname: Irene Dea
          isHf: false
          isPro: false
          name: irenedea
          type: user
        html: "<p>Manually tested with</p>\n<pre><code>from transformers import AutoTokenizer\n\
          \ntokenizer = AutoTokenizer.from_pretrained('mosaicml/mpt-7b-8k-chat', revision='refs/pr/7')\n\
          \nchat = [\n    {\"role\": \"system\", \"content\": \"This is a system prompt!\"\
          },\n   {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n   {\"\
          role\": \"assistant\", \"content\": \"I'm doing great. How can I help you\
          \ today?\"},\n   {\"role\": \"user\", \"content\": \"I'd like to show off\
          \ how chat templating works!\"},\n]\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n\n# Remove system prompt\nchat = chat[1:]\n\nprint(\"\
          \\nUsing default system prompt!\\n\")\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n</code></pre>\n<p>output:</p>\n<pre><code>&lt;|im_start|&gt;system\n\
          This is a system prompt!\n&lt;|im_start|&gt;user\nHello, how are you?&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;assistant\nI'm doing great. How can I help you today?&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;user\nI'd like to show off how chat templating works!&lt;|im_end|&gt;\n\
          \nUsing default system prompt!\n\n&lt;|im_start|&gt;system\nA conversation\
          \ between a user and an LLM-based AI assistant. The assistant gives helpful\
          \ and honest answers.\n&lt;|im_start|&gt;user\nHello, how are you?&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;assistant\nI'm doing great. How can I help you today?&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;user\nI'd like to show off how chat templating works!&lt;|im_end|&gt;\n\
          </code></pre>\n"
        raw: "Manually tested with\n```\nfrom transformers import AutoTokenizer\n\n\
          tokenizer = AutoTokenizer.from_pretrained('mosaicml/mpt-7b-8k-chat', revision='refs/pr/7')\n\
          \nchat = [\n    {\"role\": \"system\", \"content\": \"This is a system prompt!\"\
          },\n   {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n   {\"\
          role\": \"assistant\", \"content\": \"I'm doing great. How can I help you\
          \ today?\"},\n   {\"role\": \"user\", \"content\": \"I'd like to show off\
          \ how chat templating works!\"},\n]\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n\n# Remove system prompt\nchat = chat[1:]\n\nprint(\"\
          \\nUsing default system prompt!\\n\")\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n```\n\noutput:\n```\n<|im_start|>system\nThis is a system\
          \ prompt!\n<|im_start|>user\nHello, how are you?<|im_end|>\n<|im_start|>assistant\n\
          I'm doing great. How can I help you today?<|im_end|>\n<|im_start|>user\n\
          I'd like to show off how chat templating works!<|im_end|>\n\nUsing default\
          \ system prompt!\n\n<|im_start|>system\nA conversation between a user and\
          \ an LLM-based AI assistant. The assistant gives helpful and honest answers.\n\
          <|im_start|>user\nHello, how are you?<|im_end|>\n<|im_start|>assistant\n\
          I'm doing great. How can I help you today?<|im_end|>\n<|im_start|>user\n\
          I'd like to show off how chat templating works!<|im_end|>\n```"
        updatedAt: '2024-01-19T17:31:39.932Z'
      numEdits: 1
      reactions: []
    id: 65aab1ab0844d9e0d6f0224f
    type: comment
  author: irenedea
  content: "Manually tested with\n```\nfrom transformers import AutoTokenizer\n\n\
    tokenizer = AutoTokenizer.from_pretrained('mosaicml/mpt-7b-8k-chat', revision='refs/pr/7')\n\
    \nchat = [\n    {\"role\": \"system\", \"content\": \"This is a system prompt!\"\
    },\n   {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n   {\"role\"\
    : \"assistant\", \"content\": \"I'm doing great. How can I help you today?\"},\n\
    \   {\"role\": \"user\", \"content\": \"I'd like to show off how chat templating\
    \ works!\"},\n]\n\nprint(tokenizer.apply_chat_template(chat, tokenize=False))\n\
    \n# Remove system prompt\nchat = chat[1:]\n\nprint(\"\\nUsing default system prompt!\\\
    n\")\n\nprint(tokenizer.apply_chat_template(chat, tokenize=False))\n```\n\noutput:\n\
    ```\n<|im_start|>system\nThis is a system prompt!\n<|im_start|>user\nHello, how\
    \ are you?<|im_end|>\n<|im_start|>assistant\nI'm doing great. How can I help you\
    \ today?<|im_end|>\n<|im_start|>user\nI'd like to show off how chat templating\
    \ works!<|im_end|>\n\nUsing default system prompt!\n\n<|im_start|>system\nA conversation\
    \ between a user and an LLM-based AI assistant. The assistant gives helpful and\
    \ honest answers.\n<|im_start|>user\nHello, how are you?<|im_end|>\n<|im_start|>assistant\n\
    I'm doing great. How can I help you today?<|im_end|>\n<|im_start|>user\nI'd like\
    \ to show off how chat templating works!<|im_end|>\n```"
  created_at: 2024-01-19 17:30:19+00:00
  edited: true
  hidden: false
  id: 65aab1ab0844d9e0d6f0224f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/21a9a778ee5350a1e620d2bd848ee581.svg
      fullname: Irene Dea
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: irenedea
      type: user
    createdAt: '2024-01-19T17:30:20.000Z'
    data:
      oid: 6bff2e3eee113e574c8bd3dd17b01b898cbf1eaa
      parents:
      - 650f92b8c18c2167b10b6a44ed8c1bfdfa854b00
      subject: Add chat_template to tokenizer_config.json
    id: 65aab1ac0000000000000000
    type: commit
  author: irenedea
  created_at: 2024-01-19 17:30:20+00:00
  id: 65aab1ac0000000000000000
  oid: 6bff2e3eee113e574c8bd3dd17b01b898cbf1eaa
  summary: Add chat_template to tokenizer_config.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
      fullname: Sam Havens
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sam-mosaic
      type: user
    createdAt: '2024-01-19T18:01:52.000Z'
    data:
      edited: false
      editors:
      - sam-mosaic
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5141879916191101
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
          fullname: Sam Havens
          isHf: false
          isPro: false
          name: sam-mosaic
          type: user
        html: '<p>LGTM!</p>

          '
        raw: LGTM!
        updatedAt: '2024-01-19T18:01:52.747Z'
      numEdits: 0
      reactions: []
    id: 65aab910fd4261f531e394dc
    type: comment
  author: sam-mosaic
  content: LGTM!
  created_at: 2024-01-19 18:01:52+00:00
  edited: false
  hidden: false
  id: 65aab910fd4261f531e394dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
      fullname: Sam Havens
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sam-mosaic
      type: user
    createdAt: '2024-01-19T18:14:09.000Z'
    data:
      status: merged
    id: 65aabbf1f8111f40c0542662
    type: status-change
  author: sam-mosaic
  created_at: 2024-01-19 18:14:09+00:00
  id: 65aabbf1f8111f40c0542662
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 03fb479d26de4c9c358909f375b2d8942422a9d9
num: 7
repo_id: mosaicml/mpt-7b-8k-chat
repo_type: model
status: merged
target_branch: refs/heads/main
title: Add chat_template to tokenizer_config.json
