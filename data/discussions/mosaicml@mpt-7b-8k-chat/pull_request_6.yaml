!!python/object:huggingface_hub.community.DiscussionWithDetails
author: irenedea
conflicting_files:
- tokenizer_config.json
created_at: 2024-01-11 18:05:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/21a9a778ee5350a1e620d2bd848ee581.svg
      fullname: Irene Dea
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: irenedea
      type: user
    createdAt: '2024-01-11T18:05:17.000Z'
    data:
      edited: true
      editors:
      - irenedea
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7200829982757568
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/21a9a778ee5350a1e620d2bd848ee581.svg
          fullname: Irene Dea
          isHf: false
          isPro: false
          name: irenedea
          type: user
        html: "<p>Manually tested with</p>\n<pre><code>from transformers import AutoTokenizer\n\
          \ntokenizer = AutoTokenizer.from_pretrained('mosaicml/mpt-7b-8k-chat', revision='refs/pr/6')\n\
          \nchat = [\n    {\"role\": \"system\", \"content\": \"This is a system prompt!\"\
          },\n   {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n   {\"\
          role\": \"assistant\", \"content\": \"I'm doing great. How can I help you\
          \ today?\"},\n   {\"role\": \"user\", \"content\": \"I'd like to show off\
          \ how chat templating works!\"},\n]\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n\n# Remove system prompt\nchat = chat[1:]\n\nprint(\"\
          \\nUsing default system prompt!\\n\")\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n</code></pre>\n<p>output:</p>\n<pre><code>&lt;|im_start|&gt;system\n\
          This is a system prompt!\n&lt;|im_start|&gt;user\nHello, how are you?&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;assistant\nI'm doing great. How can I help you today?&lt;|im_end|&gt;&lt;|endoftext|&gt;\n\
          &lt;|im_start|&gt;user\nI'd like to show off how chat templating works!&lt;|im_end|&gt;\n\
          \nUsing default system prompt!\n\n&lt;|im_start|&gt;system\nA conversation\
          \ between a user and an LLM-based AI assistant. The assistant gives helpful\
          \ and honest answers.\n&lt;|im_start|&gt;user\nHello, how are you?&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;assistant\nI'm doing great. How can I help you today?&lt;|im_end|&gt;&lt;|endoftext|&gt;\n\
          &lt;|im_start|&gt;user\nI'd like to show off how chat templating works!&lt;|im_end|&gt;\n\
          </code></pre>\n"
        raw: "Manually tested with\n```\nfrom transformers import AutoTokenizer\n\n\
          tokenizer = AutoTokenizer.from_pretrained('mosaicml/mpt-7b-8k-chat', revision='refs/pr/6')\n\
          \nchat = [\n    {\"role\": \"system\", \"content\": \"This is a system prompt!\"\
          },\n   {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n   {\"\
          role\": \"assistant\", \"content\": \"I'm doing great. How can I help you\
          \ today?\"},\n   {\"role\": \"user\", \"content\": \"I'd like to show off\
          \ how chat templating works!\"},\n]\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n\n# Remove system prompt\nchat = chat[1:]\n\nprint(\"\
          \\nUsing default system prompt!\\n\")\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n```\n\noutput:\n```\n<|im_start|>system\nThis is a system\
          \ prompt!\n<|im_start|>user\nHello, how are you?<|im_end|>\n<|im_start|>assistant\n\
          I'm doing great. How can I help you today?<|im_end|><|endoftext|>\n<|im_start|>user\n\
          I'd like to show off how chat templating works!<|im_end|>\n\nUsing default\
          \ system prompt!\n\n<|im_start|>system\nA conversation between a user and\
          \ an LLM-based AI assistant. The assistant gives helpful and honest answers.\n\
          <|im_start|>user\nHello, how are you?<|im_end|>\n<|im_start|>assistant\n\
          I'm doing great. How can I help you today?<|im_end|><|endoftext|>\n<|im_start|>user\n\
          I'd like to show off how chat templating works!<|im_end|>\n```"
        updatedAt: '2024-01-11T18:05:57.474Z'
      numEdits: 1
      reactions: []
    id: 65a02ddd90eb7a1524d0d1d9
    type: comment
  author: irenedea
  content: "Manually tested with\n```\nfrom transformers import AutoTokenizer\n\n\
    tokenizer = AutoTokenizer.from_pretrained('mosaicml/mpt-7b-8k-chat', revision='refs/pr/6')\n\
    \nchat = [\n    {\"role\": \"system\", \"content\": \"This is a system prompt!\"\
    },\n   {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n   {\"role\"\
    : \"assistant\", \"content\": \"I'm doing great. How can I help you today?\"},\n\
    \   {\"role\": \"user\", \"content\": \"I'd like to show off how chat templating\
    \ works!\"},\n]\n\nprint(tokenizer.apply_chat_template(chat, tokenize=False))\n\
    \n# Remove system prompt\nchat = chat[1:]\n\nprint(\"\\nUsing default system prompt!\\\
    n\")\n\nprint(tokenizer.apply_chat_template(chat, tokenize=False))\n```\n\noutput:\n\
    ```\n<|im_start|>system\nThis is a system prompt!\n<|im_start|>user\nHello, how\
    \ are you?<|im_end|>\n<|im_start|>assistant\nI'm doing great. How can I help you\
    \ today?<|im_end|><|endoftext|>\n<|im_start|>user\nI'd like to show off how chat\
    \ templating works!<|im_end|>\n\nUsing default system prompt!\n\n<|im_start|>system\n\
    A conversation between a user and an LLM-based AI assistant. The assistant gives\
    \ helpful and honest answers.\n<|im_start|>user\nHello, how are you?<|im_end|>\n\
    <|im_start|>assistant\nI'm doing great. How can I help you today?<|im_end|><|endoftext|>\n\
    <|im_start|>user\nI'd like to show off how chat templating works!<|im_end|>\n\
    ```"
  created_at: 2024-01-11 18:05:17+00:00
  edited: true
  hidden: false
  id: 65a02ddd90eb7a1524d0d1d9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/21a9a778ee5350a1e620d2bd848ee581.svg
      fullname: Irene Dea
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: irenedea
      type: user
    createdAt: '2024-01-11T18:05:18.000Z'
    data:
      oid: 3d10b01f56bbab9bab89054a9e9e1c7023fbefc3
      parents:
      - 650f92b8c18c2167b10b6a44ed8c1bfdfa854b00
      subject: Add chat_template to tokenizer_config.json
    id: 65a02dde0000000000000000
    type: commit
  author: irenedea
  created_at: 2024-01-11 18:05:18+00:00
  id: 65a02dde0000000000000000
  oid: 3d10b01f56bbab9bab89054a9e9e1c7023fbefc3
  summary: Add chat_template to tokenizer_config.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/21a9a778ee5350a1e620d2bd848ee581.svg
      fullname: Irene Dea
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: irenedea
      type: user
    createdAt: '2024-01-19T17:31:49.000Z'
    data:
      status: closed
    id: 65aab20564c9b93ecaa6a7ee
    type: status-change
  author: irenedea
  created_at: 2024-01-19 17:31:49+00:00
  id: 65aab20564c9b93ecaa6a7ee
  new_status: closed
  type: status-change
is_pull_request: true
merge_commit_oid: null
num: 6
repo_id: mosaicml/mpt-7b-8k-chat
repo_type: model
status: closed
target_branch: refs/heads/main
title: Add chat_template to tokenizer_config.json
