!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Xeba111
conflicting_files: null
created_at: 2023-09-27 15:46:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/605398d6c38217ea8540c669ddaff1d6.svg
      fullname: "Sebasti\xE1n "
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Xeba111
      type: user
    createdAt: '2023-09-27T16:46:48.000Z'
    data:
      edited: false
      editors:
      - Xeba111
      hidden: false
      identifiedLanguage:
        language: es
        probability: 0.9706020951271057
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/605398d6c38217ea8540c669ddaff1d6.svg
          fullname: "Sebasti\xE1n "
          isHf: false
          isPro: false
          name: Xeba111
          type: user
        html: "<p>Actualmente estoy haciendo mi tesis de pregrado para la universidad.\
          \ Quiero construir un chatbot que responda preguntas acerca de un tema espec\xED\
          fico, los impuestos en Ecuador, mi pa\xEDs. Para lograr esto quiero usar\
          \ t\xE9cnicas de fine-tuning, ya que el poder comptuacional no es un problema\
          \ porque mi universidad dispone de Workstations. Dicho esto, quisiera saber\
          \ si \xBFpuedo usar este modelo para hacerle fine-tuning respecto a mi tema\
          \ o se perder\xEDan los weights que ya tiene el modelo y no me dar\xEDa\
          \ mejoras notables sobre usar el LLAMA2 normal?</p>\n"
        raw: "Actualmente estoy haciendo mi tesis de pregrado para la universidad.\
          \ Quiero construir un chatbot que responda preguntas acerca de un tema espec\xED\
          fico, los impuestos en Ecuador, mi pa\xEDs. Para lograr esto quiero usar\
          \ t\xE9cnicas de fine-tuning, ya que el poder comptuacional no es un problema\
          \ porque mi universidad dispone de Workstations. Dicho esto, quisiera saber\
          \ si \xBFpuedo usar este modelo para hacerle fine-tuning respecto a mi tema\
          \ o se perder\xEDan los weights que ya tiene el modelo y no me dar\xEDa\
          \ mejoras notables sobre usar el LLAMA2 normal?"
        updatedAt: '2023-09-27T16:46:48.094Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F92F"
        users:
        - EZUNIGAF
      - count: 1
        reaction: "\U0001F44D"
        users:
        - EZUNIGAF
    id: 65145c784a40f1435957347e
    type: comment
  author: Xeba111
  content: "Actualmente estoy haciendo mi tesis de pregrado para la universidad. Quiero\
    \ construir un chatbot que responda preguntas acerca de un tema espec\xEDfico,\
    \ los impuestos en Ecuador, mi pa\xEDs. Para lograr esto quiero usar t\xE9cnicas\
    \ de fine-tuning, ya que el poder comptuacional no es un problema porque mi universidad\
    \ dispone de Workstations. Dicho esto, quisiera saber si \xBFpuedo usar este modelo\
    \ para hacerle fine-tuning respecto a mi tema o se perder\xEDan los weights que\
    \ ya tiene el modelo y no me dar\xEDa mejoras notables sobre usar el LLAMA2 normal?"
  created_at: 2023-09-27 15:46:48+00:00
  edited: false
  hidden: false
  id: 65145c784a40f1435957347e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: clibrain/Llama-2-13b-ft-instruct-es
repo_type: model
status: open
target_branch: null
title: "Hola, \xBFpodr\xEDa hacerle fine-tuning a este modelo?"
