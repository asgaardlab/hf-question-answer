!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hujunc
conflicting_files: null
created_at: 2023-12-05 12:56:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cc5ef8e6e212c675c4d016a173e5683b.svg
      fullname: hujunchi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hujunc
      type: user
    createdAt: '2023-12-05T12:56:38.000Z'
    data:
      edited: false
      editors:
      - hujunc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8918026089668274
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cc5ef8e6e212c675c4d016a173e5683b.svg
          fullname: hujunchi
          isHf: false
          isPro: false
          name: hujunc
          type: user
        html: '<p>why there is no tokenizer file?</p>

          '
        raw: why there is no tokenizer file?
        updatedAt: '2023-12-05T12:56:38.935Z'
      numEdits: 0
      reactions: []
    id: 656f1e0624afea3d6314b7ab
    type: comment
  author: hujunc
  content: why there is no tokenizer file?
  created_at: 2023-12-05 12:56:38+00:00
  edited: false
  hidden: false
  id: 656f1e0624afea3d6314b7ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a191c4a3bff2197715c356865565ccfb.svg
      fullname: FOUILHE
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gfouilhe
      type: user
    createdAt: '2023-12-05T16:13:56.000Z'
    data:
      edited: false
      editors:
      - gfouilhe
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.325501948595047
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a191c4a3bff2197715c356865565ccfb.svg
          fullname: FOUILHE
          isHf: false
          isPro: false
          name: gfouilhe
          type: user
        html: "<p>According to the released code (<a rel=\"nofollow\" href=\"https://github.com/state-spaces/mamba/blob/main/benchmarks/benchmark_generation_mamba_simple.py\"\
          >https://github.com/state-spaces/mamba/blob/main/benchmarks/benchmark_generation_mamba_simple.py</a>)</p>\n\
          <pre><code class=\"language-python\">(Line <span class=\"hljs-number\">33</span>)\n\
          is_mamba = args.model_name.startswith(<span class=\"hljs-string\">\"state-spaces/mamba-\"\
          </span>)\n<span class=\"hljs-keyword\">if</span> is_mamba:\n    tokenizer\
          \ = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"EleutherAI/gpt-neox-20b\"\
          </span>)\n    model = MambaLMHeadModel.from_pretrained(args.model_name,\
          \ device=device, dtype=dtype)\n</code></pre>\n<p>You should use <code>AutoTokenizer.from_pretrained(\"\
          EleutherAI/gpt-neox-20b\")</code> </p>\n"
        raw: "According to the released code (https://github.com/state-spaces/mamba/blob/main/benchmarks/benchmark_generation_mamba_simple.py)\n\
          ```python \n(Line 33)\nis_mamba = args.model_name.startswith(\"state-spaces/mamba-\"\
          )\nif is_mamba:\n    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\"\
          )\n    model = MambaLMHeadModel.from_pretrained(args.model_name, device=device,\
          \ dtype=dtype)\n ```\n\nYou should use `AutoTokenizer.from_pretrained(\"\
          EleutherAI/gpt-neox-20b\")` "
        updatedAt: '2023-12-05T16:13:56.398Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - Maykeye
        - hujunc
        - Sciumo
        - roffmonster
        - taylorbollman
    id: 656f4c441c90ddf8fbba806d
    type: comment
  author: gfouilhe
  content: "According to the released code (https://github.com/state-spaces/mamba/blob/main/benchmarks/benchmark_generation_mamba_simple.py)\n\
    ```python \n(Line 33)\nis_mamba = args.model_name.startswith(\"state-spaces/mamba-\"\
    )\nif is_mamba:\n    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\"\
    )\n    model = MambaLMHeadModel.from_pretrained(args.model_name, device=device,\
    \ dtype=dtype)\n ```\n\nYou should use `AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\"\
    )` "
  created_at: 2023-12-05 16:13:56+00:00
  edited: false
  hidden: false
  id: 656f4c441c90ddf8fbba806d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: state-spaces/mamba-2.8b
repo_type: model
status: open
target_branch: null
title: Tokenizer
