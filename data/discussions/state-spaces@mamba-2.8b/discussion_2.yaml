!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TinyPixel
conflicting_files: null
created_at: 2023-12-05 12:30:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b27cafa4ae69ab8986dd1a216523f38b.svg
      fullname: WiseOwl
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TinyPixel
      type: user
    createdAt: '2023-12-05T12:30:20.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/b27cafa4ae69ab8986dd1a216523f38b.svg
          fullname: WiseOwl
          isHf: false
          isPro: false
          name: TinyPixel
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-12-06T08:36:59.392Z'
      numEdits: 0
      reactions: []
    id: 656f17dc2cd7a3e34819611c
    type: comment
  author: TinyPixel
  content: This comment has been hidden
  created_at: 2023-12-05 12:30:20+00:00
  edited: true
  hidden: true
  id: 656f17dc2cd7a3e34819611c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cc5ef8e6e212c675c4d016a173e5683b.svg
      fullname: hujunchi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hujunc
      type: user
    createdAt: '2023-12-05T13:07:42.000Z'
    data:
      edited: false
      editors:
      - hujunc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9657281041145325
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cc5ef8e6e212c675c4d016a173e5683b.svg
          fullname: hujunchi
          isHf: false
          isPro: false
          name: hujunc
          type: user
        html: '<p>I guess transformer has not been updated.lol</p>

          '
        raw: I guess transformer has not been updated.lol
        updatedAt: '2023-12-05T13:07:42.349Z'
      numEdits: 0
      reactions: []
    id: 656f209ec205a2ae739906b6
    type: comment
  author: hujunc
  content: I guess transformer has not been updated.lol
  created_at: 2023-12-05 13:07:42+00:00
  edited: false
  hidden: false
  id: 656f209ec205a2ae739906b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/PwaTO6BJYQ1Yjv6q4R2pL.jpeg?w=200&h=200&f=face
      fullname: Hlib Avietisov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HAvietisov
      type: user
    createdAt: '2023-12-05T14:12:10.000Z'
    data:
      edited: false
      editors:
      - HAvietisov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5315789580345154
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/PwaTO6BJYQ1Yjv6q4R2pL.jpeg?w=200&h=200&f=face
          fullname: Hlib Avietisov
          isHf: false
          isPro: false
          name: HAvietisov
          type: user
        html: '<p>Follow instructions in github :<br><a rel="nofollow" href="https://github.com/havietisov/mamba">https://github.com/havietisov/mamba</a></p>

          '
        raw: "Follow instructions in github : \nhttps://github.com/havietisov/mamba"
        updatedAt: '2023-12-05T14:12:10.503Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Yhyu13
    id: 656f2fba43804c3c75f99b9d
    type: comment
  author: HAvietisov
  content: "Follow instructions in github : \nhttps://github.com/havietisov/mamba"
  created_at: 2023-12-05 14:12:10+00:00
  edited: false
  hidden: false
  id: 656f2fba43804c3c75f99b9d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-12-06T05:55:24.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9062093496322632
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<p>Mamba is a brand new Deep learning architeture , parallel to RNN,
          LSTM, Transformers, and so on</p>

          '
        raw: Mamba is a brand new Deep learning architeture , parallel to RNN, LSTM,
          Transformers, and so on
        updatedAt: '2023-12-06T05:55:24.610Z'
      numEdits: 0
      reactions: []
    id: 65700ccc34440bdf2ee10eb4
    type: comment
  author: Yhyu13
  content: Mamba is a brand new Deep learning architeture , parallel to RNN, LSTM,
    Transformers, and so on
  created_at: 2023-12-06 05:55:24+00:00
  edited: false
  hidden: false
  id: 65700ccc34440bdf2ee10eb4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a4e5cfbba447ae4ccf71a6fc168a630.svg
      fullname: Lucien Shui
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LucienShui
      type: user
    createdAt: '2023-12-07T07:08:17.000Z'
    data:
      edited: false
      editors:
      - LucienShui
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9357731342315674
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7a4e5cfbba447ae4ccf71a6fc168a630.svg
          fullname: Lucien Shui
          isHf: false
          isPro: false
          name: LucienShui
          type: user
        html: '<p>There is nothing like <code>modeling.py</code> and so on, so I guess
          you need to waiting for repository update or <code>transformers</code> upgraded.</p>

          '
        raw: There is nothing like `modeling.py` and so on, so I guess you need to
          waiting for repository update or `transformers` upgraded.
        updatedAt: '2023-12-07T07:08:17.420Z'
      numEdits: 0
      reactions: []
    id: 65716f61c4993b8fb9930bfe
    type: comment
  author: LucienShui
  content: There is nothing like `modeling.py` and so on, so I guess you need to waiting
    for repository update or `transformers` upgraded.
  created_at: 2023-12-07 07:08:17+00:00
  edited: false
  hidden: false
  id: 65716f61c4993b8fb9930bfe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/db81628971c39994af28cac632e33133.svg
      fullname: ChulHo Shin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LostArk
      type: user
    createdAt: '2023-12-08T08:55:02.000Z'
    data:
      edited: false
      editors:
      - LostArk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.888733446598053
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/db81628971c39994af28cac632e33133.svg
          fullname: ChulHo Shin
          isHf: false
          isPro: false
          name: LostArk
          type: user
        html: '<p>how to fine tune this model?</p>

          '
        raw: how to fine tune this model?
        updatedAt: '2023-12-08T08:55:02.320Z'
      numEdits: 0
      reactions: []
    id: 6572d9e6f99c9022ac4bae20
    type: comment
  author: LostArk
  content: how to fine tune this model?
  created_at: 2023-12-08 08:55:02+00:00
  edited: false
  hidden: false
  id: 6572d9e6f99c9022ac4bae20
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a3c6507abdaa25a81ce659/Z7e4xiH7sjQYt2Qga4W8o.png?w=200&h=200&f=face
      fullname: M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Maykeye
      type: user
    createdAt: '2023-12-09T13:51:40.000Z'
    data:
      edited: false
      editors:
      - Maykeye
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6789129972457886
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a3c6507abdaa25a81ce659/Z7e4xiH7sjQYt2Qga4W8o.png?w=200&h=200&f=face
          fullname: M
          isHf: false
          isPro: false
          name: Maykeye
          type: user
        html: "<blockquote>\n<p>There is nothing like <code>modeling.py</code> and\
          \ so on, so I guess you need to waiting for repository update or <code>transformers</code>\
          \ upgraded.<br>Or you can taketheir <a rel=\"nofollow\" href=\"https://github.com/state-spaces/mamba/blob/main/benchmarks/benchmark_generation_mamba_simple.py\"\
          >simple generator</a> and base usage on it.</p>\n</blockquote>\n<p>Here's\
          \ for example a simle working example assuming mamba_ssm is installed and\
          \ model lies in ~/models</p>\n<pre><code class=\"language-python\"><span\
          \ class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\"\
          >import</span> os\n<span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> AutoTokenizer\n<span class=\"\
          hljs-keyword\">from</span> mamba_ssm.models.mixer_seq_simple <span class=\"\
          hljs-keyword\">import</span> MambaLMHeadModel\ntokenizer = AutoTokenizer.from_pretrained(<span\
          \ class=\"hljs-string\">\"EleutherAI/gpt-neox-20b\"</span>)\nmodel = MambaLMHeadModel.from_pretrained(os.path.expanduser(<span\
          \ class=\"hljs-string\">\"~/models/state-spaces_mamba-2.8b/\"</span>), device=<span\
          \ class=\"hljs-string\">\"cuda\"</span>, dtype=torch.bfloat16)\ntokens =\
          \ tokenizer(<span class=\"hljs-string\">\"Once upon a time, a cat named\"\
          </span>, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\ninput_ids\
          \ = tokens.input_ids.to(device=<span class=\"hljs-string\">\"cuda\"</span>)\n\
          max_length = input_ids.shape[<span class=\"hljs-number\">1</span>] + <span\
          \ class=\"hljs-number\">80</span>\nfn = <span class=\"hljs-keyword\">lambda</span>:\
          \ model.generate(\n        input_ids=input_ids, max_length=max_length, cg=<span\
          \ class=\"hljs-literal\">True</span>,\n        return_dict_in_generate=<span\
          \ class=\"hljs-literal\">True</span>, output_scores=<span class=\"hljs-literal\"\
          >True</span>,\n        enable_timing=<span class=\"hljs-literal\">False</span>,\
          \ temperature=<span class=\"hljs-number\">0.9</span>, top_k=<span class=\"\
          hljs-number\">40</span>, top_p=<span class=\"hljs-number\">0.9</span>,)\n\
          out = fn()\n<span class=\"hljs-built_in\">print</span>(tokenizer.decode(out[<span\
          \ class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>]))\n\
          </code></pre>\n<blockquote>\n<p>Once upon a time, a cat named Puss-in-Boots\
          \ was running around town. And when Puss-in-Boots ran, he left little pawprints.\
          \ And when Puss-in-Boots climbed, he left little pawprints. And when Puss-in-Boots\
          \ fell, he left little pawprints. And, when Puss-in-Boots was sleeping,\
          \ the cats in town</p>\n</blockquote>\n"
        raw: "> There is nothing like `modeling.py` and so on, so I guess you need\
          \ to waiting for repository update or `transformers` upgraded.\nOr you can\
          \ taketheir [simple generator](https://github.com/state-spaces/mamba/blob/main/benchmarks/benchmark_generation_mamba_simple.py)\
          \ and base usage on it.\n\nHere's for example a simle working example assuming\
          \ mamba_ssm is installed and model lies in ~/models\n```python\nimport torch\n\
          import os\nfrom transformers import AutoTokenizer\nfrom mamba_ssm.models.mixer_seq_simple\
          \ import MambaLMHeadModel\ntokenizer = AutoTokenizer.from_pretrained(\"\
          EleutherAI/gpt-neox-20b\")\nmodel = MambaLMHeadModel.from_pretrained(os.path.expanduser(\"\
          ~/models/state-spaces_mamba-2.8b/\"), device=\"cuda\", dtype=torch.bfloat16)\n\
          tokens = tokenizer(\"Once upon a time, a cat named\", return_tensors=\"\
          pt\")\ninput_ids = tokens.input_ids.to(device=\"cuda\")\nmax_length = input_ids.shape[1]\
          \ + 80\nfn = lambda: model.generate(\n        input_ids=input_ids, max_length=max_length,\
          \ cg=True,\n        return_dict_in_generate=True, output_scores=True,\n\
          \        enable_timing=False, temperature=0.9, top_k=40, top_p=0.9,)\nout\
          \ = fn()\nprint(tokenizer.decode(out[0][0]))\n```\n> Once upon a time, a\
          \ cat named Puss-in-Boots was running around town. And when Puss-in-Boots\
          \ ran, he left little pawprints. And when Puss-in-Boots climbed, he left\
          \ little pawprints. And when Puss-in-Boots fell, he left little pawprints.\
          \ And, when Puss-in-Boots was sleeping, the cats in town"
        updatedAt: '2023-12-09T13:51:40.036Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F91D"
        users:
        - TinyPixel
        - MaxxxP
        - fasterinnerlooper
        - P4rsee
        - taylorbollman
    id: 657470ecb951d40e7a16c848
    type: comment
  author: Maykeye
  content: "> There is nothing like `modeling.py` and so on, so I guess you need to\
    \ waiting for repository update or `transformers` upgraded.\nOr you can taketheir\
    \ [simple generator](https://github.com/state-spaces/mamba/blob/main/benchmarks/benchmark_generation_mamba_simple.py)\
    \ and base usage on it.\n\nHere's for example a simle working example assuming\
    \ mamba_ssm is installed and model lies in ~/models\n```python\nimport torch\n\
    import os\nfrom transformers import AutoTokenizer\nfrom mamba_ssm.models.mixer_seq_simple\
    \ import MambaLMHeadModel\ntokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\"\
    )\nmodel = MambaLMHeadModel.from_pretrained(os.path.expanduser(\"~/models/state-spaces_mamba-2.8b/\"\
    ), device=\"cuda\", dtype=torch.bfloat16)\ntokens = tokenizer(\"Once upon a time,\
    \ a cat named\", return_tensors=\"pt\")\ninput_ids = tokens.input_ids.to(device=\"\
    cuda\")\nmax_length = input_ids.shape[1] + 80\nfn = lambda: model.generate(\n\
    \        input_ids=input_ids, max_length=max_length, cg=True,\n        return_dict_in_generate=True,\
    \ output_scores=True,\n        enable_timing=False, temperature=0.9, top_k=40,\
    \ top_p=0.9,)\nout = fn()\nprint(tokenizer.decode(out[0][0]))\n```\n> Once upon\
    \ a time, a cat named Puss-in-Boots was running around town. And when Puss-in-Boots\
    \ ran, he left little pawprints. And when Puss-in-Boots climbed, he left little\
    \ pawprints. And when Puss-in-Boots fell, he left little pawprints. And, when\
    \ Puss-in-Boots was sleeping, the cats in town"
  created_at: 2023-12-09 13:51:40+00:00
  edited: false
  hidden: false
  id: 657470ecb951d40e7a16c848
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/25f00641622a9b73d9119fe89fd4bfed.svg
      fullname: Taylor Bollman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: taylorbollman
      type: user
    createdAt: '2024-01-11T04:22:41.000Z'
    data:
      edited: false
      editors:
      - taylorbollman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7111011743545532
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/25f00641622a9b73d9119fe89fd4bfed.svg
          fullname: Taylor Bollman
          isHf: false
          isPro: false
          name: taylorbollman
          type: user
        html: '<p>You can also see example here: <a href="https://huggingface.co/spaces/reach-vb/mamba/tree/main">https://huggingface.co/spaces/reach-vb/mamba/tree/main</a></p>

          '
        raw: 'You can also see example here: https://huggingface.co/spaces/reach-vb/mamba/tree/main'
        updatedAt: '2024-01-11T04:22:41.117Z'
      numEdits: 0
      reactions: []
    id: 659f6d11f0f3ed62ab2b41a4
    type: comment
  author: taylorbollman
  content: 'You can also see example here: https://huggingface.co/spaces/reach-vb/mamba/tree/main'
  created_at: 2024-01-11 04:22:41+00:00
  edited: false
  hidden: false
  id: 659f6d11f0f3ed62ab2b41a4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: state-spaces/mamba-2.8b
repo_type: model
status: open
target_branch: null
title: How to use this model
