!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tonic
conflicting_files: null
created_at: 2023-12-07 19:19:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a3bb1cd0d8c2c2169f0b88/eT2TS0IlQbZtz-F_zHLz9.jpeg?w=200&h=200&f=face
      fullname: Joseph Pollack
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tonic
      type: user
    createdAt: '2023-12-07T19:19:42.000Z'
    data:
      edited: false
      editors:
      - Tonic
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9168574810028076
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a3bb1cd0d8c2c2169f0b88/eT2TS0IlQbZtz-F_zHLz9.jpeg?w=200&h=200&f=face
          fullname: Joseph Pollack
          isHf: false
          isPro: false
          name: Tonic
          type: user
        html: "<p>hi there, big fan of stable lm since the alpha :-) </p>\n<p>this\
          \ one seems great, but i'm getting warnings about the attention mask and\
          \ the pad token id :-) </p>\n<p>will dig in as always but it would be a\
          \ quick fix on the example code.</p>\n<p>congrats on the cool release !\
          \ \U0001F680</p>\n"
        raw: "hi there, big fan of stable lm since the alpha :-) \r\n\r\nthis one\
          \ seems great, but i'm getting warnings about the attention mask and the\
          \ pad token id :-) \r\n\r\nwill dig in as always but it would be a quick\
          \ fix on the example code.\r\n\r\ncongrats on the cool release ! \U0001F680"
        updatedAt: '2023-12-07T19:19:42.193Z'
      numEdits: 0
      reactions: []
    id: 65721ace6334cefa686a94e5
    type: comment
  author: Tonic
  content: "hi there, big fan of stable lm since the alpha :-) \r\n\r\nthis one seems\
    \ great, but i'm getting warnings about the attention mask and the pad token id\
    \ :-) \r\n\r\nwill dig in as always but it would be a quick fix on the example\
    \ code.\r\n\r\ncongrats on the cool release ! \U0001F680"
  created_at: 2023-12-07 19:19:42+00:00
  edited: false
  hidden: false
  id: 65721ace6334cefa686a94e5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8714a8c41882ae964816361947858841.svg
      fullname: Simon G
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Simon1V
      type: user
    createdAt: '2023-12-07T22:58:51.000Z'
    data:
      edited: false
      editors:
      - Simon1V
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6873375773429871
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8714a8c41882ae964816361947858841.svg
          fullname: Simon G
          isHf: false
          isPro: false
          name: Simon1V
          type: user
        html: "<blockquote>\n<p>hi there, big fan of stable lm since the alpha :-)\
          \ </p>\n<p>this one seems great, but i'm getting warnings about the attention\
          \ mask and the pad token id :-) </p>\n<p>will dig in as always but it would\
          \ be a quick fix on the example code.</p>\n<p>congrats on the cool release\
          \ ! \U0001F680</p>\n</blockquote>\n<p>Adding   pad_token_id=tokenizer.pad_token_id,\
          \ fixes it:<br>tokens = model.generate(<br>        inputs.to(model.device),<br>\
          \        pad_token_id=tokenizer.pad_token_id,<br>        max_new_tokens=1024,<br>\
          \        temperature=0.8,<br>        do_sample=True</p>\n<p>(Tried with\
          \ transformers version 4.35.2) </p>\n"
        raw: "> hi there, big fan of stable lm since the alpha :-) \n> \n> this one\
          \ seems great, but i'm getting warnings about the attention mask and the\
          \ pad token id :-) \n> \n> will dig in as always but it would be a quick\
          \ fix on the example code.\n> \n> congrats on the cool release ! \U0001F680\
          \n\nAdding   pad_token_id=tokenizer.pad_token_id, fixes it: \ntokens = model.generate(\n\
          \        inputs.to(model.device), \n        pad_token_id=tokenizer.pad_token_id,\n\
          \        max_new_tokens=1024,\n        temperature=0.8,\n        do_sample=True\n\
          \n(Tried with transformers version 4.35.2) "
        updatedAt: '2023-12-07T22:58:51.313Z'
      numEdits: 0
      reactions: []
    id: 65724e2bb3d8dd7b9212ef35
    type: comment
  author: Simon1V
  content: "> hi there, big fan of stable lm since the alpha :-) \n> \n> this one\
    \ seems great, but i'm getting warnings about the attention mask and the pad token\
    \ id :-) \n> \n> will dig in as always but it would be a quick fix on the example\
    \ code.\n> \n> congrats on the cool release ! \U0001F680\n\nAdding   pad_token_id=tokenizer.pad_token_id,\
    \ fixes it: \ntokens = model.generate(\n        inputs.to(model.device), \n  \
    \      pad_token_id=tokenizer.pad_token_id,\n        max_new_tokens=1024,\n  \
    \      temperature=0.8,\n        do_sample=True\n\n(Tried with transformers version\
    \ 4.35.2) "
  created_at: 2023-12-07 22:58:51+00:00
  edited: false
  hidden: false
  id: 65724e2bb3d8dd7b9212ef35
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: stabilityai/stablelm-zephyr-3b
repo_type: model
status: open
target_branch: null
title: would be great to have the example code for the attention mask and the pad
  token id
