!!python/object:huggingface_hub.community.DiscussionWithDetails
author: limcheekin
conflicting_files: null
created_at: 2023-10-01 07:56:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/24a8c63c897efdd980ef9d4805cbff7b.svg
      fullname: Lim Chee Kin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: limcheekin
      type: user
    createdAt: '2023-10-01T08:56:59.000Z'
    data:
      edited: false
      editors:
      - limcheekin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.935090184211731
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/24a8c63c897efdd980ef9d4805cbff7b.svg
          fullname: Lim Chee Kin
          isHf: false
          isPro: false
          name: limcheekin
          type: user
        html: '<p>Hi there,</p>

          <p>I deployed the model as OpenAI API compatible endpoint at <a href="https://huggingface.co/spaces/limcheekin/Mistral-7B-Instruct-v0.1-GGUF">https://huggingface.co/spaces/limcheekin/Mistral-7B-Instruct-v0.1-GGUF</a>.</p>

          <p>Also, I created a jupyter notebook to get you started to use the API
          endpoint in no time.</p>

          <p>Lastly, if you find this resource valuable, your support in the form
          of starring the space would be greatly appreciated. </p>

          <p>Thank you.</p>

          '
        raw: "Hi there,\r\n\r\nI deployed the model as OpenAI API compatible endpoint\
          \ at https://huggingface.co/spaces/limcheekin/Mistral-7B-Instruct-v0.1-GGUF.\r\
          \n\r\nAlso, I created a jupyter notebook to get you started to use the API\
          \ endpoint in no time.\r\n\r\nLastly, if you find this resource valuable,\
          \ your support in the form of starring the space would be greatly appreciated.\
          \ \r\n\r\nThank you."
        updatedAt: '2023-10-01T08:56:59.692Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - ztime
        - ayymen
    id: 6519345bff197684a533edf2
    type: comment
  author: limcheekin
  content: "Hi there,\r\n\r\nI deployed the model as OpenAI API compatible endpoint\
    \ at https://huggingface.co/spaces/limcheekin/Mistral-7B-Instruct-v0.1-GGUF.\r\
    \n\r\nAlso, I created a jupyter notebook to get you started to use the API endpoint\
    \ in no time.\r\n\r\nLastly, if you find this resource valuable, your support\
    \ in the form of starring the space would be greatly appreciated. \r\n\r\nThank\
    \ you."
  created_at: 2023-10-01 07:56:59+00:00
  edited: false
  hidden: false
  id: 6519345bff197684a533edf2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/820472235f43fdd590bb0a7ce1603dd6.svg
      fullname: Marek Kerka
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marekk
      type: user
    createdAt: '2023-10-03T15:16:27.000Z'
    data:
      edited: false
      editors:
      - marekk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7540547847747803
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/820472235f43fdd590bb0a7ce1603dd6.svg
          fullname: Marek Kerka
          isHf: false
          isPro: false
          name: marekk
          type: user
        html: "<p>Hi, thank you for your work. I tried embedding endpoint and I got\
          \ an error.<br>Query:</p>\n<pre><code>curl -X 'POST' \\\n  'https://limcheekin-mistral-7b-instruct-v0-1-gguf.hf.space/v1/embeddings'\
          \ \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json'\
          \ \\\n  -d '{\n  \"input\": \"The food was delicious and the waiter...\"\
          \n}'\n</code></pre>\n<p>Error reponse:</p>\n<pre><code>{\n  \"error\": {\n\
          \    \"message\": \"Llama model must be created with embedding=True to call\
          \ this method\",\n    \"type\": \"internal_server_error\",\n    \"param\"\
          : null,\n    \"code\": null\n  }\n}\n</code></pre>\n"
        raw: "Hi, thank you for your work. I tried embedding endpoint and I got an\
          \ error.\nQuery:\n```\ncurl -X 'POST' \\\n  'https://limcheekin-mistral-7b-instruct-v0-1-gguf.hf.space/v1/embeddings'\
          \ \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json'\
          \ \\\n  -d '{\n  \"input\": \"The food was delicious and the waiter...\"\
          \n}'\n```\nError reponse:\n```\n{\n  \"error\": {\n    \"message\": \"Llama\
          \ model must be created with embedding=True to call this method\",\n   \
          \ \"type\": \"internal_server_error\",\n    \"param\": null,\n    \"code\"\
          : null\n  }\n}\n```"
        updatedAt: '2023-10-03T15:16:27.935Z'
      numEdits: 0
      reactions: []
    id: 651c304b4560189b7a603e64
    type: comment
  author: marekk
  content: "Hi, thank you for your work. I tried embedding endpoint and I got an error.\n\
    Query:\n```\ncurl -X 'POST' \\\n  'https://limcheekin-mistral-7b-instruct-v0-1-gguf.hf.space/v1/embeddings'\
    \ \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json'\
    \ \\\n  -d '{\n  \"input\": \"The food was delicious and the waiter...\"\n}'\n\
    ```\nError reponse:\n```\n{\n  \"error\": {\n    \"message\": \"Llama model must\
    \ be created with embedding=True to call this method\",\n    \"type\": \"internal_server_error\"\
    ,\n    \"param\": null,\n    \"code\": null\n  }\n}\n```"
  created_at: 2023-10-03 14:16:27+00:00
  edited: false
  hidden: false
  id: 651c304b4560189b7a603e64
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/24a8c63c897efdd980ef9d4805cbff7b.svg
      fullname: Lim Chee Kin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: limcheekin
      type: user
    createdAt: '2023-10-03T23:10:02.000Z'
    data:
      edited: false
      editors:
      - limcheekin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8532174825668335
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/24a8c63c897efdd980ef9d4805cbff7b.svg
          fullname: Lim Chee Kin
          isHf: false
          isPro: false
          name: limcheekin
          type: user
        html: "<blockquote>\n<p>Hi, thank you for your work. I tried embedding endpoint\
          \ and I got an error.<br>Query:</p>\n<pre><code>curl -X 'POST' \\\n  'https://limcheekin-mistral-7b-instruct-v0-1-gguf.hf.space/v1/embeddings'\
          \ \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json'\
          \ \\\n  -d '{\n  \"input\": \"The food was delicious and the waiter...\"\
          \n}'\n</code></pre>\n<p>Error reponse:</p>\n<pre><code>{\n  \"error\": {\n\
          \    \"message\": \"Llama model must be created with embedding=True to call\
          \ this method\",\n    \"type\": \"internal_server_error\",\n    \"param\"\
          : null,\n    \"code\": null\n  }\n}\n</code></pre>\n</blockquote>\n<p>Yeah,\
          \ I should stated clearly in the doc the <code>embeddings</code> endpoint\
          \ has been disabled on purpose as I tested that the <code>embeddings</code>\
          \ created by Llama models is NOT better than other open-source text embeddings\
          \ models such as BAAI/bge-large-en, intfloat/e5-large-v2, sentence-transformers/all-MiniLM-L6-v2,\
          \ sentence-transformers/all-mpnet-base-v2, etc. Hence, I created the Python\
          \ package at <a rel=\"nofollow\" href=\"https://github.com/limcheekin/open-text-embeddings\"\
          >https://github.com/limcheekin/open-text-embeddings</a>.</p>\n<p>Anyway,\
          \ that's just my experience of few months ago and my current understanding,\
          \ I just enabled (turn on) the <code>embeddings</code> endpoint and go ahead\
          \ and test it out yourself and appreciate you share the result here.</p>\n\
          <p>Thank you.</p>\n"
        raw: '> Hi, thank you for your work. I tried embedding endpoint and I got
          an error.

          > Query:

          > ```

          > curl -X ''POST'' \

          >   ''https://limcheekin-mistral-7b-instruct-v0-1-gguf.hf.space/v1/embeddings''
          \

          >   -H ''accept: application/json'' \

          >   -H ''Content-Type: application/json'' \

          >   -d ''{

          >   "input": "The food was delicious and the waiter..."

          > }''

          > ```

          > Error reponse:

          > ```

          > {

          >   "error": {

          >     "message": "Llama model must be created with embedding=True to call
          this method",

          >     "type": "internal_server_error",

          >     "param": null,

          >     "code": null

          >   }

          > }

          > ```


          Yeah, I should stated clearly in the doc the `embeddings` endpoint has been
          disabled on purpose as I tested that the `embeddings` created by Llama models
          is NOT better than other open-source text embeddings models such as BAAI/bge-large-en,
          intfloat/e5-large-v2, sentence-transformers/all-MiniLM-L6-v2, sentence-transformers/all-mpnet-base-v2,
          etc. Hence, I created the Python package at https://github.com/limcheekin/open-text-embeddings.


          Anyway, that''s just my experience of few months ago and my current understanding,
          I just enabled (turn on) the `embeddings` endpoint and go ahead and test
          it out yourself and appreciate you share the result here.


          Thank you.'
        updatedAt: '2023-10-03T23:10:02.733Z'
      numEdits: 0
      reactions: []
    id: 651c9f4a6ef9cce878c0a530
    type: comment
  author: limcheekin
  content: '> Hi, thank you for your work. I tried embedding endpoint and I got an
    error.

    > Query:

    > ```

    > curl -X ''POST'' \

    >   ''https://limcheekin-mistral-7b-instruct-v0-1-gguf.hf.space/v1/embeddings''
    \

    >   -H ''accept: application/json'' \

    >   -H ''Content-Type: application/json'' \

    >   -d ''{

    >   "input": "The food was delicious and the waiter..."

    > }''

    > ```

    > Error reponse:

    > ```

    > {

    >   "error": {

    >     "message": "Llama model must be created with embedding=True to call this
    method",

    >     "type": "internal_server_error",

    >     "param": null,

    >     "code": null

    >   }

    > }

    > ```


    Yeah, I should stated clearly in the doc the `embeddings` endpoint has been disabled
    on purpose as I tested that the `embeddings` created by Llama models is NOT better
    than other open-source text embeddings models such as BAAI/bge-large-en, intfloat/e5-large-v2,
    sentence-transformers/all-MiniLM-L6-v2, sentence-transformers/all-mpnet-base-v2,
    etc. Hence, I created the Python package at https://github.com/limcheekin/open-text-embeddings.


    Anyway, that''s just my experience of few months ago and my current understanding,
    I just enabled (turn on) the `embeddings` endpoint and go ahead and test it out
    yourself and appreciate you share the result here.


    Thank you.'
  created_at: 2023-10-03 22:10:02+00:00
  edited: false
  hidden: false
  id: 651c9f4a6ef9cce878c0a530
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/Mistral-7B-Instruct-v0.1-GGUF
repo_type: model
status: open
target_branch: null
title: Ready to use Mistral-7B-Instruct-v0.1-GGUF model as OpenAI API compatible endpoint
