!!python/object:huggingface_hub.community.DiscussionWithDetails
author: UmangK
conflicting_files: null
created_at: 2024-01-24 06:36:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/09bad88329ecc3e27c2b91c112ce6f7b.svg
      fullname: Kalavadiya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: UmangK
      type: user
    createdAt: '2024-01-24T06:36:45.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/09bad88329ecc3e27c2b91c112ce6f7b.svg
          fullname: Kalavadiya
          isHf: false
          isPro: false
          name: UmangK
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2024-01-24T06:42:00.442Z'
      numEdits: 0
      reactions: []
    id: 65b0affdc9a5a7680f84160e
    type: comment
  author: UmangK
  content: This comment has been hidden
  created_at: 2024-01-24 06:36:45+00:00
  edited: true
  hidden: true
  id: 65b0affdc9a5a7680f84160e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/09bad88329ecc3e27c2b91c112ce6f7b.svg
      fullname: Kalavadiya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: UmangK
      type: user
    createdAt: '2024-01-24T06:41:51.000Z'
    data:
      status: closed
    id: 65b0b12fbf467a67b87ec7fa
    type: status-change
  author: UmangK
  created_at: 2024-01-24 06:41:51+00:00
  id: 65b0b12fbf467a67b87ec7fa
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/09bad88329ecc3e27c2b91c112ce6f7b.svg
      fullname: Kalavadiya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: UmangK
      type: user
    createdAt: '2024-01-24T06:42:55.000Z'
    data:
      status: open
    id: 65b0b16f0648e8d10b5d9c5e
    type: status-change
  author: UmangK
  created_at: 2024-01-24 06:42:55+00:00
  id: 65b0b16f0648e8d10b5d9c5e
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/09bad88329ecc3e27c2b91c112ce6f7b.svg
      fullname: Kalavadiya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: UmangK
      type: user
    createdAt: '2024-01-24T06:43:21.000Z'
    data:
      edited: false
      editors:
      - UmangK
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4611976146697998
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/09bad88329ecc3e27c2b91c112ce6f7b.svg
          fullname: Kalavadiya
          isHf: false
          isPro: false
          name: UmangK
          type: user
        html: '<p>I am building streamlit app for language translation using this
          code but it is taking around 1 min to translate one sentence.</p>

          <p>import streamlit as st<br>from langchain.chains import LLMChain<br>from
          langchain.llms import CTransformers<br>from langchain.prompts import PromptTemplate</p>

          <p>Mistral configuration<br>config = {''max_new_tokens'': 256, ''temperature'':
          0.8, ''context_length'': 256}<br>llm = CTransformers(model="TheBloke/Mistral-7B-Instruct-v0.1-GGUF",<br>model_file="mistral-7b-instruct-v0.1.Q4_K_M.gguf",<br>config=config)</p>

          <p>Streamlit app<br>st.title("Language Translation with Mistral")</p>

          <p>Sidebar for selecting languages<br>language_options = ["English", "French",
          "Spanish", "German", "Chinese", "Japanese", "Russian", "Arabic", "Hindi",
          "Swahili"]<br>original_language = st.sidebar.selectbox("Select Original
          Language", language_options)<br>target_language = st.sidebar.selectbox("Select
          Target Language", language_options)</p>

          <p>Input text box<br>input_text = st.text_area("Enter Text to Translate",
          "")</p>

          <p>if st.button("Translate"):</p>

          <h1 id="translate-using-mistral">Translate using Mistral</h1>

          <p>chunk_size = 100 # Adjust the chunk size as needed<br>chunks = [input_text[i:i
          + chunk_size] for i in range(0, len(input_text), chunk_size)]</p>

          <p>translated_chunks = []<br>for chunk in chunks:<br>    map_template =
          f"<s>[INST] Translate the following text from {original_language} to {target_language}:
          {chunk} [/INST] </s>"<br>    map_prompt = PromptTemplate.from_template(map_template)<br>    translate_chain
          = LLMChain(llm=llm, prompt=map_prompt)<br>    translated_chunk = translate_chain.run({})<br>    translated_chunks.append(translated_chunk)</p>

          <p>translated_text = "".join(translated_chunks)</p>

          <h1 id="display-translated-text">Display translated text</h1>

          <p>st.subheader("Translated Text:")<br>st.write(translated_text)</p>

          '
        raw: "I am building streamlit app for language translation using this code\
          \ but it is taking around 1 min to translate one sentence.\n\nimport streamlit\
          \ as st\nfrom langchain.chains import LLMChain\nfrom langchain.llms import\
          \ CTransformers\nfrom langchain.prompts import PromptTemplate\n\nMistral\
          \ configuration\nconfig = {'max_new_tokens': 256, 'temperature': 0.8, 'context_length':\
          \ 256}\nllm = CTransformers(model=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\"\
          ,\nmodel_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\nconfig=config)\n\
          \nStreamlit app\nst.title(\"Language Translation with Mistral\")\n\nSidebar\
          \ for selecting languages\nlanguage_options = [\"English\", \"French\",\
          \ \"Spanish\", \"German\", \"Chinese\", \"Japanese\", \"Russian\", \"Arabic\"\
          , \"Hindi\", \"Swahili\"]\noriginal_language = st.sidebar.selectbox(\"Select\
          \ Original Language\", language_options)\ntarget_language = st.sidebar.selectbox(\"\
          Select Target Language\", language_options)\n\nInput text box\ninput_text\
          \ = st.text_area(\"Enter Text to Translate\", \"\")\n\nif st.button(\"Translate\"\
          ):\n# Translate using Mistral\nchunk_size = 100 # Adjust the chunk size\
          \ as needed\nchunks = [input_text[i:i + chunk_size] for i in range(0, len(input_text),\
          \ chunk_size)]\n\ntranslated_chunks = []\nfor chunk in chunks:\n    map_template\
          \ = f\"<s>[INST] Translate the following text from {original_language} to\
          \ {target_language}: {chunk} [/INST] </s>\"\n    map_prompt = PromptTemplate.from_template(map_template)\n\
          \    translate_chain = LLMChain(llm=llm, prompt=map_prompt)\n    translated_chunk\
          \ = translate_chain.run({})\n    translated_chunks.append(translated_chunk)\n\
          \ntranslated_text = \"\".join(translated_chunks)\n\n# Display translated\
          \ text\nst.subheader(\"Translated Text:\")\nst.write(translated_text)"
        updatedAt: '2024-01-24T06:43:21.017Z'
      numEdits: 0
      reactions: []
    id: 65b0b1897febbcc2afe1ac6f
    type: comment
  author: UmangK
  content: "I am building streamlit app for language translation using this code but\
    \ it is taking around 1 min to translate one sentence.\n\nimport streamlit as\
    \ st\nfrom langchain.chains import LLMChain\nfrom langchain.llms import CTransformers\n\
    from langchain.prompts import PromptTemplate\n\nMistral configuration\nconfig\
    \ = {'max_new_tokens': 256, 'temperature': 0.8, 'context_length': 256}\nllm =\
    \ CTransformers(model=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\nmodel_file=\"\
    mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\nconfig=config)\n\nStreamlit app\nst.title(\"\
    Language Translation with Mistral\")\n\nSidebar for selecting languages\nlanguage_options\
    \ = [\"English\", \"French\", \"Spanish\", \"German\", \"Chinese\", \"Japanese\"\
    , \"Russian\", \"Arabic\", \"Hindi\", \"Swahili\"]\noriginal_language = st.sidebar.selectbox(\"\
    Select Original Language\", language_options)\ntarget_language = st.sidebar.selectbox(\"\
    Select Target Language\", language_options)\n\nInput text box\ninput_text = st.text_area(\"\
    Enter Text to Translate\", \"\")\n\nif st.button(\"Translate\"):\n# Translate\
    \ using Mistral\nchunk_size = 100 # Adjust the chunk size as needed\nchunks =\
    \ [input_text[i:i + chunk_size] for i in range(0, len(input_text), chunk_size)]\n\
    \ntranslated_chunks = []\nfor chunk in chunks:\n    map_template = f\"<s>[INST]\
    \ Translate the following text from {original_language} to {target_language}:\
    \ {chunk} [/INST] </s>\"\n    map_prompt = PromptTemplate.from_template(map_template)\n\
    \    translate_chain = LLMChain(llm=llm, prompt=map_prompt)\n    translated_chunk\
    \ = translate_chain.run({})\n    translated_chunks.append(translated_chunk)\n\n\
    translated_text = \"\".join(translated_chunks)\n\n# Display translated text\n\
    st.subheader(\"Translated Text:\")\nst.write(translated_text)"
  created_at: 2024-01-24 06:43:21+00:00
  edited: false
  hidden: false
  id: 65b0b1897febbcc2afe1ac6f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: TheBloke/Mistral-7B-Instruct-v0.1-GGUF
repo_type: model
status: open
target_branch: null
title: Taking too much time to process simple request.
