!!python/object:huggingface_hub.community.DiscussionWithDetails
author: shivammehta
conflicting_files: null
created_at: 2023-10-18 06:00:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2e441d2ae599b51824fb9db8d2a89fff.svg
      fullname: mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shivammehta
      type: user
    createdAt: '2023-10-18T07:00:55.000Z'
    data:
      edited: false
      editors:
      - shivammehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6561245918273926
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2e441d2ae599b51824fb9db8d2a89fff.svg
          fullname: mehta
          isHf: false
          isPro: false
          name: shivammehta
          type: user
        html: '<p>I am getting a warning of the "Number of tokens exceeded maximum
          context length (512)" as shown in the screenshot below.<br>how to solve
          this issue.<br>code :<br>def load_llm():</p>

          <h1 id="load-the-locally-downloaded-model-here">Load the locally downloaded
          model here</h1>

          <p>llm = CTransformers(<br>model = "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",<br>model_type="llama",<br>max_new_tokens
          = 512,<br>temperature = 0.5<br>)<br>return llm<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/sSZ7767YJRBREDIa6fyUU.png"><img
          alt="MicrosoftTeams-image (34).png" src="https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/sSZ7767YJRBREDIa6fyUU.png"></a></p>

          '
        raw: "I am getting a warning of the \"Number of tokens exceeded maximum context\
          \ length (512)\" as shown in the screenshot below.\r\nhow to solve this\
          \ issue.\r\ncode :\r\ndef load_llm():\r\n# Load the locally downloaded model\
          \ here\r\nllm = CTransformers(\r\nmodel = \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\"\
          ,\r\nmodel_type=\"llama\",\r\nmax_new_tokens = 512,\r\ntemperature = 0.5\r\
          \n)\r\nreturn llm\r\n![MicrosoftTeams-image (34).png](https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/sSZ7767YJRBREDIa6fyUU.png)\r\
          \n"
        updatedAt: '2023-10-18T07:00:55.565Z'
      numEdits: 0
      reactions: []
    id: 652f82a757845998fce75256
    type: comment
  author: shivammehta
  content: "I am getting a warning of the \"Number of tokens exceeded maximum context\
    \ length (512)\" as shown in the screenshot below.\r\nhow to solve this issue.\r\
    \ncode :\r\ndef load_llm():\r\n# Load the locally downloaded model here\r\nllm\
    \ = CTransformers(\r\nmodel = \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\r\n\
    model_type=\"llama\",\r\nmax_new_tokens = 512,\r\ntemperature = 0.5\r\n)\r\nreturn\
    \ llm\r\n![MicrosoftTeams-image (34).png](https://cdn-uploads.huggingface.co/production/uploads/6453a499fc2b5f69e8fb0fde/sSZ7767YJRBREDIa6fyUU.png)\r\
    \n"
  created_at: 2023-10-18 06:00:55+00:00
  edited: false
  hidden: false
  id: 652f82a757845998fce75256
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fc243c5664c8e271218b9518d8b6e25c.svg
      fullname: Giovanni Casari
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: infopz512
      type: user
    createdAt: '2023-10-18T15:17:15.000Z'
    data:
      edited: false
      editors:
      - infopz512
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.29844456911087036
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fc243c5664c8e271218b9518d8b6e25c.svg
          fullname: Giovanni Casari
          isHf: false
          isPro: false
          name: infopz512
          type: user
        html: '<p>You need to set the correct value via the config parameters</p>

          <pre><code>config = {''max_new_tokens'': 400, ''temperature'': 0, ''context_length'':
          4096}

          llm = CTransformers(model=''TheBloke/Mistral-7B-Instruct-v0.1-GGUF'',model_file="mistral-7b-instruct-v0.1.Q8_0.gguf",
          config=config)

          </code></pre>

          '
        raw: 'You need to set the correct value via the config parameters

          ```

          config = {''max_new_tokens'': 400, ''temperature'': 0, ''context_length'':
          4096}

          llm = CTransformers(model=''TheBloke/Mistral-7B-Instruct-v0.1-GGUF'',model_file="mistral-7b-instruct-v0.1.Q8_0.gguf",
          config=config)

          ```'
        updatedAt: '2023-10-18T15:17:15.761Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - zBaptiste
    id: 652ff6fbc5745652a8025419
    type: comment
  author: infopz512
  content: 'You need to set the correct value via the config parameters

    ```

    config = {''max_new_tokens'': 400, ''temperature'': 0, ''context_length'': 4096}

    llm = CTransformers(model=''TheBloke/Mistral-7B-Instruct-v0.1-GGUF'',model_file="mistral-7b-instruct-v0.1.Q8_0.gguf",
    config=config)

    ```'
  created_at: 2023-10-18 14:17:15+00:00
  edited: false
  hidden: false
  id: 652ff6fbc5745652a8025419
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/lB_IN3agrUh49Ta5OcMg4.png?w=200&h=200&f=face
      fullname: "Marco Louren\xE7o"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: esuriddick
      type: user
    createdAt: '2023-12-12T10:23:17.000Z'
    data:
      edited: true
      editors:
      - esuriddick
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5425478219985962
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/lB_IN3agrUh49Ta5OcMg4.png?w=200&h=200&f=face
          fullname: "Marco Louren\xE7o"
          isHf: false
          isPro: false
          name: esuriddick
          type: user
        html: '<p>Based on the above, I tried the following and I still get an error:<br>from
          ctransformers import AutoModelForCausalLM<br>model_chat_ckpt = "TheBloke/Mistral-7B-Instruct-v0.1-GGUF"<br>model_chat_file
          = ''mistral-7b-instruct-v0.1.Q4_K_M.gguf''<br>model_chat_type = ''mistral''</p>

          <p>config = {''context_length'' : 4096}<br> model = AutoModelForCausalLM.from_pretrained(model_path_or_repo_id
          = model_chat_path<br>                                                 ,model_type
          = model_chat_type<br>                                                 ,model_file
          = model_chat_file<br>                                                 ,local_files_only
          = True<br>                                                 ,config = config.config<br>                                                 )   </p>

          <p>AttributeError: ''dict'' object has no attribute ''config''</p>

          '
        raw: "Based on the above, I tried the following and I still get an error:\n\
          from ctransformers import AutoModelForCausalLM\nmodel_chat_ckpt = \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\"\
          \nmodel_chat_file = 'mistral-7b-instruct-v0.1.Q4_K_M.gguf'\nmodel_chat_type\
          \ = 'mistral'\n\nconfig = {'context_length' : 4096}\n model = AutoModelForCausalLM.from_pretrained(model_path_or_repo_id\
          \ = model_chat_path\n                                                 ,model_type\
          \ = model_chat_type\n                                                 ,model_file\
          \ = model_chat_file\n                                                 ,local_files_only\
          \ = True\n                                                 ,config = config.config\n\
          \                                                 )   \n\nAttributeError:\
          \ 'dict' object has no attribute 'config'"
        updatedAt: '2023-12-12T10:24:33.251Z'
      numEdits: 2
      reactions: []
    id: 6578349558d7a2cc893ff9b4
    type: comment
  author: esuriddick
  content: "Based on the above, I tried the following and I still get an error:\n\
    from ctransformers import AutoModelForCausalLM\nmodel_chat_ckpt = \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\"\
    \nmodel_chat_file = 'mistral-7b-instruct-v0.1.Q4_K_M.gguf'\nmodel_chat_type =\
    \ 'mistral'\n\nconfig = {'context_length' : 4096}\n model = AutoModelForCausalLM.from_pretrained(model_path_or_repo_id\
    \ = model_chat_path\n                                                 ,model_type\
    \ = model_chat_type\n                                                 ,model_file\
    \ = model_chat_file\n                                                 ,local_files_only\
    \ = True\n                                                 ,config = config.config\n\
    \                                                 )   \n\nAttributeError: 'dict'\
    \ object has no attribute 'config'"
  created_at: 2023-12-12 10:23:17+00:00
  edited: true
  hidden: false
  id: 6578349558d7a2cc893ff9b4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: TheBloke/Mistral-7B-Instruct-v0.1-GGUF
repo_type: model
status: open
target_branch: null
title: Number of tokens exceeded maximum context length (512)
