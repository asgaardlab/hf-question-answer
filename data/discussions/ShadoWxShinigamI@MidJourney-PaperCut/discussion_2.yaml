!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AxonAxis
conflicting_files: null
created_at: 2022-11-28 09:41:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678619646507-6345351b84d547b0066248f5.png?w=200&h=200&f=face
      fullname: Xanarcher
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AxonAxis
      type: user
    createdAt: '2022-11-28T09:41:17.000Z'
    data:
      edited: false
      editors:
      - AxonAxis
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678619646507-6345351b84d547b0066248f5.png?w=200&h=200&f=face
          fullname: Xanarcher
          isHf: false
          isPro: false
          name: AxonAxis
          type: user
        html: '<p>I have experienced couple of  your  models, especially the paper-cut
          and it feel super great. Can you share your experience in training models?
          For example, how many photos in training set and class/reg set as usual
          ,training steps, training Epochs, the learning rate , etc. Thank you very
          much!</p>

          '
        raw: I have experienced couple of  your  models, especially the paper-cut
          and it feel super great. Can you share your experience in training models?
          For example, how many photos in training set and class/reg set as usual
          ,training steps, training Epochs, the learning rate , etc. Thank you very
          much!
        updatedAt: '2022-11-28T09:41:17.485Z'
      numEdits: 0
      reactions: []
    id: 6384823db4d5a5b7f43edd48
    type: comment
  author: AxonAxis
  content: I have experienced couple of  your  models, especially the paper-cut and
    it feel super great. Can you share your experience in training models? For example,
    how many photos in training set and class/reg set as usual ,training steps, training
    Epochs, the learning rate , etc. Thank you very much!
  created_at: 2022-11-28 09:41:17+00:00
  edited: false
  hidden: false
  id: 6384823db4d5a5b7f43edd48
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1664766468790-noauth.jpeg?w=200&h=200&f=face
      fullname: Harsha Subramanyam
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShadoWxShinigamI
      type: user
    createdAt: '2022-11-28T13:26:41.000Z'
    data:
      edited: false
      editors:
      - ShadoWxShinigamI
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1664766468790-noauth.jpeg?w=200&h=200&f=face
          fullname: Harsha Subramanyam
          isHf: false
          isPro: false
          name: ShadoWxShinigamI
          type: user
        html: '<p>Hey mate! Thank you for the kind words. </p>

          <p>I generally train with somewhere around 20-40 images, depending on the
          quality of base images. I try to keep my images as varied as possible with
          regards to subjects when training a style (eg: animals, landscapes, portraits,
          objects, vehicles, etc) ; This helps with making sure the model only learns
          the general style aesthetic and not the actual subjects, although, this
          is not an exact science. </p>

          <p>Step count depends on the amount of images used. When using the LastBen
          Notebook, I was using the number of images x 100. With text encoder training
          set to 30%.</p>

          <p>When I use local dreambooth from within the WEB-UI, I generally use Number
          of images x 30 steps with EMA training and Text encoder Training Enabled
          with 1e-6 LR polynomial, continue for images x 40 steps without text encoder
          at 4e-7 LR polynomial, then finish with images x 10 steps with text encoder
          enabled at 1e-7 LR Constant.</p>

          <p>I usually crop my images to 640x640 and train them with a batch size
          of 2.</p>

          '
        raw: "Hey mate! Thank you for the kind words. \n\nI generally train with somewhere\
          \ around 20-40 images, depending on the quality of base images. I try to\
          \ keep my images as varied as possible with regards to subjects when training\
          \ a style (eg: animals, landscapes, portraits, objects, vehicles, etc) ;\
          \ This helps with making sure the model only learns the general style aesthetic\
          \ and not the actual subjects, although, this is not an exact science. \n\
          \nStep count depends on the amount of images used. When using the LastBen\
          \ Notebook, I was using the number of images x 100. With text encoder training\
          \ set to 30%.\n\nWhen I use local dreambooth from within the WEB-UI, I generally\
          \ use Number of images x 30 steps with EMA training and Text encoder Training\
          \ Enabled with 1e-6 LR polynomial, continue for images x 40 steps without\
          \ text encoder at 4e-7 LR polynomial, then finish with images x 10 steps\
          \ with text encoder enabled at 1e-7 LR Constant.\n\nI usually crop my images\
          \ to 640x640 and train them with a batch size of 2."
        updatedAt: '2022-11-28T13:26:41.422Z'
      numEdits: 0
      reactions: []
    id: 6384b711a179f85600568e9e
    type: comment
  author: ShadoWxShinigamI
  content: "Hey mate! Thank you for the kind words. \n\nI generally train with somewhere\
    \ around 20-40 images, depending on the quality of base images. I try to keep\
    \ my images as varied as possible with regards to subjects when training a style\
    \ (eg: animals, landscapes, portraits, objects, vehicles, etc) ; This helps with\
    \ making sure the model only learns the general style aesthetic and not the actual\
    \ subjects, although, this is not an exact science. \n\nStep count depends on\
    \ the amount of images used. When using the LastBen Notebook, I was using the\
    \ number of images x 100. With text encoder training set to 30%.\n\nWhen I use\
    \ local dreambooth from within the WEB-UI, I generally use Number of images x\
    \ 30 steps with EMA training and Text encoder Training Enabled with 1e-6 LR polynomial,\
    \ continue for images x 40 steps without text encoder at 4e-7 LR polynomial, then\
    \ finish with images x 10 steps with text encoder enabled at 1e-7 LR Constant.\n\
    \nI usually crop my images to 640x640 and train them with a batch size of 2."
  created_at: 2022-11-28 13:26:41+00:00
  edited: false
  hidden: false
  id: 6384b711a179f85600568e9e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678619646507-6345351b84d547b0066248f5.png?w=200&h=200&f=face
      fullname: Xanarcher
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AxonAxis
      type: user
    createdAt: '2022-11-28T13:59:21.000Z'
    data:
      edited: false
      editors:
      - AxonAxis
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678619646507-6345351b84d547b0066248f5.png?w=200&h=200&f=face
          fullname: Xanarcher
          isHf: false
          isPro: false
          name: AxonAxis
          type: user
        html: '<p>Thank you very much for your thorough reply ,it was so helpful.one
          more questions, Would you tell me How to set the Warmup and the Adam optimizer
          in WebUI  dreambooth?</p>

          '
        raw: Thank you very much for your thorough reply ,it was so helpful.one more
          questions, Would you tell me How to set the Warmup and the Adam optimizer
          in WebUI  dreambooth?
        updatedAt: '2022-11-28T13:59:21.956Z'
      numEdits: 0
      reactions: []
    id: 6384beb9e57073c0ba187d55
    type: comment
  author: AxonAxis
  content: Thank you very much for your thorough reply ,it was so helpful.one more
    questions, Would you tell me How to set the Warmup and the Adam optimizer in WebUI  dreambooth?
  created_at: 2022-11-28 13:59:21+00:00
  edited: false
  hidden: false
  id: 6384beb9e57073c0ba187d55
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1664766468790-noauth.jpeg?w=200&h=200&f=face
      fullname: Harsha Subramanyam
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShadoWxShinigamI
      type: user
    createdAt: '2022-11-29T15:33:21.000Z'
    data:
      edited: false
      editors:
      - ShadoWxShinigamI
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1664766468790-noauth.jpeg?w=200&h=200&f=face
          fullname: Harsha Subramanyam
          isHf: false
          isPro: false
          name: ShadoWxShinigamI
          type: user
        html: '<p>I dont know much about the adam optimiser<br>Warmup (which i dont
          use) is generally best for 10% of total steps. I.e:- 1000 steps total training
          will have 100 steps warmup</p>

          '
        raw: 'I dont know much about the adam optimiser

          Warmup (which i dont use) is generally best for 10% of total steps. I.e:-
          1000 steps total training will have 100 steps warmup'
        updatedAt: '2022-11-29T15:33:21.301Z'
      numEdits: 0
      reactions: []
    id: 63862641988cb440e7cfb080
    type: comment
  author: ShadoWxShinigamI
  content: 'I dont know much about the adam optimiser

    Warmup (which i dont use) is generally best for 10% of total steps. I.e:- 1000
    steps total training will have 100 steps warmup'
  created_at: 2022-11-29 15:33:21+00:00
  edited: false
  hidden: false
  id: 63862641988cb440e7cfb080
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678619646507-6345351b84d547b0066248f5.png?w=200&h=200&f=face
      fullname: Xanarcher
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AxonAxis
      type: user
    createdAt: '2022-11-30T11:42:24.000Z'
    data:
      edited: false
      editors:
      - AxonAxis
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678619646507-6345351b84d547b0066248f5.png?w=200&h=200&f=face
          fullname: Xanarcher
          isHf: false
          isPro: false
          name: AxonAxis
          type: user
        html: '<p>Get it. THX Bro!</p>

          '
        raw: Get it. THX Bro!
        updatedAt: '2022-11-30T11:42:24.836Z'
      numEdits: 0
      reactions: []
    id: 638741a0189d6915f1d49b0c
    type: comment
  author: AxonAxis
  content: Get it. THX Bro!
  created_at: 2022-11-30 11:42:24+00:00
  edited: false
  hidden: false
  id: 638741a0189d6915f1d49b0c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662287267361-noauth.png?w=200&h=200&f=face
      fullname: '0x1337'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: '0x1337'
      type: user
    createdAt: '2022-11-30T20:58:50.000Z'
    data:
      edited: false
      editors:
      - '0x1337'
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662287267361-noauth.png?w=200&h=200&f=face
          fullname: '0x1337'
          isHf: false
          isPro: false
          name: '0x1337'
          type: user
        html: '<p>can we make some SD2 768 model ? &lt;3 &lt;3</p>

          '
        raw: can we make some SD2 768 model ? <3 <3
        updatedAt: '2022-11-30T20:58:50.408Z'
      numEdits: 0
      reactions: []
    id: 6387c40a1901766b8804d2d3
    type: comment
  author: '0x1337'
  content: can we make some SD2 768 model ? <3 <3
  created_at: 2022-11-30 20:58:50+00:00
  edited: false
  hidden: false
  id: 6387c40a1901766b8804d2d3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/95e3f781baa4d5dbdcd417bc9551736f.svg
      fullname: Vincent Yang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vfyang
      type: user
    createdAt: '2023-01-25T07:24:32.000Z'
    data:
      edited: false
      editors:
      - vfyang
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/95e3f781baa4d5dbdcd417bc9551736f.svg
          fullname: Vincent Yang
          isHf: false
          isPro: false
          name: vfyang
          type: user
        html: '<p>What''s the best size for this model? 512x512 or 768x768?</p>

          '
        raw: What's the best size for this model? 512x512 or 768x768?
        updatedAt: '2023-01-25T07:24:32.472Z'
      numEdits: 0
      reactions: []
    id: 63d0d93062f0de677d7c5b66
    type: comment
  author: vfyang
  content: What's the best size for this model? 512x512 or 768x768?
  created_at: 2023-01-25 07:24:32+00:00
  edited: false
  hidden: false
  id: 63d0d93062f0de677d7c5b66
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: ShadoWxShinigamI/MidJourney-PaperCut
repo_type: model
status: open
target_branch: null
title: About Model Training
