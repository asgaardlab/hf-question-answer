!!python/object:huggingface_hub.community.DiscussionWithDetails
author: vasilee
conflicting_files: null
created_at: 2023-07-06 13:33:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/895f7245c0e03f23e737900bd3e47aa2.svg
      fullname: Vasile Ermicioi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vasilee
      type: user
    createdAt: '2023-07-06T14:33:08.000Z'
    data:
      edited: false
      editors:
      - vasilee
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.948723316192627
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/895f7245c0e03f23e737900bd3e47aa2.svg
          fullname: Vasile Ermicioi
          isHf: false
          isPro: false
          name: vasilee
          type: user
        html: "<p>for the prompt<br><code>Translate the following English text into\
          \ French: \"The sun rises in the east and sets in the west.\"</code><br>it\
          \ says<br><code>&lt;0x0A&gt; is [eod] \xA9 \U0001F449 yourself [eod]</code></p>\n"
        raw: "for the prompt\r\n`Translate the following English text into French:\
          \ \"The sun rises in the east and sets in the west.\"`\r\nit says\r\n`<0x0A>\
          \ is [eod] \xA9 \U0001F449 yourself [eod]`"
        updatedAt: '2023-07-06T14:33:08.599Z'
      numEdits: 0
      reactions: []
    id: 64a6d0a4bf296d7481649e0e
    type: comment
  author: vasilee
  content: "for the prompt\r\n`Translate the following English text into French: \"\
    The sun rises in the east and sets in the west.\"`\r\nit says\r\n`<0x0A> is [eod]\
    \ \xA9 \U0001F449 yourself [eod]`"
  created_at: 2023-07-06 13:33:08+00:00
  edited: false
  hidden: false
  id: 64a6d0a4bf296d7481649e0e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678756856820-63b2d9ce922f26a27e7538ef.jpeg?w=200&h=200&f=face
      fullname: Praneet Pabolu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DeathReaper0965
      type: user
    createdAt: '2023-07-20T10:09:20.000Z'
    data:
      edited: true
      editors:
      - DeathReaper0965
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9790562987327576
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678756856820-63b2d9ce922f26a27e7538ef.jpeg?w=200&h=200&f=face
          fullname: Praneet Pabolu
          isHf: false
          isPro: false
          name: DeathReaper0965
          type: user
        html: '<p><code>umt5</code> or any other <code>mT5</code> models are not meant
          to be used directly out of the box as they are not pre-trained with any
          supervised training. However the model is trained to have some level of
          language understanding, so its suggested to use the model by performing
          the finetuning on your downstream task to achieve good results.</p>

          '
        raw: '`umt5` or any other `mT5` models are not meant to be used directly out
          of the box as they are not pre-trained with any supervised training. However
          the model is trained to have some level of language understanding, so its
          suggested to use the model by performing the finetuning on your downstream
          task to achieve good results.'
        updatedAt: '2023-07-20T10:18:46.122Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ArthurZ
    id: 64b907d00d8834cb32442f73
    type: comment
  author: DeathReaper0965
  content: '`umt5` or any other `mT5` models are not meant to be used directly out
    of the box as they are not pre-trained with any supervised training. However the
    model is trained to have some level of language understanding, so its suggested
    to use the model by performing the finetuning on your downstream task to achieve
    good results.'
  created_at: 2023-07-20 09:09:20+00:00
  edited: true
  hidden: false
  id: 64b907d00d8834cb32442f73
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/895f7245c0e03f23e737900bd3e47aa2.svg
      fullname: Vasile Ermicioi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vasilee
      type: user
    createdAt: '2023-07-20T11:56:44.000Z'
    data:
      edited: true
      editors:
      - vasilee
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8345041275024414
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/895f7245c0e03f23e737900bd3e47aa2.svg
          fullname: Vasile Ermicioi
          isHf: false
          isPro: false
          name: vasilee
          type: user
        html: '<p>do you know how to use it?<br><a href="https://huggingface.co/docs/transformers/v4.31.0/en/model_doc/umt5#sample-usage">https://huggingface.co/docs/transformers/v4.31.0/en/model_doc/umt5#sample-usage</a><br>for
          the example in the docs <code>A &lt;extra_id_0&gt; walks into a bar and
          orders a &lt;extra_id_1&gt; with &lt;extra_id_2&gt; pinch of &lt;extra_id_3&gt;.</code><br>it
          says <code>.&lt;0x0A&gt;Then hemargarita1....</code><br>instead of what
          is shown in the example </p>

          <p>my expectation would be to use the same way as t5 or flan-t5 and the
          only difference is to be multilingual</p>

          '
        raw: "do you know how to use it? \nhttps://huggingface.co/docs/transformers/v4.31.0/en/model_doc/umt5#sample-usage\n\
          for the example in the docs `A <extra_id_0> walks into a bar and orders\
          \ a <extra_id_1> with <extra_id_2> pinch of <extra_id_3>.`\nit says `.<0x0A>Then\
          \ hemargarita1....`\ninstead of what is shown in the example \n\nmy expectation\
          \ would be to use the same way as t5 or flan-t5 and the only difference\
          \ is to be multilingual\n"
        updatedAt: '2023-07-20T11:57:09.216Z'
      numEdits: 1
      reactions: []
    id: 64b920fc56f81f15e2af2a1b
    type: comment
  author: vasilee
  content: "do you know how to use it? \nhttps://huggingface.co/docs/transformers/v4.31.0/en/model_doc/umt5#sample-usage\n\
    for the example in the docs `A <extra_id_0> walks into a bar and orders a <extra_id_1>\
    \ with <extra_id_2> pinch of <extra_id_3>.`\nit says `.<0x0A>Then hemargarita1....`\n\
    instead of what is shown in the example \n\nmy expectation would be to use the\
    \ same way as t5 or flan-t5 and the only difference is to be multilingual\n"
  created_at: 2023-07-20 10:56:44+00:00
  edited: true
  hidden: false
  id: 64b920fc56f81f15e2af2a1b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678756856820-63b2d9ce922f26a27e7538ef.jpeg?w=200&h=200&f=face
      fullname: Praneet Pabolu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DeathReaper0965
      type: user
    createdAt: '2023-07-20T12:25:04.000Z'
    data:
      edited: false
      editors:
      - DeathReaper0965
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9413295984268188
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678756856820-63b2d9ce922f26a27e7538ef.jpeg?w=200&h=200&f=face
          fullname: Praneet Pabolu
          isHf: false
          isPro: false
          name: DeathReaper0965
          type: user
        html: '<p>The example shown is just the usage of how to invoke the model for
          inference and yes, even I''m unable to reproduce the exact outputs that
          are shown in the image as it could be because of the sampling that''s applied
          when you call the <code>generate()</code> function.<br>However, as I mentioned
          before, the model is not usable by default as it will not produce any meaningful
          outputs. See the <code>Note</code> section here: <a href="https://huggingface.co/google/umt5-base">https://huggingface.co/google/umt5-base</a></p>

          <p>The only way to use this model is to finetune it on your own downstream
          task using your own data, only then will you be able to generate any meaningful
          outputs.</p>

          <p>I''ve planned to finetune it on some public data in a few days from now,
          will share you the approach here once I finish it.</p>

          '
        raw: "The example shown is just the usage of how to invoke the model for inference\
          \ and yes, even I'm unable to reproduce the exact outputs that are shown\
          \ in the image as it could be because of the sampling that's applied when\
          \ you call the `generate()` function. \nHowever, as I mentioned before,\
          \ the model is not usable by default as it will not produce any meaningful\
          \ outputs. See the `Note` section here: https://huggingface.co/google/umt5-base\n\
          \nThe only way to use this model is to finetune it on your own downstream\
          \ task using your own data, only then will you be able to generate any meaningful\
          \ outputs.\n\nI've planned to finetune it on some public data in a few days\
          \ from now, will share you the approach here once I finish it."
        updatedAt: '2023-07-20T12:25:04.200Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - vasilee
    id: 64b927a025b0493d5182fb6c
    type: comment
  author: DeathReaper0965
  content: "The example shown is just the usage of how to invoke the model for inference\
    \ and yes, even I'm unable to reproduce the exact outputs that are shown in the\
    \ image as it could be because of the sampling that's applied when you call the\
    \ `generate()` function. \nHowever, as I mentioned before, the model is not usable\
    \ by default as it will not produce any meaningful outputs. See the `Note` section\
    \ here: https://huggingface.co/google/umt5-base\n\nThe only way to use this model\
    \ is to finetune it on your own downstream task using your own data, only then\
    \ will you be able to generate any meaningful outputs.\n\nI've planned to finetune\
    \ it on some public data in a few days from now, will share you the approach here\
    \ once I finish it."
  created_at: 2023-07-20 11:25:04+00:00
  edited: false
  hidden: false
  id: 64b927a025b0493d5182fb6c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-10T18:08:38.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.258344441652298
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: "<p>As <span data-props=\"{&quot;user&quot;:&quot;DeathReaper0965&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/DeathReaper0965\"\
          >@<span class=\"underline\">DeathReaper0965</span></a></span>\n\n\t</span></span>\
          \ mentions, the model is a pretrained artifact that should be fine-tuned.\
          \ However here is a test showing how to get somewhat OK predictions:<br>(taken\
          \ from <a rel=\"nofollow\" href=\"https://github.com/ArthurZucker/transformers/blob/fix-main/tests/models/umt5/test_modeling_umt5.py#L549\"\
          >here</a>)</p>\n<pre><code class=\"language-python\">    <span class=\"\
          hljs-keyword\">def</span> <span class=\"hljs-title function_\">test_small_integration_test</span>(<span\
          \ class=\"hljs-params\">self</span>):\n        <span class=\"hljs-string\"\
          >\"\"\"</span>\n<span class=\"hljs-string\">        For comparison run the\
          \ kaggle notbook available here : https://www.kaggle.com/arthurzucker/umt5-inference</span>\n\
          <span class=\"hljs-string\">        \"\"\"</span>\n\n        model = UMT5ForConditionalGeneration.from_pretrained(<span\
          \ class=\"hljs-string\">\"google/umt5-small\"</span>, return_dict=<span\
          \ class=\"hljs-literal\">True</span>).to(torch_device)\n        tokenizer\
          \ = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"google/umt5-small\"\
          </span>, use_fast=<span class=\"hljs-literal\">False</span>, legacy=<span\
          \ class=\"hljs-literal\">False</span>)\n        input_text = [\n       \
          \     <span class=\"hljs-string\">\"Bonjour monsieur &lt;extra_id_0&gt;\
          \ bien &lt;extra_id_1&gt;.\"</span>,\n            <span class=\"hljs-string\"\
          >\"No se como puedo &lt;extra_id_0&gt;.\"</span>,\n            <span class=\"\
          hljs-string\">\"This is the reason why we &lt;extra_id_0&gt; them.\"</span>,\n\
          \            <span class=\"hljs-string\">\"The &lt;extra_id_0&gt; walks\
          \ in &lt;extra_id_1&gt;, seats\"</span>,\n            <span class=\"hljs-string\"\
          >\"A &lt;extra_id_0&gt; walks into a bar and orders a &lt;extra_id_1&gt;\
          \ with &lt;extra_id_2&gt; pinch of &lt;extra_id_3&gt;.\"</span>,\n     \
          \   ]\n        input_ids = tokenizer(input_text, return_tensors=<span class=\"\
          hljs-string\">\"pt\"</span>, padding=<span class=\"hljs-literal\">True</span>).input_ids\n\
          \        <span class=\"hljs-comment\"># fmt: off</span>\n        EXPECTED_IDS\
          \ = torch.tensor(\n            [\n                [ <span class=\"hljs-number\"\
          >38530</span>, <span class=\"hljs-number\">210703</span>, <span class=\"\
          hljs-number\">256299</span>, <span class=\"hljs-number\">1410</span>, <span\
          \ class=\"hljs-number\">256298</span>, <span class=\"hljs-number\">274</span>,\
          \ <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0</span>,<span\
          \ class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>,\
          \ <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>,\
          \ <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>,\
          \ <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>,<span\
          \ class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>],\n\
          \                [   <span class=\"hljs-number\">826</span>, <span class=\"\
          hljs-number\">321</span>, <span class=\"hljs-number\">671</span>, <span\
          \ class=\"hljs-number\">25922</span>, <span class=\"hljs-number\">256299</span>,\
          \ <span class=\"hljs-number\">274</span>, <span class=\"hljs-number\">1</span>,\
          \ <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,\
          \ <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>,\
          \ <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>,\
          \ <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>,\
          \ <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,\
          \ <span class=\"hljs-number\">0</span>],\n                [  <span class=\"\
          hljs-number\">1460</span>, <span class=\"hljs-number\">339</span>, <span\
          \ class=\"hljs-number\">312</span>, <span class=\"hljs-number\">19014</span>,\
          \ <span class=\"hljs-number\">10620</span>, <span class=\"hljs-number\"\
          >758</span>, <span class=\"hljs-number\">256299</span>, <span class=\"hljs-number\"\
          >2355</span>,<span class=\"hljs-number\">274</span>, <span class=\"hljs-number\"\
          >1</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\"\
          >0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\"\
          >0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\"\
          >0</span>,<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\"\
          >0</span>],\n                [   <span class=\"hljs-number\">517</span>,\
          \ <span class=\"hljs-number\">256299</span>, <span class=\"hljs-number\"\
          >14869</span>, <span class=\"hljs-number\">281</span>, <span class=\"hljs-number\"\
          >301</span>, <span class=\"hljs-number\">256298</span>, <span class=\"hljs-number\"\
          >275</span>, <span class=\"hljs-number\">119983</span>,<span class=\"hljs-number\"\
          >1</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\"\
          >0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\"\
          >0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\"\
          >0</span>, <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\"\
          >0</span>, <span class=\"hljs-number\">0</span>],\n                [   <span\
          \ class=\"hljs-number\">320</span>, <span class=\"hljs-number\">256299</span>,\
          \ <span class=\"hljs-number\">14869</span>, <span class=\"hljs-number\"\
          >281</span>, <span class=\"hljs-number\">2234</span>, <span class=\"hljs-number\"\
          >289</span>, <span class=\"hljs-number\">2275</span>, <span class=\"hljs-number\"\
          >333</span>,<span class=\"hljs-number\">61391</span>, <span class=\"hljs-number\"\
          >289</span>, <span class=\"hljs-number\">256298</span>, <span class=\"hljs-number\"\
          >543</span>, <span class=\"hljs-number\">256297</span>, <span class=\"hljs-number\"\
          >168714</span>, <span class=\"hljs-number\">329</span>, <span class=\"hljs-number\"\
          >256296</span>,<span class=\"hljs-number\">274</span>, <span class=\"hljs-number\"\
          >1</span>],\n            ]\n        )\n        <span class=\"hljs-comment\"\
          ># fmt: on</span>\n        torch.testing.assert_allclose(input_ids, EXPECTED_IDS)\n\
          \n        generated_ids = model.generate(input_ids.to(torch_device))\n \
          \       EXPECTED_FILLING = [\n            <span class=\"hljs-string\">\"\
          &lt;pad&gt;&lt;extra_id_0&gt; et&lt;extra_id_1&gt; [eod] &lt;extra_id_2&gt;&lt;extra_id_55&gt;..\
          \ [eod] \U0001F490 \U0001F490 \U0001F490 \U0001F490 \U0001F490 \U0001F490\
          \ \U0001F490 \U0001F490 \U0001F490 \U0001F490 \U0001F490 &lt;extra_id_56&gt;aj\u0161\
          ietosto&lt;extra_id_56&gt;lleux&lt;extra_id_19&gt;&lt;extra_id_6&gt;aj\u0161\
          ie&lt;/s&gt;\"</span>,\n            <span class=\"hljs-string\">\"&lt;pad&gt;&lt;extra_id_0&gt;.&lt;extra_id_1&gt;.,&lt;0x0A&gt;...spech\
          \ &lt;0x0A&gt;&lt;extra_id_20&gt; &lt;extra_id_21&gt;&lt;/s&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;\"\
          </span>,\n            <span class=\"hljs-string\">\"&lt;pad&gt;&lt;extra_id_0&gt;\
          \ are not going to be a part of the world. We are not going to be a part\
          \ of&lt;extra_id_1&gt; and&lt;extra_id_2&gt;&lt;0x0A&gt;&lt;extra_id_48&gt;.&lt;extra_id_48&gt;&lt;/s&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;\"\
          </span>,\n            <span class=\"hljs-string\">\"&lt;pad&gt;&lt;extra_id_0&gt;\
          \ door&lt;extra_id_1&gt;, the door&lt;extra_id_2&gt; \uD53C\uD574[/&lt;/s&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;\"\
          </span>,\n            <span class=\"hljs-string\">\"&lt;pad&gt;&lt;extra_id_0&gt;nyone\
          \ who&lt;extra_id_1&gt; drink&lt;extra_id_2&gt; a&lt;extra_id_3&gt; alcohol&lt;extra_id_4&gt;\
          \ A&lt;extra_id_5&gt; A. This&lt;extra_id_6&gt; I&lt;extra_id_7&gt;&lt;extra_id_52&gt;&lt;extra_id_53&gt;&lt;/s&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;\"\
          </span>,\n        ]\n        filling = tokenizer.batch_decode(generated_ids)\n\
          \        self.assertEqual(filling, EXPECTED_FILLING)\n</code></pre>\n"
        raw: "As @DeathReaper0965 mentions, the model is a pretrained artifact that\
          \ should be fine-tuned. However here is a test showing how to get somewhat\
          \ OK predictions:\n(taken from [here](https://github.com/ArthurZucker/transformers/blob/fix-main/tests/models/umt5/test_modeling_umt5.py#L549))\n\
          ```python\n    def test_small_integration_test(self):\n        \"\"\"\n\
          \        For comparison run the kaggle notbook available here : https://www.kaggle.com/arthurzucker/umt5-inference\n\
          \        \"\"\"\n\n        model = UMT5ForConditionalGeneration.from_pretrained(\"\
          google/umt5-small\", return_dict=True).to(torch_device)\n        tokenizer\
          \ = AutoTokenizer.from_pretrained(\"google/umt5-small\", use_fast=False,\
          \ legacy=False)\n        input_text = [\n            \"Bonjour monsieur\
          \ <extra_id_0> bien <extra_id_1>.\",\n            \"No se como puedo <extra_id_0>.\"\
          ,\n            \"This is the reason why we <extra_id_0> them.\",\n     \
          \       \"The <extra_id_0> walks in <extra_id_1>, seats\",\n           \
          \ \"A <extra_id_0> walks into a bar and orders a <extra_id_1> with <extra_id_2>\
          \ pinch of <extra_id_3>.\",\n        ]\n        input_ids = tokenizer(input_text,\
          \ return_tensors=\"pt\", padding=True).input_ids\n        # fmt: off\n \
          \       EXPECTED_IDS = torch.tensor(\n            [\n                [ 38530,\
          \ 210703, 256299, 1410, 256298, 274, 1, 0,0, 0, 0, 0, 0, 0, 0, 0,0, 0],\n\
          \                [   826, 321, 671, 25922, 256299, 274, 1, 0,0, 0, 0, 0,\
          \ 0, 0, 0, 0,0, 0],\n                [  1460, 339, 312, 19014, 10620, 758,\
          \ 256299, 2355,274, 1, 0, 0, 0, 0, 0, 0,0, 0],\n                [   517,\
          \ 256299, 14869, 281, 301, 256298, 275, 119983,1, 0, 0, 0, 0, 0, 0, 0,0,\
          \ 0],\n                [   320, 256299, 14869, 281, 2234, 289, 2275, 333,61391,\
          \ 289, 256298, 543, 256297, 168714, 329, 256296,274, 1],\n            ]\n\
          \        )\n        # fmt: on\n        torch.testing.assert_allclose(input_ids,\
          \ EXPECTED_IDS)\n\n        generated_ids = model.generate(input_ids.to(torch_device))\n\
          \        EXPECTED_FILLING = [\n            \"<pad><extra_id_0> et<extra_id_1>\
          \ [eod] <extra_id_2><extra_id_55>.. [eod] \U0001F490 \U0001F490 \U0001F490\
          \ \U0001F490 \U0001F490 \U0001F490 \U0001F490 \U0001F490 \U0001F490 \U0001F490\
          \ \U0001F490 <extra_id_56>aj\u0161ietosto<extra_id_56>lleux<extra_id_19><extra_id_6>aj\u0161\
          ie</s>\",\n            \"<pad><extra_id_0>.<extra_id_1>.,<0x0A>...spech\
          \ <0x0A><extra_id_20> <extra_id_21></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\
          ,\n            \"<pad><extra_id_0> are not going to be a part of the world.\
          \ We are not going to be a part of<extra_id_1> and<extra_id_2><0x0A><extra_id_48>.<extra_id_48></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\
          ,\n            \"<pad><extra_id_0> door<extra_id_1>, the door<extra_id_2>\
          \ \uD53C\uD574[/</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\
          ,\n            \"<pad><extra_id_0>nyone who<extra_id_1> drink<extra_id_2>\
          \ a<extra_id_3> alcohol<extra_id_4> A<extra_id_5> A. This<extra_id_6> I<extra_id_7><extra_id_52><extra_id_53></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\
          ,\n        ]\n        filling = tokenizer.batch_decode(generated_ids)\n\
          \        self.assertEqual(filling, EXPECTED_FILLING)\n```"
        updatedAt: '2023-10-10T18:08:38.221Z'
      numEdits: 0
      reactions: []
    id: 65259326c0dcf4cffe5a71f0
    type: comment
  author: ArthurZ
  content: "As @DeathReaper0965 mentions, the model is a pretrained artifact that\
    \ should be fine-tuned. However here is a test showing how to get somewhat OK\
    \ predictions:\n(taken from [here](https://github.com/ArthurZucker/transformers/blob/fix-main/tests/models/umt5/test_modeling_umt5.py#L549))\n\
    ```python\n    def test_small_integration_test(self):\n        \"\"\"\n      \
    \  For comparison run the kaggle notbook available here : https://www.kaggle.com/arthurzucker/umt5-inference\n\
    \        \"\"\"\n\n        model = UMT5ForConditionalGeneration.from_pretrained(\"\
    google/umt5-small\", return_dict=True).to(torch_device)\n        tokenizer = AutoTokenizer.from_pretrained(\"\
    google/umt5-small\", use_fast=False, legacy=False)\n        input_text = [\n \
    \           \"Bonjour monsieur <extra_id_0> bien <extra_id_1>.\",\n          \
    \  \"No se como puedo <extra_id_0>.\",\n            \"This is the reason why we\
    \ <extra_id_0> them.\",\n            \"The <extra_id_0> walks in <extra_id_1>,\
    \ seats\",\n            \"A <extra_id_0> walks into a bar and orders a <extra_id_1>\
    \ with <extra_id_2> pinch of <extra_id_3>.\",\n        ]\n        input_ids =\
    \ tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids\n     \
    \   # fmt: off\n        EXPECTED_IDS = torch.tensor(\n            [\n        \
    \        [ 38530, 210703, 256299, 1410, 256298, 274, 1, 0,0, 0, 0, 0, 0, 0, 0,\
    \ 0,0, 0],\n                [   826, 321, 671, 25922, 256299, 274, 1, 0,0, 0,\
    \ 0, 0, 0, 0, 0, 0,0, 0],\n                [  1460, 339, 312, 19014, 10620, 758,\
    \ 256299, 2355,274, 1, 0, 0, 0, 0, 0, 0,0, 0],\n                [   517, 256299,\
    \ 14869, 281, 301, 256298, 275, 119983,1, 0, 0, 0, 0, 0, 0, 0,0, 0],\n       \
    \         [   320, 256299, 14869, 281, 2234, 289, 2275, 333,61391, 289, 256298,\
    \ 543, 256297, 168714, 329, 256296,274, 1],\n            ]\n        )\n      \
    \  # fmt: on\n        torch.testing.assert_allclose(input_ids, EXPECTED_IDS)\n\
    \n        generated_ids = model.generate(input_ids.to(torch_device))\n       \
    \ EXPECTED_FILLING = [\n            \"<pad><extra_id_0> et<extra_id_1> [eod] <extra_id_2><extra_id_55>..\
    \ [eod] \U0001F490 \U0001F490 \U0001F490 \U0001F490 \U0001F490 \U0001F490 \U0001F490\
    \ \U0001F490 \U0001F490 \U0001F490 \U0001F490 <extra_id_56>aj\u0161ietosto<extra_id_56>lleux<extra_id_19><extra_id_6>aj\u0161\
    ie</s>\",\n            \"<pad><extra_id_0>.<extra_id_1>.,<0x0A>...spech <0x0A><extra_id_20>\
    \ <extra_id_21></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\
    ,\n            \"<pad><extra_id_0> are not going to be a part of the world. We\
    \ are not going to be a part of<extra_id_1> and<extra_id_2><0x0A><extra_id_48>.<extra_id_48></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\
    ,\n            \"<pad><extra_id_0> door<extra_id_1>, the door<extra_id_2> \uD53C\
    \uD574[/</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\
    ,\n            \"<pad><extra_id_0>nyone who<extra_id_1> drink<extra_id_2> a<extra_id_3>\
    \ alcohol<extra_id_4> A<extra_id_5> A. This<extra_id_6> I<extra_id_7><extra_id_52><extra_id_53></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\
    ,\n        ]\n        filling = tokenizer.batch_decode(generated_ids)\n      \
    \  self.assertEqual(filling, EXPECTED_FILLING)\n```"
  created_at: 2023-10-10 17:08:38+00:00
  edited: false
  hidden: false
  id: 65259326c0dcf4cffe5a71f0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: google/umt5-base
repo_type: model
status: open
target_branch: null
title: bug? example of usage?
