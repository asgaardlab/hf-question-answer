!!python/object:huggingface_hub.community.DiscussionWithDetails
author: leojames
conflicting_files: null
created_at: 2023-05-05 16:22:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4a8c44891f3e8243c8cfe76286adbd4a.svg
      fullname: James
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: leojames
      type: user
    createdAt: '2023-05-05T17:22:42.000Z'
    data:
      edited: false
      editors:
      - leojames
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4a8c44891f3e8243c8cfe76286adbd4a.svg
          fullname: James
          isHf: false
          isPro: false
          name: leojames
          type: user
        html: '<p>when i run the demo i found that cuda gpu use share memory is not
          work  . Anyone have same proplem ?</p>

          <p>Traceback (most recent call last):<br>  File "/export/anaconda3/envs/code/lib/python3.10/site-packages/gradio/routes.py",
          line 412, in run_predict<br>    output = await app.get_blocks().process_api(<br>  File
          "/export/anaconda3/envs/code/lib/python3.10/site-packages/gradio/blocks.py",
          line 1299, in process_api<br>    result = await self.call_function(<br>  File
          "/export/anaconda3/envs/code/lib/python3.10/site-packages/gradio/blocks.py",
          line 1021, in call_function<br>    prediction = await anyio.to_thread.run_sync(<br>  File
          "/export/anaconda3/envs/code/lib/python3.10/site-packages/anyio/to_thread.py",
          line 31, in run_sync<br>    return await get_asynclib().run_sync_in_worker_thread(<br>  File
          "/export/anaconda3/envs/code/lib/python3.10/site-packages/anyio/_backends/_asyncio.py",
          line 937, in run_sync_in_worker_thread<br>    return await future<br>  File
          "/export/anaconda3/envs/code/lib/python3.10/site-packages/anyio/_backends/_asyncio.py",
          line 867, in run<br>    result = context.run(func, *args)<br>  File "/export/code/gradio_code.py",
          line 13, in to_black<br>    y = model.generate(x, max_length=500, do_sample=True,
          top_p=0.95, top_k=4, temperature=0.2, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)<br>  File
          "/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/utils/_contextlib.py",
          line 115, in decorate_context<br>    return func(*args, **kwargs)<br>  File
          "/export/anaconda3/envs/code/lib/python3.10/site-packages/transformers/generation/utils.py",
          line 1485, in generate<br>    return self.sample(<br>  File "/export/anaconda3/envs/code/lib/python3.10/site-packages/transformers/generation/utils.py",
          line 2524, in sample<br>    outputs = self(<br>  File "/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm.py",
          line 355, in forward<br>    x, past_key_value = block(x,<br>  File "/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/gpt_blocks.py",
          line 81, in forward<br>    b, _, past_key_value = self.attn(a,<br>  File
          "/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl<br>    return forward_call(*args, **kwargs)<br>  File
          "/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/attention.py",
          line 333, in forward<br>    context, attn_weights = self.attn_fn(<br>  File
          "/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/attention.py",
          line 227, in triton_flash_attn_fn<br>    attn_output = flash_attn_triton.flash_attn_func(query,
          key, value,<br>  File "/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/autograd/function.py",
          line 506, in apply<br>    return super().apply(*args, **kwargs)  # type:
          ignore[misc]<br>  File "/export/anaconda3/envs/code/lib/python3.10/site-packages/flash_attn/flash_attn_triton.py",
          line 810, in forward<br>    o, lse, ctx.softmax_scale = _flash_attn_forward(<br>  File
          "/export/anaconda3/envs/code/lib/python3.10/site-packages/flash_attn/flash_attn_triton.py",
          line 623, in _flash_attn_forward<br>    _fwd_kernel[grid](<br>  File "/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/runtime/jit.py",
          line 106, in launcher<br>    return self.run(*args, grid=grid, **kwargs)<br>  File
          "/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/runtime/autotuner.py",
          line 200, in run<br>    return self.fn.run(*args, **kwargs)<br>  File "",
          line 41, in _fwd_kernel<br>  File "/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/compiler.py",
          line 1256, in compile<br>    asm, shared, kernel_name = _compile(fn, signature,
          device, constants, configs[0], num_warps, num_stages,<br>  File "/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/compiler.py",
          line 901, in _compile<br>    name, asm, shared_mem = _triton.code_gen.compile_ttir(backend,
          module, device, num_warps, num_stages, extern_libs, cc)<br>RuntimeError:
          Device does not support shared memory of 98304bytes</p>

          '
        raw: "when i run the demo i found that cuda gpu use share memory is not work\
          \  . Anyone have same proplem ?\r\n\r\nTraceback (most recent call last):\r\
          \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/gradio/routes.py\"\
          , line 412, in run_predict\r\n    output = await app.get_blocks().process_api(\r\
          \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 1299, in process_api\r\n    result = await self.call_function(\r\n\
          \  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 1021, in call_function\r\n    prediction = await anyio.to_thread.run_sync(\r\
          \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/anyio/to_thread.py\"\
          , line 31, in run_sync\r\n    return await get_asynclib().run_sync_in_worker_thread(\r\
          \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 937, in run_sync_in_worker_thread\r\n    return await future\r\n\
          \  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 867, in run\r\n    result = context.run(func, *args)\r\n  File \"\
          /export/code/gradio_code.py\", line 13, in to_black\r\n    y = model.generate(x,\
          \ max_length=500, do_sample=True, top_p=0.95, top_k=4, temperature=0.2,\
          \ num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\r\n  File\
          \ \"/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n\
          \  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1485, in generate\r\n    return self.sample(\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 2524, in sample\r\n    outputs = self(\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm.py\"\
          , line 355, in forward\r\n    x, past_key_value = block(x,\r\n  File \"\
          /export/anaconda3/envs/code/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/gpt_blocks.py\"\
          , line 81, in forward\r\n    b, _, past_key_value = self.attn(a,\r\n  File\
          \ \"/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n  File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/attention.py\"\
          , line 333, in forward\r\n    context, attn_weights = self.attn_fn(\r\n\
          \  File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/attention.py\"\
          , line 227, in triton_flash_attn_fn\r\n    attn_output = flash_attn_triton.flash_attn_func(query,\
          \ key, value,\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/autograd/function.py\"\
          , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type:\
          \ ignore[misc]\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/flash_attn/flash_attn_triton.py\"\
          , line 810, in forward\r\n    o, lse, ctx.softmax_scale = _flash_attn_forward(\r\
          \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/flash_attn/flash_attn_triton.py\"\
          , line 623, in _flash_attn_forward\r\n    _fwd_kernel[grid](\r\n  File \"\
          /export/anaconda3/envs/code/lib/python3.10/site-packages/triton/runtime/jit.py\"\
          , line 106, in launcher\r\n    return self.run(*args, grid=grid, **kwargs)\r\
          \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/runtime/autotuner.py\"\
          , line 200, in run\r\n    return self.fn.run(*args, **kwargs)\r\n  File\
          \ \"<string>\", line 41, in _fwd_kernel\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/compiler.py\"\
          , line 1256, in compile\r\n    asm, shared, kernel_name = _compile(fn, signature,\
          \ device, constants, configs[0], num_warps, num_stages,\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/compiler.py\"\
          , line 901, in _compile\r\n    name, asm, shared_mem = _triton.code_gen.compile_ttir(backend,\
          \ module, device, num_warps, num_stages, extern_libs, cc)\r\nRuntimeError:\
          \ Device does not support shared memory of 98304bytes\r\n\r\n"
        updatedAt: '2023-05-05T17:22:42.545Z'
      numEdits: 0
      reactions: []
    id: 64553b62e4952d1c6cb5cf0d
    type: comment
  author: leojames
  content: "when i run the demo i found that cuda gpu use share memory is not work\
    \  . Anyone have same proplem ?\r\n\r\nTraceback (most recent call last):\r\n\
    \  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/gradio/routes.py\"\
    , line 412, in run_predict\r\n    output = await app.get_blocks().process_api(\r\
    \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/gradio/blocks.py\"\
    , line 1299, in process_api\r\n    result = await self.call_function(\r\n  File\
    \ \"/export/anaconda3/envs/code/lib/python3.10/site-packages/gradio/blocks.py\"\
    , line 1021, in call_function\r\n    prediction = await anyio.to_thread.run_sync(\r\
    \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/anyio/to_thread.py\"\
    , line 31, in run_sync\r\n    return await get_asynclib().run_sync_in_worker_thread(\r\
    \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
    , line 937, in run_sync_in_worker_thread\r\n    return await future\r\n  File\
    \ \"/export/anaconda3/envs/code/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
    , line 867, in run\r\n    result = context.run(func, *args)\r\n  File \"/export/code/gradio_code.py\"\
    , line 13, in to_black\r\n    y = model.generate(x, max_length=500, do_sample=True,\
    \ top_p=0.95, top_k=4, temperature=0.2, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\r\
    \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File\
    \ \"/export/anaconda3/envs/code/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 1485, in generate\r\n    return self.sample(\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 2524, in sample\r\n    outputs = self(\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm.py\"\
    , line 355, in forward\r\n    x, past_key_value = block(x,\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/gpt_blocks.py\"\
    , line 81, in forward\r\n    b, _, past_key_value = self.attn(a,\r\n  File \"\
    /export/anaconda3/envs/code/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File\
    \ \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/attention.py\"\
    , line 333, in forward\r\n    context, attn_weights = self.attn_fn(\r\n  File\
    \ \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/attention.py\"\
    , line 227, in triton_flash_attn_fn\r\n    attn_output = flash_attn_triton.flash_attn_func(query,\
    \ key, value,\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/torch/autograd/function.py\"\
    , line 506, in apply\r\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\r\
    \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/flash_attn/flash_attn_triton.py\"\
    , line 810, in forward\r\n    o, lse, ctx.softmax_scale = _flash_attn_forward(\r\
    \n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/flash_attn/flash_attn_triton.py\"\
    , line 623, in _flash_attn_forward\r\n    _fwd_kernel[grid](\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/runtime/jit.py\"\
    , line 106, in launcher\r\n    return self.run(*args, grid=grid, **kwargs)\r\n\
    \  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/runtime/autotuner.py\"\
    , line 200, in run\r\n    return self.fn.run(*args, **kwargs)\r\n  File \"<string>\"\
    , line 41, in _fwd_kernel\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/compiler.py\"\
    , line 1256, in compile\r\n    asm, shared, kernel_name = _compile(fn, signature,\
    \ device, constants, configs[0], num_warps, num_stages,\r\n  File \"/export/anaconda3/envs/code/lib/python3.10/site-packages/triton/compiler.py\"\
    , line 901, in _compile\r\n    name, asm, shared_mem = _triton.code_gen.compile_ttir(backend,\
    \ module, device, num_warps, num_stages, extern_libs, cc)\r\nRuntimeError: Device\
    \ does not support shared memory of 98304bytes\r\n\r\n"
  created_at: 2023-05-05 16:22:42+00:00
  edited: false
  hidden: false
  id: 64553b62e4952d1c6cb5cf0d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa933dbbbfe85eb59f73c12e065ed712.svg
      fullname: Madhav
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: madhavatreplit
      type: user
    createdAt: '2023-05-08T17:59:42.000Z'
    data:
      edited: false
      editors:
      - madhavatreplit
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa933dbbbfe85eb59f73c12e065ed712.svg
          fullname: Madhav
          isHf: false
          isPro: false
          name: madhavatreplit
          type: user
        html: '<p>Hey! Can you share more details about your environment? All package
          versions, NVIDIA GPU details, CUDA drivers, etc. will be a helpful first
          step. </p>

          <p>Also if you could check what does <code>nvidia-smi</code>output once
          you load up the model from your script? Getting a sense of how much GPU
          memory is used out of the available will be helpful as well.</p>

          '
        raw: "Hey! Can you share more details about your environment? All package\
          \ versions, NVIDIA GPU details, CUDA drivers, etc. will be a helpful first\
          \ step. \n\nAlso if you could check what does `nvidia-smi`output once you\
          \ load up the model from your script? Getting a sense of how much GPU memory\
          \ is used out of the available will be helpful as well."
        updatedAt: '2023-05-08T17:59:42.330Z'
      numEdits: 0
      reactions: []
    id: 6459388ef92601affa350725
    type: comment
  author: madhavatreplit
  content: "Hey! Can you share more details about your environment? All package versions,\
    \ NVIDIA GPU details, CUDA drivers, etc. will be a helpful first step. \n\nAlso\
    \ if you could check what does `nvidia-smi`output once you load up the model from\
    \ your script? Getting a sense of how much GPU memory is used out of the available\
    \ will be helpful as well."
  created_at: 2023-05-08 16:59:42+00:00
  edited: false
  hidden: false
  id: 6459388ef92601affa350725
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4a8c44891f3e8243c8cfe76286adbd4a.svg
      fullname: James
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: leojames
      type: user
    createdAt: '2023-05-24T06:22:41.000Z'
    data:
      edited: false
      editors:
      - leojames
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4a8c44891f3e8243c8cfe76286adbd4a.svg
          fullname: James
          isHf: false
          isPro: false
          name: leojames
          type: user
        html: '<blockquote>

          <p>Hey! Can you share more details about your environment? All package versions,
          NVIDIA GPU details, CUDA drivers, etc. will be a helpful first step. </p>

          <p>Also if you could check what does <code>nvidia-smi</code>output once
          you load up the model from your script? Getting a sense of how much GPU
          memory is used out of the available will be helpful as well.</p>

          </blockquote>

          <p>I used the NVIDIA GPU P100, which is based on the Pascal architecture,
          so it does not support this type of acceleration. Even after switching to
          A30, the speed is still slow.</p>

          '
        raw: "> Hey! Can you share more details about your environment? All package\
          \ versions, NVIDIA GPU details, CUDA drivers, etc. will be a helpful first\
          \ step. \n> \n> Also if you could check what does `nvidia-smi`output once\
          \ you load up the model from your script? Getting a sense of how much GPU\
          \ memory is used out of the available will be helpful as well.\n\nI used\
          \ the NVIDIA GPU P100, which is based on the Pascal architecture, so it\
          \ does not support this type of acceleration. Even after switching to A30,\
          \ the speed is still slow."
        updatedAt: '2023-05-24T06:22:41.485Z'
      numEdits: 0
      reactions: []
    id: 646dad3140e741b1912b6709
    type: comment
  author: leojames
  content: "> Hey! Can you share more details about your environment? All package\
    \ versions, NVIDIA GPU details, CUDA drivers, etc. will be a helpful first step.\
    \ \n> \n> Also if you could check what does `nvidia-smi`output once you load up\
    \ the model from your script? Getting a sense of how much GPU memory is used out\
    \ of the available will be helpful as well.\n\nI used the NVIDIA GPU P100, which\
    \ is based on the Pascal architecture, so it does not support this type of acceleration.\
    \ Even after switching to A30, the speed is still slow."
  created_at: 2023-05-24 05:22:41+00:00
  edited: false
  hidden: false
  id: 646dad3140e741b1912b6709
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6434ad9cea46c009904c91c2/Ofa-wDlcUHSWH48LgOHeZ.jpeg?w=200&h=200&f=face
      fullname: Michele Catasta
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pirroh
      type: user
    createdAt: '2023-06-05T03:01:31.000Z'
    data:
      edited: false
      editors:
      - pirroh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9678050875663757
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6434ad9cea46c009904c91c2/Ofa-wDlcUHSWH48LgOHeZ.jpeg?w=200&h=200&f=face
          fullname: Michele Catasta
          isHf: false
          isPro: false
          name: pirroh
          type: user
        html: '<p>Closing as the issue has been solved by moving to a more recent
          GPU.<br>For additional performance, we recommend to double check that you
          are using Triton flash attention (as described in the README) and <code>bfloat16</code>.</p>

          '
        raw: 'Closing as the issue has been solved by moving to a more recent GPU.

          For additional performance, we recommend to double check that you are using
          Triton flash attention (as described in the README) and `bfloat16`.'
        updatedAt: '2023-06-05T03:01:31.015Z'
      numEdits: 0
      reactions: []
      relatedEventId: 647d500bc788767ab5e4ffa4
    id: 647d500bc788767ab5e4ffa3
    type: comment
  author: pirroh
  content: 'Closing as the issue has been solved by moving to a more recent GPU.

    For additional performance, we recommend to double check that you are using Triton
    flash attention (as described in the README) and `bfloat16`.'
  created_at: 2023-06-05 02:01:31+00:00
  edited: false
  hidden: false
  id: 647d500bc788767ab5e4ffa3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6434ad9cea46c009904c91c2/Ofa-wDlcUHSWH48LgOHeZ.jpeg?w=200&h=200&f=face
      fullname: Michele Catasta
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pirroh
      type: user
    createdAt: '2023-06-05T03:01:31.000Z'
    data:
      status: closed
    id: 647d500bc788767ab5e4ffa4
    type: status-change
  author: pirroh
  created_at: 2023-06-05 02:01:31+00:00
  id: 647d500bc788767ab5e4ffa4
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: replit/replit-code-v1-3b
repo_type: model
status: closed
target_branch: null
title: 'RuntimeError: Device does not support shared memory of 98304bytes'
