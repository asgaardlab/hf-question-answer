!!python/object:huggingface_hub.community.DiscussionWithDetails
author: LouiSum
conflicting_files: null
created_at: 2023-05-04 05:17:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e11778d6d7c0e789763a758bc8fca171.svg
      fullname: Loui Sum
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LouiSum
      type: user
    createdAt: '2023-05-04T06:17:01.000Z'
    data:
      edited: false
      editors:
      - LouiSum
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e11778d6d7c0e789763a758bc8fca171.svg
          fullname: Loui Sum
          isHf: false
          isPro: false
          name: LouiSum
          type: user
        html: '<p>Currently the LM is using Triton for attention implementation. Can
          we change it in config to torch?</p>

          '
        raw: Currently the LM is using Triton for attention implementation. Can we
          change it in config to torch?
        updatedAt: '2023-05-04T06:17:01.516Z'
      numEdits: 0
      reactions: []
    id: 64534ddd4871691ae74ba5e0
    type: comment
  author: LouiSum
  content: Currently the LM is using Triton for attention implementation. Can we change
    it in config to torch?
  created_at: 2023-05-04 05:17:01+00:00
  edited: false
  hidden: false
  id: 64534ddd4871691ae74ba5e0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa933dbbbfe85eb59f73c12e065ed712.svg
      fullname: Madhav
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: madhavatreplit
      type: user
    createdAt: '2023-05-04T16:42:08.000Z'
    data:
      edited: true
      editors:
      - madhavatreplit
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa933dbbbfe85eb59f73c12e065ed712.svg
          fullname: Madhav
          isHf: false
          isPro: false
          name: madhavatreplit
          type: user
        html: '<p>Yes, the model support <code>torch</code> or <code>triton</code>
          for the <code>attn_impl</code> kwarg, and ''torch'' is the default.  </p>

          <p>So just don''t pass in the <code>attn_impl</code> kwarg to the <code>AutoModelFromCausalLM.from_pretrained</code>
          call and it will default to using the attention implementation in torch!</p>

          <p>Lmk if you continue to have trouble with this!</p>

          '
        raw: "Yes, the model support `torch` or `triton` for the `attn_impl` kwarg,\
          \ and 'torch' is the default.  \n\nSo just don't pass in the `attn_impl`\
          \ kwarg to the `AutoModelFromCausalLM.from_pretrained` call and it will\
          \ default to using the attention implementation in torch!\n\nLmk if you\
          \ continue to have trouble with this!"
        updatedAt: '2023-05-04T16:43:05.621Z'
      numEdits: 2
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - pirroh
        - muhtasham
    id: 6453e060b8c58783d665adfb
    type: comment
  author: madhavatreplit
  content: "Yes, the model support `torch` or `triton` for the `attn_impl` kwarg,\
    \ and 'torch' is the default.  \n\nSo just don't pass in the `attn_impl` kwarg\
    \ to the `AutoModelFromCausalLM.from_pretrained` call and it will default to using\
    \ the attention implementation in torch!\n\nLmk if you continue to have trouble\
    \ with this!"
  created_at: 2023-05-04 15:42:08+00:00
  edited: true
  hidden: false
  id: 6453e060b8c58783d665adfb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e11778d6d7c0e789763a758bc8fca171.svg
      fullname: Loui Sum
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LouiSum
      type: user
    createdAt: '2023-05-05T14:03:52.000Z'
    data:
      edited: false
      editors:
      - LouiSum
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e11778d6d7c0e789763a758bc8fca171.svg
          fullname: Loui Sum
          isHf: false
          isPro: false
          name: LouiSum
          type: user
        html: '<p>It works. Thanks</p>

          '
        raw: It works. Thanks
        updatedAt: '2023-05-05T14:03:52.655Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - pirroh
    id: 64550cc8f61f10d69dc77676
    type: comment
  author: LouiSum
  content: It works. Thanks
  created_at: 2023-05-05 13:03:52+00:00
  edited: false
  hidden: false
  id: 64550cc8f61f10d69dc77676
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/fa933dbbbfe85eb59f73c12e065ed712.svg
      fullname: Madhav
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: madhavatreplit
      type: user
    createdAt: '2023-05-08T06:59:01.000Z'
    data:
      status: closed
    id: 64589db5c5d0d57ba416fdd1
    type: status-change
  author: madhavatreplit
  created_at: 2023-05-08 05:59:01+00:00
  id: 64589db5c5d0d57ba416fdd1
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: replit/replit-code-v1-3b
repo_type: model
status: closed
target_branch: null
title: Can use torch for attention implementation?
