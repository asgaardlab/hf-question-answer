!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Sardar
conflicting_files: null
created_at: 2023-06-17 02:49:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1656842600052-noauth.jpeg?w=200&h=200&f=face
      fullname: 'Arslan Mushtaq '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sardar
      type: user
    createdAt: '2023-06-17T03:49:11.000Z'
    data:
      edited: false
      editors:
      - Sardar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2980668246746063
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1656842600052-noauth.jpeg?w=200&h=200&f=face
          fullname: 'Arslan Mushtaq '
          isHf: false
          isPro: false
          name: Sardar
          type: user
        html: "<p>This was the code:<br>from peft import prepare_model_for_kbit_training</p>\n\
          <p>model.gradient_checkpointing_enable()<br>model = prepare_model_for_kbit_training(model)</p>\n\
          <p>This was the error:<br>\u256D\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \ Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u256E<br>\u2502 in &lt;cell line: 3&gt;:3                 \
          \                                                             \u2502<br>\u2502\
          \                                                                      \
          \                            \u2502<br>\u2502 /usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1624\
          \ in                   \u2502<br>\u2502 gradient_checkpointing_enable  \
          \                                                                  \u2502\
          <br>\u2502                                                             \
          \                                     \u2502<br>\u2502   1621 \u2502   \u2502\
          \   activations\".                                                     \
          \                \u2502<br>\u2502   1622 \u2502   \u2502   \"\"\"      \
          \                                                                      \
          \   \u2502<br>\u2502   1623 \u2502   \u2502   if not self.supports_gradient_checkpointing:\
          \                                      \u2502<br>\u2502 \u2771 1624 \u2502\
          \   \u2502   \u2502   raise ValueError(f\"{self.<strong>class</strong>.<strong>name</strong>}\
          \ does not support gradient check  \u2502<br>\u2502   1625 \u2502   \u2502\
          \   self.apply(partial(self._set_gradient_checkpointing, value=True))  \
          \               \u2502<br>\u2502   1626 \u2502                         \
          \                                                                \u2502\
          <br>\u2502   1627 \u2502   def gradient_checkpointing_disable(self):   \
          \                                          \u2502<br>\u2570\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256F\
          <br>ValueError: MPTForCausalLM does not support gradient checkpointing.</p>\n"
        raw: "This was the code:\r\nfrom peft import prepare_model_for_kbit_training\r\
          \n\r\nmodel.gradient_checkpointing_enable()\r\nmodel = prepare_model_for_kbit_training(model)\r\
          \n\r\n\r\nThis was the error:\r\n\u256D\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u256E\r\n\u2502 in <cell line: 3>:3                       \
          \                                                       \u2502\r\n\u2502\
          \                                                                      \
          \                            \u2502\r\n\u2502 /usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1624\
          \ in                   \u2502\r\n\u2502 gradient_checkpointing_enable  \
          \                                                                  \u2502\
          \r\n\u2502                                                             \
          \                                     \u2502\r\n\u2502   1621 \u2502   \u2502\
          \   activations\".                                                     \
          \                \u2502\r\n\u2502   1622 \u2502   \u2502   \"\"\"      \
          \                                                                      \
          \   \u2502\r\n\u2502   1623 \u2502   \u2502   if not self.supports_gradient_checkpointing:\
          \                                      \u2502\r\n\u2502 \u2771 1624 \u2502\
          \   \u2502   \u2502   raise ValueError(f\"{self.__class__.__name__} does\
          \ not support gradient check  \u2502\r\n\u2502   1625 \u2502   \u2502  \
          \ self.apply(partial(self._set_gradient_checkpointing, value=True))    \
          \             \u2502\r\n\u2502   1626 \u2502                           \
          \                                                              \u2502\r\n\
          \u2502   1627 \u2502   def gradient_checkpointing_disable(self):       \
          \                                      \u2502\r\n\u2570\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256F\
          \r\nValueError: MPTForCausalLM does not support gradient checkpointing."
        updatedAt: '2023-06-17T03:49:11.885Z'
      numEdits: 0
      reactions: []
    id: 648d2d374e46c331f07cc24e
    type: comment
  author: Sardar
  content: "This was the code:\r\nfrom peft import prepare_model_for_kbit_training\r\
    \n\r\nmodel.gradient_checkpointing_enable()\r\nmodel = prepare_model_for_kbit_training(model)\r\
    \n\r\n\r\nThis was the error:\r\n\u256D\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most\
    \ recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256E\r\n\u2502 in <cell\
    \ line: 3>:3                                                                 \
    \             \u2502\r\n\u2502                                               \
    \                                                   \u2502\r\n\u2502 /usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1624\
    \ in                   \u2502\r\n\u2502 gradient_checkpointing_enable        \
    \                                                            \u2502\r\n\u2502\
    \                                                                            \
    \                      \u2502\r\n\u2502   1621 \u2502   \u2502   activations\"\
    .                                                                     \u2502\r\
    \n\u2502   1622 \u2502   \u2502   \"\"\"                                     \
    \                                          \u2502\r\n\u2502   1623 \u2502   \u2502\
    \   if not self.supports_gradient_checkpointing:                             \
    \         \u2502\r\n\u2502 \u2771 1624 \u2502   \u2502   \u2502   raise ValueError(f\"\
    {self.__class__.__name__} does not support gradient check  \u2502\r\n\u2502  \
    \ 1625 \u2502   \u2502   self.apply(partial(self._set_gradient_checkpointing,\
    \ value=True))                 \u2502\r\n\u2502   1626 \u2502                \
    \                                                                         \u2502\
    \r\n\u2502   1627 \u2502   def gradient_checkpointing_disable(self):         \
    \                                    \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u256F\r\nValueError: MPTForCausalLM does not support gradient checkpointing."
  created_at: 2023-06-17 02:49:11+00:00
  edited: false
  hidden: false
  id: 648d2d374e46c331f07cc24e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 22
repo_id: replit/replit-code-v1-3b
repo_type: model
status: open
target_branch: null
title: How to train it with qlora?
