!!python/object:huggingface_hub.community.DiscussionWithDetails
author: fengcaiwen
conflicting_files: null
created_at: 2023-10-23 06:20:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/gDIzdH7aepKMg-iS4TSON.jpeg?w=200&h=200&f=face
      fullname: ' '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fengcaiwen
      type: user
    createdAt: '2023-10-23T07:20:46.000Z'
    data:
      edited: false
      editors:
      - fengcaiwen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4410010278224945
      isReport: true
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/gDIzdH7aepKMg-iS4TSON.jpeg?w=200&h=200&f=face
          fullname: ' '
          isHf: false
          isPro: false
          name: fengcaiwen
          type: user
        html: "<p>\u279C  docker build -t naison/fastchat:v1 -f /Users/users/Desktop/new/demo/LLM/fastchat.Dockerfile\
          \ .<br>[+] Building 57.4s (20/20) FINISHED<br> =&gt; [internal] load build\
          \ definition from fastchat.Dockerfile                                  \
          \                                                                      \
          \  0.1s<br> =&gt; =&gt; transferring dockerfile: 1.18kB                \
          \                                                                      \
          \                                           0.0s<br> =&gt; [internal] load\
          \ .dockerignore                                                        \
          \                                                                      \
          \        0.1s<br> =&gt; =&gt; transferring context: 2B                 \
          \                                                                      \
          \                                                 0.0s<br> =&gt; [internal]\
          \ load metadata for docker.io/nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04\
          \                                                                      \
          \           0.0s<br> =&gt; [ 1/16] FROM docker.io/nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04\
          \                                                                      \
          \                           0.0s<br> =&gt; [internal] load build context\
          \                                                                      \
          \                                                                0.0s<br>\
          \ =&gt; =&gt; transferring context: 9.53kB                             \
          \                                                                      \
          \                                 0.0s<br> =&gt; CACHED [ 2/16] WORKDIR\
          \ /app/FastChat                                                        \
          \                                                                      \
          \ 0.0s<br> =&gt; CACHED [ 3/16] RUN apt-get update                     \
          \                                                                      \
          \                                       0.0s<br> =&gt; CACHED [ 4/16] RUN\
          \ apt-get install -y software-properties-common                        \
          \                                                                      \
          \     0.0s<br> =&gt; CACHED [ 5/16] RUN apt-get update                 \
          \                                                                      \
          \                                           0.0s<br> =&gt; CACHED [ 6/16]\
          \ RUN apt-get install -y git                                           \
          \                                                                      \
          \         0.0s<br> =&gt; CACHED [ 7/16] RUN apt-get install -y   python3.11\
          \   python3-pip                                                        \
          \                                           0.0s<br> =&gt; CACHED [ 8/16]\
          \ RUN curl --proto '=https' --tlsv1.2 -sSf <a rel=\"nofollow\" href=\"https://sh.rustup.rs\"\
          >https://sh.rustup.rs</a> | sh                                         \
          \                                         0.0s<br> =&gt; CACHED [ 9/16]\
          \ RUN git clone <a rel=\"nofollow\" href=\"https://github.com/lm-sys/FastChat.git\"\
          >https://github.com/lm-sys/FastChat.git</a> .                          \
          \                                                                    0.0s<br>\
          \ =&gt; CACHED [10/16] RUN pip3 install --upgrade pip                  \
          \                                                                      \
          \                              0.0s<br> =&gt; CACHED [11/16] RUN pip3 install\
          \ -e \".[model_worker,webui]\"                                         \
          \                                                                0.0s<br>\
          \ =&gt; CACHED [12/16] RUN pip3 install accelerate                     \
          \                                                                      \
          \                              0.0s<br> =&gt; CACHED [13/16] RUN pip3 install\
          \ transformers                                                         \
          \                                                              0.0s<br>\
          \ =&gt; CACHED [14/16] RUN mkdir -p /app/models/output                 \
          \                                                                      \
          \                              0.0s<br> =&gt; [15/16] COPY replit-code-v1-3b\
          \ /app/models/replit-code-v1-3b                                        \
          \                                                              51.0s<br>\
          \ =&gt; ERROR [16/16] RUN python3 -m fastchat.serve.cli     --model /app/models/replit-code-v1-3b\
          \ --debug                                                              \
          \    6.1s</p>\n<hr>\n<blockquote>\n<p>[16/16] RUN python3 -m fastchat.serve.cli\
          \     --model /app/models/replit-code-v1-3b --debug:<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.673 Traceback (most recent call last):<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.673   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main<br><a\
          \ href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a> 5.673     return\
          \ _run_code(code, main_globals, None,<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.673   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code<br><a\
          \ href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a> 5.673     exec(code,\
          \ run_globals)<br><a href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a>\
          \ 5.673   File \"/app/FastChat/fastchat/serve/cli.py\", line 291, in <br><a\
          \ href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a> 5.673     main(args)<br><a\
          \ href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a> 5.673   File\
          \ \"/app/FastChat/fastchat/serve/cli.py\", line 215, in main<br><a href=\"\
          /replit/replit-code-v1-3b/discussions/20\">#20</a> 5.673     chat_loop(<br><a\
          \ href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a> 5.673   File\
          \ \"/app/FastChat/fastchat/serve/inference.py\", line 313, in chat_loop<br><a\
          \ href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a> 5.673     model,\
          \ tokenizer = load_model(<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.673   File \"/app/FastChat/fastchat/model/model_adapter.py\"\
          , line 301, in load_model<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.673     model, tokenizer = adapter.load_model(model_path, kwargs)<br><a\
          \ href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a> 5.673   File\
          \ \"/app/FastChat/fastchat/model/model_adapter.py\", line 70, in load_model<br><a\
          \ href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a> 5.673     tokenizer\
          \ = AutoTokenizer.from_pretrained(<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.673   File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 738, in from_pretrained<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.675     return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.675   File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\"\
          , line 2017, in from_pretrained<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.678     return cls._from_pretrained(<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.678   File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\"\
          , line 2249, in _from_pretrained<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.679     tokenizer = cls(*init_inputs, **init_kwargs)<br><a href=\"\
          /replit/replit-code-v1-3b/discussions/20\">#20</a> 5.679   File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm_tokenizer.py\"\
          , line 66, in <strong>init</strong><br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.679     super().<strong>init</strong>(bos_token=bos_token, eos_token=eos_token,\
          \ unk_token=unk_token, pad_token=pad_token, sep_token=sep_token, sp_model_kwargs=self.sp_model_kwargs,\
          \ **kwargs)<br><a href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a>\
          \ 5.679   File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\"\
          , line 367, in <strong>init</strong><br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.681     self._add_tokens(<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.681   File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\"\
          , line 467, in _add_tokens<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.682     current_vocab = self.get_vocab().copy()<br><a href=\"\
          /replit/replit-code-v1-3b/discussions/20\">#20</a> 5.682   File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm_tokenizer.py\"\
          , line 76, in get_vocab<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.682     vocab = {self.convert_ids_to_tokens(i): i for i in range(self.vocab_size)}<br><a\
          \ href=\"/replit/replit-code-v1-3b/discussions/20\">#20</a> 5.682   File\
          \ \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm_tokenizer.py\"\
          , line 73, in vocab_size<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.682     return self.sp_model.get_piece_size()<br><a href=\"/replit/replit-code-v1-3b/discussions/20\"\
          >#20</a> 5.682 AttributeError: 'ReplitLMTokenizer' object has no attribute\
          \ 'sp_model'</p>\n</blockquote>\n<hr>\n<p>executor failed running [/bin/sh\
          \ -c python3 -m fastchat.serve.cli     --model /app/models/replit-code-v1-3b\
          \ --debug]: exit code: 1</p>\n<p>replitLM cann't access via fastchat?</p>\n"
        raw: "\u279C  docker build -t naison/fastchat:v1 -f /Users/users/Desktop/new/demo/LLM/fastchat.Dockerfile\
          \ .\r\n[+] Building 57.4s (20/20) FINISHED\r\n => [internal] load build\
          \ definition from fastchat.Dockerfile                                  \
          \                                                                      \
          \  0.1s\r\n => => transferring dockerfile: 1.18kB                      \
          \                                                                      \
          \                                     0.0s\r\n => [internal] load .dockerignore\
          \                                                                      \
          \                                                                0.1s\r\n\
          \ => => transferring context: 2B                                       \
          \                                                                      \
          \                           0.0s\r\n => [internal] load metadata for docker.io/nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04\
          \                                                                      \
          \           0.0s\r\n => [ 1/16] FROM docker.io/nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04\
          \                                                                      \
          \                           0.0s\r\n => [internal] load build context  \
          \                                                                      \
          \                                                              0.0s\r\n\
          \ => => transferring context: 9.53kB                                   \
          \                                                                      \
          \                           0.0s\r\n => CACHED [ 2/16] WORKDIR /app/FastChat\
          \                                                                      \
          \                                                         0.0s\r\n => CACHED\
          \ [ 3/16] RUN apt-get update                                           \
          \                                                                      \
          \                 0.0s\r\n => CACHED [ 4/16] RUN apt-get install -y software-properties-common\
          \                                                                      \
          \                             0.0s\r\n => CACHED [ 5/16] RUN apt-get update\
          \                                                                      \
          \                                                            0.0s\r\n =>\
          \ CACHED [ 6/16] RUN apt-get install -y git                            \
          \                                                                      \
          \                        0.0s\r\n => CACHED [ 7/16] RUN apt-get install\
          \ -y   python3.11   python3-pip                                        \
          \                                                           0.0s\r\n =>\
          \ CACHED [ 8/16] RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs\
          \ | sh                                                                 \
          \                 0.0s\r\n => CACHED [ 9/16] RUN git clone https://github.com/lm-sys/FastChat.git\
          \ .                                                                    \
          \                          0.0s\r\n => CACHED [10/16] RUN pip3 install --upgrade\
          \ pip                                                                  \
          \                                                    0.0s\r\n => CACHED\
          \ [11/16] RUN pip3 install -e \".[model_worker,webui]\"                \
          \                                                                      \
          \                   0.0s\r\n => CACHED [12/16] RUN pip3 install accelerate\
          \                                                                      \
          \                                                   0.0s\r\n => CACHED [13/16]\
          \ RUN pip3 install transformers                                        \
          \                                                                      \
          \         0.0s\r\n => CACHED [14/16] RUN mkdir -p /app/models/output   \
          \                                                                      \
          \                                            0.0s\r\n => [15/16] COPY replit-code-v1-3b\
          \ /app/models/replit-code-v1-3b                                        \
          \                                                              51.0s\r\n\
          \ => ERROR [16/16] RUN python3 -m fastchat.serve.cli     --model /app/models/replit-code-v1-3b\
          \ --debug                                                              \
          \    6.1s\r\n------\r\n > [16/16] RUN python3 -m fastchat.serve.cli    \
          \ --model /app/models/replit-code-v1-3b --debug:\r\n#20 5.673 Traceback\
          \ (most recent call last):\r\n#20 5.673   File \"/usr/lib/python3.10/runpy.py\"\
          , line 196, in _run_module_as_main\r\n#20 5.673     return _run_code(code,\
          \ main_globals, None,\r\n#20 5.673   File \"/usr/lib/python3.10/runpy.py\"\
          , line 86, in _run_code\r\n#20 5.673     exec(code, run_globals)\r\n#20\
          \ 5.673   File \"/app/FastChat/fastchat/serve/cli.py\", line 291, in <module>\r\
          \n#20 5.673     main(args)\r\n#20 5.673   File \"/app/FastChat/fastchat/serve/cli.py\"\
          , line 215, in main\r\n#20 5.673     chat_loop(\r\n#20 5.673   File \"/app/FastChat/fastchat/serve/inference.py\"\
          , line 313, in chat_loop\r\n#20 5.673     model, tokenizer = load_model(\r\
          \n#20 5.673   File \"/app/FastChat/fastchat/model/model_adapter.py\", line\
          \ 301, in load_model\r\n#20 5.673     model, tokenizer = adapter.load_model(model_path,\
          \ kwargs)\r\n#20 5.673   File \"/app/FastChat/fastchat/model/model_adapter.py\"\
          , line 70, in load_model\r\n#20 5.673     tokenizer = AutoTokenizer.from_pretrained(\r\
          \n#20 5.673   File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 738, in from_pretrained\r\n#20 5.675     return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\r\n#20 5.675   File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\"\
          , line 2017, in from_pretrained\r\n#20 5.678     return cls._from_pretrained(\r\
          \n#20 5.678   File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\"\
          , line 2249, in _from_pretrained\r\n#20 5.679     tokenizer = cls(*init_inputs,\
          \ **init_kwargs)\r\n#20 5.679   File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm_tokenizer.py\"\
          , line 66, in __init__\r\n#20 5.679     super().__init__(bos_token=bos_token,\
          \ eos_token=eos_token, unk_token=unk_token, pad_token=pad_token, sep_token=sep_token,\
          \ sp_model_kwargs=self.sp_model_kwargs, **kwargs)\r\n#20 5.679   File \"\
          /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\"\
          , line 367, in __init__\r\n#20 5.681     self._add_tokens(\r\n#20 5.681\
          \   File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\"\
          , line 467, in _add_tokens\r\n#20 5.682     current_vocab = self.get_vocab().copy()\r\
          \n#20 5.682   File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm_tokenizer.py\"\
          , line 76, in get_vocab\r\n#20 5.682     vocab = {self.convert_ids_to_tokens(i):\
          \ i for i in range(self.vocab_size)}\r\n#20 5.682   File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm_tokenizer.py\"\
          , line 73, in vocab_size\r\n#20 5.682     return self.sp_model.get_piece_size()\r\
          \n#20 5.682 AttributeError: 'ReplitLMTokenizer' object has no attribute\
          \ 'sp_model'\r\n------\r\nexecutor failed running [/bin/sh -c python3 -m\
          \ fastchat.serve.cli     --model /app/models/replit-code-v1-3b --debug]:\
          \ exit code: 1\r\n\r\n\r\n\r\nreplitLM cann't access via fastchat?"
        updatedAt: '2023-10-23T07:20:46.235Z'
      numEdits: 0
      reactions: []
    id: 65361ecea2c81a3d29bcde92
    type: comment
  author: fengcaiwen
  content: "\u279C  docker build -t naison/fastchat:v1 -f /Users/users/Desktop/new/demo/LLM/fastchat.Dockerfile\
    \ .\r\n[+] Building 57.4s (20/20) FINISHED\r\n => [internal] load build definition\
    \ from fastchat.Dockerfile                                                   \
    \                                                       0.1s\r\n => => transferring\
    \ dockerfile: 1.18kB                                                         \
    \                                                                        0.0s\r\
    \n => [internal] load .dockerignore                                          \
    \                                                                            \
    \                0.1s\r\n => => transferring context: 2B                     \
    \                                                                            \
    \                                       0.0s\r\n => [internal] load metadata for\
    \ docker.io/nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04                      \
    \                                                           0.0s\r\n => [ 1/16]\
    \ FROM docker.io/nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04                 \
    \                                                                            \
    \    0.0s\r\n => [internal] load build context                               \
    \                                                                            \
    \                           0.0s\r\n => => transferring context: 9.53kB      \
    \                                                                            \
    \                                                  0.0s\r\n => CACHED [ 2/16]\
    \ WORKDIR /app/FastChat                                                      \
    \                                                                         0.0s\r\
    \n => CACHED [ 3/16] RUN apt-get update                                      \
    \                                                                            \
    \                0.0s\r\n => CACHED [ 4/16] RUN apt-get install -y software-properties-common\
    \                                                                            \
    \                       0.0s\r\n => CACHED [ 5/16] RUN apt-get update        \
    \                                                                            \
    \                                              0.0s\r\n => CACHED [ 6/16] RUN\
    \ apt-get install -y git                                                     \
    \                                                                     0.0s\r\n\
    \ => CACHED [ 7/16] RUN apt-get install -y   python3.11   python3-pip        \
    \                                                                            \
    \               0.0s\r\n => CACHED [ 8/16] RUN curl --proto '=https' --tlsv1.2\
    \ -sSf https://sh.rustup.rs | sh                                             \
    \                                     0.0s\r\n => CACHED [ 9/16] RUN git clone\
    \ https://github.com/lm-sys/FastChat.git .                                   \
    \                                                           0.0s\r\n => CACHED\
    \ [10/16] RUN pip3 install --upgrade pip                                     \
    \                                                                            \
    \     0.0s\r\n => CACHED [11/16] RUN pip3 install -e \".[model_worker,webui]\"\
    \                                                                            \
    \                             0.0s\r\n => CACHED [12/16] RUN pip3 install accelerate\
    \                                                                            \
    \                                             0.0s\r\n => CACHED [13/16] RUN pip3\
    \ install transformers                                                       \
    \                                                                0.0s\r\n => CACHED\
    \ [14/16] RUN mkdir -p /app/models/output                                    \
    \                                                                            \
    \     0.0s\r\n => [15/16] COPY replit-code-v1-3b /app/models/replit-code-v1-3b\
    \                                                                            \
    \                          51.0s\r\n => ERROR [16/16] RUN python3 -m fastchat.serve.cli\
    \     --model /app/models/replit-code-v1-3b --debug                          \
    \                                        6.1s\r\n------\r\n > [16/16] RUN python3\
    \ -m fastchat.serve.cli     --model /app/models/replit-code-v1-3b --debug:\r\n\
    #20 5.673 Traceback (most recent call last):\r\n#20 5.673   File \"/usr/lib/python3.10/runpy.py\"\
    , line 196, in _run_module_as_main\r\n#20 5.673     return _run_code(code, main_globals,\
    \ None,\r\n#20 5.673   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\r\
    \n#20 5.673     exec(code, run_globals)\r\n#20 5.673   File \"/app/FastChat/fastchat/serve/cli.py\"\
    , line 291, in <module>\r\n#20 5.673     main(args)\r\n#20 5.673   File \"/app/FastChat/fastchat/serve/cli.py\"\
    , line 215, in main\r\n#20 5.673     chat_loop(\r\n#20 5.673   File \"/app/FastChat/fastchat/serve/inference.py\"\
    , line 313, in chat_loop\r\n#20 5.673     model, tokenizer = load_model(\r\n#20\
    \ 5.673   File \"/app/FastChat/fastchat/model/model_adapter.py\", line 301, in\
    \ load_model\r\n#20 5.673     model, tokenizer = adapter.load_model(model_path,\
    \ kwargs)\r\n#20 5.673   File \"/app/FastChat/fastchat/model/model_adapter.py\"\
    , line 70, in load_model\r\n#20 5.673     tokenizer = AutoTokenizer.from_pretrained(\r\
    \n#20 5.673   File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\"\
    , line 738, in from_pretrained\r\n#20 5.675     return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\r\n#20 5.675   File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\"\
    , line 2017, in from_pretrained\r\n#20 5.678     return cls._from_pretrained(\r\
    \n#20 5.678   File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\"\
    , line 2249, in _from_pretrained\r\n#20 5.679     tokenizer = cls(*init_inputs,\
    \ **init_kwargs)\r\n#20 5.679   File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm_tokenizer.py\"\
    , line 66, in __init__\r\n#20 5.679     super().__init__(bos_token=bos_token,\
    \ eos_token=eos_token, unk_token=unk_token, pad_token=pad_token, sep_token=sep_token,\
    \ sp_model_kwargs=self.sp_model_kwargs, **kwargs)\r\n#20 5.679   File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\"\
    , line 367, in __init__\r\n#20 5.681     self._add_tokens(\r\n#20 5.681   File\
    \ \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\"\
    , line 467, in _add_tokens\r\n#20 5.682     current_vocab = self.get_vocab().copy()\r\
    \n#20 5.682   File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm_tokenizer.py\"\
    , line 76, in get_vocab\r\n#20 5.682     vocab = {self.convert_ids_to_tokens(i):\
    \ i for i in range(self.vocab_size)}\r\n#20 5.682   File \"/root/.cache/huggingface/modules/transformers_modules/replit-code-v1-3b/replit_lm_tokenizer.py\"\
    , line 73, in vocab_size\r\n#20 5.682     return self.sp_model.get_piece_size()\r\
    \n#20 5.682 AttributeError: 'ReplitLMTokenizer' object has no attribute 'sp_model'\r\
    \n------\r\nexecutor failed running [/bin/sh -c python3 -m fastchat.serve.cli\
    \     --model /app/models/replit-code-v1-3b --debug]: exit code: 1\r\n\r\n\r\n\
    \r\nreplitLM cann't access via fastchat?"
  created_at: 2023-10-23 06:20:46+00:00
  edited: false
  hidden: false
  id: 65361ecea2c81a3d29bcde92
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/gDIzdH7aepKMg-iS4TSON.jpeg?w=200&h=200&f=face
      fullname: ' '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fengcaiwen
      type: user
    createdAt: '2023-10-26T10:06:32.000Z'
    data:
      from: "\U0001F6A9 Report: Ethical issue(s)"
      to: "\U0001F6A9 Integrate with fastChat ?"
    id: 653a3a28882e390615694203
    type: title-change
  author: fengcaiwen
  created_at: 2023-10-26 09:06:32+00:00
  id: 653a3a28882e390615694203
  new_title: "\U0001F6A9 Integrate with fastChat ?"
  old_title: "\U0001F6A9 Report: Ethical issue(s)"
  type: title-change
is_pull_request: false
merge_commit_oid: null
num: 31
repo_id: replit/replit-code-v1-3b
repo_type: model
status: open
target_branch: null
title: "\U0001F6A9 Integrate with fastChat ?"
