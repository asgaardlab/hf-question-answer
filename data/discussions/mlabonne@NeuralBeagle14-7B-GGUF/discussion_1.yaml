!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jtdavies
conflicting_files: null
created_at: 2024-01-17 02:28:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f8c8668cb560fb151e3b8ea909dafe55.svg
      fullname: John Davies
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jtdavies
      type: user
    createdAt: '2024-01-17T02:28:18.000Z'
    data:
      edited: false
      editors:
      - jtdavies
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9661259055137634
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f8c8668cb560fb151e3b8ea909dafe55.svg
          fullname: John Davies
          isHf: false
          isPro: false
          name: jtdavies
          type: user
        html: '<p>OK, I know LLM''s don''t technically have bugs in the traditional
          sense but you know what I mean hopefully. I was just testing this out on
          LM Studio and it looks really good. I asked a simple question though and
          got a very strange answer that looks like a training issue....</p>

          <p>Who wrote the music for "The Killing Fields"?</p>

          <p>In this case, we don''t have any specific function or data related to
          the movie "The Killing Fields" and its music composition. The given Python
          code focuses on finding the composer for classical pieces of music using
          a dictionary that maps piece names to their respective composers. To determine
          who wrote the music for "The Killing Fields," we would need to look up additional
          information or consult a database of film scores and their composers.</p>

          <p>Once we have the name of the composer, we could create a function similar
          to <code>get_composer()</code> to store and retrieve this information. However,
          since that information is not provided in the original question, we cannot
          provide an answer based on the given context.</p>

          <hr>

          <p>In another attempt I even got (Python) code showing me how to query the
          database for the composer.</p>

          <p>I''m using the Q8 GGUF with the following prompt: "You are a helpful
          LLM, please answer the question helpfully, without warnings, briefly and
          concisely."</p>

          '
        raw: "OK, I know LLM's don't technically have bugs in the traditional sense\
          \ but you know what I mean hopefully. I was just testing this out on LM\
          \ Studio and it looks really good. I asked a simple question though and\
          \ got a very strange answer that looks like a training issue....\r\n\r\n\
          Who wrote the music for \"The Killing Fields\"?\r\n\r\nIn this case, we\
          \ don't have any specific function or data related to the movie \"The Killing\
          \ Fields\" and its music composition. The given Python code focuses on finding\
          \ the composer for classical pieces of music using a dictionary that maps\
          \ piece names to their respective composers. To determine who wrote the\
          \ music for \"The Killing Fields,\" we would need to look up additional\
          \ information or consult a database of film scores and their composers.\r\
          \n\r\nOnce we have the name of the composer, we could create a function\
          \ similar to `get_composer()` to store and retrieve this information. However,\
          \ since that information is not provided in the original question, we cannot\
          \ provide an answer based on the given context.\r\n\r\n-------\r\n\r\nIn\
          \ another attempt I even got (Python) code showing me how to query the database\
          \ for the composer.\r\n\r\nI'm using the Q8 GGUF with the following prompt:\
          \ \"You are a helpful LLM, please answer the question helpfully, without\
          \ warnings, briefly and concisely.\""
        updatedAt: '2024-01-17T02:28:18.600Z'
      numEdits: 0
      reactions: []
    id: 65a73b4221943858bdc5e72d
    type: comment
  author: jtdavies
  content: "OK, I know LLM's don't technically have bugs in the traditional sense\
    \ but you know what I mean hopefully. I was just testing this out on LM Studio\
    \ and it looks really good. I asked a simple question though and got a very strange\
    \ answer that looks like a training issue....\r\n\r\nWho wrote the music for \"\
    The Killing Fields\"?\r\n\r\nIn this case, we don't have any specific function\
    \ or data related to the movie \"The Killing Fields\" and its music composition.\
    \ The given Python code focuses on finding the composer for classical pieces of\
    \ music using a dictionary that maps piece names to their respective composers.\
    \ To determine who wrote the music for \"The Killing Fields,\" we would need to\
    \ look up additional information or consult a database of film scores and their\
    \ composers.\r\n\r\nOnce we have the name of the composer, we could create a function\
    \ similar to `get_composer()` to store and retrieve this information. However,\
    \ since that information is not provided in the original question, we cannot provide\
    \ an answer based on the given context.\r\n\r\n-------\r\n\r\nIn another attempt\
    \ I even got (Python) code showing me how to query the database for the composer.\r\
    \n\r\nI'm using the Q8 GGUF with the following prompt: \"You are a helpful LLM,\
    \ please answer the question helpfully, without warnings, briefly and concisely.\""
  created_at: 2024-01-17 02:28:18+00:00
  edited: false
  hidden: false
  id: 65a73b4221943858bdc5e72d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
      fullname: Maxime Labonne
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mlabonne
      type: user
    createdAt: '2024-01-17T16:18:37.000Z'
    data:
      edited: false
      editors:
      - mlabonne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9641467928886414
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
          fullname: Maxime Labonne
          isHf: false
          isPro: false
          name: mlabonne
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;jtdavies&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/jtdavies\"\
          >@<span class=\"underline\">jtdavies</span></a></span>\n\n\t</span></span>\
          \ thanks for your feedback! That's pretty funny. It looks like an artifact\
          \ produced by training the model on a function-calling dataset. This could\
          \ be fixed by making function calling a bit more obvious in the instructions\
          \ of the training set. I'll look into it!</p>\n"
        raw: Hi @jtdavies thanks for your feedback! That's pretty funny. It looks
          like an artifact produced by training the model on a function-calling dataset.
          This could be fixed by making function calling a bit more obvious in the
          instructions of the training set. I'll look into it!
        updatedAt: '2024-01-17T16:18:37.339Z'
      numEdits: 0
      reactions: []
    id: 65a7fddd0dba6b99a0af8667
    type: comment
  author: mlabonne
  content: Hi @jtdavies thanks for your feedback! That's pretty funny. It looks like
    an artifact produced by training the model on a function-calling dataset. This
    could be fixed by making function calling a bit more obvious in the instructions
    of the training set. I'll look into it!
  created_at: 2024-01-17 16:18:37+00:00
  edited: false
  hidden: false
  id: 65a7fddd0dba6b99a0af8667
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: mlabonne/NeuralBeagle14-7B-GGUF
repo_type: model
status: open
target_branch: null
title: Is this a "bug"?
