!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KnutJaegersberg
conflicting_files: null
created_at: 2023-10-15 05:53:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-10-15T06:53:19.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.44519516825675964
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>I tried to use it, but got this exception:</p>

          <p>2023-10-15 08:52:03 INFO:Loading rwkv-4-430m-pile...<br>2023-10-15 08:52:29
          ERROR:Failed to load the model.<br>Traceback (most recent call last):<br>  File
          "/run/media/knut/HD/text-generation-webui/modules/ui_model_menu.py", line
          201, in load_model_wrapper<br>    shared.model, shared.tokenizer = load_model(shared.model_name,
          loader)<br>  File "/run/media/knut/HD/text-generation-webui/modules/models.py",
          line 87, in load_model<br>    tokenizer = load_tokenizer(model_name, model)<br>  File
          "/run/media/knut/HD/text-generation-webui/modules/models.py", line 106,
          in load_tokenizer<br>    tokenizer = AutoTokenizer.from_pretrained(<br>  File
          "/home/knut/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py",
          line 749, in from_pretrained<br>    raise ValueError(<br>ValueError: Tokenizer
          class GPTNeoXTokenizer does not exist or is not currently imported.</p>

          '
        raw: "I tried to use it, but got this exception:\r\n\r\n2023-10-15 08:52:03\
          \ INFO:Loading rwkv-4-430m-pile...\r\n2023-10-15 08:52:29 ERROR:Failed to\
          \ load the model.\r\nTraceback (most recent call last):\r\n  File \"/run/media/knut/HD/text-generation-webui/modules/ui_model_menu.py\"\
          , line 201, in load_model_wrapper\r\n    shared.model, shared.tokenizer\
          \ = load_model(shared.model_name, loader)\r\n  File \"/run/media/knut/HD/text-generation-webui/modules/models.py\"\
          , line 87, in load_model\r\n    tokenizer = load_tokenizer(model_name, model)\r\
          \n  File \"/run/media/knut/HD/text-generation-webui/modules/models.py\"\
          , line 106, in load_tokenizer\r\n    tokenizer = AutoTokenizer.from_pretrained(\r\
          \n  File \"/home/knut/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 749, in from_pretrained\r\n    raise ValueError(\r\nValueError: Tokenizer\
          \ class GPTNeoXTokenizer does not exist or is not currently imported.\r\n"
        updatedAt: '2023-10-15T06:53:19.372Z'
      numEdits: 0
      reactions: []
    id: 652b8c5ff6390fe048f00d6b
    type: comment
  author: KnutJaegersberg
  content: "I tried to use it, but got this exception:\r\n\r\n2023-10-15 08:52:03\
    \ INFO:Loading rwkv-4-430m-pile...\r\n2023-10-15 08:52:29 ERROR:Failed to load\
    \ the model.\r\nTraceback (most recent call last):\r\n  File \"/run/media/knut/HD/text-generation-webui/modules/ui_model_menu.py\"\
    , line 201, in load_model_wrapper\r\n    shared.model, shared.tokenizer = load_model(shared.model_name,\
    \ loader)\r\n  File \"/run/media/knut/HD/text-generation-webui/modules/models.py\"\
    , line 87, in load_model\r\n    tokenizer = load_tokenizer(model_name, model)\r\
    \n  File \"/run/media/knut/HD/text-generation-webui/modules/models.py\", line\
    \ 106, in load_tokenizer\r\n    tokenizer = AutoTokenizer.from_pretrained(\r\n\
    \  File \"/home/knut/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
    , line 749, in from_pretrained\r\n    raise ValueError(\r\nValueError: Tokenizer\
    \ class GPTNeoXTokenizer does not exist or is not currently imported.\r\n"
  created_at: 2023-10-15 05:53:19+00:00
  edited: false
  hidden: false
  id: 652b8c5ff6390fe048f00d6b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/257bf58ea2d86758983b5da93e046575.svg
      fullname: Kalei Neely
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KaleiNeely
      type: user
    createdAt: '2023-10-15T07:32:22.000Z'
    data:
      edited: false
      editors:
      - KaleiNeely
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6086863875389099
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/257bf58ea2d86758983b5da93e046575.svg
          fullname: Kalei Neely
          isHf: false
          isPro: false
          name: KaleiNeely
          type: user
        html: "<p>try:<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/648fcae847a7c818298d925d/wdtbiKedTNmi8tfDdHf7u.png\"\
          ><img alt=\"\u56FE\u7247.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/648fcae847a7c818298d925d/wdtbiKedTNmi8tfDdHf7u.png\"\
          ></a></p>\n"
        raw: "try: \n![\u56FE\u7247.png](https://cdn-uploads.huggingface.co/production/uploads/648fcae847a7c818298d925d/wdtbiKedTNmi8tfDdHf7u.png)\n"
        updatedAt: '2023-10-15T07:32:22.065Z'
      numEdits: 0
      reactions: []
    id: 652b958690e317f2438f350a
    type: comment
  author: KaleiNeely
  content: "try: \n![\u56FE\u7247.png](https://cdn-uploads.huggingface.co/production/uploads/648fcae847a7c818298d925d/wdtbiKedTNmi8tfDdHf7u.png)\n"
  created_at: 2023-10-15 06:32:22+00:00
  edited: false
  hidden: false
  id: 652b958690e317f2438f350a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/257bf58ea2d86758983b5da93e046575.svg
      fullname: Kalei Neely
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KaleiNeely
      type: user
    createdAt: '2023-10-15T07:35:24.000Z'
    data:
      edited: false
      editors:
      - KaleiNeely
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8819958567619324
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/257bf58ea2d86758983b5da93e046575.svg
          fullname: Kalei Neely
          isHf: false
          isPro: false
          name: KaleiNeely
          type: user
        html: '<p>I am quite curious, it should use a custom tokenizer (RWKVWorldTokenizer)
          here, why would it call GPTNeoXTokenizer?</p>

          '
        raw: I am quite curious, it should use a custom tokenizer (RWKVWorldTokenizer)
          here, why would it call GPTNeoXTokenizer?
        updatedAt: '2023-10-15T07:35:24.297Z'
      numEdits: 0
      reactions: []
    id: 652b963ca21958f7db64de5e
    type: comment
  author: KaleiNeely
  content: I am quite curious, it should use a custom tokenizer (RWKVWorldTokenizer)
    here, why would it call GPTNeoXTokenizer?
  created_at: 2023-10-15 06:35:24+00:00
  edited: false
  hidden: false
  id: 652b963ca21958f7db64de5e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-10-15T09:13:05.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.662464439868927
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>I can load this model with this adjustment. I get another exception
          when trying inference but I don''t know if it is related to the text-gen-webui
          or something else. I get the same error with RWKV-5-world-167m after downgrading
          to transformers-4.33.0. I can load that model, too with that version.<br>I
          don''t know what''s going on. perhaps it doesnt use the custom tokenizer?
          </p>

          <p>Traceback (most recent call last):<br>  File "/run/media/knut/HD/text-generation-webui/modules/callbacks.py",
          line 56, in gentask<br>    ret = self.mfunc(callback=_callback, *args, **self.kwargs)<br>  File
          "/run/media/knut/HD/text-generation-webui/modules/text_generation.py", line
          349, in generate_with_callback<br>    shared.model.generate(**kwargs)<br>  File
          "/home/knut/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/utils/_contextlib.py",
          line 115, in decorate_context<br>    return func(*args, **kwargs)<br>  File
          "/home/knut/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/generation/utils.py",
          line 1443, in generate<br>    eos_token_id = eos_token_id[0]<br>IndexError:
          list index out of range</p>

          '
        raw: "I can load this model with this adjustment. I get another exception\
          \ when trying inference but I don't know if it is related to the text-gen-webui\
          \ or something else. I get the same error with RWKV-5-world-167m after downgrading\
          \ to transformers-4.33.0. I can load that model, too with that version.\
          \ \nI don't know what's going on. perhaps it doesnt use the custom tokenizer?\
          \ \n\nTraceback (most recent call last):\n  File \"/run/media/knut/HD/text-generation-webui/modules/callbacks.py\"\
          , line 56, in gentask\n    ret = self.mfunc(callback=_callback, *args, **self.kwargs)\n\
          \  File \"/run/media/knut/HD/text-generation-webui/modules/text_generation.py\"\
          , line 349, in generate_with_callback\n    shared.model.generate(**kwargs)\n\
          \  File \"/home/knut/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/home/knut/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/generation/utils.py\"\
          , line 1443, in generate\n    eos_token_id = eos_token_id[0]\nIndexError:\
          \ list index out of range\n"
        updatedAt: '2023-10-15T09:13:05.859Z'
      numEdits: 0
      reactions: []
    id: 652bad2168f1d7d1d279c372
    type: comment
  author: KnutJaegersberg
  content: "I can load this model with this adjustment. I get another exception when\
    \ trying inference but I don't know if it is related to the text-gen-webui or\
    \ something else. I get the same error with RWKV-5-world-167m after downgrading\
    \ to transformers-4.33.0. I can load that model, too with that version. \nI don't\
    \ know what's going on. perhaps it doesnt use the custom tokenizer? \n\nTraceback\
    \ (most recent call last):\n  File \"/run/media/knut/HD/text-generation-webui/modules/callbacks.py\"\
    , line 56, in gentask\n    ret = self.mfunc(callback=_callback, *args, **self.kwargs)\n\
    \  File \"/run/media/knut/HD/text-generation-webui/modules/text_generation.py\"\
    , line 349, in generate_with_callback\n    shared.model.generate(**kwargs)\n \
    \ File \"/home/knut/miniconda3/envs/textgen/lib/python3.10/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/knut/miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/generation/utils.py\"\
    , line 1443, in generate\n    eos_token_id = eos_token_id[0]\nIndexError: list\
    \ index out of range\n"
  created_at: 2023-10-15 08:13:05+00:00
  edited: false
  hidden: false
  id: 652bad2168f1d7d1d279c372
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/61c37ed2861d6ab9f705e4629c85c4af.svg
      fullname: Zhang Xiaoyu
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: BBuf
      type: user
    createdAt: '2023-10-15T10:00:29.000Z'
    data:
      edited: false
      editors:
      - BBuf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5967227816581726
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/61c37ed2861d6ab9f705e4629c85c4af.svg
          fullname: Zhang Xiaoyu
          isHf: false
          isPro: false
          name: BBuf
          type: user
        html: "<p>It has been fixed now!</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/63647823a1503c61efd4fbcb/r6Kl-Tzpu0YlbBAiH2O9u.png\"\
          ><img alt=\"\u56FE\u7247.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/63647823a1503c61efd4fbcb/r6Kl-Tzpu0YlbBAiH2O9u.png\"\
          ></a></p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/63647823a1503c61efd4fbcb/2PF9vve7ZptyaA3LcP7SF.png\"\
          ><img alt=\"\u56FE\u7247.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/63647823a1503c61efd4fbcb/2PF9vve7ZptyaA3LcP7SF.png\"\
          ></a></p>\n"
        raw: "It has been fixed now!\n\n\n![\u56FE\u7247.png](https://cdn-uploads.huggingface.co/production/uploads/63647823a1503c61efd4fbcb/r6Kl-Tzpu0YlbBAiH2O9u.png)\n\
          \n\n![\u56FE\u7247.png](https://cdn-uploads.huggingface.co/production/uploads/63647823a1503c61efd4fbcb/2PF9vve7ZptyaA3LcP7SF.png)\n\
          \n"
        updatedAt: '2023-10-15T10:00:29.408Z'
      numEdits: 0
      reactions: []
    id: 652bb83d62a48851898ff95e
    type: comment
  author: BBuf
  content: "It has been fixed now!\n\n\n![\u56FE\u7247.png](https://cdn-uploads.huggingface.co/production/uploads/63647823a1503c61efd4fbcb/r6Kl-Tzpu0YlbBAiH2O9u.png)\n\
    \n\n![\u56FE\u7247.png](https://cdn-uploads.huggingface.co/production/uploads/63647823a1503c61efd4fbcb/2PF9vve7ZptyaA3LcP7SF.png)\n\
    \n"
  created_at: 2023-10-15 09:00:29+00:00
  edited: false
  hidden: false
  id: 652bb83d62a48851898ff95e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/61c37ed2861d6ab9f705e4629c85c4af.svg
      fullname: Zhang Xiaoyu
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: BBuf
      type: user
    createdAt: '2023-10-15T10:02:39.000Z'
    data:
      edited: false
      editors:
      - BBuf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9355856776237488
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/61c37ed2861d6ab9f705e4629c85c4af.svg
          fullname: Zhang Xiaoyu
          isHf: false
          isPro: false
          name: BBuf
          type: user
        html: '<p>For subsequent questions, please go directly to the RWKV community,
          my personal page will not upload newly developed and converted RWKV series
          models anymore.</p>

          '
        raw: For subsequent questions, please go directly to the RWKV community, my
          personal page will not upload newly developed and converted RWKV series
          models anymore.
        updatedAt: '2023-10-15T10:02:39.732Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - KnutJaegersberg
    id: 652bb8bf1aeebac333f146d0
    type: comment
  author: BBuf
  content: For subsequent questions, please go directly to the RWKV community, my
    personal page will not upload newly developed and converted RWKV series models
    anymore.
  created_at: 2023-10-15 09:02:39+00:00
  edited: false
  hidden: false
  id: 652bb8bf1aeebac333f146d0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-10-15T10:09:25.000Z'
    data:
      status: closed
    id: 652bba55789d84df6f1fadf0
    type: status-change
  author: KnutJaegersberg
  created_at: 2023-10-15 09:09:25+00:00
  id: 652bba55789d84df6f1fadf0
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: BBuf/RWKV-4-World-430M
repo_type: model
status: closed
target_branch: null
title: 'ValueError: Tokenizer class GPTNeoXTokenizer does not exist or is not currently
  imported.'
