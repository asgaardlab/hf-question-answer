!!python/object:huggingface_hub.community.DiscussionWithDetails
author: brianjking
conflicting_files: null
created_at: 2023-07-10 15:48:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0f4ee1c029ab2241dd9b24ae86fb31a.svg
      fullname: Brian King
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brianjking
      type: user
    createdAt: '2023-07-10T16:48:31.000Z'
    data:
      edited: false
      editors:
      - brianjking
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.43631434440612793
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0f4ee1c029ab2241dd9b24ae86fb31a.svg
          fullname: Brian King
          isHf: false
          isPro: false
          name: brianjking
          type: user
        html: '<p>Hello,</p>

          <p>I''d love to deploy this to the Huggingface Inference Endpoint, however,
          it''s missing the handler.py file.</p>

          <p>Does anyone have any tips? <a href="https://huggingface.co/docs/inference-endpoints/guides/custom_handler">https://huggingface.co/docs/inference-endpoints/guides/custom_handler</a></p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63a336328c0c89dcae356ce5/EG73JhFOBPthYwXgbIWQs.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/63a336328c0c89dcae356ce5/EG73JhFOBPthYwXgbIWQs.png"></a></p>

          <p>When I tried to deploy it I received this error:</p>

          <p>56f5d4ff8bqr6jr 2023-07-10T16:39:16.116Z INFO | Start loading image artifacts
          from huggingface.co<br>56f5d4ff8bqr6jr 2023-07-10T16:39:16.116Z INFO | Repository
          Revision: <a href="/Salesforce/instructblip-flan-t5-xl/commit/6c0cf6bef6330a114473cb5cec43d7beeb2a74ac">6c0cf6bef6330a114473cb5cec43d7beeb2a74ac</a><br>56f5d4ff8bqr6jr
          2023-07-10T16:39:16.116Z INFO | Used configuration:<br>56f5d4ff8bqr6jr 2023-07-10T16:39:16.116Z
          INFO | Repository ID: Salesforce/instructblip-flan-t5-xl<br>56f5d4ff8bqr6jr
          2023-07-10T16:39:16.116Z INFO | Ignore regex pattern for files, which are
          not downloaded: tf*, flax*, rust*, *onnx, *safetensors, *mlmodel, *tflite,
          *tar.gz, *ckpt<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.193Z 2023-07-10 16:42:45,192
          | INFO | Initializing model from directory:/repository<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:45.193Z 2023-07-10 16:42:45,193 | INFO | Using device GPU<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:45.193Z 2023-07-10 16:42:45,192 | INFO | No custom pipeline
          found at /repository/handler.py<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z
          return HuggingFaceHandler(model_dir=model_dir, task=task)<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:45.194Z await handler()<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z
          KeyError: ''instructblip''<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File
          "/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py",
          line 917, in from_pretrained<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z
          File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py", line
          654, in startup<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z self.pipeline
          = get_pipeline(model_dir=model_dir, task=task)<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z
          File "/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py",
          line 623, in <strong>getitem</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z
          File "/app/huggingface_inference_toolkit/handler.py", line 17, in <strong>init</strong><br>56f5d4ff8bqr6jr
          2023-07-10T16:42:45.194Z File "/app/webservice_starlette.py", line 57, in
          some_startup_task<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z config_class
          = CONFIG_MAPPING[config_dict["model_type"]]<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z
          raise KeyError(key)<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z config =
          AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs, **model_kwargs)<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:45.194Z<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z async
          with self.lifespan_context(app) as maybe_state:<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z
          File "/app/huggingface_inference_toolkit/utils.py", line 263, in get_pipeline<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:45.194Z File "/app/huggingface_inference_toolkit/handler.py",
          line 46, in get_inference_handler_either_custom_or_default_handler<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:45.194Z File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py",
          line 677, in lifespan<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z Application
          startup failed. Exiting.<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File
          "/opt/conda/lib/python3.9/site-packages/transformers/pipelines/<strong>init</strong>.py",
          line 692, in pipeline<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py",
          line 566, in <strong>aenter</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z
          hf_pipeline = pipeline(task=task, model=model_dir, device=device, **kwargs)<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:45.194Z inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,
          task=HF_TASK)<br>56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z await self._router.startup()<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:45.194Z Traceback (most recent call last):<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:48.903Z 2023-07-10 16:42:48,903 | INFO | Initializing model
          from directory:/repository<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.903Z 2023-07-10
          16:42:48,903 | INFO | No custom pipeline found at /repository/handler.py<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:48.903Z 2023-07-10 16:42:48,903 | INFO | Using device GPU<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:48.904Z raise KeyError(key)<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z
          self.pipeline = get_pipeline(model_dir=model_dir, task=task)<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:48.904Z await self._router.startup()<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:48.904Z hf_pipeline = pipeline(task=task, model=model_dir,
          device=device, **kwargs)<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File
          "/app/huggingface_inference_toolkit/utils.py", line 263, in get_pipeline<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:48.904Z File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py",
          line 677, in lifespan<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File "/app/huggingface_inference_toolkit/handler.py",
          line 17, in <strong>init</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z
          File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py", line
          566, in <strong>aenter</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z
          config = AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs,
          **model_kwargs)<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z KeyError: ''instructblip''<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:48.904Z File "/app/huggingface_inference_toolkit/handler.py",
          line 46, in get_inference_handler_either_custom_or_default_handler<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:48.904Z File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py",
          line 654, in startup<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File "/opt/conda/lib/python3.9/site-packages/transformers/pipelines/<strong>init</strong>.py",
          line 692, in pipeline<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z Traceback
          (most recent call last):<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z config_class
          = CONFIG_MAPPING[config_dict["model_type"]]<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z
          await handler()<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File "/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py",
          line 623, in <strong>getitem</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z
          File "/app/webservice_starlette.py", line 57, in some_startup_task<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:48.904Z inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,
          task=HF_TASK)<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z<br>56f5d4ff8bqr6jr
          2023-07-10T16:42:48.904Z return HuggingFaceHandler(model_dir=model_dir,
          task=task)<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z async with self.lifespan_context(app)
          as maybe_state:<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File "/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py",
          line 917, in from_pretrained<br>56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z
          Application startup failed. Exiting.<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.920Z
          2023-07-10 16:43:06,920 | INFO | Initializing model from directory:/repository<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:06.920Z 2023-07-10 16:43:06,920 | INFO | Using device GPU<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:06.920Z 2023-07-10 16:43:06,920 | INFO | No custom pipeline
          found at /repository/handler.py<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z
          Application startup failed. Exiting.<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z
          config_class = CONFIG_MAPPING[config_dict["model_type"]]<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:06.921Z<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File
          "/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py",
          line 917, in from_pretrained<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z
          async with self.lifespan_context(app) as maybe_state:<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:06.921Z config = AutoConfig.from_pretrained(model, _from_pipeline=task,
          **hub_kwargs, **model_kwargs)<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z
          Traceback (most recent call last):<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z
          File "/app/huggingface_inference_toolkit/handler.py", line 46, in get_inference_handler_either_custom_or_default_handler<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:06.921Z File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py",
          line 677, in lifespan<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z KeyError:
          ''instructblip''<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py",
          line 566, in <strong>aenter</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z
          await handler()<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File "/opt/conda/lib/python3.9/site-packages/transformers/pipelines/<strong>init</strong>.py",
          line 692, in pipeline<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z self.pipeline
          = get_pipeline(model_dir=model_dir, task=task)<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z
          return HuggingFaceHandler(model_dir=model_dir, task=task)<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:06.921Z File "/app/webservice_starlette.py", line 57, in
          some_startup_task<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py",
          line 654, in startup<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File "/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py",
          line 623, in <strong>getitem</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z
          File "/app/huggingface_inference_toolkit/utils.py", line 263, in get_pipeline<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:06.921Z File "/app/huggingface_inference_toolkit/handler.py",
          line 17, in <strong>init</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z
          inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,
          task=HF_TASK)<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z raise KeyError(key)<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:06.921Z hf_pipeline = pipeline(task=task, model=model_dir,
          device=device, **kwargs)<br>56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z await
          self._router.startup()<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.903Z 2023-07-10
          16:43:36,902 | INFO | Initializing model from directory:/repository<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:36.903Z 2023-07-10 16:43:36,903 | INFO | No custom pipeline
          found at /repository/handler.py<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.903Z
          2023-07-10 16:43:36,903 | INFO | Using device GPU<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:36.904Z File "/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py",
          line 623, in <strong>getitem</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z
          File "/app/huggingface_inference_toolkit/utils.py", line 263, in get_pipeline<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:36.904Z File "/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py",
          line 917, in from_pretrained<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z
          KeyError: ''instructblip''<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z self.pipeline
          = get_pipeline(model_dir=model_dir, task=task)<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z
          return HuggingFaceHandler(model_dir=model_dir, task=task)<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:36.904Z File "/app/webservice_starlette.py", line 57, in
          some_startup_task<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z hf_pipeline
          = pipeline(task=task, model=model_dir, device=device, **kwargs)<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:36.904Z File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py",
          line 566, in <strong>aenter</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z
          await self._router.startup()<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z
          File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py", line
          654, in startup<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z config_class
          = CONFIG_MAPPING[config_dict["model_type"]]<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z
          File "/opt/conda/lib/python3.9/site-packages/transformers/pipelines/<strong>init</strong>.py",
          line 692, in pipeline<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z config
          = AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs, **model_kwargs)<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:36.904Z File "/opt/conda/lib/python3.9/site-packages/starlette/routing.py",
          line 677, in lifespan<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z Application
          startup failed. Exiting.<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z raise
          KeyError(key)<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File "/app/huggingface_inference_toolkit/handler.py",
          line 17, in <strong>init</strong><br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z
          inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,
          task=HF_TASK)<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z async with self.lifespan_context(app)
          as maybe_state:<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File "/app/huggingface_inference_toolkit/handler.py",
          line 46, in get_inference_handler_either_custom_or_default_handler<br>56f5d4ff8bqr6jr
          2023-07-10T16:43:36.904Z await handler()<br>56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z
          Traceback (most recent call last):</p>

          '
        raw: "Hello,\r\n\r\nI'd love to deploy this to the Huggingface Inference Endpoint,\
          \ however, it's missing the handler.py file.\r\n\r\nDoes anyone have any\
          \ tips? https://huggingface.co/docs/inference-endpoints/guides/custom_handler\r\
          \n\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63a336328c0c89dcae356ce5/EG73JhFOBPthYwXgbIWQs.png)\r\
          \n\r\n\r\nWhen I tried to deploy it I received this error:\r\n\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:39:16.116Z INFO | Start loading image artifacts from huggingface.co\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:39:16.116Z INFO | Repository Revision: 6c0cf6bef6330a114473cb5cec43d7beeb2a74ac\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:39:16.116Z INFO | Used configuration:\r\n\
          56f5d4ff8bqr6jr 2023-07-10T16:39:16.116Z INFO | Repository ID: Salesforce/instructblip-flan-t5-xl\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:39:16.116Z INFO | Ignore regex pattern for\
          \ files, which are not downloaded: tf*, flax*, rust*, *onnx, *safetensors,\
          \ *mlmodel, *tflite, *tar.gz, *ckpt\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.193Z\
          \ 2023-07-10 16:42:45,192 | INFO | Initializing model from directory:/repository\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.193Z 2023-07-10 16:42:45,193 | INFO\
          \ | Using device GPU\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.193Z 2023-07-10\
          \ 16:42:45,192 | INFO | No custom pipeline found at /repository/handler.py\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z return HuggingFaceHandler(model_dir=model_dir,\
          \ task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z await handler()\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z KeyError: 'instructblip'\r\n\
          56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 917, in from_pretrained\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z\
          \ File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\",\
          \ line 654, in startup\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z self.pipeline\
          \ = get_pipeline(model_dir=model_dir, task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z\
          \ File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 623, in __getitem__\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File\
          \ \"/app/huggingface_inference_toolkit/handler.py\", line 17, in __init__\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"/app/webservice_starlette.py\"\
          , line 57, in some_startup_task\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z\
          \ config_class = CONFIG_MAPPING[config_dict[\"model_type\"]]\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:42:45.194Z raise KeyError(key)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z\
          \ config = AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs,\
          \ **model_kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:42:45.194Z async with self.lifespan_context(app) as maybe_state:\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"/app/huggingface_inference_toolkit/utils.py\"\
          , line 263, in get_pipeline\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z\
          \ File \"/app/huggingface_inference_toolkit/handler.py\", line 46, in get_inference_handler_either_custom_or_default_handler\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 677, in lifespan\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z Application\
          \ startup failed. Exiting.\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File\
          \ \"/opt/conda/lib/python3.9/site-packages/transformers/pipelines/__init__.py\"\
          , line 692, in pipeline\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File\
          \ \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line\
          \ 566, in __aenter__\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z hf_pipeline\
          \ = pipeline(task=task, model=model_dir, device=device, **kwargs)\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:42:45.194Z inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z await self._router.startup()\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z Traceback (most recent call last):\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.903Z 2023-07-10 16:42:48,903 | INFO\
          \ | Initializing model from directory:/repository\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.903Z\
          \ 2023-07-10 16:42:48,903 | INFO | No custom pipeline found at /repository/handler.py\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.903Z 2023-07-10 16:42:48,903 | INFO\
          \ | Using device GPU\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z raise KeyError(key)\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z self.pipeline = get_pipeline(model_dir=model_dir,\
          \ task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z await self._router.startup()\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z hf_pipeline = pipeline(task=task,\
          \ model=model_dir, device=device, **kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z\
          \ File \"/app/huggingface_inference_toolkit/utils.py\", line 263, in get_pipeline\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 677, in lifespan\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File\
          \ \"/app/huggingface_inference_toolkit/handler.py\", line 17, in __init__\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 566, in __aenter__\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z config\
          \ = AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs,\
          \ **model_kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z KeyError:\
          \ 'instructblip'\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 46, in get_inference_handler_either_custom_or_default_handler\r\n\
          56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 654, in startup\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File\
          \ \"/opt/conda/lib/python3.9/site-packages/transformers/pipelines/__init__.py\"\
          , line 692, in pipeline\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z Traceback\
          \ (most recent call last):\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z config_class\
          \ = CONFIG_MAPPING[config_dict[\"model_type\"]]\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z\
          \ await handler()\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 623, in __getitem__\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File\
          \ \"/app/webservice_starlette.py\", line 57, in some_startup_task\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:42:48.904Z inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:42:48.904Z return HuggingFaceHandler(model_dir=model_dir,\
          \ task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z async with self.lifespan_context(app)\
          \ as maybe_state:\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 917, in from_pretrained\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z\
          \ Application startup failed. Exiting.\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.920Z\
          \ 2023-07-10 16:43:06,920 | INFO | Initializing model from directory:/repository\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:43:06.920Z 2023-07-10 16:43:06,920 | INFO\
          \ | Using device GPU\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.920Z 2023-07-10\
          \ 16:43:06,920 | INFO | No custom pipeline found at /repository/handler.py\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z Application startup failed. Exiting.\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z config_class = CONFIG_MAPPING[config_dict[\"\
          model_type\"]]\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:43:06.921Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 917, in from_pretrained\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z\
          \ async with self.lifespan_context(app) as maybe_state:\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:43:06.921Z config = AutoConfig.from_pretrained(model, _from_pipeline=task,\
          \ **hub_kwargs, **model_kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z\
          \ Traceback (most recent call last):\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z\
          \ File \"/app/huggingface_inference_toolkit/handler.py\", line 46, in get_inference_handler_either_custom_or_default_handler\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 677, in lifespan\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z KeyError:\
          \ 'instructblip'\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 566, in __aenter__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z await\
          \ handler()\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"/opt/conda/lib/python3.9/site-packages/transformers/pipelines/__init__.py\"\
          , line 692, in pipeline\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z self.pipeline\
          \ = get_pipeline(model_dir=model_dir, task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z\
          \ return HuggingFaceHandler(model_dir=model_dir, task=task)\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:43:06.921Z File \"/app/webservice_starlette.py\", line 57,\
          \ in some_startup_task\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File\
          \ \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line\
          \ 654, in startup\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 623, in __getitem__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File\
          \ \"/app/huggingface_inference_toolkit/utils.py\", line 263, in get_pipeline\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 17, in __init__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z inference_handler\
          \ = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z raise KeyError(key)\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z hf_pipeline = pipeline(task=task,\
          \ model=model_dir, device=device, **kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z\
          \ await self._router.startup()\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.903Z\
          \ 2023-07-10 16:43:36,902 | INFO | Initializing model from directory:/repository\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:43:36.903Z 2023-07-10 16:43:36,903 | INFO\
          \ | No custom pipeline found at /repository/handler.py\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:43:36.903Z 2023-07-10 16:43:36,903 | INFO | Using device\
          \ GPU\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z\
          \ File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 623, in __getitem__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File\
          \ \"/app/huggingface_inference_toolkit/utils.py\", line 263, in get_pipeline\r\
          \n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 917, in from_pretrained\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z\
          \ KeyError: 'instructblip'\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z self.pipeline\
          \ = get_pipeline(model_dir=model_dir, task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z\
          \ return HuggingFaceHandler(model_dir=model_dir, task=task)\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:43:36.904Z File \"/app/webservice_starlette.py\", line 57,\
          \ in some_startup_task\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z hf_pipeline\
          \ = pipeline(task=task, model=model_dir, device=device, **kwargs)\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:43:36.904Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 566, in __aenter__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z await\
          \ self._router.startup()\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File\
          \ \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line\
          \ 654, in startup\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z config_class\
          \ = CONFIG_MAPPING[config_dict[\"model_type\"]]\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z\
          \ File \"/opt/conda/lib/python3.9/site-packages/transformers/pipelines/__init__.py\"\
          , line 692, in pipeline\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z config\
          \ = AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs,\
          \ **model_kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
          , line 677, in lifespan\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z Application\
          \ startup failed. Exiting.\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z raise\
          \ KeyError(key)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 17, in __init__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z inference_handler\
          \ = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
          \ task=HF_TASK)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z async with self.lifespan_context(app)\
          \ as maybe_state:\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File \"/app/huggingface_inference_toolkit/handler.py\"\
          , line 46, in get_inference_handler_either_custom_or_default_handler\r\n\
          56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z await handler()\r\n56f5d4ff8bqr6jr\
          \ 2023-07-10T16:43:36.904Z Traceback (most recent call last):"
        updatedAt: '2023-07-10T16:48:31.184Z'
      numEdits: 0
      reactions: []
    id: 64ac365f264bbbf1719496f2
    type: comment
  author: brianjking
  content: "Hello,\r\n\r\nI'd love to deploy this to the Huggingface Inference Endpoint,\
    \ however, it's missing the handler.py file.\r\n\r\nDoes anyone have any tips?\
    \ https://huggingface.co/docs/inference-endpoints/guides/custom_handler\r\n\r\n\
    \r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63a336328c0c89dcae356ce5/EG73JhFOBPthYwXgbIWQs.png)\r\
    \n\r\n\r\nWhen I tried to deploy it I received this error:\r\n\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:39:16.116Z INFO | Start loading image artifacts from huggingface.co\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:39:16.116Z INFO | Repository Revision: 6c0cf6bef6330a114473cb5cec43d7beeb2a74ac\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:39:16.116Z INFO | Used configuration:\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:39:16.116Z INFO | Repository ID: Salesforce/instructblip-flan-t5-xl\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:39:16.116Z INFO | Ignore regex pattern for files,\
    \ which are not downloaded: tf*, flax*, rust*, *onnx, *safetensors, *mlmodel,\
    \ *tflite, *tar.gz, *ckpt\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.193Z 2023-07-10\
    \ 16:42:45,192 | INFO | Initializing model from directory:/repository\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:42:45.193Z 2023-07-10 16:42:45,193 | INFO | Using device GPU\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.193Z 2023-07-10 16:42:45,192 | INFO | No\
    \ custom pipeline found at /repository/handler.py\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z\
    \ return HuggingFaceHandler(model_dir=model_dir, task=task)\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:42:45.194Z await handler()\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z\
    \ KeyError: 'instructblip'\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"\
    /opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 917, in from_pretrained\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File\
    \ \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line 654, in\
    \ startup\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z self.pipeline = get_pipeline(model_dir=model_dir,\
    \ task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 623, in __getitem__\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"\
    /app/huggingface_inference_toolkit/handler.py\", line 17, in __init__\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:42:45.194Z File \"/app/webservice_starlette.py\", line 57, in\
    \ some_startup_task\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z config_class =\
    \ CONFIG_MAPPING[config_dict[\"model_type\"]]\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z\
    \ raise KeyError(key)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z config = AutoConfig.from_pretrained(model,\
    \ _from_pipeline=task, **hub_kwargs, **model_kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z async with self.lifespan_context(app)\
    \ as maybe_state:\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"/app/huggingface_inference_toolkit/utils.py\"\
    , line 263, in get_pipeline\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"\
    /app/huggingface_inference_toolkit/handler.py\", line 46, in get_inference_handler_either_custom_or_default_handler\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 677, in lifespan\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z Application\
    \ startup failed. Exiting.\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"\
    /opt/conda/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line\
    \ 692, in pipeline\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 566, in __aenter__\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z hf_pipeline\
    \ = pipeline(task=task, model=model_dir, device=device, **kwargs)\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:42:45.194Z inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
    \ task=HF_TASK)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z await self._router.startup()\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:42:45.194Z Traceback (most recent call last):\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.903Z 2023-07-10 16:42:48,903 | INFO | Initializing\
    \ model from directory:/repository\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.903Z\
    \ 2023-07-10 16:42:48,903 | INFO | No custom pipeline found at /repository/handler.py\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.903Z 2023-07-10 16:42:48,903 | INFO | Using\
    \ device GPU\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z raise KeyError(key)\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z self.pipeline = get_pipeline(model_dir=model_dir,\
    \ task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z await self._router.startup()\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z hf_pipeline = pipeline(task=task, model=model_dir,\
    \ device=device, **kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"\
    /app/huggingface_inference_toolkit/utils.py\", line 263, in get_pipeline\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 677, in lifespan\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 17, in __init__\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 566, in __aenter__\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z config =\
    \ AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs, **model_kwargs)\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z KeyError: 'instructblip'\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:42:48.904Z File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 46, in get_inference_handler_either_custom_or_default_handler\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 654, in startup\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/transformers/pipelines/__init__.py\"\
    , line 692, in pipeline\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z Traceback\
    \ (most recent call last):\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z config_class\
    \ = CONFIG_MAPPING[config_dict[\"model_type\"]]\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z\
    \ await handler()\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 623, in __getitem__\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"\
    /app/webservice_starlette.py\", line 57, in some_startup_task\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:42:48.904Z inference_handler = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR,\
    \ task=HF_TASK)\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:42:48.904Z return HuggingFaceHandler(model_dir=model_dir, task=task)\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z async with self.lifespan_context(app)\
    \ as maybe_state:\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 917, in from_pretrained\r\n56f5d4ff8bqr6jr 2023-07-10T16:42:48.904Z Application\
    \ startup failed. Exiting.\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.920Z 2023-07-10\
    \ 16:43:06,920 | INFO | Initializing model from directory:/repository\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:43:06.920Z 2023-07-10 16:43:06,920 | INFO | Using device GPU\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:43:06.920Z 2023-07-10 16:43:06,920 | INFO | No\
    \ custom pipeline found at /repository/handler.py\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z\
    \ Application startup failed. Exiting.\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z\
    \ config_class = CONFIG_MAPPING[config_dict[\"model_type\"]]\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:43:06.921Z\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"\
    /opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 917, in from_pretrained\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z async\
    \ with self.lifespan_context(app) as maybe_state:\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z\
    \ config = AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs,\
    \ **model_kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z Traceback (most\
    \ recent call last):\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 46, in get_inference_handler_either_custom_or_default_handler\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:43:06.921Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 677, in lifespan\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z KeyError:\
    \ 'instructblip'\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 566, in __aenter__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z await handler()\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"/opt/conda/lib/python3.9/site-packages/transformers/pipelines/__init__.py\"\
    , line 692, in pipeline\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z self.pipeline\
    \ = get_pipeline(model_dir=model_dir, task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z\
    \ return HuggingFaceHandler(model_dir=model_dir, task=task)\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:43:06.921Z File \"/app/webservice_starlette.py\", line 57, in\
    \ some_startup_task\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 654, in startup\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 623, in __getitem__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z File \"\
    /app/huggingface_inference_toolkit/utils.py\", line 263, in get_pipeline\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:43:06.921Z File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 17, in __init__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z inference_handler\
    \ = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR, task=HF_TASK)\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z raise KeyError(key)\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:43:06.921Z hf_pipeline = pipeline(task=task, model=model_dir,\
    \ device=device, **kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:06.921Z await self._router.startup()\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:43:36.903Z 2023-07-10 16:43:36,902 | INFO | Initializing\
    \ model from directory:/repository\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.903Z\
    \ 2023-07-10 16:43:36,903 | INFO | No custom pipeline found at /repository/handler.py\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:43:36.903Z 2023-07-10 16:43:36,903 | INFO | Using\
    \ device GPU\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z\
    \ File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 623, in __getitem__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File \"\
    /app/huggingface_inference_toolkit/utils.py\", line 263, in get_pipeline\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:43:36.904Z File \"/opt/conda/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 917, in from_pretrained\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z KeyError:\
    \ 'instructblip'\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z self.pipeline = get_pipeline(model_dir=model_dir,\
    \ task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z return HuggingFaceHandler(model_dir=model_dir,\
    \ task=task)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File \"/app/webservice_starlette.py\"\
    , line 57, in some_startup_task\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z hf_pipeline\
    \ = pipeline(task=task, model=model_dir, device=device, **kwargs)\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:43:36.904Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 566, in __aenter__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z await self._router.startup()\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\"\
    , line 654, in startup\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z config_class\
    \ = CONFIG_MAPPING[config_dict[\"model_type\"]]\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z\
    \ File \"/opt/conda/lib/python3.9/site-packages/transformers/pipelines/__init__.py\"\
    , line 692, in pipeline\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z config = AutoConfig.from_pretrained(model,\
    \ _from_pipeline=task, **hub_kwargs, **model_kwargs)\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z\
    \ File \"/opt/conda/lib/python3.9/site-packages/starlette/routing.py\", line 677,\
    \ in lifespan\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z Application startup\
    \ failed. Exiting.\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z raise KeyError(key)\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 17, in __init__\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z inference_handler\
    \ = get_inference_handler_either_custom_or_default_handler(HF_MODEL_DIR, task=HF_TASK)\r\
    \n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z async with self.lifespan_context(app)\
    \ as maybe_state:\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z File \"/app/huggingface_inference_toolkit/handler.py\"\
    , line 46, in get_inference_handler_either_custom_or_default_handler\r\n56f5d4ff8bqr6jr\
    \ 2023-07-10T16:43:36.904Z await handler()\r\n56f5d4ff8bqr6jr 2023-07-10T16:43:36.904Z\
    \ Traceback (most recent call last):"
  created_at: 2023-07-10 15:48:31+00:00
  edited: false
  hidden: false
  id: 64ac365f264bbbf1719496f2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/e0f4ee1c029ab2241dd9b24ae86fb31a.svg
      fullname: Brian King
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brianjking
      type: user
    createdAt: '2023-07-10T16:48:44.000Z'
    data:
      from: How to Deploy on Inference Endpoints
      to: How to Deploy on Inference Endpoints - handler.py
    id: 64ac366c0078182535d47f2c
    type: title-change
  author: brianjking
  created_at: 2023-07-10 15:48:44+00:00
  id: 64ac366c0078182535d47f2c
  new_title: How to Deploy on Inference Endpoints - handler.py
  old_title: How to Deploy on Inference Endpoints
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2023-07-10T18:21:23.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9019761085510254
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Hi,</p>

          <p>Have you implemented a handler script as explained in the guide above?
          If so, could you share this script?</p>

          '
        raw: 'Hi,


          Have you implemented a handler script as explained in the guide above? If
          so, could you share this script?'
        updatedAt: '2023-07-10T18:21:23.835Z'
      numEdits: 0
      reactions: []
    id: 64ac4c23eb8265083e69d97d
    type: comment
  author: nielsr
  content: 'Hi,


    Have you implemented a handler script as explained in the guide above? If so,
    could you share this script?'
  created_at: 2023-07-10 17:21:23+00:00
  edited: false
  hidden: false
  id: 64ac4c23eb8265083e69d97d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0f4ee1c029ab2241dd9b24ae86fb31a.svg
      fullname: Brian King
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brianjking
      type: user
    createdAt: '2023-07-10T18:49:18.000Z'
    data:
      edited: false
      editors:
      - brianjking
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7677814364433289
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0f4ee1c029ab2241dd9b24ae86fb31a.svg
          fullname: Brian King
          isHf: false
          isPro: false
          name: brianjking
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;nielsr&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/nielsr\">@<span class=\"\
          underline\">nielsr</span></a></span>\n\n\t</span></span> I tried to submit\
          \ a PR, I have no idea if this works or not <a href=\"https://huggingface.co/Salesforce/instructblip-flan-t5-xl/discussions/5\"\
          >https://huggingface.co/Salesforce/instructblip-flan-t5-xl/discussions/5</a>.</p>\n\
          <p>Any help? Thanks!</p>\n"
        raw: '@nielsr I tried to submit a PR, I have no idea if this works or not
          https://huggingface.co/Salesforce/instructblip-flan-t5-xl/discussions/5.


          Any help? Thanks!'
        updatedAt: '2023-07-10T18:49:18.042Z'
      numEdits: 0
      reactions: []
    id: 64ac52ae5b181f6cca8f6e98
    type: comment
  author: brianjking
  content: '@nielsr I tried to submit a PR, I have no idea if this works or not https://huggingface.co/Salesforce/instructblip-flan-t5-xl/discussions/5.


    Any help? Thanks!'
  created_at: 2023-07-10 17:49:18+00:00
  edited: false
  hidden: false
  id: 64ac52ae5b181f6cca8f6e98
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Salesforce/instructblip-flan-t5-xl
repo_type: model
status: open
target_branch: null
title: How to Deploy on Inference Endpoints - handler.py
