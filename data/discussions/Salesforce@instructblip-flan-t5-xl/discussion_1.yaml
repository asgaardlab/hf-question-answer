!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Marcushenriksboe
conflicting_files: null
created_at: 2023-05-31 15:27:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e9285de27cd7839dba6aaecb316002c7.svg
      fullname: Marcus Henriksboe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Marcushenriksboe
      type: user
    createdAt: '2023-05-31T16:27:28.000Z'
    data:
      edited: false
      editors:
      - Marcushenriksboe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e9285de27cd7839dba6aaecb316002c7.svg
          fullname: Marcus Henriksboe
          isHf: false
          isPro: false
          name: Marcushenriksboe
          type: user
        html: '<p>Hi, I''m really keen on trying out instructblip here before its
          merged into huggingface. Tried installing transformers from the branch repo
          but getting "cannot import name ''InstructBlipProcessor'' from ''transformers".
          Wondering if anyone has a quickfix for trying out the branch.</p>

          '
        raw: Hi, I'm really keen on trying out instructblip here before its merged
          into huggingface. Tried installing transformers from the branch repo but
          getting "cannot import name 'InstructBlipProcessor' from 'transformers".
          Wondering if anyone has a quickfix for trying out the branch.
        updatedAt: '2023-05-31T16:27:28.615Z'
      numEdits: 0
      reactions: []
    id: 64777570168cb428e00ea746
    type: comment
  author: Marcushenriksboe
  content: Hi, I'm really keen on trying out instructblip here before its merged into
    huggingface. Tried installing transformers from the branch repo but getting "cannot
    import name 'InstructBlipProcessor' from 'transformers". Wondering if anyone has
    a quickfix for trying out the branch.
  created_at: 2023-05-31 15:27:28+00:00
  edited: false
  hidden: false
  id: 64777570168cb428e00ea746
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2023-05-31T19:58:39.000Z'
    data:
      edited: true
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: "<p>Hi,</p>\n<p>Basically you can try it out by doing pip install --upgrade\
          \ git+<a rel=\"nofollow\" href=\"https://github.com/NielsRogge/transformers.git@add_instruct_blip\"\
          >https://github.com/NielsRogge/transformers.git@add_instruct_blip</a></p>\n\
          <p>and then do:</p>\n<pre><code>from transformers import InstructBlipProcessor,\
          \ InstructBlipForConditionalGeneration\nimport torch\nfrom PIL import Image\n\
          import requests\n\nmodel = InstructBlipForConditionalGeneration.from_pretrained(\"\
          nielsr/instructblip-flan-t5-xl\")\nprocessor = InstructBlipProcessor.from_pretrained(\"\
          nielsr/instructblip-flan-t5-xl\")\n\ndevice = \"cuda\" if torch.cuda.is_available()\
          \ else \"cpu\"\nmodel.to(device)\n\nurl = \"https://raw.githubusercontent.com/salesforce/LAVIS/main/docs/_static/Confusing-Pictures.jpg\"\
          \nimage = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\"\
          )\nprompt = \"What is unusual about this image?\"\ninputs = processor(images=image,\
          \ text=prompt, return_tensors=\"pt\")\n\noutputs = model.generate(\n   \
          \     **inputs,\n        do_sample=False,\n        num_beams=5,\n      \
          \  max_length=256,\n        min_length=1,\n        top_p=0.9,\n        repetition_penalty=1.5,\n\
          \        length_penalty=1.0,\n        temperature=1,\n)\ngenerated_text\
          \ = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n\
          print(generated_text)\n</code></pre>\n"
        raw: "Hi,\n\nBasically you can try it out by doing pip install --upgrade git+https://github.com/NielsRogge/transformers.git@add_instruct_blip\n\
          \nand then do:\n\n```\nfrom transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n\
          import torch\nfrom PIL import Image\nimport requests\n\nmodel = InstructBlipForConditionalGeneration.from_pretrained(\"\
          nielsr/instructblip-flan-t5-xl\")\nprocessor = InstructBlipProcessor.from_pretrained(\"\
          nielsr/instructblip-flan-t5-xl\")\n\ndevice = \"cuda\" if torch.cuda.is_available()\
          \ else \"cpu\"\nmodel.to(device)\n\nurl = \"https://raw.githubusercontent.com/salesforce/LAVIS/main/docs/_static/Confusing-Pictures.jpg\"\
          \nimage = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\"\
          )\nprompt = \"What is unusual about this image?\"\ninputs = processor(images=image,\
          \ text=prompt, return_tensors=\"pt\")\n\noutputs = model.generate(\n   \
          \     **inputs,\n        do_sample=False,\n        num_beams=5,\n      \
          \  max_length=256,\n        min_length=1,\n        top_p=0.9,\n        repetition_penalty=1.5,\n\
          \        length_penalty=1.0,\n        temperature=1,\n)\ngenerated_text\
          \ = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n\
          print(generated_text)\n```"
        updatedAt: '2023-06-04T19:48:20.060Z'
      numEdits: 1
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - pluk
        - nolestock
        - YYChen
    id: 6477a6efbb7681ad670ca053
    type: comment
  author: nielsr
  content: "Hi,\n\nBasically you can try it out by doing pip install --upgrade git+https://github.com/NielsRogge/transformers.git@add_instruct_blip\n\
    \nand then do:\n\n```\nfrom transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n\
    import torch\nfrom PIL import Image\nimport requests\n\nmodel = InstructBlipForConditionalGeneration.from_pretrained(\"\
    nielsr/instructblip-flan-t5-xl\")\nprocessor = InstructBlipProcessor.from_pretrained(\"\
    nielsr/instructblip-flan-t5-xl\")\n\ndevice = \"cuda\" if torch.cuda.is_available()\
    \ else \"cpu\"\nmodel.to(device)\n\nurl = \"https://raw.githubusercontent.com/salesforce/LAVIS/main/docs/_static/Confusing-Pictures.jpg\"\
    \nimage = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\nprompt\
    \ = \"What is unusual about this image?\"\ninputs = processor(images=image, text=prompt,\
    \ return_tensors=\"pt\")\n\noutputs = model.generate(\n        **inputs,\n   \
    \     do_sample=False,\n        num_beams=5,\n        max_length=256,\n      \
    \  min_length=1,\n        top_p=0.9,\n        repetition_penalty=1.5,\n      \
    \  length_penalty=1.0,\n        temperature=1,\n)\ngenerated_text = processor.batch_decode(outputs,\
    \ skip_special_tokens=True)[0].strip()\nprint(generated_text)\n```"
  created_at: 2023-05-31 18:58:39+00:00
  edited: true
  hidden: false
  id: 6477a6efbb7681ad670ca053
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a8c6906a15cd27179c858041227b8460.svg
      fullname: Yangyi Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YYChen
      type: user
    createdAt: '2023-06-14T15:53:27.000Z'
    data:
      edited: false
      editors:
      - YYChen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8891422152519226
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a8c6906a15cd27179c858041227b8460.svg
          fullname: Yangyi Chen
          isHf: false
          isPro: false
          name: YYChen
          type: user
        html: '<p>Hi,<br>I run this code and get the warning:  Some weights of the
          model checkpoint were not used when initializing Blip2ForConditionalGeneration,
          and it lists some parameters in QFormer. </p>

          <p>Is this normal? thanks! </p>

          '
        raw: "Hi, \nI run this code and get the warning:  Some weights of the model\
          \ checkpoint were not used when initializing Blip2ForConditionalGeneration,\
          \ and it lists some parameters in QFormer. \n\nIs this normal? thanks! "
        updatedAt: '2023-06-14T15:53:27.405Z'
      numEdits: 0
      reactions: []
    id: 6489e277af0917a72d173344
    type: comment
  author: YYChen
  content: "Hi, \nI run this code and get the warning:  Some weights of the model\
    \ checkpoint were not used when initializing Blip2ForConditionalGeneration, and\
    \ it lists some parameters in QFormer. \n\nIs this normal? thanks! "
  created_at: 2023-06-14 14:53:27+00:00
  edited: false
  hidden: false
  id: 6489e277af0917a72d173344
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/030705b5db36079851ef6809b4808315.svg
      fullname: Advaith Malladi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: advaith20
      type: user
    createdAt: '2023-06-16T05:31:05.000Z'
    data:
      edited: false
      editors:
      - advaith20
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7725376486778259
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/030705b5db36079851ef6809b4808315.svg
          fullname: Advaith Malladi
          isHf: false
          isPro: false
          name: advaith20
          type: user
        html: '<p>Hey, </p>

          <p>Even after doing  doing pip install --upgrade git+<a rel="nofollow" href="https://github.com/NielsRogge/transformers.git@add_instruct_blip">https://github.com/NielsRogge/transformers.git@add_instruct_blip</a>
          and running "from transformers import InstructBlipProcessor" I''m still
          getting cannot import name ''InstructBlipProcessor'' from ''transformers".
          How do I fix it?</p>

          '
        raw: "Hey, \n\nEven after doing  doing pip install --upgrade git+https://github.com/NielsRogge/transformers.git@add_instruct_blip\
          \ and running \"from transformers import InstructBlipProcessor\" I'm still\
          \ getting cannot import name 'InstructBlipProcessor' from 'transformers\"\
          . How do I fix it?\n"
        updatedAt: '2023-06-16T05:31:05.632Z'
      numEdits: 0
      reactions: []
    id: 648bf399f11318e0a448b9ae
    type: comment
  author: advaith20
  content: "Hey, \n\nEven after doing  doing pip install --upgrade git+https://github.com/NielsRogge/transformers.git@add_instruct_blip\
    \ and running \"from transformers import InstructBlipProcessor\" I'm still getting\
    \ cannot import name 'InstructBlipProcessor' from 'transformers\". How do I fix\
    \ it?\n"
  created_at: 2023-06-16 04:31:05+00:00
  edited: false
  hidden: false
  id: 648bf399f11318e0a448b9ae
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Salesforce/instructblip-flan-t5-xl
repo_type: model
status: open
target_branch: null
title: How to use instructblip before PR is merged
