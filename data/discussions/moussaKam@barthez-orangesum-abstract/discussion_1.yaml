!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Divyashie
conflicting_files: null
created_at: 2023-01-10 13:47:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c5b2c4b3c69459376c041061101a066b.svg
      fullname: Soopal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Divyashie
      type: user
    createdAt: '2023-01-10T13:47:21.000Z'
    data:
      edited: false
      editors:
      - Divyashie
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c5b2c4b3c69459376c041061101a066b.svg
          fullname: Soopal
          isHf: false
          isPro: false
          name: Divyashie
          type: user
        html: '<p>Hi, </p>

          <p>I tried using this model but it ran fine on just the provided <code>text_sentence</code>
          but when I used mine even though I truncate the text to 1024 length. It
          is giving me this error: </p>

          <p>  File "/Users/divyasoopal/Desktop/demo-live-transcription/summarizer.py",
          line 282, in barthezSummarizer<br>    predict = barthez_model.generate(input_ids,
          max_length=100)[0]<br>  File "/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/autograd/grad_mode.py",
          line 27, in decorate_context<br>    return func(*args, **kwargs)<br>  File
          "/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/generation/utils.py",
          line 1213, in generate<br>    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(<br>  File
          "/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/generation/utils.py",
          line 610, in _prepare_encoder_decoder_kwargs_for_generation<br>    model_kwargs["encoder_outputs"]:
          ModelOutput = encoder(**encoder_kwargs)<br>  File "/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/modules/module.py",
          line 1194, in _call_impl<br>    return forward_call(*input, **kwargs)<br>  File
          "/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py",
          line 806, in forward<br>    embed_pos = self.embed_positions(input)<br>  File
          "/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/modules/module.py",
          line 1194, in _call_impl<br>    return forward_call(*input, **kwargs)<br>  File
          "/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py",
          line 145, in forward<br>    return super().forward(positions + self.offset)<br>  File
          "/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py",
          line 160, in forward<br>    return F.embedding(<br>  File "/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/functional.py",
          line 2210, in embedding<br>    return torch.embedding(weight, input, padding_idx,
          scale_grad_by_freq, sparse)<br>IndexError: index out of range in self</p>

          <p>Any idea what I might be doing wrong here. Also, when I tried computing
          it on the interface here I get the error "unknown". Any leads on this is
          much appreciated. Thanks </p>

          '
        raw: "Hi, \r\n\r\nI tried using this model but it ran fine on just the provided\
          \ `text_sentence` but when I used mine even though I truncate the text to\
          \ 1024 length. It is giving me this error: \r\n\r\n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/summarizer.py\"\
          , line 282, in barthezSummarizer\r\n    predict = barthez_model.generate(input_ids,\
          \ max_length=100)[0]\r\n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n \
          \ File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/generation/utils.py\"\
          , line 1213, in generate\r\n    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\r\
          \n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/generation/utils.py\"\
          , line 610, in _prepare_encoder_decoder_kwargs_for_generation\r\n    model_kwargs[\"\
          encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)\r\n  File \"\
          /Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1194, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py\"\
          , line 806, in forward\r\n    embed_pos = self.embed_positions(input)\r\n\
          \  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1194, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py\"\
          , line 145, in forward\r\n    return super().forward(positions + self.offset)\r\
          \n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py\"\
          , line 160, in forward\r\n    return F.embedding(\r\n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/functional.py\"\
          , line 2210, in embedding\r\n    return torch.embedding(weight, input, padding_idx,\
          \ scale_grad_by_freq, sparse)\r\nIndexError: index out of range in self\r\
          \n\r\nAny idea what I might be doing wrong here. Also, when I tried computing\
          \ it on the interface here I get the error \"unknown\". Any leads on this\
          \ is much appreciated. Thanks "
        updatedAt: '2023-01-10T13:47:21.389Z'
      numEdits: 0
      reactions: []
    id: 63bd6c693b0665ad51c80ba6
    type: comment
  author: Divyashie
  content: "Hi, \r\n\r\nI tried using this model but it ran fine on just the provided\
    \ `text_sentence` but when I used mine even though I truncate the text to 1024\
    \ length. It is giving me this error: \r\n\r\n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/summarizer.py\"\
    , line 282, in barthezSummarizer\r\n    predict = barthez_model.generate(input_ids,\
    \ max_length=100)[0]\r\n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/autograd/grad_mode.py\"\
    , line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"\
    /Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/generation/utils.py\"\
    , line 1213, in generate\r\n    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\r\
    \n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/generation/utils.py\"\
    , line 610, in _prepare_encoder_decoder_kwargs_for_generation\r\n    model_kwargs[\"\
    encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)\r\n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1194, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py\"\
    , line 806, in forward\r\n    embed_pos = self.embed_positions(input)\r\n  File\
    \ \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1194, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py\"\
    , line 145, in forward\r\n    return super().forward(positions + self.offset)\r\
    \n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py\"\
    , line 160, in forward\r\n    return F.embedding(\r\n  File \"/Users/divyasoopal/Desktop/demo-live-transcription/venv/lib/python3.9/site-packages/torch/nn/functional.py\"\
    , line 2210, in embedding\r\n    return torch.embedding(weight, input, padding_idx,\
    \ scale_grad_by_freq, sparse)\r\nIndexError: index out of range in self\r\n\r\n\
    Any idea what I might be doing wrong here. Also, when I tried computing it on\
    \ the interface here I get the error \"unknown\". Any leads on this is much appreciated.\
    \ Thanks "
  created_at: 2023-01-10 13:47:21+00:00
  edited: false
  hidden: false
  id: 63bd6c693b0665ad51c80ba6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: moussaKam/barthez-orangesum-abstract
repo_type: model
status: open
target_branch: null
title: 'Issue: Index out of range '
