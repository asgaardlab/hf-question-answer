!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rpeinl
conflicting_files: null
created_at: 2023-09-07 11:06:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/efe0eabd99455ada4da1ff729f632c83.svg
      fullname: "Ren\xE9 Peinl"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rpeinl
      type: user
    createdAt: '2023-09-07T12:06:06.000Z'
    data:
      edited: true
      editors:
      - rpeinl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9642203450202942
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/efe0eabd99455ada4da1ff729f632c83.svg
          fullname: "Ren\xE9 Peinl"
          isHf: false
          isPro: false
          name: rpeinl
          type: user
        html: '<p>Thanks for making this effort. It is great and will push the limits
          of Open Source models further.<br>However, I''m a bit surprised that the
          provided example with Idefix (the dog) does not lead to good results in
          my tests. Usually the examples the creator of a model gives are cherry-picked
          and work better than the model on average. However, when I ask the 9B model
          about the image it is hallucinating.<br>"In this picture from Asterix and
          Obelix, we can see the dog, Rufus, running. Rufus is a dog who appears in
          the Asterix comics. He is the pet of the Roman legionary, Dogmatix."<br>If
          I ask the 80B model it is correct, but rough: "In this picture from Asterix
          and Obelix, we can see a dog running."<br>Since the context in the prompt
          already hints at Asterix and Obelix, I thought it would be no problem for
          the model to identify the dog as Idefix.<br>In further tests with other
          images the trend is continued. The Cesar image you also provide as an example
          is not recognized by the 9B model (Hercules), but the 80B model answers
          correctly.<br>Given a photo of Brad Pitt, the 80B models says correctly
          that it is Brad Pitt if the prompt says "The name of the man on this picture
          is", but halluzinates if you exchange man with woman, which I did by accident
          because I tested a photo of Julia Roberts before. Any thoughts on that?</p>

          '
        raw: "Thanks for making this effort. It is great and will push the limits\
          \ of Open Source models further.\nHowever, I'm a bit surprised that the\
          \ provided example with Idefix (the dog) does not lead to good results in\
          \ my tests. Usually the examples the creator of a model gives are cherry-picked\
          \ and work better than the model on average. However, when I ask the 9B\
          \ model about the image it is hallucinating. \n\"In this picture from Asterix\
          \ and Obelix, we can see the dog, Rufus, running. Rufus is a dog who appears\
          \ in the Asterix comics. He is the pet of the Roman legionary, Dogmatix.\"\
          \ \nIf I ask the 80B model it is correct, but rough: \"In this picture from\
          \ Asterix and Obelix, we can see a dog running.\"\nSince the context in\
          \ the prompt already hints at Asterix and Obelix, I thought it would be\
          \ no problem for the model to identify the dog as Idefix. \nIn further tests\
          \ with other images the trend is continued. The Cesar image you also provide\
          \ as an example is not recognized by the 9B model (Hercules), but the 80B\
          \ model answers correctly. \nGiven a photo of Brad Pitt, the 80B models\
          \ says correctly that it is Brad Pitt if the prompt says \"The name of the\
          \ man on this picture is\", but halluzinates if you exchange man with woman,\
          \ which I did by accident because I tested a photo of Julia Roberts before.\
          \ Any thoughts on that?\n"
        updatedAt: '2023-09-07T12:06:47.403Z'
      numEdits: 1
      reactions: []
    id: 64f9bcaeb3115b4f51422cc6
    type: comment
  author: rpeinl
  content: "Thanks for making this effort. It is great and will push the limits of\
    \ Open Source models further.\nHowever, I'm a bit surprised that the provided\
    \ example with Idefix (the dog) does not lead to good results in my tests. Usually\
    \ the examples the creator of a model gives are cherry-picked and work better\
    \ than the model on average. However, when I ask the 9B model about the image\
    \ it is hallucinating. \n\"In this picture from Asterix and Obelix, we can see\
    \ the dog, Rufus, running. Rufus is a dog who appears in the Asterix comics. He\
    \ is the pet of the Roman legionary, Dogmatix.\" \nIf I ask the 80B model it is\
    \ correct, but rough: \"In this picture from Asterix and Obelix, we can see a\
    \ dog running.\"\nSince the context in the prompt already hints at Asterix and\
    \ Obelix, I thought it would be no problem for the model to identify the dog as\
    \ Idefix. \nIn further tests with other images the trend is continued. The Cesar\
    \ image you also provide as an example is not recognized by the 9B model (Hercules),\
    \ but the 80B model answers correctly. \nGiven a photo of Brad Pitt, the 80B models\
    \ says correctly that it is Brad Pitt if the prompt says \"The name of the man\
    \ on this picture is\", but halluzinates if you exchange man with woman, which\
    \ I did by accident because I tested a photo of Julia Roberts before. Any thoughts\
    \ on that?\n"
  created_at: 2023-09-07 11:06:06+00:00
  edited: true
  hidden: false
  id: 64f9bcaeb3115b4f51422cc6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652185658647-6244866a456803e9500d0f6a.jpeg?w=200&h=200&f=face
      fullname: Leo Tronchon
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Leyo
      type: user
    createdAt: '2023-09-07T17:07:28.000Z'
    data:
      edited: false
      editors:
      - Leyo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9378471374511719
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652185658647-6244866a456803e9500d0f6a.jpeg?w=200&h=200&f=face
          fullname: Leo Tronchon
          isHf: true
          isPro: false
          name: Leyo
          type: user
        html: "<p>Hi,<br>Thanks for your remarks. Indeed, the model still hallucinates\
          \ occasionally, and the 9B more so than the 80B. You should get less of\
          \ those with the greedy mode, but there are still some cases of hallucination.<br>Regarding\
          \ the Idefix example, using the one provided in greedy should yield this:\
          \ \"Yes, the characters in the image are Asterix, Obelix, and Dogmatix.\
          \ Their French names are Ast\xE9rix, Ob\xE9lix, and Id\xE9fix.\" with the\
          \ 80B version.<br>The chosen examples were picked using the 80B version\
          \ and not the 9B one, so it is not guaranteed that the 9B performs well\
          \ on all of them.<br>Hallucinations of facts are a known problem for LLMs,\
          \ so it is not surprising to see some in multimodal models as well. You\
          \ can see that in the SEED leaderboard (<a href=\"https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard\"\
          >https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard</a>), the\
          \ \"instance\" tasks which would be related to hallucinations, are far from\
          \ being solved.<br>Hallucinations are due to multiple factors including\
          \ the size of images we use  (only 224x224 here), the quality of the vision\
          \ encoder, and the quality of the finetuning. Unfortunately, the image-text\
          \ datasets used for finetuning are still early compared to the text-only\
          \ ones.<br>Hopefully future multimodal models will keep improving on those,\
          \ but Idefics 80B should be quite accurate in general!</p>\n"
        raw: "Hi, \nThanks for your remarks. Indeed, the model still hallucinates\
          \ occasionally, and the 9B more so than the 80B. You should get less of\
          \ those with the greedy mode, but there are still some cases of hallucination.\
          \ \nRegarding the Idefix example, using the one provided in greedy should\
          \ yield this: \"Yes, the characters in the image are Asterix, Obelix, and\
          \ Dogmatix. Their French names are Ast\xE9rix, Ob\xE9lix, and Id\xE9fix.\"\
          \ with the 80B version. \nThe chosen examples were picked using the 80B\
          \ version and not the 9B one, so it is not guaranteed that the 9B performs\
          \ well on all of them.\nHallucinations of facts are a known problem for\
          \ LLMs, so it is not surprising to see some in multimodal models as well.\
          \ You can see that in the SEED leaderboard (https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard),\
          \ the \"instance\" tasks which would be related to hallucinations, are far\
          \ from being solved.\nHallucinations are due to multiple factors including\
          \ the size of images we use  (only 224x224 here), the quality of the vision\
          \ encoder, and the quality of the finetuning. Unfortunately, the image-text\
          \ datasets used for finetuning are still early compared to the text-only\
          \ ones. \nHopefully future multimodal models will keep improving on those,\
          \ but Idefics 80B should be quite accurate in general!"
        updatedAt: '2023-09-07T17:07:28.184Z'
      numEdits: 0
      reactions: []
    id: 64fa03500e486522f8ef4e5a
    type: comment
  author: Leyo
  content: "Hi, \nThanks for your remarks. Indeed, the model still hallucinates occasionally,\
    \ and the 9B more so than the 80B. You should get less of those with the greedy\
    \ mode, but there are still some cases of hallucination. \nRegarding the Idefix\
    \ example, using the one provided in greedy should yield this: \"Yes, the characters\
    \ in the image are Asterix, Obelix, and Dogmatix. Their French names are Ast\xE9\
    rix, Ob\xE9lix, and Id\xE9fix.\" with the 80B version. \nThe chosen examples were\
    \ picked using the 80B version and not the 9B one, so it is not guaranteed that\
    \ the 9B performs well on all of them.\nHallucinations of facts are a known problem\
    \ for LLMs, so it is not surprising to see some in multimodal models as well.\
    \ You can see that in the SEED leaderboard (https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard),\
    \ the \"instance\" tasks which would be related to hallucinations, are far from\
    \ being solved.\nHallucinations are due to multiple factors including the size\
    \ of images we use  (only 224x224 here), the quality of the vision encoder, and\
    \ the quality of the finetuning. Unfortunately, the image-text datasets used for\
    \ finetuning are still early compared to the text-only ones. \nHopefully future\
    \ multimodal models will keep improving on those, but Idefics 80B should be quite\
    \ accurate in general!"
  created_at: 2023-09-07 16:07:28+00:00
  edited: false
  hidden: false
  id: 64fa03500e486522f8ef4e5a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: HuggingFaceM4/idefics-80b-instruct
repo_type: model
status: open
target_branch: null
title: Demo example produces bad results
