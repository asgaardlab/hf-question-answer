!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kopyl
conflicting_files: null
created_at: 2023-11-25 17:44:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d6a6d922028e8b447b87fca56c00c679.svg
      fullname: T
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kopyl
      type: user
    createdAt: '2023-11-25T17:44:33.000Z'
    data:
      edited: true
      editors:
      - kopyl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5565854907035828
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d6a6d922028e8b447b87fca56c00c679.svg
          fullname: T
          isHf: false
          isPro: false
          name: kopyl
          type: user
        html: "<p>I can run on 2 GPU, but with 3 or 4 GPUs i get errors like these:<br><code>RuntimeError:\
          \ indices should be either on cpu or on the same device as the indexed tensor\
          \ (cuda:1)</code><br>or<br><code>RuntimeError: Expected all tensors to be\
          \ on the same device, but found at least two devices</code></p>\n<p>Why?</p>\n\
          <p>I run the inference like this:</p>\n<pre><code>checkpoint = \"HuggingFaceM4/idefics-80b-instruct\"\
          \ndevice = \"cuda\"\n\nwith init_empty_weights():\n    model = IdeficsForVisionText2Text.from_pretrained(\n\
          \        checkpoint,\n        torch_dtype=torch.bfloat16,\n        low_cpu_mem_usage=True,\n\
          \        trust_remote_code=True,\n    )\n\nmodel_cache = '/workspace/HF_HOME/hub/models--HuggingFaceM4--idefics-80b-instruct/snapshots/a14d258b1be2a74a3604483de552c33121a98391'\n\
          \nmodel = load_checkpoint_and_dispatch(\n    model,\n    model_cache,\n\
          \    device_map=\"auto\",\n)\nmodel = model.eval()\nprocessor = AutoProcessor.from_pretrained(checkpoint)\n\
          \nmodel = load_checkpoint_and_dispatch(\n    model,\n    model_cache,\n\
          \    device_map=\"auto\",\n)\nprocessor = AutoProcessor.from_pretrained(checkpoint)\n\
          \ndef generate_single(image):\n    prompt = [\n        \"User:\",\n    \
          \    image,\n        (\n            \"Write caption for the image\"\n  \
          \          \"&lt;end_of_utterance&gt;\"),\n    \n        (\n           \
          \ \"\\nAssistant: an icon\"\n        ),\n    ]\n    \n    inputs = processor(prompt,\
          \ return_tensors=\"pt\").to(\"cuda\")\n    generated_ids = model.generate(**inputs,\
          \ bad_words_ids=bad_words_ids, max_length=100)\n    input_ids = inputs['input_ids']\n\
          \    generated_text = processor.decode(generated_ids[:, input_ids.shape[1]:][0],\
          \ skip_special_tokens=True)\n\n    return f\"an icon {generated_text}\"\n\
          </code></pre>\n"
        raw: "I can run on 2 GPU, but with 3 or 4 GPUs i get errors like these:\n\
          `RuntimeError: indices should be either on cpu or on the same device as\
          \ the indexed tensor (cuda:1)`\nor\n`RuntimeError: Expected all tensors\
          \ to be on the same device, but found at least two devices`\n\nWhy?\n\n\
          I run the inference like this:\n\n```\ncheckpoint = \"HuggingFaceM4/idefics-80b-instruct\"\
          \ndevice = \"cuda\"\n\nwith init_empty_weights():\n    model = IdeficsForVisionText2Text.from_pretrained(\n\
          \        checkpoint,\n        torch_dtype=torch.bfloat16,\n        low_cpu_mem_usage=True,\n\
          \        trust_remote_code=True,\n    )\n\nmodel_cache = '/workspace/HF_HOME/hub/models--HuggingFaceM4--idefics-80b-instruct/snapshots/a14d258b1be2a74a3604483de552c33121a98391'\n\
          \nmodel = load_checkpoint_and_dispatch(\n    model,\n    model_cache,\n\
          \    device_map=\"auto\",\n)\nmodel = model.eval()\nprocessor = AutoProcessor.from_pretrained(checkpoint)\n\
          \nmodel = load_checkpoint_and_dispatch(\n    model,\n    model_cache,\n\
          \    device_map=\"auto\",\n)\nprocessor = AutoProcessor.from_pretrained(checkpoint)\n\
          \ndef generate_single(image):\n    prompt = [\n        \"User:\",\n    \
          \    image,\n        (\n            \"Write caption for the image\"\n  \
          \          \"<end_of_utterance>\"),\n    \n        (\n            \"\\nAssistant:\
          \ an icon\"\n        ),\n    ]\n    \n    inputs = processor(prompt, return_tensors=\"\
          pt\").to(\"cuda\")\n    generated_ids = model.generate(**inputs, bad_words_ids=bad_words_ids,\
          \ max_length=100)\n    input_ids = inputs['input_ids']\n    generated_text\
          \ = processor.decode(generated_ids[:, input_ids.shape[1]:][0], skip_special_tokens=True)\n\
          \n    return f\"an icon {generated_text}\"\n```"
        updatedAt: '2023-11-25T18:22:43.370Z'
      numEdits: 2
      reactions: []
    id: 65623281771319d93bbd6b6e
    type: comment
  author: kopyl
  content: "I can run on 2 GPU, but with 3 or 4 GPUs i get errors like these:\n`RuntimeError:\
    \ indices should be either on cpu or on the same device as the indexed tensor\
    \ (cuda:1)`\nor\n`RuntimeError: Expected all tensors to be on the same device,\
    \ but found at least two devices`\n\nWhy?\n\nI run the inference like this:\n\n\
    ```\ncheckpoint = \"HuggingFaceM4/idefics-80b-instruct\"\ndevice = \"cuda\"\n\n\
    with init_empty_weights():\n    model = IdeficsForVisionText2Text.from_pretrained(\n\
    \        checkpoint,\n        torch_dtype=torch.bfloat16,\n        low_cpu_mem_usage=True,\n\
    \        trust_remote_code=True,\n    )\n\nmodel_cache = '/workspace/HF_HOME/hub/models--HuggingFaceM4--idefics-80b-instruct/snapshots/a14d258b1be2a74a3604483de552c33121a98391'\n\
    \nmodel = load_checkpoint_and_dispatch(\n    model,\n    model_cache,\n    device_map=\"\
    auto\",\n)\nmodel = model.eval()\nprocessor = AutoProcessor.from_pretrained(checkpoint)\n\
    \nmodel = load_checkpoint_and_dispatch(\n    model,\n    model_cache,\n    device_map=\"\
    auto\",\n)\nprocessor = AutoProcessor.from_pretrained(checkpoint)\n\ndef generate_single(image):\n\
    \    prompt = [\n        \"User:\",\n        image,\n        (\n            \"\
    Write caption for the image\"\n            \"<end_of_utterance>\"),\n    \n  \
    \      (\n            \"\\nAssistant: an icon\"\n        ),\n    ]\n    \n   \
    \ inputs = processor(prompt, return_tensors=\"pt\").to(\"cuda\")\n    generated_ids\
    \ = model.generate(**inputs, bad_words_ids=bad_words_ids, max_length=100)\n  \
    \  input_ids = inputs['input_ids']\n    generated_text = processor.decode(generated_ids[:,\
    \ input_ids.shape[1]:][0], skip_special_tokens=True)\n\n    return f\"an icon\
    \ {generated_text}\"\n```"
  created_at: 2023-11-25 17:44:33+00:00
  edited: true
  hidden: false
  id: 65623281771319d93bbd6b6e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64c38871f9cd765462fa1a17/yuIlVcqeDlQVKsUF8uEl3.jpeg?w=200&h=200&f=face
      fullname: Lei Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lemoncoke
      type: user
    createdAt: '2023-12-20T04:40:15.000Z'
    data:
      edited: false
      editors:
      - Lemoncoke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6374075412750244
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64c38871f9cd765462fa1a17/yuIlVcqeDlQVKsUF8uEl3.jpeg?w=200&h=200&f=face
          fullname: Lei Zhang
          isHf: false
          isPro: false
          name: Lemoncoke
          type: user
        html: "<p>Hello, have you solved the problem? I try to load the model like\
          \ this:</p>\n<pre><code>with init_empty_weights():\n    self.model = IdeficsForVisionText2Text.from_pretrained(\n\
          \        model_name_or_path,\n        torch_dtype=torch.bfloat16,\n    )\n\
          \nself.model = load_checkpoint_and_dispatch(\n    self.model,\n    checkpoint,\n\
          \    device_map=\"auto\",\n).eval()\n\nself.processor = AutoProcessor.from_pretrained(model_name_or_path)\n\
          </code></pre>\n<p>But all the weights are loaded on <code>cuda:0</code>,\
          \ and this is strange.\U0001F925</p>\n"
        raw: "Hello, have you solved the problem? I try to load the model like this:\n\
          ```\nwith init_empty_weights():\n    self.model = IdeficsForVisionText2Text.from_pretrained(\n\
          \        model_name_or_path,\n        torch_dtype=torch.bfloat16,\n    )\n\
          \nself.model = load_checkpoint_and_dispatch(\n    self.model,\n    checkpoint,\n\
          \    device_map=\"auto\",\n).eval()\n\nself.processor = AutoProcessor.from_pretrained(model_name_or_path)\n\
          ```\nBut all the weights are loaded on `cuda:0`, and this is strange.\U0001F925"
        updatedAt: '2023-12-20T04:40:15.236Z'
      numEdits: 0
      reactions: []
    id: 6582702f2db4c45ef3f92745
    type: comment
  author: Lemoncoke
  content: "Hello, have you solved the problem? I try to load the model like this:\n\
    ```\nwith init_empty_weights():\n    self.model = IdeficsForVisionText2Text.from_pretrained(\n\
    \        model_name_or_path,\n        torch_dtype=torch.bfloat16,\n    )\n\nself.model\
    \ = load_checkpoint_and_dispatch(\n    self.model,\n    checkpoint,\n    device_map=\"\
    auto\",\n).eval()\n\nself.processor = AutoProcessor.from_pretrained(model_name_or_path)\n\
    ```\nBut all the weights are loaded on `cuda:0`, and this is strange.\U0001F925"
  created_at: 2023-12-20 04:40:15+00:00
  edited: false
  hidden: false
  id: 6582702f2db4c45ef3f92745
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64c38871f9cd765462fa1a17/yuIlVcqeDlQVKsUF8uEl3.jpeg?w=200&h=200&f=face
      fullname: Lei Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lemoncoke
      type: user
    createdAt: '2023-12-20T05:33:11.000Z'
    data:
      edited: false
      editors:
      - Lemoncoke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6551908850669861
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64c38871f9cd765462fa1a17/yuIlVcqeDlQVKsUF8uEl3.jpeg?w=200&h=200&f=face
          fullname: Lei Zhang
          isHf: false
          isPro: false
          name: Lemoncoke
          type: user
        html: "<blockquote>\n<p>Hello, have you solved the problem? I try to load\
          \ the model like this:</p>\n<pre><code>with init_empty_weights():\n    self.model\
          \ = IdeficsForVisionText2Text.from_pretrained(\n        model_name_or_path,\n\
          \        torch_dtype=torch.bfloat16,\n    )\n\nself.model = load_checkpoint_and_dispatch(\n\
          \    self.model,\n    checkpoint,\n    device_map=\"auto\",\n).eval()\n\n\
          self.processor = AutoProcessor.from_pretrained(model_name_or_path)\n</code></pre>\n\
          <p>But all the weights are loaded on <code>cuda:0</code>, and this is strange.\U0001F925\
          </p>\n</blockquote>\n<p>I'm so stupid\U0001F605, I just set <code>CUDA_VISIBLE_DEVICES=0</code>,\
          \ and forgot it.</p>\n"
        raw: "> Hello, have you solved the problem? I try to load the model like this:\n\
          > ```\n> with init_empty_weights():\n>     self.model = IdeficsForVisionText2Text.from_pretrained(\n\
          >         model_name_or_path,\n>         torch_dtype=torch.bfloat16,\n>\
          \     )\n> \n> self.model = load_checkpoint_and_dispatch(\n>     self.model,\n\
          >     checkpoint,\n>     device_map=\"auto\",\n> ).eval()\n> \n> self.processor\
          \ = AutoProcessor.from_pretrained(model_name_or_path)\n> ```\n> But all\
          \ the weights are loaded on `cuda:0`, and this is strange.\U0001F925\n\n\
          I'm so stupid\U0001F605, I just set `CUDA_VISIBLE_DEVICES=0`, and forgot\
          \ it."
        updatedAt: '2023-12-20T05:33:11.955Z'
      numEdits: 0
      reactions: []
    id: 65827c97f3006507ea056e80
    type: comment
  author: Lemoncoke
  content: "> Hello, have you solved the problem? I try to load the model like this:\n\
    > ```\n> with init_empty_weights():\n>     self.model = IdeficsForVisionText2Text.from_pretrained(\n\
    >         model_name_or_path,\n>         torch_dtype=torch.bfloat16,\n>     )\n\
    > \n> self.model = load_checkpoint_and_dispatch(\n>     self.model,\n>     checkpoint,\n\
    >     device_map=\"auto\",\n> ).eval()\n> \n> self.processor = AutoProcessor.from_pretrained(model_name_or_path)\n\
    > ```\n> But all the weights are loaded on `cuda:0`, and this is strange.\U0001F925\
    \n\nI'm so stupid\U0001F605, I just set `CUDA_VISIBLE_DEVICES=0`, and forgot it."
  created_at: 2023-12-20 05:33:11+00:00
  edited: false
  hidden: false
  id: 65827c97f3006507ea056e80
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d6a6d922028e8b447b87fca56c00c679.svg
      fullname: T
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kopyl
      type: user
    createdAt: '2023-12-20T14:45:55.000Z'
    data:
      edited: false
      editors:
      - kopyl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.960421085357666
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d6a6d922028e8b447b87fca56c00c679.svg
          fullname: T
          isHf: false
          isPro: false
          name: kopyl
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Lemoncoke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Lemoncoke\">@<span class=\"\
          underline\">Lemoncoke</span></a></span>\n\n\t</span></span> I could not\
          \ even think about <code>CUDA_VISIBLE_DEVICES</code>, almost never used\
          \ it, so chances of me helping you would be low anyways :(</p>\n"
        raw: '@Lemoncoke I could not even think about `CUDA_VISIBLE_DEVICES`, almost
          never used it, so chances of me helping you would be low anyways :('
        updatedAt: '2023-12-20T14:45:55.205Z'
      numEdits: 0
      reactions: []
    id: 6582fe23f417510bede2f71c
    type: comment
  author: kopyl
  content: '@Lemoncoke I could not even think about `CUDA_VISIBLE_DEVICES`, almost
    never used it, so chances of me helping you would be low anyways :('
  created_at: 2023-12-20 14:45:55+00:00
  edited: false
  hidden: false
  id: 6582fe23f417510bede2f71c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
      fullname: Victor Sanh
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: true
      name: VictorSanh
      type: user
    createdAt: '2023-12-20T15:24:31.000Z'
    data:
      edited: false
      editors:
      - VictorSanh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9009106755256653
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1619623771844-5ecea265968f6028e0559fa5.jpeg?w=200&h=200&f=face
          fullname: Victor Sanh
          isHf: true
          isPro: true
          name: VictorSanh
          type: user
        html: "<blockquote>\n<p>I'm so stupid\U0001F605, I just set CUDA_VISIBLE_DEVICES=0,\
          \ and forgot it.</p>\n</blockquote>\n<p>haha, glad you found it though <span\
          \ data-props=\"{&quot;user&quot;:&quot;Lemoncoke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Lemoncoke\">@<span class=\"\
          underline\">Lemoncoke</span></a></span>\n\n\t</span></span> !</p>\n"
        raw: "> I'm so stupid\U0001F605, I just set CUDA_VISIBLE_DEVICES=0, and forgot\
          \ it.\n\nhaha, glad you found it though @Lemoncoke !"
        updatedAt: '2023-12-20T15:24:31.097Z'
      numEdits: 0
      reactions: []
    id: 6583072f93da00893391cc68
    type: comment
  author: VictorSanh
  content: "> I'm so stupid\U0001F605, I just set CUDA_VISIBLE_DEVICES=0, and forgot\
    \ it.\n\nhaha, glad you found it though @Lemoncoke !"
  created_at: 2023-12-20 15:24:31+00:00
  edited: false
  hidden: false
  id: 6583072f93da00893391cc68
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: HuggingFaceM4/idefics-80b-instruct
repo_type: model
status: open
target_branch: null
title: Multi-GPU inference.
