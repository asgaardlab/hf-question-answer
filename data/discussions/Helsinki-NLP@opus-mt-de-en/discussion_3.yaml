!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MaximilianBlanck
conflicting_files: null
created_at: 2022-12-14 08:29:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8d3a8fd0e39c50a6a6060179b5ef2946.svg
      fullname: Maximilia Blanck
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MaximilianBlanck
      type: user
    createdAt: '2022-12-14T08:29:03.000Z'
    data:
      edited: false
      editors:
      - MaximilianBlanck
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8d3a8fd0e39c50a6a6060179b5ef2946.svg
          fullname: Maximilia Blanck
          isHf: false
          isPro: false
          name: MaximilianBlanck
          type: user
        html: "<p>Hi,<br>first of all thank you for sharing such great translation\
          \ Models!</p>\n<p>Not sure if iam the only one that was shortly confused\
          \ by the formatting of the evaluation scores:<br>testset \tBLEU \tchr-F<br>newssyscomb2009.de.en\
          \ \t29.4 \t0.557</p>\n<p>The BLEU score is recoreded in 29.4% here and the\
          \ chr-F score is formated as 0.557.<br>I just thought, looking at both numbers\
          \ that you report the ROUGE score at first, becuase the formatting was different.<br>Wouldn't\
          \ it make sense to report both scores in the same format like 0.294 and\
          \ 0.557 or 29.4% and 55.7%?<br>That would probably be more consistent.</p>\n"
        raw: "Hi,\r\nfirst of all thank you for sharing such great translation Models!\r\
          \n\r\nNot sure if iam the only one that was shortly confused by the formatting\
          \ of the evaluation scores:\r\ntestset \tBLEU \tchr-F\r\nnewssyscomb2009.de.en\
          \ \t29.4 \t0.557\r\n\r\nThe BLEU score is recoreded in 29.4% here and the\
          \ chr-F score is formated as 0.557.\r\nI just thought, looking at both numbers\
          \ that you report the ROUGE score at first, becuase the formatting was different.\r\
          \nWouldn't it make sense to report both scores in the same format like 0.294\
          \ and 0.557 or 29.4% and 55.7%?\r\nThat would probably be more consistent.\r\
          \n\r\n"
        updatedAt: '2022-12-14T08:29:03.971Z'
      numEdits: 0
      reactions: []
    id: 6399894f9fed2f011017eaf0
    type: comment
  author: MaximilianBlanck
  content: "Hi,\r\nfirst of all thank you for sharing such great translation Models!\r\
    \n\r\nNot sure if iam the only one that was shortly confused by the formatting\
    \ of the evaluation scores:\r\ntestset \tBLEU \tchr-F\r\nnewssyscomb2009.de.en\
    \ \t29.4 \t0.557\r\n\r\nThe BLEU score is recoreded in 29.4% here and the chr-F\
    \ score is formated as 0.557.\r\nI just thought, looking at both numbers that\
    \ you report the ROUGE score at first, becuase the formatting was different.\r\
    \nWouldn't it make sense to report both scores in the same format like 0.294 and\
    \ 0.557 or 29.4% and 55.7%?\r\nThat would probably be more consistent.\r\n\r\n"
  created_at: 2022-12-14 08:29:03+00:00
  edited: false
  hidden: false
  id: 6399894f9fed2f011017eaf0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Helsinki-NLP/opus-mt-de-en
repo_type: model
status: open
target_branch: null
title: Eval formats in Model Card
