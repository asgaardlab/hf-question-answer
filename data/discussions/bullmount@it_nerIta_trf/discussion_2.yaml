!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zppcst
conflicting_files: null
created_at: 2022-12-05 14:59:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaa501634d51a61f8ea7968eab4c8a7d.svg
      fullname: Zappata Cristina
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zppcst
      type: user
    createdAt: '2022-12-05T14:59:01.000Z'
    data:
      edited: false
      editors:
      - zppcst
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaa501634d51a61f8ea7968eab4c8a7d.svg
          fullname: Zappata Cristina
          isHf: false
          isPro: false
          name: zppcst
          type: user
        html: '<p>Hi, I found this model very interesting and wanted to use it for
          my task. Also, I wanted to fine-tune it with my own data.</p>

          <p>So I used this link as a training guide: <a rel="nofollow" href="https://spacy.io/usage/training#basics">https://spacy.io/usage/training#basics</a></p>

          <p>Also, I used your <code>it_nerIta_trf/config.cfg</code> file  to do the
          fine-tuning.</p>

          <p>Starting the training shows this:</p>

          <pre><code>=========================== Initializing pipeline ===========================

          [2022-12-05 15:22:00,040] [INFO] Set up nlp object from config

          [2022-12-05 15:22:00,046] [INFO] Pipeline: [''transformer'', ''ner'']

          [2022-12-05 15:22:00,048] [INFO] Created vocabulary

          [2022-12-05 15:22:00,049] [INFO] Finished initializing nlp object

          Some weights of the model checkpoint at bullmount/hseBert-it-cased were
          not used when initializing BertModel: [''cls.predictions.transform.LayerNorm.weight'',
          ''cls.predictions.decoder.bias'', ''cls.predictions.transform.LayerNorm.bias'',
          ''cls.predictions.transform.dense.weight'', ''cls.predictions.transform.dense.bias'',
          ''cls.predictions.decoder.weight'', ''cls.predictions.bias'']

          - This IS expected if you are initializing BertModel from the checkpoint
          of a model trained on another task or with another architecture (e.g. initializing
          a BertForSequenceClassification model from a BertForPreTraining model).

          - This IS NOT expected if you are initializing BertModel from the checkpoint
          of a model that you expect to be exactly identical (initializing a BertForSequenceClassification
          model from a BertForSequenceClassification model).

          Some weights of BertModel were not initialized from the model checkpoint
          at bullmount/hseBert-it-cased and are newly initialized: [''bert.pooler.dense.weight'',
          ''bert.pooler.dense.bias'']

          You should probably TRAIN this model on a down-stream task to be able to
          use it for predictions and inference.

          [2022-12-05 15:22:06,822] [INFO] Initialized pipeline components: [''transformer'',
          ''ner'']

          </code></pre>

          <p>Training seems to proceed well, albeit slowly.  But I can''t figure out
          which one case I am in and whether this can cause problems in training:</p>

          <ul>

          <li><p>This IS expected if you are initializing BertModel from the checkpoint
          of a model trained on another task or with another architecture (e.g. initializing
          a BertForSequenceClassification model from a BertForPreTraining model).</p>

          </li>

          <li><p>This IS NOT expected if you are initializing BertModel from the checkpoint
          of a model that you expect to be exactly identical (initializing a BertForSequenceClassification
          model from a BertForSequenceClassification model).</p>

          </li>

          </ul>

          <p>Incidentally, this happens even if I use a standard configuration file
          provided by the spacy site mentioned above.</p>

          <p>Can you help me?</p>

          <p>Thanks in advance.</p>

          '
        raw: "Hi, I found this model very interesting and wanted to use it for my\
          \ task. Also, I wanted to fine-tune it with my own data.\r\n\r\nSo I used\
          \ this link as a training guide: [https://spacy.io/usage/training#basics](https://spacy.io/usage/training#basics)\r\
          \n\r\nAlso, I used your `it_nerIta_trf/config.cfg` file  to do the fine-tuning.\r\
          \n\r\nStarting the training shows this:\r\n\r\n```\r\n===========================\
          \ Initializing pipeline ===========================\r\n[2022-12-05 15:22:00,040]\
          \ [INFO] Set up nlp object from config\r\n[2022-12-05 15:22:00,046] [INFO]\
          \ Pipeline: ['transformer', 'ner']\r\n[2022-12-05 15:22:00,048] [INFO] Created\
          \ vocabulary\r\n[2022-12-05 15:22:00,049] [INFO] Finished initializing nlp\
          \ object\r\nSome weights of the model checkpoint at bullmount/hseBert-it-cased\
          \ were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight',\
          \ 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias',\
          \ 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias',\
          \ 'cls.predictions.decoder.weight', 'cls.predictions.bias']\r\n- This IS\
          \ expected if you are initializing BertModel from the checkpoint of a model\
          \ trained on another task or with another architecture (e.g. initializing\
          \ a BertForSequenceClassification model from a BertForPreTraining model).\r\
          \n- This IS NOT expected if you are initializing BertModel from the checkpoint\
          \ of a model that you expect to be exactly identical (initializing a BertForSequenceClassification\
          \ model from a BertForSequenceClassification model).\r\nSome weights of\
          \ BertModel were not initialized from the model checkpoint at bullmount/hseBert-it-cased\
          \ and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\r\
          \nYou should probably TRAIN this model on a down-stream task to be able\
          \ to use it for predictions and inference.\r\n[2022-12-05 15:22:06,822]\
          \ [INFO] Initialized pipeline components: ['transformer', 'ner']\r\n```\r\
          \n\r\nTraining seems to proceed well, albeit slowly.  But I can't figure\
          \ out which one case I am in and whether this can cause problems in training:\r\
          \n\r\n- This IS expected if you are initializing BertModel from the checkpoint\
          \ of a model trained on another task or with another architecture (e.g.\
          \ initializing a BertForSequenceClassification model from a BertForPreTraining\
          \ model).\r\n\r\n- This IS NOT expected if you are initializing BertModel\
          \ from the checkpoint of a model that you expect to be exactly identical\
          \ (initializing a BertForSequenceClassification model from a BertForSequenceClassification\
          \ model).\r\n\r\nIncidentally, this happens even if I use a standard configuration\
          \ file provided by the spacy site mentioned above.\r\n\r\nCan you help me?\r\
          \n\r\nThanks in advance."
        updatedAt: '2022-12-05T14:59:01.187Z'
      numEdits: 0
      reactions: []
    id: 638e0735d975533b16a62c28
    type: comment
  author: zppcst
  content: "Hi, I found this model very interesting and wanted to use it for my task.\
    \ Also, I wanted to fine-tune it with my own data.\r\n\r\nSo I used this link\
    \ as a training guide: [https://spacy.io/usage/training#basics](https://spacy.io/usage/training#basics)\r\
    \n\r\nAlso, I used your `it_nerIta_trf/config.cfg` file  to do the fine-tuning.\r\
    \n\r\nStarting the training shows this:\r\n\r\n```\r\n===========================\
    \ Initializing pipeline ===========================\r\n[2022-12-05 15:22:00,040]\
    \ [INFO] Set up nlp object from config\r\n[2022-12-05 15:22:00,046] [INFO] Pipeline:\
    \ ['transformer', 'ner']\r\n[2022-12-05 15:22:00,048] [INFO] Created vocabulary\r\
    \n[2022-12-05 15:22:00,049] [INFO] Finished initializing nlp object\r\nSome weights\
    \ of the model checkpoint at bullmount/hseBert-it-cased were not used when initializing\
    \ BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias',\
    \ 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight',\
    \ 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\r\
    \n- This IS expected if you are initializing BertModel from the checkpoint of\
    \ a model trained on another task or with another architecture (e.g. initializing\
    \ a BertForSequenceClassification model from a BertForPreTraining model).\r\n\
    - This IS NOT expected if you are initializing BertModel from the checkpoint of\
    \ a model that you expect to be exactly identical (initializing a BertForSequenceClassification\
    \ model from a BertForSequenceClassification model).\r\nSome weights of BertModel\
    \ were not initialized from the model checkpoint at bullmount/hseBert-it-cased\
    \ and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\r\
    \nYou should probably TRAIN this model on a down-stream task to be able to use\
    \ it for predictions and inference.\r\n[2022-12-05 15:22:06,822] [INFO] Initialized\
    \ pipeline components: ['transformer', 'ner']\r\n```\r\n\r\nTraining seems to\
    \ proceed well, albeit slowly.  But I can't figure out which one case I am in\
    \ and whether this can cause problems in training:\r\n\r\n- This IS expected if\
    \ you are initializing BertModel from the checkpoint of a model trained on another\
    \ task or with another architecture (e.g. initializing a BertForSequenceClassification\
    \ model from a BertForPreTraining model).\r\n\r\n- This IS NOT expected if you\
    \ are initializing BertModel from the checkpoint of a model that you expect to\
    \ be exactly identical (initializing a BertForSequenceClassification model from\
    \ a BertForSequenceClassification model).\r\n\r\nIncidentally, this happens even\
    \ if I use a standard configuration file provided by the spacy site mentioned\
    \ above.\r\n\r\nCan you help me?\r\n\r\nThanks in advance."
  created_at: 2022-12-05 14:59:01+00:00
  edited: false
  hidden: false
  id: 638e0735d975533b16a62c28
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: bullmount/it_nerIta_trf
repo_type: model
status: open
target_branch: null
title: Fine-tuning model
