!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lijunsen
conflicting_files: null
created_at: 2023-07-20 12:01:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae83a53a2148e24abdd43f2418089935.svg
      fullname: zhengdeshuai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lijunsen
      type: user
    createdAt: '2023-07-20T13:01:08.000Z'
    data:
      edited: false
      editors:
      - lijunsen
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.33063310384750366
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae83a53a2148e24abdd43f2418089935.svg
          fullname: zhengdeshuai
          isHf: false
          isPro: false
          name: lijunsen
          type: user
        html: "<p>\u751F\u6210\u91CD\u590D\u6587\u672C\uFF0C\u6BD4\u5982\uFF1A<br>\u7167\
          \u7247\u4E2D\u7684\u4E3B\u8981\u8BBE\u8BA1\u5143\u7D20\u5305\u62EC\u4E00\
          \u4E2A\u5927\u578B\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u9ED1\
          \u8272\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C\
          \ \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\
          \u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C\
          \ \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\
          \u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C\
          \ \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\
          \u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B</p>\n<p>\u4EE3\u7801\u5982\
          \u4E0B\uFF1A<br>'''</p>\n<h1 id=\"encoding-utf-8\">encoding: UTF-8</h1>\n\
          <p>from transformers import LlamaForCausalLM, LlamaTokenizer, BlipImageProcessor<br>from\
          \ modeling_ziya_blip2 import ZiyaBlip2ForCausalLM<br>from PIL import Image</p>\n\
          <p>LM_MODEL_PATH = \"/root/.cache/huggingface/model_weights/Ziya-LLaMA-13B\"\
          <br>lm_model = LlamaForCausalLM.from_pretrained(LM_MODEL_PATH)<br>tokenizer\
          \ = LlamaTokenizer.from_pretrained(LM_MODEL_PATH)</p>\n<h1 id=\"visual-model\"\
          >visual model</h1>\n<p>OPENAI_CLIP_MEAN = [0.48145466, 0.4578275, 0.40821073]<br>OPENAI_CLIP_STD\
          \ = [0.26862954, 0.26130258, 0.27577711]<br>model = ZiyaBlip2ForCausalLM.from_pretrained(\"\
          IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1\", language_model=lm_model)<br>image_size\
          \ = model.config.vision_config.image_size<br>image_processor = BlipImageProcessor(<br>\
          \    size={\"height\": image_size, \"width\": image_size},<br>    image_mean=OPENAI_CLIP_MEAN,<br>\
          \    image_std=OPENAI_CLIP_STD,<br>)<br>model.cuda()  # if you use on cpu,\
          \ comment this line</p>\n<p>generate_config = {<br>        \"max_new_tokens\"\
          : 128,<br>        \"top_p\": 0.1,<br>        \"temperature\": 0.7<br>  \
          \  }</p>\n<p>prompt = \"\u63CF\u8FF0\u4E0B\u8FD9\u5F20\u56FE\u7247\u3002\
          \"</p>\n<p>output = model.chat(<br>    tokenizer=tokenizer,<br>    pixel_values=image_processor(Image.open(\"\
          111111111.png\"), return_tensors=\"pt\").pixel_values.to(model.device),<br>\
          \    query=prompt,<br>    previous_querys=[],<br>    previous_outputs=[],<br>\
          \    **generate_config,<br>)<br>output = str(output).replace(\"<s>\", \"\
          \").replace(\"</s>\", \"\").strip()<br>print(output)<br>'''</p>\n"
        raw: "\u751F\u6210\u91CD\u590D\u6587\u672C\uFF0C\u6BD4\u5982\uFF1A\r\n\u7167\
          \u7247\u4E2D\u7684\u4E3B\u8981\u8BBE\u8BA1\u5143\u7D20\u5305\u62EC\u4E00\
          \u4E2A\u5927\u578B\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u9ED1\
          \u8272\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C\
          \ \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\
          \u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C\
          \ \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\
          \u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C\
          \ \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\
          \u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\r\n\r\n\u4EE3\u7801\u5982\
          \u4E0B\uFF1A\r\n'''\r\n# encoding: UTF-8\r\nfrom transformers import LlamaForCausalLM,\
          \ LlamaTokenizer, BlipImageProcessor\r\nfrom modeling_ziya_blip2 import\
          \ ZiyaBlip2ForCausalLM\r\nfrom PIL import Image\r\n\r\nLM_MODEL_PATH = \"\
          /root/.cache/huggingface/model_weights/Ziya-LLaMA-13B\"\r\nlm_model = LlamaForCausalLM.from_pretrained(LM_MODEL_PATH)\r\
          \ntokenizer = LlamaTokenizer.from_pretrained(LM_MODEL_PATH)\r\n# visual\
          \ model\r\nOPENAI_CLIP_MEAN = [0.48145466, 0.4578275, 0.40821073]\r\nOPENAI_CLIP_STD\
          \ = [0.26862954, 0.26130258, 0.27577711]\r\nmodel = ZiyaBlip2ForCausalLM.from_pretrained(\"\
          IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1\", language_model=lm_model)\r\nimage_size\
          \ = model.config.vision_config.image_size\r\nimage_processor = BlipImageProcessor(\r\
          \n    size={\"height\": image_size, \"width\": image_size},\r\n    image_mean=OPENAI_CLIP_MEAN,\r\
          \n    image_std=OPENAI_CLIP_STD,\r\n)\r\nmodel.cuda()  # if you use on cpu,\
          \ comment this line\r\n\r\ngenerate_config = {\r\n        \"max_new_tokens\"\
          : 128,\r\n        \"top_p\": 0.1,\r\n        \"temperature\": 0.7\r\n  \
          \  }\r\n\r\nprompt = \"\u63CF\u8FF0\u4E0B\u8FD9\u5F20\u56FE\u7247\u3002\"\
          \r\n\r\noutput = model.chat(\r\n    tokenizer=tokenizer,\r\n    pixel_values=image_processor(Image.open(\"\
          111111111.png\"), return_tensors=\"pt\").pixel_values.to(model.device),\r\
          \n    query=prompt,\r\n    previous_querys=[],\r\n    previous_outputs=[],\r\
          \n    **generate_config,\r\n)\r\noutput = str(output).replace(\"<s>\", \"\
          \").replace(\"</s>\", \"\").strip()\r\nprint(output)\r\n'''"
        updatedAt: '2023-07-20T13:01:08.931Z'
      numEdits: 0
      reactions: []
    id: 64b93014e436bbca167832c1
    type: comment
  author: lijunsen
  content: "\u751F\u6210\u91CD\u590D\u6587\u672C\uFF0C\u6BD4\u5982\uFF1A\r\n\u7167\
    \u7247\u4E2D\u7684\u4E3B\u8981\u8BBE\u8BA1\u5143\u7D20\u5305\u62EC\u4E00\u4E2A\
    \u5927\u578B\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u9ED1\u8272\u58C1\
    \u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\
    \u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C\
    \ \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\
    \u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\
    \u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089\
    \ \uFF0C \u4E00\u4E2A\u5927\u578B\u7684\u58C1\u7089 \uFF0C \u4E00\u4E2A\u5927\u578B\
    \r\n\r\n\u4EE3\u7801\u5982\u4E0B\uFF1A\r\n'''\r\n# encoding: UTF-8\r\nfrom transformers\
    \ import LlamaForCausalLM, LlamaTokenizer, BlipImageProcessor\r\nfrom modeling_ziya_blip2\
    \ import ZiyaBlip2ForCausalLM\r\nfrom PIL import Image\r\n\r\nLM_MODEL_PATH =\
    \ \"/root/.cache/huggingface/model_weights/Ziya-LLaMA-13B\"\r\nlm_model = LlamaForCausalLM.from_pretrained(LM_MODEL_PATH)\r\
    \ntokenizer = LlamaTokenizer.from_pretrained(LM_MODEL_PATH)\r\n# visual model\r\
    \nOPENAI_CLIP_MEAN = [0.48145466, 0.4578275, 0.40821073]\r\nOPENAI_CLIP_STD =\
    \ [0.26862954, 0.26130258, 0.27577711]\r\nmodel = ZiyaBlip2ForCausalLM.from_pretrained(\"\
    IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1\", language_model=lm_model)\r\nimage_size =\
    \ model.config.vision_config.image_size\r\nimage_processor = BlipImageProcessor(\r\
    \n    size={\"height\": image_size, \"width\": image_size},\r\n    image_mean=OPENAI_CLIP_MEAN,\r\
    \n    image_std=OPENAI_CLIP_STD,\r\n)\r\nmodel.cuda()  # if you use on cpu, comment\
    \ this line\r\n\r\ngenerate_config = {\r\n        \"max_new_tokens\": 128,\r\n\
    \        \"top_p\": 0.1,\r\n        \"temperature\": 0.7\r\n    }\r\n\r\nprompt\
    \ = \"\u63CF\u8FF0\u4E0B\u8FD9\u5F20\u56FE\u7247\u3002\"\r\n\r\noutput = model.chat(\r\
    \n    tokenizer=tokenizer,\r\n    pixel_values=image_processor(Image.open(\"111111111.png\"\
    ), return_tensors=\"pt\").pixel_values.to(model.device),\r\n    query=prompt,\r\
    \n    previous_querys=[],\r\n    previous_outputs=[],\r\n    **generate_config,\r\
    \n)\r\noutput = str(output).replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()\r\
    \nprint(output)\r\n'''"
  created_at: 2023-07-20 12:01:08+00:00
  edited: false
  hidden: false
  id: 64b93014e436bbca167832c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667442736294-6352637d0f9bdb641c44e52d.jpeg?w=200&h=200&f=face
      fullname: wuxiaojun
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: wuxiaojun
      type: user
    createdAt: '2023-07-21T03:14:28.000Z'
    data:
      edited: false
      editors:
      - wuxiaojun
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9995220303535461
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667442736294-6352637d0f9bdb641c44e52d.jpeg?w=200&h=200&f=face
          fullname: wuxiaojun
          isHf: false
          isPro: false
          name: wuxiaojun
          type: user
        html: "<p>\u6211\u4F7F\u7528\u8FC7\u7A0B\u4E2D\u6CA1\u9047\u5230\u8FD9\u4E2A\
          \u95EE\u9898\uFF0C\u4F60\u53EF\u4EE5\u628A\u8FD9\u5F20\u56FE\u7247\u53D1\
          \u51FA\u6765\uFF0C\u6211\u6D4B\u8BD5\u4E00\u4E0B</p>\n"
        raw: "\u6211\u4F7F\u7528\u8FC7\u7A0B\u4E2D\u6CA1\u9047\u5230\u8FD9\u4E2A\u95EE\
          \u9898\uFF0C\u4F60\u53EF\u4EE5\u628A\u8FD9\u5F20\u56FE\u7247\u53D1\u51FA\
          \u6765\uFF0C\u6211\u6D4B\u8BD5\u4E00\u4E0B"
        updatedAt: '2023-07-21T03:14:28.247Z'
      numEdits: 0
      reactions: []
    id: 64b9f814bfec89ab32b23305
    type: comment
  author: wuxiaojun
  content: "\u6211\u4F7F\u7528\u8FC7\u7A0B\u4E2D\u6CA1\u9047\u5230\u8FD9\u4E2A\u95EE\
    \u9898\uFF0C\u4F60\u53EF\u4EE5\u628A\u8FD9\u5F20\u56FE\u7247\u53D1\u51FA\u6765\
    \uFF0C\u6211\u6D4B\u8BD5\u4E00\u4E0B"
  created_at: 2023-07-21 02:14:28+00:00
  edited: false
  hidden: false
  id: 64b9f814bfec89ab32b23305
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661354483931-630626f0cfbde33ef7d78696.png?w=200&h=200&f=face
      fullname: HaloMaster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HaloMaster
      type: user
    createdAt: '2023-09-03T01:20:27.000Z'
    data:
      edited: false
      editors:
      - HaloMaster
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.997983455657959
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661354483931-630626f0cfbde33ef7d78696.png?w=200&h=200&f=face
          fullname: HaloMaster
          isHf: false
          isPro: false
          name: HaloMaster
          type: user
        html: "<p>\u5E94\u8BE5\u662F\u6A21\u578B\u8BAD\u7EC3\u7684\u95EE\u9898\u3002\
          </p>\n"
        raw: "\u5E94\u8BE5\u662F\u6A21\u578B\u8BAD\u7EC3\u7684\u95EE\u9898\u3002"
        updatedAt: '2023-09-03T01:20:27.426Z'
      numEdits: 0
      reactions: []
    id: 64f3df5bd41e83d74a003d8c
    type: comment
  author: HaloMaster
  content: "\u5E94\u8BE5\u662F\u6A21\u578B\u8BAD\u7EC3\u7684\u95EE\u9898\u3002"
  created_at: 2023-09-03 00:20:27+00:00
  edited: false
  hidden: false
  id: 64f3df5bd41e83d74a003d8c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3c9ff96d8fae2d7521350b7036b13cc9.svg
      fullname: xu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zizizizi
      type: user
    createdAt: '2023-09-17T16:38:31.000Z'
    data:
      edited: false
      editors:
      - zizizizi
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9926033616065979
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3c9ff96d8fae2d7521350b7036b13cc9.svg
          fullname: xu
          isHf: false
          isPro: false
          name: zizizizi
          type: user
        html: "<p>\u8BED\u8A00\u6A21\u578B\u8FD9\u79CD\u95EE\u9898\u5F88\u5E38\u89C1\
          \uFF0C\u6211\u4E4B\u524D\u5FAE\u8C03\u7684\u8BED\u8A00\u6A21\u578B\u5F88\
          \u591A\u90FD\u4F1A\u51FA\u73B0\u8FD9\u79CD\u95EE\u9898</p>\n"
        raw: "\u8BED\u8A00\u6A21\u578B\u8FD9\u79CD\u95EE\u9898\u5F88\u5E38\u89C1\uFF0C\
          \u6211\u4E4B\u524D\u5FAE\u8C03\u7684\u8BED\u8A00\u6A21\u578B\u5F88\u591A\
          \u90FD\u4F1A\u51FA\u73B0\u8FD9\u79CD\u95EE\u9898"
        updatedAt: '2023-09-17T16:38:31.701Z'
      numEdits: 0
      reactions: []
    id: 65072b87557a87f111d7bfd2
    type: comment
  author: zizizizi
  content: "\u8BED\u8A00\u6A21\u578B\u8FD9\u79CD\u95EE\u9898\u5F88\u5E38\u89C1\uFF0C\
    \u6211\u4E4B\u524D\u5FAE\u8C03\u7684\u8BED\u8A00\u6A21\u578B\u5F88\u591A\u90FD\
    \u4F1A\u51FA\u73B0\u8FD9\u79CD\u95EE\u9898"
  created_at: 2023-09-17 15:38:31+00:00
  edited: false
  hidden: false
  id: 65072b87557a87f111d7bfd2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1
repo_type: model
status: open
target_branch: null
title: "\u751F\u6210\u7684\u5185\u5BB9\u4E2D\u5B58\u5728\u5927\u6BB5\u7684\u91CD\u590D\
  \u6587\u672C"
