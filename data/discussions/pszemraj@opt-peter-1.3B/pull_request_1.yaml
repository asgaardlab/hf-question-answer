!!python/object:huggingface_hub.community.DiscussionWithDetails
author: patrickvonplaten
conflicting_files: []
created_at: 2022-05-25 19:29:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2022-05-25T20:29:18.000Z'
    data:
      edited: false
      editors:
      - patrickvonplaten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
          fullname: Patrick von Platen
          isHf: true
          isPro: false
          name: patrickvonplaten
          type: user
        html: '<p>This is important to prevent a nasty bug at the moment. Without
          this fix one could load the wrong tokenizer (fast gpt2) when doing tokenizer
          = AutoTokenizer.from_pretrained(''your/model/id''). Currently fast gpt2
          doesn''t work correctly with OPT and one should only use the slow one see:
          <a href="https://huggingface.co/facebook/opt-6.7b#how-to-use">https://huggingface.co/facebook/opt-6.7b#how-to-use</a></p>

          '
        raw: 'This is important to prevent a nasty bug at the moment. Without this
          fix one could load the wrong tokenizer (fast gpt2) when doing tokenizer
          = AutoTokenizer.from_pretrained(''your/model/id''). Currently fast gpt2
          doesn''t work correctly with OPT and one should only use the slow one see:
          https://huggingface.co/facebook/opt-6.7b#how-to-use'
        updatedAt: '2022-05-25T20:29:18.000Z'
      numEdits: 0
      reactions: []
    id: 628e919ee0994038b5f4db8a
    type: comment
  author: patrickvonplaten
  content: 'This is important to prevent a nasty bug at the moment. Without this fix
    one could load the wrong tokenizer (fast gpt2) when doing tokenizer = AutoTokenizer.from_pretrained(''your/model/id'').
    Currently fast gpt2 doesn''t work correctly with OPT and one should only use the
    slow one see: https://huggingface.co/facebook/opt-6.7b#how-to-use'
  created_at: 2022-05-25 19:29:18+00:00
  edited: false
  hidden: false
  id: 628e919ee0994038b5f4db8a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2022-05-25T20:29:19.000Z'
    data:
      oid: 7604530e940d92339c2880819a7385e704d60c5d
      parents:
      - 2788720d1261c4e77349105796330ca7425e29ae
      subject: Update tokenizer_config.json
    id: 628e919f0000000000000000
    type: commit
  author: patrickvonplaten
  created_at: 2022-05-25 19:29:19+00:00
  id: 628e919f0000000000000000
  oid: 7604530e940d92339c2880819a7385e704d60c5d
  summary: Update tokenizer_config.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2022-05-25T21:30:57.000Z'
    data:
      status: merged
    id: 628ea011e0994038b5f52ef1
    type: status-change
  author: pszemraj
  created_at: 2022-05-25 20:30:57+00:00
  id: 628ea011e0994038b5f52ef1
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 4d2f863decf14ae1c0153bbe3c3412f0ccce735a
num: 1
repo_id: pszemraj/opt-peter-1.3B
repo_type: model
status: merged
target_branch: refs/heads/main
title: Update tokenizer_config.json
