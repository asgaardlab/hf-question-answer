!!python/object:huggingface_hub.community.DiscussionWithDetails
author: moona99
conflicting_files: null
created_at: 2023-12-16 13:10:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9076779a93e080ff0d636a83f4793a0a.svg
      fullname: moon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: moona99
      type: user
    createdAt: '2023-12-16T13:10:21.000Z'
    data:
      edited: false
      editors:
      - moona99
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9418869018554688
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9076779a93e080ff0d636a83f4793a0a.svg
          fullname: moon
          isHf: false
          isPro: false
          name: moona99
          type: user
        html: '<p>I know its kind of out of area for this but Im kind of roaming around
          trying to figure out if I did something wrong or if I just need to wait
          for Ooga to catch up (even though it supposed to have the necessary changes
          in Llama) and I don''t mind waiting for it to catch up</p>

          <p>I get the exact same messages on loading as I would if there were no
          GGUF file at all</p>

          <p>l_menu.py", line 209, in load_model_wrapper<br>    shared.model, shared.tokenizer
          = load_model(selected_model, loader)</p>

          <p>I can reproduce the same error if I try to load from an empty folder
          in Ooga</p>

          <p>Final fun...Im running this on a Mac</p>

          '
        raw: "I know its kind of out of area for this but Im kind of roaming around\
          \ trying to figure out if I did something wrong or if I just need to wait\
          \ for Ooga to catch up (even though it supposed to have the necessary changes\
          \ in Llama) and I don't mind waiting for it to catch up\r\n\r\nI get the\
          \ exact same messages on loading as I would if there were no GGUF file at\
          \ all\r\n\r\nl_menu.py\", line 209, in load_model_wrapper\r\n    shared.model,\
          \ shared.tokenizer = load_model(selected_model, loader)\r\n            \
          \  \r\nI can reproduce the same error if I try to load from an empty folder\
          \ in Ooga\r\n\r\nFinal fun...Im running this on a Mac\r\n"
        updatedAt: '2023-12-16T13:10:21.197Z'
      numEdits: 0
      reactions: []
    id: 657da1bda982e9093f637fd0
    type: comment
  author: moona99
  content: "I know its kind of out of area for this but Im kind of roaming around\
    \ trying to figure out if I did something wrong or if I just need to wait for\
    \ Ooga to catch up (even though it supposed to have the necessary changes in Llama)\
    \ and I don't mind waiting for it to catch up\r\n\r\nI get the exact same messages\
    \ on loading as I would if there were no GGUF file at all\r\n\r\nl_menu.py\",\
    \ line 209, in load_model_wrapper\r\n    shared.model, shared.tokenizer = load_model(selected_model,\
    \ loader)\r\n              \r\nI can reproduce the same error if I try to load\
    \ from an empty folder in Ooga\r\n\r\nFinal fun...Im running this on a Mac\r\n"
  created_at: 2023-12-16 13:10:21+00:00
  edited: false
  hidden: false
  id: 657da1bda982e9093f637fd0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-12-16T14:17:07.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9664374589920044
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<blockquote>

          <p>I can reproduce the same error if I try to load from an empty folder
          in Ooga</p>

          </blockquote>

          <p>Looks like latest is broke, its hosed for me too, for any model at this
          point.  And i didnt back up what i had ....</p>

          '
        raw: "               \n> I can reproduce the same error if I try to load from\
          \ an empty folder in Ooga\n\nLooks like latest is broke, its hosed for me\
          \ too, for any model at this point.  And i didnt back up what i had ...."
        updatedAt: '2023-12-16T14:17:07.663Z'
      numEdits: 0
      reactions: []
    id: 657db163efc0f84bcb5fba82
    type: comment
  author: Nurb432
  content: "               \n> I can reproduce the same error if I try to load from\
    \ an empty folder in Ooga\n\nLooks like latest is broke, its hosed for me too,\
    \ for any model at this point.  And i didnt back up what i had ...."
  created_at: 2023-12-16 14:17:07+00:00
  edited: false
  hidden: false
  id: 657db163efc0f84bcb5fba82
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9076779a93e080ff0d636a83f4793a0a.svg
      fullname: moon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: moona99
      type: user
    createdAt: '2023-12-16T16:48:42.000Z'
    data:
      edited: false
      editors:
      - moona99
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8983938694000244
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9076779a93e080ff0d636a83f4793a0a.svg
          fullname: moon
          isHf: false
          isPro: false
          name: moona99
          type: user
        html: '<p>booo! lame.  Mine works with other models tho</p>

          '
        raw: 'booo! lame.  Mine works with other models tho

          '
        updatedAt: '2023-12-16T16:48:42.009Z'
      numEdits: 0
      reactions: []
    id: 657dd4ead70b7308f361d0bd
    type: comment
  author: moona99
  content: 'booo! lame.  Mine works with other models tho

    '
  created_at: 2023-12-16 16:48:42+00:00
  edited: false
  hidden: false
  id: 657dd4ead70b7308f361d0bd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-12-16T17:14:05.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9876365661621094
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<blockquote>

          <p>booo! lame.  Mine works with other models tho</p>

          </blockquote>

          <p>I had to roll back to previous build from github to get it to work at
          all for me.  ( by hand, since as i mentioned above, i didnt bother to backup
          this time...doh )</p>

          '
        raw: '> booo! lame.  Mine works with other models tho


          I had to roll back to previous build from github to get it to work at all
          for me.  ( by hand, since as i mentioned above, i didnt bother to backup
          this time...doh )'
        updatedAt: '2023-12-16T17:14:05.537Z'
      numEdits: 0
      reactions: []
    id: 657ddadd17f67d5b87b5b1e8
    type: comment
  author: Nurb432
  content: '> booo! lame.  Mine works with other models tho


    I had to roll back to previous build from github to get it to work at all for
    me.  ( by hand, since as i mentioned above, i didnt bother to backup this time...doh
    )'
  created_at: 2023-12-16 17:14:05+00:00
  edited: false
  hidden: false
  id: 657ddadd17f67d5b87b5b1e8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: TheBloke/Mixtral-8x7B-v0.1-GGUF
repo_type: model
status: open
target_branch: null
title: Weird. Ooga is still not loading after a fresh pull from release.
