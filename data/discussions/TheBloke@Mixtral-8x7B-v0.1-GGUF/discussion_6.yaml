!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BigDeeper
conflicting_files: null
created_at: 2023-12-11 22:42:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ace4395d175d9c1d3d11f191c3709b0.svg
      fullname: Big Deeper
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BigDeeper
      type: user
    createdAt: '2023-12-11T22:42:00.000Z'
    data:
      edited: false
      editors:
      - BigDeeper
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.463739275932312
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ace4395d175d9c1d3d11f191c3709b0.svg
          fullname: Big Deeper
          isHf: false
          isPro: false
          name: BigDeeper
          type: user
        html: "<p>llm_load_print_meta: model params     = 46.70 B<br>llm_load_print_meta:\
          \ model size       = 35.74 GiB (6.57 BPW)<br>llm_load_print_meta: general.name\
          \   = mistralai_mixtral-8x7b-v0.1<br>llm_load_print_meta: BOS token = 1\
          \ '<s>'<br>llm_load_print_meta: EOS token = 2 '</s>'<br>llm_load_print_meta:\
          \ UNK token = 0 ''<br>llm_load_print_meta: PAD token = 0 ''<br>llm_load_print_meta:\
          \ LF token  = 13 '&lt;0x0A&gt;'<br>llm_load_tensors: ggml ctx size =   \
          \ 0.33 MB<br>error loading model: create_tensor: tensor 'blk.0.ffn_gate.weight'\
          \ not found<br>llama_load_model_from_file: failed to load model<br>{\"timestamp\"\
          :1702334382,\"level\":\"ERROR\",\"function\":\"loadModel\",\"line\":267,\"\
          message\":\"unable to load model\",\"model\":\"/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc\"\
          }<br>llama_init_from_gpt_params: error: failed to load model '/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc'<br>\u2819\
          \ 2023/12/11 17:39:42 llama.go:435: failed to load model '/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc'<br>2023/12/11\
          \ 17:39:42 llama.go:443: error starting llama runner: llama runner process\
          \ has terminated<br>2023/12/11 17:39:42 llama.go:509: llama runner stopped\
          \ successfully<br>[GIN] 2023/12/11 - 17:39:42 | 500 |  3.101114238s |  \
          \     127.0.0.1 | POST     \"/api/generate\"<br>Error: llama runner: failed\
          \ to load model '/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc':\
          \ this model may be incompatible with your version of Ollama. If you previously\
          \ pulled this model, try updating it by running <code>ollama pull mixtral-8x7b-v0.1.Q6_K:latest</code><br>(AutoGen)\
          \ developer@ai:~/PROJECTS/autogen$</p>\n"
        raw: "llm_load_print_meta: model params     = 46.70 B\r\nllm_load_print_meta:\
          \ model size       = 35.74 GiB (6.57 BPW)\r\nllm_load_print_meta: general.name\
          \   = mistralai_mixtral-8x7b-v0.1\r\nllm_load_print_meta: BOS token = 1\
          \ '<s>'\r\nllm_load_print_meta: EOS token = 2 '</s>'\r\nllm_load_print_meta:\
          \ UNK token = 0 '<unk>'\r\nllm_load_print_meta: PAD token = 0 '<unk>'\r\n\
          llm_load_print_meta: LF token  = 13 '<0x0A>'\r\nllm_load_tensors: ggml ctx\
          \ size =    0.33 MB\r\nerror loading model: create_tensor: tensor 'blk.0.ffn_gate.weight'\
          \ not found\r\nllama_load_model_from_file: failed to load model\r\n{\"timestamp\"\
          :1702334382,\"level\":\"ERROR\",\"function\":\"loadModel\",\"line\":267,\"\
          message\":\"unable to load model\",\"model\":\"/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc\"\
          }\r\nllama_init_from_gpt_params: error: failed to load model '/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc'\r\
          \n\u2819 2023/12/11 17:39:42 llama.go:435: failed to load model '/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc'\r\
          \n2023/12/11 17:39:42 llama.go:443: error starting llama runner: llama runner\
          \ process has terminated\r\n2023/12/11 17:39:42 llama.go:509: llama runner\
          \ stopped successfully\r\n[GIN] 2023/12/11 - 17:39:42 | 500 |  3.101114238s\
          \ |       127.0.0.1 | POST     \"/api/generate\"\r\nError: llama runner:\
          \ failed to load model '/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc':\
          \ this model may be incompatible with your version of Ollama. If you previously\
          \ pulled this model, try updating it by running `ollama pull mixtral-8x7b-v0.1.Q6_K:latest`\r\
          \n(AutoGen) developer@ai:~/PROJECTS/autogen$\r\n"
        updatedAt: '2023-12-11T22:42:00.004Z'
      numEdits: 0
      reactions: []
    id: 65779038ee33d547aeaf1dfe
    type: comment
  author: BigDeeper
  content: "llm_load_print_meta: model params     = 46.70 B\r\nllm_load_print_meta:\
    \ model size       = 35.74 GiB (6.57 BPW)\r\nllm_load_print_meta: general.name\
    \   = mistralai_mixtral-8x7b-v0.1\r\nllm_load_print_meta: BOS token = 1 '<s>'\r\
    \nllm_load_print_meta: EOS token = 2 '</s>'\r\nllm_load_print_meta: UNK token\
    \ = 0 '<unk>'\r\nllm_load_print_meta: PAD token = 0 '<unk>'\r\nllm_load_print_meta:\
    \ LF token  = 13 '<0x0A>'\r\nllm_load_tensors: ggml ctx size =    0.33 MB\r\n\
    error loading model: create_tensor: tensor 'blk.0.ffn_gate.weight' not found\r\
    \nllama_load_model_from_file: failed to load model\r\n{\"timestamp\":1702334382,\"\
    level\":\"ERROR\",\"function\":\"loadModel\",\"line\":267,\"message\":\"unable\
    \ to load model\",\"model\":\"/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc\"\
    }\r\nllama_init_from_gpt_params: error: failed to load model '/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc'\r\
    \n\u2819 2023/12/11 17:39:42 llama.go:435: failed to load model '/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc'\r\
    \n2023/12/11 17:39:42 llama.go:443: error starting llama runner: llama runner\
    \ process has terminated\r\n2023/12/11 17:39:42 llama.go:509: llama runner stopped\
    \ successfully\r\n[GIN] 2023/12/11 - 17:39:42 | 500 |  3.101114238s |       127.0.0.1\
    \ | POST     \"/api/generate\"\r\nError: llama runner: failed to load model '/home/developer/.ollama/models/blobs/sha256:366dec12b8823603f23c549f438ee444df868f32ec8a64b60dfeae026860d3fc':\
    \ this model may be incompatible with your version of Ollama. If you previously\
    \ pulled this model, try updating it by running `ollama pull mixtral-8x7b-v0.1.Q6_K:latest`\r\
    \n(AutoGen) developer@ai:~/PROJECTS/autogen$\r\n"
  created_at: 2023-12-11 22:42:00+00:00
  edited: false
  hidden: false
  id: 65779038ee33d547aeaf1dfe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/00154d9a3f901567f25b432f3f04e6e2.svg
      fullname: Hans Schmidt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: supportend
      type: user
    createdAt: '2023-12-11T23:11:21.000Z'
    data:
      edited: false
      editors:
      - supportend
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5077853202819824
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/00154d9a3f901567f25b432f3f04e6e2.svg
          fullname: Hans Schmidt
          isHf: false
          isPro: false
          name: supportend
          type: user
        html: '<p>Do you use this:</p>

          <p><a rel="nofollow" href="https://github.com/jmorganca/ollama/pull/1475">https://github.com/jmorganca/ollama/pull/1475</a></p>

          '
        raw: 'Do you use this:


          https://github.com/jmorganca/ollama/pull/1475'
        updatedAt: '2023-12-11T23:11:21.200Z'
      numEdits: 0
      reactions: []
    id: 65779719353869cd6ede9619
    type: comment
  author: supportend
  content: 'Do you use this:


    https://github.com/jmorganca/ollama/pull/1475'
  created_at: 2023-12-11 23:11:21+00:00
  edited: false
  hidden: false
  id: 65779719353869cd6ede9619
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ace4395d175d9c1d3d11f191c3709b0.svg
      fullname: Big Deeper
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BigDeeper
      type: user
    createdAt: '2023-12-11T23:59:43.000Z'
    data:
      edited: false
      editors:
      - BigDeeper
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7601355910301208
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ace4395d175d9c1d3d11f191c3709b0.svg
          fullname: Big Deeper
          isHf: false
          isPro: false
          name: BigDeeper
          type: user
        html: "<blockquote>\n<p>Do you use this:</p>\n<p><a rel=\"nofollow\" href=\"\
          https://github.com/jmorganca/ollama/pull/1475\">https://github.com/jmorganca/ollama/pull/1475</a></p>\n\
          </blockquote>\n<p>So this fixed the problem above,  but it is back to a\
          \ different problem which I previously had solved by downgrading to 0.1.11.\
          \ Despite what the error message says, 48GiB is available to load 40GiB</p>\n\
          <p>2023/12/11 18:55:11 llama.go:506: llama runner started in 19.200715 seconds<br>[GIN]\
          \ 2023/12/11 - 18:55:11 | 200 | 20.089032212s |       127.0.0.1 | POST \
          \    \"/api/generate\"</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>What\
          \ is your name?<br>{\"timestamp\":1702338954,\"level\":\"INFO\",\"function\"\
          :\"log_server_request\",\"line\":2596,\"message\":\"request\",\"remote_addr\"\
          :\"127.0.0.1\",\"remote_port\":42538,\"status\":200,\"method\":\"HEAD\"\
          ,\"path\":\"/\",\"params\":{}}</p>\n</blockquote>\n</blockquote>\n</blockquote>\n\
          <p>cuBLAS error 15 at /home/developer/ollama/llm/llama.cpp/gguf/ggml-cuda.cu:8049<br>current\
          \ device: 0<br>GGML_ASSERT: /home/developer/ollama/llm/llama.cpp/gguf/ggml-cuda.cu:8049:\
          \ !\"cuBLAS error\"<br>memory allocation/deallocation mismatch at 0x55fa312d0a20:\
          \ allocated with malloc being deallocated with delete<br>\u283C 2023/12/11\
          \ 18:55:56 llama.go:449: signal: aborted (core dumped)<br>2023/12/11 18:55:56\
          \ llama.go:523: llama runner stopped successfully<br>[GIN] 2023/12/11 -\
          \ 18:55:56 | 200 |  2.416814444s |       127.0.0.1 | POST     \"/api/generate\"\
          <br>Error: llama runner exited, you may not have enough available memory\
          \ to run this model</p>\n"
        raw: "> Do you use this:\n> \n> https://github.com/jmorganca/ollama/pull/1475\n\
          \nSo this fixed the problem above,  but it is back to a different problem\
          \ which I previously had solved by downgrading to 0.1.11. Despite what the\
          \ error message says, 48GiB is available to load 40GiB\n\n2023/12/11 18:55:11\
          \ llama.go:506: llama runner started in 19.200715 seconds\n[GIN] 2023/12/11\
          \ - 18:55:11 | 200 | 20.089032212s |       127.0.0.1 | POST     \"/api/generate\"\
          \n>>> What is your name?\n{\"timestamp\":1702338954,\"level\":\"INFO\",\"\
          function\":\"log_server_request\",\"line\":2596,\"message\":\"request\"\
          ,\"remote_addr\":\"127.0.0.1\",\"remote_port\":42538,\"status\":200,\"method\"\
          :\"HEAD\",\"path\":\"/\",\"params\":{}}\n\ncuBLAS error 15 at /home/developer/ollama/llm/llama.cpp/gguf/ggml-cuda.cu:8049\n\
          current device: 0\nGGML_ASSERT: /home/developer/ollama/llm/llama.cpp/gguf/ggml-cuda.cu:8049:\
          \ !\"cuBLAS error\"\nmemory allocation/deallocation mismatch at 0x55fa312d0a20:\
          \ allocated with malloc being deallocated with delete\n\u283C 2023/12/11\
          \ 18:55:56 llama.go:449: signal: aborted (core dumped)\n2023/12/11 18:55:56\
          \ llama.go:523: llama runner stopped successfully\n[GIN] 2023/12/11 - 18:55:56\
          \ | 200 |  2.416814444s |       127.0.0.1 | POST     \"/api/generate\"\n\
          Error: llama runner exited, you may not have enough available memory to\
          \ run this model\n"
        updatedAt: '2023-12-11T23:59:43.963Z'
      numEdits: 0
      reactions: []
    id: 6577a26f277dceb60555d034
    type: comment
  author: BigDeeper
  content: "> Do you use this:\n> \n> https://github.com/jmorganca/ollama/pull/1475\n\
    \nSo this fixed the problem above,  but it is back to a different problem which\
    \ I previously had solved by downgrading to 0.1.11. Despite what the error message\
    \ says, 48GiB is available to load 40GiB\n\n2023/12/11 18:55:11 llama.go:506:\
    \ llama runner started in 19.200715 seconds\n[GIN] 2023/12/11 - 18:55:11 | 200\
    \ | 20.089032212s |       127.0.0.1 | POST     \"/api/generate\"\n>>> What is\
    \ your name?\n{\"timestamp\":1702338954,\"level\":\"INFO\",\"function\":\"log_server_request\"\
    ,\"line\":2596,\"message\":\"request\",\"remote_addr\":\"127.0.0.1\",\"remote_port\"\
    :42538,\"status\":200,\"method\":\"HEAD\",\"path\":\"/\",\"params\":{}}\n\ncuBLAS\
    \ error 15 at /home/developer/ollama/llm/llama.cpp/gguf/ggml-cuda.cu:8049\ncurrent\
    \ device: 0\nGGML_ASSERT: /home/developer/ollama/llm/llama.cpp/gguf/ggml-cuda.cu:8049:\
    \ !\"cuBLAS error\"\nmemory allocation/deallocation mismatch at 0x55fa312d0a20:\
    \ allocated with malloc being deallocated with delete\n\u283C 2023/12/11 18:55:56\
    \ llama.go:449: signal: aborted (core dumped)\n2023/12/11 18:55:56 llama.go:523:\
    \ llama runner stopped successfully\n[GIN] 2023/12/11 - 18:55:56 | 200 |  2.416814444s\
    \ |       127.0.0.1 | POST     \"/api/generate\"\nError: llama runner exited,\
    \ you may not have enough available memory to run this model\n"
  created_at: 2023-12-11 23:59:43+00:00
  edited: false
  hidden: false
  id: 6577a26f277dceb60555d034
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TheBloke/Mixtral-8x7B-v0.1-GGUF
repo_type: model
status: open
target_branch: null
title: Not finding  blk.0.ffn_gate.weight. I checked sha256sum, matches the Q6_K version.
  Any thoughts on how to fix this?
