!!python/object:huggingface_hub.community.DiscussionWithDetails
author: artificialgenerations4gsdfg
conflicting_files: null
created_at: 2023-08-12 19:38:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7ddca2b56096411db44768195289aa0d.svg
      fullname: ai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: artificialgenerations4gsdfg
      type: user
    createdAt: '2023-08-12T20:38:42.000Z'
    data:
      edited: false
      editors:
      - artificialgenerations4gsdfg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9356719851493835
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7ddca2b56096411db44768195289aa0d.svg
          fullname: ai
          isHf: false
          isPro: false
          name: artificialgenerations4gsdfg
          type: user
        html: '<p>You rank top of the MTEB for STS tasks (nice work, thank you!) so
          I wanted to see if I could improve a current usecase we have for document
          search, and finding relevant passages. But I noticed that locally, any two
          embeddings share an cos_sim of 0.75 or more! I would expect two random sentences
          to be roughly orthogonal in embedding space so I though I was doing something
          wrong.</p>

          <p>But alas, playing with the HF space <a href="https://huggingface.co/spaces/aruntruminds/thenlper-gte-large">https://huggingface.co/spaces/aruntruminds/thenlper-gte-large</a>
          I noticed the same results. </p>

          <p>Ex:</p>

          <pre><code>Query: The person tells there name.


          | Sim  | Sentences                      |

          |:-----|--------------------------------|

          | 0.84 | My name is Edward.             |

          | 0.89 | What is your name?             |

          | 0.79 | rvjxme eogh38ahjf eogaljg ads. |

          </code></pre>

          <p>What could be going wrong? I''ve actually noticed this behavior in other
          embedding models as well, and I have never seen an model give a negative
          similarity score, which is also counterintuitive since two sentences could
          actually be semantically opposite.</p>

          <p>A little guidance on improving accuracy please?</p>

          '
        raw: "You rank top of the MTEB for STS tasks (nice work, thank you!) so I\
          \ wanted to see if I could improve a current usecase we have for document\
          \ search, and finding relevant passages. But I noticed that locally, any\
          \ two embeddings share an cos_sim of 0.75 or more! I would expect two random\
          \ sentences to be roughly orthogonal in embedding space so I though I was\
          \ doing something wrong.\r\n\r\nBut alas, playing with the HF space https://huggingface.co/spaces/aruntruminds/thenlper-gte-large\
          \ I noticed the same results. \r\n\r\nEx:\r\n\r\n```\r\nQuery: The person\
          \ tells there name.\r\n\r\n| Sim  | Sentences                      |\r\n\
          |:-----|--------------------------------|\r\n| 0.84 | My name is Edward.\
          \             |\r\n| 0.89 | What is your name?             |\r\n| 0.79 |\
          \ rvjxme eogh38ahjf eogaljg ads. |\r\n```\r\n\r\nWhat could be going wrong?\
          \ I've actually noticed this behavior in other embedding models as well,\
          \ and I have never seen an model give a negative similarity score, which\
          \ is also counterintuitive since two sentences could actually be semantically\
          \ opposite.\r\n\r\nA little guidance on improving accuracy please?"
        updatedAt: '2023-08-12T20:38:42.870Z'
      numEdits: 0
      reactions: []
    id: 64d7edd21a81ece17db570c1
    type: comment
  author: artificialgenerations4gsdfg
  content: "You rank top of the MTEB for STS tasks (nice work, thank you!) so I wanted\
    \ to see if I could improve a current usecase we have for document search, and\
    \ finding relevant passages. But I noticed that locally, any two embeddings share\
    \ an cos_sim of 0.75 or more! I would expect two random sentences to be roughly\
    \ orthogonal in embedding space so I though I was doing something wrong.\r\n\r\
    \nBut alas, playing with the HF space https://huggingface.co/spaces/aruntruminds/thenlper-gte-large\
    \ I noticed the same results. \r\n\r\nEx:\r\n\r\n```\r\nQuery: The person tells\
    \ there name.\r\n\r\n| Sim  | Sentences                      |\r\n|:-----|--------------------------------|\r\
    \n| 0.84 | My name is Edward.             |\r\n| 0.89 | What is your name?   \
    \          |\r\n| 0.79 | rvjxme eogh38ahjf eogaljg ads. |\r\n```\r\n\r\nWhat could\
    \ be going wrong? I've actually noticed this behavior in other embedding models\
    \ as well, and I have never seen an model give a negative similarity score, which\
    \ is also counterintuitive since two sentences could actually be semantically\
    \ opposite.\r\n\r\nA little guidance on improving accuracy please?"
  created_at: 2023-08-12 19:38:42+00:00
  edited: false
  hidden: false
  id: 64d7edd21a81ece17db570c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/592327d094bf6815bcea9c4788228c34.svg
      fullname: Matthew Walker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mattgwwalker
      type: user
    createdAt: '2023-08-16T04:33:39.000Z'
    data:
      edited: false
      editors:
      - mattgwwalker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9962588548660278
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/592327d094bf6815bcea9c4788228c34.svg
          fullname: Matthew Walker
          isHf: false
          isPro: false
          name: mattgwwalker
          type: user
        html: '<p>I''ve had very good success with this model on retrieval tasks,
          so I''d didn''t initially believe you.  I was very surprised to reproduce
          your example and get the same results.  I too would be interested hear more.</p>

          '
        raw: I've had very good success with this model on retrieval tasks, so I'd
          didn't initially believe you.  I was very surprised to reproduce your example
          and get the same results.  I too would be interested hear more.
        updatedAt: '2023-08-16T04:33:39.691Z'
      numEdits: 0
      reactions: []
    id: 64dc51a30fd0857facb057ae
    type: comment
  author: mattgwwalker
  content: I've had very good success with this model on retrieval tasks, so I'd didn't
    initially believe you.  I was very surprised to reproduce your example and get
    the same results.  I too would be interested hear more.
  created_at: 2023-08-16 03:33:39+00:00
  edited: false
  hidden: false
  id: 64dc51a30fd0857facb057ae
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7ddca2b56096411db44768195289aa0d.svg
      fullname: ai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: artificialgenerations4gsdfg
      type: user
    createdAt: '2023-08-18T20:13:40.000Z'
    data:
      edited: false
      editors:
      - artificialgenerations4gsdfg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9757341146469116
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7ddca2b56096411db44768195289aa0d.svg
          fullname: ai
          isHf: false
          isPro: false
          name: artificialgenerations4gsdfg
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mattgwwalker&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/mattgwwalker\"\
          >@<span class=\"underline\">mattgwwalker</span></a></span>\n\n\t</span></span>\
          \ It makes me wonder if they were biased in their training of positive and\
          \ orthogonal (and negative) examples. Ideally, at the same time you train\
          \ similarity detection, you've gotta be training dissimilarity too (or so\
          \ one would think). And if your using cosine sim in the score, I should\
          \ think you'd generate large gradients if orthogonal sentences were rated\
          \ at <code>0.79</code>, when it should have been <code>0</code>.</p>\n<p>I\
          \ haven't found a model that <em>doesn't</em> behave this way though, so,\
          \ I must be missing something.</p>\n"
        raw: '@mattgwwalker It makes me wonder if they were biased in their training
          of positive and orthogonal (and negative) examples. Ideally, at the same
          time you train similarity detection, you''ve gotta be training dissimilarity
          too (or so one would think). And if your using cosine sim in the score,
          I should think you''d generate large gradients if orthogonal sentences were
          rated at `0.79`, when it should have been `0`.


          I haven''t found a model that *doesn''t* behave this way though, so, I must
          be missing something.'
        updatedAt: '2023-08-18T20:13:40.438Z'
      numEdits: 0
      reactions: []
    id: 64dfd0f4e8b6f3f3baaa0157
    type: comment
  author: artificialgenerations4gsdfg
  content: '@mattgwwalker It makes me wonder if they were biased in their training
    of positive and orthogonal (and negative) examples. Ideally, at the same time
    you train similarity detection, you''ve gotta be training dissimilarity too (or
    so one would think). And if your using cosine sim in the score, I should think
    you''d generate large gradients if orthogonal sentences were rated at `0.79`,
    when it should have been `0`.


    I haven''t found a model that *doesn''t* behave this way though, so, I must be
    missing something.'
  created_at: 2023-08-18 19:13:40+00:00
  edited: false
  hidden: false
  id: 64dfd0f4e8b6f3f3baaa0157
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf5c04a6032709f35e3fb48e1be6976f.svg
      fullname: Dingkun Long
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: thenlper
      type: user
    createdAt: '2023-08-19T08:29:48.000Z'
    data:
      edited: false
      editors:
      - thenlper
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9097822904586792
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf5c04a6032709f35e3fb48e1be6976f.svg
          fullname: Dingkun Long
          isHf: false
          isPro: false
          name: thenlper
          type: user
        html: '<p>The embedding model is trained based on the training objective of
          contrastive learning. The scores provided by the model focus on distinguishing
          the partial order relationship between relevant and irrelevant documents,
          and cannot be used as a strong reference for determining relevance. Other
          models offer more detailed discussions on this matter, which can be referred
          to</p>

          <p><a href="https://huggingface.co/intfloat/multilingual-e5-large/discussions/10#64ca669c38837b12d5eed6a4">https://huggingface.co/intfloat/multilingual-e5-large/discussions/10#64ca669c38837b12d5eed6a4</a></p>

          '
        raw: 'The embedding model is trained based on the training objective of contrastive
          learning. The scores provided by the model focus on distinguishing the partial
          order relationship between relevant and irrelevant documents, and cannot
          be used as a strong reference for determining relevance. Other models offer
          more detailed discussions on this matter, which can be referred to


          https://huggingface.co/intfloat/multilingual-e5-large/discussions/10#64ca669c38837b12d5eed6a4'
        updatedAt: '2023-08-19T08:29:48.457Z'
      numEdits: 0
      reactions: []
    id: 64e07d7c4ad03fafdb6d7461
    type: comment
  author: thenlper
  content: 'The embedding model is trained based on the training objective of contrastive
    learning. The scores provided by the model focus on distinguishing the partial
    order relationship between relevant and irrelevant documents, and cannot be used
    as a strong reference for determining relevance. Other models offer more detailed
    discussions on this matter, which can be referred to


    https://huggingface.co/intfloat/multilingual-e5-large/discussions/10#64ca669c38837b12d5eed6a4'
  created_at: 2023-08-19 07:29:48+00:00
  edited: false
  hidden: false
  id: 64e07d7c4ad03fafdb6d7461
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a1452c231299b3b10f98fb7956a0244b.svg
      fullname: Muthukumaran N M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mechanicmuthu
      type: user
    createdAt: '2023-08-24T15:20:20.000Z'
    data:
      edited: false
      editors:
      - mechanicmuthu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9899740815162659
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a1452c231299b3b10f98fb7956a0244b.svg
          fullname: Muthukumaran N M
          isHf: false
          isPro: false
          name: mechanicmuthu
          type: user
        html: '<p>Since both are English, the similarity is still high, what say?</p>

          '
        raw: Since both are English, the similarity is still high, what say?
        updatedAt: '2023-08-24T15:20:20.216Z'
      numEdits: 0
      reactions: []
    id: 64e77534ee144dc4eb0c0cd2
    type: comment
  author: mechanicmuthu
  content: Since both are English, the similarity is still high, what say?
  created_at: 2023-08-24 14:20:20+00:00
  edited: false
  hidden: false
  id: 64e77534ee144dc4eb0c0cd2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2a3bf0ab46b41e024fea0861c61d042d.svg
      fullname: blaze spinnaker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: blazespinnaker
      type: user
    createdAt: '2023-09-10T06:52:44.000Z'
    data:
      edited: false
      editors:
      - blazespinnaker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9302140474319458
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2a3bf0ab46b41e024fea0861c61d042d.svg
          fullname: blaze spinnaker
          isHf: false
          isPro: false
          name: blazespinnaker
          type: user
        html: '<blockquote>

          <p>The embedding model is trained based on the training objective of contrastive
          learning. The scores provided by the model focus on distinguishing the partial
          order relationship between relevant and irrelevant documents, and cannot
          be used as a strong reference for determining relevance. Other models offer
          more detailed discussions on this matter, which can be referred to</p>

          <p><a href="https://huggingface.co/intfloat/multilingual-e5-large/discussions/10#64ca669c38837b12d5eed6a4">https://huggingface.co/intfloat/multilingual-e5-large/discussions/10#64ca669c38837b12d5eed6a4</a></p>

          </blockquote>

          <p>I''m not sure I understand this.  How does it both distinguish the partial
          order relationship between relevant and irrelevant documents and not provide
          a reference for determining relevance?  Can''t we just do probability calibration?</p>

          <p>Anyways, it seems to work well, afaict.</p>

          '
        raw: "> The embedding model is trained based on the training objective of\
          \ contrastive learning. The scores provided by the model focus on distinguishing\
          \ the partial order relationship between relevant and irrelevant documents,\
          \ and cannot be used as a strong reference for determining relevance. Other\
          \ models offer more detailed discussions on this matter, which can be referred\
          \ to\n> \n> https://huggingface.co/intfloat/multilingual-e5-large/discussions/10#64ca669c38837b12d5eed6a4\n\
          \nI'm not sure I understand this.  How does it both distinguish the partial\
          \ order relationship between relevant and irrelevant documents and not provide\
          \ a reference for determining relevance?  Can't we just do probability calibration?\n\
          \nAnyways, it seems to work well, afaict."
        updatedAt: '2023-09-10T06:52:44.360Z'
      numEdits: 0
      reactions: []
    id: 64fd67bc20a2d04cc1c2641e
    type: comment
  author: blazespinnaker
  content: "> The embedding model is trained based on the training objective of contrastive\
    \ learning. The scores provided by the model focus on distinguishing the partial\
    \ order relationship between relevant and irrelevant documents, and cannot be\
    \ used as a strong reference for determining relevance. Other models offer more\
    \ detailed discussions on this matter, which can be referred to\n> \n> https://huggingface.co/intfloat/multilingual-e5-large/discussions/10#64ca669c38837b12d5eed6a4\n\
    \nI'm not sure I understand this.  How does it both distinguish the partial order\
    \ relationship between relevant and irrelevant documents and not provide a reference\
    \ for determining relevance?  Can't we just do probability calibration?\n\nAnyways,\
    \ it seems to work well, afaict."
  created_at: 2023-09-10 05:52:44+00:00
  edited: false
  hidden: false
  id: 64fd67bc20a2d04cc1c2641e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/bf5c04a6032709f35e3fb48e1be6976f.svg
      fullname: Dingkun Long
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: thenlper
      type: user
    createdAt: '2023-12-21T13:59:49.000Z'
    data:
      status: closed
    id: 658444d58d32c176005a0b07
    type: status-change
  author: thenlper
  created_at: 2023-12-21 13:59:49+00:00
  id: 658444d58d32c176005a0b07
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: thenlper/gte-large
repo_type: model
status: closed
target_branch: null
title: Cosine Similarity is always HIGH
