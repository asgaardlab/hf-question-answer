!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ivisone
conflicting_files: null
created_at: 2023-01-28 02:08:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c3793868d6eb473f210d0c40f955cf8f.svg
      fullname: ivis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ivisone
      type: user
    createdAt: '2023-01-28T02:08:01.000Z'
    data:
      edited: false
      editors:
      - Ivisone
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c3793868d6eb473f210d0c40f955cf8f.svg
          fullname: ivis
          isHf: false
          isPro: false
          name: Ivisone
          type: user
        html: '<p>RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU
          0; 8.00 GiB total capacity; 7.21 GiB already allocated; 0 bytes free; 7.35
          GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated
          memory try setting max_split_size_mb to avoid fragmentation.  See documentation
          for Memory Management and PYTORCH_CUDA_ALLOC_CONF</p>

          <p>What can I do?</p>

          '
        raw: "RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0;\
          \ 8.00 GiB total capacity; 7.21 GiB already allocated; 0 bytes free; 7.35\
          \ GiB reserved in total by PyTorch) If reserved memory is >> allocated memory\
          \ try setting max_split_size_mb to avoid fragmentation.  See documentation\
          \ for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\n\r\nWhat can I do?"
        updatedAt: '2023-01-28T02:08:01.965Z'
      numEdits: 0
      reactions: []
    id: 63d48381df01ef426a0d491e
    type: comment
  author: Ivisone
  content: "RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 8.00\
    \ GiB total capacity; 7.21 GiB already allocated; 0 bytes free; 7.35 GiB reserved\
    \ in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb\
    \ to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\
    \n\r\nWhat can I do?"
  created_at: 2023-01-28 02:08:01+00:00
  edited: false
  hidden: false
  id: 63d48381df01ef426a0d491e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
      fullname: steven slavik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hfsd
      type: user
    createdAt: '2023-01-28T04:23:19.000Z'
    data:
      edited: true
      editors:
      - hfsd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
          fullname: steven slavik
          isHf: false
          isPro: false
          name: hfsd
          type: user
        html: '<p>UPDATE SOLUTION TO MEMORY PROBLEM ON MY LAST POST BELOW</p>

          '
        raw: UPDATE SOLUTION TO MEMORY PROBLEM ON MY LAST POST BELOW
        updatedAt: '2023-01-28T05:14:59.901Z'
      numEdits: 4
      reactions: []
    id: 63d4a337ce1a38ea4eb3ead7
    type: comment
  author: hfsd
  content: UPDATE SOLUTION TO MEMORY PROBLEM ON MY LAST POST BELOW
  created_at: 2023-01-28 04:23:19+00:00
  edited: true
  hidden: false
  id: 63d4a337ce1a38ea4eb3ead7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/15a6f18c7f23496a5d0be029b28acc44.svg
      fullname: Dev
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Devel
      type: user
    createdAt: '2023-01-28T04:33:17.000Z'
    data:
      edited: false
      editors:
      - Devel
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/15a6f18c7f23496a5d0be029b28acc44.svg
          fullname: Dev
          isHf: false
          isPro: false
          name: Devel
          type: user
        html: '<p>Same. Getting CUDA error. I have 4 GB vram but I can run any models
          without problem. With this I get error. How to fix</p>

          '
        raw: Same. Getting CUDA error. I have 4 GB vram but I can run any models without
          problem. With this I get error. How to fix
        updatedAt: '2023-01-28T04:33:17.774Z'
      numEdits: 0
      reactions: []
    id: 63d4a58d2424c652f60415a3
    type: comment
  author: Devel
  content: Same. Getting CUDA error. I have 4 GB vram but I can run any models without
    problem. With this I get error. How to fix
  created_at: 2023-01-28 04:33:17+00:00
  edited: false
  hidden: false
  id: 63d4a58d2424c652f60415a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
      fullname: steven slavik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hfsd
      type: user
    createdAt: '2023-01-28T04:53:58.000Z'
    data:
      edited: true
      editors:
      - hfsd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
          fullname: steven slavik
          isHf: false
          isPro: false
          name: hfsd
          type: user
        html: '<p>UPDATE SOLUTION TO MEMORY PROBLEM ON MY LAST POST BELOW</p>

          '
        raw: UPDATE SOLUTION TO MEMORY PROBLEM ON MY LAST POST BELOW
        updatedAt: '2023-01-28T05:15:12.867Z'
      numEdits: 7
      reactions: []
    id: 63d4aa6685118edc044e28db
    type: comment
  author: hfsd
  content: UPDATE SOLUTION TO MEMORY PROBLEM ON MY LAST POST BELOW
  created_at: 2023-01-28 04:53:58+00:00
  edited: true
  hidden: false
  id: 63d4aa6685118edc044e28db
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
      fullname: steven slavik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hfsd
      type: user
    createdAt: '2023-01-28T05:10:39.000Z'
    data:
      edited: true
      editors:
      - hfsd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
          fullname: steven slavik
          isHf: false
          isPro: false
          name: hfsd
          type: user
        html: '<p>UPDATE AGAIN:</p>

          <p>Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem. Close and relaunch webui-user.bat after you edit
          the file.</p>

          '
        raw: 'UPDATE AGAIN:


          Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem. Close and relaunch webui-user.bat after you edit
          the file.'
        updatedAt: '2023-01-28T05:17:17.765Z'
      numEdits: 2
      reactions: []
    id: 63d4ae4f85118edc044e798d
    type: comment
  author: hfsd
  content: 'UPDATE AGAIN:


    Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems to fix
    the memory problem. Close and relaunch webui-user.bat after you edit the file.'
  created_at: 2023-01-28 05:10:39+00:00
  edited: true
  hidden: false
  id: 63d4ae4f85118edc044e798d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
      fullname: 'Votolato '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicv1990
      type: user
    createdAt: '2023-01-28T05:16:44.000Z'
    data:
      edited: false
      editors:
      - Nicv1990
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
          fullname: 'Votolato '
          isHf: false
          isPro: false
          name: Nicv1990
          type: user
        html: '<blockquote>

          <p>UPDATE AGAIN:</p>

          <p>Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem.</p>

          </blockquote>

          <p>how do write that exactly</p>

          '
        raw: "> UPDATE AGAIN:\n> \n> Removing \"--no-half\" from COMMANDLINE_ARGS=\
          \  in webui-user.bat file seems to fix the memory problem.\n\nhow do write\
          \ that exactly"
        updatedAt: '2023-01-28T05:16:44.864Z'
      numEdits: 0
      reactions: []
    id: 63d4afbc85118edc044e950c
    type: comment
  author: Nicv1990
  content: "> UPDATE AGAIN:\n> \n> Removing \"--no-half\" from COMMANDLINE_ARGS= \
    \ in webui-user.bat file seems to fix the memory problem.\n\nhow do write that\
    \ exactly"
  created_at: 2023-01-28 05:16:44+00:00
  edited: false
  hidden: false
  id: 63d4afbc85118edc044e950c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
      fullname: steven slavik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hfsd
      type: user
    createdAt: '2023-01-28T05:19:20.000Z'
    data:
      edited: true
      editors:
      - hfsd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
          fullname: steven slavik
          isHf: false
          isPro: false
          name: hfsd
          type: user
        html: '<blockquote>

          <blockquote>

          <p>UPDATE AGAIN:</p>

          <p>Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem.</p>

          </blockquote>

          <p>how do write that exactly</p>

          </blockquote>

          <p>find the file webui-user.bat in your stable diffusion root folder, edit
          it with notepad and remove the part that says: --no-half<br>save, close
          and relaunch it. It''s the same file you click to launch automatic1111</p>

          '
        raw: "> > UPDATE AGAIN:\n> > \n> > Removing \"--no-half\" from COMMANDLINE_ARGS=\
          \  in webui-user.bat file seems to fix the memory problem.\n> \n> how do\
          \ write that exactly\n\nfind the file webui-user.bat in your stable diffusion\
          \ root folder, edit it with notepad and remove the part that says: --no-half\n\
          save, close and relaunch it. It's the same file you click to launch automatic1111"
        updatedAt: '2023-01-28T05:19:38.537Z'
      numEdits: 1
      reactions: []
    id: 63d4b058ce1a38ea4eb4ee75
    type: comment
  author: hfsd
  content: "> > UPDATE AGAIN:\n> > \n> > Removing \"--no-half\" from COMMANDLINE_ARGS=\
    \  in webui-user.bat file seems to fix the memory problem.\n> \n> how do write\
    \ that exactly\n\nfind the file webui-user.bat in your stable diffusion root folder,\
    \ edit it with notepad and remove the part that says: --no-half\nsave, close and\
    \ relaunch it. It's the same file you click to launch automatic1111"
  created_at: 2023-01-28 05:19:20+00:00
  edited: true
  hidden: false
  id: 63d4b058ce1a38ea4eb4ee75
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
      fullname: 'Votolato '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicv1990
      type: user
    createdAt: '2023-01-28T05:23:54.000Z'
    data:
      edited: false
      editors:
      - Nicv1990
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
          fullname: 'Votolato '
          isHf: false
          isPro: false
          name: Nicv1990
          type: user
        html: '<p>how do you add this  "--no-half" to bat file how do you write it
          exactly</p>

          '
        raw: how do you add this  "--no-half" to bat file how do you write it exactly
        updatedAt: '2023-01-28T05:23:54.826Z'
      numEdits: 0
      reactions: []
    id: 63d4b16a85118edc044eb3d6
    type: comment
  author: Nicv1990
  content: how do you add this  "--no-half" to bat file how do you write it exactly
  created_at: 2023-01-28 05:23:54+00:00
  edited: false
  hidden: false
  id: 63d4b16a85118edc044eb3d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
      fullname: 'Votolato '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicv1990
      type: user
    createdAt: '2023-01-28T05:24:49.000Z'
    data:
      edited: false
      editors:
      - Nicv1990
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
          fullname: 'Votolato '
          isHf: false
          isPro: false
          name: Nicv1990
          type: user
        html: '<blockquote>

          <blockquote>

          <blockquote>

          <p>UPDATE AGAIN:</p>

          <p>Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem.</p>

          </blockquote>

          <p>how do write that exactly</p>

          </blockquote>

          <p>find the file webui-user.bat in your stable diffusion root folder, edit
          it with notepad and remove the part that says: --no-half<br>save, close
          and relaunch it. It''s the same file you click to launch automatic1111</p>

          </blockquote>

          <p>so you -- before no-half</p>

          '
        raw: "> > > UPDATE AGAIN:\n> > > \n> > > Removing \"--no-half\" from COMMANDLINE_ARGS=\
          \  in webui-user.bat file seems to fix the memory problem.\n> > \n> > how\
          \ do write that exactly\n> \n> find the file webui-user.bat in your stable\
          \ diffusion root folder, edit it with notepad and remove the part that says:\
          \ --no-half\n> save, close and relaunch it. It's the same file you click\
          \ to launch automatic1111\n\nso you -- before no-half"
        updatedAt: '2023-01-28T05:24:49.188Z'
      numEdits: 0
      reactions: []
    id: 63d4b1a1ce1a38ea4eb50694
    type: comment
  author: Nicv1990
  content: "> > > UPDATE AGAIN:\n> > > \n> > > Removing \"--no-half\" from COMMANDLINE_ARGS=\
    \  in webui-user.bat file seems to fix the memory problem.\n> > \n> > how do write\
    \ that exactly\n> \n> find the file webui-user.bat in your stable diffusion root\
    \ folder, edit it with notepad and remove the part that says: --no-half\n> save,\
    \ close and relaunch it. It's the same file you click to launch automatic1111\n\
    \nso you -- before no-half"
  created_at: 2023-01-28 05:24:49+00:00
  edited: false
  hidden: false
  id: 63d4b1a1ce1a38ea4eb50694
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
      fullname: 'Votolato '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicv1990
      type: user
    createdAt: '2023-01-28T05:27:26.000Z'
    data:
      edited: false
      editors:
      - Nicv1990
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
          fullname: 'Votolato '
          isHf: false
          isPro: false
          name: Nicv1990
          type: user
        html: '<p>i did not have  --no-half  in my bat file in first place and got
          the erra for memery</p>

          '
        raw: i did not have  --no-half  in my bat file in first place and got the
          erra for memery
        updatedAt: '2023-01-28T05:27:26.143Z'
      numEdits: 0
      reactions: []
    id: 63d4b23e2424c652f60511d9
    type: comment
  author: Nicv1990
  content: i did not have  --no-half  in my bat file in first place and got the erra
    for memery
  created_at: 2023-01-28 05:27:26+00:00
  edited: false
  hidden: false
  id: 63d4b23e2424c652f60511d9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
      fullname: 'Votolato '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicv1990
      type: user
    createdAt: '2023-01-28T05:45:39.000Z'
    data:
      edited: false
      editors:
      - Nicv1990
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
          fullname: 'Votolato '
          isHf: false
          isPro: false
          name: Nicv1990
          type: user
        html: '<p>iam getting this with and without the  that inside the bat file
          memory  issue with and without --no-half in the file</p>

          '
        raw: iam getting this with and without the  that inside the bat file memory  issue
          with and without --no-half in the file
        updatedAt: '2023-01-28T05:45:39.512Z'
      numEdits: 0
      reactions: []
    id: 63d4b683ce1a38ea4eb5673a
    type: comment
  author: Nicv1990
  content: iam getting this with and without the  that inside the bat file memory  issue
    with and without --no-half in the file
  created_at: 2023-01-28 05:45:39+00:00
  edited: false
  hidden: false
  id: 63d4b683ce1a38ea4eb5673a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
      fullname: 'Votolato '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicv1990
      type: user
    createdAt: '2023-01-28T05:46:29.000Z'
    data:
      edited: false
      editors:
      - Nicv1990
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
          fullname: 'Votolato '
          isHf: false
          isPro: false
          name: Nicv1990
          type: user
        html: '<blockquote>

          <blockquote>

          <blockquote>

          <blockquote>

          <p>UPDATE AGAIN:</p>

          <p>Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem.</p>

          </blockquote>

          <p>how do write that exactly</p>

          </blockquote>

          <p>find the file webui-user.bat in your stable diffusion root folder, edit
          it with notepad and remove the part that says: --no-half<br>save, close
          and relaunch it. It''s the same file you click to launch automatic1111</p>

          </blockquote>

          <p>so you -- before no-half</p>

          </blockquote>

          <p>iam getting this with and without the that inside the bat file memory
          issue with and without --no-half in the file</p>

          '
        raw: "> > > > UPDATE AGAIN:\n> > > > \n> > > > Removing \"--no-half\" from\
          \ COMMANDLINE_ARGS=  in webui-user.bat file seems to fix the memory problem.\n\
          > > > \n> > > how do write that exactly\n> > \n> > find the file webui-user.bat\
          \ in your stable diffusion root folder, edit it with notepad and remove\
          \ the part that says: --no-half\n> > save, close and relaunch it. It's the\
          \ same file you click to launch automatic1111\n> \n> so you -- before no-half\n\
          \niam getting this with and without the that inside the bat file memory\
          \ issue with and without --no-half in the file"
        updatedAt: '2023-01-28T05:46:29.178Z'
      numEdits: 0
      reactions: []
    id: 63d4b6b52424c652f6056b71
    type: comment
  author: Nicv1990
  content: "> > > > UPDATE AGAIN:\n> > > > \n> > > > Removing \"--no-half\" from COMMANDLINE_ARGS=\
    \  in webui-user.bat file seems to fix the memory problem.\n> > > \n> > > how\
    \ do write that exactly\n> > \n> > find the file webui-user.bat in your stable\
    \ diffusion root folder, edit it with notepad and remove the part that says: --no-half\n\
    > > save, close and relaunch it. It's the same file you click to launch automatic1111\n\
    > \n> so you -- before no-half\n\niam getting this with and without the that inside\
    \ the bat file memory issue with and without --no-half in the file"
  created_at: 2023-01-28 05:46:29+00:00
  edited: false
  hidden: false
  id: 63d4b6b52424c652f6056b71
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
      fullname: 'Votolato '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicv1990
      type: user
    createdAt: '2023-01-28T05:55:20.000Z'
    data:
      edited: false
      editors:
      - Nicv1990
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
          fullname: 'Votolato '
          isHf: false
          isPro: false
          name: Nicv1990
          type: user
        html: '<p>geting this still even without  --no-half RuntimeError: CUDA out
          of memory. Tried to allocate 48.00 MiB (GPU 0; 6.00 GiB total capacity;
          5.26 GiB already allocated; 0 bytes free; 5.30 GiB reserved in total by
          PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb
          to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF</p>

          '
        raw: 'geting this still even without  --no-half RuntimeError: CUDA out of
          memory. Tried to allocate 48.00 MiB (GPU 0; 6.00 GiB total capacity; 5.26
          GiB already allocated; 0 bytes free; 5.30 GiB reserved in total by PyTorch)
          If reserved memory is >> allocated memory try setting max_split_size_mb
          to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF'
        updatedAt: '2023-01-28T05:55:20.300Z'
      numEdits: 0
      reactions: []
    id: 63d4b8c885118edc044f4662
    type: comment
  author: Nicv1990
  content: 'geting this still even without  --no-half RuntimeError: CUDA out of memory.
    Tried to allocate 48.00 MiB (GPU 0; 6.00 GiB total capacity; 5.26 GiB already
    allocated; 0 bytes free; 5.30 GiB reserved in total by PyTorch) If reserved memory
    is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See
    documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF'
  created_at: 2023-01-28 05:55:20+00:00
  edited: false
  hidden: false
  id: 63d4b8c885118edc044f4662
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
      fullname: 'Votolato '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nicv1990
      type: user
    createdAt: '2023-01-28T06:00:39.000Z'
    data:
      edited: false
      editors:
      - Nicv1990
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ab4b0044124aa7ecf50aed80593df04.svg
          fullname: 'Votolato '
          isHf: false
          isPro: false
          name: Nicv1990
          type: user
        html: '<blockquote>

          <p>UPDATE AGAIN:</p>

          <p>Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem. Close and relaunch webui-user.bat after you edit
          the file.</p>

          </blockquote>

          <p>geting this still even without --no-half RuntimeError: CUDA out of memory.
          Tried to allocate 48.00 MiB (GPU 0; 6.00 GiB total capacity; 5.26 GiB already
          allocated; 0 bytes free; 5.30 GiB reserved in total by PyTorch) If reserved
          memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid
          fragmentation. See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CON</p>

          '
        raw: "> UPDATE AGAIN:\n> \n> Removing \"--no-half\" from COMMANDLINE_ARGS=\
          \  in webui-user.bat file seems to fix the memory problem. Close and relaunch\
          \ webui-user.bat after you edit the file.\n\ngeting this still even without\
          \ --no-half RuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB\
          \ (GPU 0; 6.00 GiB total capacity; 5.26 GiB already allocated; 0 bytes free;\
          \ 5.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated\
          \ memory try setting max_split_size_mb to avoid fragmentation. See documentation\
          \ for Memory Management and PYTORCH_CUDA_ALLOC_CON"
        updatedAt: '2023-01-28T06:00:39.882Z'
      numEdits: 0
      reactions: []
    id: 63d4ba07ce1a38ea4eb5ad43
    type: comment
  author: Nicv1990
  content: "> UPDATE AGAIN:\n> \n> Removing \"--no-half\" from COMMANDLINE_ARGS= \
    \ in webui-user.bat file seems to fix the memory problem. Close and relaunch webui-user.bat\
    \ after you edit the file.\n\ngeting this still even without --no-half RuntimeError:\
    \ CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 6.00 GiB total capacity;\
    \ 5.26 GiB already allocated; 0 bytes free; 5.30 GiB reserved in total by PyTorch)\
    \ If reserved memory is >> allocated memory try setting max_split_size_mb to avoid\
    \ fragmentation. See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CON"
  created_at: 2023-01-28 06:00:39+00:00
  edited: false
  hidden: false
  id: 63d4ba07ce1a38ea4eb5ad43
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c3793868d6eb473f210d0c40f955cf8f.svg
      fullname: ivis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ivisone
      type: user
    createdAt: '2023-01-28T06:06:00.000Z'
    data:
      edited: false
      editors:
      - Ivisone
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c3793868d6eb473f210d0c40f955cf8f.svg
          fullname: ivis
          isHf: false
          isPro: false
          name: Ivisone
          type: user
        html: '<blockquote>

          <p>UPDATE AGAIN:</p>

          <p>Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem. Close and relaunch webui-user.bat after you edit
          the file.</p>

          </blockquote>

          <p>works perfectly for me</p>

          '
        raw: "> UPDATE AGAIN:\n> \n> Removing \"--no-half\" from COMMANDLINE_ARGS=\
          \  in webui-user.bat file seems to fix the memory problem. Close and relaunch\
          \ webui-user.bat after you edit the file.\n\nworks perfectly for me"
        updatedAt: '2023-01-28T06:06:00.906Z'
      numEdits: 0
      reactions: []
    id: 63d4bb48108305eda76d9e8c
    type: comment
  author: Ivisone
  content: "> UPDATE AGAIN:\n> \n> Removing \"--no-half\" from COMMANDLINE_ARGS= \
    \ in webui-user.bat file seems to fix the memory problem. Close and relaunch webui-user.bat\
    \ after you edit the file.\n\nworks perfectly for me"
  created_at: 2023-01-28 06:06:00+00:00
  edited: false
  hidden: false
  id: 63d4bb48108305eda76d9e8c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/c3793868d6eb473f210d0c40f955cf8f.svg
      fullname: ivis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ivisone
      type: user
    createdAt: '2023-01-28T06:06:06.000Z'
    data:
      status: closed
    id: 63d4bb4ece1a38ea4eb5ca50
    type: status-change
  author: Ivisone
  created_at: 2023-01-28 06:06:06+00:00
  id: 63d4bb4ece1a38ea4eb5ca50
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/c3793868d6eb473f210d0c40f955cf8f.svg
      fullname: ivis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ivisone
      type: user
    createdAt: '2023-01-28T06:06:08.000Z'
    data:
      status: open
    id: 63d4bb502424c652f605cbd8
    type: status-change
  author: Ivisone
  created_at: 2023-01-28 06:06:08+00:00
  id: 63d4bb502424c652f605cbd8
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
      fullname: steven slavik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hfsd
      type: user
    createdAt: '2023-01-28T09:44:06.000Z'
    data:
      edited: true
      editors:
      - hfsd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
          fullname: steven slavik
          isHf: false
          isPro: false
          name: hfsd
          type: user
        html: '<blockquote>

          <blockquote>

          <p>UPDATE AGAIN:</p>

          <p>Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem. Close and relaunch webui-user.bat after you edit
          the file.</p>

          </blockquote>

          <p>geting this still even without --no-half RuntimeError: CUDA out of memory.
          Tried to allocate 48.00 MiB (GPU 0; 6.00 GiB total capacity; 5.26 GiB already
          allocated; 0 bytes free; 5.30 GiB reserved in total by PyTorch) If reserved
          memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid
          fragmentation. See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CON</p>

          </blockquote>

          <p>If you don''t have --no-half and it still give memory error problem then
          try this and let me know if it works, in your webui-user.bat file change
          the lines so it looks like this:</p>

          <p>set COMMANDLINE_ARGS=--xformers --deepdanbooru --lowvram --opt-split-attention<br>set
          ''PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:3072''</p>

          '
        raw: "> > UPDATE AGAIN:\n> > \n> > Removing \"--no-half\" from COMMANDLINE_ARGS=\
          \  in webui-user.bat file seems to fix the memory problem. Close and relaunch\
          \ webui-user.bat after you edit the file.\n> \n> geting this still even\
          \ without --no-half RuntimeError: CUDA out of memory. Tried to allocate\
          \ 48.00 MiB (GPU 0; 6.00 GiB total capacity; 5.26 GiB already allocated;\
          \ 0 bytes free; 5.30 GiB reserved in total by PyTorch) If reserved memory\
          \ is >> allocated memory try setting max_split_size_mb to avoid fragmentation.\
          \ See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CON\n\n\
          If you don't have --no-half and it still give memory error problem then\
          \ try this and let me know if it works, in your webui-user.bat file change\
          \ the lines so it looks like this:\n\nset COMMANDLINE_ARGS=--xformers --deepdanbooru\
          \ --lowvram --opt-split-attention\nset 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:3072'"
        updatedAt: '2023-01-28T09:47:44.019Z'
      numEdits: 1
      reactions: []
    id: 63d4ee6698e20226041a49a9
    type: comment
  author: hfsd
  content: "> > UPDATE AGAIN:\n> > \n> > Removing \"--no-half\" from COMMANDLINE_ARGS=\
    \  in webui-user.bat file seems to fix the memory problem. Close and relaunch\
    \ webui-user.bat after you edit the file.\n> \n> geting this still even without\
    \ --no-half RuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU\
    \ 0; 6.00 GiB total capacity; 5.26 GiB already allocated; 0 bytes free; 5.30 GiB\
    \ reserved in total by PyTorch) If reserved memory is >> allocated memory try\
    \ setting max_split_size_mb to avoid fragmentation. See documentation for Memory\
    \ Management and PYTORCH_CUDA_ALLOC_CON\n\nIf you don't have --no-half and it\
    \ still give memory error problem then try this and let me know if it works, in\
    \ your webui-user.bat file change the lines so it looks like this:\n\nset COMMANDLINE_ARGS=--xformers\
    \ --deepdanbooru --lowvram --opt-split-attention\nset 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:3072'"
  created_at: 2023-01-28 09:44:06+00:00
  edited: true
  hidden: false
  id: 63d4ee6698e20226041a49a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
      fullname: Vijay Kanhai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ItchyFingaz
      type: user
    createdAt: '2023-01-28T09:44:59.000Z'
    data:
      edited: false
      editors:
      - ItchyFingaz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
          fullname: Vijay Kanhai
          isHf: false
          isPro: false
          name: ItchyFingaz
          type: user
        html: '<p>hi guys. </p>

          <p>very stoked to work with this.<br>I get this error tho: </p>

          <p>Loading weights [ffd280ddcf] from /Users/chief/stable-diffusion-webui/models/Stable-diffusion/instruct-pix2pix-00-22000.ckpt<br>Applying
          cross attention optimization (InvokeAI).<br>Weights loaded in 3.3s (load
          weights from disk: 1.8s, apply weights to model: 0.8s, move model to device:
          0.6s).<br>Processing 1 image(s)<br>Traceback (most recent call last):<br>  File
          "/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/gradio/routes.py",
          line 337, in run_predict<br>    output = await app.get_blocks().process_api(<br>  File
          "/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/gradio/blocks.py",
          line 1015, in process_api<br>    result = await self.call_function(<br>  File
          "/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/gradio/blocks.py",
          line 833, in call_function<br>    prediction = await anyio.to_thread.run_sync(<br>  File
          "/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/anyio/to_thread.py",
          line 31, in run_sync<br>    return await get_asynclib().run_sync_in_worker_thread(<br>  File
          "/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py",
          line 937, in run_sync_in_worker_thread<br>    return await future<br>  File
          "/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py",
          line 867, in run<br>    result = context.run(func, *args)<br>  File "/Users/chief/stable-diffusion-webui/extensions/stable-diffusion-webui-instruct-pix2pix/scripts/instruct-pix2pix.py",
          line 128, in generate<br>    model.eval().cuda()<br>  File "/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py",
          line 128, in cuda<br>    device = torch.device("cuda", torch.cuda.current_device())<br>  File
          "/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/cuda/<strong>init</strong>.py",
          line 482, in current_device<br>    _lazy_init()<br>  File "/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/cuda/<strong>init</strong>.py",
          line 211, in _lazy_init<br>    raise AssertionError("Torch not compiled
          with CUDA enabled")<br>AssertionError: Torch not compiled with CUDA enabled</p>

          '
        raw: "hi guys. \n\nvery stoked to work with this. \nI get this error tho:\
          \ \n\nLoading weights [ffd280ddcf] from /Users/chief/stable-diffusion-webui/models/Stable-diffusion/instruct-pix2pix-00-22000.ckpt\n\
          Applying cross attention optimization (InvokeAI).\nWeights loaded in 3.3s\
          \ (load weights from disk: 1.8s, apply weights to model: 0.8s, move model\
          \ to device: 0.6s).\nProcessing 1 image(s)\nTraceback (most recent call\
          \ last):\n  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/gradio/routes.py\"\
          , line 337, in run_predict\n    output = await app.get_blocks().process_api(\n\
          \  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 1015, in process_api\n    result = await self.call_function(\n  File\
          \ \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 833, in call_function\n    prediction = await anyio.to_thread.run_sync(\n\
          \  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/anyio/to_thread.py\"\
          , line 31, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n\
          \  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 937, in run_sync_in_worker_thread\n    return await future\n  File\
          \ \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 867, in run\n    result = context.run(func, *args)\n  File \"/Users/chief/stable-diffusion-webui/extensions/stable-diffusion-webui-instruct-pix2pix/scripts/instruct-pix2pix.py\"\
          , line 128, in generate\n    model.eval().cuda()\n  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py\"\
          , line 128, in cuda\n    device = torch.device(\"cuda\", torch.cuda.current_device())\n\
          \  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/cuda/__init__.py\"\
          , line 482, in current_device\n    _lazy_init()\n  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/cuda/__init__.py\"\
          , line 211, in _lazy_init\n    raise AssertionError(\"Torch not compiled\
          \ with CUDA enabled\")\nAssertionError: Torch not compiled with CUDA enabled"
        updatedAt: '2023-01-28T09:44:59.236Z'
      numEdits: 0
      reactions: []
    id: 63d4ee9b963de177b60980a3
    type: comment
  author: ItchyFingaz
  content: "hi guys. \n\nvery stoked to work with this. \nI get this error tho: \n\
    \nLoading weights [ffd280ddcf] from /Users/chief/stable-diffusion-webui/models/Stable-diffusion/instruct-pix2pix-00-22000.ckpt\n\
    Applying cross attention optimization (InvokeAI).\nWeights loaded in 3.3s (load\
    \ weights from disk: 1.8s, apply weights to model: 0.8s, move model to device:\
    \ 0.6s).\nProcessing 1 image(s)\nTraceback (most recent call last):\n  File \"\
    /Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/gradio/routes.py\"\
    , line 337, in run_predict\n    output = await app.get_blocks().process_api(\n\
    \  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/gradio/blocks.py\"\
    , line 1015, in process_api\n    result = await self.call_function(\n  File \"\
    /Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/gradio/blocks.py\"\
    , line 833, in call_function\n    prediction = await anyio.to_thread.run_sync(\n\
    \  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/anyio/to_thread.py\"\
    , line 31, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n\
    \  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
    , line 937, in run_sync_in_worker_thread\n    return await future\n  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
    , line 867, in run\n    result = context.run(func, *args)\n  File \"/Users/chief/stable-diffusion-webui/extensions/stable-diffusion-webui-instruct-pix2pix/scripts/instruct-pix2pix.py\"\
    , line 128, in generate\n    model.eval().cuda()\n  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py\"\
    , line 128, in cuda\n    device = torch.device(\"cuda\", torch.cuda.current_device())\n\
    \  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/cuda/__init__.py\"\
    , line 482, in current_device\n    _lazy_init()\n  File \"/Users/chief/stable-diffusion-webui/venv/lib/python3.10/site-packages/torch/cuda/__init__.py\"\
    , line 211, in _lazy_init\n    raise AssertionError(\"Torch not compiled with\
    \ CUDA enabled\")\nAssertionError: Torch not compiled with CUDA enabled"
  created_at: 2023-01-28 09:44:59+00:00
  edited: false
  hidden: false
  id: 63d4ee9b963de177b60980a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
      fullname: Vijay Kanhai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ItchyFingaz
      type: user
    createdAt: '2023-01-28T09:46:40.000Z'
    data:
      edited: false
      editors:
      - ItchyFingaz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
          fullname: Vijay Kanhai
          isHf: false
          isPro: false
          name: ItchyFingaz
          type: user
        html: '<p>(btw I''m on Automatic1111 on a M1 Macbook)</p>

          '
        raw: (btw I'm on Automatic1111 on a M1 Macbook)
        updatedAt: '2023-01-28T09:46:40.749Z'
      numEdits: 0
      reactions: []
    id: 63d4ef0098e20226041a5841
    type: comment
  author: ItchyFingaz
  content: (btw I'm on Automatic1111 on a M1 Macbook)
  created_at: 2023-01-28 09:46:40+00:00
  edited: false
  hidden: false
  id: 63d4ef0098e20226041a5841
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
      fullname: steven slavik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hfsd
      type: user
    createdAt: '2023-01-28T09:51:24.000Z'
    data:
      edited: true
      editors:
      - hfsd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6a11e4e0f91c54ca5a77bcc0a2a50a9.svg
          fullname: steven slavik
          isHf: false
          isPro: false
          name: hfsd
          type: user
        html: '<blockquote>

          <p>(btw I''m on Automatic1111 on a M1 Macbook)</p>

          </blockquote>

          <p>Looks like you may have outdated torch version, did you update automatic1111
          to latest version? if so you need to update torch to latest version manually
          also</p>

          '
        raw: '> (btw I''m on Automatic1111 on a M1 Macbook)


          Looks like you may have outdated torch version, did you update automatic1111
          to latest version? if so you need to update torch to latest version manually
          also'
        updatedAt: '2023-01-28T09:51:36.600Z'
      numEdits: 1
      reactions: []
    id: 63d4f01c43a3934c5ddc54a4
    type: comment
  author: hfsd
  content: '> (btw I''m on Automatic1111 on a M1 Macbook)


    Looks like you may have outdated torch version, did you update automatic1111 to
    latest version? if so you need to update torch to latest version manually also'
  created_at: 2023-01-28 09:51:24+00:00
  edited: true
  hidden: false
  id: 63d4f01c43a3934c5ddc54a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/10f59ad309e631e18e7158527b0e9bce.svg
      fullname: Tobias Opitz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sacerdos82
      type: user
    createdAt: '2023-01-28T13:01:23.000Z'
    data:
      edited: false
      editors:
      - sacerdos82
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/10f59ad309e631e18e7158527b0e9bce.svg
          fullname: Tobias Opitz
          isHf: false
          isPro: false
          name: sacerdos82
          type: user
        html: '<blockquote>

          <blockquote>

          <p>(btw I''m on Automatic1111 on a M1 Macbook)</p>

          </blockquote>

          <p>Looks like you may have outdated torch version, did you update automatic1111
          to latest version? if so you need to update torch to latest version manually
          also</p>

          </blockquote>

          <p>I get the same error (M1 Max). When I try to reinstall Torch via --reinstall-torch
          I only get the message that the requirements are already met. The script
          of the WebUI gives however the message that one should install better 1.13.1
          instead of 1.12.1. But there seems to be no possibility to do so. Does anyone
          have an idea? :-)</p>

          '
        raw: "> > (btw I'm on Automatic1111 on a M1 Macbook)\n> \n> Looks like you\
          \ may have outdated torch version, did you update automatic1111 to latest\
          \ version? if so you need to update torch to latest version manually also\n\
          \nI get the same error (M1 Max). When I try to reinstall Torch via --reinstall-torch\
          \ I only get the message that the requirements are already met. The script\
          \ of the WebUI gives however the message that one should install better\
          \ 1.13.1 instead of 1.12.1. But there seems to be no possibility to do so.\
          \ Does anyone have an idea? :-)"
        updatedAt: '2023-01-28T13:01:23.238Z'
      numEdits: 0
      reactions: []
    id: 63d51ca377e8585eeee972c9
    type: comment
  author: sacerdos82
  content: "> > (btw I'm on Automatic1111 on a M1 Macbook)\n> \n> Looks like you may\
    \ have outdated torch version, did you update automatic1111 to latest version?\
    \ if so you need to update torch to latest version manually also\n\nI get the\
    \ same error (M1 Max). When I try to reinstall Torch via --reinstall-torch I only\
    \ get the message that the requirements are already met. The script of the WebUI\
    \ gives however the message that one should install better 1.13.1 instead of 1.12.1.\
    \ But there seems to be no possibility to do so. Does anyone have an idea? :-)"
  created_at: 2023-01-28 13:01:23+00:00
  edited: false
  hidden: false
  id: 63d51ca377e8585eeee972c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/15a6f18c7f23496a5d0be029b28acc44.svg
      fullname: Dev
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Devel
      type: user
    createdAt: '2023-01-28T14:36:53.000Z'
    data:
      edited: false
      editors:
      - Devel
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/15a6f18c7f23496a5d0be029b28acc44.svg
          fullname: Dev
          isHf: false
          isPro: false
          name: Devel
          type: user
        html: '<blockquote>

          <blockquote>

          <blockquote>

          <p>UPDATE AGAIN:</p>

          <p>Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem. Close and relaunch webui-user.bat after you edit
          the file.</p>

          </blockquote>

          <p>geting this still even without --no-half RuntimeError: CUDA out of memory.
          Tried to allocate 48.00 MiB (GPU 0; 6.00 GiB total capacity; 5.26 GiB already
          allocated; 0 bytes free; 5.30 GiB reserved in total by PyTorch) If reserved
          memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid
          fragmentation. See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CON</p>

          </blockquote>

          <p>If you don''t have --no-half and it still give memory error problem then
          try this and let me know if it works, in your webui-user.bat file change
          the lines so it looks like this:</p>

          <p>set COMMANDLINE_ARGS=--xformers --deepdanbooru --lowvram --opt-split-attention<br>set
          ''PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:3072''</p>

          </blockquote>

          <p>After this the model is loaded but when generating the cuda error comes
          out</p>

          '
        raw: "> > > UPDATE AGAIN:\n> > > \n> > > Removing \"--no-half\" from COMMANDLINE_ARGS=\
          \  in webui-user.bat file seems to fix the memory problem. Close and relaunch\
          \ webui-user.bat after you edit the file.\n> > \n> > geting this still even\
          \ without --no-half RuntimeError: CUDA out of memory. Tried to allocate\
          \ 48.00 MiB (GPU 0; 6.00 GiB total capacity; 5.26 GiB already allocated;\
          \ 0 bytes free; 5.30 GiB reserved in total by PyTorch) If reserved memory\
          \ is >> allocated memory try setting max_split_size_mb to avoid fragmentation.\
          \ See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CON\n>\
          \ \n> If you don't have --no-half and it still give memory error problem\
          \ then try this and let me know if it works, in your webui-user.bat file\
          \ change the lines so it looks like this:\n> \n> set COMMANDLINE_ARGS=--xformers\
          \ --deepdanbooru --lowvram --opt-split-attention\n> set 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:3072'\n\
          \nAfter this the model is loaded but when generating the cuda error comes\
          \ out"
        updatedAt: '2023-01-28T14:36:53.652Z'
      numEdits: 0
      reactions: []
    id: 63d53305963de177b60ef02b
    type: comment
  author: Devel
  content: "> > > UPDATE AGAIN:\n> > > \n> > > Removing \"--no-half\" from COMMANDLINE_ARGS=\
    \  in webui-user.bat file seems to fix the memory problem. Close and relaunch\
    \ webui-user.bat after you edit the file.\n> > \n> > geting this still even without\
    \ --no-half RuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU\
    \ 0; 6.00 GiB total capacity; 5.26 GiB already allocated; 0 bytes free; 5.30 GiB\
    \ reserved in total by PyTorch) If reserved memory is >> allocated memory try\
    \ setting max_split_size_mb to avoid fragmentation. See documentation for Memory\
    \ Management and PYTORCH_CUDA_ALLOC_CON\n> \n> If you don't have --no-half and\
    \ it still give memory error problem then try this and let me know if it works,\
    \ in your webui-user.bat file change the lines so it looks like this:\n> \n> set\
    \ COMMANDLINE_ARGS=--xformers --deepdanbooru --lowvram --opt-split-attention\n\
    > set 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:3072'\n\nAfter this the model\
    \ is loaded but when generating the cuda error comes out"
  created_at: 2023-01-28 14:36:53+00:00
  edited: false
  hidden: false
  id: 63d53305963de177b60ef02b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
      fullname: Vijay Kanhai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ItchyFingaz
      type: user
    createdAt: '2023-01-28T14:38:05.000Z'
    data:
      edited: false
      editors:
      - ItchyFingaz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
          fullname: Vijay Kanhai
          isHf: false
          isPro: false
          name: ItchyFingaz
          type: user
        html: '<p>how do you update torch manually?<br>i get requirements met</p>

          '
        raw: 'how do you update torch manually?

          i get requirements met'
        updatedAt: '2023-01-28T14:38:05.502Z'
      numEdits: 0
      reactions: []
    id: 63d5334d77e8585eeeeb44b1
    type: comment
  author: ItchyFingaz
  content: 'how do you update torch manually?

    i get requirements met'
  created_at: 2023-01-28 14:38:05+00:00
  edited: false
  hidden: false
  id: 63d5334d77e8585eeeeb44b1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/15a6f18c7f23496a5d0be029b28acc44.svg
      fullname: Dev
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Devel
      type: user
    createdAt: '2023-01-28T16:44:32.000Z'
    data:
      edited: false
      editors:
      - Devel
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/15a6f18c7f23496a5d0be029b28acc44.svg
          fullname: Dev
          isHf: false
          isPro: false
          name: Devel
          type: user
        html: '<blockquote>

          <p>how do you update torch manually?<br>i get requirements met</p>

          </blockquote>

          <p>delete the venv folder or the folder in python</p>

          '
        raw: '> how do you update torch manually?

          > i get requirements met


          delete the venv folder or the folder in python'
        updatedAt: '2023-01-28T16:44:32.934Z'
      numEdits: 0
      reactions: []
    id: 63d550f0963de177b611723a
    type: comment
  author: Devel
  content: '> how do you update torch manually?

    > i get requirements met


    delete the venv folder or the folder in python'
  created_at: 2023-01-28 16:44:32+00:00
  edited: false
  hidden: false
  id: 63d550f0963de177b611723a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
      fullname: Vijay Kanhai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ItchyFingaz
      type: user
    createdAt: '2023-01-28T16:46:40.000Z'
    data:
      edited: false
      editors:
      - ItchyFingaz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
          fullname: Vijay Kanhai
          isHf: false
          isPro: false
          name: ItchyFingaz
          type: user
        html: '<p>is it possible to run at all on M1 max? </p>

          <p>can I run dreambooth on M1? </p>

          <p>What is the best way to make use of the neural engine for stable diffusion,
          dreambooth, instruct pix-2-pix ??</p>

          '
        raw: "is it possible to run at all on M1 max? \n\ncan I run dreambooth on\
          \ M1? \n\nWhat is the best way to make use of the neural engine for stable\
          \ diffusion, dreambooth, instruct pix-2-pix ??"
        updatedAt: '2023-01-28T16:46:40.374Z'
      numEdits: 0
      reactions: []
    id: 63d5517077e8585eeeedc9a3
    type: comment
  author: ItchyFingaz
  content: "is it possible to run at all on M1 max? \n\ncan I run dreambooth on M1?\
    \ \n\nWhat is the best way to make use of the neural engine for stable diffusion,\
    \ dreambooth, instruct pix-2-pix ??"
  created_at: 2023-01-28 16:46:40+00:00
  edited: false
  hidden: false
  id: 63d5517077e8585eeeedc9a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
      fullname: Vijay Kanhai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ItchyFingaz
      type: user
    createdAt: '2023-01-28T16:48:18.000Z'
    data:
      edited: false
      editors:
      - ItchyFingaz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
          fullname: Vijay Kanhai
          isHf: false
          isPro: false
          name: ItchyFingaz
          type: user
        html: '<p>when I delete venv and run it goes : </p>

          <p>Installing collected packages: charset-normalizer, urllib3, typing-extensions,
          pillow, numpy, idna, certifi, torch, requests, torchvision<br>Successfully
          installed certifi-2022.12.7 charset-normalizer-3.0.1 idna-3.4 numpy-1.24.1
          pillow-9.4.0 requests-2.28.2 torch-1.12.1 torchvision-0.13.1 typing-extensions-4.4.0
          urllib3-1.26.14</p>

          <p>so it reinstalls torch 1.12.1. </p>

          <p>also I manually installed torch 1.13 with pip but it keeps saying 1.12
          in the bottom of the webui when I launch</p>

          '
        raw: "when I delete venv and run it goes : \n\nInstalling collected packages:\
          \ charset-normalizer, urllib3, typing-extensions, pillow, numpy, idna, certifi,\
          \ torch, requests, torchvision\nSuccessfully installed certifi-2022.12.7\
          \ charset-normalizer-3.0.1 idna-3.4 numpy-1.24.1 pillow-9.4.0 requests-2.28.2\
          \ torch-1.12.1 torchvision-0.13.1 typing-extensions-4.4.0 urllib3-1.26.14\n\
          \nso it reinstalls torch 1.12.1. \n\nalso I manually installed torch 1.13\
          \ with pip but it keeps saying 1.12 in the bottom of the webui when I launch"
        updatedAt: '2023-01-28T16:48:18.462Z'
      numEdits: 0
      reactions: []
    id: 63d551d277e8585eeeedd2a2
    type: comment
  author: ItchyFingaz
  content: "when I delete venv and run it goes : \n\nInstalling collected packages:\
    \ charset-normalizer, urllib3, typing-extensions, pillow, numpy, idna, certifi,\
    \ torch, requests, torchvision\nSuccessfully installed certifi-2022.12.7 charset-normalizer-3.0.1\
    \ idna-3.4 numpy-1.24.1 pillow-9.4.0 requests-2.28.2 torch-1.12.1 torchvision-0.13.1\
    \ typing-extensions-4.4.0 urllib3-1.26.14\n\nso it reinstalls torch 1.12.1. \n\
    \nalso I manually installed torch 1.13 with pip but it keeps saying 1.12 in the\
    \ bottom of the webui when I launch"
  created_at: 2023-01-28 16:48:18+00:00
  edited: false
  hidden: false
  id: 63d551d277e8585eeeedd2a2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
      fullname: Vijay Kanhai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ItchyFingaz
      type: user
    createdAt: '2023-01-28T16:50:31.000Z'
    data:
      edited: false
      editors:
      - ItchyFingaz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
          fullname: Vijay Kanhai
          isHf: false
          isPro: false
          name: ItchyFingaz
          type: user
        html: '<p>Checking Dreambooth requirements...<br>[+] bitsandbytes version
          0.35.0 installed.<br>[+] diffusers version 0.10.2 installed.<br>[+] transformers
          version 4.25.1 installed.<br>[ ] xformers version N/A installed.<br>[+]
          torch version 1.12.1 installed.<br>[+] torchvision version 0.13.1 installed.</p>

          <p>######################################################################################################</p>

          <p>Launching Web UI with arguments: --upcast-sampling --use-cpu interrogate<br>Warning:
          caught exception ''Torch not compiled with CUDA enabled'', memory monitor
          disabled<br>No module ''xformers''. Proceeding without it.</p>

          <hr>

          <p>not sure what to do</p>

          '
        raw: 'Checking Dreambooth requirements...

          [+] bitsandbytes version 0.35.0 installed.

          [+] diffusers version 0.10.2 installed.

          [+] transformers version 4.25.1 installed.

          [ ] xformers version N/A installed.

          [+] torch version 1.12.1 installed.

          [+] torchvision version 0.13.1 installed.


          ######################################################################################################


          Launching Web UI with arguments: --upcast-sampling --use-cpu interrogate

          Warning: caught exception ''Torch not compiled with CUDA enabled'', memory
          monitor disabled

          No module ''xformers''. Proceeding without it.


          ---


          not sure what to do'
        updatedAt: '2023-01-28T16:50:31.022Z'
      numEdits: 0
      reactions: []
    id: 63d5525798e2022604225d1f
    type: comment
  author: ItchyFingaz
  content: 'Checking Dreambooth requirements...

    [+] bitsandbytes version 0.35.0 installed.

    [+] diffusers version 0.10.2 installed.

    [+] transformers version 4.25.1 installed.

    [ ] xformers version N/A installed.

    [+] torch version 1.12.1 installed.

    [+] torchvision version 0.13.1 installed.


    ######################################################################################################


    Launching Web UI with arguments: --upcast-sampling --use-cpu interrogate

    Warning: caught exception ''Torch not compiled with CUDA enabled'', memory monitor
    disabled

    No module ''xformers''. Proceeding without it.


    ---


    not sure what to do'
  created_at: 2023-01-28 16:50:31+00:00
  edited: false
  hidden: false
  id: 63d5525798e2022604225d1f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
      fullname: Vijay Kanhai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ItchyFingaz
      type: user
    createdAt: '2023-01-30T11:26:39.000Z'
    data:
      edited: false
      editors:
      - ItchyFingaz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5da9e02036c0f6ad3a9f5a3ce7bb2246.svg
          fullname: Vijay Kanhai
          isHf: false
          isPro: false
          name: ItchyFingaz
          type: user
        html: '<p>Hi guys does anybody know how to fix this error ? very eager to
          use this</p>

          '
        raw: Hi guys does anybody know how to fix this error ? very eager to use this
        updatedAt: '2023-01-30T11:26:39.797Z'
      numEdits: 0
      reactions: []
    id: 63d7a96f143d89ad8076664f
    type: comment
  author: ItchyFingaz
  content: Hi guys does anybody know how to fix this error ? very eager to use this
  created_at: 2023-01-30 11:26:39+00:00
  edited: false
  hidden: false
  id: 63d7a96f143d89ad8076664f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4a3e673f8682b0bfd7daa63ac2cb3e31.svg
      fullname: ihost
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ihost
      type: user
    createdAt: '2023-02-12T14:33:52.000Z'
    data:
      edited: false
      editors:
      - ihost
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4a3e673f8682b0bfd7daa63ac2cb3e31.svg
          fullname: ihost
          isHf: false
          isPro: false
          name: ihost
          type: user
        html: '<blockquote>

          <blockquote>

          <p>UPDATE AGAIN:</p>

          <p>Removing "--no-half" from COMMANDLINE_ARGS=  in webui-user.bat file seems
          to fix the memory problem. Close and relaunch webui-user.bat after you edit
          the file.</p>

          </blockquote>

          <p>works perfectly for me</p>

          </blockquote>

          <p>For me removing "--no-half" in webui-user.bat is working as well. (NVIDIA
          3080 12GB)</p>

          '
        raw: "> > UPDATE AGAIN:\n> > \n> > Removing \"--no-half\" from COMMANDLINE_ARGS=\
          \  in webui-user.bat file seems to fix the memory problem. Close and relaunch\
          \ webui-user.bat after you edit the file.\n> \n> works perfectly for me\n\
          \nFor me removing \"--no-half\" in webui-user.bat is working as well. (NVIDIA\
          \ 3080 12GB)"
        updatedAt: '2023-02-12T14:33:52.446Z'
      numEdits: 0
      reactions: []
    id: 63e8f8d0919e2797bb716492
    type: comment
  author: ihost
  content: "> > UPDATE AGAIN:\n> > \n> > Removing \"--no-half\" from COMMANDLINE_ARGS=\
    \  in webui-user.bat file seems to fix the memory problem. Close and relaunch\
    \ webui-user.bat after you edit the file.\n> \n> works perfectly for me\n\nFor\
    \ me removing \"--no-half\" in webui-user.bat is working as well. (NVIDIA 3080\
    \ 12GB)"
  created_at: 2023-02-12 14:33:52+00:00
  edited: false
  hidden: false
  id: 63e8f8d0919e2797bb716492
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/445c9d67a7c2de25c6d4c27227ea320a.svg
      fullname: Qinchan Li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Wingli
      type: user
    createdAt: '2023-10-15T01:53:00.000Z'
    data:
      edited: false
      editors:
      - Wingli
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9730918407440186
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/445c9d67a7c2de25c6d4c27227ea320a.svg
          fullname: Qinchan Li
          isHf: false
          isPro: false
          name: Wingli
          type: user
        html: '<p>Hello, I have similar issues in using this pre-trained model. It
          was running fine before on my computer, but after a moment( like two weeks
          before), it started to raise the error/issue that the Vram of my computer
          is not enough. For reference, my computer has the graphic card of 3090 with
          24GB VRAM.</p>

          '
        raw: Hello, I have similar issues in using this pre-trained model. It was
          running fine before on my computer, but after a moment( like two weeks before),
          it started to raise the error/issue that the Vram of my computer is not
          enough. For reference, my computer has the graphic card of 3090 with 24GB
          VRAM.
        updatedAt: '2023-10-15T01:53:00.336Z'
      numEdits: 0
      reactions: []
    id: 652b45fc66313ebb619b33f1
    type: comment
  author: Wingli
  content: Hello, I have similar issues in using this pre-trained model. It was running
    fine before on my computer, but after a moment( like two weeks before), it started
    to raise the error/issue that the Vram of my computer is not enough. For reference,
    my computer has the graphic card of 3090 with 24GB VRAM.
  created_at: 2023-10-15 00:53:00+00:00
  edited: false
  hidden: false
  id: 652b45fc66313ebb619b33f1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: timbrooks/instruct-pix2pix
repo_type: model
status: open
target_branch: null
title: Erros
