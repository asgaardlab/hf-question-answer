!!python/object:huggingface_hub.community.DiscussionWithDetails
author: patrickvonplaten
conflicting_files: []
created_at: 2023-06-21 13:02:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2023-06-21T14:02:40.000Z'
    data:
      edited: false
      editors:
      - patrickvonplaten
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8058648705482483
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
          fullname: Patrick von Platen
          isHf: true
          isPro: false
          name: patrickvonplaten
          type: user
        html: "<p>Hey timbrooks \U0001F44B, </p>\n<p> Your model repository seems\
          \ to contain a <a href=\"https://huggingface.co/timbrooks/instruct-pix2pix/tree/fp16\"\
          ><code>fp16</code> branch</a> to load the model in float16 precision. Loading\
          \ <code>fp16</code> versions from a branch instead of the main branch is\
          \ deprecated and will eventually be forbidden. Instead, we strongly recommend\
          \ to save <code>fp16</code> versions of the model under <code>.fp16.</code>\
          \ version files directly on the 'main' branch as enabled through this PR.This\
          \ PR makes sure that your model repository allows the user to correctly\
          \ download float16 precision model weights by adding <code>fp16</code> model\
          \ weights in both safetensors and PyTorch bin format:</p>\n<pre><code class=\"\
          language-py\">pipe = DiffusionPipeline.from_pretrained(timbrooks/instruct-pix2pix,\
          \ torch_dtype=torch.float16, variant=<span class=\"hljs-string\">'fp16'</span>)\n\
          </code></pre>\n<p>For more information please have a look at: <a href=\"\
          https://huggingface.co/docs/diffusers/using-diffusers/loading#checkpoint-variants\"\
          >https://huggingface.co/docs/diffusers/using-diffusers/loading#checkpoint-variants</a>.<br>We\
          \ made sure you that you can safely merge this pull request. </p>\n<p> Best,\
          \ the \U0001F9E8 Diffusers team.</p>\n"
        raw: "Hey timbrooks \U0001F44B, \n\n Your model repository seems to contain\
          \ a [`fp16` branch](https://huggingface.co/timbrooks/instruct-pix2pix/tree/fp16)\
          \ to load the model in float16 precision. Loading `fp16` versions from a\
          \ branch instead of the main branch is deprecated and will eventually be\
          \ forbidden. Instead, we strongly recommend to save `fp16` versions of the\
          \ model under `.fp16.` version files directly on the 'main' branch as enabled\
          \ through this PR.This PR makes sure that your model repository allows the\
          \ user to correctly download float16 precision model weights by adding `fp16`\
          \ model weights in both safetensors and PyTorch bin format:\n\n```py\npipe\
          \ = DiffusionPipeline.from_pretrained(timbrooks/instruct-pix2pix, torch_dtype=torch.float16,\
          \ variant='fp16')\n```\n\nFor more information please have a look at: https://huggingface.co/docs/diffusers/using-diffusers/loading#checkpoint-variants.\n\
          We made sure you that you can safely merge this pull request. \n\n Best,\
          \ the \U0001F9E8 Diffusers team."
        updatedAt: '2023-06-21T14:02:40.363Z'
      numEdits: 0
      reactions: []
    id: 6493030033326a997e0a4a2f
    type: comment
  author: patrickvonplaten
  content: "Hey timbrooks \U0001F44B, \n\n Your model repository seems to contain\
    \ a [`fp16` branch](https://huggingface.co/timbrooks/instruct-pix2pix/tree/fp16)\
    \ to load the model in float16 precision. Loading `fp16` versions from a branch\
    \ instead of the main branch is deprecated and will eventually be forbidden. Instead,\
    \ we strongly recommend to save `fp16` versions of the model under `.fp16.` version\
    \ files directly on the 'main' branch as enabled through this PR.This PR makes\
    \ sure that your model repository allows the user to correctly download float16\
    \ precision model weights by adding `fp16` model weights in both safetensors and\
    \ PyTorch bin format:\n\n```py\npipe = DiffusionPipeline.from_pretrained(timbrooks/instruct-pix2pix,\
    \ torch_dtype=torch.float16, variant='fp16')\n```\n\nFor more information please\
    \ have a look at: https://huggingface.co/docs/diffusers/using-diffusers/loading#checkpoint-variants.\n\
    We made sure you that you can safely merge this pull request. \n\n Best, the \U0001F9E8\
    \ Diffusers team."
  created_at: 2023-06-21 13:02:40+00:00
  edited: false
  hidden: false
  id: 6493030033326a997e0a4a2f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2023-06-21T14:02:41.000Z'
    data:
      oid: 365333d06bab7a0a1816f90815ae5ef5178933a4
      parents:
      - 346c71fb13ed3a1a4a0484593b0eb5d8847dcd8e
      subject: Fix deprecated float16/fp16 variant loading through new `version` API.
    id: '649303010000000000000000'
    type: commit
  author: patrickvonplaten
  created_at: 2023-06-21 13:02:41+00:00
  id: '649303010000000000000000'
  oid: 365333d06bab7a0a1816f90815ae5ef5178933a4
  summary: Fix deprecated float16/fp16 variant loading through new `version` API.
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2023-07-05T16:19:25.000Z'
    data:
      status: merged
    id: 64a5980da580e49ee070239f
    type: status-change
  author: patrickvonplaten
  created_at: 2023-07-05 15:19:25+00:00
  id: 64a5980da580e49ee070239f
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 31519b5cb02a7fd89b906d88731cd4d6a7bbf88d
num: 17
repo_id: timbrooks/instruct-pix2pix
repo_type: model
status: merged
target_branch: refs/heads/main
title: Fix deprecated float16/fp16 variant loading through new `version` API.
