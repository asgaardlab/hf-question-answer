!!python/object:huggingface_hub.community.DiscussionWithDetails
author: digitous
conflicting_files: null
created_at: 2023-04-26 21:10:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
      fullname: Erik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: digitous
      type: user
    createdAt: '2023-04-26T22:10:48.000Z'
    data:
      edited: true
      editors:
      - digitous
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
          fullname: Erik
          isHf: false
          isPro: false
          name: digitous
          type: user
        html: '<p>I typically mix models using strategies to optimize the desired
          features from different models into an amalgamated model of selectively
          merged weights.</p>

          <p>I''m curious what this LoRA is? If it''s a secret project I stumbled
          into by accident by browsing for ''lora 30'' in a reach to find new donor
          and target models, it''s all good, don''t want to spoil any surprises.</p>

          <p>BTW love your work - I''ve used nearly all of your LoRAs [ChanSung],
          top shelf quality, all of them.</p>

          '
        raw: 'I typically mix models using strategies to optimize the desired features
          from different models into an amalgamated model of selectively merged weights.


          I''m curious what this LoRA is? If it''s a secret project I stumbled into
          by accident by browsing for ''lora 30'' in a reach to find new donor and
          target models, it''s all good, don''t want to spoil any surprises.


          BTW love your work - I''ve used nearly all of your LoRAs [ChanSung], top
          shelf quality, all of them.'
        updatedAt: '2023-04-26T22:11:41.592Z'
      numEdits: 1
      reactions: []
    id: 6449a168020f9299f2abc092
    type: comment
  author: digitous
  content: 'I typically mix models using strategies to optimize the desired features
    from different models into an amalgamated model of selectively merged weights.


    I''m curious what this LoRA is? If it''s a secret project I stumbled into by accident
    by browsing for ''lora 30'' in a reach to find new donor and target models, it''s
    all good, don''t want to spoil any surprises.


    BTW love your work - I''ve used nearly all of your LoRAs [ChanSung], top shelf
    quality, all of them.'
  created_at: 2023-04-26 21:10:48+00:00
  edited: true
  hidden: false
  id: 6449a168020f9299f2abc092
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659971187637-60d3b57ad7b174177faabd6e.jpeg?w=200&h=200&f=face
      fullname: chansung park
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: chansung
      type: user
    createdAt: '2023-04-26T22:40:50.000Z'
    data:
      edited: false
      editors:
      - chansung
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659971187637-60d3b57ad7b174177faabd6e.jpeg?w=200&h=200&f=face
          fullname: chansung park
          isHf: false
          isPro: true
          name: chansung
          type: user
        html: "<p>Thanks for stopping by <span data-props=\"{&quot;user&quot;:&quot;digitous&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/digitous\"\
          >@<span class=\"underline\">digitous</span></a></span>\n\n\t</span></span>\
          \  :) </p>\n<p>This is a LoRA checkpoint produced by the latest <code>transformers</code>\
          \ head branch (<code>v4.29</code>).<br>This work is done after some of the\
          \ problems of the tokenizers are resolved,<br>and at this time I used the\
          \ latest Alpaca dataset from the <a rel=\"nofollow\" href=\"https://github.com/gururise/AlpacaDataCleaned\"\
          >AlpacaDataCleaned</a> repository.</p>\n<ul>\n<li>which includes some of\
          \ the cleaned data by human + replaced data by GPT4 (note original Alpaca\
          \ data was generated by GPT3 / not even GPT3.5)</li>\n</ul>\n"
        raw: "Thanks for stopping by @digitous  :) \n\nThis is a LoRA checkpoint produced\
          \ by the latest `transformers` head branch (`v4.29`).\nThis work is done\
          \ after some of the problems of the tokenizers are resolved,\nand at this\
          \ time I used the latest Alpaca dataset from the [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned)\
          \ repository.\n- which includes some of the cleaned data by human + replaced\
          \ data by GPT4 (note original Alpaca data was generated by GPT3 / not even\
          \ GPT3.5)"
        updatedAt: '2023-04-26T22:40:50.286Z'
      numEdits: 0
      reactions: []
    id: 6449a872a281f51a62b380c0
    type: comment
  author: chansung
  content: "Thanks for stopping by @digitous  :) \n\nThis is a LoRA checkpoint produced\
    \ by the latest `transformers` head branch (`v4.29`).\nThis work is done after\
    \ some of the problems of the tokenizers are resolved,\nand at this time I used\
    \ the latest Alpaca dataset from the [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned)\
    \ repository.\n- which includes some of the cleaned data by human + replaced data\
    \ by GPT4 (note original Alpaca data was generated by GPT3 / not even GPT3.5)"
  created_at: 2023-04-26 21:40:50+00:00
  edited: false
  hidden: false
  id: 6449a872a281f51a62b380c0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b21515ab063324ad5b374b0866aef2d0.svg
      fullname: Jonathan Yankovich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tensiondriven
      type: user
    createdAt: '2023-05-01T05:00:16.000Z'
    data:
      edited: false
      editors:
      - tensiondriven
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b21515ab063324ad5b374b0866aef2d0.svg
          fullname: Jonathan Yankovich
          isHf: false
          isPro: false
          name: tensiondriven
          type: user
        html: '<p>As a side-note, could either of you point me toward resources for
          how to merge language models, specifically how to use the checkpoints generated
          during lora creation to merge back into the base model?  I haven''t been
          able to find any resources on the topic, and while I''m technical, I don''t
          have any deep learning background.</p>

          '
        raw: As a side-note, could either of you point me toward resources for how
          to merge language models, specifically how to use the checkpoints generated
          during lora creation to merge back into the base model?  I haven't been
          able to find any resources on the topic, and while I'm technical, I don't
          have any deep learning background.
        updatedAt: '2023-05-01T05:00:16.116Z'
      numEdits: 0
      reactions: []
    id: 644f4760ddf20748b0686b8b
    type: comment
  author: tensiondriven
  content: As a side-note, could either of you point me toward resources for how to
    merge language models, specifically how to use the checkpoints generated during
    lora creation to merge back into the base model?  I haven't been able to find
    any resources on the topic, and while I'm technical, I don't have any deep learning
    background.
  created_at: 2023-05-01 04:00:16+00:00
  edited: false
  hidden: false
  id: 644f4760ddf20748b0686b8b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659971187637-60d3b57ad7b174177faabd6e.jpeg?w=200&h=200&f=face
      fullname: chansung park
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: chansung
      type: user
    createdAt: '2023-05-01T07:00:35.000Z'
    data:
      edited: false
      editors:
      - chansung
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659971187637-60d3b57ad7b174177faabd6e.jpeg?w=200&h=200&f=face
          fullname: chansung park
          isHf: false
          isPro: true
          name: chansung
          type: user
        html: '<p>I guess this is it<br>: <a rel="nofollow" href="https://github.com/tloen/alpaca-lora/blob/main/export_hf_checkpoint.py">https://github.com/tloen/alpaca-lora/blob/main/export_hf_checkpoint.py</a></p>

          '
        raw: 'I guess this is it

          : https://github.com/tloen/alpaca-lora/blob/main/export_hf_checkpoint.py'
        updatedAt: '2023-05-01T07:00:35.746Z'
      numEdits: 0
      reactions: []
    id: 644f6393d5f7dafcfa574e11
    type: comment
  author: chansung
  content: 'I guess this is it

    : https://github.com/tloen/alpaca-lora/blob/main/export_hf_checkpoint.py'
  created_at: 2023-05-01 06:00:35+00:00
  edited: false
  hidden: false
  id: 644f6393d5f7dafcfa574e11
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: LLMs/Alpaca-LoRA-30B-elina
repo_type: model
status: open
target_branch: null
title: Curious
