!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dondraper
conflicting_files: null
created_at: 2023-04-10 01:45:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2b8bbb77f84566321800/vBdIs222m14F2HGYWkd9T.jpeg?w=200&h=200&f=face
      fullname: Don Draper
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dondraper
      type: user
    createdAt: '2023-04-10T02:45:48.000Z'
    data:
      edited: false
      editors:
      - dondraper
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2b8bbb77f84566321800/vBdIs222m14F2HGYWkd9T.jpeg?w=200&h=200&f=face
          fullname: Don Draper
          isHf: false
          isPro: false
          name: dondraper
          type: user
        html: '<p>I have experimented with the model up until version 7. However,
          I have been unable to obtain lengthy responses despite various adjustments.
          Are there any plans to enhance this aspect of the model, or could you suggest
          specific settings that might help in achieving longer responses?</p>

          <p>Additionally, could you provide some insights into the model''s capability
          to handle larger tokens (exceeding 2048)?</p>

          '
        raw: "I have experimented with the model up until version 7. However, I have\
          \ been unable to obtain lengthy responses despite various adjustments. Are\
          \ there any plans to enhance this aspect of the model, or could you suggest\
          \ specific settings that might help in achieving longer responses?\r\n\r\
          \nAdditionally, could you provide some insights into the model's capability\
          \ to handle larger tokens (exceeding 2048)?\r\n"
        updatedAt: '2023-04-10T02:45:48.920Z'
      numEdits: 0
      reactions: []
    id: 6433785c6c2a26ae66d73c5c
    type: comment
  author: dondraper
  content: "I have experimented with the model up until version 7. However, I have\
    \ been unable to obtain lengthy responses despite various adjustments. Are there\
    \ any plans to enhance this aspect of the model, or could you suggest specific\
    \ settings that might help in achieving longer responses?\r\n\r\nAdditionally,\
    \ could you provide some insights into the model's capability to handle larger\
    \ tokens (exceeding 2048)?\r\n"
  created_at: 2023-04-10 01:45:48+00:00
  edited: false
  hidden: false
  id: 6433785c6c2a26ae66d73c5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655953609090-noauth.jpeg?w=200&h=200&f=face
      fullname: BlinkDL
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: BlinkDL
      type: user
    createdAt: '2023-04-10T14:38:06.000Z'
    data:
      edited: true
      editors:
      - BlinkDL
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655953609090-noauth.jpeg?w=200&h=200&f=face
          fullname: BlinkDL
          isHf: false
          isPro: false
          name: BlinkDL
          type: user
        html: '<p>You can simply talk to Alice in ChatRWKV v2 (Raven v8) and get very
          long responses.</p>

          <p>The 7B and 14B Raven models can handle ctxlen 4096 and beyond.</p>

          '
        raw: 'You can simply talk to Alice in ChatRWKV v2 (Raven v8) and get very
          long responses.


          The 7B and 14B Raven models can handle ctxlen 4096 and beyond.'
        updatedAt: '2023-04-10T14:38:36.111Z'
      numEdits: 1
      reactions: []
    id: 64341f4e1d83dc03c8e79521
    type: comment
  author: BlinkDL
  content: 'You can simply talk to Alice in ChatRWKV v2 (Raven v8) and get very long
    responses.


    The 7B and 14B Raven models can handle ctxlen 4096 and beyond.'
  created_at: 2023-04-10 13:38:06+00:00
  edited: true
  hidden: false
  id: 64341f4e1d83dc03c8e79521
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2b8bbb77f84566321800/vBdIs222m14F2HGYWkd9T.jpeg?w=200&h=200&f=face
      fullname: Don Draper
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dondraper
      type: user
    createdAt: '2023-04-12T16:58:33.000Z'
    data:
      edited: true
      editors:
      - dondraper
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2b8bbb77f84566321800/vBdIs222m14F2HGYWkd9T.jpeg?w=200&h=200&f=face
          fullname: Don Draper
          isHf: false
          isPro: false
          name: dondraper
          type: user
        html: '<p>I''ve verified that the model generates longer content in versions
          8 and above, which is great to see. However, one major weakness of these
          models is their inability to consistently follow clear instructions. For
          instance, when asked to ''List 20 breeds of dogs'', the model often generates
          a list with more than 20 dogs and with several duplicates, regardless of
          the settings used. While I haven''t tested the newer v9 model yet, I suspect
          it may face similar limitations. Could this be a limitation with 100% RNN
          models?</p>

          '
        raw: I've verified that the model generates longer content in versions 8 and
          above, which is great to see. However, one major weakness of these models
          is their inability to consistently follow clear instructions. For instance,
          when asked to 'List 20 breeds of dogs', the model often generates a list
          with more than 20 dogs and with several duplicates, regardless of the settings
          used. While I haven't tested the newer v9 model yet, I suspect it may face
          similar limitations. Could this be a limitation with 100% RNN models?
        updatedAt: '2023-04-12T16:59:47.209Z'
      numEdits: 1
      reactions: []
    id: 6436e33942fc843bde8f94a3
    type: comment
  author: dondraper
  content: I've verified that the model generates longer content in versions 8 and
    above, which is great to see. However, one major weakness of these models is their
    inability to consistently follow clear instructions. For instance, when asked
    to 'List 20 breeds of dogs', the model often generates a list with more than 20
    dogs and with several duplicates, regardless of the settings used. While I haven't
    tested the newer v9 model yet, I suspect it may face similar limitations. Could
    this be a limitation with 100% RNN models?
  created_at: 2023-04-12 15:58:33+00:00
  edited: true
  hidden: false
  id: 6436e33942fc843bde8f94a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655953609090-noauth.jpeg?w=200&h=200&f=face
      fullname: BlinkDL
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: BlinkDL
      type: user
    createdAt: '2023-04-12T19:57:19.000Z'
    data:
      edited: false
      editors:
      - BlinkDL
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655953609090-noauth.jpeg?w=200&h=200&f=face
          fullname: BlinkDL
          isHf: false
          isPro: false
          name: BlinkDL
          type: user
        html: '<p>Reduce top_p to 0 or 0.1 or 0.2 or 0.5</p>

          '
        raw: Reduce top_p to 0 or 0.1 or 0.2 or 0.5
        updatedAt: '2023-04-12T19:57:19.967Z'
      numEdits: 0
      reactions: []
    id: 64370d1ff8962b4332bb13af
    type: comment
  author: BlinkDL
  content: Reduce top_p to 0 or 0.1 or 0.2 or 0.5
  created_at: 2023-04-12 18:57:19+00:00
  edited: false
  hidden: false
  id: 64370d1ff8962b4332bb13af
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: BlinkDL/rwkv-4-raven
repo_type: model
status: open
target_branch: null
title: Seeking Improvements and Configuration Advice for Longer Responses and Larger
  Tokens
