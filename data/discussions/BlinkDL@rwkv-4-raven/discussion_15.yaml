!!python/object:huggingface_hub.community.DiscussionWithDetails
author: phi0112358
conflicting_files: null
created_at: 2023-04-25 17:17:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661340992329-noauth.png?w=200&h=200&f=face
      fullname: Yazan Agha-Schrader
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: phi0112358
      type: user
    createdAt: '2023-04-25T18:17:14.000Z'
    data:
      edited: true
      editors:
      - phi0112358
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661340992329-noauth.png?w=200&h=200&f=face
          fullname: Yazan Agha-Schrader
          isHf: false
          isPro: false
          name: phi0112358
          type: user
        html: '<p>The first time I tried to run rwkv and raven llms on my imac (i5,
          16 gb ram) but it was too slow and the more important thing, the output
          wasn''t that coherent, even with the 7B model. Now i ran the 3B model on
          my macbook with m1 and only 8gb ram, but </p>

          <ol>

          <li>it runs amazingly fast, like there is almost no loading time! </li>

          <li>I recognized that the conversations make much more sense now. The answers
          are coherent, they are accurate, the llm doesnt hallucinate (at least until
          now. alice now says "i don''t know" or "i never heard from it" etc), the
          conversation in general feels quite natural.</li>

          <li>Just for fun I tried to talk in german with Alice she/the llm answers
          in pretty good german. I am really surprised, since it is trained with 99%
          english stuff and the llm''s german skills are better than alpaca''s. I
          mean I am talking about the 3B model (q4, flt16, it runs with 2 gb in ram!!!).
          I can have long and consistent conversations with alice in german language.
          HOW does this work?</li>

          <li>I asked Alice which date is today and she/the llm answerd with "8th
          of April 2023" - so this is the date the file was published. How does the
          llm knows this day? I assume the model was trained until this date, but
          I thought with datasets that were older of course.</li>

          <li>What is reason for such different outputs on different computers? i
          used the same files and havent change anything. does the output quality
          correlate with the speed/general performance?</li>

          </ol>

          <p>I want to thank the developer of these llms for this great work! I am
          excited what the 7B model will show on the m1 : D</p>

          '
        raw: "The first time I tried to run rwkv and raven llms on my imac (i5, 16\
          \ gb ram) but it was too slow and the more important thing, the output wasn't\
          \ that coherent, even with the 7B model. Now i ran the 3B model on my macbook\
          \ with m1 and only 8gb ram, but \n1) it runs amazingly fast, like there\
          \ is almost no loading time! \n2) I recognized that the conversations make\
          \ much more sense now. The answers are coherent, they are accurate, the\
          \ llm doesnt hallucinate (at least until now. alice now says \"i don't know\"\
          \ or \"i never heard from it\" etc), the conversation in general feels quite\
          \ natural.\n3) Just for fun I tried to talk in german with Alice she/the\
          \ llm answers in pretty good german. I am really surprised, since it is\
          \ trained with 99% english stuff and the llm's german skills are better\
          \ than alpaca's. I mean I am talking about the 3B model (q4, flt16, it runs\
          \ with 2 gb in ram!!!). I can have long and consistent conversations with\
          \ alice in german language. HOW does this work?\n4) I asked Alice which\
          \ date is today and she/the llm answerd with \"8th of April 2023\" - so\
          \ this is the date the file was published. How does the llm knows this day?\
          \ I assume the model was trained until this date, but I thought with datasets\
          \ that were older of course.\n5) What is reason for such different outputs\
          \ on different computers? i used the same files and havent change anything.\
          \ does the output quality correlate with the speed/general performance?\n\
          \nI want to thank the developer of these llms for this great work! I am\
          \ excited what the 7B model will show on the m1 : D"
        updatedAt: '2023-04-25T18:20:04.684Z'
      numEdits: 1
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - Yhyu13
        - tantony
        - MaziyarPanahi
    id: 6448192a30fa4ecb85e18500
    type: comment
  author: phi0112358
  content: "The first time I tried to run rwkv and raven llms on my imac (i5, 16 gb\
    \ ram) but it was too slow and the more important thing, the output wasn't that\
    \ coherent, even with the 7B model. Now i ran the 3B model on my macbook with\
    \ m1 and only 8gb ram, but \n1) it runs amazingly fast, like there is almost no\
    \ loading time! \n2) I recognized that the conversations make much more sense\
    \ now. The answers are coherent, they are accurate, the llm doesnt hallucinate\
    \ (at least until now. alice now says \"i don't know\" or \"i never heard from\
    \ it\" etc), the conversation in general feels quite natural.\n3) Just for fun\
    \ I tried to talk in german with Alice she/the llm answers in pretty good german.\
    \ I am really surprised, since it is trained with 99% english stuff and the llm's\
    \ german skills are better than alpaca's. I mean I am talking about the 3B model\
    \ (q4, flt16, it runs with 2 gb in ram!!!). I can have long and consistent conversations\
    \ with alice in german language. HOW does this work?\n4) I asked Alice which date\
    \ is today and she/the llm answerd with \"8th of April 2023\" - so this is the\
    \ date the file was published. How does the llm knows this day? I assume the model\
    \ was trained until this date, but I thought with datasets that were older of\
    \ course.\n5) What is reason for such different outputs on different computers?\
    \ i used the same files and havent change anything. does the output quality correlate\
    \ with the speed/general performance?\n\nI want to thank the developer of these\
    \ llms for this great work! I am excited what the 7B model will show on the m1\
    \ : D"
  created_at: 2023-04-25 17:17:14+00:00
  edited: true
  hidden: false
  id: 6448192a30fa4ecb85e18500
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655953609090-noauth.jpeg?w=200&h=200&f=face
      fullname: BlinkDL
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: BlinkDL
      type: user
    createdAt: '2023-04-26T14:35:34.000Z'
    data:
      edited: false
      editors:
      - BlinkDL
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655953609090-noauth.jpeg?w=200&h=200&f=face
          fullname: BlinkDL
          isHf: false
          isPro: false
          name: BlinkDL
          type: user
        html: '<p>Thank you!</p>

          <ol>

          <li><p>Will be multiple times faster after optimization.</p>

          </li>

          <li><p>Yeah and I just released v11. I think we can reach v30 this year.</p>

          </li>

          <li><p>RWKV has better understanding of human language :)</p>

          </li>

          <li><p>The base model was trained on Pile v1 (2020), then finetuned on ChatGPT
          data and these are newer.</p>

          </li>

          <li><p>The same is true for all language models. You can reduce "top-p"
          for more consistent results, but it will also be boring (lack of variations).</p>

          </li>

          </ol>

          '
        raw: 'Thank you!


          1. Will be multiple times faster after optimization.


          2. Yeah and I just released v11. I think we can reach v30 this year.


          3. RWKV has better understanding of human language :)


          4. The base model was trained on Pile v1 (2020), then finetuned on ChatGPT
          data and these are newer.


          5. The same is true for all language models. You can reduce "top-p" for
          more consistent results, but it will also be boring (lack of variations).'
        updatedAt: '2023-04-26T14:35:34.033Z'
      numEdits: 0
      reactions: []
    id: 644936b6d16a70c0159613a8
    type: comment
  author: BlinkDL
  content: 'Thank you!


    1. Will be multiple times faster after optimization.


    2. Yeah and I just released v11. I think we can reach v30 this year.


    3. RWKV has better understanding of human language :)


    4. The base model was trained on Pile v1 (2020), then finetuned on ChatGPT data
    and these are newer.


    5. The same is true for all language models. You can reduce "top-p" for more consistent
    results, but it will also be boring (lack of variations).'
  created_at: 2023-04-26 13:35:34+00:00
  edited: false
  hidden: false
  id: 644936b6d16a70c0159613a8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2b8bbb77f84566321800/vBdIs222m14F2HGYWkd9T.jpeg?w=200&h=200&f=face
      fullname: Don Draper
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dondraper
      type: user
    createdAt: '2023-04-26T14:43:33.000Z'
    data:
      edited: false
      editors:
      - dondraper
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2b8bbb77f84566321800/vBdIs222m14F2HGYWkd9T.jpeg?w=200&h=200&f=face
          fullname: Don Draper
          isHf: false
          isPro: false
          name: dondraper
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;BlinkDL&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/BlinkDL\">@<span class=\"\
          underline\">BlinkDL</span></a></span>\n\n\t</span></span> Are there release\
          \ notes anywhere so we can have a better understanding of the changes in\
          \ each new release?</p>\n"
        raw: '@BlinkDL Are there release notes anywhere so we can have a better understanding
          of the changes in each new release?'
        updatedAt: '2023-04-26T14:43:33.724Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Raspbfox
        - Yhyu13
    id: 6449389571d33f18edf6bb8d
    type: comment
  author: dondraper
  content: '@BlinkDL Are there release notes anywhere so we can have a better understanding
    of the changes in each new release?'
  created_at: 2023-04-26 13:43:33+00:00
  edited: false
  hidden: false
  id: 6449389571d33f18edf6bb8d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9afb6855674631132f4041e2599cbd0e.svg
      fullname: Varun Mathur
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: varun500
      type: user
    createdAt: '2023-04-30T07:32:30.000Z'
    data:
      edited: false
      editors:
      - varun500
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9afb6855674631132f4041e2599cbd0e.svg
          fullname: Varun Mathur
          isHf: false
          isPro: false
          name: varun500
          type: user
        html: '<p>How to load this model from huggingface? It does not seem to have
          a model card?</p>

          '
        raw: How to load this model from huggingface? It does not seem to have a model
          card?
        updatedAt: '2023-04-30T07:32:30.374Z'
      numEdits: 0
      reactions: []
    id: 644e198ecf72e60a5b71ebda
    type: comment
  author: varun500
  content: How to load this model from huggingface? It does not seem to have a model
    card?
  created_at: 2023-04-30 06:32:30+00:00
  edited: false
  hidden: false
  id: 644e198ecf72e60a5b71ebda
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655953609090-noauth.jpeg?w=200&h=200&f=face
      fullname: BlinkDL
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: BlinkDL
      type: user
    createdAt: '2023-05-01T05:13:49.000Z'
    data:
      edited: false
      editors:
      - BlinkDL
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655953609090-noauth.jpeg?w=200&h=200&f=face
          fullname: BlinkDL
          isHf: false
          isPro: false
          name: BlinkDL
          type: user
        html: '<p>Use <a rel="nofollow" href="https://github.com/BlinkDL/ChatRWKV">https://github.com/BlinkDL/ChatRWKV</a>
          for now<br>We are working on HF integration: <a rel="nofollow" href="https://github.com/huggingface/transformers/pull/22797">https://github.com/huggingface/transformers/pull/22797</a></p>

          '
        raw: 'Use https://github.com/BlinkDL/ChatRWKV for now

          We are working on HF integration: https://github.com/huggingface/transformers/pull/22797'
        updatedAt: '2023-05-01T05:13:49.045Z'
      numEdits: 0
      reactions: []
    id: 644f4a8dddf20748b068a8c3
    type: comment
  author: BlinkDL
  content: 'Use https://github.com/BlinkDL/ChatRWKV for now

    We are working on HF integration: https://github.com/huggingface/transformers/pull/22797'
  created_at: 2023-05-01 04:13:49+00:00
  edited: false
  hidden: false
  id: 644f4a8dddf20748b068a8c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ffbed610a75a8687ba5e74d83510c448.svg
      fullname: ycc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hehongyuan
      type: user
    createdAt: '2023-05-05T10:26:30.000Z'
    data:
      edited: true
      editors:
      - hehongyuan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ffbed610a75a8687ba5e74d83510c448.svg
          fullname: ycc
          isHf: false
          isPro: false
          name: hehongyuan
          type: user
        html: '<blockquote>

          <p>The first time I tried to run rwkv and raven llms on my imac (i5, 16
          gb ram) but it was too slow and the more important thing, the output wasn''t
          that coherent, even with the 7B model. Now i ran the 3B model on my macbook
          with m1 and only 8gb ram, but </p>

          <ol>

          <li>it runs amazingly fast, like there is almost no loading time! </li>

          <li>I recognized that the conversations make much more sense now. The answers
          are coherent, they are accurate, the llm doesnt hallucinate (at least until
          now. alice now says "i don''t know" or "i never heard from it" etc), the
          conversation in general feels quite natural.</li>

          <li>Just for fun I tried to talk in german with Alice she/the llm answers
          in pretty good german. I am really surprised, since it is trained with 99%
          english stuff and the llm''s german skills are better than alpaca''s. I
          mean I am talking about the 3B model (q4, flt16, it runs with 2 gb in ram!!!).
          I can have long and consistent conversations with alice in german language.
          HOW does this work?</li>

          <li>I asked Alice which date is today and she/the llm answerd with "8th
          of April 2023" - so this is the date the file was published. How does the
          llm knows this day? I assume the model was trained until this date, but
          I thought with datasets that were older of course.</li>

          <li>What is reason for such different outputs on different computers? i
          used the same files and havent change anything. does the output quality
          correlate with the speed/general performance?</li>

          </ol>

          <p>I want to thank the developer of these llms for this great work! I am
          excited what the 7B model will show on the m1 : D</p>

          </blockquote>

          <p>Do you have m1 to get q4, flt16 and good loading example code</p>

          '
        raw: "> The first time I tried to run rwkv and raven llms on my imac (i5,\
          \ 16 gb ram) but it was too slow and the more important thing, the output\
          \ wasn't that coherent, even with the 7B model. Now i ran the 3B model on\
          \ my macbook with m1 and only 8gb ram, but \n> 1) it runs amazingly fast,\
          \ like there is almost no loading time! \n> 2) I recognized that the conversations\
          \ make much more sense now. The answers are coherent, they are accurate,\
          \ the llm doesnt hallucinate (at least until now. alice now says \"i don't\
          \ know\" or \"i never heard from it\" etc), the conversation in general\
          \ feels quite natural.\n> 3) Just for fun I tried to talk in german with\
          \ Alice she/the llm answers in pretty good german. I am really surprised,\
          \ since it is trained with 99% english stuff and the llm's german skills\
          \ are better than alpaca's. I mean I am talking about the 3B model (q4,\
          \ flt16, it runs with 2 gb in ram!!!). I can have long and consistent conversations\
          \ with alice in german language. HOW does this work?\n> 4) I asked Alice\
          \ which date is today and she/the llm answerd with \"8th of April 2023\"\
          \ - so this is the date the file was published. How does the llm knows this\
          \ day? I assume the model was trained until this date, but I thought with\
          \ datasets that were older of course.\n> 5) What is reason for such different\
          \ outputs on different computers? i used the same files and havent change\
          \ anything. does the output quality correlate with the speed/general performance?\n\
          > \n> I want to thank the developer of these llms for this great work! I\
          \ am excited what the 7B model will show on the m1 : D\n\n\nDo you have\
          \ m1 to get q4, flt16 and good loading example code"
        updatedAt: '2023-05-05T10:26:52.516Z'
      numEdits: 1
      reactions: []
    id: 6454d9d6a473375be56afb1b
    type: comment
  author: hehongyuan
  content: "> The first time I tried to run rwkv and raven llms on my imac (i5, 16\
    \ gb ram) but it was too slow and the more important thing, the output wasn't\
    \ that coherent, even with the 7B model. Now i ran the 3B model on my macbook\
    \ with m1 and only 8gb ram, but \n> 1) it runs amazingly fast, like there is almost\
    \ no loading time! \n> 2) I recognized that the conversations make much more sense\
    \ now. The answers are coherent, they are accurate, the llm doesnt hallucinate\
    \ (at least until now. alice now says \"i don't know\" or \"i never heard from\
    \ it\" etc), the conversation in general feels quite natural.\n> 3) Just for fun\
    \ I tried to talk in german with Alice she/the llm answers in pretty good german.\
    \ I am really surprised, since it is trained with 99% english stuff and the llm's\
    \ german skills are better than alpaca's. I mean I am talking about the 3B model\
    \ (q4, flt16, it runs with 2 gb in ram!!!). I can have long and consistent conversations\
    \ with alice in german language. HOW does this work?\n> 4) I asked Alice which\
    \ date is today and she/the llm answerd with \"8th of April 2023\" - so this is\
    \ the date the file was published. How does the llm knows this day? I assume the\
    \ model was trained until this date, but I thought with datasets that were older\
    \ of course.\n> 5) What is reason for such different outputs on different computers?\
    \ i used the same files and havent change anything. does the output quality correlate\
    \ with the speed/general performance?\n> \n> I want to thank the developer of\
    \ these llms for this great work! I am excited what the 7B model will show on\
    \ the m1 : D\n\n\nDo you have m1 to get q4, flt16 and good loading example code"
  created_at: 2023-05-05 09:26:30+00:00
  edited: true
  hidden: false
  id: 6454d9d6a473375be56afb1b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: BlinkDL/rwkv-4-raven
repo_type: model
status: open
target_branch: null
title: Amazing results with Raven 3B!! It speaks other languages, it knows the date..
  How does this work?
