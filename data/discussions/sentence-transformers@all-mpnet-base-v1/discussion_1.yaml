!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sondalex
conflicting_files: null
created_at: 2023-01-09 14:49:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aa653e597af6435840c3809b73a1d8a6.svg
      fullname: Alexandre Sonderegger
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sondalex
      type: user
    createdAt: '2023-01-09T14:49:47.000Z'
    data:
      edited: false
      editors:
      - sondalex
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aa653e597af6435840c3809b73a1d8a6.svg
          fullname: Alexandre Sonderegger
          isHf: false
          isPro: false
          name: sondalex
          type: user
        html: '<p>Hi,  the repository README mentions:</p>

          <pre><code class="language-text">By default, input text longer than 128
          word pieces is truncated.

          </code></pre>

          <p>However, the parameter max_seq_length from  sentence_transformers returns
          512.</p>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer

          model_st = SentenceTransformer(<span class="hljs-string">''all-mpnet-base-v1''</span>)

          model_st.max_seq_length

          <span class="hljs-comment"># 512</span>

          </code></pre>

          <p>Same value is returned for the Hugging face transformer approach: </p>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

          tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">''sentence-transformers/all-mpnet-base-v1''</span>)

          tokenizer.model_max_length

          <span class="hljs-comment"># 512</span>

          </code></pre>

          <p>Shouldn''t the README be updated from 128 to 512  ?</p>

          <hr>

          <p>Output of pip freeze:</p>

          <pre><code class="language-text">...

          sentence-transformers==2.2.2

          huggingface-hub==0.10.1

          transformers==4.23.1

          torch==1.12.1

          ...

          </code></pre>

          '
        raw: "Hi,  the repository README mentions:\r\n\r\n```text\r\nBy default, input\
          \ text longer than 128 word pieces is truncated.\r\n```\r\n\r\nHowever,\
          \ the parameter max_seq_length from  sentence_transformers returns 512.\r\
          \n\r\n```python\r\nfrom sentence_transformers import SentenceTransformer\r\
          \nmodel_st = SentenceTransformer('all-mpnet-base-v1')\r\nmodel_st.max_seq_length\r\
          \n# 512\r\n```\r\n\r\nSame value is returned for the Hugging face transformer\
          \ approach: \r\n\r\n```python\r\nfrom transformers import AutoTokenizer,\
          \ AutoModel\r\ntokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v1')\r\
          \ntokenizer.model_max_length\r\n# 512\r\n```\r\n\r\nShouldn't the README\
          \ be updated from 128 to 512  ?\r\n \r\n\r\n-----\r\n\r\nOutput of pip freeze:\r\
          \n```text\r\n...\r\nsentence-transformers==2.2.2\r\nhuggingface-hub==0.10.1\r\
          \ntransformers==4.23.1\r\ntorch==1.12.1\r\n...\r\n```"
        updatedAt: '2023-01-09T14:49:47.231Z'
      numEdits: 0
      reactions: []
    id: 63bc298bb8c61b8aa496e1f3
    type: comment
  author: sondalex
  content: "Hi,  the repository README mentions:\r\n\r\n```text\r\nBy default, input\
    \ text longer than 128 word pieces is truncated.\r\n```\r\n\r\nHowever, the parameter\
    \ max_seq_length from  sentence_transformers returns 512.\r\n\r\n```python\r\n\
    from sentence_transformers import SentenceTransformer\r\nmodel_st = SentenceTransformer('all-mpnet-base-v1')\r\
    \nmodel_st.max_seq_length\r\n# 512\r\n```\r\n\r\nSame value is returned for the\
    \ Hugging face transformer approach: \r\n\r\n```python\r\nfrom transformers import\
    \ AutoTokenizer, AutoModel\r\ntokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v1')\r\
    \ntokenizer.model_max_length\r\n# 512\r\n```\r\n\r\nShouldn't the README be updated\
    \ from 128 to 512  ?\r\n \r\n\r\n-----\r\n\r\nOutput of pip freeze:\r\n```text\r\
    \n...\r\nsentence-transformers==2.2.2\r\nhuggingface-hub==0.10.1\r\ntransformers==4.23.1\r\
    \ntorch==1.12.1\r\n...\r\n```"
  created_at: 2023-01-09 14:49:47+00:00
  edited: false
  hidden: false
  id: 63bc298bb8c61b8aa496e1f3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660092421231-5ef3a3e6518622264685b0da.png?w=200&h=200&f=face
      fullname: John Giorgi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: johngiorgi
      type: user
    createdAt: '2023-02-07T17:38:43.000Z'
    data:
      edited: false
      editors:
      - johngiorgi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660092421231-5ef3a3e6518622264685b0da.png?w=200&h=200&f=face
          fullname: John Giorgi
          isHf: false
          isPro: false
          name: johngiorgi
          type: user
        html: '<p>I have the same question! Looking to embed text up to the maximum
          sequence length of 512. I am assuming it won''t be truncated at 128 despite
          what the README says?</p>

          '
        raw: I have the same question! Looking to embed text up to the maximum sequence
          length of 512. I am assuming it won't be truncated at 128 despite what the
          README says?
        updatedAt: '2023-02-07T17:38:43.795Z'
      numEdits: 0
      reactions: []
    id: 63e28ca3dd70dbdb82316cfe
    type: comment
  author: johngiorgi
  content: I have the same question! Looking to embed text up to the maximum sequence
    length of 512. I am assuming it won't be truncated at 128 despite what the README
    says?
  created_at: 2023-02-07 17:38:43+00:00
  edited: false
  hidden: false
  id: 63e28ca3dd70dbdb82316cfe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e5cf9a1d34a4986c12ff96ad6b12f55f.svg
      fullname: Yong Huang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yongh7
      type: user
    createdAt: '2023-08-22T13:39:37.000Z'
    data:
      edited: false
      editors:
      - yongh7
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9343221187591553
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e5cf9a1d34a4986c12ff96ad6b12f55f.svg
          fullname: Yong Huang
          isHf: false
          isPro: false
          name: yongh7
          type: user
        html: '<p>That''s a great observation, thank you for posting this</p>

          '
        raw: That's a great observation, thank you for posting this
        updatedAt: '2023-08-22T13:39:37.625Z'
      numEdits: 0
      reactions: []
    id: 64e4ba9999e8c24452f5f394
    type: comment
  author: yongh7
  content: That's a great observation, thank you for posting this
  created_at: 2023-08-22 12:39:37+00:00
  edited: false
  hidden: false
  id: 64e4ba9999e8c24452f5f394
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: sentence-transformers/all-mpnet-base-v1
repo_type: model
status: open
target_branch: null
title: 'Max Input Length Documentation '
