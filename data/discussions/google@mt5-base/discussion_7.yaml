!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ZeroneBo
conflicting_files: null
created_at: 2023-12-14 15:38:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e1f13940319dc25d3face90a5e6a2b99.svg
      fullname: ZeroneBo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ZeroneBo
      type: user
    createdAt: '2023-12-14T15:38:53.000Z'
    data:
      edited: false
      editors:
      - ZeroneBo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8949653506278992
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e1f13940319dc25d3face90a5e6a2b99.svg
          fullname: ZeroneBo
          isHf: false
          isPro: false
          name: ZeroneBo
          type: user
        html: '<p>The output of the model is strange, as described in the following
          link. Appreciate for any suggestions that may be helpful.<br><a href="https://huggingface.co/google/mt5-base/discussions/3#657b1f6c69a46ce96bd2c607">https://huggingface.co/google/mt5-base/discussions/3#657b1f6c69a46ce96bd2c607</a></p>

          '
        raw: "The output of the model is strange, as described in the following link.\
          \ Appreciate for any suggestions that may be helpful.\r\nhttps://huggingface.co/google/mt5-base/discussions/3#657b1f6c69a46ce96bd2c607\r\
          \n"
        updatedAt: '2023-12-14T15:38:53.602Z'
      numEdits: 0
      reactions: []
    id: 657b218d2cbb7f638231c465
    type: comment
  author: ZeroneBo
  content: "The output of the model is strange, as described in the following link.\
    \ Appreciate for any suggestions that may be helpful.\r\nhttps://huggingface.co/google/mt5-base/discussions/3#657b1f6c69a46ce96bd2c607\r\
    \n"
  created_at: 2023-12-14 15:38:53+00:00
  edited: false
  hidden: false
  id: 657b218d2cbb7f638231c465
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-12-14T17:15:33.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9845894575119019
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>hi <span data-props=\"{&quot;user&quot;:&quot;ZeroneBo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ZeroneBo\"\
          >@<span class=\"underline\">ZeroneBo</span></a></span>\n\n\t</span></span><br>Thanks\
          \ for the issue, I think this is expected as the model is a pre-trained\
          \ model that has been pre-trained on text de-noising objective. You need\
          \ to use fine-tuned models such as flan-t5 in order to prompt them out of\
          \ the box</p>\n"
        raw: "hi @ZeroneBo \nThanks for the issue, I think this is expected as the\
          \ model is a pre-trained model that has been pre-trained on text de-noising\
          \ objective. You need to use fine-tuned models such as flan-t5 in order\
          \ to prompt them out of the box"
        updatedAt: '2023-12-14T17:15:33.898Z'
      numEdits: 0
      reactions: []
    id: 657b38353a230db5891e7384
    type: comment
  author: ybelkada
  content: "hi @ZeroneBo \nThanks for the issue, I think this is expected as the model\
    \ is a pre-trained model that has been pre-trained on text de-noising objective.\
    \ You need to use fine-tuned models such as flan-t5 in order to prompt them out\
    \ of the box"
  created_at: 2023-12-14 17:15:33+00:00
  edited: false
  hidden: false
  id: 657b38353a230db5891e7384
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e1f13940319dc25d3face90a5e6a2b99.svg
      fullname: ZeroneBo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ZeroneBo
      type: user
    createdAt: '2023-12-15T10:49:08.000Z'
    data:
      edited: false
      editors:
      - ZeroneBo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8851717710494995
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e1f13940319dc25d3face90a5e6a2b99.svg
          fullname: ZeroneBo
          isHf: false
          isPro: false
          name: ZeroneBo
          type: user
        html: "<p>Thanks for your explanation <span data-props=\"{&quot;user&quot;:&quot;ybelkada&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ybelkada\"\
          >@<span class=\"underline\">ybelkada</span></a></span>\n\n\t</span></span>\
          \ . I am new with t5 families.<br>I have tried flan-t5-base, it seems don't\
          \ suppose Chinese, becasuse it encodes Chinese characters into unk.<br>Is\
          \ there a recommended prompt template for translation task  finetuning mt5?\
          \ And are there recommended prompt templates for other tasks?<br>I don't\
          \ know whether need to add task labels manually before the input for mt5,\
          \ such as: \"&lt;nli&gt; [inputs]\" for nli task; \"&lt;translate&gt; [inputs]\"\
          \ for translation task, or just give the instruct finetune it, such as \"\
          Translate from Chinese to English.\\nChinese: [zh_input]\\nEnglish:\" and\
          \ label:\"[en_input]\" ?<br>Thanks again!</p>\n"
        raw: 'Thanks for your explanation @ybelkada . I am new with t5 families.

          I have tried flan-t5-base, it seems don''t suppose Chinese, becasuse it
          encodes Chinese characters into unk.

          Is there a recommended prompt template for translation task  finetuning
          mt5? And are there recommended prompt templates for other tasks?

          I don''t know whether need to add task labels manually before the input
          for mt5, such as: "\<nli\> [inputs]" for nli task; "\<translate\> [inputs]"
          for translation task, or just give the instruct finetune it, such as "Translate
          from Chinese to English.\nChinese: [zh_input]\nEnglish:" and label:"[en_input]"
          ?

          Thanks again!'
        updatedAt: '2023-12-15T10:49:08.863Z'
      numEdits: 0
      reactions: []
    id: 657c2f24504b90a3c5ad269a
    type: comment
  author: ZeroneBo
  content: 'Thanks for your explanation @ybelkada . I am new with t5 families.

    I have tried flan-t5-base, it seems don''t suppose Chinese, becasuse it encodes
    Chinese characters into unk.

    Is there a recommended prompt template for translation task  finetuning mt5? And
    are there recommended prompt templates for other tasks?

    I don''t know whether need to add task labels manually before the input for mt5,
    such as: "\<nli\> [inputs]" for nli task; "\<translate\> [inputs]" for translation
    task, or just give the instruct finetune it, such as "Translate from Chinese to
    English.\nChinese: [zh_input]\nEnglish:" and label:"[en_input]" ?

    Thanks again!'
  created_at: 2023-12-15 10:49:08+00:00
  edited: false
  hidden: false
  id: 657c2f24504b90a3c5ad269a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-12-15T12:55:51.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9172423481941223
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;ZeroneBo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ZeroneBo\"\
          >@<span class=\"underline\">ZeroneBo</span></a></span>\n\n\t</span></span><br>Thanks\
          \ very much for getting back!<br>Indeed Chinese is not supported by flan\
          \ family at all :/ From what I recall, for the prompt template it should\
          \ be natural prompts such as <code>Translate from Chinese to English.\\\
          nChinese: [zh_input]\\nEnglish:</code><br>However, for translating I would\
          \ suggest to use NLLB family models which should in thoery support chinese\
          \ as well: <a href=\"https://huggingface.co/facebook/nllb-200-distilled-600M\"\
          >https://huggingface.co/facebook/nllb-200-distilled-600M</a> / <a href=\"\
          https://huggingface.co/docs/transformers/model_doc/nllb\">https://huggingface.co/docs/transformers/model_doc/nllb</a><br>If\
          \ you have enough GPU RAM, you can also run the NLLB-MoE model <a href=\"\
          https://huggingface.co/facebook/nllb-moe-54b\">https://huggingface.co/facebook/nllb-moe-54b</a>\
          \ - let me know how it goes!</p>\n"
        raw: "Hi @ZeroneBo \nThanks very much for getting back!\nIndeed Chinese is\
          \ not supported by flan family at all :/ From what I recall, for the prompt\
          \ template it should be natural prompts such as `Translate from Chinese\
          \ to English.\\nChinese: [zh_input]\\nEnglish:`\nHowever, for translating\
          \ I would suggest to use NLLB family models which should in thoery support\
          \ chinese as well: https://huggingface.co/facebook/nllb-200-distilled-600M\
          \ / https://huggingface.co/docs/transformers/model_doc/nllb\nIf you have\
          \ enough GPU RAM, you can also run the NLLB-MoE model https://huggingface.co/facebook/nllb-moe-54b\
          \ - let me know how it goes!"
        updatedAt: '2023-12-15T12:55:51.606Z'
      numEdits: 0
      reactions: []
    id: 657c4cd75a9de2407724c595
    type: comment
  author: ybelkada
  content: "Hi @ZeroneBo \nThanks very much for getting back!\nIndeed Chinese is not\
    \ supported by flan family at all :/ From what I recall, for the prompt template\
    \ it should be natural prompts such as `Translate from Chinese to English.\\nChinese:\
    \ [zh_input]\\nEnglish:`\nHowever, for translating I would suggest to use NLLB\
    \ family models which should in thoery support chinese as well: https://huggingface.co/facebook/nllb-200-distilled-600M\
    \ / https://huggingface.co/docs/transformers/model_doc/nllb\nIf you have enough\
    \ GPU RAM, you can also run the NLLB-MoE model https://huggingface.co/facebook/nllb-moe-54b\
    \ - let me know how it goes!"
  created_at: 2023-12-15 12:55:51+00:00
  edited: false
  hidden: false
  id: 657c4cd75a9de2407724c595
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e1f13940319dc25d3face90a5e6a2b99.svg
      fullname: ZeroneBo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ZeroneBo
      type: user
    createdAt: '2023-12-16T08:55:01.000Z'
    data:
      edited: true
      editors:
      - ZeroneBo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9188434481620789
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e1f13940319dc25d3face90a5e6a2b99.svg
          fullname: ZeroneBo
          isHf: false
          isPro: false
          name: ZeroneBo
          type: user
        html: "<p>Thank you <span data-props=\"{&quot;user&quot;:&quot;ybelkada&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ybelkada\"\
          >@<span class=\"underline\">ybelkada</span></a></span>\n\n\t</span></span><br>I\
          \ looked for some relevant documents of t5 and mt5 and readed them, the\
          \ pretrained mt5 can indeed only predict the sentinel tokens and should\
          \ finetune it with natural prompts before using it.<br>Another tiny technical\
          \ issue, to make train phase faster, when creating a batch of examples,\
          \ should it be dynamically padded as the length of longest squence in each\
          \ batch or all squences and all batches padded a bigger fixed num? In my\
          \ opinion, the dynamic method can save some GPU RAM and allow a bigger batch_size\
          \ but a fixed length may be faster too, maybe the two ways cost a similar\
          \ time and the differences between them can be ignored. Do you have any\
          \ suggestions based on your experience? My device is 2~3 * 32G V100 or 1~2\
          \ * 40G A100 and I installed accelerate and deepspeed py-lib.</p>\n"
        raw: "Thank you @ybelkada \nI looked for some relevant documents of t5 and\
          \ mt5 and readed them, the pretrained mt5 can indeed only predict the sentinel\
          \ tokens and should finetune it with natural prompts before using it. \n\
          Another tiny technical issue, to make train phase faster, when creating\
          \ a batch of examples, should it be dynamically padded as the length of\
          \ longest squence in each batch or all squences and all batches padded a\
          \ bigger fixed num? In my opinion, the dynamic method can save some GPU\
          \ RAM and allow a bigger batch_size but a fixed length may be faster too,\
          \ maybe the two ways cost a similar time and the differences between them\
          \ can be ignored. Do you have any suggestions based on your experience?\
          \ My device is 2\\~3 * 32G V100 or 1\\~2 * 40G A100 and I installed accelerate\
          \ and deepspeed py-lib.\n"
        updatedAt: '2023-12-16T08:59:40.028Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - ybelkada
    id: 657d65e5e1116d68e97a69bf
    type: comment
  author: ZeroneBo
  content: "Thank you @ybelkada \nI looked for some relevant documents of t5 and mt5\
    \ and readed them, the pretrained mt5 can indeed only predict the sentinel tokens\
    \ and should finetune it with natural prompts before using it. \nAnother tiny\
    \ technical issue, to make train phase faster, when creating a batch of examples,\
    \ should it be dynamically padded as the length of longest squence in each batch\
    \ or all squences and all batches padded a bigger fixed num? In my opinion, the\
    \ dynamic method can save some GPU RAM and allow a bigger batch_size but a fixed\
    \ length may be faster too, maybe the two ways cost a similar time and the differences\
    \ between them can be ignored. Do you have any suggestions based on your experience?\
    \ My device is 2\\~3 * 32G V100 or 1\\~2 * 40G A100 and I installed accelerate\
    \ and deepspeed py-lib.\n"
  created_at: 2023-12-16 08:55:01+00:00
  edited: true
  hidden: false
  id: 657d65e5e1116d68e97a69bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/e1f13940319dc25d3face90a5e6a2b99.svg
      fullname: ZeroneBo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ZeroneBo
      type: user
    createdAt: '2023-12-19T02:29:54.000Z'
    data:
      status: closed
    id: 65810022c15f9833027699a9
    type: status-change
  author: ZeroneBo
  created_at: 2023-12-19 02:29:54+00:00
  id: 65810022c15f9833027699a9
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: google/mt5-base
repo_type: model
status: closed
target_branch: null
title: model's output is abnormal
