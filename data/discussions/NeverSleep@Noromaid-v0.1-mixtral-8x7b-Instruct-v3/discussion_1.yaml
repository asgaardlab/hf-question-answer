!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sandmanbuzz
conflicting_files: null
created_at: 2023-12-27 14:22:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3c1057104f8a30de9242946d35f93a9a.svg
      fullname: z xcv
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sandmanbuzz
      type: user
    createdAt: '2023-12-27T14:22:27.000Z'
    data:
      edited: false
      editors:
      - sandmanbuzz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.968082070350647
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3c1057104f8a30de9242946d35f93a9a.svg
          fullname: z xcv
          isHf: false
          isPro: false
          name: sandmanbuzz
          type: user
        html: '<p>The test team came up with the below settings as the best we could
          do.  I don''t think any of us are going to use this model as a daily driver,
          but here''s what we did to salvage the model:</p>

          <p>Samplers Preset (this is the only thing that worked at all):<br><a rel="nofollow"
          href="https://files.catbox.moe/adpb5r.json">https://files.catbox.moe/adpb5r.json</a><br>t=1.50,
          min.p=0.018, and it''s not a terrible idea to add some tfs to take the edge
          off so I did that in this version of the file</p>

          <p>Fixed Instruct Preset:<br>There was some wishful thinking junk in the
          existing preset that I removed, and some style guide stuff that shouldn''t
          have been there (and would break lots of cards), and the model does MUCH
          better using mistral instruct than it does under Alpaca.  I fixed that.<br><a
          rel="nofollow" href="https://files.catbox.moe/bjibow.json">https://files.catbox.moe/bjibow.json</a></p>

          <p>It''s probably not a bad idea to fix your context template to have [INST]
          [/INST] around it, too.  I''m not going to bother to make a preset for that,
          anyone can do that themselves.</p>

          <p>Thanks, Undi!</p>

          <p>Like I said in discord, this is the closest Noromaid to "usable" we''ve
          seen so far.  Better than the non-instruct.</p>

          '
        raw: "The test team came up with the below settings as the best we could do.\
          \  I don't think any of us are going to use this model as a daily driver,\
          \ but here's what we did to salvage the model:\r\n\r\nSamplers Preset (this\
          \ is the only thing that worked at all):\r\nhttps://files.catbox.moe/adpb5r.json\r\
          \nt=1.50, min.p=0.018, and it's not a terrible idea to add some tfs to take\
          \ the edge off so I did that in this version of the file\r\n\r\nFixed Instruct\
          \ Preset: \r\nThere was some wishful thinking junk in the existing preset\
          \ that I removed, and some style guide stuff that shouldn't have been there\
          \ (and would break lots of cards), and the model does MUCH better using\
          \ mistral instruct than it does under Alpaca.  I fixed that.\r\nhttps://files.catbox.moe/bjibow.json\r\
          \n\r\nIt's probably not a bad idea to fix your context template to have\
          \ [INST] [/INST] around it, too.  I'm not going to bother to make a preset\
          \ for that, anyone can do that themselves.\r\n\r\nThanks, Undi!\r\n\r\n\
          Like I said in discord, this is the closest Noromaid to \"usable\" we've\
          \ seen so far.  Better than the non-instruct."
        updatedAt: '2023-12-27T14:22:27.402Z'
      numEdits: 0
      reactions: []
    id: 658c3323c1229bf1132c1c1f
    type: comment
  author: sandmanbuzz
  content: "The test team came up with the below settings as the best we could do.\
    \  I don't think any of us are going to use this model as a daily driver, but\
    \ here's what we did to salvage the model:\r\n\r\nSamplers Preset (this is the\
    \ only thing that worked at all):\r\nhttps://files.catbox.moe/adpb5r.json\r\n\
    t=1.50, min.p=0.018, and it's not a terrible idea to add some tfs to take the\
    \ edge off so I did that in this version of the file\r\n\r\nFixed Instruct Preset:\
    \ \r\nThere was some wishful thinking junk in the existing preset that I removed,\
    \ and some style guide stuff that shouldn't have been there (and would break lots\
    \ of cards), and the model does MUCH better using mistral instruct than it does\
    \ under Alpaca.  I fixed that.\r\nhttps://files.catbox.moe/bjibow.json\r\n\r\n\
    It's probably not a bad idea to fix your context template to have [INST] [/INST]\
    \ around it, too.  I'm not going to bother to make a preset for that, anyone can\
    \ do that themselves.\r\n\r\nThanks, Undi!\r\n\r\nLike I said in discord, this\
    \ is the closest Noromaid to \"usable\" we've seen so far.  Better than the non-instruct."
  created_at: 2023-12-27 14:22:27+00:00
  edited: false
  hidden: false
  id: 658c3323c1229bf1132c1c1f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
      fullname: IkariDev
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: IkariDev
      type: user
    createdAt: '2023-12-27T14:57:00.000Z'
    data:
      edited: false
      editors:
      - IkariDev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9294052124023438
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
          fullname: IkariDev
          isHf: false
          isPro: false
          name: IkariDev
          type: user
        html: '<p>You know this model is <strong>only</strong> intended for rp right?</p>

          '
        raw: You know this model is **only** intended for rp right?
        updatedAt: '2023-12-27T14:57:00.754Z'
      numEdits: 0
      reactions: []
    id: 658c3b3c5a8f8a309e8a2530
    type: comment
  author: IkariDev
  content: You know this model is **only** intended for rp right?
  created_at: 2023-12-27 14:57:00+00:00
  edited: false
  hidden: false
  id: 658c3b3c5a8f8a309e8a2530
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3c1057104f8a30de9242946d35f93a9a.svg
      fullname: z xcv
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sandmanbuzz
      type: user
    createdAt: '2023-12-27T14:58:41.000Z'
    data:
      edited: false
      editors:
      - sandmanbuzz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9730261564254761
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3c1057104f8a30de9242946d35f93a9a.svg
          fullname: z xcv
          isHf: false
          isPro: false
          name: sandmanbuzz
          type: user
        html: '<p>That''s almost entirely the test use case we put it through.</p>

          '
        raw: That's almost entirely the test use case we put it through.
        updatedAt: '2023-12-27T14:58:41.406Z'
      numEdits: 0
      reactions: []
    id: 658c3ba1bc3644bd239850a0
    type: comment
  author: sandmanbuzz
  content: That's almost entirely the test use case we put it through.
  created_at: 2023-12-27 14:58:41+00:00
  edited: false
  hidden: false
  id: 658c3ba1bc3644bd239850a0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
      fullname: IkariDev
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: IkariDev
      type: user
    createdAt: '2023-12-27T15:01:04.000Z'
    data:
      edited: false
      editors:
      - IkariDev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9717667102813721
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
          fullname: IkariDev
          isHf: false
          isPro: false
          name: IkariDev
          type: user
        html: '<p>Ok then i really dont understand why it failed/did bad at most tests,
          this models is by far the best mistral model ive tried for rp, which some
          other agreed with. And no we are not gonna adjust our template to use [INST]
          stuff as the model was trained on alpaca.</p>

          '
        raw: Ok then i really dont understand why it failed/did bad at most tests,
          this models is by far the best mistral model ive tried for rp, which some
          other agreed with. And no we are not gonna adjust our template to use [INST]
          stuff as the model was trained on alpaca.
        updatedAt: '2023-12-27T15:01:04.734Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Midgardsormr
    id: 658c3c305578adf7aa17e790
    type: comment
  author: IkariDev
  content: Ok then i really dont understand why it failed/did bad at most tests, this
    models is by far the best mistral model ive tried for rp, which some other agreed
    with. And no we are not gonna adjust our template to use [INST] stuff as the model
    was trained on alpaca.
  created_at: 2023-12-27 15:01:04+00:00
  edited: false
  hidden: false
  id: 658c3c305578adf7aa17e790
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
      fullname: IkariDev
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: IkariDev
      type: user
    createdAt: '2023-12-27T15:01:59.000Z'
    data:
      edited: false
      editors:
      - IkariDev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5825015902519226
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
          fullname: IkariDev
          isHf: false
          isPro: false
          name: IkariDev
          type: user
        html: '<p>*Mixtral</p>

          '
        raw: '*Mixtral

          '
        updatedAt: '2023-12-27T15:01:59.134Z'
      numEdits: 0
      reactions: []
    id: 658c3c677ecef7270a0e866f
    type: comment
  author: IkariDev
  content: '*Mixtral

    '
  created_at: 2023-12-27 15:01:59+00:00
  edited: false
  hidden: false
  id: 658c3c677ecef7270a0e866f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3c1057104f8a30de9242946d35f93a9a.svg
      fullname: z xcv
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sandmanbuzz
      type: user
    createdAt: '2023-12-27T15:18:02.000Z'
    data:
      edited: false
      editors:
      - sandmanbuzz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9554025530815125
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3c1057104f8a30de9242946d35f93a9a.svg
          fullname: z xcv
          isHf: false
          isPro: false
          name: sandmanbuzz
          type: user
        html: "<p>It was really nice to see the fresh prose and card behavior coming\
          \ out of it, similar to base Mixtral-instruct.  However it has the typical\
          \ Noro symptoms of maddeningly bad terseness, hence the ridiculously low\
          \ recommended min.p, which was the only way we could get it to stop that.\
          \   And generally the inability to crit.  Crit rate (positive reader surprise\
          \ at the response) went up when we moved away from Alpaca-like to [INST]\
          \ stuff on a lark knowing full well the training was against Alpaca, but\
          \ there's still only that tiny narrow band of min.p that is usable at all.\
          \  Outside that band, it falls into terseness or plain/boring responses\
          \ (with higher min.p), overly-prosaic pseudo-intellectual excessiveness\
          \ (with lower min.p or higher temp), or loses traction on card instructions.\
          \  We didn't find a way to get it closer to a razor edge of crit rate (high\
          \ level of reader surprise) / card adherence / token surprise like one gets\
          \ with ultra-high miro \u2014platinum and above\u2014 on non-MoE models\
          \ with Lightning instruct and Lightning 1.2 AN.</p>\n<p>There's clearly\
          \ more to come from this line of work, but overcoming the head-desk factor\
          \ of Noro blurting out tiny, non-continuable responses and low crit rate\
          \ is going to take some research on the prompting side.</p>\n<p>For those\
          \ folks continuing to use this model, we highly recommend one or more of\
          \ the presets I provided.  The sampler preset alone did help, and [INST]\
          \ stuff really did get results.</p>\n"
        raw: "It was really nice to see the fresh prose and card behavior coming out\
          \ of it, similar to base Mixtral-instruct.  However it has the typical Noro\
          \ symptoms of maddeningly bad terseness, hence the ridiculously low recommended\
          \ min.p, which was the only way we could get it to stop that.   And generally\
          \ the inability to crit.  Crit rate (positive reader surprise at the response)\
          \ went up when we moved away from Alpaca-like to [INST] stuff on a lark\
          \ knowing full well the training was against Alpaca, but there's still only\
          \ that tiny narrow band of min.p that is usable at all.  Outside that band,\
          \ it falls into terseness or plain/boring responses (with higher min.p),\
          \ overly-prosaic pseudo-intellectual excessiveness (with lower min.p or\
          \ higher temp), or loses traction on card instructions.  We didn't find\
          \ a way to get it closer to a razor edge of crit rate (high level of reader\
          \ surprise) / card adherence / token surprise like one gets with ultra-high\
          \ miro \u2014platinum and above\u2014 on non-MoE models with Lightning instruct\
          \ and Lightning 1.2 AN.\n\nThere's clearly more to come from this line of\
          \ work, but overcoming the head-desk factor of Noro blurting out tiny, non-continuable\
          \ responses and low crit rate is going to take some research on the prompting\
          \ side.\n\nFor those folks continuing to use this model, we highly recommend\
          \ one or more of the presets I provided.  The sampler preset alone did help,\
          \ and [INST] stuff really did get results."
        updatedAt: '2023-12-27T15:18:02.536Z'
      numEdits: 0
      reactions: []
    id: 658c402a2e5a4350cf754aa2
    type: comment
  author: sandmanbuzz
  content: "It was really nice to see the fresh prose and card behavior coming out\
    \ of it, similar to base Mixtral-instruct.  However it has the typical Noro symptoms\
    \ of maddeningly bad terseness, hence the ridiculously low recommended min.p,\
    \ which was the only way we could get it to stop that.   And generally the inability\
    \ to crit.  Crit rate (positive reader surprise at the response) went up when\
    \ we moved away from Alpaca-like to [INST] stuff on a lark knowing full well the\
    \ training was against Alpaca, but there's still only that tiny narrow band of\
    \ min.p that is usable at all.  Outside that band, it falls into terseness or\
    \ plain/boring responses (with higher min.p), overly-prosaic pseudo-intellectual\
    \ excessiveness (with lower min.p or higher temp), or loses traction on card instructions.\
    \  We didn't find a way to get it closer to a razor edge of crit rate (high level\
    \ of reader surprise) / card adherence / token surprise like one gets with ultra-high\
    \ miro \u2014platinum and above\u2014 on non-MoE models with Lightning instruct\
    \ and Lightning 1.2 AN.\n\nThere's clearly more to come from this line of work,\
    \ but overcoming the head-desk factor of Noro blurting out tiny, non-continuable\
    \ responses and low crit rate is going to take some research on the prompting\
    \ side.\n\nFor those folks continuing to use this model, we highly recommend one\
    \ or more of the presets I provided.  The sampler preset alone did help, and [INST]\
    \ stuff really did get results."
  created_at: 2023-12-27 15:18:02+00:00
  edited: false
  hidden: false
  id: 658c402a2e5a4350cf754aa2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3c1057104f8a30de9242946d35f93a9a.svg
      fullname: z xcv
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sandmanbuzz
      type: user
    createdAt: '2023-12-27T15:33:05.000Z'
    data:
      edited: false
      editors:
      - sandmanbuzz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9350721836090088
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3c1057104f8a30de9242946d35f93a9a.svg
          fullname: z xcv
          isHf: false
          isPro: false
          name: sandmanbuzz
          type: user
        html: "<p>It's also worth mentioning that I personally found it stronger in\
          \ ERP chat segments\u2014and in those unit tests\u2014over a broader range\
          \ of presets, but that non-ERP segments of chat fell apart badly outside\
          \ the tiny min.p band.  Other testers seemed to prefer the narrow band.\
          \  For regular users, it might be worth noting that turning up the temp\
          \ sampler is something you can do when \"turning up the heat\" in your chat.</p>\n"
        raw: "It's also worth mentioning that I personally found it stronger in ERP\
          \ chat segments\u2014and in those unit tests\u2014over a broader range of\
          \ presets, but that non-ERP segments of chat fell apart badly outside the\
          \ tiny min.p band.  Other testers seemed to prefer the narrow band.  For\
          \ regular users, it might be worth noting that turning up the temp sampler\
          \ is something you can do when \"turning up the heat\" in your chat."
        updatedAt: '2023-12-27T15:33:05.863Z'
      numEdits: 0
      reactions: []
    id: 658c43b1f075fa6df1910770
    type: comment
  author: sandmanbuzz
  content: "It's also worth mentioning that I personally found it stronger in ERP\
    \ chat segments\u2014and in those unit tests\u2014over a broader range of presets,\
    \ but that non-ERP segments of chat fell apart badly outside the tiny min.p band.\
    \  Other testers seemed to prefer the narrow band.  For regular users, it might\
    \ be worth noting that turning up the temp sampler is something you can do when\
    \ \"turning up the heat\" in your chat."
  created_at: 2023-12-27 15:33:05+00:00
  edited: false
  hidden: false
  id: 658c43b1f075fa6df1910770
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
      fullname: IkariDev
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: IkariDev
      type: user
    createdAt: '2023-12-27T15:53:22.000Z'
    data:
      edited: false
      editors:
      - IkariDev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9849991202354431
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
          fullname: IkariDev
          isHf: false
          isPro: false
          name: IkariDev
          type: user
        html: '<p>I understand your point, maybe im just into differerent rp but for
          me personally i have not encountered these problems. Almost all sampler
          present in sillytavern worked for me. If you have any example chats you
          could kindly provide i could maybe catch on the problems you were having.
          One thing i should note is that the majority of this model was trained on
          this format: *do* say.</p>

          '
        raw: 'I understand your point, maybe im just into differerent rp but for me
          personally i have not encountered these problems. Almost all sampler present
          in sillytavern worked for me. If you have any example chats you could kindly
          provide i could maybe catch on the problems you were having. One thing i
          should note is that the majority of this model was trained on this format:
          \*do\* say.'
        updatedAt: '2023-12-27T15:53:22.830Z'
      numEdits: 0
      reactions: []
    id: 658c48722e5a4350cf768d02
    type: comment
  author: IkariDev
  content: 'I understand your point, maybe im just into differerent rp but for me
    personally i have not encountered these problems. Almost all sampler present in
    sillytavern worked for me. If you have any example chats you could kindly provide
    i could maybe catch on the problems you were having. One thing i should note is
    that the majority of this model was trained on this format: \*do\* say.'
  created_at: 2023-12-27 15:53:22+00:00
  edited: false
  hidden: false
  id: 658c48722e5a4350cf768d02
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
      fullname: IkariDev
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: IkariDev
      type: user
    createdAt: '2023-12-27T15:56:03.000Z'
    data:
      edited: false
      editors:
      - IkariDev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7691655158996582
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667690511692-630dfb008df86f1e5becadc3.png?w=200&h=200&f=face
          fullname: IkariDev
          isHf: false
          isPro: false
          name: IkariDev
          type: user
        html: '<p>Also i should ask, when you mean "most usable in the noromaid series",
          do you mean the entire series(7b, 13b, 20b), or just the mixtral noromaids?</p>

          '
        raw: Also i should ask, when you mean "most usable in the noromaid series",
          do you mean the entire series(7b, 13b, 20b), or just the mixtral noromaids?
        updatedAt: '2023-12-27T15:56:03.609Z'
      numEdits: 0
      reactions: []
    id: 658c49131260e506f1600929
    type: comment
  author: IkariDev
  content: Also i should ask, when you mean "most usable in the noromaid series",
    do you mean the entire series(7b, 13b, 20b), or just the mixtral noromaids?
  created_at: 2023-12-27 15:56:03+00:00
  edited: false
  hidden: false
  id: 658c49131260e506f1600929
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3c1057104f8a30de9242946d35f93a9a.svg
      fullname: z xcv
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sandmanbuzz
      type: user
    createdAt: '2023-12-27T16:33:18.000Z'
    data:
      edited: false
      editors:
      - sandmanbuzz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.969265878200531
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3c1057104f8a30de9242946d35f93a9a.svg
          fullname: z xcv
          isHf: false
          isPro: false
          name: sandmanbuzz
          type: user
        html: "<p>Our testing of Noromaids has been pretty sporadic; tester bandwidth\
          \ and attention isn't unlimited, and it's a relatively manual\u2014and frankly,\
          \ somewhat ad hoc\u2014process since it's done by editorial reading and\
          \ evaluation rather than by statistical analysis.  The llama Noromaids got\
          \ fairly cursory examination, without a lot of fussing around with samplers\
          \ and instruct since they respond to standard miro settings.  Since it was\
          \ much harder to break them of terseness, testing effort tapered off pretty\
          \ quickly, pretty much \"yep, it's a Noro, wait for the next one.\"</p>\n\
          <p>We put a little more effort into non-instruct, but since early results\
          \ looked similar to past results we threw it back into the pond.  This one\
          \ got focused attention at Undi's request, and by serendipity we had a nice\
          \ day with multiple testers available to collaborate synchronously, which\
          \ gives faster, deeper results.</p>\n<p>The \"<em>do</em> say\" dataset\
          \ definitely comes out, and in my purely personal opinion, I think it's\
          \ overtrained to it and that's what leads me to bounce off of Noro models.\
          \ Pacing is often slow and terse, with <em>do</em> being at most a very\
          \ short paragraph, and \"say\" being a single line of dialogue.  It doesn't\
          \ give enough room for character expression, action, or reaction, or allow\
          \ for multiple threads of conversation.  Cards respond with brevity that\
          \ doesn't reflect the user prompt, or even the description or AN instruction.\
          \  This winds up being disappointing in early chat, especially, and limits\
          \ richness and immersion.  It's especially tough with some types of character\
          \ RP spawners, since spawners rely on the desc instructions to fire a rich\
          \ \"#2\" as their real FM.</p>\n<p>Purely personal anecdote again, rather\
          \ than recorded test result, but cards with stronger FMs tend to do better\
          \ than weak FMs, as you'd expect a lot of models to do, but because of the\
          \ more constrained options for high temp or other \"digging deep for tokens\"\
          \ sampling you can't prod your way past the \"<em>do</em> say\" training\
          \ to get around it.  Some of the more old school llama models (like Emer,\
          \ Psyfighter, or Sydney) can really shine in situations like this where\
          \ the user needs the model to bootstrap a chat out of the desc.</p>\n<p>For\
          \ use cases where a paragraph of <em>do</em> say is what the user wants,\
          \ Noromaid default does the deed.  Getting a solid, 300-600 token response\
          \ that doesn't quite start to trail off into white text or parroting yet,\
          \ that's not what it does.</p>\n"
        raw: "Our testing of Noromaids has been pretty sporadic; tester bandwidth\
          \ and attention isn't unlimited, and it's a relatively manual\u2014and frankly,\
          \ somewhat ad hoc\u2014process since it's done by editorial reading and\
          \ evaluation rather than by statistical analysis.  The llama Noromaids got\
          \ fairly cursory examination, without a lot of fussing around with samplers\
          \ and instruct since they respond to standard miro settings.  Since it was\
          \ much harder to break them of terseness, testing effort tapered off pretty\
          \ quickly, pretty much \"yep, it's a Noro, wait for the next one.\"\n\n\
          We put a little more effort into non-instruct, but since early results looked\
          \ similar to past results we threw it back into the pond.  This one got\
          \ focused attention at Undi's request, and by serendipity we had a nice\
          \ day with multiple testers available to collaborate synchronously, which\
          \ gives faster, deeper results.\n\nThe \"*do* say\" dataset definitely comes\
          \ out, and in my purely personal opinion, I think it's overtrained to it\
          \ and that's what leads me to bounce off of Noro models. Pacing is often\
          \ slow and terse, with *do* being at most a very short paragraph, and \"\
          say\" being a single line of dialogue.  It doesn't give enough room for\
          \ character expression, action, or reaction, or allow for multiple threads\
          \ of conversation.  Cards respond with brevity that doesn't reflect the\
          \ user prompt, or even the description or AN instruction.  This winds up\
          \ being disappointing in early chat, especially, and limits richness and\
          \ immersion.  It's especially tough with some types of character RP spawners,\
          \ since spawners rely on the desc instructions to fire a rich \"#2\" as\
          \ their real FM.\n\nPurely personal anecdote again, rather than recorded\
          \ test result, but cards with stronger FMs tend to do better than weak FMs,\
          \ as you'd expect a lot of models to do, but because of the more constrained\
          \ options for high temp or other \"digging deep for tokens\" sampling you\
          \ can't prod your way past the \"*do* say\" training to get around it. \
          \ Some of the more old school llama models (like Emer, Psyfighter, or Sydney)\
          \ can really shine in situations like this where the user needs the model\
          \ to bootstrap a chat out of the desc.\n\nFor use cases where a paragraph\
          \ of *do* say is what the user wants, Noromaid default does the deed.  Getting\
          \ a solid, 300-600 token response that doesn't quite start to trail off\
          \ into white text or parroting yet, that's not what it does."
        updatedAt: '2023-12-27T16:33:18.195Z'
      numEdits: 0
      reactions: []
    id: 658c51ce6f797d950b861cab
    type: comment
  author: sandmanbuzz
  content: "Our testing of Noromaids has been pretty sporadic; tester bandwidth and\
    \ attention isn't unlimited, and it's a relatively manual\u2014and frankly, somewhat\
    \ ad hoc\u2014process since it's done by editorial reading and evaluation rather\
    \ than by statistical analysis.  The llama Noromaids got fairly cursory examination,\
    \ without a lot of fussing around with samplers and instruct since they respond\
    \ to standard miro settings.  Since it was much harder to break them of terseness,\
    \ testing effort tapered off pretty quickly, pretty much \"yep, it's a Noro, wait\
    \ for the next one.\"\n\nWe put a little more effort into non-instruct, but since\
    \ early results looked similar to past results we threw it back into the pond.\
    \  This one got focused attention at Undi's request, and by serendipity we had\
    \ a nice day with multiple testers available to collaborate synchronously, which\
    \ gives faster, deeper results.\n\nThe \"*do* say\" dataset definitely comes out,\
    \ and in my purely personal opinion, I think it's overtrained to it and that's\
    \ what leads me to bounce off of Noro models. Pacing is often slow and terse,\
    \ with *do* being at most a very short paragraph, and \"say\" being a single line\
    \ of dialogue.  It doesn't give enough room for character expression, action,\
    \ or reaction, or allow for multiple threads of conversation.  Cards respond with\
    \ brevity that doesn't reflect the user prompt, or even the description or AN\
    \ instruction.  This winds up being disappointing in early chat, especially, and\
    \ limits richness and immersion.  It's especially tough with some types of character\
    \ RP spawners, since spawners rely on the desc instructions to fire a rich \"\
    #2\" as their real FM.\n\nPurely personal anecdote again, rather than recorded\
    \ test result, but cards with stronger FMs tend to do better than weak FMs, as\
    \ you'd expect a lot of models to do, but because of the more constrained options\
    \ for high temp or other \"digging deep for tokens\" sampling you can't prod your\
    \ way past the \"*do* say\" training to get around it.  Some of the more old school\
    \ llama models (like Emer, Psyfighter, or Sydney) can really shine in situations\
    \ like this where the user needs the model to bootstrap a chat out of the desc.\n\
    \nFor use cases where a paragraph of *do* say is what the user wants, Noromaid\
    \ default does the deed.  Getting a solid, 300-600 token response that doesn't\
    \ quite start to trail off into white text or parroting yet, that's not what it\
    \ does."
  created_at: 2023-12-27 16:33:18+00:00
  edited: false
  hidden: false
  id: 658c51ce6f797d950b861cab
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: NeverSleep/Noromaid-v0.1-mixtral-8x7b-Instruct-v3
repo_type: model
status: open
target_branch: null
title: Settings from the test team
