!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AliceThirty
conflicting_files: null
created_at: 2024-01-01 20:36:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/08ef692a79efbf9ae1448743740f1a99.svg
      fullname: Smaug Leterrible
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AliceThirty
      type: user
    createdAt: '2024-01-01T20:36:28.000Z'
    data:
      edited: true
      editors:
      - AliceThirty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9185823202133179
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/08ef692a79efbf9ae1448743740f1a99.svg
          fullname: Smaug Leterrible
          isHf: false
          isPro: false
          name: AliceThirty
          type: user
        html: '<p>Thank you, this model is doing extremely good AND it''s running
          on my laptop! I love it.<br>Sorry if I missed the information somewhere
          but what''s the context size please?</p>

          '
        raw: "Thank you, this model is doing extremely good AND it's running on my\
          \ laptop! I love it. \nSorry if I missed the information somewhere but what's\
          \ the context size please?"
        updatedAt: '2024-01-01T20:57:44.098Z'
      numEdits: 1
      reactions: []
    id: 6593224cb72f4ce63ba47114
    type: comment
  author: AliceThirty
  content: "Thank you, this model is doing extremely good AND it's running on my laptop!\
    \ I love it. \nSorry if I missed the information somewhere but what's the context\
    \ size please?"
  created_at: 2024-01-01 20:36:28+00:00
  edited: true
  hidden: false
  id: 6593224cb72f4ce63ba47114
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/08ef692a79efbf9ae1448743740f1a99.svg
      fullname: Smaug Leterrible
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AliceThirty
      type: user
    createdAt: '2024-01-01T20:57:53.000Z'
    data:
      from: Context size?
      to: What's the context size ?
    id: 65932751e7c71d6d9e75da2e
    type: title-change
  author: AliceThirty
  created_at: 2024-01-01 20:57:53+00:00
  id: 65932751e7c71d6d9e75da2e
  new_title: What's the context size ?
  old_title: Context size?
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ea2244afe294e6174b2726089b9ae64a.svg
      fullname: None Tobeknown
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Firepin
      type: user
    createdAt: '2024-01-01T21:34:19.000Z'
    data:
      edited: false
      editors:
      - Firepin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6488155126571655
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ea2244afe294e6174b2726089b9ae64a.svg
          fullname: None Tobeknown
          isHf: false
          isPro: false
          name: Firepin
          type: user
        html: '<p>should be 32000</p>

          '
        raw: should be 32000
        updatedAt: '2024-01-01T21:34:19.776Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - AliceThirty
    id: 65932fdbf0152a21fc5dd4a4
    type: comment
  author: Firepin
  content: should be 32000
  created_at: 2024-01-01 21:34:19+00:00
  edited: false
  hidden: false
  id: 65932fdbf0152a21fc5dd4a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Undi95
      type: user
    createdAt: '2024-01-02T00:16:14.000Z'
    data:
      edited: false
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9683996438980103
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<p>Yes, same as Mixtral! 32k</p>

          '
        raw: Yes, same as Mixtral! 32k
        updatedAt: '2024-01-02T00:16:14.244Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - AliceThirty
    id: 659355ce43971eed457968bc
    type: comment
  author: Undi95
  content: Yes, same as Mixtral! 32k
  created_at: 2024-01-02 00:16:14+00:00
  edited: false
  hidden: false
  id: 659355ce43971eed457968bc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/08ef692a79efbf9ae1448743740f1a99.svg
      fullname: Smaug Leterrible
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AliceThirty
      type: user
    createdAt: '2024-01-02T00:47:49.000Z'
    data:
      edited: false
      editors:
      - AliceThirty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.46368739008903503
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/08ef692a79efbf9ae1448743740f1a99.svg
          fullname: Smaug Leterrible
          isHf: false
          isPro: false
          name: AliceThirty
          type: user
        html: '<p>Thank you!</p>

          '
        raw: Thank you!
        updatedAt: '2024-01-02T00:47:49.285Z'
      numEdits: 0
      reactions: []
    id: 65935d352a0a886ef0977f37
    type: comment
  author: AliceThirty
  content: Thank you!
  created_at: 2024-01-02 00:47:49+00:00
  edited: false
  hidden: false
  id: 65935d352a0a886ef0977f37
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8be96de1d60161f4efa40e778f75712e.svg
      fullname: Johnathan Corbano
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: papercanteen111
      type: user
    createdAt: '2024-01-02T13:34:56.000Z'
    data:
      edited: false
      editors:
      - papercanteen111
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9443089962005615
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8be96de1d60161f4efa40e778f75712e.svg
          fullname: Johnathan Corbano
          isHf: false
          isPro: false
          name: papercanteen111
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;AliceThirty&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/AliceThirty\"\
          >@<span class=\"underline\">AliceThirty</span></a></span>\n\n\t</span></span>\
          \ what kind of GPU in that laptop?  I've been unable to get it working with\
          \ 8gb VRAM and 64gb ram :thinkies:</p>\n"
        raw: '@AliceThirty what kind of GPU in that laptop?  I''ve been unable to
          get it working with 8gb VRAM and 64gb ram :thinkies:'
        updatedAt: '2024-01-02T13:34:56.945Z'
      numEdits: 0
      reactions: []
    id: 65941100f7291078f971d6e4
    type: comment
  author: papercanteen111
  content: '@AliceThirty what kind of GPU in that laptop?  I''ve been unable to get
    it working with 8gb VRAM and 64gb ram :thinkies:'
  created_at: 2024-01-02 13:34:56+00:00
  edited: false
  hidden: false
  id: 65941100f7291078f971d6e4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/80eb489f00cf499ab4d87ff349102222.svg
      fullname: Sergey Kiseev
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sergkisel3v
      type: user
    createdAt: '2024-01-02T13:50:51.000Z'
    data:
      edited: false
      editors:
      - sergkisel3v
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8229318261146545
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/80eb489f00cf499ab4d87ff349102222.svg
          fullname: Sergey Kiseev
          isHf: false
          isPro: false
          name: sergkisel3v
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;papercanteen111&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/papercanteen111\"\
          >@<span class=\"underline\">papercanteen111</span></a></span>\n\n\t</span></span>\
          \ According to Mistral AI, original Mixtral needs around 110 gb of VRAM\
          \ (~2x V100 80gb in cloud), but you can run quantized gguf version on CPU&amp;gpu\
          \ (I'm running 4 but quantization on 64 gb ram + 8gb VRAM and it works pretty\
          \ well).</p>\n"
        raw: '@papercanteen111 According to Mistral AI, original Mixtral needs around
          110 gb of VRAM (~2x V100 80gb in cloud), but you can run quantized gguf
          version on CPU&gpu (I''m running 4 but quantization on 64 gb ram + 8gb VRAM
          and it works pretty well).'
        updatedAt: '2024-01-02T13:50:51.802Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - papercanteen111
    id: 659414bbc04427eb3811094c
    type: comment
  author: sergkisel3v
  content: '@papercanteen111 According to Mistral AI, original Mixtral needs around
    110 gb of VRAM (~2x V100 80gb in cloud), but you can run quantized gguf version
    on CPU&gpu (I''m running 4 but quantization on 64 gb ram + 8gb VRAM and it works
    pretty well).'
  created_at: 2024-01-02 13:50:51+00:00
  edited: false
  hidden: false
  id: 659414bbc04427eb3811094c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/SskUDcMVnMSZrCGcplXwv.png?w=200&h=200&f=face
      fullname: hyeonse o
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hyeonse
      type: user
    createdAt: '2024-01-03T14:52:50.000Z'
    data:
      edited: false
      editors:
      - hyeonse
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9297577142715454
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/SskUDcMVnMSZrCGcplXwv.png?w=200&h=200&f=face
          fullname: hyeonse o
          isHf: false
          isPro: false
          name: hyeonse
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;papercanteen111&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/papercanteen111\"\
          >@<span class=\"underline\">papercanteen111</span></a></span>\n\n\t</span></span>\
          \ Experimentally I've succeeded in making a q3 of this model \"run\" on\
          \ my GPU with 12gb VRAM, but it would take actual 8 minutes to load 2k context\
          \ and take 3 minutes to produce a response at 0.4 tokens per second. I'm\
          \ toying with it on a rented 48gb VRAM GPU and it generates faster than\
          \ my eye can read in that environment.</p>\n<p>Additionally there's some\
          \ researching regarding HQQ + MoE offloading that has succeeded in making\
          \ Mixtral 8x7b run at usable speed in 12gb VRAM happening as of two days\
          \ ago. Maybe there will be an easy way to generalize that effect for all\
          \ MoEs soon?</p>\n"
        raw: '@papercanteen111 Experimentally I''ve succeeded in making a q3 of this
          model "run" on my GPU with 12gb VRAM, but it would take actual 8 minutes
          to load 2k context and take 3 minutes to produce a response at 0.4 tokens
          per second. I''m toying with it on a rented 48gb VRAM GPU and it generates
          faster than my eye can read in that environment.


          Additionally there''s some researching regarding HQQ + MoE offloading that
          has succeeded in making Mixtral 8x7b run at usable speed in 12gb VRAM happening
          as of two days ago. Maybe there will be an easy way to generalize that effect
          for all MoEs soon?'
        updatedAt: '2024-01-03T14:52:50.839Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - papercanteen111
    id: 659574c2fbbe972cfb2db82b
    type: comment
  author: hyeonse
  content: '@papercanteen111 Experimentally I''ve succeeded in making a q3 of this
    model "run" on my GPU with 12gb VRAM, but it would take actual 8 minutes to load
    2k context and take 3 minutes to produce a response at 0.4 tokens per second.
    I''m toying with it on a rented 48gb VRAM GPU and it generates faster than my
    eye can read in that environment.


    Additionally there''s some researching regarding HQQ + MoE offloading that has
    succeeded in making Mixtral 8x7b run at usable speed in 12gb VRAM happening as
    of two days ago. Maybe there will be an easy way to generalize that effect for
    all MoEs soon?'
  created_at: 2024-01-03 14:52:50+00:00
  edited: false
  hidden: false
  id: 659574c2fbbe972cfb2db82b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/08ef692a79efbf9ae1448743740f1a99.svg
      fullname: Smaug Leterrible
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AliceThirty
      type: user
    createdAt: '2024-01-04T08:46:12.000Z'
    data:
      edited: true
      editors:
      - AliceThirty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9031654596328735
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/08ef692a79efbf9ae1448743740f1a99.svg
          fullname: Smaug Leterrible
          isHf: false
          isPro: false
          name: AliceThirty
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;AliceThirty&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/AliceThirty\"\
          >@<span class=\"underline\">AliceThirty</span></a></span>\n\n\t</span></span>\
          \ what kind of GPU in that laptop?  I've been unable to get it working with\
          \ 8gb VRAM and 64gb ram :thinkies:</p>\n</blockquote>\n<p>Sorry for the\
          \ missunderstanding, I am not running this model but the GGUF version (Q5_K_M)\
          \ on my laptop. I have 64GB of RAM and a rtx 3080 ti with 16GB of VRAM<br>(I\
          \ opened this thread in the wrong page)</p>\n"
        raw: '> @AliceThirty what kind of GPU in that laptop?  I''ve been unable to
          get it working with 8gb VRAM and 64gb ram :thinkies:


          Sorry for the missunderstanding, I am not running this model but the GGUF
          version (Q5_K_M) on my laptop. I have 64GB of RAM and a rtx 3080 ti with
          16GB of VRAM

          (I opened this thread in the wrong page)'
        updatedAt: '2024-01-04T08:48:39.251Z'
      numEdits: 2
      reactions: []
    id: 659670543c052b956a36f573
    type: comment
  author: AliceThirty
  content: '> @AliceThirty what kind of GPU in that laptop?  I''ve been unable to
    get it working with 8gb VRAM and 64gb ram :thinkies:


    Sorry for the missunderstanding, I am not running this model but the GGUF version
    (Q5_K_M) on my laptop. I have 64GB of RAM and a rtx 3080 ti with 16GB of VRAM

    (I opened this thread in the wrong page)'
  created_at: 2024-01-04 08:46:12+00:00
  edited: true
  hidden: false
  id: 659670543c052b956a36f573
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: NeverSleep/Noromaid-v0.1-mixtral-8x7b-Instruct-v3
repo_type: model
status: open
target_branch: null
title: What's the context size ?
