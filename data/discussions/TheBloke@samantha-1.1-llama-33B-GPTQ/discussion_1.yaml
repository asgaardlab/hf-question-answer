!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cleverest
conflicting_files: null
created_at: 2023-07-10 14:02:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1f437f318770edea28ec92d7cb14bd73.svg
      fullname: Brett S
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cleverest
      type: user
    createdAt: '2023-07-10T15:02:04.000Z'
    data:
      edited: false
      editors:
      - cleverest
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.44332966208457947
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1f437f318770edea28ec92d7cb14bd73.svg
          fullname: Brett S
          isHf: false
          isPro: false
          name: cleverest
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63913f0a2e1b430e96cdee95/DUVO6x_73R1ursVptw3Yo.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/63913f0a2e1b430e96cdee95/DUVO6x_73R1ursVptw3Yo.png"></a></p>

          '
        raw: "\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63913f0a2e1b430e96cdee95/DUVO6x_73R1ursVptw3Yo.png)\r\
          \n"
        updatedAt: '2023-07-10T15:02:04.277Z'
      numEdits: 0
      reactions: []
    id: 64ac1d6cc275702c3c99fb15
    type: comment
  author: cleverest
  content: "\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63913f0a2e1b430e96cdee95/DUVO6x_73R1ursVptw3Yo.png)\r\
    \n"
  created_at: 2023-07-10 14:02:04+00:00
  edited: false
  hidden: false
  id: 64ac1d6cc275702c3c99fb15
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-10T15:12:56.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9709801077842712
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Oh whoops, there weren''t meant to be two files there.  I uploaded
          the 4bit-128g file by mistake, then uploaded the 4bit no groupsize file
          but forgot to delete the formet.</p>

          <p>If you''re using ExLlama, you can use the 4bit-128g file, which has higher
          accuracy.  It''ll be too slow to use with AutoGPTQ or GPTQ-for-LLaMa (which
          is why I don''t provide it normally), but ExLlama can run it at the same
          speed.</p>

          <p>In future I plan to provide multiple GPTQ versions for each repo, to
          give people a choice. Though they will be in separate branches, not in the
          same folder.   </p>

          '
        raw: 'Oh whoops, there weren''t meant to be two files there.  I uploaded the
          4bit-128g file by mistake, then uploaded the 4bit no groupsize file but
          forgot to delete the formet.


          If you''re using ExLlama, you can use the 4bit-128g file, which has higher
          accuracy.  It''ll be too slow to use with AutoGPTQ or GPTQ-for-LLaMa (which
          is why I don''t provide it normally), but ExLlama can run it at the same
          speed.


          In future I plan to provide multiple GPTQ versions for each repo, to give
          people a choice. Though they will be in separate branches, not in the same
          folder.   '
        updatedAt: '2023-07-10T15:12:56.745Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - cleverest
    id: 64ac1ff8ab35a74f7306f71a
    type: comment
  author: TheBloke
  content: 'Oh whoops, there weren''t meant to be two files there.  I uploaded the
    4bit-128g file by mistake, then uploaded the 4bit no groupsize file but forgot
    to delete the formet.


    If you''re using ExLlama, you can use the 4bit-128g file, which has higher accuracy.  It''ll
    be too slow to use with AutoGPTQ or GPTQ-for-LLaMa (which is why I don''t provide
    it normally), but ExLlama can run it at the same speed.


    In future I plan to provide multiple GPTQ versions for each repo, to give people
    a choice. Though they will be in separate branches, not in the same folder.   '
  created_at: 2023-07-10 14:12:56+00:00
  edited: false
  hidden: false
  id: 64ac1ff8ab35a74f7306f71a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/samantha-1.1-llama-33B-GPTQ
repo_type: model
status: open
target_branch: null
title: Using Oogabooga and a 4090 (windows install) - which model of the two available
  do I use?
