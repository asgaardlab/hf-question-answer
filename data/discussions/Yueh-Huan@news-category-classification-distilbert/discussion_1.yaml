!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AdaptiveStoryfinder
conflicting_files: null
created_at: 2023-08-09 21:04:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1bef23f12c657180028a5213ad6f156f.svg
      fullname: Adaptive Storyfinder
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AdaptiveStoryfinder
      type: user
    createdAt: '2023-08-09T22:04:37.000Z'
    data:
      edited: false
      editors:
      - AdaptiveStoryfinder
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9367188811302185
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1bef23f12c657180028a5213ad6f156f.svg
          fullname: Adaptive Storyfinder
          isHf: false
          isPro: false
          name: AdaptiveStoryfinder
          type: user
        html: '<p>Hi,<br>I would like to see all possibility of the prediction just
          like in the host inference. In transformers pipeline it could just return
          the first highest possibiilty of classification. Is there any ways that
          I could get all possibiilty except using inference API cause it has rate
          limit?</p>

          <p>Thank you for your help.</p>

          '
        raw: "Hi,\r\nI would like to see all possibility of the prediction just like\
          \ in the host inference. In transformers pipeline it could just return the\
          \ first highest possibiilty of classification. Is there any ways that I\
          \ could get all possibiilty except using inference API cause it has rate\
          \ limit?\r\n\r\nThank you for your help."
        updatedAt: '2023-08-09T22:04:37.698Z'
      numEdits: 0
      reactions: []
    id: 64d40d752f93eee2d27d9f11
    type: comment
  author: AdaptiveStoryfinder
  content: "Hi,\r\nI would like to see all possibility of the prediction just like\
    \ in the host inference. In transformers pipeline it could just return the first\
    \ highest possibiilty of classification. Is there any ways that I could get all\
    \ possibiilty except using inference API cause it has rate limit?\r\n\r\nThank\
    \ you for your help."
  created_at: 2023-08-09 21:04:37+00:00
  edited: false
  hidden: false
  id: 64d40d752f93eee2d27d9f11
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Yueh-Huan/news-category-classification-distilbert
repo_type: model
status: open
target_branch: null
title: How to get all possibility of the prediction
