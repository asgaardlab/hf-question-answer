!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ipark
conflicting_files: null
created_at: 2023-05-09 15:53:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d3ceebfba9a98a24d69febc9679c1c60.svg
      fullname: ipark
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ipark
      type: user
    createdAt: '2023-05-09T16:53:15.000Z'
    data:
      edited: true
      editors:
      - ipark
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d3ceebfba9a98a24d69febc9679c1c60.svg
          fullname: ipark
          isHf: false
          isPro: false
          name: ipark
          type: user
        html: '<p>Hello!</p>

          <p>I have a question on Example 2: Fine-tuning on a set of user-defined
          sequences.<br>You provided two parts of scripts:<br>[part 1] input="sequences.fasta"
          ==&gt;   output="2.7.3.13_processed.txt" (each line has len(tokenizer(value+padding)[''input_ids'']))<br>[part
          2] input="2.7.3.13_processed.txt" ==&gt;  output=(''./dataset/train2/<em>.arrow)
          + (''./dataset/eval2/</em>.arrow'')</p>

          <p>Since run_clm.py contains a preprocessing like in [part2],<br>I''m wondering
          that can''t we just fine-tune run directly with a "2.7.3.13_processed.txt"
          by skipping [part2] such as following?</p>

          <p>$ python run_clm.py --tokenizer_name /path/to/ZymCTRL<br>--train_file
          2.7.3.13_processed.txt  <br>--validation_split_percentage 10 <br> --do_train
          --do_eval --output_dir output ...</p>

          <p>Thank you!</p>

          '
        raw: "Hello!\n\nI have a question on Example 2: Fine-tuning on a set of user-defined\
          \ sequences.\nYou provided two parts of scripts: \n[part 1] input=\"sequences.fasta\"\
          \ ==>   output=\"2.7.3.13_processed.txt\" (each line has len(tokenizer(value+padding)['input_ids']))\n\
          [part 2] input=\"2.7.3.13_processed.txt\" ==>  output=('./dataset/train2/*.arrow)\
          \ + ('./dataset/eval2/*.arrow')\n\nSince run_clm.py contains a preprocessing\
          \ like in [part2], \nI'm wondering that can't we just fine-tune run directly\
          \ with a \"2.7.3.13_processed.txt\" by skipping [part2] such as following?\n\
          \n$ python run_clm.py --tokenizer_name /path/to/ZymCTRL\n--train_file 2.7.3.13_processed.txt\
          \  \\\n--validation_split_percentage 10 \\\n --do_train --do_eval --output_dir\
          \ output ...\n\nThank you!"
        updatedAt: '2023-05-09T16:56:22.538Z'
      numEdits: 1
      reactions: []
    id: 645a7a7b21ab438e7329d671
    type: comment
  author: ipark
  content: "Hello!\n\nI have a question on Example 2: Fine-tuning on a set of user-defined\
    \ sequences.\nYou provided two parts of scripts: \n[part 1] input=\"sequences.fasta\"\
    \ ==>   output=\"2.7.3.13_processed.txt\" (each line has len(tokenizer(value+padding)['input_ids']))\n\
    [part 2] input=\"2.7.3.13_processed.txt\" ==>  output=('./dataset/train2/*.arrow)\
    \ + ('./dataset/eval2/*.arrow')\n\nSince run_clm.py contains a preprocessing like\
    \ in [part2], \nI'm wondering that can't we just fine-tune run directly with a\
    \ \"2.7.3.13_processed.txt\" by skipping [part2] such as following?\n\n$ python\
    \ run_clm.py --tokenizer_name /path/to/ZymCTRL\n--train_file 2.7.3.13_processed.txt\
    \  \\\n--validation_split_percentage 10 \\\n --do_train --do_eval --output_dir\
    \ output ...\n\nThank you!"
  created_at: 2023-05-09 15:53:15+00:00
  edited: true
  hidden: false
  id: 645a7a7b21ab438e7329d671
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nferruz
      type: user
    createdAt: '2023-05-16T12:28:14.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: '<p>mmmh, yes, you''re right! I think that would also be possible if
          I am not missing any critical step in the script.<br>Let me know how it
          goes!</p>

          '
        raw: "mmmh, yes, you're right! I think that would also be possible if I am\
          \ not missing any critical step in the script. \nLet me know how it goes!"
        updatedAt: '2023-05-16T12:28:14.066Z'
      numEdits: 0
      reactions: []
    id: 646376dea429ec3af0a54d3c
    type: comment
  author: nferruz
  content: "mmmh, yes, you're right! I think that would also be possible if I am not\
    \ missing any critical step in the script. \nLet me know how it goes!"
  created_at: 2023-05-16 11:28:14+00:00
  edited: false
  hidden: false
  id: 646376dea429ec3af0a54d3c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d3ceebfba9a98a24d69febc9679c1c60.svg
      fullname: ipark
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ipark
      type: user
    createdAt: '2023-05-16T16:23:35.000Z'
    data:
      edited: false
      editors:
      - ipark
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d3ceebfba9a98a24d69febc9679c1c60.svg
          fullname: ipark
          isHf: false
          isPro: false
          name: ipark
          type: user
        html: '<p>Thanks for the reply.  </p>

          <p>Actually I did only [part1] and then ran using run_clm.py (in lieu of
          your 5.run_clm-post.py)<br>Seems working well.  </p>

          <p>Thanks!</p>

          '
        raw: "Thanks for the reply.  \n\nActually I did only [part1] and then ran\
          \ using run_clm.py (in lieu of your 5.run_clm-post.py)\nSeems working well.\
          \  \n\nThanks!"
        updatedAt: '2023-05-16T16:23:35.549Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - nferruz
    id: 6463ae076e4f6dc60155f04a
    type: comment
  author: ipark
  content: "Thanks for the reply.  \n\nActually I did only [part1] and then ran using\
    \ run_clm.py (in lieu of your 5.run_clm-post.py)\nSeems working well.  \n\nThanks!"
  created_at: 2023-05-16 15:23:35+00:00
  edited: false
  hidden: false
  id: 6463ae076e4f6dc60155f04a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: AI4PD/ZymCTRL
repo_type: model
status: open
target_branch: null
title: 'Example 2: Fine-tuning on a set of user-defined sequences'
