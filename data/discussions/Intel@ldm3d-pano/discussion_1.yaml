!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Huang1997
conflicting_files: null
created_at: 2023-08-08 07:36:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e948c8d01c338a185b5e8b0135bd98c2.svg
      fullname: Li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Huang1997
      type: user
    createdAt: '2023-08-08T08:36:12.000Z'
    data:
      edited: false
      editors:
      - Huang1997
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.930738091468811
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e948c8d01c338a185b5e8b0135bd98c2.svg
          fullname: Li
          isHf: false
          isPro: false
          name: Huang1997
          type: user
        html: '<p>Hi, first of all, thank you very mush for sharing ldm3d tech, the
          results are very impressvie! I''m just getting into the 3D filed and have
          some questions about panoramas generation.I hope you can help me.</p>

          <p>First,  I followed the guidance of  ldm3d huggingface space  and generated
          some panoramas images. but I found that the performace of panoramas generated
          by ldm3d-pano checkpoints is not as good as that in the demo(<a rel="nofollow"
          href="https://www.youtube.com/watch?v=3hbUo-hwAs0">https://www.youtube.com/watch?v=3hbUo-hwAs0</a>).  In
          the generated settings, the height is 1024, the width is 2048, and the prompt
          text is "360 view of a beautiful garden in CG style", use default values
          for other parameters. However, the result style is not CG style and geometric
          deformation is serious. Could you tell me some suggestions about generating
          better quality panoramas?</p>

          <p>Second,  The dataset used in the original paper was LAION-400M, which
          does not contain panorama images. So the ldm3d-pano model was trained on
          another dataset that contains panoramas image, depth image and caption tuple?</p>

          <p>Three, I found some bugs in the generated panorama images,  and that
          is, inconsistencies at the stitching. Have you considered how to deal with
          this bug, whether to solve it directly from the model structure or through
          post-processing?</p>

          <p>Looking forward to your reply!!!</p>

          '
        raw: "Hi, first of all, thank you very mush for sharing ldm3d tech, the results\
          \ are very impressvie! I'm just getting into the 3D filed and have some\
          \ questions about panoramas generation.I hope you can help me.\r\n\r\nFirst,\
          \  I followed the guidance of  ldm3d huggingface space  and generated some\
          \ panoramas images. but I found that the performace of panoramas generated\
          \ by ldm3d-pano checkpoints is not as good as that in the demo(https://www.youtube.com/watch?v=3hbUo-hwAs0).\
          \  In the generated settings, the height is 1024, the width is 2048, and\
          \ the prompt text is \"360 view of a beautiful garden in CG style\", use\
          \ default values for other parameters. However, the result style is not\
          \ CG style and geometric deformation is serious. Could you tell me some\
          \ suggestions about generating better quality panoramas?\r\n\r\nSecond,\
          \  The dataset used in the original paper was LAION-400M, which does not\
          \ contain panorama images. So the ldm3d-pano model was trained on another\
          \ dataset that contains panoramas image, depth image and caption tuple?\r\
          \n\r\nThree, I found some bugs in the generated panorama images,  and that\
          \ is, inconsistencies at the stitching. Have you considered how to deal\
          \ with this bug, whether to solve it directly from the model structure or\
          \ through post-processing?\r\n\r\nLooking forward to your reply!!!\r\n"
        updatedAt: '2023-08-08T08:36:12.110Z'
      numEdits: 0
      reactions: []
    id: 64d1fe7c2f1f9578a07093c2
    type: comment
  author: Huang1997
  content: "Hi, first of all, thank you very mush for sharing ldm3d tech, the results\
    \ are very impressvie! I'm just getting into the 3D filed and have some questions\
    \ about panoramas generation.I hope you can help me.\r\n\r\nFirst,  I followed\
    \ the guidance of  ldm3d huggingface space  and generated some panoramas images.\
    \ but I found that the performace of panoramas generated by ldm3d-pano checkpoints\
    \ is not as good as that in the demo(https://www.youtube.com/watch?v=3hbUo-hwAs0).\
    \  In the generated settings, the height is 1024, the width is 2048, and the prompt\
    \ text is \"360 view of a beautiful garden in CG style\", use default values for\
    \ other parameters. However, the result style is not CG style and geometric deformation\
    \ is serious. Could you tell me some suggestions about generating better quality\
    \ panoramas?\r\n\r\nSecond,  The dataset used in the original paper was LAION-400M,\
    \ which does not contain panorama images. So the ldm3d-pano model was trained\
    \ on another dataset that contains panoramas image, depth image and caption tuple?\r\
    \n\r\nThree, I found some bugs in the generated panorama images,  and that is,\
    \ inconsistencies at the stitching. Have you considered how to deal with this\
    \ bug, whether to solve it directly from the model structure or through post-processing?\r\
    \n\r\nLooking forward to your reply!!!\r\n"
  created_at: 2023-08-08 07:36:12+00:00
  edited: false
  hidden: false
  id: 64d1fe7c2f1f9578a07093c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/13dc0a370bb24271653c352897a2673e.svg
      fullname: Estelle Aflalo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: estellea
      type: user
    createdAt: '2023-08-21T09:37:30.000Z'
    data:
      edited: true
      editors:
      - estellea
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9586073160171509
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/13dc0a370bb24271653c352897a2673e.svg
          fullname: Estelle Aflalo
          isHf: false
          isPro: false
          name: estellea
          type: user
        html: '<p>Thank you for the interest in our work!</p>

          <p>Regarding your first comment: we are not using the same method to display
          than the one used in the youtube demo.  The demo used in Spaces is lighter
          and more appropriate for a large-scale use compared to the demo you saw
          on YouTube. Have you maybe tried to play with the resolution (maybe smaller
          resolution? the one we trained on is 512 by 1024.).  I am not sure what
          CG style is, but LDM3D was finetuned on Stable Diffusion 1.5 so it leverages
          the dataset it was trained on. Do you get good results with SD1.5 when using
          "CG style"?</p>

          <p>Regarding the 2nd I addressed this by creating the model card with all
          the relevant info</p>

          <p>For the 3rd and last question: we are aware of the stitching issue and
          thinking on how to address with this. However, its not among our current
          priorities </p>

          '
        raw: 'Thank you for the interest in our work!


          Regarding your first comment: we are not using the same method to display
          than the one used in the youtube demo.  The demo used in Spaces is lighter
          and more appropriate for a large-scale use compared to the demo you saw
          on YouTube. Have you maybe tried to play with the resolution (maybe smaller
          resolution? the one we trained on is 512 by 1024.).  I am not sure what
          CG style is, but LDM3D was finetuned on Stable Diffusion 1.5 so it leverages
          the dataset it was trained on. Do you get good results with SD1.5 when using
          "CG style"?


          Regarding the 2nd I addressed this by creating the model card with all the
          relevant info


          For the 3rd and last question: we are aware of the stitching issue and thinking
          on how to address with this. However, its not among our current priorities '
        updatedAt: '2023-08-21T10:08:30.667Z'
      numEdits: 1
      reactions: []
    id: 64e3305a618cd90997d504df
    type: comment
  author: estellea
  content: 'Thank you for the interest in our work!


    Regarding your first comment: we are not using the same method to display than
    the one used in the youtube demo.  The demo used in Spaces is lighter and more
    appropriate for a large-scale use compared to the demo you saw on YouTube. Have
    you maybe tried to play with the resolution (maybe smaller resolution? the one
    we trained on is 512 by 1024.).  I am not sure what CG style is, but LDM3D was
    finetuned on Stable Diffusion 1.5 so it leverages the dataset it was trained on.
    Do you get good results with SD1.5 when using "CG style"?


    Regarding the 2nd I addressed this by creating the model card with all the relevant
    info


    For the 3rd and last question: we are aware of the stitching issue and thinking
    on how to address with this. However, its not among our current priorities '
  created_at: 2023-08-21 08:37:30+00:00
  edited: true
  hidden: false
  id: 64e3305a618cd90997d504df
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Intel/ldm3d-pano
repo_type: model
status: open
target_branch: null
title: some quesetions about panorama images generation
