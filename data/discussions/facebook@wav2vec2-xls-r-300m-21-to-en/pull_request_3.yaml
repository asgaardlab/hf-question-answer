!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sanchit-gandhi
conflicting_files: []
created_at: 2022-09-07 12:38:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2022-09-07T13:38:35.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Running the step-by-step example throws a TypeError when loading\
          \ the <code>Speech2Text2Processor</code>:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> Speech2Text2Processor,\
          \ SpeechEncoderDecoderModel\n<span class=\"hljs-keyword\">from</span> datasets\
          \ <span class=\"hljs-keyword\">import</span> load_dataset\n\nmodel = SpeechEncoderDecoderModel.from_pretrained(<span\
          \ class=\"hljs-string\">\"facebook/wav2vec2-xls-r-300m-21-to-en\"</span>)\n\
          processor = Speech2Text2Processor.from_pretrained(<span class=\"hljs-string\"\
          >\"facebook/wav2vec2-xls-r-300m-21-to-en\"</span>)\n</code></pre>\n<details>\n\
          \n<summary> Full stack trace </summary>\n\n<pre><code class=\"language-python\"\
          >----&gt; <span class=\"hljs-number\">1</span> processor = Speech2Text2Processor.from_pretrained(<span\
          \ class=\"hljs-string\">\"facebook/wav2vec2-xls-r-300m-21-to-en\"</span>)\n\
          \nFile ~/transformers/src/transformers/processing_utils.py:<span class=\"\
          hljs-number\">186</span>, <span class=\"hljs-keyword\">in</span> ProcessorMixin.from_pretrained(cls,\
          \ pretrained_model_name_or_path, **kwargs)\n    <span class=\"hljs-number\"\
          >156</span> @<span class=\"hljs-built_in\">classmethod</span>\n    <span\
          \ class=\"hljs-number\">157</span> <span class=\"hljs-keyword\">def</span>\
          \ <span class=\"hljs-title function_\">from_pretrained</span>(<span class=\"\
          hljs-params\">cls, pretrained_model_name_or_path, **kwargs</span>):\n  \
          \  <span class=\"hljs-number\">158</span>     <span class=\"hljs-string\"\
          >r\"\"\"</span>\n<span class=\"hljs-string\">    159     Instantiate a processor\
          \ associated with a pretrained model.</span>\n<span class=\"hljs-string\"\
          >    160 </span>\n<span class=\"hljs-string\">   (...)</span>\n<span class=\"\
          hljs-string\">    184             [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].</span>\n\
          <span class=\"hljs-string\">    185     \"\"\"</span>\n--&gt; <span class=\"\
          hljs-number\">186</span>     args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs)\n    <span class=\"hljs-number\">187</span>     <span class=\"\
          hljs-keyword\">return</span> cls(*args)\n\nFile ~/transformers/src/transformers/processing_utils.py:<span\
          \ class=\"hljs-number\">230</span>, <span class=\"hljs-keyword\">in</span>\
          \ ProcessorMixin._get_arguments_from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\n    <span class=\"hljs-number\">227</span>     <span class=\"\
          hljs-keyword\">else</span>:\n    <span class=\"hljs-number\">228</span>\
          \         attribute_class = <span class=\"hljs-built_in\">getattr</span>(transformers_module,\
          \ class_name)\n--&gt; <span class=\"hljs-number\">230</span>     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs))\n    <span class=\"hljs-number\">231</span> <span class=\"\
          hljs-keyword\">return</span> args\n\nFile ~/transformers/src/transformers/tokenization_utils_base.py:<span\
          \ class=\"hljs-number\">1805</span>, <span class=\"hljs-keyword\">in</span>\
          \ PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *init_inputs, **kwargs)\n   <span class=\"hljs-number\">1802</span>  \
          \   <span class=\"hljs-keyword\">else</span>:\n   <span class=\"hljs-number\"\
          >1803</span>         logger.info(<span class=\"hljs-string\">f\"loading\
          \ file <span class=\"hljs-subst\">{file_path}</span> from cache at <span\
          \ class=\"hljs-subst\">{resolved_vocab_files[file_id]}</span>\"</span>)\n\
          -&gt; <span class=\"hljs-number\">1805</span> <span class=\"hljs-keyword\"\
          >return</span> cls._from_pretrained(\n   <span class=\"hljs-number\">1806</span>\
          \     resolved_vocab_files,\n   <span class=\"hljs-number\">1807</span>\
          \     pretrained_model_name_or_path,\n   <span class=\"hljs-number\">1808</span>\
          \     init_configuration,\n   <span class=\"hljs-number\">1809</span>  \
          \   *init_inputs,\n   <span class=\"hljs-number\">1810</span>     use_auth_token=use_auth_token,\n\
          \   <span class=\"hljs-number\">1811</span>     cache_dir=cache_dir,\n \
          \  <span class=\"hljs-number\">1812</span>     **kwargs,\n   <span class=\"\
          hljs-number\">1813</span> )\n\nFile ~/transformers/src/transformers/tokenization_utils_base.py:<span\
          \ class=\"hljs-number\">1950</span>, <span class=\"hljs-keyword\">in</span>\
          \ PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,\
          \ init_configuration, use_auth_token, cache_dir, *init_inputs, **kwargs)\n\
          \   <span class=\"hljs-number\">1948</span> <span class=\"hljs-comment\"\
          ># Instantiate tokenizer.</span>\n   <span class=\"hljs-number\">1949</span>\
          \ <span class=\"hljs-keyword\">try</span>:\n-&gt; <span class=\"hljs-number\"\
          >1950</span>     tokenizer = cls(*init_inputs, **init_kwargs)\n   <span\
          \ class=\"hljs-number\">1951</span> <span class=\"hljs-keyword\">except</span>\
          \ OSError:\n   <span class=\"hljs-number\">1952</span>     <span class=\"\
          hljs-keyword\">raise</span> OSError(\n   <span class=\"hljs-number\">1953</span>\
          \         <span class=\"hljs-string\">\"Unable to load vocabulary from file.\
          \ \"</span>\n   <span class=\"hljs-number\">1954</span>         <span class=\"\
          hljs-string\">\"Please check that the provided vocabulary is accessible\
          \ and not corrupted.\"</span>\n   <span class=\"hljs-number\">1955</span>\
          \     )\n\nFile ~/transformers/src/transformers/models/speech_to_text_2/tokenization_speech_to_text_2.py:<span\
          \ class=\"hljs-number\">124</span>, <span class=\"hljs-keyword\">in</span>\
          \ Speech2Text2Tokenizer.__init__(self, vocab_file, bos_token, pad_token,\
          \ eos_token, unk_token, do_lower_case, merges_file, **kwargs)\n    <span\
          \ class=\"hljs-number\">113</span> <span class=\"hljs-built_in\">super</span>().__init__(\n\
          \    <span class=\"hljs-number\">114</span>     unk_token=unk_token,\n \
          \   <span class=\"hljs-number\">115</span>     bos_token=bos_token,\n  \
          \ (...)\n    <span class=\"hljs-number\">119</span>     **kwargs,\n    <span\
          \ class=\"hljs-number\">120</span> )\n    <span class=\"hljs-number\">122</span>\
          \ self.do_lower_case = do_lower_case\n--&gt; <span class=\"hljs-number\"\
          >124</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\"\
          >open</span>(vocab_file, encoding=<span class=\"hljs-string\">\"utf-8\"\
          </span>) <span class=\"hljs-keyword\">as</span> vocab_handle:\n    <span\
          \ class=\"hljs-number\">125</span>     self.encoder = json.load(vocab_handle)\n\
          \    <span class=\"hljs-number\">126</span> self.decoder = {v: k <span class=\"\
          hljs-keyword\">for</span> k, v <span class=\"hljs-keyword\">in</span> self.encoder.items()}\n\
          \nTypeError: expected <span class=\"hljs-built_in\">str</span>, <span class=\"\
          hljs-built_in\">bytes</span> <span class=\"hljs-keyword\">or</span> os.PathLike\
          \ <span class=\"hljs-built_in\">object</span>, <span class=\"hljs-keyword\"\
          >not</span> NoneType\n</code></pre>\n</details>\n\n<p>This is remedied by\
          \ loading the correct processor class (<code>Wav2Vec2Processor</code>):</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">import</span>\
          \ torch\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"\
          hljs-keyword\">import</span> Wav2Vec2Processor, SpeechEncoderDecoderModel\n\
          <span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\"\
          >import</span> load_dataset\n\nmodel = SpeechEncoderDecoderModel.from_pretrained(<span\
          \ class=\"hljs-string\">\"facebook/wav2vec2-xls-r-300m-21-to-en\"</span>)\n\
          processor = Wav2Vec2Processor.from_pretrained(<span class=\"hljs-string\"\
          >\"facebook/wav2vec2-xls-r-300m-21-to-en\"</span>)\n</code></pre>\n"
        raw: "Running the step-by-step example throws a TypeError when loading the\
          \ `Speech2Text2Processor`:\n```python\nimport torch\nfrom transformers import\
          \ Speech2Text2Processor, SpeechEncoderDecoderModel\nfrom datasets import\
          \ load_dataset\n\nmodel = SpeechEncoderDecoderModel.from_pretrained(\"facebook/wav2vec2-xls-r-300m-21-to-en\"\
          )\nprocessor = Speech2Text2Processor.from_pretrained(\"facebook/wav2vec2-xls-r-300m-21-to-en\"\
          )\n\n```\n\n<details>\n\n<summary> Full stack trace </summary>\n\n```python\n\
          ----> 1 processor = Speech2Text2Processor.from_pretrained(\"facebook/wav2vec2-xls-r-300m-21-to-en\"\
          )\n\nFile ~/transformers/src/transformers/processing_utils.py:186, in ProcessorMixin.from_pretrained(cls,\
          \ pretrained_model_name_or_path, **kwargs)\n    156 @classmethod\n    157\
          \ def from_pretrained(cls, pretrained_model_name_or_path, **kwargs):\n \
          \   158     r\"\"\"\n    159     Instantiate a processor associated with\
          \ a pretrained model.\n    160 \n   (...)\n    184             [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].\n\
          \    185     \"\"\"\n--> 186     args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs)\n    187     return cls(*args)\n\nFile ~/transformers/src/transformers/processing_utils.py:230,\
          \ in ProcessorMixin._get_arguments_from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\n    227     else:\n    228         attribute_class = getattr(transformers_module,\
          \ class_name)\n--> 230     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs))\n    231 return args\n\nFile ~/transformers/src/transformers/tokenization_utils_base.py:1805,\
          \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *init_inputs, **kwargs)\n   1802     else:\n   1803         logger.info(f\"\
          loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\
          )\n-> 1805 return cls._from_pretrained(\n   1806     resolved_vocab_files,\n\
          \   1807     pretrained_model_name_or_path,\n   1808     init_configuration,\n\
          \   1809     *init_inputs,\n   1810     use_auth_token=use_auth_token,\n\
          \   1811     cache_dir=cache_dir,\n   1812     **kwargs,\n   1813 )\n\n\
          File ~/transformers/src/transformers/tokenization_utils_base.py:1950, in\
          \ PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,\
          \ init_configuration, use_auth_token, cache_dir, *init_inputs, **kwargs)\n\
          \   1948 # Instantiate tokenizer.\n   1949 try:\n-> 1950     tokenizer =\
          \ cls(*init_inputs, **init_kwargs)\n   1951 except OSError:\n   1952   \
          \  raise OSError(\n   1953         \"Unable to load vocabulary from file.\
          \ \"\n   1954         \"Please check that the provided vocabulary is accessible\
          \ and not corrupted.\"\n   1955     )\n\nFile ~/transformers/src/transformers/models/speech_to_text_2/tokenization_speech_to_text_2.py:124,\
          \ in Speech2Text2Tokenizer.__init__(self, vocab_file, bos_token, pad_token,\
          \ eos_token, unk_token, do_lower_case, merges_file, **kwargs)\n    113 super().__init__(\n\
          \    114     unk_token=unk_token,\n    115     bos_token=bos_token,\n  \
          \ (...)\n    119     **kwargs,\n    120 )\n    122 self.do_lower_case =\
          \ do_lower_case\n--> 124 with open(vocab_file, encoding=\"utf-8\") as vocab_handle:\n\
          \    125     self.encoder = json.load(vocab_handle)\n    126 self.decoder\
          \ = {v: k for k, v in self.encoder.items()}\n\nTypeError: expected str,\
          \ bytes or os.PathLike object, not NoneType\n```\n\n</details>\n\nThis is\
          \ remedied by loading the correct processor class (`Wav2Vec2Processor`):\n\
          \n```python\nimport torch\nfrom transformers import Wav2Vec2Processor, SpeechEncoderDecoderModel\n\
          from datasets import load_dataset\n\nmodel = SpeechEncoderDecoderModel.from_pretrained(\"\
          facebook/wav2vec2-xls-r-300m-21-to-en\")\nprocessor = Wav2Vec2Processor.from_pretrained(\"\
          facebook/wav2vec2-xls-r-300m-21-to-en\")\n```"
        updatedAt: '2022-09-07T13:38:35.866Z'
      numEdits: 0
      reactions: []
    id: 63189edb92aef33be06186a7
    type: comment
  author: sanchit-gandhi
  content: "Running the step-by-step example throws a TypeError when loading the `Speech2Text2Processor`:\n\
    ```python\nimport torch\nfrom transformers import Speech2Text2Processor, SpeechEncoderDecoderModel\n\
    from datasets import load_dataset\n\nmodel = SpeechEncoderDecoderModel.from_pretrained(\"\
    facebook/wav2vec2-xls-r-300m-21-to-en\")\nprocessor = Speech2Text2Processor.from_pretrained(\"\
    facebook/wav2vec2-xls-r-300m-21-to-en\")\n\n```\n\n<details>\n\n<summary> Full\
    \ stack trace </summary>\n\n```python\n----> 1 processor = Speech2Text2Processor.from_pretrained(\"\
    facebook/wav2vec2-xls-r-300m-21-to-en\")\n\nFile ~/transformers/src/transformers/processing_utils.py:186,\
    \ in ProcessorMixin.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\n\
    \    156 @classmethod\n    157 def from_pretrained(cls, pretrained_model_name_or_path,\
    \ **kwargs):\n    158     r\"\"\"\n    159     Instantiate a processor associated\
    \ with a pretrained model.\n    160 \n   (...)\n    184             [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].\n\
    \    185     \"\"\"\n--> 186     args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
    \ **kwargs)\n    187     return cls(*args)\n\nFile ~/transformers/src/transformers/processing_utils.py:230,\
    \ in ProcessorMixin._get_arguments_from_pretrained(cls, pretrained_model_name_or_path,\
    \ **kwargs)\n    227     else:\n    228         attribute_class = getattr(transformers_module,\
    \ class_name)\n--> 230     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
    \ **kwargs))\n    231 return args\n\nFile ~/transformers/src/transformers/tokenization_utils_base.py:1805,\
    \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
    \ *init_inputs, **kwargs)\n   1802     else:\n   1803         logger.info(f\"\
    loading file {file_path} from cache at {resolved_vocab_files[file_id]}\")\n->\
    \ 1805 return cls._from_pretrained(\n   1806     resolved_vocab_files,\n   1807\
    \     pretrained_model_name_or_path,\n   1808     init_configuration,\n   1809\
    \     *init_inputs,\n   1810     use_auth_token=use_auth_token,\n   1811     cache_dir=cache_dir,\n\
    \   1812     **kwargs,\n   1813 )\n\nFile ~/transformers/src/transformers/tokenization_utils_base.py:1950,\
    \ in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,\
    \ init_configuration, use_auth_token, cache_dir, *init_inputs, **kwargs)\n   1948\
    \ # Instantiate tokenizer.\n   1949 try:\n-> 1950     tokenizer = cls(*init_inputs,\
    \ **init_kwargs)\n   1951 except OSError:\n   1952     raise OSError(\n   1953\
    \         \"Unable to load vocabulary from file. \"\n   1954         \"Please\
    \ check that the provided vocabulary is accessible and not corrupted.\"\n   1955\
    \     )\n\nFile ~/transformers/src/transformers/models/speech_to_text_2/tokenization_speech_to_text_2.py:124,\
    \ in Speech2Text2Tokenizer.__init__(self, vocab_file, bos_token, pad_token, eos_token,\
    \ unk_token, do_lower_case, merges_file, **kwargs)\n    113 super().__init__(\n\
    \    114     unk_token=unk_token,\n    115     bos_token=bos_token,\n   (...)\n\
    \    119     **kwargs,\n    120 )\n    122 self.do_lower_case = do_lower_case\n\
    --> 124 with open(vocab_file, encoding=\"utf-8\") as vocab_handle:\n    125  \
    \   self.encoder = json.load(vocab_handle)\n    126 self.decoder = {v: k for k,\
    \ v in self.encoder.items()}\n\nTypeError: expected str, bytes or os.PathLike\
    \ object, not NoneType\n```\n\n</details>\n\nThis is remedied by loading the correct\
    \ processor class (`Wav2Vec2Processor`):\n\n```python\nimport torch\nfrom transformers\
    \ import Wav2Vec2Processor, SpeechEncoderDecoderModel\nfrom datasets import load_dataset\n\
    \nmodel = SpeechEncoderDecoderModel.from_pretrained(\"facebook/wav2vec2-xls-r-300m-21-to-en\"\
    )\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-xls-r-300m-21-to-en\"\
    )\n```"
  created_at: 2022-09-07 12:38:35+00:00
  edited: false
  hidden: false
  id: 63189edb92aef33be06186a7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2022-09-07T13:38:36.000Z'
    data:
      oid: c21534a843b9dacf9b2ef8e96bdbbcf2615954ef
      parents:
      - 4df5c4fb8b8fa521c0d84cf5ce8e7a681ff14e3d
      subject: Update import of processor in README.md
    id: 63189edc0000000000000000
    type: commit
  author: sanchit-gandhi
  created_at: 2022-09-07 12:38:36+00:00
  id: 63189edc0000000000000000
  oid: c21534a843b9dacf9b2ef8e96bdbbcf2615954ef
  summary: Update import of processor in README.md
  type: commit
is_pull_request: true
merge_commit_oid: null
num: 3
repo_id: facebook/wav2vec2-xls-r-300m-21-to-en
repo_type: model
status: open
target_branch: refs/heads/main
title: Update import of processor in README.md
