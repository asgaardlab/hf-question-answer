!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Daniel-P-Gonzalez
conflicting_files: null
created_at: 2023-11-13 16:09:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3550690fdb4fcb2ab8efc3ebe6d3bc11.svg
      fullname: Daniel Gonzalez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Daniel-P-Gonzalez
      type: user
    createdAt: '2023-11-13T16:09:38.000Z'
    data:
      edited: false
      editors:
      - Daniel-P-Gonzalez
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.688685953617096
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3550690fdb4fcb2ab8efc3ebe6d3bc11.svg
          fullname: Daniel Gonzalez
          isHf: false
          isPro: false
          name: Daniel-P-Gonzalez
          type: user
        html: '<p>In modeling_transnormer.py and utils.py, <code>eval</code> is used
          to parse environment variables.<br>Instead of:</p>

          <pre><code>some_option = eval(os.environ.get("some_option", default="False"))

          </code></pre>

          <p>I would recommend using something like:</p>

          <pre><code>some_option = os.environ.get("some_option", default="False").lower()
          in ["true", "yes", "y", "1"]

          </code></pre>

          <p>Also, <code>do_eval</code> in particular is evaluated on every <code>forward</code>
          call for each <code>NormLinearAttention</code> layer. Is there a particular
          reason for this, or should it instead be a global?</p>

          '
        raw: "In modeling_transnormer.py and utils.py, `eval` is used to parse environment\
          \ variables.\r\nInstead of:\r\n```\r\nsome_option = eval(os.environ.get(\"\
          some_option\", default=\"False\"))\r\n```\r\nI would recommend using something\
          \ like:\r\n```\r\nsome_option = os.environ.get(\"some_option\", default=\"\
          False\").lower() in [\"true\", \"yes\", \"y\", \"1\"]\r\n```\r\n\r\nAlso,\
          \ `do_eval` in particular is evaluated on every `forward` call for each\
          \ `NormLinearAttention` layer. Is there a particular reason for this, or\
          \ should it instead be a global?"
        updatedAt: '2023-11-13T16:09:38.471Z'
      numEdits: 0
      reactions: []
    id: 65524a42c5fcedbaa316f26b
    type: comment
  author: Daniel-P-Gonzalez
  content: "In modeling_transnormer.py and utils.py, `eval` is used to parse environment\
    \ variables.\r\nInstead of:\r\n```\r\nsome_option = eval(os.environ.get(\"some_option\"\
    , default=\"False\"))\r\n```\r\nI would recommend using something like:\r\n```\r\
    \nsome_option = os.environ.get(\"some_option\", default=\"False\").lower() in\
    \ [\"true\", \"yes\", \"y\", \"1\"]\r\n```\r\n\r\nAlso, `do_eval` in particular\
    \ is evaluated on every `forward` call for each `NormLinearAttention` layer. Is\
    \ there a particular reason for this, or should it instead be a global?"
  created_at: 2023-11-13 16:09:38+00:00
  edited: false
  hidden: false
  id: 65524a42c5fcedbaa316f26b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2024-01-12T07:55:13.000Z'
    data:
      edited: true
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.951052725315094
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<p>They are just poor codes, there should be a pr to improve these
          code.</p>

          <p>The reason for eval in every forward is probably bc the authors has some
          testing code that can be made easy to switch between evaluation and training
          for their own convinence.<br> It shouldn''t be this way though. In practice,
          we should replace the do_eval assignment with checks derived from user''s
          previous call to pytorch model.eval(), ie. the model.training bool <a rel="nofollow"
          href="https://discuss.pytorch.org/t/check-if-model-is-eval-or-train/9395">https://discuss.pytorch.org/t/check-if-model-is-eval-or-train/9395</a></p>

          '
        raw: "They are just poor codes, there should be a pr to improve these code.\n\
          \nThe reason for eval in every forward is probably bc the authors has some\
          \ testing code that can be made easy to switch between evaluation and training\
          \ for their own convinence.\n It shouldn't be this way though. In practice,\
          \ we should replace the do_eval assignment with checks derived from user's\
          \ previous call to pytorch model.eval(), ie. the model.training bool https://discuss.pytorch.org/t/check-if-model-is-eval-or-train/9395"
        updatedAt: '2024-01-12T07:58:25.444Z'
      numEdits: 3
      reactions: []
    id: 65a0f06185f9cc25562bdaf1
    type: comment
  author: Yhyu13
  content: "They are just poor codes, there should be a pr to improve these code.\n\
    \nThe reason for eval in every forward is probably bc the authors has some testing\
    \ code that can be made easy to switch between evaluation and training for their\
    \ own convinence.\n It shouldn't be this way though. In practice, we should replace\
    \ the do_eval assignment with checks derived from user's previous call to pytorch\
    \ model.eval(), ie. the model.training bool https://discuss.pytorch.org/t/check-if-model-is-eval-or-train/9395"
  created_at: 2024-01-12 07:55:13+00:00
  edited: true
  hidden: false
  id: 65a0f06185f9cc25562bdaf1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dfd78c8d55485c22be6e616670a633e5.svg
      fullname: zhenqin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Doreamonzzz
      type: user
    createdAt: '2024-01-12T08:03:44.000Z'
    data:
      edited: false
      editors:
      - Doreamonzzz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9359380006790161
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dfd78c8d55485c22be6e616670a633e5.svg
          fullname: zhenqin
          isHf: false
          isPro: false
          name: Doreamonzzz
          type: user
        html: '<p>Hello, thank you for your suggestion. We will optimize the code
          in the future. The "do_eval" is related to attention calculation, and we
          will also update this in the future.</p>

          '
        raw: Hello, thank you for your suggestion. We will optimize the code in the
          future. The "do_eval" is related to attention calculation, and we will also
          update this in the future.
        updatedAt: '2024-01-12T08:03:44.409Z'
      numEdits: 0
      reactions: []
    id: 65a0f260fbad78ab681c69bb
    type: comment
  author: Doreamonzzz
  content: Hello, thank you for your suggestion. We will optimize the code in the
    future. The "do_eval" is related to attention calculation, and we will also update
    this in the future.
  created_at: 2024-01-12 08:03:44+00:00
  edited: false
  hidden: false
  id: 65a0f260fbad78ab681c69bb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: OpenNLPLab/TransNormerLLM-7B
repo_type: model
status: open
target_branch: null
title: Unsafe use of eval
