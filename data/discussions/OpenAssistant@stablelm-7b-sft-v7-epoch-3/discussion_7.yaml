!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pszemraj
conflicting_files: null
created_at: 2023-05-08 06:26:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2023-05-08T07:26:08.000Z'
    data:
      edited: false
      editors:
      - pszemraj
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
          fullname: Peter Szemraj
          isHf: false
          isPro: false
          name: pszemraj
          type: user
        html: "<p>Hi! In case anyone finds useful, I made a 4bit quantized version\
          \ of this using GPTQ and 7,500 examples from the open assistant dataset\
          \ to guide the quantization. Check it out below &amp; there\u2019s a demo/usage\
          \ guide on the model card:</p>\n<p><a href=\"https://huggingface.co/pszemraj/stablelm-7b-sft-v7e3-autogptq-4bit-128g\"\
          >https://huggingface.co/pszemraj/stablelm-7b-sft-v7e3-autogptq-4bit-128g</a></p>\n"
        raw: "Hi! In case anyone finds useful, I made a 4bit quantized version of\
          \ this using GPTQ and 7,500 examples from the open assistant dataset to\
          \ guide the quantization. Check it out below & there\u2019s a demo/usage\
          \ guide on the model card:\r\n\r\n\r\nhttps://huggingface.co/pszemraj/stablelm-7b-sft-v7e3-autogptq-4bit-128g"
        updatedAt: '2023-05-08T07:26:08.356Z'
      numEdits: 0
      reactions: []
    id: 6458a410c16ecb4815dcea1e
    type: comment
  author: pszemraj
  content: "Hi! In case anyone finds useful, I made a 4bit quantized version of this\
    \ using GPTQ and 7,500 examples from the open assistant dataset to guide the quantization.\
    \ Check it out below & there\u2019s a demo/usage guide on the model card:\r\n\r\
    \n\r\nhttps://huggingface.co/pszemraj/stablelm-7b-sft-v7e3-autogptq-4bit-128g"
  created_at: 2023-05-08 06:26:08+00:00
  edited: false
  hidden: false
  id: 6458a410c16ecb4815dcea1e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: OpenAssistant/stablelm-7b-sft-v7-epoch-3
repo_type: model
status: open
target_branch: null
title: 'GPTQ 4bit 128g '
