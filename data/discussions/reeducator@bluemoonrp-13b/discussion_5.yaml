!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Delta36652
conflicting_files: null
created_at: 2023-05-29 19:21:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0c4677ae94058f95d01935153de2a23e.svg
      fullname: Delta36652
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delta36652
      type: user
    createdAt: '2023-05-29T20:21:36.000Z'
    data:
      edited: false
      editors:
      - Delta36652
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0c4677ae94058f95d01935153de2a23e.svg
          fullname: Delta36652
          isHf: false
          isPro: false
          name: Delta36652
          type: user
        html: '<p>Hello. First of all, thank you for tuning this model.<br>What sampling
          settings (temperature, TopP, etc) do you recommend for this model and for
          30B one?</p>

          <p>Offtopic question:<br>Are there any other RP sites, that can be used
          for finetuning further such models?</p>

          '
        raw: "Hello. First of all, thank you for tuning this model. \r\nWhat sampling\
          \ settings (temperature, TopP, etc) do you recommend for this model and\
          \ for 30B one?\r\n\r\nOfftopic question:\r\nAre there any other RP sites,\
          \ that can be used for finetuning further such models?"
        updatedAt: '2023-05-29T20:21:36.920Z'
      numEdits: 0
      reactions: []
    id: 647509507d131daf633f6122
    type: comment
  author: Delta36652
  content: "Hello. First of all, thank you for tuning this model. \r\nWhat sampling\
    \ settings (temperature, TopP, etc) do you recommend for this model and for 30B\
    \ one?\r\n\r\nOfftopic question:\r\nAre there any other RP sites, that can be\
    \ used for finetuning further such models?"
  created_at: 2023-05-29 19:21:36+00:00
  edited: false
  hidden: false
  id: 647509507d131daf633f6122
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/37bfa79033dfa10085b474ae84598081.svg
      fullname: reeducator
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: reeducator
      type: user
    createdAt: '2023-06-02T08:33:10.000Z'
    data:
      edited: false
      editors:
      - reeducator
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/37bfa79033dfa10085b474ae84598081.svg
          fullname: reeducator
          isHf: false
          isPro: false
          name: reeducator
          type: user
        html: "<p>I don't have any particular settings I highly endorse, since the\
          \ model is still WIP and the settings may vary according to preference,\
          \ but I might suggest starting with temperature something like 0.9, and\
          \ increase it from there a bit in increments of 0.05 or so depending whether\
          \ you find it too robotic or dull. For top_k and top_p, try 40 and 0.5,\
          \ respectively. The repeat penalty tokens should be around 100-300, with\
          \ the penalty around 1.1~1.2.</p>\n<blockquote>\n<p>Are there any other\
          \ RP sites, that can be used for finetuning further such models?</p>\n</blockquote>\n\
          <p>There certainly are, and there are some scrapes available from those\
          \ from which datasets can be further derived:<br><a rel=\"nofollow\" href=\"\
          https://rentry.org/qib8f\">https://rentry.org/qib8f</a><br>Quite many might\
          \ make an interesting addition, and perhaps help further pushing the context\
          \ size as well.</p>\n<p>If you're interested in including anything from\
          \ any in to an RP finetune cocktail, contributions are welcome by cleaning\
          \ the samples for instance. There's a handy tool from <span data-props=\"\
          {&quot;user&quot;:&quot;Squish42&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/Squish42\">@<span class=\"underline\">Squish42</span></a></span>\n\
          \n\t</span></span> now that can make the job easier, and one can check out\
          \ here <a href=\"https://huggingface.co/datasets/Squish42/bluemoon-fandom-1-1-rp-cleaned/discussions/1#646ed5b034fde71fdaa69e5c\"\
          >https://huggingface.co/datasets/Squish42/bluemoon-fandom-1-1-rp-cleaned/discussions/1#646ed5b034fde71fdaa69e5c</a>\
          \ as an example how the bluemoon fandom was prepared.</p>\n"
        raw: 'I don''t have any particular settings I highly endorse, since the model
          is still WIP and the settings may vary according to preference, but I might
          suggest starting with temperature something like 0.9, and increase it from
          there a bit in increments of 0.05 or so depending whether you find it too
          robotic or dull. For top_k and top_p, try 40 and 0.5, respectively. The
          repeat penalty tokens should be around 100-300, with the penalty around
          1.1~1.2.


          >Are there any other RP sites, that can be used for finetuning further such
          models?


          There certainly are, and there are some scrapes available from those from
          which datasets can be further derived:

          https://rentry.org/qib8f

          Quite many might make an interesting addition, and perhaps help further
          pushing the context size as well.


          If you''re interested in including anything from any in to an RP finetune
          cocktail, contributions are welcome by cleaning the samples for instance.
          There''s a handy tool from @Squish42 now that can make the job easier, and
          one can check out here https://huggingface.co/datasets/Squish42/bluemoon-fandom-1-1-rp-cleaned/discussions/1#646ed5b034fde71fdaa69e5c
          as an example how the bluemoon fandom was prepared.'
        updatedAt: '2023-06-02T08:33:10.480Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Squish42
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Delta36652
    id: 6479a9461a2aefceecd240e3
    type: comment
  author: reeducator
  content: 'I don''t have any particular settings I highly endorse, since the model
    is still WIP and the settings may vary according to preference, but I might suggest
    starting with temperature something like 0.9, and increase it from there a bit
    in increments of 0.05 or so depending whether you find it too robotic or dull.
    For top_k and top_p, try 40 and 0.5, respectively. The repeat penalty tokens should
    be around 100-300, with the penalty around 1.1~1.2.


    >Are there any other RP sites, that can be used for finetuning further such models?


    There certainly are, and there are some scrapes available from those from which
    datasets can be further derived:

    https://rentry.org/qib8f

    Quite many might make an interesting addition, and perhaps help further pushing
    the context size as well.


    If you''re interested in including anything from any in to an RP finetune cocktail,
    contributions are welcome by cleaning the samples for instance. There''s a handy
    tool from @Squish42 now that can make the job easier, and one can check out here
    https://huggingface.co/datasets/Squish42/bluemoon-fandom-1-1-rp-cleaned/discussions/1#646ed5b034fde71fdaa69e5c
    as an example how the bluemoon fandom was prepared.'
  created_at: 2023-06-02 07:33:10+00:00
  edited: false
  hidden: false
  id: 6479a9461a2aefceecd240e3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: reeducator/bluemoonrp-13b
repo_type: model
status: open
target_branch: null
title: Suggested sampling settings
