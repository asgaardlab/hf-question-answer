!!python/object:huggingface_hub.community.DiscussionWithDetails
author: DanielTTY
conflicting_files: null
created_at: 2023-07-02 00:48:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/481394619236c114ade0003e6e424dec.svg
      fullname: TTY
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DanielTTY
      type: user
    createdAt: '2023-07-02T01:48:10.000Z'
    data:
      edited: false
      editors:
      - DanielTTY
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8318516612052917
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/481394619236c114ade0003e6e424dec.svg
          fullname: TTY
          isHf: false
          isPro: false
          name: DanielTTY
          type: user
        html: '<p>I tried this and it gives the error:<br>TypeError: forward() takes
          2 positional arguments but 3 were given</p>

          <p>This is the same error when one sets "--gradient_checkpointing False".</p>

          '
        raw: "I tried this and it gives the error:\r\nTypeError: forward() takes 2\
          \ positional arguments but 3 were given\r\n\r\nThis is the same error when\
          \ one sets \"--gradient_checkpointing False\"."
        updatedAt: '2023-07-02T01:48:10.126Z'
      numEdits: 0
      reactions: []
    id: 64a0d75ae867a334b10a07af
    type: comment
  author: DanielTTY
  content: "I tried this and it gives the error:\r\nTypeError: forward() takes 2 positional\
    \ arguments but 3 were given\r\n\r\nThis is the same error when one sets \"--gradient_checkpointing\
    \ False\"."
  created_at: 2023-07-02 00:48:10+00:00
  edited: false
  hidden: false
  id: 64a0d75ae867a334b10a07af
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39a73e66f89443c108d41edd6683184a.svg
      fullname: Enxhell Luzhnica
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: eluzhnica
      type: user
    createdAt: '2023-07-04T02:16:43.000Z'
    data:
      edited: true
      editors:
      - eluzhnica
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.921541154384613
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39a73e66f89443c108d41edd6683184a.svg
          fullname: Enxhell Luzhnica
          isHf: false
          isPro: false
          name: eluzhnica
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;DanielTTY&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/DanielTTY\">@<span class=\"\
          underline\">DanielTTY</span></a></span>\n\n\t</span></span> i'll take a\
          \ look at this tomorrow if you give me more information</p>\n<p>Does it\
          \ work for you with the 7B parameter model from cekal? Can you also confirm\
          \ your pytorch and transformers versions? Also can you post the full stack\
          \ trace and maybe a minimal reproducible script if you have it handy</p>\n"
        raw: '@DanielTTY i''ll take a look at this tomorrow if you give me more information


          Does it work for you with the 7B parameter model from cekal? Can you also
          confirm your pytorch and transformers versions? Also can you post the full
          stack trace and maybe a minimal reproducible script if you have it handy'
        updatedAt: '2023-07-04T21:18:33.641Z'
      numEdits: 2
      reactions: []
    id: 64a3810b9794cf9d4e050f2f
    type: comment
  author: eluzhnica
  content: '@DanielTTY i''ll take a look at this tomorrow if you give me more information


    Does it work for you with the 7B parameter model from cekal? Can you also confirm
    your pytorch and transformers versions? Also can you post the full stack trace
    and maybe a minimal reproducible script if you have it handy'
  created_at: 2023-07-04 01:16:43+00:00
  edited: true
  hidden: false
  id: 64a3810b9794cf9d4e050f2f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39a73e66f89443c108d41edd6683184a.svg
      fullname: Enxhell Luzhnica
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: eluzhnica
      type: user
    createdAt: '2023-07-06T00:07:14.000Z'
    data:
      edited: false
      editors:
      - eluzhnica
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.964799165725708
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39a73e66f89443c108d41edd6683184a.svg
          fullname: Enxhell Luzhnica
          isHf: false
          isPro: false
          name: eluzhnica
          type: user
        html: "<p>hey <span data-props=\"{&quot;user&quot;:&quot;DanielTTY&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/DanielTTY\"\
          >@<span class=\"underline\">DanielTTY</span></a></span>\n\n\t</span></span>\
          \ , I haven't managed to replicate this. I'm using pytorch 2.0.1 and transformers\
          \ 4.28.1. </p>\n<p>I won't be able to help much unless I get a way to replicate\
          \ this so if you can help answer the questions above i'll take a closer\
          \ look. Not sure which \"forward\" method is failing there (it doesn't seem\
          \ to be the MPT one, that doesn't have 2 positional arguments) so if you\
          \ can post the full trace that'd help.</p>\n"
        raw: "hey @DanielTTY , I haven't managed to replicate this. I'm using pytorch\
          \ 2.0.1 and transformers 4.28.1. \n\nI won't be able to help much unless\
          \ I get a way to replicate this so if you can help answer the questions\
          \ above i'll take a closer look. Not sure which \"forward\" method is failing\
          \ there (it doesn't seem to be the MPT one, that doesn't have 2 positional\
          \ arguments) so if you can post the full trace that'd help."
        updatedAt: '2023-07-06T00:07:14.682Z'
      numEdits: 0
      reactions: []
    id: 64a605b2ec9e01d9a37845d1
    type: comment
  author: eluzhnica
  content: "hey @DanielTTY , I haven't managed to replicate this. I'm using pytorch\
    \ 2.0.1 and transformers 4.28.1. \n\nI won't be able to help much unless I get\
    \ a way to replicate this so if you can help answer the questions above i'll take\
    \ a closer look. Not sure which \"forward\" method is failing there (it doesn't\
    \ seem to be the MPT one, that doesn't have 2 positional arguments) so if you\
    \ can post the full trace that'd help."
  created_at: 2023-07-05 23:07:14+00:00
  edited: false
  hidden: false
  id: 64a605b2ec9e01d9a37845d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/39a73e66f89443c108d41edd6683184a.svg
      fullname: Enxhell Luzhnica
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: eluzhnica
      type: user
    createdAt: '2023-08-04T11:17:36.000Z'
    data:
      status: closed
    id: 64ccde50dc4e838857105a60
    type: status-change
  author: eluzhnica
  created_at: 2023-08-04 10:17:36+00:00
  id: 64ccde50dc4e838857105a60
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: eluzhnica/mpt-30b-peft-compatible
repo_type: model
status: closed
target_branch: null
title: 'TypeError: forward() takes 2 positional arguments but 3 were given'
