!!python/object:huggingface_hub.community.DiscussionWithDetails
author: de-Rodrigo
conflicting_files: null
created_at: 2023-02-16 16:27:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676563169736-noauth.jpeg?w=200&h=200&f=face
      fullname: de Rodrigo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: de-Rodrigo
      type: user
    createdAt: '2023-02-16T16:27:42.000Z'
    data:
      edited: false
      editors:
      - de-Rodrigo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676563169736-noauth.jpeg?w=200&h=200&f=face
          fullname: de Rodrigo
          isHf: false
          isPro: false
          name: de-Rodrigo
          type: user
        html: '<p>Dear Community, I have been studying LayoutLMv2 for the last couple
          of months. I recently implemented a Saliency Map technique to visualize
          the most significant visual features for Token Classification, so I could
          understand more about "where the model is looking at in the image."</p>

          <p>I have observed surprising behavior from these experiments: LayoutLMv2
          almost wholly relies on the model''s textual part, while the model''s visual
          part (visual backbone) contributes nearly nothing. I could even train LayoutLMv2
          with black-out images (adequately labeled so that the textual part could
          work) and still obtain the same results as when conventionally trained.
          This result suggests that the visual backbone is not working correctly (or
          I am doing something wrong).</p>

          <p>Could I share my pieces of evidence with you?<br>Teamwork makes the dreamwork</p>

          '
        raw: "Dear Community, I have been studying LayoutLMv2 for the last couple\
          \ of months. I recently implemented a Saliency Map technique to visualize\
          \ the most significant visual features for Token Classification, so I could\
          \ understand more about \"where the model is looking at in the image.\"\r\
          \n \r\nI have observed surprising behavior from these experiments: LayoutLMv2\
          \ almost wholly relies on the model's textual part, while the model's visual\
          \ part (visual backbone) contributes nearly nothing. I could even train\
          \ LayoutLMv2 with black-out images (adequately labeled so that the textual\
          \ part could work) and still obtain the same results as when conventionally\
          \ trained. This result suggests that the visual backbone is not working\
          \ correctly (or I am doing something wrong).\r\n \r\nCould I share my pieces\
          \ of evidence with you?\r\nTeamwork makes the dreamwork\r\n"
        updatedAt: '2023-02-16T16:27:42.303Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - bhn4477
    id: 63ee597e230251af5ca62982
    type: comment
  author: de-Rodrigo
  content: "Dear Community, I have been studying LayoutLMv2 for the last couple of\
    \ months. I recently implemented a Saliency Map technique to visualize the most\
    \ significant visual features for Token Classification, so I could understand\
    \ more about \"where the model is looking at in the image.\"\r\n \r\nI have observed\
    \ surprising behavior from these experiments: LayoutLMv2 almost wholly relies\
    \ on the model's textual part, while the model's visual part (visual backbone)\
    \ contributes nearly nothing. I could even train LayoutLMv2 with black-out images\
    \ (adequately labeled so that the textual part could work) and still obtain the\
    \ same results as when conventionally trained. This result suggests that the visual\
    \ backbone is not working correctly (or I am doing something wrong).\r\n \r\n\
    Could I share my pieces of evidence with you?\r\nTeamwork makes the dreamwork\r\
    \n"
  created_at: 2023-02-16 16:27:42+00:00
  edited: false
  hidden: false
  id: 63ee597e230251af5ca62982
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: microsoft/layoutlmv2-base-uncased
repo_type: model
status: open
target_branch: null
title: ' LayoutLMv2: Visual-Backbone unexpected behavior'
