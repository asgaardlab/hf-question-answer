!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mert-kurttutan
conflicting_files: null
created_at: 2023-04-13 17:58:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ec6a7bc3f6c07c4b515b40db90db682c.svg
      fullname: Mert Kurttutan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mert-kurttutan
      type: user
    createdAt: '2023-04-13T18:58:42.000Z'
    data:
      edited: false
      editors:
      - mert-kurttutan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ec6a7bc3f6c07c4b515b40db90db682c.svg
          fullname: Mert Kurttutan
          isHf: false
          isPro: false
          name: mert-kurttutan
          type: user
        html: "<p>When you run the original tokenizer from whisper package</p>\n<pre><code>whisper_tokenizer\
          \ = tokenizer.get_tokenizer(multilingual=True, language=\"en\", task=\"\
          transcribe\")\nwhisper_tokenizer.encoding.encode(\" the\")\n</code></pre>\n\
          <p>You get </p>\n<pre><code>[264]\n</code></pre>\n<p>But the same code gives\
          \ different result using the tokenizer.json included here</p>\n<pre><code>hf_tok\
          \ = tokenizers.Tokenizer.from_pretrained(\"openai/whisper-large\")\nhf_tok.encode(\"\
          \ the\", add_special_tokens=False).ids\n</code></pre>\n<p>You get</p>\n\
          <pre><code>[220, 3322]\n</code></pre>\n<p>I think this is because of missing\
          \ merge (but that is present in the original BPE)</p>\n<p>Using the function\
          \ <a rel=\"nofollow\" href=\"https://github.com/openai/tiktoken/issues/60#issuecomment-1499977960\"\
          >here</a>,<br>I detected only one missing merge<br>Correct tokenizer.json\
          \ should be as follows</p>\n<pre><code>    \"merges\": [\n      \"\u0120\
          \ t\",\n      \"\u0120 a\",\n      \"\u0120t h\",\n</code></pre>\n<p>whereas\
          \ current one</p>\n<pre><code>    \"merges\": [\n      \"\u0120 a\",\n \
          \     \"\u0120t h\",\n</code></pre>\n<p>Accordingly, other repos and merges.txt\
          \ should be modified</p>\n"
        raw: "When you run the original tokenizer from whisper package\r\n```\r\n\
          whisper_tokenizer = tokenizer.get_tokenizer(multilingual=True, language=\"\
          en\", task=\"transcribe\")\r\nwhisper_tokenizer.encoding.encode(\" the\"\
          )\r\n```\r\nYou get \r\n\r\n```\r\n[264]\r\n```\r\nBut the same code gives\
          \ different result using the tokenizer.json included here\r\n\r\n```\r\n\
          hf_tok = tokenizers.Tokenizer.from_pretrained(\"openai/whisper-large\")\r\
          \nhf_tok.encode(\" the\", add_special_tokens=False).ids\r\n```\r\nYou get\r\
          \n\r\n```\r\n[220, 3322]\r\n```\r\n\r\nI think this is because of missing\
          \ merge (but that is present in the original BPE)\r\n\r\nUsing the function\
          \ [here](https://github.com/openai/tiktoken/issues/60#issuecomment-1499977960),\r\
          \nI detected only one missing merge\r\nCorrect tokenizer.json should be\
          \ as follows\r\n```\r\n    \"merges\": [\r\n      \"\u0120 t\",\r\n    \
          \  \"\u0120 a\",\r\n      \"\u0120t h\",\r\n```\r\nwhereas current one\r\
          \n\r\n```\r\n    \"merges\": [\r\n      \"\u0120 a\",\r\n      \"\u0120\
          t h\",\r\n```\r\n\r\nAccordingly, other repos and merges.txt should be modified"
        updatedAt: '2023-04-13T18:58:42.445Z'
      numEdits: 0
      reactions: []
    id: 643850e227a3c24cf4a29bd3
    type: comment
  author: mert-kurttutan
  content: "When you run the original tokenizer from whisper package\r\n```\r\nwhisper_tokenizer\
    \ = tokenizer.get_tokenizer(multilingual=True, language=\"en\", task=\"transcribe\"\
    )\r\nwhisper_tokenizer.encoding.encode(\" the\")\r\n```\r\nYou get \r\n\r\n```\r\
    \n[264]\r\n```\r\nBut the same code gives different result using the tokenizer.json\
    \ included here\r\n\r\n```\r\nhf_tok = tokenizers.Tokenizer.from_pretrained(\"\
    openai/whisper-large\")\r\nhf_tok.encode(\" the\", add_special_tokens=False).ids\r\
    \n```\r\nYou get\r\n\r\n```\r\n[220, 3322]\r\n```\r\n\r\nI think this is because\
    \ of missing merge (but that is present in the original BPE)\r\n\r\nUsing the\
    \ function [here](https://github.com/openai/tiktoken/issues/60#issuecomment-1499977960),\r\
    \nI detected only one missing merge\r\nCorrect tokenizer.json should be as follows\r\
    \n```\r\n    \"merges\": [\r\n      \"\u0120 t\",\r\n      \"\u0120 a\",\r\n \
    \     \"\u0120t h\",\r\n```\r\nwhereas current one\r\n\r\n```\r\n    \"merges\"\
    : [\r\n      \"\u0120 a\",\r\n      \"\u0120t h\",\r\n```\r\n\r\nAccordingly,\
    \ other repos and merges.txt should be modified"
  created_at: 2023-04-13 17:58:42+00:00
  edited: false
  hidden: false
  id: 643850e227a3c24cf4a29bd3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-04-18T17:30:00.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>cc <span data-props=\"{&quot;user&quot;:&quot;ArthurZ&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ArthurZ\">@<span class=\"\
          underline\">ArthurZ</span></a></span>\n\n\t</span></span> when you get the\
          \ chance \U0001F64C</p>\n"
        raw: "cc @ArthurZ when you get the chance \U0001F64C"
        updatedAt: '2023-04-18T17:30:00.342Z'
      numEdits: 0
      reactions: []
    id: 643ed398f2ed3bc5c0619a59
    type: comment
  author: sanchit-gandhi
  content: "cc @ArthurZ when you get the chance \U0001F64C"
  created_at: 2023-04-18 16:30:00+00:00
  edited: false
  hidden: false
  id: 643ed398f2ed3bc5c0619a59
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e571d4a731bc6a9c395b1af150d298d8.svg
      fullname: N Lewins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nlewins
      type: user
    createdAt: '2023-12-12T09:14:28.000Z'
    data:
      edited: false
      editors:
      - nlewins
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.990573525428772
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e571d4a731bc6a9c395b1af150d298d8.svg
          fullname: N Lewins
          isHf: false
          isPro: false
          name: nlewins
          type: user
        html: '<p>I just tripped over this too.  It would be good to see it fixed.</p>

          '
        raw: I just tripped over this too.  It would be good to see it fixed.
        updatedAt: '2023-12-12T09:14:28.356Z'
      numEdits: 0
      reactions: []
    id: 657824746cb1dcb957dbde85
    type: comment
  author: nlewins
  content: I just tripped over this too.  It would be good to see it fixed.
  created_at: 2023-12-12 09:14:28+00:00
  edited: false
  hidden: false
  id: 657824746cb1dcb957dbde85
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-12T10:51:19.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.998483419418335
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Oh wow sorry. Just saw that as well will have look</p>

          '
        raw: Oh wow sorry. Just saw that as well will have look
        updatedAt: '2023-12-12T10:51:19.640Z'
      numEdits: 0
      reactions: []
    id: 65783b271e0b436ae7775d14
    type: comment
  author: ArthurZ
  content: Oh wow sorry. Just saw that as well will have look
  created_at: 2023-12-12 10:51:19+00:00
  edited: false
  hidden: false
  id: 65783b271e0b436ae7775d14
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-15T09:11:43.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8971837162971497
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>I''ll check the conversion script, there might be a bug in there.
          </p>

          '
        raw: 'I''ll check the conversion script, there might be a bug in there. '
        updatedAt: '2023-12-15T09:11:43.270Z'
      numEdits: 0
      reactions: []
    id: 657c184f10609bba274ce600
    type: comment
  author: ArthurZ
  content: 'I''ll check the conversion script, there might be a bug in there. '
  created_at: 2023-12-15 09:11:43+00:00
  edited: false
  hidden: false
  id: 657c184f10609bba274ce600
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-18T07:00:27.000Z'
    data:
      edited: true
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6936966180801392
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p><a href="/openai/whisper-base/discussions/28">#28</a> adresses this</p>

          '
        raw: '#28 adresses this'
        updatedAt: '2023-12-18T07:03:07.065Z'
      numEdits: 1
      reactions: []
    id: 657fee0bd70b7308f3b9b71e
    type: comment
  author: ArthurZ
  content: '#28 adresses this'
  created_at: 2023-12-18 07:00:27+00:00
  edited: true
  hidden: false
  id: 657fee0bd70b7308f3b9b71e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-18T07:23:48.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8472903370857239
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>What''s weird is that installing <code>pip install  openai-whisper==20230117</code>
          and doing:</p>

          <pre><code class="language-python"><span class="hljs-meta">&gt;&gt;&gt;
          </span><span class="hljs-keyword">from</span> whisper.tokenizer <span class="hljs-keyword">import</span>
          get_tokenizer

          <span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = get_tokenizer(<span
          class="hljs-literal">True</span>)

          <span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.encode(<span class="hljs-string">"
          the"</span>)

          [<span class="hljs-number">220</span>, <span class="hljs-number">3322</span>]

          </code></pre>

          <p>also gives the wrong result.<br>However the merge was there since day
          1: <a rel="nofollow" href="https://github.com/openai/whisper/blame/ad3250a846fe7553a25064a2dc593e492dadf040/whisper/assets/gpt2/merges.txt">https://github.com/openai/whisper/blame/ad3250a846fe7553a25064a2dc593e492dadf040/whisper/assets/gpt2/merges.txt</a>.<br>The
          conversion from slow to fast is <del>probably</del> removing it .</p>

          <p>See: </p>

          <pre><code class="language-python">tokenizer.tokenizer.save_pretrained(<span
          class="hljs-string">"local_path/whisper-old"</span>)

          </code></pre>

          <p>opening the <code>merges.txt</code>,  it no longer has the first merge.<br>If
          we remove the <code>tokenizer.json</code> and add the correct merge to <code>merges.txt</code>
          the conversions works well with <code>tokenizer.from_pretrained("local_path/whisper-old")</code>,
          meaning it''s probably the layer on top of transformers that was causing
          this. </p>

          '
        raw: "What's weird is that installing `pip install  openai-whisper==20230117`\
          \ and doing:\n```python \n>>> from whisper.tokenizer import get_tokenizer\n\
          >>> tokenizer = get_tokenizer(True)\n>>> tokenizer.encode(\" the\")\n[220,\
          \ 3322]\n```\nalso gives the wrong result. \nHowever the merge was there\
          \ since day 1: https://github.com/openai/whisper/blame/ad3250a846fe7553a25064a2dc593e492dadf040/whisper/assets/gpt2/merges.txt.\
          \ \nThe conversion from slow to fast is ~probably~ removing it .\n\nSee:\
          \ \n```python \ntokenizer.tokenizer.save_pretrained(\"local_path/whisper-old\"\
          )\n``` \nopening the `merges.txt`,  it no longer has the first merge. \n\
          If we remove the `tokenizer.json` and add the correct merge to `merges.txt`\
          \ the conversions works well with `tokenizer.from_pretrained(\"local_path/whisper-old\"\
          )`, meaning it's probably the layer on top of transformers that was causing\
          \ this. "
        updatedAt: '2023-12-18T07:23:48.924Z'
      numEdits: 0
      reactions: []
    id: 657ff384792970912844e700
    type: comment
  author: ArthurZ
  content: "What's weird is that installing `pip install  openai-whisper==20230117`\
    \ and doing:\n```python \n>>> from whisper.tokenizer import get_tokenizer\n>>>\
    \ tokenizer = get_tokenizer(True)\n>>> tokenizer.encode(\" the\")\n[220, 3322]\n\
    ```\nalso gives the wrong result. \nHowever the merge was there since day 1: https://github.com/openai/whisper/blame/ad3250a846fe7553a25064a2dc593e492dadf040/whisper/assets/gpt2/merges.txt.\
    \ \nThe conversion from slow to fast is ~probably~ removing it .\n\nSee: \n```python\
    \ \ntokenizer.tokenizer.save_pretrained(\"local_path/whisper-old\")\n``` \nopening\
    \ the `merges.txt`,  it no longer has the first merge. \nIf we remove the `tokenizer.json`\
    \ and add the correct merge to `merges.txt` the conversions works well with `tokenizer.from_pretrained(\"\
    local_path/whisper-old\")`, meaning it's probably the layer on top of transformers\
    \ that was causing this. "
  created_at: 2023-12-18 07:23:48+00:00
  edited: false
  hidden: false
  id: 657ff384792970912844e700
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: openai/whisper-base
repo_type: model
status: open
target_branch: null
title: Missing Merge Pair (based on the original BPE from whisper)
