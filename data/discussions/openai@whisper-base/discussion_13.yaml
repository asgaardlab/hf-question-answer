!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xyang16
conflicting_files: null
created_at: 2023-03-27 21:29:39+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/786aca4e0c45e08ce29ad5af2fa55b0e.svg
      fullname: XY
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xyang16
      type: user
    createdAt: '2023-03-27T22:29:39.000Z'
    data:
      edited: true
      editors:
      - xyang16
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/786aca4e0c45e08ce29ad5af2fa55b0e.svg
          fullname: XY
          isHf: false
          isPro: false
          name: xyang16
          type: user
        html: '<p>When I run the model using the whisper model on an audio around
          2 minutes, the output is truncated without the &lt;|endoftext|&gt; tag.</p>

          <pre><code>processor = WhisperProcessor.from_pretrained("openai/whisper-base")

          model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base")

          </code></pre>

          <p>Output:</p>

          <pre><code>&lt;|startoftranscript|&gt; &lt;|en|&gt; &lt;|transcribe|&gt;
          null Well , she was very short . She was about five foot tall . So she always
          had this rather null null bou ff ant hairstyle , and you see , to give her
          a few extra inches , and very , very high heels , null null which she wore
          even first thing on a Sunday morning . And a terrifying mean , I think .
          null null I say all these things about her because as a the youngest child
          by some years after my older null null siblings , I was always kind of an
          observer of this , and a slightly am

          </code></pre>

          <p>Is there any way to transcribe the whole audio longer than 30 seconds?</p>

          '
        raw: 'When I run the model using the whisper model on an audio around 2 minutes,
          the output is truncated without the <|endoftext|> tag.


          ```

          processor = WhisperProcessor.from_pretrained("openai/whisper-base")

          model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base")

          ```


          Output:


          ```

          <|startoftranscript|> <|en|> <|transcribe|> null Well , she was very short
          . She was about five foot tall . So she always had this rather null null
          bou ff ant hairstyle , and you see , to give her a few extra inches , and
          very , very high heels , null null which she wore even first thing on a
          Sunday morning . And a terrifying mean , I think . null null I say all these
          things about her because as a the youngest child by some years after my
          older null null siblings , I was always kind of an observer of this , and
          a slightly am

          ```


          Is there any way to transcribe the whole audio longer than 30 seconds?'
        updatedAt: '2023-03-27T22:41:28.295Z'
      numEdits: 1
      reactions: []
    id: 642218d32cc2b3c39e849f8c
    type: comment
  author: xyang16
  content: 'When I run the model using the whisper model on an audio around 2 minutes,
    the output is truncated without the <|endoftext|> tag.


    ```

    processor = WhisperProcessor.from_pretrained("openai/whisper-base")

    model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base")

    ```


    Output:


    ```

    <|startoftranscript|> <|en|> <|transcribe|> null Well , she was very short . She
    was about five foot tall . So she always had this rather null null bou ff ant
    hairstyle , and you see , to give her a few extra inches , and very , very high
    heels , null null which she wore even first thing on a Sunday morning . And a
    terrifying mean , I think . null null I say all these things about her because
    as a the youngest child by some years after my older null null siblings , I was
    always kind of an observer of this , and a slightly am

    ```


    Is there any way to transcribe the whole audio longer than 30 seconds?'
  created_at: 2023-03-27 21:29:39+00:00
  edited: true
  hidden: false
  id: 642218d32cc2b3c39e849f8c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/786aca4e0c45e08ce29ad5af2fa55b0e.svg
      fullname: XY
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xyang16
      type: user
    createdAt: '2023-03-27T22:30:26.000Z'
    data:
      from: Transcribe audio longer than 30 second
      to: Transcribe audio longer than 30 seconds
    id: 64221902332961f4dfad1df6
    type: title-change
  author: xyang16
  created_at: 2023-03-27 21:30:26+00:00
  id: 64221902332961f4dfad1df6
  new_title: Transcribe audio longer than 30 seconds
  old_title: Transcribe audio longer than 30 second
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-04-04T16:57:31.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Yes <span data-props=\"{&quot;user&quot;:&quot;xyang16&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/xyang16\"\
          >@<span class=\"underline\">xyang16</span></a></span>\n\n\t</span></span>!\
          \ See <a href=\"https://huggingface.co/openai/whisper-base#long-form-transcription\"\
          >https://huggingface.co/openai/whisper-base#long-form-transcription</a></p>\n"
        raw: Yes @xyang16! See https://huggingface.co/openai/whisper-base#long-form-transcription
        updatedAt: '2023-04-04T16:57:31.581Z'
      numEdits: 0
      reactions: []
    id: 642c56fbd3340aee0441a30b
    type: comment
  author: sanchit-gandhi
  content: Yes @xyang16! See https://huggingface.co/openai/whisper-base#long-form-transcription
  created_at: 2023-04-04 15:57:31+00:00
  edited: false
  hidden: false
  id: 642c56fbd3340aee0441a30b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/42e3cb63dde7222907b9864e3a231129.svg
      fullname: v-zhidu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: v-zhidu
      type: user
    createdAt: '2023-05-24T03:53:10.000Z'
    data:
      edited: false
      editors:
      - v-zhidu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/42e3cb63dde7222907b9864e3a231129.svg
          fullname: v-zhidu
          isHf: false
          isPro: false
          name: v-zhidu
          type: user
        html: '<p>Hi, How to use Pipeline to process long audio with non-English language
          ?</p>

          '
        raw: Hi, How to use Pipeline to process long audio with non-English language
          ?
        updatedAt: '2023-05-24T03:53:10.173Z'
      numEdits: 0
      reactions: []
    id: 646d8a26acc13867a1449fba
    type: comment
  author: v-zhidu
  content: Hi, How to use Pipeline to process long audio with non-English language
    ?
  created_at: 2023-05-24 02:53:10+00:00
  edited: false
  hidden: false
  id: 646d8a26acc13867a1449fba
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-05-24T14:48:11.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>You should be able to do the following for Hindi:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">import</span> torch\n\
          <span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> pipeline\n<span class=\"hljs-keyword\">from</span> datasets\
          \ <span class=\"hljs-keyword\">import</span> load_dataset\n\ndevice = <span\
          \ class=\"hljs-string\">\"cuda:0\"</span> <span class=\"hljs-keyword\">if</span>\
          \ torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> <span\
          \ class=\"hljs-string\">\"cpu\"</span>\n\npipe = pipeline(\n  <span class=\"\
          hljs-string\">\"automatic-speech-recognition\"</span>,\n  model=<span class=\"\
          hljs-string\">\"openai/whisper-base\"</span>,\n  chunk_length_s=<span class=\"\
          hljs-number\">30</span>,\n  device=device,\n)\n\nds = load_dataset(<span\
          \ class=\"hljs-string\">\"common_voice\"</span>, <span class=\"hljs-string\"\
          >\"hi\"</span>, split=<span class=\"hljs-string\">\"validation\"</span>,\
          \ streaming=<span class=\"hljs-literal\">True</span>)\nsample = <span class=\"\
          hljs-built_in\">next</span>(<span class=\"hljs-built_in\">iter</span>(ds))[<span\
          \ class=\"hljs-string\">\"audio\"</span>]\n\nprediction = pipe(sample.copy(),\
          \ batch_size=<span class=\"hljs-number\">8</span>, generate_kwargs={<span\
          \ class=\"hljs-string\">\"language\"</span>: <span class=\"hljs-string\"\
          >\"hi\"</span>, <span class=\"hljs-string\">\"task\"</span>: <span class=\"\
          hljs-string\">\"transcribe\"</span>})[<span class=\"hljs-string\">\"text\"\
          </span>]\n\n<span class=\"hljs-comment\"># we can also return timestamps\
          \ for the predictions</span>\nprediction = pipe(sample.copy(), batch_size=<span\
          \ class=\"hljs-number\">8</span>, generate_kwargs={<span class=\"hljs-string\"\
          >\"language\"</span>: <span class=\"hljs-string\">\"hi\"</span>, <span class=\"\
          hljs-string\">\"task\"</span>: <span class=\"hljs-string\">\"transcribe\"\
          </span>}, return_timestamps=<span class=\"hljs-literal\">True</span>)[<span\
          \ class=\"hljs-string\">\"chunks\"</span>]\n</code></pre>\n<p>You can change\
          \ the language and task arguments as required.</p>\n"
        raw: "You should be able to do the following for Hindi:\n```python\nimport\
          \ torch\nfrom transformers import pipeline\nfrom datasets import load_dataset\n\
          \ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\npipe\
          \ = pipeline(\n  \"automatic-speech-recognition\",\n  model=\"openai/whisper-base\"\
          ,\n  chunk_length_s=30,\n  device=device,\n)\n\nds = load_dataset(\"common_voice\"\
          , \"hi\", split=\"validation\", streaming=True)\nsample = next(iter(ds))[\"\
          audio\"]\n\nprediction = pipe(sample.copy(), batch_size=8, generate_kwargs={\"\
          language\": \"hi\", \"task\": \"transcribe\"})[\"text\"]\n\n# we can also\
          \ return timestamps for the predictions\nprediction = pipe(sample.copy(),\
          \ batch_size=8, generate_kwargs={\"language\": \"hi\", \"task\": \"transcribe\"\
          }, return_timestamps=True)[\"chunks\"]\n```\nYou can change the language\
          \ and task arguments as required."
        updatedAt: '2023-05-24T14:48:45.608Z'
      numEdits: 2
      reactions: []
    id: 646e23ab40e741b1913f4d02
    type: comment
  author: sanchit-gandhi
  content: "You should be able to do the following for Hindi:\n```python\nimport torch\n\
    from transformers import pipeline\nfrom datasets import load_dataset\n\ndevice\
    \ = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\npipe = pipeline(\n\
    \  \"automatic-speech-recognition\",\n  model=\"openai/whisper-base\",\n  chunk_length_s=30,\n\
    \  device=device,\n)\n\nds = load_dataset(\"common_voice\", \"hi\", split=\"validation\"\
    , streaming=True)\nsample = next(iter(ds))[\"audio\"]\n\nprediction = pipe(sample.copy(),\
    \ batch_size=8, generate_kwargs={\"language\": \"hi\", \"task\": \"transcribe\"\
    })[\"text\"]\n\n# we can also return timestamps for the predictions\nprediction\
    \ = pipe(sample.copy(), batch_size=8, generate_kwargs={\"language\": \"hi\", \"\
    task\": \"transcribe\"}, return_timestamps=True)[\"chunks\"]\n```\nYou can change\
    \ the language and task arguments as required."
  created_at: 2023-05-24 13:48:11+00:00
  edited: true
  hidden: false
  id: 646e23ab40e741b1913f4d02
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: openai/whisper-base
repo_type: model
status: open
target_branch: null
title: Transcribe audio longer than 30 seconds
