!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mwgupta
conflicting_files: null
created_at: 2023-08-08 15:54:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3f54e7aa54f16e51a0f8aab6a820cb5e.svg
      fullname: Meili Gupta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mwgupta
      type: user
    createdAt: '2023-08-08T16:54:17.000Z'
    data:
      edited: false
      editors:
      - mwgupta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7497323155403137
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3f54e7aa54f16e51a0f8aab6a820cb5e.svg
          fullname: Meili Gupta
          isHf: false
          isPro: false
          name: mwgupta
          type: user
        html: '<p>max_new_token parameter upper bound seems to be 512 (couldn''t find
          documentation online about upper bound, bigger than 512 returns an index
          out of range error). Any suggestions on workarounds?</p>

          '
        raw: max_new_token parameter upper bound seems to be 512 (couldn't find documentation
          online about upper bound, bigger than 512 returns an index out of range
          error). Any suggestions on workarounds?
        updatedAt: '2023-08-08T16:54:17.981Z'
      numEdits: 0
      reactions: []
    id: 64d273394f2a57d70b0d6f2e
    type: comment
  author: mwgupta
  content: max_new_token parameter upper bound seems to be 512 (couldn't find documentation
    online about upper bound, bigger than 512 returns an index out of range error).
    Any suggestions on workarounds?
  created_at: 2023-08-08 15:54:17+00:00
  edited: false
  hidden: false
  id: 64d273394f2a57d70b0d6f2e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/V6Qj6xRFGH48qagPSkCVn.jpeg?w=200&h=200&f=face
      fullname: "M. \xC1ngel Gonz\xE1lez"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AITEK-DEV
      type: user
    createdAt: '2023-08-08T21:48:07.000Z'
    data:
      edited: false
      editors:
      - AITEK-DEV
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9034451246261597
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/V6Qj6xRFGH48qagPSkCVn.jpeg?w=200&h=200&f=face
          fullname: "M. \xC1ngel Gonz\xE1lez"
          isHf: false
          isPro: false
          name: AITEK-DEV
          type: user
        html: '<p>The maximum token limit  is indeed 2048 tokens. If you encounter
          an "index out of range" error, it could be due to the text being cut off
          before reaching that limit. Make sure to count both input and output tokens,
          and if the total exceeds 2048, you''ll need to truncate or omit parts of
          the text. Keep in mind that very long conversations may lead to incomplete
          replies.</p>

          '
        raw: The maximum token limit  is indeed 2048 tokens. If you encounter an "index
          out of range" error, it could be due to the text being cut off before reaching
          that limit. Make sure to count both input and output tokens, and if the
          total exceeds 2048, you'll need to truncate or omit parts of the text. Keep
          in mind that very long conversations may lead to incomplete replies.
        updatedAt: '2023-08-08T21:48:07.463Z'
      numEdits: 0
      reactions: []
    id: 64d2b817611eb500dcc16b6b
    type: comment
  author: AITEK-DEV
  content: The maximum token limit  is indeed 2048 tokens. If you encounter an "index
    out of range" error, it could be due to the text being cut off before reaching
    that limit. Make sure to count both input and output tokens, and if the total
    exceeds 2048, you'll need to truncate or omit parts of the text. Keep in mind
    that very long conversations may lead to incomplete replies.
  created_at: 2023-08-08 20:48:07+00:00
  edited: false
  hidden: false
  id: 64d2b817611eb500dcc16b6b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: microsoft/CodeGPT-small-py
repo_type: model
status: open
target_branch: null
title: Small max new token limit
