!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AlexWortega
conflicting_files: null
created_at: 2023-04-11 19:10:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60b23b069c978cce68723b25/jfG5kbQM5c7WYuePvZtBe.jpeg?w=200&h=200&f=face
      fullname: Wortega
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AlexWortega
      type: user
    createdAt: '2023-04-11T20:10:41.000Z'
    data:
      edited: false
      editors:
      - AlexWortega
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60b23b069c978cce68723b25/jfG5kbQM5c7WYuePvZtBe.jpeg?w=200&h=200&f=face
          fullname: Wortega
          isHf: false
          isPro: false
          name: AlexWortega
          type: user
        html: '<p>Can you add readme with difference?</p>

          '
        raw: Can you add readme with difference?
        updatedAt: '2023-04-11T20:10:41.234Z'
      numEdits: 0
      reactions: []
    id: 6435bec12d0ed796668e7c10
    type: comment
  author: AlexWortega
  content: Can you add readme with difference?
  created_at: 2023-04-11 19:10:41+00:00
  edited: false
  hidden: false
  id: 6435bec12d0ed796668e7c10
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-04-12T16:56:04.000Z'
    data:
      edited: false
      editors:
      - rwightman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;AlexWortega&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/AlexWortega\"\
          >@<span class=\"underline\">AlexWortega</span></a></span>\n\n\t</span></span>\
          \ it's a different version of <a href=\"https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s12B-b42K\"\
          >https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s12B-b42K</a> not bigG\
          \ (larger model), trained on same data but for more samples and w/ a larger\
          \ global batch size</p>\n"
        raw: '@AlexWortega it''s a different version of https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s12B-b42K
          not bigG (larger model), trained on same data but for more samples and w/
          a larger global batch size'
        updatedAt: '2023-04-12T16:56:04.222Z'
      numEdits: 0
      reactions: []
    id: 6436e2a4c06cb2064ae3075e
    type: comment
  author: rwightman
  content: '@AlexWortega it''s a different version of https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s12B-b42K
    not bigG (larger model), trained on same data but for more samples and w/ a larger
    global batch size'
  created_at: 2023-04-12 15:56:04+00:00
  edited: false
  hidden: false
  id: 6436e2a4c06cb2064ae3075e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-04-12T16:57:16.000Z'
    data:
      edited: true
      editors:
      - rwightman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: '<p>s34B means 34B samples seen during training, b88K means a global
          batch size of ~88000 instead of 12B samples and ~42000 batch size for the
          earlier ''g''</p>

          <p>From <a rel="nofollow" href="https://github.com/mlfoundations/open_clip">https://github.com/mlfoundations/open_clip</a>
          README, this is the 78.5. Should update the README here yes, but there''s
          a big stack of TODOs :)</p>

          <ul>

          <li>ViT-H/14 on LAION-2B with an accuracy of <strong>78.0</strong>. The
          second best in1k zero-shot for released, open-source weights thus far.</li>

          <li>ViT-g/14 on LAION-2B with an accuracy of <strong>76.6</strong>. This
          was trained on reduced 12B samples seen schedule, same samples seen as 400M
          models.</li>

          <li>ViT-g/14 on LAION-2B with an accuracy of <strong>78.5</strong>. Full
          34B samples seen schedule.</li>

          <li>ViT-G/14 on LAION-2B with an accuracy of <strong>80.1</strong>. The
          best in1k zero-shot for released, open-source weights thus far.</li>

          </ul>

          '
        raw: "s34B means 34B samples seen during training, b88K means a global batch\
          \ size of ~88000 instead of 12B samples and ~42000 batch size for the earlier\
          \ 'g'\n\nFrom https://github.com/mlfoundations/open_clip README, this is\
          \ the 78.5. Should update the README here yes, but there's a big stack of\
          \ TODOs :)\n\n  * ViT-H/14 on LAION-2B with an accuracy of **78.0**. The\
          \ second best in1k zero-shot for released, open-source weights thus far.\n\
          \  * ViT-g/14 on LAION-2B with an accuracy of **76.6**. This was trained\
          \ on reduced 12B samples seen schedule, same samples seen as 400M models.\n\
          \  * ViT-g/14 on LAION-2B with an accuracy of **78.5**. Full 34B samples\
          \ seen schedule.\n  * ViT-G/14 on LAION-2B with an accuracy of **80.1**.\
          \ The best in1k zero-shot for released, open-source weights thus far."
        updatedAt: '2023-04-12T16:59:46.278Z'
      numEdits: 1
      reactions: []
    id: 6436e2ecc06cb2064ae30970
    type: comment
  author: rwightman
  content: "s34B means 34B samples seen during training, b88K means a global batch\
    \ size of ~88000 instead of 12B samples and ~42000 batch size for the earlier\
    \ 'g'\n\nFrom https://github.com/mlfoundations/open_clip README, this is the 78.5.\
    \ Should update the README here yes, but there's a big stack of TODOs :)\n\n \
    \ * ViT-H/14 on LAION-2B with an accuracy of **78.0**. The second best in1k zero-shot\
    \ for released, open-source weights thus far.\n  * ViT-g/14 on LAION-2B with an\
    \ accuracy of **76.6**. This was trained on reduced 12B samples seen schedule,\
    \ same samples seen as 400M models.\n  * ViT-g/14 on LAION-2B with an accuracy\
    \ of **78.5**. Full 34B samples seen schedule.\n  * ViT-G/14 on LAION-2B with\
    \ an accuracy of **80.1**. The best in1k zero-shot for released, open-source weights\
    \ thus far."
  created_at: 2023-04-12 15:57:16+00:00
  edited: true
  hidden: false
  id: 6436e2ecc06cb2064ae30970
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: laion/CLIP-ViT-g-14-laion2B-s34B-b88K
repo_type: model
status: open
target_branch: null
title: What is difference between this and CLIP-ViT-g-14-laion2B-s12B-b42K and  CLIP-ViT-bigG-14-laion2B-39B-b160k
