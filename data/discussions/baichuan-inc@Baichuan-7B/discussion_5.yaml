!!python/object:huggingface_hub.community.DiscussionWithDetails
author: itkingtao
conflicting_files: null
created_at: 2023-06-16 01:36:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7548b9e13e00ad1c080c32c05173fca4.svg
      fullname: walker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: itkingtao
      type: user
    createdAt: '2023-06-16T02:36:04.000Z'
    data:
      edited: false
      editors:
      - itkingtao
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.6070914268493652
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7548b9e13e00ad1c080c32c05173fca4.svg
          fullname: walker
          isHf: false
          isPro: false
          name: itkingtao
          type: user
        html: "<p>\u8DD1\u4E86\u7B2C\u4E8C\u8F6E\u5C31\u5305PYTORCH_CUDA_ALLOC_CONF\u4E86\
          \uFF0C\u5E0C\u671B\u6301\u7EED\u4F18\u5316\u6A21\u578B\u7684\u5185\u5B58\
          \u5360\u7528</p>\n"
        raw: "\u8DD1\u4E86\u7B2C\u4E8C\u8F6E\u5C31\u5305PYTORCH_CUDA_ALLOC_CONF\u4E86\
          \uFF0C\u5E0C\u671B\u6301\u7EED\u4F18\u5316\u6A21\u578B\u7684\u5185\u5B58\
          \u5360\u7528"
        updatedAt: '2023-06-16T02:36:04.815Z'
      numEdits: 0
      reactions: []
    id: 648bca94a27d011c3cbfc902
    type: comment
  author: itkingtao
  content: "\u8DD1\u4E86\u7B2C\u4E8C\u8F6E\u5C31\u5305PYTORCH_CUDA_ALLOC_CONF\u4E86\
    \uFF0C\u5E0C\u671B\u6301\u7EED\u4F18\u5316\u6A21\u578B\u7684\u5185\u5B58\u5360\
    \u7528"
  created_at: 2023-06-16 01:36:04+00:00
  edited: false
  hidden: false
  id: 648bca94a27d011c3cbfc902
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/167a6b4428910f310783876d6f321b75.svg
      fullname: chenzhoufeng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tianniu
      type: user
    createdAt: '2023-06-16T06:37:28.000Z'
    data:
      edited: false
      editors:
      - tianniu
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.7687023282051086
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/167a6b4428910f310783876d6f321b75.svg
          fullname: chenzhoufeng
          isHf: false
          isPro: false
          name: tianniu
          type: user
        html: "<p>\u621124G\u4E00\u8F6E\u90FD\u8DD1\u4E0D\u8D77\u6765</p>\n"
        raw: "\u621124G\u4E00\u8F6E\u90FD\u8DD1\u4E0D\u8D77\u6765"
        updatedAt: '2023-06-16T06:37:28.132Z'
      numEdits: 0
      reactions: []
    id: 648c0328ded4c3eb97117cd1
    type: comment
  author: tianniu
  content: "\u621124G\u4E00\u8F6E\u90FD\u8DD1\u4E0D\u8D77\u6765"
  created_at: 2023-06-16 05:37:28+00:00
  edited: false
  hidden: false
  id: 648c0328ded4c3eb97117cd1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a41f55a65da4d0e73af2a7965671abc.svg
      fullname: chen.yiwan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yiwan
      type: user
    createdAt: '2023-06-16T07:31:11.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/7a41f55a65da4d0e73af2a7965671abc.svg
          fullname: chen.yiwan
          isHf: false
          isPro: false
          name: yiwan
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-06-16T07:55:56.671Z'
      numEdits: 0
      reactions: []
    id: 648c0fbf17c7ceb9b41e2bf9
    type: comment
  author: yiwan
  content: This comment has been hidden
  created_at: 2023-06-16 06:31:11+00:00
  edited: true
  hidden: true
  id: 648c0fbf17c7ceb9b41e2bf9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a41f55a65da4d0e73af2a7965671abc.svg
      fullname: chen.yiwan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yiwan
      type: user
    createdAt: '2023-06-16T07:40:53.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/7a41f55a65da4d0e73af2a7965671abc.svg
          fullname: chen.yiwan
          isHf: false
          isPro: false
          name: yiwan
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-06-16T07:54:03.923Z'
      numEdits: 0
      reactions: []
    id: 648c12056321055b4aad2c61
    type: comment
  author: yiwan
  content: This comment has been hidden
  created_at: 2023-06-16 06:40:53+00:00
  edited: true
  hidden: true
  id: 648c12056321055b4aad2c61
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7a41f55a65da4d0e73af2a7965671abc.svg
      fullname: chen.yiwan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yiwan
      type: user
    createdAt: '2023-06-16T07:55:47.000Z'
    data:
      edited: false
      editors:
      - yiwan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.30571624636650085
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7a41f55a65da4d0e73af2a7965671abc.svg
          fullname: chen.yiwan
          isHf: false
          isPro: false
          name: yiwan
          type: user
        html: "<pre><code>\nimport os\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM,\
          \ AutoConfig\nimport torch\n\nPRE_TRAINED_MODEL_PATH = \"../model/\"\n\n\
          \n# \u7A0B\u5E8F\u5165\u53E3\ndef main():\n    os.environ[\"CUDA_VISIBLE_DEVICES\"\
          ] = \"2\"\n    tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_PATH,\
          \ trust_remote_code=True)\n    tokenizer.pad_token_id = 0 if tokenizer.pad_token_id\
          \ is None else tokenizer.pad_token_id  # set as the &lt;unk&gt; token\n\
          \    if tokenizer.pad_token_id == 64000:\n        tokenizer.pad_token_id\
          \ = 0  # for baichuan model (need fix)\n\n    config = AutoConfig.from_pretrained(PRE_TRAINED_MODEL_PATH,\
          \ trust_remote_code=True)\n    model = AutoModelForCausalLM.from_pretrained(PRE_TRAINED_MODEL_PATH,\
          \ config=config, torch_dtype=torch.float16,\n                          \
          \                       trust_remote_code=True, device_map=\"auto\", low_cpu_mem_usage=True)\n\
          \    with torch.autocast(\"cuda\"):\n        while True:\n            try:\n\
          \                input_txt = input(\"user:\")\n                inputs =\
          \ tokenizer(input_txt, return_tensors='pt')\n                inputs = inputs.to(\"\
          cuda:0\")\n                response = model.generate(**inputs, max_new_tokens=64,\
          \ repetition_penalty=1.1)\n                response = tokenizer.decode(response.cpu()[0],\
          \ skip_special_tokens=True)\n                print(\"bot:\", response)\n\
          \                torch.cuda.empty_cache()\n            except Exception\
          \ as e:\n                print(e)\n                break\n\n\nif __name__\
          \ == '__main__':\n    main()\n\n</code></pre>\n<p>\u627E\u4E86\u4E00\u4E2A\
          \u522B\u4EBA\u5199\u7684\u4EE3\u7801\uFF0C\u6539\u9020 \u4E86\u4E00\u4E0B\
          \uFF0C\u53EF\u4EE5\u8DD1\u4E86\u3002</p>\n"
        raw: "~~~\n\nimport os\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM,\
          \ AutoConfig\nimport torch\n\nPRE_TRAINED_MODEL_PATH = \"../model/\"\n\n\
          \n# \u7A0B\u5E8F\u5165\u53E3\ndef main():\n    os.environ[\"CUDA_VISIBLE_DEVICES\"\
          ] = \"2\"\n    tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_PATH,\
          \ trust_remote_code=True)\n    tokenizer.pad_token_id = 0 if tokenizer.pad_token_id\
          \ is None else tokenizer.pad_token_id  # set as the <unk> token\n    if\
          \ tokenizer.pad_token_id == 64000:\n        tokenizer.pad_token_id = 0 \
          \ # for baichuan model (need fix)\n\n    config = AutoConfig.from_pretrained(PRE_TRAINED_MODEL_PATH,\
          \ trust_remote_code=True)\n    model = AutoModelForCausalLM.from_pretrained(PRE_TRAINED_MODEL_PATH,\
          \ config=config, torch_dtype=torch.float16,\n                          \
          \                       trust_remote_code=True, device_map=\"auto\", low_cpu_mem_usage=True)\n\
          \    with torch.autocast(\"cuda\"):\n        while True:\n            try:\n\
          \                input_txt = input(\"user:\")\n                inputs =\
          \ tokenizer(input_txt, return_tensors='pt')\n                inputs = inputs.to(\"\
          cuda:0\")\n                response = model.generate(**inputs, max_new_tokens=64,\
          \ repetition_penalty=1.1)\n                response = tokenizer.decode(response.cpu()[0],\
          \ skip_special_tokens=True)\n                print(\"bot:\", response)\n\
          \                torch.cuda.empty_cache()\n            except Exception\
          \ as e:\n                print(e)\n                break\n\n\nif __name__\
          \ == '__main__':\n    main()\n\n\n~~~\n\n\u627E\u4E86\u4E00\u4E2A\u522B\u4EBA\
          \u5199\u7684\u4EE3\u7801\uFF0C\u6539\u9020 \u4E86\u4E00\u4E0B\uFF0C\u53EF\
          \u4EE5\u8DD1\u4E86\u3002"
        updatedAt: '2023-06-16T07:55:47.556Z'
      numEdits: 0
      reactions: []
    id: 648c15830e9d83dadf75c225
    type: comment
  author: yiwan
  content: "~~~\n\nimport os\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM,\
    \ AutoConfig\nimport torch\n\nPRE_TRAINED_MODEL_PATH = \"../model/\"\n\n\n# \u7A0B\
    \u5E8F\u5165\u53E3\ndef main():\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\
    2\"\n    tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_PATH, trust_remote_code=True)\n\
    \    tokenizer.pad_token_id = 0 if tokenizer.pad_token_id is None else tokenizer.pad_token_id\
    \  # set as the <unk> token\n    if tokenizer.pad_token_id == 64000:\n       \
    \ tokenizer.pad_token_id = 0  # for baichuan model (need fix)\n\n    config =\
    \ AutoConfig.from_pretrained(PRE_TRAINED_MODEL_PATH, trust_remote_code=True)\n\
    \    model = AutoModelForCausalLM.from_pretrained(PRE_TRAINED_MODEL_PATH, config=config,\
    \ torch_dtype=torch.float16,\n                                               \
    \  trust_remote_code=True, device_map=\"auto\", low_cpu_mem_usage=True)\n    with\
    \ torch.autocast(\"cuda\"):\n        while True:\n            try:\n         \
    \       input_txt = input(\"user:\")\n                inputs = tokenizer(input_txt,\
    \ return_tensors='pt')\n                inputs = inputs.to(\"cuda:0\")\n     \
    \           response = model.generate(**inputs, max_new_tokens=64, repetition_penalty=1.1)\n\
    \                response = tokenizer.decode(response.cpu()[0], skip_special_tokens=True)\n\
    \                print(\"bot:\", response)\n                torch.cuda.empty_cache()\n\
    \            except Exception as e:\n                print(e)\n              \
    \  break\n\n\nif __name__ == '__main__':\n    main()\n\n\n~~~\n\n\u627E\u4E86\u4E00\
    \u4E2A\u522B\u4EBA\u5199\u7684\u4EE3\u7801\uFF0C\u6539\u9020 \u4E86\u4E00\u4E0B\
    \uFF0C\u53EF\u4EE5\u8DD1\u4E86\u3002"
  created_at: 2023-06-16 06:55:47+00:00
  edited: false
  hidden: false
  id: 648c15830e9d83dadf75c225
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642ec929894e7cbd2d2a1699/1Fr-2NSD4tNxnok5EMrBS.png?w=200&h=200&f=face
      fullname: gaofei
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: feifeiyechuan
      type: user
    createdAt: '2023-06-16T10:34:00.000Z'
    data:
      edited: false
      editors:
      - feifeiyechuan
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.704425036907196
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642ec929894e7cbd2d2a1699/1Fr-2NSD4tNxnok5EMrBS.png?w=200&h=200&f=face
          fullname: gaofei
          isHf: false
          isPro: false
          name: feifeiyechuan
          type: user
        html: "<p>\u5219\u4F1A\u662F\u4E0D\u662F\u628Amax_new_tokens\u6539\u5C0F\u4E86\
          </p>\n"
        raw: "\u5219\u4F1A\u662F\u4E0D\u662F\u628Amax_new_tokens\u6539\u5C0F\u4E86"
        updatedAt: '2023-06-16T10:34:00.096Z'
      numEdits: 0
      reactions: []
    id: 648c3a9834fcdad8723080c9
    type: comment
  author: feifeiyechuan
  content: "\u5219\u4F1A\u662F\u4E0D\u662F\u628Amax_new_tokens\u6539\u5C0F\u4E86"
  created_at: 2023-06-16 09:34:00+00:00
  edited: false
  hidden: false
  id: 648c3a9834fcdad8723080c9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: baichuan-inc/Baichuan-7B
repo_type: model
status: open
target_branch: null
title: "24G\u7684\u663E\u5361\u8DD1\u4E24\u4E0B\u5C31\u6B47\u83DC\u4E86"
