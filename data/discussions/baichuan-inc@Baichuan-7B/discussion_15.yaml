!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ma227
conflicting_files: null
created_at: 2023-06-21 00:41:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8f1a4540048a0002421e5915511cf37e.svg
      fullname: XiaoShou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ma227
      type: user
    createdAt: '2023-06-21T01:41:03.000Z'
    data:
      edited: true
      editors:
      - Ma227
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.38869142532348633
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8f1a4540048a0002421e5915511cf37e.svg
          fullname: XiaoShou
          isHf: false
          isPro: false
          name: Ma227
          type: user
        html: "<p>from transformers import AutoTokenizer<br>model_path = \"./modesl/baichuan-7B'<br>tokenizer\
          \ = AutoTokenizer .from_pretrained(model_path, trust_remote_code=True)<br>\u63D0\
          \u793A\u7C7B\u578B\u9519\u8BEF not a string<br>Traceback (most recent call\
          \ last):<br>  File \"/AI/models/baichuan-7B/test.py\", line 7, in <br> \
          \   tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True\
          \ , local_files_only=True )<br>  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 678, in from_pretrained<br>    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)<br>  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1825, in from_pretrained<br>    return cls._from_pretrained(<br>\
          \  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1988, in _from_pretrained<br>    tokenizer = cls(*init_inputs, **init_kwargs)<br>\
          \  File \"/home/appuser/.cache/huggingface/modules/transformers_modules/baichuan-7B/tokenization_baichuan.py\"\
          , line 89, in <strong>init</strong><br>    self.sp_model.Load(vocab_file)<br>\
          \  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/sentencepiece/<strong>init</strong>.py\"\
          , line 905, in Load<br>    return self.LoadFromFile(model_file)<br>  File\
          \ \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/sentencepiece/<strong>init</strong>.py\"\
          , line 310, in LoadFromFile<br>    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
          \ arg)<br>TypeError: not a string</p>\n<p>\u5B8C\u6574\u6D4B\u8BD5\u4EE3\
          \u7801<br>from transformers import AutoModelForCausalLM, AutoTokenizer,\
          \ AutoConfig<br>import torch</p>\n<p>#model_path = './models/baichuan-7B'<br>model_path\
          \ = \"/AI/models/baichuan-7B/models/baichuan-7B\"<br>print(type(model_path))<br>tokenizer\
          \ = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True , local_files_only=True\
          \ )<br>tokenizer.pad_token_id = 0 if tokenizer.pad_token_id is None else\
          \ tokenizer.pad_token_id # set as the  token<br>if tokenizer.pad_token_id\
          \ == 64000:<br>    tokenizer.pad_token_id = 0 # for baichuan model (need\
          \ fix)</p>\n<p>config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)<br>print(\"\
          &gt;&gt;&gt; load model...\")</p>\n<p>model = AutoModelForCausalLM.from_pretrained(model_path,\
          \ config=config, torch_dtype=torch.float16, trust_remote_code=True, device_map=\"\
          auto\", low_cpu_mem_usage=True)</p>\n<p>print(\"&gt;&gt;&gt; start pred...\"\
          )</p>\n<p>for i in [\"\u5199\u4E00\u9996\u6625\u5929\u7684\u8BD7\u6B4C\uFF1A\
          \", '\u767B\u9E73\u96C0\u697C-&gt;\u738B\u4E4B\u6DA3\\n\u591C\u96E8\u5BC4\
          \u5317-&gt;']:<br>    inputs = tokenizer(i, return_tensors='pt')<br>   \
          \ inputs = inputs.to('cuda:0')<br>    print(f\"start to pred: {i}\")<br>\
          \    pred = model.generate(**inputs, max_new_tokens=64)<br>    print(tokenizer.decode(pred.cpu()[0],\
          \ skip_special_tokens=True))</p>\n"
        raw: "from transformers import AutoTokenizer \nmodel_path = \"./modesl/baichuan-7B'\
          \ \ntokenizer = AutoTokenizer .from_pretrained(model_path, trust_remote_code=True)\n\
          \u63D0\u793A\u7C7B\u578B\u9519\u8BEF not a string \nTraceback (most recent\
          \ call last):\n  File \"/AI/models/baichuan-7B/test.py\", line 7, in <module>\n\
          \    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True\
          \ , local_files_only=True )\n  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 678, in from_pretrained\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\n  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1825, in from_pretrained\n    return cls._from_pretrained(\n  File\
          \ \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1988, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \  File \"/home/appuser/.cache/huggingface/modules/transformers_modules/baichuan-7B/tokenization_baichuan.py\"\
          , line 89, in __init__\n    self.sp_model.Load(vocab_file)\n  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/sentencepiece/__init__.py\"\
          , line 905, in Load\n    return self.LoadFromFile(model_file)\n  File \"\
          /AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/sentencepiece/__init__.py\"\
          , line 310, in LoadFromFile\n    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
          \ arg)\nTypeError: not a string\n\n\n\u5B8C\u6574\u6D4B\u8BD5\u4EE3\u7801\
          \nfrom transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n\
          import torch\n\n#model_path = './models/baichuan-7B'\nmodel_path = \"/AI/models/baichuan-7B/models/baichuan-7B\"\
          \nprint(type(model_path))\ntokenizer = AutoTokenizer.from_pretrained(model_path,\
          \ trust_remote_code=True , local_files_only=True )\ntokenizer.pad_token_id\
          \ = 0 if tokenizer.pad_token_id is None else tokenizer.pad_token_id # set\
          \ as the <unk> token\nif tokenizer.pad_token_id == 64000:\n    tokenizer.pad_token_id\
          \ = 0 # for baichuan model (need fix)\n\nconfig = AutoConfig.from_pretrained(model_path,\
          \ trust_remote_code=True)\nprint(\">>> load model...\")\n\nmodel = AutoModelForCausalLM.from_pretrained(model_path,\
          \ config=config, torch_dtype=torch.float16, trust_remote_code=True, device_map=\"\
          auto\", low_cpu_mem_usage=True)\n\nprint(\">>> start pred...\")\n\nfor i\
          \ in [\"\u5199\u4E00\u9996\u6625\u5929\u7684\u8BD7\u6B4C\uFF1A\", '\u767B\
          \u9E73\u96C0\u697C->\u738B\u4E4B\u6DA3\\n\u591C\u96E8\u5BC4\u5317->']:\n\
          \    inputs = tokenizer(i, return_tensors='pt')\n    inputs = inputs.to('cuda:0')\n\
          \    print(f\"start to pred: {i}\")\n    pred = model.generate(**inputs,\
          \ max_new_tokens=64)\n    print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))"
        updatedAt: '2023-06-21T01:41:26.861Z'
      numEdits: 1
      reactions: []
    id: 6492552f48acce7afaff9f0d
    type: comment
  author: Ma227
  content: "from transformers import AutoTokenizer \nmodel_path = \"./modesl/baichuan-7B'\
    \ \ntokenizer = AutoTokenizer .from_pretrained(model_path, trust_remote_code=True)\n\
    \u63D0\u793A\u7C7B\u578B\u9519\u8BEF not a string \nTraceback (most recent call\
    \ last):\n  File \"/AI/models/baichuan-7B/test.py\", line 7, in <module>\n   \
    \ tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True\
    \ , local_files_only=True )\n  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
    , line 678, in from_pretrained\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\n  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1825, in from_pretrained\n    return cls._from_pretrained(\n  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1988, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
    \  File \"/home/appuser/.cache/huggingface/modules/transformers_modules/baichuan-7B/tokenization_baichuan.py\"\
    , line 89, in __init__\n    self.sp_model.Load(vocab_file)\n  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/sentencepiece/__init__.py\"\
    , line 905, in Load\n    return self.LoadFromFile(model_file)\n  File \"/AI/anaconda3/envs/baichuan/lib/python3.10/site-packages/sentencepiece/__init__.py\"\
    , line 310, in LoadFromFile\n    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
    \ arg)\nTypeError: not a string\n\n\n\u5B8C\u6574\u6D4B\u8BD5\u4EE3\u7801\nfrom\
    \ transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\nimport\
    \ torch\n\n#model_path = './models/baichuan-7B'\nmodel_path = \"/AI/models/baichuan-7B/models/baichuan-7B\"\
    \nprint(type(model_path))\ntokenizer = AutoTokenizer.from_pretrained(model_path,\
    \ trust_remote_code=True , local_files_only=True )\ntokenizer.pad_token_id = 0\
    \ if tokenizer.pad_token_id is None else tokenizer.pad_token_id # set as the <unk>\
    \ token\nif tokenizer.pad_token_id == 64000:\n    tokenizer.pad_token_id = 0 #\
    \ for baichuan model (need fix)\n\nconfig = AutoConfig.from_pretrained(model_path,\
    \ trust_remote_code=True)\nprint(\">>> load model...\")\n\nmodel = AutoModelForCausalLM.from_pretrained(model_path,\
    \ config=config, torch_dtype=torch.float16, trust_remote_code=True, device_map=\"\
    auto\", low_cpu_mem_usage=True)\n\nprint(\">>> start pred...\")\n\nfor i in [\"\
    \u5199\u4E00\u9996\u6625\u5929\u7684\u8BD7\u6B4C\uFF1A\", '\u767B\u9E73\u96C0\u697C\
    ->\u738B\u4E4B\u6DA3\\n\u591C\u96E8\u5BC4\u5317->']:\n    inputs = tokenizer(i,\
    \ return_tensors='pt')\n    inputs = inputs.to('cuda:0')\n    print(f\"start to\
    \ pred: {i}\")\n    pred = model.generate(**inputs, max_new_tokens=64)\n    print(tokenizer.decode(pred.cpu()[0],\
    \ skip_special_tokens=True))"
  created_at: 2023-06-21 00:41:03+00:00
  edited: true
  hidden: false
  id: 6492552f48acce7afaff9f0d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4c8499aeef3f8b040cac643263aa7e7b.svg
      fullname: AoiEugeo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AoiEugeo
      type: user
    createdAt: '2023-06-21T10:43:05.000Z'
    data:
      edited: false
      editors:
      - AoiEugeo
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9854257702827454
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4c8499aeef3f8b040cac643263aa7e7b.svg
          fullname: AoiEugeo
          isHf: false
          isPro: false
          name: AoiEugeo
          type: user
        html: "<p>\u6211\u4E5F\u662F\uFF0C\u4F60\u73B0\u5728\u89E3\u51B3\u4E86\u5417\
          \uFF0C\u6211\u662F\u7528\u7684\u662Fwindows10\u73AF\u5883\uFF0C\u662Fwin\u7684\
          \u95EE\u9898\u5417</p>\n"
        raw: "\u6211\u4E5F\u662F\uFF0C\u4F60\u73B0\u5728\u89E3\u51B3\u4E86\u5417\uFF0C\
          \u6211\u662F\u7528\u7684\u662Fwindows10\u73AF\u5883\uFF0C\u662Fwin\u7684\
          \u95EE\u9898\u5417"
        updatedAt: '2023-06-21T10:43:05.070Z'
      numEdits: 0
      reactions: []
    id: 6492d4395e049caee68b0166
    type: comment
  author: AoiEugeo
  content: "\u6211\u4E5F\u662F\uFF0C\u4F60\u73B0\u5728\u89E3\u51B3\u4E86\u5417\uFF0C\
    \u6211\u662F\u7528\u7684\u662Fwindows10\u73AF\u5883\uFF0C\u662Fwin\u7684\u95EE\
    \u9898\u5417"
  created_at: 2023-06-21 09:43:05+00:00
  edited: false
  hidden: false
  id: 6492d4395e049caee68b0166
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8f1a4540048a0002421e5915511cf37e.svg
      fullname: XiaoShou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ma227
      type: user
    createdAt: '2023-06-25T00:48:11.000Z'
    data:
      edited: false
      editors:
      - Ma227
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9875457286834717
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8f1a4540048a0002421e5915511cf37e.svg
          fullname: XiaoShou
          isHf: false
          isPro: false
          name: Ma227
          type: user
        html: "<p>\u6211\u7528\u7684Linux\u73AF\u5883 CentOS7.4 \u6CA1\u6709\u89E3\
          \u51B3</p>\n"
        raw: "\u6211\u7528\u7684Linux\u73AF\u5883 CentOS7.4 \u6CA1\u6709\u89E3\u51B3"
        updatedAt: '2023-06-25T00:48:11.464Z'
      numEdits: 0
      reactions: []
    id: 64978ecb483e1df593364474
    type: comment
  author: Ma227
  content: "\u6211\u7528\u7684Linux\u73AF\u5883 CentOS7.4 \u6CA1\u6709\u89E3\u51B3"
  created_at: 2023-06-24 23:48:11+00:00
  edited: false
  hidden: false
  id: 64978ecb483e1df593364474
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: baichuan-inc/Baichuan-7B
repo_type: model
status: open
target_branch: null
title: "\u4F7F\u7528transformers\u5E93\u52A0\u8F7D\u6A21\u578B\u65F6\uFF0C\u63D0\u793A\
  \u7C7B\u578B\u9519\u8BEF not a string"
