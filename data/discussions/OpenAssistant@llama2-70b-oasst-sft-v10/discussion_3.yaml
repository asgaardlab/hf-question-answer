!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mgunther
conflicting_files: null
created_at: 2023-08-28 13:17:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7cdf54133cb701a256dc93cef3fe6340.svg
      fullname: Mathew Gunther
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mgunther
      type: user
    createdAt: '2023-08-28T14:17:16.000Z'
    data:
      edited: false
      editors:
      - mgunther
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7810220122337341
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7cdf54133cb701a256dc93cef3fe6340.svg
          fullname: Mathew Gunther
          isHf: false
          isPro: false
          name: mgunther
          type: user
        html: '<p>Is there an open issue on <a rel="nofollow" href="https://github.com/huggingface/text-generation-inference">https://github.com/huggingface/text-generation-inference</a>
          tracking the sharded 16 bit floating point problem?</p>

          '
        raw: "Is there an open issue on https://github.com/huggingface/text-generation-inference\
          \ tracking the sharded 16 bit floating point problem?\r\n\r\n"
        updatedAt: '2023-08-28T14:17:16.382Z'
      numEdits: 0
      reactions: []
    id: 64ecac6c4aa51daa2ef658f6
    type: comment
  author: mgunther
  content: "Is there an open issue on https://github.com/huggingface/text-generation-inference\
    \ tracking the sharded 16 bit floating point problem?\r\n\r\n"
  created_at: 2023-08-28 13:17:16+00:00
  edited: false
  hidden: false
  id: 64ecac6c4aa51daa2ef658f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b888106cf60e8c3d00dc86/lNCiIc424q60PC2D33vxN.jpeg?w=200&h=200&f=face
      fullname: "Andreas K\xF6pf"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: andreaskoepf
      type: user
    createdAt: '2023-08-28T15:30:50.000Z'
    data:
      edited: false
      editors:
      - andreaskoepf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9419352412223816
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b888106cf60e8c3d00dc86/lNCiIc424q60PC2D33vxN.jpeg?w=200&h=200&f=face
          fullname: "Andreas K\xF6pf"
          isHf: false
          isPro: false
          name: andreaskoepf
          type: user
        html: '<p>No, not yet. Most likely it is related to the vocabulary size of
          <code>32007</code> .. unfortunately I noticed it too late, it should at
          least have been rounded number divisible by 16.<br>I heard from others that
          TGI didn''t start and gave them the error "The choosen size 32007 is not
          compatible with sharding on 4 shards". caused by an <code>assert</code>
          added by this commit: <a rel="nofollow" href="https://github.com/huggingface/text-generation-inference/commit/67347950b7518efeb64c7f99ee360af685b53934">https://github.com/huggingface/text-generation-inference/commit/67347950b7518efeb64c7f99ee360af685b53934</a></p>

          '
        raw: 'No, not yet. Most likely it is related to the vocabulary size of `32007`
          .. unfortunately I noticed it too late, it should at least have been rounded
          number divisible by 16.

          I heard from others that TGI didn''t start and gave them the error "The
          choosen size 32007 is not compatible with sharding on 4 shards". caused
          by an `assert` added by this commit: https://github.com/huggingface/text-generation-inference/commit/67347950b7518efeb64c7f99ee360af685b53934'
        updatedAt: '2023-08-28T15:30:50.765Z'
      numEdits: 0
      reactions: []
    id: 64ecbdaa76a07046863d0e03
    type: comment
  author: andreaskoepf
  content: 'No, not yet. Most likely it is related to the vocabulary size of `32007`
    .. unfortunately I noticed it too late, it should at least have been rounded number
    divisible by 16.

    I heard from others that TGI didn''t start and gave them the error "The choosen
    size 32007 is not compatible with sharding on 4 shards". caused by an `assert`
    added by this commit: https://github.com/huggingface/text-generation-inference/commit/67347950b7518efeb64c7f99ee360af685b53934'
  created_at: 2023-08-28 14:30:50+00:00
  edited: false
  hidden: false
  id: 64ecbdaa76a07046863d0e03
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7cdf54133cb701a256dc93cef3fe6340.svg
      fullname: Mathew Gunther
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mgunther
      type: user
    createdAt: '2023-08-28T15:57:46.000Z'
    data:
      edited: false
      editors:
      - mgunther
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8918306231498718
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7cdf54133cb701a256dc93cef3fe6340.svg
          fullname: Mathew Gunther
          isHf: false
          isPro: false
          name: mgunther
          type: user
        html: '<p>Ah.  Thanks for the update.  I didn''t get the assertion error you
          mentioned. That is, the model ran for me on when using the docker iamge
          ghcr.io/huggingface/text-generation-inference:1.0.1.  But the responses
          to questions like "Can you write a python script to calculate Fibonacci
          sequence?" were only correct in python syntax and english grammar, but not
          in code algorithm or conversation flow. (E.g. it would answer its own questions)
          . (For reference, the pythia 12b oasst model gets the python fibonacci sequence
          correct. )</p>

          '
        raw: Ah.  Thanks for the update.  I didn't get the assertion error you mentioned.
          That is, the model ran for me on when using the docker iamge ghcr.io/huggingface/text-generation-inference:1.0.1.  But
          the responses to questions like "Can you write a python script to calculate
          Fibonacci sequence?" were only correct in python syntax and english grammar,
          but not in code algorithm or conversation flow. (E.g. it would answer its
          own questions) . (For reference, the pythia 12b oasst model gets the python
          fibonacci sequence correct. )
        updatedAt: '2023-08-28T15:57:46.175Z'
      numEdits: 0
      reactions: []
    id: 64ecc3fa4e57da8993716dcb
    type: comment
  author: mgunther
  content: Ah.  Thanks for the update.  I didn't get the assertion error you mentioned.
    That is, the model ran for me on when using the docker iamge ghcr.io/huggingface/text-generation-inference:1.0.1.  But
    the responses to questions like "Can you write a python script to calculate Fibonacci
    sequence?" were only correct in python syntax and english grammar, but not in
    code algorithm or conversation flow. (E.g. it would answer its own questions)
    . (For reference, the pythia 12b oasst model gets the python fibonacci sequence
    correct. )
  created_at: 2023-08-28 14:57:46+00:00
  edited: false
  hidden: false
  id: 64ecc3fa4e57da8993716dcb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b888106cf60e8c3d00dc86/lNCiIc424q60PC2D33vxN.jpeg?w=200&h=200&f=face
      fullname: "Andreas K\xF6pf"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: andreaskoepf
      type: user
    createdAt: '2023-08-28T18:22:58.000Z'
    data:
      edited: false
      editors:
      - andreaskoepf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.932925283908844
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b888106cf60e8c3d00dc86/lNCiIc424q60PC2D33vxN.jpeg?w=200&h=200&f=face
          fullname: "Andreas K\xF6pf"
          isHf: false
          isPro: false
          name: andreaskoepf
          type: user
        html: '<p>You could try with <code>nf4</code> quantization and  <code>--sharded
          false</code> ...</p>

          '
        raw: You could try with `nf4` quantization and  `--sharded false` ...
        updatedAt: '2023-08-28T18:22:58.843Z'
      numEdits: 0
      reactions: []
    id: 64ece602266afc1d935e83ca
    type: comment
  author: andreaskoepf
  content: You could try with `nf4` quantization and  `--sharded false` ...
  created_at: 2023-08-28 17:22:58+00:00
  edited: false
  hidden: false
  id: 64ece602266afc1d935e83ca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b888106cf60e8c3d00dc86/lNCiIc424q60PC2D33vxN.jpeg?w=200&h=200&f=face
      fullname: "Andreas K\xF6pf"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: andreaskoepf
      type: user
    createdAt: '2023-08-29T14:11:25.000Z'
    data:
      edited: false
      editors:
      - andreaskoepf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9647002816200256
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b888106cf60e8c3d00dc86/lNCiIc424q60PC2D33vxN.jpeg?w=200&h=200&f=face
          fullname: "Andreas K\xF6pf"
          isHf: false
          isPro: false
          name: andreaskoepf
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mgunther&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mgunther\">@<span class=\"\
          underline\">mgunther</span></a></span>\n\n\t</span></span> I uploaded a\
          \ new version with resized embedding &amp; lm_head layers which now have\
          \ a size divisible by 128. Could you please try again if it now works for\
          \ you?</p>\n"
        raw: '@mgunther I uploaded a new version with resized embedding & lm_head
          layers which now have a size divisible by 128. Could you please try again
          if it now works for you?'
        updatedAt: '2023-08-29T14:11:25.523Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mgunther
    id: 64edfc8d031dfa2b8bf5ed25
    type: comment
  author: andreaskoepf
  content: '@mgunther I uploaded a new version with resized embedding & lm_head layers
    which now have a size divisible by 128. Could you please try again if it now works
    for you?'
  created_at: 2023-08-29 13:11:25+00:00
  edited: false
  hidden: false
  id: 64edfc8d031dfa2b8bf5ed25
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7cdf54133cb701a256dc93cef3fe6340.svg
      fullname: Mathew Gunther
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mgunther
      type: user
    createdAt: '2023-08-29T14:37:14.000Z'
    data:
      edited: false
      editors:
      - mgunther
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8698766231536865
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7cdf54133cb701a256dc93cef3fe6340.svg
          fullname: Mathew Gunther
          isHf: false
          isPro: false
          name: mgunther
          type: user
        html: '<p>Yes, the nf4 quantization with no sharding works better, but haven''t
          extensively tested.  Currently downloading the new model. Will follow up
          once tested.</p>

          <p>The vllm inference server  mentioned in the model card ( <a rel="nofollow"
          href="https://github.com/vllm-project/vllm">https://github.com/vllm-project/vllm</a>
          )  gets python fibonacci sequence code correct. </p>

          '
        raw: 'Yes, the nf4 quantization with no sharding works better, but haven''t
          extensively tested.  Currently downloading the new model. Will follow up
          once tested.


          The vllm inference server  mentioned in the model card ( https://github.com/vllm-project/vllm
          )  gets python fibonacci sequence code correct. '
        updatedAt: '2023-08-29T14:37:14.244Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - andreaskoepf
    id: 64ee029ab1c173df74e444b5
    type: comment
  author: mgunther
  content: 'Yes, the nf4 quantization with no sharding works better, but haven''t
    extensively tested.  Currently downloading the new model. Will follow up once
    tested.


    The vllm inference server  mentioned in the model card ( https://github.com/vllm-project/vllm
    )  gets python fibonacci sequence code correct. '
  created_at: 2023-08-29 13:37:14+00:00
  edited: false
  hidden: false
  id: 64ee029ab1c173df74e444b5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7cdf54133cb701a256dc93cef3fe6340.svg
      fullname: Mathew Gunther
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mgunther
      type: user
    createdAt: '2023-08-29T15:51:22.000Z'
    data:
      edited: false
      editors:
      - mgunther
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9253243803977966
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7cdf54133cb701a256dc93cef3fe6340.svg
          fullname: Mathew Gunther
          isHf: false
          isPro: false
          name: mgunther
          type: user
        html: '<p>It looks like the new oasst lamma 2 model is working well with the
          tgi docker image 1.0.2 and sharding. ( gets py fib script correct).</p>

          <p>Thanks Andreas!</p>

          '
        raw: 'It looks like the new oasst lamma 2 model is working well with the tgi
          docker image 1.0.2 and sharding. ( gets py fib script correct).


          Thanks Andreas!'
        updatedAt: '2023-08-29T15:51:22.878Z'
      numEdits: 0
      reactions: []
    id: 64ee13fa1bd9f65ad4587000
    type: comment
  author: mgunther
  content: 'It looks like the new oasst lamma 2 model is working well with the tgi
    docker image 1.0.2 and sharding. ( gets py fib script correct).


    Thanks Andreas!'
  created_at: 2023-08-29 14:51:22+00:00
  edited: false
  hidden: false
  id: 64ee13fa1bd9f65ad4587000
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b888106cf60e8c3d00dc86/lNCiIc424q60PC2D33vxN.jpeg?w=200&h=200&f=face
      fullname: "Andreas K\xF6pf"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: andreaskoepf
      type: user
    createdAt: '2023-08-29T16:42:11.000Z'
    data:
      edited: false
      editors:
      - andreaskoepf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8381322026252747
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b888106cf60e8c3d00dc86/lNCiIc424q60PC2D33vxN.jpeg?w=200&h=200&f=face
          fullname: "Andreas K\xF6pf"
          isHf: false
          isPro: false
          name: andreaskoepf
          type: user
        html: '<p>Great, thanks for testing! I will update the readme.</p>

          '
        raw: Great, thanks for testing! I will update the readme.
        updatedAt: '2023-08-29T16:42:11.051Z'
      numEdits: 0
      reactions: []
    id: 64ee1fe38f8f8ac22cc39876
    type: comment
  author: andreaskoepf
  content: Great, thanks for testing! I will update the readme.
  created_at: 2023-08-29 15:42:11+00:00
  edited: false
  hidden: false
  id: 64ee1fe38f8f8ac22cc39876
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: OpenAssistant/llama2-70b-oasst-sft-v10
repo_type: model
status: open
target_branch: null
title: text generation inference github issue?
