!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mbrunecky
conflicting_files: null
created_at: 2022-09-30 21:26:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/48a398e540b3d602a2bdec4bd2a0f6bc.svg
      fullname: Martin Brunecky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mbrunecky
      type: user
    createdAt: '2022-09-30T22:26:46.000Z'
    data:
      edited: false
      editors:
      - mbrunecky
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/48a398e540b3d602a2bdec4bd2a0f6bc.svg
          fullname: Martin Brunecky
          isHf: false
          isPro: false
          name: mbrunecky
          type: user
        html: '<p>I an using Spacy (3.4) for my NER projects, either the the NER,
          SpanCategorizer or Transformer. Intrigued by the ConvBERT description, I
          am trying to evaluate using conv-bert-base instead of (Spacy default) roberta.</p>

          <p>It all seems to be working, but on each model save (checkpoint), I am
          getting about thousand warnings:</p>

          <p><em>The OrderedVocab you are attempting to save contains a hole for index
          1311, your vocabulary could be corrupted !<br> .. thru ..<br>The OrderedVocab
          you are attempting to save contains a hole for index 30519, your vocabulary
          could be corrupted !</em></p>

          <p>Following that, the training appears to proceed normally. But while training
          log reports ''reasonable'' p/r/f scores (~97%) , when I try to evaluate
          the <em>saved</em> model the scores go to near zero. Apparently, while training,
          the evaluation uses an existing in-memory model. But the checkpoint-saved
          model is corrupt.</p>

          <p>Anybody can give me some hint as to where to look for ''OrderedVocab''
          and how to fix / workaround this?</p>

          <p>My data comes from OCR, hence it contains a lot of OOV ''words'' (various
          garbage), so I am not surprised by an excessive vocabulary. But failure
          to save the model (vocab) is a show stopper.</p>

          '
        raw: "I an using Spacy (3.4) for my NER projects, either the the NER, SpanCategorizer\
          \ or Transformer. Intrigued by the ConvBERT description, I am trying to\
          \ evaluate using conv-bert-base instead of (Spacy default) roberta.\r\n\r\
          \nIt all seems to be working, but on each model save (checkpoint), I am\
          \ getting about thousand warnings:\r\n\r\n_The OrderedVocab you are attempting\
          \ to save contains a hole for index 1311, your vocabulary could be corrupted\
          \ !\r\n .. thru ..\r\nThe OrderedVocab you are attempting to save contains\
          \ a hole for index 30519, your vocabulary could be corrupted !_\r\n\r\n\
          Following that, the training appears to proceed normally. But while training\
          \ log reports 'reasonable' p/r/f scores (~97%) , when I try to evaluate\
          \ the _saved_ model the scores go to near zero. Apparently, while training,\
          \ the evaluation uses an existing in-memory model. But the checkpoint-saved\
          \ model is corrupt.\r\n\r\nAnybody can give me some hint as to where to\
          \ look for 'OrderedVocab' and how to fix / workaround this?\r\n\r\nMy data\
          \ comes from OCR, hence it contains a lot of OOV 'words' (various garbage),\
          \ so I am not surprised by an excessive vocabulary. But failure to save\
          \ the model (vocab) is a show stopper.\r\n\r\n"
        updatedAt: '2022-09-30T22:26:46.309Z'
      numEdits: 0
      reactions: []
    id: 63376d265f0025d728baf1f9
    type: comment
  author: mbrunecky
  content: "I an using Spacy (3.4) for my NER projects, either the the NER, SpanCategorizer\
    \ or Transformer. Intrigued by the ConvBERT description, I am trying to evaluate\
    \ using conv-bert-base instead of (Spacy default) roberta.\r\n\r\nIt all seems\
    \ to be working, but on each model save (checkpoint), I am getting about thousand\
    \ warnings:\r\n\r\n_The OrderedVocab you are attempting to save contains a hole\
    \ for index 1311, your vocabulary could be corrupted !\r\n .. thru ..\r\nThe OrderedVocab\
    \ you are attempting to save contains a hole for index 30519, your vocabulary\
    \ could be corrupted !_\r\n\r\nFollowing that, the training appears to proceed\
    \ normally. But while training log reports 'reasonable' p/r/f scores (~97%) ,\
    \ when I try to evaluate the _saved_ model the scores go to near zero. Apparently,\
    \ while training, the evaluation uses an existing in-memory model. But the checkpoint-saved\
    \ model is corrupt.\r\n\r\nAnybody can give me some hint as to where to look for\
    \ 'OrderedVocab' and how to fix / workaround this?\r\n\r\nMy data comes from OCR,\
    \ hence it contains a lot of OOV 'words' (various garbage), so I am not surprised\
    \ by an excessive vocabulary. But failure to save the model (vocab) is a show\
    \ stopper.\r\n\r\n"
  created_at: 2022-09-30 21:26:46+00:00
  edited: false
  hidden: false
  id: 63376d265f0025d728baf1f9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/48a398e540b3d602a2bdec4bd2a0f6bc.svg
      fullname: Martin Brunecky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mbrunecky
      type: user
    createdAt: '2022-10-03T18:14:40.000Z'
    data:
      edited: false
      editors:
      - mbrunecky
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/48a398e540b3d602a2bdec4bd2a0f6bc.svg
          fullname: Martin Brunecky
          isHf: false
          isPro: false
          name: mbrunecky
          type: user
        html: '<p>The problem is in checked-in vocab.txt. It contains many replicated
          tokens. I uploaded my patch and more comments to :<br><a rel="nofollow"
          href="https://github.com/huggingface/tokenizers/pull/954">https://github.com/huggingface/tokenizers/pull/954</a></p>

          '
        raw: 'The problem is in checked-in vocab.txt. It contains many replicated
          tokens. I uploaded my patch and more comments to :

          https://github.com/huggingface/tokenizers/pull/954'
        updatedAt: '2022-10-03T18:14:40.705Z'
      numEdits: 0
      reactions: []
      relatedEventId: 633b26900d68f86e2d957a6c
    id: 633b26900d68f86e2d957a6b
    type: comment
  author: mbrunecky
  content: 'The problem is in checked-in vocab.txt. It contains many replicated tokens.
    I uploaded my patch and more comments to :

    https://github.com/huggingface/tokenizers/pull/954'
  created_at: 2022-10-03 17:14:40+00:00
  edited: false
  hidden: false
  id: 633b26900d68f86e2d957a6b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/48a398e540b3d602a2bdec4bd2a0f6bc.svg
      fullname: Martin Brunecky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mbrunecky
      type: user
    createdAt: '2022-10-03T18:14:40.000Z'
    data:
      status: closed
    id: 633b26900d68f86e2d957a6c
    type: status-change
  author: mbrunecky
  created_at: 2022-10-03 17:14:40+00:00
  id: 633b26900d68f86e2d957a6c
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: YituTech/conv-bert-base
repo_type: model
status: closed
target_branch: null
title: Failing to save OrderedVocab when using conv-bert-base
