!!python/object:huggingface_hub.community.DiscussionWithDetails
author: IUYG
conflicting_files: null
created_at: 2023-12-03 21:46:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e78fc6ce912dce824a2132728028ec43.svg
      fullname: AYFG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: IUYG
      type: user
    createdAt: '2023-12-03T21:46:11.000Z'
    data:
      edited: false
      editors:
      - IUYG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9206697344779968
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e78fc6ce912dce824a2132728028ec43.svg
          fullname: AYFG
          isHf: false
          isPro: false
          name: IUYG
          type: user
        html: "<p>Thanks for the work. Is there an example script provided to reproduce\
          \ the samples you added in HF? I tested the burger example using your script\
          \ from <a rel=\"nofollow\" href=\"https://github.com/qnguyen3/hermes-llava/blob/main/llava/eval/run_llava.py\"\
          >https://github.com/qnguyen3/hermes-llava/blob/main/llava/eval/run_llava.py</a>\
          \ and the output I received was mostly wrong and hallucinating. The output\
          \ is</p>\n<pre><code>{\n  \"food_list\": [\n    \"Double Decker Burger\"\
          ,\n    \"Cheeseburger\",\n    \"Chicken Burger\",\n    \"French Fries\"\
          ,\n    \"Shrimp Fries\",\n    \"French Fries\",\n    \"Shrimp Fries\",\n\
          \    \"Cheeseburger Fries\",\n    \"Chicken Fries\",\n    \"French Fries\"\
          ,\n    \"Shrimp Fries\",\n    \"Cheeseburger Fries\",\n    \"Chicken Fries\"\
          ,\n    \"French Fries\",\n    \"Shrimp Fries\",\n</code></pre>\n<p>It seems\
          \ that the model is hallucinating and the output is not JSON formatted correctly.\
          \ I might be using the prompt wrongly as I copied that prompt in HF and\
          \ added it to run_llava.py. Is this the correct way to run it?  and do you\
          \ have any scores compared to Llava 1.5?</p>\n<p>Excited about the work\
          \ and hoping to test this again!</p>\n"
        raw: "Thanks for the work. Is there an example script provided to reproduce\
          \ the samples you added in HF? I tested the burger example using your script\
          \ from https://github.com/qnguyen3/hermes-llava/blob/main/llava/eval/run_llava.py\
          \ and the output I received was mostly wrong and hallucinating. The output\
          \ is\r\n```\r\n{\r\n  \"food_list\": [\r\n    \"Double Decker Burger\",\r\
          \n    \"Cheeseburger\",\r\n    \"Chicken Burger\",\r\n    \"French Fries\"\
          ,\r\n    \"Shrimp Fries\",\r\n    \"French Fries\",\r\n    \"Shrimp Fries\"\
          ,\r\n    \"Cheeseburger Fries\",\r\n    \"Chicken Fries\",\r\n    \"French\
          \ Fries\",\r\n    \"Shrimp Fries\",\r\n    \"Cheeseburger Fries\",\r\n \
          \   \"Chicken Fries\",\r\n    \"French Fries\",\r\n    \"Shrimp Fries\"\
          ,\r\n```\r\nIt seems that the model is hallucinating and the output is not\
          \ JSON formatted correctly. I might be using the prompt wrongly as I copied\
          \ that prompt in HF and added it to run_llava.py. Is this the correct way\
          \ to run it?  and do you have any scores compared to Llava 1.5?\r\n\r\n\
          Excited about the work and hoping to test this again!"
        updatedAt: '2023-12-03T21:46:11.921Z'
      numEdits: 0
      reactions: []
    id: 656cf7231f8d9b618dcd8b88
    type: comment
  author: IUYG
  content: "Thanks for the work. Is there an example script provided to reproduce\
    \ the samples you added in HF? I tested the burger example using your script from\
    \ https://github.com/qnguyen3/hermes-llava/blob/main/llava/eval/run_llava.py and\
    \ the output I received was mostly wrong and hallucinating. The output is\r\n\
    ```\r\n{\r\n  \"food_list\": [\r\n    \"Double Decker Burger\",\r\n    \"Cheeseburger\"\
    ,\r\n    \"Chicken Burger\",\r\n    \"French Fries\",\r\n    \"Shrimp Fries\"\
    ,\r\n    \"French Fries\",\r\n    \"Shrimp Fries\",\r\n    \"Cheeseburger Fries\"\
    ,\r\n    \"Chicken Fries\",\r\n    \"French Fries\",\r\n    \"Shrimp Fries\",\r\
    \n    \"Cheeseburger Fries\",\r\n    \"Chicken Fries\",\r\n    \"French Fries\"\
    ,\r\n    \"Shrimp Fries\",\r\n```\r\nIt seems that the model is hallucinating\
    \ and the output is not JSON formatted correctly. I might be using the prompt\
    \ wrongly as I copied that prompt in HF and added it to run_llava.py. Is this\
    \ the correct way to run it?  and do you have any scores compared to Llava 1.5?\r\
    \n\r\nExcited about the work and hoping to test this again!"
  created_at: 2023-12-03 21:46:11+00:00
  edited: false
  hidden: false
  id: 656cf7231f8d9b618dcd8b88
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64137e2150358a805203cbac/w9RQx8Q07UvgFyIZ3ce_k.jpeg?w=200&h=200&f=face
      fullname: Jade
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: euclaise
      type: user
    createdAt: '2023-12-03T22:27:42.000Z'
    data:
      edited: false
      editors:
      - euclaise
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.45349669456481934
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64137e2150358a805203cbac/w9RQx8Q07UvgFyIZ3ce_k.jpeg?w=200&h=200&f=face
          fullname: Jade
          isHf: false
          isPro: false
          name: euclaise
          type: user
        html: '<p><a rel="nofollow" href="https://twitter.com/Teknium1/status/1731409499595194679">https://twitter.com/Teknium1/status/1731409499595194679</a></p>

          '
        raw: https://twitter.com/Teknium1/status/1731409499595194679
        updatedAt: '2023-12-03T22:27:42.305Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F614"
        users:
        - teknium
      - count: 1
        reaction: "\U0001F44D"
        users:
        - teknium
    id: 656d00deadba74cd5e8124db
    type: comment
  author: euclaise
  content: https://twitter.com/Teknium1/status/1731409499595194679
  created_at: 2023-12-03 22:27:42+00:00
  edited: false
  hidden: false
  id: 656d00deadba74cd5e8124db
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-12-04T04:28:51.000Z'
    data:
      status: closed
    id: 656d5583b9fa60e33d15a275
    type: status-change
  author: teknium
  created_at: 2023-12-04 04:28:51+00:00
  id: 656d5583b9fa60e33d15a275
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: NousResearch/Nous-Hermes-2-Vision-Alpha
repo_type: model
status: closed
target_branch: null
title: Model somehow has bad performance and is not working as shown?
