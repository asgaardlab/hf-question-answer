!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hrituraj
conflicting_files: null
created_at: 2023-09-26 23:30:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bc0600062d921b1cb90e1d16af669211.svg
      fullname: Hrituraj Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hrituraj
      type: user
    createdAt: '2023-09-27T00:30:41.000Z'
    data:
      edited: false
      editors:
      - hrituraj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8615689873695374
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bc0600062d921b1cb90e1d16af669211.svg
          fullname: Hrituraj Singh
          isHf: false
          isPro: false
          name: hrituraj
          type: user
        html: '<p>Thanks for this work guys - I have been trying to download and setup
          this model locally but have not been able to do so.</p>

          <p>Directly using <code>Yukang/Llama-2-70b-chat-longlora-32k-sft</code>
          threw the following error</p>

          <pre><code>OSError: Can''t load tokenizer for ''Yukang/Llama-2-70b-chat-longlora-32k-sft''.
          If you were trying to load it from ''https://huggingface.co/models'', make
          sure you don''t have a local directory with the same name. Otherwise, make
          sure ''Yukang/Llama-2-70b-chat-longlora-32k-sft'' is the correct path to
          a directory containing all relevant files for a LlamaTokenizer tokenizer.

          </code></pre>

          <p>So, I pointed the tokenizer towards <code>Yukang/Llama-13b-chat-longlora-32k-sft</code>
          assuming same tokenizer must have been used. I, then started receiving the
          following error though -</p>

          <pre><code>OSError: Can''t load the model for ''/dataset/pretrained-models/Llama-2-70b-chat-hf''.
          If you were trying to load it from ''https://huggingface.co/models'', make
          sure you don''t have a local directory with the same name. Otherwise, make
          sure ''/dataset/pretrained-models/Llama-2-70b-chat-hf'' is the correct path
          to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt
          or flax_model.msgpack

          </code></pre>

          <p>Coul you please look into it?</p>

          '
        raw: "Thanks for this work guys - I have been trying to download and setup\
          \ this model locally but have not been able to do so.\r\n\r\nDirectly using\
          \ `Yukang/Llama-2-70b-chat-longlora-32k-sft` threw the following error\r\
          \n```\r\nOSError: Can't load tokenizer for 'Yukang/Llama-2-70b-chat-longlora-32k-sft'.\
          \ If you were trying to load it from 'https://huggingface.co/models', make\
          \ sure you don't have a local directory with the same name. Otherwise, make\
          \ sure 'Yukang/Llama-2-70b-chat-longlora-32k-sft' is the correct path to\
          \ a directory containing all relevant files for a LlamaTokenizer tokenizer.\r\
          \n```\r\n\r\nSo, I pointed the tokenizer towards `Yukang/Llama-13b-chat-longlora-32k-sft`\
          \ assuming same tokenizer must have been used. I, then started receiving\
          \ the following error though -\r\n```\r\nOSError: Can't load the model for\
          \ '/dataset/pretrained-models/Llama-2-70b-chat-hf'. If you were trying to\
          \ load it from 'https://huggingface.co/models', make sure you don't have\
          \ a local directory with the same name. Otherwise, make sure '/dataset/pretrained-models/Llama-2-70b-chat-hf'\
          \ is the correct path to a directory containing a file named pytorch_model.bin,\
          \ tf_model.h5, model.ckpt or flax_model.msgpack\r\n```\r\nCoul you please\
          \ look into it?\r\n"
        updatedAt: '2023-09-27T00:30:41.735Z'
      numEdits: 0
      reactions: []
    id: 651377b197fb08378ddf8932
    type: comment
  author: hrituraj
  content: "Thanks for this work guys - I have been trying to download and setup this\
    \ model locally but have not been able to do so.\r\n\r\nDirectly using `Yukang/Llama-2-70b-chat-longlora-32k-sft`\
    \ threw the following error\r\n```\r\nOSError: Can't load tokenizer for 'Yukang/Llama-2-70b-chat-longlora-32k-sft'.\
    \ If you were trying to load it from 'https://huggingface.co/models', make sure\
    \ you don't have a local directory with the same name. Otherwise, make sure 'Yukang/Llama-2-70b-chat-longlora-32k-sft'\
    \ is the correct path to a directory containing all relevant files for a LlamaTokenizer\
    \ tokenizer.\r\n```\r\n\r\nSo, I pointed the tokenizer towards `Yukang/Llama-13b-chat-longlora-32k-sft`\
    \ assuming same tokenizer must have been used. I, then started receiving the following\
    \ error though -\r\n```\r\nOSError: Can't load the model for '/dataset/pretrained-models/Llama-2-70b-chat-hf'.\
    \ If you were trying to load it from 'https://huggingface.co/models', make sure\
    \ you don't have a local directory with the same name. Otherwise, make sure '/dataset/pretrained-models/Llama-2-70b-chat-hf'\
    \ is the correct path to a directory containing a file named pytorch_model.bin,\
    \ tf_model.h5, model.ckpt or flax_model.msgpack\r\n```\r\nCoul you please look\
    \ into it?\r\n"
  created_at: 2023-09-26 23:30:41+00:00
  edited: false
  hidden: false
  id: 651377b197fb08378ddf8932
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653710384819-62919485a29097b211bc7b83.png?w=200&h=200&f=face
      fullname: YukangChen
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Yukang
      type: user
    createdAt: '2023-09-27T00:34:43.000Z'
    data:
      edited: false
      editors:
      - Yukang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8922600746154785
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653710384819-62919485a29097b211bc7b83.png?w=200&h=200&f=face
          fullname: YukangChen
          isHf: false
          isPro: false
          name: Yukang
          type: user
        html: '<p>Hi,</p>

          <p>Because this is a lora weight, you need to merge it into the base model
          first to get the pytorch_model.bin and tokenizer files. Please refer to
          the step in the Github README.<br><a rel="nofollow" href="https://github.com/dvlab-research/LongLoRA#merge-lora-weight">https://github.com/dvlab-research/LongLoRA#merge-lora-weight</a></p>

          <p>Regards,<br>Yukang Chen</p>

          '
        raw: 'Hi,


          Because this is a lora weight, you need to merge it into the base model
          first to get the pytorch_model.bin and tokenizer files. Please refer to
          the step in the Github README.

          https://github.com/dvlab-research/LongLoRA#merge-lora-weight


          Regards,

          Yukang Chen'
        updatedAt: '2023-09-27T00:34:43.900Z'
      numEdits: 0
      reactions: []
    id: 651378a3749380c079b7e53d
    type: comment
  author: Yukang
  content: 'Hi,


    Because this is a lora weight, you need to merge it into the base model first
    to get the pytorch_model.bin and tokenizer files. Please refer to the step in
    the Github README.

    https://github.com/dvlab-research/LongLoRA#merge-lora-weight


    Regards,

    Yukang Chen'
  created_at: 2023-09-26 23:34:43+00:00
  edited: false
  hidden: false
  id: 651378a3749380c079b7e53d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Yukang/Llama-2-70b-chat-longlora-32k-sft
repo_type: model
status: open
target_branch: null
title: I am unable to directly load this model?
