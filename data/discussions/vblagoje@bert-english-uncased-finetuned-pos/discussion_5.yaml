!!python/object:huggingface_hub.community.DiscussionWithDetails
author: maithakh
conflicting_files: null
created_at: 2023-05-06 18:22:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d70d0035852bee82f97ad7cb98dd3847.svg
      fullname: Maitha Khanji
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: maithakh
      type: user
    createdAt: '2023-05-06T19:22:03.000Z'
    data:
      edited: false
      editors:
      - maithakh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d70d0035852bee82f97ad7cb98dd3847.svg
          fullname: Maitha Khanji
          isHf: false
          isPro: false
          name: maithakh
          type: user
        html: '<p>Hello,<br>This is the code i executed. I am wondering why the words
          are broken into non-English tokens ? </p>

          <p>text = "Visible porosity appears moderate, characterized by minor to
          common mouldic, intraparticle and vuggy macropores, along with rare to minor
          grain and matrix-hosted microporosity. The measured value is agreeable with
          the observed volume. However, common cementation has degraded connectivity
          and common cracks and fractures may have affected the measured permeability
          value. Therefore, a poor to possibly moderate reservoir quality is inferred.
          Open cracks and fractures are interpreted to be artefacts from sample preparation."</p>

          <p>model_name = "vblagoje/bert-english-uncased-finetuned-pos"<br>tokenizer
          = AutoTokenizer.from_pretrained(model_name)<br>model = AutoModelForTokenClassification.from_pretrained(model_name)</p>

          <p>pipeline = TokenClassificationPipeline(model=model, tokenizer=tokenizer)<br>outputs
          = pipeline(text)</p>

          <p>for output in outputs:<br>    if output[''entity''] in [''NOUN'',''ADJ'']:<br>        #print(output)<br>        print(output[''word'']
          , "", output[''entity''])</p>

          <p>This is the output I am getting:</p>

          <p>visible  ADJ<br>por  NOUN<br>##osity  NOUN<br>moderate  ADJ<br>minor  ADJ<br>common  ADJ<br>mo  NOUN<br>##uld  NOUN<br>##ic  ADJ<br>intra  ADJ<br>##par  NOUN<br>##tic  NOUN<br>##le  NOUN<br>vu  ADJ<br>##ggy  ADJ<br>macro  NOUN<br>##pore  NOUN<br>##s  NOUN<br>##rar  NOUN<br>##e  ADJ<br>minor  ADJ<br>grain  NOUN<br>matrix  NOUN<br>micro  NOUN<br>##por  NOUN<br>##osity  NOUN<br>value  NOUN<br>agree  ADJ<br>##able  ADJ<br>volume  NOUN<br>common  ADJ<br>cement  NOUN<br>##ation  NOUN<br>connectivity  NOUN<br>common  ADJ<br>cracks  NOUN<br>fractures  NOUN<br>per  NOUN<br>##me  NOUN<br>##ability  NOUN<br>value  NOUN<br>poor  ADJ<br>moderate  ADJ<br>reservoir  NOUN<br>quality  NOUN<br>open  ADJ<br>cracks  NOUN<br>fractures  NOUN<br>artefacts  NOUN<br>sample  NOUN<br>preparation  NOUN<br><a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6454845f36821f6860001a42/ayva-sY5TgFG6cxVUSAl6.png"><img
          alt="issue in tokenization.png" src="https://cdn-uploads.huggingface.co/production/uploads/6454845f36821f6860001a42/ayva-sY5TgFG6cxVUSAl6.png"></a></p>

          <p>Any idea what is the reason and how to solve this issue ? </p>

          '
        raw: "Hello, \r\nThis is the code i executed. I am wondering why the words\
          \ are broken into non-English tokens ? \r\n\r\ntext = \"Visible porosity\
          \ appears moderate, characterized by minor to common mouldic, intraparticle\
          \ and vuggy macropores, along with rare to minor grain and matrix-hosted\
          \ microporosity. The measured value is agreeable with the observed volume.\
          \ However, common cementation has degraded connectivity and common cracks\
          \ and fractures may have affected the measured permeability value. Therefore,\
          \ a poor to possibly moderate reservoir quality is inferred. Open cracks\
          \ and fractures are interpreted to be artefacts from sample preparation.\"\
          \r\n\r\nmodel_name = \"vblagoje/bert-english-uncased-finetuned-pos\"\r\n\
          tokenizer = AutoTokenizer.from_pretrained(model_name)\r\nmodel = AutoModelForTokenClassification.from_pretrained(model_name)\r\
          \n\r\npipeline = TokenClassificationPipeline(model=model, tokenizer=tokenizer)\r\
          \noutputs = pipeline(text)\r\n\r\nfor output in outputs:\r\n    if output['entity']\
          \ in ['NOUN','ADJ']:\r\n        #print(output)\r\n        print(output['word']\
          \ , \"\", output['entity'])\r\n\r\nThis is the output I am getting:\r\n\r\
          \nvisible  ADJ\r\npor  NOUN\r\n##osity  NOUN\r\nmoderate  ADJ\r\nminor \
          \ ADJ\r\ncommon  ADJ\r\nmo  NOUN\r\n##uld  NOUN\r\n##ic  ADJ\r\nintra  ADJ\r\
          \n##par  NOUN\r\n##tic  NOUN\r\n##le  NOUN\r\nvu  ADJ\r\n##ggy  ADJ\r\n\
          macro  NOUN\r\n##pore  NOUN\r\n##s  NOUN\r\n##rar  NOUN\r\n##e  ADJ\r\n\
          minor  ADJ\r\ngrain  NOUN\r\nmatrix  NOUN\r\nmicro  NOUN\r\n##por  NOUN\r\
          \n##osity  NOUN\r\nvalue  NOUN\r\nagree  ADJ\r\n##able  ADJ\r\nvolume  NOUN\r\
          \ncommon  ADJ\r\ncement  NOUN\r\n##ation  NOUN\r\nconnectivity  NOUN\r\n\
          common  ADJ\r\ncracks  NOUN\r\nfractures  NOUN\r\nper  NOUN\r\n##me  NOUN\r\
          \n##ability  NOUN\r\nvalue  NOUN\r\npoor  ADJ\r\nmoderate  ADJ\r\nreservoir\
          \  NOUN\r\nquality  NOUN\r\nopen  ADJ\r\ncracks  NOUN\r\nfractures  NOUN\r\
          \nartefacts  NOUN\r\nsample  NOUN\r\npreparation  NOUN\r\n![issue in tokenization.png](https://cdn-uploads.huggingface.co/production/uploads/6454845f36821f6860001a42/ayva-sY5TgFG6cxVUSAl6.png)\r\
          \n\r\n\r\n\r\nAny idea what is the reason and how to solve this issue ? "
        updatedAt: '2023-05-06T19:22:03.580Z'
      numEdits: 0
      reactions: []
    id: 6456a8db4a7ffb7d5a4a3c34
    type: comment
  author: maithakh
  content: "Hello, \r\nThis is the code i executed. I am wondering why the words are\
    \ broken into non-English tokens ? \r\n\r\ntext = \"Visible porosity appears moderate,\
    \ characterized by minor to common mouldic, intraparticle and vuggy macropores,\
    \ along with rare to minor grain and matrix-hosted microporosity. The measured\
    \ value is agreeable with the observed volume. However, common cementation has\
    \ degraded connectivity and common cracks and fractures may have affected the\
    \ measured permeability value. Therefore, a poor to possibly moderate reservoir\
    \ quality is inferred. Open cracks and fractures are interpreted to be artefacts\
    \ from sample preparation.\"\r\n\r\nmodel_name = \"vblagoje/bert-english-uncased-finetuned-pos\"\
    \r\ntokenizer = AutoTokenizer.from_pretrained(model_name)\r\nmodel = AutoModelForTokenClassification.from_pretrained(model_name)\r\
    \n\r\npipeline = TokenClassificationPipeline(model=model, tokenizer=tokenizer)\r\
    \noutputs = pipeline(text)\r\n\r\nfor output in outputs:\r\n    if output['entity']\
    \ in ['NOUN','ADJ']:\r\n        #print(output)\r\n        print(output['word']\
    \ , \"\", output['entity'])\r\n\r\nThis is the output I am getting:\r\n\r\nvisible\
    \  ADJ\r\npor  NOUN\r\n##osity  NOUN\r\nmoderate  ADJ\r\nminor  ADJ\r\ncommon\
    \  ADJ\r\nmo  NOUN\r\n##uld  NOUN\r\n##ic  ADJ\r\nintra  ADJ\r\n##par  NOUN\r\n\
    ##tic  NOUN\r\n##le  NOUN\r\nvu  ADJ\r\n##ggy  ADJ\r\nmacro  NOUN\r\n##pore  NOUN\r\
    \n##s  NOUN\r\n##rar  NOUN\r\n##e  ADJ\r\nminor  ADJ\r\ngrain  NOUN\r\nmatrix\
    \  NOUN\r\nmicro  NOUN\r\n##por  NOUN\r\n##osity  NOUN\r\nvalue  NOUN\r\nagree\
    \  ADJ\r\n##able  ADJ\r\nvolume  NOUN\r\ncommon  ADJ\r\ncement  NOUN\r\n##ation\
    \  NOUN\r\nconnectivity  NOUN\r\ncommon  ADJ\r\ncracks  NOUN\r\nfractures  NOUN\r\
    \nper  NOUN\r\n##me  NOUN\r\n##ability  NOUN\r\nvalue  NOUN\r\npoor  ADJ\r\nmoderate\
    \  ADJ\r\nreservoir  NOUN\r\nquality  NOUN\r\nopen  ADJ\r\ncracks  NOUN\r\nfractures\
    \  NOUN\r\nartefacts  NOUN\r\nsample  NOUN\r\npreparation  NOUN\r\n![issue in\
    \ tokenization.png](https://cdn-uploads.huggingface.co/production/uploads/6454845f36821f6860001a42/ayva-sY5TgFG6cxVUSAl6.png)\r\
    \n\r\n\r\n\r\nAny idea what is the reason and how to solve this issue ? "
  created_at: 2023-05-06 18:22:03+00:00
  edited: false
  hidden: false
  id: 6456a8db4a7ffb7d5a4a3c34
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: vblagoje/bert-english-uncased-finetuned-pos
repo_type: model
status: open
target_branch: null
title: Problem in tokens
