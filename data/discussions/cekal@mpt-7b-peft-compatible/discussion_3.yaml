!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kdua
conflicting_files: null
created_at: 2023-06-01 09:35:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1b1837277fb9200e22fcf604baa369b0.svg
      fullname: Karan Dua
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kdua
      type: user
    createdAt: '2023-06-01T10:35:34.000Z'
    data:
      edited: true
      editors:
      - kdua
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1b1837277fb9200e22fcf604baa369b0.svg
          fullname: Karan Dua
          isHf: false
          isPro: false
          name: kdua
          type: user
        html: '<p>Hello<br>Thank you for making this work.<br>I wanted to check if
          you could please share the finetuning code using PEFT? I am running into
          an error and suspect that there may be issues in my finetuning code. Following
          is the code I am using:</p>

          <p>model = AutoModelForCausalLM.from_pretrained(''./mpt-7b-peft-compatible'',
          trust_remote_code=True, torch_dtype=torch.bfloat16)</p>

          <p>from torch import nn</p>

          <p>for param in model.parameters():<br>    param.requires_grad = False  #
          freeze the model - train adapters later</p>

          <p>model.gradient_checkpointing_enable()  # reduce number of stored activations<br>model.enable_input_require_grads()</p>

          <p>def print_trainable_parameters(model):<br>    """<br>    Prints the number
          of trainable parameters in the model.<br>    """<br>    trainable_params
          = 0<br>    all_param = 0<br>    for _, param in model.named_parameters():<br>        all_param
          += param.numel()<br>        if param.requires_grad:<br>            trainable_params
          += param.numel()<br>    print(<br>        f"trainable params: {trainable_params}
          || all params: {all_param} || trainable%: {100 * trainable_params / all_param}"<br>    )</p>

          <p>from peft import LoraConfig, get_peft_model </p>

          <p>config = LoraConfig(<br>    r=16,<br>    lora_alpha=32,<br>    target_modules=["up_proj",
          "down_proj"],<br>    lora_dropout=0.05,<br>    bias="none",<br>    task_type="CAUSAL_LM"<br>)</p>

          <p>model = get_peft_model(model, config)<br>print_trainable_parameters(model)</p>

          <p>output_dir = ''mpt-finetuned''</p>

          <p>trainer = Trainer(<br>    model=model,<br>    train_dataset=train_ds_tokenized,<br>    args=TrainingArguments(<br>        per_device_train_batch_size=4,<br>        gradient_accumulation_steps=4,<br>        warmup_steps=100,<br>        max_steps=200,<br>        learning_rate=2e-4,<br>        fp16=True,<br>        logging_steps=1,<br>        output_dir=output_dir<br>    ),<br>    data_collator=DataCollatorForLanguageModeling(tokenizer,
          mlm=False)<br>)</p>

          <p>trainer.train()</p>

          <p>I get this error on trainer.train():   AttributeError: ''MPTForCausalLM''
          object has no attribute ''model_parallel''</p>

          '
        raw: "Hello\nThank you for making this work.\nI wanted to check if you could\
          \ please share the finetuning code using PEFT? I am running into an error\
          \ and suspect that there may be issues in my finetuning code. Following\
          \ is the code I am using:\n\nmodel = AutoModelForCausalLM.from_pretrained('./mpt-7b-peft-compatible',\
          \ trust_remote_code=True, torch_dtype=torch.bfloat16)\n\nfrom torch import\
          \ nn\n\nfor param in model.parameters():\n    param.requires_grad = False\
          \  # freeze the model - train adapters later\n\nmodel.gradient_checkpointing_enable()\
          \  # reduce number of stored activations\nmodel.enable_input_require_grads()\n\
          \n\ndef print_trainable_parameters(model):\n    \"\"\"\n    Prints the number\
          \ of trainable parameters in the model.\n    \"\"\"\n    trainable_params\
          \ = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n\
          \        all_param += param.numel()\n        if param.requires_grad:\n \
          \           trainable_params += param.numel()\n    print(\n        f\"trainable\
          \ params: {trainable_params} || all params: {all_param} || trainable%: {100\
          \ * trainable_params / all_param}\"\n    )\n\nfrom peft import LoraConfig,\
          \ get_peft_model \n\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=32,\n\
          \    target_modules=[\"up_proj\", \"down_proj\"],\n    lora_dropout=0.05,\n\
          \    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model,\
          \ config)\nprint_trainable_parameters(model)\n\noutput_dir = 'mpt-finetuned'\n\
          \ntrainer = Trainer(\n    model=model, \n    train_dataset=train_ds_tokenized,\n\
          \    args=TrainingArguments(\n        per_device_train_batch_size=4, \n\
          \        gradient_accumulation_steps=4,\n        warmup_steps=100, \n  \
          \      max_steps=200, \n        learning_rate=2e-4, \n        fp16=True,\n\
          \        logging_steps=1, \n        output_dir=output_dir\n    ),\n    data_collator=DataCollatorForLanguageModeling(tokenizer,\
          \ mlm=False)\n)\n\ntrainer.train()\n\nI get this error on trainer.train():\
          \   AttributeError: 'MPTForCausalLM' object has no attribute 'model_parallel'"
        updatedAt: '2023-06-01T10:36:45.810Z'
      numEdits: 1
      reactions: []
    id: 64787476403cd7ae4b7a0cec
    type: comment
  author: kdua
  content: "Hello\nThank you for making this work.\nI wanted to check if you could\
    \ please share the finetuning code using PEFT? I am running into an error and\
    \ suspect that there may be issues in my finetuning code. Following is the code\
    \ I am using:\n\nmodel = AutoModelForCausalLM.from_pretrained('./mpt-7b-peft-compatible',\
    \ trust_remote_code=True, torch_dtype=torch.bfloat16)\n\nfrom torch import nn\n\
    \nfor param in model.parameters():\n    param.requires_grad = False  # freeze\
    \ the model - train adapters later\n\nmodel.gradient_checkpointing_enable()  #\
    \ reduce number of stored activations\nmodel.enable_input_require_grads()\n\n\n\
    def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable\
    \ parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param\
    \ = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n\
    \        if param.requires_grad:\n            trainable_params += param.numel()\n\
    \    print(\n        f\"trainable params: {trainable_params} || all params: {all_param}\
    \ || trainable%: {100 * trainable_params / all_param}\"\n    )\n\nfrom peft import\
    \ LoraConfig, get_peft_model \n\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=32,\n\
    \    target_modules=[\"up_proj\", \"down_proj\"],\n    lora_dropout=0.05,\n  \
    \  bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model,\
    \ config)\nprint_trainable_parameters(model)\n\noutput_dir = 'mpt-finetuned'\n\
    \ntrainer = Trainer(\n    model=model, \n    train_dataset=train_ds_tokenized,\n\
    \    args=TrainingArguments(\n        per_device_train_batch_size=4, \n      \
    \  gradient_accumulation_steps=4,\n        warmup_steps=100, \n        max_steps=200,\
    \ \n        learning_rate=2e-4, \n        fp16=True,\n        logging_steps=1,\
    \ \n        output_dir=output_dir\n    ),\n    data_collator=DataCollatorForLanguageModeling(tokenizer,\
    \ mlm=False)\n)\n\ntrainer.train()\n\nI get this error on trainer.train():   AttributeError:\
    \ 'MPTForCausalLM' object has no attribute 'model_parallel'"
  created_at: 2023-06-01 09:35:34+00:00
  edited: true
  hidden: false
  id: 64787476403cd7ae4b7a0cec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-06-02T21:55:43.000Z'
    data:
      edited: false
      editors:
      - cekal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8149300217628479
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
          fullname: Vojtech Cekal
          isHf: false
          isPro: true
          name: cekal
          type: user
        html: '<p>Hi, try this notebook: <a rel="nofollow" href="https://colab.research.google.com/drive/1iBeY5UTLHE3aL6yNLiCIJHOBDqWBYbi5?usp=sharing">https://colab.research.google.com/drive/1iBeY5UTLHE3aL6yNLiCIJHOBDqWBYbi5?usp=sharing</a></p>

          <p>Works fine for me. If you''ll still encounter issues, try updating some
          packages or let me know with the specific error.</p>

          '
        raw: 'Hi, try this notebook: https://colab.research.google.com/drive/1iBeY5UTLHE3aL6yNLiCIJHOBDqWBYbi5?usp=sharing


          Works fine for me. If you''ll still encounter issues, try updating some
          packages or let me know with the specific error.'
        updatedAt: '2023-06-02T21:55:43.277Z'
      numEdits: 0
      reactions: []
    id: 647a655f822b7e8ccbd8c3b9
    type: comment
  author: cekal
  content: 'Hi, try this notebook: https://colab.research.google.com/drive/1iBeY5UTLHE3aL6yNLiCIJHOBDqWBYbi5?usp=sharing


    Works fine for me. If you''ll still encounter issues, try updating some packages
    or let me know with the specific error.'
  created_at: 2023-06-02 20:55:43+00:00
  edited: false
  hidden: false
  id: 647a655f822b7e8ccbd8c3b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3bc825b0deaea185cd0dcbe492473691.svg
      fullname: Thang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: envyt48
      type: user
    createdAt: '2023-06-05T04:20:32.000Z'
    data:
      edited: false
      editors:
      - envyt48
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6487611532211304
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3bc825b0deaea185cd0dcbe492473691.svg
          fullname: Thang
          isHf: false
          isPro: false
          name: envyt48
          type: user
        html: "<p>I got this error: <code>AttributeError: 'MPTForCausalLM' object\
          \ has no attribute 'model_parallel'</code>.<br><span data-props=\"{&quot;user&quot;:&quot;cekal&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/cekal\"\
          >@<span class=\"underline\">cekal</span></a></span>\n\n\t</span></span>\
          \ do you have any idea ?</p>\n"
        raw: 'I got this error: `AttributeError: ''MPTForCausalLM'' object has no
          attribute ''model_parallel''`.

          @cekal do you have any idea ?'
        updatedAt: '2023-06-05T04:20:32.492Z'
      numEdits: 0
      reactions: []
    id: 647d629060dfe0f35d6b650a
    type: comment
  author: envyt48
  content: 'I got this error: `AttributeError: ''MPTForCausalLM'' object has no attribute
    ''model_parallel''`.

    @cekal do you have any idea ?'
  created_at: 2023-06-05 03:20:32+00:00
  edited: false
  hidden: false
  id: 647d629060dfe0f35d6b650a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-06-05T10:59:20.000Z'
    data:
      edited: false
      editors:
      - cekal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6507782340049744
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
          fullname: Vojtech Cekal
          isHf: false
          isPro: true
          name: cekal
          type: user
        html: '<p>Even when using this notebook? <a rel="nofollow" href="https://colab.research.google.com/drive/1iBeY5UTLHE3aL6yNLiCIJHOBDqWBYbi5?usp=sharing">https://colab.research.google.com/drive/1iBeY5UTLHE3aL6yNLiCIJHOBDqWBYbi5?usp=sharing</a><br>Worked
          fine for me on Google colab.</p>

          '
        raw: 'Even when using this notebook? https://colab.research.google.com/drive/1iBeY5UTLHE3aL6yNLiCIJHOBDqWBYbi5?usp=sharing

          Worked fine for me on Google colab.'
        updatedAt: '2023-06-05T10:59:20.878Z'
      numEdits: 0
      reactions: []
    id: 647dc0085214d172cbb3aa5a
    type: comment
  author: cekal
  content: 'Even when using this notebook? https://colab.research.google.com/drive/1iBeY5UTLHE3aL6yNLiCIJHOBDqWBYbi5?usp=sharing

    Worked fine for me on Google colab.'
  created_at: 2023-06-05 09:59:20+00:00
  edited: false
  hidden: false
  id: 647dc0085214d172cbb3aa5a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3bc825b0deaea185cd0dcbe492473691.svg
      fullname: Thang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: envyt48
      type: user
    createdAt: '2023-06-05T11:26:39.000Z'
    data:
      edited: false
      editors:
      - envyt48
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5883648991584778
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3bc825b0deaea185cd0dcbe492473691.svg
          fullname: Thang
          isHf: false
          isPro: false
          name: envyt48
          type: user
        html: '<p>Yes,  I run this notebook directly on Google Colab Pro.<br><a rel="nofollow"
          href="https://cdn-uploads.huggingface.co/production/uploads/647d6231adaf5cc26daaefa6/unuicN_zd-1giwX23uRTC.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/647d6231adaf5cc26daaefa6/unuicN_zd-1giwX23uRTC.png"></a><br>Is
          it a problem when the runtime is A100 GPU ?</p>

          '
        raw: 'Yes,  I run this notebook directly on Google Colab Pro.

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/647d6231adaf5cc26daaefa6/unuicN_zd-1giwX23uRTC.png)

          Is it a problem when the runtime is A100 GPU ?'
        updatedAt: '2023-06-05T11:26:39.328Z'
      numEdits: 0
      reactions: []
    id: 647dc66f5214d172cbb48dd7
    type: comment
  author: envyt48
  content: 'Yes,  I run this notebook directly on Google Colab Pro.

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/647d6231adaf5cc26daaefa6/unuicN_zd-1giwX23uRTC.png)

    Is it a problem when the runtime is A100 GPU ?'
  created_at: 2023-06-05 10:26:39+00:00
  edited: false
  hidden: false
  id: 647dc66f5214d172cbb48dd7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1b1837277fb9200e22fcf604baa369b0.svg
      fullname: Karan Dua
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kdua
      type: user
    createdAt: '2023-06-05T16:08:23.000Z'
    data:
      edited: false
      editors:
      - kdua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6568807363510132
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1b1837277fb9200e22fcf604baa369b0.svg
          fullname: Karan Dua
          isHf: false
          isPro: false
          name: kdua
          type: user
        html: '<p>Getting exactly the same error: ''MPTForCausalLM'' object has no
          attribute ''model_parallel''<br>I am using a custom V100 setup</p>

          '
        raw: 'Getting exactly the same error: ''MPTForCausalLM'' object has no attribute
          ''model_parallel''

          I am using a custom V100 setup'
        updatedAt: '2023-06-05T16:08:23.860Z'
      numEdits: 0
      reactions: []
    id: 647e0877f14eafc3b45585d1
    type: comment
  author: kdua
  content: 'Getting exactly the same error: ''MPTForCausalLM'' object has no attribute
    ''model_parallel''

    I am using a custom V100 setup'
  created_at: 2023-06-05 15:08:23+00:00
  edited: false
  hidden: false
  id: 647e0877f14eafc3b45585d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1b1837277fb9200e22fcf604baa369b0.svg
      fullname: Karan Dua
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kdua
      type: user
    createdAt: '2023-06-06T06:13:36.000Z'
    data:
      edited: false
      editors:
      - kdua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8783702254295349
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1b1837277fb9200e22fcf604baa369b0.svg
          fullname: Karan Dua
          isHf: false
          isPro: false
          name: kdua
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;envyt48&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/envyt48\">@<span class=\"\
          underline\">envyt48</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;cekal&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/cekal\">@<span class=\"underline\">cekal</span></a></span>\n\
          \n\t</span></span><br>I managed to solve the problem. You need to move the\
          \ following code (already present in the above shared notebook at line 243-246)\
          \ to before LoraConfig (line 192) initialization. Basically, the peft model's\
          \ model_parallel attribute was being set but not for the underlying model.\
          \ We need to set it for the underlying model</p>\n<p>if not ddp and torch.cuda.device_count()\
          \ &gt; 1:<br>        # keeps Trainer from trying its own DataParallelism\
          \ when more than 1 gpu is available<br>        model.is_parallelizable =\
          \ True<br>        model.model_parallel = True</p>\n<p>This is a copy of\
          \ the edited notebook and this should work now: <a rel=\"nofollow\" href=\"\
          https://colab.research.google.com/drive/1A9bnjSfRQg6GciIkSxbfX7vS8PuP83FN\"\
          >https://colab.research.google.com/drive/1A9bnjSfRQg6GciIkSxbfX7vS8PuP83FN</a></p>\n"
        raw: "@envyt48 @cekal \nI managed to solve the problem. You need to move the\
          \ following code (already present in the above shared notebook at line 243-246)\
          \ to before LoraConfig (line 192) initialization. Basically, the peft model's\
          \ model_parallel attribute was being set but not for the underlying model.\
          \ We need to set it for the underlying model\n\nif not ddp and torch.cuda.device_count()\
          \ > 1:\n        # keeps Trainer from trying its own DataParallelism when\
          \ more than 1 gpu is available\n        model.is_parallelizable = True\n\
          \        model.model_parallel = True\n\n\nThis is a copy of the edited notebook\
          \ and this should work now: https://colab.research.google.com/drive/1A9bnjSfRQg6GciIkSxbfX7vS8PuP83FN"
        updatedAt: '2023-06-06T06:13:36.023Z'
      numEdits: 0
      reactions: []
    id: 647ece909c31024457931f48
    type: comment
  author: kdua
  content: "@envyt48 @cekal \nI managed to solve the problem. You need to move the\
    \ following code (already present in the above shared notebook at line 243-246)\
    \ to before LoraConfig (line 192) initialization. Basically, the peft model's\
    \ model_parallel attribute was being set but not for the underlying model. We\
    \ need to set it for the underlying model\n\nif not ddp and torch.cuda.device_count()\
    \ > 1:\n        # keeps Trainer from trying its own DataParallelism when more\
    \ than 1 gpu is available\n        model.is_parallelizable = True\n        model.model_parallel\
    \ = True\n\n\nThis is a copy of the edited notebook and this should work now:\
    \ https://colab.research.google.com/drive/1A9bnjSfRQg6GciIkSxbfX7vS8PuP83FN"
  created_at: 2023-06-06 05:13:36+00:00
  edited: false
  hidden: false
  id: 647ece909c31024457931f48
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e27b045966c7971a609e496f2ad4c1e4.svg
      fullname: Zach Blank
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zachblank
      type: user
    createdAt: '2023-06-07T11:19:43.000Z'
    data:
      edited: false
      editors:
      - zachblank
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.328345388174057
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e27b045966c7971a609e496f2ad4c1e4.svg
          fullname: Zach Blank
          isHf: false
          isPro: false
          name: zachblank
          type: user
        html: "<p>I ran the above notebook (had to modify the code that <span data-props=\"\
          {&quot;user&quot;:&quot;kdua&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/kdua\">@<span class=\"underline\">kdua</span></a></span>\n\
          \n\t</span></span> mentioned by explicitly setting the two parallel props\
          \ to False (running on a single Colab GPU). Ran for about 5 hours and came\
          \ up with an error trying to save but more concerning, the loss did not\
          \ decrease. See screenshot:</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/644422a69c1bd83bd19e9ee0/R3Y33mQflkEXiJP9RyNj2.png\"\
          ><img alt=\"Screenshot 2023-06-07 at 4.11.40 AM.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/644422a69c1bd83bd19e9ee0/R3Y33mQflkEXiJP9RyNj2.png\"\
          ></a></p>\n<p>The full error text is:<br>There were missing keys in the\
          \ checkpoint model loaded: ['base_model.model.transformer.wte.weight', 'base_model.model.transformer.blocks.0.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.0.attn.Wqkv.weight', 'base_model.model.transformer.blocks.0.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.0.norm_2.weight', 'base_model.model.transformer.blocks.0.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.0.ffn.down_proj.weight', 'base_model.model.transformer.blocks.1.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.1.attn.Wqkv.weight', 'base_model.model.transformer.blocks.1.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.1.norm_2.weight', 'base_model.model.transformer.blocks.1.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.1.ffn.down_proj.weight', 'base_model.model.transformer.blocks.2.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.2.attn.Wqkv.weight', 'base_model.model.transformer.blocks.2.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.2.norm_2.weight', 'base_model.model.transformer.blocks.2.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.2.ffn.down_proj.weight', 'base_model.model.transformer.blocks.3.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.3.attn.Wqkv.weight', 'base_model.model.transformer.blocks.3.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.3.norm_2.weight', 'base_model.model.transformer.blocks.3.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.3.ffn.down_proj.weight', 'base_model.model.transformer.blocks.4.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.4.attn.Wqkv.weight', 'base_model.model.transformer.blocks.4.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.4.norm_2.weight', 'base_model.model.transformer.blocks.4.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.4.ffn.down_proj.weight', 'base_model.model.transformer.blocks.5.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.5.attn.Wqkv.weight', 'base_model.model.transformer.blocks.5.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.5.norm_2.weight', 'base_model.model.transformer.blocks.5.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.5.ffn.down_proj.weight', 'base_model.model.transformer.blocks.6.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.6.attn.Wqkv.weight', 'base_model.model.transformer.blocks.6.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.6.norm_2.weight', 'base_model.model.transformer.blocks.6.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.6.ffn.down_proj.weight', 'base_model.model.transformer.blocks.7.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.7.attn.Wqkv.weight', 'base_model.model.transformer.blocks.7.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.7.norm_2.weight', 'base_model.model.transformer.blocks.7.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.7.ffn.down_proj.weight', 'base_model.model.transformer.blocks.8.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.8.attn.Wqkv.weight', 'base_model.model.transformer.blocks.8.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.8.norm_2.weight', 'base_model.model.transformer.blocks.8.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.8.ffn.down_proj.weight', 'base_model.model.transformer.blocks.9.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.9.attn.Wqkv.weight', 'base_model.model.transformer.blocks.9.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.9.norm_2.weight', 'base_model.model.transformer.blocks.9.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.9.ffn.down_proj.weight', 'base_model.model.transformer.blocks.10.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.10.attn.Wqkv.weight', 'base_model.model.transformer.blocks.10.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.10.norm_2.weight', 'base_model.model.transformer.blocks.10.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.10.ffn.down_proj.weight', 'base_model.model.transformer.blocks.11.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.11.attn.Wqkv.weight', 'base_model.model.transformer.blocks.11.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.11.norm_2.weight', 'base_model.model.transformer.blocks.11.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.11.ffn.down_proj.weight', 'base_model.model.transformer.blocks.12.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.12.attn.Wqkv.weight', 'base_model.model.transformer.blocks.12.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.12.norm_2.weight', 'base_model.model.transformer.blocks.12.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.12.ffn.down_proj.weight', 'base_model.model.transformer.blocks.13.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.13.attn.Wqkv.weight', 'base_model.model.transformer.blocks.13.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.13.norm_2.weight', 'base_model.model.transformer.blocks.13.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.13.ffn.down_proj.weight', 'base_model.model.transformer.blocks.14.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.14.attn.Wqkv.weight', 'base_model.model.transformer.blocks.14.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.14.norm_2.weight', 'base_model.model.transformer.blocks.14.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.14.ffn.down_proj.weight', 'base_model.model.transformer.blocks.15.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.15.attn.Wqkv.weight', 'base_model.model.transformer.blocks.15.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.15.norm_2.weight', 'base_model.model.transformer.blocks.15.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.15.ffn.down_proj.weight', 'base_model.model.transformer.blocks.16.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.16.attn.Wqkv.weight', 'base_model.model.transformer.blocks.16.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.16.norm_2.weight', 'base_model.model.transformer.blocks.16.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.16.ffn.down_proj.weight', 'base_model.model.transformer.blocks.17.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.17.attn.Wqkv.weight', 'base_model.model.transformer.blocks.17.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.17.norm_2.weight', 'base_model.model.transformer.blocks.17.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.17.ffn.down_proj.weight', 'base_model.model.transformer.blocks.18.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.18.attn.Wqkv.weight', 'base_model.model.transformer.blocks.18.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.18.norm_2.weight', 'base_model.model.transformer.blocks.18.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.18.ffn.down_proj.weight', 'base_model.model.transformer.blocks.19.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.19.attn.Wqkv.weight', 'base_model.model.transformer.blocks.19.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.19.norm_2.weight', 'base_model.model.transformer.blocks.19.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.19.ffn.down_proj.weight', 'base_model.model.transformer.blocks.20.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.20.attn.Wqkv.weight', 'base_model.model.transformer.blocks.20.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.20.norm_2.weight', 'base_model.model.transformer.blocks.20.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.20.ffn.down_proj.weight', 'base_model.model.transformer.blocks.21.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.21.attn.Wqkv.weight', 'base_model.model.transformer.blocks.21.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.21.norm_2.weight', 'base_model.model.transformer.blocks.21.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.21.ffn.down_proj.weight', 'base_model.model.transformer.blocks.22.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.22.attn.Wqkv.weight', 'base_model.model.transformer.blocks.22.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.22.norm_2.weight', 'base_model.model.transformer.blocks.22.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.22.ffn.down_proj.weight', 'base_model.model.transformer.blocks.23.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.23.attn.Wqkv.weight', 'base_model.model.transformer.blocks.23.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.23.norm_2.weight', 'base_model.model.transformer.blocks.23.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.23.ffn.down_proj.weight', 'base_model.model.transformer.blocks.24.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.24.attn.Wqkv.weight', 'base_model.model.transformer.blocks.24.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.24.norm_2.weight', 'base_model.model.transformer.blocks.24.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.24.ffn.down_proj.weight', 'base_model.model.transformer.blocks.25.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.25.attn.Wqkv.weight', 'base_model.model.transformer.blocks.25.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.25.norm_2.weight', 'base_model.model.transformer.blocks.25.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.25.ffn.down_proj.weight', 'base_model.model.transformer.blocks.26.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.26.attn.Wqkv.weight', 'base_model.model.transformer.blocks.26.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.26.norm_2.weight', 'base_model.model.transformer.blocks.26.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.26.ffn.down_proj.weight', 'base_model.model.transformer.blocks.27.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.27.attn.Wqkv.weight', 'base_model.model.transformer.blocks.27.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.27.norm_2.weight', 'base_model.model.transformer.blocks.27.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.27.ffn.down_proj.weight', 'base_model.model.transformer.blocks.28.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.28.attn.Wqkv.weight', 'base_model.model.transformer.blocks.28.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.28.norm_2.weight', 'base_model.model.transformer.blocks.28.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.28.ffn.down_proj.weight', 'base_model.model.transformer.blocks.29.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.29.attn.Wqkv.weight', 'base_model.model.transformer.blocks.29.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.29.norm_2.weight', 'base_model.model.transformer.blocks.29.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.29.ffn.down_proj.weight', 'base_model.model.transformer.blocks.30.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.30.attn.Wqkv.weight', 'base_model.model.transformer.blocks.30.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.30.norm_2.weight', 'base_model.model.transformer.blocks.30.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.30.ffn.down_proj.weight', 'base_model.model.transformer.blocks.31.norm_1.weight',\
          \ 'base_model.model.transformer.blocks.31.attn.Wqkv.weight', 'base_model.model.transformer.blocks.31.attn.out_proj.weight',\
          \ 'base_model.model.transformer.blocks.31.norm_2.weight', 'base_model.model.transformer.blocks.31.ffn.up_proj.weight',\
          \ 'base_model.model.transformer.blocks.31.ffn.down_proj.weight', 'base_model.model.transformer.norm_f.weight'].<br>ERROR:\
          \ Could not consume arg: -f</p>\n"
        raw: 'I ran the above notebook (had to modify the code that @kdua mentioned
          by explicitly setting the two parallel props to False (running on a single
          Colab GPU). Ran for about 5 hours and came up with an error trying to save
          but more concerning, the loss did not decrease. See screenshot:


          ![Screenshot 2023-06-07 at 4.11.40 AM.png](https://cdn-uploads.huggingface.co/production/uploads/644422a69c1bd83bd19e9ee0/R3Y33mQflkEXiJP9RyNj2.png)


          The full error text is:

          There were missing keys in the checkpoint model loaded: [''base_model.model.transformer.wte.weight'',
          ''base_model.model.transformer.blocks.0.norm_1.weight'', ''base_model.model.transformer.blocks.0.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.0.attn.out_proj.weight'', ''base_model.model.transformer.blocks.0.norm_2.weight'',
          ''base_model.model.transformer.blocks.0.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.0.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.1.norm_1.weight'', ''base_model.model.transformer.blocks.1.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.1.attn.out_proj.weight'', ''base_model.model.transformer.blocks.1.norm_2.weight'',
          ''base_model.model.transformer.blocks.1.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.1.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.2.norm_1.weight'', ''base_model.model.transformer.blocks.2.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.2.attn.out_proj.weight'', ''base_model.model.transformer.blocks.2.norm_2.weight'',
          ''base_model.model.transformer.blocks.2.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.2.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.3.norm_1.weight'', ''base_model.model.transformer.blocks.3.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.3.attn.out_proj.weight'', ''base_model.model.transformer.blocks.3.norm_2.weight'',
          ''base_model.model.transformer.blocks.3.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.3.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.4.norm_1.weight'', ''base_model.model.transformer.blocks.4.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.4.attn.out_proj.weight'', ''base_model.model.transformer.blocks.4.norm_2.weight'',
          ''base_model.model.transformer.blocks.4.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.4.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.5.norm_1.weight'', ''base_model.model.transformer.blocks.5.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.5.attn.out_proj.weight'', ''base_model.model.transformer.blocks.5.norm_2.weight'',
          ''base_model.model.transformer.blocks.5.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.5.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.6.norm_1.weight'', ''base_model.model.transformer.blocks.6.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.6.attn.out_proj.weight'', ''base_model.model.transformer.blocks.6.norm_2.weight'',
          ''base_model.model.transformer.blocks.6.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.6.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.7.norm_1.weight'', ''base_model.model.transformer.blocks.7.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.7.attn.out_proj.weight'', ''base_model.model.transformer.blocks.7.norm_2.weight'',
          ''base_model.model.transformer.blocks.7.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.7.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.8.norm_1.weight'', ''base_model.model.transformer.blocks.8.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.8.attn.out_proj.weight'', ''base_model.model.transformer.blocks.8.norm_2.weight'',
          ''base_model.model.transformer.blocks.8.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.8.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.9.norm_1.weight'', ''base_model.model.transformer.blocks.9.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.9.attn.out_proj.weight'', ''base_model.model.transformer.blocks.9.norm_2.weight'',
          ''base_model.model.transformer.blocks.9.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.9.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.10.norm_1.weight'', ''base_model.model.transformer.blocks.10.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.10.attn.out_proj.weight'', ''base_model.model.transformer.blocks.10.norm_2.weight'',
          ''base_model.model.transformer.blocks.10.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.10.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.11.norm_1.weight'', ''base_model.model.transformer.blocks.11.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.11.attn.out_proj.weight'', ''base_model.model.transformer.blocks.11.norm_2.weight'',
          ''base_model.model.transformer.blocks.11.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.11.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.12.norm_1.weight'', ''base_model.model.transformer.blocks.12.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.12.attn.out_proj.weight'', ''base_model.model.transformer.blocks.12.norm_2.weight'',
          ''base_model.model.transformer.blocks.12.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.12.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.13.norm_1.weight'', ''base_model.model.transformer.blocks.13.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.13.attn.out_proj.weight'', ''base_model.model.transformer.blocks.13.norm_2.weight'',
          ''base_model.model.transformer.blocks.13.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.13.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.14.norm_1.weight'', ''base_model.model.transformer.blocks.14.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.14.attn.out_proj.weight'', ''base_model.model.transformer.blocks.14.norm_2.weight'',
          ''base_model.model.transformer.blocks.14.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.14.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.15.norm_1.weight'', ''base_model.model.transformer.blocks.15.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.15.attn.out_proj.weight'', ''base_model.model.transformer.blocks.15.norm_2.weight'',
          ''base_model.model.transformer.blocks.15.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.15.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.16.norm_1.weight'', ''base_model.model.transformer.blocks.16.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.16.attn.out_proj.weight'', ''base_model.model.transformer.blocks.16.norm_2.weight'',
          ''base_model.model.transformer.blocks.16.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.16.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.17.norm_1.weight'', ''base_model.model.transformer.blocks.17.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.17.attn.out_proj.weight'', ''base_model.model.transformer.blocks.17.norm_2.weight'',
          ''base_model.model.transformer.blocks.17.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.17.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.18.norm_1.weight'', ''base_model.model.transformer.blocks.18.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.18.attn.out_proj.weight'', ''base_model.model.transformer.blocks.18.norm_2.weight'',
          ''base_model.model.transformer.blocks.18.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.18.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.19.norm_1.weight'', ''base_model.model.transformer.blocks.19.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.19.attn.out_proj.weight'', ''base_model.model.transformer.blocks.19.norm_2.weight'',
          ''base_model.model.transformer.blocks.19.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.19.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.20.norm_1.weight'', ''base_model.model.transformer.blocks.20.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.20.attn.out_proj.weight'', ''base_model.model.transformer.blocks.20.norm_2.weight'',
          ''base_model.model.transformer.blocks.20.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.20.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.21.norm_1.weight'', ''base_model.model.transformer.blocks.21.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.21.attn.out_proj.weight'', ''base_model.model.transformer.blocks.21.norm_2.weight'',
          ''base_model.model.transformer.blocks.21.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.21.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.22.norm_1.weight'', ''base_model.model.transformer.blocks.22.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.22.attn.out_proj.weight'', ''base_model.model.transformer.blocks.22.norm_2.weight'',
          ''base_model.model.transformer.blocks.22.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.22.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.23.norm_1.weight'', ''base_model.model.transformer.blocks.23.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.23.attn.out_proj.weight'', ''base_model.model.transformer.blocks.23.norm_2.weight'',
          ''base_model.model.transformer.blocks.23.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.23.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.24.norm_1.weight'', ''base_model.model.transformer.blocks.24.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.24.attn.out_proj.weight'', ''base_model.model.transformer.blocks.24.norm_2.weight'',
          ''base_model.model.transformer.blocks.24.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.24.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.25.norm_1.weight'', ''base_model.model.transformer.blocks.25.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.25.attn.out_proj.weight'', ''base_model.model.transformer.blocks.25.norm_2.weight'',
          ''base_model.model.transformer.blocks.25.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.25.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.26.norm_1.weight'', ''base_model.model.transformer.blocks.26.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.26.attn.out_proj.weight'', ''base_model.model.transformer.blocks.26.norm_2.weight'',
          ''base_model.model.transformer.blocks.26.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.26.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.27.norm_1.weight'', ''base_model.model.transformer.blocks.27.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.27.attn.out_proj.weight'', ''base_model.model.transformer.blocks.27.norm_2.weight'',
          ''base_model.model.transformer.blocks.27.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.27.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.28.norm_1.weight'', ''base_model.model.transformer.blocks.28.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.28.attn.out_proj.weight'', ''base_model.model.transformer.blocks.28.norm_2.weight'',
          ''base_model.model.transformer.blocks.28.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.28.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.29.norm_1.weight'', ''base_model.model.transformer.blocks.29.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.29.attn.out_proj.weight'', ''base_model.model.transformer.blocks.29.norm_2.weight'',
          ''base_model.model.transformer.blocks.29.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.29.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.30.norm_1.weight'', ''base_model.model.transformer.blocks.30.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.30.attn.out_proj.weight'', ''base_model.model.transformer.blocks.30.norm_2.weight'',
          ''base_model.model.transformer.blocks.30.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.30.ffn.down_proj.weight'',
          ''base_model.model.transformer.blocks.31.norm_1.weight'', ''base_model.model.transformer.blocks.31.attn.Wqkv.weight'',
          ''base_model.model.transformer.blocks.31.attn.out_proj.weight'', ''base_model.model.transformer.blocks.31.norm_2.weight'',
          ''base_model.model.transformer.blocks.31.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.31.ffn.down_proj.weight'',
          ''base_model.model.transformer.norm_f.weight''].

          ERROR: Could not consume arg: -f'
        updatedAt: '2023-06-07T11:19:43.352Z'
      numEdits: 0
      reactions: []
    id: 648067cf40facadc556b0efe
    type: comment
  author: zachblank
  content: 'I ran the above notebook (had to modify the code that @kdua mentioned
    by explicitly setting the two parallel props to False (running on a single Colab
    GPU). Ran for about 5 hours and came up with an error trying to save but more
    concerning, the loss did not decrease. See screenshot:


    ![Screenshot 2023-06-07 at 4.11.40 AM.png](https://cdn-uploads.huggingface.co/production/uploads/644422a69c1bd83bd19e9ee0/R3Y33mQflkEXiJP9RyNj2.png)


    The full error text is:

    There were missing keys in the checkpoint model loaded: [''base_model.model.transformer.wte.weight'',
    ''base_model.model.transformer.blocks.0.norm_1.weight'', ''base_model.model.transformer.blocks.0.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.0.attn.out_proj.weight'', ''base_model.model.transformer.blocks.0.norm_2.weight'',
    ''base_model.model.transformer.blocks.0.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.0.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.1.norm_1.weight'', ''base_model.model.transformer.blocks.1.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.1.attn.out_proj.weight'', ''base_model.model.transformer.blocks.1.norm_2.weight'',
    ''base_model.model.transformer.blocks.1.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.1.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.2.norm_1.weight'', ''base_model.model.transformer.blocks.2.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.2.attn.out_proj.weight'', ''base_model.model.transformer.blocks.2.norm_2.weight'',
    ''base_model.model.transformer.blocks.2.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.2.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.3.norm_1.weight'', ''base_model.model.transformer.blocks.3.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.3.attn.out_proj.weight'', ''base_model.model.transformer.blocks.3.norm_2.weight'',
    ''base_model.model.transformer.blocks.3.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.3.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.4.norm_1.weight'', ''base_model.model.transformer.blocks.4.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.4.attn.out_proj.weight'', ''base_model.model.transformer.blocks.4.norm_2.weight'',
    ''base_model.model.transformer.blocks.4.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.4.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.5.norm_1.weight'', ''base_model.model.transformer.blocks.5.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.5.attn.out_proj.weight'', ''base_model.model.transformer.blocks.5.norm_2.weight'',
    ''base_model.model.transformer.blocks.5.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.5.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.6.norm_1.weight'', ''base_model.model.transformer.blocks.6.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.6.attn.out_proj.weight'', ''base_model.model.transformer.blocks.6.norm_2.weight'',
    ''base_model.model.transformer.blocks.6.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.6.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.7.norm_1.weight'', ''base_model.model.transformer.blocks.7.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.7.attn.out_proj.weight'', ''base_model.model.transformer.blocks.7.norm_2.weight'',
    ''base_model.model.transformer.blocks.7.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.7.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.8.norm_1.weight'', ''base_model.model.transformer.blocks.8.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.8.attn.out_proj.weight'', ''base_model.model.transformer.blocks.8.norm_2.weight'',
    ''base_model.model.transformer.blocks.8.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.8.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.9.norm_1.weight'', ''base_model.model.transformer.blocks.9.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.9.attn.out_proj.weight'', ''base_model.model.transformer.blocks.9.norm_2.weight'',
    ''base_model.model.transformer.blocks.9.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.9.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.10.norm_1.weight'', ''base_model.model.transformer.blocks.10.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.10.attn.out_proj.weight'', ''base_model.model.transformer.blocks.10.norm_2.weight'',
    ''base_model.model.transformer.blocks.10.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.10.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.11.norm_1.weight'', ''base_model.model.transformer.blocks.11.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.11.attn.out_proj.weight'', ''base_model.model.transformer.blocks.11.norm_2.weight'',
    ''base_model.model.transformer.blocks.11.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.11.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.12.norm_1.weight'', ''base_model.model.transformer.blocks.12.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.12.attn.out_proj.weight'', ''base_model.model.transformer.blocks.12.norm_2.weight'',
    ''base_model.model.transformer.blocks.12.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.12.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.13.norm_1.weight'', ''base_model.model.transformer.blocks.13.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.13.attn.out_proj.weight'', ''base_model.model.transformer.blocks.13.norm_2.weight'',
    ''base_model.model.transformer.blocks.13.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.13.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.14.norm_1.weight'', ''base_model.model.transformer.blocks.14.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.14.attn.out_proj.weight'', ''base_model.model.transformer.blocks.14.norm_2.weight'',
    ''base_model.model.transformer.blocks.14.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.14.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.15.norm_1.weight'', ''base_model.model.transformer.blocks.15.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.15.attn.out_proj.weight'', ''base_model.model.transformer.blocks.15.norm_2.weight'',
    ''base_model.model.transformer.blocks.15.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.15.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.16.norm_1.weight'', ''base_model.model.transformer.blocks.16.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.16.attn.out_proj.weight'', ''base_model.model.transformer.blocks.16.norm_2.weight'',
    ''base_model.model.transformer.blocks.16.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.16.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.17.norm_1.weight'', ''base_model.model.transformer.blocks.17.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.17.attn.out_proj.weight'', ''base_model.model.transformer.blocks.17.norm_2.weight'',
    ''base_model.model.transformer.blocks.17.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.17.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.18.norm_1.weight'', ''base_model.model.transformer.blocks.18.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.18.attn.out_proj.weight'', ''base_model.model.transformer.blocks.18.norm_2.weight'',
    ''base_model.model.transformer.blocks.18.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.18.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.19.norm_1.weight'', ''base_model.model.transformer.blocks.19.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.19.attn.out_proj.weight'', ''base_model.model.transformer.blocks.19.norm_2.weight'',
    ''base_model.model.transformer.blocks.19.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.19.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.20.norm_1.weight'', ''base_model.model.transformer.blocks.20.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.20.attn.out_proj.weight'', ''base_model.model.transformer.blocks.20.norm_2.weight'',
    ''base_model.model.transformer.blocks.20.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.20.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.21.norm_1.weight'', ''base_model.model.transformer.blocks.21.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.21.attn.out_proj.weight'', ''base_model.model.transformer.blocks.21.norm_2.weight'',
    ''base_model.model.transformer.blocks.21.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.21.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.22.norm_1.weight'', ''base_model.model.transformer.blocks.22.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.22.attn.out_proj.weight'', ''base_model.model.transformer.blocks.22.norm_2.weight'',
    ''base_model.model.transformer.blocks.22.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.22.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.23.norm_1.weight'', ''base_model.model.transformer.blocks.23.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.23.attn.out_proj.weight'', ''base_model.model.transformer.blocks.23.norm_2.weight'',
    ''base_model.model.transformer.blocks.23.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.23.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.24.norm_1.weight'', ''base_model.model.transformer.blocks.24.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.24.attn.out_proj.weight'', ''base_model.model.transformer.blocks.24.norm_2.weight'',
    ''base_model.model.transformer.blocks.24.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.24.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.25.norm_1.weight'', ''base_model.model.transformer.blocks.25.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.25.attn.out_proj.weight'', ''base_model.model.transformer.blocks.25.norm_2.weight'',
    ''base_model.model.transformer.blocks.25.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.25.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.26.norm_1.weight'', ''base_model.model.transformer.blocks.26.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.26.attn.out_proj.weight'', ''base_model.model.transformer.blocks.26.norm_2.weight'',
    ''base_model.model.transformer.blocks.26.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.26.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.27.norm_1.weight'', ''base_model.model.transformer.blocks.27.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.27.attn.out_proj.weight'', ''base_model.model.transformer.blocks.27.norm_2.weight'',
    ''base_model.model.transformer.blocks.27.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.27.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.28.norm_1.weight'', ''base_model.model.transformer.blocks.28.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.28.attn.out_proj.weight'', ''base_model.model.transformer.blocks.28.norm_2.weight'',
    ''base_model.model.transformer.blocks.28.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.28.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.29.norm_1.weight'', ''base_model.model.transformer.blocks.29.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.29.attn.out_proj.weight'', ''base_model.model.transformer.blocks.29.norm_2.weight'',
    ''base_model.model.transformer.blocks.29.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.29.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.30.norm_1.weight'', ''base_model.model.transformer.blocks.30.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.30.attn.out_proj.weight'', ''base_model.model.transformer.blocks.30.norm_2.weight'',
    ''base_model.model.transformer.blocks.30.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.30.ffn.down_proj.weight'',
    ''base_model.model.transformer.blocks.31.norm_1.weight'', ''base_model.model.transformer.blocks.31.attn.Wqkv.weight'',
    ''base_model.model.transformer.blocks.31.attn.out_proj.weight'', ''base_model.model.transformer.blocks.31.norm_2.weight'',
    ''base_model.model.transformer.blocks.31.ffn.up_proj.weight'', ''base_model.model.transformer.blocks.31.ffn.down_proj.weight'',
    ''base_model.model.transformer.norm_f.weight''].

    ERROR: Could not consume arg: -f'
  created_at: 2023-06-07 10:19:43+00:00
  edited: false
  hidden: false
  id: 648067cf40facadc556b0efe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-06-07T11:21:21.000Z'
    data:
      edited: true
      editors:
      - cekal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6473757028579712
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
          fullname: Vojtech Cekal
          isHf: false
          isPro: true
          name: cekal
          type: user
        html: "<p>Missing keys error should be okay. Can you check if the adapters\
          \ were saved? If so, what\u2019s their size? Should be named adapter_model.bin\
          \ and adapter_config.json.</p>\n<p>Let me know</p>\n"
        raw: "Missing keys error should be okay. Can you check if the adapters were\
          \ saved? If so, what\u2019s their size? Should be named adapter_model.bin\
          \ and adapter_config.json.\n\nLet me know"
        updatedAt: '2023-06-07T11:22:44.297Z'
      numEdits: 1
      reactions: []
      relatedEventId: 6480683140facadc556b153d
    id: 6480683140facadc556b153c
    type: comment
  author: cekal
  content: "Missing keys error should be okay. Can you check if the adapters were\
    \ saved? If so, what\u2019s their size? Should be named adapter_model.bin and\
    \ adapter_config.json.\n\nLet me know"
  created_at: 2023-06-07 10:21:21+00:00
  edited: true
  hidden: false
  id: 6480683140facadc556b153c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-06-07T11:21:21.000Z'
    data:
      status: closed
    id: 6480683140facadc556b153d
    type: status-change
  author: cekal
  created_at: 2023-06-07 10:21:21+00:00
  id: 6480683140facadc556b153d
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-06-07T11:22:56.000Z'
    data:
      status: open
    id: 6480689040facadc556b1b90
    type: status-change
  author: cekal
  created_at: 2023-06-07 10:22:56+00:00
  id: 6480689040facadc556b1b90
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-06-07T11:24:11.000Z'
    data:
      edited: false
      editors:
      - cekal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9765093922615051
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
          fullname: Vojtech Cekal
          isHf: false
          isPro: true
          name: cekal
          type: user
        html: '<p>The loss did not decrease for me either, and it seemed to learn
          the patters from my training dataset well.</p>

          '
        raw: The loss did not decrease for me either, and it seemed to learn the patters
          from my training dataset well.
        updatedAt: '2023-06-07T11:24:11.549Z'
      numEdits: 0
      reactions: []
    id: 648068dbe1421e205fd5f5e1
    type: comment
  author: cekal
  content: The loss did not decrease for me either, and it seemed to learn the patters
    from my training dataset well.
  created_at: 2023-06-07 10:24:11+00:00
  edited: false
  hidden: false
  id: 648068dbe1421e205fd5f5e1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/1b1837277fb9200e22fcf604baa369b0.svg
      fullname: Karan Dua
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kdua
      type: user
    createdAt: '2023-06-08T13:58:45.000Z'
    data:
      status: closed
    id: 6481de956f283a746866cf02
    type: status-change
  author: kdua
  created_at: 2023-06-08 12:58:45+00:00
  id: 6481de956f283a746866cf02
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: cekal/mpt-7b-peft-compatible
repo_type: model
status: closed
target_branch: null
title: PEFT Finetuning Code Please
