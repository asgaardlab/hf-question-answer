!!python/object:huggingface_hub.community.DiscussionWithDetails
author: muelletm
conflicting_files: []
created_at: 2023-05-27 13:54:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646410244848-5fce6464e80c09ad2760251c.jpeg?w=200&h=200&f=face
      fullname: "Thomas M\xFCller"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: muelletm
      type: user
    createdAt: '2023-05-27T14:54:38.000Z'
    data:
      edited: true
      editors:
      - muelletm
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646410244848-5fce6464e80c09ad2760251c.jpeg?w=200&h=200&f=face
          fullname: "Thomas M\xFCller"
          isHf: false
          isPro: false
          name: muelletm
          type: user
        html: "<p>Make sure hidden state and wte weights are on same device when in\
          \ parallel model.</p>\n<p>Based on this:<br><a rel=\"nofollow\" href=\"\
          https://github.com/huggingface/transformers/blob/3ec7a47664ebe40c40f4b722f6bb1cd30c3821ec/src/transformers/models/gpt2/modeling_gpt2.py#L1093\"\
          >https://github.com/huggingface/transformers/blob/3ec7a47664ebe40c40f4b722f6bb1cd30c3821ec/src/transformers/models/gpt2/modeling_gpt2.py#L1093</a>\
          \ </p>\n<p>This should fix the following crash when running qlora:</p>\n\
          <pre><code>Traceback (most recent call last):\n  File \"/code/qlora/qlora.py\"\
          , line 758, in &lt;module&gt;\n    train()\n  File \"/code/qlora/qlora.py\"\
          , line 720, in train\n    train_result = trainer.train(resume_from_checkpoint=checkpoint_dir)\n\
          \  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 1696, in train\n    return inner_training_loop(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 1973, in _inner_training_loop\n    tr_loss_step = self.training_step(model,\
          \ inputs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 2787, in training_step\n    loss = self.compute_loss(model, inputs)\n\
          \  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 2819, in compute_loss\n    outputs = model(**inputs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/opt/conda/lib/python3.10/site-packages/peft/peft_model.py\", line\
          \ 686, in forward\n    return self.base_model(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py\",\
          \ line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/root/.cache/huggingface/modules/transformers_modules/mpt-7b/modeling_mpt.py\"\
          , line 294, in forward\n    logits = F.linear(outputs.last_hidden_state,\
          \ self.transformer.wte.weight)\n</code></pre>\n"
        raw: "Make sure hidden state and wte weights are on same device when in parallel\
          \ model.\n\nBased on this:\nhttps://github.com/huggingface/transformers/blob/3ec7a47664ebe40c40f4b722f6bb1cd30c3821ec/src/transformers/models/gpt2/modeling_gpt2.py#L1093\
          \ \n\nThis should fix the following crash when running qlora:\n\n```\nTraceback\
          \ (most recent call last):\n  File \"/code/qlora/qlora.py\", line 758, in\
          \ <module>\n    train()\n  File \"/code/qlora/qlora.py\", line 720, in train\n\
          \    train_result = trainer.train(resume_from_checkpoint=checkpoint_dir)\n\
          \  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 1696, in train\n    return inner_training_loop(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 1973, in _inner_training_loop\n    tr_loss_step = self.training_step(model,\
          \ inputs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 2787, in training_step\n    loss = self.compute_loss(model, inputs)\n\
          \  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
          , line 2819, in compute_loss\n    outputs = model(**inputs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/opt/conda/lib/python3.10/site-packages/peft/peft_model.py\", line\
          \ 686, in forward\n    return self.base_model(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n \
          \ File \"/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py\",\
          \ line 165, in new_forward\n    output = old_forward(*args, **kwargs)\n\
          \  File \"/root/.cache/huggingface/modules/transformers_modules/mpt-7b/modeling_mpt.py\"\
          , line 294, in forward\n    logits = F.linear(outputs.last_hidden_state,\
          \ self.transformer.wte.weight)\n```"
        updatedAt: '2023-05-27T15:06:39.857Z'
      numEdits: 1
      reactions: []
    id: 647219ae5afd6a6965831071
    type: comment
  author: muelletm
  content: "Make sure hidden state and wte weights are on same device when in parallel\
    \ model.\n\nBased on this:\nhttps://github.com/huggingface/transformers/blob/3ec7a47664ebe40c40f4b722f6bb1cd30c3821ec/src/transformers/models/gpt2/modeling_gpt2.py#L1093\
    \ \n\nThis should fix the following crash when running qlora:\n\n```\nTraceback\
    \ (most recent call last):\n  File \"/code/qlora/qlora.py\", line 758, in <module>\n\
    \    train()\n  File \"/code/qlora/qlora.py\", line 720, in train\n    train_result\
    \ = trainer.train(resume_from_checkpoint=checkpoint_dir)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 1696, in train\n    return inner_training_loop(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 1973, in _inner_training_loop\n    tr_loss_step = self.training_step(model,\
    \ inputs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\"\
    , line 2787, in training_step\n    loss = self.compute_loss(model, inputs)\n \
    \ File \"/opt/conda/lib/python3.10/site-packages/transformers/trainer.py\", line\
    \ 2819, in compute_loss\n    outputs = model(**inputs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /opt/conda/lib/python3.10/site-packages/peft/peft_model.py\", line 686, in forward\n\
    \    return self.base_model(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"\
    /opt/conda/lib/python3.10/site-packages/accelerate/hooks.py\", line 165, in new_forward\n\
    \    output = old_forward(*args, **kwargs)\n  File \"/root/.cache/huggingface/modules/transformers_modules/mpt-7b/modeling_mpt.py\"\
    , line 294, in forward\n    logits = F.linear(outputs.last_hidden_state, self.transformer.wte.weight)\n\
    ```"
  created_at: 2023-05-27 13:54:38+00:00
  edited: true
  hidden: false
  id: 647219ae5afd6a6965831071
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646410244848-5fce6464e80c09ad2760251c.jpeg?w=200&h=200&f=face
      fullname: "Thomas M\xFCller"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: muelletm
      type: user
    createdAt: '2023-05-27T14:59:54.000Z'
    data:
      oid: 28721e3af813215f032e0c09dd0e786b6ccf3ba6
      parents:
      - a5eab52c1c61c1d50a4e01428949f6ff90c73c48
      subject: Make sure hidden state and wte weights are on same device when in parallel
        model.
    id: 64721aea0000000000000000
    type: commit
  author: muelletm
  created_at: 2023-05-27 13:59:54+00:00
  id: 64721aea0000000000000000
  oid: 28721e3af813215f032e0c09dd0e786b6ccf3ba6
  summary: Make sure hidden state and wte weights are on same device when in parallel
    model.
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646410244848-5fce6464e80c09ad2760251c.jpeg?w=200&h=200&f=face
      fullname: "Thomas M\xFCller"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: muelletm
      type: user
    createdAt: '2023-05-27T15:05:31.000Z'
    data:
      edited: true
      editors:
      - muelletm
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646410244848-5fce6464e80c09ad2760251c.jpeg?w=200&h=200&f=face
          fullname: "Thomas M\xFCller"
          isHf: false
          isPro: false
          name: muelletm
          type: user
        html: '<p>[DELETED]</p>

          '
        raw: '[DELETED]'
        updatedAt: '2023-05-27T15:07:00.093Z'
      numEdits: 1
      reactions: []
      relatedEventId: 64721c3bc27f74a0eba2bbad
    id: 64721c3bc27f74a0eba2bbac
    type: comment
  author: muelletm
  content: '[DELETED]'
  created_at: 2023-05-27 14:05:31+00:00
  edited: true
  hidden: false
  id: 64721c3bc27f74a0eba2bbac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646410244848-5fce6464e80c09ad2760251c.jpeg?w=200&h=200&f=face
      fullname: "Thomas M\xFCller"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: muelletm
      type: user
    createdAt: '2023-05-27T15:05:31.000Z'
    data:
      status: open
    id: 64721c3bc27f74a0eba2bbad
    type: status-change
  author: muelletm
  created_at: 2023-05-27 14:05:31+00:00
  id: 64721c3bc27f74a0eba2bbad
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
      fullname: Vojtech Cekal
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: cekal
      type: user
    createdAt: '2023-05-27T18:30:05.000Z'
    data:
      edited: false
      editors:
      - cekal
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ebfd71ca08a72ba9ce6fe0/WEXOVko_Lgvq_Y8_Zlb4o.png?w=200&h=200&f=face
          fullname: Vojtech Cekal
          isHf: false
          isPro: true
          name: cekal
          type: user
        html: "<p>Hi, I've made the requested changes, try it now. Will also update\
          \ README. \U0001F44D</p>\n"
        raw: "Hi, I've made the requested changes, try it now. Will also update README.\
          \ \U0001F44D"
        updatedAt: '2023-05-27T18:30:05.506Z'
      numEdits: 0
      reactions: []
    id: 64724c2d5afd6a6965891c11
    type: comment
  author: cekal
  content: "Hi, I've made the requested changes, try it now. Will also update README.\
    \ \U0001F44D"
  created_at: 2023-05-27 17:30:05+00:00
  edited: false
  hidden: false
  id: 64724c2d5afd6a6965891c11
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646410244848-5fce6464e80c09ad2760251c.jpeg?w=200&h=200&f=face
      fullname: "Thomas M\xFCller"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: muelletm
      type: user
    createdAt: '2023-05-27T18:40:49.000Z'
    data:
      edited: true
      editors:
      - muelletm
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646410244848-5fce6464e80c09ad2760251c.jpeg?w=200&h=200&f=face
          fullname: "Thomas M\xFCller"
          isHf: false
          isPro: false
          name: muelletm
          type: user
        html: '<p>Thanks! (I don''t know if you saw the PR attached to this, I guess
          we can close it now?)</p>

          '
        raw: Thanks! (I don't know if you saw the PR attached to this, I guess we
          can close it now?)
        updatedAt: '2023-05-27T18:41:01.322Z'
      numEdits: 1
      reactions: []
    id: 64724eb197a75cc77ab58bb7
    type: comment
  author: muelletm
  content: Thanks! (I don't know if you saw the PR attached to this, I guess we can
    close it now?)
  created_at: 2023-05-27 17:40:49+00:00
  edited: true
  hidden: false
  id: 64724eb197a75cc77ab58bb7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646410244848-5fce6464e80c09ad2760251c.jpeg?w=200&h=200&f=face
      fullname: "Thomas M\xFCller"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: muelletm
      type: user
    createdAt: '2023-05-27T18:41:08.000Z'
    data:
      status: closed
    id: 64724ec4c27f74a0eba86010
    type: status-change
  author: muelletm
  created_at: 2023-05-27 17:41:08+00:00
  id: 64724ec4c27f74a0eba86010
  new_status: closed
  type: status-change
is_pull_request: true
merge_commit_oid: null
num: 2
repo_id: cekal/mpt-7b-peft-compatible
repo_type: model
status: closed
target_branch: refs/heads/main
title: qlora-support
