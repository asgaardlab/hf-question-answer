!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Aryanne
conflicting_files: null
created_at: 2023-10-12 15:50:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
      fullname: Aryanne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aryanne
      type: user
    createdAt: '2023-10-12T16:50:38.000Z'
    data:
      edited: false
      editors:
      - Aryanne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9269548058509827
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
          fullname: Aryanne
          isHf: false
          isPro: false
          name: Aryanne
          type: user
        html: '<p>can you do the same with mistral? </p>

          '
        raw: 'can you do the same with mistral? '
        updatedAt: '2023-10-12T16:50:38.253Z'
      numEdits: 0
      reactions: []
    id: 652823de591c20f2dec331fd
    type: comment
  author: Aryanne
  content: 'can you do the same with mistral? '
  created_at: 2023-10-12 15:50:38+00:00
  edited: false
  hidden: false
  id: 652823de591c20f2dec331fd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618969698200-noauth.png?w=200&h=200&f=face
      fullname: Princeton NLP group
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: princeton-nlp
      type: user
    createdAt: '2023-10-12T20:46:49.000Z'
    data:
      edited: false
      editors:
      - princeton-nlp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9588027596473694
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618969698200-noauth.png?w=200&h=200&f=face
          fullname: Princeton NLP group
          isHf: false
          isPro: false
          name: princeton-nlp
          type: user
        html: '<p>Yes, I think the idea applies to mistral. </p>

          '
        raw: 'Yes, I think the idea applies to mistral. '
        updatedAt: '2023-10-12T20:46:49.201Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\u2764\uFE0F"
        users:
        - appvoid
        - vasilee
        - Aryanne
        - JoshXT
        - khu
      - count: 3
        reaction: "\U0001F44D"
        users:
        - Aryanne
        - vasilee
        - khu
    id: 65285b399e472a150ef4d614
    type: comment
  author: princeton-nlp
  content: 'Yes, I think the idea applies to mistral. '
  created_at: 2023-10-12 19:46:49+00:00
  edited: false
  hidden: false
  id: 65285b399e472a150ef4d614
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a813dedbb9e28866a91b27/i2pGYzY1htiY-L3WFPSgl.jpeg?w=200&h=200&f=face
      fullname: appvoid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: appvoid
      type: user
    createdAt: '2023-10-13T04:04:02.000Z'
    data:
      edited: false
      editors:
      - appvoid
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9900652766227722
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a813dedbb9e28866a91b27/i2pGYzY1htiY-L3WFPSgl.jpeg?w=200&h=200&f=face
          fullname: appvoid
          isHf: false
          isPro: false
          name: appvoid
          type: user
        html: '<p>I''m really excited to see where this goes!</p>

          '
        raw: I'm really excited to see where this goes!
        updatedAt: '2023-10-13T04:04:02.060Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Aryanne
    id: 6528c1b2bb31f9ed0c89af28
    type: comment
  author: appvoid
  content: I'm really excited to see where this goes!
  created_at: 2023-10-13 03:04:02+00:00
  edited: false
  hidden: false
  id: 6528c1b2bb31f9ed0c89af28
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/895f7245c0e03f23e737900bd3e47aa2.svg
      fullname: Vasile Ermicioi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vasilee
      type: user
    createdAt: '2023-10-13T06:54:58.000Z'
    data:
      edited: false
      editors:
      - vasilee
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9333778023719788
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/895f7245c0e03f23e737900bd3e47aa2.svg
          fullname: Vasile Ermicioi
          isHf: false
          isPro: false
          name: vasilee
          type: user
        html: '<blockquote>

          <p>Yes, I think the idea applies to mistral.</p>

          </blockquote>

          <p>this model looks extremely good for a base model, I would like to see
          a fine-tuned version (e.g. OpenOrca),<br>for tasks like answering from the
          context (RAG), we don''t need big models,<br>so I would say a Mistral little
          brother with the same big context (32K) and architecture (Grouped-query
          attention and Sliding Window Attention) and fine-tuned to follow instructions
          (e.g. Mistral-7B-OpenOrca) is more than enough</p>

          '
        raw: '> Yes, I think the idea applies to mistral.


          this model looks extremely good for a base model, I would like to see a
          fine-tuned version (e.g. OpenOrca),

          for tasks like answering from the context (RAG), we don''t need big models,

          so I would say a Mistral little brother with the same big context (32K)
          and architecture (Grouped-query attention and Sliding Window Attention)
          and fine-tuned to follow instructions (e.g. Mistral-7B-OpenOrca) is more
          than enough

          '
        updatedAt: '2023-10-13T06:54:58.950Z'
      numEdits: 0
      reactions:
      - count: 7
        reaction: "\u2764\uFE0F"
        users:
        - Aryanne
        - appvoid
        - princeton-nlp
        - tkon99
        - JoshXT
        - carlfm01
        - khu
    id: 6528e9c264aaab7f8189b7e7
    type: comment
  author: vasilee
  content: '> Yes, I think the idea applies to mistral.


    this model looks extremely good for a base model, I would like to see a fine-tuned
    version (e.g. OpenOrca),

    for tasks like answering from the context (RAG), we don''t need big models,

    so I would say a Mistral little brother with the same big context (32K) and architecture
    (Grouped-query attention and Sliding Window Attention) and fine-tuned to follow
    instructions (e.g. Mistral-7B-OpenOrca) is more than enough

    '
  created_at: 2023-10-13 05:54:58+00:00
  edited: false
  hidden: false
  id: 6528e9c264aaab7f8189b7e7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: princeton-nlp/Sheared-LLaMA-2.7B
repo_type: model
status: open
target_branch: null
title: mistral
