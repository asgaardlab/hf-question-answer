!!python/object:huggingface_hub.community.DiscussionWithDetails
author: vanSamstroem
conflicting_files: null
created_at: 2023-04-24 20:35:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3dafb66d51cf0e1ebd86dda7daa1898c.svg
      fullname: DS
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vanSamstroem
      type: user
    createdAt: '2023-04-24T21:35:19.000Z'
    data:
      edited: true
      editors:
      - vanSamstroem
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3dafb66d51cf0e1ebd86dda7daa1898c.svg
          fullname: DS
          isHf: false
          isPro: false
          name: vanSamstroem
          type: user
        html: '<p>Thank you very much but what is the difference between these *.bin
          files?</p>

          <p>alpaca-lora-65B.GGML.q4_0.bin<br>alpaca-lora-65B.GGML.q4_2.bin<br>alpaca-lora-65B.GGML.q4_3.bin</p>

          <p>Downloaded this one "alpaca-lora-65B.GGML.q4_3.bin" because I thought
          it was the newest one but I can''t get it to work with "Alpaca Electron
          App" nor via Terminal with llama.cpp on M1 Max 64GB Macbook.  Failed to
          load model (bad f16 value 6)...</p>

          '
        raw: 'Thank you very much but what is the difference between these *.bin files?


          alpaca-lora-65B.GGML.q4_0.bin

          alpaca-lora-65B.GGML.q4_2.bin

          alpaca-lora-65B.GGML.q4_3.bin


          Downloaded this one "alpaca-lora-65B.GGML.q4_3.bin" because I thought it
          was the newest one but I can''t get it to work with "Alpaca Electron App"
          nor via Terminal with llama.cpp on M1 Max 64GB Macbook.  Failed to load
          model (bad f16 value 6)...'
        updatedAt: '2023-04-24T22:12:00.320Z'
      numEdits: 1
      reactions: []
    id: 6446f617bd9e0e0edf51f65c
    type: comment
  author: vanSamstroem
  content: 'Thank you very much but what is the difference between these *.bin files?


    alpaca-lora-65B.GGML.q4_0.bin

    alpaca-lora-65B.GGML.q4_2.bin

    alpaca-lora-65B.GGML.q4_3.bin


    Downloaded this one "alpaca-lora-65B.GGML.q4_3.bin" because I thought it was the
    newest one but I can''t get it to work with "Alpaca Electron App" nor via Terminal
    with llama.cpp on M1 Max 64GB Macbook.  Failed to load model (bad f16 value 6)...'
  created_at: 2023-04-24 20:35:19+00:00
  edited: true
  hidden: false
  id: 6446f617bd9e0e0edf51f65c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-25T07:59:18.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Sorry for the lack of explanation. I''ve now updated the README
          to explain.</p>

          <p>All of the files will require recent versions of llama.cpp to run. So
          it''s likely your app isn''t using a recent enough version of the llama.cpp
          code.</p>

          '
        raw: 'Sorry for the lack of explanation. I''ve now updated the README to explain.


          All of the files will require recent versions of llama.cpp to run. So it''s
          likely your app isn''t using a recent enough version of the llama.cpp code.'
        updatedAt: '2023-04-25T07:59:18.034Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64478856058f3572dd05c940
    id: 64478856058f3572dd05c93f
    type: comment
  author: TheBloke
  content: 'Sorry for the lack of explanation. I''ve now updated the README to explain.


    All of the files will require recent versions of llama.cpp to run. So it''s likely
    your app isn''t using a recent enough version of the llama.cpp code.'
  created_at: 2023-04-25 06:59:18+00:00
  edited: false
  hidden: false
  id: 64478856058f3572dd05c93f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-25T07:59:18.000Z'
    data:
      status: closed
    id: 64478856058f3572dd05c940
    type: status-change
  author: TheBloke
  created_at: 2023-04-25 06:59:18+00:00
  id: 64478856058f3572dd05c940
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3dafb66d51cf0e1ebd86dda7daa1898c.svg
      fullname: DS
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vanSamstroem
      type: user
    createdAt: '2023-04-25T08:29:36.000Z'
    data:
      edited: false
      editors:
      - vanSamstroem
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3dafb66d51cf0e1ebd86dda7daa1898c.svg
          fullname: DS
          isHf: false
          isPro: false
          name: vanSamstroem
          type: user
        html: '<p>Thank you very much!</p>

          '
        raw: Thank you very much!
        updatedAt: '2023-04-25T08:29:36.990Z'
      numEdits: 0
      reactions: []
    id: 64478f70058f3572dd066251
    type: comment
  author: vanSamstroem
  content: Thank you very much!
  created_at: 2023-04-25 07:29:36+00:00
  edited: false
  hidden: false
  id: 64478f70058f3572dd066251
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: TheBloke/alpaca-lora-65B-GGML
repo_type: model
status: closed
target_branch: null
title: What is the difference q4_0 / q4_2 / q4_3 ???
