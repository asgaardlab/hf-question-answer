!!python/object:huggingface_hub.community.DiscussionWithDetails
author: HGamal
conflicting_files: null
created_at: 2022-09-04 02:34:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2015ecd90fe947f819aef39dfb76f957.svg
      fullname: Heba Gamal El-Din
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HGamal
      type: user
    createdAt: '2022-09-04T03:34:17.000Z'
    data:
      edited: false
      editors:
      - HGamal
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2015ecd90fe947f819aef39dfb76f957.svg
          fullname: Heba Gamal El-Din
          isHf: false
          isPro: false
          name: HGamal
          type: user
        html: '<p>Hey, I''m trying to train a handwritten arabic OCR using ArOCR and
          trOCR-Ar-small, but the preprocessor doesn''t load so I used "giganticode/roberta-base-ar_miner"
          as the tokenizer.<br>When I check the validation set predictions it''s all
          like a repeated garbage as shown.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1662262431507-63141b29e29fb2e86d63a608.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1662262431507-63141b29e29fb2e86d63a608.png"></a></p>

          <p>here''s my loadings:<br>def load_model(from_disk: bool) -&gt; VisionEncoderDecoderModel:<br>    model:
          VisionEncoderDecoderModel = VisionEncoderDecoderModel.from_pretrained(''gagan3012/TrOCR-Ar-Small'')#.from_encoder_decoder_pretrained("google/vit-base-patch16-224-in21k",
          "giganticode/roberta-base-ar_miner")#<br>    print(f"Using device {device}.")<br>    model.to(device)<br>    return
          model</p>

          <p>def init_model_for_training(model: VisionEncoderDecoderModel, processor:
          TrOCRProcessor):<br>    model.config.decoder_start_token_id = processor.tokenizer.cls_token_id<br>    model.config.pad_token_id
          = processor.tokenizer.pad_token_id<br>    model.config.vocab_size = model.config.decoder.vocab_size<br>    model.config.bos_token_id
          = processor.tokenizer.bos_token_id<br>    model.config.decoder_start_token_id
          = 0<br>    model.config.decoder.is_decoder = True<br>    model.config.decoder.add_cross_attention
          = True</p>

          <p>def load_processor() -&gt; TrOCRProcessor:<br>    feature_extractor=ViTFeatureExtractor.from_pretrained("google/vit-base-patch16-384")<br>    model_path
          = "giganticode/roberta-base-ar_miner"<br>    tokenizer = AutoTokenizer.from_pretrained(model_path)<br>    return
          TrOCRProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)</p>

          '
        raw: "Hey, I'm trying to train a handwritten arabic OCR using ArOCR and trOCR-Ar-small,\
          \ but the preprocessor doesn't load so I used \"giganticode/roberta-base-ar_miner\"\
          \ as the tokenizer. \r\nWhen I check the validation set predictions it's\
          \ all like a repeated garbage as shown.\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1662262431507-63141b29e29fb2e86d63a608.png)\r\
          \n\r\nhere's my loadings:\r\ndef load_model(from_disk: bool) -> VisionEncoderDecoderModel:\r\
          \n    model: VisionEncoderDecoderModel = VisionEncoderDecoderModel.from_pretrained('gagan3012/TrOCR-Ar-Small')#.from_encoder_decoder_pretrained(\"\
          google/vit-base-patch16-224-in21k\", \"giganticode/roberta-base-ar_miner\"\
          )#\r\n    print(f\"Using device {device}.\")\r\n    model.to(device)\r\n\
          \    return model\r\n\r\ndef init_model_for_training(model: VisionEncoderDecoderModel,\
          \ processor: TrOCRProcessor):\r\n    model.config.decoder_start_token_id\
          \ = processor.tokenizer.cls_token_id\r\n    model.config.pad_token_id =\
          \ processor.tokenizer.pad_token_id\r\n    model.config.vocab_size = model.config.decoder.vocab_size\r\
          \n    model.config.bos_token_id = processor.tokenizer.bos_token_id\r\n \
          \   model.config.decoder_start_token_id = 0\r\n    model.config.decoder.is_decoder\
          \ = True\r\n    model.config.decoder.add_cross_attention = True\r\n\r\n\r\
          \ndef load_processor() -> TrOCRProcessor:\r\n    feature_extractor=ViTFeatureExtractor.from_pretrained(\"\
          google/vit-base-patch16-384\")\r\n    model_path = \"giganticode/roberta-base-ar_miner\"\
          \r\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\r\n    return\
          \ TrOCRProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)\r\
          \n"
        updatedAt: '2022-09-04T03:34:17.395Z'
      numEdits: 0
      reactions: []
    id: 63141cb917838d05195326c4
    type: comment
  author: HGamal
  content: "Hey, I'm trying to train a handwritten arabic OCR using ArOCR and trOCR-Ar-small,\
    \ but the preprocessor doesn't load so I used \"giganticode/roberta-base-ar_miner\"\
    \ as the tokenizer. \r\nWhen I check the validation set predictions it's all like\
    \ a repeated garbage as shown.\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1662262431507-63141b29e29fb2e86d63a608.png)\r\
    \n\r\nhere's my loadings:\r\ndef load_model(from_disk: bool) -> VisionEncoderDecoderModel:\r\
    \n    model: VisionEncoderDecoderModel = VisionEncoderDecoderModel.from_pretrained('gagan3012/TrOCR-Ar-Small')#.from_encoder_decoder_pretrained(\"\
    google/vit-base-patch16-224-in21k\", \"giganticode/roberta-base-ar_miner\")#\r\
    \n    print(f\"Using device {device}.\")\r\n    model.to(device)\r\n    return\
    \ model\r\n\r\ndef init_model_for_training(model: VisionEncoderDecoderModel, processor:\
    \ TrOCRProcessor):\r\n    model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\r\
    \n    model.config.pad_token_id = processor.tokenizer.pad_token_id\r\n    model.config.vocab_size\
    \ = model.config.decoder.vocab_size\r\n    model.config.bos_token_id = processor.tokenizer.bos_token_id\r\
    \n    model.config.decoder_start_token_id = 0\r\n    model.config.decoder.is_decoder\
    \ = True\r\n    model.config.decoder.add_cross_attention = True\r\n\r\n\r\ndef\
    \ load_processor() -> TrOCRProcessor:\r\n    feature_extractor=ViTFeatureExtractor.from_pretrained(\"\
    google/vit-base-patch16-384\")\r\n    model_path = \"giganticode/roberta-base-ar_miner\"\
    \r\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\r\n    return TrOCRProcessor(feature_extractor=feature_extractor,\
    \ tokenizer=tokenizer)\r\n"
  created_at: 2022-09-04 02:34:17+00:00
  edited: false
  hidden: false
  id: 63141cb917838d05195326c4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: gagan3012/ArOCR
repo_type: model
status: open
target_branch: null
title: what preprocessor should I use to train the handwritten arabic ocr on this
  base of ArOCR model?
