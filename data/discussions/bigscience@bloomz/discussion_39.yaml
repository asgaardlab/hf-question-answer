!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Charm3link
conflicting_files: null
created_at: 2023-03-15 20:10:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666122903077-noauth.png?w=200&h=200&f=face
      fullname: Connor Harmelink
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Charm3link
      type: user
    createdAt: '2023-03-15T21:10:05.000Z'
    data:
      edited: false
      editors:
      - Charm3link
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666122903077-noauth.png?w=200&h=200&f=face
          fullname: Connor Harmelink
          isHf: false
          isPro: false
          name: Charm3link
          type: user
        html: '<p>T5, BERT, and many other models seem to have strict limits on their
          input lengths. I haven''t seen this discussed for Bloomz or Mt0, and they
          seem to handle very long inputs. Is there a hard limit like the other models
          I mentioned, or is it only limited by the hardware running the models? </p>

          '
        raw: 'T5, BERT, and many other models seem to have strict limits on their
          input lengths. I haven''t seen this discussed for Bloomz or Mt0, and they
          seem to handle very long inputs. Is there a hard limit like the other models
          I mentioned, or is it only limited by the hardware running the models? '
        updatedAt: '2023-03-15T21:10:05.420Z'
      numEdits: 0
      reactions: []
    id: 6412342dac08ffb7079220cf
    type: comment
  author: Charm3link
  content: 'T5, BERT, and many other models seem to have strict limits on their input
    lengths. I haven''t seen this discussed for Bloomz or Mt0, and they seem to handle
    very long inputs. Is there a hard limit like the other models I mentioned, or
    is it only limited by the hardware running the models? '
  created_at: 2023-03-15 20:10:05+00:00
  edited: false
  hidden: false
  id: 6412342dac08ffb7079220cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2023-03-15T21:34:22.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<p>For BLOOMZ models it''s unlimited due to their alibi position embeddings,
          tho I havn''t done/seen an evaluation of how well it works for contexts
          &gt; 2048 tokens.<br>For mT0 models, it''s 512 tokens max input length like
          for mT5 / T5.</p>

          '
        raw: 'For BLOOMZ models it''s unlimited due to their alibi position embeddings,
          tho I havn''t done/seen an evaluation of how well it works for contexts
          > 2048 tokens.

          For mT0 models, it''s 512 tokens max input length like for mT5 / T5.'
        updatedAt: '2023-03-15T21:34:22.987Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Charm3link
        - kujakey
    id: 641239deed3c91c5e9e0cba3
    type: comment
  author: Muennighoff
  content: 'For BLOOMZ models it''s unlimited due to their alibi position embeddings,
    tho I havn''t done/seen an evaluation of how well it works for contexts > 2048
    tokens.

    For mT0 models, it''s 512 tokens max input length like for mT5 / T5.'
  created_at: 2023-03-15 20:34:22+00:00
  edited: false
  hidden: false
  id: 641239deed3c91c5e9e0cba3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666122903077-noauth.png?w=200&h=200&f=face
      fullname: Connor Harmelink
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Charm3link
      type: user
    createdAt: '2023-03-28T19:04:43.000Z'
    data:
      status: closed
    id: 64233a4b5aed4fac78a015b9
    type: status-change
  author: Charm3link
  created_at: 2023-03-28 18:04:43+00:00
  id: 64233a4b5aed4fac78a015b9
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 39
repo_id: bigscience/bloomz
repo_type: model
status: closed
target_branch: null
title: What is the maximum input length for Bloomz and MT0?
