!!python/object:huggingface_hub.community.DiscussionWithDetails
author: micole66
conflicting_files: null
created_at: 2022-12-01 19:20:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60322794e8149a962412a67a/OnLOF_23u0C7PXtATznTw.jpeg?w=200&h=200&f=face
      fullname: Micole Bellocchio
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: micole66
      type: user
    createdAt: '2022-12-01T19:20:15.000Z'
    data:
      edited: false
      editors:
      - micole66
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60322794e8149a962412a67a/OnLOF_23u0C7PXtATznTw.jpeg?w=200&h=200&f=face
          fullname: Micole Bellocchio
          isHf: false
          isPro: false
          name: micole66
          type: user
        html: '<p>Whyyyyyyyyyyyyyyyyyyyyyyyyyy?</p>

          '
        raw: Whyyyyyyyyyyyyyyyyyyyyyyyyyy?
        updatedAt: '2022-12-01T19:20:15.851Z'
      numEdits: 0
      reactions: []
    id: 6388fe6f43d8b0797a0a4313
    type: comment
  author: micole66
  content: Whyyyyyyyyyyyyyyyyyyyyyyyyyy?
  created_at: 2022-12-01 19:20:15+00:00
  edited: false
  hidden: false
  id: 6388fe6f43d8b0797a0a4313
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2022-12-01T19:44:56.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<blockquote>

          <p>Whyyyyyyyyyyyyyyyyyyyyyyyyyy?</p>

          </blockquote>

          <p>It costs ~30K  USD / month to keep up the inference widget, so we decided
          to turn it off after the first month. Really sorry :(<br>You can of course
          still download the model and run it on your own hardware if you have the
          resources available.</p>

          '
        raw: "> Whyyyyyyyyyyyyyyyyyyyyyyyyyy?\n\nIt costs ~30K  USD / month to keep\
          \ up the inference widget, so we decided to turn it off after the first\
          \ month. Really sorry :( \nYou can of course still download the model and\
          \ run it on your own hardware if you have the resources available."
        updatedAt: '2022-12-01T19:44:56.969Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F92F"
        users:
        - yahma
    id: 63890438c0b95b2c293872f9
    type: comment
  author: Muennighoff
  content: "> Whyyyyyyyyyyyyyyyyyyyyyyyyyy?\n\nIt costs ~30K  USD / month to keep\
    \ up the inference widget, so we decided to turn it off after the first month.\
    \ Really sorry :( \nYou can of course still download the model and run it on your\
    \ own hardware if you have the resources available."
  created_at: 2022-12-01 19:44:56+00:00
  edited: false
  hidden: false
  id: 63890438c0b95b2c293872f9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60322794e8149a962412a67a/OnLOF_23u0C7PXtATznTw.jpeg?w=200&h=200&f=face
      fullname: Micole Bellocchio
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: micole66
      type: user
    createdAt: '2022-12-01T20:52:17.000Z'
    data:
      edited: false
      editors:
      - micole66
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60322794e8149a962412a67a/OnLOF_23u0C7PXtATznTw.jpeg?w=200&h=200&f=face
          fullname: Micole Bellocchio
          isHf: false
          isPro: false
          name: micole66
          type: user
        html: '<p>oh no</p>

          '
        raw: oh no
        updatedAt: '2022-12-01T20:52:17.378Z'
      numEdits: 0
      reactions: []
    id: 6389140143d8b0797a0b0290
    type: comment
  author: micole66
  content: oh no
  created_at: 2022-12-01 20:52:17+00:00
  edited: false
  hidden: false
  id: 6389140143d8b0797a0b0290
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/495da69fc13e4ba3fc8c57ea753127cf.svg
      fullname: lewiswu1209
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lewiswu1209
      type: user
    createdAt: '2022-12-02T11:50:11.000Z'
    data:
      edited: false
      editors:
      - lewiswu1209
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/495da69fc13e4ba3fc8c57ea753127cf.svg
          fullname: lewiswu1209
          isHf: false
          isPro: false
          name: lewiswu1209
          type: user
        html: '<p>I like it more than bloom</p>

          '
        raw: I like it more than bloom
        updatedAt: '2022-12-02T11:50:11.975Z'
      numEdits: 0
      reactions: []
    id: 6389e67356f8a656a3c7c503
    type: comment
  author: lewiswu1209
  content: I like it more than bloom
  created_at: 2022-12-02 11:50:11+00:00
  edited: false
  hidden: false
  id: 6389e67356f8a656a3c7c503
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60322794e8149a962412a67a/OnLOF_23u0C7PXtATznTw.jpeg?w=200&h=200&f=face
      fullname: Micole Bellocchio
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: micole66
      type: user
    createdAt: '2022-12-02T12:20:44.000Z'
    data:
      edited: false
      editors:
      - micole66
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60322794e8149a962412a67a/OnLOF_23u0C7PXtATznTw.jpeg?w=200&h=200&f=face
          fullname: Micole Bellocchio
          isHf: false
          isPro: false
          name: micole66
          type: user
        html: '<blockquote>

          <p>I like it more than bloom</p>

          </blockquote>

          <p>Same</p>

          '
        raw: '> I like it more than bloom


          Same'
        updatedAt: '2022-12-02T12:20:44.544Z'
      numEdits: 0
      reactions: []
    id: 6389ed9c92ad533329bf2eaf
    type: comment
  author: micole66
  content: '> I like it more than bloom


    Same'
  created_at: 2022-12-02 12:20:44+00:00
  edited: false
  hidden: false
  id: 6389ed9c92ad533329bf2eaf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a543d6e201fc08cce30b562673a68566.svg
      fullname: Yoan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yonow
      type: user
    createdAt: '2022-12-02T14:07:36.000Z'
    data:
      edited: false
      editors:
      - yonow
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a543d6e201fc08cce30b562673a68566.svg
          fullname: Yoan
          isHf: false
          isPro: false
          name: yonow
          type: user
        html: "<p>NOOOOOOOOOO \U0001F62D</p>\n"
        raw: "NOOOOOOOOOO \U0001F62D"
        updatedAt: '2022-12-02T14:07:36.948Z'
      numEdits: 0
      reactions: []
    id: 638a06a8043fc0ee61b110ec
    type: comment
  author: yonow
  content: "NOOOOOOOOOO \U0001F62D"
  created_at: 2022-12-02 14:07:36+00:00
  edited: false
  hidden: false
  id: 638a06a8043fc0ee61b110ec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2022-12-02T21:48:24.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: "<p>:(<br>On the bright side <a href=\"https://huggingface.co/bigscience/mt0-xxl\"\
          >mt0-xxl</a> &amp; <a href=\"https://huggingface.co/bigscience/mt0-xxl-mt\"\
          >mt0-xxl-mt</a> can still be used via the inference widget. \U0001F917</p>\n\
          <p>Definitely share if you find them more / less useful &amp; if so why\
          \ \U0001F9D0<br>In my experiments I found them better at following instructions\
          \ requiring short answers &amp; worse at instructions requiring long answers.</p>\n"
        raw: ":(\nOn the bright side [mt0-xxl](https://huggingface.co/bigscience/mt0-xxl)\
          \ & [mt0-xxl-mt](https://huggingface.co/bigscience/mt0-xxl-mt) can still\
          \ be used via the inference widget. \U0001F917\n\nDefinitely share if you\
          \ find them more / less useful & if so why \U0001F9D0\nIn my experiments\
          \ I found them better at following instructions requiring short answers\
          \ & worse at instructions requiring long answers."
        updatedAt: '2022-12-02T21:48:24.630Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - julien-c
        - pedevineau
    id: 638a72a80f10aa3064f13fda
    type: comment
  author: Muennighoff
  content: ":(\nOn the bright side [mt0-xxl](https://huggingface.co/bigscience/mt0-xxl)\
    \ & [mt0-xxl-mt](https://huggingface.co/bigscience/mt0-xxl-mt) can still be used\
    \ via the inference widget. \U0001F917\n\nDefinitely share if you find them more\
    \ / less useful & if so why \U0001F9D0\nIn my experiments I found them better\
    \ at following instructions requiring short answers & worse at instructions requiring\
    \ long answers."
  created_at: 2022-12-02 21:48:24+00:00
  edited: false
  hidden: false
  id: 638a72a80f10aa3064f13fda
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/495da69fc13e4ba3fc8c57ea753127cf.svg
      fullname: lewiswu1209
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lewiswu1209
      type: user
    createdAt: '2022-12-03T17:08:04.000Z'
    data:
      edited: false
      editors:
      - lewiswu1209
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/495da69fc13e4ba3fc8c57ea753127cf.svg
          fullname: lewiswu1209
          isHf: false
          isPro: false
          name: lewiswu1209
          type: user
        html: "<blockquote>\n<p>:(<br>On the bright side <a href=\"https://huggingface.co/bigscience/mt0-xxl\"\
          >mt0-xxl</a> &amp; <a href=\"https://huggingface.co/bigscience/mt0-xxl-mt\"\
          >mt0-xxl-mt</a> can still be used via the inference widget. \U0001F917</p>\n\
          <p>Definitely share if you find them more / less useful &amp; if so why\
          \ \U0001F9D0<br>In my experiments I found them better at following instructions\
          \ requiring short answers &amp; worse at instructions requiring long answers.</p>\n\
          </blockquote>\n<p>Bloomz know when to stop, Bloom don't.</p>\n"
        raw: "> :(\n> On the bright side [mt0-xxl](https://huggingface.co/bigscience/mt0-xxl)\
          \ & [mt0-xxl-mt](https://huggingface.co/bigscience/mt0-xxl-mt) can still\
          \ be used via the inference widget. \U0001F917\n> \n> Definitely share if\
          \ you find them more / less useful & if so why \U0001F9D0\n> In my experiments\
          \ I found them better at following instructions requiring short answers\
          \ & worse at instructions requiring long answers.\n\nBloomz know when to\
          \ stop, Bloom don't."
        updatedAt: '2022-12-03T17:08:04.688Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Muennighoff
    id: 638b82747f62078b2a754abf
    type: comment
  author: lewiswu1209
  content: "> :(\n> On the bright side [mt0-xxl](https://huggingface.co/bigscience/mt0-xxl)\
    \ & [mt0-xxl-mt](https://huggingface.co/bigscience/mt0-xxl-mt) can still be used\
    \ via the inference widget. \U0001F917\n> \n> Definitely share if you find them\
    \ more / less useful & if so why \U0001F9D0\n> In my experiments I found them\
    \ better at following instructions requiring short answers & worse at instructions\
    \ requiring long answers.\n\nBloomz know when to stop, Bloom don't."
  created_at: 2022-12-03 17:08:04+00:00
  edited: false
  hidden: false
  id: 638b82747f62078b2a754abf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6375860de3413701a9eef992/oKngiohHerShFMpW9VSQb.png?w=200&h=200&f=face
      fullname: Ryan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Robo0890
      type: user
    createdAt: '2022-12-05T04:05:58.000Z'
    data:
      edited: true
      editors:
      - Robo0890
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6375860de3413701a9eef992/oKngiohHerShFMpW9VSQb.png?w=200&h=200&f=face
          fullname: Ryan
          isHf: false
          isPro: false
          name: Robo0890
          type: user
        html: '<p>I also found that Bloomz almost stopped too soon. When summarizing
          text, it ended after a single sentence. And since it only generated one
          sentence, it was never given the opportunity to follow the prompt. I honestly
          found Bloom more helpful. It could respond to longer prompts well, especially
          few shot prompts. But Bloomz seems to only work with short Q and A prompts.
          I do have hope that if it keeps getting better, Bloomz will become more
          diverse in capability.</p>

          '
        raw: I also found that Bloomz almost stopped too soon. When summarizing text,
          it ended after a single sentence. And since it only generated one sentence,
          it was never given the opportunity to follow the prompt. I honestly found
          Bloom more helpful. It could respond to longer prompts well, especially
          few shot prompts. But Bloomz seems to only work with short Q and A prompts.
          I do have hope that if it keeps getting better, Bloomz will become more
          diverse in capability.
        updatedAt: '2022-12-05T04:06:45.108Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Muennighoff
        - yahma
    id: 638d6e265982970665597178
    type: comment
  author: Robo0890
  content: I also found that Bloomz almost stopped too soon. When summarizing text,
    it ended after a single sentence. And since it only generated one sentence, it
    was never given the opportunity to follow the prompt. I honestly found Bloom more
    helpful. It could respond to longer prompts well, especially few shot prompts.
    But Bloomz seems to only work with short Q and A prompts. I do have hope that
    if it keeps getting better, Bloomz will become more diverse in capability.
  created_at: 2022-12-05 04:05:58+00:00
  edited: true
  hidden: false
  id: 638d6e265982970665597178
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/495da69fc13e4ba3fc8c57ea753127cf.svg
      fullname: lewiswu1209
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lewiswu1209
      type: user
    createdAt: '2022-12-05T04:59:15.000Z'
    data:
      edited: false
      editors:
      - lewiswu1209
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/495da69fc13e4ba3fc8c57ea753127cf.svg
          fullname: lewiswu1209
          isHf: false
          isPro: false
          name: lewiswu1209
          type: user
        html: '<blockquote>

          <p>I also found that Bloomz almost stopped too soon. When summarizing text,
          it ended after a single sentence. And since it only generated one sentence,
          it was never given the opportunity to follow the prompt. I honestly found
          Bloom more helpful. It could respond to longer prompts well, especially
          few shot prompts. But Bloomz seems to only work with short Q and A prompts.
          I do have hope that if it keeps getting better, Bloomz will become more
          diverse in capability.</p>

          </blockquote>

          <p>Because of XP3 dataset i think. Most of the answers in this dataset are
          short.</p>

          '
        raw: '> I also found that Bloomz almost stopped too soon. When summarizing
          text, it ended after a single sentence. And since it only generated one
          sentence, it was never given the opportunity to follow the prompt. I honestly
          found Bloom more helpful. It could respond to longer prompts well, especially
          few shot prompts. But Bloomz seems to only work with short Q and A prompts.
          I do have hope that if it keeps getting better, Bloomz will become more
          diverse in capability.


          Because of XP3 dataset i think. Most of the answers in this dataset are
          short.'
        updatedAt: '2022-12-05T04:59:15.203Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Muennighoff
    id: 638d7aa39fd4474f0a276c36
    type: comment
  author: lewiswu1209
  content: '> I also found that Bloomz almost stopped too soon. When summarizing text,
    it ended after a single sentence. And since it only generated one sentence, it
    was never given the opportunity to follow the prompt. I honestly found Bloom more
    helpful. It could respond to longer prompts well, especially few shot prompts.
    But Bloomz seems to only work with short Q and A prompts. I do have hope that
    if it keeps getting better, Bloomz will become more diverse in capability.


    Because of XP3 dataset i think. Most of the answers in this dataset are short.'
  created_at: 2022-12-05 04:59:15+00:00
  edited: false
  hidden: false
  id: 638d7aa39fd4474f0a276c36
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
      fullname: Thomas Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TimeRobber
      type: user
    createdAt: '2022-12-05T05:33:48.000Z'
    data:
      status: closed
    id: 638d82bc9fd4474f0a27a2e9
    type: status-change
  author: TimeRobber
  created_at: 2022-12-05 05:33:48+00:00
  id: 638d82bc9fd4474f0a27a2e9
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3d6e4b4d02eda7b5ef28e1cc0fb8e08a.svg
      fullname: Thomas Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TimeRobber
      type: user
    createdAt: '2022-12-05T06:19:04.000Z'
    data:
      status: open
    id: 638d8d58df246d4e14855c86
    type: status-change
  author: TimeRobber
  created_at: 2022-12-05 06:19:04+00:00
  id: 638d8d58df246d4e14855c86
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1620133776745-noauth.jpeg?w=200&h=200&f=face
      fullname: Alexander Borzunov
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: borzunov
      type: user
    createdAt: '2023-01-18T01:29:59.000Z'
    data:
      edited: true
      editors:
      - borzunov
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1620133776745-noauth.jpeg?w=200&h=200&f=face
          fullname: Alexander Borzunov
          isHf: false
          isPro: false
          name: borzunov
          type: user
        html: '<p>Now you can run inference and fine-tune BLOOMZ (the 176B English
          version) using <a rel="nofollow" href="https://github.com/bigscience-workshop/petals">the
          Petals swarm</a>.</p>

          <p>You can use BLOOMZ via <a rel="nofollow" href="https://colab.research.google.com/drive/1Ervk6HPNS6AYVr3xVdQnY5a-TjjmLCdQ?usp=sharing">this
          Colab notebook</a> to get the inference speed of <strong>1-2 sec/token</strong>
          for a single sequence. Running the notebook on a local machine is also fine,
          you''d need only 10+ GB GPU memory or 12+ GB RAM (though it will be slower
          without a GPU).</p>

          <p>Note: Don''t forget to replace <code>bigscience/bloom-petals</code> with
          <code>bigscience/bloomz-petals</code> in the model name.</p>

          <p>As an example, there is a <a rel="nofollow" href="http://chat.petals.ml">chatbot
          app</a> running BLOOMZ this way.</p>

          '
        raw: 'Now you can run inference and fine-tune BLOOMZ (the 176B English version)
          using [the Petals swarm](https://github.com/bigscience-workshop/petals).


          You can use BLOOMZ via [this Colab notebook](https://colab.research.google.com/drive/1Ervk6HPNS6AYVr3xVdQnY5a-TjjmLCdQ?usp=sharing)
          to get the inference speed of **1-2 sec/token** for a single sequence. Running
          the notebook on a local machine is also fine, you''d need only 10+ GB GPU
          memory or 12+ GB RAM (though it will be slower without a GPU).


          Note: Don''t forget to replace `bigscience/bloom-petals` with `bigscience/bloomz-petals`
          in the model name.


          As an example, there is a [chatbot app](http://chat.petals.ml) running BLOOMZ
          this way.'
        updatedAt: '2023-01-18T02:04:19.068Z'
      numEdits: 29
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Muennighoff
    id: 63c74b972f651b67629541f1
    type: comment
  author: borzunov
  content: 'Now you can run inference and fine-tune BLOOMZ (the 176B English version)
    using [the Petals swarm](https://github.com/bigscience-workshop/petals).


    You can use BLOOMZ via [this Colab notebook](https://colab.research.google.com/drive/1Ervk6HPNS6AYVr3xVdQnY5a-TjjmLCdQ?usp=sharing)
    to get the inference speed of **1-2 sec/token** for a single sequence. Running
    the notebook on a local machine is also fine, you''d need only 10+ GB GPU memory
    or 12+ GB RAM (though it will be slower without a GPU).


    Note: Don''t forget to replace `bigscience/bloom-petals` with `bigscience/bloomz-petals`
    in the model name.


    As an example, there is a [chatbot app](http://chat.petals.ml) running BLOOMZ
    this way.'
  created_at: 2023-01-18 01:29:59+00:00
  edited: true
  hidden: false
  id: 63c74b972f651b67629541f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a093d63e7d1dda047039fc/QGpVSKuJLwl2EsiffCYML.jpeg?w=200&h=200&f=face
      fullname: Olivier Dehaene
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: olivierdehaene
      type: user
    createdAt: '2023-03-02T10:45:07.000Z'
    data:
      edited: true
      editors:
      - olivierdehaene
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62a093d63e7d1dda047039fc/QGpVSKuJLwl2EsiffCYML.jpeg?w=200&h=200&f=face
          fullname: Olivier Dehaene
          isHf: true
          isPro: false
          name: olivierdehaene
          type: user
        html: "<p>Bloomz is back and even stronger than before. You can now do token\
          \ streaming:</p>\n<p><code>pip install sseclient-py</code> (do NOT install\
          \ <code>sseclient</code>, be sure to install <code>sseclient-py</code>)</p>\n\
          <pre><code>import sseclient\nimport requests\n\nprompt = \"Why is the sky\
          \ blue? Explain in a detailled paragraph.\"\nparameters = {\"max_new_tokens\"\
          : 200, \"top_p\": 0.9, \"seed\": 0}\noptions = {\"use_cache\": False}\n\n\
          payload = {\"inputs\": prompt, \"stream\": True, \"parameters\": parameters,\
          \ \"options\": options}\n\nr = requests.post(\"https://api-inference.huggingface.co/models/bigscience/bloomz\"\
          , stream=True, json=payload)\nsse_client = sseclient.SSEClient(r)\n\nfor\
          \ i, event in enumerate(sse_client.events()):\n    print(i, event.data)\n\
          </code></pre>\n"
        raw: "Bloomz is back and even stronger than before. You can now do token streaming:\n\
          \n`pip install sseclient-py` (do NOT install `sseclient`, be sure to install\
          \ `sseclient-py`)\n\n```\nimport sseclient\nimport requests\n\nprompt =\
          \ \"Why is the sky blue? Explain in a detailled paragraph.\"\nparameters\
          \ = {\"max_new_tokens\": 200, \"top_p\": 0.9, \"seed\": 0}\noptions = {\"\
          use_cache\": False}\n\npayload = {\"inputs\": prompt, \"stream\": True,\
          \ \"parameters\": parameters, \"options\": options}\n\nr = requests.post(\"\
          https://api-inference.huggingface.co/models/bigscience/bloomz\", stream=True,\
          \ json=payload)\nsse_client = sseclient.SSEClient(r)\n\nfor i, event in\
          \ enumerate(sse_client.events()):\n    print(i, event.data)\n```"
        updatedAt: '2023-03-02T10:53:17.715Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Muennighoff
    id: 64007e332a6805d272d67a47
    type: comment
  author: olivierdehaene
  content: "Bloomz is back and even stronger than before. You can now do token streaming:\n\
    \n`pip install sseclient-py` (do NOT install `sseclient`, be sure to install `sseclient-py`)\n\
    \n```\nimport sseclient\nimport requests\n\nprompt = \"Why is the sky blue? Explain\
    \ in a detailled paragraph.\"\nparameters = {\"max_new_tokens\": 200, \"top_p\"\
    : 0.9, \"seed\": 0}\noptions = {\"use_cache\": False}\n\npayload = {\"inputs\"\
    : prompt, \"stream\": True, \"parameters\": parameters, \"options\": options}\n\
    \nr = requests.post(\"https://api-inference.huggingface.co/models/bigscience/bloomz\"\
    , stream=True, json=payload)\nsse_client = sseclient.SSEClient(r)\n\nfor i, event\
    \ in enumerate(sse_client.events()):\n    print(i, event.data)\n```"
  created_at: 2023-03-02 10:45:07+00:00
  edited: true
  hidden: false
  id: 64007e332a6805d272d67a47
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 21
repo_id: bigscience/bloomz
repo_type: model
status: open
target_branch: null
title: No longer available, why?
