!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mishavee
conflicting_files: null
created_at: 2022-11-06 17:07:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2022-11-06T17:07:05.000Z'
    data:
      edited: false
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>Does the system have 2048 tokens? How many words is that approximately?
          </p>

          '
        raw: 'Does the system have 2048 tokens? How many words is that approximately? '
        updatedAt: '2022-11-06T17:07:05.965Z'
      numEdits: 0
      reactions: []
    id: 6367e9b9468567a2e42a67c2
    type: comment
  author: mishavee
  content: 'Does the system have 2048 tokens? How many words is that approximately? '
  created_at: 2022-11-06 17:07:05+00:00
  edited: false
  hidden: false
  id: 6367e9b9468567a2e42a67c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2022-11-06T18:55:06.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<p>yes &amp; 2048 ~ 1500 words<br>(<a rel="nofollow" href="https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them">https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them</a>)</p>

          '
        raw: 'yes & 2048 ~ 1500 words

          (https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)'
        updatedAt: '2022-11-06T18:55:06.610Z'
      numEdits: 0
      reactions: []
    id: 6368030a46919b9619bcdd06
    type: comment
  author: Muennighoff
  content: 'yes & 2048 ~ 1500 words

    (https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)'
  created_at: 2022-11-06 18:55:06+00:00
  edited: false
  hidden: false
  id: 6368030a46919b9619bcdd06
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2022-11-06T19:05:26.000Z'
    data:
      edited: false
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>Is that total for both prompt and completion? Gpt3 seems to allow
          4097 tokens total. Is it the same here?</p>

          '
        raw: Is that total for both prompt and completion? Gpt3 seems to allow 4097
          tokens total. Is it the same here?
        updatedAt: '2022-11-06T19:05:26.757Z'
      numEdits: 0
      reactions: []
    id: 63680576468567a2e42b7b0a
    type: comment
  author: mishavee
  content: Is that total for both prompt and completion? Gpt3 seems to allow 4097
    tokens total. Is it the same here?
  created_at: 2022-11-06 19:05:26+00:00
  edited: false
  hidden: false
  id: 63680576468567a2e42b7b0a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2022-11-06T20:27:12.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<p>Technically you can do much more than 2048 of tokens with bloom
          &amp; bloomz as we use Alibi position embeddings, but havn''t done experiments
          on that yet</p>

          '
        raw: Technically you can do much more than 2048 of tokens with bloom & bloomz
          as we use Alibi position embeddings, but havn't done experiments on that
          yet
        updatedAt: '2022-11-06T20:27:12.764Z'
      numEdits: 0
      reactions: []
    id: 636818a0f280c3616a40fb16
    type: comment
  author: Muennighoff
  content: Technically you can do much more than 2048 of tokens with bloom & bloomz
    as we use Alibi position embeddings, but havn't done experiments on that yet
  created_at: 2022-11-06 20:27:12+00:00
  edited: false
  hidden: false
  id: 636818a0f280c3616a40fb16
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
      fullname: Mike Vinitsky
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mishavee
      type: user
    createdAt: '2022-11-06T20:42:48.000Z'
    data:
      edited: false
      editors:
      - mishavee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/474bab3ba399fa7861ae098f6e4b3901.svg
          fullname: Mike Vinitsky
          isHf: false
          isPro: false
          name: mishavee
          type: user
        html: '<p>what is alibi position embeddings? </p>

          <p>what is approximate limit with it?</p>

          '
        raw: "what is alibi position embeddings? \n\nwhat is approximate limit with\
          \ it?"
        updatedAt: '2022-11-06T20:42:48.899Z'
      numEdits: 0
      reactions: []
    id: 63681c48cca0a0a962bf77a9
    type: comment
  author: mishavee
  content: "what is alibi position embeddings? \n\nwhat is approximate limit with\
    \ it?"
  created_at: 2022-11-06 20:42:48+00:00
  edited: false
  hidden: false
  id: 63681c48cca0a0a962bf77a9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: bigscience/bloomz
repo_type: model
status: open
target_branch: null
title: tokens
