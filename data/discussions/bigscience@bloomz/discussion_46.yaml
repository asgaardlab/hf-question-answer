!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Cyrile
conflicting_files: null
created_at: 2023-08-04 11:38:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1634332912347-noauth.png?w=200&h=200&f=face
      fullname: Cyrile Delestre
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cyrile
      type: user
    createdAt: '2023-08-04T12:38:01.000Z'
    data:
      edited: false
      editors:
      - Cyrile
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9527469873428345
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1634332912347-noauth.png?w=200&h=200&f=face
          fullname: Cyrile Delestre
          isHf: false
          isPro: false
          name: Cyrile
          type: user
        html: '<p>Hello, I have a technical question. It''s about training for text
          generation in a causal manner. I noticed that the training objective is
          cross-entropy based on a simple shift of the input_ids. However, the attention
          mechanism is causal thanks to the mask, but the feed-forward part is non-causal,
          am I correct? Therefore, isn''t the way the model is trained in the HuggingFace
          library incorrect? Shouldn''t we apply cross-entropy only on the prediction
          of the last token or also put a causal-mask on the MLP part?</p>

          '
        raw: Hello, I have a technical question. It's about training for text generation
          in a causal manner. I noticed that the training objective is cross-entropy
          based on a simple shift of the input_ids. However, the attention mechanism
          is causal thanks to the mask, but the feed-forward part is non-causal, am
          I correct? Therefore, isn't the way the model is trained in the HuggingFace
          library incorrect? Shouldn't we apply cross-entropy only on the prediction
          of the last token or also put a causal-mask on the MLP part?
        updatedAt: '2023-08-04T12:38:01.433Z'
      numEdits: 0
      reactions: []
    id: 64ccf12986d8dc0caa7c9fcc
    type: comment
  author: Cyrile
  content: Hello, I have a technical question. It's about training for text generation
    in a causal manner. I noticed that the training objective is cross-entropy based
    on a simple shift of the input_ids. However, the attention mechanism is causal
    thanks to the mask, but the feed-forward part is non-causal, am I correct? Therefore,
    isn't the way the model is trained in the HuggingFace library incorrect? Shouldn't
    we apply cross-entropy only on the prediction of the last token or also put a
    causal-mask on the MLP part?
  created_at: 2023-08-04 11:38:01+00:00
  edited: false
  hidden: false
  id: 64ccf12986d8dc0caa7c9fcc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1634332912347-noauth.png?w=200&h=200&f=face
      fullname: Cyrile Delestre
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cyrile
      type: user
    createdAt: '2023-08-04T20:09:15.000Z'
    data:
      status: closed
    id: 64cd5aeb6f107411da52b464
    type: status-change
  author: Cyrile
  created_at: 2023-08-04 19:09:15+00:00
  id: 64cd5aeb6f107411da52b464
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1634332912347-noauth.png?w=200&h=200&f=face
      fullname: Cyrile Delestre
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cyrile
      type: user
    createdAt: '2023-08-04T20:10:50.000Z'
    data:
      edited: false
      editors:
      - Cyrile
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9963851571083069
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1634332912347-noauth.png?w=200&h=200&f=face
          fullname: Cyrile Delestre
          isHf: false
          isPro: false
          name: Cyrile
          type: user
        html: '<p>Excuse me, I made a mistake and this is wrong.</p>

          '
        raw: Excuse me, I made a mistake and this is wrong.
        updatedAt: '2023-08-04T20:10:50.147Z'
      numEdits: 0
      reactions: []
    id: 64cd5b4a59503263d99cd62b
    type: comment
  author: Cyrile
  content: Excuse me, I made a mistake and this is wrong.
  created_at: 2023-08-04 19:10:50+00:00
  edited: false
  hidden: false
  id: 64cd5b4a59503263d99cd62b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 46
repo_id: bigscience/bloomz
repo_type: model
status: closed
target_branch: null
title: Is the CausalML model from HuggingFace truly causal?
