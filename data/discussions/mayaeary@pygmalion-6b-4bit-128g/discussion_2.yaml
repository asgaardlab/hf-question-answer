!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Vlagamer
conflicting_files: null
created_at: 2023-04-13 17:10:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/efb0dedaae321df3ea660b93dae5f521.svg
      fullname: Vladimir gerasimenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vlagamer
      type: user
    createdAt: '2023-04-13T18:10:48.000Z'
    data:
      edited: false
      editors:
      - Vlagamer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/efb0dedaae321df3ea660b93dae5f521.svg
          fullname: Vladimir gerasimenko
          isHf: false
          isPro: false
          name: Vlagamer
          type: user
        html: "<p>i know what isnt a github but (Starting the web UI...</p>\n<p>\u200B\
          </p>\n<p>===================================BUG REPORT===================================</p>\n\
          <p>Welcome to bitsandbytes. For bug reports, please submit your error trace\
          \ to: <a rel=\"nofollow\" href=\"https://github.com/TimDettmers/bitsandbytes/issues\"\
          >https://github.com/TimDettmers/bitsandbytes/issues</a></p>\n<p>================================================================================</p>\n\
          <p>CUDA SETUP: CUDA runtime path found: D:\\Games\\oobabooga-windows\\installer_files\\\
          env\\bin\\cudart64_110.dll</p>\n<p>CUDA SETUP: Highest compute capability\
          \ among GPUs detected: 7.5</p>\n<p>CUDA SETUP: Detected CUDA version 117</p>\n\
          <p>CUDA SETUP: Loading binary D:\\Games\\oobabooga-windows\\installer_files\\\
          env\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll...</p>\n\
          <p>Loading mayaeary_pygmalion-6b_dev-4bit-128g...</p>\n<p>Found the following\
          \ quantized model: models\\mayaeary_pygmalion-6b_dev-4bit-128g\\pygmalion-6b_dev-4bit-128g.safetensors</p>\n\
          <p>Loading model ...</p>\n<p>D:\\Games\\oobabooga-windows\\installer_files\\\
          env\\lib\\site-packages\\safetensors\\<a rel=\"nofollow\" href=\"https://torch.py:99\"\
          >torch.py:99</a>: UserWarning: TypedStorage is deprecated. It will be removed\
          \ in the future and UntypedStorage will be the only storage class. This\
          \ should only matter to you if you are using storages directly.  To access\
          \ UntypedStorage directly, use tensor.untyped_storage() instead of <a rel=\"\
          nofollow\" href=\"https://tensor.storage\">tensor.storage</a>()</p>\n<p>with\
          \ safe_open(filename, framework=\"pt\", device=device) as f:</p>\n<p>D:\\\
          Games\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\torch\\\
          _utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed\
          \ in the future and UntypedStorage will be the only storage class. This\
          \ should only matter to you if you are using storages directly.  To access\
          \ UntypedStorage directly, use tensor.untyped_storage() instead of <a rel=\"\
          nofollow\" href=\"https://tensor.storage\">tensor.storage</a>()</p>\n<p>return\
          \ self.fget.__get__(instance, owner)()</p>\n<p>D:\\Games\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\torch\\<a rel=\"nofollow\" href=\"\
          https://storage.py:899\">storage.py:899</a>: UserWarning: TypedStorage is\
          \ deprecated. It will be removed in the future and UntypedStorage will be\
          \ the only storage class. This should only matter to you if you are using\
          \ storages directly.  To access UntypedStorage directly, use tensor.untyped_storage()\
          \ instead of <a rel=\"nofollow\" href=\"https://tensor.storage\">tensor.storage</a>()</p>\n\
          <p>storage = cls(wrap_storage=untyped_storage) ) i got this error tell me\
          \ what to do in fact I have these configurations --wbits 4 --groupsize 128\
          \ --extensions api</p>\n"
        raw: "i know what isnt a github but (Starting the web UI...\r\n\r\n&#x200B;\r\
          \n\r\n===================================BUG REPORT===================================\r\
          \n\r\nWelcome to bitsandbytes. For bug reports, please submit your error\
          \ trace to: [https://github.com/TimDettmers/bitsandbytes/issues](https://github.com/TimDettmers/bitsandbytes/issues)\r\
          \n\r\n================================================================================\r\
          \n\r\nCUDA SETUP: CUDA runtime path found: D:\\\\Games\\\\oobabooga-windows\\\
          \\installer\\_files\\\\env\\\\bin\\\\cudart64\\_110.dll\r\n\r\nCUDA SETUP:\
          \ Highest compute capability among GPUs detected: 7.5\r\n\r\nCUDA SETUP:\
          \ Detected CUDA version 117\r\n\r\nCUDA SETUP: Loading binary D:\\\\Games\\\
          \\oobabooga-windows\\\\installer\\_files\\\\env\\\\lib\\\\site-packages\\\
          \\bitsandbytes\\\\libbitsandbytes\\_cuda117.dll...\r\n\r\nLoading mayaeary\\\
          _pygmalion-6b\\_dev-4bit-128g...\r\n\r\nFound the following quantized model:\
          \ models\\\\mayaeary\\_pygmalion-6b\\_dev-4bit-128g\\\\pygmalion-6b\\_dev-4bit-128g.safetensors\r\
          \n\r\nLoading model ...\r\n\r\nD:\\\\Games\\\\oobabooga-windows\\\\installer\\\
          _files\\\\env\\\\lib\\\\site-packages\\\\safetensors\\\\[torch.py:99](https://torch.py:99):\
          \ UserWarning: TypedStorage is deprecated. It will be removed in the future\
          \ and UntypedStorage will be the only storage class. This should only matter\
          \ to you if you are using storages directly.  To access UntypedStorage directly,\
          \ use tensor.untyped\\_storage() instead of [tensor.storage](https://tensor.storage)()\r\
          \n\r\nwith safe\\_open(filename, framework=\"pt\", device=device) as f:\r\
          \n\r\nD:\\\\Games\\\\oobabooga-windows\\\\installer\\_files\\\\env\\\\lib\\\
          \\site-packages\\\\torch\\\\\\_utils.py:776: UserWarning: TypedStorage is\
          \ deprecated. It will be removed in the future and UntypedStorage will be\
          \ the only storage class. This should only matter to you if you are using\
          \ storages directly.  To access UntypedStorage directly, use tensor.untyped\\\
          _storage() instead of [tensor.storage](https://tensor.storage)()\r\n\r\n\
          return self.fget.\\_\\_get\\_\\_(instance, owner)()\r\n\r\nD:\\\\Games\\\
          \\oobabooga-windows\\\\installer\\_files\\\\env\\\\lib\\\\site-packages\\\
          \\torch\\\\[storage.py:899](https://storage.py:899): UserWarning: TypedStorage\
          \ is deprecated. It will be removed in the future and UntypedStorage will\
          \ be the only storage class. This should only matter to you if you are using\
          \ storages directly.  To access UntypedStorage directly, use tensor.untyped\\\
          _storage() instead of [tensor.storage](https://tensor.storage)()\r\n\r\n\
          storage = cls(wrap\\_storage=untyped\\_storage) ) i got this error tell\
          \ me what to do in fact I have these configurations --wbits 4 --groupsize\
          \ 128 --extensions api"
        updatedAt: '2023-04-13T18:10:48.655Z'
      numEdits: 0
      reactions: []
    id: 643845a8b885944a187135eb
    type: comment
  author: Vlagamer
  content: "i know what isnt a github but (Starting the web UI...\r\n\r\n&#x200B;\r\
    \n\r\n===================================BUG REPORT===================================\r\
    \n\r\nWelcome to bitsandbytes. For bug reports, please submit your error trace\
    \ to: [https://github.com/TimDettmers/bitsandbytes/issues](https://github.com/TimDettmers/bitsandbytes/issues)\r\
    \n\r\n================================================================================\r\
    \n\r\nCUDA SETUP: CUDA runtime path found: D:\\\\Games\\\\oobabooga-windows\\\\\
    installer\\_files\\\\env\\\\bin\\\\cudart64\\_110.dll\r\n\r\nCUDA SETUP: Highest\
    \ compute capability among GPUs detected: 7.5\r\n\r\nCUDA SETUP: Detected CUDA\
    \ version 117\r\n\r\nCUDA SETUP: Loading binary D:\\\\Games\\\\oobabooga-windows\\\
    \\installer\\_files\\\\env\\\\lib\\\\site-packages\\\\bitsandbytes\\\\libbitsandbytes\\\
    _cuda117.dll...\r\n\r\nLoading mayaeary\\_pygmalion-6b\\_dev-4bit-128g...\r\n\r\
    \nFound the following quantized model: models\\\\mayaeary\\_pygmalion-6b\\_dev-4bit-128g\\\
    \\pygmalion-6b\\_dev-4bit-128g.safetensors\r\n\r\nLoading model ...\r\n\r\nD:\\\
    \\Games\\\\oobabooga-windows\\\\installer\\_files\\\\env\\\\lib\\\\site-packages\\\
    \\safetensors\\\\[torch.py:99](https://torch.py:99): UserWarning: TypedStorage\
    \ is deprecated. It will be removed in the future and UntypedStorage will be the\
    \ only storage class. This should only matter to you if you are using storages\
    \ directly.  To access UntypedStorage directly, use tensor.untyped\\_storage()\
    \ instead of [tensor.storage](https://tensor.storage)()\r\n\r\nwith safe\\_open(filename,\
    \ framework=\"pt\", device=device) as f:\r\n\r\nD:\\\\Games\\\\oobabooga-windows\\\
    \\installer\\_files\\\\env\\\\lib\\\\site-packages\\\\torch\\\\\\_utils.py:776:\
    \ UserWarning: TypedStorage is deprecated. It will be removed in the future and\
    \ UntypedStorage will be the only storage class. This should only matter to you\
    \ if you are using storages directly.  To access UntypedStorage directly, use\
    \ tensor.untyped\\_storage() instead of [tensor.storage](https://tensor.storage)()\r\
    \n\r\nreturn self.fget.\\_\\_get\\_\\_(instance, owner)()\r\n\r\nD:\\\\Games\\\
    \\oobabooga-windows\\\\installer\\_files\\\\env\\\\lib\\\\site-packages\\\\torch\\\
    \\[storage.py:899](https://storage.py:899): UserWarning: TypedStorage is deprecated.\
    \ It will be removed in the future and UntypedStorage will be the only storage\
    \ class. This should only matter to you if you are using storages directly.  To\
    \ access UntypedStorage directly, use tensor.untyped\\_storage() instead of [tensor.storage](https://tensor.storage)()\r\
    \n\r\nstorage = cls(wrap\\_storage=untyped\\_storage) ) i got this error tell\
    \ me what to do in fact I have these configurations --wbits 4 --groupsize 128\
    \ --extensions api"
  created_at: 2023-04-13 17:10:48+00:00
  edited: false
  hidden: false
  id: 643845a8b885944a187135eb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641cad3f043963b1c0a263e6/WWHO2tAFv2q2mcgkr1nw-.jpeg?w=200&h=200&f=face
      fullname: Maya Eary
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mayaeary
      type: user
    createdAt: '2023-04-14T23:04:35.000Z'
    data:
      edited: true
      editors:
      - mayaeary
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641cad3f043963b1c0a263e6/WWHO2tAFv2q2mcgkr1nw-.jpeg?w=200&h=200&f=face
          fullname: Maya Eary
          isHf: false
          isPro: false
          name: mayaeary
          type: user
        html: '<p>It isn''t errors, it just warnings. You should be able to use model
          without problems.</p>

          '
        raw: It isn't errors, it just warnings. You should be able to use model without
          problems.
        updatedAt: '2023-04-14T23:11:42.362Z'
      numEdits: 2
      reactions: []
    id: 6439dc03623c97018804b86d
    type: comment
  author: mayaeary
  content: It isn't errors, it just warnings. You should be able to use model without
    problems.
  created_at: 2023-04-14 22:04:35+00:00
  edited: true
  hidden: false
  id: 6439dc03623c97018804b86d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c6a95fabcfc2abfa913ccd953ba0b742.svg
      fullname: W.W.A
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: WAitester79
      type: user
    createdAt: '2023-04-16T18:49:31.000Z'
    data:
      edited: false
      editors:
      - WAitester79
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c6a95fabcfc2abfa913ccd953ba0b742.svg
          fullname: W.W.A
          isHf: false
          isPro: false
          name: WAitester79
          type: user
        html: '<p>I have this error loading  the model</p>

          <p>Traceback (most recent call last):<br>File "C:\AIweb\oobabooga-windows\text-generation-webui\server.py",
          line 85, in load_model_wrapper<br>shared.model, shared.tokenizer = load_model(shared.model_name)<br>File
          "C:\AIweb\oobabooga-windows\text-generation-webui\modules\models.py", line
          188, in load_model<br>tokenizer = AutoTokenizer.from_pretrained(Path(f"{shared.args.model_dir}/{shared.model_name}/"))<br>File
          "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\models\auto\tokenization_auto.py",
          line 702, in from_pretrained<br>return tokenizer_class.from_pretrained(pretrained_model_name_or_path,
          *inputs, **kwargs)<br>File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\tokenization_utils_base.py",
          line 1811, in from_pretrained<br>return cls._from_pretrained(<br>File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\tokenization_utils_base.py",
          line 1841, in _from_pretrained<br>slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(<br>File
          "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\tokenization_utils_base.py",
          line 1965, in _from_pretrained<br>tokenizer = cls(*init_inputs, **init_kwargs)<br>File
          "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\models\gpt2\tokenization_gpt2.py",
          line 188, in init<br>with open(vocab_file, encoding="utf-8") as vocab_handle:<br>TypeError:
          expected str, bytes or os.PathLike object, not NoneType</p>

          '
        raw: 'I have this error loading  the model


          Traceback (most recent call last):

          File "C:\AIweb\oobabooga-windows\text-generation-webui\server.py", line
          85, in load_model_wrapper

          shared.model, shared.tokenizer = load_model(shared.model_name)

          File "C:\AIweb\oobabooga-windows\text-generation-webui\modules\models.py",
          line 188, in load_model

          tokenizer = AutoTokenizer.from_pretrained(Path(f"{shared.args.model_dir}/{shared.model_name}/"))

          File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\models\auto\tokenization_auto.py",
          line 702, in from_pretrained

          return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs,
          **kwargs)

          File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\tokenization_utils_base.py",
          line 1811, in from_pretrained

          return cls._from_pretrained(

          File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\tokenization_utils_base.py",
          line 1841, in _from_pretrained

          slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(

          File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\tokenization_utils_base.py",
          line 1965, in _from_pretrained

          tokenizer = cls(*init_inputs, **init_kwargs)

          File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\models\gpt2\tokenization_gpt2.py",
          line 188, in init

          with open(vocab_file, encoding="utf-8") as vocab_handle:

          TypeError: expected str, bytes or os.PathLike object, not NoneType'
        updatedAt: '2023-04-16T18:49:31.463Z'
      numEdits: 0
      reactions: []
    id: 643c433b2168686700409136
    type: comment
  author: WAitester79
  content: 'I have this error loading  the model


    Traceback (most recent call last):

    File "C:\AIweb\oobabooga-windows\text-generation-webui\server.py", line 85, in
    load_model_wrapper

    shared.model, shared.tokenizer = load_model(shared.model_name)

    File "C:\AIweb\oobabooga-windows\text-generation-webui\modules\models.py", line
    188, in load_model

    tokenizer = AutoTokenizer.from_pretrained(Path(f"{shared.args.model_dir}/{shared.model_name}/"))

    File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\models\auto\tokenization_auto.py",
    line 702, in from_pretrained

    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs,
    **kwargs)

    File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\tokenization_utils_base.py",
    line 1811, in from_pretrained

    return cls._from_pretrained(

    File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\tokenization_utils_base.py",
    line 1841, in _from_pretrained

    slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(

    File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\tokenization_utils_base.py",
    line 1965, in _from_pretrained

    tokenizer = cls(*init_inputs, **init_kwargs)

    File "C:\AIweb\oobabooga-windows\installer_files\env\lib\site-packages\transformers\models\gpt2\tokenization_gpt2.py",
    line 188, in init

    with open(vocab_file, encoding="utf-8") as vocab_handle:

    TypeError: expected str, bytes or os.PathLike object, not NoneType'
  created_at: 2023-04-16 17:49:31+00:00
  edited: false
  hidden: false
  id: 643c433b2168686700409136
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
      fullname: brucethemoose
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brucethemoose
      type: user
    createdAt: '2023-04-20T19:27:48.000Z'
    data:
      edited: false
      editors:
      - brucethemoose
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670003187019-noauth.png?w=200&h=200&f=face
          fullname: brucethemoose
          isHf: false
          isPro: false
          name: brucethemoose
          type: user
        html: '<p>That means the model isn''t downloaded properly, you have to clone/download
          the whole folder so that it matches this repo exactly.</p>

          '
        raw: That means the model isn't downloaded properly, you have to clone/download
          the whole folder so that it matches this repo exactly.
        updatedAt: '2023-04-20T19:27:48.481Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - WAitester79
    id: 64419234e46e14ed55966ef1
    type: comment
  author: brucethemoose
  content: That means the model isn't downloaded properly, you have to clone/download
    the whole folder so that it matches this repo exactly.
  created_at: 2023-04-20 18:27:48+00:00
  edited: false
  hidden: false
  id: 64419234e46e14ed55966ef1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: mayaeary/pygmalion-6b-4bit-128g
repo_type: model
status: open
target_branch: null
title: 'Don''t load in oobabooga webui (gtx 1660 ti, intel core i5) '
