!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SudhanshuBlaze
conflicting_files: null
created_at: 2023-04-26 18:52:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654803380905-noauth.jpeg?w=200&h=200&f=face
      fullname: Sudhanshu Kumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SudhanshuBlaze
      type: user
    createdAt: '2023-04-26T19:52:43.000Z'
    data:
      edited: false
      editors:
      - SudhanshuBlaze
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654803380905-noauth.jpeg?w=200&h=200&f=face
          fullname: Sudhanshu Kumar
          isHf: false
          isPro: false
          name: SudhanshuBlaze
          type: user
        html: "<p>Can we use this model in the pipeline() function of HuggingFace,\
          \ if yes then how?</p>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span>\
          \ AutoTokenizer, AutoModelWithLMHead\n\ntokenizer = AutoTokenizer.from_pretrained(<span\
          \ class=\"hljs-string\">\"mrm8488/t5-base-finetuned-emotion\"</span>)\n\n\
          model = AutoModelWithLMHead.from_pretrained(<span class=\"hljs-string\"\
          >\"mrm8488/t5-base-finetuned-emotion\"</span>)\n\n<span class=\"hljs-keyword\"\
          >def</span> <span class=\"hljs-title function_\">get_emotion</span>(<span\
          \ class=\"hljs-params\">text</span>):\n  input_ids = tokenizer.encode(text\
          \ + <span class=\"hljs-string\">'&lt;/s&gt;'</span>, return_tensors=<span\
          \ class=\"hljs-string\">'pt'</span>)\n\n  output = model.generate(input_ids=input_ids,\n\
          \               max_length=<span class=\"hljs-number\">2</span>)\n  \n \
          \ dec = [tokenizer.decode(ids) <span class=\"hljs-keyword\">for</span> ids\
          \ <span class=\"hljs-keyword\">in</span> output]\n  label = dec[<span class=\"\
          hljs-number\">0</span>]\n  <span class=\"hljs-keyword\">return</span> label\n\
          \  \n get_emotion(<span class=\"hljs-string\">\"i feel as if i havent blogged\
          \ in ages are at least truly blogged i am doing an update cute\"</span>)\
          \ <span class=\"hljs-comment\"># Output: 'joy'</span>\n \n get_emotion(<span\
          \ class=\"hljs-string\">\"i have a feeling i kinda lost my best friend\"\
          </span>) <span class=\"hljs-comment\"># Output: 'sadness'</span>\n</code></pre>\n"
        raw: "Can we use this model in the pipeline() function of HuggingFace, if\
          \ yes then how?\r\n\r\n```python\r\nfrom transformers import AutoTokenizer,\
          \ AutoModelWithLMHead\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          mrm8488/t5-base-finetuned-emotion\")\r\n\r\nmodel = AutoModelWithLMHead.from_pretrained(\"\
          mrm8488/t5-base-finetuned-emotion\")\r\n\r\ndef get_emotion(text):\r\n \
          \ input_ids = tokenizer.encode(text + '</s>', return_tensors='pt')\r\n\r\
          \n  output = model.generate(input_ids=input_ids,\r\n               max_length=2)\r\
          \n  \r\n  dec = [tokenizer.decode(ids) for ids in output]\r\n  label = dec[0]\r\
          \n  return label\r\n  \r\n get_emotion(\"i feel as if i havent blogged in\
          \ ages are at least truly blogged i am doing an update cute\") # Output:\
          \ 'joy'\r\n \r\n get_emotion(\"i have a feeling i kinda lost my best friend\"\
          ) # Output: 'sadness'\r\n```"
        updatedAt: '2023-04-26T19:52:43.278Z'
      numEdits: 0
      reactions: []
    id: 6449810b6fa5e1ba98a26447
    type: comment
  author: SudhanshuBlaze
  content: "Can we use this model in the pipeline() function of HuggingFace, if yes\
    \ then how?\r\n\r\n```python\r\nfrom transformers import AutoTokenizer, AutoModelWithLMHead\r\
    \n\r\ntokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\"\
    )\r\n\r\nmodel = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\"\
    )\r\n\r\ndef get_emotion(text):\r\n  input_ids = tokenizer.encode(text + '</s>',\
    \ return_tensors='pt')\r\n\r\n  output = model.generate(input_ids=input_ids,\r\
    \n               max_length=2)\r\n  \r\n  dec = [tokenizer.decode(ids) for ids\
    \ in output]\r\n  label = dec[0]\r\n  return label\r\n  \r\n get_emotion(\"i feel\
    \ as if i havent blogged in ages are at least truly blogged i am doing an update\
    \ cute\") # Output: 'joy'\r\n \r\n get_emotion(\"i have a feeling i kinda lost\
    \ my best friend\") # Output: 'sadness'\r\n```"
  created_at: 2023-04-26 18:52:43+00:00
  edited: false
  hidden: false
  id: 6449810b6fa5e1ba98a26447
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: mrm8488/t5-base-finetuned-emotion
repo_type: model
status: open
target_branch: null
title: HuggingFace pipeline() function
