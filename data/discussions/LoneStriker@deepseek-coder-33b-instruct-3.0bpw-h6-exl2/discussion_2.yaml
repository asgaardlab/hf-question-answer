!!python/object:huggingface_hub.community.DiscussionWithDetails
author: eramax
conflicting_files: null
created_at: 2023-12-15 21:00:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
      fullname: Ahmed Morsi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eramax
      type: user
    createdAt: '2023-12-15T21:00:31.000Z'
    data:
      edited: false
      editors:
      - eramax
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6156870126724243
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
          fullname: Ahmed Morsi
          isHf: false
          isPro: false
          name: eramax
          type: user
        html: "<p>I have tried multiple versions of deepseek models and found it always\
          \ give me incorrect response </p>\n<pre><code>python examples/chat.py -m\
          \ ./deepseek-coder-33b-instruct-3.0bpw-h6-exl2 -mode llama\n</code></pre>\n\
          <p>the result</p>\n<pre><code>-- Model: /content/model\n -- Options: ['rope_scale\
          \ 1.0', 'rope_alpha 1.0']\n -- Loading model...\n -- Loading tokenizer...\n\
          \ -- Prompt format: llama\n -- System prompt:\n\nYou are a helpful, respectful\
          \ and honest assistant. Always answer as helpfully as possible, while being\
          \ safe.  Your answers should not include any harmful, unethical, racist,\
          \ sexist, toxic, dangerous, or illegal content. Please ensure that your\
          \ responses are socially unbiased and positive in nature.\n\nUser: explain\
          \ quick sort\n\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\n\
          </code></pre>\n"
        raw: "I have tried multiple versions of deepseek models and found it always\
          \ give me incorrect response \r\n```\r\npython examples/chat.py -m ./deepseek-coder-33b-instruct-3.0bpw-h6-exl2\
          \ -mode llama\r\n```\r\nthe result\r\n```\r\n-- Model: /content/model\r\n\
          \ -- Options: ['rope_scale 1.0', 'rope_alpha 1.0']\r\n -- Loading model...\r\
          \n -- Loading tokenizer...\r\n -- Prompt format: llama\r\n -- System prompt:\r\
          \n\r\nYou are a helpful, respectful and honest assistant. Always answer\
          \ as helpfully as possible, while being safe.  Your answers should not include\
          \ any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\
          \ Please ensure that your responses are socially unbiased and positive in\
          \ nature.\r\n\r\nUser: explain quick sort\r\n\r\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\r\
          \n```\r\n"
        updatedAt: '2023-12-15T21:00:31.801Z'
      numEdits: 0
      reactions: []
    id: 657cbe6f3480ce8aae515614
    type: comment
  author: eramax
  content: "I have tried multiple versions of deepseek models and found it always\
    \ give me incorrect response \r\n```\r\npython examples/chat.py -m ./deepseek-coder-33b-instruct-3.0bpw-h6-exl2\
    \ -mode llama\r\n```\r\nthe result\r\n```\r\n-- Model: /content/model\r\n -- Options:\
    \ ['rope_scale 1.0', 'rope_alpha 1.0']\r\n -- Loading model...\r\n -- Loading\
    \ tokenizer...\r\n -- Prompt format: llama\r\n -- System prompt:\r\n\r\nYou are\
    \ a helpful, respectful and honest assistant. Always answer as helpfully as possible,\
    \ while being safe.  Your answers should not include any harmful, unethical, racist,\
    \ sexist, toxic, dangerous, or illegal content. Please ensure that your responses\
    \ are socially unbiased and positive in nature.\r\n\r\nUser: explain quick sort\r\
    \n\r\n]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\r\
    \n```\r\n"
  created_at: 2023-12-15 21:00:31+00:00
  edited: false
  hidden: false
  id: 657cbe6f3480ce8aae515614
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-12-16T13:01:24.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.828536868095398
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: "<p>The model works fine with the right prompt template; the prompt\
          \ format is automatically detected in ooba text-generation-webui.  You're\
          \ going to have to encode the prompt template in the example chat script\
          \ to get it to work.  Here's the output in ooba notebook mode (you'll need\
          \ to add the stop token as well).  I edited the stupid system prompt below\
          \ (the default one tells the model to refuse to answer for certain questions.</p>\n\
          <pre><code>You are an AI programming assistant, utilizing the Deepseek Coder\
          \ model, developed by Deepseek Company. You will answer all questions truthfully\
          \ and honestly.\n### Instruction:\nexplain quick sort\n### Response:\nQuick\
          \ Sort is a Divide and Conquer algorithm. It works by selecting a 'pivot'\
          \ element from the array and partitioning the other elements into two sub-arrays,\
          \ according to whether they are less than or greater than the pivot. The\
          \ sub-arrays are then recursively sorted. \n\nHere is a Python implementation\
          \ of QuickSort:\n\n```python\ndef quicksort(array):\n    if len(array) &lt;=\
          \ 1:\n        return array\n    else:\n        pivot = array[len(array)\
          \ // 2]\n        lesser = [x for x in array if x &lt; pivot]\n        equal\
          \ = [x for x in array if x == pivot]\n        greater = [x for x in array\
          \ if x &gt; pivot]\n        return quicksort(lesser) + equal + quicksort(greater)\n\
          </code></pre>\n<p>In this code, we first check if the length of the input\
          \ list <code>array</code> is less than or equal to one (meaning it has reached\
          \ its base case). If so, the function returns the list itself as it doesn't\
          \ need any further sorting. Otherwise, the middle index value is selected\
          \ as the pivot. Then three lists are created - <code>lesser</code> which\
          \ contains values smaller than the pivot, <code>equal</code> containing\
          \ values equal to the pivot and <code>greater</code> with values larger\
          \ than the pivot. These lists are then concatenated together using the <code>+</code>\
          \ operator after calling the same function on them to perform the sort again.\
          \ This continues until the smallest possible lists of size 1 are reached.\
          \ At that point, the lists merge back up through the call stack.<br>&lt;|EOT|&gt;\
          \ \u2705\uFE0F<br>&lt;|EOT|&gt; \U0001F44D\U0001F3FC<br>&lt;|EOT|&gt; \U0001F604\
          <br>```</p>\n"
        raw: "The model works fine with the right prompt template; the prompt format\
          \ is automatically detected in ooba text-generation-webui.  You're going\
          \ to have to encode the prompt template in the example chat script to get\
          \ it to work.  Here's the output in ooba notebook mode (you'll need to add\
          \ the stop token as well).  I edited the stupid system prompt below (the\
          \ default one tells the model to refuse to answer for certain questions.\n\
          \n```\nYou are an AI programming assistant, utilizing the Deepseek Coder\
          \ model, developed by Deepseek Company. You will answer all questions truthfully\
          \ and honestly.\n### Instruction:\nexplain quick sort\n### Response:\nQuick\
          \ Sort is a Divide and Conquer algorithm. It works by selecting a 'pivot'\
          \ element from the array and partitioning the other elements into two sub-arrays,\
          \ according to whether they are less than or greater than the pivot. The\
          \ sub-arrays are then recursively sorted. \n\nHere is a Python implementation\
          \ of QuickSort:\n\n```python\ndef quicksort(array):\n    if len(array) <=\
          \ 1:\n        return array\n    else:\n        pivot = array[len(array)\
          \ // 2]\n        lesser = [x for x in array if x < pivot]\n        equal\
          \ = [x for x in array if x == pivot]\n        greater = [x for x in array\
          \ if x > pivot]\n        return quicksort(lesser) + equal + quicksort(greater)\n\
          ```\n\nIn this code, we first check if the length of the input list `array`\
          \ is less than or equal to one (meaning it has reached its base case). If\
          \ so, the function returns the list itself as it doesn't need any further\
          \ sorting. Otherwise, the middle index value is selected as the pivot. Then\
          \ three lists are created - `lesser` which contains values smaller than\
          \ the pivot, `equal` containing values equal to the pivot and `greater`\
          \ with values larger than the pivot. These lists are then concatenated together\
          \ using the `+` operator after calling the same function on them to perform\
          \ the sort again. This continues until the smallest possible lists of size\
          \ 1 are reached. At that point, the lists merge back up through the call\
          \ stack.\n<|EOT|> \u2705\uFE0F\n<|EOT|> \U0001F44D\U0001F3FC\n<|EOT|> \U0001F604\
          \n```"
        updatedAt: '2023-12-16T13:01:24.138Z'
      numEdits: 0
      reactions: []
    id: 657d9fa449ec77d48e6e45ee
    type: comment
  author: LoneStriker
  content: "The model works fine with the right prompt template; the prompt format\
    \ is automatically detected in ooba text-generation-webui.  You're going to have\
    \ to encode the prompt template in the example chat script to get it to work.\
    \  Here's the output in ooba notebook mode (you'll need to add the stop token\
    \ as well).  I edited the stupid system prompt below (the default one tells the\
    \ model to refuse to answer for certain questions.\n\n```\nYou are an AI programming\
    \ assistant, utilizing the Deepseek Coder model, developed by Deepseek Company.\
    \ You will answer all questions truthfully and honestly.\n### Instruction:\nexplain\
    \ quick sort\n### Response:\nQuick Sort is a Divide and Conquer algorithm. It\
    \ works by selecting a 'pivot' element from the array and partitioning the other\
    \ elements into two sub-arrays, according to whether they are less than or greater\
    \ than the pivot. The sub-arrays are then recursively sorted. \n\nHere is a Python\
    \ implementation of QuickSort:\n\n```python\ndef quicksort(array):\n    if len(array)\
    \ <= 1:\n        return array\n    else:\n        pivot = array[len(array) //\
    \ 2]\n        lesser = [x for x in array if x < pivot]\n        equal = [x for\
    \ x in array if x == pivot]\n        greater = [x for x in array if x > pivot]\n\
    \        return quicksort(lesser) + equal + quicksort(greater)\n```\n\nIn this\
    \ code, we first check if the length of the input list `array` is less than or\
    \ equal to one (meaning it has reached its base case). If so, the function returns\
    \ the list itself as it doesn't need any further sorting. Otherwise, the middle\
    \ index value is selected as the pivot. Then three lists are created - `lesser`\
    \ which contains values smaller than the pivot, `equal` containing values equal\
    \ to the pivot and `greater` with values larger than the pivot. These lists are\
    \ then concatenated together using the `+` operator after calling the same function\
    \ on them to perform the sort again. This continues until the smallest possible\
    \ lists of size 1 are reached. At that point, the lists merge back up through\
    \ the call stack.\n<|EOT|> \u2705\uFE0F\n<|EOT|> \U0001F44D\U0001F3FC\n<|EOT|>\
    \ \U0001F604\n```"
  created_at: 2023-12-16 13:01:24+00:00
  edited: false
  hidden: false
  id: 657d9fa449ec77d48e6e45ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
      fullname: Ahmed Morsi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eramax
      type: user
    createdAt: '2023-12-16T13:32:30.000Z'
    data:
      edited: false
      editors:
      - eramax
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.786004364490509
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
          fullname: Ahmed Morsi
          isHf: false
          isPro: false
          name: eramax
          type: user
        html: '<p>Thsnk you for your answer, I didn''t use <code>ooba text-generation-webui</code>
          just used the <code>examples/chat.py</code> attached in the repo, Can I
          use this script or any other scripts and apply the prompt formats ?<br>Regards,</p>

          '
        raw: 'Thsnk you for your answer, I didn''t use `ooba text-generation-webui`
          just used the `examples/chat.py` attached in the repo, Can I use this script
          or any other scripts and apply the prompt formats ?

          Regards,'
        updatedAt: '2023-12-16T13:32:30.347Z'
      numEdits: 0
      reactions: []
    id: 657da6ee365456e362058f5c
    type: comment
  author: eramax
  content: 'Thsnk you for your answer, I didn''t use `ooba text-generation-webui`
    just used the `examples/chat.py` attached in the repo, Can I use this script or
    any other scripts and apply the prompt formats ?

    Regards,'
  created_at: 2023-12-16 13:32:30+00:00
  edited: false
  hidden: false
  id: 657da6ee365456e362058f5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-12-16T13:33:59.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.766681432723999
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>You''ll need to see how Turboderp defines the prompt templates.
          Just copy them and create a new one for deepseek-coder.</p>

          '
        raw: You'll need to see how Turboderp defines the prompt templates. Just copy
          them and create a new one for deepseek-coder.
        updatedAt: '2023-12-16T13:33:59.594Z'
      numEdits: 0
      reactions: []
    id: 657da747aed79486aefb1333
    type: comment
  author: LoneStriker
  content: You'll need to see how Turboderp defines the prompt templates. Just copy
    them and create a new one for deepseek-coder.
  created_at: 2023-12-16 13:33:59+00:00
  edited: false
  hidden: false
  id: 657da747aed79486aefb1333
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: LoneStriker/deepseek-coder-33b-instruct-3.0bpw-h6-exl2
repo_type: model
status: open
target_branch: null
title: bad output
