!!python/object:huggingface_hub.community.DiscussionWithDetails
author: birgermoell
conflicting_files: null
created_at: 2022-10-19 11:12:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2022-10-19T12:12:32.000Z'
    data:
      edited: false
      editors:
      - birgermoell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
          fullname: Birger Moell
          isHf: false
          isPro: false
          name: birgermoell
          type: user
        html: '<p>I loaded it through the use in transformer code and got the following
          error.</p>

          <p>from transformers import AutoProcessor, AutoModelForPreTraining</p>

          <p>processor = AutoProcessor.from_pretrained("KBLab/wav2vec2-large-voxrex")</p>

          <p>model = AutoModelForPreTraining.from_pretrained("KBLab/wav2vec2-large-voxrex")</p>

          <p>Maybe you would like to add information to the repo or change the default
          code to work directly from Use in Transformers?</p>

          <p>OSError: Can''t load tokenizer for ''KBLab/wav2vec2-large-voxrex''. If
          you were trying to load it from ''<a href="https://huggingface.co/models''">https://huggingface.co/models''</a>,
          make sure you don''t have a local directory with the same name. Otherwise,
          make sure ''KBLab/wav2vec2-large-voxrex'' is the correct path to a directory
          containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.</p>

          '
        raw: "I loaded it through the use in transformer code and got the following\
          \ error.\r\n\r\nfrom transformers import AutoProcessor, AutoModelForPreTraining\r\
          \n\r\nprocessor = AutoProcessor.from_pretrained(\"KBLab/wav2vec2-large-voxrex\"\
          )\r\n\r\nmodel = AutoModelForPreTraining.from_pretrained(\"KBLab/wav2vec2-large-voxrex\"\
          )\r\n\r\nMaybe you would like to add information to the repo or change the\
          \ default code to work directly from Use in Transformers?\r\n\r\nOSError:\
          \ Can't load tokenizer for 'KBLab/wav2vec2-large-voxrex'. If you were trying\
          \ to load it from 'https://huggingface.co/models', make sure you don't have\
          \ a local directory with the same name. Otherwise, make sure 'KBLab/wav2vec2-large-voxrex'\
          \ is the correct path to a directory containing all relevant files for a\
          \ Wav2Vec2CTCTokenizer tokenizer."
        updatedAt: '2022-10-19T12:12:32.637Z'
      numEdits: 0
      reactions: []
    id: 634fe9b014fb199c7656337b
    type: comment
  author: birgermoell
  content: "I loaded it through the use in transformer code and got the following\
    \ error.\r\n\r\nfrom transformers import AutoProcessor, AutoModelForPreTraining\r\
    \n\r\nprocessor = AutoProcessor.from_pretrained(\"KBLab/wav2vec2-large-voxrex\"\
    )\r\n\r\nmodel = AutoModelForPreTraining.from_pretrained(\"KBLab/wav2vec2-large-voxrex\"\
    )\r\n\r\nMaybe you would like to add information to the repo or change the default\
    \ code to work directly from Use in Transformers?\r\n\r\nOSError: Can't load tokenizer\
    \ for 'KBLab/wav2vec2-large-voxrex'. If you were trying to load it from 'https://huggingface.co/models',\
    \ make sure you don't have a local directory with the same name. Otherwise, make\
    \ sure 'KBLab/wav2vec2-large-voxrex' is the correct path to a directory containing\
    \ all relevant files for a Wav2Vec2CTCTokenizer tokenizer."
  created_at: 2022-10-19 11:12:32+00:00
  edited: false
  hidden: false
  id: 634fe9b014fb199c7656337b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8fedebb29532e2fb1648814a291a96d4.svg
      fullname: Faton Rekathati
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Lauler
      type: user
    createdAt: '2022-10-19T12:35:18.000Z'
    data:
      edited: true
      editors:
      - Lauler
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8fedebb29532e2fb1648814a291a96d4.svg
          fullname: Faton Rekathati
          isHf: false
          isPro: false
          name: Lauler
          type: user
        html: '<p><code>wav2vec2-large-voxrex</code> is a different repo which does
          <a href="https://huggingface.co/KBLab/wav2vec2-large-voxrex/tree/main">not
          have a vocabulary</a> (vocab.json) nor a tokenizer config file (tokenizer_config.json).  You''d
          need to clone that  repo with git and add your own vocabulary manually.<br>This
          repo is <code>wav2vec2-large-voxrex-swedish</code>. You can load it for
          continued pretraining <del>using existing vocab</del> (<strong>edit</strong>:
          continued pretraining doesn''t need a vocab, see comment below this one):</p>

          <pre><code>from transformers import AutoProcessor, AutoModelForPreTraining

          processor = AutoProcessor.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

          model = AutoModelForPreTraining.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

          </code></pre>

          <p>or with CTC</p>

          <pre><code>from transformers import AutoProcessor, AutoModelForCTC

          processor = AutoProcessor.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

          model = AutoModelForCTC.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

          </code></pre>

          <p>See links below for differences in files they include<br><a href="https://huggingface.co/KBLab/wav2vec2-large-voxrex/tree/main">https://huggingface.co/KBLab/wav2vec2-large-voxrex/tree/main</a><br><a
          href="https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish/tree/main">https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish/tree/main</a></p>

          '
        raw: '`wav2vec2-large-voxrex` is a different repo which does [not have a vocabulary](

          https://huggingface.co/KBLab/wav2vec2-large-voxrex/tree/main) (vocab.json)
          nor a tokenizer config file (tokenizer_config.json).  You''d need to clone
          that  repo with git and add your own vocabulary manually.

          This repo is `wav2vec2-large-voxrex-swedish`. You can load it for continued
          pretraining ~~using existing vocab~~ (**edit**: continued pretraining doesn''t
          need a vocab, see comment below this one):


          ```

          from transformers import AutoProcessor, AutoModelForPreTraining

          processor = AutoProcessor.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

          model = AutoModelForPreTraining.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

          ```


          or with CTC


          ```

          from transformers import AutoProcessor, AutoModelForCTC

          processor = AutoProcessor.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

          model = AutoModelForCTC.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

          ```


          See links below for differences in files they include

          https://huggingface.co/KBLab/wav2vec2-large-voxrex/tree/main

          https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish/tree/main'
        updatedAt: '2022-10-19T13:28:06.124Z'
      numEdits: 2
      reactions: []
    id: 634fef0614fb199c76565dc6
    type: comment
  author: Lauler
  content: '`wav2vec2-large-voxrex` is a different repo which does [not have a vocabulary](

    https://huggingface.co/KBLab/wav2vec2-large-voxrex/tree/main) (vocab.json) nor
    a tokenizer config file (tokenizer_config.json).  You''d need to clone that  repo
    with git and add your own vocabulary manually.

    This repo is `wav2vec2-large-voxrex-swedish`. You can load it for continued pretraining
    ~~using existing vocab~~ (**edit**: continued pretraining doesn''t need a vocab,
    see comment below this one):


    ```

    from transformers import AutoProcessor, AutoModelForPreTraining

    processor = AutoProcessor.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

    model = AutoModelForPreTraining.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

    ```


    or with CTC


    ```

    from transformers import AutoProcessor, AutoModelForCTC

    processor = AutoProcessor.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

    model = AutoModelForCTC.from_pretrained("KBLab/wav2vec2-large-voxrex-swedish")

    ```


    See links below for differences in files they include

    https://huggingface.co/KBLab/wav2vec2-large-voxrex/tree/main

    https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish/tree/main'
  created_at: 2022-10-19 11:35:18+00:00
  edited: true
  hidden: false
  id: 634fef0614fb199c76565dc6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8fedebb29532e2fb1648814a291a96d4.svg
      fullname: Faton Rekathati
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Lauler
      type: user
    createdAt: '2022-10-19T13:02:54.000Z'
    data:
      edited: true
      editors:
      - Lauler
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8fedebb29532e2fb1648814a291a96d4.svg
          fullname: Faton Rekathati
          isHf: false
          isPro: false
          name: Lauler
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;marma&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/marma\">@<span class=\"\
          underline\">marma</span></a></span>\n\n\t</span></span> Is it necessary\
          \ to have vocab during unsupervised pretraining? </p>\n<p>If you want to\
          \ continue to pretrain, you may not need vocab: <a href=\"https://huggingface.co/docs/transformers/v4.23.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining\"\
          >https://huggingface.co/docs/transformers/v4.23.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining</a>\
          \ . There is no supervised data to feed the model in such a scenario.</p>\n\
          <p>Pretraining setup (no <code>processor</code>):</p>\n<pre><code>import\
          \ torch\nfrom transformers import AutoFeatureExtractor, Wav2Vec2ForPreTraining\n\
          \nfeature_extractor = AutoFeatureExtractor.from_pretrained(\"KBLab/wav2vec2-large-voxrex\"\
          )\nmodel = Wav2Vec2ForPreTraining.from_pretrained(\"KBLab/wav2vec2-large-voxrex\"\
          )\n</code></pre>\n<p>Otherwise, if you need to finetune the model yourself\
          \ <span data-props=\"{&quot;user&quot;:&quot;birgermoell&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/birgermoell\">@<span\
          \ class=\"underline\">birgermoell</span></a></span>\n\n\t</span></span>,\
          \ my suggestion would be to <code>git clone https://huggingface.co/KBLab/wav2vec2-large-voxrex</code>,\
          \ and add all tokenizer related files from <code>https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish/tree/main</code>\
          \ to your cloned folder. Then load the model locally on your computer. </p>\n\
          <p>See: <a href=\"https://huggingface.co/blog/fine-tune-wav2vec2-english\"\
          >https://huggingface.co/blog/fine-tune-wav2vec2-english</a> for example\
          \ on creating vocab from scratch, and for finetuning. However, you should\
          \ just be able to copy over tokenizer related files from <code>KBLab/wav2vec2-large-voxrex-swedish</code>to\
          \ your cloned folder if your purpose is to finetune.</p>\n"
        raw: "@marma Is it necessary to have vocab during unsupervised pretraining?\
          \ \n\nIf you want to continue to pretrain, you may not need vocab: https://huggingface.co/docs/transformers/v4.23.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining\
          \ . There is no supervised data to feed the model in such a scenario.\n\n\
          Pretraining setup (no `processor`):\n\n```\nimport torch\nfrom transformers\
          \ import AutoFeatureExtractor, Wav2Vec2ForPreTraining\n\nfeature_extractor\
          \ = AutoFeatureExtractor.from_pretrained(\"KBLab/wav2vec2-large-voxrex\"\
          )\nmodel = Wav2Vec2ForPreTraining.from_pretrained(\"KBLab/wav2vec2-large-voxrex\"\
          )\n```\n\nOtherwise, if you need to finetune the model yourself @birgermoell,\
          \ my suggestion would be to `git clone https://huggingface.co/KBLab/wav2vec2-large-voxrex`,\
          \ and add all tokenizer related files from `https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish/tree/main`\
          \ to your cloned folder. Then load the model locally on your computer. \n\
          \nSee: [https://huggingface.co/blog/fine-tune-wav2vec2-english](https://huggingface.co/blog/fine-tune-wav2vec2-english)\
          \ for example on creating vocab from scratch, and for finetuning. However,\
          \ you should just be able to copy over tokenizer related files from `KBLab/wav2vec2-large-voxrex-swedish`to\
          \ your cloned folder if your purpose is to finetune."
        updatedAt: '2022-10-19T13:29:10.909Z'
      numEdits: 5
      reactions: []
    id: 634ff57e1d81beb8e24473f6
    type: comment
  author: Lauler
  content: "@marma Is it necessary to have vocab during unsupervised pretraining?\
    \ \n\nIf you want to continue to pretrain, you may not need vocab: https://huggingface.co/docs/transformers/v4.23.1/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining\
    \ . There is no supervised data to feed the model in such a scenario.\n\nPretraining\
    \ setup (no `processor`):\n\n```\nimport torch\nfrom transformers import AutoFeatureExtractor,\
    \ Wav2Vec2ForPreTraining\n\nfeature_extractor = AutoFeatureExtractor.from_pretrained(\"\
    KBLab/wav2vec2-large-voxrex\")\nmodel = Wav2Vec2ForPreTraining.from_pretrained(\"\
    KBLab/wav2vec2-large-voxrex\")\n```\n\nOtherwise, if you need to finetune the\
    \ model yourself @birgermoell, my suggestion would be to `git clone https://huggingface.co/KBLab/wav2vec2-large-voxrex`,\
    \ and add all tokenizer related files from `https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish/tree/main`\
    \ to your cloned folder. Then load the model locally on your computer. \n\nSee:\
    \ [https://huggingface.co/blog/fine-tune-wav2vec2-english](https://huggingface.co/blog/fine-tune-wav2vec2-english)\
    \ for example on creating vocab from scratch, and for finetuning. However, you\
    \ should just be able to copy over tokenizer related files from `KBLab/wav2vec2-large-voxrex-swedish`to\
    \ your cloned folder if your purpose is to finetune."
  created_at: 2022-10-19 12:02:54+00:00
  edited: true
  hidden: false
  id: 634ff57e1d81beb8e24473f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616427289000-6048a7b45da6ba4b1dfb9e27.jpeg?w=200&h=200&f=face
      fullname: Martin Malmsten
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: marma
      type: user
    createdAt: '2022-10-19T14:19:07.000Z'
    data:
      edited: true
      editors:
      - marma
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616427289000-6048a7b45da6ba4b1dfb9e27.jpeg?w=200&h=200&f=face
          fullname: Martin Malmsten
          isHf: false
          isPro: false
          name: marma
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Lauler&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Lauler\">@<span class=\"\
          underline\">Lauler</span></a></span>\n\n\t</span></span> You are right,\
          \ unsupervised pretraining does not need a vocab. The vocab is derived from\
          \ the speech-text pairs used in finetuning.</p>\n"
        raw: '@Lauler You are right, unsupervised pretraining does not need a vocab.
          The vocab is derived from the speech-text pairs used in finetuning.'
        updatedAt: '2022-10-19T14:19:31.046Z'
      numEdits: 1
      reactions: []
    id: 6350075bc5acdbefb8eabf1f
    type: comment
  author: marma
  content: '@Lauler You are right, unsupervised pretraining does not need a vocab.
    The vocab is derived from the speech-text pairs used in finetuning.'
  created_at: 2022-10-19 13:19:07+00:00
  edited: true
  hidden: false
  id: 6350075bc5acdbefb8eabf1f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
      fullname: Birger Moell
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: birgermoell
      type: user
    createdAt: '2022-10-20T11:12:58.000Z'
    data:
      edited: false
      editors:
      - birgermoell
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg?w=200&h=200&f=face
          fullname: Birger Moell
          isHf: false
          isPro: false
          name: birgermoell
          type: user
        html: '<p>My hope was to get the embeddings out from the base model in order
          to use it for a classification task (which is not dependent on transcription
          and that is why I don''t want to use the embeddings from the fine-tuned
          models). I''m honestly a bit confused between the difference between <a
          href="https://huggingface.co/KBLab/wav2vec2-large-voxrex">https://huggingface.co/KBLab/wav2vec2-large-voxrex</a>
          and <a href="https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish">https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish</a></p>

          '
        raw: My hope was to get the embeddings out from the base model in order to
          use it for a classification task (which is not dependent on transcription
          and that is why I don't want to use the embeddings from the fine-tuned models).
          I'm honestly a bit confused between the difference between https://huggingface.co/KBLab/wav2vec2-large-voxrex
          and https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish
        updatedAt: '2022-10-20T11:12:58.602Z'
      numEdits: 0
      reactions: []
    id: 63512d3ac9c5280e5ddc1590
    type: comment
  author: birgermoell
  content: My hope was to get the embeddings out from the base model in order to use
    it for a classification task (which is not dependent on transcription and that
    is why I don't want to use the embeddings from the fine-tuned models). I'm honestly
    a bit confused between the difference between https://huggingface.co/KBLab/wav2vec2-large-voxrex
    and https://huggingface.co/KBLab/wav2vec2-large-voxrex-swedish
  created_at: 2022-10-20 10:12:58+00:00
  edited: false
  hidden: false
  id: 63512d3ac9c5280e5ddc1590
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616427289000-6048a7b45da6ba4b1dfb9e27.jpeg?w=200&h=200&f=face
      fullname: Martin Malmsten
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: marma
      type: user
    createdAt: '2022-10-20T13:00:07.000Z'
    data:
      edited: false
      editors:
      - marma
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1616427289000-6048a7b45da6ba4b1dfb9e27.jpeg?w=200&h=200&f=face
          fullname: Martin Malmsten
          isHf: false
          isPro: false
          name: marma
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;birgermoell&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/birgermoell\"\
          >@<span class=\"underline\">birgermoell</span></a></span>\n\n\t</span></span>\
          \ The only difference is that VoxRex-swedish is a Wav2Vec2ForCTC, i.e it\
          \ has a CTC head on top of the pretrained model that has been fintuned for\
          \ Swedish. My guess is that you want <code>pooled_output</code> or something\
          \ similar. Maybe this[1] already does that?</p>\n<ol>\n<li><a href=\"https://huggingface.co/docs/transformers/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification\"\
          >https://huggingface.co/docs/transformers/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification</a></li>\n\
          </ol>\n"
        raw: '@birgermoell The only difference is that VoxRex-swedish is a Wav2Vec2ForCTC,
          i.e it has a CTC head on top of the pretrained model that has been fintuned
          for Swedish. My guess is that you want `pooled_output` or something similar.
          Maybe this[1] already does that?


          1. https://huggingface.co/docs/transformers/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification'
        updatedAt: '2022-10-20T13:00:07.098Z'
      numEdits: 0
      reactions: []
    id: 63514657a8822aadf57329ae
    type: comment
  author: marma
  content: '@birgermoell The only difference is that VoxRex-swedish is a Wav2Vec2ForCTC,
    i.e it has a CTC head on top of the pretrained model that has been fintuned for
    Swedish. My guess is that you want `pooled_output` or something similar. Maybe
    this[1] already does that?


    1. https://huggingface.co/docs/transformers/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification'
  created_at: 2022-10-20 12:00:07+00:00
  edited: false
  hidden: false
  id: 63514657a8822aadf57329ae
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: KBLab/wav2vec2-large-voxrex-swedish
repo_type: model
status: open
target_branch: null
title: Error while loading through the code at huggingface
