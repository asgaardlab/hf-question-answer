!!python/object:huggingface_hub.community.DiscussionWithDetails
author: carolinedockes
conflicting_files: null
created_at: 2023-06-01 10:19:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/849ad71356fe9dc838587f75936f91fa.svg
      fullname: Caroline Dockes
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: carolinedockes
      type: user
    createdAt: '2023-06-01T11:19:13.000Z'
    data:
      edited: true
      editors:
      - carolinedockes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/849ad71356fe9dc838587f75936f91fa.svg
          fullname: Caroline Dockes
          isHf: false
          isPro: false
          name: carolinedockes
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;pere&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/pere\">@<span class=\"\
          underline\">pere</span></a></span>\n\n\t</span></span>  Hi, very useful\
          \ model thank you! However I think there is an issue with the <code>spiece.model</code>\
          \ file.  <code>AutoTokenizer.from_pretrained(\"pere/nb-nn-translation\"\
          , use_fast = False)</code> gives a tokenizer with vocab size 250,100 whereas\
          \  <code>AutoTokenizer.from_pretrained(\"pere/nb-nn-translation\", use_fast\
          \ = True)</code> gives a vocab size of 50,003. I believe the latter, which\
          \ doesn't rely on the sentencepiece model directly, is the correct one.\
          \ Would you be able to upload the right file? Thanks!</p>\n"
        raw: '@pere  Hi, very useful model thank you! However I think there is an
          issue with the `spiece.model` file.  `AutoTokenizer.from_pretrained("pere/nb-nn-translation",
          use_fast = False)` gives a tokenizer with vocab size 250,100 whereas  `AutoTokenizer.from_pretrained("pere/nb-nn-translation",
          use_fast = True)` gives a vocab size of 50,003. I believe the latter, which
          doesn''t rely on the sentencepiece model directly, is the correct one. Would
          you be able to upload the right file? Thanks!'
        updatedAt: '2023-06-01T12:19:02.614Z'
      numEdits: 1
      reactions: []
    id: 64787eb12b3730b6b63c64fc
    type: comment
  author: carolinedockes
  content: '@pere  Hi, very useful model thank you! However I think there is an issue
    with the `spiece.model` file.  `AutoTokenizer.from_pretrained("pere/nb-nn-translation",
    use_fast = False)` gives a tokenizer with vocab size 250,100 whereas  `AutoTokenizer.from_pretrained("pere/nb-nn-translation",
    use_fast = True)` gives a vocab size of 50,003. I believe the latter, which doesn''t
    rely on the sentencepiece model directly, is the correct one. Would you be able
    to upload the right file? Thanks!'
  created_at: 2023-06-01 10:19:13+00:00
  edited: true
  hidden: false
  id: 64787eb12b3730b6b63c64fc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/849ad71356fe9dc838587f75936f91fa.svg
      fullname: Caroline Dockes
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: carolinedockes
      type: user
    createdAt: '2023-06-01T12:18:40.000Z'
    data:
      status: closed
    id: 64788ca01f9756aa89d103b2
    type: status-change
  author: carolinedockes
  created_at: 2023-06-01 11:18:40+00:00
  id: 64788ca01f9756aa89d103b2
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/849ad71356fe9dc838587f75936f91fa.svg
      fullname: Caroline Dockes
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: carolinedockes
      type: user
    createdAt: '2023-06-01T12:18:44.000Z'
    data:
      status: open
    id: 64788ca41f9756aa89d1040a
    type: status-change
  author: carolinedockes
  created_at: 2023-06-01 11:18:44+00:00
  id: 64788ca41f9756aa89d1040a
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/849ad71356fe9dc838587f75936f91fa.svg
      fullname: Caroline Dockes
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: carolinedockes
      type: user
    createdAt: '2023-06-01T13:45:33.000Z'
    data:
      edited: false
      editors:
      - carolinedockes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/849ad71356fe9dc838587f75936f91fa.svg
          fullname: Caroline Dockes
          isHf: false
          isPro: false
          name: carolinedockes
          type: user
        html: '<p>(alternatively removing that file would ensure it doesn''t get used
          by mistake)</p>

          '
        raw: (alternatively removing that file would ensure it doesn't get used by
          mistake)
        updatedAt: '2023-06-01T13:45:33.188Z'
      numEdits: 0
      reactions: []
    id: 6478a0fdad83f3939b4e51af
    type: comment
  author: carolinedockes
  content: (alternatively removing that file would ensure it doesn't get used by mistake)
  created_at: 2023-06-01 12:45:33+00:00
  edited: false
  hidden: false
  id: 6478a0fdad83f3939b4e51af
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: pere/nb-nn-translation
repo_type: model
status: open
target_branch: null
title: Wrong sentencepiece model
