!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hfgdfdsd
conflicting_files: null
created_at: 2023-07-10 23:56:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d50d4d465548524f3fe98e810681662b.svg
      fullname: f
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hfgdfdsd
      type: user
    createdAt: '2023-07-11T00:56:11.000Z'
    data:
      edited: false
      editors:
      - hfgdfdsd
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.24883213639259338
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d50d4d465548524f3fe98e810681662b.svg
          fullname: f
          isHf: false
          isPro: false
          name: hfgdfdsd
          type: user
        html: '<p>When I load it in autogptq, I just get this error. </p>

          <p>''transformers_modules.falcon-7b-instruct-GPTQ.configuration_RW.RWConfig''&gt;
          to build an AutoTokenizer.<br>Model type should be one of AlbertConfig,
          AlignConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig,<br>BigBirdPegasusConfig,
          BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BlipConfig, Blip2Config,
          BloomConfig,<br>BridgeTowerConfig, CamembertConfig, CanineConfig, ChineseCLIPConfig,
          ClapConfig, CLIPConfig, CLIPSegConfig,<br>CodeGenConfig, ConvBertConfig,
          CpmAntConfig, CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config,<br>DistilBertConfig,
          DPRConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FlaubertConfig,
          FNetConfig,<br>FSMTConfig, FunnelConfig, GitConfig, GPT2Config, GPT2Config,
          GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig,<br>GPTNeoXJapaneseConfig,
          GPTJConfig, GPTSanJapaneseConfig, GroupViTConfig, HubertConfig, IBertConfig,<br>InstructBlipConfig,
          JukeboxConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig,
          LiltConfig,<br>LlamaConfig, LongformerConfig, LongT5Config, LukeConfig,
          LxmertConfig, M2M100Config, MarianConfig, MBartConfig,<br>MegaConfig, MegatronBertConfig,
          MgpstrConfig, MobileBertConfig, MPNetConfig, MT5Config, MvpConfig, NezhaConfig,<br>NllbMoeConfig,
          NystromformerConfig, OneFormerConfig, OpenAIGPTConfig, OPTConfig, OwlViTConfig,
          PegasusConfig,<br>PegasusXConfig, PerceiverConfig, Pix2StructConfig, PLBartConfig,
          ProphetNetConfig, QDQBertConfig, RagConfig,<br>RealmConfig, ReformerConfig,
          RemBertConfig, RetriBertConfig, RobertaConfig, RobertaPreLayerNormConfig,<br>RoCBertConfig,
          RoFormerConfig, RwkvConfig, Speech2TextConfig, Speech2Text2Config, SpeechT5Config,
          SplinterConfig,<br>SqueezeBertConfig, SwitchTransformersConfig, T5Config,
          TapasConfig, TransfoXLConfig, ViltConfig, VisualBertConfig,<br>Wav2Vec2Config,
          Wav2Vec2ConformerConfig, WhisperConfig, XCLIPConfig, XGLMConfig, XLMConfig,
          XLMProphetNetConfig,<br>XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig,
          XmodConfig, YosoConfig.<br>m.seqlen = 8192</p>

          '
        raw: "When I load it in autogptq, I just get this error. \r\n\r\n'transformers_modules.falcon-7b-instruct-GPTQ.configuration_RW.RWConfig'>\
          \ to build an AutoTokenizer.\r\nModel type should be one of AlbertConfig,\
          \ AlignConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig,\r\
          \nBigBirdPegasusConfig, BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig,\
          \ BlipConfig, Blip2Config, BloomConfig, \r\nBridgeTowerConfig, CamembertConfig,\
          \ CanineConfig, ChineseCLIPConfig, ClapConfig, CLIPConfig, CLIPSegConfig,\
          \ \r\nCodeGenConfig, ConvBertConfig, CpmAntConfig, CTRLConfig, Data2VecTextConfig,\
          \ DebertaConfig, DebertaV2Config, \r\nDistilBertConfig, DPRConfig, ElectraConfig,\
          \ ErnieConfig, ErnieMConfig, EsmConfig, FlaubertConfig, FNetConfig, \r\n\
          FSMTConfig, FunnelConfig, GitConfig, GPT2Config, GPT2Config, GPTBigCodeConfig,\
          \ GPTNeoConfig, GPTNeoXConfig, \r\nGPTNeoXJapaneseConfig, GPTJConfig, GPTSanJapaneseConfig,\
          \ GroupViTConfig, HubertConfig, IBertConfig, \r\nInstructBlipConfig, JukeboxConfig,\
          \ LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig,\
          \ \r\nLlamaConfig, LongformerConfig, LongT5Config, LukeConfig, LxmertConfig,\
          \ M2M100Config, MarianConfig, MBartConfig, \r\nMegaConfig, MegatronBertConfig,\
          \ MgpstrConfig, MobileBertConfig, MPNetConfig, MT5Config, MvpConfig, NezhaConfig,\
          \ \r\nNllbMoeConfig, NystromformerConfig, OneFormerConfig, OpenAIGPTConfig,\
          \ OPTConfig, OwlViTConfig, PegasusConfig, \r\nPegasusXConfig, PerceiverConfig,\
          \ Pix2StructConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, RagConfig,\
          \ \r\nRealmConfig, ReformerConfig, RemBertConfig, RetriBertConfig, RobertaConfig,\
          \ RobertaPreLayerNormConfig, \r\nRoCBertConfig, RoFormerConfig, RwkvConfig,\
          \ Speech2TextConfig, Speech2Text2Config, SpeechT5Config, SplinterConfig,\
          \ \r\nSqueezeBertConfig, SwitchTransformersConfig, T5Config, TapasConfig,\
          \ TransfoXLConfig, ViltConfig, VisualBertConfig, \r\nWav2Vec2Config, Wav2Vec2ConformerConfig,\
          \ WhisperConfig, XCLIPConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig,\
          \ \r\nXLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig.\r\
          \nm.seqlen = 8192\r\n\r\n"
        updatedAt: '2023-07-11T00:56:11.978Z'
      numEdits: 0
      reactions: []
    id: 64aca8ab5c6fc404f0d3dfad
    type: comment
  author: hfgdfdsd
  content: "When I load it in autogptq, I just get this error. \r\n\r\n'transformers_modules.falcon-7b-instruct-GPTQ.configuration_RW.RWConfig'>\
    \ to build an AutoTokenizer.\r\nModel type should be one of AlbertConfig, AlignConfig,\
    \ BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig,\r\nBigBirdPegasusConfig,\
    \ BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BlipConfig, Blip2Config,\
    \ BloomConfig, \r\nBridgeTowerConfig, CamembertConfig, CanineConfig, ChineseCLIPConfig,\
    \ ClapConfig, CLIPConfig, CLIPSegConfig, \r\nCodeGenConfig, ConvBertConfig, CpmAntConfig,\
    \ CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, \r\nDistilBertConfig,\
    \ DPRConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FlaubertConfig,\
    \ FNetConfig, \r\nFSMTConfig, FunnelConfig, GitConfig, GPT2Config, GPT2Config,\
    \ GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, \r\nGPTNeoXJapaneseConfig, GPTJConfig,\
    \ GPTSanJapaneseConfig, GroupViTConfig, HubertConfig, IBertConfig, \r\nInstructBlipConfig,\
    \ JukeboxConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig,\
    \ LiltConfig, \r\nLlamaConfig, LongformerConfig, LongT5Config, LukeConfig, LxmertConfig,\
    \ M2M100Config, MarianConfig, MBartConfig, \r\nMegaConfig, MegatronBertConfig,\
    \ MgpstrConfig, MobileBertConfig, MPNetConfig, MT5Config, MvpConfig, NezhaConfig,\
    \ \r\nNllbMoeConfig, NystromformerConfig, OneFormerConfig, OpenAIGPTConfig, OPTConfig,\
    \ OwlViTConfig, PegasusConfig, \r\nPegasusXConfig, PerceiverConfig, Pix2StructConfig,\
    \ PLBartConfig, ProphetNetConfig, QDQBertConfig, RagConfig, \r\nRealmConfig, ReformerConfig,\
    \ RemBertConfig, RetriBertConfig, RobertaConfig, RobertaPreLayerNormConfig, \r\
    \nRoCBertConfig, RoFormerConfig, RwkvConfig, Speech2TextConfig, Speech2Text2Config,\
    \ SpeechT5Config, SplinterConfig, \r\nSqueezeBertConfig, SwitchTransformersConfig,\
    \ T5Config, TapasConfig, TransfoXLConfig, ViltConfig, VisualBertConfig, \r\nWav2Vec2Config,\
    \ Wav2Vec2ConformerConfig, WhisperConfig, XCLIPConfig, XGLMConfig, XLMConfig,\
    \ XLMProphetNetConfig, \r\nXLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig,\
    \ XmodConfig, YosoConfig.\r\nm.seqlen = 8192\r\n\r\n"
  created_at: 2023-07-10 23:56:11+00:00
  edited: false
  hidden: false
  id: 64aca8ab5c6fc404f0d3dfad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-11T09:48:52.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8071481585502625
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Are you using pipeline? If so this warning is expected and can be
          ignored.  Check the example code in the README for details on how to hide
          the message.</p>

          '
        raw: Are you using pipeline? If so this warning is expected and can be ignored.  Check
          the example code in the README for details on how to hide the message.
        updatedAt: '2023-07-11T09:48:52.507Z'
      numEdits: 0
      reactions: []
    id: 64ad25840fb9b20dbac09860
    type: comment
  author: TheBloke
  content: Are you using pipeline? If so this warning is expected and can be ignored.  Check
    the example code in the README for details on how to hide the message.
  created_at: 2023-07-11 08:48:52+00:00
  edited: false
  hidden: false
  id: 64ad25840fb9b20dbac09860
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 14
repo_id: TheBloke/Falcon-7B-Instruct-GPTQ
repo_type: model
status: open
target_branch: null
title: 'ValueError: Unrecognized configuration class '
