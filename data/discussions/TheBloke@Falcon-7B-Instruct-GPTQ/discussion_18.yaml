!!python/object:huggingface_hub.community.DiscussionWithDetails
author: herMaster
conflicting_files: null
created_at: 2023-11-20 09:22:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a0dc02e135efdb1eec6523e067d532b.svg
      fullname: Devang Dinesh Pagare
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: herMaster
      type: user
    createdAt: '2023-11-20T09:22:38.000Z'
    data:
      edited: false
      editors:
      - herMaster
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5660254955291748
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a0dc02e135efdb1eec6523e067d532b.svg
          fullname: Devang Dinesh Pagare
          isHf: false
          isPro: false
          name: herMaster
          type: user
        html: '<p>After loading the model and tokenizer, I set text generation as
          the task in the pipeline. After loading the model, its description is -
          </p>

          <p>RWGPTQForCausalLM(<br>  (model): RWForCausalLM(<br>    (transformer):
          RWModel(<br>      (word_embeddings): Embedding(65024, 4544)<br>      (h):
          ModuleList(<br>        (0-31): 32 x DecoderLayer(<br>          (input_layernorm):
          LayerNorm((4544,), eps=1e-05, elementwise_affine=True)<br>          (self_attention):
          Attention(<br>            (maybe_rotary): RotaryEmbedding()<br>            (attention_dropout):
          Dropout(p=0.0, inplace=False)<br>            (dense): GeneralQuantLinear(in_features=4544,
          out_features=4544, bias=True)<br>            (query_key_value): GeneralQuantLinear(in_features=4544,
          out_features=4672, bias=True)<br>          )<br>          (mlp): MLP(<br>            (act):
          GELU(approximate=''none'')<br>            (dense_4h_to_h): GeneralQuantLinear(in_features=18176,
          out_features=4544, bias=True)<br>            (dense_h_to_4h): GeneralQuantLinear(in_features=4544,
          out_features=18176, bias=True)<br>          )<br>        )<br>      )<br>      (ln_f):
          LayerNorm((4544,), eps=1e-05, elementwise_affine=True)<br>    )<br>    (lm_head):
          Linear(in_features=4544, out_features=65024, bias=False)<br>  )<br>)</p>

          <p>But when we set text generation as the task in the pipeline, the colab
          gives an error mentioned in the Title.</p>

          '
        raw: "After loading the model and tokenizer, I set text generation as the\
          \ task in the pipeline. After loading the model, its description is - \r\
          \n\r\nRWGPTQForCausalLM(\r\n  (model): RWForCausalLM(\r\n    (transformer):\
          \ RWModel(\r\n      (word_embeddings): Embedding(65024, 4544)\r\n      (h):\
          \ ModuleList(\r\n        (0-31): 32 x DecoderLayer(\r\n          (input_layernorm):\
          \ LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\r\n          (self_attention):\
          \ Attention(\r\n            (maybe_rotary): RotaryEmbedding()\r\n      \
          \      (attention_dropout): Dropout(p=0.0, inplace=False)\r\n          \
          \  (dense): GeneralQuantLinear(in_features=4544, out_features=4544, bias=True)\r\
          \n            (query_key_value): GeneralQuantLinear(in_features=4544, out_features=4672,\
          \ bias=True)\r\n          )\r\n          (mlp): MLP(\r\n            (act):\
          \ GELU(approximate='none')\r\n            (dense_4h_to_h): GeneralQuantLinear(in_features=18176,\
          \ out_features=4544, bias=True)\r\n            (dense_h_to_4h): GeneralQuantLinear(in_features=4544,\
          \ out_features=18176, bias=True)\r\n          )\r\n        )\r\n      )\r\
          \n      (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\r\
          \n    )\r\n    (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\r\
          \n  )\r\n)\r\n\r\nBut when we set text generation as the task in the pipeline,\
          \ the colab gives an error mentioned in the Title."
        updatedAt: '2023-11-20T09:22:38.436Z'
      numEdits: 0
      reactions: []
    id: 655b255ec692310739f4d9da
    type: comment
  author: herMaster
  content: "After loading the model and tokenizer, I set text generation as the task\
    \ in the pipeline. After loading the model, its description is - \r\n\r\nRWGPTQForCausalLM(\r\
    \n  (model): RWForCausalLM(\r\n    (transformer): RWModel(\r\n      (word_embeddings):\
    \ Embedding(65024, 4544)\r\n      (h): ModuleList(\r\n        (0-31): 32 x DecoderLayer(\r\
    \n          (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\r\
    \n          (self_attention): Attention(\r\n            (maybe_rotary): RotaryEmbedding()\r\
    \n            (attention_dropout): Dropout(p=0.0, inplace=False)\r\n         \
    \   (dense): GeneralQuantLinear(in_features=4544, out_features=4544, bias=True)\r\
    \n            (query_key_value): GeneralQuantLinear(in_features=4544, out_features=4672,\
    \ bias=True)\r\n          )\r\n          (mlp): MLP(\r\n            (act): GELU(approximate='none')\r\
    \n            (dense_4h_to_h): GeneralQuantLinear(in_features=18176, out_features=4544,\
    \ bias=True)\r\n            (dense_h_to_4h): GeneralQuantLinear(in_features=4544,\
    \ out_features=18176, bias=True)\r\n          )\r\n        )\r\n      )\r\n  \
    \    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\r\n    )\r\
    \n    (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\r\n\
    \  )\r\n)\r\n\r\nBut when we set text generation as the task in the pipeline,\
    \ the colab gives an error mentioned in the Title."
  created_at: 2023-11-20 09:22:38+00:00
  edited: false
  hidden: false
  id: 655b255ec692310739f4d9da
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: TheBloke/Falcon-7B-Instruct-GPTQ
repo_type: model
status: open
target_branch: null
title: The model 'RWGPTQForCausalLM' is not supported for text-generation.
