!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mosama
conflicting_files: null
created_at: 2024-01-10 20:41:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/35b78e198d959cbe4e0119c415bdea6d.svg
      fullname: Muhammad Osama
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mosama
      type: user
    createdAt: '2024-01-10T20:41:11.000Z'
    data:
      edited: false
      editors:
      - mosama
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8974432945251465
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/35b78e198d959cbe4e0119c415bdea6d.svg
          fullname: Muhammad Osama
          isHf: false
          isPro: false
          name: mosama
          type: user
        html: '<p>Why don''t you guys train mistral 7b 0.2 which has 32k context length
          on long context as well as short? Long Context datasets such as: </p>

          <ol>

          <li>wckwan/M4LE</li>

          <li>THUDM/LongBench</li>

          <li>togethercomputer/Long-Data-Collections</li>

          </ol>

          <p>or maybe your own long context curated ones.</p>

          '
        raw: "Why don't you guys train mistral 7b 0.2 which has 32k context length\
          \ on long context as well as short? Long Context datasets such as: \r\n\
          1) wckwan/M4LE\r\n2) THUDM/LongBench\r\n3) togethercomputer/Long-Data-Collections\r\
          \n\r\nor maybe your own long context curated ones."
        updatedAt: '2024-01-10T20:41:11.444Z'
      numEdits: 0
      reactions:
      - count: 7
        reaction: "\U0001F44D"
        users:
        - mosama
        - ziozzang
        - carlos447
        - blacksuan19
        - mirek190
        - riddlechen
        - MaziyarPanahi
    id: 659f00e7e5f0eba1c4666196
    type: comment
  author: mosama
  content: "Why don't you guys train mistral 7b 0.2 which has 32k context length on\
    \ long context as well as short? Long Context datasets such as: \r\n1) wckwan/M4LE\r\
    \n2) THUDM/LongBench\r\n3) togethercomputer/Long-Data-Collections\r\n\r\nor maybe\
    \ your own long context curated ones."
  created_at: 2024-01-10 20:41:11+00:00
  edited: false
  hidden: false
  id: 659f00e7e5f0eba1c4666196
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/35b78e198d959cbe4e0119c415bdea6d.svg
      fullname: Muhammad Osama
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mosama
      type: user
    createdAt: '2024-01-10T20:41:28.000Z'
    data:
      from: Trainv Mistral 7B 0.2
      to: Train Mistral 7B 0.2
    id: 659f00f87edb2a072eca90dc
    type: title-change
  author: mosama
  created_at: 2024-01-10 20:41:28+00:00
  id: 659f00f87edb2a072eca90dc
  new_title: Train Mistral 7B 0.2
  old_title: Trainv Mistral 7B 0.2
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2024-01-10T21:35:44.000Z'
    data:
      edited: false
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9477840065956116
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: '<p>Yea i agree, I was considering using this model in a mixtral-merge
          becuase of the scores but it would difficult considering the context constraints
          of only 8k. Making any other mistral model in the merge be limited to 8k
          despite being able to produce 32k tokens of content. </p>

          '
        raw: 'Yea i agree, I was considering using this model in a mixtral-merge becuase
          of the scores but it would difficult considering the context constraints
          of only 8k. Making any other mistral model in the merge be limited to 8k
          despite being able to produce 32k tokens of content. '
        updatedAt: '2024-01-10T21:35:44.985Z'
      numEdits: 0
      reactions: []
    id: 659f0db0b62804e6f42353e1
    type: comment
  author: rombodawg
  content: 'Yea i agree, I was considering using this model in a mixtral-merge becuase
    of the scores but it would difficult considering the context constraints of only
    8k. Making any other mistral model in the merge be limited to 8k despite being
    able to produce 32k tokens of content. '
  created_at: 2024-01-10 21:35:44+00:00
  edited: false
  hidden: false
  id: 659f0db0b62804e6f42353e1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/X0-rUPX2X2FoQ9Yy3D_lR.jpeg?w=200&h=200&f=face
      fullname: Jose Carlos Castro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: carlos447
      type: user
    createdAt: '2024-01-12T09:31:24.000Z'
    data:
      edited: false
      editors:
      - carlos447
      hidden: false
      identifiedLanguage:
        language: it
        probability: 0.9861560463905334
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/X0-rUPX2X2FoQ9Yy3D_lR.jpeg?w=200&h=200&f=face
          fullname: Jose Carlos Castro
          isHf: false
          isPro: false
          name: carlos447
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2024-01-12T09:31:24.892Z'
      numEdits: 0
      reactions: []
    id: 65a106ec26d1e9df4f096e03
    type: comment
  author: carlos447
  content: '+1'
  created_at: 2024-01-12 09:31:24+00:00
  edited: false
  hidden: false
  id: 65a106ec26d1e9df4f096e03
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1643912098555-noauth.jpeg?w=200&h=200&f=face
      fullname: Anthonny OLIME
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Citaman
      type: user
    createdAt: '2024-01-15T10:28:30.000Z'
    data:
      edited: false
      editors:
      - Citaman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.950791597366333
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1643912098555-noauth.jpeg?w=200&h=200&f=face
          fullname: Anthonny OLIME
          isHf: false
          isPro: false
          name: Citaman
          type: user
        html: '<p>I would say that the Mistral 7B V0.2 is not a pretrained model,
          but an instruction-tuned one, and therefore already has a bias towards the
          finetuning phase. For complete control over the model''s performance, it
          is best to start from a pretrained model. That may be why.</p>

          '
        raw: I would say that the Mistral 7B V0.2 is not a pretrained model, but an
          instruction-tuned one, and therefore already has a bias towards the finetuning
          phase. For complete control over the model's performance, it is best to
          start from a pretrained model. That may be why.
        updatedAt: '2024-01-15T10:28:30.062Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - sackoh
        - MaziyarPanahi
    id: 65a508ceb7897304be54af82
    type: comment
  author: Citaman
  content: I would say that the Mistral 7B V0.2 is not a pretrained model, but an
    instruction-tuned one, and therefore already has a bias towards the finetuning
    phase. For complete control over the model's performance, it is best to start
    from a pretrained model. That may be why.
  created_at: 2024-01-15 10:28:30+00:00
  edited: false
  hidden: false
  id: 65a508ceb7897304be54af82
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4c039d25c853041ebce2714ad906e0dc.svg
      fullname: Riddle Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: riddlechen
      type: user
    createdAt: '2024-01-17T08:41:10.000Z'
    data:
      edited: false
      editors:
      - riddlechen
      hidden: false
      identifiedLanguage:
        language: it
        probability: 0.9861560463905334
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4c039d25c853041ebce2714ad906e0dc.svg
          fullname: Riddle Chen
          isHf: false
          isPro: false
          name: riddlechen
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2024-01-17T08:41:10.476Z'
      numEdits: 0
      reactions: []
    id: 65a792a603548d61db68632e
    type: comment
  author: riddlechen
  content: '+1'
  created_at: 2024-01-17 08:41:10+00:00
  edited: false
  hidden: false
  id: 65a792a603548d61db68632e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b975b696676e40d0ea08aa/fXZFY9a6JxvaQt4iUCFzl.jpeg?w=200&h=200&f=face
      fullname: Sourav Chakraborty
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SvCy
      type: user
    createdAt: '2024-01-22T13:58:19.000Z'
    data:
      edited: true
      editors:
      - SvCy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3492666184902191
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64b975b696676e40d0ea08aa/fXZFY9a6JxvaQt4iUCFzl.jpeg?w=200&h=200&f=face
          fullname: Sourav Chakraborty
          isHf: false
          isPro: false
          name: SvCy
          type: user
        html: '<p><del>nvm</del><br>and i think they should definitely go beyond 7B
          parameters with openchat!</p>

          '
        raw: '~nvm~

          and i think they should definitely go beyond 7B parameters with openchat!'
        updatedAt: '2024-01-22T14:02:44.912Z'
      numEdits: 1
      reactions: []
    id: 65ae747b1dac7b5be468b2b2
    type: comment
  author: SvCy
  content: '~nvm~

    and i think they should definitely go beyond 7B parameters with openchat!'
  created_at: 2024-01-22 13:58:19+00:00
  edited: true
  hidden: false
  id: 65ae747b1dac7b5be468b2b2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: openchat/openchat-3.5-0106
repo_type: model
status: open
target_branch: null
title: Train Mistral 7B 0.2
