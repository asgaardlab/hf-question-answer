!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KatyKunXD
conflicting_files: null
created_at: 2023-10-23 05:15:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T06:15:11.000Z'
    data:
      edited: true
      editors:
      - KatyKunXD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.886457622051239
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
          fullname: Katy
          isHf: false
          isPro: false
          name: KatyKunXD
          type: user
        html: '<p>Is there any way to execute this model using a singular executable
          file like kobold CPP, I want to use it offline without having to install
          anything, Like a portable USB installation.</p>

          '
        raw: Is there any way to execute this model using a singular executable file
          like kobold CPP, I want to use it offline without having to install anything,
          Like a portable USB installation.
        updatedAt: '2023-10-23T09:23:52.778Z'
      numEdits: 1
      reactions: []
    id: 65360f6fdea545ecdac19ae1
    type: comment
  author: KatyKunXD
  content: Is there any way to execute this model using a singular executable file
    like kobold CPP, I want to use it offline without having to install anything,
    Like a portable USB installation.
  created_at: 2023-10-23 05:15:11+00:00
  edited: true
  hidden: false
  id: 65360f6fdea545ecdac19ae1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
      fullname: Laurent Mazare
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lmz
      type: user
    createdAt: '2023-10-23T07:20:34.000Z'
    data:
      edited: false
      editors:
      - lmz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.780608057975769
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
          fullname: Laurent Mazare
          isHf: false
          isPro: false
          name: lmz
          type: user
        html: '<p>You can actually run the candle executable offline with the following
          command line:</p>

          <pre><code>./phi --prompt ''my favorite programming language is '' --sample-len
          200 --quantized --weight-file model-q4k.gguf --tokenizer tokenizer.json

          </code></pre>

          <p>If you want a single executable file, you would have to pack the <code>phi</code>
          executable together with the <code>model-q4k.gguf</code> and <code>tokenizer.json</code>
          files in a self-extracting binay. This should be pretty easy to do with
          something like <a rel="nofollow" href="https://makeself.io/">makeself</a>.</p>

          '
        raw: 'You can actually run the candle executable offline with the following
          command line:

          ```

          ./phi --prompt ''my favorite programming language is '' --sample-len 200
          --quantized --weight-file model-q4k.gguf --tokenizer tokenizer.json

          ```

          If you want a single executable file, you would have to pack the `phi` executable
          together with the `model-q4k.gguf` and `tokenizer.json` files in a self-extracting
          binay. This should be pretty easy to do with something like [makeself](https://makeself.io/).'
        updatedAt: '2023-10-23T07:20:34.830Z'
      numEdits: 0
      reactions: []
    id: 65361ec2910b844786cacdc2
    type: comment
  author: lmz
  content: 'You can actually run the candle executable offline with the following
    command line:

    ```

    ./phi --prompt ''my favorite programming language is '' --sample-len 200 --quantized
    --weight-file model-q4k.gguf --tokenizer tokenizer.json

    ```

    If you want a single executable file, you would have to pack the `phi` executable
    together with the `model-q4k.gguf` and `tokenizer.json` files in a self-extracting
    binay. This should be pretty easy to do with something like [makeself](https://makeself.io/).'
  created_at: 2023-10-23 06:20:34+00:00
  edited: false
  hidden: false
  id: 65361ec2910b844786cacdc2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T08:14:16.000Z'
    data:
      edited: false
      editors:
      - KatyKunXD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8512989282608032
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
          fullname: Katy
          isHf: false
          isPro: false
          name: KatyKunXD
          type: user
        html: '<p>so the ./phi directory should contain ''model-q4k.gguf and ''tokenizer.json''?
          and for the candle executable where could I get that? sorry if Isound stupid
          but i''m not familiar with the candle framework. I see the github <a rel="nofollow"
          href="https://github.com/huggingface/candle">https://github.com/huggingface/candle</a>
          but no single exe for candle itself. do you have any easy guide for this?</p>

          '
        raw: so the ./phi directory should contain 'model-q4k.gguf and 'tokenizer.json'?
          and for the candle executable where could I get that? sorry if Isound stupid
          but i'm not familiar with the candle framework. I see the github https://github.com/huggingface/candle
          but no single exe for candle itself. do you have any easy guide for this?
        updatedAt: '2023-10-23T08:14:16.764Z'
      numEdits: 0
      reactions: []
    id: 65362b58a78e70d19cd46c8b
    type: comment
  author: KatyKunXD
  content: so the ./phi directory should contain 'model-q4k.gguf and 'tokenizer.json'?
    and for the candle executable where could I get that? sorry if Isound stupid but
    i'm not familiar with the candle framework. I see the github https://github.com/huggingface/candle
    but no single exe for candle itself. do you have any easy guide for this?
  created_at: 2023-10-23 07:14:16+00:00
  edited: false
  hidden: false
  id: 65362b58a78e70d19cd46c8b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
      fullname: Laurent Mazare
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lmz
      type: user
    createdAt: '2023-10-23T08:16:21.000Z'
    data:
      edited: false
      editors:
      - lmz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7802780866622925
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
          fullname: Laurent Mazare
          isHf: false
          isPro: false
          name: lmz
          type: user
        html: '<p>Ah sorry, <code>phi</code> is actually the executable name, to build
          it you can run from the root of the candle repo:</p>

          <pre><code class="language-bash">cargo build --example phi --release

          </code></pre>

          <p>And then you will find it under <code>./target/release/examples/phi</code>.</p>

          '
        raw: 'Ah sorry, `phi` is actually the executable name, to build it you can
          run from the root of the candle repo:

          ```bash

          cargo build --example phi --release

          ```

          And then you will find it under `./target/release/examples/phi`.'
        updatedAt: '2023-10-23T08:16:21.909Z'
      numEdits: 0
      reactions: []
    id: 65362bd5ae42162a1e18a941
    type: comment
  author: lmz
  content: 'Ah sorry, `phi` is actually the executable name, to build it you can run
    from the root of the candle repo:

    ```bash

    cargo build --example phi --release

    ```

    And then you will find it under `./target/release/examples/phi`.'
  created_at: 2023-10-23 07:16:21+00:00
  edited: false
  hidden: false
  id: 65362bd5ae42162a1e18a941
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T09:04:29.000Z'
    data:
      edited: false
      editors:
      - KatyKunXD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9608752727508545
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
          fullname: Katy
          isHf: false
          isPro: false
          name: KatyKunXD
          type: user
        html: '<p>Thank you, I''ll test this a bit later when I get a chance!</p>

          '
        raw: Thank you, I'll test this a bit later when I get a chance!
        updatedAt: '2023-10-23T09:04:29.515Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - lmz
    id: 6536371db3852ed1cefc22e0
    type: comment
  author: KatyKunXD
  content: Thank you, I'll test this a bit later when I get a chance!
  created_at: 2023-10-23 08:04:29+00:00
  edited: false
  hidden: false
  id: 6536371db3852ed1cefc22e0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T14:15:33.000Z'
    data:
      edited: true
      editors:
      - KatyKunXD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4784580171108246
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
          fullname: Katy
          isHf: false
          isPro: false
          name: KatyKunXD
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/647f66e15e1bc47537462af4/kN-DNMhBVDbenF-UAhI2l.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/647f66e15e1bc47537462af4/kN-DNMhBVDbenF-UAhI2l.png"></a></p>

          <p>I seem to get this error when running the model, any idea why?</p>

          '
        raw: '

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/647f66e15e1bc47537462af4/kN-DNMhBVDbenF-UAhI2l.png)


          I seem to get this error when running the model, any idea why?'
        updatedAt: '2023-10-23T14:15:44.424Z'
      numEdits: 1
      reactions: []
    id: 65368005d94ca568057c32f1
    type: comment
  author: KatyKunXD
  content: '

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/647f66e15e1bc47537462af4/kN-DNMhBVDbenF-UAhI2l.png)


    I seem to get this error when running the model, any idea why?'
  created_at: 2023-10-23 13:15:33+00:00
  edited: true
  hidden: false
  id: 65368005d94ca568057c32f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
      fullname: Laurent Mazare
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lmz
      type: user
    createdAt: '2023-10-23T14:21:23.000Z'
    data:
      edited: false
      editors:
      - lmz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6666097044944763
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
          fullname: Laurent Mazare
          isHf: false
          isPro: false
          name: lmz
          type: user
        html: '<p>The default model is phi-1.5, if you want to use puffin-phi-v2 you
          can pass the <code>--model puffin-phi-v2</code> flag.</p>

          '
        raw: The default model is phi-1.5, if you want to use puffin-phi-v2 you can
          pass the `--model puffin-phi-v2` flag.
        updatedAt: '2023-10-23T14:21:23.614Z'
      numEdits: 0
      reactions: []
    id: 6536816389cdab24b805005c
    type: comment
  author: lmz
  content: The default model is phi-1.5, if you want to use puffin-phi-v2 you can
    pass the `--model puffin-phi-v2` flag.
  created_at: 2023-10-23 13:21:23+00:00
  edited: false
  hidden: false
  id: 6536816389cdab24b805005c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T14:23:50.000Z'
    data:
      edited: false
      editors:
      - KatyKunXD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9688151478767395
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
          fullname: Katy
          isHf: false
          isPro: false
          name: KatyKunXD
          type: user
        html: '<p>Thanks, I had just figured it out, I notice that it generates nothing
          just a singular token.</p>

          '
        raw: Thanks, I had just figured it out, I notice that it generates nothing
          just a singular token.
        updatedAt: '2023-10-23T14:23:50.667Z'
      numEdits: 0
      reactions: []
    id: 653681f64e4e28611d2cc521
    type: comment
  author: KatyKunXD
  content: Thanks, I had just figured it out, I notice that it generates nothing just
    a singular token.
  created_at: 2023-10-23 13:23:50+00:00
  edited: false
  hidden: false
  id: 653681f64e4e28611d2cc521
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T14:25:29.000Z'
    data:
      edited: false
      editors:
      - KatyKunXD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9872409105300903
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
          fullname: Katy
          isHf: false
          isPro: false
          name: KatyKunXD
          type: user
        html: '<p>I think its just because I need to prompt it correctly</p>

          '
        raw: I think its just because I need to prompt it correctly
        updatedAt: '2023-10-23T14:25:29.003Z'
      numEdits: 0
      reactions: []
    id: 65368259fa9f02750d06ae6e
    type: comment
  author: KatyKunXD
  content: I think its just because I need to prompt it correctly
  created_at: 2023-10-23 13:25:29+00:00
  edited: false
  hidden: false
  id: 65368259fa9f02750d06ae6e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T14:41:23.000Z'
    data:
      edited: false
      editors:
      - KatyKunXD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7899680137634277
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
          fullname: Katy
          isHf: false
          isPro: false
          name: KatyKunXD
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/647f66e15e1bc47537462af4/sk2AvWTsnUSoc-wNRkQLY.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/647f66e15e1bc47537462af4/sk2AvWTsnUSoc-wNRkQLY.png"></a></p>

          <p>Works great thank you! Could you maybe add examples of inferencing your
          models in the future? also are standard gguf''s compatible with the Llama
          candle example?</p>

          '
        raw: '

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/647f66e15e1bc47537462af4/sk2AvWTsnUSoc-wNRkQLY.png)


          Works great thank you! Could you maybe add examples of inferencing your
          models in the future? also are standard gguf''s compatible with the Llama
          candle example?'
        updatedAt: '2023-10-23T14:41:23.125Z'
      numEdits: 0
      reactions: []
    id: 65368613d325b3f02f931622
    type: comment
  author: KatyKunXD
  content: '

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/647f66e15e1bc47537462af4/sk2AvWTsnUSoc-wNRkQLY.png)


    Works great thank you! Could you maybe add examples of inferencing your models
    in the future? also are standard gguf''s compatible with the Llama candle example?'
  created_at: 2023-10-23 13:41:23+00:00
  edited: false
  hidden: false
  id: 65368613d325b3f02f931622
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
      fullname: Laurent Mazare
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lmz
      type: user
    createdAt: '2023-10-23T14:45:03.000Z'
    data:
      edited: false
      editors:
      - lmz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9520014524459839
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
          fullname: Laurent Mazare
          isHf: false
          isPro: false
          name: lmz
          type: user
        html: '<p>Cool, though I''m still on the side that Pluton should be considered
          as a planet :)<br>I think there is an example showing how to inference at
          the bottom of this <a rel="nofollow" href="https://github.com/huggingface/candle/tree/main/candle-examples/examples/phi">readme</a>
          that should cover what you mention? Or maybe it''s missing some details?<br>Standard
          gguf files should work well with the <code>quantized</code> example, let
          me know if you find cases where it doesn''t work but it has been tested
          on llama2, llama2-code, mistral and a few other variants.</p>

          '
        raw: 'Cool, though I''m still on the side that Pluton should be considered
          as a planet :)

          I think there is an example showing how to inference at the bottom of this
          [readme](https://github.com/huggingface/candle/tree/main/candle-examples/examples/phi)
          that should cover what you mention? Or maybe it''s missing some details?

          Standard gguf files should work well with the `quantized` example, let me
          know if you find cases where it doesn''t work but it has been tested on
          llama2, llama2-code, mistral and a few other variants.'
        updatedAt: '2023-10-23T14:45:03.778Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - KatyKunXD
    id: 653686ef7f86289757f6fd73
    type: comment
  author: lmz
  content: 'Cool, though I''m still on the side that Pluton should be considered as
    a planet :)

    I think there is an example showing how to inference at the bottom of this [readme](https://github.com/huggingface/candle/tree/main/candle-examples/examples/phi)
    that should cover what you mention? Or maybe it''s missing some details?

    Standard gguf files should work well with the `quantized` example, let me know
    if you find cases where it doesn''t work but it has been tested on llama2, llama2-code,
    mistral and a few other variants.'
  created_at: 2023-10-23 13:45:03+00:00
  edited: false
  hidden: false
  id: 653686ef7f86289757f6fd73
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T15:59:56.000Z'
    data:
      status: closed
    id: 6536987c62dd8126cf768795
    type: status-change
  author: KatyKunXD
  created_at: 2023-10-23 14:59:56+00:00
  id: 6536987c62dd8126cf768795
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T16:16:55.000Z'
    data:
      status: open
    id: 65369c777f86289757fab6ae
    type: status-change
  author: KatyKunXD
  created_at: 2023-10-23 15:16:55+00:00
  id: 65369c777f86289757fab6ae
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T16:17:44.000Z'
    data:
      edited: false
      editors:
      - KatyKunXD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9987818598747253
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
          fullname: Katy
          isHf: false
          isPro: false
          name: KatyKunXD
          type: user
        html: '<p>Sorry, I had another issue, It seems the exe isn''t portable, as
          in it doesn''t work on any other computer than the one it was compiled on.</p>

          '
        raw: Sorry, I had another issue, It seems the exe isn't portable, as in it
          doesn't work on any other computer than the one it was compiled on.
        updatedAt: '2023-10-23T16:17:44.768Z'
      numEdits: 0
      reactions: []
    id: 65369ca8605a07338de7e407
    type: comment
  author: KatyKunXD
  content: Sorry, I had another issue, It seems the exe isn't portable, as in it doesn't
    work on any other computer than the one it was compiled on.
  created_at: 2023-10-23 15:17:44+00:00
  edited: false
  hidden: false
  id: 65369ca8605a07338de7e407
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
      fullname: Laurent Mazare
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lmz
      type: user
    createdAt: '2023-10-23T17:07:09.000Z'
    data:
      edited: false
      editors:
      - lmz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8329266905784607
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
          fullname: Laurent Mazare
          isHf: false
          isPro: false
          name: lmz
          type: user
        html: '<p>Right, that''s likely because of this <a rel="nofollow" href="https://github.com/huggingface/candle/blob/main/.cargo/config.toml">config.toml</a>
          that ensures we use all the optimizations available on the cpu at compile
          time. You can try removing these flags but note that it will disable simd
          acceleration so things will be a lot slower.</p>

          '
        raw: Right, that's likely because of this [config.toml](https://github.com/huggingface/candle/blob/main/.cargo/config.toml)
          that ensures we use all the optimizations available on the cpu at compile
          time. You can try removing these flags but note that it will disable simd
          acceleration so things will be a lot slower.
        updatedAt: '2023-10-23T17:07:09.825Z'
      numEdits: 0
      reactions: []
    id: 6536a83de48353201e4f1965
    type: comment
  author: lmz
  content: Right, that's likely because of this [config.toml](https://github.com/huggingface/candle/blob/main/.cargo/config.toml)
    that ensures we use all the optimizations available on the cpu at compile time.
    You can try removing these flags but note that it will disable simd acceleration
    so things will be a lot slower.
  created_at: 2023-10-23 16:07:09+00:00
  edited: false
  hidden: false
  id: 6536a83de48353201e4f1965
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T17:26:23.000Z'
    data:
      edited: false
      editors:
      - KatyKunXD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8811299800872803
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
          fullname: Katy
          isHf: false
          isPro: false
          name: KatyKunXD
          type: user
        html: '<p>Can the executable be made portable without compromising the optimizations?
          Are there any plans to introduce an auto-detect feature that applies optimizations
          dynamically? Apologies for the annoying amount of questions.</p>

          '
        raw: Can the executable be made portable without compromising the optimizations?
          Are there any plans to introduce an auto-detect feature that applies optimizations
          dynamically? Apologies for the annoying amount of questions.
        updatedAt: '2023-10-23T17:26:23.290Z'
      numEdits: 0
      reactions: []
    id: 6536acbf1c6cecb1f90fcdc3
    type: comment
  author: KatyKunXD
  content: Can the executable be made portable without compromising the optimizations?
    Are there any plans to introduce an auto-detect feature that applies optimizations
    dynamically? Apologies for the annoying amount of questions.
  created_at: 2023-10-23 16:26:23+00:00
  edited: false
  hidden: false
  id: 6536acbf1c6cecb1f90fcdc3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
      fullname: Laurent Mazare
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lmz
      type: user
    createdAt: '2023-10-23T17:46:03.000Z'
    data:
      edited: false
      editors:
      - lmz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9873337745666504
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf7f30a334d23c1c561a4512f55c9b3.svg
          fullname: Laurent Mazare
          isHf: false
          isPro: false
          name: lmz
          type: user
        html: '<p>That ends up being surprisingly tricky to do in a reliable way so
          we don''t have any immediate plans for this (long term this would be good
          to have though).</p>

          '
        raw: That ends up being surprisingly tricky to do in a reliable way so we
          don't have any immediate plans for this (long term this would be good to
          have though).
        updatedAt: '2023-10-23T17:46:03.734Z'
      numEdits: 0
      reactions: []
    id: 6536b15b06194959889bc8f7
    type: comment
  author: lmz
  content: That ends up being surprisingly tricky to do in a reliable way so we don't
    have any immediate plans for this (long term this would be good to have though).
  created_at: 2023-10-23 16:46:03+00:00
  edited: false
  hidden: false
  id: 6536b15b06194959889bc8f7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T18:22:35.000Z'
    data:
      edited: false
      editors:
      - KatyKunXD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.991089940071106
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
          fullname: Katy
          isHf: false
          isPro: false
          name: KatyKunXD
          type: user
        html: '<p>Thank you for being so helpful! I really appreciate it, I''m definitely
          going to keep trying candle out!</p>

          '
        raw: Thank you for being so helpful! I really appreciate it, I'm definitely
          going to keep trying candle out!
        updatedAt: '2023-10-23T18:22:35.708Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - lmz
      relatedEventId: 6536b9eb568d8be8fae58766
    id: 6536b9eb568d8be8fae58764
    type: comment
  author: KatyKunXD
  content: Thank you for being so helpful! I really appreciate it, I'm definitely
    going to keep trying candle out!
  created_at: 2023-10-23 17:22:35+00:00
  edited: false
  hidden: false
  id: 6536b9eb568d8be8fae58764
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/6ba11f383d0eabbdeedc6b309c9410d6.svg
      fullname: Katy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyKunXD
      type: user
    createdAt: '2023-10-23T18:22:35.000Z'
    data:
      status: closed
    id: 6536b9eb568d8be8fae58766
    type: status-change
  author: KatyKunXD
  created_at: 2023-10-23 17:22:35+00:00
  id: 6536b9eb568d8be8fae58766
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: lmz/candle-quantized-phi
repo_type: model
status: closed
target_branch: null
title: easy execution
