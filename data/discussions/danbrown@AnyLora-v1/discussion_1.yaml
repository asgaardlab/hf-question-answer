!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cemalgndzz
conflicting_files: null
created_at: 2023-05-11 10:09:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/30e181cf870a8b551f4593ceb34abc4c.svg
      fullname: "Cemal G\xFCnd\xFCz"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cemalgndzz
      type: user
    createdAt: '2023-05-11T11:09:29.000Z'
    data:
      edited: false
      editors:
      - cemalgndzz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/30e181cf870a8b551f4593ceb34abc4c.svg
          fullname: "Cemal G\xFCnd\xFCz"
          isHf: false
          isPro: false
          name: cemalgndzz
          type: user
        html: '<p>Hi, I have trained my own lora model with anylora base model. I
          have my weights file as safetensor and I want to use it with diffusers.
          So how can I generate a huggingface library like you did for my own trained
          lora model to use with diffusers. How did you do it ? Can you help me pls
          ?</p>

          '
        raw: Hi, I have trained my own lora model with anylora base model. I have
          my weights file as safetensor and I want to use it with diffusers. So how
          can I generate a huggingface library like you did for my own trained lora
          model to use with diffusers. How did you do it ? Can you help me pls ?
        updatedAt: '2023-05-11T11:09:29.026Z'
      numEdits: 0
      reactions: []
    id: 645ccce9f5760d1530d29644
    type: comment
  author: cemalgndzz
  content: Hi, I have trained my own lora model with anylora base model. I have my
    weights file as safetensor and I want to use it with diffusers. So how can I generate
    a huggingface library like you did for my own trained lora model to use with diffusers.
    How did you do it ? Can you help me pls ?
  created_at: 2023-05-11 10:09:29+00:00
  edited: false
  hidden: false
  id: 645ccce9f5760d1530d29644
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661956847983-noauth.png?w=200&h=200&f=face
      fullname: Daniel Brown
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: danbrown
      type: user
    createdAt: '2023-05-22T19:34:52.000Z'
    data:
      edited: false
      editors:
      - danbrown
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661956847983-noauth.png?w=200&h=200&f=face
          fullname: Daniel Brown
          isHf: false
          isPro: false
          name: danbrown
          type: user
        html: "<blockquote>\n<p>Hi, I have trained my own lora model with anylora\
          \ base model. I have my weights file as safetensor and I want to use it\
          \ with diffusers. So how can I generate a huggingface library like you did\
          \ for my own trained lora model to use with diffusers. How did you do it\
          \ ? Can you help me pls ?</p>\n</blockquote>\n<p>Hello! Sorry for the late\
          \ response, I was not aware of my notifications here. </p>\n<p>So, this\
          \ model here is a checkpoint converted to diffusers format. If you check\
          \ my profile I have many other models converted.<br>I use this scripts for\
          \ converting checkpoints, they don't work for LoRAs: <a rel=\"nofollow\"\
          \ href=\"https://github.com/danbrown/ckpt-to-diffusers\">https://github.com/danbrown/ckpt-to-diffusers</a><br>Feel\
          \ free to take a look.</p>\n<p>For using LoRAs with diffusers you can take\
          \ a look at Diffusers documentation and do your own implementation:<br><a\
          \ href=\"https://huggingface.co/docs/diffusers/v0.16.0/en/training/text2image#lora\"\
          >https://huggingface.co/docs/diffusers/v0.16.0/en/training/text2image#lora</a></p>\n\
          <p>But honestly I don't use it, I have another method with this <code>useLora</code>\
          \ function, here is a sample usage code:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\"\
          >from</span> diffusers <span class=\"hljs-keyword\">import</span> StableDiffusionPipeline\n\
          \npipe = StableDiffusionPipeline.from_pretrained(<span class=\"hljs-string\"\
          >\"runwayml/stable-diffusion-v1-5\"</span>, torch_dtype=torch.float16)\n\
          pipe = pipe.to(<span class=\"hljs-string\">\"cuda\"</span>)\n\nlora_alpha\
          \ = <span class=\"hljs-number\">0.75</span>\n\npipe = useLora(pipe, <span\
          \ class=\"hljs-string\">\"./LORAFILE.safetensors\"</span>, lora_alpha)\n\
          \nprompt = <span class=\"hljs-string\">\"a photo of an KEYWORD riding a\
          \ horse on mars\"</span>\nimage = pipe(prompt).images[<span class=\"hljs-number\"\
          >0</span>]\n</code></pre>\n<p>And here is the mentioned <code>useLora</code>\
          \ function:</p>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >import</span> time\n<span class=\"hljs-keyword\">import</span> os\n<span\
          \ class=\"hljs-keyword\">from</span> safetensors.torch <span class=\"hljs-keyword\"\
          >import</span> load_file\n\nLORA_PREFIX_UNET = <span class=\"hljs-string\"\
          >'lora_unet'</span>\nLORA_PREFIX_TEXT_ENCODER = <span class=\"hljs-string\"\
          >'lora_te'</span>\n\n<span class=\"hljs-keyword\">def</span> <span class=\"\
          hljs-title function_\">useLora</span>(<span class=\"hljs-params\">pipeline,\
          \ model_path, alpha</span>):\n\n    <span class=\"hljs-keyword\">if</span>\
          \ <span class=\"hljs-keyword\">not</span> os.path.exists(model_path):\n\
          \        <span class=\"hljs-keyword\">raise</span> Exception(<span class=\"\
          hljs-string\">\"Lora path {} does not exist\"</span>.<span class=\"hljs-built_in\"\
          >format</span>(model_path))\n\n    start = time.time()\n\n    state_dict\
          \ = load_file(model_path)\n    visited = []\n\n    <span class=\"hljs-comment\"\
          ># directly update weight in diffusers model</span>\n    <span class=\"\
          hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> state_dict:\n\
          \        \n        <span class=\"hljs-comment\"># it is suggested to print\
          \ out the key, it usually will be something like below</span>\n        <span\
          \ class=\"hljs-comment\"># \"lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\"\
          </span>\n        \n        <span class=\"hljs-comment\"># as we have set\
          \ the alpha beforehand, so just skip</span>\n        <span class=\"hljs-keyword\"\
          >if</span> <span class=\"hljs-string\">'.alpha'</span> <span class=\"hljs-keyword\"\
          >in</span> key <span class=\"hljs-keyword\">or</span> key <span class=\"\
          hljs-keyword\">in</span> visited:\n            <span class=\"hljs-keyword\"\
          >continue</span>\n            \n        <span class=\"hljs-keyword\">if</span>\
          \ <span class=\"hljs-string\">'text'</span> <span class=\"hljs-keyword\"\
          >in</span> key:\n            layer_infos = key.split(<span class=\"hljs-string\"\
          >'.'</span>)[<span class=\"hljs-number\">0</span>].split(LORA_PREFIX_TEXT_ENCODER+<span\
          \ class=\"hljs-string\">'_'</span>)[-<span class=\"hljs-number\">1</span>].split(<span\
          \ class=\"hljs-string\">'_'</span>)\n            curr_layer = pipeline.text_encoder\n\
          \        <span class=\"hljs-keyword\">else</span>:\n            layer_infos\
          \ = key.split(<span class=\"hljs-string\">'.'</span>)[<span class=\"hljs-number\"\
          >0</span>].split(LORA_PREFIX_UNET+<span class=\"hljs-string\">'_'</span>)[-<span\
          \ class=\"hljs-number\">1</span>].split(<span class=\"hljs-string\">'_'</span>)\n\
          \            curr_layer = pipeline.unet\n\n        <span class=\"hljs-comment\"\
          ># find the target layer</span>\n        temp_name = layer_infos.pop(<span\
          \ class=\"hljs-number\">0</span>)\n        <span class=\"hljs-keyword\"\
          >while</span> <span class=\"hljs-built_in\">len</span>(layer_infos) &gt;\
          \ -<span class=\"hljs-number\">1</span>:\n            <span class=\"hljs-keyword\"\
          >try</span>:\n                curr_layer = curr_layer.__getattr__(temp_name)\n\
          \                <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\"\
          >len</span>(layer_infos) &gt; <span class=\"hljs-number\">0</span>:\n  \
          \                  temp_name = layer_infos.pop(<span class=\"hljs-number\"\
          >0</span>)\n                <span class=\"hljs-keyword\">elif</span> <span\
          \ class=\"hljs-built_in\">len</span>(layer_infos) == <span class=\"hljs-number\"\
          >0</span>:\n                    <span class=\"hljs-keyword\">break</span>\n\
          \            <span class=\"hljs-keyword\">except</span> Exception:\n   \
          \             <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\"\
          >len</span>(temp_name) &gt; <span class=\"hljs-number\">0</span>:\n    \
          \                temp_name += <span class=\"hljs-string\">'_'</span>+layer_infos.pop(<span\
          \ class=\"hljs-number\">0</span>)\n                <span class=\"hljs-keyword\"\
          >else</span>:\n                    temp_name = layer_infos.pop(<span class=\"\
          hljs-number\">0</span>)\n        \n        <span class=\"hljs-comment\"\
          ># org_forward(x) + lora_up(lora_down(x)) * multiplier</span>\n        pair_keys\
          \ = []\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\"\
          >'lora_down'</span> <span class=\"hljs-keyword\">in</span> key:\n      \
          \      pair_keys.append(key.replace(<span class=\"hljs-string\">'lora_down'</span>,\
          \ <span class=\"hljs-string\">'lora_up'</span>))\n            pair_keys.append(key)\n\
          \        <span class=\"hljs-keyword\">else</span>:\n            pair_keys.append(key)\n\
          \            pair_keys.append(key.replace(<span class=\"hljs-string\">'lora_up'</span>,\
          \ <span class=\"hljs-string\">'lora_down'</span>))\n        \n        <span\
          \ class=\"hljs-comment\"># update weight</span>\n        <span class=\"\
          hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(state_dict[pair_keys[<span\
          \ class=\"hljs-number\">0</span>]].shape) == <span class=\"hljs-number\"\
          >4</span>:\n            weight_up = state_dict[pair_keys[<span class=\"\
          hljs-number\">0</span>]].squeeze(<span class=\"hljs-number\">3</span>).squeeze(<span\
          \ class=\"hljs-number\">2</span>).to(torch.float32)\n            weight_down\
          \ = state_dict[pair_keys[<span class=\"hljs-number\">1</span>]].squeeze(<span\
          \ class=\"hljs-number\">3</span>).squeeze(<span class=\"hljs-number\">2</span>).to(torch.float32)\n\
          \            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down).unsqueeze(<span\
          \ class=\"hljs-number\">2</span>).unsqueeze(<span class=\"hljs-number\"\
          >3</span>)\n        <span class=\"hljs-keyword\">else</span>:\n        \
          \    weight_up = state_dict[pair_keys[<span class=\"hljs-number\">0</span>]].to(torch.float32)\n\
          \            weight_down = state_dict[pair_keys[<span class=\"hljs-number\"\
          >1</span>]].to(torch.float32)\n            curr_layer.weight.data += alpha\
          \ * torch.mm(weight_up, weight_down)\n            \n        <span class=\"\
          hljs-comment\"># update visited list</span>\n        <span class=\"hljs-keyword\"\
          >for</span> item <span class=\"hljs-keyword\">in</span> pair_keys:\n   \
          \         visited.append(item)\n\n    <span class=\"hljs-built_in\">print</span>(<span\
          \ class=\"hljs-string\">\"Lora model {} loaded in pipeline in {} seconds\"\
          </span>.<span class=\"hljs-built_in\">format</span>(model_path, time.time()\
          \ - start))\n    <span class=\"hljs-keyword\">return</span> pipeline\n</code></pre>\n"
        raw: "> Hi, I have trained my own lora model with anylora base model. I have\
          \ my weights file as safetensor and I want to use it with diffusers. So\
          \ how can I generate a huggingface library like you did for my own trained\
          \ lora model to use with diffusers. How did you do it ? Can you help me\
          \ pls ?\n\nHello! Sorry for the late response, I was not aware of my notifications\
          \ here. \n\nSo, this model here is a checkpoint converted to diffusers format.\
          \ If you check my profile I have many other models converted.\nI use this\
          \ scripts for converting checkpoints, they don't work for LoRAs: https://github.com/danbrown/ckpt-to-diffusers\n\
          Feel free to take a look.\n\nFor using LoRAs with diffusers you can take\
          \ a look at Diffusers documentation and do your own implementation:\nhttps://huggingface.co/docs/diffusers/v0.16.0/en/training/text2image#lora\n\
          \nBut honestly I don't use it, I have another method with this `useLora`\
          \ function, here is a sample usage code:\n```python\nimport torch\nfrom\
          \ diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\"\
          runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\npipe = pipe.to(\"\
          cuda\")\n\nlora_alpha = 0.75\n\npipe = useLora(pipe, \"./LORAFILE.safetensors\"\
          , lora_alpha)\n\nprompt = \"a photo of an KEYWORD riding a horse on mars\"\
          \nimage = pipe(prompt).images[0]\n```\n\nAnd here is the mentioned `useLora`\
          \ function:\n\n\n```python\nimport time\nimport os\nfrom safetensors.torch\
          \ import load_file\n\nLORA_PREFIX_UNET = 'lora_unet'\nLORA_PREFIX_TEXT_ENCODER\
          \ = 'lora_te'\n\ndef useLora(pipeline, model_path, alpha):\n\n    if not\
          \ os.path.exists(model_path):\n        raise Exception(\"Lora path {} does\
          \ not exist\".format(model_path))\n\n    start = time.time()\n\n    state_dict\
          \ = load_file(model_path)\n    visited = []\n\n    # directly update weight\
          \ in diffusers model\n    for key in state_dict:\n        \n        # it\
          \ is suggested to print out the key, it usually will be something like below\n\
          \        # \"lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\"\
          \n        \n        # as we have set the alpha beforehand, so just skip\n\
          \        if '.alpha' in key or key in visited:\n            continue\n \
          \           \n        if 'text' in key:\n            layer_infos = key.split('.')[0].split(LORA_PREFIX_TEXT_ENCODER+'_')[-1].split('_')\n\
          \            curr_layer = pipeline.text_encoder\n        else:\n       \
          \     layer_infos = key.split('.')[0].split(LORA_PREFIX_UNET+'_')[-1].split('_')\n\
          \            curr_layer = pipeline.unet\n\n        # find the target layer\n\
          \        temp_name = layer_infos.pop(0)\n        while len(layer_infos)\
          \ > -1:\n            try:\n                curr_layer = curr_layer.__getattr__(temp_name)\n\
          \                if len(layer_infos) > 0:\n                    temp_name\
          \ = layer_infos.pop(0)\n                elif len(layer_infos) == 0:\n  \
          \                  break\n            except Exception:\n              \
          \  if len(temp_name) > 0:\n                    temp_name += '_'+layer_infos.pop(0)\n\
          \                else:\n                    temp_name = layer_infos.pop(0)\n\
          \        \n        # org_forward(x) + lora_up(lora_down(x)) * multiplier\n\
          \        pair_keys = []\n        if 'lora_down' in key:\n            pair_keys.append(key.replace('lora_down',\
          \ 'lora_up'))\n            pair_keys.append(key)\n        else:\n      \
          \      pair_keys.append(key)\n            pair_keys.append(key.replace('lora_up',\
          \ 'lora_down'))\n        \n        # update weight\n        if len(state_dict[pair_keys[0]].shape)\
          \ == 4:\n            weight_up = state_dict[pair_keys[0]].squeeze(3).squeeze(2).to(torch.float32)\n\
          \            weight_down = state_dict[pair_keys[1]].squeeze(3).squeeze(2).to(torch.float32)\n\
          \            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down).unsqueeze(2).unsqueeze(3)\n\
          \        else:\n            weight_up = state_dict[pair_keys[0]].to(torch.float32)\n\
          \            weight_down = state_dict[pair_keys[1]].to(torch.float32)\n\
          \            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down)\n\
          \            \n        # update visited list\n        for item in pair_keys:\n\
          \            visited.append(item)\n\n    print(\"Lora model {} loaded in\
          \ pipeline in {} seconds\".format(model_path, time.time() - start))\n  \
          \  return pipeline\n```"
        updatedAt: '2023-05-22T19:34:52.222Z'
      numEdits: 0
      reactions: []
    id: 646bc3dc5d68f5c15a2f5b0c
    type: comment
  author: danbrown
  content: "> Hi, I have trained my own lora model with anylora base model. I have\
    \ my weights file as safetensor and I want to use it with diffusers. So how can\
    \ I generate a huggingface library like you did for my own trained lora model\
    \ to use with diffusers. How did you do it ? Can you help me pls ?\n\nHello! Sorry\
    \ for the late response, I was not aware of my notifications here. \n\nSo, this\
    \ model here is a checkpoint converted to diffusers format. If you check my profile\
    \ I have many other models converted.\nI use this scripts for converting checkpoints,\
    \ they don't work for LoRAs: https://github.com/danbrown/ckpt-to-diffusers\nFeel\
    \ free to take a look.\n\nFor using LoRAs with diffusers you can take a look at\
    \ Diffusers documentation and do your own implementation:\nhttps://huggingface.co/docs/diffusers/v0.16.0/en/training/text2image#lora\n\
    \nBut honestly I don't use it, I have another method with this `useLora` function,\
    \ here is a sample usage code:\n```python\nimport torch\nfrom diffusers import\
    \ StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\"\
    runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\npipe = pipe.to(\"\
    cuda\")\n\nlora_alpha = 0.75\n\npipe = useLora(pipe, \"./LORAFILE.safetensors\"\
    , lora_alpha)\n\nprompt = \"a photo of an KEYWORD riding a horse on mars\"\nimage\
    \ = pipe(prompt).images[0]\n```\n\nAnd here is the mentioned `useLora` function:\n\
    \n\n```python\nimport time\nimport os\nfrom safetensors.torch import load_file\n\
    \nLORA_PREFIX_UNET = 'lora_unet'\nLORA_PREFIX_TEXT_ENCODER = 'lora_te'\n\ndef\
    \ useLora(pipeline, model_path, alpha):\n\n    if not os.path.exists(model_path):\n\
    \        raise Exception(\"Lora path {} does not exist\".format(model_path))\n\
    \n    start = time.time()\n\n    state_dict = load_file(model_path)\n    visited\
    \ = []\n\n    # directly update weight in diffusers model\n    for key in state_dict:\n\
    \        \n        # it is suggested to print out the key, it usually will be\
    \ something like below\n        # \"lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\"\
    \n        \n        # as we have set the alpha beforehand, so just skip\n    \
    \    if '.alpha' in key or key in visited:\n            continue\n           \
    \ \n        if 'text' in key:\n            layer_infos = key.split('.')[0].split(LORA_PREFIX_TEXT_ENCODER+'_')[-1].split('_')\n\
    \            curr_layer = pipeline.text_encoder\n        else:\n            layer_infos\
    \ = key.split('.')[0].split(LORA_PREFIX_UNET+'_')[-1].split('_')\n           \
    \ curr_layer = pipeline.unet\n\n        # find the target layer\n        temp_name\
    \ = layer_infos.pop(0)\n        while len(layer_infos) > -1:\n            try:\n\
    \                curr_layer = curr_layer.__getattr__(temp_name)\n            \
    \    if len(layer_infos) > 0:\n                    temp_name = layer_infos.pop(0)\n\
    \                elif len(layer_infos) == 0:\n                    break\n    \
    \        except Exception:\n                if len(temp_name) > 0:\n         \
    \           temp_name += '_'+layer_infos.pop(0)\n                else:\n     \
    \               temp_name = layer_infos.pop(0)\n        \n        # org_forward(x)\
    \ + lora_up(lora_down(x)) * multiplier\n        pair_keys = []\n        if 'lora_down'\
    \ in key:\n            pair_keys.append(key.replace('lora_down', 'lora_up'))\n\
    \            pair_keys.append(key)\n        else:\n            pair_keys.append(key)\n\
    \            pair_keys.append(key.replace('lora_up', 'lora_down'))\n        \n\
    \        # update weight\n        if len(state_dict[pair_keys[0]].shape) == 4:\n\
    \            weight_up = state_dict[pair_keys[0]].squeeze(3).squeeze(2).to(torch.float32)\n\
    \            weight_down = state_dict[pair_keys[1]].squeeze(3).squeeze(2).to(torch.float32)\n\
    \            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down).unsqueeze(2).unsqueeze(3)\n\
    \        else:\n            weight_up = state_dict[pair_keys[0]].to(torch.float32)\n\
    \            weight_down = state_dict[pair_keys[1]].to(torch.float32)\n      \
    \      curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down)\n  \
    \          \n        # update visited list\n        for item in pair_keys:\n \
    \           visited.append(item)\n\n    print(\"Lora model {} loaded in pipeline\
    \ in {} seconds\".format(model_path, time.time() - start))\n    return pipeline\n\
    ```"
  created_at: 2023-05-22 18:34:52+00:00
  edited: false
  hidden: false
  id: 646bc3dc5d68f5c15a2f5b0c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: danbrown/AnyLora-v1
repo_type: model
status: open
target_branch: null
title: weights safetensor to huggingface repo
