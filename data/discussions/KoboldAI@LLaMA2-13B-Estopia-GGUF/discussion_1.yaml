!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Susierune
conflicting_files: null
created_at: 2024-01-18 23:30:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/afaf17efe86a72e6c22e86f0d0471aa1.svg
      fullname: Kris Dreemurr
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Susierune
      type: user
    createdAt: '2024-01-18T23:30:25.000Z'
    data:
      edited: false
      editors:
      - Susierune
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9624541401863098
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/afaf17efe86a72e6c22e86f0d0471aa1.svg
          fullname: Kris Dreemurr
          isHf: false
          isPro: false
          name: Susierune
          type: user
        html: '<p>First of all, I''m glad that the format is provided. So far this
          has been the best 13b I''ve used when it comes to creativity and prose.
          It picked up the right information on the character cards thus leading to
          provide a better roleplay experience. It reminds me of 20b models sometimes.
          However, the logical errors are a problem when it comes to this model. I
          had temperature set to 0.90 and tried lowering it to 0.80. I still feel
          like there is room for improvement. If the logic of this model can be improved
          without sacrificing its creativity and prose it could be a pretty good model.</p>

          '
        raw: First of all, I'm glad that the format is provided. So far this has been
          the best 13b I've used when it comes to creativity and prose. It picked
          up the right information on the character cards thus leading to provide
          a better roleplay experience. It reminds me of 20b models sometimes. However,
          the logical errors are a problem when it comes to this model. I had temperature
          set to 0.90 and tried lowering it to 0.80. I still feel like there is room
          for improvement. If the logic of this model can be improved without sacrificing
          its creativity and prose it could be a pretty good model.
        updatedAt: '2024-01-18T23:30:25.902Z'
      numEdits: 0
      reactions: []
    id: 65a9b49160170e802567e670
    type: comment
  author: Susierune
  content: First of all, I'm glad that the format is provided. So far this has been
    the best 13b I've used when it comes to creativity and prose. It picked up the
    right information on the character cards thus leading to provide a better roleplay
    experience. It reminds me of 20b models sometimes. However, the logical errors
    are a problem when it comes to this model. I had temperature set to 0.90 and tried
    lowering it to 0.80. I still feel like there is room for improvement. If the logic
    of this model can be improved without sacrificing its creativity and prose it
    could be a pretty good model.
  created_at: 2024-01-18 23:30:25+00:00
  edited: false
  hidden: false
  id: 65a9b49160170e802567e670
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: KoboldAI/LLaMA2-13B-Estopia-GGUF
repo_type: model
status: open
target_branch: null
title: Great creativity
