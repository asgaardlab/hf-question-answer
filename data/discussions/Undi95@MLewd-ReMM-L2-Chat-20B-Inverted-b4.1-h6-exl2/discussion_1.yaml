!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SekkSea
conflicting_files: null
created_at: 2023-09-19 20:07:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3b6689c0c08083a26b4b251a0a9d37ca.svg
      fullname: Edward Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SekkSea
      type: user
    createdAt: '2023-09-19T21:07:27.000Z'
    data:
      edited: false
      editors:
      - SekkSea
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9952885508537292
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3b6689c0c08083a26b4b251a0a9d37ca.svg
          fullname: Edward Smith
          isHf: false
          isPro: false
          name: SekkSea
          type: user
        html: '<p>I was going to download until I read the part about it being broken.
          Thanks for the effort anyway. Three hours is a long time... I didn''t know
          converting to exl2 was that bad.</p>

          '
        raw: I was going to download until I read the part about it being broken.
          Thanks for the effort anyway. Three hours is a long time... I didn't know
          converting to exl2 was that bad.
        updatedAt: '2023-09-19T21:07:27.498Z'
      numEdits: 0
      reactions: []
    id: 650a0d8f623330a3a536ad5f
    type: comment
  author: SekkSea
  content: I was going to download until I read the part about it being broken. Thanks
    for the effort anyway. Three hours is a long time... I didn't know converting
    to exl2 was that bad.
  created_at: 2023-09-19 20:07:27+00:00
  edited: false
  hidden: false
  id: 650a0d8f623330a3a536ad5f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2023-09-19T22:36:21.000Z'
    data:
      edited: false
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9809024333953857
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<blockquote>

          <p>I was going to download until I read the part about it being broken.
          Thanks for the effort anyway. Three hours is a long time... I didn''t know
          converting to exl2 was that bad.</p>

          </blockquote>

          <p>I''m sorry, apparently the last update of Oobabooga broke EXL2 so i''m
          waiting a little before putting it down to double check.<br>I hope you can
          use the GGUF anyway!</p>

          '
        raw: '> I was going to download until I read the part about it being broken.
          Thanks for the effort anyway. Three hours is a long time... I didn''t know
          converting to exl2 was that bad.


          I''m sorry, apparently the last update of Oobabooga broke EXL2 so i''m waiting
          a little before putting it down to double check.

          I hope you can use the GGUF anyway!'
        updatedAt: '2023-09-19T22:36:21.149Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - SekkSea
    id: 650a226523196fb2d856bed9
    type: comment
  author: Undi95
  content: '> I was going to download until I read the part about it being broken.
    Thanks for the effort anyway. Three hours is a long time... I didn''t know converting
    to exl2 was that bad.


    I''m sorry, apparently the last update of Oobabooga broke EXL2 so i''m waiting
    a little before putting it down to double check.

    I hope you can use the GGUF anyway!'
  created_at: 2023-09-19 21:36:21+00:00
  edited: false
  hidden: false
  id: 650a226523196fb2d856bed9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3b6689c0c08083a26b4b251a0a9d37ca.svg
      fullname: Edward Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SekkSea
      type: user
    createdAt: '2023-09-20T01:03:34.000Z'
    data:
      edited: false
      editors:
      - SekkSea
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9368780255317688
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3b6689c0c08083a26b4b251a0a9d37ca.svg
          fullname: Edward Smith
          isHf: false
          isPro: false
          name: SekkSea
          type: user
        html: '<p>No worries, and thanks for the heads up about the latest oobabooga
          update. I think I''ll skip that one, lol...</p>

          '
        raw: No worries, and thanks for the heads up about the latest oobabooga update.
          I think I'll skip that one, lol...
        updatedAt: '2023-09-20T01:03:34.814Z'
      numEdits: 0
      reactions: []
    id: 650a44e6ac5108b93a9e2779
    type: comment
  author: SekkSea
  content: No worries, and thanks for the heads up about the latest oobabooga update.
    I think I'll skip that one, lol...
  created_at: 2023-09-20 00:03:34+00:00
  edited: false
  hidden: false
  id: 650a44e6ac5108b93a9e2779
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ef9580409b265901c409d64d9ede3f0.svg
      fullname: hun ty
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hunty1
      type: user
    createdAt: '2023-09-20T10:14:54.000Z'
    data:
      edited: false
      editors:
      - hunty1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9802727103233337
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ef9580409b265901c409d64d9ede3f0.svg
          fullname: hun ty
          isHf: false
          isPro: false
          name: hunty1
          type: user
        html: '<p>This works pretty well for me..?</p>

          '
        raw: This works pretty well for me..?
        updatedAt: '2023-09-20T10:14:54.201Z'
      numEdits: 0
      reactions: []
    id: 650ac61eb5a04c8675f3adcb
    type: comment
  author: hunty1
  content: This works pretty well for me..?
  created_at: 2023-09-20 09:14:54+00:00
  edited: false
  hidden: false
  id: 650ac61eb5a04c8675f3adcb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2023-09-20T12:01:45.000Z'
    data:
      edited: false
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9280059933662415
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<blockquote>

          <p>This works pretty well for me..?</p>

          </blockquote>

          <p>Are you on Oobabooga ?<br>Also thanks for the double check!</p>

          '
        raw: '> This works pretty well for me..?


          Are you on Oobabooga ?

          Also thanks for the double check!'
        updatedAt: '2023-09-20T12:01:45.807Z'
      numEdits: 0
      reactions: []
    id: 650adf297f89a2bf35b81025
    type: comment
  author: Undi95
  content: '> This works pretty well for me..?


    Are you on Oobabooga ?

    Also thanks for the double check!'
  created_at: 2023-09-20 11:01:45+00:00
  edited: false
  hidden: false
  id: 650adf297f89a2bf35b81025
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ef9580409b265901c409d64d9ede3f0.svg
      fullname: hun ty
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hunty1
      type: user
    createdAt: '2023-09-20T12:26:58.000Z'
    data:
      edited: true
      editors:
      - hunty1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9575616717338562
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ef9580409b265901c409d64d9ede3f0.svg
          fullname: hun ty
          isHf: false
          isPro: false
          name: hunty1
          type: user
        html: '<blockquote>

          <blockquote>

          <p>This works pretty well for me..?</p>

          </blockquote>

          <p>Are you on Oobabooga ?<br>Also thanks for the double check!</p>

          </blockquote>

          <p>Ooba yep, exxlama 2, 4096 context.  Takes up 19GB of VRAM on a 3090,
          gens are fast and the quality is really good. (8k context just barely doesn''t
          fit, it starts using system ram and becomes extremely slow) Way better coom
          output than Mytho, and I feel like it''s smarter too, following defs a lot
          better. So I don''t think it''s broken at all.</p>

          '
        raw: "> > This works pretty well for me..?\n> \n> Are you on Oobabooga ?\n\
          > Also thanks for the double check!\n\nOoba yep, exxlama 2, 4096 context.\
          \  Takes up 19GB of VRAM on a 3090, gens are fast and the quality is really\
          \ good. (8k context just barely doesn't fit, it starts using system ram\
          \ and becomes extremely slow) Way better coom output than Mytho, and I feel\
          \ like it's smarter too, following defs a lot better. So I don't think it's\
          \ broken at all."
        updatedAt: '2023-09-20T12:27:24.914Z'
      numEdits: 1
      reactions: []
    id: 650ae51292b07d067ccf5670
    type: comment
  author: hunty1
  content: "> > This works pretty well for me..?\n> \n> Are you on Oobabooga ?\n>\
    \ Also thanks for the double check!\n\nOoba yep, exxlama 2, 4096 context.  Takes\
    \ up 19GB of VRAM on a 3090, gens are fast and the quality is really good. (8k\
    \ context just barely doesn't fit, it starts using system ram and becomes extremely\
    \ slow) Way better coom output than Mytho, and I feel like it's smarter too, following\
    \ defs a lot better. So I don't think it's broken at all."
  created_at: 2023-09-20 11:26:58+00:00
  edited: true
  hidden: false
  id: 650ae51292b07d067ccf5670
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3b6689c0c08083a26b4b251a0a9d37ca.svg
      fullname: Edward Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SekkSea
      type: user
    createdAt: '2023-09-20T20:30:33.000Z'
    data:
      edited: true
      editors:
      - SekkSea
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9462274312973022
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3b6689c0c08083a26b4b251a0a9d37ca.svg
          fullname: Edward Smith
          isHf: false
          isPro: false
          name: SekkSea
          type: user
        html: '<p>Nice! I ended up downloading it. At 1500-2024 context, it takes
          up about 14GB of VRAM, slightly more than my budget 3060 can handle, as
          about 2GB goes to the CPU, but it''s still responding surprisingly fast.
          I''m getting 2 tokens per second. I guess this must be a result of the exl2
          file type? With exllama1 + GPTQ, when I went 2GB over the GPU limit I would
          get about 0.24 tokens per second.</p>

          <p>It''s definitely worth the wait. Way better than Mythomax 13b.</p>

          '
        raw: 'Nice! I ended up downloading it. At 1500-2024 context, it takes up about
          14GB of VRAM, slightly more than my budget 3060 can handle, as about 2GB
          goes to the CPU, but it''s still responding surprisingly fast. I''m getting
          2 tokens per second. I guess this must be a result of the exl2 file type?
          With exllama1 + GPTQ, when I went 2GB over the GPU limit I would get about
          0.24 tokens per second.


          It''s definitely worth the wait. Way better than Mythomax 13b.'
        updatedAt: '2023-09-20T20:43:17.914Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Undi95
    id: 650b56693d41ccbfdf0fd409
    type: comment
  author: SekkSea
  content: 'Nice! I ended up downloading it. At 1500-2024 context, it takes up about
    14GB of VRAM, slightly more than my budget 3060 can handle, as about 2GB goes
    to the CPU, but it''s still responding surprisingly fast. I''m getting 2 tokens
    per second. I guess this must be a result of the exl2 file type? With exllama1
    + GPTQ, when I went 2GB over the GPU limit I would get about 0.24 tokens per second.


    It''s definitely worth the wait. Way better than Mythomax 13b.'
  created_at: 2023-09-20 19:30:33+00:00
  edited: true
  hidden: false
  id: 650b56693d41ccbfdf0fd409
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Undi95/MLewd-ReMM-L2-Chat-20B-Inverted-b4.1-h6-exl2
repo_type: model
status: open
target_branch: null
title: Yikes
