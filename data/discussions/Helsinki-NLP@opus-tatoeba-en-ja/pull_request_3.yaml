!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sgugger
conflicting_files: []
created_at: 2023-06-20 14:30:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593126474392-5ef50182b71947201082a4e5.jpeg?w=200&h=200&f=face
      fullname: Sylvain Gugger
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sgugger
      type: user
    createdAt: '2023-06-20T15:30:04.000Z'
    data:
      edited: false
      editors:
      - sgugger
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9755750894546509
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593126474392-5ef50182b71947201082a4e5.jpeg?w=200&h=200&f=face
          fullname: Sylvain Gugger
          isHf: false
          isPro: false
          name: sgugger
          type: user
        html: '<p>There was probably a bug in the initial conversion script that created
          those models, as the weights they have have a<br>different value for <code>lm_head.weight</code>
          and <code>model.decoder.embed_tokens.weight</code>. Those models are tied
          though.</p>

          <p>This was not a problem until now as the model was tied after the load
          and the (wrong) value of <code>lm_head.weight</code> was<br>replaced by
          the value of <code>model.decoder.embed_tokens.weight</code>. This does not
          work any more if we tie the weights before<br>the load however, as the value
          picked might be the one from <code>lm_head.weight</code> depending on how
          the models are tied.<br>As far as I can see, the model stop generating properly
          on Transformers main.</p>

          <p>This should fix the bug without any side effect.</p>

          '
        raw: 'There was probably a bug in the initial conversion script that created
          those models, as the weights they have have a

          different value for `lm_head.weight` and `model.decoder.embed_tokens.weight`.
          Those models are tied though.


          This was not a problem until now as the model was tied after the load and
          the (wrong) value of `lm_head.weight` was

          replaced by the value of `model.decoder.embed_tokens.weight`. This does
          not work any more if we tie the weights before

          the load however, as the value picked might be the one from `lm_head.weight`
          depending on how the models are tied.

          As far as I can see, the model stop generating properly on Transformers
          main.


          This should fix the bug without any side effect.'
        updatedAt: '2023-06-20T15:30:04.776Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - droussis
    id: 6491c5fc4aef3e6f9cbcf1a4
    type: comment
  author: sgugger
  content: 'There was probably a bug in the initial conversion script that created
    those models, as the weights they have have a

    different value for `lm_head.weight` and `model.decoder.embed_tokens.weight`.
    Those models are tied though.


    This was not a problem until now as the model was tied after the load and the
    (wrong) value of `lm_head.weight` was

    replaced by the value of `model.decoder.embed_tokens.weight`. This does not work
    any more if we tie the weights before

    the load however, as the value picked might be the one from `lm_head.weight` depending
    on how the models are tied.

    As far as I can see, the model stop generating properly on Transformers main.


    This should fix the bug without any side effect.'
  created_at: 2023-06-20 14:30:04+00:00
  edited: false
  hidden: false
  id: 6491c5fc4aef3e6f9cbcf1a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1593126474392-5ef50182b71947201082a4e5.jpeg?w=200&h=200&f=face
      fullname: Sylvain Gugger
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sgugger
      type: user
    createdAt: '2023-06-20T15:30:05.000Z'
    data:
      oid: 00ab68db67d8add0109783fda8845e7e24d4754f
      parents:
      - 036f9bdb2cdd445ceaf9319defc0e0eda5c68b9a
      subject: Fix weights by putting the right value in `lm_head.weight`
    id: 6491c5fd0000000000000000
    type: commit
  author: sgugger
  created_at: 2023-06-20 14:30:05+00:00
  id: 6491c5fd0000000000000000
  oid: 00ab68db67d8add0109783fda8845e7e24d4754f
  summary: Fix weights by putting the right value in `lm_head.weight`
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-09-18T18:54:04.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.979691743850708
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Thanks I can''t merge but this fixes the issues for these models</p>

          '
        raw: Thanks I can't merge but this fixes the issues for these models
        updatedAt: '2023-09-18T18:54:04.075Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - droussis
    id: 65089cccc2d4c8fc37741e4e
    type: comment
  author: ArthurZ
  content: Thanks I can't merge but this fixes the issues for these models
  created_at: 2023-09-18 17:54:04+00:00
  edited: false
  hidden: false
  id: 65089cccc2d4c8fc37741e4e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6366fe0ba2abcdf2fd6be58b/5Uy79Kr-TTCXYYU-sqsX9.jpeg?w=200&h=200&f=face
      fullname: Dimitris Roussis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: droussis
      type: user
    createdAt: '2023-09-18T21:40:22.000Z'
    data:
      edited: false
      editors:
      - droussis
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8726463913917542
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6366fe0ba2abcdf2fd6be58b/5Uy79Kr-TTCXYYU-sqsX9.jpeg?w=200&h=200&f=face
          fullname: Dimitris Roussis
          isHf: false
          isPro: false
          name: droussis
          type: user
        html: '<p>Thank you very much.  I''m a bit confused though.<br>I want to convert
          a Marian MT model (from <a rel="nofollow" href="https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models">Tatoeba-Challenge</a>)
          to PyTorch, so as to use it with HF locally.<br>In order to apply this fix,
          should I make changes to the <a rel="nofollow" href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/marian/modeling_marian.py">MarianMTModel</a>
          or in the conversion script as well?</p>

          '
        raw: "Thank you very much.  I'm a bit confused though. \nI want to convert\
          \ a Marian MT model (from [Tatoeba-Challenge](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models))\
          \ to PyTorch, so as to use it with HF locally.\nIn order to apply this fix,\
          \ should I make changes to the [MarianMTModel](https://github.com/huggingface/transformers/blob/main/src/transformers/models/marian/modeling_marian.py)\
          \ or in the conversion script as well?"
        updatedAt: '2023-09-18T21:40:22.034Z'
      numEdits: 0
      reactions: []
    id: 6508c3c6f36bb51c50fd1180
    type: comment
  author: droussis
  content: "Thank you very much.  I'm a bit confused though. \nI want to convert a\
    \ Marian MT model (from [Tatoeba-Challenge](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models))\
    \ to PyTorch, so as to use it with HF locally.\nIn order to apply this fix, should\
    \ I make changes to the [MarianMTModel](https://github.com/huggingface/transformers/blob/main/src/transformers/models/marian/modeling_marian.py)\
    \ or in the conversion script as well?"
  created_at: 2023-09-18 20:40:22+00:00
  edited: false
  hidden: false
  id: 6508c3c6f36bb51c50fd1180
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-09-19T10:55:14.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8107739090919495
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>If you use the latest release of transformers, the conversion should
          work out of the box! Does it not?</p>

          '
        raw: If you use the latest release of transformers, the conversion should
          work out of the box! Does it not?
        updatedAt: '2023-09-19T10:55:14.984Z'
      numEdits: 0
      reactions: []
    id: 65097e12ed23af2c5d1bb26b
    type: comment
  author: ArthurZ
  content: If you use the latest release of transformers, the conversion should work
    out of the box! Does it not?
  created_at: 2023-09-19 09:55:14+00:00
  edited: false
  hidden: false
  id: 65097e12ed23af2c5d1bb26b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/0223584657947ca7393ba46d211d6970.svg
      fullname: "J\xF6rg Tiedemann"
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: tiedeman
      type: user
    createdAt: '2023-09-19T11:15:18.000Z'
    data:
      status: merged
    id: 650982c66fb511ba9e831fd2
    type: status-change
  author: tiedeman
  created_at: 2023-09-19 10:15:18+00:00
  id: 650982c66fb511ba9e831fd2
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 3a282648cb991174f3c423e376aff3a13e5edaaf
num: 3
repo_id: Helsinki-NLP/opus-tatoeba-en-ja
repo_type: model
status: merged
target_branch: refs/heads/main
title: Fix weights by putting the right value in `lm_head.weight`
