!!python/object:huggingface_hub.community.DiscussionWithDetails
author: adamo1139
conflicting_files: null
created_at: 2023-06-07 22:31:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3f7d24c9cfa2f12d2fd42fcc0a8d820a.svg
      fullname: Adam
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: adamo1139
      type: user
    createdAt: '2023-06-07T23:31:13.000Z'
    data:
      edited: false
      editors:
      - adamo1139
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9378200173377991
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3f7d24c9cfa2f12d2fd42fcc0a8d820a.svg
          fullname: Adam
          isHf: false
          isPro: false
          name: adamo1139
          type: user
        html: '<p>Aeala released two LoRA''s for this model. One 3.2 GB trained for
          1200 steps and then one trained on updated QLoRA repo that was trained for
          1000 steps and weights 1.6 GB. Are all quantizations in this repo, even
          the new methods, merges of the older 1200 step 3.2 GB LoRA with base model?</p>

          '
        raw: Aeala released two LoRA's for this model. One 3.2 GB trained for 1200
          steps and then one trained on updated QLoRA repo that was trained for 1000
          steps and weights 1.6 GB. Are all quantizations in this repo, even the new
          methods, merges of the older 1200 step 3.2 GB LoRA with base model?
        updatedAt: '2023-06-07T23:31:13.038Z'
      numEdits: 0
      reactions: []
    id: 64811341856901b0edbc8705
    type: comment
  author: adamo1139
  content: Aeala released two LoRA's for this model. One 3.2 GB trained for 1200 steps
    and then one trained on updated QLoRA repo that was trained for 1000 steps and
    weights 1.6 GB. Are all quantizations in this repo, even the new methods, merges
    of the older 1200 step 3.2 GB LoRA with base model?
  created_at: 2023-06-07 22:31:13+00:00
  edited: false
  hidden: false
  id: 64811341856901b0edbc8705
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-07T23:54:22.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9781399369239807
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>All the files will be whatever was in Aeala''s repo 9 days ago,
          which I assume is the 1200 step one?</p>

          <p>When I did the new quants I didn''t re-merge the LoRA. I re-quantised
          from the fp16 merge I did when I first made the repo 9 days ago.</p>

          <p>If there''s a new and better version out then I can add this to my list
          of models, and re-do all the quants in the next few days.</p>

          '
        raw: 'All the files will be whatever was in Aeala''s repo 9 days ago, which
          I assume is the 1200 step one?


          When I did the new quants I didn''t re-merge the LoRA. I re-quantised from
          the fp16 merge I did when I first made the repo 9 days ago.


          If there''s a new and better version out then I can add this to my list
          of models, and re-do all the quants in the next few days.'
        updatedAt: '2023-06-07T23:54:22.807Z'
      numEdits: 0
      reactions: []
    id: 648118ae40facadc5576f97d
    type: comment
  author: TheBloke
  content: 'All the files will be whatever was in Aeala''s repo 9 days ago, which
    I assume is the 1200 step one?


    When I did the new quants I didn''t re-merge the LoRA. I re-quantised from the
    fp16 merge I did when I first made the repo 9 days ago.


    If there''s a new and better version out then I can add this to my list of models,
    and re-do all the quants in the next few days.'
  created_at: 2023-06-07 22:54:22+00:00
  edited: false
  hidden: false
  id: 648118ae40facadc5576f97d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/BYs57LZ4sV-_IV1tRFD8W.png?w=200&h=200&f=face
      fullname: A'eala
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aeala
      type: user
    createdAt: '2023-07-10T08:46:23.000Z'
    data:
      edited: false
      editors:
      - Aeala
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9910855889320374
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/BYs57LZ4sV-_IV1tRFD8W.png?w=200&h=200&f=face
          fullname: A'eala
          isHf: false
          isPro: false
          name: Aeala
          type: user
        html: '<p>I did release a new one since then that was redone with a newer
          version of the QLoRA repo, so if there were bugs caused from the last one,
          they''re likely fixed this one. Up to you whether you want to redo them
          of course. ^~^ Thanks for your work!</p>

          '
        raw: I did release a new one since then that was redone with a newer version
          of the QLoRA repo, so if there were bugs caused from the last one, they're
          likely fixed this one. Up to you whether you want to redo them of course.
          ^~^ Thanks for your work!
        updatedAt: '2023-07-10T08:46:23.436Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - phi0112358
    id: 64abc55f4135aae75f56465a
    type: comment
  author: Aeala
  content: I did release a new one since then that was redone with a newer version
    of the QLoRA repo, so if there were bugs caused from the last one, they're likely
    fixed this one. Up to you whether you want to redo them of course. ^~^ Thanks
    for your work!
  created_at: 2023-07-10 07:46:23+00:00
  edited: false
  hidden: false
  id: 64abc55f4135aae75f56465a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/VicUnlocked-alpaca-65B-QLoRA-GGML
repo_type: model
status: open
target_branch: null
title: Is it older attempt stopped at 1200 steps or the newer one stopped at 1000
  steps?
