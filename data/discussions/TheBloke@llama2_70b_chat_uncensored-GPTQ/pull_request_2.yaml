!!python/object:huggingface_hub.community.DiscussionWithDetails
author: YokaiKoibito
conflicting_files:
- README.md
created_at: 2023-09-06 18:49:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
      fullname: Yokai Koibito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YokaiKoibito
      type: user
    createdAt: '2023-09-06T19:49:59.000Z'
    data:
      edited: false
      editors:
      - YokaiKoibito
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
          fullname: Yokai Koibito
          isHf: false
          isPro: false
          name: YokaiKoibito
          type: user
        html: ''
        raw: ''
        updatedAt: '2023-09-06T19:49:59.309Z'
      numEdits: 0
      reactions: []
    id: 64f8d7e729a9aa4778ee68b3
    type: comment
  author: YokaiKoibito
  content: ''
  created_at: 2023-09-06 18:49:59+00:00
  edited: false
  hidden: false
  id: 64f8d7e729a9aa4778ee68b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
      fullname: Yokai Koibito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YokaiKoibito
      type: user
    createdAt: '2023-09-06T19:50:00.000Z'
    data:
      oid: b546c838f83b90614a887f37718f1b7fcb127b08
      parents:
      - 9d9709128edfb96e611e19deb74f001884b35183
      subject: Expand Repositories section to add links to a couple more versions
    id: 64f8d7e80000000000000000
    type: commit
  author: YokaiKoibito
  created_at: 2023-09-06 18:50:00+00:00
  id: 64f8d7e80000000000000000
  oid: b546c838f83b90614a887f37718f1b7fcb127b08
  summary: Expand Repositories section to add links to a couple more versions
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-09-06T19:55:30.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9590003490447998
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I''m a bit confused about what this is for?  You''ve added a GGUF
          link to a Wizard Falcon 40B GGUF?  Why would that be linked from llama2
          70B Chat Uncensored?  Also the URL is invalid.</p>

          <p>My GGUFs for this model, llama2 70b Chat Uncensored are next in the queue
          actually, so will appear quite soon.</p>

          <p>I''ll be getting around to Falcon GGUFs quite soon.</p>

          '
        raw: 'I''m a bit confused about what this is for?  You''ve added a GGUF link
          to a Wizard Falcon 40B GGUF?  Why would that be linked from llama2 70B Chat
          Uncensored?  Also the URL is invalid.


          My GGUFs for this model, llama2 70b Chat Uncensored are next in the queue
          actually, so will appear quite soon.


          I''ll be getting around to Falcon GGUFs quite soon.'
        updatedAt: '2023-09-06T19:57:45.315Z'
      numEdits: 2
      reactions: []
      relatedEventId: 64f8d932c29cdd969464e12e
    id: 64f8d932c29cdd969464e12a
    type: comment
  author: TheBloke
  content: 'I''m a bit confused about what this is for?  You''ve added a GGUF link
    to a Wizard Falcon 40B GGUF?  Why would that be linked from llama2 70B Chat Uncensored?  Also
    the URL is invalid.


    My GGUFs for this model, llama2 70b Chat Uncensored are next in the queue actually,
    so will appear quite soon.


    I''ll be getting around to Falcon GGUFs quite soon.'
  created_at: 2023-09-06 18:55:30+00:00
  edited: true
  hidden: false
  id: 64f8d932c29cdd969464e12a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-09-06T19:55:30.000Z'
    data:
      status: closed
    id: 64f8d932c29cdd969464e12e
    type: status-change
  author: TheBloke
  created_at: 2023-09-06 18:55:30+00:00
  id: 64f8d932c29cdd969464e12e
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
      fullname: Yokai Koibito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YokaiKoibito
      type: user
    createdAt: '2023-09-07T07:47:49.000Z'
    data:
      edited: true
      editors:
      - YokaiKoibito
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9889617562294006
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
          fullname: Yokai Koibito
          isHf: false
          isPro: false
          name: YokaiKoibito
          type: user
        html: '<p>Sorry, it looks like I must have garbled the edit: I was doing GGUFs
          of two models that you hadn''t got to, and it sounds like I must have added
          the wrong crosslink. Anyway, if you''re going to do them soon, it''s probably
          less confusing for people if everything comes through you.</p>

          <p>Incidentally, is there any logistical issue to doing GGUFs of the new
          Falcon 180B, or is it just a matter of getting it done?</p>

          '
        raw: 'Sorry, it looks like I must have garbled the edit: I was doing GGUFs
          of two models that you hadn''t got to, and it sounds like I must have added
          the wrong crosslink. Anyway, if you''re going to do them soon, it''s probably
          less confusing for people if everything comes through you.


          Incidentally, is there any logistical issue to doing GGUFs of the new Falcon
          180B, or is it just a matter of getting it done?'
        updatedAt: '2023-09-07T08:46:20.520Z'
      numEdits: 2
      reactions: []
    id: 64f98025159055330801fb3c
    type: comment
  author: YokaiKoibito
  content: 'Sorry, it looks like I must have garbled the edit: I was doing GGUFs of
    two models that you hadn''t got to, and it sounds like I must have added the wrong
    crosslink. Anyway, if you''re going to do them soon, it''s probably less confusing
    for people if everything comes through you.


    Incidentally, is there any logistical issue to doing GGUFs of the new Falcon 180B,
    or is it just a matter of getting it done?'
  created_at: 2023-09-07 06:47:49+00:00
  edited: true
  hidden: false
  id: 64f98025159055330801fb3c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-09-07T08:29:46.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9761253595352173
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>OK, understood, and thanks. </p>

          <p>  I did Llama 2 70B Chat Uncensored last night and I''m nearly done with
          all the Llama 2 models in GGUF. Then I''ll start looking at Llama 1 and
          Falcon models.</p>

          <p>There was one challenge with Falcon 180B, which was the convert script
          had to be updated.  That was done by someone on the llama.cpp Github last
          night, and I''m making the GGUFs right now.  Two are uploaded as I write
          this, and the rest will come soon:  <a href="https://huggingface.co/TheBloke/Falcon-180B-Chat-GGUF/tree/main">https://huggingface.co/TheBloke/Falcon-180B-Chat-GGUF/tree/main</a></p>

          <p>Unfortunately every one of them is bigger than 50GB so they all have
          to be split for upload to HF, so there''s a bit of manual work required
          by the user before they can be used (details will be in the README).  But
          they work!</p>

          '
        raw: "OK, understood, and thanks. \n\n  I did Llama 2 70B Chat Uncensored\
          \ last night and I'm nearly done with all the Llama 2 models in GGUF. Then\
          \ I'll start looking at Llama 1 and Falcon models.\n\nThere was one challenge\
          \ with Falcon 180B, which was the convert script had to be updated.  That\
          \ was done by someone on the llama.cpp Github last night, and I'm making\
          \ the GGUFs right now.  Two are uploaded as I write this, and the rest will\
          \ come soon:  https://huggingface.co/TheBloke/Falcon-180B-Chat-GGUF/tree/main\n\
          \nUnfortunately every one of them is bigger than 50GB so they all have to\
          \ be split for upload to HF, so there's a bit of manual work required by\
          \ the user before they can be used (details will be in the README).  But\
          \ they work!"
        updatedAt: '2023-09-07T08:29:46.772Z'
      numEdits: 0
      reactions: []
    id: 64f989fafb1db00f1394bc3f
    type: comment
  author: TheBloke
  content: "OK, understood, and thanks. \n\n  I did Llama 2 70B Chat Uncensored last\
    \ night and I'm nearly done with all the Llama 2 models in GGUF. Then I'll start\
    \ looking at Llama 1 and Falcon models.\n\nThere was one challenge with Falcon\
    \ 180B, which was the convert script had to be updated.  That was done by someone\
    \ on the llama.cpp Github last night, and I'm making the GGUFs right now.  Two\
    \ are uploaded as I write this, and the rest will come soon:  https://huggingface.co/TheBloke/Falcon-180B-Chat-GGUF/tree/main\n\
    \nUnfortunately every one of them is bigger than 50GB so they all have to be split\
    \ for upload to HF, so there's a bit of manual work required by the user before\
    \ they can be used (details will be in the README).  But they work!"
  created_at: 2023-09-07 07:29:46+00:00
  edited: false
  hidden: false
  id: 64f989fafb1db00f1394bc3f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
      fullname: Yokai Koibito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YokaiKoibito
      type: user
    createdAt: '2023-09-07T08:37:58.000Z'
    data:
      edited: true
      editors:
      - YokaiKoibito
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8436123728752136
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
          fullname: Yokai Koibito
          isHf: false
          isPro: false
          name: YokaiKoibito
          type: user
        html: '<p>By the way, my GGUF quantization for WizardLM-Uncensored-Falcon-40b
          seems to be unsuccessful -- I''ve done it twice now, with identical results,
          and when I try to load it into koboldcpp, it fails with:</p>

          <p>error loading model: create_tensor: tensor ''token_embd.weight'' has
          wrong shape; expected  8192, 65024, got  8192, 65025,     1,     1<br>llama_load_model_from_file:
          failed to load model<br>gpttype_load_model: error: failed to load model
          ''/Users/.../Documents/GitHub/koboldcpp/models/WizardLM-Uncensored-Falcon-40b-Q8_0.gguf''<br>Load
          Model OK: False<br>Could not load model: /Users/.../Documents/GitHub/koboldcpp/models/WizardLM-Uncensored-Falcon-40b-Q8_0.gguf</p>

          <p>Even stranger, the same Python notebook running on the same hardware
          quantized the base Falcon 40B model and the result was successfully loaded
          by the same installation of koboldcpp, i.e. the problem seems to differ
          between different Falcon 40B models. So I''ll download and test your GGUF
          version of WizardLM-Uncensored-Falcon-40b once it''s done, and let you know
          if I have any problems with it.</p>

          '
        raw: 'By the way, my GGUF quantization for WizardLM-Uncensored-Falcon-40b
          seems to be unsuccessful -- I''ve done it twice now, with identical results,
          and when I try to load it into koboldcpp, it fails with:


          error loading model: create_tensor: tensor ''token_embd.weight'' has wrong
          shape; expected  8192, 65024, got  8192, 65025,     1,     1

          llama_load_model_from_file: failed to load model

          gpttype_load_model: error: failed to load model ''/Users/.../Documents/GitHub/koboldcpp/models/WizardLM-Uncensored-Falcon-40b-Q8_0.gguf''

          Load Model OK: False

          Could not load model: /Users/.../Documents/GitHub/koboldcpp/models/WizardLM-Uncensored-Falcon-40b-Q8_0.gguf


          Even stranger, the same Python notebook running on the same hardware quantized
          the base Falcon 40B model and the result was successfully loaded by the
          same installation of koboldcpp, i.e. the problem seems to differ between
          different Falcon 40B models. So I''ll download and test your GGUF version
          of WizardLM-Uncensored-Falcon-40b once it''s done, and let you know if I
          have any problems with it.'
        updatedAt: '2023-09-07T08:45:50.964Z'
      numEdits: 3
      reactions: []
    id: 64f98be6fdd92bd7112128d6
    type: comment
  author: YokaiKoibito
  content: 'By the way, my GGUF quantization for WizardLM-Uncensored-Falcon-40b seems
    to be unsuccessful -- I''ve done it twice now, with identical results, and when
    I try to load it into koboldcpp, it fails with:


    error loading model: create_tensor: tensor ''token_embd.weight'' has wrong shape;
    expected  8192, 65024, got  8192, 65025,     1,     1

    llama_load_model_from_file: failed to load model

    gpttype_load_model: error: failed to load model ''/Users/.../Documents/GitHub/koboldcpp/models/WizardLM-Uncensored-Falcon-40b-Q8_0.gguf''

    Load Model OK: False

    Could not load model: /Users/.../Documents/GitHub/koboldcpp/models/WizardLM-Uncensored-Falcon-40b-Q8_0.gguf


    Even stranger, the same Python notebook running on the same hardware quantized
    the base Falcon 40B model and the result was successfully loaded by the same installation
    of koboldcpp, i.e. the problem seems to differ between different Falcon 40B models.
    So I''ll download and test your GGUF version of WizardLM-Uncensored-Falcon-40b
    once it''s done, and let you know if I have any problems with it.'
  created_at: 2023-09-07 07:37:58+00:00
  edited: true
  hidden: false
  id: 64f98be6fdd92bd7112128d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
      fullname: Yokai Koibito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YokaiKoibito
      type: user
    createdAt: '2023-09-07T08:42:42.000Z'
    data:
      edited: true
      editors:
      - YokaiKoibito
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9711198806762695
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
          fullname: Yokai Koibito
          isHf: false
          isPro: false
          name: YokaiKoibito
          type: user
        html: '<p>Sadly my 64GB company Mac laptop doesn''t have enough memory to
          run Falcon 180B locally even in Q2_K :-( And I asked them for a 128GB one
          when I joined...</p>

          '
        raw: Sadly my 64GB company Mac laptop doesn't have enough memory to run Falcon
          180B locally even in Q2_K :-( And I asked them for a 128GB one when I joined...
        updatedAt: '2023-09-07T08:54:59.861Z'
      numEdits: 1
      reactions: []
    id: 64f98d02be1d509884de5ebb
    type: comment
  author: YokaiKoibito
  content: Sadly my 64GB company Mac laptop doesn't have enough memory to run Falcon
    180B locally even in Q2_K :-( And I asked them for a 128GB one when I joined...
  created_at: 2023-09-07 07:42:42+00:00
  edited: true
  hidden: false
  id: 64f98d02be1d509884de5ebb
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 2
repo_id: TheBloke/llama2_70b_chat_uncensored-GPTQ
repo_type: model
status: closed
target_branch: refs/heads/main
title: Expand Repositories section to add links to a couple more versions
