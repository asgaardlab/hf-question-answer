!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Sebogoss11
conflicting_files: null
created_at: 2023-12-26 12:58:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/03e8064dda4ed93d2e3ffed3b40b98eb.svg
      fullname: Seboss1111
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sebogoss11
      type: user
    createdAt: '2023-12-26T12:58:09.000Z'
    data:
      edited: true
      editors:
      - Sebogoss11
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5949965715408325
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/03e8064dda4ed93d2e3ffed3b40b98eb.svg
          fullname: Seboss1111
          isHf: false
          isPro: false
          name: Sebogoss11
          type: user
        html: "<p>When running the most basic python code example : </p>\n<p>CODE\
          \ : </p>\n<p>from gradio_client import Client</p>\n<p>client = Client(\"\
          <a rel=\"nofollow\" href=\"https://coqui-xtts.hf.space/--replicas/29c56/&quot;\"\
          >https://coqui-xtts.hf.space/--replicas/29c56/\"</a>)<br>result = client.predict(<br>\
          \        \"Howdy!\",\t# str  in 'Text Prompt' Textbox component<br>    \
          \    \"en,en\",\t# str (Option from: [('en', 'en'), ('es', 'es'), ('fr',\
          \ 'fr'), ('de', 'de'), ('it', 'it'), ('pt', 'pt'), ('pl', 'pl'), ('tr',\
          \ 'tr'), ('ru', 'ru'), ('nl', 'nl'), ('cs', 'cs'), ('ar', 'ar'), ('zh-cn',\
          \ 'zh-cn'), ('ja', 'ja'), ('ko', 'ko'), ('hu', 'hu'), ('hi', 'hi')]) in\
          \ 'Language' Dropdown component<br>        \"<a rel=\"nofollow\" href=\"\
          https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav&quot;\"\
          >https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav\"\
          </a>,\t# str (filepath on your computer (or URL) of file) in 'Reference\
          \ Audio' Audio component<br>        \"<a rel=\"nofollow\" href=\"https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav&quot;\"\
          >https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav\"\
          </a>,\t# str (filepath on your computer (or URL) of file) in 'Use Microphone\
          \ for Reference' Audio component<br>        True,\t# bool  in 'Use Microphone'\
          \ Checkbox component<br>        True,\t# bool  in 'Cleanup Reference Voice'\
          \ Checkbox component<br>        True,\t# bool  in 'Do not use language auto-detect'\
          \ Checkbox component<br>        True,\t# bool  in 'Agree' Checkbox component<br>\
          \        fn_index=1<br>)<br>print(result)</p>\n<p>OUTPUT :<br>Loaded as\
          \ API: <a rel=\"nofollow\" href=\"https://coqui-xtts.hf.space/--replicas/29c56/\"\
          >https://coqui-xtts.hf.space/--replicas/29c56/</a> \u2714<br>    raise HTTPStatusError(message,\
          \ request=request, response=self)<br>httpx.HTTPStatusError: Redirect response\
          \ '302 Found' for url '<a rel=\"nofollow\" href=\"https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav'\"\
          >https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav'</a><br>Redirect\
          \ location: '<a rel=\"nofollow\" href=\"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav'\"\
          >https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav'</a><br>For\
          \ more information check: <a rel=\"nofollow\" href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/302\"\
          >https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/302</a></p>\n\
          <p>So i change the links for the ones provided : \"<a rel=\"nofollow\" href=\"\
          https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav&quot;\"\
          >https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav\"\
          </a></p>\n<p>CODE :</p>\n<p>from gradio_client import Client</p>\n<p>client\
          \ = Client(\"<a rel=\"nofollow\" href=\"https://coqui-xtts.hf.space/--replicas/29c56/&quot;\"\
          >https://coqui-xtts.hf.space/--replicas/29c56/\"</a>)<br>result = client.predict(<br>\
          \        \"Howdy!\",\t# str  in 'Text Prompt' Textbox component<br>    \
          \    \"en,en\",\t# str (Option from: [('en', 'en'), ('es', 'es'), ('fr',\
          \ 'fr'), ('de', 'de'), ('it', 'it'), ('pt', 'pt'), ('pl', 'pl'), ('tr',\
          \ 'tr'), ('ru', 'ru'), ('nl', 'nl'), ('cs', 'cs'), ('ar', 'ar'), ('zh-cn',\
          \ 'zh-cn'), ('ja', 'ja'), ('ko', 'ko'), ('hu', 'hu'), ('hi', 'hi')]) in\
          \ 'Language' Dropdown component<br>        \"<a rel=\"nofollow\" href=\"\
          https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav&quot;\"\
          >https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav\"\
          </a>,\t# str (filepath on your computer (or URL) of file) in 'Reference\
          \ Audio' Audio component<br>        \"<a rel=\"nofollow\" href=\"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav&quot;\"\
          >https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav\"\
          </a>,\t# str (filepath on your computer (or URL) of file) in 'Use Microphone\
          \ for Reference' Audio component<br>        True,\t# bool  in 'Use Microphone'\
          \ Checkbox component<br>        True,\t# bool  in 'Cleanup Reference Voice'\
          \ Checkbox component<br>        True,\t# bool  in 'Do not use language auto-detect'\
          \ Checkbox component<br>        True,\t# bool  in 'Agree' Checkbox component<br>\
          \        fn_index=1<br>)<br>print(result)</p>\n<p>OUPUT :<br>Loaded as API:\
          \ <a rel=\"nofollow\" href=\"https://coqui-xtts.hf.space/--replicas/29c56/\"\
          >https://coqui-xtts.hf.space/--replicas/29c56/</a> \u2714<br>    raise ValueError(f\"\
          Expected tuple of length 2. Received: {x}\")<br>ValueError: Expected tuple\
          \ of length 2. Received: None</p>\n<p>Then i tried to some code found on\
          \ the doc... It seems that the outputof client.predict is'nt a tuple as\
          \ it is supposed to be ? client.predict crashes alone on the response...</p>\n\
          <p>CODE:</p>\n<p>from gradio_client import Client</p>\n<p>client = Client(\"\
          <a rel=\"nofollow\" href=\"https://coqui-xtts.hf.space/--replicas/29c56/&quot;\"\
          >https://coqui-xtts.hf.space/--replicas/29c56/\"</a>)<br>client.view_api()</p>\n\
          <p>result = client.predict(<br>\"Hello!\",  # str  in 'Text Prompt' Textbox\
          \ component<br>\"en,en\",  # str (Option from: [('en', 'en'), ('es', 'es'),\
          \ ('fr', 'fr'), ('de', 'de'), ('it', 'it'), ('pt', 'pt'), ('pl', 'pl'),\
          \ ('tr', 'tr'), ('ru', 'ru'), ('nl', 'nl'), ('cs', 'cs'), ('ar', 'ar'),\
          \ ('zh-cn', 'zh-cn'), ('ja', 'ja'), ('ko', 'ko'), ('hu', 'hu'), ('hi', 'hi')])\
          \ in 'Language' Dropdown component<br>\"<a href=\"https://huggingface.co/spaces/coqui/xtts/blob/main/examples/male.wav&quot;,#\"\
          >https://huggingface.co/spaces/coqui/xtts/blob/main/examples/male.wav\"\
          ,#</a> str (filepath on your computer (or URL) of file) in 'Reference Audio'\
          \ Audio component<br>\"<a href=\"https://huggingface.co/spaces/coqui/xtts/blob/main/examples/male.wav&quot;,#\"\
          >https://huggingface.co/spaces/coqui/xtts/blob/main/examples/male.wav\"\
          ,#</a> str (filepath on your computer (or URL) of file) in 'Use Microphone\
          \ for Reference' Audio component<br>False,  # bool  in 'Use Microphone'\
          \ Checkbox component<br>True,  # bool  in 'Cleanup Reference Voice' Checkbox\
          \ component<br>True,  # bool  in 'Do not use language auto-detect' Checkbox\
          \ component<br>True,  # bool  in 'Agree' Checkbox component<br>fn_index=1,<br>)</p>\n\
          <p>print(result)</p>\n<p>OUPUT :<br>Loaded as API: <a rel=\"nofollow\" href=\"\
          https://coqui-xtts.hf.space/--replicas/29c56/\">https://coqui-xtts.hf.space/--replicas/29c56/</a>\
          \ \u2714<br>Client.predict() Usage Info</p>\n<p>Named API endpoints: 0</p>\n\
          <p>Unnamed API endpoints: 1</p>\n<ul>\n<li>predict(text_prompt, language,\
          \ reference_audio, use_microphone_for_reference, use_microphone, cleanup_reference_voice,\
          \ do_not_use_language_autodetect, agree, fn_index=1) -&gt; (waveform_visual,\
          \ synthesised_audio, metrics, reference_audio_used)<br> Parameters:<ul>\n\
          <li>[Textbox] text_prompt: str </li>\n<li>[Dropdown] language: str (Option\
          \ from: [('en', 'en'), ('es', 'es'), ('fr', 'fr'), ('de', 'de'), ('it',\
          \ 'it'), ('pt', 'pt'), ('pl', 'pl'), ('tr', 'tr'), ('ru', 'ru'), ('nl',\
          \ 'nl'), ('cs', 'cs'), ('ar', 'ar'), ('zh-cn', 'zh-cn'), ('ja', 'ja'), ('ko',\
          \ 'ko'), ('hu', 'hu'), ('hi', 'hi')]) </li>\n<li>[Audio] reference_audio:\
          \ str | Dict(name: str (name of file), data: str (base64 representation\
          \ of file), size: int (size of image in bytes), is_file: bool (true if the\
          \ file has been uploaded to the server), orig_name: str (original name of\
          \ the file)) </li>\n<li>[Audio] use_microphone_for_reference: str | Dict(name:\
          \ str (name of file), data: str (base64 representation of file), size: int\
          \ (size of image in bytes), is_file: bool (true if the file has been uploaded\
          \ to the server), orig_name: str (original name of the file)) </li>\n<li>[Checkbox]\
          \ use_microphone: bool </li>\n<li>[Checkbox] cleanup_reference_voice: bool\
          \ </li>\n<li>[Checkbox] do_not_use_language_autodetect: bool </li>\n<li>[Checkbox]\
          \ agree: bool<br> Returns:</li>\n<li>[Video] waveform_visual: str | Dict(name:\
          \ str (name of file), data: str (base64 representation of file), size: int\
          \ (size of image in bytes), is_file: bool (true if the file has been uploaded\
          \ to the server), orig_name: str (original name of the file)) | List[str\
          \ | Dict(name: str (name of file), data: str (base64 representation of file),\
          \ size: int (size of image in bytes), is_file: bool (true if the file has\
          \ been uploaded to the server), orig_name: str (original name of the file))]\
          \ </li>\n<li>[Audio] synthesised_audio: str | Dict(name: str (name of file),\
          \ data: str (base64 representation of file), size: int (size of image in\
          \ bytes), is_file: bool (true if the file has been uploaded to the server),\
          \ orig_name: str (original name of the file)) </li>\n<li>[Textbox] metrics:\
          \ str </li>\n<li>[Audio] reference_audio_used: str | Dict(name: str (name\
          \ of file), data: str (base64 representation of file), size: int (size of\
          \ image in bytes), is_file: bool (true if the file has been uploaded to\
          \ the server), orig_name: str (original name of the file))</li>\n</ul>\n\
          </li>\n</ul>\n<p>Traceback (most recent call last):<br> _predict<br>   \
          \ raise ValueError(result[\"error\"])<br>ValueError: None</p>\n<p> I find\
          \ it very disapointing to not be able to run the mode through the api. Plus,\
          \ they're is absolutely not help whatsoever on the internet on that error\
          \ from the gradio API. For the record, i also tried with my own duplicate\
          \ space of the XTTS-v2 (with token specified) but it doesn't work either\
          \ (same errors).<br>What's wrong ? Can you update the huggingface space\
          \ code to make the python basic code example work please ?</p>\n"
        raw: "When running the most basic python code example : \n\nCODE : \n\nfrom\
          \ gradio_client import Client\n\nclient = Client(\"https://coqui-xtts.hf.space/--replicas/29c56/\"\
          )\nresult = client.predict(\n\t\t\"Howdy!\",\t# str  in 'Text Prompt' Textbox\
          \ component\n\t\t\"en,en\",\t# str (Option from: [('en', 'en'), ('es', 'es'),\
          \ ('fr', 'fr'), ('de', 'de'), ('it', 'it'), ('pt', 'pt'), ('pl', 'pl'),\
          \ ('tr', 'tr'), ('ru', 'ru'), ('nl', 'nl'), ('cs', 'cs'), ('ar', 'ar'),\
          \ ('zh-cn', 'zh-cn'), ('ja', 'ja'), ('ko', 'ko'), ('hu', 'hu'), ('hi', 'hi')])\
          \ in 'Language' Dropdown component\n\t\t\"https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav\"\
          ,\t# str (filepath on your computer (or URL) of file) in 'Reference Audio'\
          \ Audio component\n\t\t\"https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav\"\
          ,\t# str (filepath on your computer (or URL) of file) in 'Use Microphone\
          \ for Reference' Audio component\n\t\tTrue,\t# bool  in 'Use Microphone'\
          \ Checkbox component\n\t\tTrue,\t# bool  in 'Cleanup Reference Voice' Checkbox\
          \ component\n\t\tTrue,\t# bool  in 'Do not use language auto-detect' Checkbox\
          \ component\n\t\tTrue,\t# bool  in 'Agree' Checkbox component\n\t\tfn_index=1\n\
          )\nprint(result)\n\nOUTPUT : \nLoaded as API: https://coqui-xtts.hf.space/--replicas/29c56/\
          \ \u2714\n    raise HTTPStatusError(message, request=request, response=self)\n\
          httpx.HTTPStatusError: Redirect response '302 Found' for url 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav'\n\
          Redirect location: 'https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav'\n\
          For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/302\n\
          \n\nSo i change the links for the ones provided : \"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav\"\
          \n\nCODE :\n\nfrom gradio_client import Client\n\nclient = Client(\"https://coqui-xtts.hf.space/--replicas/29c56/\"\
          )\nresult = client.predict(\n\t\t\"Howdy!\",\t# str  in 'Text Prompt' Textbox\
          \ component\n\t\t\"en,en\",\t# str (Option from: [('en', 'en'), ('es', 'es'),\
          \ ('fr', 'fr'), ('de', 'de'), ('it', 'it'), ('pt', 'pt'), ('pl', 'pl'),\
          \ ('tr', 'tr'), ('ru', 'ru'), ('nl', 'nl'), ('cs', 'cs'), ('ar', 'ar'),\
          \ ('zh-cn', 'zh-cn'), ('ja', 'ja'), ('ko', 'ko'), ('hu', 'hu'), ('hi', 'hi')])\
          \ in 'Language' Dropdown component\n\t\t\"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav\"\
          ,\t# str (filepath on your computer (or URL) of file) in 'Reference Audio'\
          \ Audio component\n\t\t\"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav\"\
          ,\t# str (filepath on your computer (or URL) of file) in 'Use Microphone\
          \ for Reference' Audio component\n\t\tTrue,\t# bool  in 'Use Microphone'\
          \ Checkbox component\n\t\tTrue,\t# bool  in 'Cleanup Reference Voice' Checkbox\
          \ component\n\t\tTrue,\t# bool  in 'Do not use language auto-detect' Checkbox\
          \ component\n\t\tTrue,\t# bool  in 'Agree' Checkbox component\n\t\tfn_index=1\n\
          )\nprint(result)\n\nOUPUT :\nLoaded as API: https://coqui-xtts.hf.space/--replicas/29c56/\
          \ \u2714\n    raise ValueError(f\"Expected tuple of length 2. Received:\
          \ {x}\")\nValueError: Expected tuple of length 2. Received: None\n\n\n\n\
          Then i tried to some code found on the doc... It seems that the outputof\
          \ client.predict is'nt a tuple as it is supposed to be ? client.predict\
          \ crashes alone on the response...\n\n\nCODE:\n\nfrom gradio_client import\
          \ Client\n\nclient = Client(\"https://coqui-xtts.hf.space/--replicas/29c56/\"\
          )\nclient.view_api()\n\nresult = client.predict(\n\"Hello!\",  # str  in\
          \ 'Text Prompt' Textbox component\n\"en,en\",  # str (Option from: [('en',\
          \ 'en'), ('es', 'es'), ('fr', 'fr'), ('de', 'de'), ('it', 'it'), ('pt',\
          \ 'pt'), ('pl', 'pl'), ('tr', 'tr'), ('ru', 'ru'), ('nl', 'nl'), ('cs',\
          \ 'cs'), ('ar', 'ar'), ('zh-cn', 'zh-cn'), ('ja', 'ja'), ('ko', 'ko'), ('hu',\
          \ 'hu'), ('hi', 'hi')]) in 'Language' Dropdown component\n\"https://huggingface.co/spaces/coqui/xtts/blob/main/examples/male.wav\"\
          ,# str (filepath on your computer (or URL) of file) in 'Reference Audio'\
          \ Audio component\n\"https://huggingface.co/spaces/coqui/xtts/blob/main/examples/male.wav\"\
          ,# str (filepath on your computer (or URL) of file) in 'Use Microphone for\
          \ Reference' Audio component\nFalse,  # bool  in 'Use Microphone' Checkbox\
          \ component\nTrue,  # bool  in 'Cleanup Reference Voice' Checkbox component\n\
          True,  # bool  in 'Do not use language auto-detect' Checkbox component\n\
          True,  # bool  in 'Agree' Checkbox component\nfn_index=1,\n)\n\nprint(result)\n\
          \nOUPUT :\nLoaded as API: https://coqui-xtts.hf.space/--replicas/29c56/\
          \ \u2714\nClient.predict() Usage Info\n\nNamed API endpoints: 0\n\nUnnamed\
          \ API endpoints: 1\n\n - predict(text_prompt, language, reference_audio,\
          \ use_microphone_for_reference, use_microphone, cleanup_reference_voice,\
          \ do_not_use_language_autodetect, agree, fn_index=1) -> (waveform_visual,\
          \ synthesised_audio, metrics, reference_audio_used)\n    Parameters:\n \
          \    - [Textbox] text_prompt: str \n     - [Dropdown] language: str (Option\
          \ from: [('en', 'en'), ('es', 'es'), ('fr', 'fr'), ('de', 'de'), ('it',\
          \ 'it'), ('pt', 'pt'), ('pl', 'pl'), ('tr', 'tr'), ('ru', 'ru'), ('nl',\
          \ 'nl'), ('cs', 'cs'), ('ar', 'ar'), ('zh-cn', 'zh-cn'), ('ja', 'ja'), ('ko',\
          \ 'ko'), ('hu', 'hu'), ('hi', 'hi')]) \n     - [Audio] reference_audio:\
          \ str | Dict(name: str (name of file), data: str (base64 representation\
          \ of file), size: int (size of image in bytes), is_file: bool (true if the\
          \ file has been uploaded to the server), orig_name: str (original name of\
          \ the file)) \n     - [Audio] use_microphone_for_reference: str | Dict(name:\
          \ str (name of file), data: str (base64 representation of file), size: int\
          \ (size of image in bytes), is_file: bool (true if the file has been uploaded\
          \ to the server), orig_name: str (original name of the file)) \n     - [Checkbox]\
          \ use_microphone: bool \n     - [Checkbox] cleanup_reference_voice: bool\
          \ \n     - [Checkbox] do_not_use_language_autodetect: bool \n     - [Checkbox]\
          \ agree: bool \n    Returns:\n     - [Video] waveform_visual: str | Dict(name:\
          \ str (name of file), data: str (base64 representation of file), size: int\
          \ (size of image in bytes), is_file: bool (true if the file has been uploaded\
          \ to the server), orig_name: str (original name of the file)) | List[str\
          \ | Dict(name: str (name of file), data: str (base64 representation of file),\
          \ size: int (size of image in bytes), is_file: bool (true if the file has\
          \ been uploaded to the server), orig_name: str (original name of the file))]\
          \ \n     - [Audio] synthesised_audio: str | Dict(name: str (name of file),\
          \ data: str (base64 representation of file), size: int (size of image in\
          \ bytes), is_file: bool (true if the file has been uploaded to the server),\
          \ orig_name: str (original name of the file)) \n     - [Textbox] metrics:\
          \ str \n     - [Audio] reference_audio_used: str | Dict(name: str (name\
          \ of file), data: str (base64 representation of file), size: int (size of\
          \ image in bytes), is_file: bool (true if the file has been uploaded to\
          \ the server), orig_name: str (original name of the file)) \n\nTraceback\
          \ (most recent call last):\n _predict\n    raise ValueError(result[\"error\"\
          ])\nValueError: None\n\n\n I find it very disapointing to not be able to\
          \ run the mode through the api. Plus, they're is absolutely not help whatsoever\
          \ on the internet on that error from the gradio API. For the record, i also\
          \ tried with my own duplicate space of the XTTS-v2 (with token specified)\
          \ but it doesn't work either (same errors).\nWhat's wrong ? Can you update\
          \ the huggingface space code to make the python basic code example work\
          \ please ?"
        updatedAt: '2023-12-26T13:00:38.817Z'
      numEdits: 2
      reactions: []
    id: 658acde1085a5bce618ad604
    type: comment
  author: Sebogoss11
  content: "When running the most basic python code example : \n\nCODE : \n\nfrom\
    \ gradio_client import Client\n\nclient = Client(\"https://coqui-xtts.hf.space/--replicas/29c56/\"\
    )\nresult = client.predict(\n\t\t\"Howdy!\",\t# str  in 'Text Prompt' Textbox\
    \ component\n\t\t\"en,en\",\t# str (Option from: [('en', 'en'), ('es', 'es'),\
    \ ('fr', 'fr'), ('de', 'de'), ('it', 'it'), ('pt', 'pt'), ('pl', 'pl'), ('tr',\
    \ 'tr'), ('ru', 'ru'), ('nl', 'nl'), ('cs', 'cs'), ('ar', 'ar'), ('zh-cn', 'zh-cn'),\
    \ ('ja', 'ja'), ('ko', 'ko'), ('hu', 'hu'), ('hi', 'hi')]) in 'Language' Dropdown\
    \ component\n\t\t\"https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav\"\
    ,\t# str (filepath on your computer (or URL) of file) in 'Reference Audio' Audio\
    \ component\n\t\t\"https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav\"\
    ,\t# str (filepath on your computer (or URL) of file) in 'Use Microphone for Reference'\
    \ Audio component\n\t\tTrue,\t# bool  in 'Use Microphone' Checkbox component\n\
    \t\tTrue,\t# bool  in 'Cleanup Reference Voice' Checkbox component\n\t\tTrue,\t\
    # bool  in 'Do not use language auto-detect' Checkbox component\n\t\tTrue,\t#\
    \ bool  in 'Agree' Checkbox component\n\t\tfn_index=1\n)\nprint(result)\n\nOUTPUT\
    \ : \nLoaded as API: https://coqui-xtts.hf.space/--replicas/29c56/ \u2714\n  \
    \  raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError:\
    \ Redirect response '302 Found' for url 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav'\n\
    Redirect location: 'https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav'\n\
    For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/302\n\
    \n\nSo i change the links for the ones provided : \"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav\"\
    \n\nCODE :\n\nfrom gradio_client import Client\n\nclient = Client(\"https://coqui-xtts.hf.space/--replicas/29c56/\"\
    )\nresult = client.predict(\n\t\t\"Howdy!\",\t# str  in 'Text Prompt' Textbox\
    \ component\n\t\t\"en,en\",\t# str (Option from: [('en', 'en'), ('es', 'es'),\
    \ ('fr', 'fr'), ('de', 'de'), ('it', 'it'), ('pt', 'pt'), ('pl', 'pl'), ('tr',\
    \ 'tr'), ('ru', 'ru'), ('nl', 'nl'), ('cs', 'cs'), ('ar', 'ar'), ('zh-cn', 'zh-cn'),\
    \ ('ja', 'ja'), ('ko', 'ko'), ('hu', 'hu'), ('hi', 'hi')]) in 'Language' Dropdown\
    \ component\n\t\t\"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav\"\
    ,\t# str (filepath on your computer (or URL) of file) in 'Reference Audio' Audio\
    \ component\n\t\t\"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/audio_sample.wav\"\
    ,\t# str (filepath on your computer (or URL) of file) in 'Use Microphone for Reference'\
    \ Audio component\n\t\tTrue,\t# bool  in 'Use Microphone' Checkbox component\n\
    \t\tTrue,\t# bool  in 'Cleanup Reference Voice' Checkbox component\n\t\tTrue,\t\
    # bool  in 'Do not use language auto-detect' Checkbox component\n\t\tTrue,\t#\
    \ bool  in 'Agree' Checkbox component\n\t\tfn_index=1\n)\nprint(result)\n\nOUPUT\
    \ :\nLoaded as API: https://coqui-xtts.hf.space/--replicas/29c56/ \u2714\n   \
    \ raise ValueError(f\"Expected tuple of length 2. Received: {x}\")\nValueError:\
    \ Expected tuple of length 2. Received: None\n\n\n\nThen i tried to some code\
    \ found on the doc... It seems that the outputof client.predict is'nt a tuple\
    \ as it is supposed to be ? client.predict crashes alone on the response...\n\n\
    \nCODE:\n\nfrom gradio_client import Client\n\nclient = Client(\"https://coqui-xtts.hf.space/--replicas/29c56/\"\
    )\nclient.view_api()\n\nresult = client.predict(\n\"Hello!\",  # str  in 'Text\
    \ Prompt' Textbox component\n\"en,en\",  # str (Option from: [('en', 'en'), ('es',\
    \ 'es'), ('fr', 'fr'), ('de', 'de'), ('it', 'it'), ('pt', 'pt'), ('pl', 'pl'),\
    \ ('tr', 'tr'), ('ru', 'ru'), ('nl', 'nl'), ('cs', 'cs'), ('ar', 'ar'), ('zh-cn',\
    \ 'zh-cn'), ('ja', 'ja'), ('ko', 'ko'), ('hu', 'hu'), ('hi', 'hi')]) in 'Language'\
    \ Dropdown component\n\"https://huggingface.co/spaces/coqui/xtts/blob/main/examples/male.wav\"\
    ,# str (filepath on your computer (or URL) of file) in 'Reference Audio' Audio\
    \ component\n\"https://huggingface.co/spaces/coqui/xtts/blob/main/examples/male.wav\"\
    ,# str (filepath on your computer (or URL) of file) in 'Use Microphone for Reference'\
    \ Audio component\nFalse,  # bool  in 'Use Microphone' Checkbox component\nTrue,\
    \  # bool  in 'Cleanup Reference Voice' Checkbox component\nTrue,  # bool  in\
    \ 'Do not use language auto-detect' Checkbox component\nTrue,  # bool  in 'Agree'\
    \ Checkbox component\nfn_index=1,\n)\n\nprint(result)\n\nOUPUT :\nLoaded as API:\
    \ https://coqui-xtts.hf.space/--replicas/29c56/ \u2714\nClient.predict() Usage\
    \ Info\n\nNamed API endpoints: 0\n\nUnnamed API endpoints: 1\n\n - predict(text_prompt,\
    \ language, reference_audio, use_microphone_for_reference, use_microphone, cleanup_reference_voice,\
    \ do_not_use_language_autodetect, agree, fn_index=1) -> (waveform_visual, synthesised_audio,\
    \ metrics, reference_audio_used)\n    Parameters:\n     - [Textbox] text_prompt:\
    \ str \n     - [Dropdown] language: str (Option from: [('en', 'en'), ('es', 'es'),\
    \ ('fr', 'fr'), ('de', 'de'), ('it', 'it'), ('pt', 'pt'), ('pl', 'pl'), ('tr',\
    \ 'tr'), ('ru', 'ru'), ('nl', 'nl'), ('cs', 'cs'), ('ar', 'ar'), ('zh-cn', 'zh-cn'),\
    \ ('ja', 'ja'), ('ko', 'ko'), ('hu', 'hu'), ('hi', 'hi')]) \n     - [Audio] reference_audio:\
    \ str | Dict(name: str (name of file), data: str (base64 representation of file),\
    \ size: int (size of image in bytes), is_file: bool (true if the file has been\
    \ uploaded to the server), orig_name: str (original name of the file)) \n    \
    \ - [Audio] use_microphone_for_reference: str | Dict(name: str (name of file),\
    \ data: str (base64 representation of file), size: int (size of image in bytes),\
    \ is_file: bool (true if the file has been uploaded to the server), orig_name:\
    \ str (original name of the file)) \n     - [Checkbox] use_microphone: bool \n\
    \     - [Checkbox] cleanup_reference_voice: bool \n     - [Checkbox] do_not_use_language_autodetect:\
    \ bool \n     - [Checkbox] agree: bool \n    Returns:\n     - [Video] waveform_visual:\
    \ str | Dict(name: str (name of file), data: str (base64 representation of file),\
    \ size: int (size of image in bytes), is_file: bool (true if the file has been\
    \ uploaded to the server), orig_name: str (original name of the file)) | List[str\
    \ | Dict(name: str (name of file), data: str (base64 representation of file),\
    \ size: int (size of image in bytes), is_file: bool (true if the file has been\
    \ uploaded to the server), orig_name: str (original name of the file))] \n   \
    \  - [Audio] synthesised_audio: str | Dict(name: str (name of file), data: str\
    \ (base64 representation of file), size: int (size of image in bytes), is_file:\
    \ bool (true if the file has been uploaded to the server), orig_name: str (original\
    \ name of the file)) \n     - [Textbox] metrics: str \n     - [Audio] reference_audio_used:\
    \ str | Dict(name: str (name of file), data: str (base64 representation of file),\
    \ size: int (size of image in bytes), is_file: bool (true if the file has been\
    \ uploaded to the server), orig_name: str (original name of the file)) \n\nTraceback\
    \ (most recent call last):\n _predict\n    raise ValueError(result[\"error\"])\n\
    ValueError: None\n\n\n I find it very disapointing to not be able to run the mode\
    \ through the api. Plus, they're is absolutely not help whatsoever on the internet\
    \ on that error from the gradio API. For the record, i also tried with my own\
    \ duplicate space of the XTTS-v2 (with token specified) but it doesn't work either\
    \ (same errors).\nWhat's wrong ? Can you update the huggingface space code to\
    \ make the python basic code example work please ?"
  created_at: 2023-12-26 12:58:09+00:00
  edited: true
  hidden: false
  id: 658acde1085a5bce618ad604
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 29
repo_id: coqui/XTTS-v2
repo_type: model
status: open
target_branch: null
title: Impossible to use the gradio API using python basic example
