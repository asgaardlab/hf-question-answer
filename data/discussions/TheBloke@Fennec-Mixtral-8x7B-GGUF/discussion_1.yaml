!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aadityaverma
conflicting_files: null
created_at: 2023-12-19 03:36:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d8eb6a6f789b92a8ae78989a27142ec0.svg
      fullname: aditya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aadityaverma
      type: user
    createdAt: '2023-12-19T03:36:53.000Z'
    data:
      edited: false
      editors:
      - aadityaverma
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.256369948387146
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d8eb6a6f789b92a8ae78989a27142ec0.svg
          fullname: aditya
          isHf: false
          isPro: false
          name: aadityaverma
          type: user
        html: '<p>Traceback (most recent call last):</p>

          <p>File "/home/-/llm/text-generation-webui/modules/ui_model_menu.py", line
          209, in load_model_wrapper</p>

          <p>shared.model, shared.tokenizer = load_model(shared.model_name, loader)</p>

          <pre><code>                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/-/llm/text-generation-webui/modules/models.py", line 88,
          in load_model</p>

          <p>output = load_func_map<a rel="nofollow" href="model_name">loader</a></p>

          <pre><code>     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/-/llm/text-generation-webui/modules/models.py", line 253,
          in llamacpp_loader</p>

          <p>model, tokenizer = LlamaCppModel.from_pretrained(model_file)</p>

          <pre><code>               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/-/llm/text-generation-webui/modules/llamacpp_model.py", line
          91, in from_pretrained</p>

          <p>result.model = Llama(**params)</p>

          <pre><code>           ^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/-/llm/text-generation-webui/installer_files/env/lib/python3.11/site-packages/llama_cpp_cuda/llama.py",
          line 923, in init</p>

          <p>self._n_vocab = self.n_vocab()</p>

          <pre><code>            ^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/-/llm/text-generation-webui/installer_files/env/lib/python3.11/site-packages/llama_cpp_cuda/llama.py",
          line 2184, in n_vocab</p>

          <p>return self._model.n_vocab()</p>

          <pre><code>   ^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "/home/-/llm/text-generation-webui/installer_files/env/lib/python3.11/site-packages/llama_cpp_cuda/llama.py",
          line 250, in n_vocab</p>

          <p>assert self.model is not None</p>

          <pre><code>   ^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>AssertionError</p>

          '
        raw: "Traceback (most recent call last):\r\n\r\nFile \"/home/-/llm/text-generation-webui/modules/ui_model_menu.py\"\
          , line 209, in load_model_wrapper\r\n\r\nshared.model, shared.tokenizer\
          \ = load_model(shared.model_name, loader)\r\n\r\n                      \
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/-/llm/text-generation-webui/modules/models.py\"\
          , line 88, in load_model\r\n\r\noutput = load_func_map[loader](model_name)\r\
          \n\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/-/llm/text-generation-webui/modules/models.py\"\
          , line 253, in llamacpp_loader\r\n\r\nmodel, tokenizer = LlamaCppModel.from_pretrained(model_file)\r\
          \n\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\
          \nFile \"/home/-/llm/text-generation-webui/modules/llamacpp_model.py\",\
          \ line 91, in from_pretrained\r\n\r\nresult.model = Llama(**params)\r\n\r\
          \n               ^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/-/llm/text-generation-webui/installer_files/env/lib/python3.11/site-packages/llama_cpp_cuda/llama.py\"\
          , line 923, in init\r\n\r\nself._n_vocab = self.n_vocab()\r\n\r\n      \
          \          ^^^^^^^^^^^^^^\r\n\r\nFile \"/home/-/llm/text-generation-webui/installer_files/env/lib/python3.11/site-packages/llama_cpp_cuda/llama.py\"\
          , line 2184, in n_vocab\r\n\r\nreturn self._model.n_vocab()\r\n\r\n    \
          \   ^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/-/llm/text-generation-webui/installer_files/env/lib/python3.11/site-packages/llama_cpp_cuda/llama.py\"\
          , line 250, in n_vocab\r\n\r\nassert self.model is not None\r\n\r\n    \
          \   ^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nAssertionError"
        updatedAt: '2023-12-19T03:36:53.619Z'
      numEdits: 0
      reactions: []
    id: 65810fd542d7e36f4afecb9f
    type: comment
  author: aadityaverma
  content: "Traceback (most recent call last):\r\n\r\nFile \"/home/-/llm/text-generation-webui/modules/ui_model_menu.py\"\
    , line 209, in load_model_wrapper\r\n\r\nshared.model, shared.tokenizer = load_model(shared.model_name,\
    \ loader)\r\n\r\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n\r\nFile \"/home/-/llm/text-generation-webui/modules/models.py\", line 88, in\
    \ load_model\r\n\r\noutput = load_func_map[loader](model_name)\r\n\r\n       \
    \  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/-/llm/text-generation-webui/modules/models.py\"\
    , line 253, in llamacpp_loader\r\n\r\nmodel, tokenizer = LlamaCppModel.from_pretrained(model_file)\r\
    \n\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nFile\
    \ \"/home/-/llm/text-generation-webui/modules/llamacpp_model.py\", line 91, in\
    \ from_pretrained\r\n\r\nresult.model = Llama(**params)\r\n\r\n              \
    \ ^^^^^^^^^^^^^^^\r\n\r\nFile \"/home/-/llm/text-generation-webui/installer_files/env/lib/python3.11/site-packages/llama_cpp_cuda/llama.py\"\
    , line 923, in init\r\n\r\nself._n_vocab = self.n_vocab()\r\n\r\n            \
    \    ^^^^^^^^^^^^^^\r\n\r\nFile \"/home/-/llm/text-generation-webui/installer_files/env/lib/python3.11/site-packages/llama_cpp_cuda/llama.py\"\
    , line 2184, in n_vocab\r\n\r\nreturn self._model.n_vocab()\r\n\r\n       ^^^^^^^^^^^^^^^^^^^^^\r\
    \n\r\nFile \"/home/-/llm/text-generation-webui/installer_files/env/lib/python3.11/site-packages/llama_cpp_cuda/llama.py\"\
    , line 250, in n_vocab\r\n\r\nassert self.model is not None\r\n\r\n       ^^^^^^^^^^^^^^^^^^^^^^\r\
    \n\r\nAssertionError"
  created_at: 2023-12-19 03:36:53+00:00
  edited: false
  hidden: false
  id: 65810fd542d7e36f4afecb9f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d8eb6a6f789b92a8ae78989a27142ec0.svg
      fullname: aditya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aadityaverma
      type: user
    createdAt: '2023-12-19T03:40:04.000Z'
    data:
      edited: false
      editors:
      - aadityaverma
      hidden: false
      identifiedLanguage:
        language: es
        probability: 0.5055806040763855
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d8eb6a6f789b92a8ae78989a27142ec0.svg
          fullname: aditya
          isHf: false
          isPro: false
          name: aadityaverma
          type: user
        html: '<p>Ok I hadnt updated llama cpp</p>

          '
        raw: Ok I hadnt updated llama cpp
        updatedAt: '2023-12-19T03:40:04.736Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6581109424c030b7d388861d
    id: 6581109424c030b7d388861b
    type: comment
  author: aadityaverma
  content: Ok I hadnt updated llama cpp
  created_at: 2023-12-19 03:40:04+00:00
  edited: false
  hidden: false
  id: 6581109424c030b7d388861b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/d8eb6a6f789b92a8ae78989a27142ec0.svg
      fullname: aditya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aadityaverma
      type: user
    createdAt: '2023-12-19T03:40:04.000Z'
    data:
      status: closed
    id: 6581109424c030b7d388861d
    type: status-change
  author: aadityaverma
  created_at: 2023-12-19 03:40:04+00:00
  id: 6581109424c030b7d388861d
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Fennec-Mixtral-8x7B-GGUF
repo_type: model
status: closed
target_branch: null
title: Error in Web UI
