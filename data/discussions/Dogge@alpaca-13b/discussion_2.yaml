!!python/object:huggingface_hub.community.DiscussionWithDetails
author: teknium
conflicting_files: null
created_at: 2023-03-20 05:18:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-03-20T06:18:07.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>Is this a LORA or full fine tune?</p>

          '
        raw: Is this a LORA or full fine tune?
        updatedAt: '2023-03-20T06:18:07.735Z'
      numEdits: 0
      reactions: []
    id: 6417fa9f90dec983ee0d7157
    type: comment
  author: teknium
  content: Is this a LORA or full fine tune?
  created_at: 2023-03-20 05:18:07+00:00
  edited: false
  hidden: false
  id: 6417fa9f90dec983ee0d7157
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb448511090323ea9c8654a500963dc3.svg
      fullname: dd
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Dogge
      type: user
    createdAt: '2023-03-20T19:26:29.000Z'
    data:
      edited: false
      editors:
      - Dogge
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb448511090323ea9c8654a500963dc3.svg
          fullname: dd
          isHf: false
          isPro: false
          name: Dogge
          type: user
        html: '<p>full fine tune with datasets</p>

          '
        raw: full fine tune with datasets
        updatedAt: '2023-03-20T19:26:29.164Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - nacs
    id: 6418b365be72e3e47822a192
    type: comment
  author: Dogge
  content: full fine tune with datasets
  created_at: 2023-03-20 18:26:29+00:00
  edited: false
  hidden: false
  id: 6418b365be72e3e47822a192
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-03-21T00:13:42.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>Thanks, can I ask why the model files are split into so many? And
          why half are 300mb others 600?</p>

          '
        raw: Thanks, can I ask why the model files are split into so many? And why
          half are 300mb others 600?
        updatedAt: '2023-03-21T00:13:42.266Z'
      numEdits: 0
      reactions: []
    id: 6418f6b68b14a25b75892b0a
    type: comment
  author: teknium
  content: Thanks, can I ask why the model files are split into so many? And why half
    are 300mb others 600?
  created_at: 2023-03-20 23:13:42+00:00
  edited: false
  hidden: false
  id: 6418f6b68b14a25b75892b0a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-03-21T03:30:06.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>Some weights of the model checkpoint at alpaca-13b were not used
          when initializing LlamaForCausalLM: [''base_model.model.lm_head.weight'']</p>

          <ul>

          <li>This IS expected if you are initializing LlamaForCausalLM from the checkpoint
          of a model trained on another task or with another architecture (e.g. initializing
          a BertForSequenceClassification model from a BertForPreTraining model).</li>

          <li>This IS NOT expected if you are initializing LlamaForCausalLM from the
          checkpoint of a model that you expect to be exactly identical (initializing
          a BertForSequenceClassification model from a BertForSequenceClassification
          model).</li>

          </ul>

          <p>ValueError: weight is on the meta device, we need a <code>value</code>
          to put in on 0.</p>

          '
        raw: 'Some weights of the model checkpoint at alpaca-13b were not used when
          initializing LlamaForCausalLM: [''base_model.model.lm_head.weight'']

          - This IS expected if you are initializing LlamaForCausalLM from the checkpoint
          of a model trained on another task or with another architecture (e.g. initializing
          a BertForSequenceClassification model from a BertForPreTraining model).

          - This IS NOT expected if you are initializing LlamaForCausalLM from the
          checkpoint of a model that you expect to be exactly identical (initializing
          a BertForSequenceClassification model from a BertForSequenceClassification
          model).


          ValueError: weight is on the meta device, we need a `value` to put in on
          0.'
        updatedAt: '2023-03-21T03:30:06.265Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - elinas
    id: 641924be11cfb28df917a020
    type: comment
  author: teknium
  content: 'Some weights of the model checkpoint at alpaca-13b were not used when
    initializing LlamaForCausalLM: [''base_model.model.lm_head.weight'']

    - This IS expected if you are initializing LlamaForCausalLM from the checkpoint
    of a model trained on another task or with another architecture (e.g. initializing
    a BertForSequenceClassification model from a BertForPreTraining model).

    - This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint
    of a model that you expect to be exactly identical (initializing a BertForSequenceClassification
    model from a BertForSequenceClassification model).


    ValueError: weight is on the meta device, we need a `value` to put in on 0.'
  created_at: 2023-03-21 02:30:06+00:00
  edited: false
  hidden: false
  id: 641924be11cfb28df917a020
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
      fullname: Teknium
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teknium
      type: user
    createdAt: '2023-03-21T03:40:25.000Z'
    data:
      edited: false
      editors:
      - teknium
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317aade83d8d2fd903192d9/erOwgMXc_CZih3uMoyTAp.jpeg?w=200&h=200&f=face
          fullname: Teknium
          isHf: false
          isPro: false
          name: teknium
          type: user
        html: '<p>I get this error, do you happen to know how to fix, using this:</p>

          <p>model = LlamaForCausalLM.from_pretrained(<br>    "alpaca",<br>    load_in_8bit=True,<br>    torch_dtype=torch.float16,<br>    device_map="auto"<br>)</p>

          '
        raw: "I get this error, do you happen to know how to fix, using this:\n\n\
          model = LlamaForCausalLM.from_pretrained(\n    \"alpaca\",\n    load_in_8bit=True,\n\
          \    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)"
        updatedAt: '2023-03-21T03:40:25.945Z'
      numEdits: 0
      reactions: []
    id: 6419272909150c11010573f9
    type: comment
  author: teknium
  content: "I get this error, do you happen to know how to fix, using this:\n\nmodel\
    \ = LlamaForCausalLM.from_pretrained(\n    \"alpaca\",\n    load_in_8bit=True,\n\
    \    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)"
  created_at: 2023-03-21 02:40:25+00:00
  edited: false
  hidden: false
  id: 6419272909150c11010573f9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ab3a649a64dfa36417c2fd0f969f676a.svg
      fullname: Jake
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bikkies
      type: user
    createdAt: '2023-03-22T20:34:57.000Z'
    data:
      edited: false
      editors:
      - Bikkies
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ab3a649a64dfa36417c2fd0f969f676a.svg
          fullname: Jake
          isHf: false
          isPro: false
          name: Bikkies
          type: user
        html: '<p>I''m also getting this error with just this model, trying to load
          it in the text-generation-webui in 8bit</p>

          <p>env/lib/python3.10/site-packages/accelerate/utils/modeling.py", line
          136, in set_module_tensor_to_device<br>    raise ValueError(f"{tensor_name}
          is on the meta device, we need a <code>value</code> to put in on {device}.")<br>ValueError:
          weight is on the meta device, we need a <code>value</code> to put in on
          0.</p>

          '
        raw: "I'm also getting this error with just this model, trying to load it\
          \ in the text-generation-webui in 8bit\n\nenv/lib/python3.10/site-packages/accelerate/utils/modeling.py\"\
          , line 136, in set_module_tensor_to_device\n    raise ValueError(f\"{tensor_name}\
          \ is on the meta device, we need a `value` to put in on {device}.\")\nValueError:\
          \ weight is on the meta device, we need a `value` to put in on 0."
        updatedAt: '2023-03-22T20:34:57.322Z'
      numEdits: 0
      reactions: []
    id: 641b6671d42926275da6f07b
    type: comment
  author: Bikkies
  content: "I'm also getting this error with just this model, trying to load it in\
    \ the text-generation-webui in 8bit\n\nenv/lib/python3.10/site-packages/accelerate/utils/modeling.py\"\
    , line 136, in set_module_tensor_to_device\n    raise ValueError(f\"{tensor_name}\
    \ is on the meta device, we need a `value` to put in on {device}.\")\nValueError:\
    \ weight is on the meta device, we need a `value` to put in on 0."
  created_at: 2023-03-22 19:34:57+00:00
  edited: false
  hidden: false
  id: 641b6671d42926275da6f07b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
      fullname: elinas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: elinas
      type: user
    createdAt: '2023-03-24T01:22:39.000Z'
    data:
      edited: true
      editors:
      - elinas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
          fullname: elinas
          isHf: false
          isPro: false
          name: elinas
          type: user
        html: '<p>Don''t bother, this model is broken beyond repair, also it''s not
          finetuned, it''s LoRA.</p>

          '
        raw: Don't bother, this model is broken beyond repair, also it's not finetuned,
          it's LoRA.
        updatedAt: '2023-03-24T01:22:56.464Z'
      numEdits: 1
      reactions: []
    id: 641cfb5fa073e0d29323eafb
    type: comment
  author: elinas
  content: Don't bother, this model is broken beyond repair, also it's not finetuned,
    it's LoRA.
  created_at: 2023-03-24 00:22:39+00:00
  edited: true
  hidden: false
  id: 641cfb5fa073e0d29323eafb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8a7ca49c1e9e39ace4ebf65f7c38397f.svg
      fullname: 9cento
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 9cento
      type: user
    createdAt: '2023-03-27T12:36:46.000Z'
    data:
      edited: false
      editors:
      - 9cento
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8a7ca49c1e9e39ace4ebf65f7c38397f.svg
          fullname: 9cento
          isHf: false
          isPro: false
          name: 9cento
          type: user
        html: '<blockquote>

          <p>Don''t bother, this model is broken beyond repair, also it''s not finetuned,
          it''s LoRA.</p>

          </blockquote>

          <p>Is there a way to check if a model is LoRA, and more in general to get
          every possible detail out of it, beyond any doubt? I''m very interested
          in this</p>

          '
        raw: '> Don''t bother, this model is broken beyond repair, also it''s not
          finetuned, it''s LoRA.


          Is there a way to check if a model is LoRA, and more in general to get every
          possible detail out of it, beyond any doubt? I''m very interested in this'
        updatedAt: '2023-03-27T12:36:46.304Z'
      numEdits: 0
      reactions: []
    id: 64218dde5acad90e6b6d81c7
    type: comment
  author: 9cento
  content: '> Don''t bother, this model is broken beyond repair, also it''s not finetuned,
    it''s LoRA.


    Is there a way to check if a model is LoRA, and more in general to get every possible
    detail out of it, beyond any doubt? I''m very interested in this'
  created_at: 2023-03-27 11:36:46+00:00
  edited: false
  hidden: false
  id: 64218dde5acad90e6b6d81c7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b21515ab063324ad5b374b0866aef2d0.svg
      fullname: Jonathan Yankovich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tensiondriven
      type: user
    createdAt: '2023-04-01T22:59:05.000Z'
    data:
      edited: false
      editors:
      - tensiondriven
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b21515ab063324ad5b374b0866aef2d0.svg
          fullname: Jonathan Yankovich
          isHf: false
          isPro: false
          name: tensiondriven
          type: user
        html: '<p>The size is a good indication.  I''m sure there are other ways,
          too.</p>

          '
        raw: The size is a good indication.  I'm sure there are other ways, too.
        updatedAt: '2023-04-01T22:59:05.914Z'
      numEdits: 0
      reactions: []
    id: 6428b73952f1fac0b9dda3a1
    type: comment
  author: tensiondriven
  content: The size is a good indication.  I'm sure there are other ways, too.
  created_at: 2023-04-01 21:59:05+00:00
  edited: false
  hidden: false
  id: 6428b73952f1fac0b9dda3a1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Dogge/alpaca-13b
repo_type: model
status: open
target_branch: null
title: Is this a LORA or full fine tune?
