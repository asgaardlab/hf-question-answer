!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ransom
conflicting_files: null
created_at: 2023-06-11 06:37:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39851163dc31c98e5b2fef1b9fddf632.svg
      fullname: Malando
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ransom
      type: user
    createdAt: '2023-06-11T07:37:55.000Z'
    data:
      edited: false
      editors:
      - Ransom
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.39732488989830017
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39851163dc31c98e5b2fef1b9fddf632.svg
          fullname: Malando
          isHf: false
          isPro: false
          name: Ransom
          type: user
        html: "<p>Traceback (most recent call last): File \u201CE:\\llmRunner\\textV2\\\
          oobabooga-windows\\text-generation-webui\\server.py\u201D, line 69, in load_model_wrapper\
          \ shared.model, shared.tokenizer = load_model(shared.model_name) File \u201C\
          E:\\llmRunner\\textV2\\oobabooga-windows\\text-generation-webui\\modules\\\
          models.py\u201D, line 102, in load_model tokenizer = load_tokenizer(model_name,\
          \ model) File \u201CE:\\llmRunner\\textV2\\oobabooga-windows\\text-generation-webui\\\
          modules\\models.py\u201D, line 127, in load_tokenizer tokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}/\u201C), clean_up_tokenization_spaces=True)\
          \ File \u201CE:\\llmRunner\\textV2\\oobabooga-windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D\
          , line 1812, in from_pretrained return cls.from_pretrained( File \u201C\
          E:\\llmRunner\\textV2\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          transformers\\tokenization_utils_base.py\u201D, line 1975, in from_pretrained\
          \ tokenizer = cls(*init_inputs, **init_kwargs) File \u201CE:\\llmRunner\\\
          textV2\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
          models\\llama\\tokenization_llama.py\u201D, line 96, in init self.sp_model.Load(vocab_file)\
          \ File \"E:\\llmRunner\\textV2\\oobabooga-windows\\installer_files\\env\\\
          lib\\site-packages\\sentencepiece_init.py\", line 905, in Load return self.LoadFromFile(model_file)\
          \ File \"E:\\llmRunner\\textV2\\oobabooga-windows\\installer_files\\env\\\
          lib\\site-packages\\sentencepiece_init.py\u201D, line 310, in LoadFromFile\
          \ return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg) TypeError:\
          \ not a string</p>\n<p>Can anyone help?</p>\n<p>Thanks</p>\n"
        raw: "Traceback (most recent call last): File \u201CE:\\llmRunner\\textV2\\\
          oobabooga-windows\\text-generation-webui\\server.py\u201D, line 69, in load_model_wrapper\
          \ shared.model, shared.tokenizer = load_model(shared.model_name) File \u201C\
          E:\\llmRunner\\textV2\\oobabooga-windows\\text-generation-webui\\modules\\\
          models.py\u201D, line 102, in load_model tokenizer = load_tokenizer(model_name,\
          \ model) File \u201CE:\\llmRunner\\textV2\\oobabooga-windows\\text-generation-webui\\\
          modules\\models.py\u201D, line 127, in load_tokenizer tokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}/\u201C), clean_up_tokenization_spaces=True)\
          \ File \u201CE:\\llmRunner\\textV2\\oobabooga-windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D\
          , line 1812, in from_pretrained return cls.from_pretrained( File \u201C\
          E:\\llmRunner\\textV2\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          transformers\\tokenization_utils_base.py\u201D, line 1975, in from_pretrained\
          \ tokenizer = cls(*init_inputs, **init_kwargs) File \u201CE:\\llmRunner\\\
          textV2\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
          models\\llama\\tokenization_llama.py\u201D, line 96, in init self.sp_model.Load(vocab_file)\
          \ File \"E:\\llmRunner\\textV2\\oobabooga-windows\\installer_files\\env\\\
          lib\\site-packages\\sentencepiece_init.py\", line 905, in Load return self.LoadFromFile(model_file)\
          \ File \"E:\\llmRunner\\textV2\\oobabooga-windows\\installer_files\\env\\\
          lib\\site-packages\\sentencepiece_init.py\u201D, line 310, in LoadFromFile\
          \ return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg) TypeError:\
          \ not a string\r\n\r\nCan anyone help?\r\n\r\nThanks"
        updatedAt: '2023-06-11T07:37:55.966Z'
      numEdits: 0
      reactions: []
    id: 648579d36843136a3d0f6249
    type: comment
  author: Ransom
  content: "Traceback (most recent call last): File \u201CE:\\llmRunner\\textV2\\\
    oobabooga-windows\\text-generation-webui\\server.py\u201D, line 69, in load_model_wrapper\
    \ shared.model, shared.tokenizer = load_model(shared.model_name) File \u201CE:\\\
    llmRunner\\textV2\\oobabooga-windows\\text-generation-webui\\modules\\models.py\u201D\
    , line 102, in load_model tokenizer = load_tokenizer(model_name, model) File \u201C\
    E:\\llmRunner\\textV2\\oobabooga-windows\\text-generation-webui\\modules\\models.py\u201D\
    , line 127, in load_tokenizer tokenizer = LlamaTokenizer.from_pretrained(Path(f\"\
    {shared.args.model_dir}/{model_name}/\u201C), clean_up_tokenization_spaces=True)\
    \ File \u201CE:\\llmRunner\\textV2\\oobabooga-windows\\installer_files\\env\\\
    lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D, line 1812,\
    \ in from_pretrained return cls.from_pretrained( File \u201CE:\\llmRunner\\textV2\\\
    oobabooga-windows\\installer_files\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D\
    , line 1975, in from_pretrained tokenizer = cls(*init_inputs, **init_kwargs) File\
    \ \u201CE:\\llmRunner\\textV2\\oobabooga-windows\\installer_files\\env\\lib\\\
    site-packages\\transformers\\models\\llama\\tokenization_llama.py\u201D, line\
    \ 96, in init self.sp_model.Load(vocab_file) File \"E:\\llmRunner\\textV2\\oobabooga-windows\\\
    installer_files\\env\\lib\\site-packages\\sentencepiece_init.py\", line 905, in\
    \ Load return self.LoadFromFile(model_file) File \"E:\\llmRunner\\textV2\\oobabooga-windows\\\
    installer_files\\env\\lib\\site-packages\\sentencepiece_init.py\u201D, line 310,\
    \ in LoadFromFile return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
    \ arg) TypeError: not a string\r\n\r\nCan anyone help?\r\n\r\nThanks"
  created_at: 2023-06-11 06:37:55+00:00
  edited: false
  hidden: false
  id: 648579d36843136a3d0f6249
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-13T02:24:21.000Z'
    data:
      edited: false
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.458207905292511
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: '<p>I get (IndexError: list index out of range)</p>

          '
        raw: 'I get (IndexError: list index out of range)'
        updatedAt: '2023-06-13T02:24:21.887Z'
      numEdits: 0
      reactions: []
    id: 6487d3556d93bc7eb4817d96
    type: comment
  author: vdruts
  content: 'I get (IndexError: list index out of range)'
  created_at: 2023-06-13 01:24:21+00:00
  edited: false
  hidden: false
  id: 6487d3556d93bc7eb4817d96
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-16T11:51:29.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3683123290538788
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Try updating your text-generation-webui to the latest version.  </p>

          '
        raw: 'Try updating your text-generation-webui to the latest version.  '
        updatedAt: '2023-06-16T11:51:29.403Z'
      numEdits: 0
      reactions: []
    id: 648c4cc1e1b6e19cc57011eb
    type: comment
  author: TheBloke
  content: 'Try updating your text-generation-webui to the latest version.  '
  created_at: 2023-06-16 10:51:29+00:00
  edited: false
  hidden: false
  id: 648c4cc1e1b6e19cc57011eb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/tulu-30B-GPTQ
repo_type: model
status: open
target_branch: null
title: Error loading in text-generation-webui
