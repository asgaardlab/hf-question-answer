!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xiajinxiong
conflicting_files: null
created_at: 2022-07-21 14:42:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/68802152b538ba02579a83de9a0ee8cc.svg
      fullname: North wind
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xiajinxiong
      type: user
    createdAt: '2022-07-21T15:42:24.000Z'
    data:
      edited: false
      editors:
      - xiajinxiong
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/68802152b538ba02579a83de9a0ee8cc.svg
          fullname: North wind
          isHf: false
          isPro: false
          name: xiajinxiong
          type: user
        html: '<p>When I run the following code to load the OPT model, it always raises
          a KeyError:<br>`<br>import torch<br>from transformers import AutoModelForCausalLM,
          AutoTokenizer</p>

          <p>model = AutoModelForCausalLM.from_pretrained("facebook/opt-66b", torch_dtype=torch.float16)<br>`</p>

          <p>Error:</p>

          <p>KeyError                                  Traceback (most recent call
          last)</p>

          <p> in <br>      2 from transformers import AutoModelForCausalLM, AutoTokenizer,
          AutoModel<br>      3<br>----&gt; 4 model = AutoModelForCausalLM.from_pretrained("facebook/opt-66b",
          torch_dtype=torch.float16)<br>      5 # model = AutoModelForCausalLM.from_pretrained("facebook/opt-350m",
          torch_dtype=torch.float16)<br>      6 #</p>

          <p>~/workspace/anaconda3/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py
          in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)<br>    421         kwargs["_from_auto"]
          = True<br>    422         if not isinstance(config, PretrainedConfig):<br>--&gt;
          423             config, kwargs = AutoConfig.from_pretrained(<br>    424                 pretrained_model_name_or_path,
          return_unused_kwargs=True, trust_remote_code=trust_remote_code, **kwargs<br>    425             )</p>

          <p>~/workspace/anaconda3/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py
          in from_pretrained(cls, pretrained_model_name_or_path, **kwargs)<br>    670<br>    671         Examples:<br>--&gt;
          672<br>    673         ```python<br>    674         &gt;&gt;&gt; from transformers
          import AutoConfig</p>

          <p>~/workspace/anaconda3/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py
          in <strong>getitem</strong>(self, key)<br>    385         ("xlsr_wav2vec2",
          "XLSR-Wav2Vec2"),<br>    386         ("yolos", "YOLOS"),<br>--&gt; 387         ("yoso",
          "YOSO"),<br>    388     ]<br>    389 )</p>

          <p>KeyError: ''opt''</p>

          '
        raw: "When I run the following code to load the OPT model, it always raises\
          \ a KeyError:\r\n`\r\nimport torch\r\nfrom transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(\"facebook/opt-66b\"\
          , torch_dtype=torch.float16)\r\n`\r\n\r\n\r\nError:\r\n\r\nKeyError    \
          \                              Traceback (most recent call last)\r\n\r\n\
          <ipython-input-12-55ecaa089590> in <module>\r\n      2 from transformers\
          \ import AutoModelForCausalLM, AutoTokenizer, AutoModel\r\n      3 \r\n\
          ----> 4 model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-66b\"\
          , torch_dtype=torch.float16)\r\n      5 # model = AutoModelForCausalLM.from_pretrained(\"\
          facebook/opt-350m\", torch_dtype=torch.float16)\r\n      6 #\r\n\r\n~/workspace/anaconda3/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)\r\
          \n    421         kwargs[\"_from_auto\"] = True\r\n    422         if not\
          \ isinstance(config, PretrainedConfig):\r\n--> 423             config, kwargs\
          \ = AutoConfig.from_pretrained(\r\n    424                 pretrained_model_name_or_path,\
          \ return_unused_kwargs=True, trust_remote_code=trust_remote_code, **kwargs\r\
          \n    425             )\r\n\r\n~/workspace/anaconda3/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\n \
          \   670 \r\n    671         Examples:\r\n--> 672 \r\n    673         ```python\r\
          \n    674         >>> from transformers import AutoConfig\r\n\r\n~/workspace/anaconda3/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\
          \ in __getitem__(self, key)\r\n    385         (\"xlsr_wav2vec2\", \"XLSR-Wav2Vec2\"\
          ),\r\n    386         (\"yolos\", \"YOLOS\"),\r\n--> 387         (\"yoso\"\
          , \"YOSO\"),\r\n    388     ]\r\n    389 )\r\n\r\nKeyError: 'opt'"
        updatedAt: '2022-07-21T15:42:24.065Z'
      numEdits: 0
      reactions: []
    id: 62d973e0810069dec2d38a17
    type: comment
  author: xiajinxiong
  content: "When I run the following code to load the OPT model, it always raises\
    \ a KeyError:\r\n`\r\nimport torch\r\nfrom transformers import AutoModelForCausalLM,\
    \ AutoTokenizer\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(\"facebook/opt-66b\"\
    , torch_dtype=torch.float16)\r\n`\r\n\r\n\r\nError:\r\n\r\nKeyError          \
    \                        Traceback (most recent call last)\r\n\r\n<ipython-input-12-55ecaa089590>\
    \ in <module>\r\n      2 from transformers import AutoModelForCausalLM, AutoTokenizer,\
    \ AutoModel\r\n      3 \r\n----> 4 model = AutoModelForCausalLM.from_pretrained(\"\
    facebook/opt-66b\", torch_dtype=torch.float16)\r\n      5 # model = AutoModelForCausalLM.from_pretrained(\"\
    facebook/opt-350m\", torch_dtype=torch.float16)\r\n      6 #\r\n\r\n~/workspace/anaconda3/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\
    \ in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)\r\
    \n    421         kwargs[\"_from_auto\"] = True\r\n    422         if not isinstance(config,\
    \ PretrainedConfig):\r\n--> 423             config, kwargs = AutoConfig.from_pretrained(\r\
    \n    424                 pretrained_model_name_or_path, return_unused_kwargs=True,\
    \ trust_remote_code=trust_remote_code, **kwargs\r\n    425             )\r\n\r\
    \n~/workspace/anaconda3/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\
    \ in from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\n    670\
    \ \r\n    671         Examples:\r\n--> 672 \r\n    673         ```python\r\n \
    \   674         >>> from transformers import AutoConfig\r\n\r\n~/workspace/anaconda3/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\
    \ in __getitem__(self, key)\r\n    385         (\"xlsr_wav2vec2\", \"XLSR-Wav2Vec2\"\
    ),\r\n    386         (\"yolos\", \"YOLOS\"),\r\n--> 387         (\"yoso\", \"\
    YOSO\"),\r\n    388     ]\r\n    389 )\r\n\r\nKeyError: 'opt'"
  created_at: 2022-07-21 14:42:24+00:00
  edited: false
  hidden: false
  id: 62d973e0810069dec2d38a17
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/68802152b538ba02579a83de9a0ee8cc.svg
      fullname: North wind
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xiajinxiong
      type: user
    createdAt: '2022-07-22T16:17:45.000Z'
    data:
      status: closed
    id: 62dacda9e30ea13bdf0d663e
    type: status-change
  author: xiajinxiong
  created_at: 2022-07-22 15:17:45+00:00
  id: 62dacda9e30ea13bdf0d663e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: facebook/opt-66b
repo_type: model
status: closed
target_branch: null
title: Loading model raises KeyError
