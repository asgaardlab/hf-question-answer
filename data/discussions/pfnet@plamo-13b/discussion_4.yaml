!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ysuz
conflicting_files: null
created_at: 2023-10-04 07:12:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8f1b9351ec39a39a406398d3885427d8.svg
      fullname: Yuta Suzuki
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ysuz
      type: user
    createdAt: '2023-10-04T08:12:38.000Z'
    data:
      edited: false
      editors:
      - ysuz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7057967185974121
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8f1b9351ec39a39a406398d3885427d8.svg
          fullname: Yuta Suzuki
          isHf: false
          isPro: false
          name: ysuz
          type: user
        html: '<p>Hello, I would like to report an unintended behavior that I have
          encountered.</p>

          <h2 id="summary">Summary:</h2>

          <p>In environments with <code>transformers &gt; 4.32.0</code>, loading a
          Tokenizer results in an <code>AttributeError: ''PlamoTokenizer'' object
          has no attribute ''sp_model''</code>. I have confirmed this issue in an
          environment with <code>transformers 4.34.0</code>, <code>tokenizers 0.14.0</code>,
          and <code>sentencepiece 0.1.99</code>. It is unclear whether this issue
          originates from the transformers library or from other dependent packages.</p>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM

          tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"pfnet/plamo-13b"</span>,
          trust_remote_code=<span class="hljs-literal">True</span>) <span class="hljs-comment">#
          raise error</span>

          <span class="hljs-comment"># model = AutoModelForCausalLM.from_pretrained("pfnet/plamo-13b",
          trust_remote_code=True)</span>

          </code></pre>

          <p>Strangely enough, text generation works without any errors with transformers
          version 4.34.0 when using the pipeline.</p>

          <pre><code class="language-python"><span class="hljs-keyword">import</span>
          transformers

          pipeline = transformers.pipeline(<span class="hljs-string">"text-generation"</span>,
          model=<span class="hljs-string">"pfnet/plamo-13b"</span>, trust_remote_code=<span
          class="hljs-literal">True</span>)

          <span class="hljs-built_in">print</span>(pipeline(<span class="hljs-string">"The
          future of artificial intelligence technology is "</span>, max_new_tokens=<span
          class="hljs-number">32</span>))

          </code></pre>

          <h2 id="workaround">Workaround:</h2>

          <p><code>pip install transformers==4.32.0</code></p>

          '
        raw: "Hello, I would like to report an unintended behavior that I have encountered.\r\
          \n\r\n## Summary: \r\nIn environments with `transformers > 4.32.0`, loading\
          \ a Tokenizer results in an `AttributeError: 'PlamoTokenizer' object has\
          \ no attribute 'sp_model'`. I have confirmed this issue in an environment\
          \ with `transformers 4.34.0`, `tokenizers 0.14.0`, and `sentencepiece 0.1.99`.\
          \ It is unclear whether this issue originates from the transformers library\
          \ or from other dependent packages.\r\n\r\n```python\r\nfrom transformers\
          \ import AutoTokenizer, AutoModelForCausalLM\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          pfnet/plamo-13b\", trust_remote_code=True) # raise error\r\n# model = AutoModelForCausalLM.from_pretrained(\"\
          pfnet/plamo-13b\", trust_remote_code=True)\r\n```\r\n\r\nStrangely enough,\
          \ text generation works without any errors with transformers version 4.34.0\
          \ when using the pipeline.\r\n```python\r\nimport transformers\r\npipeline\
          \ = transformers.pipeline(\"text-generation\", model=\"pfnet/plamo-13b\"\
          , trust_remote_code=True)\r\nprint(pipeline(\"The future of artificial intelligence\
          \ technology is \", max_new_tokens=32))\r\n```\r\n\r\n## Workaround:\r\n\
          `pip install transformers==4.32.0`"
        updatedAt: '2023-10-04T08:12:38.053Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - sokada
        - p1atdev
        - hariby
    id: 651d1e7689f39456c53e98c9
    type: comment
  author: ysuz
  content: "Hello, I would like to report an unintended behavior that I have encountered.\r\
    \n\r\n## Summary: \r\nIn environments with `transformers > 4.32.0`, loading a\
    \ Tokenizer results in an `AttributeError: 'PlamoTokenizer' object has no attribute\
    \ 'sp_model'`. I have confirmed this issue in an environment with `transformers\
    \ 4.34.0`, `tokenizers 0.14.0`, and `sentencepiece 0.1.99`. It is unclear whether\
    \ this issue originates from the transformers library or from other dependent\
    \ packages.\r\n\r\n```python\r\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\r\
    \ntokenizer = AutoTokenizer.from_pretrained(\"pfnet/plamo-13b\", trust_remote_code=True)\
    \ # raise error\r\n# model = AutoModelForCausalLM.from_pretrained(\"pfnet/plamo-13b\"\
    , trust_remote_code=True)\r\n```\r\n\r\nStrangely enough, text generation works\
    \ without any errors with transformers version 4.34.0 when using the pipeline.\r\
    \n```python\r\nimport transformers\r\npipeline = transformers.pipeline(\"text-generation\"\
    , model=\"pfnet/plamo-13b\", trust_remote_code=True)\r\nprint(pipeline(\"The future\
    \ of artificial intelligence technology is \", max_new_tokens=32))\r\n```\r\n\r\
    \n## Workaround:\r\n`pip install transformers==4.32.0`"
  created_at: 2023-10-04 07:12:38+00:00
  edited: false
  hidden: false
  id: 651d1e7689f39456c53e98c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6487d46ac4b44322c12313aa/mmaFqOCXxX2-_n5JpmgfW.png?w=200&h=200&f=face
      fullname: shintarou okada
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sokada
      type: user
    createdAt: '2023-10-04T08:31:03.000Z'
    data:
      edited: false
      editors:
      - sokada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9661169648170471
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6487d46ac4b44322c12313aa/mmaFqOCXxX2-_n5JpmgfW.png?w=200&h=200&f=face
          fullname: shintarou okada
          isHf: false
          isPro: false
          name: sokada
          type: user
        html: '<p>Thank you for bringing this issue to our attention. We have confirmed
          the problem and are currently working on a fix in <code>tokenization_plamo.py</code>.
          We appreciate your patience as we work towards resolving the issue.</p>

          '
        raw: Thank you for bringing this issue to our attention. We have confirmed
          the problem and are currently working on a fix in `tokenization_plamo.py`.
          We appreciate your patience as we work towards resolving the issue.
        updatedAt: '2023-10-04T08:31:03.614Z'
      numEdits: 0
      reactions: []
    id: 651d22c7dc229d2e818d6945
    type: comment
  author: sokada
  content: Thank you for bringing this issue to our attention. We have confirmed the
    problem and are currently working on a fix in `tokenization_plamo.py`. We appreciate
    your patience as we work towards resolving the issue.
  created_at: 2023-10-04 07:31:03+00:00
  edited: false
  hidden: false
  id: 651d22c7dc229d2e818d6945
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/ICTuyjzcut5mWWWPYXC_X.jpeg?w=200&h=200&f=face
      fullname: Daiki Higurashi
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: dhigurashi
      type: user
    createdAt: '2023-10-10T07:12:23.000Z'
    data:
      edited: false
      editors:
      - dhigurashi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9303762912750244
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/ICTuyjzcut5mWWWPYXC_X.jpeg?w=200&h=200&f=face
          fullname: Daiki Higurashi
          isHf: false
          isPro: false
          name: dhigurashi
          type: user
        html: '<p>We have updated. Thank you for your report!</p>

          '
        raw: We have updated. Thank you for your report!
        updatedAt: '2023-10-10T07:12:23.372Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6524f95759f6001307a7847f
    id: 6524f95759f6001307a7847c
    type: comment
  author: dhigurashi
  content: We have updated. Thank you for your report!
  created_at: 2023-10-10 06:12:23+00:00
  edited: false
  hidden: false
  id: 6524f95759f6001307a7847c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/ICTuyjzcut5mWWWPYXC_X.jpeg?w=200&h=200&f=face
      fullname: Daiki Higurashi
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: dhigurashi
      type: user
    createdAt: '2023-10-10T07:12:23.000Z'
    data:
      status: closed
    id: 6524f95759f6001307a7847f
    type: status-change
  author: dhigurashi
  created_at: 2023-10-10 06:12:23+00:00
  id: 6524f95759f6001307a7847f
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: pfnet/plamo-13b
repo_type: model
status: closed
target_branch: null
title: Incompatibility with Transformers > 4.32.0
