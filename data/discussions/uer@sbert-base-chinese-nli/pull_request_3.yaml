!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pe65374
conflicting_files: []
created_at: 2022-11-04 07:49:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665398834110-noauth.png?w=200&h=200&f=face
      fullname: Zhang ning
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pe65374
      type: user
    createdAt: '2022-11-04T08:49:21.000Z'
    data:
      edited: false
      editors:
      - pe65374
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665398834110-noauth.png?w=200&h=200&f=face
          fullname: Zhang ning
          isHf: false
          isPro: false
          name: pe65374
          type: user
        html: '<p>4 configs file. config.json under 1_Pooling directory as described
          in modules.json.<br>With putting those 4 files under the sbert-base-chinese-nli/
          ,  the Warning "WARNING - No sentence-transformers model found with name
          /Users/peter42/.cache/torch/sentence_transformers/uer_sbert-base-chinese-nli.
          Creating a new one with MEAN pooling."  would be solved.<br>The reason of
          Warning is described in the source code of <a rel="nofollow" href="https://github.com/UKPLab/sentence-transformers">https://github.com/UKPLab/sentence-transformers</a>
          </p>

          <p>If modules.json exsits, standard sentence_transformers load function
          is called. Or Auto model/Tokenize as huggingface model with mean pooling
          will be called.</p>

          '
        raw: "4 configs file. config.json under 1_Pooling directory as described in\
          \ modules.json.\nWith putting those 4 files under the sbert-base-chinese-nli/\
          \ ,  the Warning \"WARNING - No sentence-transformers model found with name\
          \ /Users/peter42/.cache/torch/sentence_transformers/uer_sbert-base-chinese-nli.\
          \ Creating a new one with MEAN pooling.\"  would be solved. \nThe reason\
          \ of Warning is described in the source code of https://github.com/UKPLab/sentence-transformers\
          \ \n\nIf modules.json exsits, standard sentence_transformers load function\
          \ is called. Or Auto model/Tokenize as huggingface model with mean pooling\
          \ will be called."
        updatedAt: '2022-11-04T08:49:21.899Z'
      numEdits: 0
      reactions: []
    id: 6364d211f31ef76df4f8a06c
    type: comment
  author: pe65374
  content: "4 configs file. config.json under 1_Pooling directory as described in\
    \ modules.json.\nWith putting those 4 files under the sbert-base-chinese-nli/\
    \ ,  the Warning \"WARNING - No sentence-transformers model found with name /Users/peter42/.cache/torch/sentence_transformers/uer_sbert-base-chinese-nli.\
    \ Creating a new one with MEAN pooling.\"  would be solved. \nThe reason of Warning\
    \ is described in the source code of https://github.com/UKPLab/sentence-transformers\
    \ \n\nIf modules.json exsits, standard sentence_transformers load function is\
    \ called. Or Auto model/Tokenize as huggingface model with mean pooling will be\
    \ called."
  created_at: 2022-11-04 07:49:21+00:00
  edited: false
  hidden: false
  id: 6364d211f31ef76df4f8a06c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665398834110-noauth.png?w=200&h=200&f=face
      fullname: Zhang ning
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pe65374
      type: user
    createdAt: '2022-11-04T08:49:22.000Z'
    data:
      oid: 827d1b828afae1e0fde9f26a590ff0e1eaded589
      parents:
      - 1e1b01f82c062cb48af4443ab0aa89809e490ad8
      subject: To solve the warning from sentence_transformers, add 4 configs files.
    id: 6364d2120000000000000000
    type: commit
  author: pe65374
  created_at: 2022-11-04 07:49:22+00:00
  id: 6364d2120000000000000000
  oid: 827d1b828afae1e0fde9f26a590ff0e1eaded589
  summary: To solve the warning from sentence_transformers, add 4 configs files.
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a79c21bd823c981f0ba20e12c3703764.svg
      fullname: ying zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yingzhang79
      type: user
    createdAt: '2022-11-24T06:48:19.000Z'
    data:
      edited: false
      editors:
      - yingzhang79
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a79c21bd823c981f0ba20e12c3703764.svg
          fullname: ying zhang
          isHf: false
          isPro: false
          name: yingzhang79
          type: user
        html: "<p>i try your method, but i do not successfully load the model, because\
          \ i get an new error: RuntimeError: Error(s) in loading state_dict for BertModel:<br>\
          \    size mismatch for embeddings.word_embeddings.weight: copying a param\
          \ with shape torch.Size([21128, 768]) from checkpoint, the shape in current\
          \ model is torch.Size([30522, 768]).<br>    You may consider adding <code>ignore_mismatched_sizes=True</code>\
          \ in the model <code>from_pretrained</code> method.</p>\n<p>what i do:<br>1\u3001\
          i add three json files under the sbert-base-chinese-nli/, the content i\
          \ added came from pasting your code in the file changed.<br>2\u3001i change\
          \ the content in the config.json, replaceing 22 line code into 6 line that\
          \ i paste in files changed too.</p>\n<p>is there any wrong? thx.</p>\n"
        raw: "i try your method, but i do not successfully load the model, because\
          \ i get an new error: RuntimeError: Error(s) in loading state_dict for BertModel:\n\
          \tsize mismatch for embeddings.word_embeddings.weight: copying a param with\
          \ shape torch.Size([21128, 768]) from checkpoint, the shape in current model\
          \ is torch.Size([30522, 768]).\n\tYou may consider adding `ignore_mismatched_sizes=True`\
          \ in the model `from_pretrained` method.\n\nwhat i do:\n1\u3001i add three\
          \ json files under the sbert-base-chinese-nli/, the content i added came\
          \ from pasting your code in the file changed.\n2\u3001i change the content\
          \ in the config.json, replaceing 22 line code into 6 line that i paste in\
          \ files changed too.\n\nis there any wrong? thx."
        updatedAt: '2022-11-24T06:48:19.323Z'
      numEdits: 0
      reactions: []
    id: 637f13b394e007a34cc1f2b3
    type: comment
  author: yingzhang79
  content: "i try your method, but i do not successfully load the model, because i\
    \ get an new error: RuntimeError: Error(s) in loading state_dict for BertModel:\n\
    \tsize mismatch for embeddings.word_embeddings.weight: copying a param with shape\
    \ torch.Size([21128, 768]) from checkpoint, the shape in current model is torch.Size([30522,\
    \ 768]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model\
    \ `from_pretrained` method.\n\nwhat i do:\n1\u3001i add three json files under\
    \ the sbert-base-chinese-nli/, the content i added came from pasting your code\
    \ in the file changed.\n2\u3001i change the content in the config.json, replaceing\
    \ 22 line code into 6 line that i paste in files changed too.\n\nis there any\
    \ wrong? thx."
  created_at: 2022-11-24 06:48:19+00:00
  edited: false
  hidden: false
  id: 637f13b394e007a34cc1f2b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e9ac2f30d4491da5335acc52524361fa.svg
      fullname: Yunyi Shen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yshen99
      type: user
    createdAt: '2022-12-09T20:01:20.000Z'
    data:
      edited: false
      editors:
      - yshen99
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e9ac2f30d4491da5335acc52524361fa.svg
          fullname: Yunyi Shen
          isHf: false
          isPro: false
          name: yshen99
          type: user
        html: "<blockquote>\n<p>i try your method, but i do not successfully load\
          \ the model, because i get an new error: RuntimeError: Error(s) in loading\
          \ state_dict for BertModel:<br>    size mismatch for embeddings.word_embeddings.weight:\
          \ copying a param with shape torch.Size([21128, 768]) from checkpoint, the\
          \ shape in current model is torch.Size([30522, 768]).<br>    You may consider\
          \ adding <code>ignore_mismatched_sizes=True</code> in the model <code>from_pretrained</code>\
          \ method.</p>\n<p>what i do:<br>1\u3001i add three json files under the\
          \ sbert-base-chinese-nli/, the content i added came from pasting your code\
          \ in the file changed.<br>2\u3001i change the content in the config.json,\
          \ replaceing 22 line code into 6 line that i paste in files changed too.</p>\n\
          <p>is there any wrong? thx.</p>\n</blockquote>\n<p>It turns out you need\
          \ to keep the original <code>config.json</code> in the home directory and\
          \ add another <code>1_Pooling</code> directory and have the changed <code>config.json</code>\
          \ in that directory. Take a look at this example: e.g. <a href=\"https://huggingface.co/sentence-transformers/multi-qa-distilbert-cos-v1/tree/main\"\
          >https://huggingface.co/sentence-transformers/multi-qa-distilbert-cos-v1/tree/main</a></p>\n"
        raw: "> i try your method, but i do not successfully load the model, because\
          \ i get an new error: RuntimeError: Error(s) in loading state_dict for BertModel:\n\
          > \tsize mismatch for embeddings.word_embeddings.weight: copying a param\
          \ with shape torch.Size([21128, 768]) from checkpoint, the shape in current\
          \ model is torch.Size([30522, 768]).\n> \tYou may consider adding `ignore_mismatched_sizes=True`\
          \ in the model `from_pretrained` method.\n> \n> what i do:\n> 1\u3001i add\
          \ three json files under the sbert-base-chinese-nli/, the content i added\
          \ came from pasting your code in the file changed.\n> 2\u3001i change the\
          \ content in the config.json, replaceing 22 line code into 6 line that i\
          \ paste in files changed too.\n> \n> is there any wrong? thx.\n\nIt turns\
          \ out you need to keep the original `config.json` in the home directory\
          \ and add another `1_Pooling` directory and have the changed `config.json`\
          \ in that directory. Take a look at this example: e.g. https://huggingface.co/sentence-transformers/multi-qa-distilbert-cos-v1/tree/main"
        updatedAt: '2022-12-09T20:01:20.716Z'
      numEdits: 0
      reactions: []
    id: 63939410233814b266323585
    type: comment
  author: yshen99
  content: "> i try your method, but i do not successfully load the model, because\
    \ i get an new error: RuntimeError: Error(s) in loading state_dict for BertModel:\n\
    > \tsize mismatch for embeddings.word_embeddings.weight: copying a param with\
    \ shape torch.Size([21128, 768]) from checkpoint, the shape in current model is\
    \ torch.Size([30522, 768]).\n> \tYou may consider adding `ignore_mismatched_sizes=True`\
    \ in the model `from_pretrained` method.\n> \n> what i do:\n> 1\u3001i add three\
    \ json files under the sbert-base-chinese-nli/, the content i added came from\
    \ pasting your code in the file changed.\n> 2\u3001i change the content in the\
    \ config.json, replaceing 22 line code into 6 line that i paste in files changed\
    \ too.\n> \n> is there any wrong? thx.\n\nIt turns out you need to keep the original\
    \ `config.json` in the home directory and add another `1_Pooling` directory and\
    \ have the changed `config.json` in that directory. Take a look at this example:\
    \ e.g. https://huggingface.co/sentence-transformers/multi-qa-distilbert-cos-v1/tree/main"
  created_at: 2022-12-09 20:01:20+00:00
  edited: false
  hidden: false
  id: 63939410233814b266323585
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 3
repo_id: uer/sbert-base-chinese-nli
repo_type: model
status: open
target_branch: refs/heads/main
title: To solve the warning from sentence_transformers, add 4 configs files.
