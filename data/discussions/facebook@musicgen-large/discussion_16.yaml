!!python/object:huggingface_hub.community.DiscussionWithDetails
author: severos
conflicting_files: null
created_at: 2023-12-11 02:01:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c64b8dc12b23471aaf29d23eacfaedb9.svg
      fullname: Tarek Aoukar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: severos
      type: user
    createdAt: '2023-12-11T02:01:18.000Z'
    data:
      edited: false
      editors:
      - severos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.743533194065094
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c64b8dc12b23471aaf29d23eacfaedb9.svg
          fullname: Tarek Aoukar
          isHf: false
          isPro: false
          name: severos
          type: user
        html: "<p>Generating audio incrementally using 2 seconds steps:</p>\n<ol>\n\
          <li>2 seconds are generated by text condition <code>\"80s pop synth guitars\
          \ and heavy drums\"</code></li>\n<li>Write result to file</li>\n<li>Read\
          \ previous file</li>\n<li>Generate 2 seconds using text condition <code>\"\
          80s pop synth guitars and heavy drums\"</code> and previous audio file</li>\n\
          <li>Repeat from 2</li>\n</ol>\n<p>So far so good, everything works.<br>However,\
          \ when changing the text condition in step 4, ex: text condition is <code>\"\
          80s pop track with bassy drums and synth\", \"90s rock song with loud guitars\
          \ and heavy drums\"</code>, a runtime error will be thrown: </p>\n<pre><code>Traceback\
          \ (most recent call last):\n  File \"main.py\", line 32, in &lt;module&gt;\n\
          \    audio_values = model.generate(**inputs, max_new_tokens=128)\n  File\
          \ \"C:\\Python38\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line\
          \ 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"\
          C:\\Python38\\lib\\site-packages\\transformers\\models\\musicgen\\modeling_musicgen.py\"\
          , line 2279, in generate\n    input_ids, model_kwargs = self._prepare_decoder_input_ids_for_generation(\n\
          \  File \"C:\\Python38\\lib\\site-packages\\transformers\\models\\musicgen\\\
          modeling_musicgen.py\", line 1993, in _prepare_decoder_input_ids_for_generation\n\
          \    decoder_input_ids = torch.cat([decoder_input_ids_start, decoder_input_ids],\
          \ dim=-1)\nRuntimeError: Sizes of tensors must match except in dimension\
          \ 1. Expected size 8 but got size 4 for tensor number 1 in the list.\n</code></pre>\n\
          <p>I expected this would work without issue since the model should treat\
          \ each iteration from step 3 as a separate prompt processing, or am I misunderstanding\
          \ something in here?</p>\n"
        raw: "Generating audio incrementally using 2 seconds steps:\r\n1. 2 seconds\
          \ are generated by text condition `\"80s pop synth guitars and heavy drums\"\
          `\r\n2. Write result to file\r\n3. Read previous file\r\n4. Generate 2 seconds\
          \ using text condition `\"80s pop synth guitars and heavy drums\"` and previous\
          \ audio file\r\n5. Repeat from 2\r\n\r\nSo far so good, everything works.\r\
          \nHowever, when changing the text condition in step 4, ex: text condition\
          \ is `\"80s pop track with bassy drums and synth\", \"90s rock song with\
          \ loud guitars and heavy drums\"`, a runtime error will be thrown: \r\n\r\
          \n    Traceback (most recent call last):\r\n      File \"main.py\", line\
          \ 32, in <module>\r\n        audio_values = model.generate(**inputs, max_new_tokens=128)\r\
          \n      File \"C:\\Python38\\lib\\site-packages\\torch\\utils\\_contextlib.py\"\
          , line 115, in decorate_context\r\n        return func(*args, **kwargs)\r\
          \n      File \"C:\\Python38\\lib\\site-packages\\transformers\\models\\\
          musicgen\\modeling_musicgen.py\", line 2279, in generate\r\n        input_ids,\
          \ model_kwargs = self._prepare_decoder_input_ids_for_generation(\r\n   \
          \   File \"C:\\Python38\\lib\\site-packages\\transformers\\models\\musicgen\\\
          modeling_musicgen.py\", line 1993, in _prepare_decoder_input_ids_for_generation\r\
          \n        decoder_input_ids = torch.cat([decoder_input_ids_start, decoder_input_ids],\
          \ dim=-1)\r\n    RuntimeError: Sizes of tensors must match except in dimension\
          \ 1. Expected size 8 but got size 4 for tensor number 1 in the list.\r\n\
          \r\nI expected this would work without issue since the model should treat\
          \ each iteration from step 3 as a separate prompt processing, or am I misunderstanding\
          \ something in here?"
        updatedAt: '2023-12-11T02:01:18.825Z'
      numEdits: 0
      reactions: []
    id: 65766d6ee09de6aa746532b0
    type: comment
  author: severos
  content: "Generating audio incrementally using 2 seconds steps:\r\n1. 2 seconds\
    \ are generated by text condition `\"80s pop synth guitars and heavy drums\"`\r\
    \n2. Write result to file\r\n3. Read previous file\r\n4. Generate 2 seconds using\
    \ text condition `\"80s pop synth guitars and heavy drums\"` and previous audio\
    \ file\r\n5. Repeat from 2\r\n\r\nSo far so good, everything works.\r\nHowever,\
    \ when changing the text condition in step 4, ex: text condition is `\"80s pop\
    \ track with bassy drums and synth\", \"90s rock song with loud guitars and heavy\
    \ drums\"`, a runtime error will be thrown: \r\n\r\n    Traceback (most recent\
    \ call last):\r\n      File \"main.py\", line 32, in <module>\r\n        audio_values\
    \ = model.generate(**inputs, max_new_tokens=128)\r\n      File \"C:\\Python38\\\
    lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\r\
    \n        return func(*args, **kwargs)\r\n      File \"C:\\Python38\\lib\\site-packages\\\
    transformers\\models\\musicgen\\modeling_musicgen.py\", line 2279, in generate\r\
    \n        input_ids, model_kwargs = self._prepare_decoder_input_ids_for_generation(\r\
    \n      File \"C:\\Python38\\lib\\site-packages\\transformers\\models\\musicgen\\\
    modeling_musicgen.py\", line 1993, in _prepare_decoder_input_ids_for_generation\r\
    \n        decoder_input_ids = torch.cat([decoder_input_ids_start, decoder_input_ids],\
    \ dim=-1)\r\n    RuntimeError: Sizes of tensors must match except in dimension\
    \ 1. Expected size 8 but got size 4 for tensor number 1 in the list.\r\n\r\nI\
    \ expected this would work without issue since the model should treat each iteration\
    \ from step 3 as a separate prompt processing, or am I misunderstanding something\
    \ in here?"
  created_at: 2023-12-11 02:01:18+00:00
  edited: false
  hidden: false
  id: 65766d6ee09de6aa746532b0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: facebook/musicgen-large
repo_type: model
status: open
target_branch: null
title: Tensors size error when generating audio incrementally.
