!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ReXommendation
conflicting_files: null
created_at: 2023-06-12 09:12:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bb50f47c5235ec070041a4a9f78fe396.svg
      fullname: ReXommendation
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ReXommendation
      type: user
    createdAt: '2023-06-12T10:12:31.000Z'
    data:
      edited: false
      editors:
      - ReXommendation
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3808598518371582
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bb50f47c5235ec070041a4a9f78fe396.svg
          fullname: ReXommendation
          isHf: false
          isPro: false
          name: ReXommendation
          type: user
        html: '<p>Traceback (most recent call last):<br>  File "/home/rexommendation/Programs/musicgen-large/musicgen.py",
          line 10, in <br>    wav = model.generate(descriptions)  # generates 3 samples.<br>          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/musicgen.py",
          line 144, in generate<br>    return self._generate_tokens(attributes, prompt_tokens,
          progress)<br>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/musicgen.py",
          line 279, in _generate_tokens<br>    gen_tokens = self.lm.generate(prompt_tokens,
          attributes, callback=callback, **self.generation_params)<br>                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/torch/utils/_contextlib.py",
          line 115, in decorate_context<br>    return func(*args, **kwargs)<br>           ^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/lm.py",
          line 489, in generate<br>    next_token = self._sample_next_token(<br>                 ^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/lm.py",
          line 354, in _sample_next_token<br>    all_logits = model(<br>                 ^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py",
          line 1501, in <em>call_impl<br>    return forward_call(*args, **kwargs)<br>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/lm.py",
          line 253, in forward<br>    out = self.transformer(input</em>, cross_attention_src=cross_attention_input)<br>          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl<br>    return forward_call(*args, **kwargs)<br>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py",
          line 657, in forward<br>    x = self._apply_layer(layer, x, *args, **kwargs)<br>        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py",
          line 614, in _apply_layer<br>    return layer(*args, **kwargs)<br>           ^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl<br>    return forward_call(*args, **kwargs)<br>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py",
          line 508, in forward<br>    self._sa_block(self.norm1(x), src_mask, src_key_padding_mask))<br>    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/transformer.py",
          line 581, in _sa_block<br>    x = self.self_attn(x, x, x,<br>        ^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py",
          line 1501, in _call_impl<br>    return forward_call(*args, **kwargs)<br>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py",
          line 367, in forward<br>    x = ops.memory_efficient_attention(q, k, v,
          attn_mask, p=p)<br>        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/<strong>init</strong>.py",
          line 197, in memory_efficient_attention<br>    return _memory_efficient_attention(<br>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/<strong>init</strong>.py",
          line 293, in _memory_efficient_attention<br>    return _memory_efficient_attention_forward(<br>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/<strong>init</strong>.py",
          line 309, in _memory_efficient_attention_forward<br>    op = _dispatch_fw(inp)<br>         ^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/dispatch.py",
          line 95, in _dispatch_fw<br>    return _run_priority_list(<br>           ^^^^^^^^^^^^^^^^^^^<br>  File
          "/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/dispatch.py",
          line 70, in _run_priority_list<br>    raise NotImplementedError(msg)<br>NotImplementedError:
          No operator found for <code>memory_efficient_attention_forward</code> with
          inputs:<br>     query       : shape=(6, 1, 32, 64) (torch.float16)<br>     key         :
          shape=(6, 1, 32, 64) (torch.float16)<br>     value       : shape=(6, 1,
          32, 64) (torch.float16)<br>     attn_bias   : &lt;class ''NoneType''&gt;<br>     p           :
          0<br><code>flshattF</code> is not supported because:<br>    xFormers wasn''t
          build with CUDA support<br>    requires a GPU with compute capability &gt;
          7.5<br><code>tritonflashattF</code> is not supported because:<br>    xFormers
          wasn''t build with CUDA support<br>    requires A100 GPU<br><code>cutlassF</code>
          is not supported because:<br>    xFormers wasn''t build with CUDA support<br><code>smallkF</code>
          is not supported because:<br>    xFormers wasn''t build with CUDA support<br>    dtype=torch.float16
          (supported: {torch.float32})<br>    max(query.shape[-1] != value.shape[-1])
          &gt; 32<br>    unsupported embed per head: 64</p>

          '
        raw: "Traceback (most recent call last):\r\n  File \"/home/rexommendation/Programs/musicgen-large/musicgen.py\"\
          , line 10, in <module>\r\n    wav = model.generate(descriptions)  # generates\
          \ 3 samples.\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/musicgen.py\"\
          , line 144, in generate\r\n    return self._generate_tokens(attributes,\
          \ prompt_tokens, progress)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/musicgen.py\"\
          , line 279, in _generate_tokens\r\n    gen_tokens = self.lm.generate(prompt_tokens,\
          \ attributes, callback=callback, **self.generation_params)\r\n         \
          \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/utils/_contextlib.py\"\
          , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n\
          \           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/lm.py\"\
          , line 489, in generate\r\n    next_token = self._sample_next_token(\r\n\
          \                 ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/lm.py\"\
          , line 354, in _sample_next_token\r\n    all_logits = model(\r\n       \
          \          ^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/lm.py\"\
          , line 253, in forward\r\n    out = self.transformer(input_, cross_attention_src=cross_attention_input)\r\
          \n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py\"\
          , line 657, in forward\r\n    x = self._apply_layer(layer, x, *args, **kwargs)\r\
          \n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py\"\
          , line 614, in _apply_layer\r\n    return layer(*args, **kwargs)\r\n   \
          \        ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py\"\
          , line 508, in forward\r\n    self._sa_block(self.norm1(x), src_mask, src_key_padding_mask))\r\
          \n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\
          \  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/transformer.py\"\
          , line 581, in _sa_block\r\n    x = self.self_attn(x, x, x,\r\n        ^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
          , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py\"\
          , line 367, in forward\r\n    x = ops.memory_efficient_attention(q, k, v,\
          \ attn_mask, p=p)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py\"\
          , line 197, in memory_efficient_attention\r\n    return _memory_efficient_attention(\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py\"\
          , line 293, in _memory_efficient_attention\r\n    return _memory_efficient_attention_forward(\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py\"\
          , line 309, in _memory_efficient_attention_forward\r\n    op = _dispatch_fw(inp)\r\
          \n         ^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/dispatch.py\"\
          , line 95, in _dispatch_fw\r\n    return _run_priority_list(\r\n       \
          \    ^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/dispatch.py\"\
          , line 70, in _run_priority_list\r\n    raise NotImplementedError(msg)\r\
          \nNotImplementedError: No operator found for `memory_efficient_attention_forward`\
          \ with inputs:\r\n     query       : shape=(6, 1, 32, 64) (torch.float16)\r\
          \n     key         : shape=(6, 1, 32, 64) (torch.float16)\r\n     value\
          \       : shape=(6, 1, 32, 64) (torch.float16)\r\n     attn_bias   : <class\
          \ 'NoneType'>\r\n     p           : 0\r\n`flshattF` is not supported because:\r\
          \n    xFormers wasn't build with CUDA support\r\n    requires a GPU with\
          \ compute capability > 7.5\r\n`tritonflashattF` is not supported because:\r\
          \n    xFormers wasn't build with CUDA support\r\n    requires A100 GPU\r\
          \n`cutlassF` is not supported because:\r\n    xFormers wasn't build with\
          \ CUDA support\r\n`smallkF` is not supported because:\r\n    xFormers wasn't\
          \ build with CUDA support\r\n    dtype=torch.float16 (supported: {torch.float32})\r\
          \n    max(query.shape[-1] != value.shape[-1]) > 32\r\n    unsupported embed\
          \ per head: 64"
        updatedAt: '2023-06-12T10:12:31.608Z'
      numEdits: 0
      reactions: []
    id: 6486ef8fe2721deca7fa3b11
    type: comment
  author: ReXommendation
  content: "Traceback (most recent call last):\r\n  File \"/home/rexommendation/Programs/musicgen-large/musicgen.py\"\
    , line 10, in <module>\r\n    wav = model.generate(descriptions)  # generates\
    \ 3 samples.\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/musicgen.py\"\
    , line 144, in generate\r\n    return self._generate_tokens(attributes, prompt_tokens,\
    \ progress)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/musicgen.py\"\
    , line 279, in _generate_tokens\r\n    gen_tokens = self.lm.generate(prompt_tokens,\
    \ attributes, callback=callback, **self.generation_params)\r\n               \
    \  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/utils/_contextlib.py\"\
    , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n      \
    \     ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/lm.py\"\
    , line 489, in generate\r\n    next_token = self._sample_next_token(\r\n     \
    \            ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/lm.py\"\
    , line 354, in _sample_next_token\r\n    all_logits = model(\r\n             \
    \    ^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/models/lm.py\"\
    , line 253, in forward\r\n    out = self.transformer(input_, cross_attention_src=cross_attention_input)\r\
    \n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py\"\
    , line 657, in forward\r\n    x = self._apply_layer(layer, x, *args, **kwargs)\r\
    \n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py\"\
    , line 614, in _apply_layer\r\n    return layer(*args, **kwargs)\r\n         \
    \  ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py\"\
    , line 508, in forward\r\n    self._sa_block(self.norm1(x), src_mask, src_key_padding_mask))\r\
    \n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File\
    \ \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/transformer.py\"\
    , line 581, in _sa_block\r\n    x = self.self_attn(x, x, x,\r\n        ^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\"\
    , line 1501, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n   \
    \        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/audiocraft/modules/transformer.py\"\
    , line 367, in forward\r\n    x = ops.memory_efficient_attention(q, k, v, attn_mask,\
    \ p=p)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\
    \  File \"/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py\"\
    , line 197, in memory_efficient_attention\r\n    return _memory_efficient_attention(\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py\"\
    , line 293, in _memory_efficient_attention\r\n    return _memory_efficient_attention_forward(\r\
    \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/__init__.py\"\
    , line 309, in _memory_efficient_attention_forward\r\n    op = _dispatch_fw(inp)\r\
    \n         ^^^^^^^^^^^^^^^^^\r\n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/dispatch.py\"\
    , line 95, in _dispatch_fw\r\n    return _run_priority_list(\r\n           ^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"/home/rexommendation/.local/lib/python3.11/site-packages/xformers/ops/fmha/dispatch.py\"\
    , line 70, in _run_priority_list\r\n    raise NotImplementedError(msg)\r\nNotImplementedError:\
    \ No operator found for `memory_efficient_attention_forward` with inputs:\r\n\
    \     query       : shape=(6, 1, 32, 64) (torch.float16)\r\n     key         :\
    \ shape=(6, 1, 32, 64) (torch.float16)\r\n     value       : shape=(6, 1, 32,\
    \ 64) (torch.float16)\r\n     attn_bias   : <class 'NoneType'>\r\n     p     \
    \      : 0\r\n`flshattF` is not supported because:\r\n    xFormers wasn't build\
    \ with CUDA support\r\n    requires a GPU with compute capability > 7.5\r\n`tritonflashattF`\
    \ is not supported because:\r\n    xFormers wasn't build with CUDA support\r\n\
    \    requires A100 GPU\r\n`cutlassF` is not supported because:\r\n    xFormers\
    \ wasn't build with CUDA support\r\n`smallkF` is not supported because:\r\n  \
    \  xFormers wasn't build with CUDA support\r\n    dtype=torch.float16 (supported:\
    \ {torch.float32})\r\n    max(query.shape[-1] != value.shape[-1]) > 32\r\n   \
    \ unsupported embed per head: 64"
  created_at: 2023-06-12 09:12:31+00:00
  edited: false
  hidden: false
  id: 6486ef8fe2721deca7fa3b11
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: facebook/musicgen-large
repo_type: model
status: open
target_branch: null
title: Error when attempting to run on a P40
