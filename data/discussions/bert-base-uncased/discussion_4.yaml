!!python/object:huggingface_hub.community.DiscussionWithDetails
author: EvokerKing
conflicting_files: null
created_at: 2022-09-04 12:36:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662298377474-noauth.jpeg?w=200&h=200&f=face
      fullname: Hex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: EvokerKing
      type: user
    createdAt: '2022-09-04T13:36:46.000Z'
    data:
      edited: false
      editors:
      - EvokerKing
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662298377474-noauth.jpeg?w=200&h=200&f=face
          fullname: Hex
          isHf: false
          isPro: false
          name: EvokerKing
          type: user
        html: '<p>Code:</p>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForMaskedLM


          tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"bert-base-uncased"</span>)


          model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">"bert-base-uncased"</span>)

          </code></pre>

          <p>Error:<br>Some weights of the model checkpoint at bert-base-uncased were
          not used when initializing BertForMaskedLM: [''cls.seq_relationship.weight'',
          ''cls.seq_relationship.bias'']</p>

          <ul>

          <li>This IS expected if you are initializing BertForMaskedLM from the checkpoint
          of a model trained on another task or with another architecture (e.g. initializing
          a BertForSequenceClassification model from a BertForPreTraining model).</li>

          <li>This IS NOT expected if you are initializing BertForMaskedLM from the
          checkpoint of a model that you expect to be exactly identical (initializing
          a BertForSequenceClassification model from a BertForSequenceClassification
          model).</li>

          </ul>

          '
        raw: "Code:\r\n```python\r\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\r\
          \n\r\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\r\
          \n\r\nmodel = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\"\
          )\r\n```\r\n\r\nError:\r\nSome weights of the model checkpoint at bert-base-uncased\
          \ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight',\
          \ 'cls.seq_relationship.bias']\r\n- This IS expected if you are initializing\
          \ BertForMaskedLM from the checkpoint of a model trained on another task\
          \ or with another architecture (e.g. initializing a BertForSequenceClassification\
          \ model from a BertForPreTraining model).\r\n- This IS NOT expected if you\
          \ are initializing BertForMaskedLM from the checkpoint of a model that you\
          \ expect to be exactly identical (initializing a BertForSequenceClassification\
          \ model from a BertForSequenceClassification model)."
        updatedAt: '2022-09-04T13:36:46.709Z'
      numEdits: 0
      reactions: []
    id: 6314a9eeb031f7b1c7bd1b52
    type: comment
  author: EvokerKing
  content: "Code:\r\n```python\r\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\r\
    \n\r\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\r\n\r\n\
    model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\r\n```\r\n\
    \r\nError:\r\nSome weights of the model checkpoint at bert-base-uncased were not\
    \ used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\r\
    \n- This IS expected if you are initializing BertForMaskedLM from the checkpoint\
    \ of a model trained on another task or with another architecture (e.g. initializing\
    \ a BertForSequenceClassification model from a BertForPreTraining model).\r\n\
    - This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint\
    \ of a model that you expect to be exactly identical (initializing a BertForSequenceClassification\
    \ model from a BertForSequenceClassification model)."
  created_at: 2022-09-04 12:36:46+00:00
  edited: false
  hidden: false
  id: 6314a9eeb031f7b1c7bd1b52
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662298377474-noauth.jpeg?w=200&h=200&f=face
      fullname: Hex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: EvokerKing
      type: user
    createdAt: '2022-09-04T13:36:53.000Z'
    data:
      status: closed
    id: 6314a9f527d020853f634be0
    type: status-change
  author: EvokerKing
  created_at: 2022-09-04 12:36:53+00:00
  id: 6314a9f527d020853f634be0
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662298377474-noauth.jpeg?w=200&h=200&f=face
      fullname: Hex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: EvokerKing
      type: user
    createdAt: '2022-09-04T13:36:54.000Z'
    data:
      status: open
    id: 6314a9f64f283a6af5066b75
    type: status-change
  author: EvokerKing
  created_at: 2022-09-04 12:36:54+00:00
  id: 6314a9f64f283a6af5066b75
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662366999970-noauth.jpeg?w=200&h=200&f=face
      fullname: Canal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Oleguer
      type: user
    createdAt: '2022-09-05T08:37:49.000Z'
    data:
      edited: false
      editors:
      - Oleguer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662366999970-noauth.jpeg?w=200&h=200&f=face
          fullname: Canal
          isHf: false
          isPro: false
          name: Oleguer
          type: user
        html: '<p>Same issue</p>

          '
        raw: Same issue
        updatedAt: '2022-09-05T08:37:49.450Z'
      numEdits: 0
      reactions: []
    id: 6315b55da9456afe2b9b045a
    type: comment
  author: Oleguer
  content: Same issue
  created_at: 2022-09-05 07:37:49+00:00
  edited: false
  hidden: false
  id: 6315b55da9456afe2b9b045a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2022-09-05T10:15:02.000Z'
    data:
      edited: false
      editors:
      - lysandre
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: '<p>Hello! This is a warning, not an error. It tells you that by loading
          the <code>bert-base-uncased</code> checkpoint in the <code>BertForMaskedLM</code>
          architecture, you''re dropping two weights: <code>[''cls.seq_relationship.weight'',
          ''cls.seq_relationship.bias'']</code>. </p>

          <p>These are the weights used for next-sentence prediction, which aren''t
          necessary for Masked Language Modeling.<br>If you''re only interested in
          doing masked language modeling, then you can safely disregard this warning.</p>

          '
        raw: "Hello! This is a warning, not an error. It tells you that by loading\
          \ the `bert-base-uncased` checkpoint in the `BertForMaskedLM` architecture,\
          \ you're dropping two weights: `['cls.seq_relationship.weight', 'cls.seq_relationship.bias']`.\
          \ \n\nThese are the weights used for next-sentence prediction, which aren't\
          \ necessary for Masked Language Modeling.\nIf you're only interested in\
          \ doing masked language modeling, then you can safely disregard this warning."
        updatedAt: '2022-09-05T10:15:02.037Z'
      numEdits: 0
      reactions:
      - count: 8
        reaction: "\U0001F44D"
        users:
        - Oleguer
        - EvokerKing
        - llxnb
        - danielrsantana-humaitrix
        - Shaier
        - nicholasneo78
        - caplike
        - EliasKD
    id: 6315cc26a9456afe2b9bbec9
    type: comment
  author: lysandre
  content: "Hello! This is a warning, not an error. It tells you that by loading the\
    \ `bert-base-uncased` checkpoint in the `BertForMaskedLM` architecture, you're\
    \ dropping two weights: `['cls.seq_relationship.weight', 'cls.seq_relationship.bias']`.\
    \ \n\nThese are the weights used for next-sentence prediction, which aren't necessary\
    \ for Masked Language Modeling.\nIf you're only interested in doing masked language\
    \ modeling, then you can safely disregard this warning."
  created_at: 2022-09-05 09:15:02+00:00
  edited: false
  hidden: false
  id: 6315cc26a9456afe2b9bbec9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: bert-base-uncased
repo_type: model
status: open
target_branch: null
title: 'Error: "Some weights of the model checkpoint were not used"'
