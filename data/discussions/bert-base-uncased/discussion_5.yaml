!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rikka
conflicting_files: null
created_at: 2022-09-05 07:28:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fca2536d01c5240d7ecc037872c281fd.svg
      fullname: ztr
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rikka
      type: user
    createdAt: '2022-09-05T08:28:02.000Z'
    data:
      edited: false
      editors:
      - rikka
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fca2536d01c5240d7ecc037872c281fd.svg
          fullname: ztr
          isHf: false
          isPro: false
          name: rikka
          type: user
        html: "<p>hello there, I was building an app using </p>\n<pre><code>OWL_MODEL\
          \ = f\"google/owlvit-base-patch32\"\n</code></pre>\n<p>and while running\
          \ the codes below</p>\n<pre><code>device = \"cuda\"\ninputs = owl_processor(text=texts,\
          \ images=image, return_tensors=\"pt\").to(device)\nowl_model.to(device)\n\
          with torch.no_grad():\n    outputs = owl_model(**inputs)\n</code></pre>\n\
          <p>I found this ERROR</p>\n<pre><code>---------------------------------------------------------------------------\n\
          RuntimeError                              Traceback (most recent call last)\n\
          Input In [38], in &lt;cell line: 4&gt;()\n      3 owl_model.to(device)\n\
          \      4 with torch.no_grad():\n----&gt; 5     outputs = owl_model(**inputs)\n\
          \nFile ~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,\
          \ in Module._call_impl(self, *input, **kwargs)\n   1126 # If we don't have\
          \ any hooks, we want to skip the rest of the logic in\n   1127 # this function,\
          \ and just call forward.\n   1128 if not (self._backward_hooks or self._forward_hooks\
          \ or self._forward_pre_hooks or _global_backward_hooks\n   1129        \
          \ or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1130  \
          \   return forward_call(*input, **kwargs)\n   1131 # Do not call functions\
          \ when jit is used\n   1132 full_backward_hooks, non_full_backward_hooks\
          \ = [], []\n\nFile ~/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/owlvit/modeling_owlvit.py:1373,\
          \ in OwlViTForObjectDetection.forward(self, pixel_values, input_ids, attention_mask,\
          \ output_attentions, output_hidden_states, return_dict)\n   1370 (pred_logits,\
          \ class_embeds) = self.class_predictor(image_feats, query_embeds, query_mask)\n\
          \   1372 # Predict object boxes\n-&gt; 1373 pred_boxes = self.box_predictor(image_feats,\
          \ feature_map)\n   1375 if not return_dict:\n   1376     return (\n   1377\
          \         pred_logits,\n   1378         pred_boxes,\n   (...)\n   1383 \
          \        vision_model_last_hidden_states,\n   1384     )\n\nFile ~/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/owlvit/modeling_owlvit.py:1223,\
          \ in OwlViTForObjectDetection.box_predictor(self, image_feats, feature_map)\n\
          \   1220 pred_boxes = self.box_head(image_feats)\n   1222 # Compute the\
          \ location of each token on the grid and use it to compute a bias for the\
          \ bbox prediction\n-&gt; 1223 pred_boxes += self.compute_box_bias(feature_map)\n\
          \   1224 pred_boxes = self.sigmoid(pred_boxes)\n   1225 return pred_boxes\n\
          \nRuntimeError: Expected all tensors to be on the same device, but found\
          \ at least two devices, cuda:0 and cpu!\n</code></pre>\n<p><em><strong>when\
          \ I change the device from \"cuda\" to \"cpu\", it worked jsut fine</strong></em></p>\n\
          <p>any ideas how to solve this?</p>\n<p>envs:<br>python 3.8.13<br>transformers\
          \ '4.21.1'</p>\n"
        raw: "hello there, I was building an app using \r\n```\r\nOWL_MODEL = f\"\
          google/owlvit-base-patch32\"\r\n```\r\nand while running the codes below\r\
          \n```\r\ndevice = \"cuda\"\r\ninputs = owl_processor(text=texts, images=image,\
          \ return_tensors=\"pt\").to(device)\r\nowl_model.to(device)\r\nwith torch.no_grad():\r\
          \n    outputs = owl_model(**inputs)\r\n```\r\nI found this ERROR\r\n```\r\
          \n---------------------------------------------------------------------------\r\
          \nRuntimeError                              Traceback (most recent call\
          \ last)\r\nInput In [38], in <cell line: 4>()\r\n      3 owl_model.to(device)\r\
          \n      4 with torch.no_grad():\r\n----> 5     outputs = owl_model(**inputs)\r\
          \n\r\nFile ~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,\
          \ in Module._call_impl(self, *input, **kwargs)\r\n   1126 # If we don't\
          \ have any hooks, we want to skip the rest of the logic in\r\n   1127 #\
          \ this function, and just call forward.\r\n   1128 if not (self._backward_hooks\
          \ or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\
          \n   1129         or _global_forward_hooks or _global_forward_pre_hooks):\r\
          \n-> 1130     return forward_call(*input, **kwargs)\r\n   1131 # Do not\
          \ call functions when jit is used\r\n   1132 full_backward_hooks, non_full_backward_hooks\
          \ = [], []\r\n\r\nFile ~/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/owlvit/modeling_owlvit.py:1373,\
          \ in OwlViTForObjectDetection.forward(self, pixel_values, input_ids, attention_mask,\
          \ output_attentions, output_hidden_states, return_dict)\r\n   1370 (pred_logits,\
          \ class_embeds) = self.class_predictor(image_feats, query_embeds, query_mask)\r\
          \n   1372 # Predict object boxes\r\n-> 1373 pred_boxes = self.box_predictor(image_feats,\
          \ feature_map)\r\n   1375 if not return_dict:\r\n   1376     return (\r\n\
          \   1377         pred_logits,\r\n   1378         pred_boxes,\r\n   (...)\r\
          \n   1383         vision_model_last_hidden_states,\r\n   1384     )\r\n\r\
          \nFile ~/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/owlvit/modeling_owlvit.py:1223,\
          \ in OwlViTForObjectDetection.box_predictor(self, image_feats, feature_map)\r\
          \n   1220 pred_boxes = self.box_head(image_feats)\r\n   1222 # Compute the\
          \ location of each token on the grid and use it to compute a bias for the\
          \ bbox prediction\r\n-> 1223 pred_boxes += self.compute_box_bias(feature_map)\r\
          \n   1224 pred_boxes = self.sigmoid(pred_boxes)\r\n   1225 return pred_boxes\r\
          \n\r\nRuntimeError: Expected all tensors to be on the same device, but found\
          \ at least two devices, cuda:0 and cpu!\r\n```\r\n\r\n***when I change the\
          \ device from \"cuda\" to \"cpu\", it worked jsut fine***\r\n\r\nany ideas\
          \ how to solve this?\r\n\r\nenvs:\r\npython 3.8.13\r\ntransformers '4.21.1'"
        updatedAt: '2022-09-05T08:28:02.356Z'
      numEdits: 0
      reactions: []
    id: 6315b312a9456afe2b9af13e
    type: comment
  author: rikka
  content: "hello there, I was building an app using \r\n```\r\nOWL_MODEL = f\"google/owlvit-base-patch32\"\
    \r\n```\r\nand while running the codes below\r\n```\r\ndevice = \"cuda\"\r\ninputs\
    \ = owl_processor(text=texts, images=image, return_tensors=\"pt\").to(device)\r\
    \nowl_model.to(device)\r\nwith torch.no_grad():\r\n    outputs = owl_model(**inputs)\r\
    \n```\r\nI found this ERROR\r\n```\r\n---------------------------------------------------------------------------\r\
    \nRuntimeError                              Traceback (most recent call last)\r\
    \nInput In [38], in <cell line: 4>()\r\n      3 owl_model.to(device)\r\n     \
    \ 4 with torch.no_grad():\r\n----> 5     outputs = owl_model(**inputs)\r\n\r\n\
    File ~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,\
    \ in Module._call_impl(self, *input, **kwargs)\r\n   1126 # If we don't have any\
    \ hooks, we want to skip the rest of the logic in\r\n   1127 # this function,\
    \ and just call forward.\r\n   1128 if not (self._backward_hooks or self._forward_hooks\
    \ or self._forward_pre_hooks or _global_backward_hooks\r\n   1129         or _global_forward_hooks\
    \ or _global_forward_pre_hooks):\r\n-> 1130     return forward_call(*input, **kwargs)\r\
    \n   1131 # Do not call functions when jit is used\r\n   1132 full_backward_hooks,\
    \ non_full_backward_hooks = [], []\r\n\r\nFile ~/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/owlvit/modeling_owlvit.py:1373,\
    \ in OwlViTForObjectDetection.forward(self, pixel_values, input_ids, attention_mask,\
    \ output_attentions, output_hidden_states, return_dict)\r\n   1370 (pred_logits,\
    \ class_embeds) = self.class_predictor(image_feats, query_embeds, query_mask)\r\
    \n   1372 # Predict object boxes\r\n-> 1373 pred_boxes = self.box_predictor(image_feats,\
    \ feature_map)\r\n   1375 if not return_dict:\r\n   1376     return (\r\n   1377\
    \         pred_logits,\r\n   1378         pred_boxes,\r\n   (...)\r\n   1383 \
    \        vision_model_last_hidden_states,\r\n   1384     )\r\n\r\nFile ~/anaconda3/envs/py38/lib/python3.8/site-packages/transformers/models/owlvit/modeling_owlvit.py:1223,\
    \ in OwlViTForObjectDetection.box_predictor(self, image_feats, feature_map)\r\n\
    \   1220 pred_boxes = self.box_head(image_feats)\r\n   1222 # Compute the location\
    \ of each token on the grid and use it to compute a bias for the bbox prediction\r\
    \n-> 1223 pred_boxes += self.compute_box_bias(feature_map)\r\n   1224 pred_boxes\
    \ = self.sigmoid(pred_boxes)\r\n   1225 return pred_boxes\r\n\r\nRuntimeError:\
    \ Expected all tensors to be on the same device, but found at least two devices,\
    \ cuda:0 and cpu!\r\n```\r\n\r\n***when I change the device from \"cuda\" to \"\
    cpu\", it worked jsut fine***\r\n\r\nany ideas how to solve this?\r\n\r\nenvs:\r\
    \npython 3.8.13\r\ntransformers '4.21.1'"
  created_at: 2022-09-05 07:28:02+00:00
  edited: false
  hidden: false
  id: 6315b312a9456afe2b9af13e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: bert-base-uncased
repo_type: model
status: open
target_branch: null
title: ERROR when inference on gpu
