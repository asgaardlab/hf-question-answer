!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Sio91
conflicting_files: null
created_at: 2022-10-03 13:40:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/941848671cd5e620dba48619ae9cbfcf.svg
      fullname: Sioooo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sio91
      type: user
    createdAt: '2022-10-03T14:40:57.000Z'
    data:
      edited: false
      editors:
      - Sio91
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/941848671cd5e620dba48619ae9cbfcf.svg
          fullname: Sioooo
          isHf: false
          isPro: false
          name: Sio91
          type: user
        html: '<p>Could you please tell me which one should be downloaded?</p>

          '
        raw: Could you please tell me which one should be downloaded?
        updatedAt: '2022-10-03T14:40:57.428Z'
      numEdits: 0
      reactions: []
    id: 633af4797af633cbcd00dc67
    type: comment
  author: Sio91
  content: Could you please tell me which one should be downloaded?
  created_at: 2022-10-03 13:40:57+00:00
  edited: false
  hidden: false
  id: 633af4797af633cbcd00dc67
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
      fullname: Erik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: digitous
      type: user
    createdAt: '2022-10-03T17:32:36.000Z'
    data:
      edited: false
      editors:
      - digitous
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
          fullname: Erik
          isHf: false
          isPro: false
          name: digitous
          type: user
        html: '<p>Functionally they''re all the same. Nearly no one will use the full.
          You could have the same seed, same prompt, same everything and likely have
          near exact same results with each; the difference is extra data not relevant
          to image generation is pruned from the full, and we''re left with F16 or
          F32. 32 is full precision, 16 is half.</p>

          <p>If you have 24gb VRAM 32bit precision is easy, if you have less you may
          still use it depending on your SD build and how it optimizes memory use.
          Best to stick with 16 is you''re not sure. Difference in quality is virtually
          imperceptible.</p>

          '
        raw: 'Functionally they''re all the same. Nearly no one will use the full.
          You could have the same seed, same prompt, same everything and likely have
          near exact same results with each; the difference is extra data not relevant
          to image generation is pruned from the full, and we''re left with F16 or
          F32. 32 is full precision, 16 is half.


          If you have 24gb VRAM 32bit precision is easy, if you have less you may
          still use it depending on your SD build and how it optimizes memory use.
          Best to stick with 16 is you''re not sure. Difference in quality is virtually
          imperceptible.'
        updatedAt: '2022-10-03T17:32:36.797Z'
      numEdits: 0
      reactions: []
    id: 633b1cb41fd49ee0b64d1185
    type: comment
  author: digitous
  content: 'Functionally they''re all the same. Nearly no one will use the full. You
    could have the same seed, same prompt, same everything and likely have near exact
    same results with each; the difference is extra data not relevant to image generation
    is pruned from the full, and we''re left with F16 or F32. 32 is full precision,
    16 is half.


    If you have 24gb VRAM 32bit precision is easy, if you have less you may still
    use it depending on your SD build and how it optimizes memory use. Best to stick
    with 16 is you''re not sure. Difference in quality is virtually imperceptible.'
  created_at: 2022-10-03 16:32:36+00:00
  edited: false
  hidden: false
  id: 633b1cb41fd49ee0b64d1185
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1645138575893-606918bb3959960e820cb47d.jpeg?w=200&h=200&f=face
      fullname: Reimu Hakurei
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: hakurei
      type: user
    createdAt: '2022-10-05T02:38:32.000Z'
    data:
      edited: false
      editors:
      - hakurei
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1645138575893-606918bb3959960e820cb47d.jpeg?w=200&h=200&f=face
          fullname: Reimu Hakurei
          isHf: false
          isPro: false
          name: hakurei
          type: user
        html: '<p>I''ve left the full epochs in the repo since there are slight differences
          between full, float32, and float16. Plus, you can also finetune with the
          full weights lol</p>

          '
        raw: I've left the full epochs in the repo since there are slight differences
          between full, float32, and float16. Plus, you can also finetune with the
          full weights lol
        updatedAt: '2022-10-05T02:38:32.869Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - GripenANM
        - neilb
        - Novaborn
        - w-a-cat
        - everyusernameistaken
        - digitous
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Sio91
    id: 633cee28c0fb6fd232f9248a
    type: comment
  author: hakurei
  content: I've left the full epochs in the repo since there are slight differences
    between full, float32, and float16. Plus, you can also finetune with the full
    weights lol
  created_at: 2022-10-05 01:38:32+00:00
  edited: false
  hidden: false
  id: 633cee28c0fb6fd232f9248a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/941848671cd5e620dba48619ae9cbfcf.svg
      fullname: Sioooo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sio91
      type: user
    createdAt: '2022-10-19T11:10:45.000Z'
    data:
      edited: false
      editors:
      - Sio91
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/941848671cd5e620dba48619ae9cbfcf.svg
          fullname: Sioooo
          isHf: false
          isPro: false
          name: Sio91
          type: user
        html: '<p>thank you</p>

          '
        raw: thank you
        updatedAt: '2022-10-19T11:10:45.943Z'
      numEdits: 0
      reactions: []
    id: 634fdb3514fb199c7655c4f6
    type: comment
  author: Sio91
  content: thank you
  created_at: 2022-10-19 10:10:45+00:00
  edited: false
  hidden: false
  id: 634fdb3514fb199c7655c4f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666145940405-noauth.png?w=200&h=200&f=face
      fullname: Jonathan Navarro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JonnyNava367
      type: user
    createdAt: '2022-11-12T03:23:48.000Z'
    data:
      edited: false
      editors:
      - JonnyNava367
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666145940405-noauth.png?w=200&h=200&f=face
          fullname: Jonathan Navarro
          isHf: false
          isPro: false
          name: JonnyNava367
          type: user
        html: '<blockquote>

          <p>I''ve left the full epochs in the repo since there are slight differences
          between full, float32, and float16. Plus, you can also finetune with the
          full weights lol</p>

          </blockquote>

          <p>Is fine-tuning when training or getting more precise results when prompting?</p>

          '
        raw: '> I''ve left the full epochs in the repo since there are slight differences
          between full, float32, and float16. Plus, you can also finetune with the
          full weights lol


          Is fine-tuning when training or getting more precise results when prompting?'
        updatedAt: '2022-11-12T03:23:48.478Z'
      numEdits: 0
      reactions: []
    id: 636f11c48ba65db4a09d938c
    type: comment
  author: JonnyNava367
  content: '> I''ve left the full epochs in the repo since there are slight differences
    between full, float32, and float16. Plus, you can also finetune with the full
    weights lol


    Is fine-tuning when training or getting more precise results when prompting?'
  created_at: 2022-11-12 03:23:48+00:00
  edited: false
  hidden: false
  id: 636f11c48ba65db4a09d938c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
      fullname: Erik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: digitous
      type: user
    createdAt: '2023-02-18T03:41:36.000Z'
    data:
      edited: false
      editors:
      - digitous
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
          fullname: Erik
          isHf: false
          isPro: false
          name: digitous
          type: user
        html: '<p>Fine-tuning is when a model is trained on a dataset; WD would make
          a great base for many art/anime models. If someone wanted a bias to more
          80''s style anime or a particular look, the full would provide the possibility
          to train WD in that direction.</p>

          '
        raw: Fine-tuning is when a model is trained on a dataset; WD would make a
          great base for many art/anime models. If someone wanted a bias to more 80's
          style anime or a particular look, the full would provide the possibility
          to train WD in that direction.
        updatedAt: '2023-02-18T03:41:36.139Z'
      numEdits: 0
      reactions: []
    id: 63f048f002ab9938d783df29
    type: comment
  author: digitous
  content: Fine-tuning is when a model is trained on a dataset; WD would make a great
    base for many art/anime models. If someone wanted a bias to more 80's style anime
    or a particular look, the full would provide the possibility to train WD in that
    direction.
  created_at: 2023-02-18 03:41:36+00:00
  edited: false
  hidden: false
  id: 63f048f002ab9938d783df29
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: hakurei/waifu-diffusion-v1-3
repo_type: model
status: open
target_branch: null
title: what is the difference between 16 32 and full? I don't know anything about
  this topic :/
