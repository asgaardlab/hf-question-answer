!!python/object:huggingface_hub.community.DiscussionWithDetails
author: carmona
conflicting_files: null
created_at: 2023-05-19 07:44:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/74331e14364b58245f4d9fabe5e61f1e.svg
      fullname: Juan Carlos Armenteros Carmona
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: carmona
      type: user
    createdAt: '2023-05-19T08:44:26.000Z'
    data:
      edited: false
      editors:
      - carmona
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/74331e14364b58245f4d9fabe5e61f1e.svg
          fullname: Juan Carlos Armenteros Carmona
          isHf: false
          isPro: false
          name: carmona
          type: user
        html: '<p>Hello,</p>

          <p>I am trying to apply the final step from the instructions provided on
          the "<a href="https://huggingface.co/OpenAssistant/oasst-rlhf-2-llama-30b-7k-steps-xor&quot;">https://huggingface.co/OpenAssistant/oasst-rlhf-2-llama-30b-7k-steps-xor"</a>
          page. Specifically, I am having issues while running the "xor_codec.py"
          script. The MD5 hashes of the output model files do not match the ones posted
          in the instructions (all previous steps are ok). Instead, these are the
          hashes I get:</p>

          <pre><code>20788f92b8e441ac1f4fc6f7f9ddd4af  ./pytorch_model-00005-of-00007.bin

          ff416d3a305b4d74c0cad3323a7fa6eb  ./pytorch_model-00002-of-00007.bin

          eeec4125e9c7560836b4873b6f8e3025  ./tokenizer.model

          ed59bfee4e87b9193fea5897d610ab24  ./tokenizer_config.json

          7e91abda6782ecbb58202e40cd618002  ./pytorch_model-00007-of-00007.bin

          704373f0c0d62be75e5f7d41d39a7e57  ./special_tokens_map.json

          9a4d2468ecf85bf07420b200faefb4af  ./config.json

          148bfd184af630a7633b4de2f41bfc49  ./generation_config.json

          f60488bcbf2cc29d591d442c7ff30af3  ./pytorch_model-00004-of-00007.bin

          0c86e7d88aac7583d88953957dc543a6  ./pytorch_model-00003-of-00007.bin

          492c80909300e3cb2e9dcd88f1cf15e3  ./pytorch_model-00006-of-00007.bin

          deb33dd4ffc3d2baddcce275a00b7c1b  ./tokenizer.json

          27b0dc092f99aa2efaf467b2d8026c3f  ./added_tokens.json

          9723be7088896c9211b76be7aa88aafc  ./pytorch_model.bin.index.json

          ec27a39bafd24e94c5a37b887d115561  ./pytorch_model-00001-of-00007.bin

          </code></pre>

          <p>I am completely puzzled and surprised that I can''t get the correct hashes.
          I have exhausted all the troubleshooting options I could think of, and I
          would deeply appreciate any assistance or insights you might be able to
          provide.</p>

          <p>Best regards,</p>

          <p>Carmona</p>

          '
        raw: "Hello,\r\n\r\nI am trying to apply the final step from the instructions\
          \ provided on the \"https://huggingface.co/OpenAssistant/oasst-rlhf-2-llama-30b-7k-steps-xor\"\
          \ page. Specifically, I am having issues while running the \"xor_codec.py\"\
          \ script. The MD5 hashes of the output model files do not match the ones\
          \ posted in the instructions (all previous steps are ok). Instead, these\
          \ are the hashes I get:\r\n\r\n```\r\n20788f92b8e441ac1f4fc6f7f9ddd4af \
          \ ./pytorch_model-00005-of-00007.bin\r\nff416d3a305b4d74c0cad3323a7fa6eb\
          \  ./pytorch_model-00002-of-00007.bin\r\neeec4125e9c7560836b4873b6f8e3025\
          \  ./tokenizer.model\r\ned59bfee4e87b9193fea5897d610ab24  ./tokenizer_config.json\r\
          \n7e91abda6782ecbb58202e40cd618002  ./pytorch_model-00007-of-00007.bin\r\
          \n704373f0c0d62be75e5f7d41d39a7e57  ./special_tokens_map.json\r\n9a4d2468ecf85bf07420b200faefb4af\
          \  ./config.json\r\n148bfd184af630a7633b4de2f41bfc49  ./generation_config.json\r\
          \nf60488bcbf2cc29d591d442c7ff30af3  ./pytorch_model-00004-of-00007.bin\r\
          \n0c86e7d88aac7583d88953957dc543a6  ./pytorch_model-00003-of-00007.bin\r\
          \n492c80909300e3cb2e9dcd88f1cf15e3  ./pytorch_model-00006-of-00007.bin\r\
          \ndeb33dd4ffc3d2baddcce275a00b7c1b  ./tokenizer.json\r\n27b0dc092f99aa2efaf467b2d8026c3f\
          \  ./added_tokens.json\r\n9723be7088896c9211b76be7aa88aafc  ./pytorch_model.bin.index.json\r\
          \nec27a39bafd24e94c5a37b887d115561  ./pytorch_model-00001-of-00007.bin\r\
          \n```\r\n\r\nI am completely puzzled and surprised that I can't get the\
          \ correct hashes. I have exhausted all the troubleshooting options I could\
          \ think of, and I would deeply appreciate any assistance or insights you\
          \ might be able to provide.\r\n\r\nBest regards,\r\n\r\nCarmona"
        updatedAt: '2023-05-19T08:44:26.753Z'
      numEdits: 0
      reactions: []
    id: 646736ea696e7355f5d32c38
    type: comment
  author: carmona
  content: "Hello,\r\n\r\nI am trying to apply the final step from the instructions\
    \ provided on the \"https://huggingface.co/OpenAssistant/oasst-rlhf-2-llama-30b-7k-steps-xor\"\
    \ page. Specifically, I am having issues while running the \"xor_codec.py\" script.\
    \ The MD5 hashes of the output model files do not match the ones posted in the\
    \ instructions (all previous steps are ok). Instead, these are the hashes I get:\r\
    \n\r\n```\r\n20788f92b8e441ac1f4fc6f7f9ddd4af  ./pytorch_model-00005-of-00007.bin\r\
    \nff416d3a305b4d74c0cad3323a7fa6eb  ./pytorch_model-00002-of-00007.bin\r\neeec4125e9c7560836b4873b6f8e3025\
    \  ./tokenizer.model\r\ned59bfee4e87b9193fea5897d610ab24  ./tokenizer_config.json\r\
    \n7e91abda6782ecbb58202e40cd618002  ./pytorch_model-00007-of-00007.bin\r\n704373f0c0d62be75e5f7d41d39a7e57\
    \  ./special_tokens_map.json\r\n9a4d2468ecf85bf07420b200faefb4af  ./config.json\r\
    \n148bfd184af630a7633b4de2f41bfc49  ./generation_config.json\r\nf60488bcbf2cc29d591d442c7ff30af3\
    \  ./pytorch_model-00004-of-00007.bin\r\n0c86e7d88aac7583d88953957dc543a6  ./pytorch_model-00003-of-00007.bin\r\
    \n492c80909300e3cb2e9dcd88f1cf15e3  ./pytorch_model-00006-of-00007.bin\r\ndeb33dd4ffc3d2baddcce275a00b7c1b\
    \  ./tokenizer.json\r\n27b0dc092f99aa2efaf467b2d8026c3f  ./added_tokens.json\r\
    \n9723be7088896c9211b76be7aa88aafc  ./pytorch_model.bin.index.json\r\nec27a39bafd24e94c5a37b887d115561\
    \  ./pytorch_model-00001-of-00007.bin\r\n```\r\n\r\nI am completely puzzled and\
    \ surprised that I can't get the correct hashes. I have exhausted all the troubleshooting\
    \ options I could think of, and I would deeply appreciate any assistance or insights\
    \ you might be able to provide.\r\n\r\nBest regards,\r\n\r\nCarmona"
  created_at: 2023-05-19 07:44:26+00:00
  edited: false
  hidden: false
  id: 646736ea696e7355f5d32c38
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678892702901-6303f5f37b50dd9d0a371b28.jpeg?w=200&h=200&f=face
      fullname: Oliver Stanley
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: OllieStanley
      type: user
    createdAt: '2023-05-22T21:45:28.000Z'
    data:
      edited: false
      editors:
      - OllieStanley
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678892702901-6303f5f37b50dd9d0a371b28.jpeg?w=200&h=200&f=face
          fullname: Oliver Stanley
          isHf: false
          isPro: false
          name: OllieStanley
          type: user
        html: '<p>I have updated the readme with some new information, please let
          me know if you are able to solve this issue with the updated steps</p>

          '
        raw: I have updated the readme with some new information, please let me know
          if you are able to solve this issue with the updated steps
        updatedAt: '2023-05-22T21:45:28.957Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - Yhyu13
        - carmona
    id: 646be278f85ebf65c53f6d3b
    type: comment
  author: OllieStanley
  content: I have updated the readme with some new information, please let me know
    if you are able to solve this issue with the updated steps
  created_at: 2023-05-22 20:45:28+00:00
  edited: false
  hidden: false
  id: 646be278f85ebf65c53f6d3b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-05-23T12:07:05.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<blockquote>

          <p>I have updated the readme with some new information, please let me know
          if you are able to solve this issue with the updated steps</p>

          </blockquote>

          <p>Thanks, using the exact setup works! Here is my results : <a href="https://huggingface.co/OpenAssistant/oasst-rlhf-2-llama-30b-7k-steps-xor/discussions/7">https://huggingface.co/OpenAssistant/oasst-rlhf-2-llama-30b-7k-steps-xor/discussions/7</a></p>

          '
        raw: '> I have updated the readme with some new information, please let me
          know if you are able to solve this issue with the updated steps


          Thanks, using the exact setup works! Here is my results : https://huggingface.co/OpenAssistant/oasst-rlhf-2-llama-30b-7k-steps-xor/discussions/7'
        updatedAt: '2023-05-23T12:07:05.995Z'
      numEdits: 0
      reactions: []
    id: 646cac69393c77ea4b89091a
    type: comment
  author: Yhyu13
  content: '> I have updated the readme with some new information, please let me know
    if you are able to solve this issue with the updated steps


    Thanks, using the exact setup works! Here is my results : https://huggingface.co/OpenAssistant/oasst-rlhf-2-llama-30b-7k-steps-xor/discussions/7'
  created_at: 2023-05-23 11:07:05+00:00
  edited: false
  hidden: false
  id: 646cac69393c77ea4b89091a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678892702901-6303f5f37b50dd9d0a371b28.jpeg?w=200&h=200&f=face
      fullname: Oliver Stanley
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: OllieStanley
      type: user
    createdAt: '2023-05-23T16:59:47.000Z'
    data:
      status: closed
    id: 646cf1032abe5323fe12d913
    type: status-change
  author: OllieStanley
  created_at: 2023-05-23 15:59:47+00:00
  id: 646cf1032abe5323fe12d913
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: OpenAssistant/oasst-rlhf-2-llama-30b-7k-steps-xor
repo_type: model
status: closed
target_branch: null
title: Trouble Applying XOR Decoding to LLaMa-Based Model Weights
