!!python/object:huggingface_hub.community.DiscussionWithDetails
author: grg
conflicting_files: null
created_at: 2023-05-12 13:15:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663681720771-noauth.jpeg?w=200&h=200&f=face
      fullname: Grgur Kovac
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: grg
      type: user
    createdAt: '2023-05-12T14:15:31.000Z'
    data:
      edited: false
      editors:
      - grg
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663681720771-noauth.jpeg?w=200&h=200&f=face
          fullname: Grgur Kovac
          isHf: false
          isPro: false
          name: grg
          type: user
        html: '<p>Hello,<br>I believe that you have an error in the config.json files,
          as they cannot be parsed on my side (also, after xoring i don''t get the
          correct hash).</p>

          <p>Here is the output of cat config.json.<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6329c4decf7d40df9b3a2180/FjerNn9aUpv4xJws7Srus.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6329c4decf7d40df9b3a2180/FjerNn9aUpv4xJws7Srus.png"></a></p>

          <p>I believe you have the same error in other llama based models. </p>

          '
        raw: "Hello,\r\nI believe that you have an error in the config.json files,\
          \ as they cannot be parsed on my side (also, after xoring i don't get the\
          \ correct hash).\r\n\r\nHere is the output of cat config.json. \r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6329c4decf7d40df9b3a2180/FjerNn9aUpv4xJws7Srus.png)\r\
          \n\r\nI believe you have the same error in other llama based models. \r\n"
        updatedAt: '2023-05-12T14:15:31.719Z'
      numEdits: 0
      reactions: []
    id: 645e4a030c5080bd7751582a
    type: comment
  author: grg
  content: "Hello,\r\nI believe that you have an error in the config.json files, as\
    \ they cannot be parsed on my side (also, after xoring i don't get the correct\
    \ hash).\r\n\r\nHere is the output of cat config.json. \r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6329c4decf7d40df9b3a2180/FjerNn9aUpv4xJws7Srus.png)\r\
    \n\r\nI believe you have the same error in other llama based models. \r\n"
  created_at: 2023-05-12 13:15:31+00:00
  edited: false
  hidden: false
  id: 645e4a030c5080bd7751582a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678892702901-6303f5f37b50dd9d0a371b28.jpeg?w=200&h=200&f=face
      fullname: Oliver Stanley
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: OllieStanley
      type: user
    createdAt: '2023-05-22T21:46:07.000Z'
    data:
      edited: false
      editors:
      - OllieStanley
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678892702901-6303f5f37b50dd9d0a371b28.jpeg?w=200&h=200&f=face
          fullname: Oliver Stanley
          isHf: false
          isPro: false
          name: OllieStanley
          type: user
        html: '<p>They are XORs from other JSON files, so are not meant to work as
          standalone JSONs. Some users (especially, but not exclusively, on Windows)
          have had issues with the JSONs due to line endings being messed up - could
          this be your problem? I have added more information to the readme, let me
          know if it helps</p>

          '
        raw: They are XORs from other JSON files, so are not meant to work as standalone
          JSONs. Some users (especially, but not exclusively, on Windows) have had
          issues with the JSONs due to line endings being messed up - could this be
          your problem? I have added more information to the readme, let me know if
          it helps
        updatedAt: '2023-05-22T21:46:07.449Z'
      numEdits: 0
      reactions: []
    id: 646be29fdb697c798a4d28fb
    type: comment
  author: OllieStanley
  content: They are XORs from other JSON files, so are not meant to work as standalone
    JSONs. Some users (especially, but not exclusively, on Windows) have had issues
    with the JSONs due to line endings being messed up - could this be your problem?
    I have added more information to the readme, let me know if it helps
  created_at: 2023-05-22 20:46:07+00:00
  edited: false
  hidden: false
  id: 646be29fdb697c798a4d28fb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1678892702901-6303f5f37b50dd9d0a371b28.jpeg?w=200&h=200&f=face
      fullname: Oliver Stanley
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: OllieStanley
      type: user
    createdAt: '2023-05-23T17:00:02.000Z'
    data:
      status: closed
    id: 646cf112e0c5e395734d9c6d
    type: status-change
  author: OllieStanley
  created_at: 2023-05-23 16:00:02+00:00
  id: 646cf112e0c5e395734d9c6d
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663681720771-noauth.jpeg?w=200&h=200&f=face
      fullname: Grgur Kovac
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: grg
      type: user
    createdAt: '2023-06-19T17:51:58.000Z'
    data:
      edited: false
      editors:
      - grg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7079592943191528
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663681720771-noauth.jpeg?w=200&h=200&f=face
          fullname: Grgur Kovac
          isHf: false
          isPro: false
          name: grg
          type: user
        html: '<p>Hello, thanks for your reply. I do not think that is related to
          my issue, as I am using Linux. Also, the hash is not the same, so it is
          possible that there is some issue with the file you have on git lfs. </p>

          <p>I fixed this issue by manually editing the conf file to be as follows:<br>"""<br>{<br>  "_name_or_path":
          "OpenAssistant/oasst-sft-7e2-llama-30b",<br>  "architectures": [<br>    "LlamaForCausalLM"<br>  ],<br>  "bos_token_id":
          1,<br>  "eos_token_id": 2,<br>  "hidden_act": "silu",<br>  "hidden_size":
          6656,<br>  "initializer_range": 0.02,<br>  "intermediate_size": 17920,<br>  "max_position_embeddings":
          2048,<br>  "model_type": "llama",<br>  "num_attention_heads": 52,<br>  "num_hidden_layers":
          60,<br>  "pad_token_id": 0,<br>  "rms_norm_eps": 1e-06,<br>  "tie_word_embeddings":
          false,<br>  "torch_dtype": "float16",<br>  "transformers_version": "4.28.1",<br>  "use_cache":
          true,<br>  "vocab_size": 32006<br>}<br>"""</p>

          <p>Now the hash checks out - 9a4d2468ecf85bf07420b200faefb4af</p>

          '
        raw: "Hello, thanks for your reply. I do not think that is related to my issue,\
          \ as I am using Linux. Also, the hash is not the same, so it is possible\
          \ that there is some issue with the file you have on git lfs. \n\nI fixed\
          \ this issue by manually editing the conf file to be as follows:\n\"\"\"\
          \n{\n  \"_name_or_path\": \"OpenAssistant/oasst-sft-7e2-llama-30b\",\n \
          \ \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"bos_token_id\"\
          : 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\"\
          : 6656,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 17920,\n\
          \  \"max_position_embeddings\": 2048,\n  \"model_type\": \"llama\",\n  \"\
          num_attention_heads\": 52,\n  \"num_hidden_layers\": 60,\n  \"pad_token_id\"\
          : 0,\n  \"rms_norm_eps\": 1e-06,\n  \"tie_word_embeddings\": false,\n  \"\
          torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.28.1\",\n \
          \ \"use_cache\": true,\n  \"vocab_size\": 32006\n}\n\"\"\"\n\nNow the hash\
          \ checks out - 9a4d2468ecf85bf07420b200faefb4af"
        updatedAt: '2023-06-19T17:51:58.477Z'
      numEdits: 0
      reactions: []
      relatedEventId: 649095be0ac22b36494a0d7a
    id: 649095be0ac22b36494a0d78
    type: comment
  author: grg
  content: "Hello, thanks for your reply. I do not think that is related to my issue,\
    \ as I am using Linux. Also, the hash is not the same, so it is possible that\
    \ there is some issue with the file you have on git lfs. \n\nI fixed this issue\
    \ by manually editing the conf file to be as follows:\n\"\"\"\n{\n  \"_name_or_path\"\
    : \"OpenAssistant/oasst-sft-7e2-llama-30b\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\
    \n  ],\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\"\
    ,\n  \"hidden_size\": 6656,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\"\
    : 17920,\n  \"max_position_embeddings\": 2048,\n  \"model_type\": \"llama\",\n\
    \  \"num_attention_heads\": 52,\n  \"num_hidden_layers\": 60,\n  \"pad_token_id\"\
    : 0,\n  \"rms_norm_eps\": 1e-06,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\"\
    : \"float16\",\n  \"transformers_version\": \"4.28.1\",\n  \"use_cache\": true,\n\
    \  \"vocab_size\": 32006\n}\n\"\"\"\n\nNow the hash checks out - 9a4d2468ecf85bf07420b200faefb4af"
  created_at: 2023-06-19 16:51:58+00:00
  edited: false
  hidden: false
  id: 649095be0ac22b36494a0d78
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663681720771-noauth.jpeg?w=200&h=200&f=face
      fullname: Grgur Kovac
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: grg
      type: user
    createdAt: '2023-06-19T17:51:58.000Z'
    data:
      status: open
    id: 649095be0ac22b36494a0d7a
    type: status-change
  author: grg
  created_at: 2023-06-19 16:51:58+00:00
  id: 649095be0ac22b36494a0d7a
  new_status: open
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: OpenAssistant/oasst-rlhf-2-llama-30b-7k-steps-xor
repo_type: model
status: open
target_branch: null
title: Error in the config.json
