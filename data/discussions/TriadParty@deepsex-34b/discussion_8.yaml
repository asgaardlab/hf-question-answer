!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tachyphylaxis
conflicting_files: null
created_at: 2023-12-25 00:59:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e8a081099e6d560e1b9016666568584e.svg
      fullname: Blair Sadewitz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tachyphylaxis
      type: user
    createdAt: '2023-12-25T00:59:45.000Z'
    data:
      edited: true
      editors:
      - tachyphylaxis
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9542450904846191
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e8a081099e6d560e1b9016666568584e.svg
          fullname: Blair Sadewitz
          isHf: false
          isPro: false
          name: tachyphylaxis
          type: user
        html: '<p>Hey.  I''m assuming that the example you give isn''t actually supposed
          to look like that, but like the actual alpaca format (e.g. "### Instruction:"
          ...).  But I haven''t ever seen it with history before.  Could you give
          me an example prompt?  I mean, it''s not too hard to guess, but I just want
          to be sure, because this model seems  to be very particular about the prompt
          format.  Also, is there a sillytavern macro that I can use to feed it the
          chat history?  If not, which client(s) do you use?  Thanks.</p>

          <p>That is, I assume it doesn''t actually look like this, as you said "alpaca",
          and that has the ###, etc.</p>

          <p>  {<br>    "instruction": "user instruction (required)",<br>    "input":
          "user input (optional)",<br>    "output": "model response (required)",<br>    "history":
          [<br>      ["user instruction in the first round (optional)", "model response
          in the first round (optional)"],<br>      ["user instruction in the second
          round (optional)", "model response in the second round (optional)"]<br>    ]<br>  }<br>]</p>

          <p>Also, do you know any clients which can make use of the history?  Can
          SillyTavern?  If so, I haven''t found how in the docs yet. Does the history
          have ### Input: in it?  Just paste an example, please. ;-)</p>

          '
        raw: "Hey.  I'm assuming that the example you give isn't actually supposed\
          \ to look like that, but like the actual alpaca format (e.g. \"### Instruction:\"\
          \ ...).  But I haven't ever seen it with history before.  Could you give\
          \ me an example prompt?  I mean, it's not too hard to guess, but I just\
          \ want to be sure, because this model seems  to be very particular about\
          \ the prompt format.  Also, is there a sillytavern macro that I can use\
          \ to feed it the chat history?  If not, which client(s) do you use?  Thanks.\n\
          \nThat is, I assume it doesn't actually look like this, as you said \"alpaca\"\
          , and that has the ###, etc.\n\n  {\n    \"instruction\": \"user instruction\
          \ (required)\",\n    \"input\": \"user input (optional)\",\n    \"output\"\
          : \"model response (required)\",\n    \"history\": [\n      [\"user instruction\
          \ in the first round (optional)\", \"model response in the first round (optional)\"\
          ],\n      [\"user instruction in the second round (optional)\", \"model\
          \ response in the second round (optional)\"]\n    ]\n  }\n]\n\nAlso, do\
          \ you know any clients which can make use of the history?  Can SillyTavern?\
          \  If so, I haven't found how in the docs yet. Does the history have ###\
          \ Input: in it?  Just paste an example, please. ;-)"
        updatedAt: '2023-12-25T02:33:23.639Z'
      numEdits: 3
      reactions: []
    id: 6588d401304552ba0cbdec75
    type: comment
  author: tachyphylaxis
  content: "Hey.  I'm assuming that the example you give isn't actually supposed to\
    \ look like that, but like the actual alpaca format (e.g. \"### Instruction:\"\
    \ ...).  But I haven't ever seen it with history before.  Could you give me an\
    \ example prompt?  I mean, it's not too hard to guess, but I just want to be sure,\
    \ because this model seems  to be very particular about the prompt format.  Also,\
    \ is there a sillytavern macro that I can use to feed it the chat history?  If\
    \ not, which client(s) do you use?  Thanks.\n\nThat is, I assume it doesn't actually\
    \ look like this, as you said \"alpaca\", and that has the ###, etc.\n\n  {\n\
    \    \"instruction\": \"user instruction (required)\",\n    \"input\": \"user\
    \ input (optional)\",\n    \"output\": \"model response (required)\",\n    \"\
    history\": [\n      [\"user instruction in the first round (optional)\", \"model\
    \ response in the first round (optional)\"],\n      [\"user instruction in the\
    \ second round (optional)\", \"model response in the second round (optional)\"\
    ]\n    ]\n  }\n]\n\nAlso, do you know any clients which can make use of the history?\
    \  Can SillyTavern?  If so, I haven't found how in the docs yet. Does the history\
    \ have ### Input: in it?  Just paste an example, please. ;-)"
  created_at: 2023-12-25 00:59:45+00:00
  edited: true
  hidden: false
  id: 6588d401304552ba0cbdec75
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661737644873-noauth.jpeg?w=200&h=200&f=face
      fullname: triad party
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: TriadParty
      type: user
    createdAt: '2023-12-25T23:51:24.000Z'
    data:
      edited: false
      editors:
      - TriadParty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8760013580322266
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661737644873-noauth.jpeg?w=200&h=200&f=face
          fullname: triad party
          isHf: false
          isPro: false
          name: TriadParty
          type: user
        html: '<p>It seems to be the reason why alpaca''s instruction following effect
          is not very good. During the sft stage training, all the data is indeed
          in alpaca format. But there is indeed a certain probability that the output
          format is not the default alpaca. Next, I plan to open source the base version
          and retrain the v2 version using chatml format as sft stage data. Also,
          I''m looking for a Sillytarven macro to import history...</p>

          '
        raw: It seems to be the reason why alpaca's instruction following effect is
          not very good. During the sft stage training, all the data is indeed in
          alpaca format. But there is indeed a certain probability that the output
          format is not the default alpaca. Next, I plan to open source the base version
          and retrain the v2 version using chatml format as sft stage data. Also,
          I'm looking for a Sillytarven macro to import history...
        updatedAt: '2023-12-25T23:51:24.779Z'
      numEdits: 0
      reactions: []
    id: 658a157cfb9c2bdfae6f1f52
    type: comment
  author: TriadParty
  content: It seems to be the reason why alpaca's instruction following effect is
    not very good. During the sft stage training, all the data is indeed in alpaca
    format. But there is indeed a certain probability that the output format is not
    the default alpaca. Next, I plan to open source the base version and retrain the
    v2 version using chatml format as sft stage data. Also, I'm looking for a Sillytarven
    macro to import history...
  created_at: 2023-12-25 23:51:24+00:00
  edited: false
  hidden: false
  id: 658a157cfb9c2bdfae6f1f52
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e8a081099e6d560e1b9016666568584e.svg
      fullname: Blair Sadewitz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tachyphylaxis
      type: user
    createdAt: '2024-01-18T21:36:55.000Z'
    data:
      edited: true
      editors:
      - tachyphylaxis
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9420596957206726
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e8a081099e6d560e1b9016666568584e.svg
          fullname: Blair Sadewitz
          isHf: false
          isPro: false
          name: tachyphylaxis
          type: user
        html: '<p>Oh, hi, I missed this response.  How is the history represented
          in alpaca format? That is, I assume that this means:</p>

          <p>Preamble.</p>

          <p>''### Instruction:<br>User''s instruction.</p>

          <p>''### Input:<br>Additional information/context.</p>

          <p>''### Response:<br>Model''s response.</p>

          <p>Now, for "history", does that mean just that these tuples are appended
          to this prompt, with up to two tuples?  I''m fairly new to this, so I think
          maybe I don''t understand the formatting convention you have used to represent
          the prompt.  Is it just appended, or is there ### History, or what?  The
          single quotes are there to keep this thing from picking it up as a formatting
          tag and emboldening it.  I don''t know how to tell it not to do that, lol.  Oh,
          also, the Yi model was revised, renaming the layers (or whatever, not sure
          I remember lol) so it doesn''t have to use the custom code.  I have no idea
          why they did that in the first place, because there doesn''t seem to be
          anything that they actually gained.  It just made it incompatible.  I was
          reading through some threads on the model page, and people really took them
          to task for this.  Why rename them?  What''s the point?  Just so people
          think it''s a novel model or something?  But who would think that?  Lol,
          I don''t understand.  But there are some programs (well, at least KoboldAI)
          that can''t deal with trust_remote_code.  I''ve loaded it by adding trust_remote_code=True
          in every relevant call  because I don''t know how to properly fix it because
          I don''t really know python haha.  Anyway, the Yi people renamed them back
          to the standard names, so it doesn''t need the custom code anymore.  I really
          like the model, so if it''s not too labor-intensive, please do update it.  Thanks.  I
          think you did a great job selecting the corpus to train it on; its output
          is unique.</p>

          '
        raw: 'Oh, hi, I missed this response.  How is the history represented in alpaca
          format? That is, I assume that this means:


          Preamble.


          ''### Instruction:

          User''s instruction.


          ''### Input:

          Additional information/context.


          ''### Response:

          Model''s response.


          Now, for "history", does that mean just that these tuples are appended to
          this prompt, with up to two tuples?  I''m fairly new to this, so I think
          maybe I don''t understand the formatting convention you have used to represent
          the prompt.  Is it just appended, or is there ### History, or what?  The
          single quotes are there to keep this thing from picking it up as a formatting
          tag and emboldening it.  I don''t know how to tell it not to do that, lol.  Oh,
          also, the Yi model was revised, renaming the layers (or whatever, not sure
          I remember lol) so it doesn''t have to use the custom code.  I have no idea
          why they did that in the first place, because there doesn''t seem to be
          anything that they actually gained.  It just made it incompatible.  I was
          reading through some threads on the model page, and people really took them
          to task for this.  Why rename them?  What''s the point?  Just so people
          think it''s a novel model or something?  But who would think that?  Lol,
          I don''t understand.  But there are some programs (well, at least KoboldAI)
          that can''t deal with trust_remote_code.  I''ve loaded it by adding trust_remote_code=True
          in every relevant call  because I don''t know how to properly fix it because
          I don''t really know python haha.  Anyway, the Yi people renamed them back
          to the standard names, so it doesn''t need the custom code anymore.  I really
          like the model, so if it''s not too labor-intensive, please do update it.  Thanks.  I
          think you did a great job selecting the corpus to train it on; its output
          is unique.'
        updatedAt: '2024-01-18T21:49:35.399Z'
      numEdits: 9
      reactions: []
    id: 65a999f7206a2a9fd0846ce0
    type: comment
  author: tachyphylaxis
  content: 'Oh, hi, I missed this response.  How is the history represented in alpaca
    format? That is, I assume that this means:


    Preamble.


    ''### Instruction:

    User''s instruction.


    ''### Input:

    Additional information/context.


    ''### Response:

    Model''s response.


    Now, for "history", does that mean just that these tuples are appended to this
    prompt, with up to two tuples?  I''m fairly new to this, so I think maybe I don''t
    understand the formatting convention you have used to represent the prompt.  Is
    it just appended, or is there ### History, or what?  The single quotes are there
    to keep this thing from picking it up as a formatting tag and emboldening it.  I
    don''t know how to tell it not to do that, lol.  Oh, also, the Yi model was revised,
    renaming the layers (or whatever, not sure I remember lol) so it doesn''t have
    to use the custom code.  I have no idea why they did that in the first place,
    because there doesn''t seem to be anything that they actually gained.  It just
    made it incompatible.  I was reading through some threads on the model page, and
    people really took them to task for this.  Why rename them?  What''s the point?  Just
    so people think it''s a novel model or something?  But who would think that?  Lol,
    I don''t understand.  But there are some programs (well, at least KoboldAI) that
    can''t deal with trust_remote_code.  I''ve loaded it by adding trust_remote_code=True
    in every relevant call  because I don''t know how to properly fix it because I
    don''t really know python haha.  Anyway, the Yi people renamed them back to the
    standard names, so it doesn''t need the custom code anymore.  I really like the
    model, so if it''s not too labor-intensive, please do update it.  Thanks.  I think
    you did a great job selecting the corpus to train it on; its output is unique.'
  created_at: 2024-01-18 21:36:55+00:00
  edited: true
  hidden: false
  id: 65a999f7206a2a9fd0846ce0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661737644873-noauth.jpeg?w=200&h=200&f=face
      fullname: triad party
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: TriadParty
      type: user
    createdAt: '2024-01-22T02:30:00.000Z'
    data:
      edited: false
      editors:
      - TriadParty
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9892794489860535
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661737644873-noauth.jpeg?w=200&h=200&f=face
          fullname: triad party
          isHf: false
          isPro: false
          name: TriadParty
          type: user
        html: '<p>In fact, I''m actually training version 2 for the reasons you mentioned.
          The biggest problem with this version is that Yi later changed the name
          of the layer... but I still pulled it when they were just released, which
          was very embarrassing. But anyway, thanks to 01, the nsfw finetune can work.
          The security mechanism of the previous qwen and other models was too messed
          up, and using the nsfw corpus for training will not have any effect.</p>

          '
        raw: In fact, I'm actually training version 2 for the reasons you mentioned.
          The biggest problem with this version is that Yi later changed the name
          of the layer... but I still pulled it when they were just released, which
          was very embarrassing. But anyway, thanks to 01, the nsfw finetune can work.
          The security mechanism of the previous qwen and other models was too messed
          up, and using the nsfw corpus for training will not have any effect.
        updatedAt: '2024-01-22T02:30:00.947Z'
      numEdits: 0
      reactions: []
    id: 65add32871c5d01a287062c6
    type: comment
  author: TriadParty
  content: In fact, I'm actually training version 2 for the reasons you mentioned.
    The biggest problem with this version is that Yi later changed the name of the
    layer... but I still pulled it when they were just released, which was very embarrassing.
    But anyway, thanks to 01, the nsfw finetune can work. The security mechanism of
    the previous qwen and other models was too messed up, and using the nsfw corpus
    for training will not have any effect.
  created_at: 2024-01-22 02:30:00+00:00
  edited: false
  hidden: false
  id: 65add32871c5d01a287062c6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: TriadParty/deepsex-34b
repo_type: model
status: open
target_branch: null
title: Prompt format (history)
