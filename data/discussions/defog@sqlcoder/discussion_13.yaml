!!python/object:huggingface_hub.community.DiscussionWithDetails
author: alfgo
conflicting_files: null
created_at: 2023-09-15 08:09:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf5f30801e78a0ff97aef334c498033e.svg
      fullname: alfgo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alfgo
      type: user
    createdAt: '2023-09-15T09:09:46.000Z'
    data:
      edited: false
      editors:
      - alfgo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7485679388046265
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf5f30801e78a0ff97aef334c498033e.svg
          fullname: alfgo
          isHf: false
          isPro: false
          name: alfgo
          type: user
        html: '<p>Can vllm support be provided</p>

          '
        raw: Can vllm support be provided
        updatedAt: '2023-09-15T09:09:46.620Z'
      numEdits: 0
      reactions: []
    id: 65041f5aa450492f843e1cde
    type: comment
  author: alfgo
  content: Can vllm support be provided
  created_at: 2023-09-15 08:09:46+00:00
  edited: false
  hidden: false
  id: 65041f5aa450492f843e1cde
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fb44d0a95cd946b17a6a45e8a97142fc.svg
      fullname: Wong
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jp-defog
      type: user
    createdAt: '2023-09-19T15:15:43.000Z'
    data:
      edited: true
      editors:
      - jp-defog
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9749826788902283
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fb44d0a95cd946b17a6a45e8a97142fc.svg
          fullname: Wong
          isHf: false
          isPro: false
          name: jp-defog
          type: user
        html: "<p>(edit) Hi <span data-props=\"{&quot;user&quot;:&quot;alfgo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/alfgo\"\
          >@<span class=\"underline\">alfgo</span></a></span>\n\n\t</span></span>\
          \ , you should be able to use vllm with our model out of the box as it is\
          \ a <code>GPTBigCodeForCausalLM</code> model, which VLLM supports out of\
          \ the box: <a rel=\"nofollow\" href=\"https://vllm.readthedocs.io/en/latest/models/supported_models.html\"\
          >https://vllm.readthedocs.io/en/latest/models/supported_models.html</a></p>\n"
        raw: '(edit) Hi @alfgo , you should be able to use vllm with our model out
          of the box as it is a `GPTBigCodeForCausalLM` model, which VLLM supports
          out of the box: https://vllm.readthedocs.io/en/latest/models/supported_models.html'
        updatedAt: '2023-09-19T15:17:29.130Z'
      numEdits: 1
      reactions: []
      relatedEventId: 6509bb1f948ce5dce8b53ed9
    id: 6509bb1f948ce5dce8b53ed6
    type: comment
  author: jp-defog
  content: '(edit) Hi @alfgo , you should be able to use vllm with our model out of
    the box as it is a `GPTBigCodeForCausalLM` model, which VLLM supports out of the
    box: https://vllm.readthedocs.io/en/latest/models/supported_models.html'
  created_at: 2023-09-19 14:15:43+00:00
  edited: true
  hidden: false
  id: 6509bb1f948ce5dce8b53ed6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/fb44d0a95cd946b17a6a45e8a97142fc.svg
      fullname: Wong
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jp-defog
      type: user
    createdAt: '2023-09-19T15:15:43.000Z'
    data:
      status: closed
    id: 6509bb1f948ce5dce8b53ed9
    type: status-change
  author: jp-defog
  created_at: 2023-09-19 14:15:43+00:00
  id: 6509bb1f948ce5dce8b53ed9
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: defog/sqlcoder
repo_type: model
status: closed
target_branch: null
title: Can vllm support be provided
