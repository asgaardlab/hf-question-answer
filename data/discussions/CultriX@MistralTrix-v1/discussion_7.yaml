!!python/object:huggingface_hub.community.DiscussionWithDetails
author: georgewalker
conflicting_files: null
created_at: 2024-01-10 19:31:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cdba3c70a0c2e69d548bd44f70552d7b.svg
      fullname: George Walker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: georgewalker
      type: user
    createdAt: '2024-01-10T19:31:19.000Z'
    data:
      edited: false
      editors:
      - georgewalker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9359884858131409
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cdba3c70a0c2e69d548bd44f70552d7b.svg
          fullname: George Walker
          isHf: false
          isPro: false
          name: georgewalker
          type: user
        html: '<p>Like several of the top ''7B'' models on the leaderboard, this is
          actually a 9B, downstream of <a href="https://huggingface.co/zyh3826/GML-Mistral-merged-v1">https://huggingface.co/zyh3826/GML-Mistral-merged-v1</a>,
          a merge that combined the first 32 layers (ie all of them) of one Mistral-7B
          finetune with the last 8 layers of another Mistral finetune, creating a
          model that is about 9B parameters.</p>

          <p>It is helpful to label model sizes appropriately. Better would be if
          Huggingface labeled models based on their file size and bpw, instead of
          allowing for these sorts of mistakes to occur and proliferate, as one mislabeled
          model begets others derived from it.</p>

          '
        raw: "Like several of the top '7B' models on the leaderboard, this is actually\
          \ a 9B, downstream of https://huggingface.co/zyh3826/GML-Mistral-merged-v1,\
          \ a merge that combined the first 32 layers (ie all of them) of one Mistral-7B\
          \ finetune with the last 8 layers of another Mistral finetune, creating\
          \ a model that is about 9B parameters.\r\n\r\nIt is helpful to label model\
          \ sizes appropriately. Better would be if Huggingface labeled models based\
          \ on their file size and bpw, instead of allowing for these sorts of mistakes\
          \ to occur and proliferate, as one mislabeled model begets others derived\
          \ from it."
        updatedAt: '2024-01-10T19:31:19.907Z'
      numEdits: 0
      reactions: []
    id: 659ef087e6d28c70c08bef34
    type: comment
  author: georgewalker
  content: "Like several of the top '7B' models on the leaderboard, this is actually\
    \ a 9B, downstream of https://huggingface.co/zyh3826/GML-Mistral-merged-v1, a\
    \ merge that combined the first 32 layers (ie all of them) of one Mistral-7B finetune\
    \ with the last 8 layers of another Mistral finetune, creating a model that is\
    \ about 9B parameters.\r\n\r\nIt is helpful to label model sizes appropriately.\
    \ Better would be if Huggingface labeled models based on their file size and bpw,\
    \ instead of allowing for these sorts of mistakes to occur and proliferate, as\
    \ one mislabeled model begets others derived from it."
  created_at: 2024-01-10 19:31:19+00:00
  edited: false
  hidden: false
  id: 659ef087e6d28c70c08bef34
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/320243a2588740e3ad886cebb082098c.svg
      fullname: Ontario
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ont
      type: user
    createdAt: '2024-01-14T04:27:35.000Z'
    data:
      edited: true
      editors:
      - Ont
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9730813503265381
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/320243a2588740e3ad886cebb082098c.svg
          fullname: Ontario
          isHf: false
          isPro: false
          name: Ont
          type: user
        html: '<p>Some responses from this model appear better considered than those
          of some other 7B models, but this model employs 25% more layers to achieve
          its winning performance. I agree that this model best be labeled as a 9B
          model.</p>

          '
        raw: Some responses from this model appear better considered than those of
          some other 7B models, but this model employs 25% more layers to achieve
          its winning performance. I agree that this model best be labeled as a 9B
          model.
        updatedAt: '2024-01-14T04:29:14.587Z'
      numEdits: 1
      reactions: []
    id: 65a362b79f0a34c173ba7ebc
    type: comment
  author: Ont
  content: Some responses from this model appear better considered than those of some
    other 7B models, but this model employs 25% more layers to achieve its winning
    performance. I agree that this model best be labeled as a 9B model.
  created_at: 2024-01-14 04:27:35+00:00
  edited: true
  hidden: false
  id: 65a362b79f0a34c173ba7ebc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: CultriX/MistralTrix-v1
repo_type: model
status: open
target_branch: null
title: This is not a 7B. It's a ~9B. Please label appropriately.
