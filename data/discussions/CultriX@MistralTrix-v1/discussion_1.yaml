!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Kquant03
conflicting_files: null
created_at: 2024-01-03 16:15:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
      fullname: Stanley Sebastian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kquant03
      type: user
    createdAt: '2024-01-03T16:15:56.000Z'
    data:
      edited: true
      editors:
      - Kquant03
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8687159419059753
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
          fullname: Stanley Sebastian
          isHf: false
          isPro: false
          name: Kquant03
          type: user
        html: '<p>I managed to merge 8x of these into a mixtral but I can''t test
          until I convert it to GGUF.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/6O3ORksLymuP5rOubf3r6.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/6O3ORksLymuP5rOubf3r6.png"></a></p>

          <p>Did you name your weights something strange? Here''s the model I''m trying
          to quantize. <a href="https://huggingface.co/Kquant03/MistralTrix8x9B/blob/main/README.md">https://huggingface.co/Kquant03/MistralTrix8x9B/blob/main/README.md</a></p>

          '
        raw: 'I managed to merge 8x of these into a mixtral but I can''t test until
          I convert it to GGUF.



          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/6O3ORksLymuP5rOubf3r6.png)


          Did you name your weights something strange? Here''s the model I''m trying
          to quantize. https://huggingface.co/Kquant03/MistralTrix8x9B/blob/main/README.md'
        updatedAt: '2024-01-04T00:12:47.543Z'
      numEdits: 1
      reactions: []
    id: 6595883c25b1c7a9104339cf
    type: comment
  author: Kquant03
  content: 'I managed to merge 8x of these into a mixtral but I can''t test until
    I convert it to GGUF.



    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/6O3ORksLymuP5rOubf3r6.png)


    Did you name your weights something strange? Here''s the model I''m trying to
    quantize. https://huggingface.co/Kquant03/MistralTrix8x9B/blob/main/README.md'
  created_at: 2024-01-03 16:15:56+00:00
  edited: true
  hidden: false
  id: 6595883c25b1c7a9104339cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/320243a2588740e3ad886cebb082098c.svg
      fullname: Ontario
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ont
      type: user
    createdAt: '2024-01-04T01:32:28.000Z'
    data:
      edited: false
      editors:
      - Ont
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8576058149337769
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/320243a2588740e3ad886cebb082098c.svg
          fullname: Ontario
          isHf: false
          isPro: false
          name: Ont
          type: user
        html: '<p>That tensor name "model.layers.0.block_sparse_moe.experts.0.w3.weight"
          is from Mixtral, not MistralTrix which uses standard Mistral tensor names
          aside from the extra layers.</p>

          <p>For whatever reason, convert.py isn''t expecting to handle Mixtral input
          there.</p>

          '
        raw: 'That tensor name "model.layers.0.block_sparse_moe.experts.0.w3.weight"
          is from Mixtral, not MistralTrix which uses standard Mistral tensor names
          aside from the extra layers.


          For whatever reason, convert.py isn''t expecting to handle Mixtral input
          there.'
        updatedAt: '2024-01-04T01:32:28.324Z'
      numEdits: 0
      reactions: []
    id: 65960aac665c29891f64d135
    type: comment
  author: Ont
  content: 'That tensor name "model.layers.0.block_sparse_moe.experts.0.w3.weight"
    is from Mixtral, not MistralTrix which uses standard Mistral tensor names aside
    from the extra layers.


    For whatever reason, convert.py isn''t expecting to handle Mixtral input there.'
  created_at: 2024-01-04 01:32:28+00:00
  edited: false
  hidden: false
  id: 65960aac665c29891f64d135
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
      fullname: Stanley Sebastian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kquant03
      type: user
    createdAt: '2024-01-04T02:33:54.000Z'
    data:
      edited: true
      editors:
      - Kquant03
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9387838244438171
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
          fullname: Stanley Sebastian
          isHf: false
          isPro: false
          name: Kquant03
          type: user
        html: '<blockquote>

          <p>That tensor name "model.layers.0.block_sparse_moe.experts.0.w3.weight"
          is from Mixtral, not MistralTrix which uses standard Mistral tensor names
          aside from the extra layers.</p>

          <p>For whatever reason, convert.py isn''t expecting to handle Mixtral input
          there.</p>

          </blockquote>

          <p>thanks for letting me know. Don''t worry...I''ll just leave it as base,
          then. I think I''m about to drop two back to back open LLm <a href="/CultriX/MistralTrix-v1/discussions/1">#1</a>
          spots. That base float is nasty...it knows more than I ever possibly thought
          it would have.</p>

          '
        raw: "> That tensor name \"model.layers.0.block_sparse_moe.experts.0.w3.weight\"\
          \ is from Mixtral, not MistralTrix which uses standard Mistral tensor names\
          \ aside from the extra layers.\n> \n> For whatever reason, convert.py isn't\
          \ expecting to handle Mixtral input there.\n\nthanks for letting me know.\
          \ Don't worry...I'll just leave it as base, then. I think I'm about to drop\
          \ two back to back open LLm #1 spots. That base float is nasty...it knows\
          \ more than I ever possibly thought it would have."
        updatedAt: '2024-01-04T02:34:38.279Z'
      numEdits: 1
      reactions: []
    id: 65961912fa54621c41ea4fb0
    type: comment
  author: Kquant03
  content: "> That tensor name \"model.layers.0.block_sparse_moe.experts.0.w3.weight\"\
    \ is from Mixtral, not MistralTrix which uses standard Mistral tensor names aside\
    \ from the extra layers.\n> \n> For whatever reason, convert.py isn't expecting\
    \ to handle Mixtral input there.\n\nthanks for letting me know. Don't worry...I'll\
    \ just leave it as base, then. I think I'm about to drop two back to back open\
    \ LLm #1 spots. That base float is nasty...it knows more than I ever possibly\
    \ thought it would have."
  created_at: 2024-01-04 02:33:54+00:00
  edited: true
  hidden: false
  id: 65961912fa54621c41ea4fb0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
      fullname: Stanley Sebastian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kquant03
      type: user
    createdAt: '2024-01-05T20:42:46.000Z'
    data:
      edited: false
      editors:
      - Kquant03
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9135971665382385
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
          fullname: Stanley Sebastian
          isHf: false
          isPro: false
          name: Kquant03
          type: user
        html: '<p>To anyone worried about quantizing MoE''s of this model, it''s not
          just this model...it''s mergekit-moe in general. Most models over 8x7B will
          not convert to GGUF. Just letting everyone know.</p>

          <p>This model is great, btw...I''m making a 4x MoE of it right now for roleplay
          haha</p>

          '
        raw: 'To anyone worried about quantizing MoE''s of this model, it''s not just
          this model...it''s mergekit-moe in general. Most models over 8x7B will not
          convert to GGUF. Just letting everyone know.


          This model is great, btw...I''m making a 4x MoE of it right now for roleplay
          haha'
        updatedAt: '2024-01-05T20:42:46.684Z'
      numEdits: 0
      reactions: []
    id: 659869c6b0c5357368bcd099
    type: comment
  author: Kquant03
  content: 'To anyone worried about quantizing MoE''s of this model, it''s not just
    this model...it''s mergekit-moe in general. Most models over 8x7B will not convert
    to GGUF. Just letting everyone know.


    This model is great, btw...I''m making a 4x MoE of it right now for roleplay haha'
  created_at: 2024-01-05 20:42:46+00:00
  edited: false
  hidden: false
  id: 659869c6b0c5357368bcd099
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
      fullname: Stanley Sebastian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kquant03
      type: user
    createdAt: '2024-01-05T20:43:31.000Z'
    data:
      status: closed
    id: 659869f36da3461e28648fe3
    type: status-change
  author: Kquant03
  created_at: 2024-01-05 20:43:31+00:00
  id: 659869f36da3461e28648fe3
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
      fullname: Stanley Sebastian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kquant03
      type: user
    createdAt: '2024-01-05T20:43:34.000Z'
    data:
      status: open
    id: 659869f6be7822d24d36328f
    type: status-change
  author: Kquant03
  created_at: 2024-01-05 20:43:34+00:00
  id: 659869f6be7822d24d36328f
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
      fullname: Stanley Sebastian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kquant03
      type: user
    createdAt: '2024-01-05T22:52:49.000Z'
    data:
      from: I'm trying to convert to GGUF
      to: I have managed to convert mixtral to GGUF
    id: 65988841a3259bc41780033f
    type: title-change
  author: Kquant03
  created_at: 2024-01-05 22:52:49+00:00
  id: 65988841a3259bc41780033f
  new_title: I have managed to convert mixtral to GGUF
  old_title: I'm trying to convert to GGUF
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
      fullname: Stanley Sebastian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kquant03
      type: user
    createdAt: '2024-01-05T22:54:36.000Z'
    data:
      edited: true
      editors:
      - Kquant03
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9521057605743408
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
          fullname: Stanley Sebastian
          isHf: false
          isPro: false
          name: Kquant03
          type: user
        html: '<p>After days of merging and editing code and trying new things...I
          found out that convert-hf-to-gguf.py works, but is very bugged when used
          for MoEs created by mergekit-moe. This thread will be closed, now.</p>

          '
        raw: After days of merging and editing code and trying new things...I found
          out that convert-hf-to-gguf.py works, but is very bugged when used for MoEs
          created by mergekit-moe. This thread will be closed, now.
        updatedAt: '2024-01-06T08:10:16.025Z'
      numEdits: 1
      reactions: []
      relatedEventId: 659888ac654fe4eb0a6580c8
    id: 659888ac654fe4eb0a6580c3
    type: comment
  author: Kquant03
  content: After days of merging and editing code and trying new things...I found
    out that convert-hf-to-gguf.py works, but is very bugged when used for MoEs created
    by mergekit-moe. This thread will be closed, now.
  created_at: 2024-01-05 22:54:36+00:00
  edited: true
  hidden: false
  id: 659888ac654fe4eb0a6580c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
      fullname: Stanley Sebastian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kquant03
      type: user
    createdAt: '2024-01-05T22:54:36.000Z'
    data:
      status: closed
    id: 659888ac654fe4eb0a6580c8
    type: status-change
  author: Kquant03
  created_at: 2024-01-05 22:54:36+00:00
  id: 659888ac654fe4eb0a6580c8
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: CultriX/MistralTrix-v1
repo_type: model
status: closed
target_branch: null
title: I have managed to convert mixtral to GGUF
