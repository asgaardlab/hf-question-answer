!!python/object:huggingface_hub.community.DiscussionWithDetails
author: developerbayman
conflicting_files: null
created_at: 2023-06-03 14:54:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d8d798337166c1864ade52160e716d81.svg
      fullname: jeremy vernotzy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: developerbayman
      type: user
    createdAt: '2023-06-03T15:54:27.000Z'
    data:
      edited: true
      editors:
      - developerbayman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4578273892402649
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d8d798337166c1864ade52160e716d81.svg
          fullname: jeremy vernotzy
          isHf: false
          isPro: false
          name: developerbayman
          type: user
        html: '<p>im struggling to properly implement this to my ai script it appears
          to run based on the redlining of the cpu usage but times out? currently
          i have no clue on how to define the cpu npu ang gpu properly also managing  resource
          constraints here is my code if you wanna try to make this better its 2 files
          "huggingface_autodetect.py" and "chat_commands.py"</p>

          '
        raw: im struggling to properly implement this to my ai script it appears to
          run based on the redlining of the cpu usage but times out? currently i have
          no clue on how to define the cpu npu ang gpu properly also managing  resource
          constraints here is my code if you wanna try to make this better its 2 files
          "huggingface_autodetect.py" and "chat_commands.py"
        updatedAt: '2023-06-03T15:55:21.974Z'
      numEdits: 1
      reactions: []
    id: 647b62336a79fbf5e996d2de
    type: comment
  author: developerbayman
  content: im struggling to properly implement this to my ai script it appears to
    run based on the redlining of the cpu usage but times out? currently i have no
    clue on how to define the cpu npu ang gpu properly also managing  resource constraints
    here is my code if you wanna try to make this better its 2 files "huggingface_autodetect.py"
    and "chat_commands.py"
  created_at: 2023-06-03 14:54:27+00:00
  edited: true
  hidden: false
  id: 647b62336a79fbf5e996d2de
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d8d798337166c1864ade52160e716d81.svg
      fullname: jeremy vernotzy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: developerbayman
      type: user
    createdAt: '2023-06-03T15:55:56.000Z'
    data:
      edited: true
      editors:
      - developerbayman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.34279802441596985
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d8d798337166c1864ade52160e716d81.svg
          fullname: jeremy vernotzy
          isHf: false
          isPro: false
          name: developerbayman
          type: user
        html: "<p>'''import threading<br>import time<br>import sys<br>from gtts import\
          \ gTTS<br>import os<br>import tkinter as tk<br>from tkinter import filedialog,\
          \ messagebox, ttk<br>import speech_recognition as sr<br>import webbrowser<br>import\
          \ re<br>import subprocess<br>import openai<br>from transformers import AutoTokenizer,\
          \ AutoModelForCausalLM<br>import tracemalloc<br>import functools<br>import\
          \ torch</p>\n<p>doListenToCommand = True<br>listening = False<br>is_decoder\
          \ = True<br>despedida = [\"Goodbye\", \"goodbye\", \"bye\", \"Bye\", \"\
          See you later\", \"see you later\"]</p>\n<h1 id=\"processor-selector-variables\"\
          >Processor selector variables</h1>\n<p>use_npu = False<br>use_gpu = False<br>use_cpu\
          \ = True</p>\n<p>window = tk.Tk()<br>window.title(\"Computer: AI\")<br>window.geometry(\"\
          400x400\")</p>\n<p>text_entry = tk.Entry(window, width=50)<br>text_entry.pack(side=tk.BOTTOM)</p>\n\
          <p>submit_button = tk.Button(window, text=\"Submit\", command=lambda: submit())<br>submit_button.pack(side=tk.BOTTOM)</p>\n\
          <p>text_output = tk.Text(window, height=300, width=300)<br>text_output.pack(side=tk.BOTTOM)</p>\n\
          <p>scrollbar = tk.Scrollbar(window)<br>scrollbar.pack(side=tk.RIGHT, fill=tk.Y)<br>text_output.config(yscrollcommand=scrollbar.set)<br>scrollbar.config(command=text_output.yview)</p>\n\
          <p>tokenizer = AutoTokenizer.from_pretrained(\"Aeala/GPT4-x-AlpacaDente2-30b\"\
          )</p>\n<p>@functools.lru_cache(maxsize=128)<br>def get_model():<br>    return\
          \ AutoModelForCausalLM.from_pretrained(\"Aeala/GPT4-x-AlpacaDente2-30b\"\
          )</p>\n<h1 id=\"set-your-openai-api-key-here\">Set your OpenAI API key here</h1>\n\
          <p>openai.api_key = \"\"</p>\n<p>def submit(event=None, text_input=None):<br>\
          \    global doListenToCommand<br>    global listening</p>\n<pre><code>if\
          \ text_input is not None and text_input != \"\":\n    usuario = text_input\n\
          else:\n    usuario = text_entry.get()\n\nif usuario in despedida:\n    on_closing()\n\
          else:\n    prompt = f\"You are ChatGPT and answer my following message:\
          \ {usuario}\"\n\nif not use_offline:\n    response = openai.Completion.create(\n\
          \        engine=\"text-davinci-003\",\n        prompt=prompt,\n        max_tokens=100,\n\
          \        n=1,\n        stop=None,\n        temperature=0.7,\n        top_p=1.0,\n\
          \        frequency_penalty=0.0,\n        presence_penalty=0.0\n    )\n\n\
          \    respuesta = response.choices[0].text.strip()\n\nelse:\n    input_ids\
          \ = tokenizer.encode(prompt, return_tensors=\"pt\")\n    model = get_model()\n\
          \n    device = torch.device(\"cpu\")\n    if use_npu and torch.cuda.is_available():\n\
          \        device = torch.device(\"cuda\")\n    elif use_cpu:\n        device\
          \ = torch.device(\"cpu\")\n\n    model = model.to(device)\n    input_ids\
          \ = input_ids.to(device)\n\n    output = model.generate(input_ids, max_length=100,\
          \ num_return_sequences=1)\n\n    respuesta = tokenizer.decode(output[0],\
          \ skip_special_tokens=True)\n    respuesta = respuesta.replace(prompt, \"\
          \").strip()\n\ntexto = str(respuesta)\ntts = gTTS(texto, lang='en', tld='ie')\n\
          tts.save(\"audio.mp3\")\n\ntext_output.insert(tk.END, \"ChatGPT: \" + respuesta\
          \ + \"\\n\")\ntext_entry.delete(0, tk.END)\n\nif doListenToCommand:\n  \
          \  doListenToCommand = False\n    text_output.insert(tk.END, \"Computer\
          \ is now quiet...\\n\")\n    window.update()\n    time.sleep(1)\n    doListenToCommand\
          \ = True\n</code></pre>\n<p>def play_audio():<br>    if sys.platform.startswith('darwin'):<br>\
          \        subprocess.call([\"afplay\", \"audio.mp3\"])<br>    elif sys.platform.startswith('win32'):<br>\
          \        os.startfile(\"audio.mp3\")<br>    elif sys.platform.startswith('linux'):<br>\
          \        subprocess.call([\"paplay\", \"audio.mp3\"])</p>\n<p>def listen_to_command():<br>\
          \    global doListenToCommand<br>    global listening</p>\n<pre><code>if\
          \ not doListenToCommand:\n    return\n\nif listening:\n    return\n\nlistening\
          \ = True\nprint(\"Listening...\")\n\nr = sr.Recognizer()\nr.energy_threshold\
          \ = 3000\n\nwith sr.Microphone() as source:\n    audio = r.listen(source)\n\
          \ntry:\n    command = r.recognize_google(audio)\n    print(\"You said: \"\
          \ + command)\n\n    text_output.insert(tk.END, \"You: \" + command + \"\\\
          n\")\n    text_entry.delete(0, tk.END)\n\n    submit(text_input=command)\n\
          \nexcept sr.UnknownValueError:\n    print(\"Speech recognition could not\
          \ understand audio.\")\nexcept sr.RequestError as e:\n    print(\"Could\
          \ not request results from Google Speech Recognition service:\", str(e))\n\
          \nlistening = False\nlisten_to_command()\n</code></pre>\n<p>def on_closing():<br>\
          \    if messagebox.askokcancel(\"Quit\", \"Do you want to quit?\"):<br>\
          \        window.destroy()</p>\n<p>window.protocol(\"WM_DELETE_WINDOW\",\
          \ on_closing)</p>\n<p>menu_bar = tk.Menu(window)</p>\n<p>file_menu = tk.Menu(menu_bar,\
          \ tearoff=0)<br>file_menu.add_separator()<br>file_menu.add_command(label=\"\
          Exit\", command=on_closing)<br>menu_bar.add_cascade(label=\"File\", menu=file_menu)</p>\n\
          <p>run_menu = tk.Menu(menu_bar, tearoff=0)<br>run_menu.add_command(label=\"\
          Run Online\", command=lambda: threading.Thread(target=run_online).start())<br>run_menu.add_command(label=\"\
          Run Offline\", command=lambda: threading.Thread(target=run_offline).start())<br>menu_bar.add_cascade(label=\"\
          Run\", menu=run_menu)</p>\n<p>window.config(menu=menu_bar)</p>\n<p>def clear_output():<br>\
          \    text_output.delete(\"1.0\", tk.END)</p>\n<p>def run_online():<br> \
          \   global use_offline<br>    use_offline = False</p>\n<p>def run_offline():<br>\
          \    global use_offline<br>    use_offline = True</p>\n<p>start_listening_thread\
          \ = threading.Thread(target=listen_to_command)<br>start_listening_thread.daemon\
          \ = True<br>start_listening_thread.start()<br>window.mainloop() '''</p>\n"
        raw: "'''import threading\nimport time\nimport sys\nfrom gtts import gTTS\n\
          import os\nimport tkinter as tk\nfrom tkinter import filedialog, messagebox,\
          \ ttk\nimport speech_recognition as sr\nimport webbrowser\nimport re\nimport\
          \ subprocess\nimport openai\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
          import tracemalloc\nimport functools\nimport torch\n\ndoListenToCommand\
          \ = True\nlistening = False\nis_decoder = True\ndespedida = [\"Goodbye\"\
          , \"goodbye\", \"bye\", \"Bye\", \"See you later\", \"see you later\"]\n\
          \n# Processor selector variables\nuse_npu = False\nuse_gpu = False\nuse_cpu\
          \ = True\n\nwindow = tk.Tk()\nwindow.title(\"Computer: AI\")\nwindow.geometry(\"\
          400x400\")\n\ntext_entry = tk.Entry(window, width=50)\ntext_entry.pack(side=tk.BOTTOM)\n\
          \nsubmit_button = tk.Button(window, text=\"Submit\", command=lambda: submit())\n\
          submit_button.pack(side=tk.BOTTOM)\n\ntext_output = tk.Text(window, height=300,\
          \ width=300)\ntext_output.pack(side=tk.BOTTOM)\n\nscrollbar = tk.Scrollbar(window)\n\
          scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\ntext_output.config(yscrollcommand=scrollbar.set)\n\
          scrollbar.config(command=text_output.yview)\n\ntokenizer = AutoTokenizer.from_pretrained(\"\
          Aeala/GPT4-x-AlpacaDente2-30b\")\n\n@functools.lru_cache(maxsize=128)\n\
          def get_model():\n    return AutoModelForCausalLM.from_pretrained(\"Aeala/GPT4-x-AlpacaDente2-30b\"\
          )\n\n# Set your OpenAI API key here\nopenai.api_key = \"\"\n\ndef submit(event=None,\
          \ text_input=None):\n    global doListenToCommand\n    global listening\n\
          \n    if text_input is not None and text_input != \"\":\n        usuario\
          \ = text_input\n    else:\n        usuario = text_entry.get()\n\n    if\
          \ usuario in despedida:\n        on_closing()\n    else:\n        prompt\
          \ = f\"You are ChatGPT and answer my following message: {usuario}\"\n\n\
          \    if not use_offline:\n        response = openai.Completion.create(\n\
          \            engine=\"text-davinci-003\",\n            prompt=prompt,\n\
          \            max_tokens=100,\n            n=1,\n            stop=None,\n\
          \            temperature=0.7,\n            top_p=1.0,\n            frequency_penalty=0.0,\n\
          \            presence_penalty=0.0\n        )\n\n        respuesta = response.choices[0].text.strip()\n\
          \n    else:\n        input_ids = tokenizer.encode(prompt, return_tensors=\"\
          pt\")\n        model = get_model()\n\n        device = torch.device(\"cpu\"\
          )\n        if use_npu and torch.cuda.is_available():\n            device\
          \ = torch.device(\"cuda\")\n        elif use_cpu:\n            device =\
          \ torch.device(\"cpu\")\n\n        model = model.to(device)\n        input_ids\
          \ = input_ids.to(device)\n\n        output = model.generate(input_ids, max_length=100,\
          \ num_return_sequences=1)\n\n        respuesta = tokenizer.decode(output[0],\
          \ skip_special_tokens=True)\n        respuesta = respuesta.replace(prompt,\
          \ \"\").strip()\n\n    texto = str(respuesta)\n    tts = gTTS(texto, lang='en',\
          \ tld='ie')\n    tts.save(\"audio.mp3\")\n\n    text_output.insert(tk.END,\
          \ \"ChatGPT: \" + respuesta + \"\\n\")\n    text_entry.delete(0, tk.END)\n\
          \n    if doListenToCommand:\n        doListenToCommand = False\n       \
          \ text_output.insert(tk.END, \"Computer is now quiet...\\n\")\n        window.update()\n\
          \        time.sleep(1)\n        doListenToCommand = True\n\ndef play_audio():\n\
          \    if sys.platform.startswith('darwin'):\n        subprocess.call([\"\
          afplay\", \"audio.mp3\"])\n    elif sys.platform.startswith('win32'):\n\
          \        os.startfile(\"audio.mp3\")\n    elif sys.platform.startswith('linux'):\n\
          \        subprocess.call([\"paplay\", \"audio.mp3\"])\n\ndef listen_to_command():\n\
          \    global doListenToCommand\n    global listening\n\n    if not doListenToCommand:\n\
          \        return\n\n    if listening:\n        return\n\n    listening =\
          \ True\n    print(\"Listening...\")\n\n    r = sr.Recognizer()\n    r.energy_threshold\
          \ = 3000\n\n    with sr.Microphone() as source:\n        audio = r.listen(source)\n\
          \n    try:\n        command = r.recognize_google(audio)\n        print(\"\
          You said: \" + command)\n\n        text_output.insert(tk.END, \"You: \"\
          \ + command + \"\\n\")\n        text_entry.delete(0, tk.END)\n\n       \
          \ submit(text_input=command)\n\n    except sr.UnknownValueError:\n     \
          \   print(\"Speech recognition could not understand audio.\")\n    except\
          \ sr.RequestError as e:\n        print(\"Could not request results from\
          \ Google Speech Recognition service:\", str(e))\n\n    listening = False\n\
          \    listen_to_command()\n\ndef on_closing():\n    if messagebox.askokcancel(\"\
          Quit\", \"Do you want to quit?\"):\n        window.destroy()\n\nwindow.protocol(\"\
          WM_DELETE_WINDOW\", on_closing)\n\nmenu_bar = tk.Menu(window)\n\nfile_menu\
          \ = tk.Menu(menu_bar, tearoff=0)\nfile_menu.add_separator()\nfile_menu.add_command(label=\"\
          Exit\", command=on_closing)\nmenu_bar.add_cascade(label=\"File\", menu=file_menu)\n\
          \nrun_menu = tk.Menu(menu_bar, tearoff=0)\nrun_menu.add_command(label=\"\
          Run Online\", command=lambda: threading.Thread(target=run_online).start())\n\
          run_menu.add_command(label=\"Run Offline\", command=lambda: threading.Thread(target=run_offline).start())\n\
          menu_bar.add_cascade(label=\"Run\", menu=run_menu)\n\nwindow.config(menu=menu_bar)\n\
          \ndef clear_output():\n    text_output.delete(\"1.0\", tk.END)\n\ndef run_online():\n\
          \    global use_offline\n    use_offline = False\n\ndef run_offline():\n\
          \    global use_offline\n    use_offline = True\n\nstart_listening_thread\
          \ = threading.Thread(target=listen_to_command)\nstart_listening_thread.daemon\
          \ = True\nstart_listening_thread.start()\nwindow.mainloop() '''"
        updatedAt: '2023-06-03T15:57:55.558Z'
      numEdits: 1
      reactions: []
    id: 647b628cb31514a4a6dc9da2
    type: comment
  author: developerbayman
  content: "'''import threading\nimport time\nimport sys\nfrom gtts import gTTS\n\
    import os\nimport tkinter as tk\nfrom tkinter import filedialog, messagebox, ttk\n\
    import speech_recognition as sr\nimport webbrowser\nimport re\nimport subprocess\n\
    import openai\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\
    import tracemalloc\nimport functools\nimport torch\n\ndoListenToCommand = True\n\
    listening = False\nis_decoder = True\ndespedida = [\"Goodbye\", \"goodbye\", \"\
    bye\", \"Bye\", \"See you later\", \"see you later\"]\n\n# Processor selector\
    \ variables\nuse_npu = False\nuse_gpu = False\nuse_cpu = True\n\nwindow = tk.Tk()\n\
    window.title(\"Computer: AI\")\nwindow.geometry(\"400x400\")\n\ntext_entry = tk.Entry(window,\
    \ width=50)\ntext_entry.pack(side=tk.BOTTOM)\n\nsubmit_button = tk.Button(window,\
    \ text=\"Submit\", command=lambda: submit())\nsubmit_button.pack(side=tk.BOTTOM)\n\
    \ntext_output = tk.Text(window, height=300, width=300)\ntext_output.pack(side=tk.BOTTOM)\n\
    \nscrollbar = tk.Scrollbar(window)\nscrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n\
    text_output.config(yscrollcommand=scrollbar.set)\nscrollbar.config(command=text_output.yview)\n\
    \ntokenizer = AutoTokenizer.from_pretrained(\"Aeala/GPT4-x-AlpacaDente2-30b\"\
    )\n\n@functools.lru_cache(maxsize=128)\ndef get_model():\n    return AutoModelForCausalLM.from_pretrained(\"\
    Aeala/GPT4-x-AlpacaDente2-30b\")\n\n# Set your OpenAI API key here\nopenai.api_key\
    \ = \"\"\n\ndef submit(event=None, text_input=None):\n    global doListenToCommand\n\
    \    global listening\n\n    if text_input is not None and text_input != \"\"\
    :\n        usuario = text_input\n    else:\n        usuario = text_entry.get()\n\
    \n    if usuario in despedida:\n        on_closing()\n    else:\n        prompt\
    \ = f\"You are ChatGPT and answer my following message: {usuario}\"\n\n    if\
    \ not use_offline:\n        response = openai.Completion.create(\n           \
    \ engine=\"text-davinci-003\",\n            prompt=prompt,\n            max_tokens=100,\n\
    \            n=1,\n            stop=None,\n            temperature=0.7,\n    \
    \        top_p=1.0,\n            frequency_penalty=0.0,\n            presence_penalty=0.0\n\
    \        )\n\n        respuesta = response.choices[0].text.strip()\n\n    else:\n\
    \        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n       \
    \ model = get_model()\n\n        device = torch.device(\"cpu\")\n        if use_npu\
    \ and torch.cuda.is_available():\n            device = torch.device(\"cuda\")\n\
    \        elif use_cpu:\n            device = torch.device(\"cpu\")\n\n       \
    \ model = model.to(device)\n        input_ids = input_ids.to(device)\n\n     \
    \   output = model.generate(input_ids, max_length=100, num_return_sequences=1)\n\
    \n        respuesta = tokenizer.decode(output[0], skip_special_tokens=True)\n\
    \        respuesta = respuesta.replace(prompt, \"\").strip()\n\n    texto = str(respuesta)\n\
    \    tts = gTTS(texto, lang='en', tld='ie')\n    tts.save(\"audio.mp3\")\n\n \
    \   text_output.insert(tk.END, \"ChatGPT: \" + respuesta + \"\\n\")\n    text_entry.delete(0,\
    \ tk.END)\n\n    if doListenToCommand:\n        doListenToCommand = False\n  \
    \      text_output.insert(tk.END, \"Computer is now quiet...\\n\")\n        window.update()\n\
    \        time.sleep(1)\n        doListenToCommand = True\n\ndef play_audio():\n\
    \    if sys.platform.startswith('darwin'):\n        subprocess.call([\"afplay\"\
    , \"audio.mp3\"])\n    elif sys.platform.startswith('win32'):\n        os.startfile(\"\
    audio.mp3\")\n    elif sys.platform.startswith('linux'):\n        subprocess.call([\"\
    paplay\", \"audio.mp3\"])\n\ndef listen_to_command():\n    global doListenToCommand\n\
    \    global listening\n\n    if not doListenToCommand:\n        return\n\n   \
    \ if listening:\n        return\n\n    listening = True\n    print(\"Listening...\"\
    )\n\n    r = sr.Recognizer()\n    r.energy_threshold = 3000\n\n    with sr.Microphone()\
    \ as source:\n        audio = r.listen(source)\n\n    try:\n        command =\
    \ r.recognize_google(audio)\n        print(\"You said: \" + command)\n\n     \
    \   text_output.insert(tk.END, \"You: \" + command + \"\\n\")\n        text_entry.delete(0,\
    \ tk.END)\n\n        submit(text_input=command)\n\n    except sr.UnknownValueError:\n\
    \        print(\"Speech recognition could not understand audio.\")\n    except\
    \ sr.RequestError as e:\n        print(\"Could not request results from Google\
    \ Speech Recognition service:\", str(e))\n\n    listening = False\n    listen_to_command()\n\
    \ndef on_closing():\n    if messagebox.askokcancel(\"Quit\", \"Do you want to\
    \ quit?\"):\n        window.destroy()\n\nwindow.protocol(\"WM_DELETE_WINDOW\"\
    , on_closing)\n\nmenu_bar = tk.Menu(window)\n\nfile_menu = tk.Menu(menu_bar, tearoff=0)\n\
    file_menu.add_separator()\nfile_menu.add_command(label=\"Exit\", command=on_closing)\n\
    menu_bar.add_cascade(label=\"File\", menu=file_menu)\n\nrun_menu = tk.Menu(menu_bar,\
    \ tearoff=0)\nrun_menu.add_command(label=\"Run Online\", command=lambda: threading.Thread(target=run_online).start())\n\
    run_menu.add_command(label=\"Run Offline\", command=lambda: threading.Thread(target=run_offline).start())\n\
    menu_bar.add_cascade(label=\"Run\", menu=run_menu)\n\nwindow.config(menu=menu_bar)\n\
    \ndef clear_output():\n    text_output.delete(\"1.0\", tk.END)\n\ndef run_online():\n\
    \    global use_offline\n    use_offline = False\n\ndef run_offline():\n    global\
    \ use_offline\n    use_offline = True\n\nstart_listening_thread = threading.Thread(target=listen_to_command)\n\
    start_listening_thread.daemon = True\nstart_listening_thread.start()\nwindow.mainloop()\
    \ '''"
  created_at: 2023-06-03 14:55:56+00:00
  edited: true
  hidden: false
  id: 647b628cb31514a4a6dc9da2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d8d798337166c1864ade52160e716d81.svg
      fullname: jeremy vernotzy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: developerbayman
      type: user
    createdAt: '2023-06-03T15:56:18.000Z'
    data:
      edited: false
      editors:
      - developerbayman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5761122107505798
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d8d798337166c1864ade52160e716d81.svg
          fullname: jeremy vernotzy
          isHf: false
          isPro: false
          name: developerbayman
          type: user
        html: "<p>import subprocess<br>import webbrowser<br>import re<br>import validators<br>import\
          \ sys</p>\n<p>def process_commands(passed_commands, command):<br>    if\
          \ \"computer\" in command.lower():<br>        print(\"Activated Command:\
          \ Computer\")<br>        passed_commands.text_output.insert(<br>       \
          \     passed_commands.tk.END, \"Activated Command: Computer\" + \"\\n\"\
          )<br>        passed_commands.submit(text_input=command)<br>        # listen_to_command()</p>\n\
          <pre><code>    # Open a website\n    #if command.lower().startswith(\"open\
          \ website\"):\n    if \"open website\" in command.lower():\n        # Extract\
          \ the website URL from the command\n        #url = command.replace(\"open\
          \ website\", \"\")\n        url = command.partition(\"open website\")\n\
          \        # access third tuple element\n        url = url[2]\n        url\
          \ = url.strip() # Strip whitespace on both ends. Not working? As there is\
          \ a space in the leading part of the URL variable after this.\n        #\
          \ Test for http:// or https:// and add http:// to the URL if missing.\n\
          \        if not url.startswith(\"http://\") and not url.startswith(\"https://\"\
          ):\n            url = \"http://\" + url\n        \n        print(\"Trying\
          \ to open website: \" + url)\n\n        # Validating if the URL is correct\n\
          \        if validators.url(url):\n            webbrowser.open(url, new=0,\
          \ autoraise=True)\n            \n            passed_commands.text_output.insert(\n\
          \                passed_commands.tk.END, \"Opening website: \" + url + \"\
          \\n\")\n        else:\n            print(\"Invalid URL command. URL: \"\
          \ + url)\n            passed_commands.text_output.insert(\n            \
          \    passed_commands.tk.END, \"Invalid URL command. URL: \" + url + \"\\\
          n\")\n\n    return\n</code></pre>\n<p>def process_commands(passed_commands,\
          \ command):<br>    if \"computer\" in command.lower():<br>        print(\"\
          Activated Command: Computer\")<br>        passed_commands.text_output.insert(<br>\
          \            passed_commands.tk.END, \"Activated Command: Computer\" + \"\
          \\n\")<br>        passed_commands.submit(text_input=command)<br>       \
          \ # listen_to_command()</p>\n<pre><code>    # Open an application\n    if\
          \ \"run program\" in command.lower():\n        # Extract the application\
          \ name from the command\n        app_name = command.partition(\"run program\"\
          )[2]\n        app_name = app_name.strip()\n\n        print(\"Trying to open\
          \ program: \" + app_name)\n\n        try:\n            subprocess.Popen(app_name)\n\
          \            passed_commands.text_output.insert(\n                passed_commands.tk.END,\
          \ \"Opening program: \" + app_name + \"\\n\")\n        except FileNotFoundError:\n\
          \            print(\"Program not found: \" + app_name)\n            passed_commands.text_output.insert(\n\
          \                passed_commands.tk.END, \"Program not found: \" + app_name\
          \ + \"\\n\")\n\n        return\n\n    print(\"Invalid command\")\n    passed_commands.text_output.insert(\n\
          \        passed_commands.tk.END, \"Invalid command\" + \"\\n\")\n\n\n# Testing\n\
          # Stop listening to the microphone\nif command.lower() == \"stop listening\"\
          :\n    passed_commands.text_output.insert(\n        passed_commands.tk.END,\
          \ \"Stopping the microphone.\" + \"\\n\")\n    # What goes here?\n\n   \
          \ return\n\n# Testing\n# Allow program exit via voice.\nif command.lower()\
          \ == \"stop program\":\n    passed_commands.text_output.insert(\n      \
          \  passed_commands.tk.END, \"Stopping the program.\" + \"\\n\")\n    \n\
          \    sys.exit()\n\n    return\n</code></pre>\n"
        raw: "import subprocess\nimport webbrowser\nimport re\nimport validators\n\
          import sys\n\ndef process_commands(passed_commands, command):\n    if \"\
          computer\" in command.lower():\n        print(\"Activated Command: Computer\"\
          )\n        passed_commands.text_output.insert(\n            passed_commands.tk.END,\
          \ \"Activated Command: Computer\" + \"\\n\")\n        passed_commands.submit(text_input=command)\n\
          \        # listen_to_command()\n\n        # Open a website\n        #if\
          \ command.lower().startswith(\"open website\"):\n        if \"open website\"\
          \ in command.lower():\n            # Extract the website URL from the command\n\
          \            #url = command.replace(\"open website\", \"\")\n          \
          \  url = command.partition(\"open website\")\n            # access third\
          \ tuple element\n            url = url[2]\n            url = url.strip()\
          \ # Strip whitespace on both ends. Not working? As there is a space in the\
          \ leading part of the URL variable after this.\n            # Test for http://\
          \ or https:// and add http:// to the URL if missing.\n            if not\
          \ url.startswith(\"http://\") and not url.startswith(\"https://\"):\n  \
          \              url = \"http://\" + url\n            \n            print(\"\
          Trying to open website: \" + url)\n\n            # Validating if the URL\
          \ is correct\n            if validators.url(url):\n                webbrowser.open(url,\
          \ new=0, autoraise=True)\n                \n                passed_commands.text_output.insert(\n\
          \                    passed_commands.tk.END, \"Opening website: \" + url\
          \ + \"\\n\")\n            else:\n                print(\"Invalid URL command.\
          \ URL: \" + url)\n                passed_commands.text_output.insert(\n\
          \                    passed_commands.tk.END, \"Invalid URL command. URL:\
          \ \" + url + \"\\n\")\n\n        return\n\ndef process_commands(passed_commands,\
          \ command):\n    if \"computer\" in command.lower():\n        print(\"Activated\
          \ Command: Computer\")\n        passed_commands.text_output.insert(\n  \
          \          passed_commands.tk.END, \"Activated Command: Computer\" + \"\\\
          n\")\n        passed_commands.submit(text_input=command)\n        # listen_to_command()\n\
          \n        # Open an application\n        if \"run program\" in command.lower():\n\
          \            # Extract the application name from the command\n         \
          \   app_name = command.partition(\"run program\")[2]\n            app_name\
          \ = app_name.strip()\n\n            print(\"Trying to open program: \" +\
          \ app_name)\n\n            try:\n                subprocess.Popen(app_name)\n\
          \                passed_commands.text_output.insert(\n                 \
          \   passed_commands.tk.END, \"Opening program: \" + app_name + \"\\n\")\n\
          \            except FileNotFoundError:\n                print(\"Program\
          \ not found: \" + app_name)\n                passed_commands.text_output.insert(\n\
          \                    passed_commands.tk.END, \"Program not found: \" + app_name\
          \ + \"\\n\")\n\n            return\n\n        print(\"Invalid command\"\
          )\n        passed_commands.text_output.insert(\n            passed_commands.tk.END,\
          \ \"Invalid command\" + \"\\n\")\n\n\n    # Testing\n    # Stop listening\
          \ to the microphone\n    if command.lower() == \"stop listening\":\n   \
          \     passed_commands.text_output.insert(\n            passed_commands.tk.END,\
          \ \"Stopping the microphone.\" + \"\\n\")\n        # What goes here?\n\n\
          \        return\n\n    # Testing\n    # Allow program exit via voice.\n\
          \    if command.lower() == \"stop program\":\n        passed_commands.text_output.insert(\n\
          \            passed_commands.tk.END, \"Stopping the program.\" + \"\\n\"\
          )\n        \n        sys.exit()\n\n        return"
        updatedAt: '2023-06-03T15:56:18.384Z'
      numEdits: 0
      reactions: []
    id: 647b62a2b31514a4a6dc9fc2
    type: comment
  author: developerbayman
  content: "import subprocess\nimport webbrowser\nimport re\nimport validators\nimport\
    \ sys\n\ndef process_commands(passed_commands, command):\n    if \"computer\"\
    \ in command.lower():\n        print(\"Activated Command: Computer\")\n      \
    \  passed_commands.text_output.insert(\n            passed_commands.tk.END, \"\
    Activated Command: Computer\" + \"\\n\")\n        passed_commands.submit(text_input=command)\n\
    \        # listen_to_command()\n\n        # Open a website\n        #if command.lower().startswith(\"\
    open website\"):\n        if \"open website\" in command.lower():\n          \
    \  # Extract the website URL from the command\n            #url = command.replace(\"\
    open website\", \"\")\n            url = command.partition(\"open website\")\n\
    \            # access third tuple element\n            url = url[2]\n        \
    \    url = url.strip() # Strip whitespace on both ends. Not working? As there\
    \ is a space in the leading part of the URL variable after this.\n           \
    \ # Test for http:// or https:// and add http:// to the URL if missing.\n    \
    \        if not url.startswith(\"http://\") and not url.startswith(\"https://\"\
    ):\n                url = \"http://\" + url\n            \n            print(\"\
    Trying to open website: \" + url)\n\n            # Validating if the URL is correct\n\
    \            if validators.url(url):\n                webbrowser.open(url, new=0,\
    \ autoraise=True)\n                \n                passed_commands.text_output.insert(\n\
    \                    passed_commands.tk.END, \"Opening website: \" + url + \"\\\
    n\")\n            else:\n                print(\"Invalid URL command. URL: \"\
    \ + url)\n                passed_commands.text_output.insert(\n              \
    \      passed_commands.tk.END, \"Invalid URL command. URL: \" + url + \"\\n\"\
    )\n\n        return\n\ndef process_commands(passed_commands, command):\n    if\
    \ \"computer\" in command.lower():\n        print(\"Activated Command: Computer\"\
    )\n        passed_commands.text_output.insert(\n            passed_commands.tk.END,\
    \ \"Activated Command: Computer\" + \"\\n\")\n        passed_commands.submit(text_input=command)\n\
    \        # listen_to_command()\n\n        # Open an application\n        if \"\
    run program\" in command.lower():\n            # Extract the application name\
    \ from the command\n            app_name = command.partition(\"run program\")[2]\n\
    \            app_name = app_name.strip()\n\n            print(\"Trying to open\
    \ program: \" + app_name)\n\n            try:\n                subprocess.Popen(app_name)\n\
    \                passed_commands.text_output.insert(\n                    passed_commands.tk.END,\
    \ \"Opening program: \" + app_name + \"\\n\")\n            except FileNotFoundError:\n\
    \                print(\"Program not found: \" + app_name)\n                passed_commands.text_output.insert(\n\
    \                    passed_commands.tk.END, \"Program not found: \" + app_name\
    \ + \"\\n\")\n\n            return\n\n        print(\"Invalid command\")\n   \
    \     passed_commands.text_output.insert(\n            passed_commands.tk.END,\
    \ \"Invalid command\" + \"\\n\")\n\n\n    # Testing\n    # Stop listening to the\
    \ microphone\n    if command.lower() == \"stop listening\":\n        passed_commands.text_output.insert(\n\
    \            passed_commands.tk.END, \"Stopping the microphone.\" + \"\\n\")\n\
    \        # What goes here?\n\n        return\n\n    # Testing\n    # Allow program\
    \ exit via voice.\n    if command.lower() == \"stop program\":\n        passed_commands.text_output.insert(\n\
    \            passed_commands.tk.END, \"Stopping the program.\" + \"\\n\")\n  \
    \      \n        sys.exit()\n\n        return"
  created_at: 2023-06-03 14:56:18+00:00
  edited: false
  hidden: false
  id: 647b62a2b31514a4a6dc9fc2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d8d798337166c1864ade52160e716d81.svg
      fullname: jeremy vernotzy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: developerbayman
      type: user
    createdAt: '2023-06-03T15:59:11.000Z'
    data:
      edited: false
      editors:
      - developerbayman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9601793885231018
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d8d798337166c1864ade52160e716d81.svg
          fullname: jeremy vernotzy
          isHf: false
          isPro: false
          name: developerbayman
          type: user
        html: '<p>sorry it appears '''''' '''''' isnt working"</p>

          '
        raw: sorry it appears ''' ''' isnt working"
        updatedAt: '2023-06-03T15:59:11.059Z'
      numEdits: 0
      reactions: []
    id: 647b634fb31514a4a6dcae56
    type: comment
  author: developerbayman
  content: sorry it appears ''' ''' isnt working"
  created_at: 2023-06-03 14:59:11+00:00
  edited: false
  hidden: false
  id: 647b634fb31514a4a6dcae56
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: Aeala/GPT4-x-AlpacaDente2-30b
repo_type: model
status: open
target_branch: null
title: implementing processor manageability on a orange pi 5
