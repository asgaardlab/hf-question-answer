!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zhexiu
conflicting_files: null
created_at: 2023-11-10 08:06:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e3c663f279c070e012c6aa3f2cd36267.svg
      fullname: zhexiu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zhexiu
      type: user
    createdAt: '2023-11-10T08:06:14.000Z'
    data:
      edited: false
      editors:
      - zhexiu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.1464574933052063
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e3c663f279c070e012c6aa3f2cd36267.svg
          fullname: zhexiu
          isHf: false
          isPro: false
          name: zhexiu
          type: user
        html: '<p>Traceback (most recent call last):</p>

          <p>File "E:\text-generation-webui\text-generation-webui-main\modules\ui_model_menu.py",
          line 210, in load_model_wrapper</p>

          <p>shared.model, shared.tokenizer = load_model(shared.model_name, loader)</p>

          <pre><code>                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "E:\text-generation-webui\text-generation-webui-main\modules\models.py",
          line 93, in load_model</p>

          <p>tokenizer = load_tokenizer(model_name, model)</p>

          <pre><code>        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "E:\text-generation-webui\text-generation-webui-main\modules\models.py",
          line 113, in load_tokenizer</p>

          <p>tokenizer = AutoTokenizer.from_pretrained(</p>

          <pre><code>        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "E:\text-generation-webui\text-generation-webui-main\installer_files\env\Lib\site-packages\transformers\models\auto\tokenization_auto.py",
          line 768, in from_pretrained</p>

          <p>return tokenizer_class.from_pretrained(pretrained_model_name_or_path,
          *inputs, **kwargs)</p>

          <pre><code>   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "E:\text-generation-webui\text-generation-webui-main\installer_files\env\Lib\site-packages\transformers\tokenization_utils_base.py",
          line 2024, in from_pretrained</p>

          <p>return cls._from_pretrained(</p>

          <pre><code>   ^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "E:\text-generation-webui\text-generation-webui-main\installer_files\env\Lib\site-packages\transformers\tokenization_utils_base.py",
          line 2256, in _from_pretrained</p>

          <p>tokenizer = cls(*init_inputs, **init_kwargs)</p>

          <pre><code>        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "E:\text-generation-webui\text-generation-webui-main\installer_files\env\Lib\site-packages\transformers\models\t5\tokenization_t5.py",
          line 166, in init</p>

          <p>self.sp_model.Load(vocab_file)<br>File "E:\text-generation-webui\text-generation-webui-main\installer_files\env\Lib\site-packages\sentencepiece_init_.py",
          line 905, in Load</p>

          <p>return self.LoadFromFile(model_file)</p>

          <pre><code>   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>File "E:\text-generation-webui\text-generation-webui-main\installer_files\env\Lib\site-packages\sentencepiece_init_.py",
          line 310, in LoadFromFile</p>

          <p>return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)</p>

          <pre><code>   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

          </code></pre>

          <p>TypeError: not a string</p>

          '
        raw: "Traceback (most recent call last):\r\n\r\nFile \"E:\\text-generation-webui\\\
          text-generation-webui-main\\modules\\ui_model_menu.py\", line 210, in load_model_wrapper\r\
          \n\r\n\r\nshared.model, shared.tokenizer = load_model(shared.model_name,\
          \ loader)\r\n\r\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \nFile \"E:\\text-generation-webui\\text-generation-webui-main\\modules\\\
          models.py\", line 93, in load_model\r\n\r\n\r\ntokenizer = load_tokenizer(model_name,\
          \ model)\r\n\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"\
          E:\\text-generation-webui\\text-generation-webui-main\\modules\\models.py\"\
          , line 113, in load_tokenizer\r\n\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\r\
          \n\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"E:\\text-generation-webui\\\
          text-generation-webui-main\\installer_files\\env\\Lib\\site-packages\\transformers\\\
          models\\auto\\tokenization_auto.py\", line 768, in from_pretrained\r\n\r\
          \n\r\nreturn tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\r\n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \nFile \"E:\\text-generation-webui\\text-generation-webui-main\\installer_files\\\
          env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\", line\
          \ 2024, in from_pretrained\r\n\r\n\r\nreturn cls._from_pretrained(\r\n\r\
          \n       ^^^^^^^^^^^^^^^^^^^^^\r\nFile \"E:\\text-generation-webui\\text-generation-webui-main\\\
          installer_files\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\"\
          , line 2256, in _from_pretrained\r\n\r\n\r\ntokenizer = cls(*init_inputs,\
          \ **init_kwargs)\r\n\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\
          File \"E:\\text-generation-webui\\text-generation-webui-main\\installer_files\\\
          env\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py\"\
          , line 166, in init\r\n\r\n\r\nself.sp_model.Load(vocab_file)\r\nFile \"\
          E:\\text-generation-webui\\text-generation-webui-main\\installer_files\\\
          env\\Lib\\site-packages\\sentencepiece_init_.py\", line 905, in Load\r\n\
          \r\n\r\nreturn self.LoadFromFile(model_file)\r\n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \nFile \"E:\\text-generation-webui\\text-generation-webui-main\\installer_files\\\
          env\\Lib\\site-packages\\sentencepiece_init_.py\", line 310, in LoadFromFile\r\
          \n\r\n\r\nreturn _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
          \ arg)\r\n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \nTypeError: not a string"
        updatedAt: '2023-11-10T08:06:14.887Z'
      numEdits: 0
      reactions: []
    id: 654de4760351be570768653b
    type: comment
  author: zhexiu
  content: "Traceback (most recent call last):\r\n\r\nFile \"E:\\text-generation-webui\\\
    text-generation-webui-main\\modules\\ui_model_menu.py\", line 210, in load_model_wrapper\r\
    \n\r\n\r\nshared.model, shared.tokenizer = load_model(shared.model_name, loader)\r\
    \n\r\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \nFile \"E:\\text-generation-webui\\text-generation-webui-main\\modules\\models.py\"\
    , line 93, in load_model\r\n\r\n\r\ntokenizer = load_tokenizer(model_name, model)\r\
    \n\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"E:\\text-generation-webui\\\
    text-generation-webui-main\\modules\\models.py\", line 113, in load_tokenizer\r\
    \n\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\r\n\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \nFile \"E:\\text-generation-webui\\text-generation-webui-main\\installer_files\\\
    env\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py\", line\
    \ 768, in from_pretrained\r\n\r\n\r\nreturn tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\r\n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \nFile \"E:\\text-generation-webui\\text-generation-webui-main\\installer_files\\\
    env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 2024,\
    \ in from_pretrained\r\n\r\n\r\nreturn cls._from_pretrained(\r\n\r\n       ^^^^^^^^^^^^^^^^^^^^^\r\
    \nFile \"E:\\text-generation-webui\\text-generation-webui-main\\installer_files\\\
    env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 2256,\
    \ in _from_pretrained\r\n\r\n\r\ntokenizer = cls(*init_inputs, **init_kwargs)\r\
    \n\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"E:\\text-generation-webui\\\
    text-generation-webui-main\\installer_files\\env\\Lib\\site-packages\\transformers\\\
    models\\t5\\tokenization_t5.py\", line 166, in init\r\n\r\n\r\nself.sp_model.Load(vocab_file)\r\
    \nFile \"E:\\text-generation-webui\\text-generation-webui-main\\installer_files\\\
    env\\Lib\\site-packages\\sentencepiece_init_.py\", line 905, in Load\r\n\r\n\r\
    \nreturn self.LoadFromFile(model_file)\r\n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \nFile \"E:\\text-generation-webui\\text-generation-webui-main\\installer_files\\\
    env\\Lib\\site-packages\\sentencepiece_init_.py\", line 310, in LoadFromFile\r\
    \n\r\n\r\nreturn _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)\r\
    \n\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\
    TypeError: not a string"
  created_at: 2023-11-10 08:06:14+00:00
  edited: false
  hidden: false
  id: 654de4760351be570768653b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: larryvrh/mt5-translation-ja_zh
repo_type: model
status: open
target_branch: null
title: "i dont know why \uFF0Cbut i get something wrong"
