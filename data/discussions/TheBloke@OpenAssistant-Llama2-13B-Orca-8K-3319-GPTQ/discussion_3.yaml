!!python/object:huggingface_hub.community.DiscussionWithDetails
author: funkytaco
conflicting_files: null
created_at: 2023-07-26 04:53:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/w31p7WZ7MuPtjhJ8j45PX.jpeg?w=200&h=200&f=face
      fullname: Luis Gonzalez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: funkytaco
      type: user
    createdAt: '2023-07-26T05:53:30.000Z'
    data:
      edited: false
      editors:
      - funkytaco
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.49476340413093567
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/w31p7WZ7MuPtjhJ8j45PX.jpeg?w=200&h=200&f=face
          fullname: Luis Gonzalez
          isHf: false
          isPro: false
          name: funkytaco
          type: user
        html: '<p>I''m new to Colab, notebooks, but not python.</p>

          <p>Will this work in colab:</p>

          <p>model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,<br>        model_basename=model_basename,<br>        use_safetensors=True,<br>        trust_remote_code=False,<br>        device="cuda:0",<br>        use_triton=use_triton,<br>        quantize_config=None)</p>

          <p>I get this from autogptq:<br>/usr/local/lib/python3.10/dist-packages/auto_gptq/modeling/_base.py
          in from_pretrained(cls, save_dir)<br>     49     @classmethod<br>     50     def
          from_pretrained(cls, save_dir: str):<br>---&gt; 51         with open(join(save_dir,
          "quantize_config.json"), "r", encoding="utf-8") as f:<br>     52             return
          cls(**json.load(f))<br>     53 </p>

          <p>FileNotFoundError: [Errno 2] No such file or directory: ''TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ/quantize_config.json''</p>

          '
        raw: "I'm new to Colab, notebooks, but not python.\r\n\r\nWill this work in\
          \ colab:\r\n\r\nmodel = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\r\
          \n        model_basename=model_basename,\r\n        use_safetensors=True,\r\
          \n        trust_remote_code=False,\r\n        device=\"cuda:0\",\r\n   \
          \     use_triton=use_triton,\r\n        quantize_config=None)\r\n\r\nI get\
          \ this from autogptq:\r\n/usr/local/lib/python3.10/dist-packages/auto_gptq/modeling/_base.py\
          \ in from_pretrained(cls, save_dir)\r\n     49     @classmethod\r\n    \
          \ 50     def from_pretrained(cls, save_dir: str):\r\n---> 51         with\
          \ open(join(save_dir, \"quantize_config.json\"), \"r\", encoding=\"utf-8\"\
          ) as f:\r\n     52             return cls(**json.load(f))\r\n     53 \r\n\
          \r\nFileNotFoundError: [Errno 2] No such file or directory: 'TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ/quantize_config.json'"
        updatedAt: '2023-07-26T05:53:30.019Z'
      numEdits: 0
      reactions: []
    id: 64c0b4dabf550559c60dd323
    type: comment
  author: funkytaco
  content: "I'm new to Colab, notebooks, but not python.\r\n\r\nWill this work in\
    \ colab:\r\n\r\nmodel = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\r\
    \n        model_basename=model_basename,\r\n        use_safetensors=True,\r\n\
    \        trust_remote_code=False,\r\n        device=\"cuda:0\",\r\n        use_triton=use_triton,\r\
    \n        quantize_config=None)\r\n\r\nI get this from autogptq:\r\n/usr/local/lib/python3.10/dist-packages/auto_gptq/modeling/_base.py\
    \ in from_pretrained(cls, save_dir)\r\n     49     @classmethod\r\n     50   \
    \  def from_pretrained(cls, save_dir: str):\r\n---> 51         with open(join(save_dir,\
    \ \"quantize_config.json\"), \"r\", encoding=\"utf-8\") as f:\r\n     52     \
    \        return cls(**json.load(f))\r\n     53 \r\n\r\nFileNotFoundError: [Errno\
    \ 2] No such file or directory: 'TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ/quantize_config.json'"
  created_at: 2023-07-26 04:53:30+00:00
  edited: false
  hidden: false
  id: 64c0b4dabf550559c60dd323
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-26T07:34:36.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.906434178352356
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Someone else reported a similar issue and it turned out they were
          using an old version of AutoGPTQ, which was caused by AutoGPTQ failing to
          properly install.  Please try the following:</p>

          <pre><code>!pip3 uninstall -y auto-gptq

          !GITHUB_ACTIONS=true CUDA_VERSION="" pip3 install auto-gptq==0.2.2

          !pip3 install transformers==4.31.0

          </code></pre>

          <p>Then test again</p>

          '
        raw: 'Someone else reported a similar issue and it turned out they were using
          an old version of AutoGPTQ, which was caused by AutoGPTQ failing to properly
          install.  Please try the following:


          ```

          !pip3 uninstall -y auto-gptq

          !GITHUB_ACTIONS=true CUDA_VERSION="" pip3 install auto-gptq==0.2.2

          !pip3 install transformers==4.31.0

          ```


          Then test again'
        updatedAt: '2023-07-26T07:34:36.615Z'
      numEdits: 0
      reactions: []
    id: 64c0cc8c8137192a1e2c46e2
    type: comment
  author: TheBloke
  content: 'Someone else reported a similar issue and it turned out they were using
    an old version of AutoGPTQ, which was caused by AutoGPTQ failing to properly install.  Please
    try the following:


    ```

    !pip3 uninstall -y auto-gptq

    !GITHUB_ACTIONS=true CUDA_VERSION="" pip3 install auto-gptq==0.2.2

    !pip3 install transformers==4.31.0

    ```


    Then test again'
  created_at: 2023-07-26 06:34:36+00:00
  edited: false
  hidden: false
  id: 64c0cc8c8137192a1e2c46e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    createdAt: '2023-07-27T04:41:51.000Z'
    data:
      edited: false
      editors:
      - deleted
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8592076897621155
      isReport: false
      latest:
        html: "<p>I've tried your commands I got an error:</p>\n<p>Building wheels\
          \ for collected packages: auto-gptq<br>  error: subprocess-exited-with-error</p>\n\
          <p>  \xD7 python setup.py bdist_wheel did not run successfully.<br>  \u2502\
          \ exit code: 1<br>  \u2570\u2500&gt; See above for output.</p>\n<p>  note:\
          \ This error originates from a subprocess, and is likely not a problem with\
          \ pip.<br>  Building wheel for auto-gptq (setup.py) ... error<br>  ERROR:\
          \ Failed building wheel for auto-gptq<br>  Running setup.py clean for auto-gptq<br>Failed\
          \ to build auto-gptq<br>ERROR: Could not build wheels for auto-gptq, which\
          \ is required to install pyproject.toml-based projects</p>\n"
        raw: "I've tried your commands I got an error:\n\nBuilding wheels for collected\
          \ packages: auto-gptq\n  error: subprocess-exited-with-error\n  \n  \xD7\
          \ python setup.py bdist_wheel did not run successfully.\n  \u2502 exit code:\
          \ 1\n  \u2570\u2500> See above for output.\n  \n  note: This error originates\
          \ from a subprocess, and is likely not a problem with pip.\n  Building wheel\
          \ for auto-gptq (setup.py) ... error\n  ERROR: Failed building wheel for\
          \ auto-gptq\n  Running setup.py clean for auto-gptq\nFailed to build auto-gptq\n\
          ERROR: Could not build wheels for auto-gptq, which is required to install\
          \ pyproject.toml-based projects"
        updatedAt: '2023-07-27T04:41:51.191Z'
      numEdits: 0
      reactions: []
    id: 64c1f58fc1d1f89163cc6ac6
    type: comment
  author: deleted
  content: "I've tried your commands I got an error:\n\nBuilding wheels for collected\
    \ packages: auto-gptq\n  error: subprocess-exited-with-error\n  \n  \xD7 python\
    \ setup.py bdist_wheel did not run successfully.\n  \u2502 exit code: 1\n  \u2570\
    \u2500> See above for output.\n  \n  note: This error originates from a subprocess,\
    \ and is likely not a problem with pip.\n  Building wheel for auto-gptq (setup.py)\
    \ ... error\n  ERROR: Failed building wheel for auto-gptq\n  Running setup.py\
    \ clean for auto-gptq\nFailed to build auto-gptq\nERROR: Could not build wheels\
    \ for auto-gptq, which is required to install pyproject.toml-based projects"
  created_at: 2023-07-27 03:41:51+00:00
  edited: false
  hidden: false
  id: 64c1f58fc1d1f89163cc6ac6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5fdc3cbd79368a14eaf878d18e058de4.svg
      fullname: Jakub Keller
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jakubskeller
      type: user
    createdAt: '2023-09-21T20:11:46.000Z'
    data:
      edited: false
      editors:
      - jakubskeller
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8227340579032898
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5fdc3cbd79368a14eaf878d18e058de4.svg
          fullname: Jakub Keller
          isHf: false
          isPro: false
          name: jakubskeller
          type: user
        html: '<p>Nope.</p>

          '
        raw: Nope.
        updatedAt: '2023-09-21T20:11:46.644Z'
      numEdits: 0
      reactions: []
    id: 650ca38249e89cb6748aecb1
    type: comment
  author: jakubskeller
  content: Nope.
  created_at: 2023-09-21 19:11:46+00:00
  edited: false
  hidden: false
  id: 650ca38249e89cb6748aecb1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ
repo_type: model
status: open
target_branch: null
title: Will this work in a Google Colab notebook?
