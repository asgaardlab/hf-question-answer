!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ShivanshMathur007
conflicting_files: null
created_at: 2024-01-12 12:39:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0a0fb779052d1e8beb7cbe553f1fd6b8.svg
      fullname: Shivansh Mathur
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ShivanshMathur007
      type: user
    createdAt: '2024-01-12T12:39:25.000Z'
    data:
      edited: false
      editors:
      - ShivanshMathur007
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4379110336303711
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0a0fb779052d1e8beb7cbe553f1fd6b8.svg
          fullname: Shivansh Mathur
          isHf: false
          isPro: false
          name: ShivanshMathur007
          type: user
        html: '<p>Can anyone describe the difference between max_pos_embeddings=512(config.json)
          , max_seq_length=128(sentence_bert_config.json), model_max_length=512(tokenizer_config.json).<br>Also
          how can I set these values by using langchain.</p>

          '
        raw: "Can anyone describe the difference between max_pos_embeddings=512(config.json)\
          \ , max_seq_length=128(sentence_bert_config.json), model_max_length=512(tokenizer_config.json).\r\
          \nAlso how can I set these values by using langchain.\r\n"
        updatedAt: '2024-01-12T12:39:25.245Z'
      numEdits: 0
      reactions: []
    id: 65a132fdfbad78ab6832bc40
    type: comment
  author: ShivanshMathur007
  content: "Can anyone describe the difference between max_pos_embeddings=512(config.json)\
    \ , max_seq_length=128(sentence_bert_config.json), model_max_length=512(tokenizer_config.json).\r\
    \nAlso how can I set these values by using langchain.\r\n"
  created_at: 2024-01-12 12:39:25+00:00
  edited: false
  hidden: false
  id: 65a132fdfbad78ab6832bc40
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
      fullname: Tom Aarsen
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: tomaarsen
      type: user
    createdAt: '2024-01-17T09:12:34.000Z'
    data:
      edited: false
      editors:
      - tomaarsen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.924491286277771
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
          fullname: Tom Aarsen
          isHf: true
          isPro: false
          name: tomaarsen
          type: user
        html: '<p>Hello!</p>

          <p>The 512 values are defined by the MiniLM base model, whereas 128 is the
          maximum sequence length that was used when finetuning the model to be an
          embedding model. As a result, 128 is the recommended maximum sequence length
          (after which you''ll get much worse embeddings), and 512 is the maximum
          sequence length after which the model will simply crash.<br>I''m not sure
          how to set these values in LangChain.</p>

          <ul>

          <li>Tom Aarsen</li>

          </ul>

          '
        raw: 'Hello!


          The 512 values are defined by the MiniLM base model, whereas 128 is the
          maximum sequence length that was used when finetuning the model to be an
          embedding model. As a result, 128 is the recommended maximum sequence length
          (after which you''ll get much worse embeddings), and 512 is the maximum
          sequence length after which the model will simply crash.

          I''m not sure how to set these values in LangChain.


          - Tom Aarsen'
        updatedAt: '2024-01-17T09:12:34.769Z'
      numEdits: 0
      reactions: []
    id: 65a79a0233299b87f6ac6381
    type: comment
  author: tomaarsen
  content: 'Hello!


    The 512 values are defined by the MiniLM base model, whereas 128 is the maximum
    sequence length that was used when finetuning the model to be an embedding model.
    As a result, 128 is the recommended maximum sequence length (after which you''ll
    get much worse embeddings), and 512 is the maximum sequence length after which
    the model will simply crash.

    I''m not sure how to set these values in LangChain.


    - Tom Aarsen'
  created_at: 2024-01-17 09:12:34+00:00
  edited: false
  hidden: false
  id: 65a79a0233299b87f6ac6381
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: sentence-transformers/all-MiniLM-L12-v2
repo_type: model
status: open
target_branch: null
title: Different Input Lengths
