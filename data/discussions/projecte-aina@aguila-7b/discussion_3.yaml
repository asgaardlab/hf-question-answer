!!python/object:huggingface_hub.community.DiscussionWithDetails
author: griu
conflicting_files: null
created_at: 2023-09-29 16:41:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86ee7599e4be747dfd76489b00b82185.svg
      fullname: Ferran
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: griu
      type: user
    createdAt: '2023-09-29T17:41:32.000Z'
    data:
      edited: false
      editors:
      - griu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2729553282260895
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86ee7599e4be747dfd76489b00b82185.svg
          fullname: Ferran
          isHf: false
          isPro: false
          name: griu
          type: user
        html: '<p>Hello,</p>

          <p>I''m loading the model with </p>

          <blockquote>

          <blockquote>

          <blockquote>

          <p>transformers.<strong>version</strong><br>''4.32.1''<br>torch.<strong>version</strong><br>''2.0.1+cu117''</p>

          </blockquote>

          </blockquote>

          </blockquote>

          <p>Following the code in de Model card. When I execute :<br>tokenizer =
          AutoTokenizer.from_pretrained(model_id)</p>

          <p>I get the following error:<br>ValueError: Unrecognized configuration
          class &lt;class ''transformers_modules.projecte-aina_aguila-7b.configuration_RW.RWConfig''&gt;to
          build an AutoTokenizer.</p>

          <p>Model type should be one of AlbertConfig, AlignConfig, BarkConfig, BartConfig,
          BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig,
          BlenderbotConfig, BlenderbotSmallConfig, BlipConfig, Blip2Config, BloomConfig,
          BridgeTowerConfig, CamembertConfig, CanineConfig, ChineseCLIPConfig, ClapConfig,
          CLIPConfig, CLIPSegConfig, CodeGenConfig, ConvBertConfig, CpmAntConfig,
          CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig,
          DPRConfig, ElectraConfig,ErnieConfig, ErnieMConfig, EsmConfig, FlaubertConfig,
          FNetConfig, FSMTConfig, FunnelConfig, GitConfig, GPT2Config, GPT2Config,
          GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig,
          GPTSanJapaneseConfig, GroupViTConfig, HubertConfig, IBertConfig, IdeficsConfig,
          InstructBlipConfig, JukeboxConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config,
          LEDConfig, LiltConfig, LlamaConfig, LongformerConfig, LongT5Config, LukeConfig,
          LxmertConfig, M2M100Config, MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig,
          MgpstrConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config,
          MusicgenConfig, MvpConfig, NezhaConfig, NllbMoeConfig, NystromformerConfig,
          OneFormerConfig, OpenAIGPTConfig, OPTConfig, OwlViTConfig,PegasusConfig,
          PegasusXConfig, PerceiverConfig, Pix2StructConfig, PLBartConfig, ProphetNetConfig,
          QDQBertConfig, RagConfig, RealmConfig, ReformerConfig, RemBertConfig, RetriBertConfig,
          RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig,
          RwkvConfig, Speech2TextConfig, Speech2Text2Config, SpeechT5Config, SplinterConfig,
          SqueezeBertConfig, SwitchTransformersConfig, T5Config, TapasConfig, TransfoXLConfig,
          UMT5Config, ViltConfig, VisualBertConfig, Wav2Vec2Config, Wav2Vec2ConformerConfig,
          WhisperConfig, XCLIPConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig,
          XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig.</p>

          <p>Any idea on this error?</p>

          <p>Thanks,<br>Ferran</p>

          '
        raw: "Hello,\r\n\r\nI'm loading the model with \r\n>>> transformers.__version__\r\
          \n'4.32.1'\r\n>>> torch.__version__\r\n'2.0.1+cu117'\r\n\r\nFollowing the\
          \ code in de Model card. When I execute :\r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\
          \n\r\nI get the following error:\r\nValueError: Unrecognized configuration\
          \ class <class 'transformers_modules.projecte-aina_aguila-7b.configuration_RW.RWConfig'>to\
          \ build an AutoTokenizer.\r\n\r\nModel type should be one of AlbertConfig,\
          \ AlignConfig, BarkConfig, BartConfig, BertConfig, BertGenerationConfig,\
          \ BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig,\
          \ BlipConfig, Blip2Config, BloomConfig, BridgeTowerConfig, CamembertConfig,\
          \ CanineConfig, ChineseCLIPConfig, ClapConfig, CLIPConfig, CLIPSegConfig,\
          \ CodeGenConfig, ConvBertConfig, CpmAntConfig, CTRLConfig, Data2VecTextConfig,\
          \ DebertaConfig, DebertaV2Config, DistilBertConfig, DPRConfig, ElectraConfig,ErnieConfig,\
          \ ErnieMConfig, EsmConfig, FlaubertConfig, FNetConfig, FSMTConfig, FunnelConfig,\
          \ GitConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig,\
          \ GPTNeoXJapaneseConfig, GPTJConfig, GPTSanJapaneseConfig, GroupViTConfig,\
          \ HubertConfig, IBertConfig, IdeficsConfig, InstructBlipConfig, JukeboxConfig,\
          \ LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig,\
          \ LlamaConfig, LongformerConfig, LongT5Config, LukeConfig, LxmertConfig,\
          \ M2M100Config, MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig,\
          \ MgpstrConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config,\
          \ MusicgenConfig, MvpConfig, NezhaConfig, NllbMoeConfig, NystromformerConfig,\
          \ OneFormerConfig, OpenAIGPTConfig, OPTConfig, OwlViTConfig,PegasusConfig,\
          \ PegasusXConfig, PerceiverConfig, Pix2StructConfig, PLBartConfig, ProphetNetConfig,\
          \ QDQBertConfig, RagConfig, RealmConfig, ReformerConfig, RemBertConfig,\
          \ RetriBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig,\
          \ RoFormerConfig, RwkvConfig, Speech2TextConfig, Speech2Text2Config, SpeechT5Config,\
          \ SplinterConfig, SqueezeBertConfig, SwitchTransformersConfig, T5Config,\
          \ TapasConfig, TransfoXLConfig, UMT5Config, ViltConfig, VisualBertConfig,\
          \ Wav2Vec2Config, Wav2Vec2ConformerConfig, WhisperConfig, XCLIPConfig, XGLMConfig,\
          \ XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig,\
          \ XLNetConfig, XmodConfig, YosoConfig.\r\n\r\nAny idea on this error?\r\n\
          \r\nThanks,\r\nFerran"
        updatedAt: '2023-09-29T17:41:32.486Z'
      numEdits: 0
      reactions: []
    id: 65170c4c70746a75c1f3714f
    type: comment
  author: griu
  content: "Hello,\r\n\r\nI'm loading the model with \r\n>>> transformers.__version__\r\
    \n'4.32.1'\r\n>>> torch.__version__\r\n'2.0.1+cu117'\r\n\r\nFollowing the code\
    \ in de Model card. When I execute :\r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\
    \n\r\nI get the following error:\r\nValueError: Unrecognized configuration class\
    \ <class 'transformers_modules.projecte-aina_aguila-7b.configuration_RW.RWConfig'>to\
    \ build an AutoTokenizer.\r\n\r\nModel type should be one of AlbertConfig, AlignConfig,\
    \ BarkConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig,\
    \ BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BlipConfig, Blip2Config,\
    \ BloomConfig, BridgeTowerConfig, CamembertConfig, CanineConfig, ChineseCLIPConfig,\
    \ ClapConfig, CLIPConfig, CLIPSegConfig, CodeGenConfig, ConvBertConfig, CpmAntConfig,\
    \ CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig,\
    \ DPRConfig, ElectraConfig,ErnieConfig, ErnieMConfig, EsmConfig, FlaubertConfig,\
    \ FNetConfig, FSMTConfig, FunnelConfig, GitConfig, GPT2Config, GPT2Config, GPTBigCodeConfig,\
    \ GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, GPTSanJapaneseConfig,\
    \ GroupViTConfig, HubertConfig, IBertConfig, IdeficsConfig, InstructBlipConfig,\
    \ JukeboxConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig,\
    \ LiltConfig, LlamaConfig, LongformerConfig, LongT5Config, LukeConfig, LxmertConfig,\
    \ M2M100Config, MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MgpstrConfig,\
    \ MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config, MusicgenConfig,\
    \ MvpConfig, NezhaConfig, NllbMoeConfig, NystromformerConfig, OneFormerConfig,\
    \ OpenAIGPTConfig, OPTConfig, OwlViTConfig,PegasusConfig, PegasusXConfig, PerceiverConfig,\
    \ Pix2StructConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, RagConfig,\
    \ RealmConfig, ReformerConfig, RemBertConfig, RetriBertConfig, RobertaConfig,\
    \ RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, Speech2TextConfig,\
    \ Speech2Text2Config, SpeechT5Config, SplinterConfig, SqueezeBertConfig, SwitchTransformersConfig,\
    \ T5Config, TapasConfig, TransfoXLConfig, UMT5Config, ViltConfig, VisualBertConfig,\
    \ Wav2Vec2Config, Wav2Vec2ConformerConfig, WhisperConfig, XCLIPConfig, XGLMConfig,\
    \ XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig,\
    \ XmodConfig, YosoConfig.\r\n\r\nAny idea on this error?\r\n\r\nThanks,\r\nFerran"
  created_at: 2023-09-29 16:41:32+00:00
  edited: false
  hidden: false
  id: 65170c4c70746a75c1f3714f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5bdcae1bdefcab9821dc378699a18bd8.svg
      fullname: Joan Llop Palao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: joanllop
      type: user
    createdAt: '2023-10-10T15:25:27.000Z'
    data:
      edited: false
      editors:
      - joanllop
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6811569929122925
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5bdcae1bdefcab9821dc378699a18bd8.svg
          fullname: Joan Llop Palao
          isHf: false
          isPro: false
          name: joanllop
          type: user
        html: '<p>Hello Ferran,</p>

          <p>It seems that the code is trying to load a model from the default configs
          instead of reading the config from the model files (<a href="https://huggingface.co/projecte-aina/aguila-7b/blob/main/modelling_RW.py">https://huggingface.co/projecte-aina/aguila-7b/blob/main/modelling_RW.py</a>
          and <a href="https://huggingface.co/projecte-aina/aguila-7b/blob/main/configuration_RW.py">https://huggingface.co/projecte-aina/aguila-7b/blob/main/configuration_RW.py</a>)<br>It
          may be possible that you need to add the trust_remote_code=True in the AutoTokenizer.from_pretrained
          function:</p>

          <pre><code class="language-python">tokenizer = AutoTokenizer.from_pretrained(model_id,
          trust_remote_code=<span class="hljs-literal">True</span>)

          </code></pre>

          <p>Hope it solves the problem,<br>Joan</p>

          '
        raw: 'Hello Ferran,


          It seems that the code is trying to load a model from the default configs
          instead of reading the config from the model files (https://huggingface.co/projecte-aina/aguila-7b/blob/main/modelling_RW.py
          and https://huggingface.co/projecte-aina/aguila-7b/blob/main/configuration_RW.py)

          It may be possible that you need to add the trust_remote_code=True in the
          AutoTokenizer.from_pretrained function:


          ```python

          tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)

          ```


          Hope it solves the problem,

          Joan'
        updatedAt: '2023-10-10T15:25:27.996Z'
      numEdits: 0
      reactions: []
    id: 65256ce7fa9f6e569489191d
    type: comment
  author: joanllop
  content: 'Hello Ferran,


    It seems that the code is trying to load a model from the default configs instead
    of reading the config from the model files (https://huggingface.co/projecte-aina/aguila-7b/blob/main/modelling_RW.py
    and https://huggingface.co/projecte-aina/aguila-7b/blob/main/configuration_RW.py)

    It may be possible that you need to add the trust_remote_code=True in the AutoTokenizer.from_pretrained
    function:


    ```python

    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)

    ```


    Hope it solves the problem,

    Joan'
  created_at: 2023-10-10 14:25:27+00:00
  edited: false
  hidden: false
  id: 65256ce7fa9f6e569489191d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: projecte-aina/aguila-7b
repo_type: model
status: open
target_branch: null
title: Unrecognized configuration class
