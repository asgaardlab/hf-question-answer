!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cnicu
conflicting_files: null
created_at: 2023-07-19 09:57:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679413553722-62093e86576225edf60ced22.jpeg?w=200&h=200&f=face
      fullname: Cosmina Nicu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cnicu
      type: user
    createdAt: '2023-07-19T10:57:34.000Z'
    data:
      edited: false
      editors:
      - cnicu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.1886431872844696
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679413553722-62093e86576225edf60ced22.jpeg?w=200&h=200&f=face
          fullname: Cosmina Nicu
          isHf: false
          isPro: false
          name: cnicu
          type: user
        html: "<p>Hello!</p>\n<p>I'm trying to deploy this model on AWS SageMaker\
          \ by following the steps provided in the documentation. However, I'm encountering\
          \ some errors during the endpoint creation process. I've double-checked\
          \ my configurations, but the issues persist.</p>\n<p>If anyone has experience\
          \ deploying this model on AWS SageMaker or any insights into resolving similar\
          \ errors, I'd greatly appreciate your help. Thanks in advance for any assistance\
          \ you can offer!</p>\n<p>Errors:</p>\n<pre><code>Error: DownloadError\n\
          \    utils.convert_files(local_pt_files, local_st_files)\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/convert.py\"\
          , line 84, in convert_files\n    convert_file(pt_file, sf_file)\n  File\
          \ \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/convert.py\"\
          , line 62, in convert_file\n    save_file(pt_state, str(sf_file), metadata={\n\
          \    \"format\": \"pt\"\n})\n  File \"/opt/conda/lib/python3.9/site-packages/safetensors/torch.py\"\
          , line 232, in save_file\n    serialize_file(_flatten(tensors), filename,\
          \ metadata=metadata)\n  File \"/opt/conda/lib/python3.9/site-packages/safetensors/torch.py\"\
          , line 394, in _flatten\n    raise RuntimeError(\n</code></pre>\n<p>And\
          \ the following error:</p>\n<pre><code>RuntimeError: \n            Some\
          \ tensors share memory, this will lead to duplicate memory on disk and potential\
          \ differences when loading them again: [{'transformer.h.6.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.26.mlp.dense_4h_to_h.weight', 'transformer.h.4.self_attention.query_key_value.weight',\
          \ 'transformer.h.22.mlp.dense_h_to_4h.weight', 'transformer.h.23.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.5.mlp.dense_h_to_4h.weight', 'transformer.h.25.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.25.mlp.dense_4h_to_h.weight', 'transformer.h.0.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.11.mlp.dense_h_to_4h.weight', 'transformer.h.29.self_attention.dense.weight',\
          \ 'transformer.h.24.self_attention.query_key_value.weight', 'transformer.h.24.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.14.mlp.dense_4h_to_h.weight', 'transformer.h.1.self_attention.dense.weight',\
          \ 'transformer.h.13.mlp.dense_4h_to_h.weight', 'transformer.h.8.self_attention.query_key_value.weight',\
          \ 'transformer.h.20.self_attention.query_key_value.weight', 'transformer.h.27.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.22.self_attention.query_key_value.weight', 'transformer.h.11.self_attention.query_key_value.weight',\
          \ 'transformer.h.23.self_attention.query_key_value.weight', 'transformer.h.13.self_attention.dense.weight',\
          \ 'transformer.h.15.mlp.dense_h_to_4h.weight', 'transformer.h.9.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.15.self_attention.query_key_value.weight', 'transformer.h.24.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.31.self_attention.query_key_value.weight', 'transformer.h.7.self_attention.dense.weight',\
          \ 'transformer.h.27.self_attention.query_key_value.weight', 'transformer.h.1.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.21.mlp.dense_4h_to_h.weight', 'transformer.h.24.self_attention.dense.weight',\
          \ 'transformer.h.16.mlp.dense_4h_to_h.weight', 'transformer.h.20.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.27.self_attention.dense.weight', 'transformer.h.4.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.3.mlp.dense_h_to_4h.weight', 'transformer.h.25.self_attention.dense.weight',\
          \ 'transformer.h.7.mlp.dense_4h_to_h.weight', 'transformer.h.17.self_attention.query_key_value.weight',\
          \ 'transformer.h.19.self_attention.dense.weight', 'transformer.h.12.self_attention.query_key_value.weight',\
          \ 'transformer.h.3.self_attention.dense.weight', 'transformer.h.28.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.19.mlp.dense_h_to_4h.weight', 'transformer.h.20.self_attention.dense.weight',\
          \ 'transformer.h.14.self_attention.query_key_value.weight', 'transformer.h.21.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.12.mlp.dense_h_to_4h.weight', 'transformer.h.29.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.6.mlp.dense_h_to_4h.weight', 'transformer.h.14.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.30.self_attention.dense.weight', 'transformer.h.10.self_attention.query_key_value.weight',\
          \ 'transformer.h.6.self_attention.query_key_value.weight', 'transformer.h.10.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.23.mlp.dense_4h_to_h.weight', 'transformer.h.21.self_attention.query_key_value.weight',\
          \ 'transformer.h.30.self_attention.query_key_value.weight', 'transformer.h.8.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.30.mlp.dense_h_to_4h.weight', 'transformer.h.18.self_attention.query_key_value.weight',\
          \ 'transformer.h.5.mlp.dense_4h_to_h.weight', 'transformer.h.15.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.26.self_attention.dense.weight', 'transformer.h.9.self_attention.query_key_value.weight',\
          \ 'transformer.h.17.mlp.dense_4h_to_h.weight', 'transformer.h.10.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.6.self_attention.dense.weight', 'transformer.h.2.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.5.self_attention.dense.weight', 'transformer.h.9.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.3.mlp.dense_4h_to_h.weight', 'transformer.h.17.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.27.mlp.dense_4h_to_h.weight', 'transformer.h.29.self_attention.query_key_value.weight',\
          \ 'transformer.h.5.self_attention.query_key_value.weight', 'transformer.h.11.self_attention.dense.weight',\
          \ 'transformer.h.19.mlp.dense_4h_to_h.weight', 'transformer.h.16.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.8.mlp.dense_4h_to_h.weight', 'transformer.h.30.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.31.mlp.dense_h_to_4h.weight', 'transformer.h.1.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.28.self_attention.dense.weight', 'transformer.h.22.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.31.self_attention.dense.weight', 'transformer.h.4.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.19.self_attention.query_key_value.weight', 'transformer.h.0.self_attention.dense.weight',\
          \ 'transformer.h.1.self_attention.query_key_value.weight', 'transformer.h.17.self_attention.dense.weight',\
          \ 'transformer.h.18.self_attention.dense.weight', 'transformer.h.23.self_attention.dense.weight',\
          \ 'transformer.h.28.self_attention.query_key_value.weight', 'transformer.h.12.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.16.self_attention.query_key_value.weight', 'transformer.h.22.self_attention.dense.weight',\
          \ 'transformer.h.18.mlp.dense_4h_to_h.weight', 'transformer.h.2.self_attention.query_key_value.weight',\
          \ 'transformer.h.18.mlp.dense_h_to_4h.weight', 'transformer.h.8.self_attention.dense.weight',\
          \ 'transformer.h.12.self_attention.dense.weight', 'transformer.h.29.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.10.self_attention.dense.weight', 'transformer.h.26.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.31.mlp.dense_4h_to_h.weight', 'transformer.h.3.self_attention.query_key_value.weight',\
          \ 'transformer.h.16.self_attention.dense.weight', 'transformer.h.9.self_attention.dense.weight',\
          \ 'transformer.h.21.self_attention.dense.weight', 'transformer.h.0.self_attention.query_key_value.weight',\
          \ 'transformer.h.28.mlp.dense_4h_to_h.weight', 'transformer.word_embeddings.weight',\
          \ 'transformer.h.0.mlp.dense_h_to_4h.weight', 'transformer.h.4.self_attention.dense.weight',\
          \ 'transformer.h.13.self_attention.query_key_value.weight', 'transformer.h.7.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.2.mlp.dense_h_to_4h.weight', 'transformer.h.7.self_attention.query_key_value.weight',\
          \ 'transformer.h.11.mlp.dense_4h_to_h.weight', 'transformer.h.2.self_attention.dense.weight',\
          \ 'transformer.h.13.mlp.dense_h_to_4h.weight', 'transformer.h.14.self_attention.dense.weight',\
          \ 'transformer.h.15.self_attention.dense.weight', 'transformer.h.25.self_attention.query_key_value.weight',\
          \ 'transformer.h.26.self_attention.query_key_value.weight', 'transformer.h.20.mlp.dense_h_to_4h.weight'},\
          \ {'transformer.h.22.input_layernorm.bias', 'transformer.h.17.input_layernorm.bias',\
          \ 'transformer.h.20.input_layernorm.weight', 'transformer.h.20.input_layernorm.bias',\
          \ 'transformer.h.1.input_layernorm.bias', 'transformer.h.18.input_layernorm.bias',\
          \ 'transformer.h.28.input_layernorm.bias', 'transformer.h.7.input_layernorm.bias',\
          \ 'transformer.h.5.input_layernorm.weight', 'transformer.h.8.input_layernorm.weight',\
          \ 'transformer.h.0.input_layernorm.weight', 'transformer.h.9.input_layernorm.bias',\
          \ 'transformer.h.12.input_layernorm.weight', 'transformer.h.19.input_layernorm.weight',\
          \ 'transformer.h.30.input_layernorm.bias', 'transformer.h.31.input_layernorm.weight',\
          \ 'transformer.h.6.input_layernorm.bias', 'transformer.h.7.input_layernorm.weight',\
          \ 'transformer.h.6.input_layernorm.weight', 'transformer.ln_f.weight', 'transformer.h.5.input_layernorm.bias',\
          \ 'transformer.h.13.input_layernorm.weight', 'transformer.h.13.input_layernorm.bias',\
          \ 'transformer.h.30.input_layernorm.weight', 'transformer.h.19.input_layernorm.bias',\
          \ 'transformer.h.18.input_layernorm.weight', 'transformer.h.16.input_layernorm.bias',\
          \ 'transformer.h.27.input_layernorm.bias', 'transformer.h.21.input_layernorm.weight',\
          \ 'transformer.h.14.input_layernorm.weight', 'transformer.h.16.input_layernorm.weight',\
          \ 'transformer.h.10.input_layernorm.bias', 'transformer.h.25.input_layernorm.bias',\
          \ 'transformer.h.23.input_layernorm.bias', 'transformer.h.29.input_layernorm.weight',\
          \ 'transformer.h.11.input_layernorm.weight', 'transformer.h.3.input_layernorm.bias',\
          \ 'transformer.ln_f.bias', 'transformer.h.22.input_layernorm.weight', 'transformer.h.28.input_layernorm.weight',\
          \ 'transformer.h.0.input_layernorm.bias', 'transformer.h.1.input_layernorm.weight',\
          \ 'transformer.h.14.input_layernorm.bias', 'transformer.h.24.input_layernorm.bias',\
          \ 'transformer.h.8.input_layernorm.bias', 'transformer.h.21.input_layernorm.bias',\
          \ 'transformer.h.10.input_layernorm.weight', 'transformer.h.12.input_layernorm.bias',\
          \ 'transformer.h.27.input_layernorm.weight', 'transformer.h.31.input_layernorm.bias',\
          \ 'transformer.h.11.input_layernorm.bias', 'transformer.h.23.input_layernorm.weight',\
          \ 'transformer.h.26.input_layernorm.bias', 'transformer.h.29.input_layernorm.bias',\
          \ 'transformer.h.15.input_layernorm.bias', 'transformer.h.2.input_layernorm.weight',\
          \ 'transformer.h.2.input_layernorm.bias', 'transformer.h.24.input_layernorm.weight',\
          \ 'transformer.h.4.input_layernorm.weight', 'transformer.h.26.input_layernorm.weight',\
          \ 'transformer.h.15.input_layernorm.weight', 'transformer.h.4.input_layernorm.bias',\
          \ 'transformer.h.9.input_layernorm.weight', 'transformer.h.25.input_layernorm.weight',\
          \ 'transformer.h.3.input_layernorm.weight', 'transformer.h.17.input_layernorm.weight'}].\n\
          \            A potential way to correctly save your model is to use `save_model`.\n\
          \            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n\
          </code></pre>\n"
        raw: "Hello!\r\n\r\nI'm trying to deploy this model on AWS SageMaker by following\
          \ the steps provided in the documentation. However, I'm encountering some\
          \ errors during the endpoint creation process. I've double-checked my configurations,\
          \ but the issues persist.\r\n\r\nIf anyone has experience deploying this\
          \ model on AWS SageMaker or any insights into resolving similar errors,\
          \ I'd greatly appreciate your help. Thanks in advance for any assistance\
          \ you can offer!\r\n\r\nErrors:\r\n````\r\nError: DownloadError\r\n    utils.convert_files(local_pt_files,\
          \ local_st_files)\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/convert.py\"\
          , line 84, in convert_files\r\n    convert_file(pt_file, sf_file)\r\n  File\
          \ \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/convert.py\"\
          , line 62, in convert_file\r\n    save_file(pt_state, str(sf_file), metadata={\r\
          \n    \"format\": \"pt\"\r\n})\r\n  File \"/opt/conda/lib/python3.9/site-packages/safetensors/torch.py\"\
          , line 232, in save_file\r\n    serialize_file(_flatten(tensors), filename,\
          \ metadata=metadata)\r\n  File \"/opt/conda/lib/python3.9/site-packages/safetensors/torch.py\"\
          , line 394, in _flatten\r\n    raise RuntimeError(\r\n````\r\n\r\nAnd the\
          \ following error:\r\n````\r\nRuntimeError: \r\n            Some tensors\
          \ share memory, this will lead to duplicate memory on disk and potential\
          \ differences when loading them again: [{'transformer.h.6.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.26.mlp.dense_4h_to_h.weight', 'transformer.h.4.self_attention.query_key_value.weight',\
          \ 'transformer.h.22.mlp.dense_h_to_4h.weight', 'transformer.h.23.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.5.mlp.dense_h_to_4h.weight', 'transformer.h.25.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.25.mlp.dense_4h_to_h.weight', 'transformer.h.0.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.11.mlp.dense_h_to_4h.weight', 'transformer.h.29.self_attention.dense.weight',\
          \ 'transformer.h.24.self_attention.query_key_value.weight', 'transformer.h.24.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.14.mlp.dense_4h_to_h.weight', 'transformer.h.1.self_attention.dense.weight',\
          \ 'transformer.h.13.mlp.dense_4h_to_h.weight', 'transformer.h.8.self_attention.query_key_value.weight',\
          \ 'transformer.h.20.self_attention.query_key_value.weight', 'transformer.h.27.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.22.self_attention.query_key_value.weight', 'transformer.h.11.self_attention.query_key_value.weight',\
          \ 'transformer.h.23.self_attention.query_key_value.weight', 'transformer.h.13.self_attention.dense.weight',\
          \ 'transformer.h.15.mlp.dense_h_to_4h.weight', 'transformer.h.9.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.15.self_attention.query_key_value.weight', 'transformer.h.24.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.31.self_attention.query_key_value.weight', 'transformer.h.7.self_attention.dense.weight',\
          \ 'transformer.h.27.self_attention.query_key_value.weight', 'transformer.h.1.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.21.mlp.dense_4h_to_h.weight', 'transformer.h.24.self_attention.dense.weight',\
          \ 'transformer.h.16.mlp.dense_4h_to_h.weight', 'transformer.h.20.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.27.self_attention.dense.weight', 'transformer.h.4.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.3.mlp.dense_h_to_4h.weight', 'transformer.h.25.self_attention.dense.weight',\
          \ 'transformer.h.7.mlp.dense_4h_to_h.weight', 'transformer.h.17.self_attention.query_key_value.weight',\
          \ 'transformer.h.19.self_attention.dense.weight', 'transformer.h.12.self_attention.query_key_value.weight',\
          \ 'transformer.h.3.self_attention.dense.weight', 'transformer.h.28.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.19.mlp.dense_h_to_4h.weight', 'transformer.h.20.self_attention.dense.weight',\
          \ 'transformer.h.14.self_attention.query_key_value.weight', 'transformer.h.21.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.12.mlp.dense_h_to_4h.weight', 'transformer.h.29.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.6.mlp.dense_h_to_4h.weight', 'transformer.h.14.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.30.self_attention.dense.weight', 'transformer.h.10.self_attention.query_key_value.weight',\
          \ 'transformer.h.6.self_attention.query_key_value.weight', 'transformer.h.10.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.23.mlp.dense_4h_to_h.weight', 'transformer.h.21.self_attention.query_key_value.weight',\
          \ 'transformer.h.30.self_attention.query_key_value.weight', 'transformer.h.8.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.30.mlp.dense_h_to_4h.weight', 'transformer.h.18.self_attention.query_key_value.weight',\
          \ 'transformer.h.5.mlp.dense_4h_to_h.weight', 'transformer.h.15.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.26.self_attention.dense.weight', 'transformer.h.9.self_attention.query_key_value.weight',\
          \ 'transformer.h.17.mlp.dense_4h_to_h.weight', 'transformer.h.10.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.6.self_attention.dense.weight', 'transformer.h.2.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.5.self_attention.dense.weight', 'transformer.h.9.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.3.mlp.dense_4h_to_h.weight', 'transformer.h.17.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.27.mlp.dense_4h_to_h.weight', 'transformer.h.29.self_attention.query_key_value.weight',\
          \ 'transformer.h.5.self_attention.query_key_value.weight', 'transformer.h.11.self_attention.dense.weight',\
          \ 'transformer.h.19.mlp.dense_4h_to_h.weight', 'transformer.h.16.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.8.mlp.dense_4h_to_h.weight', 'transformer.h.30.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.31.mlp.dense_h_to_4h.weight', 'transformer.h.1.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.28.self_attention.dense.weight', 'transformer.h.22.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.31.self_attention.dense.weight', 'transformer.h.4.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.19.self_attention.query_key_value.weight', 'transformer.h.0.self_attention.dense.weight',\
          \ 'transformer.h.1.self_attention.query_key_value.weight', 'transformer.h.17.self_attention.dense.weight',\
          \ 'transformer.h.18.self_attention.dense.weight', 'transformer.h.23.self_attention.dense.weight',\
          \ 'transformer.h.28.self_attention.query_key_value.weight', 'transformer.h.12.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.16.self_attention.query_key_value.weight', 'transformer.h.22.self_attention.dense.weight',\
          \ 'transformer.h.18.mlp.dense_4h_to_h.weight', 'transformer.h.2.self_attention.query_key_value.weight',\
          \ 'transformer.h.18.mlp.dense_h_to_4h.weight', 'transformer.h.8.self_attention.dense.weight',\
          \ 'transformer.h.12.self_attention.dense.weight', 'transformer.h.29.mlp.dense_4h_to_h.weight',\
          \ 'transformer.h.10.self_attention.dense.weight', 'transformer.h.26.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.31.mlp.dense_4h_to_h.weight', 'transformer.h.3.self_attention.query_key_value.weight',\
          \ 'transformer.h.16.self_attention.dense.weight', 'transformer.h.9.self_attention.dense.weight',\
          \ 'transformer.h.21.self_attention.dense.weight', 'transformer.h.0.self_attention.query_key_value.weight',\
          \ 'transformer.h.28.mlp.dense_4h_to_h.weight', 'transformer.word_embeddings.weight',\
          \ 'transformer.h.0.mlp.dense_h_to_4h.weight', 'transformer.h.4.self_attention.dense.weight',\
          \ 'transformer.h.13.self_attention.query_key_value.weight', 'transformer.h.7.mlp.dense_h_to_4h.weight',\
          \ 'transformer.h.2.mlp.dense_h_to_4h.weight', 'transformer.h.7.self_attention.query_key_value.weight',\
          \ 'transformer.h.11.mlp.dense_4h_to_h.weight', 'transformer.h.2.self_attention.dense.weight',\
          \ 'transformer.h.13.mlp.dense_h_to_4h.weight', 'transformer.h.14.self_attention.dense.weight',\
          \ 'transformer.h.15.self_attention.dense.weight', 'transformer.h.25.self_attention.query_key_value.weight',\
          \ 'transformer.h.26.self_attention.query_key_value.weight', 'transformer.h.20.mlp.dense_h_to_4h.weight'},\
          \ {'transformer.h.22.input_layernorm.bias', 'transformer.h.17.input_layernorm.bias',\
          \ 'transformer.h.20.input_layernorm.weight', 'transformer.h.20.input_layernorm.bias',\
          \ 'transformer.h.1.input_layernorm.bias', 'transformer.h.18.input_layernorm.bias',\
          \ 'transformer.h.28.input_layernorm.bias', 'transformer.h.7.input_layernorm.bias',\
          \ 'transformer.h.5.input_layernorm.weight', 'transformer.h.8.input_layernorm.weight',\
          \ 'transformer.h.0.input_layernorm.weight', 'transformer.h.9.input_layernorm.bias',\
          \ 'transformer.h.12.input_layernorm.weight', 'transformer.h.19.input_layernorm.weight',\
          \ 'transformer.h.30.input_layernorm.bias', 'transformer.h.31.input_layernorm.weight',\
          \ 'transformer.h.6.input_layernorm.bias', 'transformer.h.7.input_layernorm.weight',\
          \ 'transformer.h.6.input_layernorm.weight', 'transformer.ln_f.weight', 'transformer.h.5.input_layernorm.bias',\
          \ 'transformer.h.13.input_layernorm.weight', 'transformer.h.13.input_layernorm.bias',\
          \ 'transformer.h.30.input_layernorm.weight', 'transformer.h.19.input_layernorm.bias',\
          \ 'transformer.h.18.input_layernorm.weight', 'transformer.h.16.input_layernorm.bias',\
          \ 'transformer.h.27.input_layernorm.bias', 'transformer.h.21.input_layernorm.weight',\
          \ 'transformer.h.14.input_layernorm.weight', 'transformer.h.16.input_layernorm.weight',\
          \ 'transformer.h.10.input_layernorm.bias', 'transformer.h.25.input_layernorm.bias',\
          \ 'transformer.h.23.input_layernorm.bias', 'transformer.h.29.input_layernorm.weight',\
          \ 'transformer.h.11.input_layernorm.weight', 'transformer.h.3.input_layernorm.bias',\
          \ 'transformer.ln_f.bias', 'transformer.h.22.input_layernorm.weight', 'transformer.h.28.input_layernorm.weight',\
          \ 'transformer.h.0.input_layernorm.bias', 'transformer.h.1.input_layernorm.weight',\
          \ 'transformer.h.14.input_layernorm.bias', 'transformer.h.24.input_layernorm.bias',\
          \ 'transformer.h.8.input_layernorm.bias', 'transformer.h.21.input_layernorm.bias',\
          \ 'transformer.h.10.input_layernorm.weight', 'transformer.h.12.input_layernorm.bias',\
          \ 'transformer.h.27.input_layernorm.weight', 'transformer.h.31.input_layernorm.bias',\
          \ 'transformer.h.11.input_layernorm.bias', 'transformer.h.23.input_layernorm.weight',\
          \ 'transformer.h.26.input_layernorm.bias', 'transformer.h.29.input_layernorm.bias',\
          \ 'transformer.h.15.input_layernorm.bias', 'transformer.h.2.input_layernorm.weight',\
          \ 'transformer.h.2.input_layernorm.bias', 'transformer.h.24.input_layernorm.weight',\
          \ 'transformer.h.4.input_layernorm.weight', 'transformer.h.26.input_layernorm.weight',\
          \ 'transformer.h.15.input_layernorm.weight', 'transformer.h.4.input_layernorm.bias',\
          \ 'transformer.h.9.input_layernorm.weight', 'transformer.h.25.input_layernorm.weight',\
          \ 'transformer.h.3.input_layernorm.weight', 'transformer.h.17.input_layernorm.weight'}].\r\
          \n            A potential way to correctly save your model is to use `save_model`.\r\
          \n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\r\
          \n````"
        updatedAt: '2023-07-19T10:57:34.970Z'
      numEdits: 0
      reactions: []
    id: 64b7c19ef72c6cd946dfab6c
    type: comment
  author: cnicu
  content: "Hello!\r\n\r\nI'm trying to deploy this model on AWS SageMaker by following\
    \ the steps provided in the documentation. However, I'm encountering some errors\
    \ during the endpoint creation process. I've double-checked my configurations,\
    \ but the issues persist.\r\n\r\nIf anyone has experience deploying this model\
    \ on AWS SageMaker or any insights into resolving similar errors, I'd greatly\
    \ appreciate your help. Thanks in advance for any assistance you can offer!\r\n\
    \r\nErrors:\r\n````\r\nError: DownloadError\r\n    utils.convert_files(local_pt_files,\
    \ local_st_files)\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/convert.py\"\
    , line 84, in convert_files\r\n    convert_file(pt_file, sf_file)\r\n  File \"\
    /opt/conda/lib/python3.9/site-packages/text_generation_server/utils/convert.py\"\
    , line 62, in convert_file\r\n    save_file(pt_state, str(sf_file), metadata={\r\
    \n    \"format\": \"pt\"\r\n})\r\n  File \"/opt/conda/lib/python3.9/site-packages/safetensors/torch.py\"\
    , line 232, in save_file\r\n    serialize_file(_flatten(tensors), filename, metadata=metadata)\r\
    \n  File \"/opt/conda/lib/python3.9/site-packages/safetensors/torch.py\", line\
    \ 394, in _flatten\r\n    raise RuntimeError(\r\n````\r\n\r\nAnd the following\
    \ error:\r\n````\r\nRuntimeError: \r\n            Some tensors share memory, this\
    \ will lead to duplicate memory on disk and potential differences when loading\
    \ them again: [{'transformer.h.6.mlp.dense_4h_to_h.weight', 'transformer.h.26.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.4.self_attention.query_key_value.weight', 'transformer.h.22.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.23.mlp.dense_h_to_4h.weight', 'transformer.h.5.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.25.mlp.dense_h_to_4h.weight', 'transformer.h.25.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.0.mlp.dense_4h_to_h.weight', 'transformer.h.11.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.29.self_attention.dense.weight', 'transformer.h.24.self_attention.query_key_value.weight',\
    \ 'transformer.h.24.mlp.dense_h_to_4h.weight', 'transformer.h.14.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.1.self_attention.dense.weight', 'transformer.h.13.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.8.self_attention.query_key_value.weight', 'transformer.h.20.self_attention.query_key_value.weight',\
    \ 'transformer.h.27.mlp.dense_h_to_4h.weight', 'transformer.h.22.self_attention.query_key_value.weight',\
    \ 'transformer.h.11.self_attention.query_key_value.weight', 'transformer.h.23.self_attention.query_key_value.weight',\
    \ 'transformer.h.13.self_attention.dense.weight', 'transformer.h.15.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.9.mlp.dense_h_to_4h.weight', 'transformer.h.15.self_attention.query_key_value.weight',\
    \ 'transformer.h.24.mlp.dense_4h_to_h.weight', 'transformer.h.31.self_attention.query_key_value.weight',\
    \ 'transformer.h.7.self_attention.dense.weight', 'transformer.h.27.self_attention.query_key_value.weight',\
    \ 'transformer.h.1.mlp.dense_h_to_4h.weight', 'transformer.h.21.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.24.self_attention.dense.weight', 'transformer.h.16.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.20.mlp.dense_4h_to_h.weight', 'transformer.h.27.self_attention.dense.weight',\
    \ 'transformer.h.4.mlp.dense_4h_to_h.weight', 'transformer.h.3.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.25.self_attention.dense.weight', 'transformer.h.7.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.17.self_attention.query_key_value.weight', 'transformer.h.19.self_attention.dense.weight',\
    \ 'transformer.h.12.self_attention.query_key_value.weight', 'transformer.h.3.self_attention.dense.weight',\
    \ 'transformer.h.28.mlp.dense_h_to_4h.weight', 'transformer.h.19.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.20.self_attention.dense.weight', 'transformer.h.14.self_attention.query_key_value.weight',\
    \ 'transformer.h.21.mlp.dense_h_to_4h.weight', 'transformer.h.12.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.29.mlp.dense_h_to_4h.weight', 'transformer.h.6.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.14.mlp.dense_h_to_4h.weight', 'transformer.h.30.self_attention.dense.weight',\
    \ 'transformer.h.10.self_attention.query_key_value.weight', 'transformer.h.6.self_attention.query_key_value.weight',\
    \ 'transformer.h.10.mlp.dense_4h_to_h.weight', 'transformer.h.23.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.21.self_attention.query_key_value.weight', 'transformer.h.30.self_attention.query_key_value.weight',\
    \ 'transformer.h.8.mlp.dense_h_to_4h.weight', 'transformer.h.30.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.18.self_attention.query_key_value.weight', 'transformer.h.5.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.15.mlp.dense_4h_to_h.weight', 'transformer.h.26.self_attention.dense.weight',\
    \ 'transformer.h.9.self_attention.query_key_value.weight', 'transformer.h.17.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.10.mlp.dense_h_to_4h.weight', 'transformer.h.6.self_attention.dense.weight',\
    \ 'transformer.h.2.mlp.dense_4h_to_h.weight', 'transformer.h.5.self_attention.dense.weight',\
    \ 'transformer.h.9.mlp.dense_4h_to_h.weight', 'transformer.h.3.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.17.mlp.dense_h_to_4h.weight', 'transformer.h.27.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.29.self_attention.query_key_value.weight', 'transformer.h.5.self_attention.query_key_value.weight',\
    \ 'transformer.h.11.self_attention.dense.weight', 'transformer.h.19.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.16.mlp.dense_h_to_4h.weight', 'transformer.h.8.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.30.mlp.dense_4h_to_h.weight', 'transformer.h.31.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.1.mlp.dense_4h_to_h.weight', 'transformer.h.28.self_attention.dense.weight',\
    \ 'transformer.h.22.mlp.dense_4h_to_h.weight', 'transformer.h.31.self_attention.dense.weight',\
    \ 'transformer.h.4.mlp.dense_h_to_4h.weight', 'transformer.h.19.self_attention.query_key_value.weight',\
    \ 'transformer.h.0.self_attention.dense.weight', 'transformer.h.1.self_attention.query_key_value.weight',\
    \ 'transformer.h.17.self_attention.dense.weight', 'transformer.h.18.self_attention.dense.weight',\
    \ 'transformer.h.23.self_attention.dense.weight', 'transformer.h.28.self_attention.query_key_value.weight',\
    \ 'transformer.h.12.mlp.dense_4h_to_h.weight', 'transformer.h.16.self_attention.query_key_value.weight',\
    \ 'transformer.h.22.self_attention.dense.weight', 'transformer.h.18.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.2.self_attention.query_key_value.weight', 'transformer.h.18.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.8.self_attention.dense.weight', 'transformer.h.12.self_attention.dense.weight',\
    \ 'transformer.h.29.mlp.dense_4h_to_h.weight', 'transformer.h.10.self_attention.dense.weight',\
    \ 'transformer.h.26.mlp.dense_h_to_4h.weight', 'transformer.h.31.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.3.self_attention.query_key_value.weight', 'transformer.h.16.self_attention.dense.weight',\
    \ 'transformer.h.9.self_attention.dense.weight', 'transformer.h.21.self_attention.dense.weight',\
    \ 'transformer.h.0.self_attention.query_key_value.weight', 'transformer.h.28.mlp.dense_4h_to_h.weight',\
    \ 'transformer.word_embeddings.weight', 'transformer.h.0.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.4.self_attention.dense.weight', 'transformer.h.13.self_attention.query_key_value.weight',\
    \ 'transformer.h.7.mlp.dense_h_to_4h.weight', 'transformer.h.2.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.7.self_attention.query_key_value.weight', 'transformer.h.11.mlp.dense_4h_to_h.weight',\
    \ 'transformer.h.2.self_attention.dense.weight', 'transformer.h.13.mlp.dense_h_to_4h.weight',\
    \ 'transformer.h.14.self_attention.dense.weight', 'transformer.h.15.self_attention.dense.weight',\
    \ 'transformer.h.25.self_attention.query_key_value.weight', 'transformer.h.26.self_attention.query_key_value.weight',\
    \ 'transformer.h.20.mlp.dense_h_to_4h.weight'}, {'transformer.h.22.input_layernorm.bias',\
    \ 'transformer.h.17.input_layernorm.bias', 'transformer.h.20.input_layernorm.weight',\
    \ 'transformer.h.20.input_layernorm.bias', 'transformer.h.1.input_layernorm.bias',\
    \ 'transformer.h.18.input_layernorm.bias', 'transformer.h.28.input_layernorm.bias',\
    \ 'transformer.h.7.input_layernorm.bias', 'transformer.h.5.input_layernorm.weight',\
    \ 'transformer.h.8.input_layernorm.weight', 'transformer.h.0.input_layernorm.weight',\
    \ 'transformer.h.9.input_layernorm.bias', 'transformer.h.12.input_layernorm.weight',\
    \ 'transformer.h.19.input_layernorm.weight', 'transformer.h.30.input_layernorm.bias',\
    \ 'transformer.h.31.input_layernorm.weight', 'transformer.h.6.input_layernorm.bias',\
    \ 'transformer.h.7.input_layernorm.weight', 'transformer.h.6.input_layernorm.weight',\
    \ 'transformer.ln_f.weight', 'transformer.h.5.input_layernorm.bias', 'transformer.h.13.input_layernorm.weight',\
    \ 'transformer.h.13.input_layernorm.bias', 'transformer.h.30.input_layernorm.weight',\
    \ 'transformer.h.19.input_layernorm.bias', 'transformer.h.18.input_layernorm.weight',\
    \ 'transformer.h.16.input_layernorm.bias', 'transformer.h.27.input_layernorm.bias',\
    \ 'transformer.h.21.input_layernorm.weight', 'transformer.h.14.input_layernorm.weight',\
    \ 'transformer.h.16.input_layernorm.weight', 'transformer.h.10.input_layernorm.bias',\
    \ 'transformer.h.25.input_layernorm.bias', 'transformer.h.23.input_layernorm.bias',\
    \ 'transformer.h.29.input_layernorm.weight', 'transformer.h.11.input_layernorm.weight',\
    \ 'transformer.h.3.input_layernorm.bias', 'transformer.ln_f.bias', 'transformer.h.22.input_layernorm.weight',\
    \ 'transformer.h.28.input_layernorm.weight', 'transformer.h.0.input_layernorm.bias',\
    \ 'transformer.h.1.input_layernorm.weight', 'transformer.h.14.input_layernorm.bias',\
    \ 'transformer.h.24.input_layernorm.bias', 'transformer.h.8.input_layernorm.bias',\
    \ 'transformer.h.21.input_layernorm.bias', 'transformer.h.10.input_layernorm.weight',\
    \ 'transformer.h.12.input_layernorm.bias', 'transformer.h.27.input_layernorm.weight',\
    \ 'transformer.h.31.input_layernorm.bias', 'transformer.h.11.input_layernorm.bias',\
    \ 'transformer.h.23.input_layernorm.weight', 'transformer.h.26.input_layernorm.bias',\
    \ 'transformer.h.29.input_layernorm.bias', 'transformer.h.15.input_layernorm.bias',\
    \ 'transformer.h.2.input_layernorm.weight', 'transformer.h.2.input_layernorm.bias',\
    \ 'transformer.h.24.input_layernorm.weight', 'transformer.h.4.input_layernorm.weight',\
    \ 'transformer.h.26.input_layernorm.weight', 'transformer.h.15.input_layernorm.weight',\
    \ 'transformer.h.4.input_layernorm.bias', 'transformer.h.9.input_layernorm.weight',\
    \ 'transformer.h.25.input_layernorm.weight', 'transformer.h.3.input_layernorm.weight',\
    \ 'transformer.h.17.input_layernorm.weight'}].\r\n            A potential way\
    \ to correctly save your model is to use `save_model`.\r\n            More information\
    \ at https://huggingface.co/docs/safetensors/torch_shared_tensors\r\n````"
  created_at: 2023-07-19 09:57:34+00:00
  edited: false
  hidden: false
  id: 64b7c19ef72c6cd946dfab6c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5bdcae1bdefcab9821dc378699a18bd8.svg
      fullname: Joan Llop Palao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: joanllop
      type: user
    createdAt: '2023-07-19T17:51:39.000Z'
    data:
      edited: true
      editors:
      - joanllop
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9507408142089844
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5bdcae1bdefcab9821dc378699a18bd8.svg
          fullname: Joan Llop Palao
          isHf: false
          isPro: false
          name: joanllop
          type: user
        html: '<p>Hi!</p>

          <p>The error is related to safetensors, We have uploaded safetensors, but
          we still having some trouble with the text-generation-inference container,
          so it might still fail.</p>

          <p>Sorry for the inconvenience, We hope to fix it soon.</p>

          '
        raw: 'Hi!


          The error is related to safetensors, We have uploaded safetensors, but we
          still having some trouble with the text-generation-inference container,
          so it might still fail.


          Sorry for the inconvenience, We hope to fix it soon.'
        updatedAt: '2023-07-19T17:52:09.929Z'
      numEdits: 1
      reactions: []
    id: 64b822abd6ced0fd74a30fd1
    type: comment
  author: joanllop
  content: 'Hi!


    The error is related to safetensors, We have uploaded safetensors, but we still
    having some trouble with the text-generation-inference container, so it might
    still fail.


    Sorry for the inconvenience, We hope to fix it soon.'
  created_at: 2023-07-19 16:51:39+00:00
  edited: true
  hidden: false
  id: 64b822abd6ced0fd74a30fd1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5bdcae1bdefcab9821dc378699a18bd8.svg
      fullname: Joan Llop Palao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: joanllop
      type: user
    createdAt: '2023-07-20T11:43:35.000Z'
    data:
      edited: false
      editors:
      - joanllop
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.855770468711853
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5bdcae1bdefcab9821dc378699a18bd8.svg
          fullname: Joan Llop Palao
          isHf: false
          isPro: false
          name: joanllop
          type: user
        html: '<p>Hi!</p>

          <p>Everything should work now :-)<br>We have tested with v0.9.3 of the text-generation-inference.</p>

          <p>Sorry for the delay,<br>Best regards,<br>Joan</p>

          '
        raw: 'Hi!


          Everything should work now :-)

          We have tested with v0.9.3 of the text-generation-inference.


          Sorry for the delay,

          Best regards,

          Joan'
        updatedAt: '2023-07-20T11:43:35.848Z'
      numEdits: 0
      reactions: []
    id: 64b91de7126cfeb8fddf7d78
    type: comment
  author: joanllop
  content: 'Hi!


    Everything should work now :-)

    We have tested with v0.9.3 of the text-generation-inference.


    Sorry for the delay,

    Best regards,

    Joan'
  created_at: 2023-07-20 10:43:35+00:00
  edited: false
  hidden: false
  id: 64b91de7126cfeb8fddf7d78
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/5bdcae1bdefcab9821dc378699a18bd8.svg
      fullname: Joan Llop Palao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: joanllop
      type: user
    createdAt: '2023-07-20T12:52:48.000Z'
    data:
      status: closed
    id: 64b92e20cf14c2fabeaa58c4
    type: status-change
  author: joanllop
  created_at: 2023-07-20 11:52:48+00:00
  id: 64b92e20cf14c2fabeaa58c4
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: projecte-aina/aguila-7b
repo_type: model
status: closed
target_branch: null
title: Error deploying Aguila on AWS SageMaker
