!!python/object:huggingface_hub.community.DiscussionWithDetails
author: fkov
conflicting_files: null
created_at: 2023-07-03 07:44:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a17e6120a0e504c9d8e95147efaadb7.svg
      fullname: FK
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fkov
      type: user
    createdAt: '2023-07-03T08:44:30.000Z'
    data:
      edited: false
      editors:
      - fkov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8291016817092896
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a17e6120a0e504c9d8e95147efaadb7.svg
          fullname: FK
          isHf: false
          isPro: false
          name: fkov
          type: user
        html: "<p>hi <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ , may you provide specs for setting up your environment for pytorch+deepspeed+transformers\
          \ (for cluster if you had that), please ?</p>\n<p>I keep getting the error:<br>NotADirectoryError:\
          \ [Errno 20] Not a directory: 'hipconfig'</p>\n"
        raw: "hi @sanchit-gandhi , may you provide specs for setting up your environment\
          \ for pytorch+deepspeed+transformers (for cluster if you had that), please\
          \ ?\r\n\r\n\r\nI keep getting the error:\r\nNotADirectoryError: [Errno 20]\
          \ Not a directory: 'hipconfig'"
        updatedAt: '2023-07-03T08:44:30.656Z'
      numEdits: 0
      reactions: []
    id: 64a28a6e04ddc5c3c6eacf8e
    type: comment
  author: fkov
  content: "hi @sanchit-gandhi , may you provide specs for setting up your environment\
    \ for pytorch+deepspeed+transformers (for cluster if you had that), please ?\r\
    \n\r\n\r\nI keep getting the error:\r\nNotADirectoryError: [Errno 20] Not a directory:\
    \ 'hipconfig'"
  created_at: 2023-07-03 07:44:30+00:00
  edited: false
  hidden: false
  id: 64a28a6e04ddc5c3c6eacf8e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-07-03T16:00:42.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8183485865592957
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;fkov&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/fkov\">@<span class=\"\
          underline\">fkov</span></a></span>\n\n\t</span></span> - this was done on\
          \ a vanilla Google GCP T4, see framework info here: <a href=\"https://huggingface.co/sanchit-gandhi/whisper-medium-fleurs-lang-id#framework-versions\"\
          >https://huggingface.co/sanchit-gandhi/whisper-medium-fleurs-lang-id#framework-versions</a></p>\n\
          <p>To set-up, I just pip installed PyTorch (following the <a rel=\"nofollow\"\
          \ href=\"https://pytorch.org/get-started/locally/\">local installation instructions</a>)\
          \ + DeepSpeed, and installed transformers from main. Could you share the\
          \ full stack trace for your error please?</p>\n"
        raw: 'Hey @fkov - this was done on a vanilla Google GCP T4, see framework
          info here: https://huggingface.co/sanchit-gandhi/whisper-medium-fleurs-lang-id#framework-versions


          To set-up, I just pip installed PyTorch (following the [local installation
          instructions](https://pytorch.org/get-started/locally/)) + DeepSpeed, and
          installed transformers from main. Could you share the full stack trace for
          your error please?'
        updatedAt: '2023-07-03T16:00:42.346Z'
      numEdits: 0
      reactions: []
    id: 64a2f0aa97ef81b3009ebd63
    type: comment
  author: sanchit-gandhi
  content: 'Hey @fkov - this was done on a vanilla Google GCP T4, see framework info
    here: https://huggingface.co/sanchit-gandhi/whisper-medium-fleurs-lang-id#framework-versions


    To set-up, I just pip installed PyTorch (following the [local installation instructions](https://pytorch.org/get-started/locally/))
    + DeepSpeed, and installed transformers from main. Could you share the full stack
    trace for your error please?'
  created_at: 2023-07-03 15:00:42+00:00
  edited: false
  hidden: false
  id: 64a2f0aa97ef81b3009ebd63
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a17e6120a0e504c9d8e95147efaadb7.svg
      fullname: FK
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fkov
      type: user
    createdAt: '2023-07-07T13:25:46.000Z'
    data:
      edited: true
      editors:
      - fkov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.44192373752593994
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a17e6120a0e504c9d8e95147efaadb7.svg
          fullname: FK
          isHf: false
          isPro: false
          name: fkov
          type: user
        html: "<p>I tried with </p>\n<p><em>GPU: NVIDIA A100-SXM4-40GB</em></p>\n\
          <p>1.<br><code>https://pytorch.org/get-started/locally/: Stable(2.0.1),\
          \ Linux, Conda, Python, Cuda 11.8:  conda install pytorch torchvision torchaudio\
          \ pytorch-cuda=11.8 -c pytorch -c nvidia</code></p>\n<p>2.<br><code>transformers\
          \ version: 4.31.0.dev0 (from source using git clone https://github.com/huggingface/transformers\
          \ ) cd transformers pip install . pip install -r /home/fkov/transformers/examples/pytorch/audio-classification/requirements.txt</code></p>\n\
          <p>3.<br><code>git clone https://github.com/microsoft/DeepSpeed/ cd DeepSpeed\
          \ rm -rf build TORCH_CUDA_ARCH_LIST=\u201C8.0\u201D DS_BUILD_CPU_ADAM=1\
          \ DS_BUILD_UTILS=1; python setup.py build_ext -j8 bdist_wheel pip install\
          \ . </code></p>\n<p>ERROR is: </p>\n<p><code>Using /home/fkov/.cache/torch_extensions/py311_cu118\
          \ as PyTorch extensions root... Detected CUDA files, patching ldflags Emitting\
          \ ninja build file /home/fkov/.cache/torch_extensions/py311_cu118/cpu_adam/build.ninja...\
          \ Building extension module cpu_adam... Allowing ninja to set a default\
          \ number of workers... (overridable by setting the environment variable\
          \ MAX_JOBS=N)</code></p>\n<details>\n<summary>\u2026</summary>\n\n<p>[1/2]\
          \ /usr/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H\
          \ -DPYBIND11_COMPILER_TYPE=\"<em>gcc\" -DPYBIND11_STDLIB=\"<em>libstdcpp\"\
          \ -DPYBIND11_BUILD_ABI=\"<em>cxxabi1011\" -I/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/includes\
          \ -I/usr/include -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/torch/csrc/api/include\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/TH\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/THC\
          \ -isystem /home/fkov/.conda/envs/ws/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0\
          \ -D__CUDA_NO_HALF_OPERATORS</em></em> -D__CUDA_NO_HALF_CONVERSIONS</em>_\
          \ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr\
          \ -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80\
          \ --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__\
          \ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80\
          \ -gencode=arch=compute_80,code=compute_80 -DBF16_AVAILABLE -c /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu\
          \ -o custom_cuda_kernel.cuda.o </p>\n</details>\n\n<blockquote>\n<p>FAILED:\
          \ custom_cuda_kernel.cuda.o </p>\n</blockquote>\n<details>\n<summary>/usr/bin/nvcc</summary>\n\
          \n<p>/usr/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H\
          \ -DPYBIND11_COMPILER_TYPE=\"<em>gcc\" -DPYBIND11_STDLIB=\"<em>libstdcpp\"\
          \ -DPYBIND11_BUILD_ABI=\"<em>cxxabi1011\" -I/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/includes\
          \ -I/usr/include -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/torch/csrc/api/include\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/TH\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/THC\
          \ -isystem /home/fkov/.conda/envs/ws/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0\
          \ -D__CUDA_NO_HALF_OPERATORS</em></em> -D__CUDA_NO_HALF_CONVERSIONS</em>_\
          \ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr\
          \ -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80\
          \ --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__\
          \ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80\
          \ -gencode=arch=compute_80,code=compute_80 -DBF16_AVAILABLE -c /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu\
          \ -o custom_cuda_kernel.cuda.o </p>\n</details>\n\n<blockquote>\n<p>ERROR:\
          \ No supported gcc/g++ host compiler found.<br>       Use 'nvcc -ccbin '\
          \ to specify a host compiler.</p>\n</blockquote>\n<p><code>ninja: build\
          \ stopped: subcommand failed. Traceback (most recent call last):   File\
          \ \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
          , line 1893, in _run_ninja_build     subprocess.run(   File \"/home/fkov/.conda/envs/ws/lib/python3.11/subprocess.py\"\
          , line 571, in run     raise CalledProcessError(retcode, process.args, subprocess.CalledProcessError:\
          \ Command '['ninja', '-v']' returned non-zero exit status 1.</code></p>\n\
          <details>\n<summary>The above exception was the direct cause of the following\
          \ exception:</summary>\n\n\n<p>Traceback (most recent call last):<br>  File\
          \ \"/home/fkov/transformers/examples/pytorch/audio-classification/run_audio_classification_w.py\"\
          , line 51, in <br>    deepspeed.ops.op_builder.CPUAdamBuilder().load()<br>\
          \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py\"\
          , line 454, in load<br>    return self.jit_load(verbose)<br>           ^^^^^^^^^^^^^^^^^^^^^^<br>\
          \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py\"\
          , line 497, in jit_load<br>    op_module = load(name=self.name,<br>    \
          \            ^^^^^^^^^^^^^^^^^^^^<br>  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
          , line 1284, in load<br>    return _jit_compile(<br>           ^^^^^^^^^^^^^<br>\
          \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
          , line 1509, in _jit_compile<br>    _write_ninja_file_and_build_library(<br>\
          \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
          , line 1624, in _write_ninja_file_and_build_library<br>    _run_ninja_build(<br>\
          \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
          , line 1909, in _run_ninja_build<br>    raise RuntimeError(message) from\
          \ e</p>\n</details>\n\n<blockquote>\n<p>RuntimeError: Error building extension\
          \ 'cpu_adam'</p>\n</blockquote>\n<p><code>[2023-07-07 16:33:02,027] [INFO]\
          \ [launch.py:315:sigkill_handler] Killing subprocess 2819509 [2023-07-07\
          \ 16:33:02,028] [ERROR] [launch.py:321:sigkill_handler] ['/home/fkov/.conda/envs/ws/bin/python',\
          \ '-u', 'run_audio_classification_w.py', '--local_rank=0', '--deepspeed',\
          \ '/home/fkov/transformers/examples/pytorch/audio-classification/ds_config.json',\
          \ '--model_name_or_path', 'openai/whisper-medium', '--output_dir', 'l/users/fkov/outputs/w_sn',\
          \ '--overwrite_output_dir', '--remove_unused_columns', 'False', '--do_train',\
          \ '--do_eval', '--fp16', '--learning_rate', '3e-5', '--max_length_seconds',\
          \ '30', '--attention_mask', 'False', '--warmup_ratio', '0.1', '--num_train_epochs',\
          \ '3', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps',\
          \ '2', '--gradient_checkpointing', 'True', '--per_device_eval_batch_size',\
          \ '32', '--dataloader_num_workers', '8', '--logging_strategy', 'steps',\
          \ '--logging_steps', '25', '--evaluation_strategy', 'epoch', '--save_strategy',\
          \ 'epoch', '--load_best_model_at_end', 'True', '--metric_for_best_model',\
          \ 'accuracy', '--seed', '0', '--freeze_feature_encoder', 'False', '--push_to_hub']\
          \ exits with return code = 1</code></p>\n"
        raw: "I tried with \n\n*GPU: NVIDIA A100-SXM4-40GB*\n\n1. \n` https://pytorch.org/get-started/locally/:\
          \ Stable(2.0.1), Linux, Conda, Python, Cuda 11.8:  conda install pytorch\
          \ torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia `\n\n2.\
          \ \n`transformers version: 4.31.0.dev0 (from source using git clone https://github.com/huggingface/transformers\
          \ )\ncd transformers\npip install .\npip install -r /home/fkov/transformers/examples/pytorch/audio-classification/requirements.txt`\n\
          \n3. \n`git clone https://github.com/microsoft/DeepSpeed/\ncd DeepSpeed\n\
          rm -rf build\nTORCH_CUDA_ARCH_LIST=\u201C8.0\u201D DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1;\
          \ python setup.py build_ext -j8 bdist_wheel\npip install . `\n\n\n\n\n\n\
          \n\nERROR is: \n\n\n\n\n`Using /home/fkov/.cache/torch_extensions/py311_cu118\
          \ as PyTorch extensions root...\nDetected CUDA files, patching ldflags\n\
          Emitting ninja build file /home/fkov/.cache/torch_extensions/py311_cu118/cpu_adam/build.ninja...\n\
          Building extension module cpu_adam...\nAllowing ninja to set a default number\
          \ of workers... (overridable by setting the environment variable MAX_JOBS=N)`\n\
          \n<details>\n<summary>\u2026</summary>\n\n[1/2] /usr/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam\
          \ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\"\
          \ -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\
          \" -I/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/includes\
          \ -I/usr/include -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/torch/csrc/api/include\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/TH\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/THC\
          \ -isystem /home/fkov/.conda/envs/ws/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0\
          \ -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__\
          \ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80\
          \ -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math\
          \ -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__\
          \ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80\
          \ -DBF16_AVAILABLE -c /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu\
          \ -o custom_cuda_kernel.cuda.o \n\n</details>\n\n> FAILED: custom_cuda_kernel.cuda.o\
          \ \n\n<details>\n<summary>/usr/bin/nvcc</summary>\n\n/usr/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam\
          \ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\"\
          \ -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\
          \" -I/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/includes\
          \ -I/usr/include -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/torch/csrc/api/include\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/TH\
          \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/THC\
          \ -isystem /home/fkov/.conda/envs/ws/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0\
          \ -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__\
          \ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80\
          \ -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math\
          \ -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__\
          \ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80\
          \ -DBF16_AVAILABLE -c /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu\
          \ -o custom_cuda_kernel.cuda.o \n\n</details>\n\n> ERROR: No supported gcc/g++\
          \ host compiler found.\n>        Use 'nvcc -ccbin <compiler>' to specify\
          \ a host compiler.\n\n`ninja: build stopped: subcommand failed.\nTraceback\
          \ (most recent call last):\n  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
          , line 1893, in _run_ninja_build\n    subprocess.run(\n  File \"/home/fkov/.conda/envs/ws/lib/python3.11/subprocess.py\"\
          , line 571, in run\n    raise CalledProcessError(retcode, process.args,\n\
          subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero\
          \ exit status 1.`\n\n\n<details>\n<summary>The above exception was the direct\
          \ cause of the following exception:</summary>\n\n\nTraceback (most recent\
          \ call last):\n  File \"/home/fkov/transformers/examples/pytorch/audio-classification/run_audio_classification_w.py\"\
          , line 51, in <module>\n    deepspeed.ops.op_builder.CPUAdamBuilder().load()\n\
          \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py\"\
          , line 454, in load\n    return self.jit_load(verbose)\n           ^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py\"\
          , line 497, in jit_load\n    op_module = load(name=self.name,\n        \
          \        ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
          , line 1284, in load\n    return _jit_compile(\n           ^^^^^^^^^^^^^\n\
          \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
          , line 1509, in _jit_compile\n    _write_ninja_file_and_build_library(\n\
          \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
          , line 1624, in _write_ninja_file_and_build_library\n    _run_ninja_build(\n\
          \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
          , line 1909, in _run_ninja_build\n    raise RuntimeError(message) from e\n\
          \n</details>\n\n> RuntimeError: Error building extension 'cpu_adam'\n\n\n\
          \n`[2023-07-07 16:33:02,027] [INFO] [launch.py:315:sigkill_handler] Killing\
          \ subprocess 2819509\n[2023-07-07 16:33:02,028] [ERROR] [launch.py:321:sigkill_handler]\
          \ ['/home/fkov/.conda/envs/ws/bin/python', '-u', 'run_audio_classification_w.py',\
          \ '--local_rank=0', '--deepspeed', '/home/fkov/transformers/examples/pytorch/audio-classification/ds_config.json',\
          \ '--model_name_or_path', 'openai/whisper-medium', '--output_dir', 'l/users/fkov/outputs/w_sn',\
          \ '--overwrite_output_dir', '--remove_unused_columns', 'False', '--do_train',\
          \ '--do_eval', '--fp16', '--learning_rate', '3e-5', '--max_length_seconds',\
          \ '30', '--attention_mask', 'False', '--warmup_ratio', '0.1', '--num_train_epochs',\
          \ '3', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps',\
          \ '2', '--gradient_checkpointing', 'True', '--per_device_eval_batch_size',\
          \ '32', '--dataloader_num_workers', '8', '--logging_strategy', 'steps',\
          \ '--logging_steps', '25', '--evaluation_strategy', 'epoch', '--save_strategy',\
          \ 'epoch', '--load_best_model_at_end', 'True', '--metric_for_best_model',\
          \ 'accuracy', '--seed', '0', '--freeze_feature_encoder', 'False', '--push_to_hub']\
          \ exits with return code = 1`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
        updatedAt: '2023-07-07T15:15:27.670Z'
      numEdits: 7
      reactions: []
    id: 64a8125a4b01c33cf68e4128
    type: comment
  author: fkov
  content: "I tried with \n\n*GPU: NVIDIA A100-SXM4-40GB*\n\n1. \n` https://pytorch.org/get-started/locally/:\
    \ Stable(2.0.1), Linux, Conda, Python, Cuda 11.8:  conda install pytorch torchvision\
    \ torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia `\n\n2. \n`transformers version:\
    \ 4.31.0.dev0 (from source using git clone https://github.com/huggingface/transformers\
    \ )\ncd transformers\npip install .\npip install -r /home/fkov/transformers/examples/pytorch/audio-classification/requirements.txt`\n\
    \n3. \n`git clone https://github.com/microsoft/DeepSpeed/\ncd DeepSpeed\nrm -rf\
    \ build\nTORCH_CUDA_ARCH_LIST=\u201C8.0\u201D DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1;\
    \ python setup.py build_ext -j8 bdist_wheel\npip install . `\n\n\n\n\n\n\n\nERROR\
    \ is: \n\n\n\n\n`Using /home/fkov/.cache/torch_extensions/py311_cu118 as PyTorch\
    \ extensions root...\nDetected CUDA files, patching ldflags\nEmitting ninja build\
    \ file /home/fkov/.cache/torch_extensions/py311_cu118/cpu_adam/build.ninja...\n\
    Building extension module cpu_adam...\nAllowing ninja to set a default number\
    \ of workers... (overridable by setting the environment variable MAX_JOBS=N)`\n\
    \n<details>\n<summary>\u2026</summary>\n\n[1/2] /usr/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam\
    \ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\
    \"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/includes\
    \ -I/usr/include -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include\
    \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/torch/csrc/api/include\
    \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/TH\
    \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/THC\
    \ -isystem /home/fkov/.conda/envs/ws/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0\
    \ -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__\
    \ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80\
    \ -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math\
    \ -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__\
    \ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80\
    \ -DBF16_AVAILABLE -c /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu\
    \ -o custom_cuda_kernel.cuda.o \n\n</details>\n\n> FAILED: custom_cuda_kernel.cuda.o\
    \ \n\n<details>\n<summary>/usr/bin/nvcc</summary>\n\n/usr/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam\
    \ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\
    \"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/includes\
    \ -I/usr/include -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include\
    \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/torch/csrc/api/include\
    \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/TH\
    \ -isystem /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/include/THC\
    \ -isystem /home/fkov/.conda/envs/ws/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0\
    \ -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__\
    \ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80\
    \ -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math\
    \ -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__\
    \ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80\
    \ -DBF16_AVAILABLE -c /home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu\
    \ -o custom_cuda_kernel.cuda.o \n\n</details>\n\n> ERROR: No supported gcc/g++\
    \ host compiler found.\n>        Use 'nvcc -ccbin <compiler>' to specify a host\
    \ compiler.\n\n`ninja: build stopped: subcommand failed.\nTraceback (most recent\
    \ call last):\n  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
    , line 1893, in _run_ninja_build\n    subprocess.run(\n  File \"/home/fkov/.conda/envs/ws/lib/python3.11/subprocess.py\"\
    , line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError:\
    \ Command '['ninja', '-v']' returned non-zero exit status 1.`\n\n\n<details>\n\
    <summary>The above exception was the direct cause of the following exception:</summary>\n\
    \n\nTraceback (most recent call last):\n  File \"/home/fkov/transformers/examples/pytorch/audio-classification/run_audio_classification_w.py\"\
    , line 51, in <module>\n    deepspeed.ops.op_builder.CPUAdamBuilder().load()\n\
    \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py\"\
    , line 454, in load\n    return self.jit_load(verbose)\n           ^^^^^^^^^^^^^^^^^^^^^^\n\
    \  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py\"\
    , line 497, in jit_load\n    op_module = load(name=self.name,\n              \
    \  ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
    , line 1284, in load\n    return _jit_compile(\n           ^^^^^^^^^^^^^\n  File\
    \ \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
    , line 1509, in _jit_compile\n    _write_ninja_file_and_build_library(\n  File\
    \ \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
    , line 1624, in _write_ninja_file_and_build_library\n    _run_ninja_build(\n \
    \ File \"/home/fkov/.conda/envs/ws/lib/python3.11/site-packages/torch/utils/cpp_extension.py\"\
    , line 1909, in _run_ninja_build\n    raise RuntimeError(message) from e\n\n</details>\n\
    \n> RuntimeError: Error building extension 'cpu_adam'\n\n\n\n`[2023-07-07 16:33:02,027]\
    \ [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2819509\n[2023-07-07\
    \ 16:33:02,028] [ERROR] [launch.py:321:sigkill_handler] ['/home/fkov/.conda/envs/ws/bin/python',\
    \ '-u', 'run_audio_classification_w.py', '--local_rank=0', '--deepspeed', '/home/fkov/transformers/examples/pytorch/audio-classification/ds_config.json',\
    \ '--model_name_or_path', 'openai/whisper-medium', '--output_dir', 'l/users/fkov/outputs/w_sn',\
    \ '--overwrite_output_dir', '--remove_unused_columns', 'False', '--do_train',\
    \ '--do_eval', '--fp16', '--learning_rate', '3e-5', '--max_length_seconds', '30',\
    \ '--attention_mask', 'False', '--warmup_ratio', '0.1', '--num_train_epochs',\
    \ '3', '--per_device_train_batch_size', '16', '--gradient_accumulation_steps',\
    \ '2', '--gradient_checkpointing', 'True', '--per_device_eval_batch_size', '32',\
    \ '--dataloader_num_workers', '8', '--logging_strategy', 'steps', '--logging_steps',\
    \ '25', '--evaluation_strategy', 'epoch', '--save_strategy', 'epoch', '--load_best_model_at_end',\
    \ 'True', '--metric_for_best_model', 'accuracy', '--seed', '0', '--freeze_feature_encoder',\
    \ 'False', '--push_to_hub'] exits with return code = 1`\n\n\n\n\n\n\n\n\n\n\n\n\
    \n\n\n\n\n\n\n\n\n\n"
  created_at: 2023-07-07 12:25:46+00:00
  edited: true
  hidden: false
  id: 64a8125a4b01c33cf68e4128
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-07-10T14:49:39.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9655314683914185
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: '<p>I managed to do this just installing <code>deepspeed</code> from
          the most recent pypi version - could you try doing it this way rather than
          building from source?</p>

          '
        raw: I managed to do this just installing `deepspeed` from the most recent
          pypi version - could you try doing it this way rather than building from
          source?
        updatedAt: '2023-07-10T14:49:39.595Z'
      numEdits: 0
      reactions: []
    id: 64ac1a836ded799c42a72984
    type: comment
  author: sanchit-gandhi
  content: I managed to do this just installing `deepspeed` from the most recent pypi
    version - could you try doing it this way rather than building from source?
  created_at: 2023-07-10 13:49:39+00:00
  edited: false
  hidden: false
  id: 64ac1a836ded799c42a72984
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a17e6120a0e504c9d8e95147efaadb7.svg
      fullname: FK
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fkov
      type: user
    createdAt: '2023-07-12T05:41:54.000Z'
    data:
      edited: false
      editors:
      - fkov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8220780491828918
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a17e6120a0e504c9d8e95147efaadb7.svg
          fullname: FK
          isHf: false
          isPro: false
          name: fkov
          type: user
        html: "<p>I suspect DeepSpeed is not working because I am using a SLURM on-premise\
          \ cluster for it? <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \  is there a guide on installing DeepSpeed in Conda on cluster login node\
          \ and then being able to from bash script call the  DeepSpeed on other GPU\
          \ nodes?</p>\n<p>right now I tried installing DeepSpeed on login cluster\
          \ node (without GPU), then run bash script in the created environment on\
          \ login node. In the bash script I specify the gpu resources and the classification.py\
          \ to run finetuning</p>\n"
        raw: 'I suspect DeepSpeed is not working because I am using a SLURM on-premise
          cluster for it? @sanchit-gandhi  is there a guide on installing DeepSpeed
          in Conda on cluster login node and then being able to from bash script call
          the  DeepSpeed on other GPU nodes?


          right now I tried installing DeepSpeed on login cluster node (without GPU),
          then run bash script in the created environment on login node. In the bash
          script I specify the gpu resources and the classification.py to run finetuning

          '
        updatedAt: '2023-07-12T05:41:54.754Z'
      numEdits: 0
      reactions: []
    id: 64ae3d2250c5936418ccd77c
    type: comment
  author: fkov
  content: 'I suspect DeepSpeed is not working because I am using a SLURM on-premise
    cluster for it? @sanchit-gandhi  is there a guide on installing DeepSpeed in Conda
    on cluster login node and then being able to from bash script call the  DeepSpeed
    on other GPU nodes?


    right now I tried installing DeepSpeed on login cluster node (without GPU), then
    run bash script in the created environment on login node. In the bash script I
    specify the gpu resources and the classification.py to run finetuning

    '
  created_at: 2023-07-12 04:41:54+00:00
  edited: false
  hidden: false
  id: 64ae3d2250c5936418ccd77c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a17e6120a0e504c9d8e95147efaadb7.svg
      fullname: FK
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fkov
      type: user
    createdAt: '2023-07-12T06:46:10.000Z'
    data:
      edited: false
      editors:
      - fkov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8535717129707336
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a17e6120a0e504c9d8e95147efaadb7.svg
          fullname: FK
          isHf: false
          isPro: false
          name: fkov
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>,\
          \ got the solution. I had to use DS_BUILD_OPS=0 pip install deepspeed on\
          \ the login node </p>\n"
        raw: '@sanchit-gandhi, got the solution. I had to use DS_BUILD_OPS=0 pip install
          deepspeed on the login node '
        updatedAt: '2023-07-12T06:46:10.433Z'
      numEdits: 0
      reactions: []
    id: 64ae4c3292772101d05a7fb8
    type: comment
  author: fkov
  content: '@sanchit-gandhi, got the solution. I had to use DS_BUILD_OPS=0 pip install
    deepspeed on the login node '
  created_at: 2023-07-12 05:46:10+00:00
  edited: false
  hidden: false
  id: 64ae4c3292772101d05a7fb8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: sanchit-gandhi/whisper-medium-fleurs-lang-id
repo_type: model
status: open
target_branch: null
title: 'env setup guide: pytorch+deepspeed+transformers'
