!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kimedaka
conflicting_files: null
created_at: 2023-06-07 12:10:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679231812475-6416fc1e8f689506e70ea702.png?w=200&h=200&f=face
      fullname: K Ghosh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kimedaka
      type: user
    createdAt: '2023-06-07T13:10:54.000Z'
    data:
      edited: false
      editors:
      - kimedaka
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7561424374580383
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679231812475-6416fc1e8f689506e70ea702.png?w=200&h=200&f=face
          fullname: K Ghosh
          isHf: false
          isPro: false
          name: kimedaka
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>,<br>Thanks\
          \ for sharing this Audio Classification model!!<br>Could you please suggest\
          \ how I can use my own Audio Classifier? Is my understanding correct that\
          \ AutoModelForAudioClassification actually uses WhisperForAudioClassification\
          \ from <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/blob/v4.29.1/src/transformers/models/whisper/modeling_whisper.py#L1664\"\
          >https://github.com/huggingface/transformers/blob/v4.29.1/src/transformers/models/whisper/modeling_whisper.py#L1664</a>\
          \ ?<br>If yes, can I define my own custom audio classifier the way WhisperForAudioClassification\
          \ is defined with suitable modifications and use it directly without using\
          \ AutoModelForAudioClassification ?<br>I am very much looking forward to\
          \ hearing from you soon :)<br>Regards,<br>K</p>\n"
        raw: "Hello @sanchit-gandhi, \r\nThanks for sharing this Audio Classification\
          \ model!!\r\nCould you please suggest how I can use my own Audio Classifier?\
          \ Is my understanding correct that AutoModelForAudioClassification actually\
          \ uses WhisperForAudioClassification from https://github.com/huggingface/transformers/blob/v4.29.1/src/transformers/models/whisper/modeling_whisper.py#L1664\
          \ ? \r\nIf yes, can I define my own custom audio classifier the way WhisperForAudioClassification\
          \ is defined with suitable modifications and use it directly without using\
          \ AutoModelForAudioClassification ? \r\nI am very much looking forward to\
          \ hearing from you soon :) \r\nRegards,\r\nK"
        updatedAt: '2023-06-07T13:10:54.982Z'
      numEdits: 0
      reactions: []
    id: 648081de7d65d9ac173064cb
    type: comment
  author: kimedaka
  content: "Hello @sanchit-gandhi, \r\nThanks for sharing this Audio Classification\
    \ model!!\r\nCould you please suggest how I can use my own Audio Classifier? Is\
    \ my understanding correct that AutoModelForAudioClassification actually uses\
    \ WhisperForAudioClassification from https://github.com/huggingface/transformers/blob/v4.29.1/src/transformers/models/whisper/modeling_whisper.py#L1664\
    \ ? \r\nIf yes, can I define my own custom audio classifier the way WhisperForAudioClassification\
    \ is defined with suitable modifications and use it directly without using AutoModelForAudioClassification\
    \ ? \r\nI am very much looking forward to hearing from you soon :) \r\nRegards,\r\
    \nK"
  created_at: 2023-06-07 12:10:54+00:00
  edited: false
  hidden: false
  id: 648081de7d65d9ac173064cb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-06-12T16:24:01.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7007248401641846
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;kimedaka&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/kimedaka\"\
          >@<span class=\"underline\">kimedaka</span></a></span>\n\n\t</span></span>\
          \ - you can see the source code for <code>WhisperForAudioClassification</code>\
          \ <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/blob/e5dd7432e7f274d7292666d3e8f3b3f9041d6e6c/src/transformers/models/whisper/modeling_whisper.py#L1710\"\
          >here</a> and make and changes as desired (you can copy the modelling file,\
          \ update the imports from relative to absolute, the make the changes you\
          \ want)</p>\n"
        raw: Hey @kimedaka - you can see the source code for `WhisperForAudioClassification`
          [here](https://github.com/huggingface/transformers/blob/e5dd7432e7f274d7292666d3e8f3b3f9041d6e6c/src/transformers/models/whisper/modeling_whisper.py#L1710)
          and make and changes as desired (you can copy the modelling file, update
          the imports from relative to absolute, the make the changes you want)
        updatedAt: '2023-06-12T16:24:01.643Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - kimedaka
    id: 648746a1b2b5fdf3f9445d90
    type: comment
  author: sanchit-gandhi
  content: Hey @kimedaka - you can see the source code for `WhisperForAudioClassification`
    [here](https://github.com/huggingface/transformers/blob/e5dd7432e7f274d7292666d3e8f3b3f9041d6e6c/src/transformers/models/whisper/modeling_whisper.py#L1710)
    and make and changes as desired (you can copy the modelling file, update the imports
    from relative to absolute, the make the changes you want)
  created_at: 2023-06-12 15:24:01+00:00
  edited: false
  hidden: false
  id: 648746a1b2b5fdf3f9445d90
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679231812475-6416fc1e8f689506e70ea702.png?w=200&h=200&f=face
      fullname: K Ghosh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kimedaka
      type: user
    createdAt: '2023-08-06T14:14:05.000Z'
    data:
      edited: true
      editors:
      - kimedaka
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7697207927703857
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679231812475-6416fc1e8f689506e70ea702.png?w=200&h=200&f=face
          fullname: K Ghosh
          isHf: false
          isPro: false
          name: kimedaka
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>,\
          \ </p>\n<p>Thanks so very much for your suggestion! It did work for me :)\
          \ </p>\n<ol>\n<li><p>I saw in your code for WhisperForAudioClassification\
          \ (line #1724), you defined freeze_encoder(), but in your run_audio_classification.py\
          \ script for this model, you used model.freeze_feature_encoder() (line #357)\
          \ instead of freeze_encoder(). Are these methods/function same? If not,\
          \ why did you use model.freeze_feature_encoder()?</p>\n</li>\n<li><p>In\
          \ your blog post: \"Fine-Tune Whisper For Multilingual ASR with \U0001F917\
          \ Transformers\", you said and used: </p>\n<p> -#compute log-Mel input features\
          \ from input audio array<br> batch[\"input_features\"] = feature_extractor(audio[\"\
          array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]</p>\n\
          </li>\n</ol>\n<ul>\n<li>that is, the first element of input_features 'list'\
          \ of feature_extractor, but run_audio_classification.py script (line #303)\
          \ for this model you used input_features  itself; not its first element\
          \ (i.e.  output_batch = {model_input_name: inputs.get(model_input_name)}).\
          \ What is the reason of doing so?</li>\n</ul>\n<p>Regards,<br>K</p>\n"
        raw: "Hello @sanchit-gandhi, \n\nThanks so very much for your suggestion!\
          \ It did work for me :) \n\n1)  I saw in your code for WhisperForAudioClassification\
          \ (line #1724), you defined freeze_encoder(), but in your run_audio_classification.py\
          \ script for this model, you used model.freeze_feature_encoder() (line #357)\
          \ instead of freeze_encoder(). Are these methods/function same? If not,\
          \ why did you use model.freeze_feature_encoder()?\n\n2) In your blog post:\
          \ \"Fine-Tune Whisper For Multilingual ASR with \U0001F917 Transformers\"\
          , you said and used: \n\n    -#compute log-Mel input features from input\
          \ audio array \n    batch[\"input_features\"] = feature_extractor(audio[\"\
          array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]  \n\n\
          - that is, the first element of input_features 'list' of feature_extractor,\
          \ but run_audio_classification.py script (line #303) for this model you\
          \ used input_features  itself; not its first element (i.e.  output_batch\
          \ = {model_input_name: inputs.get(model_input_name)}). What is the reason\
          \ of doing so? \n\nRegards,\nK\n"
        updatedAt: '2023-08-06T15:32:49.973Z'
      numEdits: 1
      reactions: []
    id: 64cfaaad2f92537fbc05b4da
    type: comment
  author: kimedaka
  content: "Hello @sanchit-gandhi, \n\nThanks so very much for your suggestion! It\
    \ did work for me :) \n\n1)  I saw in your code for WhisperForAudioClassification\
    \ (line #1724), you defined freeze_encoder(), but in your run_audio_classification.py\
    \ script for this model, you used model.freeze_feature_encoder() (line #357) instead\
    \ of freeze_encoder(). Are these methods/function same? If not, why did you use\
    \ model.freeze_feature_encoder()?\n\n2) In your blog post: \"Fine-Tune Whisper\
    \ For Multilingual ASR with \U0001F917 Transformers\", you said and used: \n\n\
    \    -#compute log-Mel input features from input audio array \n    batch[\"input_features\"\
    ] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"\
    ]).input_features[0]  \n\n- that is, the first element of input_features 'list'\
    \ of feature_extractor, but run_audio_classification.py script (line #303) for\
    \ this model you used input_features  itself; not its first element (i.e.  output_batch\
    \ = {model_input_name: inputs.get(model_input_name)}). What is the reason of doing\
    \ so? \n\nRegards,\nK\n"
  created_at: 2023-08-06 13:14:05+00:00
  edited: true
  hidden: false
  id: 64cfaaad2f92537fbc05b4da
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: sanchit-gandhi/whisper-medium-fleurs-lang-id
repo_type: model
status: open
target_branch: null
title: Custom Classifier
