!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Yhyu13
conflicting_files: null
created_at: 2023-07-20 13:30:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-07-20T14:30:20.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9338821172714233
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<p>Is it the same as meta''s llama2-hf repo?</p>

          '
        raw: Is it the same as meta's llama2-hf repo?
        updatedAt: '2023-07-20T14:30:20.187Z'
      numEdits: 0
      reactions: []
    id: 64b944fc35c815492d3fc42f
    type: comment
  author: Yhyu13
  content: Is it the same as meta's llama2-hf repo?
  created_at: 2023-07-20 13:30:20+00:00
  edited: false
  hidden: false
  id: 64b944fc35c815492d3fc42f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-20T14:32:08.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9730572700500488
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Effectively, yes. I uploaded them partly because some people couldn''t
          get access to Meta''s repo, and also because when I tried to quantise from
          the Meta HF repos, I got weird errors.</p>

          <p>It turned out that the error was caused by an incorrectly set parameter
          in the HF repo, <code>"pretraining_tp": 2,</code>.  But I don''t think that
          affects normal inference.</p>

          <p>But yeah, if you have access to Llama-2-13B-HF there''s no real reason
          to use this repo and I may delete it eventually.</p>

          '
        raw: 'Effectively, yes. I uploaded them partly because some people couldn''t
          get access to Meta''s repo, and also because when I tried to quantise from
          the Meta HF repos, I got weird errors.


          It turned out that the error was caused by an incorrectly set parameter
          in the HF repo, `"pretraining_tp": 2,`.  But I don''t think that affects
          normal inference.


          But yeah, if you have access to Llama-2-13B-HF there''s no real reason to
          use this repo and I may delete it eventually.'
        updatedAt: '2023-07-20T14:32:08.297Z'
      numEdits: 0
      reactions: []
    id: 64b94568acfb31c3f7b8aeb2
    type: comment
  author: TheBloke
  content: 'Effectively, yes. I uploaded them partly because some people couldn''t
    get access to Meta''s repo, and also because when I tried to quantise from the
    Meta HF repos, I got weird errors.


    It turned out that the error was caused by an incorrectly set parameter in the
    HF repo, `"pretraining_tp": 2,`.  But I don''t think that affects normal inference.


    But yeah, if you have access to Llama-2-13B-HF there''s no real reason to use
    this repo and I may delete it eventually.'
  created_at: 2023-07-20 13:32:08+00:00
  edited: false
  hidden: false
  id: 64b94568acfb31c3f7b8aeb2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-20T14:40:02.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9949458837509155
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I see that HF have fixed the pretraining_tp issue in the upstream
          repo now</p>

          <p>The other difference with my repo and theirs was that mine was fp16 and
          they mistakenly uploaded theirs in fp32. But that is also fixed now.</p>

          <p>So yeah, no reason to use my repo at all now I would say.</p>

          '
        raw: 'I see that HF have fixed the pretraining_tp issue in the upstream repo
          now


          The other difference with my repo and theirs was that mine was fp16 and
          they mistakenly uploaded theirs in fp32. But that is also fixed now.


          So yeah, no reason to use my repo at all now I would say.'
        updatedAt: '2023-07-20T14:40:02.393Z'
      numEdits: 0
      reactions: []
    id: 64b94742339adc8f30cfcb76
    type: comment
  author: TheBloke
  content: 'I see that HF have fixed the pretraining_tp issue in the upstream repo
    now


    The other difference with my repo and theirs was that mine was fp16 and they mistakenly
    uploaded theirs in fp32. But that is also fixed now.


    So yeah, no reason to use my repo at all now I would say.'
  created_at: 2023-07-20 13:40:02+00:00
  edited: false
  hidden: false
  id: 64b94742339adc8f30cfcb76
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/29785b386e2bbacf315bf2c15f2a239b.svg
      fullname: Alex Schmitt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xms991
      type: user
    createdAt: '2023-07-20T20:38:41.000Z'
    data:
      edited: false
      editors:
      - xms991
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.97417151927948
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/29785b386e2bbacf315bf2c15f2a239b.svg
          fullname: Alex Schmitt
          isHf: false
          isPro: false
          name: xms991
          type: user
        html: '<p>Is there a reason these are provided as .bin files instead of .safetensors?
          </p>

          <p>Thanks as always for all your work :) </p>

          '
        raw: "Is there a reason these are provided as .bin files instead of .safetensors?\
          \ \n\nThanks as always for all your work :) "
        updatedAt: '2023-07-20T20:38:41.907Z'
      numEdits: 0
      reactions: []
    id: 64b99b51a6ccf0f64b39a2e6
    type: comment
  author: xms991
  content: "Is there a reason these are provided as .bin files instead of .safetensors?\
    \ \n\nThanks as always for all your work :) "
  created_at: 2023-07-20 19:38:41+00:00
  edited: false
  hidden: false
  id: 64b99b51a6ccf0f64b39a2e6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-20T20:40:25.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.992929995059967
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Only that I didn''t bother specifying them to be saved as safetensors!  I
          did later for the Llama 70B fp16s</p>

          <p>As I was saying earlier, I only put these repos up because a couple of
          people asked me because they''d not yet got access to the Meta ones, and
          because I discovered an issue in the Meta repo.  That issue has been fixed
          now, and I think most people have access to Meta''s repos if they want it
          by now.  So maybe I should just delete these..</p>

          '
        raw: 'Only that I didn''t bother specifying them to be saved as safetensors!  I
          did later for the Llama 70B fp16s


          As I was saying earlier, I only put these repos up because a couple of people
          asked me because they''d not yet got access to the Meta ones, and because
          I discovered an issue in the Meta repo.  That issue has been fixed now,
          and I think most people have access to Meta''s repos if they want it by
          now.  So maybe I should just delete these..'
        updatedAt: '2023-07-20T20:40:25.280Z'
      numEdits: 0
      reactions: []
    id: 64b99bb95c4deebf699a851e
    type: comment
  author: TheBloke
  content: 'Only that I didn''t bother specifying them to be saved as safetensors!  I
    did later for the Llama 70B fp16s


    As I was saying earlier, I only put these repos up because a couple of people
    asked me because they''d not yet got access to the Meta ones, and because I discovered
    an issue in the Meta repo.  That issue has been fixed now, and I think most people
    have access to Meta''s repos if they want it by now.  So maybe I should just delete
    these..'
  created_at: 2023-07-20 19:40:25+00:00
  edited: false
  hidden: false
  id: 64b99bb95c4deebf699a851e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Llama-2-13B-fp16
repo_type: model
status: open
target_branch: null
title: The same as meta's repo?
