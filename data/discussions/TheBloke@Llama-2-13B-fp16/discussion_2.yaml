!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Yurkoff
conflicting_files: null
created_at: 2023-08-23 09:45:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
      fullname: Yurkov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yurkoff
      type: user
    createdAt: '2023-08-23T10:45:34.000Z'
    data:
      edited: true
      editors:
      - Yurkoff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7581908702850342
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
          fullname: Yurkov
          isHf: false
          isPro: false
          name: Yurkoff
          type: user
        html: '<p>There is a memory leak somewhere. After the calculations are completed,
          the model does not return the used memory to the pool.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/cG5svPYk2gdxIFDHuZuqo.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/cG5svPYk2gdxIFDHuZuqo.png"></a></p>

          <p>This is what it looks like when the model boots up.<br><a rel="nofollow"
          href="https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/CZDA44Si_ATtHy0C_E7AU.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/CZDA44Si_ATtHy0C_E7AU.png"></a></p>

          '
        raw: 'There is a memory leak somewhere. After the calculations are completed,
          the model does not return the used memory to the pool.


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/cG5svPYk2gdxIFDHuZuqo.png)


          This is what it looks like when the model boots up.

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/CZDA44Si_ATtHy0C_E7AU.png)

          '
        updatedAt: '2023-08-23T11:08:14.796Z'
      numEdits: 1
      reactions: []
    id: 64e5e34ec7881777cb4bb09f
    type: comment
  author: Yurkoff
  content: 'There is a memory leak somewhere. After the calculations are completed,
    the model does not return the used memory to the pool.


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/cG5svPYk2gdxIFDHuZuqo.png)


    This is what it looks like when the model boots up.

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/642f00ad9b2484d7d852fb5e/CZDA44Si_ATtHy0C_E7AU.png)

    '
  created_at: 2023-08-23 09:45:34+00:00
  edited: true
  hidden: false
  id: 64e5e34ec7881777cb4bb09f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-23T10:59:09.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9656687378883362
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>That''s a code problem, nothing to do with the model itself.  And
          no-one can help with that without seeing the code being run.</p>

          '
        raw: That's a code problem, nothing to do with the model itself.  And no-one
          can help with that without seeing the code being run.
        updatedAt: '2023-08-23T10:59:09.778Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Nurb432
    id: 64e5e67d90c41695ad8b3426
    type: comment
  author: TheBloke
  content: That's a code problem, nothing to do with the model itself.  And no-one
    can help with that without seeing the code being run.
  created_at: 2023-08-23 09:59:09+00:00
  edited: false
  hidden: false
  id: 64e5e67d90c41695ad8b3426
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-08-23T11:16:29.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9642430543899536
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>Might want to report this to the dev of whatever app/module/etc
          you are using. </p>

          '
        raw: 'Might want to report this to the dev of whatever app/module/etc you
          are using. '
        updatedAt: '2023-08-23T11:16:29.623Z'
      numEdits: 0
      reactions: []
    id: 64e5ea8d07274d5a5a8d0bf2
    type: comment
  author: Nurb432
  content: 'Might want to report this to the dev of whatever app/module/etc you are
    using. '
  created_at: 2023-08-23 10:16:29+00:00
  edited: false
  hidden: false
  id: 64e5ea8d07274d5a5a8d0bf2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
      fullname: Yurkov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yurkoff
      type: user
    createdAt: '2023-08-23T11:32:53.000Z'
    data:
      edited: false
      editors:
      - Yurkoff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.35586661100387573
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
          fullname: Yurkov
          isHf: false
          isPro: false
          name: Yurkoff
          type: user
        html: "<p>My code:</p>\n<pre><code>import torch\nfrom transformers import\
          \ LlamaTokenizerFast, LlamaForCausalLM\n\n\ntokenizer = LlamaTokenizerFast.from_pretrained(model_dir)\n\
          model = LlamaForCausalLM.from_pretrained(model_dir,\n                  \
          \                       load_in_8bit=True,\n                           \
          \              device_map='sequential',\n                              \
          \           torch_dtype=torch.float16,\n                               \
          \          low_cpu_mem_usage=True,\n                                   \
          \      )\n\n\ninputs = self.tokenizer(prompts)\noutput_ids = self.model.generate(torch.as_tensor(inputs.input_ids).to(self.device),\n\
          \                                 do_sample=True,\n                    \
          \             temperature=0.8,\n                                 max_new_tokens=512,\n\
          \                                 top_p=0.95,\n                        \
          \         # synced_gpus=True,\n                                 )\nresults\
          \ = self.tokenizer.batch_decode(output_ids,\n                          \
          \            skip_special_tokens=True,\n                               \
          \       clean_up_tokenization_spaces=False)[0]\n</code></pre>\n"
        raw: "My code:\n```\nimport torch\nfrom transformers import LlamaTokenizerFast,\
          \ LlamaForCausalLM\n\n\ntokenizer = LlamaTokenizerFast.from_pretrained(model_dir)\n\
          model = LlamaForCausalLM.from_pretrained(model_dir,\n                  \
          \                       load_in_8bit=True,\n                           \
          \              device_map='sequential',\n                              \
          \           torch_dtype=torch.float16,\n                               \
          \          low_cpu_mem_usage=True,\n                                   \
          \      )\n\n\ninputs = self.tokenizer(prompts)\noutput_ids = self.model.generate(torch.as_tensor(inputs.input_ids).to(self.device),\n\
          \                                 do_sample=True,\n                    \
          \             temperature=0.8,\n                                 max_new_tokens=512,\n\
          \                                 top_p=0.95,\n                        \
          \         # synced_gpus=True,\n                                 )\nresults\
          \ = self.tokenizer.batch_decode(output_ids,\n                          \
          \            skip_special_tokens=True,\n                               \
          \       clean_up_tokenization_spaces=False)[0]\n```"
        updatedAt: '2023-08-23T11:32:53.785Z'
      numEdits: 0
      reactions: []
    id: 64e5ee656f6ccc7eb8b92ec5
    type: comment
  author: Yurkoff
  content: "My code:\n```\nimport torch\nfrom transformers import LlamaTokenizerFast,\
    \ LlamaForCausalLM\n\n\ntokenizer = LlamaTokenizerFast.from_pretrained(model_dir)\n\
    model = LlamaForCausalLM.from_pretrained(model_dir,\n                        \
    \                 load_in_8bit=True,\n                                       \
    \  device_map='sequential',\n                                         torch_dtype=torch.float16,\n\
    \                                         low_cpu_mem_usage=True,\n          \
    \                               )\n\n\ninputs = self.tokenizer(prompts)\noutput_ids\
    \ = self.model.generate(torch.as_tensor(inputs.input_ids).to(self.device),\n \
    \                                do_sample=True,\n                           \
    \      temperature=0.8,\n                                 max_new_tokens=512,\n\
    \                                 top_p=0.95,\n                              \
    \   # synced_gpus=True,\n                                 )\nresults = self.tokenizer.batch_decode(output_ids,\n\
    \                                      skip_special_tokens=True,\n           \
    \                           clean_up_tokenization_spaces=False)[0]\n```"
  created_at: 2023-08-23 10:32:53+00:00
  edited: false
  hidden: false
  id: 64e5ee656f6ccc7eb8b92ec5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
      fullname: Yurkov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yurkoff
      type: user
    createdAt: '2023-08-23T14:26:34.000Z'
    data:
      edited: false
      editors:
      - Yurkoff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3750544488430023
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
          fullname: Yurkov
          isHf: false
          isPro: false
          name: Yurkoff
          type: user
        html: '<p>Virsions of my packeges:</p>

          <pre><code>torch==2.0.1+cu118; sys_platform == ''linux''

          torchvision==0.15.2+cu118; sys_platform == ''linux''

          torchtext==0.15.2; sys_platform == ''linux''

          torchaudio==2.0.2+cu118; sys_platform == ''linux''

          psutil==5.9.5

          requests==2.31.0

          captum==0.6.0

          packaging==23.1

          pynvml==11.4.1

          pyyaml==6.0

          nvgpu

          cython==0.29.34

          wheel==0.40.0

          pillow==9.3.0

          numpy==1.24.3

          torchtext==0.15.2

          torchserve==0.7.1

          torch-model-archiver==0.7.1

          transformers==4.31.0

          tokenizers==0.13.3

          sentencepiece==0.1.99

          bitsandbytes==0.41.1

          accelerate==0.21.0

          scipy==1.10.1

          </code></pre>

          '
        raw: 'Virsions of my packeges:

          ```

          torch==2.0.1+cu118; sys_platform == ''linux''

          torchvision==0.15.2+cu118; sys_platform == ''linux''

          torchtext==0.15.2; sys_platform == ''linux''

          torchaudio==2.0.2+cu118; sys_platform == ''linux''

          psutil==5.9.5

          requests==2.31.0

          captum==0.6.0

          packaging==23.1

          pynvml==11.4.1

          pyyaml==6.0

          nvgpu

          cython==0.29.34

          wheel==0.40.0

          pillow==9.3.0

          numpy==1.24.3

          torchtext==0.15.2

          torchserve==0.7.1

          torch-model-archiver==0.7.1

          transformers==4.31.0

          tokenizers==0.13.3

          sentencepiece==0.1.99

          bitsandbytes==0.41.1

          accelerate==0.21.0

          scipy==1.10.1

          ```'
        updatedAt: '2023-08-23T14:26:34.514Z'
      numEdits: 0
      reactions: []
    id: 64e6171abe651cead87285f8
    type: comment
  author: Yurkoff
  content: 'Virsions of my packeges:

    ```

    torch==2.0.1+cu118; sys_platform == ''linux''

    torchvision==0.15.2+cu118; sys_platform == ''linux''

    torchtext==0.15.2; sys_platform == ''linux''

    torchaudio==2.0.2+cu118; sys_platform == ''linux''

    psutil==5.9.5

    requests==2.31.0

    captum==0.6.0

    packaging==23.1

    pynvml==11.4.1

    pyyaml==6.0

    nvgpu

    cython==0.29.34

    wheel==0.40.0

    pillow==9.3.0

    numpy==1.24.3

    torchtext==0.15.2

    torchserve==0.7.1

    torch-model-archiver==0.7.1

    transformers==4.31.0

    tokenizers==0.13.3

    sentencepiece==0.1.99

    bitsandbytes==0.41.1

    accelerate==0.21.0

    scipy==1.10.1

    ```'
  created_at: 2023-08-23 13:26:34+00:00
  edited: false
  hidden: false
  id: 64e6171abe651cead87285f8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
      fullname: Yurkov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yurkoff
      type: user
    createdAt: '2023-08-24T04:55:04.000Z'
    data:
      edited: false
      editors:
      - Yurkoff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6870676279067993
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
          fullname: Yurkov
          isHf: false
          isPro: false
          name: Yurkoff
          type: user
        html: '<p>I solved problem. After each inference i call</p>

          <pre><code>gc.collect()

          torch.cuda.empty_cache()

          </code></pre>

          <p><a rel="nofollow" href="https://github.com/huggingface/transformers/issues/25690">https://github.com/huggingface/transformers/issues/25690</a></p>

          '
        raw: 'I solved problem. After each inference i call

          ```

          gc.collect()

          torch.cuda.empty_cache()

          ```

          https://github.com/huggingface/transformers/issues/25690'
        updatedAt: '2023-08-24T04:55:04.415Z'
      numEdits: 0
      reactions: []
    id: 64e6e2a814a7448ab95644e7
    type: comment
  author: Yurkoff
  content: 'I solved problem. After each inference i call

    ```

    gc.collect()

    torch.cuda.empty_cache()

    ```

    https://github.com/huggingface/transformers/issues/25690'
  created_at: 2023-08-24 03:55:04+00:00
  edited: false
  hidden: false
  id: 64e6e2a814a7448ab95644e7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/12eeeccee2f5a7e6e97f663c37b412eb.svg
      fullname: Yurkov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yurkoff
      type: user
    createdAt: '2023-08-24T04:55:08.000Z'
    data:
      status: closed
    id: 64e6e2ac14a7448ab9564556
    type: status-change
  author: Yurkoff
  created_at: 2023-08-24 03:55:08+00:00
  id: 64e6e2ac14a7448ab9564556
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/Llama-2-13B-fp16
repo_type: model
status: closed
target_branch: null
title: Memory leak.
