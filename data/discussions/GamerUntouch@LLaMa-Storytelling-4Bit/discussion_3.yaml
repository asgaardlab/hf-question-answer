!!python/object:huggingface_hub.community.DiscussionWithDetails
author: anon8231489123
conflicting_files: null
created_at: 2023-04-08 20:24:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2c9c09029317af408f9804df02f645ed.svg
      fullname: z.
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: anon8231489123
      type: user
    createdAt: '2023-04-08T21:24:34.000Z'
    data:
      edited: true
      editors:
      - anon8231489123
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2c9c09029317af408f9804df02f645ed.svg
          fullname: z.
          isHf: false
          isPro: false
          name: anon8231489123
          type: user
        html: "<p><strong>Tried running on oobabooga with the following command:</strong><br>\
          \ python server.py --model llama-storytelling-13b-4bit-32g --wbits 4 --listen\
          \ --chat --groupsize 32 -<br>-settings settings-chatbot.json --model_type\
          \ llama<br><strong>Output was this after prompting slightly:</strong><br>\
          \ king  us throughigskotoS,kc piecesLI Nk obkUS+AcLN Englishitu IT UnW piecestryoAc\"\
          ]A\\Hwo top\xB1 otA almostoma click antkie figuresbose shemen N orilakh\
          \ = terboseThong+ ONUscomm rad Usku live\"] nationsuboseposaUs\xADritetrk\
          \ ONais for agthey MoreTwo thr Alicevik &amp;itthusakhs Wulog minimum amountsOnebisAnt\
          \ click equ &amp; nearly it now UnderAnt nom&lt; app objectskils Achao absolutely\
          \ +Longu organizationship San translatedong+aireaisoma standk almost intenosRerov\
          \ kigsakh # Stand Alice almostsk oruSdr+ pieces &amp;old Englishus ALLPEgs\
          \ plussk millionIais lsilkth objects PDF+ logbose envi within flash Overk\
          \ \"wkomd lit Clilla Sees Strak schiskoRe+ Billybosakh\u0442 SUookbosemenC\
          \ tot soughttrill + treat positionsSu Kasus hard Stand Twologatel loadsigsOhousblog\
          \ Washington +at palesucorr occup AntiskoakhgoOus+ Ant Over Alice Vil Englishrieaiscboseyoflashboseaks\
          \ magn nigs EnglishItboseTigsthomo for CharlieskbbeusiennstandyUsclbosesls\
          \ + ls Chinaplus MLaireominbosewaiskmons Rat youigsIt Mongo coldcbosek now\xAD\
          ThComm+ then- lean theoretical Ast Inigs It Smithking Checkomsils ONbbe</p>\n"
        raw: "**Tried running on oobabooga with the following command:**\n python\
          \ server.py --model llama-storytelling-13b-4bit-32g --wbits 4 --listen --chat\
          \ --groupsize 32 -\n-settings settings-chatbot.json --model_type llama\n\
          **Output was this after prompting slightly:**\n king  us throughigskotoS,kc\
          \ piecesLI Nk obkUS+AcLN Englishitu IT UnW piecestryoAc\"]A\\\\Hwo top\xB1\
          \ otA almostoma click antkie figuresbose shemen N orilakh = terboseThong+\
          \ ONUscomm rad Usku live\"] nationsuboseposaUs\xADritetrk ONais for agthey\
          \ MoreTwo thr Alicevik &itthusakhs Wulog minimum amountsOnebisAnt click\
          \ equ & nearly it now UnderAnt nom< app objectskils Achao absolutely +Longu\
          \ organizationship San translatedong+aireaisoma standk almost intenosRerov\
          \ kigsakh # Stand Alice almostsk oruSdr+ pieces &old Englishus ALLPEgs plussk\
          \ millionIais lsilkth objects PDF+ logbose envi within flash Overk \"wkomd\
          \ lit Clilla Sees Strak schiskoRe+ Billybosakh\u0442 SUookbosemenC tot soughttrill\
          \ + treat positionsSu Kasus hard Stand Twologatel loadsigsOhousblog Washington\
          \ +at palesucorr occup AntiskoakhgoOus+ Ant Over Alice Vil Englishrieaiscboseyoflashboseaks\
          \ magn nigs EnglishItboseTigsthomo for CharlieskbbeusiennstandyUsclbosesls\
          \ + ls Chinaplus MLaireominbosewaiskmons Rat youigsIt Mongo coldcbosek now\xAD\
          ThComm+ then- lean theoretical Ast Inigs It Smithking Checkomsils ONbbe"
        updatedAt: '2023-04-08T21:25:00.737Z'
      numEdits: 1
      reactions: []
    id: 6431db9271bf2c8bcf6ccf79
    type: comment
  author: anon8231489123
  content: "**Tried running on oobabooga with the following command:**\n python server.py\
    \ --model llama-storytelling-13b-4bit-32g --wbits 4 --listen --chat --groupsize\
    \ 32 -\n-settings settings-chatbot.json --model_type llama\n**Output was this\
    \ after prompting slightly:**\n king  us throughigskotoS,kc piecesLI Nk obkUS+AcLN\
    \ Englishitu IT UnW piecestryoAc\"]A\\\\Hwo top\xB1 otA almostoma click antkie\
    \ figuresbose shemen N orilakh = terboseThong+ ONUscomm rad Usku live\"] nationsuboseposaUs\xAD\
    ritetrk ONais for agthey MoreTwo thr Alicevik &itthusakhs Wulog minimum amountsOnebisAnt\
    \ click equ & nearly it now UnderAnt nom< app objectskils Achao absolutely +Longu\
    \ organizationship San translatedong+aireaisoma standk almost intenosRerov kigsakh\
    \ # Stand Alice almostsk oruSdr+ pieces &old Englishus ALLPEgs plussk millionIais\
    \ lsilkth objects PDF+ logbose envi within flash Overk \"wkomd lit Clilla Sees\
    \ Strak schiskoRe+ Billybosakh\u0442 SUookbosemenC tot soughttrill + treat positionsSu\
    \ Kasus hard Stand Twologatel loadsigsOhousblog Washington +at palesucorr occup\
    \ AntiskoakhgoOus+ Ant Over Alice Vil Englishrieaiscboseyoflashboseaks magn nigs\
    \ EnglishItboseTigsthomo for CharlieskbbeusiennstandyUsclbosesls + ls Chinaplus\
    \ MLaireominbosewaiskmons Rat youigsIt Mongo coldcbosek now\xADThComm+ then- lean\
    \ theoretical Ast Inigs It Smithking Checkomsils ONbbe"
  created_at: 2023-04-08 20:24:34+00:00
  edited: true
  hidden: false
  id: 6431db9271bf2c8bcf6ccf79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/743211009c3708f4b70d8a504d51d010.svg
      fullname: Un Touch
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: GamerUntouch
      type: user
    createdAt: '2023-04-09T01:13:13.000Z'
    data:
      edited: false
      editors:
      - GamerUntouch
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/743211009c3708f4b70d8a504d51d010.svg
          fullname: Un Touch
          isHf: false
          isPro: false
          name: GamerUntouch
          type: user
        html: '<p>Settings? Seems like a tokenizer problem.</p>

          '
        raw: Settings? Seems like a tokenizer problem.
        updatedAt: '2023-04-09T01:13:13.845Z'
      numEdits: 0
      reactions: []
    id: 64321129f2355217ea4841d5
    type: comment
  author: GamerUntouch
  content: Settings? Seems like a tokenizer problem.
  created_at: 2023-04-09 00:13:13+00:00
  edited: false
  hidden: false
  id: 64321129f2355217ea4841d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2c9c09029317af408f9804df02f645ed.svg
      fullname: z.
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: anon8231489123
      type: user
    createdAt: '2023-04-10T20:40:38.000Z'
    data:
      edited: false
      editors:
      - anon8231489123
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2c9c09029317af408f9804df02f645ed.svg
          fullname: z.
          isHf: false
          isPro: false
          name: anon8231489123
          type: user
        html: '<p>Which GPTQ commit did you use?</p>

          '
        raw: Which GPTQ commit did you use?
        updatedAt: '2023-04-10T20:40:38.977Z'
      numEdits: 0
      reactions: []
    id: 64347446938d07505bb9380f
    type: comment
  author: anon8231489123
  content: Which GPTQ commit did you use?
  created_at: 2023-04-10 19:40:38+00:00
  edited: false
  hidden: false
  id: 64347446938d07505bb9380f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/743211009c3708f4b70d8a504d51d010.svg
      fullname: Un Touch
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: GamerUntouch
      type: user
    createdAt: '2023-04-10T23:13:58.000Z'
    data:
      edited: false
      editors:
      - GamerUntouch
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/743211009c3708f4b70d8a504d51d010.svg
          fullname: Un Touch
          isHf: false
          isPro: false
          name: GamerUntouch
          type: user
        html: '<p>I think it was 4b7c8bd, but I''m using the latest version on the
          cuda branch and it''s working on my end.</p>

          '
        raw: I think it was 4b7c8bd, but I'm using the latest version on the cuda
          branch and it's working on my end.
        updatedAt: '2023-04-10T23:13:58.459Z'
      numEdits: 0
      reactions: []
    id: 64349836b1d842fdbe7f9976
    type: comment
  author: GamerUntouch
  content: I think it was 4b7c8bd, but I'm using the latest version on the cuda branch
    and it's working on my end.
  created_at: 2023-04-10 22:13:58+00:00
  edited: false
  hidden: false
  id: 64349836b1d842fdbe7f9976
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-11T07:45:30.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah if a GPTQ model is created with the latest GPTQ-for-LLaMa code,
          you then have to use that same latest GPTQ-for-LLaMa code in <code>text-generation-webui/repositories</code>
          otherwise you get gibberish.</p>

          <p>I include  instructions on how to update <code>text-generation-webui</code>
          with the latest GPTQ code in my GPTQ models. Example: <a href="https://huggingface.co/TheBloke/vicuna-7B-GPTQ-4bit-128g">https://huggingface.co/TheBloke/vicuna-7B-GPTQ-4bit-128g</a></p>

          <p>Alternatively, if the GPTQ is done with the GPTQ-for-LLaMa fork provided
          by oobabooga (<a rel="nofollow" href="https://github.com/oobabooga/GPTQ-for-LLaMa">https://github.com/oobabooga/GPTQ-for-LLaMa</a>)
          then it will work immediately in text-generation-webui.  However I found
          with this older code you cannot use <code>--act-order</code> in the GPTQ
          settings, as otherwise it again produces gibberish.  And without <code>--act-order</code>
          the inference results may be slightly lower quality (I don''t know how much.)</p>

          <p>On my Koala repos, eg <a href="https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g">https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g</a>,
          I also provided an older GPTQ made with oobabooga''s fork.  But it takes
          a lot of time to produce three GPTQ files for every repo!</p>

          '
        raw: 'Yeah if a GPTQ model is created with the latest GPTQ-for-LLaMa code,
          you then have to use that same latest GPTQ-for-LLaMa code in `text-generation-webui/repositories`
          otherwise you get gibberish.


          I include  instructions on how to update `text-generation-webui` with the
          latest GPTQ code in my GPTQ models. Example: https://huggingface.co/TheBloke/vicuna-7B-GPTQ-4bit-128g


          Alternatively, if the GPTQ is done with the GPTQ-for-LLaMa fork provided
          by oobabooga (https://github.com/oobabooga/GPTQ-for-LLaMa) then it will
          work immediately in text-generation-webui.  However I found with this older
          code you cannot use `--act-order` in the GPTQ settings, as otherwise it
          again produces gibberish.  And without `--act-order` the inference results
          may be slightly lower quality (I don''t know how much.)


          On my Koala repos, eg https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g,
          I also provided an older GPTQ made with oobabooga''s fork.  But it takes
          a lot of time to produce three GPTQ files for every repo!'
        updatedAt: '2023-04-11T07:46:48.428Z'
      numEdits: 1
      reactions: []
    id: 6435101a65d578e85b7ea9c6
    type: comment
  author: TheBloke
  content: 'Yeah if a GPTQ model is created with the latest GPTQ-for-LLaMa code, you
    then have to use that same latest GPTQ-for-LLaMa code in `text-generation-webui/repositories`
    otherwise you get gibberish.


    I include  instructions on how to update `text-generation-webui` with the latest
    GPTQ code in my GPTQ models. Example: https://huggingface.co/TheBloke/vicuna-7B-GPTQ-4bit-128g


    Alternatively, if the GPTQ is done with the GPTQ-for-LLaMa fork provided by oobabooga
    (https://github.com/oobabooga/GPTQ-for-LLaMa) then it will work immediately in
    text-generation-webui.  However I found with this older code you cannot use `--act-order`
    in the GPTQ settings, as otherwise it again produces gibberish.  And without `--act-order`
    the inference results may be slightly lower quality (I don''t know how much.)


    On my Koala repos, eg https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g,
    I also provided an older GPTQ made with oobabooga''s fork.  But it takes a lot
    of time to produce three GPTQ files for every repo!'
  created_at: 2023-04-11 06:45:30+00:00
  edited: true
  hidden: false
  id: 6435101a65d578e85b7ea9c6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: GamerUntouch/LLaMa-Storytelling-4Bit
repo_type: model
status: open
target_branch: null
title: Seems to generate gibberish for me
