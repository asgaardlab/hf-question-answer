!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nixgd
conflicting_files: []
created_at: 2024-01-24 09:42:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ef23e9bd065674f6dad0bc85ec468dd6.svg
      fullname: Nix Goldowsky-Dill
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nixgd
      type: user
    createdAt: '2024-01-24T09:42:32.000Z'
    data:
      edited: false
      editors:
      - nixgd
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9345076084136963
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ef23e9bd065674f6dad0bc85ec468dd6.svg
          fullname: Nix Goldowsky-Dill
          isHf: false
          isPro: false
          name: nixgd
          type: user
        html: '<p>The model appears to have been trained with context window = 512,
          not 2048 as claimed here. This can be seen by looking at the average loss
          by sequence position on the GPT4 tiny stories dataset (packed into inputs
          of length 2048):</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/65b0cb8770773c0ab8fde1e0/qXnk9-RtXGrXlUlkZCxl3.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/65b0cb8770773c0ab8fde1e0/qXnk9-RtXGrXlUlkZCxl3.png"></a></p>

          <p>It would be great to get this changed (for all tinystories models), as
          the current config is misleading.</p>

          '
        raw: 'The model appears to have been trained with context window = 512, not
          2048 as claimed here. This can be seen by looking at the average loss by
          sequence position on the GPT4 tiny stories dataset (packed into inputs of
          length 2048):


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/65b0cb8770773c0ab8fde1e0/qXnk9-RtXGrXlUlkZCxl3.png)


          It would be great to get this changed (for all tinystories models), as the
          current config is misleading.'
        updatedAt: '2024-01-24T09:42:32.847Z'
      numEdits: 0
      reactions: []
    id: 65b0db88a6eb6610a9f9725a
    type: comment
  author: nixgd
  content: 'The model appears to have been trained with context window = 512, not
    2048 as claimed here. This can be seen by looking at the average loss by sequence
    position on the GPT4 tiny stories dataset (packed into inputs of length 2048):


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/65b0cb8770773c0ab8fde1e0/qXnk9-RtXGrXlUlkZCxl3.png)


    It would be great to get this changed (for all tinystories models), as the current
    config is misleading.'
  created_at: 2024-01-24 09:42:32+00:00
  edited: false
  hidden: false
  id: 65b0db88a6eb6610a9f9725a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/ef23e9bd065674f6dad0bc85ec468dd6.svg
      fullname: Nix Goldowsky-Dill
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nixgd
      type: user
    createdAt: '2024-01-24T09:42:33.000Z'
    data:
      oid: 97b7275022f4821a71ad48d62e0ee0b2c802e33c
      parents:
      - 85c27af33c821254dc9b5a90618b4b10c57251d3
      subject: Correct maximum positional embeddings
    id: 65b0db890000000000000000
    type: commit
  author: nixgd
  created_at: 2024-01-24 09:42:33+00:00
  id: 65b0db890000000000000000
  oid: 97b7275022f4821a71ad48d62e0ee0b2c802e33c
  summary: Correct maximum positional embeddings
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652501708302-noauth.jpeg?w=200&h=200&f=face
      fullname: Corianas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Corianas
      type: user
    createdAt: '2024-01-25T01:42:42.000Z'
    data:
      edited: false
      editors:
      - Corianas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6972146034240723
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1652501708302-noauth.jpeg?w=200&h=200&f=face
          fullname: Corianas
          isHf: false
          isPro: false
          name: Corianas
          type: user
        html: "<p>You are quite correct, not sure what is up with the huggingface\
          \ models as:<br>From the paper: OurmodelsareavailableonHuggingfacenamedTinyStories-1M/3M/9M/28M/33M/1Layer/2LayerandTinyStories-Instruct-\u2217\
          .We use GPT-Neoarchitecturewithwindowsize256andcontext length512 .WeuseGPT-Neotokenizerbut\
          \ only keep the top 10K most common tokens.</p>\n"
        raw: "You are quite correct, not sure what is up with the huggingface models\
          \ as:\nFrom the paper: OurmodelsareavailableonHuggingfacenamedTinyStories-1M/3M/9M/28M/33M/1Layer/2LayerandTinyStories-Instruct-\u2217\
          .We use GPT-Neoarchitecturewithwindowsize256andcontext length512 .WeuseGPT-Neotokenizerbut\
          \ only keep the top 10K most common tokens."
        updatedAt: '2024-01-25T01:42:42.384Z'
      numEdits: 0
      reactions: []
    id: 65b1bc92b389ca2de134a175
    type: comment
  author: Corianas
  content: "You are quite correct, not sure what is up with the huggingface models\
    \ as:\nFrom the paper: OurmodelsareavailableonHuggingfacenamedTinyStories-1M/3M/9M/28M/33M/1Layer/2LayerandTinyStories-Instruct-\u2217\
    .We use GPT-Neoarchitecturewithwindowsize256andcontext length512 .WeuseGPT-Neotokenizerbut\
    \ only keep the top 10K most common tokens."
  created_at: 2024-01-25 01:42:42+00:00
  edited: false
  hidden: false
  id: 65b1bc92b389ca2de134a175
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/22bb971597e9f3abfa343280a9d0f65f.svg
      fullname: Ronen Eldan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: roneneldan
      type: user
    createdAt: '2024-01-25T05:47:14.000Z'
    data:
      edited: false
      editors:
      - roneneldan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9031273126602173
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/22bb971597e9f3abfa343280a9d0f65f.svg
          fullname: Ronen Eldan
          isHf: false
          isPro: false
          name: roneneldan
          type: user
        html: '<p>You''re right. Our paper does indicate that we use 512 seq len in
          training, but the model''s config should be updated...</p>

          '
        raw: You're right. Our paper does indicate that we use 512 seq len in training,
          but the model's config should be updated...
        updatedAt: '2024-01-25T05:47:14.436Z'
      numEdits: 0
      reactions: []
    id: 65b1f5e2cd9b73cf844f9412
    type: comment
  author: roneneldan
  content: You're right. Our paper does indicate that we use 512 seq len in training,
    but the model's config should be updated...
  created_at: 2024-01-25 05:47:14+00:00
  edited: false
  hidden: false
  id: 65b1f5e2cd9b73cf844f9412
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 17
repo_id: roneneldan/TinyStories-33M
repo_type: model
status: open
target_branch: refs/heads/main
title: Correct maximum positional embeddings
