!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Alealejandrooo
conflicting_files: null
created_at: 2024-01-08 17:48:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b70da17010bf491d4ba8312097adf057.svg
      fullname: Alessandro Alviani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Alealejandrooo
      type: user
    createdAt: '2024-01-08T17:48:13.000Z'
    data:
      edited: true
      editors:
      - Alealejandrooo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5892428755760193
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b70da17010bf491d4ba8312097adf057.svg
          fullname: Alessandro Alviani
          isHf: false
          isPro: false
          name: Alealejandrooo
          type: user
        html: '<p>The model will output:<br>["I''m sorry. I''m sorry. I''m sorry."]
          </p>

          <p>when prompted on an empty string:</p>

          <p>Code to reproduce the error:</p>

          <p>''''''from transformers import MarianTokenizer, AutoModelForSeq2SeqLM<br>name
          = "Helsinki-NLP/opus-mt-sv-en"<br>model = AutoModelForSeq2SeqLM.from_pretrained(name)<br>tokenizer
          = MarianTokenizer.from_pretrained(name)<br>inputs = tokenizer(" ", padding=True,
          truncation=True, return_tensors="pt")<br>translated_outputs = model.generate(**inputs)<br>translations
          = [tokenizer.decode(output, skip_special_tokens=True) for output in translated_outputs]''''''</p>

          <p>Anyone having the same issue and possibly a solution to fix it? </p>

          <p>Thanks! </p>

          '
        raw: "The model will output: \n[\"I'm sorry. I'm sorry. I'm sorry.\"] \n\n\
          when prompted on an empty string:\n\nCode to reproduce the error:\n\n'''from\
          \ transformers import MarianTokenizer, AutoModelForSeq2SeqLM\nname = \"\
          Helsinki-NLP/opus-mt-sv-en\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(name)\n\
          tokenizer = MarianTokenizer.from_pretrained(name)\ninputs = tokenizer(\"\
          \ \", padding=True, truncation=True, return_tensors=\"pt\")\ntranslated_outputs\
          \ = model.generate(**inputs)\ntranslations = [tokenizer.decode(output, skip_special_tokens=True)\
          \ for output in translated_outputs]'''\n\nAnyone having the same issue and\
          \ possibly a solution to fix it? \n\nThanks! "
        updatedAt: '2024-01-08T17:49:10.126Z'
      numEdits: 2
      reactions: []
    id: 659c355d881feb6b9ae4b3c0
    type: comment
  author: Alealejandrooo
  content: "The model will output: \n[\"I'm sorry. I'm sorry. I'm sorry.\"] \n\nwhen\
    \ prompted on an empty string:\n\nCode to reproduce the error:\n\n'''from transformers\
    \ import MarianTokenizer, AutoModelForSeq2SeqLM\nname = \"Helsinki-NLP/opus-mt-sv-en\"\
    \nmodel = AutoModelForSeq2SeqLM.from_pretrained(name)\ntokenizer = MarianTokenizer.from_pretrained(name)\n\
    inputs = tokenizer(\" \", padding=True, truncation=True, return_tensors=\"pt\"\
    )\ntranslated_outputs = model.generate(**inputs)\ntranslations = [tokenizer.decode(output,\
    \ skip_special_tokens=True) for output in translated_outputs]'''\n\nAnyone having\
    \ the same issue and possibly a solution to fix it? \n\nThanks! "
  created_at: 2024-01-08 17:48:13+00:00
  edited: true
  hidden: false
  id: 659c355d881feb6b9ae4b3c0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Helsinki-NLP/opus-mt-sv-en
repo_type: model
status: open
target_branch: null
title: Wrong generations on empty strings
