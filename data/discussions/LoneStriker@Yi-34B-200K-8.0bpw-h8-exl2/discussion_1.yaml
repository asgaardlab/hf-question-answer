!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bdambrosio
conflicting_files: null
created_at: 2023-11-12 17:35:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a5cbe88512c48efa55279c262e84c396.svg
      fullname: Bruce D'Ambrosio
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bdambrosio
      type: user
    createdAt: '2023-11-12T17:35:38.000Z'
    data:
      edited: false
      editors:
      - bdambrosio
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.933573305606842
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a5cbe88512c48efa55279c262e84c396.svg
          fullname: Bruce D'Ambrosio
          isHf: false
          isPro: false
          name: bdambrosio
          type: user
        html: '<p>Sorry if this has been asked - do these converted models need the
          .py files from the original Yi models?</p>

          '
        raw: Sorry if this has been asked - do these converted models need the .py
          files from the original Yi models?
        updatedAt: '2023-11-12T17:35:38.117Z'
      numEdits: 0
      reactions: []
    id: 65510ceab79a662d526f01e4
    type: comment
  author: bdambrosio
  content: Sorry if this has been asked - do these converted models need the .py files
    from the original Yi models?
  created_at: 2023-11-12 17:35:38+00:00
  edited: false
  hidden: false
  id: 65510ceab79a662d526f01e4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-11-12T19:41:43.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9737151265144348
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>It''s a bit complicated.  I believe you need the one for tokenization
          at a minimum. Earlier fine-tunes of Yi 34B like this one used the original
          base models as released. For some of the later fine-tunes, they are typically
          based on the Yi 34b-Llama model that renames two layers from Yi back to
          what they were in standard Llama.  With these later fine-tunes, you do not
          need to trust remote code to run.  But, earlier fine-tunes will need trust
          remote.</p>

          '
        raw: It's a bit complicated.  I believe you need the one for tokenization
          at a minimum. Earlier fine-tunes of Yi 34B like this one used the original
          base models as released. For some of the later fine-tunes, they are typically
          based on the Yi 34b-Llama model that renames two layers from Yi back to
          what they were in standard Llama.  With these later fine-tunes, you do not
          need to trust remote code to run.  But, earlier fine-tunes will need trust
          remote.
        updatedAt: '2023-11-12T19:41:43.232Z'
      numEdits: 0
      reactions: []
    id: 65512a77f908d2479a865cde
    type: comment
  author: LoneStriker
  content: It's a bit complicated.  I believe you need the one for tokenization at
    a minimum. Earlier fine-tunes of Yi 34B like this one used the original base models
    as released. For some of the later fine-tunes, they are typically based on the
    Yi 34b-Llama model that renames two layers from Yi back to what they were in standard
    Llama.  With these later fine-tunes, you do not need to trust remote code to run.  But,
    earlier fine-tunes will need trust remote.
  created_at: 2023-11-12 19:41:43+00:00
  edited: false
  hidden: false
  id: 65512a77f908d2479a865cde
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a5cbe88512c48efa55279c262e84c396.svg
      fullname: Bruce D'Ambrosio
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bdambrosio
      type: user
    createdAt: '2023-11-12T21:39:31.000Z'
    data:
      edited: true
      editors:
      - bdambrosio
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9194520711898804
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a5cbe88512c48efa55279c262e84c396.svg
          fullname: Bruce D'Ambrosio
          isHf: false
          isPro: false
          name: bdambrosio
          type: user
        html: '<p>Yup, I''m running your 6.0bpw of Yi-34B just fine with just the
          tokenizer .py ( and newest exllamav2, that accepts a yi param, but not using
          that - hmm, or maybe I am, forget)<br>Had trouble with 34B-200k-8.0bpw,
          said not enough vram. (2x4090!)<br>I''ll try other variants.<br>btw - prompt?<br>I''m
          using &lt;|Human|&gt;: and &lt;|Assistant|&gt;:  (single space after each,
          just as a guess, since I saw &lt;|Human|&gt;,  &lt;|Assistant|&gt;, and
          &lt;|System|&gt;  early in the tokens.json. But there was also &lt;|endoftext|&gt;,
          &lt;|startoftext|&gt;, not clear the : is appropriate after &lt;|Human|&gt;,
          its a large experiment space, any help appreciated. Thanks!</p>

          <p>Ah - I found this thread in the yi github: <a rel="nofollow" href="https://github.com/01-ai/Yi/issues/30">https://github.com/01-ai/Yi/issues/30</a><br>doesn''t
          really clarify, but they claim &lt;|Huma|&gt; etc aren''t used in current
          model, although &lt;|endoftext|&gt; IS important. confusing.</p>

          <p>Update - switched to your spicyboros 8bpw model. now trying llama-2 prompt,
          same one I use w jondurbin''s models. still not having much luck. Example
          prompt:</p>

          <p>\n[INST] &lt;&gt;\nyou are a chatty ai.\n&lt;&gt;\nhi. Can I call you
          Alice? \n[/INST]    (note what appears as &lt;&gt; is actually the correct
          SYS prompt, doesn''t make it through markdown_</p>

          '
        raw: 'Yup, I''m running your 6.0bpw of Yi-34B just fine with just the tokenizer
          .py ( and newest exllamav2, that accepts a yi param, but not using that
          - hmm, or maybe I am, forget)

          Had trouble with 34B-200k-8.0bpw, said not enough vram. (2x4090!)

          I''ll try other variants.

          btw - prompt?

          I''m using <|Human|>: and <|Assistant|>:  (single space after each, just
          as a guess, since I saw <|Human|>,  <|Assistant|>, and <|System|>  early
          in the tokens.json. But there was also <|endoftext|>, <|startoftext|>, not
          clear the : is appropriate after <|Human|>, its a large experiment space,
          any help appreciated. Thanks!


          Ah - I found this thread in the yi github: https://github.com/01-ai/Yi/issues/30

          doesn''t really clarify, but they claim <|Huma|> etc aren''t used in current
          model, although <|endoftext|> IS important. confusing.


          Update - switched to your spicyboros 8bpw model. now trying llama-2 prompt,
          same one I use w jondurbin''s models. still not having much luck. Example
          prompt:


          \n[INST] <<SYS>>\nyou are a chatty ai.\n<</SYS>>\nhi. Can I call you Alice?
          \n[/INST]    (note what appears as <> is actually the correct SYS prompt,
          doesn''t make it through markdown_'
        updatedAt: '2023-11-13T02:51:02.761Z'
      numEdits: 6
      reactions: []
    id: 65514613f908d2479a8a68bb
    type: comment
  author: bdambrosio
  content: 'Yup, I''m running your 6.0bpw of Yi-34B just fine with just the tokenizer
    .py ( and newest exllamav2, that accepts a yi param, but not using that - hmm,
    or maybe I am, forget)

    Had trouble with 34B-200k-8.0bpw, said not enough vram. (2x4090!)

    I''ll try other variants.

    btw - prompt?

    I''m using <|Human|>: and <|Assistant|>:  (single space after each, just as a
    guess, since I saw <|Human|>,  <|Assistant|>, and <|System|>  early in the tokens.json.
    But there was also <|endoftext|>, <|startoftext|>, not clear the : is appropriate
    after <|Human|>, its a large experiment space, any help appreciated. Thanks!


    Ah - I found this thread in the yi github: https://github.com/01-ai/Yi/issues/30

    doesn''t really clarify, but they claim <|Huma|> etc aren''t used in current model,
    although <|endoftext|> IS important. confusing.


    Update - switched to your spicyboros 8bpw model. now trying llama-2 prompt, same
    one I use w jondurbin''s models. still not having much luck. Example prompt:


    \n[INST] <<SYS>>\nyou are a chatty ai.\n<</SYS>>\nhi. Can I call you Alice? \n[/INST]    (note
    what appears as <> is actually the correct SYS prompt, doesn''t make it through
    markdown_'
  created_at: 2023-11-12 21:39:31+00:00
  edited: true
  hidden: false
  id: 65514613f908d2479a8a68bb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: LoneStriker/Yi-34B-200K-8.0bpw-h8-exl2
repo_type: model
status: open
target_branch: null
title: trust remote code?
