!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TS0001
conflicting_files: null
created_at: 2023-06-05 20:48:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/76e0c7207e584ee772789eca37d8902c.svg
      fullname: Tamer Shafik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TS0001
      type: user
    createdAt: '2023-06-05T21:48:56.000Z'
    data:
      edited: false
      editors:
      - TS0001
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9234107136726379
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/76e0c7207e584ee772789eca37d8902c.svg
          fullname: Tamer Shafik
          isHf: false
          isPro: false
          name: TS0001
          type: user
        html: "<p>Awesome work <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>!\
          \ Thank you.</p>\n<p>I have this running on runpod.io with Text Generation\
          \ UI, on an A100 with 80 GB VRAM and 125 GB RAM 16 vCPU. Performance is\
          \ quite slow. I'm wondering if anyone has it running with reasonable performance,\
          \ and if so, on what hardware?</p>\n<p>Thanks!</p>\n"
        raw: "Awesome work @TheBloke! Thank you.\r\n\r\nI have this running on runpod.io\
          \ with Text Generation UI, on an A100 with 80 GB VRAM and 125 GB RAM 16\
          \ vCPU. Performance is quite slow. I'm wondering if anyone has it running\
          \ with reasonable performance, and if so, on what hardware?\r\n\r\nThanks!"
        updatedAt: '2023-06-05T21:48:56.303Z'
      numEdits: 0
      reactions: []
    id: 647e5848cfca67bc50fe0291
    type: comment
  author: TS0001
  content: "Awesome work @TheBloke! Thank you.\r\n\r\nI have this running on runpod.io\
    \ with Text Generation UI, on an A100 with 80 GB VRAM and 125 GB RAM 16 vCPU.\
    \ Performance is quite slow. I'm wondering if anyone has it running with reasonable\
    \ performance, and if so, on what hardware?\r\n\r\nThanks!"
  created_at: 2023-06-05 20:48:56+00:00
  edited: false
  hidden: false
  id: 647e5848cfca67bc50fe0291
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-06-05T23:14:52.000Z'
    data:
      edited: false
      editors:
      - mancub
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9907206296920776
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
          fullname: Man Cub
          isHf: false
          isPro: false
          name: mancub
          type: user
        html: '<p>I think the issue is AutoGPTQ which is slow, but I don''t know enough
          about it, only what I''ve been reading people say.</p>

          <p>I get ~2 t/s on my 3090 with this model which I consider reasonable for
          the setup (WSL2). :)</p>

          '
        raw: 'I think the issue is AutoGPTQ which is slow, but I don''t know enough
          about it, only what I''ve been reading people say.


          I get ~2 t/s on my 3090 with this model which I consider reasonable for
          the setup (WSL2). :)'
        updatedAt: '2023-06-05T23:14:52.784Z'
      numEdits: 0
      reactions: []
    id: 647e6c6cf14eafc3b4611e1d
    type: comment
  author: mancub
  content: 'I think the issue is AutoGPTQ which is slow, but I don''t know enough
    about it, only what I''ve been reading people say.


    I get ~2 t/s on my 3090 with this model which I consider reasonable for the setup
    (WSL2). :)'
  created_at: 2023-06-05 22:14:52+00:00
  edited: false
  hidden: false
  id: 647e6c6cf14eafc3b4611e1d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/182b1994ad37ed23d8a066caeaef83d5.svg
      fullname: dario
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: prudant
      type: user
    createdAt: '2023-06-30T02:58:56.000Z'
    data:
      edited: false
      editors:
      - prudant
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9810248017311096
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/182b1994ad37ed23d8a066caeaef83d5.svg
          fullname: dario
          isHf: false
          isPro: false
          name: prudant
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mancub&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mancub\">@<span class=\"\
          underline\">mancub</span></a></span>\n\n\t</span></span> how much vram does\
          \ have your 3090? thanks</p>\n"
        raw: '@mancub how much vram does have your 3090? thanks'
        updatedAt: '2023-06-30T02:58:56.634Z'
      numEdits: 0
      reactions: []
    id: 649e44f0146ec61a0b6c5cf7
    type: comment
  author: prudant
  content: '@mancub how much vram does have your 3090? thanks'
  created_at: 2023-06-30 01:58:56+00:00
  edited: false
  hidden: false
  id: 649e44f0146ec61a0b6c5cf7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/182b1994ad37ed23d8a066caeaef83d5.svg
      fullname: dario
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: prudant
      type: user
    createdAt: '2023-06-30T03:00:10.000Z'
    data:
      edited: false
      editors:
      - prudant
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9142398834228516
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/182b1994ad37ed23d8a066caeaef83d5.svg
          fullname: dario
          isHf: false
          isPro: false
          name: prudant
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TS0001&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TS0001\">@<span class=\"\
          underline\">TS0001</span></a></span>\n\n\t</span></span> how much token/sec\
          \ do you get on the  A100? thanks</p>\n"
        raw: '@TS0001 how much token/sec do you get on the  A100? thanks'
        updatedAt: '2023-06-30T03:00:10.008Z'
      numEdits: 0
      reactions: []
    id: 649e453a59ff3a11c1b81c26
    type: comment
  author: prudant
  content: '@TS0001 how much token/sec do you get on the  A100? thanks'
  created_at: 2023-06-30 02:00:10+00:00
  edited: false
  hidden: false
  id: 649e453a59ff3a11c1b81c26
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/xV4Xlk01BsqfRqxAWsO8Z.png?w=200&h=200&f=face
      fullname: Viktor Ferenczi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: viktor-ferenczi
      type: user
    createdAt: '2023-07-02T02:02:00.000Z'
    data:
      edited: false
      editors:
      - viktor-ferenczi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9535784125328064
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/xV4Xlk01BsqfRqxAWsO8Z.png?w=200&h=200&f=face
          fullname: Viktor Ferenczi
          isHf: false
          isPro: false
          name: viktor-ferenczi
          type: user
        html: '<p>What is the fastest way to run this model on GPU?</p>

          '
        raw: What is the fastest way to run this model on GPU?
        updatedAt: '2023-07-02T02:02:00.164Z'
      numEdits: 0
      reactions: []
    id: 64a0da98712900fcf270d2c0
    type: comment
  author: viktor-ferenczi
  content: What is the fastest way to run this model on GPU?
  created_at: 2023-07-02 01:02:00+00:00
  edited: false
  hidden: false
  id: 64a0da98712900fcf270d2c0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/WizardLM-Uncensored-Falcon-40B-GPTQ
repo_type: model
status: open
target_branch: null
title: What hardware do I need for reasonable performance?
