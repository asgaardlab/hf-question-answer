!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Akagi951620
conflicting_files: null
created_at: 2023-06-26 04:41:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8cf8924684004b5de977107b914a3c78.svg
      fullname: HengWang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Akagi951620
      type: user
    createdAt: '2023-06-26T05:41:53.000Z'
    data:
      edited: false
      editors:
      - Akagi951620
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9341024160385132
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8cf8924684004b5de977107b914a3c78.svg
          fullname: HengWang
          isHf: false
          isPro: false
          name: Akagi951620
          type: user
        html: '<p>Hi! I used the model finetuned on the Gov-Report training dataset
          in this repository to evaluate the RUGUE-2 on validation and test datasets.
          However, I have not reached the reported results of Table 3 in the paper,
          15.3% vs 19.6%. I have found a solution <a rel="nofollow" href="https://github.com/abertsch72/unlimiformer/issues/17">https://github.com/abertsch72/unlimiformer/issues/17</a>,
          but it still needs to fine-tune the fine-tuned model. I am confused.</p>

          '
        raw: Hi! I used the model finetuned on the Gov-Report training dataset in
          this repository to evaluate the RUGUE-2 on validation and test datasets.
          However, I have not reached the reported results of Table 3 in the paper,
          15.3% vs 19.6%. I have found a solution https://github.com/abertsch72/unlimiformer/issues/17,
          but it still needs to fine-tune the fine-tuned model. I am confused.
        updatedAt: '2023-06-26T05:41:53.066Z'
      numEdits: 0
      reactions: []
    id: 6499252173e20520c1df6404
    type: comment
  author: Akagi951620
  content: Hi! I used the model finetuned on the Gov-Report training dataset in this
    repository to evaluate the RUGUE-2 on validation and test datasets. However, I
    have not reached the reported results of Table 3 in the paper, 15.3% vs 19.6%.
    I have found a solution https://github.com/abertsch72/unlimiformer/issues/17,
    but it still needs to fine-tune the fine-tuned model. I am confused.
  created_at: 2023-06-26 04:41:53+00:00
  edited: false
  hidden: false
  id: 6499252173e20520c1df6404
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dacd7792a37b4abf1ef67cd4a0312924.svg
      fullname: Amanda Bertsch
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: abertsch
      type: user
    createdAt: '2023-06-28T19:28:17.000Z'
    data:
      edited: false
      editors:
      - abertsch
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8780023455619812
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dacd7792a37b4abf1ef67cd4a0312924.svg
          fullname: Amanda Bertsch
          isHf: false
          isPro: false
          name: abertsch
          type: user
        html: '<p>Hi, and sorry for the late response-- I didn''t know about the discussion
          feature here :) </p>

          <p>If you use the model without cloning the unlimiformer repo and using
          the --test_unlimiformer argument, it will not use the Unlimiformer method
          and the results will be lower. The set of arguments that Uri provides in
          the issue you linked does not finetune the model (It provides some training
          arguments like learning rate and train batch size, but these are ignored
          because it does not set do_train=True). If you run with that set of arguments,
          do you still see a difference in ROUGE from the table? </p>

          '
        raw: "Hi, and sorry for the late response-- I didn't know about the discussion\
          \ feature here :) \n\nIf you use the model without cloning the unlimiformer\
          \ repo and using the --test_unlimiformer argument, it will not use the Unlimiformer\
          \ method and the results will be lower. The set of arguments that Uri provides\
          \ in the issue you linked does not finetune the model (It provides some\
          \ training arguments like learning rate and train batch size, but these\
          \ are ignored because it does not set do_train=True). If you run with that\
          \ set of arguments, do you still see a difference in ROUGE from the table? "
        updatedAt: '2023-06-28T19:28:17.155Z'
      numEdits: 0
      reactions: []
    id: 649c89d1722486c3ce6ec6ee
    type: comment
  author: abertsch
  content: "Hi, and sorry for the late response-- I didn't know about the discussion\
    \ feature here :) \n\nIf you use the model without cloning the unlimiformer repo\
    \ and using the --test_unlimiformer argument, it will not use the Unlimiformer\
    \ method and the results will be lower. The set of arguments that Uri provides\
    \ in the issue you linked does not finetune the model (It provides some training\
    \ arguments like learning rate and train batch size, but these are ignored because\
    \ it does not set do_train=True). If you run with that set of arguments, do you\
    \ still see a difference in ROUGE from the table? "
  created_at: 2023-06-28 18:28:17+00:00
  edited: false
  hidden: false
  id: 649c89d1722486c3ce6ec6ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8cf8924684004b5de977107b914a3c78.svg
      fullname: HengWang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Akagi951620
      type: user
    createdAt: '2023-07-11T02:51:13.000Z'
    data:
      edited: false
      editors:
      - Akagi951620
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9572346210479736
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8cf8924684004b5de977107b914a3c78.svg
          fullname: HengWang
          isHf: false
          isPro: false
          name: Akagi951620
          type: user
        html: '<p>I used the public github repo and reproduce the results of GovReport
          and ScreenSumm. However, the result of the BookSum dataset has not been
          reproduced. Thank you very much.</p>

          '
        raw: I used the public github repo and reproduce the results of GovReport
          and ScreenSumm. However, the result of the BookSum dataset has not been
          reproduced. Thank you very much.
        updatedAt: '2023-07-11T02:51:13.102Z'
      numEdits: 0
      reactions: []
    id: 64acc3a1b7e4b2c1ce355dcf
    type: comment
  author: Akagi951620
  content: I used the public github repo and reproduce the results of GovReport and
    ScreenSumm. However, the result of the BookSum dataset has not been reproduced.
    Thank you very much.
  created_at: 2023-07-11 01:51:13+00:00
  edited: false
  hidden: false
  id: 64acc3a1b7e4b2c1ce355dcf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dacd7792a37b4abf1ef67cd4a0312924.svg
      fullname: Amanda Bertsch
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: abertsch
      type: user
    createdAt: '2023-07-21T14:25:14.000Z'
    data:
      edited: false
      editors:
      - abertsch
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9484724402427673
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dacd7792a37b4abf1ef67cd4a0312924.svg
          fullname: Amanda Bertsch
          isHf: false
          isPro: false
          name: abertsch
          type: user
        html: '<p>Thanks for replicating, I appreciate it! Can you share what arguments
          you used for BookSum and I''ll look into this further?</p>

          '
        raw: Thanks for replicating, I appreciate it! Can you share what arguments
          you used for BookSum and I'll look into this further?
        updatedAt: '2023-07-21T14:25:14.285Z'
      numEdits: 0
      reactions: []
    id: 64ba954a367f9a05963a7518
    type: comment
  author: abertsch
  content: Thanks for replicating, I appreciate it! Can you share what arguments you
    used for BookSum and I'll look into this further?
  created_at: 2023-07-21 13:25:14+00:00
  edited: false
  hidden: false
  id: 64ba954a367f9a05963a7518
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: abertsch/bart-base-govreport
repo_type: model
status: open
target_branch: null
title: Reproduce the bart-base + test unlimiformer on the gov-report datasets
