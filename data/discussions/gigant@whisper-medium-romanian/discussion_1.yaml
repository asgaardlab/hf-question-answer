!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Equilibrier
conflicting_files: null
created_at: 2023-02-13 11:01:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/62ebe64f3a8f6bd3479ca23c26521521.svg
      fullname: Cosmin Popescu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Equilibrier
      type: user
    createdAt: '2023-02-13T11:01:32.000Z'
    data:
      edited: false
      editors:
      - Equilibrier
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/62ebe64f3a8f6bd3479ca23c26521521.svg
          fullname: Cosmin Popescu
          isHf: false
          isPro: false
          name: Equilibrier
          type: user
        html: '<p>Hi, in your example you are loading an audio dataset contents, but
          I would like to use an external file to test this fork.<br>How can I load
          a simple wav/mp3 in the python code you provided, instead of the dataset
          ?</p>

          '
        raw: "Hi, in your example you are loading an audio dataset contents, but I\
          \ would like to use an external file to test this fork.\r\nHow can I load\
          \ a simple wav/mp3 in the python code you provided, instead of the dataset\
          \ ?"
        updatedAt: '2023-02-13T11:01:32.116Z'
      numEdits: 0
      reactions: []
    id: 63ea188cafddf881179db717
    type: comment
  author: Equilibrier
  content: "Hi, in your example you are loading an audio dataset contents, but I would\
    \ like to use an external file to test this fork.\r\nHow can I load a simple wav/mp3\
    \ in the python code you provided, instead of the dataset ?"
  created_at: 2023-02-13 11:01:32+00:00
  edited: false
  hidden: false
  id: 63ea188cafddf881179db717
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1645712223620-60d35154d7b174177faabd55.jpeg?w=200&h=200&f=face
      fullname: "Th\xE9o Gigant"
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: gigant
      type: user
    createdAt: '2023-02-24T09:35:25.000Z'
    data:
      edited: true
      editors:
      - gigant
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1645712223620-60d35154d7b174177faabd55.jpeg?w=200&h=200&f=face
          fullname: "Th\xE9o Gigant"
          isHf: false
          isPro: false
          name: gigant
          type: user
        html: "<p>Hi,</p>\n<p>If you want to have the output, you can use the demo\
          \ space ( <a href=\"https://huggingface.co/spaces/gigant/romanian-whisper\"\
          >https://huggingface.co/spaces/gigant/romanian-whisper</a> ) in which you\
          \ can use either audio files or record with your microphone. Otherwhise\
          \ if you run the code by yourself, you can use <code>torchaudio.load</code>\
          \ to load an array from a file, just make sure that you you a sample rate\
          \ of 16kHz because that is the one used for training.<br>For instance you\
          \ can resample using torchaudio like this:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">import</span> torchaudio.functional <span\
          \ class=\"hljs-keyword\">as</span> F\n\n<span class=\"hljs-keyword\">def</span>\
          \ <span class=\"hljs-title function_\">resample</span>(<span class=\"hljs-params\"\
          >sample, resample_rate = <span class=\"hljs-number\">16000</span></span>):\n\
          \  sample_rate = sample[<span class=\"hljs-number\">1</span>]\n  resampled_waveform\
          \ = F.resample(sample[<span class=\"hljs-number\">0</span>], sample_rate,\
          \ resample_rate, lowpass_filter_width=<span class=\"hljs-number\">512</span>,\
          \ rolloff=<span class=\"hljs-number\">0.99</span>)\n  <span class=\"hljs-keyword\"\
          >return</span> resampled_waveform\n</code></pre>\n<p>If you are using the\
          \ <code>pipeline</code> from transformers, you can give the filepath as\
          \ is, check the code in <a href=\"https://huggingface.co/spaces/gigant/romanian-whisper/blob/main/app.py\"\
          >https://huggingface.co/spaces/gigant/romanian-whisper/blob/main/app.py</a>\
          \ for example. Basically it is:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> pipeline\n\
          \ndevice = <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\"\
          >if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span>\
          \ <span class=\"hljs-string\">\"cpu\"</span>\n\nMODEL_NAME = <span class=\"\
          hljs-string\">\"gigant/whisper-medium-romanian\"</span>\nlang = <span class=\"\
          hljs-string\">\"ro\"</span>\n\npipe = pipeline(\n    task=<span class=\"\
          hljs-string\">\"automatic-speech-recognition\"</span>,\n    model=MODEL_NAME,\n\
          \    chunk_length_s=<span class=\"hljs-number\">30</span>,\n    device=device,\n\
          )\n\npipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=lang,\
          \ task=<span class=\"hljs-string\">\"transcribe\"</span>)\n\ntext = pipe(file)[<span\
          \ class=\"hljs-string\">\"text\"</span>] <span class=\"hljs-comment\">#with\
          \ \"file\"  being the path to your audio file</span>\n</code></pre>\n<p>Hope\
          \ this helps</p>\n"
        raw: "Hi,\n\nIf you want to have the output, you can use the demo space (\
          \ https://huggingface.co/spaces/gigant/romanian-whisper ) in which you can\
          \ use either audio files or record with your microphone. Otherwhise if you\
          \ run the code by yourself, you can use `torchaudio.load` to load an array\
          \ from a file, just make sure that you you a sample rate of 16kHz because\
          \ that is the one used for training.\nFor instance you can resample using\
          \ torchaudio like this:\n```python\nimport torchaudio.functional as F\n\n\
          def resample(sample, resample_rate = 16000):\n  sample_rate = sample[1]\n\
          \  resampled_waveform = F.resample(sample[0], sample_rate, resample_rate,\
          \ lowpass_filter_width=512, rolloff=0.99)\n  return resampled_waveform\n\
          ```\nIf you are using the `pipeline` from transformers, you can give the\
          \ filepath as is, check the code in https://huggingface.co/spaces/gigant/romanian-whisper/blob/main/app.py\
          \ for example. Basically it is:\n\n```python\nimport torch\nfrom transformers\
          \ import pipeline\n\ndevice = 0 if torch.cuda.is_available() else \"cpu\"\
          \n\nMODEL_NAME = \"gigant/whisper-medium-romanian\"\nlang = \"ro\"\n\npipe\
          \ = pipeline(\n    task=\"automatic-speech-recognition\",\n    model=MODEL_NAME,\n\
          \    chunk_length_s=30,\n    device=device,\n)\n\npipe.model.config.forced_decoder_ids\
          \ = pipe.tokenizer.get_decoder_prompt_ids(language=lang, task=\"transcribe\"\
          )\n\ntext = pipe(file)[\"text\"] #with \"file\"  being the path to your\
          \ audio file\n\n```\n\nHope this helps"
        updatedAt: '2023-02-24T09:37:13.254Z'
      numEdits: 1
      reactions: []
    id: 63f884dd4a7daa003c9d5487
    type: comment
  author: gigant
  content: "Hi,\n\nIf you want to have the output, you can use the demo space ( https://huggingface.co/spaces/gigant/romanian-whisper\
    \ ) in which you can use either audio files or record with your microphone. Otherwhise\
    \ if you run the code by yourself, you can use `torchaudio.load` to load an array\
    \ from a file, just make sure that you you a sample rate of 16kHz because that\
    \ is the one used for training.\nFor instance you can resample using torchaudio\
    \ like this:\n```python\nimport torchaudio.functional as F\n\ndef resample(sample,\
    \ resample_rate = 16000):\n  sample_rate = sample[1]\n  resampled_waveform = F.resample(sample[0],\
    \ sample_rate, resample_rate, lowpass_filter_width=512, rolloff=0.99)\n  return\
    \ resampled_waveform\n```\nIf you are using the `pipeline` from transformers,\
    \ you can give the filepath as is, check the code in https://huggingface.co/spaces/gigant/romanian-whisper/blob/main/app.py\
    \ for example. Basically it is:\n\n```python\nimport torch\nfrom transformers\
    \ import pipeline\n\ndevice = 0 if torch.cuda.is_available() else \"cpu\"\n\n\
    MODEL_NAME = \"gigant/whisper-medium-romanian\"\nlang = \"ro\"\n\npipe = pipeline(\n\
    \    task=\"automatic-speech-recognition\",\n    model=MODEL_NAME,\n    chunk_length_s=30,\n\
    \    device=device,\n)\n\npipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=lang,\
    \ task=\"transcribe\")\n\ntext = pipe(file)[\"text\"] #with \"file\"  being the\
    \ path to your audio file\n\n```\n\nHope this helps"
  created_at: 2023-02-24 09:35:25+00:00
  edited: true
  hidden: false
  id: 63f884dd4a7daa003c9d5487
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1645712223620-60d35154d7b174177faabd55.jpeg?w=200&h=200&f=face
      fullname: "Th\xE9o Gigant"
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: gigant
      type: user
    createdAt: '2023-05-04T15:22:09.000Z'
    data:
      status: closed
    id: 6453cda1dd49b82d7afacce0
    type: status-change
  author: gigant
  created_at: 2023-05-04 14:22:09+00:00
  id: 6453cda1dd49b82d7afacce0
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: gigant/whisper-medium-romanian
repo_type: model
status: closed
target_branch: null
title: Loading a sample audio file...
