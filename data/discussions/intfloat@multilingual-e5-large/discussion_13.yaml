!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sighduck
conflicting_files: null
created_at: 2023-08-17 15:12:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2c508fbb1c261dc57f6e02f84ba85e0b.svg
      fullname: Chris Pang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sighduck
      type: user
    createdAt: '2023-08-17T16:12:34.000Z'
    data:
      edited: false
      editors:
      - sighduck
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8648524284362793
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2c508fbb1c261dc57f6e02f84ba85e0b.svg
          fullname: Chris Pang
          isHf: false
          isPro: false
          name: sighduck
          type: user
        html: '<p>Hi! Would you consider uploading the unsupervised (contrastive pre-training
          only) version of the multilingual-e5-large model, similar to the e5-large-unsupervised
          model? Many thanks.</p>

          '
        raw: Hi! Would you consider uploading the unsupervised (contrastive pre-training
          only) version of the multilingual-e5-large model, similar to the e5-large-unsupervised
          model? Many thanks.
        updatedAt: '2023-08-17T16:12:34.614Z'
      numEdits: 0
      reactions: []
    id: 64de46f29bc64767a6209a03
    type: comment
  author: sighduck
  content: Hi! Would you consider uploading the unsupervised (contrastive pre-training
    only) version of the multilingual-e5-large model, similar to the e5-large-unsupervised
    model? Many thanks.
  created_at: 2023-08-17 15:12:34+00:00
  edited: false
  hidden: false
  id: 64de46f29bc64767a6209a03
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
      fullname: Liang Wang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: intfloat
      type: user
    createdAt: '2023-08-18T07:03:02.000Z'
    data:
      edited: false
      editors:
      - intfloat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9773157238960266
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
          fullname: Liang Wang
          isHf: false
          isPro: false
          name: intfloat
          type: user
        html: '<p>We do not plan to release the one with contrastive pre-training
          only.</p>

          <p>Curious why you are interested in that checkpoint? It does not perform
          very well without the second stage fine-tuning.</p>

          '
        raw: 'We do not plan to release the one with contrastive pre-training only.


          Curious why you are interested in that checkpoint? It does not perform very
          well without the second stage fine-tuning.'
        updatedAt: '2023-08-18T07:03:02.946Z'
      numEdits: 0
      reactions: []
    id: 64df17a69bc64767a63ee2e6
    type: comment
  author: intfloat
  content: 'We do not plan to release the one with contrastive pre-training only.


    Curious why you are interested in that checkpoint? It does not perform very well
    without the second stage fine-tuning.'
  created_at: 2023-08-18 06:03:02+00:00
  edited: false
  hidden: false
  id: 64df17a69bc64767a63ee2e6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2c508fbb1c261dc57f6e02f84ba85e0b.svg
      fullname: Chris Pang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sighduck
      type: user
    createdAt: '2023-08-18T13:59:50.000Z'
    data:
      edited: false
      editors:
      - sighduck
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9667562246322632
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2c508fbb1c261dc57f6e02f84ba85e0b.svg
          fullname: Chris Pang
          isHf: false
          isPro: false
          name: sighduck
          type: user
        html: "<p>Thank you for the quick response. I\u2019ve been using e5-large-unsupervised\
          \ and fine-tuning with my own dataset using Tevatron. I am working on a\
          \ domain with language that is fairly different from the content of the\
          \ train dataset for supervised e5-large, so chose to use unsupervised as\
          \ base and do my own fine-tuning. We have Chinese language content as well,\
          \ so I was considering switching base model to a multilingual unsupervised\
          \ if it were possible.  </p>\n<p>When you say it does not perform well,\
          \ do you mean multilingual unsupervised perform worse on BEIR than the English\
          \ unsupervised model from your paper? I thought the fact that your unsupervised\
          \ model can outperform BM25 is impressive. Even if multilingual unsupervised\
          \ performs worse I would appreciate if you were to share the checkpoint\
          \ as I think it would be useful to see the comparison, but of course very\
          \ much up to you. Thanks again. </p>\n"
        raw: "Thank you for the quick response. I\u2019ve been using e5-large-unsupervised\
          \ and fine-tuning with my own dataset using Tevatron. I am working on a\
          \ domain with language that is fairly different from the content of the\
          \ train dataset for supervised e5-large, so chose to use unsupervised as\
          \ base and do my own fine-tuning. We have Chinese language content as well,\
          \ so I was considering switching base model to a multilingual unsupervised\
          \ if it were possible.  \n\nWhen you say it does not perform well, do you\
          \ mean multilingual unsupervised perform worse on BEIR than the English\
          \ unsupervised model from your paper? I thought the fact that your unsupervised\
          \ model can outperform BM25 is impressive. Even if multilingual unsupervised\
          \ performs worse I would appreciate if you were to share the checkpoint\
          \ as I think it would be useful to see the comparison, but of course very\
          \ much up to you. Thanks again. "
        updatedAt: '2023-08-18T13:59:50.413Z'
      numEdits: 0
      reactions: []
    id: 64df7956a9bcacc18bc86313
    type: comment
  author: sighduck
  content: "Thank you for the quick response. I\u2019ve been using e5-large-unsupervised\
    \ and fine-tuning with my own dataset using Tevatron. I am working on a domain\
    \ with language that is fairly different from the content of the train dataset\
    \ for supervised e5-large, so chose to use unsupervised as base and do my own\
    \ fine-tuning. We have Chinese language content as well, so I was considering\
    \ switching base model to a multilingual unsupervised if it were possible.  \n\
    \nWhen you say it does not perform well, do you mean multilingual unsupervised\
    \ perform worse on BEIR than the English unsupervised model from your paper? I\
    \ thought the fact that your unsupervised model can outperform BM25 is impressive.\
    \ Even if multilingual unsupervised performs worse I would appreciate if you were\
    \ to share the checkpoint as I think it would be useful to see the comparison,\
    \ but of course very much up to you. Thanks again. "
  created_at: 2023-08-18 12:59:50+00:00
  edited: false
  hidden: false
  id: 64df7956a9bcacc18bc86313
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
      fullname: Liang Wang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: intfloat
      type: user
    createdAt: '2023-08-19T01:58:59.000Z'
    data:
      edited: false
      editors:
      - intfloat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.922216534614563
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
          fullname: Liang Wang
          isHf: false
          isPro: false
          name: intfloat
          type: user
        html: '<p>Thanks for your detailed comment.</p>

          <p>I mean that the multilingual unsupervised model performs worse than multilingual
          supervised ones.</p>

          <p>As for fine-tuning to adapt to your domain of interest, you can use the
          supervised one as the base model.</p>

          '
        raw: 'Thanks for your detailed comment.


          I mean that the multilingual unsupervised model performs worse than multilingual
          supervised ones.


          As for fine-tuning to adapt to your domain of interest, you can use the
          supervised one as the base model.'
        updatedAt: '2023-08-19T01:58:59.255Z'
      numEdits: 0
      reactions: []
    id: 64e021e34ad03fafdb62e675
    type: comment
  author: intfloat
  content: 'Thanks for your detailed comment.


    I mean that the multilingual unsupervised model performs worse than multilingual
    supervised ones.


    As for fine-tuning to adapt to your domain of interest, you can use the supervised
    one as the base model.'
  created_at: 2023-08-19 00:58:59+00:00
  edited: false
  hidden: false
  id: 64e021e34ad03fafdb62e675
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: intfloat/multilingual-e5-large
repo_type: model
status: open
target_branch: null
title: multilingual-e5-large-unsupervised
