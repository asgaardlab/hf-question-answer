!!python/object:huggingface_hub.community.DiscussionWithDetails
author: GiliGold
conflicting_files: null
created_at: 2023-08-02 12:18:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e848cab2094f87b6491574f364b33fdf.svg
      fullname: Goldin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GiliGold
      type: user
    createdAt: '2023-08-02T13:18:57.000Z'
    data:
      edited: false
      editors:
      - GiliGold
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9031228423118591
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e848cab2094f87b6491574f364b33fdf.svg
          fullname: Goldin
          isHf: false
          isPro: false
          name: GiliGold
          type: user
        html: '<p>I''m using this model for sentence embeddings and i''m trying to
          check if similar sentences get high cosine similarity as expected and very
          different sentences get low cosine similarity.<br>However, no matter how
          different I try my sentences/words pairs to be, I still receive high cosine
          similarity (above 0.7)<br>Usually, cosine similarity for embeddings range
          between 0 to 1, and only very close sentences get above 0.7<br>Is there
          an explanation for this? </p>

          <p>examples:<br> sent 1 is: query: I just love fruit<br>sent 2 is: query:
          a totally different sentence that has nothing in common<br>Cosine Similarity:
          0.75555754</p>

          <p>sent 1 is: query: how are you feeling?<br>sent 2 is: query: I was born
          in 1933, germany<br>Cosine Similarity: 0.75990283</p>

          <p>sent 1 is: query: The company announced record profits for the fiscal
          year.<br>sent 2 is: query: She carefully crafted a beautiful painting on
          the canvas.<br>Cosine Similarity: 0.74772125</p>

          <p>sent 1 is: query: armadillo<br>sent 2 is: query: read<br>Cosine Similarity:
          0.79260266</p>

          <p>sent 1 is: query: ajkshdk<br>sent 2 is: query: here<br>Cosine Similarity:
          0.8243466</p>

          <p>sent 1 is: query: glass<br>sent 2 is: query: smelly<br>Cosine Similarity:
          0.8391364</p>

          <p>sent 1 is: query: beautiful<br>sent 2 is: query: wound<br>Cosine Similarity:
          0.84729916</p>

          '
        raw: "I'm using this model for sentence embeddings and i'm trying to check\
          \ if similar sentences get high cosine similarity as expected and very different\
          \ sentences get low cosine similarity. \r\nHowever, no matter how different\
          \ I try my sentences/words pairs to be, I still receive high cosine similarity\
          \ (above 0.7)\r\nUsually, cosine similarity for embeddings range between\
          \ 0 to 1, and only very close sentences get above 0.7\r\nIs there an explanation\
          \ for this? \r\n\r\nexamples:\r\n sent 1 is: query: I just love fruit\r\n\
          sent 2 is: query: a totally different sentence that has nothing in common\r\
          \nCosine Similarity: 0.75555754\r\n\r\nsent 1 is: query: how are you feeling?\r\
          \nsent 2 is: query: I was born in 1933, germany\r\nCosine Similarity: 0.75990283\r\
          \n\r\nsent 1 is: query: The company announced record profits for the fiscal\
          \ year.\r\nsent 2 is: query: She carefully crafted a beautiful painting\
          \ on the canvas.\r\nCosine Similarity: 0.74772125\r\n\r\nsent 1 is: query:\
          \ armadillo\r\nsent 2 is: query: read\r\nCosine Similarity: 0.79260266\r\
          \n\r\nsent 1 is: query: ajkshdk\r\nsent 2 is: query: here\r\nCosine Similarity:\
          \ 0.8243466\r\n\r\nsent 1 is: query: glass\r\nsent 2 is: query: smelly\r\
          \nCosine Similarity: 0.8391364\r\n\r\nsent 1 is: query: beautiful\r\nsent\
          \ 2 is: query: wound\r\nCosine Similarity: 0.84729916"
        updatedAt: '2023-08-02T13:18:57.693Z'
      numEdits: 0
      reactions: []
    id: 64ca57c17846f146bd243a1e
    type: comment
  author: GiliGold
  content: "I'm using this model for sentence embeddings and i'm trying to check if\
    \ similar sentences get high cosine similarity as expected and very different\
    \ sentences get low cosine similarity. \r\nHowever, no matter how different I\
    \ try my sentences/words pairs to be, I still receive high cosine similarity (above\
    \ 0.7)\r\nUsually, cosine similarity for embeddings range between 0 to 1, and\
    \ only very close sentences get above 0.7\r\nIs there an explanation for this?\
    \ \r\n\r\nexamples:\r\n sent 1 is: query: I just love fruit\r\nsent 2 is: query:\
    \ a totally different sentence that has nothing in common\r\nCosine Similarity:\
    \ 0.75555754\r\n\r\nsent 1 is: query: how are you feeling?\r\nsent 2 is: query:\
    \ I was born in 1933, germany\r\nCosine Similarity: 0.75990283\r\n\r\nsent 1 is:\
    \ query: The company announced record profits for the fiscal year.\r\nsent 2 is:\
    \ query: She carefully crafted a beautiful painting on the canvas.\r\nCosine Similarity:\
    \ 0.74772125\r\n\r\nsent 1 is: query: armadillo\r\nsent 2 is: query: read\r\n\
    Cosine Similarity: 0.79260266\r\n\r\nsent 1 is: query: ajkshdk\r\nsent 2 is: query:\
    \ here\r\nCosine Similarity: 0.8243466\r\n\r\nsent 1 is: query: glass\r\nsent\
    \ 2 is: query: smelly\r\nCosine Similarity: 0.8391364\r\n\r\nsent 1 is: query:\
    \ beautiful\r\nsent 2 is: query: wound\r\nCosine Similarity: 0.84729916"
  created_at: 2023-08-02 12:18:57+00:00
  edited: false
  hidden: false
  id: 64ca57c17846f146bd243a1e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
      fullname: Liang Wang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: intfloat
      type: user
    createdAt: '2023-08-02T14:22:20.000Z'
    data:
      edited: false
      editors:
      - intfloat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8935073018074036
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
          fullname: Liang Wang
          isHf: false
          isPro: false
          name: intfloat
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;GiliGold&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/GiliGold\"\
          >@<span class=\"underline\">GiliGold</span></a></span>\n\n\t</span></span>\
          \ </p>\n<p>What matters for similarity search / text ranking is the relative\
          \ order of the scores instead of the absolute values. An embedding model\
          \ is good as long as the relevant text pairs receive higher scores than\
          \ irrelevant text pairs, even if the score difference is small.</p>\n<p>From\
          \ a more technical perspective, the reason the scores are distributed around\
          \ 0.7 to 1.0 is that we use a small temperature 0.01 for InfoNCE contrastive\
          \ loss.</p>\n<p>Please also refer to <a rel=\"nofollow\" href=\"https://github.com/microsoft/unilm/issues/1216#issuecomment-1646842947\"\
          >https://github.com/microsoft/unilm/issues/1216#issuecomment-1646842947</a></p>\n"
        raw: "Hi @GiliGold \n\nWhat matters for similarity search / text ranking is\
          \ the relative order of the scores instead of the absolute values. An embedding\
          \ model is good as long as the relevant text pairs receive higher scores\
          \ than irrelevant text pairs, even if the score difference is small.\n\n\
          From a more technical perspective, the reason the scores are distributed\
          \ around 0.7 to 1.0 is that we use a small temperature 0.01 for InfoNCE\
          \ contrastive loss.\n\nPlease also refer to https://github.com/microsoft/unilm/issues/1216#issuecomment-1646842947"
        updatedAt: '2023-08-02T14:22:20.676Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - GiliGold
        - drmeir
        - kardal
        - snikoyo
    id: 64ca669c38837b12d5eed6a4
    type: comment
  author: intfloat
  content: "Hi @GiliGold \n\nWhat matters for similarity search / text ranking is\
    \ the relative order of the scores instead of the absolute values. An embedding\
    \ model is good as long as the relevant text pairs receive higher scores than\
    \ irrelevant text pairs, even if the score difference is small.\n\nFrom a more\
    \ technical perspective, the reason the scores are distributed around 0.7 to 1.0\
    \ is that we use a small temperature 0.01 for InfoNCE contrastive loss.\n\nPlease\
    \ also refer to https://github.com/microsoft/unilm/issues/1216#issuecomment-1646842947"
  created_at: 2023-08-02 13:22:20+00:00
  edited: false
  hidden: false
  id: 64ca669c38837b12d5eed6a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/146e92bb2f00e74ea7ae542f492cc5b1.svg
      fullname: Lukas Kriesch
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LKriesch
      type: user
    createdAt: '2023-08-08T11:33:13.000Z'
    data:
      edited: false
      editors:
      - LKriesch
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9480366110801697
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/146e92bb2f00e74ea7ae542f492cc5b1.svg
          fullname: Lukas Kriesch
          isHf: false
          isPro: false
          name: LKriesch
          type: user
        html: "<p>I experienced the same behavior as <span data-props=\"{&quot;user&quot;:&quot;GiliGold&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/GiliGold\"\
          >@<span class=\"underline\">GiliGold</span></a></span>\n\n\t</span></span>.\
          \ I want to use the embeddings as a \"coarse filter step\" to decide which\
          \ documents i should process further and which are not in any relation to\
          \ a certain topic.<br>Due to the dense cosine similarity values it is hard\
          \ to determine an appropriate threshold for this. do you have any recommendation\
          \ on how to perform this kind of semantic search?</p>\n"
        raw: 'I experienced the same behavior as @GiliGold. I want to use the embeddings
          as a "coarse filter step" to decide which documents i should process further
          and which are not in any relation to a certain topic.

          Due to the dense cosine similarity values it is hard to determine an appropriate
          threshold for this. do you have any recommendation on how to perform this
          kind of semantic search?'
        updatedAt: '2023-08-08T11:33:13.209Z'
      numEdits: 0
      reactions: []
    id: 64d227f91e3f5f2c15c85ead
    type: comment
  author: LKriesch
  content: 'I experienced the same behavior as @GiliGold. I want to use the embeddings
    as a "coarse filter step" to decide which documents i should process further and
    which are not in any relation to a certain topic.

    Due to the dense cosine similarity values it is hard to determine an appropriate
    threshold for this. do you have any recommendation on how to perform this kind
    of semantic search?'
  created_at: 2023-08-08 10:33:13+00:00
  edited: false
  hidden: false
  id: 64d227f91e3f5f2c15c85ead
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
      fullname: Liang Wang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: intfloat
      type: user
    createdAt: '2023-08-08T12:43:20.000Z'
    data:
      edited: true
      editors:
      - intfloat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8521849513053894
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
          fullname: Liang Wang
          isHf: false
          isPro: false
          name: intfloat
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;LKriesch&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/LKriesch\">@<span class=\"\
          underline\">LKriesch</span></a></span>\n\n\t</span></span> Even though the\
          \ score distribution is dense, the ranking of scores are still informative,\
          \ you can choose the threshold as usual. In fact, if you do a simple linear\
          \ transformation <code>new_score = 2 * (old_score - 0.85) / (1.0 - 0.7)</code>,\
          \ now the scores distribute around <code>(-1, 1)</code>.</p>\n<p>In the\
          \ literature of information retrieval, most folks use embeddings to efficiently\
          \ retrieve the top-k documents, and then re-rank these documents using a\
          \ more powerful but less efficient model. Maybe you can do coarse filter\
          \ in a similar way instead of relying on the absolute values.</p>\n"
        raw: '@LKriesch Even though the score distribution is dense, the ranking of
          scores are still informative, you can choose the threshold as usual. In
          fact, if you do a simple linear transformation `new_score = 2 * (old_score
          - 0.85) / (1.0 - 0.7)`, now the scores distribute around `(-1, 1)`.


          In the literature of information retrieval, most folks use embeddings to
          efficiently retrieve the top-k documents, and then re-rank these documents
          using a more powerful but less efficient model. Maybe you can do coarse
          filter in a similar way instead of relying on the absolute values.'
        updatedAt: '2023-08-09T02:04:50.312Z'
      numEdits: 1
      reactions:
      - count: 8
        reaction: "\U0001F44D"
        users:
        - LKriesch
        - merlinr68
        - hantian
        - ivanstepanovftw
        - prooompt
        - snikoyo
        - aiisnewpower
        - frankdarkluo
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - kardal
    id: 64d23868cdde782940e6357a
    type: comment
  author: intfloat
  content: '@LKriesch Even though the score distribution is dense, the ranking of
    scores are still informative, you can choose the threshold as usual. In fact,
    if you do a simple linear transformation `new_score = 2 * (old_score - 0.85) /
    (1.0 - 0.7)`, now the scores distribute around `(-1, 1)`.


    In the literature of information retrieval, most folks use embeddings to efficiently
    retrieve the top-k documents, and then re-rank these documents using a more powerful
    but less efficient model. Maybe you can do coarse filter in a similar way instead
    of relying on the absolute values.'
  created_at: 2023-08-08 11:43:20+00:00
  edited: true
  hidden: false
  id: 64d23868cdde782940e6357a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9871969e979ffb200eabc989475e76bb.svg
      fullname: John Kim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: john-sungjin
      type: user
    createdAt: '2023-08-22T22:52:06.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/9871969e979ffb200eabc989475e76bb.svg
          fullname: John Kim
          isHf: false
          isPro: false
          name: john-sungjin
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-08-22T22:53:21.360Z'
      numEdits: 0
      reactions: []
    id: 64e53c161412b511e42f1803
    type: comment
  author: john-sungjin
  content: This comment has been hidden
  created_at: 2023-08-22 21:52:06+00:00
  edited: true
  hidden: true
  id: 64e53c161412b511e42f1803
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7ddca2b56096411db44768195289aa0d.svg
      fullname: ai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: artificialgenerations4gsdfg
      type: user
    createdAt: '2023-08-23T22:27:08.000Z'
    data:
      edited: false
      editors:
      - artificialgenerations4gsdfg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9518715739250183
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7ddca2b56096411db44768195289aa0d.svg
          fullname: ai
          isHf: false
          isPro: false
          name: artificialgenerations4gsdfg
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;intfloat&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/intfloat\">@<span class=\"\
          underline\">intfloat</span></a></span>\n\n\t</span></span> I appreciate\
          \ your answer, this has been bugging me too! </p>\n<p>Could you give an\
          \ example of a more powerful but less efficient model to use for RAG after\
          \ document retrieval?</p>\n<p>I'm wondering what the SOTA is for RAG, as\
          \ far as finding documents, and then searching documents.</p>\n"
        raw: "@intfloat I appreciate your answer, this has been bugging me too! \n\
          \nCould you give an example of a more powerful but less efficient model\
          \ to use for RAG after document retrieval?\n\nI'm wondering what the SOTA\
          \ is for RAG, as far as finding documents, and then searching documents."
        updatedAt: '2023-08-23T22:27:08.823Z'
      numEdits: 0
      reactions: []
    id: 64e687bc73723590230deaf6
    type: comment
  author: artificialgenerations4gsdfg
  content: "@intfloat I appreciate your answer, this has been bugging me too! \n\n\
    Could you give an example of a more powerful but less efficient model to use for\
    \ RAG after document retrieval?\n\nI'm wondering what the SOTA is for RAG, as\
    \ far as finding documents, and then searching documents."
  created_at: 2023-08-23 21:27:08+00:00
  edited: false
  hidden: false
  id: 64e687bc73723590230deaf6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
      fullname: Liang Wang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: intfloat
      type: user
    createdAt: '2023-08-25T04:11:51.000Z'
    data:
      edited: false
      editors:
      - intfloat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9453251361846924
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
          fullname: Liang Wang
          isHf: false
          isPro: false
          name: intfloat
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;intfloat&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/intfloat\"\
          >@<span class=\"underline\">intfloat</span></a></span>\n\n\t</span></span>\
          \ I appreciate your answer, this has been bugging me too! </p>\n<p>Could\
          \ you give an example of a more powerful but less efficient model to use\
          \ for RAG after document retrieval?</p>\n<p>I'm wondering what the SOTA\
          \ is for RAG, as far as finding documents, and then searching documents.</p>\n\
          </blockquote>\n<p>For RAG after document retrieval, you can use popular\
          \ open-source LLMs such as LLaMA.</p>\n<p>As for the SOTA of RAG, different\
          \ papers adopt quite different evaluation settings, so it is hard to say\
          \ which method is better.</p>\n"
        raw: "> @intfloat I appreciate your answer, this has been bugging me too!\
          \ \n> \n> Could you give an example of a more powerful but less efficient\
          \ model to use for RAG after document retrieval?\n> \n> I'm wondering what\
          \ the SOTA is for RAG, as far as finding documents, and then searching documents.\n\
          \nFor RAG after document retrieval, you can use popular open-source LLMs\
          \ such as LLaMA.\n\nAs for the SOTA of RAG, different papers adopt quite\
          \ different evaluation settings, so it is hard to say which method is better."
        updatedAt: '2023-08-25T04:11:51.562Z'
      numEdits: 0
      reactions: []
    id: 64e82a07db376729985f986b
    type: comment
  author: intfloat
  content: "> @intfloat I appreciate your answer, this has been bugging me too! \n\
    > \n> Could you give an example of a more powerful but less efficient model to\
    \ use for RAG after document retrieval?\n> \n> I'm wondering what the SOTA is\
    \ for RAG, as far as finding documents, and then searching documents.\n\nFor RAG\
    \ after document retrieval, you can use popular open-source LLMs such as LLaMA.\n\
    \nAs for the SOTA of RAG, different papers adopt quite different evaluation settings,\
    \ so it is hard to say which method is better."
  created_at: 2023-08-25 03:11:51+00:00
  edited: false
  hidden: false
  id: 64e82a07db376729985f986b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: intfloat/multilingual-e5-large
repo_type: model
status: open
target_branch: null
title: cosine similarity very high for any pair of sentences
