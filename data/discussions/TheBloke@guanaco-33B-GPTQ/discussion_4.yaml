!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sauravm8
conflicting_files: null
created_at: 2023-05-26 19:26:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/177baf68c9c43bb80f532c556f9457e8.svg
      fullname: Mukherjee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sauravm8
      type: user
    createdAt: '2023-05-26T20:26:13.000Z'
    data:
      edited: false
      editors:
      - sauravm8
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/177baf68c9c43bb80f532c556f9457e8.svg
          fullname: Mukherjee
          isHf: false
          isPro: false
          name: sauravm8
          type: user
        html: '<p>Hi TheBloke, thank you for your amazing work. </p>

          <p>When I am trying to load and work with the model. the model keeps hallucinating
          and going into tangents.<br>Example</p>

          <p>Hi</p>

          <p>&lt; s &gt;Hi, is anyone here?</p>

          <p>Hello,</p>

          <p>I am a beginner at programming and I am trying to create a simple program
          that can detect when the keyboard is pressed or released.</p>

          <p>My question is, what is the optimal code to achieve this? I have been
          searching online but I have not found a clear answer.</p>

          <p>Here is what I have so far:</p>

          <p>```<br>import keyboard</p>

          <p>def on_press():<br>    print("Key pressed!")</p>

          <p>def &lt; /s &gt;</p>

          <p>Code:<br>    final_message = input()<br>    inputs = tokenizer(final_message,
          return_tensors="pt").to(model.device)<br>    tokens = model.generate(**inputs,  max_new_tokens=100,
          do_sample=True, temperature=0.8)<br>    print(tokenizer.decode(tokens[0]))</p>

          '
        raw: "Hi TheBloke, thank you for your amazing work. \r\n\r\nWhen I am trying\
          \ to load and work with the model. the model keeps hallucinating and going\
          \ into tangents. \r\nExample\r\n\r\nHi\r\n\r\n\r\n< s >Hi, is anyone here?\r\
          \n\r\nHello,\r\n\r\nI am a beginner at programming and I am trying to create\
          \ a simple program that can detect when the keyboard is pressed or released.\r\
          \n\r\nMy question is, what is the optimal code to achieve this? I have been\
          \ searching online but I have not found a clear answer.\r\n\r\nHere is what\
          \ I have so far:\r\n\r\n```\r\nimport keyboard\r\n\r\ndef on_press():\r\n\
          \    print(\"Key pressed!\")\r\n\r\ndef < /s >\r\n\r\nCode:\r\n    final_message\
          \ = input()\r\n    inputs = tokenizer(final_message, return_tensors=\"pt\"\
          ).to(model.device)\r\n    tokens = model.generate(**inputs,  max_new_tokens=100,\
          \ do_sample=True, temperature=0.8)\r\n    print(tokenizer.decode(tokens[0]))"
        updatedAt: '2023-05-26T20:26:13.533Z'
      numEdits: 0
      reactions: []
    id: 647115e5085607e2f582612e
    type: comment
  author: sauravm8
  content: "Hi TheBloke, thank you for your amazing work. \r\n\r\nWhen I am trying\
    \ to load and work with the model. the model keeps hallucinating and going into\
    \ tangents. \r\nExample\r\n\r\nHi\r\n\r\n\r\n< s >Hi, is anyone here?\r\n\r\n\
    Hello,\r\n\r\nI am a beginner at programming and I am trying to create a simple\
    \ program that can detect when the keyboard is pressed or released.\r\n\r\nMy\
    \ question is, what is the optimal code to achieve this? I have been searching\
    \ online but I have not found a clear answer.\r\n\r\nHere is what I have so far:\r\
    \n\r\n```\r\nimport keyboard\r\n\r\ndef on_press():\r\n    print(\"Key pressed!\"\
    )\r\n\r\ndef < /s >\r\n\r\nCode:\r\n    final_message = input()\r\n    inputs\
    \ = tokenizer(final_message, return_tensors=\"pt\").to(model.device)\r\n    tokens\
    \ = model.generate(**inputs,  max_new_tokens=100, do_sample=True, temperature=0.8)\r\
    \n    print(tokenizer.decode(tokens[0]))"
  created_at: 2023-05-26 19:26:13+00:00
  edited: false
  hidden: false
  id: 647115e5085607e2f582612e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-27T07:48:34.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>You need to use a prompt template.  Try:</p>

          <pre><code class="language-python">prompt = <span class="hljs-built_in">input</span>()

          prompt_template = <span class="hljs-string">f''### Instruction: <span class="hljs-subst">{prompt}</span>\n###
          Response:''</span>

          inputs = tokenizer(prompt_template, return_tensors=<span class="hljs-string">"pt"</span>).to(model.device)

          tokens = model.generate(**inputs, max_new_tokens=<span class="hljs-number">100</span>,
          do_sample=<span class="hljs-literal">True</span>, temperature=<span class="hljs-number">0.8</span>)

          <span class="hljs-built_in">print</span>(tokenizer.decode(tokens[<span class="hljs-number">0</span>]))

          </code></pre>

          '
        raw: 'You need to use a prompt template.  Try:

          ```python

          prompt = input()

          prompt_template = f''### Instruction: {prompt}\n### Response:''

          inputs = tokenizer(prompt_template, return_tensors="pt").to(model.device)

          tokens = model.generate(**inputs, max_new_tokens=100, do_sample=True, temperature=0.8)

          print(tokenizer.decode(tokens[0]))

          ```'
        updatedAt: '2023-05-27T07:48:34.186Z'
      numEdits: 0
      reactions: []
    id: 6471b5d20211f85270f84034
    type: comment
  author: TheBloke
  content: 'You need to use a prompt template.  Try:

    ```python

    prompt = input()

    prompt_template = f''### Instruction: {prompt}\n### Response:''

    inputs = tokenizer(prompt_template, return_tensors="pt").to(model.device)

    tokens = model.generate(**inputs, max_new_tokens=100, do_sample=True, temperature=0.8)

    print(tokenizer.decode(tokens[0]))

    ```'
  created_at: 2023-05-27 06:48:34+00:00
  edited: false
  hidden: false
  id: 6471b5d20211f85270f84034
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/guanaco-33B-GPTQ
repo_type: model
status: open
target_branch: null
title: Model Hallucinating while loading and generating text through AutoGPTQ
