!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gongy
conflicting_files: null
created_at: 2023-06-01 16:55:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5be15bbe96f71f311a6c7b576ea4275c.svg
      fullname: Richard Gong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gongy
      type: user
    createdAt: '2023-06-01T17:55:54.000Z'
    data:
      edited: false
      editors:
      - gongy
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5be15bbe96f71f311a6c7b576ea4275c.svg
          fullname: Richard Gong
          isHf: false
          isPro: false
          name: gongy
          type: user
        html: "<p>Hi all, loading the tokenizer leads to an infinite loop with the\
          \ latest transformers:</p>\n<pre><code> File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py\"\
          , line 250, in convert_tokens_to_ids\n   return self._convert_token_to_id_with_added_voc(tokens)\n\
          \ File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py\"\
          , line 257, in _convert_token_to_id_with_added_voc\n   return self.unk_token_id\n\
          \ File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1150, in unk_token_id\n   return self.convert_tokens_to_ids(self.unk_token)\n\
          \ File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1030, in unk_token\n   return str(self._unk_token)\nRecursionError:\
          \ maximum recursion depth exceeded while getting the str of an object\n\
          </code></pre>\n<p>I resolved this by just using the 65B or 7B tokenizer\
          \ configs:</p>\n<pre><code>tokenizer = AutoTokenizer.from_pretrained(\n\
          \       \"TheBloke/guanaco-65B-GPTQ\",\n       use_fast=True\n   )\n</code></pre>\n\
          <p>Is there a reason the 33B repo has a specifically different tokenizer?</p>\n"
        raw: "Hi all, loading the tokenizer leads to an infinite loop with the latest\
          \ transformers:\r\n\r\n ```\r\n  File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py\"\
          , line 250, in convert_tokens_to_ids\r\n    return self._convert_token_to_id_with_added_voc(tokens)\r\
          \n  File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py\"\
          , line 257, in _convert_token_to_id_with_added_voc\r\n    return self.unk_token_id\r\
          \n  File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1150, in unk_token_id\r\n    return self.convert_tokens_to_ids(self.unk_token)\r\
          \n  File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1030, in unk_token\r\n    return str(self._unk_token)\r\nRecursionError:\
          \ maximum recursion depth exceeded while getting the str of an object\r\n\
          \ ```\r\n\r\nI resolved this by just using the 65B or 7B tokenizer configs:\r\
          \n ```\r\ntokenizer = AutoTokenizer.from_pretrained(\r\n        \"TheBloke/guanaco-65B-GPTQ\"\
          ,\r\n        use_fast=True\r\n    )\r\n ```\r\n\r\nIs there a reason the\
          \ 33B repo has a specifically different tokenizer?"
        updatedAt: '2023-06-01T17:55:54.292Z'
      numEdits: 0
      reactions: []
    id: 6478dbaabb9a5693c48990d2
    type: comment
  author: gongy
  content: "Hi all, loading the tokenizer leads to an infinite loop with the latest\
    \ transformers:\r\n\r\n ```\r\n  File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py\"\
    , line 250, in convert_tokens_to_ids\r\n    return self._convert_token_to_id_with_added_voc(tokens)\r\
    \n  File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py\"\
    , line 257, in _convert_token_to_id_with_added_voc\r\n    return self.unk_token_id\r\
    \n  File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1150, in unk_token_id\r\n    return self.convert_tokens_to_ids(self.unk_token)\r\
    \n  File \"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1030, in unk_token\r\n    return str(self._unk_token)\r\nRecursionError:\
    \ maximum recursion depth exceeded while getting the str of an object\r\n ```\r\
    \n\r\nI resolved this by just using the 65B or 7B tokenizer configs:\r\n ```\r\
    \ntokenizer = AutoTokenizer.from_pretrained(\r\n        \"TheBloke/guanaco-65B-GPTQ\"\
    ,\r\n        use_fast=True\r\n    )\r\n ```\r\n\r\nIs there a reason the 33B repo\
    \ has a specifically different tokenizer?"
  created_at: 2023-06-01 16:55:54+00:00
  edited: false
  hidden: false
  id: 6478dbaabb9a5693c48990d2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-05T10:29:52.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8802890181541443
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Oh, interesting.  I never noticed that.</p>

          <p>So the 33B tokenizer I got from the model Tim Dettmers merged himself,
          TimDettmers/guanaco-33b-merged.</p>

          <p>He didn''t merge the other sizes, so I merged them myself and used the
          standard Llama base tokenizers for those.</p>

          <p>I''ve compared the 33B and 65B tokenizers and yeah there''s a few differences.  For
          example the 33B doesn''t list the <code>&lt;s&gt;</code> token here:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/YWPsAK3qv-Gj_1frXUqbk.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/YWPsAK3qv-Gj_1frXUqbk.png"></a></p>

          <p>Where 65B does:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/u77k8owuv4J4jAj5sPhZQ.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/u77k8owuv4J4jAj5sPhZQ.png"></a></p>

          <p>Given you''re getting errors, I have removed the 33B tokenizer and replaced
          it with the file from my 65B repo. Thanks for the report!</p>

          '
        raw: 'Oh, interesting.  I never noticed that.


          So the 33B tokenizer I got from the model Tim Dettmers merged himself, TimDettmers/guanaco-33b-merged.


          He didn''t merge the other sizes, so I merged them myself and used the standard
          Llama base tokenizers for those.


          I''ve compared the 33B and 65B tokenizers and yeah there''s a few differences.  For
          example the 33B doesn''t list the `<s>` token here:


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/YWPsAK3qv-Gj_1frXUqbk.png)


          Where 65B does:


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/u77k8owuv4J4jAj5sPhZQ.png)


          Given you''re getting errors, I have removed the 33B tokenizer and replaced
          it with the file from my 65B repo. Thanks for the report!'
        updatedAt: '2023-06-05T10:29:52.127Z'
      numEdits: 0
      reactions: []
    id: 647db92032c471a7fa84d1c1
    type: comment
  author: TheBloke
  content: 'Oh, interesting.  I never noticed that.


    So the 33B tokenizer I got from the model Tim Dettmers merged himself, TimDettmers/guanaco-33b-merged.


    He didn''t merge the other sizes, so I merged them myself and used the standard
    Llama base tokenizers for those.


    I''ve compared the 33B and 65B tokenizers and yeah there''s a few differences.  For
    example the 33B doesn''t list the `<s>` token here:


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/YWPsAK3qv-Gj_1frXUqbk.png)


    Where 65B does:


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/u77k8owuv4J4jAj5sPhZQ.png)


    Given you''re getting errors, I have removed the 33B tokenizer and replaced it
    with the file from my 65B repo. Thanks for the report!'
  created_at: 2023-06-05 09:29:52+00:00
  edited: false
  hidden: false
  id: 647db92032c471a7fa84d1c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/39f2c95919d07814c9ce2ceefa579006.svg
      fullname: buchylx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: buchylx
      type: user
    createdAt: '2023-06-29T08:59:07.000Z'
    data:
      edited: false
      editors:
      - buchylx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9601925015449524
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/39f2c95919d07814c9ce2ceefa579006.svg
          fullname: buchylx
          isHf: false
          isPro: false
          name: buchylx
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> I think the file\
          \ \"tokenizer_config.json\" is also need to be updated.</p>\n"
        raw: '@TheBloke I think the file "tokenizer_config.json" is also need to be
          updated.'
        updatedAt: '2023-06-29T08:59:07.470Z'
      numEdits: 0
      reactions: []
    id: 649d47db65b8e583e1bd2301
    type: comment
  author: buchylx
  content: '@TheBloke I think the file "tokenizer_config.json" is also need to be
    updated.'
  created_at: 2023-06-29 07:59:07+00:00
  edited: false
  hidden: false
  id: 649d47db65b8e583e1bd2301
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-29T09:11:37.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8909067511558533
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Thanks, fixed</p>

          '
        raw: Thanks, fixed
        updatedAt: '2023-06-29T09:11:37.039Z'
      numEdits: 0
      reactions: []
    id: 649d4ac955e4fa96a5e59a78
    type: comment
  author: TheBloke
  content: Thanks, fixed
  created_at: 2023-06-29 08:11:37+00:00
  edited: false
  hidden: false
  id: 649d4ac955e4fa96a5e59a78
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: TheBloke/guanaco-33B-GPTQ
repo_type: model
status: open
target_branch: null
title: Infinite loop loading tokenizer (specific to 33B-GPTQ repo)
