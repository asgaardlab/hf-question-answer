!!python/object:huggingface_hub.community.DiscussionWithDetails
author: J001
conflicting_files: null
created_at: 2023-05-29 15:24:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0ff3c7b38442c6802174581d1035e838.svg
      fullname: J001 No
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: J001
      type: user
    createdAt: '2023-05-29T16:24:43.000Z'
    data:
      edited: true
      editors:
      - J001
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0ff3c7b38442c6802174581d1035e838.svg
          fullname: J001 No
          isHf: false
          isPro: false
          name: J001
          type: user
        html: "<p>I have tried loading this model OOM error in a low-RAM, high-VRAM\
          \ system, with text-generation-webui\uFF1B<br>I think the size of this model\
          \ &gt; 12GB System RAM.</p>\n<p>Can I load with a Sharded model chunk by\
          \ chuck to reduce RAM requirements?<br>Or it just the text-generation-webui\
          \ limitation?</p>\n"
        raw: "I have tried loading this model OOM error in a low-RAM, high-VRAM system,\
          \ with text-generation-webui\uFF1B\nI think the size of this model > 12GB\
          \ System RAM.\n\nCan I load with a Sharded model chunk by chuck to reduce\
          \ RAM requirements?\nOr it just the text-generation-webui limitation?"
        updatedAt: '2023-05-29T16:27:01.392Z'
      numEdits: 1
      reactions: []
    id: 6474d1cbb68461d5cf7bdf6c
    type: comment
  author: J001
  content: "I have tried loading this model OOM error in a low-RAM, high-VRAM system,\
    \ with text-generation-webui\uFF1B\nI think the size of this model > 12GB System\
    \ RAM.\n\nCan I load with a Sharded model chunk by chuck to reduce RAM requirements?\n\
    Or it just the text-generation-webui limitation?"
  created_at: 2023-05-29 15:24:43+00:00
  edited: true
  hidden: false
  id: 6474d1cbb68461d5cf7bdf6c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: TheBloke/guanaco-33B-GPTQ
repo_type: model
status: open
target_branch: null
title: Sharded Model request!
