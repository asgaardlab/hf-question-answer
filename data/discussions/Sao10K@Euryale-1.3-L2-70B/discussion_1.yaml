!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Puchacz19
conflicting_files: null
created_at: 2023-11-12 17:15:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12bf13fa064fb8b13093b265df2f90d9.svg
      fullname: "\u0141ukasz"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Puchacz19
      type: user
    createdAt: '2023-11-12T17:15:40.000Z'
    data:
      edited: true
      editors:
      - Puchacz19
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9490860104560852
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12bf13fa064fb8b13093b265df2f90d9.svg
          fullname: "\u0141ukasz"
          isHf: false
          isPro: false
          name: Puchacz19
          type: user
        html: '<p>I''ve already increased the max content to 6144 and it seems to
          be smart (RP with this model is a great experience, thank you!) Will increasing
          to 8k spoil my experience? I use Kobold.CPP with euryale-1.3-l2-70b.Q4_K_M.gguf.</p>

          '
        raw: 'I''ve already increased the max content to 6144 and it seems to be smart
          (RP with this model is a great experience, thank you!) Will increasing to
          8k spoil my experience? I use Kobold.CPP with euryale-1.3-l2-70b.Q4_K_M.gguf.

          '
        updatedAt: '2023-11-12T17:16:52.108Z'
      numEdits: 1
      reactions: []
    id: 6551083c9b42dac8f1921ba0
    type: comment
  author: Puchacz19
  content: 'I''ve already increased the max content to 6144 and it seems to be smart
    (RP with this model is a great experience, thank you!) Will increasing to 8k spoil
    my experience? I use Kobold.CPP with euryale-1.3-l2-70b.Q4_K_M.gguf.

    '
  created_at: 2023-11-12 17:15:40+00:00
  edited: true
  hidden: false
  id: 6551083c9b42dac8f1921ba0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64be6a5376a6e2efccc638c1/WeV-NfIS6SMPzTI--lNvd.jpeg?w=200&h=200&f=face
      fullname: Saofiq
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Sao10K
      type: user
    createdAt: '2023-11-12T23:45:46.000Z'
    data:
      edited: false
      editors:
      - Sao10K
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9675613045692444
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64be6a5376a6e2efccc638c1/WeV-NfIS6SMPzTI--lNvd.jpeg?w=200&h=200&f=face
          fullname: Saofiq
          isHf: false
          isPro: false
          name: Sao10K
          type: user
        html: '<p>What I found is with extending context, the general flavour and
          quality of the model remains fine at 8k, it''s just that numbers get messed
          up (eg. 20003 instead of 2003), and it just adheres less to formatting.
          That''s an issue with rope scaling, I think? Happens in most models.</p>

          <p>Above 8k is usually when most of the quality is lost.</p>

          <p>Other than that it should have no issues. </p>

          '
        raw: 'What I found is with extending context, the general flavour and quality
          of the model remains fine at 8k, it''s just that numbers get messed up (eg.
          20003 instead of 2003), and it just adheres less to formatting. That''s
          an issue with rope scaling, I think? Happens in most models.


          Above 8k is usually when most of the quality is lost.


          Other than that it should have no issues. '
        updatedAt: '2023-11-12T23:45:46.137Z'
      numEdits: 0
      reactions: []
    id: 655163aaea9be8f1e6e29e2d
    type: comment
  author: Sao10K
  content: 'What I found is with extending context, the general flavour and quality
    of the model remains fine at 8k, it''s just that numbers get messed up (eg. 20003
    instead of 2003), and it just adheres less to formatting. That''s an issue with
    rope scaling, I think? Happens in most models.


    Above 8k is usually when most of the quality is lost.


    Other than that it should have no issues. '
  created_at: 2023-11-12 23:45:46+00:00
  edited: false
  hidden: false
  id: 655163aaea9be8f1e6e29e2d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/12bf13fa064fb8b13093b265df2f90d9.svg
      fullname: "\u0141ukasz"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Puchacz19
      type: user
    createdAt: '2023-11-13T14:09:25.000Z'
    data:
      edited: false
      editors:
      - Puchacz19
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9524729251861572
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/12bf13fa064fb8b13093b265df2f90d9.svg
          fullname: "\u0141ukasz"
          isHf: false
          isPro: false
          name: Puchacz19
          type: user
        html: '<p>Okey! Thanks for reply!</p>

          '
        raw: 'Okey! Thanks for reply!

          '
        updatedAt: '2023-11-13T14:09:25.455Z'
      numEdits: 0
      reactions: []
    id: 65522e15e4a7feed73a50a2a
    type: comment
  author: Puchacz19
  content: 'Okey! Thanks for reply!

    '
  created_at: 2023-11-13 14:09:25+00:00
  edited: false
  hidden: false
  id: 65522e15e4a7feed73a50a2a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Sao10K/Euryale-1.3-L2-70B
repo_type: model
status: open
target_branch: null
title: Could increasing the max content to 8k spoil the wisdom of this model?
