!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TimYao
conflicting_files: null
created_at: 2023-08-14 04:52:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
      fullname: TimYao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TimYao
      type: user
    createdAt: '2023-08-14T05:52:36.000Z'
    data:
      edited: true
      editors:
      - TimYao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3912660479545593
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
          fullname: TimYao
          isHf: false
          isPro: false
          name: TimYao
          type: user
        html: "<p>I run the command as <a href=\"https://huggingface.co/coreml-community/ControlNet-Models-For-Core-ML/blob/main/MISC/3.%20Converting%20A%20ControlNet%20Model.txt#:~:text=To%20convert%20a%20ControlNet%20model%3A%20conda%20activate%20coreml_stable_diffusion,lllyasviel%2Fcontrol_v11p_sd15_softedge%20--model-version%20%22runwayml%2Fstable-diffusion-v1-5%22%20--bundle-resources-for-swift-cli%20--attention-implementation%20SPLIT_EINSUM%20-o%20%22.%2FSoftEdge%22\"\
          >3. Converting A ControlNet Model.txt</a> Line 5: </p>\n<pre><code class=\"\
          language-bash\">python -m python_coreml_stable_diffusion.torch2coreml --convert-controlnet\
          \ lllyasviel/control_v11p_sd15_softedge --model-version <span class=\"hljs-string\"\
          >\"runwayml/stable-diffusion-v1-5\"</span> --bundle-resources-for-swift-cli\
          \ --attention-implementation SPLIT_EINSUM -o <span class=\"hljs-string\"\
          >\"./SoftEdge\"</span> \n</code></pre>\n<p>But meet error as below:</p>\n\
          <pre><code class=\"language-bash\">INFO:__main__:Converting controlnet\n\
          INFO:__main__:Sample ControlNet inputs spec: {<span class=\"hljs-string\"\
          >'sample'</span>: (torch.Size([2, 4, 64, 64]), torch.float32), <span class=\"\
          hljs-string\">'timestep'</span>: (torch.Size([2]), torch.float32), <span\
          \ class=\"hljs-string\">'encoder_hidden_states'</span>: (torch.Size([2,\
          \ 768, 1, 77]), torch.float32), <span class=\"hljs-string\">'controlnet_cond'</span>:\
          \ (torch.Size([2, 3, 512, 512]), torch.float32)}\nTraceback (most recent\
          \ call last):\n  File <span class=\"hljs-string\">\"/Users/kyd6/miniconda3/envs/coreml_stable_diffusion/lib/python3.8/runpy.py\"\
          </span>, line 194, <span class=\"hljs-keyword\">in</span> _run_module_as_main\n\
          \    <span class=\"hljs-built_in\">return</span> _run_code(code, main_globals,\
          \ None,\n  File <span class=\"hljs-string\">\"/Users/kyd6/miniconda3/envs/coreml_stable_diffusion/lib/python3.8/runpy.py\"\
          </span>, line 87, <span class=\"hljs-keyword\">in</span> _run_code\n   \
          \ <span class=\"hljs-built_in\">exec</span>(code, run_globals)\n  File <span\
          \ class=\"hljs-string\">\"/Users/kyd6/Downloads/ml-stable-diffusion/python_coreml_stable_diffusion/torch2coreml.py\"\
          </span>, line 1427, <span class=\"hljs-keyword\">in</span> &lt;module&gt;\n\
          \    main(args)\n  File <span class=\"hljs-string\">\"/Users/kyd6/Downloads/ml-stable-diffusion/python_coreml_stable_diffusion/torch2coreml.py\"\
          </span>, line 1262, <span class=\"hljs-keyword\">in</span> main\n    convert_controlnet(pipe,\
          \ args)\n  File <span class=\"hljs-string\">\"/Users/kyd6/Downloads/ml-stable-diffusion/python_coreml_stable_diffusion/torch2coreml.py\"\
          </span>, line 1144, <span class=\"hljs-keyword\">in</span> convert_controlnet\n\
          \    load_state_dict_summary = reference_controlnet.load_state_dict(\n \
          \ File <span class=\"hljs-string\">\"/Users/kyd6/miniconda3/envs/coreml_stable_diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          </span>, line 2041, <span class=\"hljs-keyword\">in</span> load_state_dict\n\
          \    raise RuntimeError(<span class=\"hljs-string\">'Error(s) in loading\
          \ state_dict for {}:\\n\\t{}'</span>.format(\nRuntimeError: Error(s) <span\
          \ class=\"hljs-keyword\">in</span> loading state_dict <span class=\"hljs-keyword\"\
          >for</span> ControlNetModel:\n    Missing key(s) <span class=\"hljs-keyword\"\
          >in</span> state_dict: <span class=\"hljs-string\">\"down_blocks.3.downsamplers.0.conv.weight\"\
          </span>, <span class=\"hljs-string\">\"down_blocks.3.downsamplers.0.conv.bias\"\
          </span>. \n</code></pre>\n<p>What should I do to make the conversion success?</p>\n"
        raw: "I run the command as [3. Converting A ControlNet Model.txt](https://huggingface.co/coreml-community/ControlNet-Models-For-Core-ML/blob/main/MISC/3.%20Converting%20A%20ControlNet%20Model.txt#:~:text=To%20convert%20a%20ControlNet%20model%3A%20conda%20activate%20coreml_stable_diffusion,lllyasviel%2Fcontrol_v11p_sd15_softedge%20--model-version%20%22runwayml%2Fstable-diffusion-v1-5%22%20--bundle-resources-for-swift-cli%20--attention-implementation%20SPLIT_EINSUM%20-o%20%22.%2FSoftEdge%22)\
          \ Line 5: \n```bash\npython -m python_coreml_stable_diffusion.torch2coreml\
          \ --convert-controlnet lllyasviel/control_v11p_sd15_softedge --model-version\
          \ \"runwayml/stable-diffusion-v1-5\" --bundle-resources-for-swift-cli --attention-implementation\
          \ SPLIT_EINSUM -o \"./SoftEdge\" \n```\nBut meet error as below:\n\n```bash\n\
          INFO:__main__:Converting controlnet\nINFO:__main__:Sample ControlNet inputs\
          \ spec: {'sample': (torch.Size([2, 4, 64, 64]), torch.float32), 'timestep':\
          \ (torch.Size([2]), torch.float32), 'encoder_hidden_states': (torch.Size([2,\
          \ 768, 1, 77]), torch.float32), 'controlnet_cond': (torch.Size([2, 3, 512,\
          \ 512]), torch.float32)}\nTraceback (most recent call last):\n  File \"\
          /Users/kyd6/miniconda3/envs/coreml_stable_diffusion/lib/python3.8/runpy.py\"\
          , line 194, in _run_module_as_main\n    return _run_code(code, main_globals,\
          \ None,\n  File \"/Users/kyd6/miniconda3/envs/coreml_stable_diffusion/lib/python3.8/runpy.py\"\
          , line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Users/kyd6/Downloads/ml-stable-diffusion/python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 1427, in <module>\n    main(args)\n  File \"/Users/kyd6/Downloads/ml-stable-diffusion/python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 1262, in main\n    convert_controlnet(pipe, args)\n  File \"/Users/kyd6/Downloads/ml-stable-diffusion/python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 1144, in convert_controlnet\n    load_state_dict_summary = reference_controlnet.load_state_dict(\n\
          \  File \"/Users/kyd6/miniconda3/envs/coreml_stable_diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 2041, in load_state_dict\n    raise RuntimeError('Error(s) in loading\
          \ state_dict for {}:\\n\\t{}'.format(\nRuntimeError: Error(s) in loading\
          \ state_dict for ControlNetModel:\n\tMissing key(s) in state_dict: \"down_blocks.3.downsamplers.0.conv.weight\"\
          , \"down_blocks.3.downsamplers.0.conv.bias\". \n```\n\n\nWhat should I do\
          \ to make the conversion success?"
        updatedAt: '2023-08-14T06:18:29.155Z'
      numEdits: 1
      reactions: []
    id: 64d9c124a4839890b263e6b7
    type: comment
  author: TimYao
  content: "I run the command as [3. Converting A ControlNet Model.txt](https://huggingface.co/coreml-community/ControlNet-Models-For-Core-ML/blob/main/MISC/3.%20Converting%20A%20ControlNet%20Model.txt#:~:text=To%20convert%20a%20ControlNet%20model%3A%20conda%20activate%20coreml_stable_diffusion,lllyasviel%2Fcontrol_v11p_sd15_softedge%20--model-version%20%22runwayml%2Fstable-diffusion-v1-5%22%20--bundle-resources-for-swift-cli%20--attention-implementation%20SPLIT_EINSUM%20-o%20%22.%2FSoftEdge%22)\
    \ Line 5: \n```bash\npython -m python_coreml_stable_diffusion.torch2coreml --convert-controlnet\
    \ lllyasviel/control_v11p_sd15_softedge --model-version \"runwayml/stable-diffusion-v1-5\"\
    \ --bundle-resources-for-swift-cli --attention-implementation SPLIT_EINSUM -o\
    \ \"./SoftEdge\" \n```\nBut meet error as below:\n\n```bash\nINFO:__main__:Converting\
    \ controlnet\nINFO:__main__:Sample ControlNet inputs spec: {'sample': (torch.Size([2,\
    \ 4, 64, 64]), torch.float32), 'timestep': (torch.Size([2]), torch.float32), 'encoder_hidden_states':\
    \ (torch.Size([2, 768, 1, 77]), torch.float32), 'controlnet_cond': (torch.Size([2,\
    \ 3, 512, 512]), torch.float32)}\nTraceback (most recent call last):\n  File \"\
    /Users/kyd6/miniconda3/envs/coreml_stable_diffusion/lib/python3.8/runpy.py\",\
    \ line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n\
    \  File \"/Users/kyd6/miniconda3/envs/coreml_stable_diffusion/lib/python3.8/runpy.py\"\
    , line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Users/kyd6/Downloads/ml-stable-diffusion/python_coreml_stable_diffusion/torch2coreml.py\"\
    , line 1427, in <module>\n    main(args)\n  File \"/Users/kyd6/Downloads/ml-stable-diffusion/python_coreml_stable_diffusion/torch2coreml.py\"\
    , line 1262, in main\n    convert_controlnet(pipe, args)\n  File \"/Users/kyd6/Downloads/ml-stable-diffusion/python_coreml_stable_diffusion/torch2coreml.py\"\
    , line 1144, in convert_controlnet\n    load_state_dict_summary = reference_controlnet.load_state_dict(\n\
    \  File \"/Users/kyd6/miniconda3/envs/coreml_stable_diffusion/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
    , line 2041, in load_state_dict\n    raise RuntimeError('Error(s) in loading state_dict\
    \ for {}:\\n\\t{}'.format(\nRuntimeError: Error(s) in loading state_dict for ControlNetModel:\n\
    \tMissing key(s) in state_dict: \"down_blocks.3.downsamplers.0.conv.weight\",\
    \ \"down_blocks.3.downsamplers.0.conv.bias\". \n```\n\n\nWhat should I do to make\
    \ the conversion success?"
  created_at: 2023-08-14 04:52:36+00:00
  edited: true
  hidden: false
  id: 64d9c124a4839890b263e6b7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
      fullname: Joel Rittvo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jrrjrr
      type: user
    createdAt: '2023-08-14T16:12:34.000Z'
    data:
      edited: false
      editors:
      - jrrjrr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9632231593132019
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
          fullname: Joel Rittvo
          isHf: false
          isPro: false
          name: jrrjrr
          type: user
        html: '<p>I can duplicate the error message that you are getting. Something
          has been changed in one of the packages involved in doing these conversions
          (maybe torch) that breaks compatibility with one of the other packages (maybe
          python_coreml_stable_diffusion).  This happens from time to time as packages
          get updated.  I think I remember this particular break happening once before,
          and that I was able to fix it by commenting out a line in one of the files
          listed in the error message.  I will look into this in the next day or two.  In
          the meantime, almost any converted CN model you might need is already available
          in this repo, including all of the ones from the 14 official CN models converted
          for Split-Einsum.  You should only need to be doing a conversion yourself
          if you need a specific Original model type size that has not already been
          converted, or you are trying to convert from an "unofficial" CN model (which
          often does not work because they deviate from the specifications).  You
          are probably experimenting just to learn though, so I will try to find a
          fix for you.</p>

          '
        raw: I can duplicate the error message that you are getting. Something has
          been changed in one of the packages involved in doing these conversions
          (maybe torch) that breaks compatibility with one of the other packages (maybe
          python_coreml_stable_diffusion).  This happens from time to time as packages
          get updated.  I think I remember this particular break happening once before,
          and that I was able to fix it by commenting out a line in one of the files
          listed in the error message.  I will look into this in the next day or two.  In
          the meantime, almost any converted CN model you might need is already available
          in this repo, including all of the ones from the 14 official CN models converted
          for Split-Einsum.  You should only need to be doing a conversion yourself
          if you need a specific Original model type size that has not already been
          converted, or you are trying to convert from an "unofficial" CN model (which
          often does not work because they deviate from the specifications).  You
          are probably experimenting just to learn though, so I will try to find a
          fix for you.
        updatedAt: '2023-08-14T16:12:34.802Z'
      numEdits: 0
      reactions: []
    id: 64da5272d4d94f5027ff9aed
    type: comment
  author: jrrjrr
  content: I can duplicate the error message that you are getting. Something has been
    changed in one of the packages involved in doing these conversions (maybe torch)
    that breaks compatibility with one of the other packages (maybe python_coreml_stable_diffusion).  This
    happens from time to time as packages get updated.  I think I remember this particular
    break happening once before, and that I was able to fix it by commenting out a
    line in one of the files listed in the error message.  I will look into this in
    the next day or two.  In the meantime, almost any converted CN model you might
    need is already available in this repo, including all of the ones from the 14
    official CN models converted for Split-Einsum.  You should only need to be doing
    a conversion yourself if you need a specific Original model type size that has
    not already been converted, or you are trying to convert from an "unofficial"
    CN model (which often does not work because they deviate from the specifications).  You
    are probably experimenting just to learn though, so I will try to find a fix for
    you.
  created_at: 2023-08-14 15:12:34+00:00
  edited: false
  hidden: false
  id: 64da5272d4d94f5027ff9aed
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
      fullname: TimYao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TimYao
      type: user
    createdAt: '2023-08-14T23:59:18.000Z'
    data:
      edited: false
      editors:
      - TimYao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9250450134277344
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
          fullname: TimYao
          isHf: false
          isPro: false
          name: TimYao
          type: user
        html: '<p>Actually, what I''m trying to do is to switch to the usable <strong>Split_Einsum_V2</strong>
          version and incorporate the <strong>palletized 6-bit</strong> feature. Up
          to now, whenever I''ve attempted to test Stable Diffusion + ControlNet on
          the iPhone 14 Pro, it has failed due to insufficient memory. I''m wondering
          if using this format would allow for successful execution on the iPhone.</p>

          '
        raw: Actually, what I'm trying to do is to switch to the usable **Split_Einsum_V2**
          version and incorporate the **palletized 6-bit** feature. Up to now, whenever
          I've attempted to test Stable Diffusion + ControlNet on the iPhone 14 Pro,
          it has failed due to insufficient memory. I'm wondering if using this format
          would allow for successful execution on the iPhone.
        updatedAt: '2023-08-14T23:59:18.701Z'
      numEdits: 0
      reactions: []
    id: 64dabfd6c38427829db19550
    type: comment
  author: TimYao
  content: Actually, what I'm trying to do is to switch to the usable **Split_Einsum_V2**
    version and incorporate the **palletized 6-bit** feature. Up to now, whenever
    I've attempted to test Stable Diffusion + ControlNet on the iPhone 14 Pro, it
    has failed due to insufficient memory. I'm wondering if using this format would
    allow for successful execution on the iPhone.
  created_at: 2023-08-14 22:59:18+00:00
  edited: false
  hidden: false
  id: 64dabfd6c38427829db19550
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
      fullname: Joel Rittvo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jrrjrr
      type: user
    createdAt: '2023-08-15T00:39:05.000Z'
    data:
      edited: false
      editors:
      - jrrjrr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9553617238998413
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
          fullname: Joel Rittvo
          isHf: false
          isPro: false
          name: jrrjrr
          type: user
        html: '<p>Full use of the optimizations in s-e-v2 may require iOS 17.  This
          is the case in macOS 13 vs 14.  So unless you are running the iOS 17 beta,
          you may need to wait a bit.</p>

          <p>Beyond that, there are a lot of reports of s-e-v2 not really working
          at all, particularly on iOS.  I don''t use any of this on iOS, so I can''t
          say more than suggesting that you check through the open and closed issues
          at ml-stable-diffusion.</p>

          <p>Back to tying to do the conversion yourself . . . If I go back to using
          coremltools 6.3.0 and ml-stable-diffusion 0.4.0, the ControlNet conversion
          works again.  I will try some of these packages in newer versions, one at
          a time, to see if I can pin the issue down to just one package.</p>

          <p>Palletizing and s-e-v2 were both added in ml-stable-diffusion 1.0.0,
          so I will try with that package upgraded first.  It "requires" coremltools
          7.0b1, but I''ll try first without that.  I want to change just one thing
          at a time.  But I have one other issue to look into first.  I should have
          some additional info to report here in a few hours.</p>

          '
        raw: 'Full use of the optimizations in s-e-v2 may require iOS 17.  This is
          the case in macOS 13 vs 14.  So unless you are running the iOS 17 beta,
          you may need to wait a bit.


          Beyond that, there are a lot of reports of s-e-v2 not really working at
          all, particularly on iOS.  I don''t use any of this on iOS, so I can''t
          say more than suggesting that you check through the open and closed issues
          at ml-stable-diffusion.


          Back to tying to do the conversion yourself . . . If I go back to using
          coremltools 6.3.0 and ml-stable-diffusion 0.4.0, the ControlNet conversion
          works again.  I will try some of these packages in newer versions, one at
          a time, to see if I can pin the issue down to just one package.


          Palletizing and s-e-v2 were both added in ml-stable-diffusion 1.0.0, so
          I will try with that package upgraded first.  It "requires" coremltools
          7.0b1, but I''ll try first without that.  I want to change just one thing
          at a time.  But I have one other issue to look into first.  I should have
          some additional info to report here in a few hours.'
        updatedAt: '2023-08-15T00:39:05.333Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TimYao
    id: 64dac92978864cd2222a7fe0
    type: comment
  author: jrrjrr
  content: 'Full use of the optimizations in s-e-v2 may require iOS 17.  This is the
    case in macOS 13 vs 14.  So unless you are running the iOS 17 beta, you may need
    to wait a bit.


    Beyond that, there are a lot of reports of s-e-v2 not really working at all, particularly
    on iOS.  I don''t use any of this on iOS, so I can''t say more than suggesting
    that you check through the open and closed issues at ml-stable-diffusion.


    Back to tying to do the conversion yourself . . . If I go back to using coremltools
    6.3.0 and ml-stable-diffusion 0.4.0, the ControlNet conversion works again.  I
    will try some of these packages in newer versions, one at a time, to see if I
    can pin the issue down to just one package.


    Palletizing and s-e-v2 were both added in ml-stable-diffusion 1.0.0, so I will
    try with that package upgraded first.  It "requires" coremltools 7.0b1, but I''ll
    try first without that.  I want to change just one thing at a time.  But I have
    one other issue to look into first.  I should have some additional info to report
    here in a few hours.'
  created_at: 2023-08-14 23:39:05+00:00
  edited: false
  hidden: false
  id: 64dac92978864cd2222a7fe0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
      fullname: Joel Rittvo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jrrjrr
      type: user
    createdAt: '2023-08-15T02:31:53.000Z'
    data:
      edited: false
      editors:
      - jrrjrr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7938653826713562
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
          fullname: Joel Rittvo
          isHf: false
          isPro: false
          name: jrrjrr
          type: user
        html: '<p>The issue is with the upgrade from ml-stable-diffusion 0.4.0 to
          1.0.0.  The current coremltools package 7.0b1 and the torch 2.0.0 (or the
          torch 2.0.1 package) work fine with ml-stable-diffusion 0.4.0.  But updating
          to ml-stable-diffusion to 1.0.0 causes the ControlNet conversion process
          to errors out. </p>

          <p>The torch2coreml.py file that lists in the error message is a part of
          the ml-stable-diffusion package.  It is in the python_coreml_stable_diffusion
          subfolder that gets linked to the miniconda environment python site-packages.  It
          is the primary script running all conversions.</p>

          <p>If I substitute just the older torch2coreml.py file from the 0.4.0 ml-stable-diffusion
          package into the newer ml-stable-diffusion 1.0.0 package (and thus into
          the python_coreml_stable_diffusion package), the conversion still errors
          out.  And this older torch2coreml.py from 0.4.0 doesn''t support split-einsum-v2
          or palletizing anyway, which is our goal.</p>

          <p>But, If I substitute just the newer torch2coreml.py file from the 1.0.0
          ml-stable-diffusion package into the older ml-stable-diffusion 0.4.0 package
          (and thus into the python_coreml_stable_diffusion package), the conversion
          completes. </p>

          <p>This may be a quick fix for getting a split-einsum-v2 palletized conversion
          done.  I will try it shortly.  I need to try it with the --quantize-nbits
          argument and test the result, and then with the argument for split-einsum-v2
          (I assume there is one) and test that result.  Be back in a while.</p>

          '
        raw: "The issue is with the upgrade from ml-stable-diffusion 0.4.0 to 1.0.0.\
          \  The current coremltools package 7.0b1 and the torch 2.0.0 (or the torch\
          \ 2.0.1 package) work fine with ml-stable-diffusion 0.4.0.  But updating\
          \ to ml-stable-diffusion to 1.0.0 causes the ControlNet conversion process\
          \ to errors out. \n\nThe torch2coreml.py file that lists in the error message\
          \ is a part of the ml-stable-diffusion package.  It is in the python_coreml_stable_diffusion\
          \ subfolder that gets linked to the miniconda environment python site-packages.\
          \  It is the primary script running all conversions.\n\nIf I substitute\
          \ just the older torch2coreml.py file from the 0.4.0 ml-stable-diffusion\
          \ package into the newer ml-stable-diffusion 1.0.0 package (and thus into\
          \ the python_coreml_stable_diffusion package), the conversion still errors\
          \ out.  And this older torch2coreml.py from 0.4.0 doesn't support split-einsum-v2\
          \ or palletizing anyway, which is our goal.\n\nBut, If I substitute just\
          \ the newer torch2coreml.py file from the 1.0.0 ml-stable-diffusion package\
          \ into the older ml-stable-diffusion 0.4.0 package (and thus into the python_coreml_stable_diffusion\
          \ package), the conversion completes. \n\nThis may be a quick fix for getting\
          \ a split-einsum-v2 palletized conversion done.  I will try it shortly.\
          \  I need to try it with the --quantize-nbits argument and test the result,\
          \ and then with the argument for split-einsum-v2 (I assume there is one)\
          \ and test that result.  Be back in a while."
        updatedAt: '2023-08-15T02:31:53.393Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TimYao
    id: 64dae399e7bc8544f987f27c
    type: comment
  author: jrrjrr
  content: "The issue is with the upgrade from ml-stable-diffusion 0.4.0 to 1.0.0.\
    \  The current coremltools package 7.0b1 and the torch 2.0.0 (or the torch 2.0.1\
    \ package) work fine with ml-stable-diffusion 0.4.0.  But updating to ml-stable-diffusion\
    \ to 1.0.0 causes the ControlNet conversion process to errors out. \n\nThe torch2coreml.py\
    \ file that lists in the error message is a part of the ml-stable-diffusion package.\
    \  It is in the python_coreml_stable_diffusion subfolder that gets linked to the\
    \ miniconda environment python site-packages.  It is the primary script running\
    \ all conversions.\n\nIf I substitute just the older torch2coreml.py file from\
    \ the 0.4.0 ml-stable-diffusion package into the newer ml-stable-diffusion 1.0.0\
    \ package (and thus into the python_coreml_stable_diffusion package), the conversion\
    \ still errors out.  And this older torch2coreml.py from 0.4.0 doesn't support\
    \ split-einsum-v2 or palletizing anyway, which is our goal.\n\nBut, If I substitute\
    \ just the newer torch2coreml.py file from the 1.0.0 ml-stable-diffusion package\
    \ into the older ml-stable-diffusion 0.4.0 package (and thus into the python_coreml_stable_diffusion\
    \ package), the conversion completes. \n\nThis may be a quick fix for getting\
    \ a split-einsum-v2 palletized conversion done.  I will try it shortly.  I need\
    \ to try it with the --quantize-nbits argument and test the result, and then with\
    \ the argument for split-einsum-v2 (I assume there is one) and test that result.\
    \  Be back in a while."
  created_at: 2023-08-15 01:31:53+00:00
  edited: false
  hidden: false
  id: 64dae399e7bc8544f987f27c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
      fullname: Joel Rittvo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jrrjrr
      type: user
    createdAt: '2023-08-15T04:31:43.000Z'
    data:
      edited: true
      editors:
      - jrrjrr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9226199984550476
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
          fullname: Joel Rittvo
          isHf: false
          isPro: false
          name: jrrjrr
          type: user
        html: '<p>The above fix works for palletizing, but not for split-einsum-v2.  I
          did a regular split-einsum SoftEdge 6-bit conversion of SoftEdge and it
          works.  Save yourself some time dealing with the conversion and download
          it from here:</p>

          <p><a href="https://huggingface.co/jrrjrr/Playground/blob/main/SoftEdge_S-E_6b.zip">https://huggingface.co/jrrjrr/Playground/blob/main/SoftEdge_S-E_6b.zip</a></p>

          <p>If it solves the memory problem and you want to make other conversions
          and the post above is not detailed enough, leave a message here and I''ll
          post better instructions.  </p>

          <p>It is possible that this fix for converting ControlNets breaks converting
          regular models, so one might need to keep two miniconda environments or
          switch out some files/folders from a single one depending on what is being
          converted.  It is too late today for me to try a regular conversion with
          this altered pipeline, but I will tomorrow even if it is just to know for
          myself.</p>

          <p>And I''ll file a bug report with Apple in a day or two so they can fix
          this at some point so that all conversions work with the most current packages,
          as they should.</p>

          '
        raw: "The above fix works for palletizing, but not for split-einsum-v2.  I\
          \ did a regular split-einsum SoftEdge 6-bit conversion of SoftEdge and it\
          \ works.  Save yourself some time dealing with the conversion and download\
          \ it from here:\n\nhttps://huggingface.co/jrrjrr/Playground/blob/main/SoftEdge_S-E_6b.zip\n\
          \nIf it solves the memory problem and you want to make other conversions\
          \ and the post above is not detailed enough, leave a message here and I'll\
          \ post better instructions.  \n\nIt is possible that this fix for converting\
          \ ControlNets breaks converting regular models, so one might need to keep\
          \ two miniconda environments or switch out some files/folders from a single\
          \ one depending on what is being converted.  It is too late today for me\
          \ to try a regular conversion with this altered pipeline, but I will tomorrow\
          \ even if it is just to know for myself.\n\nAnd I'll file a bug report with\
          \ Apple in a day or two so they can fix this at some point so that all conversions\
          \ work with the most current packages, as they should."
        updatedAt: '2023-08-15T04:33:59.881Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TimYao
    id: 64daffafbb090cef556bf844
    type: comment
  author: jrrjrr
  content: "The above fix works for palletizing, but not for split-einsum-v2.  I did\
    \ a regular split-einsum SoftEdge 6-bit conversion of SoftEdge and it works. \
    \ Save yourself some time dealing with the conversion and download it from here:\n\
    \nhttps://huggingface.co/jrrjrr/Playground/blob/main/SoftEdge_S-E_6b.zip\n\nIf\
    \ it solves the memory problem and you want to make other conversions and the\
    \ post above is not detailed enough, leave a message here and I'll post better\
    \ instructions.  \n\nIt is possible that this fix for converting ControlNets breaks\
    \ converting regular models, so one might need to keep two miniconda environments\
    \ or switch out some files/folders from a single one depending on what is being\
    \ converted.  It is too late today for me to try a regular conversion with this\
    \ altered pipeline, but I will tomorrow even if it is just to know for myself.\n\
    \nAnd I'll file a bug report with Apple in a day or two so they can fix this at\
    \ some point so that all conversions work with the most current packages, as they\
    \ should."
  created_at: 2023-08-15 03:31:43+00:00
  edited: true
  hidden: false
  id: 64daffafbb090cef556bf844
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
      fullname: TimYao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TimYao
      type: user
    createdAt: '2023-08-15T05:27:06.000Z'
    data:
      edited: false
      editors:
      - TimYao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.936470627784729
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
          fullname: TimYao
          isHf: false
          isPro: false
          name: TimYao
          type: user
        html: '<p>Thank you for your help.</p>

          <p>After trying the SD1.5 split_einsum_v2 6 bit palletized model with ControlNet
          SoftEdge_S-E_6b model, it works in 13 steps denoising.<br>The app crashed
          after completing the process of generating images for the second time. It
          might have been because my phone was too hot and overheated.</p>

          <p>I think the iPhone should be able to run ControlNet; it''s a bit disappointing
          that it crashes.</p>

          <p>Test device: iPhone 14 Pro,<br>Test OS: iOS 14 beta 5</p>

          '
        raw: "Thank you for your help.\n\nAfter trying the SD1.5 split_einsum_v2 6\
          \ bit palletized model with ControlNet SoftEdge_S-E_6b model, it works in\
          \ 13 steps denoising. \nThe app crashed after completing the process of\
          \ generating images for the second time. It might have been because my phone\
          \ was too hot and overheated.\n\nI think the iPhone should be able to run\
          \ ControlNet; it's a bit disappointing that it crashes.\n\nTest device:\
          \ iPhone 14 Pro,\nTest OS: iOS 14 beta 5"
        updatedAt: '2023-08-15T05:27:06.013Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64db0caac307ee5369d58d13
    id: 64db0caac307ee5369d58d0f
    type: comment
  author: TimYao
  content: "Thank you for your help.\n\nAfter trying the SD1.5 split_einsum_v2 6 bit\
    \ palletized model with ControlNet SoftEdge_S-E_6b model, it works in 13 steps\
    \ denoising. \nThe app crashed after completing the process of generating images\
    \ for the second time. It might have been because my phone was too hot and overheated.\n\
    \nI think the iPhone should be able to run ControlNet; it's a bit disappointing\
    \ that it crashes.\n\nTest device: iPhone 14 Pro,\nTest OS: iOS 14 beta 5"
  created_at: 2023-08-15 04:27:06+00:00
  edited: false
  hidden: false
  id: 64db0caac307ee5369d58d0f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
      fullname: TimYao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TimYao
      type: user
    createdAt: '2023-08-15T05:27:06.000Z'
    data:
      status: closed
    id: 64db0caac307ee5369d58d13
    type: status-change
  author: TimYao
  created_at: 2023-08-15 04:27:06+00:00
  id: 64db0caac307ee5369d58d13
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
      fullname: Joel Rittvo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jrrjrr
      type: user
    createdAt: '2023-08-15T05:35:31.000Z'
    data:
      edited: false
      editors:
      - jrrjrr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.94496750831604
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
          fullname: Joel Rittvo
          isHf: false
          isPro: false
          name: jrrjrr
          type: user
        html: '<p>You should try it with a SD-1.5 split_einsum 6-bit (not a split_einsum_v2).   As
          I mentioned way up top, there seem to be a lot of problems with v2 on iOS
          that Apple is ignoring so far.  The v1 might work, though, to reduce memory
          pressure, but not to be faster.  I think it is worth a try, and if you do,
          post back here any results, good or bad.</p>

          '
        raw: You should try it with a SD-1.5 split_einsum 6-bit (not a split_einsum_v2).   As
          I mentioned way up top, there seem to be a lot of problems with v2 on iOS
          that Apple is ignoring so far.  The v1 might work, though, to reduce memory
          pressure, but not to be faster.  I think it is worth a try, and if you do,
          post back here any results, good or bad.
        updatedAt: '2023-08-15T05:35:31.640Z'
      numEdits: 0
      reactions: []
    id: 64db0ea395da0aa95cfae220
    type: comment
  author: jrrjrr
  content: You should try it with a SD-1.5 split_einsum 6-bit (not a split_einsum_v2).   As
    I mentioned way up top, there seem to be a lot of problems with v2 on iOS that
    Apple is ignoring so far.  The v1 might work, though, to reduce memory pressure,
    but not to be faster.  I think it is worth a try, and if you do, post back here
    any results, good or bad.
  created_at: 2023-08-15 04:35:31+00:00
  edited: false
  hidden: false
  id: 64db0ea395da0aa95cfae220
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
      fullname: Joel Rittvo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jrrjrr
      type: user
    createdAt: '2023-08-15T05:40:14.000Z'
    data:
      edited: false
      editors:
      - jrrjrr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9766696691513062
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
          fullname: Joel Rittvo
          isHf: false
          isPro: false
          name: jrrjrr
          type: user
        html: '<p>I happen to be converting an SD-1.5 split_einsum 6-bit right now.  I
          will post a link to it in case you don''t have access to one yourself.  It
          may take a while to upload it successfully.  Uploading to HF has been problematic
          for me the past week or two.</p>

          '
        raw: I happen to be converting an SD-1.5 split_einsum 6-bit right now.  I
          will post a link to it in case you don't have access to one yourself.  It
          may take a while to upload it successfully.  Uploading to HF has been problematic
          for me the past week or two.
        updatedAt: '2023-08-15T05:40:14.905Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - TimYao
    id: 64db0fbee42fba08b8a23918
    type: comment
  author: jrrjrr
  content: I happen to be converting an SD-1.5 split_einsum 6-bit right now.  I will
    post a link to it in case you don't have access to one yourself.  It may take
    a while to upload it successfully.  Uploading to HF has been problematic for me
    the past week or two.
  created_at: 2023-08-15 04:40:14+00:00
  edited: false
  hidden: false
  id: 64db0fbee42fba08b8a23918
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
      fullname: Joel Rittvo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jrrjrr
      type: user
    createdAt: '2023-08-15T06:11:48.000Z'
    data:
      edited: false
      editors:
      - jrrjrr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3189888298511505
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
          fullname: Joel Rittvo
          isHf: false
          isPro: false
          name: jrrjrr
          type: user
        html: '<p>Stable Diffusion 1.5 Split-Einsum 6-bit for ControlNet:   <a href="https://huggingface.co/jrrjrr/Playground/blob/main/Stable-Diffusion-1.5%20Split-Einsum%206-bit%20CN.zip">https://huggingface.co/jrrjrr/Playground/blob/main/Stable-Diffusion-1.5%20Split-Einsum%206-bit%20CN.zip</a></p>

          '
        raw: 'Stable Diffusion 1.5 Split-Einsum 6-bit for ControlNet:   https://huggingface.co/jrrjrr/Playground/blob/main/Stable-Diffusion-1.5%20Split-Einsum%206-bit%20CN.zip'
        updatedAt: '2023-08-15T06:11:48.150Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TimYao
      - count: 1
        reaction: "\U0001F91D"
        users:
        - TimYao
    id: 64db1724311afacb53ae7fb4
    type: comment
  author: jrrjrr
  content: 'Stable Diffusion 1.5 Split-Einsum 6-bit for ControlNet:   https://huggingface.co/jrrjrr/Playground/blob/main/Stable-Diffusion-1.5%20Split-Einsum%206-bit%20CN.zip'
  created_at: 2023-08-15 05:11:48+00:00
  edited: false
  hidden: false
  id: 64db1724311afacb53ae7fb4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
      fullname: TimYao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TimYao
      type: user
    createdAt: '2023-08-15T08:40:32.000Z'
    data:
      edited: false
      editors:
      - TimYao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.912676215171814
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
          fullname: TimYao
          isHf: false
          isPro: false
          name: TimYao
          type: user
        html: '<p>I tried but it still got crash after generating an image with controlNet.
          Maybe we need iPhone 15 with more RAM to run controlNet.</p>

          '
        raw: I tried but it still got crash after generating an image with controlNet.
          Maybe we need iPhone 15 with more RAM to run controlNet.
        updatedAt: '2023-08-15T08:40:32.178Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jrrjrr
    id: 64db3a0078864cd222386d05
    type: comment
  author: TimYao
  content: I tried but it still got crash after generating an image with controlNet.
    Maybe we need iPhone 15 with more RAM to run controlNet.
  created_at: 2023-08-15 07:40:32+00:00
  edited: false
  hidden: false
  id: 64db3a0078864cd222386d05
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
      fullname: TimYao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TimYao
      type: user
    createdAt: '2023-08-17T05:53:35.000Z'
    data:
      edited: true
      editors:
      - TimYao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8746300339698792
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
          fullname: TimYao
          isHf: false
          isPro: false
          name: TimYao
          type: user
        html: '<p>I''d like to ask if there are any limitations with Core ML''s ControlNet?<br>For
          example, if the Base Model is quantized to 6 bits, does the ControlNet also
          need to be quantized to 6 bits, can not be quantized to 4 bit  or no quantized?
          Or if the Base Model uses the Split_einsum_V2 attention implementation,
          is it not possible for the ControlNet to use Original or Split_Einsum?</p>

          '
        raw: "I'd like to ask if there are any limitations with Core ML's ControlNet?\
          \ \nFor example, if the Base Model is quantized to 6 bits, does the ControlNet\
          \ also need to be quantized to 6 bits, can not be quantized to 4 bit  or\
          \ no quantized? Or if the Base Model uses the Split_einsum_V2 attention\
          \ implementation, is it not possible for the ControlNet to use Original\
          \ or Split_Einsum?"
        updatedAt: '2023-08-17T05:54:22.050Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - zhuguanyu
    id: 64ddb5df0a23798a42f6e726
    type: comment
  author: TimYao
  content: "I'd like to ask if there are any limitations with Core ML's ControlNet?\
    \ \nFor example, if the Base Model is quantized to 6 bits, does the ControlNet\
    \ also need to be quantized to 6 bits, can not be quantized to 4 bit  or no quantized?\
    \ Or if the Base Model uses the Split_einsum_V2 attention implementation, is it\
    \ not possible for the ControlNet to use Original or Split_Einsum?"
  created_at: 2023-08-17 04:53:35+00:00
  edited: true
  hidden: false
  id: 64ddb5df0a23798a42f6e726
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642e6c76113b200fd7676956/ZWuQxth3AbO1D2uNQWPgl.jpeg?w=200&h=200&f=face
      fullname: zhumingming
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: zhuguanyu
      type: user
    createdAt: '2023-08-17T06:07:58.000Z'
    data:
      edited: false
      editors:
      - zhuguanyu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9419476389884949
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642e6c76113b200fd7676956/ZWuQxth3AbO1D2uNQWPgl.jpeg?w=200&h=200&f=face
          fullname: zhumingming
          isHf: false
          isPro: false
          name: zhuguanyu
          type: user
        html: '<p>That''s professional. Would you like to join the Mochi Diffusion
          Discord? There are more people available to answer your questions.</p>

          '
        raw: That's professional. Would you like to join the Mochi Diffusion Discord?
          There are more people available to answer your questions.
        updatedAt: '2023-08-17T06:07:58.461Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TimYao
    id: 64ddb93e32f59b1d734abbeb
    type: comment
  author: zhuguanyu
  content: That's professional. Would you like to join the Mochi Diffusion Discord?
    There are more people available to answer your questions.
  created_at: 2023-08-17 05:07:58+00:00
  edited: false
  hidden: false
  id: 64ddb93e32f59b1d734abbeb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
      fullname: TimYao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TimYao
      type: user
    createdAt: '2023-08-17T06:25:32.000Z'
    data:
      edited: false
      editors:
      - TimYao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9780358076095581
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f23b44aff8a9a560ac89750a773d107b.svg
          fullname: TimYao
          isHf: false
          isPro: false
          name: TimYao
          type: user
        html: '<p>Actually, I think this issue is more related to Apple''s ml-stable-diffusion
          library. But I wanted to ask since some people are able to run it without
          any problems.</p>

          '
        raw: Actually, I think this issue is more related to Apple's ml-stable-diffusion
          library. But I wanted to ask since some people are able to run it without
          any problems.
        updatedAt: '2023-08-17T06:25:32.570Z'
      numEdits: 0
      reactions: []
    id: 64ddbd5c240234818261808d
    type: comment
  author: TimYao
  content: Actually, I think this issue is more related to Apple's ml-stable-diffusion
    library. But I wanted to ask since some people are able to run it without any
    problems.
  created_at: 2023-08-17 05:25:32+00:00
  edited: false
  hidden: false
  id: 64ddbd5c240234818261808d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
      fullname: Joel Rittvo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jrrjrr
      type: user
    createdAt: '2023-08-17T06:32:56.000Z'
    data:
      edited: false
      editors:
      - jrrjrr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9633457660675049
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
          fullname: Joel Rittvo
          isHf: false
          isPro: false
          name: jrrjrr
          type: user
        html: '<p>I''ve mixed quantized and non-quantized without problems, so far,
          but I only tried a few combinations.  The quantized models get "converted"
          to 16 bit on the fly when they are used, so the pipeline is all 16 bit,
          which make me think any combination would work.</p>

          <p>It is probably trickier to mix spilt-einsum, split-einsum-v2, and original
          because they all use somewhat different unet architectures (dimensions,
          layers, etc) and the ControlNet unet needs to be able to "merge" with the
          base model unet.  It is something that someone should try, though, in various
          combinations.  I have not tried it at all.  I think one of the Discord member
          said he was able to use a 512x512 original ControlNet model with a split-einsum
          base model at one point.</p>

          '
        raw: 'I''ve mixed quantized and non-quantized without problems, so far, but
          I only tried a few combinations.  The quantized models get "converted" to
          16 bit on the fly when they are used, so the pipeline is all 16 bit, which
          make me think any combination would work.


          It is probably trickier to mix spilt-einsum, split-einsum-v2, and original
          because they all use somewhat different unet architectures (dimensions,
          layers, etc) and the ControlNet unet needs to be able to "merge" with the
          base model unet.  It is something that someone should try, though, in various
          combinations.  I have not tried it at all.  I think one of the Discord member
          said he was able to use a 512x512 original ControlNet model with a split-einsum
          base model at one point.'
        updatedAt: '2023-08-17T06:32:56.071Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - TimYao
        - Zabriskije
    id: 64ddbf1822f93c3288349422
    type: comment
  author: jrrjrr
  content: 'I''ve mixed quantized and non-quantized without problems, so far, but
    I only tried a few combinations.  The quantized models get "converted" to 16 bit
    on the fly when they are used, so the pipeline is all 16 bit, which make me think
    any combination would work.


    It is probably trickier to mix spilt-einsum, split-einsum-v2, and original because
    they all use somewhat different unet architectures (dimensions, layers, etc) and
    the ControlNet unet needs to be able to "merge" with the base model unet.  It
    is something that someone should try, though, in various combinations.  I have
    not tried it at all.  I think one of the Discord member said he was able to use
    a 512x512 original ControlNet model with a split-einsum base model at one point.'
  created_at: 2023-08-17 05:32:56+00:00
  edited: false
  hidden: false
  id: 64ddbf1822f93c3288349422
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
      fullname: Joel Rittvo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jrrjrr
      type: user
    createdAt: '2023-08-17T06:38:13.000Z'
    data:
      edited: false
      editors:
      - jrrjrr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9529815912246704
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677104471377-63d957976b496a404a43bcc6.jpeg?w=200&h=200&f=face
          fullname: Joel Rittvo
          isHf: false
          isPro: false
          name: jrrjrr
          type: user
        html: '<p>The people at ml-stable-diffusion that could answer these kinds
          of things generally don''t answer questions.  As zhuguanyu suggested, the
          Mochi Discord will almost always get you answers or help faster.</p>

          '
        raw: The people at ml-stable-diffusion that could answer these kinds of things
          generally don't answer questions.  As zhuguanyu suggested, the Mochi Discord
          will almost always get you answers or help faster.
        updatedAt: '2023-08-17T06:38:13.309Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - zhuguanyu
        - TimYao
        - Zabriskije
    id: 64ddc05532f59b1d734bbaab
    type: comment
  author: jrrjrr
  content: The people at ml-stable-diffusion that could answer these kinds of things
    generally don't answer questions.  As zhuguanyu suggested, the Mochi Discord will
    almost always get you answers or help faster.
  created_at: 2023-08-17 05:38:13+00:00
  edited: false
  hidden: false
  id: 64ddc05532f59b1d734bbaab
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: coreml-community/ControlNet-Models-For-Core-ML
repo_type: model
status: closed
target_branch: null
title: Convert control net model failed with "Missing key(s) in state_dict" error
