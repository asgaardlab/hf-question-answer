!!python/object:huggingface_hub.community.DiscussionWithDetails
author: shing3232
conflicting_files: null
created_at: 2024-01-13 17:38:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/298bb4ee30144181bf12af21f846c4dd.svg
      fullname: kas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shing3232
      type: user
    createdAt: '2024-01-13T17:38:24.000Z'
    data:
      edited: false
      editors:
      - shing3232
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8457245230674744
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/298bb4ee30144181bf12af21f846c4dd.svg
          fullname: kas
          isHf: false
          isPro: false
          name: shing3232
          type: user
        html: '<p>Same as the question<br>Could we do that or it does not matter at
          all.<br>Autoawq can calculate  AWQ for llama cpp quantization<br><a rel="nofollow"
          href="https://github.com/casper-hansen/AutoAWQ/pull/285">https://github.com/casper-hansen/AutoAWQ/pull/285</a><br>Thanks</p>

          '
        raw: "Same as the question\r\nCould we do that or it does not matter at all.\r\
          \nAutoawq can calculate  AWQ for llama cpp quantization \r\nhttps://github.com/casper-hansen/AutoAWQ/pull/285\r\
          \nThanks"
        updatedAt: '2024-01-13T17:38:24.342Z'
      numEdits: 0
      reactions: []
    id: 65a2ca901051c2b0db701625
    type: comment
  author: shing3232
  content: "Same as the question\r\nCould we do that or it does not matter at all.\r\
    \nAutoawq can calculate  AWQ for llama cpp quantization \r\nhttps://github.com/casper-hansen/AutoAWQ/pull/285\r\
    \nThanks"
  created_at: 2024-01-13 17:38:24+00:00
  edited: false
  hidden: false
  id: 65a2ca901051c2b0db701625
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/98d7cbc7bf4cbf4f2810cbc0a1a34d64.svg
      fullname: Iwan Kawrakow
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ikawrakow
      type: user
    createdAt: '2024-01-14T09:11:02.000Z'
    data:
      edited: false
      editors:
      - ikawrakow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9911584258079529
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/98d7cbc7bf4cbf4f2810cbc0a1a34d64.svg
          fullname: Iwan Kawrakow
          isHf: false
          isPro: false
          name: ikawrakow
          type: user
        html: '<p>What does AutoAWQ do? I can go and look around in the quoted repo,
          but it would be much easier if someone explained their approach.</p>

          '
        raw: What does AutoAWQ do? I can go and look around in the quoted repo, but
          it would be much easier if someone explained their approach.
        updatedAt: '2024-01-14T09:11:02.871Z'
      numEdits: 0
      reactions: []
    id: 65a3a5269c370409e6185042
    type: comment
  author: ikawrakow
  content: What does AutoAWQ do? I can go and look around in the quoted repo, but
    it would be much easier if someone explained their approach.
  created_at: 2024-01-14 09:11:02+00:00
  edited: false
  hidden: false
  id: 65a3a5269c370409e6185042
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/298bb4ee30144181bf12af21f846c4dd.svg
      fullname: kas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shing3232
      type: user
    createdAt: '2024-01-14T12:08:44.000Z'
    data:
      edited: true
      editors:
      - shing3232
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8327494859695435
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/298bb4ee30144181bf12af21f846c4dd.svg
          fullname: kas
          isHf: false
          isPro: false
          name: shing3232
          type: user
        html: '<blockquote>

          <p>What does AutoAWQ do? I can go and look around in the quoted repo, but
          it would be much easier if someone explained their approach.<br><a rel="nofollow"
          href="https://github.com/casper-hansen/AutoAWQ">https://github.com/casper-hansen/AutoAWQ</a><br><a
          rel="nofollow" href="https://github.com/mit-han-lab/llm-awq">https://github.com/mit-han-lab/llm-awq</a><br><a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6349bf9697fe7cc4603465a3/c8lMJzO-zV8gscRXwE0uw.png"><img
          alt="overview.png" src="https://cdn-uploads.huggingface.co/production/uploads/6349bf9697fe7cc4603465a3/c8lMJzO-zV8gscRXwE0uw.png"></a></p>

          </blockquote>

          <p><a rel="nofollow" href="https://arxiv.org/abs/2306.00978">https://arxiv.org/abs/2306.00978</a><br>Slide:
          <a rel="nofollow" href="https://www.dropbox.com/scl/fi/dtnp6h6y1mnp7g036axu6/AWQ-slide.pdf?rlkey=ffgh50hxhx8dmsnjiu8kef0ou&amp;dl=0">https://www.dropbox.com/scl/fi/dtnp6h6y1mnp7g036axu6/AWQ-slide.pdf?rlkey=ffgh50hxhx8dmsnjiu8kef0ou&amp;dl=0</a></p>

          '
        raw: '> What does AutoAWQ do? I can go and look around in the quoted repo,
          but it would be much easier if someone explained their approach.

          https://github.com/casper-hansen/AutoAWQ

          https://github.com/mit-han-lab/llm-awq

          ![overview.png](https://cdn-uploads.huggingface.co/production/uploads/6349bf9697fe7cc4603465a3/c8lMJzO-zV8gscRXwE0uw.png)


          https://arxiv.org/abs/2306.00978

          Slide: https://www.dropbox.com/scl/fi/dtnp6h6y1mnp7g036axu6/AWQ-slide.pdf?rlkey=ffgh50hxhx8dmsnjiu8kef0ou&dl=0'
        updatedAt: '2024-01-14T12:19:51.257Z'
      numEdits: 1
      reactions: []
    id: 65a3cecce8fe70d60cb24244
    type: comment
  author: shing3232
  content: '> What does AutoAWQ do? I can go and look around in the quoted repo, but
    it would be much easier if someone explained their approach.

    https://github.com/casper-hansen/AutoAWQ

    https://github.com/mit-han-lab/llm-awq

    ![overview.png](https://cdn-uploads.huggingface.co/production/uploads/6349bf9697fe7cc4603465a3/c8lMJzO-zV8gscRXwE0uw.png)


    https://arxiv.org/abs/2306.00978

    Slide: https://www.dropbox.com/scl/fi/dtnp6h6y1mnp7g036axu6/AWQ-slide.pdf?rlkey=ffgh50hxhx8dmsnjiu8kef0ou&dl=0'
  created_at: 2024-01-14 12:08:44+00:00
  edited: true
  hidden: false
  id: 65a3cecce8fe70d60cb24244
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/98d7cbc7bf4cbf4f2810cbc0a1a34d64.svg
      fullname: Iwan Kawrakow
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ikawrakow
      type: user
    createdAt: '2024-01-14T14:24:59.000Z'
    data:
      edited: false
      editors:
      - ikawrakow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9471821188926697
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/98d7cbc7bf4cbf4f2810cbc0a1a34d64.svg
          fullname: Iwan Kawrakow
          isHf: false
          isPro: false
          name: ikawrakow
          type: user
        html: '<p>If I understand their paper correctly, the scale search is also
          used in what I do for these quantized models, so not sure combining the
          two will help.</p>

          <p>But I have now contributed the quantization approach used for these models
          to <code>llama.cpp</code>.<br>My guess is that it is easier for the contributors
          of <a rel="nofollow" href="https://github.com/casper-hansen/AutoAWQ/">https://github.com/casper-hansen/AutoAWQ/</a>
          to try than for me to get up to speed with their repo.</p>

          '
        raw: 'If I understand their paper correctly, the scale search is also used
          in what I do for these quantized models, so not sure combining the two will
          help.


          But I have now contributed the quantization approach used for these models
          to `llama.cpp`.

          My guess is that it is easier for the contributors of https://github.com/casper-hansen/AutoAWQ/
          to try than for me to get up to speed with their repo.'
        updatedAt: '2024-01-14T14:24:59.514Z'
      numEdits: 0
      reactions: []
    id: 65a3eebbb4f188a4db804c0c
    type: comment
  author: ikawrakow
  content: 'If I understand their paper correctly, the scale search is also used in
    what I do for these quantized models, so not sure combining the two will help.


    But I have now contributed the quantization approach used for these models to
    `llama.cpp`.

    My guess is that it is easier for the contributors of https://github.com/casper-hansen/AutoAWQ/
    to try than for me to get up to speed with their repo.'
  created_at: 2024-01-14 14:24:59+00:00
  edited: false
  hidden: false
  id: 65a3eebbb4f188a4db804c0c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: ikawrakow/various-2bit-sota-gguf
repo_type: model
status: open
target_branch: null
title: Could We combine AWQ and Importance Matrix calculation together to further
  improve perplexity.
