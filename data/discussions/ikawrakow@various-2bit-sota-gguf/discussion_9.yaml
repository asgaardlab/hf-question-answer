!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Nexesenex
conflicting_files: null
created_at: 2024-01-23 21:29:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31b10b87d67ff7d0691f786a857d319a.svg
      fullname: Nexesenex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nexesenex
      type: user
    createdAt: '2024-01-23T21:29:10.000Z'
    data:
      edited: false
      editors:
      - Nexesenex
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9145771265029907
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31b10b87d67ff7d0691f786a857d319a.svg
          fullname: Nexesenex
          isHf: false
          isPro: false
          name: Nexesenex
          type: user
        html: '<p>You should share your parameters to make your iMatrix, man, because
          you obviously know best. ^^</p>

          '
        raw: You should share your parameters to make your iMatrix, man, because you
          obviously know best. ^^
        updatedAt: '2024-01-23T21:29:10.887Z'
      numEdits: 0
      reactions: []
    id: 65b02fa6a4953b36be16ef59
    type: comment
  author: Nexesenex
  content: You should share your parameters to make your iMatrix, man, because you
    obviously know best. ^^
  created_at: 2024-01-23 21:29:10+00:00
  edited: false
  hidden: false
  id: 65b02fa6a4953b36be16ef59
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/98d7cbc7bf4cbf4f2810cbc0a1a34d64.svg
      fullname: Iwan Kawrakow
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ikawrakow
      type: user
    createdAt: '2024-01-24T06:51:23.000Z'
    data:
      edited: false
      editors:
      - ikawrakow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8648971915245056
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/98d7cbc7bf4cbf4f2810cbc0a1a34d64.svg
          fullname: Iwan Kawrakow
          isHf: false
          isPro: false
          name: ikawrakow
          type: user
        html: '<p>According to <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/discussions/5006">this
          thread</a> I don''t really know. Tons of other people who know better :-)</p>

          <p>But if you want to know what I have done, I have simply created the importance
          matrix using</p>

          <pre><code>./imatrix -m &lt;some_model&gt; -f tests/wiki.train.raw -o some_model.imatrix
          --chunks 100

          </code></pre>

          <p>and then used it to quantize the model</p>

          <pre><code>./quantize --imatrix some_model.imatrix &lt;some_model&gt; iq2xxs.gguf
          iq2_xxs

          </code></pre>

          '
        raw: "According to [this thread](https://github.com/ggerganov/llama.cpp/discussions/5006)\
          \ I don't really know. Tons of other people who know better :-)\n\nBut if\
          \ you want to know what I have done, I have simply created the importance\
          \ matrix using\n```\n./imatrix -m <some_model> -f tests/wiki.train.raw -o\
          \ some_model.imatrix --chunks 100\n``` \nand then used it to quantize the\
          \ model\n```\n./quantize --imatrix some_model.imatrix <some_model> iq2xxs.gguf\
          \ iq2_xxs\n```\n"
        updatedAt: '2024-01-24T06:51:23.464Z'
      numEdits: 0
      reactions: []
    id: 65b0b36b717bc4853231480e
    type: comment
  author: ikawrakow
  content: "According to [this thread](https://github.com/ggerganov/llama.cpp/discussions/5006)\
    \ I don't really know. Tons of other people who know better :-)\n\nBut if you\
    \ want to know what I have done, I have simply created the importance matrix using\n\
    ```\n./imatrix -m <some_model> -f tests/wiki.train.raw -o some_model.imatrix --chunks\
    \ 100\n``` \nand then used it to quantize the model\n```\n./quantize --imatrix\
    \ some_model.imatrix <some_model> iq2xxs.gguf iq2_xxs\n```\n"
  created_at: 2024-01-24 06:51:23+00:00
  edited: false
  hidden: false
  id: 65b0b36b717bc4853231480e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: ikawrakow/various-2bit-sota-gguf
repo_type: model
status: open
target_branch: null
title: What -ctx and -chunks parameters did you use to make the iMatrix of the Lllama
  2 70b?
