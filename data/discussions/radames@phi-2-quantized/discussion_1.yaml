!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aaryaman
conflicting_files: null
created_at: 2023-12-14 18:49:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1664391462924-6330011ac375586dc3ac604c.jpeg?w=200&h=200&f=face
      fullname: Aaryaman Yadav
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aaryaman
      type: user
    createdAt: '2023-12-14T18:49:01.000Z'
    data:
      edited: false
      editors:
      - aaryaman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8712825775146484
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1664391462924-6330011ac375586dc3ac604c.jpeg?w=200&h=200&f=face
          fullname: Aaryaman Yadav
          isHf: false
          isPro: false
          name: aaryaman
          type: user
        html: '<p>Can someone provide instructions on how the original model can be
          quantized?<br>I downloaded the model from <a href="https://huggingface.co/microsoft/phi-2">microsoft/phi-2</a>
          and tried to quantize it using the scripts in <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>
          but got an error only to realize the model is not yet supported on llama.cpp.</p>

          <p>Any insights or suggestions would be greatly appreciated.</p>

          '
        raw: "Can someone provide instructions on how the original model can be quantized?\r\
          \nI downloaded the model from [microsoft/phi-2](https://huggingface.co/microsoft/phi-2)\
          \ and tried to quantize it using the scripts in [llama.cpp](https://github.com/ggerganov/llama.cpp)\
          \ but got an error only to realize the model is not yet supported on llama.cpp.\r\
          \n\r\nAny insights or suggestions would be greatly appreciated.\r\n"
        updatedAt: '2023-12-14T18:49:01.344Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Jenish-23
    id: 657b4e1dbd517f148854a38e
    type: comment
  author: aaryaman
  content: "Can someone provide instructions on how the original model can be quantized?\r\
    \nI downloaded the model from [microsoft/phi-2](https://huggingface.co/microsoft/phi-2)\
    \ and tried to quantize it using the scripts in [llama.cpp](https://github.com/ggerganov/llama.cpp)\
    \ but got an error only to realize the model is not yet supported on llama.cpp.\r\
    \n\r\nAny insights or suggestions would be greatly appreciated.\r\n"
  created_at: 2023-12-14 18:49:01+00:00
  edited: false
  hidden: false
  id: 657b4e1dbd517f148854a38e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6c696033f62ff734c965b05d93b42cb.svg
      fullname: The Bus
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bususer
      type: user
    createdAt: '2023-12-15T06:00:48.000Z'
    data:
      edited: false
      editors:
      - Bususer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9139338135719299
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6c696033f62ff734c965b05d93b42cb.svg
          fullname: The Bus
          isHf: false
          isPro: false
          name: Bususer
          type: user
        html: '<p>I think python code is used maybe python transformers library or
          the one used in example code</p>

          '
        raw: I think python code is used maybe python transformers library or the
          one used in example code
        updatedAt: '2023-12-15T06:00:48.439Z'
      numEdits: 0
      reactions: []
    id: 657beb90de028a439ec1f648
    type: comment
  author: Bususer
  content: I think python code is used maybe python transformers library or the one
    used in example code
  created_at: 2023-12-15 06:00:48+00:00
  edited: false
  hidden: false
  id: 657beb90de028a439ec1f648
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/45d50fb8dc44ee2f308b595eaa27cf90.svg
      fullname: G. Campos
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guser
      type: user
    createdAt: '2023-12-16T14:03:57.000Z'
    data:
      edited: false
      editors:
      - guser
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4748383164405823
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/45d50fb8dc44ee2f308b595eaa27cf90.svg
          fullname: G. Campos
          isHf: false
          isPro: false
          name: guser
          type: user
        html: '<p>Robin Kroonem in TheBloke/phi-2-GPTQ release discussion mentioned
          a change to fix it <a rel="nofollow" href="https://github.com/mrgraycode/llama.cpp/commit/12cc80cb8975aea3bc9f39d3c9b84f7001ab94c5#diff-150dc86746a90bad4fc2c3334aeb9b5887b3adad3cc1459446717638605348efR6239">https://github.com/mrgraycode/llama.cpp/commit/12cc80cb8975aea3bc9f39d3c9b84f7001ab94c5#diff-150dc86746a90bad4fc2c3334aeb9b5887b3adad3cc1459446717638605348efR6239</a></p>

          '
        raw: Robin Kroonem in TheBloke/phi-2-GPTQ release discussion mentioned a change
          to fix it https://github.com/mrgraycode/llama.cpp/commit/12cc80cb8975aea3bc9f39d3c9b84f7001ab94c5#diff-150dc86746a90bad4fc2c3334aeb9b5887b3adad3cc1459446717638605348efR6239
        updatedAt: '2023-12-16T14:03:57.639Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - aaryaman
    id: 657dae4d83543a061b3c1407
    type: comment
  author: guser
  content: Robin Kroonem in TheBloke/phi-2-GPTQ release discussion mentioned a change
    to fix it https://github.com/mrgraycode/llama.cpp/commit/12cc80cb8975aea3bc9f39d3c9b84f7001ab94c5#diff-150dc86746a90bad4fc2c3334aeb9b5887b3adad3cc1459446717638605348efR6239
  created_at: 2023-12-16 14:03:57+00:00
  edited: false
  hidden: false
  id: 657dae4d83543a061b3c1407
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1cb7cf8ac816ee6333eff7d3c412fd4e.svg
      fullname: Rinor Maloku
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rinormaloku
      type: user
    createdAt: '2024-01-09T14:42:15.000Z'
    data:
      edited: false
      editors:
      - rinormaloku
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9971133470535278
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1cb7cf8ac816ee6333eff7d3c412fd4e.svg
          fullname: Rinor Maloku
          isHf: false
          isPro: false
          name: rinormaloku
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;aaryaman&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/aaryaman\">@<span class=\"\
          underline\">aaryaman</span></a></span>\n\n\t</span></span> were you able\
          \ to quantize phi-2?</p>\n"
        raw: '@aaryaman were you able to quantize phi-2?'
        updatedAt: '2024-01-09T14:42:15.930Z'
      numEdits: 0
      reactions: []
    id: 659d5b47dda11310d8ab816d
    type: comment
  author: rinormaloku
  content: '@aaryaman were you able to quantize phi-2?'
  created_at: 2024-01-09 14:42:15+00:00
  edited: false
  hidden: false
  id: 659d5b47dda11310d8ab816d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: radames/phi-2-quantized
repo_type: model
status: open
target_branch: null
title: Need help with quantizing the original model
