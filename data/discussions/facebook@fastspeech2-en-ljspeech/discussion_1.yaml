!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Vlado
conflicting_files: null
created_at: 2022-06-02 18:52:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ed07571e58aa7508cc0eb99a0c8bbdd0.svg
      fullname: Portos
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vlado
      type: user
    createdAt: '2022-06-02T19:52:27.000Z'
    data:
      edited: true
      editors:
      - julien-c
      - Vlado
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/NQtzmrDdbG0H8qkZvRyGk.jpeg?w=200&h=200&f=face
          fullname: Julien Chaumond
          isHf: true
          isPro: true
          name: julien-c
          type: user
        html: "<p>Did anybody get this model working inside COG container ?</p>\n\
          <p>I'm getting this error  and not sure why :/</p>\n<pre><code> Traceback\
          \ (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/uvicorn/protocols/http/httptools_impl.py\"\
          , line 372, in run_asgi\n    result = await app(self.scope, self.receive,\
          \ self.send)\n  File \"/usr/local/lib/python3.8/site-packages/uvicorn/middleware/proxy_headers.py\"\
          , line 75, in __call__\n    return await self.app(scope, receive, send)\n\
          \  File \"/usr/local/lib/python3.8/site-packages/fastapi/applications.py\"\
          , line 269, in __call__\n    await super().__call__(scope, receive, send)\n\
          \  File \"/usr/local/lib/python3.8/site-packages/starlette/applications.py\"\
          , line 124, in __call__\n    await self.middleware_stack(scope, receive,\
          \ send)\n  File \"/usr/local/lib/python3.8/site-packages/starlette/middleware/errors.py\"\
          , line 184, in __call__\n    raise exc\n  File \"/usr/local/lib/python3.8/site-packages/starlette/middleware/errors.py\"\
          , line 162, in __call__\n    await self.app(scope, receive, _send)\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/starlette/exceptions.py\", line\
          \ 93, in __call__\n    raise exc\n  File \"/usr/local/lib/python3.8/site-packages/starlette/exceptions.py\"\
          , line 82, in __call__\n    await self.app(scope, receive, sender)\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/fastapi/middleware/asyncexitstack.py\"\
          , line 21, in __call__\n    raise e\n  File \"/usr/local/lib/python3.8/site-packages/fastapi/middleware/asyncexitstack.py\"\
          , line 18, in __call__\n    await self.app(scope, receive, send)\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/starlette/routing.py\", line\
          \ 670, in __call__\n    await route.handle(scope, receive, send)\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/starlette/routing.py\", line\
          \ 266, in handle\n    await self.app(scope, receive, send)\n  File \"/usr/local/lib/python3.8/site-packages/starlette/routing.py\"\
          , line 65, in app\n    response = await func(request)\n  File \"/usr/local/lib/python3.8/site-packages/fastapi/routing.py\"\
          , line 227, in app\n    raw_response = await run_endpoint_function(\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/fastapi/routing.py\", line 162,\
          \ in run_endpoint_function\n    return await run_in_threadpool(dependant.call,\
          \ **values)\n  File \"/usr/local/lib/python3.8/site-packages/starlette/concurrency.py\"\
          , line 41, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func,\
          \ *args)\n  File \"/usr/local/lib/python3.8/site-packages/anyio/to_thread.py\"\
          , line 31, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n\
          \  File \"/usr/local/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\"\
          , line 937, in run_sync_in_worker_thread\n    return await future\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\"\
          , line 867, in run\n    result = context.run(func, *args)\n  File \"/usr/local/lib/python3.8/site-packages/cog/server/http.py\"\
          , line 64, in predict\n    output = predictor.predict(**request.input.dict())\n\
          \  File \"predict.py\", line 17, in predict\n    self.generator = self.task.build_generator(self.model,\
          \ self.cfg)\n  File \"/fairseq/fairseq/tasks/text_to_speech.py\", line 151,\
          \ in build_generator\n    model = models[0]\nTypeError: 'FastSpeech2Model'\
          \ object is not subscriptable\n</code></pre>\n"
        raw: "Did anybody get this model working inside COG container ?\n\nI'm getting\
          \ this error  and not sure why :/\n\n```\n Traceback (most recent call last):\n\
          \  File \"/usr/local/lib/python3.8/site-packages/uvicorn/protocols/http/httptools_impl.py\"\
          , line 372, in run_asgi\n    result = await app(self.scope, self.receive,\
          \ self.send)\n  File \"/usr/local/lib/python3.8/site-packages/uvicorn/middleware/proxy_headers.py\"\
          , line 75, in __call__\n    return await self.app(scope, receive, send)\n\
          \  File \"/usr/local/lib/python3.8/site-packages/fastapi/applications.py\"\
          , line 269, in __call__\n    await super().__call__(scope, receive, send)\n\
          \  File \"/usr/local/lib/python3.8/site-packages/starlette/applications.py\"\
          , line 124, in __call__\n    await self.middleware_stack(scope, receive,\
          \ send)\n  File \"/usr/local/lib/python3.8/site-packages/starlette/middleware/errors.py\"\
          , line 184, in __call__\n    raise exc\n  File \"/usr/local/lib/python3.8/site-packages/starlette/middleware/errors.py\"\
          , line 162, in __call__\n    await self.app(scope, receive, _send)\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/starlette/exceptions.py\", line\
          \ 93, in __call__\n    raise exc\n  File \"/usr/local/lib/python3.8/site-packages/starlette/exceptions.py\"\
          , line 82, in __call__\n    await self.app(scope, receive, sender)\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/fastapi/middleware/asyncexitstack.py\"\
          , line 21, in __call__\n    raise e\n  File \"/usr/local/lib/python3.8/site-packages/fastapi/middleware/asyncexitstack.py\"\
          , line 18, in __call__\n    await self.app(scope, receive, send)\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/starlette/routing.py\", line\
          \ 670, in __call__\n    await route.handle(scope, receive, send)\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/starlette/routing.py\", line\
          \ 266, in handle\n    await self.app(scope, receive, send)\n  File \"/usr/local/lib/python3.8/site-packages/starlette/routing.py\"\
          , line 65, in app\n    response = await func(request)\n  File \"/usr/local/lib/python3.8/site-packages/fastapi/routing.py\"\
          , line 227, in app\n    raw_response = await run_endpoint_function(\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/fastapi/routing.py\", line 162,\
          \ in run_endpoint_function\n    return await run_in_threadpool(dependant.call,\
          \ **values)\n  File \"/usr/local/lib/python3.8/site-packages/starlette/concurrency.py\"\
          , line 41, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func,\
          \ *args)\n  File \"/usr/local/lib/python3.8/site-packages/anyio/to_thread.py\"\
          , line 31, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n\
          \  File \"/usr/local/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\"\
          , line 937, in run_sync_in_worker_thread\n    return await future\n  File\
          \ \"/usr/local/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\"\
          , line 867, in run\n    result = context.run(func, *args)\n  File \"/usr/local/lib/python3.8/site-packages/cog/server/http.py\"\
          , line 64, in predict\n    output = predictor.predict(**request.input.dict())\n\
          \  File \"predict.py\", line 17, in predict\n    self.generator = self.task.build_generator(self.model,\
          \ self.cfg)\n  File \"/fairseq/fairseq/tasks/text_to_speech.py\", line 151,\
          \ in build_generator\n    model = models[0]\nTypeError: 'FastSpeech2Model'\
          \ object is not subscriptable\n```"
        updatedAt: '2022-07-09T08:59:30.745Z'
      numEdits: 1
      reactions: []
    id: 629914fbea8640d87e216b83
    type: comment
  author: Vlado
  content: "Did anybody get this model working inside COG container ?\n\nI'm getting\
    \ this error  and not sure why :/\n\n```\n Traceback (most recent call last):\n\
    \  File \"/usr/local/lib/python3.8/site-packages/uvicorn/protocols/http/httptools_impl.py\"\
    , line 372, in run_asgi\n    result = await app(self.scope, self.receive, self.send)\n\
    \  File \"/usr/local/lib/python3.8/site-packages/uvicorn/middleware/proxy_headers.py\"\
    , line 75, in __call__\n    return await self.app(scope, receive, send)\n  File\
    \ \"/usr/local/lib/python3.8/site-packages/fastapi/applications.py\", line 269,\
    \ in __call__\n    await super().__call__(scope, receive, send)\n  File \"/usr/local/lib/python3.8/site-packages/starlette/applications.py\"\
    , line 124, in __call__\n    await self.middleware_stack(scope, receive, send)\n\
    \  File \"/usr/local/lib/python3.8/site-packages/starlette/middleware/errors.py\"\
    , line 184, in __call__\n    raise exc\n  File \"/usr/local/lib/python3.8/site-packages/starlette/middleware/errors.py\"\
    , line 162, in __call__\n    await self.app(scope, receive, _send)\n  File \"\
    /usr/local/lib/python3.8/site-packages/starlette/exceptions.py\", line 93, in\
    \ __call__\n    raise exc\n  File \"/usr/local/lib/python3.8/site-packages/starlette/exceptions.py\"\
    , line 82, in __call__\n    await self.app(scope, receive, sender)\n  File \"\
    /usr/local/lib/python3.8/site-packages/fastapi/middleware/asyncexitstack.py\"\
    , line 21, in __call__\n    raise e\n  File \"/usr/local/lib/python3.8/site-packages/fastapi/middleware/asyncexitstack.py\"\
    , line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/usr/local/lib/python3.8/site-packages/starlette/routing.py\"\
    , line 670, in __call__\n    await route.handle(scope, receive, send)\n  File\
    \ \"/usr/local/lib/python3.8/site-packages/starlette/routing.py\", line 266, in\
    \ handle\n    await self.app(scope, receive, send)\n  File \"/usr/local/lib/python3.8/site-packages/starlette/routing.py\"\
    , line 65, in app\n    response = await func(request)\n  File \"/usr/local/lib/python3.8/site-packages/fastapi/routing.py\"\
    , line 227, in app\n    raw_response = await run_endpoint_function(\n  File \"\
    /usr/local/lib/python3.8/site-packages/fastapi/routing.py\", line 162, in run_endpoint_function\n\
    \    return await run_in_threadpool(dependant.call, **values)\n  File \"/usr/local/lib/python3.8/site-packages/starlette/concurrency.py\"\
    , line 41, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func,\
    \ *args)\n  File \"/usr/local/lib/python3.8/site-packages/anyio/to_thread.py\"\
    , line 31, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n\
    \  File \"/usr/local/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\"\
    , line 937, in run_sync_in_worker_thread\n    return await future\n  File \"/usr/local/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\"\
    , line 867, in run\n    result = context.run(func, *args)\n  File \"/usr/local/lib/python3.8/site-packages/cog/server/http.py\"\
    , line 64, in predict\n    output = predictor.predict(**request.input.dict())\n\
    \  File \"predict.py\", line 17, in predict\n    self.generator = self.task.build_generator(self.model,\
    \ self.cfg)\n  File \"/fairseq/fairseq/tasks/text_to_speech.py\", line 151, in\
    \ build_generator\n    model = models[0]\nTypeError: 'FastSpeech2Model' object\
    \ is not subscriptable\n```"
  created_at: 2022-06-02 18:52:27+00:00
  edited: true
  hidden: false
  id: 629914fbea8640d87e216b83
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2022-06-03T10:00:54.000Z'
    data:
      edited: false
      editors:
      - patrickvonplaten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
          fullname: Patrick von Platen
          isHf: true
          isPro: false
          name: patrickvonplaten
          type: user
        html: "<p>What is a COG container? Also pinging <span data-props=\"{&quot;user&quot;:&quot;anton-l&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/anton-l\"\
          >@<span class=\"underline\">anton-l</span></a></span>\n\n\t</span></span>\
          \ here</p>\n"
        raw: What is a COG container? Also pinging @anton-l here
        updatedAt: '2022-06-03T10:00:54.918Z'
      numEdits: 0
      reactions: []
    id: 6299dbd60fa8aec7f1bac406
    type: comment
  author: patrickvonplaten
  content: What is a COG container? Also pinging @anton-l here
  created_at: 2022-06-03 09:00:54+00:00
  edited: false
  hidden: false
  id: 6299dbd60fa8aec7f1bac406
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ed07571e58aa7508cc0eb99a0c8bbdd0.svg
      fullname: Portos
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vlado
      type: user
    createdAt: '2022-06-03T10:09:31.000Z'
    data:
      edited: false
      editors:
      - Vlado
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ed07571e58aa7508cc0eb99a0c8bbdd0.svg
          fullname: Portos
          isHf: false
          isPro: false
          name: Vlado
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;patrickvonplaten&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/patrickvonplaten\"\
          >@<span class=\"underline\">patrickvonplaten</span></a></span>\n\n\t</span></span>\
          \ ah sorry, its a docker utility/framework for ML / AI.. <a rel=\"nofollow\"\
          \ href=\"https://github.com/replicate/cog\">https://github.com/replicate/cog</a>\
          \ basically you can define one yml with prerequisites, and it does most\
          \ of the stuff for you, like API </p>\n"
        raw: '@patrickvonplaten ah sorry, its a docker utility/framework for ML /
          AI.. https://github.com/replicate/cog basically you can define one yml with
          prerequisites, and it does most of the stuff for you, like API '
        updatedAt: '2022-06-03T10:09:31.490Z'
      numEdits: 0
      reactions: []
    id: 6299dddb5ab4232a3fda746c
    type: comment
  author: Vlado
  content: '@patrickvonplaten ah sorry, its a docker utility/framework for ML / AI..
    https://github.com/replicate/cog basically you can define one yml with prerequisites,
    and it does most of the stuff for you, like API '
  created_at: 2022-06-03 09:09:31+00:00
  edited: false
  hidden: false
  id: 6299dddb5ab4232a3fda746c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613655355830-noauth.png?w=200&h=200&f=face
      fullname: Anton Lozhkov
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: anton-l
      type: user
    createdAt: '2022-06-04T13:23:17.000Z'
    data:
      edited: false
      editors:
      - anton-l
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613655355830-noauth.png?w=200&h=200&f=face
          fullname: Anton Lozhkov
          isHf: true
          isPro: false
          name: anton-l
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Vlado&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Vlado\">@<span class=\"\
          underline\">Vlado</span></a></span>\n\n\t</span></span> which <code>farseq</code>\
          \ version do you use? The pip release hasn't been updated in quite a while,\
          \ so you may need to install it from source: <a rel=\"nofollow\" href=\"\
          https://github.com/facebookresearch/fairseq#requirements-and-installation\"\
          >https://github.com/facebookresearch/fairseq#requirements-and-installation</a></p>\n"
        raw: '@Vlado which `farseq` version do you use? The pip release hasn''t been
          updated in quite a while, so you may need to install it from source: https://github.com/facebookresearch/fairseq#requirements-and-installation'
        updatedAt: '2022-06-04T13:23:17.586Z'
      numEdits: 0
      reactions: []
    id: 629b5cc50a85ae646a191d82
    type: comment
  author: anton-l
  content: '@Vlado which `farseq` version do you use? The pip release hasn''t been
    updated in quite a while, so you may need to install it from source: https://github.com/facebookresearch/fairseq#requirements-and-installation'
  created_at: 2022-06-04 12:23:17+00:00
  edited: false
  hidden: false
  id: 629b5cc50a85ae646a191d82
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ed07571e58aa7508cc0eb99a0c8bbdd0.svg
      fullname: Portos
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vlado
      type: user
    createdAt: '2022-06-04T14:20:21.000Z'
    data:
      edited: false
      editors:
      - Vlado
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ed07571e58aa7508cc0eb99a0c8bbdd0.svg
          fullname: Portos
          isHf: false
          isPro: false
          name: Vlado
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;anton-l&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/anton-l\">@<span class=\"\
          underline\">anton-l</span></a></span>\n\n\t</span></span> I'm using the\
          \ latest from git.<br>My cog.yml looks like this:</p>\n<pre><code>build:\n\
          \  gpu: false\n  python_version: \"3.8\"\n  python_packages:\n    - torch==1.11.0\n\
          \    - huggingface-hub==0.7.0\n  run:\n    - git clone https://github.com/pytorch/fairseq\
          \ &amp;&amp; cd fairseq &amp;&amp; pip install --editable ./\n</code></pre>\n\
          <p>and the predictor file is just this:</p>\n<pre><code>import os\nos.environ['HF_HOME']\
          \ = '/src/cache'\nfrom cog import BasePredictor, Path, Input\nfrom fairseq.checkpoint_utils\
          \ import load_model_ensemble_and_task_from_hf_hub\nfrom fairseq.models.text_to_speech.hub_interface\
          \ import TTSHubInterface\n\n\nclass Predictor(BasePredictor):\n\n    def\
          \ predict(self, text: str = Input(description=\"Sentence to speak out\"\
          )) -&gt; str:\n        self.models, self.cfg, self.task = load_model_ensemble_and_task_from_hf_hub(\"\
          facebook/fastspeech2-en-ljspeech\", arg_overrides={\"vocoder\": \"hifigan\"\
          , \"fp16\": False})\n        self.model = self.models[0] &lt;--- THIS PART\
          \ FAILS\n        TTSHubInterface.update_cfg_with_data_cfg(self.cfg, self.task.data_cfg)\n\
          \        self.generator = self.task.build_generator(self.model, self.cfg)\n\
          \        self.sample = TTSHubInterface.get_model_input(self.task, self.text)\n\
          \        self.wav, self.rate = TTSHubInterface.get_prediction(self.task,\
          \ self.model, self.generator, self.sample)\n\n        return  self.wav,\
          \ self.rate\n</code></pre>\n<p>Maybe I'm doing it wrong :)</p>\n"
        raw: "@anton-l I'm using the latest from git.\nMy cog.yml looks like this:\n\
          \n```\nbuild:\n  gpu: false\n  python_version: \"3.8\"\n  python_packages:\n\
          \    - torch==1.11.0\n    - huggingface-hub==0.7.0\n  run:\n    - git clone\
          \ https://github.com/pytorch/fairseq && cd fairseq && pip install --editable\
          \ ./\n```\nand the predictor file is just this:\n\n```\nimport os\nos.environ['HF_HOME']\
          \ = '/src/cache'\nfrom cog import BasePredictor, Path, Input\nfrom fairseq.checkpoint_utils\
          \ import load_model_ensemble_and_task_from_hf_hub\nfrom fairseq.models.text_to_speech.hub_interface\
          \ import TTSHubInterface\n\n\nclass Predictor(BasePredictor):\n\n    def\
          \ predict(self, text: str = Input(description=\"Sentence to speak out\"\
          )) -> str:\n        self.models, self.cfg, self.task = load_model_ensemble_and_task_from_hf_hub(\"\
          facebook/fastspeech2-en-ljspeech\", arg_overrides={\"vocoder\": \"hifigan\"\
          , \"fp16\": False})\n        self.model = self.models[0] <--- THIS PART\
          \ FAILS\n        TTSHubInterface.update_cfg_with_data_cfg(self.cfg, self.task.data_cfg)\n\
          \        self.generator = self.task.build_generator(self.model, self.cfg)\n\
          \        self.sample = TTSHubInterface.get_model_input(self.task, self.text)\n\
          \        self.wav, self.rate = TTSHubInterface.get_prediction(self.task,\
          \ self.model, self.generator, self.sample)\n\n        return  self.wav,\
          \ self.rate\n```\n\nMaybe I'm doing it wrong :)\n"
        updatedAt: '2022-06-04T14:20:21.669Z'
      numEdits: 0
      reactions: []
    id: 629b6a250a85ae646a198c6f
    type: comment
  author: Vlado
  content: "@anton-l I'm using the latest from git.\nMy cog.yml looks like this:\n\
    \n```\nbuild:\n  gpu: false\n  python_version: \"3.8\"\n  python_packages:\n \
    \   - torch==1.11.0\n    - huggingface-hub==0.7.0\n  run:\n    - git clone https://github.com/pytorch/fairseq\
    \ && cd fairseq && pip install --editable ./\n```\nand the predictor file is just\
    \ this:\n\n```\nimport os\nos.environ['HF_HOME'] = '/src/cache'\nfrom cog import\
    \ BasePredictor, Path, Input\nfrom fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\n\
    from fairseq.models.text_to_speech.hub_interface import TTSHubInterface\n\n\n\
    class Predictor(BasePredictor):\n\n    def predict(self, text: str = Input(description=\"\
    Sentence to speak out\")) -> str:\n        self.models, self.cfg, self.task =\
    \ load_model_ensemble_and_task_from_hf_hub(\"facebook/fastspeech2-en-ljspeech\"\
    , arg_overrides={\"vocoder\": \"hifigan\", \"fp16\": False})\n        self.model\
    \ = self.models[0] <--- THIS PART FAILS\n        TTSHubInterface.update_cfg_with_data_cfg(self.cfg,\
    \ self.task.data_cfg)\n        self.generator = self.task.build_generator(self.model,\
    \ self.cfg)\n        self.sample = TTSHubInterface.get_model_input(self.task,\
    \ self.text)\n        self.wav, self.rate = TTSHubInterface.get_prediction(self.task,\
    \ self.model, self.generator, self.sample)\n\n        return  self.wav, self.rate\n\
    ```\n\nMaybe I'm doing it wrong :)\n"
  created_at: 2022-06-04 13:20:21+00:00
  edited: false
  hidden: false
  id: 629b6a250a85ae646a198c6f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/78c7d29b3b87c67239f434a168d15dfb.svg
      fullname: QuQu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JuliaQuQu
      type: user
    createdAt: '2022-07-07T06:13:28.000Z'
    data:
      edited: false
      editors:
      - JuliaQuQu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/78c7d29b3b87c67239f434a168d15dfb.svg
          fullname: QuQu
          isHf: false
          isPro: false
          name: JuliaQuQu
          type: user
        html: '<p>I meet the same problem<br>model = models[0]<br>TypeError: ''FastSpeech2Model''
          object does not support indexing</p>

          '
        raw: "I meet the same problem \nmodel = models[0]\nTypeError: 'FastSpeech2Model'\
          \ object does not support indexing"
        updatedAt: '2022-07-07T06:13:28.957Z'
      numEdits: 0
      reactions: []
    id: 62c679886af791614d0235d2
    type: comment
  author: JuliaQuQu
  content: "I meet the same problem \nmodel = models[0]\nTypeError: 'FastSpeech2Model'\
    \ object does not support indexing"
  created_at: 2022-07-07 05:13:28+00:00
  edited: false
  hidden: false
  id: 62c679886af791614d0235d2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/78c7d29b3b87c67239f434a168d15dfb.svg
      fullname: QuQu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JuliaQuQu
      type: user
    createdAt: '2022-07-08T02:50:23.000Z'
    data:
      edited: false
      editors:
      - JuliaQuQu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/78c7d29b3b87c67239f434a168d15dfb.svg
          fullname: QuQu
          isHf: false
          isPro: false
          name: JuliaQuQu
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;Vlado&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Vlado\"\
          >@<span class=\"underline\">Vlado</span></a></span>\n\n\t</span></span>\
          \ which <code>farseq</code> version do you use? The pip release hasn't been\
          \ updated in quite a while, so you may need to install it from source: <a\
          \ rel=\"nofollow\" href=\"https://github.com/facebookresearch/fairseq#requirements-and-installation\"\
          >https://github.com/facebookresearch/fairseq#requirements-and-installation</a><br>\
          \ File \"test_for_transformer.py\", line 12, in <br>    generator = task.build_generator(model,\
          \ cfg)<br>  File \"/data/AI-Capability/fairseq/fairseq/tasks/text_to_speech.py\"\
          , line 151, in build_generator<br>    model = models[0]<br>TypeError: 'FastSpeech2Model'\
          \ object is not subscriptable<br>Extactly the same question.</p>\n</blockquote>\n"
        raw: "> @Vlado which `farseq` version do you use? The pip release hasn't been\
          \ updated in quite a while, so you may need to install it from source: https://github.com/facebookresearch/fairseq#requirements-and-installation\n\
          \ File \"test_for_transformer.py\", line 12, in <module>\n    generator\
          \ = task.build_generator(model, cfg)\n  File \"/data/AI-Capability/fairseq/fairseq/tasks/text_to_speech.py\"\
          , line 151, in build_generator\n    model = models[0]\nTypeError: 'FastSpeech2Model'\
          \ object is not subscriptable\nExtactly the same question."
        updatedAt: '2022-07-08T02:50:23.432Z'
      numEdits: 0
      reactions: []
    id: 62c79b6fe9d8ced19f00bad0
    type: comment
  author: JuliaQuQu
  content: "> @Vlado which `farseq` version do you use? The pip release hasn't been\
    \ updated in quite a while, so you may need to install it from source: https://github.com/facebookresearch/fairseq#requirements-and-installation\n\
    \ File \"test_for_transformer.py\", line 12, in <module>\n    generator = task.build_generator(model,\
    \ cfg)\n  File \"/data/AI-Capability/fairseq/fairseq/tasks/text_to_speech.py\"\
    , line 151, in build_generator\n    model = models[0]\nTypeError: 'FastSpeech2Model'\
    \ object is not subscriptable\nExtactly the same question."
  created_at: 2022-07-08 01:50:23+00:00
  edited: false
  hidden: false
  id: 62c79b6fe9d8ced19f00bad0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/78c7d29b3b87c67239f434a168d15dfb.svg
      fullname: QuQu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JuliaQuQu
      type: user
    createdAt: '2022-07-08T03:08:00.000Z'
    data:
      edited: true
      editors:
      - julien-c
      - JuliaQuQu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/NQtzmrDdbG0H8qkZvRyGk.jpeg?w=200&h=200&f=face
          fullname: Julien Chaumond
          isHf: true
          isPro: true
          name: julien-c
          type: user
        html: '<p>Try this:</p>

          <pre><code class="language-python">model = models

          TTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)

          generator = task.build_generator(model, cfg)


          text = <span class="hljs-string">"Hello, this is a test run."</span>


          sample = TTSHubInterface.get_model_input(task, text)

          wav, rate = TTSHubInterface.get_prediction(task, model[<span class="hljs-number">0</span>],
          generator, sample)

          </code></pre>

          <p>move model[0] to the predict line. But I am not sure the result is correct.</p>

          '
        raw: 'Try this:

          ```python

          model = models

          TTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)

          generator = task.build_generator(model, cfg)


          text = "Hello, this is a test run."


          sample = TTSHubInterface.get_model_input(task, text)

          wav, rate = TTSHubInterface.get_prediction(task, model[0], generator, sample)

          ```

          move model[0] to the predict line. But I am not sure the result is correct.'
        updatedAt: '2022-07-09T08:59:58.760Z'
      numEdits: 1
      reactions: []
    id: 62c79f9090f49dcd21fd265d
    type: comment
  author: JuliaQuQu
  content: 'Try this:

    ```python

    model = models

    TTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)

    generator = task.build_generator(model, cfg)


    text = "Hello, this is a test run."


    sample = TTSHubInterface.get_model_input(task, text)

    wav, rate = TTSHubInterface.get_prediction(task, model[0], generator, sample)

    ```

    move model[0] to the predict line. But I am not sure the result is correct.'
  created_at: 2022-07-08 02:08:00+00:00
  edited: true
  hidden: false
  id: 62c79f9090f49dcd21fd265d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/NQtzmrDdbG0H8qkZvRyGk.jpeg?w=200&h=200&f=face
      fullname: Julien Chaumond
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: true
      name: julien-c
      type: user
    createdAt: '2022-07-09T09:00:33.000Z'
    data:
      edited: false
      editors:
      - julien-c
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/NQtzmrDdbG0H8qkZvRyGk.jpeg?w=200&h=200&f=face
          fullname: Julien Chaumond
          isHf: true
          isPro: true
          name: julien-c
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;vlado&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/vlado\">@<span class=\"\
          underline\">vlado</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;JuliaQuQu&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/JuliaQuQu\">@<span class=\"underline\">JuliaQuQu</span></a></span>\n\
          \n\t</span></span> I edited your comments to use backticks around code blocks\
          \ to improve legibility</p>\n"
        raw: '@vlado @JuliaQuQu I edited your comments to use backticks around code
          blocks to improve legibility'
        updatedAt: '2022-07-09T09:00:33.203Z'
      numEdits: 0
      reactions: []
    id: 62c943b168457adefc48e0c2
    type: comment
  author: julien-c
  content: '@vlado @JuliaQuQu I edited your comments to use backticks around code
    blocks to improve legibility'
  created_at: 2022-07-09 08:00:33+00:00
  edited: false
  hidden: false
  id: 62c943b168457adefc48e0c2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: facebook/fastspeech2-en-ljspeech
repo_type: model
status: open
target_branch: null
title: Working inside COG ?
