!!python/object:huggingface_hub.community.DiscussionWithDetails
author: erfankh
conflicting_files: null
created_at: 2022-11-27 14:19:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3fc636f22aaaf2f7adaa34bdf0a80a93.svg
      fullname: Erfan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: erfankh
      type: user
    createdAt: '2022-11-27T14:19:32.000Z'
    data:
      edited: false
      editors:
      - erfankh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3fc636f22aaaf2f7adaa34bdf0a80a93.svg
          fullname: Erfan
          isHf: false
          isPro: false
          name: erfankh
          type: user
        html: '<p>thanks for this great project<br>I want to use for YelpDataset.
          a total number of reviews is almost 7 million texts. how can I use this
          code for the Yelp CSV dataset?</p>

          '
        raw: "thanks for this great project\r\nI want to use for YelpDataset. a total\
          \ number of reviews is almost 7 million texts. how can I use this code for\
          \ the Yelp CSV dataset?"
        updatedAt: '2022-11-27T14:19:32.048Z'
      numEdits: 0
      reactions: []
    id: 638371f4830bbad7b9143bd2
    type: comment
  author: erfankh
  content: "thanks for this great project\r\nI want to use for YelpDataset. a total\
    \ number of reviews is almost 7 million texts. how can I use this code for the\
    \ Yelp CSV dataset?"
  created_at: 2022-11-27 14:19:32+00:00
  edited: false
  hidden: false
  id: 638371f4830bbad7b9143bd2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/35fb904ebae3616c73d76e91a4de0c4d.svg
      fullname: Hartmann
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: j-hartmann
      type: user
    createdAt: '2022-11-27T16:48:14.000Z'
    data:
      edited: false
      editors:
      - j-hartmann
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/35fb904ebae3616c73d76e91a4de0c4d.svg
          fullname: Hartmann
          isHf: false
          isPro: false
          name: j-hartmann
          type: user
        html: "<p>Thank you <span data-props=\"{&quot;user&quot;:&quot;erfankh&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/erfankh\"\
          >@<span class=\"underline\">erfankh</span></a></span>\n\n\t</span></span>.\
          \ I'm happy to hear you find the model helpful!</p>\n<p>In the Application\
          \ section of the model card, you can find an \"Open in Colab\" button that\
          \ demonstrates how you can classify your own CSV file on Google Colab (see\
          \ screenshot below).</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1669567637937-60743b8b227ff33193711103.png\"\
          ><img alt=\"grafik.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1669567637937-60743b8b227ff33193711103.png\"\
          ></a></p>\n"
        raw: 'Thank you @erfankh. I''m happy to hear you find the model helpful!


          In the Application section of the model card, you can find an "Open in Colab"
          button that demonstrates how you can classify your own CSV file on Google
          Colab (see screenshot below).


          ![grafik.png](https://cdn-uploads.huggingface.co/production/uploads/1669567637937-60743b8b227ff33193711103.png)


          '
        updatedAt: '2022-11-27T16:48:14.906Z'
      numEdits: 0
      reactions: []
      relatedEventId: 638394ce5dfbee9bd0dd6497
    id: 638394ce5dfbee9bd0dd6496
    type: comment
  author: j-hartmann
  content: 'Thank you @erfankh. I''m happy to hear you find the model helpful!


    In the Application section of the model card, you can find an "Open in Colab"
    button that demonstrates how you can classify your own CSV file on Google Colab
    (see screenshot below).


    ![grafik.png](https://cdn-uploads.huggingface.co/production/uploads/1669567637937-60743b8b227ff33193711103.png)


    '
  created_at: 2022-11-27 16:48:14+00:00
  edited: false
  hidden: false
  id: 638394ce5dfbee9bd0dd6496
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/35fb904ebae3616c73d76e91a4de0c4d.svg
      fullname: Hartmann
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: j-hartmann
      type: user
    createdAt: '2022-11-27T16:48:14.000Z'
    data:
      status: closed
    id: 638394ce5dfbee9bd0dd6497
    type: status-change
  author: j-hartmann
  created_at: 2022-11-27 16:48:14+00:00
  id: 638394ce5dfbee9bd0dd6497
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3fc636f22aaaf2f7adaa34bdf0a80a93.svg
      fullname: Erfan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: erfankh
      type: user
    createdAt: '2022-11-28T12:51:12.000Z'
    data:
      edited: true
      editors:
      - erfankh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3fc636f22aaaf2f7adaa34bdf0a80a93.svg
          fullname: Erfan
          isHf: false
          isPro: false
          name: erfankh
          type: user
        html: '<p>yeah, I saw this code but I am talking about a 4Gig text file that
          I need a lot of memory to run this code on this CSV. so my problem is how
          can I use efficiently this code for 7 million rows of long text?</p>

          <h1 id="tokenize-texts-and-create-prediction-data-set">Tokenize texts and
          create prediction data set</h1>

          <p>tokenized_texts = tokenizer(pred_texts,truncation=True,padding=True)<br>pred_dataset
          = SimpleDataset(tokenized_texts)</p>

          <p>this part of code use high memory. i don''t know how to change this part
          to use less for large dataset</p>

          '
        raw: 'yeah, I saw this code but I am talking about a 4Gig text file that I
          need a lot of memory to run this code on this CSV. so my problem is how
          can I use efficiently this code for 7 million rows of long text?


          # Tokenize texts and create prediction data set

          tokenized_texts = tokenizer(pred_texts,truncation=True,padding=True)

          pred_dataset = SimpleDataset(tokenized_texts)


          this part of code use high memory. i don''t know how to change this part
          to use less for large dataset'
        updatedAt: '2022-11-28T15:10:30.294Z'
      numEdits: 1
      reactions: []
    id: 6384aec0a179f85600564c7e
    type: comment
  author: erfankh
  content: 'yeah, I saw this code but I am talking about a 4Gig text file that I need
    a lot of memory to run this code on this CSV. so my problem is how can I use efficiently
    this code for 7 million rows of long text?


    # Tokenize texts and create prediction data set

    tokenized_texts = tokenizer(pred_texts,truncation=True,padding=True)

    pred_dataset = SimpleDataset(tokenized_texts)


    this part of code use high memory. i don''t know how to change this part to use
    less for large dataset'
  created_at: 2022-11-28 12:51:12+00:00
  edited: true
  hidden: false
  id: 6384aec0a179f85600564c7e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3fc636f22aaaf2f7adaa34bdf0a80a93.svg
      fullname: Erfan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: erfankh
      type: user
    createdAt: '2022-11-28T14:48:37.000Z'
    data:
      status: open
    id: 6384ca4516ccd1034bb14f7a
    type: status-change
  author: erfankh
  created_at: 2022-11-28 14:48:37+00:00
  id: 6384ca4516ccd1034bb14f7a
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/35fb904ebae3616c73d76e91a4de0c4d.svg
      fullname: Hartmann
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: j-hartmann
      type: user
    createdAt: '2022-11-29T07:15:51.000Z'
    data:
      edited: false
      editors:
      - j-hartmann
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/35fb904ebae3616c73d76e91a4de0c4d.svg
          fullname: Hartmann
          isHf: false
          isPro: false
          name: j-hartmann
          type: user
        html: '<p>I see. Maybe batch tokenization will work for you? For example,
          see here: <a rel="nofollow" href="https://osmanfatihkilic.medium.com/fine-tuning-huggingface-models-without-overwhelming-your-memory-d33b8a206ae2">https://osmanfatihkilic.medium.com/fine-tuning-huggingface-models-without-overwhelming-your-memory-d33b8a206ae2</a></p>

          '
        raw: 'I see. Maybe batch tokenization will work for you? For example, see
          here: https://osmanfatihkilic.medium.com/fine-tuning-huggingface-models-without-overwhelming-your-memory-d33b8a206ae2'
        updatedAt: '2022-11-29T07:15:51.220Z'
      numEdits: 0
      reactions: []
    id: 6385b1a75ea0bcbedb0e4079
    type: comment
  author: j-hartmann
  content: 'I see. Maybe batch tokenization will work for you? For example, see here:
    https://osmanfatihkilic.medium.com/fine-tuning-huggingface-models-without-overwhelming-your-memory-d33b8a206ae2'
  created_at: 2022-11-29 07:15:51+00:00
  edited: false
  hidden: false
  id: 6385b1a75ea0bcbedb0e4079
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: j-hartmann/emotion-english-distilroberta-base
repo_type: model
status: open
target_branch: null
title: Large Dataset
