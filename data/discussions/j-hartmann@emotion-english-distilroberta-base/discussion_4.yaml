!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ip
conflicting_files: null
created_at: 2022-10-22 08:04:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b0a749fc178e03624f852b68d15255d0.svg
      fullname: Ivan Petrov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ip
      type: user
    createdAt: '2022-10-22T09:04:52.000Z'
    data:
      edited: false
      editors:
      - ip
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b0a749fc178e03624f852b68d15255d0.svg
          fullname: Ivan Petrov
          isHf: false
          isPro: false
          name: ip
          type: user
        html: '<p>Hi, </p>

          <p>I''m playing with this model and noticed that in the sequence "US guys
          what do you think about this piece of shit?" (this is Reddit title) I get
          different result from browser test and from my local machine. this is the
          result:</p>

          <p>Local machine: <code>[    {       "label":"anger",       "score":0.30374875664711    },    {       "label":"disgust",       "score":0.4684724807739258    },    {       "label":"fear",       "score":0.089825838804245    },    {       "label":"joy",       "score":0.002520856214687228    },    {       "label":"neutral",       "score":0.10477810353040695    },    {       "label":"sadness",       "score":0.008448047563433647    },    {       "label":"surprise",       "score":0.02220587059855461    }
          ]</code></p>

          <p>and from browser test:<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1666429389097-62fd16a603f866462206bbdc.png"><img
          alt="Screenshot from 2022-10-22 12-02-35.png" src="https://cdn-uploads.huggingface.co/production/uploads/1666429389097-62fd16a603f866462206bbdc.png"></a></p>

          <p>I''m curious why there is such a discrepancy?</p>

          '
        raw: "Hi, \r\n\r\nI'm playing with this model and noticed that in the sequence\
          \ \"US guys what do you think about this piece of shit?\" (this is Reddit\
          \ title) I get different result from browser test and from my local machine.\
          \ this is the result:\r\n\r\nLocal machine: `[\r\n   {\r\n      \"label\"\
          :\"anger\",\r\n      \"score\":0.30374875664711\r\n   },\r\n   {\r\n   \
          \   \"label\":\"disgust\",\r\n      \"score\":0.4684724807739258\r\n   },\r\
          \n   {\r\n      \"label\":\"fear\",\r\n      \"score\":0.089825838804245\r\
          \n   },\r\n   {\r\n      \"label\":\"joy\",\r\n      \"score\":0.002520856214687228\r\
          \n   },\r\n   {\r\n      \"label\":\"neutral\",\r\n      \"score\":0.10477810353040695\r\
          \n   },\r\n   {\r\n      \"label\":\"sadness\",\r\n      \"score\":0.008448047563433647\r\
          \n   },\r\n   {\r\n      \"label\":\"surprise\",\r\n      \"score\":0.02220587059855461\r\
          \n   }\r\n]`\r\n\r\nand from browser test:\r\n![Screenshot from 2022-10-22\
          \ 12-02-35.png](https://cdn-uploads.huggingface.co/production/uploads/1666429389097-62fd16a603f866462206bbdc.png)\r\
          \n\r\nI'm curious why there is such a discrepancy?\r\n"
        updatedAt: '2022-10-22T09:04:52.421Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - rageSpin
    id: 6353b234b8aa3b0b3eb9178b
    type: comment
  author: ip
  content: "Hi, \r\n\r\nI'm playing with this model and noticed that in the sequence\
    \ \"US guys what do you think about this piece of shit?\" (this is Reddit title)\
    \ I get different result from browser test and from my local machine. this is\
    \ the result:\r\n\r\nLocal machine: `[\r\n   {\r\n      \"label\":\"anger\",\r\
    \n      \"score\":0.30374875664711\r\n   },\r\n   {\r\n      \"label\":\"disgust\"\
    ,\r\n      \"score\":0.4684724807739258\r\n   },\r\n   {\r\n      \"label\":\"\
    fear\",\r\n      \"score\":0.089825838804245\r\n   },\r\n   {\r\n      \"label\"\
    :\"joy\",\r\n      \"score\":0.002520856214687228\r\n   },\r\n   {\r\n      \"\
    label\":\"neutral\",\r\n      \"score\":0.10477810353040695\r\n   },\r\n   {\r\
    \n      \"label\":\"sadness\",\r\n      \"score\":0.008448047563433647\r\n   },\r\
    \n   {\r\n      \"label\":\"surprise\",\r\n      \"score\":0.02220587059855461\r\
    \n   }\r\n]`\r\n\r\nand from browser test:\r\n![Screenshot from 2022-10-22 12-02-35.png](https://cdn-uploads.huggingface.co/production/uploads/1666429389097-62fd16a603f866462206bbdc.png)\r\
    \n\r\nI'm curious why there is such a discrepancy?\r\n"
  created_at: 2022-10-22 08:04:52+00:00
  edited: false
  hidden: false
  id: 6353b234b8aa3b0b3eb9178b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/35fb904ebae3616c73d76e91a4de0c4d.svg
      fullname: Hartmann
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: j-hartmann
      type: user
    createdAt: '2022-10-24T09:55:15.000Z'
    data:
      edited: false
      editors:
      - j-hartmann
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/35fb904ebae3616c73d76e91a4de0c4d.svg
          fullname: Hartmann
          isHf: false
          isPro: false
          name: j-hartmann
          type: user
        html: '<p>Thanks for bringing this up. I''ll have to look into this. On Google
          Colab, I got the same results as on the Model Card (see attached). </p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1666605290021-60743b8b227ff33193711103.png"><img
          alt="Screenshot 2022-10-24 115438.png" src="https://cdn-uploads.huggingface.co/production/uploads/1666605290021-60743b8b227ff33193711103.png"></a></p>

          '
        raw: "Thanks for bringing this up. I'll have to look into this. On Google\
          \ Colab, I got the same results as on the Model Card (see attached). \n\n\
          ![Screenshot 2022-10-24 115438.png](https://cdn-uploads.huggingface.co/production/uploads/1666605290021-60743b8b227ff33193711103.png)"
        updatedAt: '2022-10-24T09:55:15.947Z'
      numEdits: 0
      reactions: []
    id: 635661033df7d65ce8e8c7ec
    type: comment
  author: j-hartmann
  content: "Thanks for bringing this up. I'll have to look into this. On Google Colab,\
    \ I got the same results as on the Model Card (see attached). \n\n![Screenshot\
    \ 2022-10-24 115438.png](https://cdn-uploads.huggingface.co/production/uploads/1666605290021-60743b8b227ff33193711103.png)"
  created_at: 2022-10-24 08:55:15+00:00
  edited: false
  hidden: false
  id: 635661033df7d65ce8e8c7ec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1c37cda35b551b187e2000b9f75a6208.svg
      fullname: Mishra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Alankrit
      type: user
    createdAt: '2022-11-17T17:16:55.000Z'
    data:
      edited: false
      editors:
      - Alankrit
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1c37cda35b551b187e2000b9f75a6208.svg
          fullname: Mishra
          isHf: false
          isPro: false
          name: Alankrit
          type: user
        html: '<p>I am facing the same issue. Also, the pipeline inference is somehow
          slower than the HF model implementation.  Is the model used in hosted inference
          different from the model card?</p>

          '
        raw: I am facing the same issue. Also, the pipeline inference is somehow slower
          than the HF model implementation.  Is the model used in hosted inference
          different from the model card?
        updatedAt: '2022-11-17T17:16:55.209Z'
      numEdits: 0
      reactions: []
    id: 63766c87ace6a1bbf33534a9
    type: comment
  author: Alankrit
  content: I am facing the same issue. Also, the pipeline inference is somehow slower
    than the HF model implementation.  Is the model used in hosted inference different
    from the model card?
  created_at: 2022-11-17 17:16:55+00:00
  edited: false
  hidden: false
  id: 63766c87ace6a1bbf33534a9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: j-hartmann/emotion-english-distilroberta-base
repo_type: model
status: open
target_branch: null
title: Browser test and local test have different result
