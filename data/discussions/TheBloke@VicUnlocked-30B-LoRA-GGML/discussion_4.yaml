!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mancub
conflicting_files: null
created_at: 2023-05-20 18:50:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-05-20T19:50:31.000Z'
    data:
      edited: false
      editors:
      - mancub
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
          fullname: Man Cub
          isHf: false
          isPro: false
          name: mancub
          type: user
        html: '<p>Latest llama.cpp pull and latest download of the model, results
          in an error:</p>

          <p>llama.cpp: loading model from models/thebloke_vicunlocked-30b-lora.ggml.v3.q8_0.bin<br>llama_model_load_internal:
          format     = ggjt v3 (latest)<br>llama_model_load_internal: n_vocab    =
          32000<br>llama_model_load_internal: n_ctx      = 2048<br>llama_model_load_internal:
          n_embd     = 6656<br>llama_model_load_internal: n_mult     = 256<br>llama_model_load_internal:
          n_head     = 52<br>llama_model_load_internal: n_layer    = 60<br>llama_model_load_internal:
          n_rot      = 128<br>llama_model_load_internal: ftype      = 7 (mostly Q8_0)<br>llama_model_load_internal:
          n_ff       = 17920<br>llama_model_load_internal: n_parts    = 1<br>llama_model_load_internal:
          model size = 30B<br>llama_model_load_internal: ggml ctx size =    0.12 MB<br>error
          loading model: llama.cpp: tensor ''layers.55.attention_norm.weight'' is
          missing from model<br>llama_init_from_file: failed to load model<br>llama_init_from_gpt_params:
          error: failed to load model ''models/thebloke_vicunlocked-30b-lora.ggml.v3.q8_0.bin''<br>main:
          error: unable to load model</p>

          '
        raw: "Latest llama.cpp pull and latest download of the model, results in an\
          \ error:\r\n\r\nllama.cpp: loading model from models/thebloke_vicunlocked-30b-lora.ggml.v3.q8_0.bin\r\
          \nllama_model_load_internal: format     = ggjt v3 (latest)\r\nllama_model_load_internal:\
          \ n_vocab    = 32000\r\nllama_model_load_internal: n_ctx      = 2048\r\n\
          llama_model_load_internal: n_embd     = 6656\r\nllama_model_load_internal:\
          \ n_mult     = 256\r\nllama_model_load_internal: n_head     = 52\r\nllama_model_load_internal:\
          \ n_layer    = 60\r\nllama_model_load_internal: n_rot      = 128\r\nllama_model_load_internal:\
          \ ftype      = 7 (mostly Q8_0)\r\nllama_model_load_internal: n_ff      \
          \ = 17920\r\nllama_model_load_internal: n_parts    = 1\r\nllama_model_load_internal:\
          \ model size = 30B\r\nllama_model_load_internal: ggml ctx size =    0.12\
          \ MB\r\nerror loading model: llama.cpp: tensor 'layers.55.attention_norm.weight'\
          \ is missing from model\r\nllama_init_from_file: failed to load model\r\n\
          llama_init_from_gpt_params: error: failed to load model 'models/thebloke_vicunlocked-30b-lora.ggml.v3.q8_0.bin'\r\
          \nmain: error: unable to load model"
        updatedAt: '2023-05-20T19:50:31.945Z'
      numEdits: 0
      reactions: []
    id: 64692487dcbb937d56b807f2
    type: comment
  author: mancub
  content: "Latest llama.cpp pull and latest download of the model, results in an\
    \ error:\r\n\r\nllama.cpp: loading model from models/thebloke_vicunlocked-30b-lora.ggml.v3.q8_0.bin\r\
    \nllama_model_load_internal: format     = ggjt v3 (latest)\r\nllama_model_load_internal:\
    \ n_vocab    = 32000\r\nllama_model_load_internal: n_ctx      = 2048\r\nllama_model_load_internal:\
    \ n_embd     = 6656\r\nllama_model_load_internal: n_mult     = 256\r\nllama_model_load_internal:\
    \ n_head     = 52\r\nllama_model_load_internal: n_layer    = 60\r\nllama_model_load_internal:\
    \ n_rot      = 128\r\nllama_model_load_internal: ftype      = 7 (mostly Q8_0)\r\
    \nllama_model_load_internal: n_ff       = 17920\r\nllama_model_load_internal:\
    \ n_parts    = 1\r\nllama_model_load_internal: model size = 30B\r\nllama_model_load_internal:\
    \ ggml ctx size =    0.12 MB\r\nerror loading model: llama.cpp: tensor 'layers.55.attention_norm.weight'\
    \ is missing from model\r\nllama_init_from_file: failed to load model\r\nllama_init_from_gpt_params:\
    \ error: failed to load model 'models/thebloke_vicunlocked-30b-lora.ggml.v3.q8_0.bin'\r\
    \nmain: error: unable to load model"
  created_at: 2023-05-20 18:50:31+00:00
  edited: false
  hidden: false
  id: 64692487dcbb937d56b807f2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-20T20:40:24.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Sorry, it looks like the q8_0 file didn''t upload properly.  I will
          fix that now. Will likely take an hour or so.</p>

          '
        raw: Sorry, it looks like the q8_0 file didn't upload properly.  I will fix
          that now. Will likely take an hour or so.
        updatedAt: '2023-05-20T20:40:24.708Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Hanssep123
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mancub
    id: 6469303897ffc33d43cd6478
    type: comment
  author: TheBloke
  content: Sorry, it looks like the q8_0 file didn't upload properly.  I will fix
    that now. Will likely take an hour or so.
  created_at: 2023-05-20 19:40:24+00:00
  edited: false
  hidden: false
  id: 6469303897ffc33d43cd6478
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-20T22:55:45.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>New q8_0 file is now uploaded, apologies for the delay.</p>

          '
        raw: New q8_0 file is now uploaded, apologies for the delay.
        updatedAt: '2023-05-20T22:55:45.131Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - hidelord
        - mancub
        - Hanssep123
    id: 64694ff17407ab1cff3bdf63
    type: comment
  author: TheBloke
  content: New q8_0 file is now uploaded, apologies for the delay.
  created_at: 2023-05-20 21:55:45+00:00
  edited: false
  hidden: false
  id: 64694ff17407ab1cff3bdf63
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-05-21T00:18:53.000Z'
    data:
      edited: false
      editors:
      - mancub
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
          fullname: Man Cub
          isHf: false
          isPro: false
          name: mancub
          type: user
        html: '<blockquote>

          <p>New q8_0 file is now uploaded, apologies for the delay.</p>

          </blockquote>

          <p>No need to apologize. We work on your time here - whenever you are ready.</p>

          <p>Downloading the new file now but still got 1 hr to go.</p>

          '
        raw: '> New q8_0 file is now uploaded, apologies for the delay.


          No need to apologize. We work on your time here - whenever you are ready.


          Downloading the new file now but still got 1 hr to go.'
        updatedAt: '2023-05-21T00:18:53.086Z'
      numEdits: 0
      reactions: []
    id: 6469636d99182de178519289
    type: comment
  author: mancub
  content: '> New q8_0 file is now uploaded, apologies for the delay.


    No need to apologize. We work on your time here - whenever you are ready.


    Downloading the new file now but still got 1 hr to go.'
  created_at: 2023-05-20 23:18:53+00:00
  edited: false
  hidden: false
  id: 6469636d99182de178519289
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-05-21T01:32:56.000Z'
    data:
      edited: false
      editors:
      - mancub
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
          fullname: Man Cub
          isHf: false
          isPro: false
          name: mancub
          type: user
        html: '<p>It''s working now, but slower than the other models. I was able
          to squeeze 41 out of 60 layers into my 3090 from the q8_0 model. :)</p>

          <p>Weirdly enough I got a "USER: continue" from it mid-sentence while it
          was writing the response. Then it backed off, repeated the last sentence
          where it stopped, and carried on.</p>

          <p>llama_print_timings:        load time = 18930.83 ms<br>llama_print_timings:      sample
          time =   425.43 ms /   687 runs   (    0.62 ms per token)<br>llama_print_timings:
          prompt eval time =  2841.70 ms /    24 tokens (  118.40 ms per token)<br>llama_print_timings:        eval
          time = 277954.03 ms /   686 runs   (  405.18 ms per token)<br>llama_print_timings:       total
          time = 297548.04 ms</p>

          <p>Going to try a more quantized version next. Although based on my testing
          of the Manticore model, it appears that q8_0 is faster than q5_1. So maybe
          I''ll try q5_0 instead as most of the layers might fit into the 3090.</p>

          '
        raw: 'It''s working now, but slower than the other models. I was able to squeeze
          41 out of 60 layers into my 3090 from the q8_0 model. :)


          Weirdly enough I got a "USER: continue" from it mid-sentence while it was
          writing the response. Then it backed off, repeated the last sentence where
          it stopped, and carried on.


          llama_print_timings:        load time = 18930.83 ms

          llama_print_timings:      sample time =   425.43 ms /   687 runs   (    0.62
          ms per token)

          llama_print_timings: prompt eval time =  2841.70 ms /    24 tokens (  118.40
          ms per token)

          llama_print_timings:        eval time = 277954.03 ms /   686 runs   (  405.18
          ms per token)

          llama_print_timings:       total time = 297548.04 ms


          Going to try a more quantized version next. Although based on my testing
          of the Manticore model, it appears that q8_0 is faster than q5_1. So maybe
          I''ll try q5_0 instead as most of the layers might fit into the 3090.'
        updatedAt: '2023-05-21T01:32:56.874Z'
      numEdits: 0
      reactions: []
    id: 646974c897ffc33d43d0d0e3
    type: comment
  author: mancub
  content: 'It''s working now, but slower than the other models. I was able to squeeze
    41 out of 60 layers into my 3090 from the q8_0 model. :)


    Weirdly enough I got a "USER: continue" from it mid-sentence while it was writing
    the response. Then it backed off, repeated the last sentence where it stopped,
    and carried on.


    llama_print_timings:        load time = 18930.83 ms

    llama_print_timings:      sample time =   425.43 ms /   687 runs   (    0.62 ms
    per token)

    llama_print_timings: prompt eval time =  2841.70 ms /    24 tokens (  118.40 ms
    per token)

    llama_print_timings:        eval time = 277954.03 ms /   686 runs   (  405.18
    ms per token)

    llama_print_timings:       total time = 297548.04 ms


    Going to try a more quantized version next. Although based on my testing of the
    Manticore model, it appears that q8_0 is faster than q5_1. So maybe I''ll try
    q5_0 instead as most of the layers might fit into the 3090.'
  created_at: 2023-05-21 00:32:56+00:00
  edited: false
  hidden: false
  id: 646974c897ffc33d43d0d0e3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-05-21T01:46:59.000Z'
    data:
      edited: false
      editors:
      - mancub
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
          fullname: Man Cub
          isHf: false
          isPro: false
          name: mancub
          type: user
        html: '<p>This models also does not want to stop rambling. Even in the instruction
          mode, it completes the response and then it gives itself another instruction,
          similar to the original one, and just keeps going.</p>

          <p>I guess it''s like Grandpa Simpson, minus the narcolepsy, LOL.</p>

          '
        raw: 'This models also does not want to stop rambling. Even in the instruction
          mode, it completes the response and then it gives itself another instruction,
          similar to the original one, and just keeps going.


          I guess it''s like Grandpa Simpson, minus the narcolepsy, LOL.'
        updatedAt: '2023-05-21T01:46:59.064Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mirek190
    id: 6469781397ffc33d43d0f7c3
    type: comment
  author: mancub
  content: 'This models also does not want to stop rambling. Even in the instruction
    mode, it completes the response and then it gives itself another instruction,
    similar to the original one, and just keeps going.


    I guess it''s like Grandpa Simpson, minus the narcolepsy, LOL.'
  created_at: 2023-05-21 00:46:59+00:00
  edited: false
  hidden: false
  id: 6469781397ffc33d43d0f7c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-21T09:05:20.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah a lot of people are reporting the auto-continue/rambling issue
          with Manticore. The model''s creator is looking at it, but is not yet sure
          why it''s happening.</p>

          <p>I know from my own experience that it doesn''t happen with the INSTRUCT
          / RESPONSE template, eg when I tested 10 or so single prompts like this,
          I never got the issue:</p>

          <pre><code>-p "###Instruction: Write an essay comparing France and Germany\n###
          Response:

          -p "###Instruction: what is pythagorus theorem? Give some examples\n###
          Response:"

          -p "###Instruction: explain in detail the differences between C, C++ and
          Objective C\n### Response:"

          </code></pre>

          '
        raw: 'Yeah a lot of people are reporting the auto-continue/rambling issue
          with Manticore. The model''s creator is looking at it, but is not yet sure
          why it''s happening.


          I know from my own experience that it doesn''t happen with the INSTRUCT
          / RESPONSE template, eg when I tested 10 or so single prompts like this,
          I never got the issue:

          ```

          -p "###Instruction: Write an essay comparing France and Germany\n### Response:

          -p "###Instruction: what is pythagorus theorem? Give some examples\n###
          Response:"

          -p "###Instruction: explain in detail the differences between C, C++ and
          Objective C\n### Response:"

          ```'
        updatedAt: '2023-05-21T09:05:20.432Z'
      numEdits: 0
      reactions: []
    id: 6469ded096cfe72aef74db4e
    type: comment
  author: TheBloke
  content: 'Yeah a lot of people are reporting the auto-continue/rambling issue with
    Manticore. The model''s creator is looking at it, but is not yet sure why it''s
    happening.


    I know from my own experience that it doesn''t happen with the INSTRUCT / RESPONSE
    template, eg when I tested 10 or so single prompts like this, I never got the
    issue:

    ```

    -p "###Instruction: Write an essay comparing France and Germany\n### Response:

    -p "###Instruction: what is pythagorus theorem? Give some examples\n### Response:"

    -p "###Instruction: explain in detail the differences between C, C++ and Objective
    C\n### Response:"

    ```'
  created_at: 2023-05-21 08:05:20+00:00
  edited: false
  hidden: false
  id: 6469ded096cfe72aef74db4e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-05-21T14:17:15.000Z'
    data:
      edited: false
      editors:
      - mancub
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
          fullname: Man Cub
          isHf: false
          isPro: false
          name: mancub
          type: user
        html: '<p>I''m talking about VicUnlocked though, not Manticore. I asked it
          to write me a story about llamas (the generic instruction) and it went to
          write several more before I CTRL-C-ed out of it.</p>

          '
        raw: I'm talking about VicUnlocked though, not Manticore. I asked it to write
          me a story about llamas (the generic instruction) and it went to write several
          more before I CTRL-C-ed out of it.
        updatedAt: '2023-05-21T14:17:15.897Z'
      numEdits: 0
      reactions: []
    id: 646a27eb13396ee0a563bfb0
    type: comment
  author: mancub
  content: I'm talking about VicUnlocked though, not Manticore. I asked it to write
    me a story about llamas (the generic instruction) and it went to write several
    more before I CTRL-C-ed out of it.
  created_at: 2023-05-21 13:17:15+00:00
  edited: false
  hidden: false
  id: 646a27eb13396ee0a563bfb0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-21T14:27:21.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Oh right yeah! Getting confused between all the models.</p>

          <p>I never really tested this model so can''t say if that''s usual or not.  According
          to the original model card, it''s a Vicuna that''s been converted to "more
          like Alpaca style", using "<strong>some</strong> of Vicuna 1.1"</p>

          <p>Vicuna 1.0 was very strict with prompt template. You had to use this
          format else it wouldn''t reply at all or would run on and on:</p>

          <pre><code>### Human: Write a story about llamas

          ### Assistant:

          </code></pre>

          <p>Maybe because this is a conversion from Vicuna to Alpaca, some of that
          issue is not fixed?  Are you using Alpaca template at the moment?  Have
          you tried Vicuna template like above?</p>

          '
        raw: 'Oh right yeah! Getting confused between all the models.


          I never really tested this model so can''t say if that''s usual or not.  According
          to the original model card, it''s a Vicuna that''s been converted to "more
          like Alpaca style", using "**some** of Vicuna 1.1"


          Vicuna 1.0 was very strict with prompt template. You had to use this format
          else it wouldn''t reply at all or would run on and on:

          ```

          ### Human: Write a story about llamas

          ### Assistant:

          ```


          Maybe because this is a conversion from Vicuna to Alpaca, some of that issue
          is not fixed?  Are you using Alpaca template at the moment?  Have you tried
          Vicuna template like above?'
        updatedAt: '2023-05-21T14:27:21.217Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - mancub
        - mirek190
    id: 646a2a493721aab2edf3d006
    type: comment
  author: TheBloke
  content: 'Oh right yeah! Getting confused between all the models.


    I never really tested this model so can''t say if that''s usual or not.  According
    to the original model card, it''s a Vicuna that''s been converted to "more like
    Alpaca style", using "**some** of Vicuna 1.1"


    Vicuna 1.0 was very strict with prompt template. You had to use this format else
    it wouldn''t reply at all or would run on and on:

    ```

    ### Human: Write a story about llamas

    ### Assistant:

    ```


    Maybe because this is a conversion from Vicuna to Alpaca, some of that issue is
    not fixed?  Are you using Alpaca template at the moment?  Have you tried Vicuna
    template like above?'
  created_at: 2023-05-21 13:27:21+00:00
  edited: false
  hidden: false
  id: 646a2a493721aab2edf3d006
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-05-22T00:15:54.000Z'
    data:
      edited: false
      editors:
      - mancub
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
          fullname: Man Cub
          isHf: false
          isPro: false
          name: mancub
          type: user
        html: '<p>That did it ! Should''ve paid more attention to what was derived
          from where. :)</p>

          <p>There are so many models now, and with all these small nuances about
          their use, it''s hard to keep track of everything.</p>

          '
        raw: 'That did it ! Should''ve paid more attention to what was derived from
          where. :)


          There are so many models now, and with all these small nuances about their
          use, it''s hard to keep track of everything.'
        updatedAt: '2023-05-22T00:15:54.359Z'
      numEdits: 0
      reactions: []
    id: 646ab43a13396ee0a56ba253
    type: comment
  author: mancub
  content: 'That did it ! Should''ve paid more attention to what was derived from
    where. :)


    There are so many models now, and with all these small nuances about their use,
    it''s hard to keep track of everything.'
  created_at: 2023-05-21 23:15:54+00:00
  edited: false
  hidden: false
  id: 646ab43a13396ee0a56ba253
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/VicUnlocked-30B-LoRA-GGML
repo_type: model
status: open
target_branch: null
title: Error loading the model - missing tensor weight?
