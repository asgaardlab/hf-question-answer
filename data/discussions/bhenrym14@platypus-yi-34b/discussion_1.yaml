!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Yhyu13
conflicting_files: null
created_at: 2023-11-23 11:10:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-11-23T11:10:16.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9523798227310181
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<p>Hi,</p>

          <p>Which framework that you for fine-tuning? I was trying to adapt ToolBench
          (<a rel="nofollow" href="https://github.com/OpenBMB/ToolBench">https://github.com/OpenBMB/ToolBench</a>),
          a function calling dataset to the Yi series, </p>

          <p>But the source code works for LLaMA2 but not for Yi seris, the train
          loss was 0.0 and eval loss being NaN. </p>

          <p>I am looking for a working/stable QLoRA framework for open source LLMs
          where users simply need to bring their models and curated datasets.</p>

          <p>Thanks!</p>

          '
        raw: "Hi,\r\n\r\nWhich framework that you for fine-tuning? I was trying to\
          \ adapt ToolBench (https://github.com/OpenBMB/ToolBench), a function calling\
          \ dataset to the Yi series, \r\n\r\nBut the source code works for LLaMA2\
          \ but not for Yi seris, the train loss was 0.0 and eval loss being NaN.\
          \ \r\n\r\nI am looking for a working/stable QLoRA framework for open source\
          \ LLMs where users simply need to bring their models and curated datasets.\r\
          \n\r\nThanks!"
        updatedAt: '2023-11-23T11:10:16.263Z'
      numEdits: 0
      reactions: []
    id: 655f33189148649cbc0e1fcc
    type: comment
  author: Yhyu13
  content: "Hi,\r\n\r\nWhich framework that you for fine-tuning? I was trying to adapt\
    \ ToolBench (https://github.com/OpenBMB/ToolBench), a function calling dataset\
    \ to the Yi series, \r\n\r\nBut the source code works for LLaMA2 but not for Yi\
    \ seris, the train loss was 0.0 and eval loss being NaN. \r\n\r\nI am looking\
    \ for a working/stable QLoRA framework for open source LLMs where users simply\
    \ need to bring their models and curated datasets.\r\n\r\nThanks!"
  created_at: 2023-11-23 11:10:16+00:00
  edited: false
  hidden: false
  id: 655f33189148649cbc0e1fcc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d7b0073571f4ff7901d38f38258c365d.svg
      fullname: Brandon
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: bhenrym14
      type: user
    createdAt: '2023-11-23T16:14:38.000Z'
    data:
      edited: false
      editors:
      - bhenrym14
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9451553821563721
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d7b0073571f4ff7901d38f38258c365d.svg
          fullname: Brandon
          isHf: false
          isPro: false
          name: bhenrym14
          type: user
        html: '<p>I use an a version of the original qlora training script that I''ve
          adapted over time; it''s rather hacked together at this point, but it works.
          This model, however, uses Yi-34b as adapted to the LLama2 architecture (<a
          href="https://huggingface.co/chargoddard/Yi-34B-Llama">https://huggingface.co/chargoddard/Yi-34B-Llama</a>),
          so in principle you should be able to get ToolBench to work if it does for
          other llama2 models (though I have no experience with ToolBench). Note that
          I use the model from the llama-tokenizer branch of that model repo to also
          remove any dependency on the Yi tokenizer definition. I haven''t tried training
          native Yi with the custom model and/or tokenizer definitions.</p>

          '
        raw: I use an a version of the original qlora training script that I've adapted
          over time; it's rather hacked together at this point, but it works. This
          model, however, uses Yi-34b as adapted to the LLama2 architecture (https://huggingface.co/chargoddard/Yi-34B-Llama),
          so in principle you should be able to get ToolBench to work if it does for
          other llama2 models (though I have no experience with ToolBench). Note that
          I use the model from the llama-tokenizer branch of that model repo to also
          remove any dependency on the Yi tokenizer definition. I haven't tried training
          native Yi with the custom model and/or tokenizer definitions.
        updatedAt: '2023-11-23T16:14:38.823Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Yhyu13
    id: 655f7a6ea3e81145769c9d5e
    type: comment
  author: bhenrym14
  content: I use an a version of the original qlora training script that I've adapted
    over time; it's rather hacked together at this point, but it works. This model,
    however, uses Yi-34b as adapted to the LLama2 architecture (https://huggingface.co/chargoddard/Yi-34B-Llama),
    so in principle you should be able to get ToolBench to work if it does for other
    llama2 models (though I have no experience with ToolBench). Note that I use the
    model from the llama-tokenizer branch of that model repo to also remove any dependency
    on the Yi tokenizer definition. I haven't tried training native Yi with the custom
    model and/or tokenizer definitions.
  created_at: 2023-11-23 16:14:38+00:00
  edited: false
  hidden: false
  id: 655f7a6ea3e81145769c9d5e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/d7b0073571f4ff7901d38f38258c365d.svg
      fullname: Brandon
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: bhenrym14
      type: user
    createdAt: '2023-12-01T20:10:09.000Z'
    data:
      status: closed
    id: 656a3da18556299698738bd5
    type: status-change
  author: bhenrym14
  created_at: 2023-12-01 20:10:09+00:00
  id: 656a3da18556299698738bd5
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: bhenrym14/platypus-yi-34b
repo_type: model
status: closed
target_branch: null
title: Fine-tuning framework?
