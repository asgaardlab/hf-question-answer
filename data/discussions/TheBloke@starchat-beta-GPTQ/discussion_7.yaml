!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ranguna
conflicting_files: null
created_at: 2023-07-08 23:12:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2ef4e0707e32d9ade0508c8fd37fa449.svg
      fullname: ranguna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ranguna
      type: user
    createdAt: '2023-07-09T00:12:43.000Z'
    data:
      edited: false
      editors:
      - ranguna
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4576568305492401
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2ef4e0707e32d9ade0508c8fd37fa449.svg
          fullname: ranguna
          isHf: false
          isPro: false
          name: ranguna
          type: user
        html: "<p>When loading this model through web text generation webui, I'm getting\
          \ the following error:</p>\n<pre><code>2023-07-09 00:52:17 ERROR:Failed\
          \ to load the model.\nTraceback (most recent call last):\n  File \"$HOME/projects/ai/text-generation-webui/server.py\"\
          , line 68, in load_model_wrapper\n    shared.model, shared.tokenizer = load_model(shared.model_name,\
          \ loader)\n  File \"$HOME/projects/ai/text-generation-webui/modules/models.py\"\
          , line 87, in load_model\n    tokenizer = load_tokenizer(model_name, model)\n\
          \  File \"$HOME/projects/ai/text-generation-webui/modules/models.py\", line\
          \ 104, in load_tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\n\
          \  File \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 691, in from_pretrained\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\n  File \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1825, in from_pretrained\n    return cls._from_pretrained(\n  File\
          \ \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1989, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \  File \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/gpt2/tokenization_gpt2.py\"\
          , line 195, in __init__\n    with open(merges_file, encoding=\"utf-8\")\
          \ as merges_handle:\nTypeError: expected str, bytes or os.PathLike object,\
          \ not NoneType\n</code></pre>\n<p>Logging call arguments passed to <code>tokenization_utils_base.py</code>,\
          \ we can see that the merges file is indeed missing:</p>\n<pre><code>{'add_prefix_space':\
          \ False, 'additional_special_tokens': ['&lt;|endoftext|&gt;', '&lt;fim_prefix&gt;',\
          \ '&lt;fim_middle&gt;', '&lt;fim_suffix&gt;', '&lt;fim_pad&gt;', '&lt;filename&gt;',\
          \ '&lt;gh_stars&gt;', '&lt;issue_start&gt;', '&lt;issue_comment&gt;', '&lt;issue_closed&gt;',\
          \ '&lt;jupyter_start&gt;', '&lt;jupyter_text&gt;', '&lt;jupyter_code&gt;',\
          \ '&lt;jupyter_output&gt;', '&lt;empty_output&gt;', '&lt;commit_before&gt;',\
          \ '&lt;commit_msg&gt;', '&lt;commit_after&gt;', '&lt;reponame&gt;'], 'bos_token':\
          \ '&lt;|endoftext|&gt;', 'clean_up_tokenization_spaces': True, 'eos_token':\
          \ '&lt;|endoftext|&gt;', 'model_max_length': 1000000000000000019884624838656,\
          \ 'unk_token': '&lt;|endoftext|&gt;', 'vocab_size': 49152, 'vocab_file':\
          \ 'models/TheBloke_starchat-beta-GPTQ/vocab.json', 'merges_file': None,\
          \ 'special_tokens_map_file': 'models/TheBloke_starchat-beta-GPTQ/special_tokens_map.json',\
          \ 'name_or_path': 'models/TheBloke_starchat-beta-GPTQ'}\n</code></pre>\n\
          <p>Is this file missing from this model or is this something with my local\
          \ setup ?</p>\n"
        raw: "When loading this model through web text generation webui, I'm getting\
          \ the following error:\r\n\r\n```\r\n2023-07-09 00:52:17 ERROR:Failed to\
          \ load the model.\r\nTraceback (most recent call last):\r\n  File \"$HOME/projects/ai/text-generation-webui/server.py\"\
          , line 68, in load_model_wrapper\r\n    shared.model, shared.tokenizer =\
          \ load_model(shared.model_name, loader)\r\n  File \"$HOME/projects/ai/text-generation-webui/modules/models.py\"\
          , line 87, in load_model\r\n    tokenizer = load_tokenizer(model_name, model)\r\
          \n  File \"$HOME/projects/ai/text-generation-webui/modules/models.py\",\
          \ line 104, in load_tokenizer\r\n    tokenizer = AutoTokenizer.from_pretrained(\r\
          \n  File \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 691, in from_pretrained\r\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\r\n  File \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1825, in from_pretrained\r\n    return cls._from_pretrained(\r\n\
          \  File \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 1989, in _from_pretrained\r\n    tokenizer = cls(*init_inputs, **init_kwargs)\r\
          \n  File \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/gpt2/tokenization_gpt2.py\"\
          , line 195, in __init__\r\n    with open(merges_file, encoding=\"utf-8\"\
          ) as merges_handle:\r\nTypeError: expected str, bytes or os.PathLike object,\
          \ not NoneType\r\n```\r\n\r\nLogging call arguments passed to `tokenization_utils_base.py`,\
          \ we can see that the merges file is indeed missing:\r\n\r\n```\r\n{'add_prefix_space':\
          \ False, 'additional_special_tokens': ['<|endoftext|>', '<fim_prefix>',\
          \ '<fim_middle>', '<fim_suffix>', '<fim_pad>', '<filename>', '<gh_stars>',\
          \ '<issue_start>', '<issue_comment>', '<issue_closed>', '<jupyter_start>',\
          \ '<jupyter_text>', '<jupyter_code>', '<jupyter_output>', '<empty_output>',\
          \ '<commit_before>', '<commit_msg>', '<commit_after>', '<reponame>'], 'bos_token':\
          \ '<|endoftext|>', 'clean_up_tokenization_spaces': True, 'eos_token': '<|endoftext|>',\
          \ 'model_max_length': 1000000000000000019884624838656, 'unk_token': '<|endoftext|>',\
          \ 'vocab_size': 49152, 'vocab_file': 'models/TheBloke_starchat-beta-GPTQ/vocab.json',\
          \ 'merges_file': None, 'special_tokens_map_file': 'models/TheBloke_starchat-beta-GPTQ/special_tokens_map.json',\
          \ 'name_or_path': 'models/TheBloke_starchat-beta-GPTQ'}\r\n```\r\n\r\nIs\
          \ this file missing from this model or is this something with my local setup\
          \ ?"
        updatedAt: '2023-07-09T00:12:43.453Z'
      numEdits: 0
      reactions: []
    id: 64a9fb7beb47b35522adebcf
    type: comment
  author: ranguna
  content: "When loading this model through web text generation webui, I'm getting\
    \ the following error:\r\n\r\n```\r\n2023-07-09 00:52:17 ERROR:Failed to load\
    \ the model.\r\nTraceback (most recent call last):\r\n  File \"$HOME/projects/ai/text-generation-webui/server.py\"\
    , line 68, in load_model_wrapper\r\n    shared.model, shared.tokenizer = load_model(shared.model_name,\
    \ loader)\r\n  File \"$HOME/projects/ai/text-generation-webui/modules/models.py\"\
    , line 87, in load_model\r\n    tokenizer = load_tokenizer(model_name, model)\r\
    \n  File \"$HOME/projects/ai/text-generation-webui/modules/models.py\", line 104,\
    \ in load_tokenizer\r\n    tokenizer = AutoTokenizer.from_pretrained(\r\n  File\
    \ \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\"\
    , line 691, in from_pretrained\r\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\r\n  File \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1825, in from_pretrained\r\n    return cls._from_pretrained(\r\n  File\
    \ \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 1989, in _from_pretrained\r\n    tokenizer = cls(*init_inputs, **init_kwargs)\r\
    \n  File \"$HOME/.miniconda3/envs/textgen/lib/python3.10/site-packages/transformers/models/gpt2/tokenization_gpt2.py\"\
    , line 195, in __init__\r\n    with open(merges_file, encoding=\"utf-8\") as merges_handle:\r\
    \nTypeError: expected str, bytes or os.PathLike object, not NoneType\r\n```\r\n\
    \r\nLogging call arguments passed to `tokenization_utils_base.py`, we can see\
    \ that the merges file is indeed missing:\r\n\r\n```\r\n{'add_prefix_space': False,\
    \ 'additional_special_tokens': ['<|endoftext|>', '<fim_prefix>', '<fim_middle>',\
    \ '<fim_suffix>', '<fim_pad>', '<filename>', '<gh_stars>', '<issue_start>', '<issue_comment>',\
    \ '<issue_closed>', '<jupyter_start>', '<jupyter_text>', '<jupyter_code>', '<jupyter_output>',\
    \ '<empty_output>', '<commit_before>', '<commit_msg>', '<commit_after>', '<reponame>'],\
    \ 'bos_token': '<|endoftext|>', 'clean_up_tokenization_spaces': True, 'eos_token':\
    \ '<|endoftext|>', 'model_max_length': 1000000000000000019884624838656, 'unk_token':\
    \ '<|endoftext|>', 'vocab_size': 49152, 'vocab_file': 'models/TheBloke_starchat-beta-GPTQ/vocab.json',\
    \ 'merges_file': None, 'special_tokens_map_file': 'models/TheBloke_starchat-beta-GPTQ/special_tokens_map.json',\
    \ 'name_or_path': 'models/TheBloke_starchat-beta-GPTQ'}\r\n```\r\n\r\nIs this\
    \ file missing from this model or is this something with my local setup ?"
  created_at: 2023-07-08 23:12:43+00:00
  edited: false
  hidden: false
  id: 64a9fb7beb47b35522adebcf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-09T08:18:49.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9889975190162659
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Sorry that was my fault. merges.txt is uploaded now. Trigger another
          download of the repo and it will download the missing file and then it should
          work</p>

          '
        raw: Sorry that was my fault. merges.txt is uploaded now. Trigger another
          download of the repo and it will download the missing file and then it should
          work
        updatedAt: '2023-07-09T08:18:49.042Z'
      numEdits: 0
      reactions: []
    id: 64aa6d6931a43d726516df49
    type: comment
  author: TheBloke
  content: Sorry that was my fault. merges.txt is uploaded now. Trigger another download
    of the repo and it will download the missing file and then it should work
  created_at: 2023-07-09 07:18:49+00:00
  edited: false
  hidden: false
  id: 64aa6d6931a43d726516df49
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2ef4e0707e32d9ade0508c8fd37fa449.svg
      fullname: ranguna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ranguna
      type: user
    createdAt: '2023-07-09T22:12:08.000Z'
    data:
      edited: false
      editors:
      - ranguna
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9425427913665771
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2ef4e0707e32d9ade0508c8fd37fa449.svg
          fullname: ranguna
          isHf: false
          isPro: false
          name: ranguna
          type: user
        html: '<p>No worries</p>

          <p>It''s working perfectly now, thanks for the awesome work!</p>

          <p>Btw, it seems the merges.txt file is also missing in this model: <a href="https://huggingface.co/TheBloke/starcoderplus-GPTQ">https://huggingface.co/TheBloke/starcoderplus-GPTQ</a></p>

          <p>Would you like me to open a discussion there ?</p>

          '
        raw: 'No worries


          It''s working perfectly now, thanks for the awesome work!


          Btw, it seems the merges.txt file is also missing in this model: https://huggingface.co/TheBloke/starcoderplus-GPTQ


          Would you like me to open a discussion there ?'
        updatedAt: '2023-07-09T22:12:08.694Z'
      numEdits: 0
      reactions: []
    id: 64ab30b8e83137142418fe95
    type: comment
  author: ranguna
  content: 'No worries


    It''s working perfectly now, thanks for the awesome work!


    Btw, it seems the merges.txt file is also missing in this model: https://huggingface.co/TheBloke/starcoderplus-GPTQ


    Would you like me to open a discussion there ?'
  created_at: 2023-07-09 21:12:08+00:00
  edited: false
  hidden: false
  id: 64ab30b8e83137142418fe95
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-09T22:13:58.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9841551184654236
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>OK thanks, that''s fixed now too.</p>

          '
        raw: OK thanks, that's fixed now too.
        updatedAt: '2023-07-09T22:13:58.497Z'
      numEdits: 0
      reactions: []
    id: 64ab3126e04e7f92247a220a
    type: comment
  author: TheBloke
  content: OK thanks, that's fixed now too.
  created_at: 2023-07-09 21:13:58+00:00
  edited: false
  hidden: false
  id: 64ab3126e04e7f92247a220a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2ef4e0707e32d9ade0508c8fd37fa449.svg
      fullname: ranguna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ranguna
      type: user
    createdAt: '2023-07-09T22:15:52.000Z'
    data:
      edited: false
      editors:
      - ranguna
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9378223419189453
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2ef4e0707e32d9ade0508c8fd37fa449.svg
          fullname: ranguna
          isHf: false
          isPro: false
          name: ranguna
          type: user
        html: '<p>Amazing. Thanks again!</p>

          '
        raw: Amazing. Thanks again!
        updatedAt: '2023-07-09T22:15:52.445Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64ab3198589212026b7b04ca
    id: 64ab3198589212026b7b04c9
    type: comment
  author: ranguna
  content: Amazing. Thanks again!
  created_at: 2023-07-09 21:15:52+00:00
  edited: false
  hidden: false
  id: 64ab3198589212026b7b04c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/2ef4e0707e32d9ade0508c8fd37fa449.svg
      fullname: ranguna
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ranguna
      type: user
    createdAt: '2023-07-09T22:15:52.000Z'
    data:
      status: closed
    id: 64ab3198589212026b7b04ca
    type: status-change
  author: ranguna
  created_at: 2023-07-09 21:15:52+00:00
  id: 64ab3198589212026b7b04ca
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: TheBloke/starchat-beta-GPTQ
repo_type: model
status: closed
target_branch: null
title: No merges.txt file with text generation webui
