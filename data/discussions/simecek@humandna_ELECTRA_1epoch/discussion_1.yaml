!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hellopbc
conflicting_files: null
created_at: 2022-08-05 12:20:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2ee88d01f4a4c586cd4243b3c02cf281.svg
      fullname: Binchao Peng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hellopbc
      type: user
    createdAt: '2022-08-05T13:20:12.000Z'
    data:
      edited: false
      editors:
      - hellopbc
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2ee88d01f4a4c586cd4243b3c02cf281.svg
          fullname: Binchao Peng
          isHf: false
          isPro: false
          name: hellopbc
          type: user
        html: "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span>\
          \ transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer,\
          \ AutoModelForMaskedLM\n\nmodel_name = <span class=\"hljs-string\">'pre-model/'</span>\
          \ + <span class=\"hljs-string\">'electra/'</span> + <span class=\"hljs-string\"\
          >'humandna_ELECTRA_1epoch'</span>\ntokenizer = AutoTokenizer.from_pretrained(<span\
          \ class=\"hljs-string\">\"simecek/humandna_ELECTRA_1epoch\"</span>)\n\n\
          model = AutoModelForMaskedLM.from_pretrained(<span class=\"hljs-string\"\
          >\"simecek/humandna_ELECTRA_1epoch\"</span>)\nx = [<span class=\"hljs-string\"\
          >\"ATGCAT GACTGT ACGTAA\"</span>, <span class=\"hljs-string\">\"ATGCAT GACTGT\
          \ GATTAG\"</span>, <span class=\"hljs-string\">\"ATTCAT GACTGT TGAAGA\"\
          </span>]\nencoded_inputs = tokenizer(x, return_tensors=<span class=\"hljs-string\"\
          >'pt'</span>)\n<span class=\"hljs-keyword\">for</span> item <span class=\"\
          hljs-keyword\">in</span> encoded_inputs[<span class=\"hljs-string\">'input_ids'</span>]:\n\
          \    decoder = tokenizer.decode(item)\n    <span class=\"hljs-built_in\"\
          >print</span>(decoder)\nX_enpr_tensor = model(**encoded_inputs)\n\n<span\
          \ class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"X_enpr_tensor:\"\
          </span>, X_enpr_tensor.shape[<span class=\"hljs-number\">0</span>])  <span\
          \ class=\"hljs-comment\"># (3, 5, 4041)</span>\n</code></pre>\n<p>4041 is\
          \ the <code>vocab_size</code>, and the <code>hidden_size</code> is 256,\
          \ so the right dimension of output is (3, 5, 256)</p>\n"
        raw: "```python\r\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\r\
          \n\r\nmodel_name = 'pre-model/' + 'electra/' + 'humandna_ELECTRA_1epoch'\r\
          \ntokenizer = AutoTokenizer.from_pretrained(\"simecek/humandna_ELECTRA_1epoch\"\
          )\r\n\r\nmodel = AutoModelForMaskedLM.from_pretrained(\"simecek/humandna_ELECTRA_1epoch\"\
          )\r\nx = [\"ATGCAT GACTGT ACGTAA\", \"ATGCAT GACTGT GATTAG\", \"ATTCAT GACTGT\
          \ TGAAGA\"]\r\nencoded_inputs = tokenizer(x, return_tensors='pt')\r\nfor\
          \ item in encoded_inputs['input_ids']:\r\n    decoder = tokenizer.decode(item)\r\
          \n    print(decoder)\r\nX_enpr_tensor = model(**encoded_inputs)\r\n\r\n\
          print(\"X_enpr_tensor:\", X_enpr_tensor.shape[0])  # (3, 5, 4041)\r\n```\r\
          \n4041 is the `vocab_size`, and the `hidden_size` is 256, so the right dimension\
          \ of output is (3, 5, 256)"
        updatedAt: '2022-08-05T13:20:12.588Z'
      numEdits: 0
      reactions: []
    id: 62ed190c9b538d02b450879f
    type: comment
  author: hellopbc
  content: "```python\r\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\r\
    \n\r\nmodel_name = 'pre-model/' + 'electra/' + 'humandna_ELECTRA_1epoch'\r\ntokenizer\
    \ = AutoTokenizer.from_pretrained(\"simecek/humandna_ELECTRA_1epoch\")\r\n\r\n\
    model = AutoModelForMaskedLM.from_pretrained(\"simecek/humandna_ELECTRA_1epoch\"\
    )\r\nx = [\"ATGCAT GACTGT ACGTAA\", \"ATGCAT GACTGT GATTAG\", \"ATTCAT GACTGT\
    \ TGAAGA\"]\r\nencoded_inputs = tokenizer(x, return_tensors='pt')\r\nfor item\
    \ in encoded_inputs['input_ids']:\r\n    decoder = tokenizer.decode(item)\r\n\
    \    print(decoder)\r\nX_enpr_tensor = model(**encoded_inputs)\r\n\r\nprint(\"\
    X_enpr_tensor:\", X_enpr_tensor.shape[0])  # (3, 5, 4041)\r\n```\r\n4041 is the\
    \ `vocab_size`, and the `hidden_size` is 256, so the right dimension of output\
    \ is (3, 5, 256)"
  created_at: 2022-08-05 12:20:12+00:00
  edited: false
  hidden: false
  id: 62ed190c9b538d02b450879f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: simecek/humandna_ELECTRA_1epoch
repo_type: model
status: open
target_branch: null
title: the output dimention
