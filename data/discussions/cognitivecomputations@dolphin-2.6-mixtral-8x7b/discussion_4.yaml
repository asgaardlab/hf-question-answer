!!python/object:huggingface_hub.community.DiscussionWithDetails
author: matimats
conflicting_files: null
created_at: 2023-12-23 19:58:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/749f40946051346bf97746c7211dfb77.svg
      fullname: Mateusz Sadowski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: matimats
      type: user
    createdAt: '2023-12-23T19:58:55.000Z'
    data:
      edited: false
      editors:
      - matimats
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9554628729820251
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/749f40946051346bf97746c7211dfb77.svg
          fullname: Mateusz Sadowski
          isHf: false
          isPro: false
          name: matimats
          type: user
        html: '<p>I''m trying to run it on my M1 Max 32GB Mac with Ollama, but I''m
          getting "Error: llama runner process has terminated". Am I doing anything
          wrong or is my machine simply not powerful enough?</p>

          '
        raw: 'I''m trying to run it on my M1 Max 32GB Mac with Ollama, but I''m getting
          "Error: llama runner process has terminated". Am I doing anything wrong
          or is my machine simply not powerful enough?'
        updatedAt: '2023-12-23T19:58:55.026Z'
      numEdits: 0
      reactions: []
    id: 65873bff438d7b1ccf0cddd3
    type: comment
  author: matimats
  content: 'I''m trying to run it on my M1 Max 32GB Mac with Ollama, but I''m getting
    "Error: llama runner process has terminated". Am I doing anything wrong or is
    my machine simply not powerful enough?'
  created_at: 2023-12-23 19:58:55+00:00
  edited: false
  hidden: false
  id: 65873bff438d7b1ccf0cddd3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6435718aaaef013d1aec3b8b/XKf-8MA47tjVAM6SCX0MP.jpeg?w=200&h=200&f=face
      fullname: Bartowski
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: bartowski
      type: user
    createdAt: '2023-12-25T04:29:35.000Z'
    data:
      edited: false
      editors:
      - bartowski
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.979342520236969
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6435718aaaef013d1aec3b8b/XKf-8MA47tjVAM6SCX0MP.jpeg?w=200&h=200&f=face
          fullname: Bartowski
          isHf: false
          isPro: false
          name: bartowski
          type: user
        html: '<p>Ollama is GGUF only, is it not?</p>

          '
        raw: Ollama is GGUF only, is it not?
        updatedAt: '2023-12-25T04:29:35.787Z'
      numEdits: 0
      reactions: []
    id: 6589052f9835f3cce2da6f7d
    type: comment
  author: bartowski
  content: Ollama is GGUF only, is it not?
  created_at: 2023-12-25 04:29:35+00:00
  edited: false
  hidden: false
  id: 6589052f9835f3cce2da6f7d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63037b895c70c21d0ea80b0e/myu35DuQn9io_HhxNLYR4.png?w=200&h=200&f=face
      fullname: Pooodle Shmith
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: Tom9000
      type: user
    createdAt: '2023-12-27T02:46:44.000Z'
    data:
      edited: false
      editors:
      - Tom9000
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8999053239822388
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63037b895c70c21d0ea80b0e/myu35DuQn9io_HhxNLYR4.png?w=200&h=200&f=face
          fullname: Pooodle Shmith
          isHf: false
          isPro: true
          name: Tom9000
          type: user
        html: '<p>You would need close to100GB ram to load it full fat.<br>But quantized
          (i.e. "dolphin-2.6-mixtral-8x7b.Q4_K_M.gguf") might be able to fit in to
          32GB.</p>

          '
        raw: 'You would need close to100GB ram to load it full fat.

          But quantized (i.e. "dolphin-2.6-mixtral-8x7b.Q4_K_M.gguf") might be able
          to fit in to 32GB.'
        updatedAt: '2023-12-27T02:46:44.721Z'
      numEdits: 0
      reactions: []
    id: 658b901401845f40ceba1c65
    type: comment
  author: Tom9000
  content: 'You would need close to100GB ram to load it full fat.

    But quantized (i.e. "dolphin-2.6-mixtral-8x7b.Q4_K_M.gguf") might be able to fit
    in to 32GB.'
  created_at: 2023-12-27 02:46:44+00:00
  edited: false
  hidden: false
  id: 658b901401845f40ceba1c65
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: cognitivecomputations/dolphin-2.6-mixtral-8x7b
repo_type: model
status: open
target_branch: null
title: Issues with running
