!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jstremme
conflicting_files: null
created_at: 2022-09-13 16:19:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615162967667-noauth.jpeg?w=200&h=200&f=face
      fullname: Joel Stremmel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jstremme
      type: user
    createdAt: '2022-09-13T17:19:26.000Z'
    data:
      edited: false
      editors:
      - jstremme
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615162967667-noauth.jpeg?w=200&h=200&f=face
          fullname: Joel Stremmel
          isHf: false
          isPro: false
          name: jstremme
          type: user
        html: '<p>When I attempt to load the QA model with:</p>

          <pre><code>from transformers import AutoTokenizer, AutoModelForQuestionAnswering

          tokenizer = AutoTokenizer.from_pretrained("vasudevgupta/bigbird-roberta-natural-questions")

          model = AutoModelForQuestionAnswering.from_pretrained("vasudevgupta/bigbird-roberta-natural-questions")

          </code></pre>

          <p>I get :</p>

          <pre><code>Some weights of the model checkpoint at vasudevgupta/bigbird-roberta-natural-questions
          were not used when initializing BigBirdForQuestionAnswering: [''bert.pooler.weight'',
          ''cls.weight'', ''bert.pooler.bias'', ''cls.bias'']

          - This IS expected if you are initializing BigBirdForQuestionAnswering from
          the checkpoint of a model trained on another task or with another architecture
          (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining
          model).

          - This IS NOT expected if you are initializing BigBirdForQuestionAnswering
          from the checkpoint of a model that you expect to be exactly identical (initializing
          a BertForSequenceClassification model from a BertForSequenceClassification
          model).

          </code></pre>

          <p>Does anyone know if this is expected behavior?  I have the same warning
          with <code>BigBirdForQuestionAnswering</code>.  I would expect the exact
          same output layers as the model checkpoint when initializing the model this
          way.  If there is a change that must be made to use the checkpoint, would
          someone be willing to share?  Many thanks!!</p>

          '
        raw: "When I attempt to load the QA model with:\r\n\r\n```\r\nfrom transformers\
          \ import AutoTokenizer, AutoModelForQuestionAnswering\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          vasudevgupta/bigbird-roberta-natural-questions\")\r\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"\
          vasudevgupta/bigbird-roberta-natural-questions\")\r\n```\r\n\r\nI get :\r\
          \n\r\n```\r\nSome weights of the model checkpoint at vasudevgupta/bigbird-roberta-natural-questions\
          \ were not used when initializing BigBirdForQuestionAnswering: ['bert.pooler.weight',\
          \ 'cls.weight', 'bert.pooler.bias', 'cls.bias']\r\n- This IS expected if\
          \ you are initializing BigBirdForQuestionAnswering from the checkpoint of\
          \ a model trained on another task or with another architecture (e.g. initializing\
          \ a BertForSequenceClassification model from a BertForPreTraining model).\r\
          \n- This IS NOT expected if you are initializing BigBirdForQuestionAnswering\
          \ from the checkpoint of a model that you expect to be exactly identical\
          \ (initializing a BertForSequenceClassification model from a BertForSequenceClassification\
          \ model).\r\n```\r\n\r\nDoes anyone know if this is expected behavior? \
          \ I have the same warning with `BigBirdForQuestionAnswering`.  I would expect\
          \ the exact same output layers as the model checkpoint when initializing\
          \ the model this way.  If there is a change that must be made to use the\
          \ checkpoint, would someone be willing to share?  Many thanks!!\r\n"
        updatedAt: '2022-09-13T17:19:26.675Z'
      numEdits: 0
      reactions: []
    id: 6320bb9ed2d45f31518012c7
    type: comment
  author: jstremme
  content: "When I attempt to load the QA model with:\r\n\r\n```\r\nfrom transformers\
    \ import AutoTokenizer, AutoModelForQuestionAnswering\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
    vasudevgupta/bigbird-roberta-natural-questions\")\r\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"\
    vasudevgupta/bigbird-roberta-natural-questions\")\r\n```\r\n\r\nI get :\r\n\r\n\
    ```\r\nSome weights of the model checkpoint at vasudevgupta/bigbird-roberta-natural-questions\
    \ were not used when initializing BigBirdForQuestionAnswering: ['bert.pooler.weight',\
    \ 'cls.weight', 'bert.pooler.bias', 'cls.bias']\r\n- This IS expected if you are\
    \ initializing BigBirdForQuestionAnswering from the checkpoint of a model trained\
    \ on another task or with another architecture (e.g. initializing a BertForSequenceClassification\
    \ model from a BertForPreTraining model).\r\n- This IS NOT expected if you are\
    \ initializing BigBirdForQuestionAnswering from the checkpoint of a model that\
    \ you expect to be exactly identical (initializing a BertForSequenceClassification\
    \ model from a BertForSequenceClassification model).\r\n```\r\n\r\nDoes anyone\
    \ know if this is expected behavior?  I have the same warning with `BigBirdForQuestionAnswering`.\
    \  I would expect the exact same output layers as the model checkpoint when initializing\
    \ the model this way.  If there is a change that must be made to use the checkpoint,\
    \ would someone be willing to share?  Many thanks!!\r\n"
  created_at: 2022-09-13 16:19:26+00:00
  edited: false
  hidden: false
  id: 6320bb9ed2d45f31518012c7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614331954727-5f6b44345e78cc6b0ed31d33.png?w=200&h=200&f=face
      fullname: Vasudev Gupta
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: vasudevgupta
      type: user
    createdAt: '2022-09-15T22:59:15.000Z'
    data:
      edited: false
      editors:
      - vasudevgupta
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1614331954727-5f6b44345e78cc6b0ed31d33.png?w=200&h=200&f=face
          fullname: Vasudev Gupta
          isHf: false
          isPro: false
          name: vasudevgupta
          type: user
        html: '<p>you should use this class: <a rel="nofollow" href="https://github.com/thevasudevgupta/bigbird/blob/2507c88ee850ec97c67c709f6be39c72075827c7/src/train_nq_torch.py#L64">https://github.com/thevasudevgupta/bigbird/blob/2507c88ee850ec97c67c709f6be39c72075827c7/src/train_nq_torch.py#L64</a>
          if you want to make the inference directly.</p>

          <p>Also, maybe you should use this checkpoint: <a href="https://huggingface.co/vasudevgupta/flax-bigbird-natural-questions">https://huggingface.co/vasudevgupta/flax-bigbird-natural-questions</a>
          instead of this one. This is trained until convergence and performs better.</p>

          '
        raw: 'you should use this class: https://github.com/thevasudevgupta/bigbird/blob/2507c88ee850ec97c67c709f6be39c72075827c7/src/train_nq_torch.py#L64
          if you want to make the inference directly.


          Also, maybe you should use this checkpoint: https://huggingface.co/vasudevgupta/flax-bigbird-natural-questions
          instead of this one. This is trained until convergence and performs better.'
        updatedAt: '2022-09-15T22:59:15.404Z'
      numEdits: 0
      reactions: []
    id: 6323ae4346247071271e0df1
    type: comment
  author: vasudevgupta
  content: 'you should use this class: https://github.com/thevasudevgupta/bigbird/blob/2507c88ee850ec97c67c709f6be39c72075827c7/src/train_nq_torch.py#L64
    if you want to make the inference directly.


    Also, maybe you should use this checkpoint: https://huggingface.co/vasudevgupta/flax-bigbird-natural-questions
    instead of this one. This is trained until convergence and performs better.'
  created_at: 2022-09-15 21:59:15+00:00
  edited: false
  hidden: false
  id: 6323ae4346247071271e0df1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615162967667-noauth.jpeg?w=200&h=200&f=face
      fullname: Joel Stremmel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jstremme
      type: user
    createdAt: '2022-09-18T23:33:41.000Z'
    data:
      edited: false
      editors:
      - jstremme
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615162967667-noauth.jpeg?w=200&h=200&f=face
          fullname: Joel Stremmel
          isHf: false
          isPro: false
          name: jstremme
          type: user
        html: "<blockquote>\n<p>you should use this class: <a rel=\"nofollow\" href=\"\
          https://github.com/thevasudevgupta/bigbird/blob/2507c88ee850ec97c67c709f6be39c72075827c7/src/train_nq_torch.py#L64\"\
          >https://github.com/thevasudevgupta/bigbird/blob/2507c88ee850ec97c67c709f6be39c72075827c7/src/train_nq_torch.py#L64</a>\
          \ if you want to make the inference directly.</p>\n<p>Also, maybe you should\
          \ use this checkpoint: <a href=\"https://huggingface.co/vasudevgupta/flax-bigbird-natural-questions\"\
          >https://huggingface.co/vasudevgupta/flax-bigbird-natural-questions</a>\
          \ instead of this one. This is trained until convergence and performs better.</p>\n\
          </blockquote>\n<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;vasudevgupta&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/vasudevgupta\"\
          >@<span class=\"underline\">vasudevgupta</span></a></span>\n\n\t</span></span>!\
          \  This is very helpful.  As I understand it, there's a difference between\
          \ the NQ and SQuAD QA formats, and this model uses the NQ format requiring\
          \ the NQ QA class referenced above, whereas the HuggingFace QA model class\
          \ is designed for SQuAD formatted inputs.</p>\n"
        raw: "> you should use this class: https://github.com/thevasudevgupta/bigbird/blob/2507c88ee850ec97c67c709f6be39c72075827c7/src/train_nq_torch.py#L64\
          \ if you want to make the inference directly.\n> \n> Also, maybe you should\
          \ use this checkpoint: https://huggingface.co/vasudevgupta/flax-bigbird-natural-questions\
          \ instead of this one. This is trained until convergence and performs better.\n\
          \nThanks @vasudevgupta!  This is very helpful.  As I understand it, there's\
          \ a difference between the NQ and SQuAD QA formats, and this model uses\
          \ the NQ format requiring the NQ QA class referenced above, whereas the\
          \ HuggingFace QA model class is designed for SQuAD formatted inputs."
        updatedAt: '2022-09-18T23:33:41.238Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6327aad5d907fdcccb5fc638
    id: 6327aad5d907fdcccb5fc637
    type: comment
  author: jstremme
  content: "> you should use this class: https://github.com/thevasudevgupta/bigbird/blob/2507c88ee850ec97c67c709f6be39c72075827c7/src/train_nq_torch.py#L64\
    \ if you want to make the inference directly.\n> \n> Also, maybe you should use\
    \ this checkpoint: https://huggingface.co/vasudevgupta/flax-bigbird-natural-questions\
    \ instead of this one. This is trained until convergence and performs better.\n\
    \nThanks @vasudevgupta!  This is very helpful.  As I understand it, there's a\
    \ difference between the NQ and SQuAD QA formats, and this model uses the NQ format\
    \ requiring the NQ QA class referenced above, whereas the HuggingFace QA model\
    \ class is designed for SQuAD formatted inputs."
  created_at: 2022-09-18 22:33:41+00:00
  edited: false
  hidden: false
  id: 6327aad5d907fdcccb5fc637
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615162967667-noauth.jpeg?w=200&h=200&f=face
      fullname: Joel Stremmel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jstremme
      type: user
    createdAt: '2022-09-18T23:33:41.000Z'
    data:
      status: closed
    id: 6327aad5d907fdcccb5fc638
    type: status-change
  author: jstremme
  created_at: 2022-09-18 22:33:41+00:00
  id: 6327aad5d907fdcccb5fc638
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: vasudevgupta/bigbird-roberta-natural-questions
repo_type: model
status: closed
target_branch: null
title: Weight Initialization Warning Using AutoModelForQuestionAnswering and BigBirdForQuestionAnswering
  with "vasudevgupta/bigbird-roberta-natural-questions"
