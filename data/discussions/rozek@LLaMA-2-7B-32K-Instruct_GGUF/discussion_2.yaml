!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Kalamia
conflicting_files: null
created_at: 2023-08-31 09:28:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64c3b0b54c9bebfa6a86ec08/XWaJ_EdV0QZlAJvsgHQyb.png?w=200&h=200&f=face
      fullname: Shinji Kanase
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kalamia
      type: user
    createdAt: '2023-08-31T10:28:29.000Z'
    data:
      edited: false
      editors:
      - Kalamia
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5180237889289856
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64c3b0b54c9bebfa6a86ec08/XWaJ_EdV0QZlAJvsgHQyb.png?w=200&h=200&f=face
          fullname: Shinji Kanase
          isHf: false
          isPro: false
          name: Kalamia
          type: user
        html: '<p>Hello, i wanted to test your model but i get a segmentation fault
          error when i try to launch it.</p>

          <p>~/llama.cpp $ ./main -t 4 -m models/LLaMA-2-7B-32K-Instruct-Q5_K_S.gguf
          --color -c 2048 --temp 0.7 --repeat_penalty 1.1 -b 10 -n -1 -i -ins<br>main:
          build = 1085 (1591e2e)<br>main: seed  = 1693477317<br>Segmentation fault</p>

          '
        raw: "Hello, i wanted to test your model but i get a segmentation fault error\
          \ when i try to launch it.\r\n\r\n~/llama.cpp $ ./main -t 4 -m models/LLaMA-2-7B-32K-Instruct-Q5_K_S.gguf\
          \ --color -c 2048 --temp 0.7 --repeat_penalty 1.1 -b 10 -n -1 -i -ins\r\n\
          main: build = 1085 (1591e2e)\r\nmain: seed  = 1693477317\r\nSegmentation\
          \ fault"
        updatedAt: '2023-08-31T10:28:29.816Z'
      numEdits: 0
      reactions: []
    id: 64f06b4dceba25851e35b935
    type: comment
  author: Kalamia
  content: "Hello, i wanted to test your model but i get a segmentation fault error\
    \ when i try to launch it.\r\n\r\n~/llama.cpp $ ./main -t 4 -m models/LLaMA-2-7B-32K-Instruct-Q5_K_S.gguf\
    \ --color -c 2048 --temp 0.7 --repeat_penalty 1.1 -b 10 -n -1 -i -ins\r\nmain:\
    \ build = 1085 (1591e2e)\r\nmain: seed  = 1693477317\r\nSegmentation fault"
  created_at: 2023-08-31 09:28:29+00:00
  edited: false
  hidden: false
  id: 64f06b4dceba25851e35b935
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/313a9e2786513613725c10b7a1a01176.svg
      fullname: Andreas Rozek
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: rozek
      type: user
    createdAt: '2023-08-31T11:38:16.000Z'
    data:
      edited: false
      editors:
      - rozek
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9219965934753418
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/313a9e2786513613725c10b7a1a01176.svg
          fullname: Andreas Rozek
          isHf: false
          isPro: false
          name: rozek
          type: user
        html: '<p>it seems that llama.cpp produces segfaults under certain conditions
          (independently of the model)</p>

          <p>I would recommend that you look through the open <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/issues">llama.cpp
          issues</a> and add yourself to those that fit best. One that I am involved
          with (albeit just a bit) is issue <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/issues/2893">#2893</a></p>

          '
        raw: 'it seems that llama.cpp produces segfaults under certain conditions
          (independently of the model)


          I would recommend that you look through the open [llama.cpp issues](https://github.com/ggerganov/llama.cpp/issues)
          and add yourself to those that fit best. One that I am involved with (albeit
          just a bit) is issue [#2893](https://github.com/ggerganov/llama.cpp/issues/2893)'
        updatedAt: '2023-08-31T11:38:16.756Z'
      numEdits: 0
      reactions: []
    id: 64f07ba88afb4939b3b1a719
    type: comment
  author: rozek
  content: 'it seems that llama.cpp produces segfaults under certain conditions (independently
    of the model)


    I would recommend that you look through the open [llama.cpp issues](https://github.com/ggerganov/llama.cpp/issues)
    and add yourself to those that fit best. One that I am involved with (albeit just
    a bit) is issue [#2893](https://github.com/ggerganov/llama.cpp/issues/2893)'
  created_at: 2023-08-31 10:38:16+00:00
  edited: false
  hidden: false
  id: 64f07ba88afb4939b3b1a719
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: rozek/LLaMA-2-7B-32K-Instruct_GGUF
repo_type: model
status: open
target_branch: null
title: Get a Segementation fault when loading the model
