!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rana-parvesh
conflicting_files: null
created_at: 2023-12-19 08:29:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/45a37580acd6b640e19112820d653133.svg
      fullname: Parvesh Rana
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rana-parvesh
      type: user
    createdAt: '2023-12-19T08:29:01.000Z'
    data:
      edited: false
      editors:
      - rana-parvesh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9780548810958862
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/45a37580acd6b640e19112820d653133.svg
          fullname: Parvesh Rana
          isHf: false
          isPro: false
          name: rana-parvesh
          type: user
        html: '<p>I want to fine tune this model can anyone give me advise how</p>

          '
        raw: I want to fine tune this model can anyone give me advise how
        updatedAt: '2023-12-19T08:29:01.840Z'
      numEdits: 0
      reactions: []
    id: 6581544de77395a0c8706225
    type: comment
  author: rana-parvesh
  content: I want to fine tune this model can anyone give me advise how
  created_at: 2023-12-19 08:29:01+00:00
  edited: false
  hidden: false
  id: 6581544de77395a0c8706225
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64df20dc22d604b137270864/C-1_EzY0tnrb-Cyn6lh93.jpeg?w=200&h=200&f=face
      fullname: TA
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NerdN
      type: user
    createdAt: '2023-12-19T08:46:02.000Z'
    data:
      edited: false
      editors:
      - NerdN
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8864575028419495
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64df20dc22d604b137270864/C-1_EzY0tnrb-Cyn6lh93.jpeg?w=200&h=200&f=face
          fullname: TA
          isHf: false
          isPro: false
          name: NerdN
          type: user
        html: '<p>i can help</p>

          '
        raw: i can help
        updatedAt: '2023-12-19T08:46:02.707Z'
      numEdits: 0
      reactions: []
    id: 6581584a419afba19a87d374
    type: comment
  author: NerdN
  content: i can help
  created_at: 2023-12-19 08:46:02+00:00
  edited: false
  hidden: false
  id: 6581584a419afba19a87d374
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2023-12-19T09:11:30.000Z'
    data:
      edited: true
      editors:
      - nielsr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7828952074050903
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Hi,</p>

          <p>Here''s a nice notebook that may help you: <a rel="nofollow" href="https://github.com/brevdev/notebooks/blob/main/phi2-finetune-own-data.ipynb">https://github.com/brevdev/notebooks/blob/main/phi2-finetune-own-data.ipynb</a>.</p>

          '
        raw: 'Hi,


          Here''s a nice notebook that may help you: https://github.com/brevdev/notebooks/blob/main/phi2-finetune-own-data.ipynb.'
        updatedAt: '2023-12-19T09:11:35.245Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - susnato
    id: 65815e4211f7f5879194eaa0
    type: comment
  author: nielsr
  content: 'Hi,


    Here''s a nice notebook that may help you: https://github.com/brevdev/notebooks/blob/main/phi2-finetune-own-data.ipynb.'
  created_at: 2023-12-19 09:11:30+00:00
  edited: true
  hidden: false
  id: 65815e4211f7f5879194eaa0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64df20dc22d604b137270864/C-1_EzY0tnrb-Cyn6lh93.jpeg?w=200&h=200&f=face
      fullname: TA
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NerdN
      type: user
    createdAt: '2023-12-19T09:14:13.000Z'
    data:
      edited: false
      editors:
      - NerdN
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9009895920753479
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64df20dc22d604b137270864/C-1_EzY0tnrb-Cyn6lh93.jpeg?w=200&h=200&f=face
          fullname: TA
          isHf: false
          isPro: false
          name: NerdN
          type: user
        html: '<p>Thanks</p>

          '
        raw: Thanks
        updatedAt: '2023-12-19T09:14:13.976Z'
      numEdits: 0
      reactions: []
    id: 65815ee56c6ea8c6683f27ce
    type: comment
  author: NerdN
  content: Thanks
  created_at: 2023-12-19 09:14:13+00:00
  edited: false
  hidden: false
  id: 65815ee56c6ea8c6683f27ce
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-12-19T13:39:19.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.1981269121170044
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: "<p>Here is my results with llama_factory</p>\n<p><a href=\"https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora\"\
          >https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora</a><br><a\
          \ href=\"https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1\">https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1</a></p>\n\
          <p>script</p>\n<pre><code>#!/bin/bash\n\neval \"$(conda shell.bash hook)\"\
          \nconda activate llama_factory\n\nMODEL_NAME=phi-2\nSTAGE=sft\nEPOCH=1 <a\
          \ href=\"/microsoft/phi-2/discussions/3\">#3</a>.0\nDATA=alpaca_gpt4_en\n\
          \nFT_TYPE=lora\nLoRA_TARGET=Wqkv #q_proj,v_proj\nTEMPLATE=default\nPREDICTION_SAMPLES=20\n\
          \nMODEL_PATH=./models/$MODEL_NAME\nif [ ! -d $MODEL_PATH ]; then\n    echo\
          \ \"Model not found: $MODEL_PATH\"\n    return 1\nfi\n\nSAVE_PATH=./models/$STAGE/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH-$FT_TYPE\n\
          if [ ! -d $SAVE_PATH ]; then\n    mkdir -p $SAVE_PATH\nfi\n\nDO_TRAIN=false\n\
          DO_PREDICT=false\nDO_EXPORT=false\n\nfor arg in \"$@\"\ndo\n if [[ \"$arg\"\
          \ == \"--train\" ]]; then\n   echo \"The '--train' argument is present in\
          \ an argument: $arg\"\n   DO_TRAIN=true\n fi\n  if [[ \"$arg\" == \"--pred\"\
          \ ]]; then\n   echo \"The '--pred' argument is present in an argument: $arg\"\
          \n   DO_PREDICT=true\n fi\n  if [[ \"$arg\" == \"--exp\" ]]; then\n   echo\
          \ \"The '--exp' argument is present in an argument: $arg\"\n   DO_EXPORT=true\n\
          \ fi\ndone\n\nif [ $DO_TRAIN == true ]; then\n    CUDA_VISIBLE_DEVICES=0\
          \ python src/train_bash.py \\\n        --seed 42 \\\n        --stage $STAGE\
          \ \\\n        --model_name_or_path $MODEL_PATH \\\n        --dataset $DATA\
          \ \\\n        --val_size .1 \\\n        --val_max_sample 20 \\\n       \
          \ --template $TEMPLATE \\\n        --finetuning_type $FT_TYPE \\\n     \
          \   --do_train \\\n        --lora_target $LoRA_TARGET \\\n        --output_dir\
          \ $SAVE_PATH \\\n        --overwrite_output_dir \\\n        --overwrite_cache\
          \ \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps\
          \ 4 \\\n        --lr_scheduler_type cosine \\\n        --logging_steps 10\
          \ \\\n        --save_steps 1000 \\\n        --learning_rate 5e-5 \\\n  \
          \      --num_train_epochs $EPOCH \\\n        --do_eval \\\n        --evaluation_strategy\
          \ epoch \\\n        --per_device_eval_batch_size 1 \\\n        --prediction_loss_only\
          \ \\\n        --plot_loss \\\n        --quantization_bit 4 \\\n        --report_to\
          \ tensorboard \\\n        |&amp; tee $SAVE_PATH/train_eval_log.txt\nfi\n\
          \nif [ $DO_PREDICT == true ]; then\n    SAVE_PATH_PREDICT=$SAVE_PATH/Predict_$PREDICTION_SAMPLES\n\
          \    if [ ! -d $SAVE_PATH_PREDICT ]; then\n        mkdir -p $SAVE_PATH_PREDICT\n\
          \    fi\n    CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n      \
          \  --stage $STAGE \\\n        --model_name_or_path $MODEL_PATH \\\n    \
          \    --do_predict \\\n        --max_samples $PREDICTION_SAMPLES \\\n   \
          \     --predict_with_generate \\\n        --dataset $DATA \\\n        --template\
          \ $TEMPLATE \\\n        --finetuning_type $FT_TYPE \\\n        --adapter_name_or_path\
          \ $SAVE_PATH \\\n        --output_dir $SAVE_PATH_PREDICT \\\n        --per_device_eval_batch_size\
          \ 1 \\\n        |&amp; tee $SAVE_PATH_PREDICT/predict_log.txt\nfi\n\nif\
          \ [ $DO_EXPORT == true ]; then\n    EXPORT_PATH=./models/export/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH\n\
          \    if [ ! -d $EXPORT_PATH ]; then\n        mkdir -p $EXPORT_PATH\n   \
          \ fi\n    CUDA_VISIBLE_DEVICES=0 python src/export_model.py \\\n       \
          \ --model_name_or_path $MODEL_PATH \\\n        --adapter_name_or_path $SAVE_PATH\
          \ \\\n        --template $TEMPLATE \\\n        --finetuning_type $FT_TYPE\
          \ \\\n        --export_dir $EXPORT_PATH \\\n        --export_size 5 \\\n\
          \        |&amp; tee $EXPORT_PATH/export_log.txt\nfi\n</code></pre>\n"
        raw: "Here is my results with llama_factory\n\nhttps://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora\n\
          https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1\n\nscript\n\n\
          ```\n#!/bin/bash\n\neval \"$(conda shell.bash hook)\"\nconda activate llama_factory\n\
          \nMODEL_NAME=phi-2\nSTAGE=sft\nEPOCH=1 #3.0\nDATA=alpaca_gpt4_en\n\nFT_TYPE=lora\n\
          LoRA_TARGET=Wqkv #q_proj,v_proj\nTEMPLATE=default\nPREDICTION_SAMPLES=20\n\
          \nMODEL_PATH=./models/$MODEL_NAME\nif [ ! -d $MODEL_PATH ]; then\n    echo\
          \ \"Model not found: $MODEL_PATH\"\n    return 1\nfi\n\nSAVE_PATH=./models/$STAGE/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH-$FT_TYPE\n\
          if [ ! -d $SAVE_PATH ]; then\n    mkdir -p $SAVE_PATH\nfi\n\nDO_TRAIN=false\n\
          DO_PREDICT=false\nDO_EXPORT=false\n\nfor arg in \"$@\"\ndo\n if [[ \"$arg\"\
          \ == \"--train\" ]]; then\n   echo \"The '--train' argument is present in\
          \ an argument: $arg\"\n   DO_TRAIN=true\n fi\n  if [[ \"$arg\" == \"--pred\"\
          \ ]]; then\n   echo \"The '--pred' argument is present in an argument: $arg\"\
          \n   DO_PREDICT=true\n fi\n  if [[ \"$arg\" == \"--exp\" ]]; then\n   echo\
          \ \"The '--exp' argument is present in an argument: $arg\"\n   DO_EXPORT=true\n\
          \ fi\ndone\n\nif [ $DO_TRAIN == true ]; then\n    CUDA_VISIBLE_DEVICES=0\
          \ python src/train_bash.py \\\n        --seed 42 \\\n        --stage $STAGE\
          \ \\\n        --model_name_or_path $MODEL_PATH \\\n        --dataset $DATA\
          \ \\\n        --val_size .1 \\\n        --val_max_sample 20 \\\n       \
          \ --template $TEMPLATE \\\n        --finetuning_type $FT_TYPE \\\n     \
          \   --do_train \\\n        --lora_target $LoRA_TARGET \\\n        --output_dir\
          \ $SAVE_PATH \\\n        --overwrite_output_dir \\\n        --overwrite_cache\
          \ \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps\
          \ 4 \\\n        --lr_scheduler_type cosine \\\n        --logging_steps 10\
          \ \\\n        --save_steps 1000 \\\n        --learning_rate 5e-5 \\\n  \
          \      --num_train_epochs $EPOCH \\\n        --do_eval \\\n        --evaluation_strategy\
          \ epoch \\\n        --per_device_eval_batch_size 1 \\\n        --prediction_loss_only\
          \ \\\n        --plot_loss \\\n        --quantization_bit 4 \\\n        --report_to\
          \ tensorboard \\\n        |& tee $SAVE_PATH/train_eval_log.txt\nfi\n\nif\
          \ [ $DO_PREDICT == true ]; then\n    SAVE_PATH_PREDICT=$SAVE_PATH/Predict_$PREDICTION_SAMPLES\n\
          \    if [ ! -d $SAVE_PATH_PREDICT ]; then\n        mkdir -p $SAVE_PATH_PREDICT\n\
          \    fi\n    CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n      \
          \  --stage $STAGE \\\n        --model_name_or_path $MODEL_PATH \\\n    \
          \    --do_predict \\\n        --max_samples $PREDICTION_SAMPLES \\\n   \
          \     --predict_with_generate \\\n        --dataset $DATA \\\n        --template\
          \ $TEMPLATE \\\n        --finetuning_type $FT_TYPE \\\n        --adapter_name_or_path\
          \ $SAVE_PATH \\\n        --output_dir $SAVE_PATH_PREDICT \\\n        --per_device_eval_batch_size\
          \ 1 \\\n        |& tee $SAVE_PATH_PREDICT/predict_log.txt\nfi\n\nif [ $DO_EXPORT\
          \ == true ]; then\n    EXPORT_PATH=./models/export/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH\n\
          \    if [ ! -d $EXPORT_PATH ]; then\n        mkdir -p $EXPORT_PATH\n   \
          \ fi\n    CUDA_VISIBLE_DEVICES=0 python src/export_model.py \\\n       \
          \ --model_name_or_path $MODEL_PATH \\\n        --adapter_name_or_path $SAVE_PATH\
          \ \\\n        --template $TEMPLATE \\\n        --finetuning_type $FT_TYPE\
          \ \\\n        --export_dir $EXPORT_PATH \\\n        --export_size 5 \\\n\
          \        |& tee $EXPORT_PATH/export_log.txt\nfi\n```"
        updatedAt: '2023-12-19T13:39:19.789Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - yunxi
        - NerdN
    id: 65819d07ca21d74c214cb3f6
    type: comment
  author: Yhyu13
  content: "Here is my results with llama_factory\n\nhttps://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora\n\
    https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1\n\nscript\n\n```\n\
    #!/bin/bash\n\neval \"$(conda shell.bash hook)\"\nconda activate llama_factory\n\
    \nMODEL_NAME=phi-2\nSTAGE=sft\nEPOCH=1 #3.0\nDATA=alpaca_gpt4_en\n\nFT_TYPE=lora\n\
    LoRA_TARGET=Wqkv #q_proj,v_proj\nTEMPLATE=default\nPREDICTION_SAMPLES=20\n\nMODEL_PATH=./models/$MODEL_NAME\n\
    if [ ! -d $MODEL_PATH ]; then\n    echo \"Model not found: $MODEL_PATH\"\n   \
    \ return 1\nfi\n\nSAVE_PATH=./models/$STAGE/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH-$FT_TYPE\n\
    if [ ! -d $SAVE_PATH ]; then\n    mkdir -p $SAVE_PATH\nfi\n\nDO_TRAIN=false\n\
    DO_PREDICT=false\nDO_EXPORT=false\n\nfor arg in \"$@\"\ndo\n if [[ \"$arg\" ==\
    \ \"--train\" ]]; then\n   echo \"The '--train' argument is present in an argument:\
    \ $arg\"\n   DO_TRAIN=true\n fi\n  if [[ \"$arg\" == \"--pred\" ]]; then\n   echo\
    \ \"The '--pred' argument is present in an argument: $arg\"\n   DO_PREDICT=true\n\
    \ fi\n  if [[ \"$arg\" == \"--exp\" ]]; then\n   echo \"The '--exp' argument is\
    \ present in an argument: $arg\"\n   DO_EXPORT=true\n fi\ndone\n\nif [ $DO_TRAIN\
    \ == true ]; then\n    CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n  \
    \      --seed 42 \\\n        --stage $STAGE \\\n        --model_name_or_path $MODEL_PATH\
    \ \\\n        --dataset $DATA \\\n        --val_size .1 \\\n        --val_max_sample\
    \ 20 \\\n        --template $TEMPLATE \\\n        --finetuning_type $FT_TYPE \\\
    \n        --do_train \\\n        --lora_target $LoRA_TARGET \\\n        --output_dir\
    \ $SAVE_PATH \\\n        --overwrite_output_dir \\\n        --overwrite_cache\
    \ \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps\
    \ 4 \\\n        --lr_scheduler_type cosine \\\n        --logging_steps 10 \\\n\
    \        --save_steps 1000 \\\n        --learning_rate 5e-5 \\\n        --num_train_epochs\
    \ $EPOCH \\\n        --do_eval \\\n        --evaluation_strategy epoch \\\n  \
    \      --per_device_eval_batch_size 1 \\\n        --prediction_loss_only \\\n\
    \        --plot_loss \\\n        --quantization_bit 4 \\\n        --report_to\
    \ tensorboard \\\n        |& tee $SAVE_PATH/train_eval_log.txt\nfi\n\nif [ $DO_PREDICT\
    \ == true ]; then\n    SAVE_PATH_PREDICT=$SAVE_PATH/Predict_$PREDICTION_SAMPLES\n\
    \    if [ ! -d $SAVE_PATH_PREDICT ]; then\n        mkdir -p $SAVE_PATH_PREDICT\n\
    \    fi\n    CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n        --stage\
    \ $STAGE \\\n        --model_name_or_path $MODEL_PATH \\\n        --do_predict\
    \ \\\n        --max_samples $PREDICTION_SAMPLES \\\n        --predict_with_generate\
    \ \\\n        --dataset $DATA \\\n        --template $TEMPLATE \\\n        --finetuning_type\
    \ $FT_TYPE \\\n        --adapter_name_or_path $SAVE_PATH \\\n        --output_dir\
    \ $SAVE_PATH_PREDICT \\\n        --per_device_eval_batch_size 1 \\\n        |&\
    \ tee $SAVE_PATH_PREDICT/predict_log.txt\nfi\n\nif [ $DO_EXPORT == true ]; then\n\
    \    EXPORT_PATH=./models/export/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH\n    if [ !\
    \ -d $EXPORT_PATH ]; then\n        mkdir -p $EXPORT_PATH\n    fi\n    CUDA_VISIBLE_DEVICES=0\
    \ python src/export_model.py \\\n        --model_name_or_path $MODEL_PATH \\\n\
    \        --adapter_name_or_path $SAVE_PATH \\\n        --template $TEMPLATE \\\
    \n        --finetuning_type $FT_TYPE \\\n        --export_dir $EXPORT_PATH \\\n\
    \        --export_size 5 \\\n        |& tee $EXPORT_PATH/export_log.txt\nfi\n\
    ```"
  created_at: 2023-12-19 13:39:19+00:00
  edited: false
  hidden: false
  id: 65819d07ca21d74c214cb3f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-03T14:22:57.000Z'
    data:
      status: closed
    id: 65956dc1e46f7097bc7ba637
    type: status-change
  author: gugarosa
  created_at: 2024-01-03 14:22:57+00:00
  id: 65956dc1e46f7097bc7ba637
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6392e8904bca25f8ee0e81fa/rs2V4KqNnr_gJ_HITRZUs.png?w=200&h=200&f=face
      fullname: Low IQ Gen AI
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fhai50032
      type: user
    createdAt: '2024-01-09T21:17:40.000Z'
    data:
      edited: false
      editors:
      - fhai50032
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.21524688601493835
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6392e8904bca25f8ee0e81fa/rs2V4KqNnr_gJ_HITRZUs.png?w=200&h=200&f=face
          fullname: Low IQ Gen AI
          isHf: false
          isPro: false
          name: fhai50032
          type: user
        html: "<blockquote>\n<p>Here is my results with llama_factory</p>\n<p><a href=\"\
          https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora\">https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora</a><br><a\
          \ href=\"https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1\">https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1</a></p>\n\
          <p>script</p>\n<pre><code>#!/bin/bash\n\neval \"$(conda shell.bash hook)\"\
          \nconda activate llama_factory\n\nMODEL_NAME=phi-2\nSTAGE=sft\nEPOCH=1 <a\
          \ href=\"/microsoft/phi-2/discussions/3\">#3</a>.0\nDATA=alpaca_gpt4_en\n\
          \nFT_TYPE=lora\nLoRA_TARGET=Wqkv #q_proj,v_proj\nTEMPLATE=default\nPREDICTION_SAMPLES=20\n\
          \nMODEL_PATH=./models/$MODEL_NAME\nif [ ! -d $MODEL_PATH ]; then\n    echo\
          \ \"Model not found: $MODEL_PATH\"\n    return 1\nfi\n\nSAVE_PATH=./models/$STAGE/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH-$FT_TYPE\n\
          if [ ! -d $SAVE_PATH ]; then\n    mkdir -p $SAVE_PATH\nfi\n\nDO_TRAIN=false\n\
          DO_PREDICT=false\nDO_EXPORT=false\n\nfor arg in \"$@\"\ndo\n if [[ \"$arg\"\
          \ == \"--train\" ]]; then\n   echo \"The '--train' argument is present in\
          \ an argument: $arg\"\n   DO_TRAIN=true\n fi\n  if [[ \"$arg\" == \"--pred\"\
          \ ]]; then\n   echo \"The '--pred' argument is present in an argument: $arg\"\
          \n   DO_PREDICT=true\n fi\n  if [[ \"$arg\" == \"--exp\" ]]; then\n   echo\
          \ \"The '--exp' argument is present in an argument: $arg\"\n   DO_EXPORT=true\n\
          \ fi\ndone\n\nif [ $DO_TRAIN == true ]; then\n    CUDA_VISIBLE_DEVICES=0\
          \ python src/train_bash.py \\\n        --seed 42 \\\n        --stage $STAGE\
          \ \\\n        --model_name_or_path $MODEL_PATH \\\n        --dataset $DATA\
          \ \\\n        --val_size .1 \\\n        --val_max_sample 20 \\\n       \
          \ --template $TEMPLATE \\\n        --finetuning_type $FT_TYPE \\\n     \
          \   --do_train \\\n        --lora_target $LoRA_TARGET \\\n        --output_dir\
          \ $SAVE_PATH \\\n        --overwrite_output_dir \\\n        --overwrite_cache\
          \ \\\n        --per_device_train_batch_size 1 \\\n        --gradient_accumulation_steps\
          \ 4 \\\n        --lr_scheduler_type cosine \\\n        --logging_steps 10\
          \ \\\n        --save_steps 1000 \\\n        --learning_rate 5e-5 \\\n  \
          \      --num_train_epochs $EPOCH \\\n        --do_eval \\\n        --evaluation_strategy\
          \ epoch \\\n        --per_device_eval_batch_size 1 \\\n        --prediction_loss_only\
          \ \\\n        --plot_loss \\\n        --quantization_bit 4 \\\n        --report_to\
          \ tensorboard \\\n        |&amp; tee $SAVE_PATH/train_eval_log.txt\nfi\n\
          \nif [ $DO_PREDICT == true ]; then\n    SAVE_PATH_PREDICT=$SAVE_PATH/Predict_$PREDICTION_SAMPLES\n\
          \    if [ ! -d $SAVE_PATH_PREDICT ]; then\n        mkdir -p $SAVE_PATH_PREDICT\n\
          \    fi\n    CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n      \
          \  --stage $STAGE \\\n        --model_name_or_path $MODEL_PATH \\\n    \
          \    --do_predict \\\n        --max_samples $PREDICTION_SAMPLES \\\n   \
          \     --predict_with_generate \\\n        --dataset $DATA \\\n        --template\
          \ $TEMPLATE \\\n        --finetuning_type $FT_TYPE \\\n        --adapter_name_or_path\
          \ $SAVE_PATH \\\n        --output_dir $SAVE_PATH_PREDICT \\\n        --per_device_eval_batch_size\
          \ 1 \\\n        |&amp; tee $SAVE_PATH_PREDICT/predict_log.txt\nfi\n\nif\
          \ [ $DO_EXPORT == true ]; then\n    EXPORT_PATH=./models/export/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH\n\
          \    if [ ! -d $EXPORT_PATH ]; then\n        mkdir -p $EXPORT_PATH\n   \
          \ fi\n    CUDA_VISIBLE_DEVICES=0 python src/export_model.py \\\n       \
          \ --model_name_or_path $MODEL_PATH \\\n        --adapter_name_or_path $SAVE_PATH\
          \ \\\n        --template $TEMPLATE \\\n        --finetuning_type $FT_TYPE\
          \ \\\n        --export_dir $EXPORT_PATH \\\n        --export_size 5 \\\n\
          \        |&amp; tee $EXPORT_PATH/export_log.txt\nfi\n</code></pre>\n</blockquote>\n\
          <p>hi , if its possible can you share phi-2 template in llama-factory which\
          \ you used to , i.e eos stop words etc...<br><a rel=\"nofollow\" href=\"\
          https://cdn-uploads.huggingface.co/production/uploads/6392e8904bca25f8ee0e81fa/cUgTZZmnZp3CCR3wUk8W9.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6392e8904bca25f8ee0e81fa/cUgTZZmnZp3CCR3wUk8W9.png\"\
          ></a></p>\n"
        raw: "> Here is my results with llama_factory\n> \n> https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora\n\
          > https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1\n> \n> script\n\
          > \n> ```\n> #!/bin/bash\n> \n> eval \"$(conda shell.bash hook)\"\n> conda\
          \ activate llama_factory\n> \n> MODEL_NAME=phi-2\n> STAGE=sft\n> EPOCH=1\
          \ #3.0\n> DATA=alpaca_gpt4_en\n> \n> FT_TYPE=lora\n> LoRA_TARGET=Wqkv #q_proj,v_proj\n\
          > TEMPLATE=default\n> PREDICTION_SAMPLES=20\n> \n> MODEL_PATH=./models/$MODEL_NAME\n\
          > if [ ! -d $MODEL_PATH ]; then\n>     echo \"Model not found: $MODEL_PATH\"\
          \n>     return 1\n> fi\n> \n> SAVE_PATH=./models/$STAGE/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH-$FT_TYPE\n\
          > if [ ! -d $SAVE_PATH ]; then\n>     mkdir -p $SAVE_PATH\n> fi\n> \n> DO_TRAIN=false\n\
          > DO_PREDICT=false\n> DO_EXPORT=false\n> \n> for arg in \"$@\"\n> do\n>\
          \  if [[ \"$arg\" == \"--train\" ]]; then\n>    echo \"The '--train' argument\
          \ is present in an argument: $arg\"\n>    DO_TRAIN=true\n>  fi\n>   if [[\
          \ \"$arg\" == \"--pred\" ]]; then\n>    echo \"The '--pred' argument is\
          \ present in an argument: $arg\"\n>    DO_PREDICT=true\n>  fi\n>   if [[\
          \ \"$arg\" == \"--exp\" ]]; then\n>    echo \"The '--exp' argument is present\
          \ in an argument: $arg\"\n>    DO_EXPORT=true\n>  fi\n> done\n> \n> if [\
          \ $DO_TRAIN == true ]; then\n>     CUDA_VISIBLE_DEVICES=0 python src/train_bash.py\
          \ \\\n>         --seed 42 \\\n>         --stage $STAGE \\\n>         --model_name_or_path\
          \ $MODEL_PATH \\\n>         --dataset $DATA \\\n>         --val_size .1\
          \ \\\n>         --val_max_sample 20 \\\n>         --template $TEMPLATE \\\
          \n>         --finetuning_type $FT_TYPE \\\n>         --do_train \\\n>  \
          \       --lora_target $LoRA_TARGET \\\n>         --output_dir $SAVE_PATH\
          \ \\\n>         --overwrite_output_dir \\\n>         --overwrite_cache \\\
          \n>         --per_device_train_batch_size 1 \\\n>         --gradient_accumulation_steps\
          \ 4 \\\n>         --lr_scheduler_type cosine \\\n>         --logging_steps\
          \ 10 \\\n>         --save_steps 1000 \\\n>         --learning_rate 5e-5\
          \ \\\n>         --num_train_epochs $EPOCH \\\n>         --do_eval \\\n>\
          \         --evaluation_strategy epoch \\\n>         --per_device_eval_batch_size\
          \ 1 \\\n>         --prediction_loss_only \\\n>         --plot_loss \\\n\
          >         --quantization_bit 4 \\\n>         --report_to tensorboard \\\n\
          >         |& tee $SAVE_PATH/train_eval_log.txt\n> fi\n> \n> if [ $DO_PREDICT\
          \ == true ]; then\n>     SAVE_PATH_PREDICT=$SAVE_PATH/Predict_$PREDICTION_SAMPLES\n\
          >     if [ ! -d $SAVE_PATH_PREDICT ]; then\n>         mkdir -p $SAVE_PATH_PREDICT\n\
          >     fi\n>     CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n>  \
          \       --stage $STAGE \\\n>         --model_name_or_path $MODEL_PATH \\\
          \n>         --do_predict \\\n>         --max_samples $PREDICTION_SAMPLES\
          \ \\\n>         --predict_with_generate \\\n>         --dataset $DATA \\\
          \n>         --template $TEMPLATE \\\n>         --finetuning_type $FT_TYPE\
          \ \\\n>         --adapter_name_or_path $SAVE_PATH \\\n>         --output_dir\
          \ $SAVE_PATH_PREDICT \\\n>         --per_device_eval_batch_size 1 \\\n>\
          \         |& tee $SAVE_PATH_PREDICT/predict_log.txt\n> fi\n> \n> if [ $DO_EXPORT\
          \ == true ]; then\n>     EXPORT_PATH=./models/export/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH\n\
          >     if [ ! -d $EXPORT_PATH ]; then\n>         mkdir -p $EXPORT_PATH\n\
          >     fi\n>     CUDA_VISIBLE_DEVICES=0 python src/export_model.py \\\n>\
          \         --model_name_or_path $MODEL_PATH \\\n>         --adapter_name_or_path\
          \ $SAVE_PATH \\\n>         --template $TEMPLATE \\\n>         --finetuning_type\
          \ $FT_TYPE \\\n>         --export_dir $EXPORT_PATH \\\n>         --export_size\
          \ 5 \\\n>         |& tee $EXPORT_PATH/export_log.txt\n> fi\n> ```\n\nhi\
          \ , if its possible can you share phi-2 template in llama-factory which\
          \ you used to , i.e eos stop words etc...\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6392e8904bca25f8ee0e81fa/cUgTZZmnZp3CCR3wUk8W9.png)\n"
        updatedAt: '2024-01-09T21:17:40.490Z'
      numEdits: 0
      reactions: []
    id: 659db7f4a2e1b65545876cfb
    type: comment
  author: fhai50032
  content: "> Here is my results with llama_factory\n> \n> https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1-lora\n\
    > https://huggingface.co/Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1\n> \n> script\n>\
    \ \n> ```\n> #!/bin/bash\n> \n> eval \"$(conda shell.bash hook)\"\n> conda activate\
    \ llama_factory\n> \n> MODEL_NAME=phi-2\n> STAGE=sft\n> EPOCH=1 #3.0\n> DATA=alpaca_gpt4_en\n\
    > \n> FT_TYPE=lora\n> LoRA_TARGET=Wqkv #q_proj,v_proj\n> TEMPLATE=default\n> PREDICTION_SAMPLES=20\n\
    > \n> MODEL_PATH=./models/$MODEL_NAME\n> if [ ! -d $MODEL_PATH ]; then\n>    \
    \ echo \"Model not found: $MODEL_PATH\"\n>     return 1\n> fi\n> \n> SAVE_PATH=./models/$STAGE/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH-$FT_TYPE\n\
    > if [ ! -d $SAVE_PATH ]; then\n>     mkdir -p $SAVE_PATH\n> fi\n> \n> DO_TRAIN=false\n\
    > DO_PREDICT=false\n> DO_EXPORT=false\n> \n> for arg in \"$@\"\n> do\n>  if [[\
    \ \"$arg\" == \"--train\" ]]; then\n>    echo \"The '--train' argument is present\
    \ in an argument: $arg\"\n>    DO_TRAIN=true\n>  fi\n>   if [[ \"$arg\" == \"\
    --pred\" ]]; then\n>    echo \"The '--pred' argument is present in an argument:\
    \ $arg\"\n>    DO_PREDICT=true\n>  fi\n>   if [[ \"$arg\" == \"--exp\" ]]; then\n\
    >    echo \"The '--exp' argument is present in an argument: $arg\"\n>    DO_EXPORT=true\n\
    >  fi\n> done\n> \n> if [ $DO_TRAIN == true ]; then\n>     CUDA_VISIBLE_DEVICES=0\
    \ python src/train_bash.py \\\n>         --seed 42 \\\n>         --stage $STAGE\
    \ \\\n>         --model_name_or_path $MODEL_PATH \\\n>         --dataset $DATA\
    \ \\\n>         --val_size .1 \\\n>         --val_max_sample 20 \\\n>        \
    \ --template $TEMPLATE \\\n>         --finetuning_type $FT_TYPE \\\n>        \
    \ --do_train \\\n>         --lora_target $LoRA_TARGET \\\n>         --output_dir\
    \ $SAVE_PATH \\\n>         --overwrite_output_dir \\\n>         --overwrite_cache\
    \ \\\n>         --per_device_train_batch_size 1 \\\n>         --gradient_accumulation_steps\
    \ 4 \\\n>         --lr_scheduler_type cosine \\\n>         --logging_steps 10\
    \ \\\n>         --save_steps 1000 \\\n>         --learning_rate 5e-5 \\\n>   \
    \      --num_train_epochs $EPOCH \\\n>         --do_eval \\\n>         --evaluation_strategy\
    \ epoch \\\n>         --per_device_eval_batch_size 1 \\\n>         --prediction_loss_only\
    \ \\\n>         --plot_loss \\\n>         --quantization_bit 4 \\\n>         --report_to\
    \ tensorboard \\\n>         |& tee $SAVE_PATH/train_eval_log.txt\n> fi\n> \n>\
    \ if [ $DO_PREDICT == true ]; then\n>     SAVE_PATH_PREDICT=$SAVE_PATH/Predict_$PREDICTION_SAMPLES\n\
    >     if [ ! -d $SAVE_PATH_PREDICT ]; then\n>         mkdir -p $SAVE_PATH_PREDICT\n\
    >     fi\n>     CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n>        \
    \ --stage $STAGE \\\n>         --model_name_or_path $MODEL_PATH \\\n>        \
    \ --do_predict \\\n>         --max_samples $PREDICTION_SAMPLES \\\n>         --predict_with_generate\
    \ \\\n>         --dataset $DATA \\\n>         --template $TEMPLATE \\\n>     \
    \    --finetuning_type $FT_TYPE \\\n>         --adapter_name_or_path $SAVE_PATH\
    \ \\\n>         --output_dir $SAVE_PATH_PREDICT \\\n>         --per_device_eval_batch_size\
    \ 1 \\\n>         |& tee $SAVE_PATH_PREDICT/predict_log.txt\n> fi\n> \n> if [\
    \ $DO_EXPORT == true ]; then\n>     EXPORT_PATH=./models/export/$MODEL_NAME-$STAGE-$DATA-ep$EPOCH\n\
    >     if [ ! -d $EXPORT_PATH ]; then\n>         mkdir -p $EXPORT_PATH\n>     fi\n\
    >     CUDA_VISIBLE_DEVICES=0 python src/export_model.py \\\n>         --model_name_or_path\
    \ $MODEL_PATH \\\n>         --adapter_name_or_path $SAVE_PATH \\\n>         --template\
    \ $TEMPLATE \\\n>         --finetuning_type $FT_TYPE \\\n>         --export_dir\
    \ $EXPORT_PATH \\\n>         --export_size 5 \\\n>         |& tee $EXPORT_PATH/export_log.txt\n\
    > fi\n> ```\n\nhi , if its possible can you share phi-2 template in llama-factory\
    \ which you used to , i.e eos stop words etc...\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6392e8904bca25f8ee0e81fa/cUgTZZmnZp3CCR3wUk8W9.png)\n"
  created_at: 2024-01-09 21:17:40+00:00
  edited: false
  hidden: false
  id: 659db7f4a2e1b65545876cfb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 35
repo_id: microsoft/phi-2
repo_type: model
status: closed
target_branch: null
title: fine-tuning
