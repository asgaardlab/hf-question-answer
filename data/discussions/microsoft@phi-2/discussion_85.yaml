!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Imran1
conflicting_files: null
created_at: 2024-01-15 09:51:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62846faa99bff5076f0a93b4/oTEr0Ns7Kmez7CzvcQEtL.jpeg?w=200&h=200&f=face
      fullname: Imran ullah
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Imran1
      type: user
    createdAt: '2024-01-15T09:51:58.000Z'
    data:
      edited: false
      editors:
      - Imran1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.35232165455818176
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62846faa99bff5076f0a93b4/oTEr0Ns7Kmez7CzvcQEtL.jpeg?w=200&h=200&f=face
          fullname: Imran ullah
          isHf: false
          isPro: false
          name: Imran1
          type: user
        html: "<p>`<br>import peft</p>\n<p>from peft import LoraConfig, prepare_model_for_kbit_training,\
          \ get_peft_model</p>\n<p>lora_config = LoraConfig(<br>    r=32,<br>    lora_alpha=16,<br>\
          \    target_modules=[<br>      'q_proj',<br>      'k_proj',<br>      'v_proj',<br>\
          \      'dense',<br>      'fc1',<br>      'fc2',</p>\n<pre><code>  ],\nbias=\"\
          none\",\nlora_dropout=0.05,\ntask_type=\"CAUSAL_LM\",\n</code></pre>\n<p>)</p>\n\
          <p>import transformers<br>from transformers import TrainingArguments<br>import\
          \ torch</p>\n<p>HAS_BFLOAT16 = torch.cuda.is_bf16_supported()</p>\n<p>training_args\
          \ = TrainingArguments(<br>    output_dir= \"phib\",<br>    max_steps = 100,<br>\
          \    per_device_train_batch_size= 1,<br>    gradient_accumulation_steps=\
          \ 4,<br>    optim=\"paged_adamw_32bit\",<br>    warmup_steps = 10,<br> \
          \   logging_steps = 1,<br>    logging_strategy=\"steps\",<br>    learning_rate\
          \ = 2e-4,<br>    fp16 =  not HAS_BFLOAT16,<br>    bf16 = HAS_BFLOAT16,<br>\
          \    weight_decay = 0.01,<br>    lr_scheduler_type = \"linear\",<br>   \
          \ group_by_length= True,<br>    #disable_tqdm=False,<br>    report_to=\"\
          none\",<br>    seed = 3407,<br>)<br>`</p>\n<p>check the lose</p>\n<p><code>Step\t\
          Training Loss 1\t0.000000 2\t0.000000 3\t0.000000 4\t0.000000 5\t0.000000\
          \ 6\t0.000000 7\t0.000000</code></p>\n"
        raw: "`\r\nimport peft\r\n\r\nfrom peft import LoraConfig, prepare_model_for_kbit_training,\
          \ get_peft_model\r\n\r\nlora_config = LoraConfig(\r\n    r=32,\r\n    lora_alpha=16,\r\
          \n    target_modules=[\r\n      'q_proj',\r\n      'k_proj',\r\n      'v_proj',\r\
          \n      'dense',\r\n      'fc1',\r\n      'fc2',\r\n      \r\n      ],\r\
          \n    bias=\"none\",\r\n    lora_dropout=0.05,\r\n    task_type=\"CAUSAL_LM\"\
          ,\r\n)\r\n\r\n\r\nimport transformers\r\nfrom transformers import TrainingArguments\r\
          \nimport torch\r\n\r\nHAS_BFLOAT16 = torch.cuda.is_bf16_supported()\r\n\r\
          \ntraining_args = TrainingArguments(\r\n    output_dir= \"phib\",\r\n  \
          \  max_steps = 100,\r\n    per_device_train_batch_size= 1,\r\n    gradient_accumulation_steps=\
          \ 4,\r\n    optim=\"paged_adamw_32bit\",\r\n    warmup_steps = 10,\r\n \
          \   logging_steps = 1,\r\n    logging_strategy=\"steps\",\r\n    learning_rate\
          \ = 2e-4,\r\n    fp16 =  not HAS_BFLOAT16,\r\n    bf16 = HAS_BFLOAT16,\r\
          \n    weight_decay = 0.01,\r\n    lr_scheduler_type = \"linear\",\r\n  \
          \  group_by_length= True,\r\n    #disable_tqdm=False,\r\n    report_to=\"\
          none\",\r\n    seed = 3407,\r\n)\r\n`\r\n\r\ncheck the lose\r\n\r\n`Step\t\
          Training Loss\r\n1\t0.000000\r\n2\t0.000000\r\n3\t0.000000\r\n4\t0.000000\r\
          \n5\t0.000000\r\n6\t0.000000\r\n7\t0.000000`\r\n"
        updatedAt: '2024-01-15T09:51:58.362Z'
      numEdits: 0
      reactions: []
    id: 65a5003e2548c41ad9dbf24f
    type: comment
  author: Imran1
  content: "`\r\nimport peft\r\n\r\nfrom peft import LoraConfig, prepare_model_for_kbit_training,\
    \ get_peft_model\r\n\r\nlora_config = LoraConfig(\r\n    r=32,\r\n    lora_alpha=16,\r\
    \n    target_modules=[\r\n      'q_proj',\r\n      'k_proj',\r\n      'v_proj',\r\
    \n      'dense',\r\n      'fc1',\r\n      'fc2',\r\n      \r\n      ],\r\n   \
    \ bias=\"none\",\r\n    lora_dropout=0.05,\r\n    task_type=\"CAUSAL_LM\",\r\n\
    )\r\n\r\n\r\nimport transformers\r\nfrom transformers import TrainingArguments\r\
    \nimport torch\r\n\r\nHAS_BFLOAT16 = torch.cuda.is_bf16_supported()\r\n\r\ntraining_args\
    \ = TrainingArguments(\r\n    output_dir= \"phib\",\r\n    max_steps = 100,\r\n\
    \    per_device_train_batch_size= 1,\r\n    gradient_accumulation_steps= 4,\r\n\
    \    optim=\"paged_adamw_32bit\",\r\n    warmup_steps = 10,\r\n    logging_steps\
    \ = 1,\r\n    logging_strategy=\"steps\",\r\n    learning_rate = 2e-4,\r\n   \
    \ fp16 =  not HAS_BFLOAT16,\r\n    bf16 = HAS_BFLOAT16,\r\n    weight_decay =\
    \ 0.01,\r\n    lr_scheduler_type = \"linear\",\r\n    group_by_length= True,\r\
    \n    #disable_tqdm=False,\r\n    report_to=\"none\",\r\n    seed = 3407,\r\n\
    )\r\n`\r\n\r\ncheck the lose\r\n\r\n`Step\tTraining Loss\r\n1\t0.000000\r\n2\t\
    0.000000\r\n3\t0.000000\r\n4\t0.000000\r\n5\t0.000000\r\n6\t0.000000\r\n7\t0.000000`\r\
    \n"
  created_at: 2024-01-15 09:51:58+00:00
  edited: false
  hidden: false
  id: 65a5003e2548c41ad9dbf24f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/92f85b168a91dd2343853ac3edff1e3f.svg
      fullname: Tetsing
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pipper
      type: user
    createdAt: '2024-01-16T16:42:31.000Z'
    data:
      edited: false
      editors:
      - Pipper
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8056529760360718
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/92f85b168a91dd2343853ac3edff1e3f.svg
          fullname: Tetsing
          isHf: false
          isPro: false
          name: Pipper
          type: user
        html: '<p>Got the same issue on similar settings</p>

          '
        raw: 'Got the same issue on similar settings

          '
        updatedAt: '2024-01-16T16:42:31.247Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - johnpana
    id: 65a6b1f74908b2676c28b374
    type: comment
  author: Pipper
  content: 'Got the same issue on similar settings

    '
  created_at: 2024-01-16 16:42:31+00:00
  edited: false
  hidden: false
  id: 65a6b1f74908b2676c28b374
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-16T17:01:12.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9023279547691345
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: '<p>Could you please try with <code>microsoft/phi-1_5</code> and report
          if you are seing the same issue?</p>

          '
        raw: Could you please try with `microsoft/phi-1_5` and report if you are seing
          the same issue?
        updatedAt: '2024-01-16T17:01:12.218Z'
      numEdits: 0
      reactions: []
    id: 65a6b658d6e5c1ed6c2c6a03
    type: comment
  author: gugarosa
  content: Could you please try with `microsoft/phi-1_5` and report if you are seing
    the same issue?
  created_at: 2024-01-16 17:01:12+00:00
  edited: false
  hidden: false
  id: 65a6b658d6e5c1ed6c2c6a03
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/92f85b168a91dd2343853ac3edff1e3f.svg
      fullname: Tetsing
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pipper
      type: user
    createdAt: '2024-01-16T17:16:18.000Z'
    data:
      edited: true
      editors:
      - Pipper
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9473980069160461
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/92f85b168a91dd2343853ac3edff1e3f.svg
          fullname: Tetsing
          isHf: false
          isPro: false
          name: Pipper
          type: user
        html: '<p>Can''t try that right now, it looks like this rev "refs/pr/23" is
          working. The lora total number of trainable parameters are somehow 2 time
          higher as previous while conserving the same setting. I am wondering if
          this is supposed to be so (refs/pr/23 vs latest(Jan 16)) .</p>

          '
        raw: Can't try that right now, it looks like this rev "refs/pr/23" is working.
          The lora total number of trainable parameters are somehow 2 time higher
          as previous while conserving the same setting. I am wondering if this is
          supposed to be so (refs/pr/23 vs latest(Jan 16)) .
        updatedAt: '2024-01-16T17:16:37.205Z'
      numEdits: 1
      reactions: []
    id: 65a6b9e24555358d2cac36ab
    type: comment
  author: Pipper
  content: Can't try that right now, it looks like this rev "refs/pr/23" is working.
    The lora total number of trainable parameters are somehow 2 time higher as previous
    while conserving the same setting. I am wondering if this is supposed to be so
    (refs/pr/23 vs latest(Jan 16)) .
  created_at: 2024-01-16 17:16:18+00:00
  edited: true
  hidden: false
  id: 65a6b9e24555358d2cac36ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-17T17:56:40.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8891789317131042
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: '<p>Could you please re-run with the latest update?</p>

          <p>We updated the <code>modeling_phi.py</code> file and disabled the auto-casting
          on the Attention layer. This is the same fix as the previous code had.</p>

          '
        raw: 'Could you please re-run with the latest update?


          We updated the `modeling_phi.py` file and disabled the auto-casting on the
          Attention layer. This is the same fix as the previous code had.'
        updatedAt: '2024-01-17T17:56:40.063Z'
      numEdits: 0
      reactions: []
    id: 65a814d8c5bf09bc93321eeb
    type: comment
  author: gugarosa
  content: 'Could you please re-run with the latest update?


    We updated the `modeling_phi.py` file and disabled the auto-casting on the Attention
    layer. This is the same fix as the previous code had.'
  created_at: 2024-01-17 17:56:40+00:00
  edited: false
  hidden: false
  id: 65a814d8c5bf09bc93321eeb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/92f85b168a91dd2343853ac3edff1e3f.svg
      fullname: Tetsing
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pipper
      type: user
    createdAt: '2024-01-18T10:30:36.000Z'
    data:
      edited: false
      editors:
      - Pipper
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8863096237182617
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/92f85b168a91dd2343853ac3edff1e3f.svg
          fullname: Tetsing
          isHf: false
          isPro: false
          name: Pipper
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;gugarosa&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/gugarosa\">@<span class=\"\
          underline\">gugarosa</span></a></span>\n\n\t</span></span> </p>\n<blockquote>\n\
          <p>Could you please re-run with the latest update?</p>\n</blockquote>\n\
          <p>great, that works fine. Thanks </p>\n"
        raw: "@gugarosa \n> Could you please re-run with the latest update?\n\ngreat,\
          \ that works fine. Thanks "
        updatedAt: '2024-01-18T10:30:36.528Z'
      numEdits: 0
      reactions: []
    id: 65a8fdcc17d869bb74a1ff9e
    type: comment
  author: Pipper
  content: "@gugarosa \n> Could you please re-run with the latest update?\n\ngreat,\
    \ that works fine. Thanks "
  created_at: 2024-01-18 10:30:36+00:00
  edited: false
  hidden: false
  id: 65a8fdcc17d869bb74a1ff9e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-19T13:56:20.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9142137765884399
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: '<p>No problems! Please let me know if you see anything else.</p>

          '
        raw: No problems! Please let me know if you see anything else.
        updatedAt: '2024-01-19T13:56:20.291Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65aa7f849aba49e1d01a43dd
    id: 65aa7f849aba49e1d01a43dc
    type: comment
  author: gugarosa
  content: No problems! Please let me know if you see anything else.
  created_at: 2024-01-19 13:56:20+00:00
  edited: false
  hidden: false
  id: 65aa7f849aba49e1d01a43dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-19T13:56:20.000Z'
    data:
      status: closed
    id: 65aa7f849aba49e1d01a43dd
    type: status-change
  author: gugarosa
  created_at: 2024-01-19 13:56:20+00:00
  id: 65aa7f849aba49e1d01a43dd
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 85
repo_id: microsoft/phi-2
repo_type: model
status: closed
target_branch: null
title: in fine tuning the model begin with zero loss.
