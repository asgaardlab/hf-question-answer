!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gaussfer
conflicting_files: null
created_at: 2024-01-08 17:41:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ce90534887f167609daf8917d6ec4f9e.svg
      fullname: Chintan Gotecha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gaussfer
      type: user
    createdAt: '2024-01-08T17:41:24.000Z'
    data:
      edited: false
      editors:
      - gaussfer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5087800621986389
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ce90534887f167609daf8917d6ec4f9e.svg
          fullname: Chintan Gotecha
          isHf: false
          isPro: false
          name: gaussfer
          type: user
        html: "<p>TGI Code:</p>\n<pre><code class=\"language-model=microsoft/phi-2\"\
          >\nvolume=$PWD/phi2\n\ndocker run  -p 8080:80 -v $volume:/data ghcr.io/huggingface/text-generation-inference:latest\
          \ --model-id $model --max-total-tokens 5024 --max-input-length 4096 --max-concurrent-requests\
          \ 128\n</code></pre>\n<p>Error:</p>\n<pre><code>2024-01-08T17:40:26.997262Z\
          \ ERROR text_generation_launcher: Error when initializing model\nTraceback\
          \ (most recent call last):\n  File \"/opt/conda/bin/text-generation-server\"\
          , line 8, in &lt;module&gt;\n    sys.exit(app())\n  File \"/opt/conda/lib/python3.9/site-packages/typer/main.py\"\
          , line 311, in __call__\n    return get_command(self)(*args, **kwargs)\n\
          \  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line 1157,\
          \ in __call__\n    return self.main(*args, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/typer/core.py\"\
          , line 778, in main\n    return _main(\n  File \"/opt/conda/lib/python3.9/site-packages/typer/core.py\"\
          , line 216, in _main\n    rv = self.invoke(ctx)\n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\"\
          , line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n\
          \  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line 1434,\
          \ in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File\
          \ \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line 783, in\
          \ invoke\n    return __callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/typer/main.py\"\
          , line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n\
          \  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
          , line 83, in serve\n    server.serve(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 207, in serve\n    asyncio.run(\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
          , line 44, in run\n    return loop.run_until_complete(main)\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
          , line 634, in run_until_complete\n    self.run_forever()\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
          , line 601, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
          , line 1905, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.9/asyncio/events.py\"\
          , line 80, in _run\n    self._context.run(self._callback, *self._args)\n\
          &gt; File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 159, in serve_inner\n    model = get_model(\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 338, in get_model\n    raise ValueError(f\"Unsupported model type\
          \ {model_type}\")\nValueError: Unsupported model type phi-msft\n\n2024-01-08T17:40:27.411136Z\
          \ ERROR shard-manager: text_generation_launcher: Shard complete standard\
          \ error output:\n\n/opt/conda/lib/python3.9/site-packages/bitsandbytes/cextension.py:34:\
          \ UserWarning: The installed version of bitsandbytes was compiled without\
          \ GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization\
          \ are unavailable.\n  warn(\"The installed version of bitsandbytes was compiled\
          \ without GPU support. \"\nTraceback (most recent call last):\n\n  File\
          \ \"/opt/conda/bin/text-generation-server\", line 8, in &lt;module&gt;\n\
          \    sys.exit(app())\n\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
          , line 83, in serve\n    server.serve(\n\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 207, in serve\n    asyncio.run(\n\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
          , line 44, in run\n    return loop.run_until_complete(main)\n\n  File \"\
          /opt/conda/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\n\
          \    return future.result()\n\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 159, in serve_inner\n    model = get_model(\n\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 338, in get_model\n    raise ValueError(f\"Unsupported model type\
          \ {model_type}\")\n\nValueError: Unsupported model type phi-msft\n rank=0\n\
          2024-01-08T17:40:27.510244Z ERROR text_generation_launcher: Shard 0 failed\
          \ to start\n2024-01-08T17:40:27.510283Z  INFO text_generation_launcher:\
          \ Shutting down shards\n</code></pre>\n"
        raw: "TGI Code:\r\n\r\n```model=microsoft/phi-2\r\n\r\nvolume=$PWD/phi2\r\n\
          \r\ndocker run  -p 8080:80 -v $volume:/data ghcr.io/huggingface/text-generation-inference:latest\
          \ --model-id $model --max-total-tokens 5024 --max-input-length 4096 --max-concurrent-requests\
          \ 128\r\n```\r\n\r\n\r\nError:\r\n```\r\n2024-01-08T17:40:26.997262Z ERROR\
          \ text_generation_launcher: Error when initializing model\r\nTraceback (most\
          \ recent call last):\r\n  File \"/opt/conda/bin/text-generation-server\"\
          , line 8, in <module>\r\n    sys.exit(app())\r\n  File \"/opt/conda/lib/python3.9/site-packages/typer/main.py\"\
          , line 311, in __call__\r\n    return get_command(self)(*args, **kwargs)\r\
          \n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line\
          \ 1157, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\
          /opt/conda/lib/python3.9/site-packages/typer/core.py\", line 778, in main\r\
          \n    return _main(\r\n  File \"/opt/conda/lib/python3.9/site-packages/typer/core.py\"\
          , line 216, in _main\r\n    rv = self.invoke(ctx)\r\n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\"\
          , line 1688, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\
          \n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line\
          \ 1434, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\
          \n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line\
          \ 783, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"\
          /opt/conda/lib/python3.9/site-packages/typer/main.py\", line 683, in wrapper\r\
          \n    return callback(**use_params)  # type: ignore\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
          , line 83, in serve\r\n    server.serve(\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 207, in serve\r\n    asyncio.run(\r\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
          , line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File\
          \ \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 634, in run_until_complete\r\
          \n    self.run_forever()\r\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
          , line 601, in run_forever\r\n    self._run_once()\r\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
          , line 1905, in _run_once\r\n    handle._run()\r\n  File \"/opt/conda/lib/python3.9/asyncio/events.py\"\
          , line 80, in _run\r\n    self._context.run(self._callback, *self._args)\r\
          \n> File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 159, in serve_inner\r\n    model = get_model(\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 338, in get_model\r\n    raise ValueError(f\"Unsupported model type\
          \ {model_type}\")\r\nValueError: Unsupported model type phi-msft\r\n\r\n\
          2024-01-08T17:40:27.411136Z ERROR shard-manager: text_generation_launcher:\
          \ Shard complete standard error output:\r\n\r\n/opt/conda/lib/python3.9/site-packages/bitsandbytes/cextension.py:34:\
          \ UserWarning: The installed version of bitsandbytes was compiled without\
          \ GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization\
          \ are unavailable.\r\n  warn(\"The installed version of bitsandbytes was\
          \ compiled without GPU support. \"\r\nTraceback (most recent call last):\r\
          \n\r\n  File \"/opt/conda/bin/text-generation-server\", line 8, in <module>\r\
          \n    sys.exit(app())\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
          , line 83, in serve\r\n    server.serve(\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 207, in serve\r\n    asyncio.run(\r\n\r\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
          , line 44, in run\r\n    return loop.run_until_complete(main)\r\n\r\n  File\
          \ \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\r\
          \n    return future.result()\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 159, in serve_inner\r\n    model = get_model(\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 338, in get_model\r\n    raise ValueError(f\"Unsupported model type\
          \ {model_type}\")\r\n\r\nValueError: Unsupported model type phi-msft\r\n\
          \ rank=0\r\n2024-01-08T17:40:27.510244Z ERROR text_generation_launcher:\
          \ Shard 0 failed to start\r\n2024-01-08T17:40:27.510283Z  INFO text_generation_launcher:\
          \ Shutting down shards\r\n```"
        updatedAt: '2024-01-08T17:41:25.001Z'
      numEdits: 0
      reactions: []
    id: 659c33c4df5ff5a30acb038f
    type: comment
  author: gaussfer
  content: "TGI Code:\r\n\r\n```model=microsoft/phi-2\r\n\r\nvolume=$PWD/phi2\r\n\r\
    \ndocker run  -p 8080:80 -v $volume:/data ghcr.io/huggingface/text-generation-inference:latest\
    \ --model-id $model --max-total-tokens 5024 --max-input-length 4096 --max-concurrent-requests\
    \ 128\r\n```\r\n\r\n\r\nError:\r\n```\r\n2024-01-08T17:40:26.997262Z ERROR text_generation_launcher:\
    \ Error when initializing model\r\nTraceback (most recent call last):\r\n  File\
    \ \"/opt/conda/bin/text-generation-server\", line 8, in <module>\r\n    sys.exit(app())\r\
    \n  File \"/opt/conda/lib/python3.9/site-packages/typer/main.py\", line 311, in\
    \ __call__\r\n    return get_command(self)(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\"\
    , line 1157, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"\
    /opt/conda/lib/python3.9/site-packages/typer/core.py\", line 778, in main\r\n\
    \    return _main(\r\n  File \"/opt/conda/lib/python3.9/site-packages/typer/core.py\"\
    , line 216, in _main\r\n    rv = self.invoke(ctx)\r\n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\"\
    , line 1688, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\
    \n  File \"/opt/conda/lib/python3.9/site-packages/click/core.py\", line 1434,\
    \ in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"\
    /opt/conda/lib/python3.9/site-packages/click/core.py\", line 783, in invoke\r\n\
    \    return __callback(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.9/site-packages/typer/main.py\"\
    , line 683, in wrapper\r\n    return callback(**use_params)  # type: ignore\r\n\
    \  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
    , line 83, in serve\r\n    server.serve(\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
    , line 207, in serve\r\n    asyncio.run(\r\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
    , line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
    , line 634, in run_until_complete\r\n    self.run_forever()\r\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
    , line 601, in run_forever\r\n    self._run_once()\r\n  File \"/opt/conda/lib/python3.9/asyncio/base_events.py\"\
    , line 1905, in _run_once\r\n    handle._run()\r\n  File \"/opt/conda/lib/python3.9/asyncio/events.py\"\
    , line 80, in _run\r\n    self._context.run(self._callback, *self._args)\r\n>\
    \ File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
    , line 159, in serve_inner\r\n    model = get_model(\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
    , line 338, in get_model\r\n    raise ValueError(f\"Unsupported model type {model_type}\"\
    )\r\nValueError: Unsupported model type phi-msft\r\n\r\n2024-01-08T17:40:27.411136Z\
    \ ERROR shard-manager: text_generation_launcher: Shard complete standard error\
    \ output:\r\n\r\n/opt/conda/lib/python3.9/site-packages/bitsandbytes/cextension.py:34:\
    \ UserWarning: The installed version of bitsandbytes was compiled without GPU\
    \ support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\r\
    \n  warn(\"The installed version of bitsandbytes was compiled without GPU support.\
    \ \"\r\nTraceback (most recent call last):\r\n\r\n  File \"/opt/conda/bin/text-generation-server\"\
    , line 8, in <module>\r\n    sys.exit(app())\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py\"\
    , line 83, in serve\r\n    server.serve(\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
    , line 207, in serve\r\n    asyncio.run(\r\n\r\n  File \"/opt/conda/lib/python3.9/asyncio/runners.py\"\
    , line 44, in run\r\n    return loop.run_until_complete(main)\r\n\r\n  File \"\
    /opt/conda/lib/python3.9/asyncio/base_events.py\", line 647, in run_until_complete\r\
    \n    return future.result()\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
    , line 159, in serve_inner\r\n    model = get_model(\r\n\r\n  File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
    , line 338, in get_model\r\n    raise ValueError(f\"Unsupported model type {model_type}\"\
    )\r\n\r\nValueError: Unsupported model type phi-msft\r\n rank=0\r\n2024-01-08T17:40:27.510244Z\
    \ ERROR text_generation_launcher: Shard 0 failed to start\r\n2024-01-08T17:40:27.510283Z\
    \  INFO text_generation_launcher: Shutting down shards\r\n```"
  created_at: 2024-01-08 17:41:24+00:00
  edited: false
  hidden: false
  id: 659c33c4df5ff5a30acb038f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-09T18:12:52.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8945809006690979
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;gaussfer&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/gaussfer\"\
          >@<span class=\"underline\">gaussfer</span></a></span>\n\n\t</span></span>!</p>\n\
          <p>Phi-2 is a \"custom\" model with a <code>model_type=phi-msft</code>,\
          \ which is not supported outside of this repository.</p>\n<p>However, there\
          \ is an ongoing PR which we will use to update Phi-2's code and fix such\
          \ an issue: <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/pull/28163\"\
          >https://github.com/huggingface/transformers/pull/28163</a>.</p>\n<p>Regards,<br>Gustavo.</p>\n"
        raw: 'Hello @gaussfer!


          Phi-2 is a "custom" model with a `model_type=phi-msft`, which is not supported
          outside of this repository.


          However, there is an ongoing PR which we will use to update Phi-2''s code
          and fix such an issue: https://github.com/huggingface/transformers/pull/28163.


          Regards,

          Gustavo.'
        updatedAt: '2024-01-09T18:12:52.728Z'
      numEdits: 0
      reactions: []
      relatedEventId: 659d8ca491519541cedcc852
    id: 659d8ca491519541cedcc84f
    type: comment
  author: gugarosa
  content: 'Hello @gaussfer!


    Phi-2 is a "custom" model with a `model_type=phi-msft`, which is not supported
    outside of this repository.


    However, there is an ongoing PR which we will use to update Phi-2''s code and
    fix such an issue: https://github.com/huggingface/transformers/pull/28163.


    Regards,

    Gustavo.'
  created_at: 2024-01-09 18:12:52+00:00
  edited: false
  hidden: false
  id: 659d8ca491519541cedcc84f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-09T18:12:52.000Z'
    data:
      status: closed
    id: 659d8ca491519541cedcc852
    type: status-change
  author: gugarosa
  created_at: 2024-01-09 18:12:52+00:00
  id: 659d8ca491519541cedcc852
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 72
repo_id: microsoft/phi-2
repo_type: model
status: closed
target_branch: null
title: Not Supported By TGI
