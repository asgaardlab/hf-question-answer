!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rizwan-ai
conflicting_files: null
created_at: 2023-12-19 10:41:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a8285009d2cc841df9c8c/JFt_jMvv_fj5AF8UjBYn9.jpeg?w=200&h=200&f=face
      fullname: Muhammad Rizwan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rizwan-ai
      type: user
    createdAt: '2023-12-19T10:41:05.000Z'
    data:
      edited: false
      editors:
      - rizwan-ai
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.24032653868198395
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a8285009d2cc841df9c8c/JFt_jMvv_fj5AF8UjBYn9.jpeg?w=200&h=200&f=face
          fullname: Muhammad Rizwan
          isHf: false
          isPro: false
          name: rizwan-ai
          type: user
        html: '<p>ValueError: Unrecognized configuration class &lt;class ''transformers_modules.microsoft.phi-2.d3186761bf5c4409f7679359284066c25ab668ee.configuration_phi.PhiConfig''&gt;
          for this kind of AutoModel: TFAutoModelForCausalLM.Model type should be
          one of BertConfig, CamembertConfig, CTRLConfig, GPT2Config, GPT2Config,
          GPTJConfig, OpenAIGPTConfig, OPTConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig,
          RoFormerConfig, TransfoXLConfig, XGLMConfig, XLMConfig, XLMRobertaConfig,
          XLNetConfig.</p>

          '
        raw: 'ValueError: Unrecognized configuration class <class ''transformers_modules.microsoft.phi-2.d3186761bf5c4409f7679359284066c25ab668ee.configuration_phi.PhiConfig''>
          for this kind of AutoModel: TFAutoModelForCausalLM.Model type should be
          one of BertConfig, CamembertConfig, CTRLConfig, GPT2Config, GPT2Config,
          GPTJConfig, OpenAIGPTConfig, OPTConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig,
          RoFormerConfig, TransfoXLConfig, XGLMConfig, XLMConfig, XLMRobertaConfig,
          XLNetConfig.'
        updatedAt: '2023-12-19T10:41:05.133Z'
      numEdits: 0
      reactions: []
    id: 658173411fb6cfa0b4a1dc8a
    type: comment
  author: rizwan-ai
  content: 'ValueError: Unrecognized configuration class <class ''transformers_modules.microsoft.phi-2.d3186761bf5c4409f7679359284066c25ab668ee.configuration_phi.PhiConfig''>
    for this kind of AutoModel: TFAutoModelForCausalLM.Model type should be one of
    BertConfig, CamembertConfig, CTRLConfig, GPT2Config, GPT2Config, GPTJConfig, OpenAIGPTConfig,
    OPTConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoFormerConfig,
    TransfoXLConfig, XGLMConfig, XLMConfig, XLMRobertaConfig, XLNetConfig.'
  created_at: 2023-12-19 10:41:05+00:00
  edited: false
  hidden: false
  id: 658173411fb6cfa0b4a1dc8a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2023-12-20T12:54:27.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7675787806510925
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: '<p>Hello @mrizwanse!</p>

          <p>Could you please provide the code you are using to load the model?</p>

          <p>Regards,<br>Gustavo.</p>

          '
        raw: 'Hello @mrizwanse!


          Could you please provide the code you are using to load the model?


          Regards,

          Gustavo.'
        updatedAt: '2023-12-20T12:54:27.345Z'
      numEdits: 0
      reactions: []
    id: 6582e40329e72d1ea4d256ca
    type: comment
  author: gugarosa
  content: 'Hello @mrizwanse!


    Could you please provide the code you are using to load the model?


    Regards,

    Gustavo.'
  created_at: 2023-12-20 12:54:27+00:00
  edited: false
  hidden: false
  id: 6582e40329e72d1ea4d256ca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a8285009d2cc841df9c8c/JFt_jMvv_fj5AF8UjBYn9.jpeg?w=200&h=200&f=face
      fullname: Muhammad Rizwan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rizwan-ai
      type: user
    createdAt: '2023-12-21T08:09:59.000Z'
    data:
      edited: false
      editors:
      - rizwan-ai
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3416847288608551
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/619a8285009d2cc841df9c8c/JFt_jMvv_fj5AF8UjBYn9.jpeg?w=200&h=200&f=face
          fullname: Muhammad Rizwan
          isHf: false
          isPro: false
          name: rizwan-ai
          type: user
        html: "<h1 id=\"importing-python-packages\">Importing Python packages</h1>\n\
          <p>from environs import Env</p>\n<h1 id=\"importing-huggingface-packages\"\
          >Importing HuggingFace packages</h1>\n<p>from transformers import TFAutoModelForCausalLM,\
          \ AutoTokenizer, pipeline</p>\n<h1 id=\"importing-langchain-packages\">Importing\
          \ LangChain packages</h1>\n<p>from langchain.llms.huggingface_pipeline import\
          \ HuggingFacePipeline<br>from langchain.prompts import PromptTemplate<br>from\
          \ langchain.chains import LLMChain</p>\n<h1 id=\"---------------------------------------------------------------------------\"\
          >---------------------------------------------------------------------------</h1>\n\
          <h1 id=\"read-environment-variables-from-env-file\">Read environment variables\
          \ from .env file</h1>\n<p>env = Env()<br>env.read_env(\".env\")</p>\n<h1\
          \ id=\"huggingface-hub-api-token\">HuggingFace Hub API token</h1>\n<h1 id=\"\
          huggingfacehub_api_token--envstrhuggingfacehub_api_token\">HUGGINGFACEHUB_API_TOKEN\
          \ = env.str(\"HUGGINGFACEHUB_API_TOKEN\")</h1>\n<h1 id=\"----------------------------------------------------------------------------1\"\
          >---------------------------------------------------------------------------</h1>\n\
          <h1 id=\"1-image-to-text-image-captioning\">1. Image to Text (Image Captioning)</h1>\n\
          <p>def img2txt(img_url):<br>    image_to_text = pipeline(<br>        task=\"\
          image-to-text\", model=\"Salesforce/blip-image-captioning-base\"<br>   \
          \ )</p>\n<pre><code>text = image_to_text(img_url)[0][\"generated_text\"\
          ]\n\n# print(\"\\n\\n\", text)\nreturn text\n</code></pre>\n<h1 id=\"2-llm-to-generate-story\"\
          >2. LLM to generate story</h1>\n<p>def generate_story(scenario):<br>   \
          \ template = \"\"\"<br>    You are a story teller;<br>    You can generate\
          \ a short story based on a simple narrative, the story should be no more\
          \ than 100 words;</p>\n<pre><code>CONTEXT: {scenario}\nSTORY:\n\"\"\"\n\n\
          prompt = PromptTemplate(template=template, input_variables=[\"scenario\"\
          ])\n\nmodel_id = \"microsoft/phi-2\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\
          model = TFAutoModelForCausalLM.from_pretrained(\n    model_id, trust_remote_code=True\n\
          )\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n\
          \    max_new_tokens=70,\n)\nstory_llm = HuggingFacePipeline(pipeline=pipe)\n\
          \nllm_chain = LLMChain(prompt=prompt, llm=story_llm, verbose=True)\n\nstory\
          \ = llm_chain.run(scenario)\n\nprint(\"\\n\\n\", story)\nreturn story\n\
          </code></pre>\n<p>generated_text = img2txt(\"images/rizwan.jpg\")<br>generated_story\
          \ = generate_story(generated_text)</p>\n<h1 id=\"python\">Python</h1>\n\
          <ul>\n<li>3.11.4</li>\n</ul>\n<h1 id=\"python-pip\">Python pip</h1>\n<ul>\n\
          <li>23.3.1</li>\n</ul>\n<h1 id=\"tensorflow\">TensorFlow</h1>\n<ul>\n<li>2.15.0</li>\n\
          </ul>\n<h1 id=\"trransformers\">Trransformers</h1>\n<ul>\n<li>4.35.2</li>\n\
          </ul>\n<h1 id=\"environs\">Environs</h1>\n<ul>\n<li>9.5.0</li>\n</ul>\n\
          <h1 id=\"pil\">PIL</h1>\n<ul>\n<li>10.1.0</li>\n</ul>\n<h1 id=\"langchain\"\
          >LangChain</h1>\n<ul>\n<li>0.0.345</li>\n</ul>\n"
        raw: "# Importing Python packages\nfrom environs import Env\n\n# Importing\
          \ HuggingFace packages\nfrom transformers import TFAutoModelForCausalLM,\
          \ AutoTokenizer, pipeline\n\n# Importing LangChain packages\nfrom langchain.llms.huggingface_pipeline\
          \ import HuggingFacePipeline\nfrom langchain.prompts import PromptTemplate\n\
          from langchain.chains import LLMChain\n\n\n# ---------------------------------------------------------------------------\
          \ #\n\n# Read environment variables from .env file\nenv = Env()\nenv.read_env(\"\
          .env\")\n\n\n# HuggingFace Hub API token\n# HUGGINGFACEHUB_API_TOKEN = env.str(\"\
          HUGGINGFACEHUB_API_TOKEN\")\n\n# ---------------------------------------------------------------------------\
          \ #\n\n\n# 1. Image to Text (Image Captioning)\ndef img2txt(img_url):\n\
          \    image_to_text = pipeline(\n        task=\"image-to-text\", model=\"\
          Salesforce/blip-image-captioning-base\"\n    )\n\n    text = image_to_text(img_url)[0][\"\
          generated_text\"]\n\n    # print(\"\\n\\n\", text)\n    return text\n\n\n\
          # 2. LLM to generate story\ndef generate_story(scenario):\n    template\
          \ = \"\"\"\n    You are a story teller;\n    You can generate a short story\
          \ based on a simple narrative, the story should be no more than 100 words;\n\
          \n    CONTEXT: {scenario}\n    STORY:\n    \"\"\"\n\n    prompt = PromptTemplate(template=template,\
          \ input_variables=[\"scenario\"])\n\n    model_id = \"microsoft/phi-2\"\n\
          \    tokenizer = AutoTokenizer.from_pretrained(model_id)\n    model = TFAutoModelForCausalLM.from_pretrained(\n\
          \        model_id, trust_remote_code=True\n    )\n    pipe = pipeline(\n\
          \        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n\
          \        max_new_tokens=70,\n    )\n    story_llm = HuggingFacePipeline(pipeline=pipe)\n\
          \n    llm_chain = LLMChain(prompt=prompt, llm=story_llm, verbose=True)\n\
          \n    story = llm_chain.run(scenario)\n\n    print(\"\\n\\n\", story)\n\
          \    return story\n\n\ngenerated_text = img2txt(\"images/rizwan.jpg\")\n\
          generated_story = generate_story(generated_text)\n\n\n# Python \n- 3.11.4\n\
          \n# Python pip\n- 23.3.1\n\n# TensorFlow \n- 2.15.0\n\n# Trransformers \n\
          - 4.35.2\n\n# Environs \n- 9.5.0\n\n# PIL\n- 10.1.0\n\n# LangChain\n- 0.0.345"
        updatedAt: '2023-12-21T08:09:59.167Z'
      numEdits: 0
      reactions: []
    id: 6583f2d71e065c276dd5661e
    type: comment
  author: rizwan-ai
  content: "# Importing Python packages\nfrom environs import Env\n\n# Importing HuggingFace\
    \ packages\nfrom transformers import TFAutoModelForCausalLM, AutoTokenizer, pipeline\n\
    \n# Importing LangChain packages\nfrom langchain.llms.huggingface_pipeline import\
    \ HuggingFacePipeline\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains\
    \ import LLMChain\n\n\n# ---------------------------------------------------------------------------\
    \ #\n\n# Read environment variables from .env file\nenv = Env()\nenv.read_env(\"\
    .env\")\n\n\n# HuggingFace Hub API token\n# HUGGINGFACEHUB_API_TOKEN = env.str(\"\
    HUGGINGFACEHUB_API_TOKEN\")\n\n# ---------------------------------------------------------------------------\
    \ #\n\n\n# 1. Image to Text (Image Captioning)\ndef img2txt(img_url):\n    image_to_text\
    \ = pipeline(\n        task=\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\"\
    \n    )\n\n    text = image_to_text(img_url)[0][\"generated_text\"]\n\n    # print(\"\
    \\n\\n\", text)\n    return text\n\n\n# 2. LLM to generate story\ndef generate_story(scenario):\n\
    \    template = \"\"\"\n    You are a story teller;\n    You can generate a short\
    \ story based on a simple narrative, the story should be no more than 100 words;\n\
    \n    CONTEXT: {scenario}\n    STORY:\n    \"\"\"\n\n    prompt = PromptTemplate(template=template,\
    \ input_variables=[\"scenario\"])\n\n    model_id = \"microsoft/phi-2\"\n    tokenizer\
    \ = AutoTokenizer.from_pretrained(model_id)\n    model = TFAutoModelForCausalLM.from_pretrained(\n\
    \        model_id, trust_remote_code=True\n    )\n    pipe = pipeline(\n     \
    \   \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n\
    \        max_new_tokens=70,\n    )\n    story_llm = HuggingFacePipeline(pipeline=pipe)\n\
    \n    llm_chain = LLMChain(prompt=prompt, llm=story_llm, verbose=True)\n\n   \
    \ story = llm_chain.run(scenario)\n\n    print(\"\\n\\n\", story)\n    return\
    \ story\n\n\ngenerated_text = img2txt(\"images/rizwan.jpg\")\ngenerated_story\
    \ = generate_story(generated_text)\n\n\n# Python \n- 3.11.4\n\n# Python pip\n\
    - 23.3.1\n\n# TensorFlow \n- 2.15.0\n\n# Trransformers \n- 4.35.2\n\n# Environs\
    \ \n- 9.5.0\n\n# PIL\n- 10.1.0\n\n# LangChain\n- 0.0.345"
  created_at: 2023-12-21 08:09:59+00:00
  edited: false
  hidden: false
  id: 6583f2d71e065c276dd5661e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-09T18:14:15.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.89072185754776
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: '<p>There is an ongoing PR which should mitigate such an issue: <a rel="nofollow"
          href="https://github.com/huggingface/transformers/pull/28163">https://github.com/huggingface/transformers/pull/28163</a>.</p>

          <p>We will use it to update Phi-2''s code.</p>

          '
        raw: 'There is an ongoing PR which should mitigate such an issue: https://github.com/huggingface/transformers/pull/28163.


          We will use it to update Phi-2''s code.'
        updatedAt: '2024-01-09T18:14:15.906Z'
      numEdits: 0
      reactions: []
      relatedEventId: 659d8cf71723f371c9cf4e71
    id: 659d8cf71723f371c9cf4e6e
    type: comment
  author: gugarosa
  content: 'There is an ongoing PR which should mitigate such an issue: https://github.com/huggingface/transformers/pull/28163.


    We will use it to update Phi-2''s code.'
  created_at: 2024-01-09 18:14:15+00:00
  edited: false
  hidden: false
  id: 659d8cf71723f371c9cf4e6e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-09T18:14:15.000Z'
    data:
      status: closed
    id: 659d8cf71723f371c9cf4e71
    type: status-change
  author: gugarosa
  created_at: 2024-01-09 18:14:15+00:00
  id: 659d8cf71723f371c9cf4e71
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 36
repo_id: microsoft/phi-2
repo_type: model
status: closed
target_branch: null
title: Unrecognized configuration class
