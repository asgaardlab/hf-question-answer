!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lukasedv
conflicting_files: null
created_at: 2024-01-13 11:52:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04b2998bd11c67eda4af3e88be9fc8fd.svg
      fullname: Lukas Lundin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lukasedv
      type: user
    createdAt: '2024-01-13T11:52:08.000Z'
    data:
      edited: false
      editors:
      - lukasedv
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8589178919792175
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/04b2998bd11c67eda4af3e88be9fc8fd.svg
          fullname: Lukas Lundin
          isHf: false
          isPro: false
          name: lukasedv
          type: user
        html: '<p>LLama Factory and existing fine-tuning tutorials target the "Wqkv"
          module for LoRA fine-tuning. This was apparently removed a couple days ago
          - which layers should be targeted now (k_proj, q_proj, v_proj, fc1, fc2
          seem to be listed in the safetensors files)?</p>

          '
        raw: LLama Factory and existing fine-tuning tutorials target the "Wqkv" module
          for LoRA fine-tuning. This was apparently removed a couple days ago - which
          layers should be targeted now (k_proj, q_proj, v_proj, fc1, fc2 seem to
          be listed in the safetensors files)?
        updatedAt: '2024-01-13T11:52:08.021Z'
      numEdits: 0
      reactions: []
    id: 65a27968680cb2eb94ce4bda
    type: comment
  author: lukasedv
  content: LLama Factory and existing fine-tuning tutorials target the "Wqkv" module
    for LoRA fine-tuning. This was apparently removed a couple days ago - which layers
    should be targeted now (k_proj, q_proj, v_proj, fc1, fc2 seem to be listed in
    the safetensors files)?
  created_at: 2024-01-13 11:52:08+00:00
  edited: false
  hidden: false
  id: 65a27968680cb2eb94ce4bda
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/812c76ddcf0b19753ebda889aba4fc0f.svg
      fullname: prachi mohnot
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: prachi1910
      type: user
    createdAt: '2024-01-14T18:42:56.000Z'
    data:
      edited: false
      editors:
      - prachi1910
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7661182880401611
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/812c76ddcf0b19753ebda889aba4fc0f.svg
          fullname: prachi mohnot
          isHf: false
          isPro: false
          name: prachi1910
          type: user
        html: '<p>I am trying to train using these target_modules=[''q_proj'',''k_proj'',''v_proj'',''dense''].<br>maybe
          you can give it a try!</p>

          '
        raw: "I am trying to train using these target_modules=['q_proj','k_proj','v_proj','dense'].\
          \ \nmaybe you can give it a try!"
        updatedAt: '2024-01-14T18:42:56.985Z'
      numEdits: 0
      reactions: []
    id: 65a42b30c0e637bd9c75ab2f
    type: comment
  author: prachi1910
  content: "I am trying to train using these target_modules=['q_proj','k_proj','v_proj','dense'].\
    \ \nmaybe you can give it a try!"
  created_at: 2024-01-14 18:42:56+00:00
  edited: false
  hidden: false
  id: 65a42b30c0e637bd9c75ab2f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5b4f04fbeffd3d7e352150294b68c894.svg
      fullname: Praveen Yerneni
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: praveeny
      type: user
    createdAt: '2024-01-15T04:07:29.000Z'
    data:
      edited: true
      editors:
      - praveeny
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7206312417984009
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5b4f04fbeffd3d7e352150294b68c894.svg
          fullname: Praveen Yerneni
          isHf: false
          isPro: false
          name: praveeny
          type: user
        html: '<p>I have been trying to fine-tune with all of the parameters listed
          in the model. The "trainable" parameters after LoRA is showing as 1.64%...
          And I am not seeing any training loss at all. Any luck figuring this out?</p>

          <p>target_modules= [<br>    ''q_proj'',<br>    ''k_proj'',<br>    ''v_proj'',<br>    ''dense'',<br>    ''fc1'',<br>    ''fc2'',<br>    ''embed_tokens'',<br>    ''lm_head''<br>    ],</p>

          <p>trainable params: 25313280 || all params: 1546705920 || trainable%: 1.64</p>

          '
        raw: "I have been trying to fine-tune with all of the parameters listed in\
          \ the model. The \"trainable\" parameters after LoRA is showing as 1.64%...\
          \ And I am not seeing any training loss at all. Any luck figuring this out?\n\
          \ntarget_modules= [\n    'q_proj', \n    'k_proj',\n    'v_proj', \n   \
          \ 'dense',\n    'fc1', \n    'fc2',\n    'embed_tokens',\n    'lm_head'\n\
          \    ],\n\n\ntrainable params: 25313280 || all params: 1546705920 || trainable%:\
          \ 1.64"
        updatedAt: '2024-01-16T04:29:58.167Z'
      numEdits: 1
      reactions: []
    id: 65a4af811051c2b0db6c6eae
    type: comment
  author: praveeny
  content: "I have been trying to fine-tune with all of the parameters listed in the\
    \ model. The \"trainable\" parameters after LoRA is showing as 1.64%... And I\
    \ am not seeing any training loss at all. Any luck figuring this out?\n\ntarget_modules=\
    \ [\n    'q_proj', \n    'k_proj',\n    'v_proj', \n    'dense',\n    'fc1', \n\
    \    'fc2',\n    'embed_tokens',\n    'lm_head'\n    ],\n\n\ntrainable params:\
    \ 25313280 || all params: 1546705920 || trainable%: 1.64"
  created_at: 2024-01-15 04:07:29+00:00
  edited: true
  hidden: false
  id: 65a4af811051c2b0db6c6eae
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/04b2998bd11c67eda4af3e88be9fc8fd.svg
      fullname: Lukas Lundin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lukasedv
      type: user
    createdAt: '2024-01-15T12:32:14.000Z'
    data:
      edited: false
      editors:
      - lukasedv
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8891478776931763
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/04b2998bd11c67eda4af3e88be9fc8fd.svg
          fullname: Lukas Lundin
          isHf: false
          isPro: false
          name: lukasedv
          type: user
        html: '<p>I am not seeing any loss with llama_factory either - not sure but
          something happened after the update. </p>

          '
        raw: 'I am not seeing any loss with llama_factory either - not sure but something
          happened after the update. '
        updatedAt: '2024-01-15T12:32:14.387Z'
      numEdits: 0
      reactions: []
    id: 65a525cedb5c00652eeb52ee
    type: comment
  author: lukasedv
  content: 'I am not seeing any loss with llama_factory either - not sure but something
    happened after the update. '
  created_at: 2024-01-15 12:32:14+00:00
  edited: false
  hidden: false
  id: 65a525cedb5c00652eeb52ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5fa432e95fd3736c1de3d5440360acab.svg
      fullname: iAManOOB
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iamanoob
      type: user
    createdAt: '2024-01-16T01:43:13.000Z'
    data:
      edited: false
      editors:
      - iamanoob
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8598408699035645
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5fa432e95fd3736c1de3d5440360acab.svg
          fullname: iAManOOB
          isHf: false
          isPro: false
          name: iamanoob
          type: user
        html: '<p>I see loss when using bf16.</p>

          <blockquote>

          <p>I am not seeing any loss with llama_factory either - not sure but something
          happened after the update.</p>

          </blockquote>

          '
        raw: 'I see loss when using bf16.

          > I am not seeing any loss with llama_factory either - not sure but something
          happened after the update.


          '
        updatedAt: '2024-01-16T01:43:13.903Z'
      numEdits: 0
      reactions: []
    id: 65a5df31bcc380edddaf8935
    type: comment
  author: iamanoob
  content: 'I see loss when using bf16.

    > I am not seeing any loss with llama_factory either - not sure but something
    happened after the update.


    '
  created_at: 2024-01-16 01:43:13+00:00
  edited: false
  hidden: false
  id: 65a5df31bcc380edddaf8935
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-17T18:07:00.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.927621066570282
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: '<p>Could you please test with the updated <code>modeling_phi.py</code>?
          We used the same fix (disabling auto-cast on Attention layer) as we had
          on some earlier revisions.</p>

          <p>It should now show a loss when fine-tuning with fp16.</p>

          '
        raw: 'Could you please test with the updated `modeling_phi.py`? We used the
          same fix (disabling auto-cast on Attention layer) as we had on some earlier
          revisions.


          It should now show a loss when fine-tuning with fp16.'
        updatedAt: '2024-01-17T18:07:00.730Z'
      numEdits: 0
      reactions: []
    id: 65a81744f0f30f7eeac8d0a6
    type: comment
  author: gugarosa
  content: 'Could you please test with the updated `modeling_phi.py`? We used the
    same fix (disabling auto-cast on Attention layer) as we had on some earlier revisions.


    It should now show a loss when fine-tuning with fp16.'
  created_at: 2024-01-17 18:07:00+00:00
  edited: false
  hidden: false
  id: 65a81744f0f30f7eeac8d0a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5b4f04fbeffd3d7e352150294b68c894.svg
      fullname: Praveen Yerneni
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: praveeny
      type: user
    createdAt: '2024-01-18T01:48:42.000Z'
    data:
      edited: false
      editors:
      - praveeny
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8489899635314941
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5b4f04fbeffd3d7e352150294b68c894.svg
          fullname: Praveen Yerneni
          isHf: false
          isPro: false
          name: praveeny
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;gugarosa&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/gugarosa\">@<span class=\"\
          underline\">gugarosa</span></a></span>\n\n\t</span></span> Just completed\
          \ training. Looking good. Thank you for the quick fix on this!</p>\n"
        raw: '@gugarosa Just completed training. Looking good. Thank you for the quick
          fix on this!'
        updatedAt: '2024-01-18T01:48:42.863Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - gugarosa
    id: 65a8837a6cb12bdc2720e383
    type: comment
  author: praveeny
  content: '@gugarosa Just completed training. Looking good. Thank you for the quick
    fix on this!'
  created_at: 2024-01-18 01:48:42+00:00
  edited: false
  hidden: false
  id: 65a8837a6cb12bdc2720e383
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-19T13:54:01.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9066547751426697
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: '<p>Please let me know if you see any more issues!</p>

          '
        raw: Please let me know if you see any more issues!
        updatedAt: '2024-01-19T13:54:01.955Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65aa7efacb5b4fb08ecef6a2
    id: 65aa7ef9cb5b4fb08ecef69d
    type: comment
  author: gugarosa
  content: Please let me know if you see any more issues!
  created_at: 2024-01-19 13:54:01+00:00
  edited: false
  hidden: false
  id: 65aa7ef9cb5b4fb08ecef69d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-19T13:54:02.000Z'
    data:
      status: closed
    id: 65aa7efacb5b4fb08ecef6a2
    type: status-change
  author: gugarosa
  created_at: 2024-01-19 13:54:02+00:00
  id: 65aa7efacb5b4fb08ecef6a2
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 82
repo_id: microsoft/phi-2
repo_type: model
status: closed
target_branch: null
title: Layers updated, which ones to target for LoRA fine-tuning?
