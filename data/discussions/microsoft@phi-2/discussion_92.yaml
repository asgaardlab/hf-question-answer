!!python/object:huggingface_hub.community.DiscussionWithDetails
author: karana657
conflicting_files: null
created_at: 2024-01-21 08:03:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/609e918a43ae3ffbe8426326ef0e8686.svg
      fullname: karana kk
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: karana657
      type: user
    createdAt: '2024-01-21T08:03:20.000Z'
    data:
      edited: false
      editors:
      - karana657
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9718343019485474
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/609e918a43ae3ffbe8426326ef0e8686.svg
          fullname: karana kk
          isHf: false
          isPro: false
          name: karana657
          type: user
        html: '<p>hi .<br>i am trying to reproduce the gsm8k accuracy. in blog its
          mentioned that with 8-cot phi-2 was 68% on gsm8k.<br>but when i tired with
          FP16 accuracy was 50% (zero-shot). and FP4 accuracy was 30%(zero-shot).
          in phi-2 hugging face how to give 8-cot is missing.<br>model is unable to
          take the COT. any explanination. should we switch to phi-1.5 ????</p>

          '
        raw: "hi .\r\ni am trying to reproduce the gsm8k accuracy. in blog its mentioned\
          \ that with 8-cot phi-2 was 68% on gsm8k.\r\nbut when i tired with FP16\
          \ accuracy was 50% (zero-shot). and FP4 accuracy was 30%(zero-shot). in\
          \ phi-2 hugging face how to give 8-cot is missing.\r\nmodel is unable to\
          \ take the COT. any explanination. should we switch to phi-1.5 ????"
        updatedAt: '2024-01-21T08:03:20.464Z'
      numEdits: 0
      reactions: []
    id: 65accfc8ac588f2a1cc47c94
    type: comment
  author: karana657
  content: "hi .\r\ni am trying to reproduce the gsm8k accuracy. in blog its mentioned\
    \ that with 8-cot phi-2 was 68% on gsm8k.\r\nbut when i tired with FP16 accuracy\
    \ was 50% (zero-shot). and FP4 accuracy was 30%(zero-shot). in phi-2 hugging face\
    \ how to give 8-cot is missing.\r\nmodel is unable to take the COT. any explanination.\
    \ should we switch to phi-1.5 ????"
  created_at: 2024-01-21 08:03:20+00:00
  edited: false
  hidden: false
  id: 65accfc8ac588f2a1cc47c94
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-22T17:50:30.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7452597618103027
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;karana657&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/karana657\"\
          >@<span class=\"underline\">karana657</span></a></span>\n\n\t</span></span>!</p>\n\
          <p>I am not able to share the full GSM8k evaluation due to some internal\
          \ imports, but this snippet might help you in using code for the evaluation:</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">def</span>\
          \ <span class=\"hljs-title function_\">_timeout_handler</span>(<span class=\"\
          hljs-params\">signum: <span class=\"hljs-built_in\">int</span>, frame: <span\
          \ class=\"hljs-type\">Any</span></span>) -&gt; <span class=\"hljs-literal\"\
          >None</span>:\n    <span class=\"hljs-keyword\">raise</span> Exception()\n\
          \n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >_validate_completion</span>(<span class=\"hljs-params\">completion: <span\
          \ class=\"hljs-built_in\">str</span>, label: <span class=\"hljs-built_in\"\
          >str</span></span>) -&gt; <span class=\"hljs-built_in\">bool</span>:\n \
          \   completion_lines = completion.split(<span class=\"hljs-string\">\"TA:\"\
          </span>)[<span class=\"hljs-number\">1</span>].strip().split(<span class=\"\
          hljs-string\">\"\\n\"</span>)\n    completion_code = <span class=\"hljs-string\"\
          >\"\\n\"</span>.join(completion_lines[<span class=\"hljs-number\">1</span>:]\
          \ <span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">\"\
          :\"</span> <span class=\"hljs-keyword\">in</span> completion_lines[<span\
          \ class=\"hljs-number\">0</span>] <span class=\"hljs-keyword\">else</span>\
          \ completion_lines)\n\n    <span class=\"hljs-keyword\">try</span>:\n  \
          \      signal.signal(signal.SIGALRM, _timeout_handler)\n        signal.alarm(<span\
          \ class=\"hljs-number\">2</span>)\n\n        <span class=\"hljs-keyword\"\
          >try</span>:\n            stdout = io.StringIO()\n            <span class=\"\
          hljs-keyword\">with</span> contextlib.redirect_stdout(stdout):\n       \
          \         <span class=\"hljs-built_in\">exec</span>(\n                 \
          \   <span class=\"hljs-string\">\"import math\\nfrom math import *\\nimport\
          \ numpy as np\\nimport hashlib\\n\"</span>\n                    + completion_code\n\
          \                    + <span class=\"hljs-string\">\"\\n\\n\"</span>\n \
          \                   + <span class=\"hljs-string\">\"if type(result) == str:\\\
          n\\tresult = result.replace(',', '')\\n\"</span>\n                    +\
          \ <span class=\"hljs-string\">f\"assert(int(result) == <span class=\"hljs-subst\"\
          >{label}</span>)\"</span>,\n                    {},\n                )\n\
          \            signal.alarm(<span class=\"hljs-number\">0</span>)\n      \
          \      prediction = <span class=\"hljs-number\">1</span>\n        <span\
          \ class=\"hljs-keyword\">except</span> Exception:\n            prediction\
          \ = <span class=\"hljs-number\">0</span>\n        <span class=\"hljs-keyword\"\
          >finally</span>:\n            signal.alarm(<span class=\"hljs-number\">0</span>)\n\
          \n    <span class=\"hljs-keyword\">except</span> Exception:\n        prediction\
          \ = <span class=\"hljs-number\">0</span>\n\n    <span class=\"hljs-keyword\"\
          >return</span> prediction\n</code></pre>\n<p>The overall idea is to execute\
          \ the code that was generated by the model and assert whether its outputs\
          \ are equal to the ground-truth label. We also added some public imports\
          \ to prevent many answers from failing.</p>\n"
        raw: "Hello @karana657!\n\nI am not able to share the full GSM8k evaluation\
          \ due to some internal imports, but this snippet might help you in using\
          \ code for the evaluation:\n\n```python\ndef _timeout_handler(signum: int,\
          \ frame: Any) -> None:\n    raise Exception()\n\ndef _validate_completion(completion:\
          \ str, label: str) -> bool:\n    completion_lines = completion.split(\"\
          TA:\")[1].strip().split(\"\\n\")\n    completion_code = \"\\n\".join(completion_lines[1:]\
          \ if \":\" in completion_lines[0] else completion_lines)\n\n    try:\n \
          \       signal.signal(signal.SIGALRM, _timeout_handler)\n        signal.alarm(2)\n\
          \n        try:\n            stdout = io.StringIO()\n            with contextlib.redirect_stdout(stdout):\n\
          \                exec(\n                    \"import math\\nfrom math import\
          \ *\\nimport numpy as np\\nimport hashlib\\n\"\n                    + completion_code\n\
          \                    + \"\\n\\n\"\n                    + \"if type(result)\
          \ == str:\\n\\tresult = result.replace(',', '')\\n\"\n                 \
          \   + f\"assert(int(result) == {label})\",\n                    {},\n  \
          \              )\n            signal.alarm(0)\n            prediction =\
          \ 1\n        except Exception:\n            prediction = 0\n        finally:\n\
          \            signal.alarm(0)\n\n    except Exception:\n        prediction\
          \ = 0\n\n    return prediction\n```\n\nThe overall idea is to execute the\
          \ code that was generated by the model and assert whether its outputs are\
          \ equal to the ground-truth label. We also added some public imports to\
          \ prevent many answers from failing.\n\n"
        updatedAt: '2024-01-22T17:50:30.226Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65aeaae65f62b764449e6ea0
    id: 65aeaae65f62b764449e6e9b
    type: comment
  author: gugarosa
  content: "Hello @karana657!\n\nI am not able to share the full GSM8k evaluation\
    \ due to some internal imports, but this snippet might help you in using code\
    \ for the evaluation:\n\n```python\ndef _timeout_handler(signum: int, frame: Any)\
    \ -> None:\n    raise Exception()\n\ndef _validate_completion(completion: str,\
    \ label: str) -> bool:\n    completion_lines = completion.split(\"TA:\")[1].strip().split(\"\
    \\n\")\n    completion_code = \"\\n\".join(completion_lines[1:] if \":\" in completion_lines[0]\
    \ else completion_lines)\n\n    try:\n        signal.signal(signal.SIGALRM, _timeout_handler)\n\
    \        signal.alarm(2)\n\n        try:\n            stdout = io.StringIO()\n\
    \            with contextlib.redirect_stdout(stdout):\n                exec(\n\
    \                    \"import math\\nfrom math import *\\nimport numpy as np\\\
    nimport hashlib\\n\"\n                    + completion_code\n                \
    \    + \"\\n\\n\"\n                    + \"if type(result) == str:\\n\\tresult\
    \ = result.replace(',', '')\\n\"\n                    + f\"assert(int(result)\
    \ == {label})\",\n                    {},\n                )\n            signal.alarm(0)\n\
    \            prediction = 1\n        except Exception:\n            prediction\
    \ = 0\n        finally:\n            signal.alarm(0)\n\n    except Exception:\n\
    \        prediction = 0\n\n    return prediction\n```\n\nThe overall idea is to\
    \ execute the code that was generated by the model and assert whether its outputs\
    \ are equal to the ground-truth label. We also added some public imports to prevent\
    \ many answers from failing.\n\n"
  created_at: 2024-01-22 17:50:30+00:00
  edited: false
  hidden: false
  id: 65aeaae65f62b764449e6e9b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-22T17:50:30.000Z'
    data:
      status: closed
    id: 65aeaae65f62b764449e6ea0
    type: status-change
  author: gugarosa
  created_at: 2024-01-22 17:50:30+00:00
  id: 65aeaae65f62b764449e6ea0
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 92
repo_id: microsoft/phi-2
repo_type: model
status: closed
target_branch: null
title: reproducing gsm8k accuracy phi-2
