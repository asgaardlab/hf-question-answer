!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tusharpaul
conflicting_files: null
created_at: 2023-12-26 17:09:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe851c5af1677c6c0f19c4bd3c3e2bff.svg
      fullname: Tushar Paul
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tusharpaul
      type: user
    createdAt: '2023-12-26T17:09:14.000Z'
    data:
      edited: false
      editors:
      - tusharpaul
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5697853565216064
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe851c5af1677c6c0f19c4bd3c3e2bff.svg
          fullname: Tushar Paul
          isHf: false
          isPro: false
          name: tusharpaul
          type: user
        html: '<p>For Fine-Tuning (Using PEFT) code :</p>

          <p>from peft import prepare_model_for_kbit_training</p>

          <p>model.gradient_checkpointing_enable()<br>model = prepare_model_for_kbit_training(model)</p>

          <p>Error :</p>

          <p>ValueError                                Traceback (most recent call
          last)<br> in &lt;cell line: 3&gt;()<br>      1 from peft import prepare_model_for_kbit_training<br>      2<br>----&gt;
          3 model.gradient_checkpointing_enable()<br>      4 model = prepare_model_for_kbit_training(model)</p>

          <p>/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py
          in gradient_checkpointing_enable(self)<br>   1629         """<br>   1630         if
          not self.supports_gradient_checkpointing:<br>-&gt; 1631             raise
          ValueError(f"{self.<strong>class</strong>.<strong>name</strong>} does not
          support gradient checkpointing.")<br>   1632         self.apply(partial(self._set_gradient_checkpointing,
          value=True))<br>   1633 </p>

          <p>ValueError: PhiForCausalLM does not support gradient checkpointing.</p>

          <p>Kindly let me know how to solve this issue.</p>

          <p>Thank You</p>

          <p>Email ID - <a rel="nofollow" href="mailto:tushar.paul@kusho.co">tushar.paul@kusho.co</a></p>

          '
        raw: "For Fine-Tuning (Using PEFT) code :\r\n\r\nfrom peft import prepare_model_for_kbit_training\r\
          \n\r\nmodel.gradient_checkpointing_enable()\r\nmodel = prepare_model_for_kbit_training(model)\r\
          \n\r\nError :\r\n\r\nValueError                                Traceback\
          \ (most recent call last)\r\n<ipython-input-16-d6b5f42e99b2> in <cell line:\
          \ 3>()\r\n      1 from peft import prepare_model_for_kbit_training\r\n \
          \     2 \r\n----> 3 model.gradient_checkpointing_enable()\r\n      4 model\
          \ = prepare_model_for_kbit_training(model)\r\n\r\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\
          \ in gradient_checkpointing_enable(self)\r\n   1629         \"\"\"\r\n \
          \  1630         if not self.supports_gradient_checkpointing:\r\n-> 1631\
          \             raise ValueError(f\"{self.__class__.__name__} does not support\
          \ gradient checkpointing.\")\r\n   1632         self.apply(partial(self._set_gradient_checkpointing,\
          \ value=True))\r\n   1633 \r\n\r\nValueError: PhiForCausalLM does not support\
          \ gradient checkpointing.\r\n\r\n\r\nKindly let me know how to solve this\
          \ issue.\r\n\r\nThank You\r\n\r\nEmail ID - tushar.paul@kusho.co"
        updatedAt: '2023-12-26T17:09:14.225Z'
      numEdits: 0
      reactions: []
    id: 658b08ba7f1e21412caa05e2
    type: comment
  author: tusharpaul
  content: "For Fine-Tuning (Using PEFT) code :\r\n\r\nfrom peft import prepare_model_for_kbit_training\r\
    \n\r\nmodel.gradient_checkpointing_enable()\r\nmodel = prepare_model_for_kbit_training(model)\r\
    \n\r\nError :\r\n\r\nValueError                                Traceback (most\
    \ recent call last)\r\n<ipython-input-16-d6b5f42e99b2> in <cell line: 3>()\r\n\
    \      1 from peft import prepare_model_for_kbit_training\r\n      2 \r\n---->\
    \ 3 model.gradient_checkpointing_enable()\r\n      4 model = prepare_model_for_kbit_training(model)\r\
    \n\r\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py in\
    \ gradient_checkpointing_enable(self)\r\n   1629         \"\"\"\r\n   1630   \
    \      if not self.supports_gradient_checkpointing:\r\n-> 1631             raise\
    \ ValueError(f\"{self.__class__.__name__} does not support gradient checkpointing.\"\
    )\r\n   1632         self.apply(partial(self._set_gradient_checkpointing, value=True))\r\
    \n   1633 \r\n\r\nValueError: PhiForCausalLM does not support gradient checkpointing.\r\
    \n\r\n\r\nKindly let me know how to solve this issue.\r\n\r\nThank You\r\n\r\n\
    Email ID - tushar.paul@kusho.co"
  created_at: 2023-12-26 17:09:14+00:00
  edited: false
  hidden: false
  id: 658b08ba7f1e21412caa05e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0cc16d7d0f85e2884130f10b0b10954d.svg
      fullname: "\u6211\u7231\u5B66\u4E60"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilovestudy
      type: user
    createdAt: '2023-12-28T03:23:44.000Z'
    data:
      edited: false
      editors:
      - ilovestudy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9905106425285339
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0cc16d7d0f85e2884130f10b0b10954d.svg
          fullname: "\u6211\u7231\u5B66\u4E60"
          isHf: false
          isPro: false
          name: ilovestudy
          type: user
        html: '<p>I also meet this issue. And i do not know how to solve it.</p>

          '
        raw: I also meet this issue. And i do not know how to solve it.
        updatedAt: '2023-12-28T03:23:44.405Z'
      numEdits: 0
      reactions: []
    id: 658cea407ff4aa6aa78d7cbf
    type: comment
  author: ilovestudy
  content: I also meet this issue. And i do not know how to solve it.
  created_at: 2023-12-28 03:23:44+00:00
  edited: false
  hidden: false
  id: 658cea407ff4aa6aa78d7cbf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0cc16d7d0f85e2884130f10b0b10954d.svg
      fullname: "\u6211\u7231\u5B66\u4E60"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilovestudy
      type: user
    createdAt: '2023-12-28T03:32:14.000Z'
    data:
      edited: false
      editors:
      - ilovestudy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8144524693489075
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0cc16d7d0f85e2884130f10b0b10954d.svg
          fullname: "\u6211\u7231\u5B66\u4E60"
          isHf: false
          isPro: false
          name: ilovestudy
          type: user
        html: '<p>I got this -&gt; <a href="https://huggingface.co/microsoft/phi-2/discussions/12">https://huggingface.co/microsoft/phi-2/discussions/12</a><br>Maybe
          in future, it can help.</p>

          '
        raw: 'I got this -> https://huggingface.co/microsoft/phi-2/discussions/12

          Maybe in future, it can help.'
        updatedAt: '2023-12-28T03:32:14.722Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - gugarosa
    id: 658cec3e29ef008a12b746b4
    type: comment
  author: ilovestudy
  content: 'I got this -> https://huggingface.co/microsoft/phi-2/discussions/12

    Maybe in future, it can help.'
  created_at: 2023-12-28 03:32:14+00:00
  edited: false
  hidden: false
  id: 658cec3e29ef008a12b746b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-03T14:25:33.000Z'
    data:
      edited: false
      editors:
      - gugarosa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8350898623466492
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
          fullname: Gustavo de Rosa
          isHf: false
          isPro: false
          name: gugarosa
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;ilovestudy&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ilovestudy\"\
          >@<span class=\"underline\">ilovestudy</span></a></span>\n\n\t</span></span>\
          \ and <span data-props=\"{&quot;user&quot;:&quot;tusharpaul&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/tusharpaul\">@<span class=\"\
          underline\">tusharpaul</span></a></span>\n\n\t</span></span>.</p>\n<p>We\
          \ will proceed with the integration of Phi directly in transformers and\
          \ it will fix the gradient checkpointing issue.</p>\n"
        raw: 'Hello @ilovestudy and @tusharpaul.


          We will proceed with the integration of Phi directly in transformers and
          it will fix the gradient checkpointing issue.'
        updatedAt: '2024-01-03T14:25:33.776Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65956e5d74e471ef4a172610
    id: 65956e5d74e471ef4a17260f
    type: comment
  author: gugarosa
  content: 'Hello @ilovestudy and @tusharpaul.


    We will proceed with the integration of Phi directly in transformers and it will
    fix the gradient checkpointing issue.'
  created_at: 2024-01-03 14:25:33+00:00
  edited: false
  hidden: false
  id: 65956e5d74e471ef4a17260f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666203761402-6157454831624da88210e627.jpeg?w=200&h=200&f=face
      fullname: Gustavo de Rosa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: gugarosa
      type: user
    createdAt: '2024-01-03T14:25:33.000Z'
    data:
      status: closed
    id: 65956e5d74e471ef4a172610
    type: status-change
  author: gugarosa
  created_at: 2024-01-03 14:25:33+00:00
  id: 65956e5d74e471ef4a172610
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 48
repo_id: microsoft/phi-2
repo_type: model
status: closed
target_branch: null
title: Query!! Kindly let me know the alternative.
