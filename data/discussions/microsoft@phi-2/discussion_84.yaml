!!python/object:huggingface_hub.community.DiscussionWithDetails
author: luckychao
conflicting_files: null
created_at: 2024-01-14 14:54:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a95f9527722845a5414d86180c8e945d.svg
      fullname: Hao Yunzhuo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luckychao
      type: user
    createdAt: '2024-01-14T14:54:51.000Z'
    data:
      edited: false
      editors:
      - luckychao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5253840088844299
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a95f9527722845a5414d86180c8e945d.svg
          fullname: Hao Yunzhuo
          isHf: false
          isPro: false
          name: luckychao
          type: user
        html: "<p>When I use phi2 for inference in colab, I get an error:  RuntimeError:\
          \ \"LayerNormKernelImpl\" not implemented for 'Half'.<br>This is my code:</p>\n\
          <pre><code>!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n\
          !pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install\
          \ -q -U git+https://github.com/huggingface/accelerate.git\n!pip install\
          \ -q -U datasets scipy ipywidgets einops\n\nimport torch\nfrom transformers\
          \ import AutoModelForCausalLM, AutoTokenizer\n\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\ntokenizer\
          \ = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n\
          \ninputs = tokenizer('''How can I get a car?''', return_tensors=\"pt\",\
          \ return_attention_mask=False)\n\noutputs = model.generate(**inputs, max_length=200)\n\
          text = tokenizer.batch_decode(outputs)[0]\nprint(text)\n</code></pre>\n\
          <p>The error content is:</p>\n<pre><code>/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\
          \ in layer_norm(input, normalized_shape, weight, bias, eps)\n   2541   \
          \          layer_norm, (input, weight, bias), input, normalized_shape, weight=weight,\
          \ bias=bias, eps=eps\n   2542         )\n-&gt; 2543     return torch.layer_norm(input,\
          \ normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\n \
          \  2544 \n   2545 \n\nRuntimeError: \"LayerNormKernelImpl\" not implemented\
          \ for 'Half'\n</code></pre>\n<p>transformers version is 4.37.0.dev0<br>Could\
          \ you help me figure out how to fix this ? thx!!</p>\n"
        raw: "When I use phi2 for inference in colab, I get an error:  RuntimeError:\
          \ \"LayerNormKernelImpl\" not implemented for 'Half'.\r\nThis is my code:\r\
          \n```\r\n!pip install -q -U bitsandbytes\r\n!pip install -q -U git+https://github.com/huggingface/transformers.git\r\
          \n!pip install -q -U git+https://github.com/huggingface/peft.git\r\n!pip\
          \ install -q -U git+https://github.com/huggingface/accelerate.git\r\n!pip\
          \ install -q -U datasets scipy ipywidgets einops\r\n\r\nimport torch\r\n\
          from transformers import AutoModelForCausalLM, AutoTokenizer\r\n\r\nmodel\
          \ = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"\
          auto\", trust_remote_code=True)\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          microsoft/phi-2\", trust_remote_code=True)\r\n\r\ninputs = tokenizer('''How\
          \ can I get a car?''', return_tensors=\"pt\", return_attention_mask=False)\r\
          \n\r\noutputs = model.generate(**inputs, max_length=200)\r\ntext = tokenizer.batch_decode(outputs)[0]\r\
          \nprint(text)\r\n```\r\nThe error content is:\r\n```\r\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\
          \ in layer_norm(input, normalized_shape, weight, bias, eps)\r\n   2541 \
          \            layer_norm, (input, weight, bias), input, normalized_shape,\
          \ weight=weight, bias=bias, eps=eps\r\n   2542         )\r\n-> 2543    \
          \ return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\r\
          \n   2544 \r\n   2545 \r\n\r\nRuntimeError: \"LayerNormKernelImpl\" not\
          \ implemented for 'Half'\r\n```\r\ntransformers version is 4.37.0.dev0\r\
          \nCould you help me figure out how to fix this ? thx!!\r\n"
        updatedAt: '2024-01-14T14:54:51.983Z'
      numEdits: 0
      reactions: []
    id: 65a3f5bb5772dbcae340995a
    type: comment
  author: luckychao
  content: "When I use phi2 for inference in colab, I get an error:  RuntimeError:\
    \ \"LayerNormKernelImpl\" not implemented for 'Half'.\r\nThis is my code:\r\n\
    ```\r\n!pip install -q -U bitsandbytes\r\n!pip install -q -U git+https://github.com/huggingface/transformers.git\r\
    \n!pip install -q -U git+https://github.com/huggingface/peft.git\r\n!pip install\
    \ -q -U git+https://github.com/huggingface/accelerate.git\r\n!pip install -q -U\
    \ datasets scipy ipywidgets einops\r\n\r\nimport torch\r\nfrom transformers import\
    \ AutoModelForCausalLM, AutoTokenizer\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(\"\
    microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\r\ntokenizer\
    \ = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\r\
    \n\r\ninputs = tokenizer('''How can I get a car?''', return_tensors=\"pt\", return_attention_mask=False)\r\
    \n\r\noutputs = model.generate(**inputs, max_length=200)\r\ntext = tokenizer.batch_decode(outputs)[0]\r\
    \nprint(text)\r\n```\r\nThe error content is:\r\n```\r\n/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\
    \ in layer_norm(input, normalized_shape, weight, bias, eps)\r\n   2541       \
    \      layer_norm, (input, weight, bias), input, normalized_shape, weight=weight,\
    \ bias=bias, eps=eps\r\n   2542         )\r\n-> 2543     return torch.layer_norm(input,\
    \ normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\r\n   2544\
    \ \r\n   2545 \r\n\r\nRuntimeError: \"LayerNormKernelImpl\" not implemented for\
    \ 'Half'\r\n```\r\ntransformers version is 4.37.0.dev0\r\nCould you help me figure\
    \ out how to fix this ? thx!!\r\n"
  created_at: 2024-01-14 14:54:51+00:00
  edited: false
  hidden: false
  id: 65a3f5bb5772dbcae340995a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a95f9527722845a5414d86180c8e945d.svg
      fullname: Hao Yunzhuo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luckychao
      type: user
    createdAt: '2024-01-14T14:57:13.000Z'
    data:
      edited: false
      editors:
      - luckychao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5826839208602905
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a95f9527722845a5414d86180c8e945d.svg
          fullname: Hao Yunzhuo
          isHf: false
          isPro: false
          name: luckychao
          type: user
        html: '<p> btw I got the same error when using transformers==4.26.2</p>

          '
        raw: ' btw I got the same error when using transformers==4.26.2'
        updatedAt: '2024-01-14T14:57:13.936Z'
      numEdits: 0
      reactions: []
    id: 65a3f6496e52f83340d41915
    type: comment
  author: luckychao
  content: ' btw I got the same error when using transformers==4.26.2'
  created_at: 2024-01-14 14:57:13+00:00
  edited: false
  hidden: false
  id: 65a3f6496e52f83340d41915
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5b4f04fbeffd3d7e352150294b68c894.svg
      fullname: Praveen Yerneni
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: praveeny
      type: user
    createdAt: '2024-01-15T04:20:14.000Z'
    data:
      edited: false
      editors:
      - praveeny
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9750450253486633
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5b4f04fbeffd3d7e352150294b68c894.svg
          fullname: Praveen Yerneni
          isHf: false
          isPro: false
          name: praveeny
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;luckychao&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/luckychao\">@<span class=\"\
          underline\">luckychao</span></a></span>\n\n\t</span></span> I had the same\
          \ issue, however it was on my desktop where I am running on a CPU. If you\
          \ are on Colab, change your runtime to T4 GPU or any other GPU and try again.\
          \ If you were planning to run it on a CPU then set torch_dtype=torch.float32\
          \ in your code.</p>\n"
        raw: '@luckychao I had the same issue, however it was on my desktop where
          I am running on a CPU. If you are on Colab, change your runtime to T4 GPU
          or any other GPU and try again. If you were planning to run it on a CPU
          then set torch_dtype=torch.float32 in your code.'
        updatedAt: '2024-01-15T04:20:14.942Z'
      numEdits: 0
      reactions: []
    id: 65a4b27e4d251e9356d77fd5
    type: comment
  author: praveeny
  content: '@luckychao I had the same issue, however it was on my desktop where I
    am running on a CPU. If you are on Colab, change your runtime to T4 GPU or any
    other GPU and try again. If you were planning to run it on a CPU then set torch_dtype=torch.float32
    in your code.'
  created_at: 2024-01-15 04:20:14+00:00
  edited: false
  hidden: false
  id: 65a4b27e4d251e9356d77fd5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a95f9527722845a5414d86180c8e945d.svg
      fullname: Hao Yunzhuo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luckychao
      type: user
    createdAt: '2024-01-16T07:16:30.000Z'
    data:
      edited: false
      editors:
      - luckychao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9749662280082703
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a95f9527722845a5414d86180c8e945d.svg
          fullname: Hao Yunzhuo
          isHf: false
          isPro: false
          name: luckychao
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;luckychao&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/luckychao\"\
          >@<span class=\"underline\">luckychao</span></a></span>\n\n\t</span></span>\
          \ I had the same issue, however it was on my desktop where I am running\
          \ on a CPU. If you are on Colab, change your runtime to T4 GPU or any other\
          \ GPU and try again. If you were planning to run it on a CPU then set torch_dtype=torch.float32\
          \ in your code.</p>\n</blockquote>\n<p>Thanks for the answer! I'll try</p>\n"
        raw: '> @luckychao I had the same issue, however it was on my desktop where
          I am running on a CPU. If you are on Colab, change your runtime to T4 GPU
          or any other GPU and try again. If you were planning to run it on a CPU
          then set torch_dtype=torch.float32 in your code.


          Thanks for the answer! I''ll try'
        updatedAt: '2024-01-16T07:16:30.956Z'
      numEdits: 0
      reactions: []
    id: 65a62d4ee1e787bdecd8c9b3
    type: comment
  author: luckychao
  content: '> @luckychao I had the same issue, however it was on my desktop where
    I am running on a CPU. If you are on Colab, change your runtime to T4 GPU or any
    other GPU and try again. If you were planning to run it on a CPU then set torch_dtype=torch.float32
    in your code.


    Thanks for the answer! I''ll try'
  created_at: 2024-01-16 07:16:30+00:00
  edited: false
  hidden: false
  id: 65a62d4ee1e787bdecd8c9b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/a95f9527722845a5414d86180c8e945d.svg
      fullname: Hao Yunzhuo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luckychao
      type: user
    createdAt: '2024-01-16T07:16:47.000Z'
    data:
      status: closed
    id: 65a62d5f0b5704678ac68c24
    type: status-change
  author: luckychao
  created_at: 2024-01-16 07:16:47+00:00
  id: 65a62d5f0b5704678ac68c24
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 84
repo_id: microsoft/phi-2
repo_type: model
status: closed
target_branch: null
title: 'RuntimeError: "LayerNormKernelImpl" not implemented for ''Half'''
