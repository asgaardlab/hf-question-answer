!!python/object:huggingface_hub.community.DiscussionWithDetails
author: doberst
conflicting_files: null
created_at: 2023-12-16 19:51:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e813b3bdc5ab53bcffc5f9d6b3eeb084.svg
      fullname: Darren Oberst
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: doberst
      type: user
    createdAt: '2023-12-16T19:51:36.000Z'
    data:
      edited: false
      editors:
      - doberst
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8453726768493652
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e813b3bdc5ab53bcffc5f9d6b3eeb084.svg
          fullname: Darren Oberst
          isHf: false
          isPro: false
          name: doberst
          type: user
        html: '<p>Congratulations on DeciLM-7B ... Great Model.   We just fine-tuned
          the model for RAG and posted at:  llmware/dragon-deci-7b-v0 - check out
          the RAG benchmark scores, which compare favorably with Mistral, Llama-2,
          and other leading open source 7B foundation models.</p>

          <p>Excellent accuracy with especially strong performance in key analytical
          areas such as not-found classification, Boolean questions, common-sense
          math and logic, multiple-choice questions, and table reading.</p>

          <p>Also, the inference speed looks to be the fastest of the 7B models ....
          (we ran inference tests on Nvidia A6000)</p>

          '
        raw: "Congratulations on DeciLM-7B ... Great Model.   We just fine-tuned the\
          \ model for RAG and posted at:  llmware/dragon-deci-7b-v0 - check out the\
          \ RAG benchmark scores, which compare favorably with Mistral, Llama-2, and\
          \ other leading open source 7B foundation models.\r\n\r\nExcellent accuracy\
          \ with especially strong performance in key analytical areas such as not-found\
          \ classification, Boolean questions, common-sense math and logic, multiple-choice\
          \ questions, and table reading.\r\n\r\nAlso, the inference speed looks to\
          \ be the fastest of the 7B models .... (we ran inference tests on Nvidia\
          \ A6000)"
        updatedAt: '2023-12-16T19:51:36.537Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F917"
        users:
        - geifmany
        - roikoren755
        - tomer
    id: 657dffc8e6759943574b5f89
    type: comment
  author: doberst
  content: "Congratulations on DeciLM-7B ... Great Model.   We just fine-tuned the\
    \ model for RAG and posted at:  llmware/dragon-deci-7b-v0 - check out the RAG\
    \ benchmark scores, which compare favorably with Mistral, Llama-2, and other leading\
    \ open source 7B foundation models.\r\n\r\nExcellent accuracy with especially\
    \ strong performance in key analytical areas such as not-found classification,\
    \ Boolean questions, common-sense math and logic, multiple-choice questions, and\
    \ table reading.\r\n\r\nAlso, the inference speed looks to be the fastest of the\
    \ 7B models .... (we ran inference tests on Nvidia A6000)"
  created_at: 2023-12-16 19:51:36+00:00
  edited: false
  hidden: false
  id: 657dffc8e6759943574b5f89
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Deci/DeciLM-7B
repo_type: model
status: open
target_branch: null
title: GREAT MODEL
