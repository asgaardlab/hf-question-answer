!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Honeybread
conflicting_files: null
created_at: 2022-07-08 22:03:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2a4d2d7656cc8a77f5ac7d81d59175bf.svg
      fullname: Stevenchun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Honeybread
      type: user
    createdAt: '2022-07-08T23:03:21.000Z'
    data:
      edited: true
      editors:
      - Honeybread
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2a4d2d7656cc8a77f5ac7d81d59175bf.svg
          fullname: Stevenchun
          isHf: false
          isPro: false
          name: Honeybread
          type: user
        html: '<p>"<br>No sentence-transformers model found with name /Users/(myname)/.cache/torch/sentence_transformers/anferico_bert-for-patents.
          Creating a new one with MEAN pooling.<br>Some weights of the model checkpoint
          at /Users/(myname)/.cache/torch/sentence_transformers/anferico_bert-for-patents
          were not used when initializing BertModel: [''cls.predictions.transform.LayerNorm.weight'',
          ''cls.predictions.decoder.bias'', ''cls.predictions.decoder.weight'', ''cls.predictions.transform.LayerNorm.bias'',
          ''cls.seq_relationship.bias'', ''cls.seq_relationship.weight'', ''cls.predictions.transform.dense.bias'',
          ''cls.predictions.transform.dense.weight'', ''cls.predictions.bias'']<br>This
          IS expected if you are initializing BertModel from the checkpoint of a model
          trained on another task or with another architecture (e.g. initializing
          a BertForSequenceClassification model from a BertForPreTraining model).<br>This
          IS NOT expected if you are initializing BertModel from the checkpoint of
          a model that you expect to be exactly identical (initializing a BertForSequenceClassification
          model from a BertForSequenceClassification model).<br>"</p>

          <p>I am trying SBERT with many different other models, but such error occurred
          only with this model.<br>As other models are working fine without any errors,
          it is seems like my code or my data or my computer is not the source of
          the problem.</p>

          <p>Can you please check why is this happening? This many also be the reason
          for recent decrease in downloading trend for this model.</p>

          '
        raw: "\"\nNo sentence-transformers model found with name /Users/(myname)/.cache/torch/sentence_transformers/anferico_bert-for-patents.\
          \ Creating a new one with MEAN pooling.\nSome weights of the model checkpoint\
          \ at /Users/(myname)/.cache/torch/sentence_transformers/anferico_bert-for-patents\
          \ were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight',\
          \ 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias',\
          \ 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias',\
          \ 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\nThis\
          \ IS expected if you are initializing BertModel from the checkpoint of a\
          \ model trained on another task or with another architecture (e.g. initializing\
          \ a BertForSequenceClassification model from a BertForPreTraining model).\n\
          This IS NOT expected if you are initializing BertModel from the checkpoint\
          \ of a model that you expect to be exactly identical (initializing a BertForSequenceClassification\
          \ model from a BertForSequenceClassification model).\n\"\n\nI am trying\
          \ SBERT with many different other models, but such error occurred only with\
          \ this model. \nAs other models are working fine without any errors, it\
          \ is seems like my code or my data or my computer is not the source of the\
          \ problem.\n\nCan you please check why is this happening? This many also\
          \ be the reason for recent decrease in downloading trend for this model."
        updatedAt: '2022-07-08T23:04:02.702Z'
      numEdits: 2
      reactions: []
    id: 62c8b7b91a68929493132c19
    type: comment
  author: Honeybread
  content: "\"\nNo sentence-transformers model found with name /Users/(myname)/.cache/torch/sentence_transformers/anferico_bert-for-patents.\
    \ Creating a new one with MEAN pooling.\nSome weights of the model checkpoint\
    \ at /Users/(myname)/.cache/torch/sentence_transformers/anferico_bert-for-patents\
    \ were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight',\
    \ 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias',\
    \ 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias',\
    \ 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\nThis IS expected\
    \ if you are initializing BertModel from the checkpoint of a model trained on\
    \ another task or with another architecture (e.g. initializing a BertForSequenceClassification\
    \ model from a BertForPreTraining model).\nThis IS NOT expected if you are initializing\
    \ BertModel from the checkpoint of a model that you expect to be exactly identical\
    \ (initializing a BertForSequenceClassification model from a BertForSequenceClassification\
    \ model).\n\"\n\nI am trying SBERT with many different other models, but such\
    \ error occurred only with this model. \nAs other models are working fine without\
    \ any errors, it is seems like my code or my data or my computer is not the source\
    \ of the problem.\n\nCan you please check why is this happening? This many also\
    \ be the reason for recent decrease in downloading trend for this model."
  created_at: 2022-07-08 22:03:21+00:00
  edited: true
  hidden: false
  id: 62c8b7b91a68929493132c19
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1633339286421-noauth.jpeg?w=200&h=200&f=face
      fullname: Francesco Cariaggi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: anferico
      type: user
    createdAt: '2022-07-09T08:39:12.000Z'
    data:
      edited: false
      editors:
      - anferico
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1633339286421-noauth.jpeg?w=200&h=200&f=face
          fullname: Francesco Cariaggi
          isHf: false
          isPro: false
          name: anferico
          type: user
        html: '<p>Hi, this is actually expected as this model is a regular BERT, not
          a SBERT. Perhaps the other models you''ve used sentence-transformers with
          were SBERT models already, which is why you didn''t get the error. In fact,
          it''s not even an error: sentence-transformers simply states "Creating a
          new one with MEAN pooling.", but then doesn''t throw any exception or anything.<br>Note
          that after a SBERT model is initialized this way (i.e. from a regular BERT),
          it must be trained on a text similarity task before you can use it for predictions.</p>

          <p>If you still have doubts, please refer to the original SBERT paper.</p>

          '
        raw: 'Hi, this is actually expected as this model is a regular BERT, not a
          SBERT. Perhaps the other models you''ve used sentence-transformers with
          were SBERT models already, which is why you didn''t get the error. In fact,
          it''s not even an error: sentence-transformers simply states "Creating a
          new one with MEAN pooling.", but then doesn''t throw any exception or anything.

          Note that after a SBERT model is initialized this way (i.e. from a regular
          BERT), it must be trained on a text similarity task before you can use it
          for predictions.


          If you still have doubts, please refer to the original SBERT paper.'
        updatedAt: '2022-07-09T08:39:12.876Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Honeybread
    id: 62c93eb0814c1fd1fc3d3430
    type: comment
  author: anferico
  content: 'Hi, this is actually expected as this model is a regular BERT, not a SBERT.
    Perhaps the other models you''ve used sentence-transformers with were SBERT models
    already, which is why you didn''t get the error. In fact, it''s not even an error:
    sentence-transformers simply states "Creating a new one with MEAN pooling.", but
    then doesn''t throw any exception or anything.

    Note that after a SBERT model is initialized this way (i.e. from a regular BERT),
    it must be trained on a text similarity task before you can use it for predictions.


    If you still have doubts, please refer to the original SBERT paper.'
  created_at: 2022-07-09 07:39:12+00:00
  edited: false
  hidden: false
  id: 62c93eb0814c1fd1fc3d3430
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2a4d2d7656cc8a77f5ac7d81d59175bf.svg
      fullname: Stevenchun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Honeybread
      type: user
    createdAt: '2022-07-09T13:38:04.000Z'
    data:
      edited: false
      editors:
      - Honeybread
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2a4d2d7656cc8a77f5ac7d81d59175bf.svg
          fullname: Stevenchun
          isHf: false
          isPro: false
          name: Honeybread
          type: user
        html: '<p>Thank you, have a wonderful weekend :)</p>

          '
        raw: Thank you, have a wonderful weekend :)
        updatedAt: '2022-07-09T13:38:04.430Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - julien-c
    id: 62c984bc0011ffa7b34a51b7
    type: comment
  author: Honeybread
  content: Thank you, have a wonderful weekend :)
  created_at: 2022-07-09 12:38:04+00:00
  edited: false
  hidden: false
  id: 62c984bc0011ffa7b34a51b7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: anferico/bert-for-patents
repo_type: model
status: open
target_branch: null
title: '"No sentence-transformers model found" error'
