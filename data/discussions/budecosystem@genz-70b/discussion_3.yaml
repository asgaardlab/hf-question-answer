!!python/object:huggingface_hub.community.DiscussionWithDetails
author: joeofportland
conflicting_files: null
created_at: 2023-11-12 05:40:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/25f65f580e5af972c3f64518c41c1bd2.svg
      fullname: Joe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joeofportland
      type: user
    createdAt: '2023-11-12T05:40:43.000Z'
    data:
      edited: true
      editors:
      - joeofportland
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9762586355209351
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/25f65f580e5af972c3f64518c41c1bd2.svg
          fullname: Joe
          isHf: false
          isPro: false
          name: joeofportland
          type: user
        html: '<p>I''ve noticed sometimes the model returns \n\nUSER: at the end of
          some responses however I don''t encounter this issue on your 13b-v2 version.
          Are they different between the models?  I''m using vicuna formatting for
          multi turn.</p>

          <p>Thanks to the team for all the work they put into this model btw, it''s
          very impressive.</p>

          '
        raw: 'I''ve noticed sometimes the model returns \n\nUSER: at the end of some
          responses however I don''t encounter this issue on your 13b-v2 version.
          Are they different between the models?  I''m using vicuna formatting for
          multi turn.


          Thanks to the team for all the work they put into this model btw, it''s
          very impressive.'
        updatedAt: '2023-11-12T05:42:00.216Z'
      numEdits: 2
      reactions: []
    id: 6550655bd93842d2435ff889
    type: comment
  author: joeofportland
  content: 'I''ve noticed sometimes the model returns \n\nUSER: at the end of some
    responses however I don''t encounter this issue on your 13b-v2 version. Are they
    different between the models?  I''m using vicuna formatting for multi turn.


    Thanks to the team for all the work they put into this model btw, it''s very impressive.'
  created_at: 2023-11-12 05:40:43+00:00
  edited: true
  hidden: false
  id: 6550655bd93842d2435ff889
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426ada943fc9833932542bd/fvZGAVsCUQPbRsDf7Mh7L.png?w=200&h=200&f=face
      fullname: Ditto
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: dittops
      type: user
    createdAt: '2023-11-12T06:21:05.000Z'
    data:
      edited: false
      editors:
      - dittops
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8131487369537354
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426ada943fc9833932542bd/fvZGAVsCUQPbRsDf7Mh7L.png?w=200&h=200&f=face
          fullname: Ditto
          isHf: false
          isPro: false
          name: dittops
          type: user
        html: '<p>I have noticed this happening when the prompt templating is not
          correct. Try checking if the prompts are in the right format.</p>

          '
        raw: I have noticed this happening when the prompt templating is not correct.
          Try checking if the prompts are in the right format.
        updatedAt: '2023-11-12T06:21:05.682Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - joeofportland
    id: 65506ed1ab39927980292106
    type: comment
  author: dittops
  content: I have noticed this happening when the prompt templating is not correct.
    Try checking if the prompts are in the right format.
  created_at: 2023-11-12 06:21:05+00:00
  edited: false
  hidden: false
  id: 65506ed1ab39927980292106
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/25f65f580e5af972c3f64518c41c1bd2.svg
      fullname: Joe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joeofportland
      type: user
    createdAt: '2023-11-12T06:44:26.000Z'
    data:
      edited: true
      editors:
      - joeofportland
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9338344931602478
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/25f65f580e5af972c3f64518c41c1bd2.svg
          fullname: Joe
          isHf: false
          isPro: false
          name: joeofportland
          type: user
        html: '<p>Ahh that''s what it is: I was using USER: ASSISTANT: template for
          13b but it looks like 70b is ### User:\nWrite a python flask code for login
          management\n\n### Assistant:\n, switching to that format fixed it, thank
          you!</p>

          <p>Out of curiosity are the new lines needed? eg. \n after User: Assistant:
          and after the response? \n\n? This formatting template stuff has been hard
          for me to understand while experimenting with LLMs.</p>

          <p>Thanks again!</p>

          '
        raw: 'Ahh that''s what it is: I was using USER: ASSISTANT: template for 13b
          but it looks like 70b is ### User:\nWrite a python flask code for login
          management\n\n### Assistant:\n, switching to that format fixed it, thank
          you!


          Out of curiosity are the new lines needed? eg. \n after User: Assistant:
          and after the response? \n\n? This formatting template stuff has been hard
          for me to understand while experimenting with LLMs.


          Thanks again!'
        updatedAt: '2023-11-12T06:44:54.427Z'
      numEdits: 1
      reactions: []
    id: 6550744ad93842d243624db5
    type: comment
  author: joeofportland
  content: 'Ahh that''s what it is: I was using USER: ASSISTANT: template for 13b
    but it looks like 70b is ### User:\nWrite a python flask code for login management\n\n###
    Assistant:\n, switching to that format fixed it, thank you!


    Out of curiosity are the new lines needed? eg. \n after User: Assistant: and after
    the response? \n\n? This formatting template stuff has been hard for me to understand
    while experimenting with LLMs.


    Thanks again!'
  created_at: 2023-11-12 06:44:26+00:00
  edited: true
  hidden: false
  id: 6550744ad93842d243624db5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: budecosystem/genz-70b
repo_type: model
status: open
target_branch: null
title: Is this tokenizer messed up?
