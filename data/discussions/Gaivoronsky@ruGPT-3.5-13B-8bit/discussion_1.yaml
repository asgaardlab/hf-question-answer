!!python/object:huggingface_hub.community.DiscussionWithDetails
author: axone
conflicting_files: null
created_at: 2023-08-16 13:22:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5cb8b4335e89c684ca9f5556c7f732a5.svg
      fullname: Alexander
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: axone
      type: user
    createdAt: '2023-08-16T14:22:43.000Z'
    data:
      edited: true
      editors:
      - axone
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.10324469208717346
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5cb8b4335e89c684ca9f5556c7f732a5.svg
          fullname: Alexander
          isHf: false
          isPro: false
          name: axone
          type: user
        html: "<p>\u041E\u0448\u0438\u0431\u043A\u0430 from_pretrained() missing 1\
          \ required positional argument: 'quantize_config'</p>\n<p>python 3.9.6<br>transformers\
          \ 4.3.1<br>auto_gptq 0.3.1</p>\n<p>TypeError                           \
          \      Traceback (most recent call last)<br>Cell In[7], line 4<br>     \
          \ 1 from transformers import AutoTokenizer<br>      2 from auto_gptq import\
          \ AutoGPTQForCausalLM<br>----&gt; 4 model = AutoGPTQForCausalLM.from_pretrained('Gaivoronsky/ruGPT-3.5-13B-8bit',\
          \ device=\"cuda:0\", use_triton=False)<br>      5 tokenizer = AutoTokenizer.from_pretrained('Gaivoronsky/ruGPT-3.5-13B-8bit')<br>\
          \      7 request = \"\u0427\u0435\u043B\u043E\u0432\u0435\u043A: \u0421\u043A\
          \u043E\u043B\u044C\u043A\u043E \u0432\u0435\u0441\u0438\u0442 \u0436\u0438\
          \u0440\u0430\u0444? \u041F\u043E\u043C\u043E\u0449\u043D\u0438\u043A: \"\
          </p>\n<p>TypeError: from_pretrained() missing 1 required positional argument:\
          \ 'quantize_config'</p>\n"
        raw: "\u041E\u0448\u0438\u0431\u043A\u0430 from_pretrained() missing 1 required\
          \ positional argument: 'quantize_config'\n\npython 3.9.6\ntransformers 4.3.1\n\
          auto_gptq 0.3.1\n\nTypeError                                 Traceback (most\
          \ recent call last)\nCell In[7], line 4\n      1 from transformers import\
          \ AutoTokenizer\n      2 from auto_gptq import AutoGPTQForCausalLM\n---->\
          \ 4 model = AutoGPTQForCausalLM.from_pretrained('Gaivoronsky/ruGPT-3.5-13B-8bit',\
          \ device=\"cuda:0\", use_triton=False)\n      5 tokenizer = AutoTokenizer.from_pretrained('Gaivoronsky/ruGPT-3.5-13B-8bit')\n\
          \      7 request = \"\u0427\u0435\u043B\u043E\u0432\u0435\u043A: \u0421\u043A\
          \u043E\u043B\u044C\u043A\u043E \u0432\u0435\u0441\u0438\u0442 \u0436\u0438\
          \u0440\u0430\u0444? \u041F\u043E\u043C\u043E\u0449\u043D\u0438\u043A: \"\
          \n\nTypeError: from_pretrained() missing 1 required positional argument:\
          \ 'quantize_config'"
        updatedAt: '2023-08-16T14:23:39.225Z'
      numEdits: 1
      reactions: []
    id: 64dcdbb33fe31a792a4ef281
    type: comment
  author: axone
  content: "\u041E\u0448\u0438\u0431\u043A\u0430 from_pretrained() missing 1 required\
    \ positional argument: 'quantize_config'\n\npython 3.9.6\ntransformers 4.3.1\n\
    auto_gptq 0.3.1\n\nTypeError                                 Traceback (most recent\
    \ call last)\nCell In[7], line 4\n      1 from transformers import AutoTokenizer\n\
    \      2 from auto_gptq import AutoGPTQForCausalLM\n----> 4 model = AutoGPTQForCausalLM.from_pretrained('Gaivoronsky/ruGPT-3.5-13B-8bit',\
    \ device=\"cuda:0\", use_triton=False)\n      5 tokenizer = AutoTokenizer.from_pretrained('Gaivoronsky/ruGPT-3.5-13B-8bit')\n\
    \      7 request = \"\u0427\u0435\u043B\u043E\u0432\u0435\u043A: \u0421\u043A\u043E\
    \u043B\u044C\u043A\u043E \u0432\u0435\u0441\u0438\u0442 \u0436\u0438\u0440\u0430\
    \u0444? \u041F\u043E\u043C\u043E\u0449\u043D\u0438\u043A: \"\n\nTypeError: from_pretrained()\
    \ missing 1 required positional argument: 'quantize_config'"
  created_at: 2023-08-16 13:22:43+00:00
  edited: true
  hidden: false
  id: 64dcdbb33fe31a792a4ef281
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60952c7b7db4b0477bb1d4f1/cERjHvTQI8VmKY04UpCik.jpeg?w=200&h=200&f=face
      fullname: Alexander Gaivoronsky
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Gaivoronsky
      type: user
    createdAt: '2023-08-18T14:17:04.000Z'
    data:
      edited: false
      editors:
      - Gaivoronsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.19677695631980896
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60952c7b7db4b0477bb1d4f1/cERjHvTQI8VmKY04UpCik.jpeg?w=200&h=200&f=face
          fullname: Alexander Gaivoronsky
          isHf: false
          isPro: false
          name: Gaivoronsky
          type: user
        html: '<p>Try updating auto-gptq</p>

          <pre><code class="language-shell">pip install auto-gptq -U

          </code></pre>

          '
        raw: 'Try updating auto-gptq

          ```shell

          pip install auto-gptq -U

          ```'
        updatedAt: '2023-08-18T14:17:04.653Z'
      numEdits: 0
      reactions: []
    id: 64df7d60e672e4d2c57b2a8e
    type: comment
  author: Gaivoronsky
  content: 'Try updating auto-gptq

    ```shell

    pip install auto-gptq -U

    ```'
  created_at: 2023-08-18 13:17:04+00:00
  edited: false
  hidden: false
  id: 64df7d60e672e4d2c57b2a8e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a32a2e358541a04e02a9f8c5c07cad1c.svg
      fullname: Ivan Zatonov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: megaroot1
      type: user
    createdAt: '2023-08-23T06:45:49.000Z'
    data:
      edited: false
      editors:
      - megaroot1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6734983921051025
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a32a2e358541a04e02a9f8c5c07cad1c.svg
          fullname: Ivan Zatonov
          isHf: false
          isPro: false
          name: megaroot1
          type: user
        html: '<p>Replacing AutoGPTQForCausalLM.from_pretrained with AutoGPTQForCausalLM.from_quantized
          helped me. Tried on python3.9 and python 3.11, auto_gptq0.3.1 and auto_gptq0.4.1(from
          source).</p>

          '
        raw: Replacing AutoGPTQForCausalLM.from_pretrained with AutoGPTQForCausalLM.from_quantized
          helped me. Tried on python3.9 and python 3.11, auto_gptq0.3.1 and auto_gptq0.4.1(from
          source).
        updatedAt: '2023-08-23T06:45:49.724Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Gaivoronsky
    id: 64e5ab1ddea9fdc57893894a
    type: comment
  author: megaroot1
  content: Replacing AutoGPTQForCausalLM.from_pretrained with AutoGPTQForCausalLM.from_quantized
    helped me. Tried on python3.9 and python 3.11, auto_gptq0.3.1 and auto_gptq0.4.1(from
    source).
  created_at: 2023-08-23 05:45:49+00:00
  edited: false
  hidden: false
  id: 64e5ab1ddea9fdc57893894a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60952c7b7db4b0477bb1d4f1/cERjHvTQI8VmKY04UpCik.jpeg?w=200&h=200&f=face
      fullname: Alexander Gaivoronsky
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Gaivoronsky
      type: user
    createdAt: '2023-08-23T10:16:08.000Z'
    data:
      status: closed
    id: 64e5dc68200adc78c1641f0e
    type: status-change
  author: Gaivoronsky
  created_at: 2023-08-23 09:16:08+00:00
  id: 64e5dc68200adc78c1641f0e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Gaivoronsky/ruGPT-3.5-13B-8bit
repo_type: model
status: closed
target_branch: null
title: "\u041F\u0440\u0438\u043B\u043E\u0436\u0435\u043D\u043D\u044B\u0439 \u043F\u0440\
  \u0438\u043C\u0435\u0440 \u043D\u0435 \u0437\u0430\u043F\u0443\u0441\u043A\u0430\
  \u0435\u0442\u0441\u044F"
