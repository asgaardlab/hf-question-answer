!!python/object:huggingface_hub.community.DiscussionWithDetails
author: DORA1222
conflicting_files: []
created_at: 2023-08-02 12:07:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/73ad6f2142b50f1603ffe0b0f2426b61.svg
      fullname: DORA.Zhao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DORA1222
      type: user
    createdAt: '2023-08-02T13:07:03.000Z'
    data:
      edited: false
      editors:
      - DORA1222
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/73ad6f2142b50f1603ffe0b0f2426b61.svg
          fullname: DORA.Zhao
          isHf: false
          isPro: false
          name: DORA1222
          type: user
        html: ''
        raw: ''
        updatedAt: '2023-08-02T13:07:03.023Z'
      numEdits: 0
      reactions: []
    id: 64ca54f7d469fc2cf816a6d4
    type: comment
  author: DORA1222
  content: ''
  created_at: 2023-08-02 12:07:03+00:00
  edited: false
  hidden: false
  id: 64ca54f7d469fc2cf816a6d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/648c64829c935db2b527a764/AnTu1dvpac3hUxLQo8A8K.jpeg?w=200&h=200&f=face
      fullname: Xin Lv
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: davidlvxin
      type: user
    createdAt: '2023-08-03T03:02:34.000Z'
    data:
      status: closed
    id: 64cb18ca917267433618dfb5
    type: status-change
  author: davidlvxin
  created_at: 2023-08-03 02:02:34+00:00
  id: 64cb18ca917267433618dfb5
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cca57044c5bddeb590ba1ac96f176310.svg
      fullname: Zhiqiang Yin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HNYZQ
      type: user
    createdAt: '2023-09-15T03:46:00.000Z'
    data:
      edited: false
      editors:
      - HNYZQ
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.3015410006046295
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cca57044c5bddeb590ba1ac96f176310.svg
          fullname: Zhiqiang Yin
          isHf: false
          isPro: false
          name: HNYZQ
          type: user
        html: "<p>\u95EE\u9898\uFF1A</p>\n<p>\u542F\u52A8chatglm2-6b-32\u6A21\u578B\
          \uFF0C\u4F7F\u7528load_model_on_gpus\u52A0\u8F7D\u4E86\u4E09\u5F20\u5361\
          \u3002\u5728\u63A8\u7406\u65F6\u51FA\u73B0\u4E86\u9519\u8BEF\uFF1A</p>\n\
          <p> File \"/home/nmnormal1/.cache/huggingface/modules/transformers_modules/chatglm2-6b-32k/modeling_chatglm.py\"\
          , line 655, in forward<br>    presents = torch.cat((presents, kv_cache),\
          \ dim=0)<br>RuntimeError: Expected all tensors to be on the same device,\
          \ but found at least two devices, cuda:0 and cuda:1! (when checking argument\
          \ for argument tensors in method wrapper_CUDA_cat)</p>\n<p>\u81EA\u5DF1\u80FD\
          \u64CD\u4F5C\u7684\u4EE3\u7801\u51FA\u9519\u4F4D\u7F6E\u662F\uFF1A<br>for\
          \ response, history, past_key_values in model.stream_chat(tokenizer, query,\
          \ history=history,<br>                                                 \
          \                   past_key_values=past_key_values,<br>               \
          \                                                     return_past_key_values=True):</p>\n\
          <p>\u89E3\u51B3\uFF1A</p>\n<p>\u628A6b-32k\u7684\u6A21\u578B\u6362\u6210\
          chatglm2-6b\u6A21\u578B\u540E\uFF0C\u540C\u6837\u7684\u4EE3\u7801\u4E0D\u51FA\
          \u9519\u3002\u56E0\u6B64\u6000\u7591\u662F32k\u7684modeling_chatglm.py\u6587\
          \u4EF6\u6709\u95EE\u9898\uFF0C\u53EFtrust_remote_code\u7684\u5B58\u5728\u6211\
          \u4E5F\u6539\u4E0D\u4E86diamagnetic\uFF0C\u7279\u6765\u6C42\u52A9\uFF01\uFF01\
          \uFF01</p>\n"
        raw: "\u95EE\u9898\uFF1A\n\n\u542F\u52A8chatglm2-6b-32\u6A21\u578B\uFF0C\u4F7F\
          \u7528load_model_on_gpus\u52A0\u8F7D\u4E86\u4E09\u5F20\u5361\u3002\u5728\
          \u63A8\u7406\u65F6\u51FA\u73B0\u4E86\u9519\u8BEF\uFF1A\n\n File \"/home/nmnormal1/.cache/huggingface/modules/transformers_modules/chatglm2-6b-32k/modeling_chatglm.py\"\
          , line 655, in forward\n    presents = torch.cat((presents, kv_cache), dim=0)\n\
          RuntimeError: Expected all tensors to be on the same device, but found at\
          \ least two devices, cuda:0 and cuda:1! (when checking argument for argument\
          \ tensors in method wrapper_CUDA_cat)\n\n\u81EA\u5DF1\u80FD\u64CD\u4F5C\u7684\
          \u4EE3\u7801\u51FA\u9519\u4F4D\u7F6E\u662F\uFF1A\nfor response, history,\
          \ past_key_values in model.stream_chat(tokenizer, query, history=history,\n\
          \                                                                    past_key_values=past_key_values,\n\
          \                                                                    return_past_key_values=True):\n\
          \n\u89E3\u51B3\uFF1A\n\n\u628A6b-32k\u7684\u6A21\u578B\u6362\u6210chatglm2-6b\u6A21\
          \u578B\u540E\uFF0C\u540C\u6837\u7684\u4EE3\u7801\u4E0D\u51FA\u9519\u3002\
          \u56E0\u6B64\u6000\u7591\u662F32k\u7684modeling_chatglm.py\u6587\u4EF6\u6709\
          \u95EE\u9898\uFF0C\u53EFtrust_remote_code\u7684\u5B58\u5728\u6211\u4E5F\u6539\
          \u4E0D\u4E86diamagnetic\uFF0C\u7279\u6765\u6C42\u52A9\uFF01\uFF01\uFF01"
        updatedAt: '2023-09-15T03:46:00.860Z'
      numEdits: 0
      reactions: []
    id: 6503d378c0620ed4bd1bd1bf
    type: comment
  author: HNYZQ
  content: "\u95EE\u9898\uFF1A\n\n\u542F\u52A8chatglm2-6b-32\u6A21\u578B\uFF0C\u4F7F\
    \u7528load_model_on_gpus\u52A0\u8F7D\u4E86\u4E09\u5F20\u5361\u3002\u5728\u63A8\
    \u7406\u65F6\u51FA\u73B0\u4E86\u9519\u8BEF\uFF1A\n\n File \"/home/nmnormal1/.cache/huggingface/modules/transformers_modules/chatglm2-6b-32k/modeling_chatglm.py\"\
    , line 655, in forward\n    presents = torch.cat((presents, kv_cache), dim=0)\n\
    RuntimeError: Expected all tensors to be on the same device, but found at least\
    \ two devices, cuda:0 and cuda:1! (when checking argument for argument tensors\
    \ in method wrapper_CUDA_cat)\n\n\u81EA\u5DF1\u80FD\u64CD\u4F5C\u7684\u4EE3\u7801\
    \u51FA\u9519\u4F4D\u7F6E\u662F\uFF1A\nfor response, history, past_key_values in\
    \ model.stream_chat(tokenizer, query, history=history,\n                     \
    \                                               past_key_values=past_key_values,\n\
    \                                                                    return_past_key_values=True):\n\
    \n\u89E3\u51B3\uFF1A\n\n\u628A6b-32k\u7684\u6A21\u578B\u6362\u6210chatglm2-6b\u6A21\
    \u578B\u540E\uFF0C\u540C\u6837\u7684\u4EE3\u7801\u4E0D\u51FA\u9519\u3002\u56E0\
    \u6B64\u6000\u7591\u662F32k\u7684modeling_chatglm.py\u6587\u4EF6\u6709\u95EE\u9898\
    \uFF0C\u53EFtrust_remote_code\u7684\u5B58\u5728\u6211\u4E5F\u6539\u4E0D\u4E86\
    diamagnetic\uFF0C\u7279\u6765\u6C42\u52A9\uFF01\uFF01\uFF01"
  created_at: 2023-09-15 02:46:00+00:00
  edited: false
  hidden: false
  id: 6503d378c0620ed4bd1bd1bf
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 1
repo_id: THUDM/chatglm2-6b-32k
repo_type: model
status: closed
target_branch: refs/heads/main
title: "\u6211\u95EE\u95EE"
