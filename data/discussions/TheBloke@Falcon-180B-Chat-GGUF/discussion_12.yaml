!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Althenwolf
conflicting_files: null
created_at: 2023-10-06 07:41:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/06c6881d1f39bdac2c5d2cda7ff72168.svg
      fullname: Martin Perez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Althenwolf
      type: user
    createdAt: '2023-10-06T08:41:03.000Z'
    data:
      edited: false
      editors:
      - Althenwolf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8282189965248108
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/06c6881d1f39bdac2c5d2cda7ff72168.svg
          fullname: Martin Perez
          isHf: false
          isPro: false
          name: Althenwolf
          type: user
        html: '<p>Hi every one. I have downloaded the different splits of the falcon-180b-chat.Q5_K_S.gguf-split-*
          model. Once downloaded I have joined them with: </p>

          <p>cat falcon-180b-chat.Q5_K_S.gguf-split-* &gt; /workvols/data2/mpperez3/projects/llama_cpp/llama.cpp/models/falcon-180b-chat.Q5_K_S.gguf</p>

          <p>However when I try to use the model I get the error:</p>

          <p>error loading model: invalid character<br>llama_load_model_from_file:
          failed to load model<br>llama_init_from_gpt_params: error: failed to load
          model ''../../models/falcon-180b-chat.Q5_K_S.gguf''</p>

          <p>I have tried with other models (without split) and they all work correctly
          with the same command. However with this one it is not possible. Does anyone
          know where the problem could be?</p>

          '
        raw: "Hi every one. I have downloaded the different splits of the falcon-180b-chat.Q5_K_S.gguf-split-*\
          \ model. Once downloaded I have joined them with: \r\n\r\ncat falcon-180b-chat.Q5_K_S.gguf-split-*\
          \ > /workvols/data2/mpperez3/projects/llama_cpp/llama.cpp/models/falcon-180b-chat.Q5_K_S.gguf\r\
          \n\r\nHowever when I try to use the model I get the error:\r\n\r\nerror\
          \ loading model: invalid character\r\nllama_load_model_from_file: failed\
          \ to load model\r\nllama_init_from_gpt_params: error: failed to load model\
          \ '../../models/falcon-180b-chat.Q5_K_S.gguf'\r\n\r\nI have tried with other\
          \ models (without split) and they all work correctly with the same command.\
          \ However with this one it is not possible. Does anyone know where the problem\
          \ could be?\r\n\r\n"
        updatedAt: '2023-10-06T08:41:03.681Z'
      numEdits: 0
      reactions: []
    id: 651fc81f0bb29b2f4edaf413
    type: comment
  author: Althenwolf
  content: "Hi every one. I have downloaded the different splits of the falcon-180b-chat.Q5_K_S.gguf-split-*\
    \ model. Once downloaded I have joined them with: \r\n\r\ncat falcon-180b-chat.Q5_K_S.gguf-split-*\
    \ > /workvols/data2/mpperez3/projects/llama_cpp/llama.cpp/models/falcon-180b-chat.Q5_K_S.gguf\r\
    \n\r\nHowever when I try to use the model I get the error:\r\n\r\nerror loading\
    \ model: invalid character\r\nllama_load_model_from_file: failed to load model\r\
    \nllama_init_from_gpt_params: error: failed to load model '../../models/falcon-180b-chat.Q5_K_S.gguf'\r\
    \n\r\nI have tried with other models (without split) and they all work correctly\
    \ with the same command. However with this one it is not possible. Does anyone\
    \ know where the problem could be?\r\n\r\n"
  created_at: 2023-10-06 07:41:03+00:00
  edited: false
  hidden: false
  id: 651fc81f0bb29b2f4edaf413
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4e3b34f0605e6e2c9b5c5beb1a9c192f.svg
      fullname: Xiao Jin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mljxy
      type: user
    createdAt: '2023-10-06T20:38:39.000Z'
    data:
      edited: false
      editors:
      - mljxy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9326709508895874
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4e3b34f0605e6e2c9b5c5beb1a9c192f.svg
          fullname: Xiao Jin
          isHf: false
          isPro: false
          name: mljxy
          type: user
        html: '<p>yeah, something with the new llama.cpp since a couple of days ago</p>

          '
        raw: yeah, something with the new llama.cpp since a couple of days ago
        updatedAt: '2023-10-06T20:38:39.482Z'
      numEdits: 0
      reactions: []
    id: 6520704fcfbef01dc77145ac
    type: comment
  author: mljxy
  content: yeah, something with the new llama.cpp since a couple of days ago
  created_at: 2023-10-06 19:38:39+00:00
  edited: false
  hidden: false
  id: 6520704fcfbef01dc77145ac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/06c6881d1f39bdac2c5d2cda7ff72168.svg
      fullname: Martin Perez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Althenwolf
      type: user
    createdAt: '2023-10-09T08:10:39.000Z'
    data:
      edited: false
      editors:
      - Althenwolf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9359334111213684
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/06c6881d1f39bdac2c5d2cda7ff72168.svg
          fullname: Martin Perez
          isHf: false
          isPro: false
          name: Althenwolf
          type: user
        html: '<p>Indeed, the problem is with llama.cpp main. I ran the model from
          python with the llama.cpp library and everything worked without problems.
          Many Thanks!</p>

          '
        raw: Indeed, the problem is with llama.cpp main. I ran the model from python
          with the llama.cpp library and everything worked without problems. Many
          Thanks!
        updatedAt: '2023-10-09T08:10:39.409Z'
      numEdits: 0
      reactions: []
    id: 6523b57ff6ceb915ccbc8079
    type: comment
  author: Althenwolf
  content: Indeed, the problem is with llama.cpp main. I ran the model from python
    with the llama.cpp library and everything worked without problems. Many Thanks!
  created_at: 2023-10-09 07:10:39+00:00
  edited: false
  hidden: false
  id: 6523b57ff6ceb915ccbc8079
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4e3b34f0605e6e2c9b5c5beb1a9c192f.svg
      fullname: Xiao Jin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mljxy
      type: user
    createdAt: '2023-10-09T15:25:36.000Z'
    data:
      edited: false
      editors:
      - mljxy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8143152594566345
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4e3b34f0605e6e2c9b5c5beb1a9c192f.svg
          fullname: Xiao Jin
          isHf: false
          isPro: false
          name: mljxy
          type: user
        html: '<p>The files needs to be converted again: <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/issues/3484">https://github.com/ggerganov/llama.cpp/issues/3484</a></p>

          '
        raw: 'The files needs to be converted again: https://github.com/ggerganov/llama.cpp/issues/3484'
        updatedAt: '2023-10-09T15:25:36.943Z'
      numEdits: 0
      reactions: []
    id: 65241b70a9a710554b0bf514
    type: comment
  author: mljxy
  content: 'The files needs to be converted again: https://github.com/ggerganov/llama.cpp/issues/3484'
  created_at: 2023-10-09 14:25:36+00:00
  edited: false
  hidden: false
  id: 65241b70a9a710554b0bf514
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f0e3e000e3f772473c53217eaa5e626b.svg
      fullname: cameron bergh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cameronbergh
      type: user
    createdAt: '2023-10-19T01:23:00.000Z'
    data:
      edited: true
      editors:
      - cameronbergh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9426183700561523
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f0e3e000e3f772473c53217eaa5e626b.svg
          fullname: cameron bergh
          isHf: false
          isPro: false
          name: cameronbergh
          type: user
        html: '<p>i have converted it and am reuploading </p>

          <p>EDIT: nvm. blokes on it.</p>

          '
        raw: "i have converted it and am reuploading \n\nEDIT: nvm. blokes on it."
        updatedAt: '2023-10-19T02:26:17.981Z'
      numEdits: 1
      reactions: []
    id: 653084f4c2f20ed637fb77ae
    type: comment
  author: cameronbergh
  content: "i have converted it and am reuploading \n\nEDIT: nvm. blokes on it."
  created_at: 2023-10-19 00:23:00+00:00
  edited: true
  hidden: false
  id: 653084f4c2f20ed637fb77ae
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-10-19T01:31:11.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9805315732955933
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Thanks for the report, I''ve triggered a re-build of the GGUF models,
          they''ll re-upload over the next few hours</p>

          '
        raw: Thanks for the report, I've triggered a re-build of the GGUF models,
          they'll re-upload over the next few hours
        updatedAt: '2023-10-19T01:31:11.976Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mljxy
    id: 653086df2168c2bddd3aedc2
    type: comment
  author: TheBloke
  content: Thanks for the report, I've triggered a re-build of the GGUF models, they'll
    re-upload over the next few hours
  created_at: 2023-10-19 00:31:11+00:00
  edited: false
  hidden: false
  id: 653086df2168c2bddd3aedc2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-10-19T11:43:44.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9620193243026733
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Re-made GGUFs have been uploading for the last 30 mins or so, and
          will finish in an hour or two. I''ve confirmed the new GGUFs work fine with
          latest llama.cpp.</p>

          <p>I''ll do Falcon 180B after that</p>

          '
        raw: 'Re-made GGUFs have been uploading for the last 30 mins or so, and will
          finish in an hour or two. I''ve confirmed the new GGUFs work fine with latest
          llama.cpp.


          I''ll do Falcon 180B after that'
        updatedAt: '2023-10-19T11:44:17.326Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Althenwolf
    id: 653116704173faa82270a798
    type: comment
  author: TheBloke
  content: 'Re-made GGUFs have been uploading for the last 30 mins or so, and will
    finish in an hour or two. I''ve confirmed the new GGUFs work fine with latest
    llama.cpp.


    I''ll do Falcon 180B after that'
  created_at: 2023-10-19 10:43:44+00:00
  edited: true
  hidden: false
  id: 653116704173faa82270a798
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: TheBloke/Falcon-180B-Chat-GGUF
repo_type: model
status: open
target_branch: null
title: 'error loading model: invalid character executing joined splited files'
