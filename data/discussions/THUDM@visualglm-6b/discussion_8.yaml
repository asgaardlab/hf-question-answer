!!python/object:huggingface_hub.community.DiscussionWithDetails
author: LittleGreen
conflicting_files: null
created_at: 2023-10-29 23:57:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ca0dba064df511e347d19dde0918ec15.svg
      fullname: Yuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LittleGreen
      type: user
    createdAt: '2023-10-30T00:57:59.000Z'
    data:
      edited: false
      editors:
      - LittleGreen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3731772005558014
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ca0dba064df511e347d19dde0918ec15.svg
          fullname: Yuan
          isHf: false
          isPro: false
          name: LittleGreen
          type: user
        html: '<p>After downloading the model via LFS, I changed the path to local
          according to the demo in the README, but the following error occurs when
          loading the Tokenizer:<br>''''''<br>Traceback (most recent call last):<br>  File
          "demo.py", line 4, in <br>    tokenizer = AutoTokenizer.from_pretrained(ModelPATH,
          trust_remote_code=True)<br>  File "/root/miniconda3/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py",
          line 738, in from_pretrained<br>    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,
          *inputs, **kwargs)<br>  File "/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py",
          line 2017, in from_pretrained<br>    return cls._from_pretrained(<br>  File
          "/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py",
          line 2249, in _from_pretrained<br>    tokenizer = cls(*init_inputs, **init_kwargs)<br>  File
          "/root/.cache/huggingface/modules/transformers_modules/visualglm-6b/tokenization_chatglm.py",
          line 196, in <strong>init</strong><br>    super().<strong>init</strong>(<br>  File
          "/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py",
          line 367, in <strong>init</strong><br>    self._add_tokens(<br>  File "/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py",
          line 467, in _add_tokens<br>    current_vocab = self.get_vocab().copy()<br>  File
          "/root/.cache/huggingface/modules/transformers_modules/visualglm-6b/tokenization_chatglm.py",
          line 248, in get_vocab<br>    vocab = {self._convert_id_to_token(i): i for
          i in range(self.vocab_size)}<br>  File "/root/.cache/huggingface/modules/transformers_modules/visualglm-6b/tokenization_chatglm.py",
          line 244, in vocab_size<br>    return self.sp_tokenizer.num_tokens<br>AttributeError:
          ''ChatGLMTokenizer'' object has no attribute ''sp_tokenizer''<br>''''''</p>

          '
        raw: "After downloading the model via LFS, I changed the path to local according\
          \ to the demo in the README, but the following error occurs when loading\
          \ the Tokenizer:\r\n'''\r\nTraceback (most recent call last):\r\n  File\
          \ \"demo.py\", line 4, in <module>\r\n    tokenizer = AutoTokenizer.from_pretrained(ModelPATH,\
          \ trust_remote_code=True)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 738, in from_pretrained\r\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2017, in from_pretrained\r\n    return cls._from_pretrained(\r\n\
          \  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2249, in _from_pretrained\r\n    tokenizer = cls(*init_inputs, **init_kwargs)\r\
          \n  File \"/root/.cache/huggingface/modules/transformers_modules/visualglm-6b/tokenization_chatglm.py\"\
          , line 196, in __init__\r\n    super().__init__(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\"\
          , line 367, in __init__\r\n    self._add_tokens(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\"\
          , line 467, in _add_tokens\r\n    current_vocab = self.get_vocab().copy()\r\
          \n  File \"/root/.cache/huggingface/modules/transformers_modules/visualglm-6b/tokenization_chatglm.py\"\
          , line 248, in get_vocab\r\n    vocab = {self._convert_id_to_token(i): i\
          \ for i in range(self.vocab_size)}\r\n  File \"/root/.cache/huggingface/modules/transformers_modules/visualglm-6b/tokenization_chatglm.py\"\
          , line 244, in vocab_size\r\n    return self.sp_tokenizer.num_tokens\r\n\
          AttributeError: 'ChatGLMTokenizer' object has no attribute 'sp_tokenizer'\r\
          \n'''"
        updatedAt: '2023-10-30T00:57:59.038Z'
      numEdits: 0
      reactions: []
    id: 653eff9706a7bb4b1da5fc8d
    type: comment
  author: LittleGreen
  content: "After downloading the model via LFS, I changed the path to local according\
    \ to the demo in the README, but the following error occurs when loading the Tokenizer:\r\
    \n'''\r\nTraceback (most recent call last):\r\n  File \"demo.py\", line 4, in\
    \ <module>\r\n    tokenizer = AutoTokenizer.from_pretrained(ModelPATH, trust_remote_code=True)\r\
    \n  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py\"\
    , line 738, in from_pretrained\r\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
    \ *inputs, **kwargs)\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2017, in from_pretrained\r\n    return cls._from_pretrained(\r\n  File\
    \ \"/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2249, in _from_pretrained\r\n    tokenizer = cls(*init_inputs, **init_kwargs)\r\
    \n  File \"/root/.cache/huggingface/modules/transformers_modules/visualglm-6b/tokenization_chatglm.py\"\
    , line 196, in __init__\r\n    super().__init__(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\"\
    , line 367, in __init__\r\n    self._add_tokens(\r\n  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils.py\"\
    , line 467, in _add_tokens\r\n    current_vocab = self.get_vocab().copy()\r\n\
    \  File \"/root/.cache/huggingface/modules/transformers_modules/visualglm-6b/tokenization_chatglm.py\"\
    , line 248, in get_vocab\r\n    vocab = {self._convert_id_to_token(i): i for i\
    \ in range(self.vocab_size)}\r\n  File \"/root/.cache/huggingface/modules/transformers_modules/visualglm-6b/tokenization_chatglm.py\"\
    , line 244, in vocab_size\r\n    return self.sp_tokenizer.num_tokens\r\nAttributeError:\
    \ 'ChatGLMTokenizer' object has no attribute 'sp_tokenizer'\r\n'''"
  created_at: 2023-10-29 23:57:59+00:00
  edited: false
  hidden: false
  id: 653eff9706a7bb4b1da5fc8d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ca0dba064df511e347d19dde0918ec15.svg
      fullname: Yuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LittleGreen
      type: user
    createdAt: '2023-10-30T01:21:07.000Z'
    data:
      edited: false
      editors:
      - LittleGreen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9648301005363464
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ca0dba064df511e347d19dde0918ec15.svg
          fullname: Yuan
          isHf: false
          isPro: false
          name: LittleGreen
          type: user
        html: '<p>alright I solved this just now, by reinstall 4.27.1 transformers,
          problem here in my environment can be solved.<br>I solved the problem by
          following your method, thank you!</p>

          '
        raw: 'alright I solved this just now, by reinstall 4.27.1 transformers, problem
          here in my environment can be solved.

          I solved the problem by following your method, thank you!'
        updatedAt: '2023-10-30T01:21:07.741Z'
      numEdits: 0
      reactions: []
      relatedEventId: 653f0504ca6e5875c4eb6fa3
    id: 653f0503ca6e5875c4eb6f97
    type: comment
  author: LittleGreen
  content: 'alright I solved this just now, by reinstall 4.27.1 transformers, problem
    here in my environment can be solved.

    I solved the problem by following your method, thank you!'
  created_at: 2023-10-30 00:21:07+00:00
  edited: false
  hidden: false
  id: 653f0503ca6e5875c4eb6f97
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/ca0dba064df511e347d19dde0918ec15.svg
      fullname: Yuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LittleGreen
      type: user
    createdAt: '2023-10-30T01:21:08.000Z'
    data:
      status: closed
    id: 653f0504ca6e5875c4eb6fa3
    type: status-change
  author: LittleGreen
  created_at: 2023-10-30 00:21:08+00:00
  id: 653f0504ca6e5875c4eb6fa3
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: THUDM/visualglm-6b
repo_type: model
status: closed
target_branch: null
title: Error while loading Tokenizer
