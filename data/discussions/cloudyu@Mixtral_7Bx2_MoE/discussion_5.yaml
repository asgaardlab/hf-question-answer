!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tanganke
conflicting_files: null
created_at: 2024-01-12 09:05:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/402a632aa770e342ceae9e2a29d33e16.svg
      fullname: Anke Tang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tanganke
      type: user
    createdAt: '2024-01-12T09:05:53.000Z'
    data:
      edited: true
      editors:
      - tanganke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9620415568351746
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/402a632aa770e342ceae9e2a29d33e16.svg
          fullname: Anke Tang
          isHf: false
          isPro: false
          name: tanganke
          type: user
        html: '<p>Great model. I wonder  know how did you get the weights for the
          MoE routers?</p>

          '
        raw: Great model. I wonder  know how did you get the weights for the MoE routers?
        updatedAt: '2024-01-12T09:06:49.607Z'
      numEdits: 1
      reactions: []
    id: 65a100f1e96941538119c409
    type: comment
  author: tanganke
  content: Great model. I wonder  know how did you get the weights for the MoE routers?
  created_at: 2024-01-12 09:05:53+00:00
  edited: true
  hidden: false
  id: 65a100f1e96941538119c409
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64618bc5cf638aa8f856137c/zbUqrIeHjz41P3O2b3eey.jpeg?w=200&h=200&f=face
      fullname: hai
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: cloudyu
      type: user
    createdAt: '2024-01-12T09:54:14.000Z'
    data:
      edited: false
      editors:
      - cloudyu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9801580309867859
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64618bc5cf638aa8f856137c/zbUqrIeHjz41P3O2b3eey.jpeg?w=200&h=200&f=face
          fullname: hai
          isHf: false
          isPro: false
          name: cloudyu
          type: user
        html: '<p>don''t need fine-tune, because only two experts</p>

          '
        raw: don't need fine-tune, because only two experts
        updatedAt: '2024-01-12T09:54:14.818Z'
      numEdits: 0
      reactions: []
    id: 65a10c4644d2a6d6fbd1ebd1
    type: comment
  author: cloudyu
  content: don't need fine-tune, because only two experts
  created_at: 2024-01-12 09:54:14+00:00
  edited: false
  hidden: false
  id: 65a10c4644d2a6d6fbd1ebd1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/402a632aa770e342ceae9e2a29d33e16.svg
      fullname: Anke Tang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tanganke
      type: user
    createdAt: '2024-01-12T10:04:49.000Z'
    data:
      edited: false
      editors:
      - tanganke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6495599150657654
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/402a632aa770e342ceae9e2a29d33e16.svg
          fullname: Anke Tang
          isHf: false
          isPro: false
          name: tanganke
          type: user
        html: "<p>Thanks for your time! </p>\n<p>I am also trying to construct a MoE\
          \ model like this using mergekit.<br>The configuration needs to specify\
          \ a base model and positive prompts. How did you set these?</p>\n<pre><code\
          \ class=\"language-yaml\"><span class=\"hljs-attr\">base_model:</span> <span\
          \ class=\"hljs-string\">???</span>\n<span class=\"hljs-attr\">gate_mode:</span>\
          \ <span class=\"hljs-string\">hidden</span>\n<span class=\"hljs-attr\">dtype:</span>\
          \ <span class=\"hljs-string\">float32</span>\n\n<span class=\"hljs-attr\"\
          >experts:</span>\n  <span class=\"hljs-bullet\">-</span> <span class=\"\
          hljs-attr\">source_model:</span> <span class=\"hljs-string\">NurtureAI/neural-chat-7b-v3-16k</span>\
          \ <span class=\"hljs-comment\"># https://huggingface.co/NurtureAI/neural-chat-7b-v3-16k</span>\n\
          \    <span class=\"hljs-attr\">positive_prompts:</span>\n      <span class=\"\
          hljs-bullet\">-</span> <span class=\"hljs-string\">\"???\"</span>\n    <span\
          \ class=\"hljs-comment\">#   (optional)</span>\n    <span class=\"hljs-comment\"\
          ># negative_prompts:</span>\n    <span class=\"hljs-comment\">#   - \"This\
          \ is a prompt expert_model_1 should not be used for\"</span>\n  <span class=\"\
          hljs-bullet\">-</span> <span class=\"hljs-attr\">source_model:</span> <span\
          \ class=\"hljs-string\">mncai/mistral-7b-dpo-v6</span> <span class=\"hljs-comment\"\
          ># https://huggingface.co/mncai/mistral-7b-dpo-v6</span>\n    <span class=\"\
          hljs-attr\">positive_prompts:</span>\n      <span class=\"hljs-bullet\"\
          >-</span> <span class=\"hljs-string\">\"???\"</span>\n</code></pre>\n"
        raw: "Thanks for your time! \n\nI am also trying to construct a MoE model\
          \ like this using mergekit. \nThe configuration needs to specify a base\
          \ model and positive prompts. How did you set these?\n\n```yaml\nbase_model:\
          \ ???\ngate_mode: hidden\ndtype: float32\n\nexperts:\n  - source_model:\
          \ NurtureAI/neural-chat-7b-v3-16k # https://huggingface.co/NurtureAI/neural-chat-7b-v3-16k\n\
          \    positive_prompts:\n      - \"???\"\n    #   (optional)\n    # negative_prompts:\n\
          \    #   - \"This is a prompt expert_model_1 should not be used for\"\n\
          \  - source_model: mncai/mistral-7b-dpo-v6 # https://huggingface.co/mncai/mistral-7b-dpo-v6\n\
          \    positive_prompts:\n      - \"???\"\n```"
        updatedAt: '2024-01-12T10:04:49.460Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MaziyarPanahi
    id: 65a10ec119665f7549841519
    type: comment
  author: tanganke
  content: "Thanks for your time! \n\nI am also trying to construct a MoE model like\
    \ this using mergekit. \nThe configuration needs to specify a base model and positive\
    \ prompts. How did you set these?\n\n```yaml\nbase_model: ???\ngate_mode: hidden\n\
    dtype: float32\n\nexperts:\n  - source_model: NurtureAI/neural-chat-7b-v3-16k\
    \ # https://huggingface.co/NurtureAI/neural-chat-7b-v3-16k\n    positive_prompts:\n\
    \      - \"???\"\n    #   (optional)\n    # negative_prompts:\n    #   - \"This\
    \ is a prompt expert_model_1 should not be used for\"\n  - source_model: mncai/mistral-7b-dpo-v6\
    \ # https://huggingface.co/mncai/mistral-7b-dpo-v6\n    positive_prompts:\n  \
    \    - \"???\"\n```"
  created_at: 2024-01-12 10:04:49+00:00
  edited: false
  hidden: false
  id: 65a10ec119665f7549841519
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64618bc5cf638aa8f856137c/zbUqrIeHjz41P3O2b3eey.jpeg?w=200&h=200&f=face
      fullname: hai
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: cloudyu
      type: user
    createdAt: '2024-01-12T10:15:05.000Z'
    data:
      edited: true
      editors:
      - cloudyu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8791674375534058
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64618bc5cf638aa8f856137c/zbUqrIeHjz41P3O2b3eey.jpeg?w=200&h=200&f=face
          fullname: hai
          isHf: false
          isPro: false
          name: cloudyu
          type: user
        html: '<p>You have to try every candidate and then locally test the model
          performance by <a rel="nofollow" href="https://github.com/EleutherAI/lm-evaluation-harness">https://github.com/EleutherAI/lm-evaluation-harness</a>.<br>I
          use hellaswag metric only and some manual testing.<br>You will find the
          best setting sooner or later.<br>Good luck!</p>

          '
        raw: 'You have to try every candidate and then locally test the model performance
          by https://github.com/EleutherAI/lm-evaluation-harness.

          I use hellaswag metric only and some manual testing.

          You will find the best setting sooner or later.

          Good luck!'
        updatedAt: '2024-01-12T10:16:58.256Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - MaziyarPanahi
    id: 65a11129e9694153811f81af
    type: comment
  author: cloudyu
  content: 'You have to try every candidate and then locally test the model performance
    by https://github.com/EleutherAI/lm-evaluation-harness.

    I use hellaswag metric only and some manual testing.

    You will find the best setting sooner or later.

    Good luck!'
  created_at: 2024-01-12 10:15:05+00:00
  edited: true
  hidden: false
  id: 65a11129e9694153811f81af
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: cloudyu/Mixtral_7Bx2_MoE
repo_type: model
status: open
target_branch: null
title: Do you need fine-tune after merging?
