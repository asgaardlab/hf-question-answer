!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lakkeo
conflicting_files: null
created_at: 2023-10-07 14:59:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fb3a695398913dc8eec51a73376197a6.svg
      fullname: Mehdi Challakh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lakkeo
      type: user
    createdAt: '2023-10-07T15:59:18.000Z'
    data:
      edited: false
      editors:
      - lakkeo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.845804750919342
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fb3a695398913dc8eec51a73376197a6.svg
          fullname: Mehdi Challakh
          isHf: false
          isPro: false
          name: lakkeo
          type: user
        html: '<p>Getting the "CUDA extension not installed." message when trying
          to load TheBloke models, I tried everything I''ve been on this problem for
          15 litteral hours.<br>I tested CUDA 122,121,118, installed 3 versions of
          bitsandbytes on windows, reinstalled torch in conda, pip, venv, tested different
          version combinaisons...</p>

          <p>The weird this is, I get good inference perf and no  "CUDA extension
          not installed." in ooba but i do get it everytime in Python using transformers.</p>

          <p>Please what am I missing I getting desperate and the similar tickets
          online are either outdated or too recent and all over the place...</p>

          '
        raw: "Getting the \"CUDA extension not installed.\" message when trying to\
          \ load TheBloke models, I tried everything I've been on this problem for\
          \ 15 litteral hours.\r\nI tested CUDA 122,121,118, installed 3 versions\
          \ of bitsandbytes on windows, reinstalled torch in conda, pip, venv, tested\
          \ different version combinaisons...\r\n\r\nThe weird this is, I get good\
          \ inference perf and no  \"CUDA extension not installed.\" in ooba but i\
          \ do get it everytime in Python using transformers.\r\n\r\nPlease what am\
          \ I missing I getting desperate and the similar tickets online are either\
          \ outdated or too recent and all over the place..."
        updatedAt: '2023-10-07T15:59:18.091Z'
      numEdits: 0
      reactions: []
    id: 65218056b80dc49ba002228a
    type: comment
  author: lakkeo
  content: "Getting the \"CUDA extension not installed.\" message when trying to load\
    \ TheBloke models, I tried everything I've been on this problem for 15 litteral\
    \ hours.\r\nI tested CUDA 122,121,118, installed 3 versions of bitsandbytes on\
    \ windows, reinstalled torch in conda, pip, venv, tested different version combinaisons...\r\
    \n\r\nThe weird this is, I get good inference perf and no  \"CUDA extension not\
    \ installed.\" in ooba but i do get it everytime in Python using transformers.\r\
    \n\r\nPlease what am I missing I getting desperate and the similar tickets online\
    \ are either outdated or too recent and all over the place..."
  created_at: 2023-10-07 14:59:18+00:00
  edited: false
  hidden: false
  id: 65218056b80dc49ba002228a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/Mistral-7B-Instruct-v0.1-GPTQ
repo_type: model
status: open
target_branch: null
title: CUDA extension not installed.
