!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Delcos
conflicting_files: null
created_at: 2023-08-27 21:38:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
      fullname: Devon M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delcos
      type: user
    createdAt: '2023-08-27T22:38:27.000Z'
    data:
      edited: false
      editors:
      - Delcos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9682067036628723
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
          fullname: Devon M
          isHf: false
          isPro: false
          name: Delcos
          type: user
        html: '<p>I''ve raised the concern on the ui page and in a discord channel
          but this model preforms FAR worse when in GGUF, even using the same seeds
          to the point of writing sentences and then stopping midway through and just
          adding a . I''ve made sure it wasn''t a download issue, so I''m not sure
          what would be causing the issue. I used the q6 versions for all of the tests
          on multiple models, including the GGLM version of this one.</p>

          '
        raw: I've raised the concern on the ui page and in a discord channel but this
          model preforms FAR worse when in GGUF, even using the same seeds to the
          point of writing sentences and then stopping midway through and just adding
          a . I've made sure it wasn't a download issue, so I'm not sure what would
          be causing the issue. I used the q6 versions for all of the tests on multiple
          models, including the GGLM version of this one.
        updatedAt: '2023-08-27T22:38:27.256Z'
      numEdits: 0
      reactions: []
    id: 64ebd063399f603330078ec4
    type: comment
  author: Delcos
  content: I've raised the concern on the ui page and in a discord channel but this
    model preforms FAR worse when in GGUF, even using the same seeds to the point
    of writing sentences and then stopping midway through and just adding a . I've
    made sure it wasn't a download issue, so I'm not sure what would be causing the
    issue. I used the q6 versions for all of the tests on multiple models, including
    the GGLM version of this one.
  created_at: 2023-08-27 21:38:27+00:00
  edited: false
  hidden: false
  id: 64ebd063399f603330078ec4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
      fullname: Devon M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delcos
      type: user
    createdAt: '2023-08-28T01:22:08.000Z'
    data:
      edited: false
      editors:
      - Delcos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.948028028011322
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
          fullname: Devon M
          isHf: false
          isPro: false
          name: Delcos
          type: user
        html: '<p>It''s been found to be an issue with the version of llama.cpp. oops</p>

          '
        raw: It's been found to be an issue with the version of llama.cpp. oops
        updatedAt: '2023-08-28T01:22:08.309Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64ebf6c0f494f8b2a09a6b9b
    id: 64ebf6c0f494f8b2a09a6b99
    type: comment
  author: Delcos
  content: It's been found to be an issue with the version of llama.cpp. oops
  created_at: 2023-08-28 00:22:08+00:00
  edited: false
  hidden: false
  id: 64ebf6c0f494f8b2a09a6b99
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
      fullname: Devon M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delcos
      type: user
    createdAt: '2023-08-28T01:22:08.000Z'
    data:
      status: closed
    id: 64ebf6c0f494f8b2a09a6b9b
    type: status-change
  author: Delcos
  created_at: 2023-08-28 00:22:08+00:00
  id: 64ebf6c0f494f8b2a09a6b9b
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Genz-70b-GGUF
repo_type: model
status: closed
target_branch: null
title: Doesn't work well at all.
