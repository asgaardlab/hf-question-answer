!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Sam2x
conflicting_files: null
created_at: 2023-04-07 14:23:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/08818b8a17a081a04395ae3d120a5ab6.svg
      fullname: Sam Bey
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sam2x
      type: user
    createdAt: '2023-04-07T15:23:06.000Z'
    data:
      edited: false
      editors:
      - Sam2x
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/08818b8a17a081a04395ae3d120a5ab6.svg
          fullname: Sam Bey
          isHf: false
          isPro: false
          name: Sam2x
          type: user
        html: '<p>Hi,</p>

          <p>First thank you for the effort to do this model , i think it will be
          great to generate a quantized version to test it on cpu!</p>

          <p>Best,</p>

          '
        raw: "Hi,\r\n\r\nFirst thank you for the effort to do this model , i think\
          \ it will be great to generate a quantized version to test it on cpu!\r\n\
          \r\nBest,"
        updatedAt: '2023-04-07T15:23:06.067Z'
      numEdits: 0
      reactions: []
    id: 6430355a8169f1dce23eebc4
    type: comment
  author: Sam2x
  content: "Hi,\r\n\r\nFirst thank you for the effort to do this model , i think it\
    \ will be great to generate a quantized version to test it on cpu!\r\n\r\nBest,"
  created_at: 2023-04-07 14:23:06+00:00
  edited: false
  hidden: false
  id: 6430355a8169f1dce23eebc4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ea3c8a9f178dfc1df3f75d71ecbe39dd.svg
      fullname: bofeng huang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: bofenghuang
      type: user
    createdAt: '2023-04-17T08:57:39.000Z'
    data:
      edited: false
      editors:
      - bofenghuang
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ea3c8a9f178dfc1df3f75d71ecbe39dd.svg
          fullname: bofeng huang
          isHf: false
          isPro: false
          name: bofenghuang
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Sam2x&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Sam2x\">@<span class=\"\
          underline\">Sam2x</span></a></span>\n\n\t</span></span>,</p>\n<p>Thanks\
          \ for your interest!</p>\n<p>Due to the license of the Meta LLaMA model,\
          \ the quantized merged model cannot be shared.</p>\n<p>I would recommend\
          \ reading this <a rel=\"nofollow\" href=\"https://github.com/bofenghuang/vigogne#try-it-out-on-your-own-pc\"\
          >section</a> for how to quantize it by yourself.</p>\n"
        raw: 'Hi @Sam2x,


          Thanks for your interest!


          Due to the license of the Meta LLaMA model, the quantized merged model cannot
          be shared.


          I would recommend reading this [section](https://github.com/bofenghuang/vigogne#try-it-out-on-your-own-pc)
          for how to quantize it by yourself.'
        updatedAt: '2023-04-17T08:57:39.442Z'
      numEdits: 0
      reactions: []
    id: 643d0a03af3fe078a397f0ca
    type: comment
  author: bofenghuang
  content: 'Hi @Sam2x,


    Thanks for your interest!


    Due to the license of the Meta LLaMA model, the quantized merged model cannot
    be shared.


    I would recommend reading this [section](https://github.com/bofenghuang/vigogne#try-it-out-on-your-own-pc)
    for how to quantize it by yourself.'
  created_at: 2023-04-17 07:57:39+00:00
  edited: false
  hidden: false
  id: 643d0a03af3fe078a397f0ca
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: bofenghuang/vigogne-7b-instruct
repo_type: model
status: open
target_branch: null
title: llama.cpp ggml 4-bit quantized please
