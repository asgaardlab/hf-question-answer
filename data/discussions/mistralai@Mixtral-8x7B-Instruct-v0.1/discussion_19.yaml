!!python/object:huggingface_hub.community.DiscussionWithDetails
author: csgxy2022
conflicting_files: null
created_at: 2023-12-12 23:50:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/584b7e81b09f022b151caea1f0ce1915.svg
      fullname: XG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: csgxy2022
      type: user
    createdAt: '2023-12-12T23:50:30.000Z'
    data:
      edited: false
      editors:
      - csgxy2022
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3279874324798584
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/584b7e81b09f022b151caea1f0ce1915.svg
          fullname: XG
          isHf: false
          isPro: false
          name: csgxy2022
          type: user
        html: "<p>Anyone experiencing the same?</p>\n<p>My code</p>\n<pre><code class=\"\
          language-python\"><span class=\"hljs-keyword\">import</span> torch\n<span\
          \ class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> AutoModelForCausalLM, AutoTokenizer\n\nmodel_id = <span class=\"\
          hljs-string\">\"mistralai/Mixtral-8x7B-v0.1\"</span>\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\
          \nmodel = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16,\
          \ device_map=<span class=\"hljs-string\">\"auto\"</span>)\n\ntext = <span\
          \ class=\"hljs-string\">\"\"\"\u5199\u4E00\u4E2A\u5173\u4E8E\u5F20\u4E09\
          \u7A7F\u8D8A\u5230\u5510\u671D\u7684\u6545\u4E8B\uFF0C\u5FC5\u987B\u6DF1\
          \u5165\u7EC6\u8282\uFF0C\u6CE8\u610F\u7EC6\u8282\uFF01\u4E0D\u8981\u6709\
          \u4E00\u5929\uFF0C\u4E5F\u4E0D\u8981\u5199\u5927\u6982\uFF08\u6BD4\u5982\
          \u751F\u6D3B\u975E\u5E38\u8270\u96BE\u5565\u7684\uFF09\uFF0C\u73B0\u5728\
          \u5F00\u59CB\u5199\u3002\"\"\"</span>\ninputs = tokenizer(text, return_tensors=<span\
          \ class=\"hljs-string\">\"pt\"</span>).to(<span class=\"hljs-number\">0</span>)\n\
          \noutputs = model.generate(**inputs, max_new_tokens=<span class=\"hljs-number\"\
          >200</span>)\n<span class=\"hljs-built_in\">print</span>(tokenizer.decode(outputs[<span\
          \ class=\"hljs-number\">0</span>], skip_special_tokens=<span class=\"hljs-literal\"\
          >True</span>))\n</code></pre>\n<p>output</p>\n<pre><code>Setting `pad_token_id`\
          \ to `eos_token_id`:2 for open-end generation.\n\u5199\u4E00\u4E2A\u5173\
          \u4E8E\u5F20\u4E09\u7A7F\u8D8A\u5230\u5510\u671D\u7684\u6545\u4E8B\uFF0C\
          \u5FC5\u987B\u6DF1\u5165\u7EC6\u8282\uFF0C\u6CE8\u610F\u7EC6\u8282\uFF01\
          \u4E0D\u8981\u6709\u4E00\u5929\uFF0C\u4E5F\u4E0D\u8981\u5199\u5927\u6982\
          \uFF08\u6BD4\u5982\u751F\u6D3B\u975E\u5E38\u8270\u96BE\u5565\u7684\uFF09\
          \uFF0C\u73B0\u5728\u5F00\u59CB\u5199\u3002\n</code></pre>\n<p>Nothing generated.\
          \ And it happens quite often for prompts I have tried. Did I do anything\
          \ wrong?</p>\n"
        raw: "Anyone experiencing the same?\r\n\r\nMy code\r\n```python\r\nimport\
          \ torch\r\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\r\
          \n\r\nmodel_id = \"mistralai/Mixtral-8x7B-v0.1\"\r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\
          \n\r\nmodel = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16,\
          \ device_map=\"auto\")\r\n\r\ntext = \"\"\"\u5199\u4E00\u4E2A\u5173\u4E8E\
          \u5F20\u4E09\u7A7F\u8D8A\u5230\u5510\u671D\u7684\u6545\u4E8B\uFF0C\u5FC5\
          \u987B\u6DF1\u5165\u7EC6\u8282\uFF0C\u6CE8\u610F\u7EC6\u8282\uFF01\u4E0D\
          \u8981\u6709\u4E00\u5929\uFF0C\u4E5F\u4E0D\u8981\u5199\u5927\u6982\uFF08\
          \u6BD4\u5982\u751F\u6D3B\u975E\u5E38\u8270\u96BE\u5565\u7684\uFF09\uFF0C\
          \u73B0\u5728\u5F00\u59CB\u5199\u3002\"\"\"\r\ninputs = tokenizer(text, return_tensors=\"\
          pt\").to(0)\r\n\r\noutputs = model.generate(**inputs, max_new_tokens=200)\r\
          \nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\r\n```\r\
          \n\r\noutput\r\n```\r\nSetting `pad_token_id` to `eos_token_id`:2 for open-end\
          \ generation.\r\n\u5199\u4E00\u4E2A\u5173\u4E8E\u5F20\u4E09\u7A7F\u8D8A\u5230\
          \u5510\u671D\u7684\u6545\u4E8B\uFF0C\u5FC5\u987B\u6DF1\u5165\u7EC6\u8282\
          \uFF0C\u6CE8\u610F\u7EC6\u8282\uFF01\u4E0D\u8981\u6709\u4E00\u5929\uFF0C\
          \u4E5F\u4E0D\u8981\u5199\u5927\u6982\uFF08\u6BD4\u5982\u751F\u6D3B\u975E\
          \u5E38\u8270\u96BE\u5565\u7684\uFF09\uFF0C\u73B0\u5728\u5F00\u59CB\u5199\
          \u3002\r\n```\r\n\r\nNothing generated. And it happens quite often for prompts\
          \ I have tried. Did I do anything wrong?"
        updatedAt: '2023-12-12T23:50:30.390Z'
      numEdits: 0
      reactions: []
    id: 6578f1c62c8d6e12c40bac1c
    type: comment
  author: csgxy2022
  content: "Anyone experiencing the same?\r\n\r\nMy code\r\n```python\r\nimport torch\r\
    \nfrom transformers import AutoModelForCausalLM, AutoTokenizer\r\n\r\nmodel_id\
    \ = \"mistralai/Mixtral-8x7B-v0.1\"\r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\
    \n\r\nmodel = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16,\
    \ device_map=\"auto\")\r\n\r\ntext = \"\"\"\u5199\u4E00\u4E2A\u5173\u4E8E\u5F20\
    \u4E09\u7A7F\u8D8A\u5230\u5510\u671D\u7684\u6545\u4E8B\uFF0C\u5FC5\u987B\u6DF1\
    \u5165\u7EC6\u8282\uFF0C\u6CE8\u610F\u7EC6\u8282\uFF01\u4E0D\u8981\u6709\u4E00\
    \u5929\uFF0C\u4E5F\u4E0D\u8981\u5199\u5927\u6982\uFF08\u6BD4\u5982\u751F\u6D3B\
    \u975E\u5E38\u8270\u96BE\u5565\u7684\uFF09\uFF0C\u73B0\u5728\u5F00\u59CB\u5199\
    \u3002\"\"\"\r\ninputs = tokenizer(text, return_tensors=\"pt\").to(0)\r\n\r\n\
    outputs = model.generate(**inputs, max_new_tokens=200)\r\nprint(tokenizer.decode(outputs[0],\
    \ skip_special_tokens=True))\r\n```\r\n\r\noutput\r\n```\r\nSetting `pad_token_id`\
    \ to `eos_token_id`:2 for open-end generation.\r\n\u5199\u4E00\u4E2A\u5173\u4E8E\
    \u5F20\u4E09\u7A7F\u8D8A\u5230\u5510\u671D\u7684\u6545\u4E8B\uFF0C\u5FC5\u987B\
    \u6DF1\u5165\u7EC6\u8282\uFF0C\u6CE8\u610F\u7EC6\u8282\uFF01\u4E0D\u8981\u6709\
    \u4E00\u5929\uFF0C\u4E5F\u4E0D\u8981\u5199\u5927\u6982\uFF08\u6BD4\u5982\u751F\
    \u6D3B\u975E\u5E38\u8270\u96BE\u5565\u7684\uFF09\uFF0C\u73B0\u5728\u5F00\u59CB\
    \u5199\u3002\r\n```\r\n\r\nNothing generated. And it happens quite often for prompts\
    \ I have tried. Did I do anything wrong?"
  created_at: 2023-12-12 23:50:30+00:00
  edited: false
  hidden: false
  id: 6578f1c62c8d6e12c40bac1c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/99eea215044a97eebbe30d1ade83b236.svg
      fullname: ronadle
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ron21
      type: user
    createdAt: '2023-12-13T01:20:26.000Z'
    data:
      edited: false
      editors:
      - ron21
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7568345069885254
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/99eea215044a97eebbe30d1ade83b236.svg
          fullname: ronadle
          isHf: false
          isPro: false
          name: ron21
          type: user
        html: '<p>Switch to mistralai/Mixtral-8x7B-Instruct-v0.1 and try again!</p>

          '
        raw: Switch to mistralai/Mixtral-8x7B-Instruct-v0.1 and try again!
        updatedAt: '2023-12-13T01:20:26.871Z'
      numEdits: 0
      reactions: []
    id: 657906dad104a61183ad9e83
    type: comment
  author: ron21
  content: Switch to mistralai/Mixtral-8x7B-Instruct-v0.1 and try again!
  created_at: 2023-12-13 01:20:26+00:00
  edited: false
  hidden: false
  id: 657906dad104a61183ad9e83
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-13T09:01:58.000Z'
    data:
      edited: true
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.996474027633667
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>This model was not trained on Chinese. </p>

          '
        raw: 'This model was not trained on Chinese. '
        updatedAt: '2023-12-13T09:02:04.466Z'
      numEdits: 1
      reactions: []
    id: 65797306c37954680aecc845
    type: comment
  author: ArthurZ
  content: 'This model was not trained on Chinese. '
  created_at: 2023-12-13 09:01:58+00:00
  edited: true
  hidden: false
  id: 65797306c37954680aecc845
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/584b7e81b09f022b151caea1f0ce1915.svg
      fullname: XG
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: csgxy2022
      type: user
    createdAt: '2023-12-14T17:31:05.000Z'
    data:
      edited: false
      editors:
      - csgxy2022
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9620864987373352
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/584b7e81b09f022b151caea1f0ce1915.svg
          fullname: XG
          isHf: false
          isPro: false
          name: csgxy2022
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ArthurZ&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ArthurZ\">@<span class=\"\
          underline\">ArthurZ</span></a></span>\n\n\t</span></span> I doubt that,\
          \ the model can obviously speak in Chinese.</p>\n<p><span data-props=\"\
          {&quot;user&quot;:&quot;ron21&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/ron21\">@<span class=\"underline\">ron21</span></a></span>\n\
          \n\t</span></span> checking the model_id, it is already the instruct model.</p>\n"
        raw: '@ArthurZ I doubt that, the model can obviously speak in Chinese.


          @ron21 checking the model_id, it is already the instruct model.'
        updatedAt: '2023-12-14T17:31:05.442Z'
      numEdits: 0
      reactions: []
    id: 657b3bd9ff16eeb2ee2209dc
    type: comment
  author: csgxy2022
  content: '@ArthurZ I doubt that, the model can obviously speak in Chinese.


    @ron21 checking the model_id, it is already the instruct model.'
  created_at: 2023-12-14 17:31:05+00:00
  edited: false
  hidden: false
  id: 657b3bd9ff16eeb2ee2209dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-18T11:50:28.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9240356087684631
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>What I mean is that you should check the ids generated. It probably
          instanstly generated a <code>&lt;/s&gt;</code> the eos . </p>

          '
        raw: "What I mean is that you should check the ids generated. It probably\
          \ instanstly generated a `</s>` the eos . \n"
        updatedAt: '2023-12-18T11:50:28.991Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - csgxy2022
    id: 658032045244948f4441afad
    type: comment
  author: ArthurZ
  content: "What I mean is that you should check the ids generated. It probably instanstly\
    \ generated a `</s>` the eos . \n"
  created_at: 2023-12-18 11:50:28+00:00
  edited: false
  hidden: false
  id: 658032045244948f4441afad
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: mistralai/Mixtral-8x7B-Instruct-v0.1
repo_type: model
status: open
target_branch: null
title: Mixtral not generating anything for some prompts
