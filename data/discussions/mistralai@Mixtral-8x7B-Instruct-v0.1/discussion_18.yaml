!!python/object:huggingface_hub.community.DiscussionWithDetails
author: elanmarkowitz
conflicting_files: null
created_at: 2023-12-12 23:28:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa97acadcc090251a4d14ebd58157f7d.svg
      fullname: Elan Markowitz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: elanmarkowitz
      type: user
    createdAt: '2023-12-12T23:28:29.000Z'
    data:
      edited: false
      editors:
      - elanmarkowitz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5068289637565613
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa97acadcc090251a4d14ebd58157f7d.svg
          fullname: Elan Markowitz
          isHf: false
          isPro: false
          name: elanmarkowitz
          type: user
        html: "<p>Trying to deploy on SageMaker with</p>\n<pre><code>import json\n\
          import sagemaker\nimport boto3\nfrom sagemaker.huggingface import HuggingFaceModel,\
          \ get_huggingface_llm_image_uri\n\ntry:\n    role = sagemaker.get_execution_role()\n\
          except ValueError:\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\
          \n# Hub Model configuration. https://huggingface.co/models\nmodel_id = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n\
          hub = {\n    'HF_MODEL_ID': model_id,\n    'SM_NUM_GPUS': json.dumps(8)\n\
          }\n\n\n\n# create Hugging Face Model Class\nhuggingface_model = HuggingFaceModel(\n\
          \    image_uri=get_huggingface_llm_image_uri(\"huggingface\"),\n    transformers_version=\"\
          4.36.0\",\n    env=hub,\n    role=role, \n    name=f\"HF-{model_id}\".replace('/','-').replace('.','-')\n\
          )\n\n# deploy model to SageMaker Inference\npredictor = huggingface_model.deploy(\n\
          \    initial_instance_count=1,\n    instance_type=\"ml.g5.48xlarge\",\n\
          \    container_startup_health_check_timeout=300,\n  )\n</code></pre>\n<p>But\
          \ get the following error</p>\n<pre><code>File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 159, in serve_inner model = get_model( File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 291, in get_model raise ValueError(\"sharded is not supported for\
          \ AutoModel\")\n</code></pre>\n<p><code>ValueError: sharded is not supported\
          \ for AutoModel</code></p>\n<p>Any ideas on how to fix?</p>\n"
        raw: "Trying to deploy on SageMaker with\r\n```\r\nimport json\r\nimport sagemaker\r\
          \nimport boto3\r\nfrom sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\r\
          \n\r\ntry:\r\n\trole = sagemaker.get_execution_role()\r\nexcept ValueError:\r\
          \n\tiam = boto3.client('iam')\r\n\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\r\
          \n\r\n# Hub Model configuration. https://huggingface.co/models\r\nmodel_id\
          \ = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\r\nhub = {\r\n\t'HF_MODEL_ID':\
          \ model_id,\r\n\t'SM_NUM_GPUS': json.dumps(8)\r\n}\r\n\r\n\r\n\r\n# create\
          \ Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\n\t\
          image_uri=get_huggingface_llm_image_uri(\"huggingface\"),\r\n    transformers_version=\"\
          4.36.0\",\r\n\tenv=hub,\r\n\trole=role, \r\n    name=f\"HF-{model_id}\"\
          .replace('/','-').replace('.','-')\r\n)\r\n\r\n# deploy model to SageMaker\
          \ Inference\r\npredictor = huggingface_model.deploy(\r\n\tinitial_instance_count=1,\r\
          \n\tinstance_type=\"ml.g5.48xlarge\",\r\n\tcontainer_startup_health_check_timeout=300,\r\
          \n  )\r\n```\r\nBut get the following error\r\n```\r\nFile \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
          , line 159, in serve_inner model = get_model( File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
          , line 291, in get_model raise ValueError(\"sharded is not supported for\
          \ AutoModel\")\r\n```\r\n`ValueError: sharded is not supported for AutoModel`\r\
          \n\r\nAny ideas on how to fix?"
        updatedAt: '2023-12-12T23:28:29.466Z'
      numEdits: 0
      reactions: []
    id: 6578ec9d8369b885d446de0c
    type: comment
  author: elanmarkowitz
  content: "Trying to deploy on SageMaker with\r\n```\r\nimport json\r\nimport sagemaker\r\
    \nimport boto3\r\nfrom sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\r\
    \n\r\ntry:\r\n\trole = sagemaker.get_execution_role()\r\nexcept ValueError:\r\n\
    \tiam = boto3.client('iam')\r\n\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\r\
    \n\r\n# Hub Model configuration. https://huggingface.co/models\r\nmodel_id = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\r\
    \nhub = {\r\n\t'HF_MODEL_ID': model_id,\r\n\t'SM_NUM_GPUS': json.dumps(8)\r\n\
    }\r\n\r\n\r\n\r\n# create Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\
    \n\timage_uri=get_huggingface_llm_image_uri(\"huggingface\"),\r\n    transformers_version=\"\
    4.36.0\",\r\n\tenv=hub,\r\n\trole=role, \r\n    name=f\"HF-{model_id}\".replace('/','-').replace('.','-')\r\
    \n)\r\n\r\n# deploy model to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\
    \n\tinitial_instance_count=1,\r\n\tinstance_type=\"ml.g5.48xlarge\",\r\n\tcontainer_startup_health_check_timeout=300,\r\
    \n  )\r\n```\r\nBut get the following error\r\n```\r\nFile \"/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py\"\
    , line 159, in serve_inner model = get_model( File \"/opt/conda/lib/python3.9/site-packages/text_generation_server/models/__init__.py\"\
    , line 291, in get_model raise ValueError(\"sharded is not supported for AutoModel\"\
    )\r\n```\r\n`ValueError: sharded is not supported for AutoModel`\r\n\r\nAny ideas\
    \ on how to fix?"
  created_at: 2023-12-12 23:28:29+00:00
  edited: false
  hidden: false
  id: 6578ec9d8369b885d446de0c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/80147200fd8355db9f7c9845096d4c2e.svg
      fullname: Manoranjan Rajguru
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: monuminu
      type: user
    createdAt: '2023-12-13T05:31:15.000Z'
    data:
      edited: false
      editors:
      - monuminu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5289177298545837
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/80147200fd8355db9f7c9845096d4c2e.svg
          fullname: Manoranjan Rajguru
          isHf: false
          isPro: false
          name: monuminu
          type: user
        html: '<p>use this image URI</p>

          <p>763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi1.3.1-gpu-py310-cu121-ubuntu20.04-v1.0</p>

          '
        raw: 'use this image URI


          763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi1.3.1-gpu-py310-cu121-ubuntu20.04-v1.0'
        updatedAt: '2023-12-13T05:31:15.443Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MikeWinkelmannXL2
    id: 657941a33a56e4034e606415
    type: comment
  author: monuminu
  content: 'use this image URI


    763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi1.3.1-gpu-py310-cu121-ubuntu20.04-v1.0'
  created_at: 2023-12-13 05:31:15+00:00
  edited: false
  hidden: false
  id: 657941a33a56e4034e606415
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa97acadcc090251a4d14ebd58157f7d.svg
      fullname: Elan Markowitz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: elanmarkowitz
      type: user
    createdAt: '2023-12-13T06:27:58.000Z'
    data:
      edited: false
      editors:
      - elanmarkowitz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8521433472633362
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa97acadcc090251a4d14ebd58157f7d.svg
          fullname: Elan Markowitz
          isHf: false
          isPro: false
          name: elanmarkowitz
          type: user
        html: '<p>Thanks. I also found this nice blog <a rel="nofollow" href="https://www.philschmid.de/sagemaker-deploy-mixtral#1-setup-development-environment">https://www.philschmid.de/sagemaker-deploy-mixtral#1-setup-development-environment</a></p>

          '
        raw: Thanks. I also found this nice blog https://www.philschmid.de/sagemaker-deploy-mixtral#1-setup-development-environment
        updatedAt: '2023-12-13T06:27:58.024Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jlzhou
      relatedEventId: 65794eeed104a61183b8722e
    id: 65794eeed104a61183b8722a
    type: comment
  author: elanmarkowitz
  content: Thanks. I also found this nice blog https://www.philschmid.de/sagemaker-deploy-mixtral#1-setup-development-environment
  created_at: 2023-12-13 06:27:58+00:00
  edited: false
  hidden: false
  id: 65794eeed104a61183b8722a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/fa97acadcc090251a4d14ebd58157f7d.svg
      fullname: Elan Markowitz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: elanmarkowitz
      type: user
    createdAt: '2023-12-13T06:27:58.000Z'
    data:
      status: closed
    id: 65794eeed104a61183b8722e
    type: status-change
  author: elanmarkowitz
  created_at: 2023-12-13 06:27:58+00:00
  id: 65794eeed104a61183b8722e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: mistralai/Mixtral-8x7B-Instruct-v0.1
repo_type: model
status: closed
target_branch: null
title: Deploying on SageMaker
