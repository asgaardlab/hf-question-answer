!!python/object:huggingface_hub.community.DiscussionWithDetails
author: guowl
conflicting_files: null
created_at: 2024-01-15 01:25:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b20961cfbacd0bade26ecc19da164581.svg
      fullname: guoweilong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guowl
      type: user
    createdAt: '2024-01-15T01:25:33.000Z'
    data:
      edited: false
      editors:
      - guowl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3922443389892578
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b20961cfbacd0bade26ecc19da164581.svg
          fullname: guoweilong
          isHf: false
          isPro: false
          name: guowl
          type: user
        html: '<p>when i use zero2.json ,it will be oom on gpu.<br>{<br>    "fp16":
          {<br>        "enabled": "auto",<br>        "loss_scale": 0,<br>        "loss_scale_window":
          1000,<br>        "initial_scale_power": 16,<br>        "hysteresis": 2,<br>        "min_loss_scale":
          1<br>    },<br>    "bf16": {<br>        "enabled": "auto"<br>    },<br>    "train_micro_batch_size_per_gpu":
          "auto",<br>    "train_batch_size": "auto",<br>    "gradient_accumulation_steps":
          "auto",<br>    "zero_optimization": {<br>        "stage": 2,<br>        "overlap_comm":
          true,<br>        "contiguous_gradients": true,<br>        "sub_group_size":
          1e9,<br>        "reduce_bucket_size": "auto"<br>    }<br>}</p>

          <p>when i use zero3.json ,when it start train, it will be hang very time
          .</p>

          <p>{<br>    "fp16": {<br>        "enabled": "auto",<br>        "loss_scale":
          0,<br>        "loss_scale_window": 1000,<br>        "initial_scale_power":
          16,<br>        "hysteresis": 2,<br>        "min_loss_scale": 1<br>    },<br>    "bf16":
          {<br>        "enabled": "auto"<br>    },<br>    "train_micro_batch_size_per_gpu":
          "auto",<br>    "train_batch_size": "auto",<br>    "gradient_accumulation_steps":
          "auto",<br>    "zero_optimization": {<br>        "stage": 3,<br>        "overlap_comm":
          true,<br>        "contiguous_gradients": true,<br>        "sub_group_size":
          1e9,<br>        "reduce_bucket_size": "auto",<br>        "stage3_prefetch_bucket_size":
          "auto",<br>        "stage3_param_persistence_threshold": "auto",<br>        "stage3_max_live_parameters":
          1e9,<br>        "stage3_max_reuse_distance": 1e9,<br>        "stage3_gather_16bit_weights_on_model_save":
          true<br>    }<br>}</p>

          <p>how to resove it ?</p>

          '
        raw: "when i use zero2.json ,it will be oom on gpu.    \r\n{\r\n    \"fp16\"\
          : {\r\n        \"enabled\": \"auto\",\r\n        \"loss_scale\": 0,\r\n\
          \        \"loss_scale_window\": 1000,\r\n        \"initial_scale_power\"\
          : 16,\r\n        \"hysteresis\": 2,\r\n        \"min_loss_scale\": 1\r\n\
          \    },\r\n    \"bf16\": {\r\n        \"enabled\": \"auto\"\r\n    },\r\n\
          \    \"train_micro_batch_size_per_gpu\": \"auto\",\r\n    \"train_batch_size\"\
          : \"auto\",\r\n    \"gradient_accumulation_steps\": \"auto\",\r\n    \"\
          zero_optimization\": {\r\n        \"stage\": 2,\r\n        \"overlap_comm\"\
          : true,\r\n        \"contiguous_gradients\": true,\r\n        \"sub_group_size\"\
          : 1e9,\r\n        \"reduce_bucket_size\": \"auto\"\r\n    }\r\n}\r\n\r\n\
          \r\n\r\nwhen i use zero3.json ,when it start train, it will be hang very\
          \ time .\r\n\r\n{\r\n    \"fp16\": {\r\n        \"enabled\": \"auto\",\r\
          \n        \"loss_scale\": 0,\r\n        \"loss_scale_window\": 1000,\r\n\
          \        \"initial_scale_power\": 16,\r\n        \"hysteresis\": 2,\r\n\
          \        \"min_loss_scale\": 1\r\n    },\r\n    \"bf16\": {\r\n        \"\
          enabled\": \"auto\"\r\n    },\r\n    \"train_micro_batch_size_per_gpu\"\
          : \"auto\",\r\n    \"train_batch_size\": \"auto\",\r\n    \"gradient_accumulation_steps\"\
          : \"auto\",\r\n    \"zero_optimization\": {\r\n        \"stage\": 3,\r\n\
          \        \"overlap_comm\": true,\r\n        \"contiguous_gradients\": true,\r\
          \n        \"sub_group_size\": 1e9,\r\n        \"reduce_bucket_size\": \"\
          auto\",\r\n        \"stage3_prefetch_bucket_size\": \"auto\",\r\n      \
          \  \"stage3_param_persistence_threshold\": \"auto\",\r\n        \"stage3_max_live_parameters\"\
          : 1e9,\r\n        \"stage3_max_reuse_distance\": 1e9,\r\n        \"stage3_gather_16bit_weights_on_model_save\"\
          : true\r\n    }\r\n}\r\n\r\n\r\n\r\nhow to resove it ?\r\n\r\n"
        updatedAt: '2024-01-15T01:25:33.830Z'
      numEdits: 0
      reactions: []
    id: 65a4898d1051c2b0db536614
    type: comment
  author: guowl
  content: "when i use zero2.json ,it will be oom on gpu.    \r\n{\r\n    \"fp16\"\
    : {\r\n        \"enabled\": \"auto\",\r\n        \"loss_scale\": 0,\r\n      \
    \  \"loss_scale_window\": 1000,\r\n        \"initial_scale_power\": 16,\r\n  \
    \      \"hysteresis\": 2,\r\n        \"min_loss_scale\": 1\r\n    },\r\n    \"\
    bf16\": {\r\n        \"enabled\": \"auto\"\r\n    },\r\n    \"train_micro_batch_size_per_gpu\"\
    : \"auto\",\r\n    \"train_batch_size\": \"auto\",\r\n    \"gradient_accumulation_steps\"\
    : \"auto\",\r\n    \"zero_optimization\": {\r\n        \"stage\": 2,\r\n     \
    \   \"overlap_comm\": true,\r\n        \"contiguous_gradients\": true,\r\n   \
    \     \"sub_group_size\": 1e9,\r\n        \"reduce_bucket_size\": \"auto\"\r\n\
    \    }\r\n}\r\n\r\n\r\n\r\nwhen i use zero3.json ,when it start train, it will\
    \ be hang very time .\r\n\r\n{\r\n    \"fp16\": {\r\n        \"enabled\": \"auto\"\
    ,\r\n        \"loss_scale\": 0,\r\n        \"loss_scale_window\": 1000,\r\n  \
    \      \"initial_scale_power\": 16,\r\n        \"hysteresis\": 2,\r\n        \"\
    min_loss_scale\": 1\r\n    },\r\n    \"bf16\": {\r\n        \"enabled\": \"auto\"\
    \r\n    },\r\n    \"train_micro_batch_size_per_gpu\": \"auto\",\r\n    \"train_batch_size\"\
    : \"auto\",\r\n    \"gradient_accumulation_steps\": \"auto\",\r\n    \"zero_optimization\"\
    : {\r\n        \"stage\": 3,\r\n        \"overlap_comm\": true,\r\n        \"\
    contiguous_gradients\": true,\r\n        \"sub_group_size\": 1e9,\r\n        \"\
    reduce_bucket_size\": \"auto\",\r\n        \"stage3_prefetch_bucket_size\": \"\
    auto\",\r\n        \"stage3_param_persistence_threshold\": \"auto\",\r\n     \
    \   \"stage3_max_live_parameters\": 1e9,\r\n        \"stage3_max_reuse_distance\"\
    : 1e9,\r\n        \"stage3_gather_16bit_weights_on_model_save\": true\r\n    }\r\
    \n}\r\n\r\n\r\n\r\nhow to resove it ?\r\n\r\n"
  created_at: 2024-01-15 01:25:33+00:00
  edited: false
  hidden: false
  id: 65a4898d1051c2b0db536614
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 91
repo_id: mistralai/Mixtral-8x7B-Instruct-v0.1
repo_type: model
status: open
target_branch: null
title: deepspeed load mixtral-8x7B hang or oom
