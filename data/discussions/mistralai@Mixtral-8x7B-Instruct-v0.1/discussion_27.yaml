!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mavjan
conflicting_files: null
created_at: 2023-12-13 18:59:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a387aef90bacbf8dd54831da64242cc7.svg
      fullname: Mav Min
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mavjan
      type: user
    createdAt: '2023-12-13T18:59:40.000Z'
    data:
      edited: false
      editors:
      - mavjan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5447030067443848
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a387aef90bacbf8dd54831da64242cc7.svg
          fullname: Mav Min
          isHf: false
          isPro: false
          name: mavjan
          type: user
        html: "<p>I am trying to deploy this model to Sagemaker using the provided\
          \ deployment code and am getting this error:</p>\n<pre><code>File \"text_generation_server/server.py\"\
          , line 159, in serve_inner\n    model = get_model(\n  File \"text_generation_server/models/__init__.py\"\
          , line 291, in get_model\n    raise ValueError(\"sharded is not supported\
          \ for AutoModel\")\n&gt; File \"text_generation_server/server.py\", line\
          \ 159, in serve_inner model = get_model( File \"text_generation_server/models/__init__.py\"\
          , line 291, in get_model raise ValueError(\"sharded is not supported for\
          \ AutoModel\")\n</code></pre>\n<p>Deployment Code for Reference: </p>\n\
          <pre><code>import json\nimport sagemaker\nimport boto3\nfrom sagemaker.huggingface\
          \ import HuggingFaceModel, get_huggingface_llm_image_uri\n\ntry:\n    role\
          \ = sagemaker.get_execution_role()\nexcept ValueError:\n    iam = boto3.client('iam')\n\
          \    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n\
          \n# Hub Model configuration. https://huggingface.co/models\nhub = {\n  \
          \  'HF_MODEL_ID':'mistralai/Mixtral-8x7B-Instruct-v0.1',\n    'SM_NUM_GPUS':\
          \ json.dumps(8)\n}\n\n\n\n# create Hugging Face Model Class\nhuggingface_model\
          \ = HuggingFaceModel(\n    image_uri=get_huggingface_llm_image_uri(\"huggingface\"\
          ,version=\"1.1.0\"),\n    env=hub,\n    role=role, \n)\n\n# deploy model\
          \ to SageMaker Inference\npredictor = huggingface_model.deploy(\n    initial_instance_count=1,\n\
          \    instance_type=\"ml.g5.48xlarge\",\n    container_startup_health_check_timeout=300,\n\
          \  )\n  \n# send request\npredictor.predict({\n    \"inputs\": \"[INST]\
          \ You are a pirate chatbot who always responds with Arr and pirate speak!\\\
          nThere's a llama on my lawn, how can I get rid of him? [/INST]\",\n})\n\
          </code></pre>\n"
        raw: "I am trying to deploy this model to Sagemaker using the provided deployment\
          \ code and am getting this error:\r\n```\r\nFile \"text_generation_server/server.py\"\
          , line 159, in serve_inner\r\n    model = get_model(\r\n  File \"text_generation_server/models/__init__.py\"\
          , line 291, in get_model\r\n    raise ValueError(\"sharded is not supported\
          \ for AutoModel\")\r\n> File \"text_generation_server/server.py\", line\
          \ 159, in serve_inner model = get_model( File \"text_generation_server/models/__init__.py\"\
          , line 291, in get_model raise ValueError(\"sharded is not supported for\
          \ AutoModel\")\r\n```\r\n\r\nDeployment Code for Reference: \r\n```\r\n\
          import json\r\nimport sagemaker\r\nimport boto3\r\nfrom sagemaker.huggingface\
          \ import HuggingFaceModel, get_huggingface_llm_image_uri\r\n\r\ntry:\r\n\
          \trole = sagemaker.get_execution_role()\r\nexcept ValueError:\r\n\tiam =\
          \ boto3.client('iam')\r\n\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\r\
          \n\r\n# Hub Model configuration. https://huggingface.co/models\r\nhub =\
          \ {\r\n\t'HF_MODEL_ID':'mistralai/Mixtral-8x7B-Instruct-v0.1',\r\n\t'SM_NUM_GPUS':\
          \ json.dumps(8)\r\n}\r\n\r\n\r\n\r\n# create Hugging Face Model Class\r\n\
          huggingface_model = HuggingFaceModel(\r\n\timage_uri=get_huggingface_llm_image_uri(\"\
          huggingface\",version=\"1.1.0\"),\r\n\tenv=hub,\r\n\trole=role, \r\n)\r\n\
          \r\n# deploy model to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\
          \n\tinitial_instance_count=1,\r\n\tinstance_type=\"ml.g5.48xlarge\",\r\n\
          \tcontainer_startup_health_check_timeout=300,\r\n  )\r\n  \r\n# send request\r\
          \npredictor.predict({\r\n\t\"inputs\": \"[INST] You are a pirate chatbot\
          \ who always responds with Arr and pirate speak!\\nThere's a llama on my\
          \ lawn, how can I get rid of him? [/INST]\",\r\n})\r\n```"
        updatedAt: '2023-12-13T18:59:40.003Z'
      numEdits: 0
      reactions: []
    id: 6579ff1c48287621b173528f
    type: comment
  author: mavjan
  content: "I am trying to deploy this model to Sagemaker using the provided deployment\
    \ code and am getting this error:\r\n```\r\nFile \"text_generation_server/server.py\"\
    , line 159, in serve_inner\r\n    model = get_model(\r\n  File \"text_generation_server/models/__init__.py\"\
    , line 291, in get_model\r\n    raise ValueError(\"sharded is not supported for\
    \ AutoModel\")\r\n> File \"text_generation_server/server.py\", line 159, in serve_inner\
    \ model = get_model( File \"text_generation_server/models/__init__.py\", line\
    \ 291, in get_model raise ValueError(\"sharded is not supported for AutoModel\"\
    )\r\n```\r\n\r\nDeployment Code for Reference: \r\n```\r\nimport json\r\nimport\
    \ sagemaker\r\nimport boto3\r\nfrom sagemaker.huggingface import HuggingFaceModel,\
    \ get_huggingface_llm_image_uri\r\n\r\ntry:\r\n\trole = sagemaker.get_execution_role()\r\
    \nexcept ValueError:\r\n\tiam = boto3.client('iam')\r\n\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\r\
    \n\r\n# Hub Model configuration. https://huggingface.co/models\r\nhub = {\r\n\t\
    'HF_MODEL_ID':'mistralai/Mixtral-8x7B-Instruct-v0.1',\r\n\t'SM_NUM_GPUS': json.dumps(8)\r\
    \n}\r\n\r\n\r\n\r\n# create Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\
    \n\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.1.0\"\
    ),\r\n\tenv=hub,\r\n\trole=role, \r\n)\r\n\r\n# deploy model to SageMaker Inference\r\
    \npredictor = huggingface_model.deploy(\r\n\tinitial_instance_count=1,\r\n\tinstance_type=\"\
    ml.g5.48xlarge\",\r\n\tcontainer_startup_health_check_timeout=300,\r\n  )\r\n\
    \  \r\n# send request\r\npredictor.predict({\r\n\t\"inputs\": \"[INST] You are\
    \ a pirate chatbot who always responds with Arr and pirate speak!\\nThere's a\
    \ llama on my lawn, how can I get rid of him? [/INST]\",\r\n})\r\n```"
  created_at: 2023-12-13 18:59:40+00:00
  edited: false
  hidden: false
  id: 6579ff1c48287621b173528f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa97acadcc090251a4d14ebd58157f7d.svg
      fullname: Elan Markowitz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: elanmarkowitz
      type: user
    createdAt: '2023-12-13T21:29:55.000Z'
    data:
      edited: false
      editors:
      - elanmarkowitz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.44154173135757446
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa97acadcc090251a4d14ebd58157f7d.svg
          fullname: Elan Markowitz
          isHf: false
          isPro: false
          name: elanmarkowitz
          type: user
        html: '<p><a href="https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1/discussions/18">https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1/discussions/18</a></p>

          '
        raw: https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1/discussions/18
        updatedAt: '2023-12-13T21:29:55.448Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mavjan
    id: 657a22531ccc3c2a5e9b6606
    type: comment
  author: elanmarkowitz
  content: https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1/discussions/18
  created_at: 2023-12-13 21:29:55+00:00
  edited: false
  hidden: false
  id: 657a22531ccc3c2a5e9b6606
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a387aef90bacbf8dd54831da64242cc7.svg
      fullname: Mav Min
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mavjan
      type: user
    createdAt: '2023-12-13T22:41:37.000Z'
    data:
      edited: false
      editors:
      - mavjan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9214843511581421
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a387aef90bacbf8dd54831da64242cc7.svg
          fullname: Mav Min
          isHf: false
          isPro: false
          name: mavjan
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;elanmarkowitz&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/elanmarkowitz\"\
          >@<span class=\"underline\">elanmarkowitz</span></a></span>\n\n\t</span></span>\
          \ , sorry did not see this before making this post.</p>\n"
        raw: Thanks @elanmarkowitz , sorry did not see this before making this post.
        updatedAt: '2023-12-13T22:41:37.720Z'
      numEdits: 0
      reactions: []
      relatedEventId: 657a3321eaef97ff4c079156
    id: 657a3321eaef97ff4c07914a
    type: comment
  author: mavjan
  content: Thanks @elanmarkowitz , sorry did not see this before making this post.
  created_at: 2023-12-13 22:41:37+00:00
  edited: false
  hidden: false
  id: 657a3321eaef97ff4c07914a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/a387aef90bacbf8dd54831da64242cc7.svg
      fullname: Mav Min
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mavjan
      type: user
    createdAt: '2023-12-13T22:41:37.000Z'
    data:
      status: closed
    id: 657a3321eaef97ff4c079156
    type: status-change
  author: mavjan
  created_at: 2023-12-13 22:41:37+00:00
  id: 657a3321eaef97ff4c079156
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 27
repo_id: mistralai/Mixtral-8x7B-Instruct-v0.1
repo_type: model
status: closed
target_branch: null
title: 'ValueError: sharded is not supported for AutoModel [Error]'
