!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ReneRockerz
conflicting_files: null
created_at: 2023-12-19 11:33:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643bb7d926f177a3e413d74e/ucNzgJkijwcJ5AHEcSeVO.jpeg?w=200&h=200&f=face
      fullname: Rene Schmitt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ReneRockerz
      type: user
    createdAt: '2023-12-19T11:33:26.000Z'
    data:
      edited: false
      editors:
      - ReneRockerz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7059746980667114
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643bb7d926f177a3e413d74e/ucNzgJkijwcJ5AHEcSeVO.jpeg?w=200&h=200&f=face
          fullname: Rene Schmitt
          isHf: false
          isPro: false
          name: ReneRockerz
          type: user
        html: '<p>Hi just some beginners here , I''ve run a model and got some errors
          even though I read some post already and had to upgrade transformers and
          pip but it still didn''t work.</p>

          <p>// check transformers version //<br>C:*<strong>*</strong>&gt;pip show
          transformers<br>Name: transformers<br>Version: 4.36.2<br>Summary: State-of-the-art
          Machine Learning for JAX, PyTorch and TensorFlow<br>Home-page: <a rel="nofollow"
          href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a><br>Author:
          The Hugging Face team (past and future) with the help of all our contributors
          (<a rel="nofollow" href="https://github.com/huggingface/transformers/graphs/contributors">https://github.com/huggingface/transformers/graphs/contributors</a>)<br>Author-email:
          <a rel="nofollow" href="mailto:transformers@huggingface.co">transformers@huggingface.co</a><br>License:
          Apache 2.0 License<br>Location: C:******\AppData\Roaming\Python\Python311\site-packages<br>Requires:
          filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors,
          tokenizers, tqdm<br>Required-by: sentence-transformers</p>

          <p>// config file //<br>config.json<br>{<br>  "_name_or_path": "/workspace/models/Mixtral-8x7B-v0.1",<br>  "architectures":
          [<br>    "MixtralForCausalLM"<br>  ],<br>  "attention_dropout": 0.0,<br>  "bos_token_id":
          1,<br>  "eos_token_id": 32000,<br>  "hidden_act": "silu",<br>  "hidden_size":
          4096,<br>  "initializer_range": 0.02,<br>  "intermediate_size": 14336,<br>  "max_position_embeddings":
          32768,<br>  "model_type": "mixtral",<br>  "num_attention_heads": 32,<br>  "num_experts_per_tok":
          2,<br>  "num_hidden_layers": 32,<br>  "num_key_value_heads": 8,<br>  "num_local_experts":
          8,<br>  "output_router_logits": false,<br>  "rms_norm_eps": 1e-05,<br>  "rope_theta":
          1000000.0,<br>  "router_aux_loss_coef": 0.02,<br>  "sliding_window": null,<br>  "tie_word_embeddings":
          false,<br>  "torch_dtype": "bfloat16",<br>  "transformers_version": "4.36.0.dev0",<br>  "use_cache":
          false,<br>  "vocab_size": 32002<br>}</p>

          <p>I would appreciate your help if there s'' another way to fix it. I''m
          using this model with text generation web UI but as I click to load the
          modal it shows me this error = KeyError: ''mixtral'' </p>

          '
        raw: "Hi just some beginners here , I've run a model and got some errors even\
          \ though I read some post already and had to upgrade transformers and pip\
          \ but it still didn't work.\r\n\r\n// check transformers version //\r\n\
          C:\\***\\***>pip show transformers\r\nName: transformers\r\nVersion: 4.36.2\r\
          \nSummary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\r\
          \nHome-page: https://github.com/huggingface/transformers\r\nAuthor: The\
          \ Hugging Face team (past and future) with the help of all our contributors\
          \ (https://github.com/huggingface/transformers/graphs/contributors)\r\n\
          Author-email: transformers@huggingface.co\r\nLicense: Apache 2.0 License\r\
          \nLocation: C:\\***\\***\\AppData\\Roaming\\Python\\Python311\\site-packages\r\
          \nRequires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex,\
          \ requests, safetensors, tokenizers, tqdm\r\nRequired-by: sentence-transformers\r\
          \n\r\n// config file //\r\nconfig.json\r\n{\r\n  \"_name_or_path\": \"/workspace/models/Mixtral-8x7B-v0.1\"\
          ,\r\n  \"architectures\": [\r\n    \"MixtralForCausalLM\"\r\n  ],\r\n  \"\
          attention_dropout\": 0.0,\r\n  \"bos_token_id\": 1,\r\n  \"eos_token_id\"\
          : 32000,\r\n  \"hidden_act\": \"silu\",\r\n  \"hidden_size\": 4096,\r\n\
          \  \"initializer_range\": 0.02,\r\n  \"intermediate_size\": 14336,\r\n \
          \ \"max_position_embeddings\": 32768,\r\n  \"model_type\": \"mixtral\",\r\
          \n  \"num_attention_heads\": 32,\r\n  \"num_experts_per_tok\": 2,\r\n  \"\
          num_hidden_layers\": 32,\r\n  \"num_key_value_heads\": 8,\r\n  \"num_local_experts\"\
          : 8,\r\n  \"output_router_logits\": false,\r\n  \"rms_norm_eps\": 1e-05,\r\
          \n  \"rope_theta\": 1000000.0,\r\n  \"router_aux_loss_coef\": 0.02,\r\n\
          \  \"sliding_window\": null,\r\n  \"tie_word_embeddings\": false,\r\n  \"\
          torch_dtype\": \"bfloat16\",\r\n  \"transformers_version\": \"4.36.0.dev0\"\
          ,\r\n  \"use_cache\": false,\r\n  \"vocab_size\": 32002\r\n}\r\n\r\nI would\
          \ appreciate your help if there s' another way to fix it. I'm using this\
          \ model with text generation web UI but as I click to load the modal it\
          \ shows me this error = KeyError: 'mixtral' \r\n\r\n"
        updatedAt: '2023-12-19T11:33:26.467Z'
      numEdits: 0
      reactions: []
    id: 65817f860d738799ecd8da11
    type: comment
  author: ReneRockerz
  content: "Hi just some beginners here , I've run a model and got some errors even\
    \ though I read some post already and had to upgrade transformers and pip but\
    \ it still didn't work.\r\n\r\n// check transformers version //\r\nC:\\***\\***>pip\
    \ show transformers\r\nName: transformers\r\nVersion: 4.36.2\r\nSummary: State-of-the-art\
    \ Machine Learning for JAX, PyTorch and TensorFlow\r\nHome-page: https://github.com/huggingface/transformers\r\
    \nAuthor: The Hugging Face team (past and future) with the help of all our contributors\
    \ (https://github.com/huggingface/transformers/graphs/contributors)\r\nAuthor-email:\
    \ transformers@huggingface.co\r\nLicense: Apache 2.0 License\r\nLocation: C:\\\
    ***\\***\\AppData\\Roaming\\Python\\Python311\\site-packages\r\nRequires: filelock,\
    \ huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers,\
    \ tqdm\r\nRequired-by: sentence-transformers\r\n\r\n// config file //\r\nconfig.json\r\
    \n{\r\n  \"_name_or_path\": \"/workspace/models/Mixtral-8x7B-v0.1\",\r\n  \"architectures\"\
    : [\r\n    \"MixtralForCausalLM\"\r\n  ],\r\n  \"attention_dropout\": 0.0,\r\n\
    \  \"bos_token_id\": 1,\r\n  \"eos_token_id\": 32000,\r\n  \"hidden_act\": \"\
    silu\",\r\n  \"hidden_size\": 4096,\r\n  \"initializer_range\": 0.02,\r\n  \"\
    intermediate_size\": 14336,\r\n  \"max_position_embeddings\": 32768,\r\n  \"model_type\"\
    : \"mixtral\",\r\n  \"num_attention_heads\": 32,\r\n  \"num_experts_per_tok\"\
    : 2,\r\n  \"num_hidden_layers\": 32,\r\n  \"num_key_value_heads\": 8,\r\n  \"\
    num_local_experts\": 8,\r\n  \"output_router_logits\": false,\r\n  \"rms_norm_eps\"\
    : 1e-05,\r\n  \"rope_theta\": 1000000.0,\r\n  \"router_aux_loss_coef\": 0.02,\r\
    \n  \"sliding_window\": null,\r\n  \"tie_word_embeddings\": false,\r\n  \"torch_dtype\"\
    : \"bfloat16\",\r\n  \"transformers_version\": \"4.36.0.dev0\",\r\n  \"use_cache\"\
    : false,\r\n  \"vocab_size\": 32002\r\n}\r\n\r\nI would appreciate your help if\
    \ there s' another way to fix it. I'm using this model with text generation web\
    \ UI but as I click to load the modal it shows me this error = KeyError: 'mixtral'\
    \ \r\n\r\n"
  created_at: 2023-12-19 11:33:26+00:00
  edited: false
  hidden: false
  id: 65817f860d738799ecd8da11
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aa50d53090ce91e9a7f042ad35678143.svg
      fullname: Lukas-Santo Puglisi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lukasLikesLinearity
      type: user
    createdAt: '2023-12-19T11:50:49.000Z'
    data:
      edited: false
      editors:
      - lukasLikesLinearity
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.782578706741333
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aa50d53090ce91e9a7f042ad35678143.svg
          fullname: Lukas-Santo Puglisi
          isHf: false
          isPro: false
          name: lukasLikesLinearity
          type: user
        html: '<p>hey there, I got the same error, I can load from AutoTokenizer the
          Mixtral-8x7B-v0.1 version after updating to transfomers_version 4.36.2 but
          not the model from AutoModelForCausalLM due to key error</p>

          '
        raw: hey there, I got the same error, I can load from AutoTokenizer the Mixtral-8x7B-v0.1
          version after updating to transfomers_version 4.36.2 but not the model from
          AutoModelForCausalLM due to key error
        updatedAt: '2023-12-19T11:50:49.118Z'
      numEdits: 0
      reactions: []
    id: 65818399154063aff8242363
    type: comment
  author: lukasLikesLinearity
  content: hey there, I got the same error, I can load from AutoTokenizer the Mixtral-8x7B-v0.1
    version after updating to transfomers_version 4.36.2 but not the model from AutoModelForCausalLM
    due to key error
  created_at: 2023-12-19 11:50:49+00:00
  edited: false
  hidden: false
  id: 65818399154063aff8242363
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643bb7d926f177a3e413d74e/ucNzgJkijwcJ5AHEcSeVO.jpeg?w=200&h=200&f=face
      fullname: Rene Schmitt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ReneRockerz
      type: user
    createdAt: '2023-12-19T15:34:23.000Z'
    data:
      status: closed
    id: 6581b7ff8ab7e9a616569222
    type: status-change
  author: ReneRockerz
  created_at: 2023-12-19 15:34:23+00:00
  id: 6581b7ff8ab7e9a616569222
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 55
repo_id: mistralai/Mixtral-8x7B-Instruct-v0.1
repo_type: model
status: closed
target_branch: null
title: 'KeyError: ''mixtral'' even transformers is 4.36.2'
