!!python/object:huggingface_hub.community.DiscussionWithDetails
author: narvind2003
conflicting_files: null
created_at: 2023-12-11 10:06:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/605cc8ef6ce6cabbb3474b6a/b8yTvn1GFhkA-jdkwat35.png?w=200&h=200&f=face
      fullname: Arvind Nagaraj
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: narvind2003
      type: user
    createdAt: '2023-12-11T10:06:56.000Z'
    data:
      edited: false
      editors:
      - narvind2003
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8232687711715698
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/605cc8ef6ce6cabbb3474b6a/b8yTvn1GFhkA-jdkwat35.png?w=200&h=200&f=face
          fullname: Arvind Nagaraj
          isHf: false
          isPro: false
          name: narvind2003
          type: user
        html: '<p>Could you please add the minimum hardware requirements to run this
          Instruct model?</p>

          '
        raw: Could you please add the minimum hardware requirements to run this Instruct
          model?
        updatedAt: '2023-12-11T10:06:56.136Z'
      numEdits: 0
      reactions:
      - count: 13
        reaction: "\U0001F91D"
        users:
        - KrishnaKaasyap
        - FujiwaraChoki
        - vantonop
        - dChandrahas
        - apiergentili
        - clemence-mw
        - Olaf
        - mfahad
        - iabhishekofficial
        - Horizon
        - acruz
        - JiunYi
        - ironmind
      - count: 8
        reaction: "\U0001F44D"
        users:
        - mfahad
        - Yuuru
        - martyn
        - Thireus
        - kefansun
        - srikanta80
        - Osd111
        - yhs0602
    id: 6576df40839aa0889963937d
    type: comment
  author: narvind2003
  content: Could you please add the minimum hardware requirements to run this Instruct
    model?
  created_at: 2023-12-11 10:06:56+00:00
  edited: false
  hidden: false
  id: 6576df40839aa0889963937d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ebb6430d20b1005bfd0903cb8ec918e3.svg
      fullname: lxw
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kev216
      type: user
    createdAt: '2023-12-11T13:32:58.000Z'
    data:
      edited: true
      editors:
      - kev216
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9886916279792786
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ebb6430d20b1005bfd0903cb8ec918e3.svg
          fullname: lxw
          isHf: false
          isPro: false
          name: kev216
          type: user
        html: "<p>I have tried using a 4090 24G, but it didn't work... \U0001F494\U0001F494\
          \U0001F494 we need more RAM.</p>\n"
        raw: "I have tried using a 4090 24G, but it didn't work... \U0001F494\U0001F494\
          \U0001F494 we need more RAM."
        updatedAt: '2023-12-11T13:33:54.720Z'
      numEdits: 1
      reactions: []
    id: 65770f8a3769477c723e5fc6
    type: comment
  author: kev216
  content: "I have tried using a 4090 24G, but it didn't work... \U0001F494\U0001F494\
    \U0001F494 we need more RAM."
  created_at: 2023-12-11 13:32:58+00:00
  edited: true
  hidden: false
  id: 65770f8a3769477c723e5fc6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6382255fcae34727b9cc149e/7xMczYu2FS0i4HXB7hwd9.png?w=200&h=200&f=face
      fullname: Ram C
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 0-hero
      type: user
    createdAt: '2023-12-11T14:03:40.000Z'
    data:
      edited: true
      editors:
      - 0-hero
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7669731378555298
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6382255fcae34727b9cc149e/7xMczYu2FS0i4HXB7hwd9.png?w=200&h=200&f=face
          fullname: Ram C
          isHf: false
          isPro: false
          name: 0-hero
          type: user
        html: "<p>\u201C&gt;130GB required\u201D</p>\n"
        raw: "\u201C>130GB required\u201D"
        updatedAt: '2023-12-11T14:03:58.540Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F614"
        users:
        - Hanssep123
        - DeltaWhiplash
    id: 657716bcf4bc642e3a60d8b4
    type: comment
  author: 0-hero
  content: "\u201C>130GB required\u201D"
  created_at: 2023-12-11 14:03:40+00:00
  edited: true
  hidden: false
  id: 657716bcf4bc642e3a60d8b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5854f9676964675824ece11892017766.svg
      fullname: Horstmann
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Olaf
      type: user
    createdAt: '2023-12-11T14:06:53.000Z'
    data:
      edited: true
      editors:
      - Olaf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6121406555175781
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5854f9676964675824ece11892017766.svg
          fullname: Horstmann
          isHf: false
          isPro: false
          name: Olaf
          type: user
        html: '<p>I believe you can find this information here: <a rel="nofollow"
          href="https://docs.mistral.ai/models/">https://docs.mistral.ai/models/</a><br>(min.
          100GB GPU RAM)</p>

          '
        raw: 'I believe you can find this information here: https://docs.mistral.ai/models/

          (min. 100GB GPU RAM)'
        updatedAt: '2023-12-11T14:08:20.014Z'
      numEdits: 1
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - kev216
        - Hanssep123
        - acruz
        - pnichite
    id: 6577177de1e7233660b1df75
    type: comment
  author: Olaf
  content: 'I believe you can find this information here: https://docs.mistral.ai/models/

    (min. 100GB GPU RAM)'
  created_at: 2023-12-11 14:06:53+00:00
  edited: true
  hidden: false
  id: 6577177de1e7233660b1df75
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ebb6430d20b1005bfd0903cb8ec918e3.svg
      fullname: lxw
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kev216
      type: user
    createdAt: '2023-12-11T14:22:44.000Z'
    data:
      edited: false
      editors:
      - kev216
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7878550887107849
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ebb6430d20b1005bfd0903cb8ec918e3.svg
          fullname: lxw
          isHf: false
          isPro: false
          name: kev216
          type: user
        html: '<blockquote>

          <p>I believe you can find this information here: <a rel="nofollow" href="https://docs.mistral.ai/models/">https://docs.mistral.ai/models/</a><br>(min.
          100GB GPU RAM)</p>

          </blockquote>

          <p>I think we may not be able to utilize such a large amount (100 GB) with
          ''load_in_4bits'' or ''load_in_8bit.'' I will attempt it with the A100 80GB.
          ^^</p>

          '
        raw: '> I believe you can find this information here: https://docs.mistral.ai/models/

          > (min. 100GB GPU RAM)


          I think we may not be able to utilize such a large amount (100 GB) with
          ''load_in_4bits'' or ''load_in_8bit.'' I will attempt it with the A100 80GB.
          ^^'
        updatedAt: '2023-12-11T14:22:44.660Z'
      numEdits: 0
      reactions: []
    id: 65771b34e1e7233660b28990
    type: comment
  author: kev216
  content: '> I believe you can find this information here: https://docs.mistral.ai/models/

    > (min. 100GB GPU RAM)


    I think we may not be able to utilize such a large amount (100 GB) with ''load_in_4bits''
    or ''load_in_8bit.'' I will attempt it with the A100 80GB. ^^'
  created_at: 2023-12-11 14:22:44+00:00
  edited: false
  hidden: false
  id: 65771b34e1e7233660b28990
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-11T14:46:48.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9833340644836426
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Load in 4 bits should work. Same as 8bit! </p>

          '
        raw: "Load in 4 bits should work. Same as 8bit! \n"
        updatedAt: '2023-12-11T14:46:48.522Z'
      numEdits: 0
      reactions: []
    id: 657720d8e1e7233660b3adc7
    type: comment
  author: ArthurZ
  content: "Load in 4 bits should work. Same as 8bit! \n"
  created_at: 2023-12-11 14:46:48+00:00
  edited: false
  hidden: false
  id: 657720d8e1e7233660b3adc7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png?w=200&h=200&f=face
      fullname: Omar Sanseviero
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: osanseviero
      type: user
    createdAt: '2023-12-11T14:51:28.000Z'
    data:
      edited: true
      editors:
      - osanseviero
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8598445057868958
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png?w=200&h=200&f=face
          fullname: Omar Sanseviero
          isHf: true
          isPro: false
          name: osanseviero
          type: user
        html: "<p>Quick math (approximate): 45 billion parameters</p>\n<ul>\n<li>In\
          \ 4-bits -&gt; 180 trillion bits, that's 22.5GB of VRAM required</li>\n\
          <li>in 8-bits -&gt;  45GB of VRAM</li>\n<li>in half-precision -&gt; 90GB\
          \ of VRAM required</li>\n</ul>\n<p>Note that 4-bits is presenting high quality\
          \ degradation. It might be interesting to explore only quantizing the experts.\
          \ <a rel=\"nofollow\" href=\"https://arxiv.org/abs/2310.16795\">https://arxiv.org/abs/2310.16795</a>,\
          \ for example, introduces QMoE which allows sub-1-bit quantization for MoEs.\
          \ <span data-props=\"{&quot;user&quot;:&quot;timdettmers&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/timdettmers\">@<span\
          \ class=\"underline\">timdettmers</span></a></span>\n\n\t</span></span>\
          \ is also exploring this topic, so I'm waiting for exciting things in the\
          \ incoming days!</p>\n"
        raw: 'Quick math (approximate): 45 billion parameters


          * In 4-bits -> 180 trillion bits, that''s 22.5GB of VRAM required

          * in 8-bits ->  45GB of VRAM

          * in half-precision -> 90GB of VRAM required


          Note that 4-bits is presenting high quality degradation. It might be interesting
          to explore only quantizing the experts. https://arxiv.org/abs/2310.16795,
          for example, introduces QMoE which allows sub-1-bit quantization for MoEs.
          @timdettmers is also exploring this topic, so I''m waiting for exciting
          things in the incoming days!'
        updatedAt: '2023-12-25T14:26:10.555Z'
      numEdits: 1
      reactions:
      - count: 19
        reaction: "\U0001F44D"
        users:
        - ybelkada
        - kev216
        - victor
        - pcuenq
        - kk3dmax
        - wolfram
        - nib12345
        - Hoioi
        - knoopx
        - Ilianos
        - ucyang
        - richardlian
        - radames
        - jordandmc
        - AwikDhar
        - odellus
        - jcole-laivly
        - Pranav-CD
        - acruz
    id: 657721f02eb103d91fd044f1
    type: comment
  author: osanseviero
  content: 'Quick math (approximate): 45 billion parameters


    * In 4-bits -> 180 trillion bits, that''s 22.5GB of VRAM required

    * in 8-bits ->  45GB of VRAM

    * in half-precision -> 90GB of VRAM required


    Note that 4-bits is presenting high quality degradation. It might be interesting
    to explore only quantizing the experts. https://arxiv.org/abs/2310.16795, for
    example, introduces QMoE which allows sub-1-bit quantization for MoEs. @timdettmers
    is also exploring this topic, so I''m waiting for exciting things in the incoming
    days!'
  created_at: 2023-12-11 14:51:28+00:00
  edited: true
  hidden: false
  id: 657721f02eb103d91fd044f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654243824339-626010a1ffe8827cb1d626ad.jpeg?w=200&h=200&f=face
      fullname: LuigiSaetta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: luigisaetta
      type: user
    createdAt: '2023-12-11T17:41:45.000Z'
    data:
      edited: false
      editors:
      - luigisaetta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.870015025138855
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654243824339-626010a1ffe8827cb1d626ad.jpeg?w=200&h=200&f=face
          fullname: LuigiSaetta
          isHf: false
          isPro: false
          name: luigisaetta
          type: user
        html: '<p>I have tested it on a VM with 2 GPU A10 (23 + 23 GB GPU) it works
          if using load_in_4bit, not 8bit. Performance in Italian are interesting</p>

          '
        raw: I have tested it on a VM with 2 GPU A10 (23 + 23 GB GPU) it works if
          using load_in_4bit, not 8bit. Performance in Italian are interesting
        updatedAt: '2023-12-11T17:41:45.382Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - Olaf
        - ybelkada
        - sainez
        - osanseviero
        - Giloh7
        - pnichite
    id: 657749d9b28a0756ef0b3bc1
    type: comment
  author: luigisaetta
  content: I have tested it on a VM with 2 GPU A10 (23 + 23 GB GPU) it works if using
    load_in_4bit, not 8bit. Performance in Italian are interesting
  created_at: 2023-12-11 17:41:45+00:00
  edited: false
  hidden: false
  id: 657749d9b28a0756ef0b3bc1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28561f897e4be4a232d253c76505f5c6.svg
      fullname: Jay Bazad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JayBZD
      type: user
    createdAt: '2023-12-12T06:34:26.000Z'
    data:
      edited: true
      editors:
      - JayBZD
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4960376024246216
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28561f897e4be4a232d253c76505f5c6.svg
          fullname: Jay Bazad
          isHf: false
          isPro: false
          name: JayBZD
          type: user
        html: '<p>RTX 4090, 24GB dedicated GPU memory + 32 GB shared GPU memory, Windows
          11, WSL (Ubuntu): </p>

          <ol>

          <li>from_pretrained(load_in_8bits=True)<br>45.8 GB</li>

          <li>from_pretrained(load_in_4bits=True)<br>27.1 GB</li>

          </ol>

          '
        raw: "RTX 4090, 24GB dedicated GPU memory + 32 GB shared GPU memory, Windows\
          \ 11, WSL (Ubuntu): \n\n1. from_pretrained(load_in_8bits=True) \n45.8 GB\n\
          2. from_pretrained(load_in_4bits=True)\n27.1 GB\n"
        updatedAt: '2023-12-12T06:38:47.865Z'
      numEdits: 1
      reactions:
      - count: 14
        reaction: "\U0001F44D"
        users:
        - kev216
        - songyh345
        - Raskoll
        - ybelkada
        - ucyang
        - Hansimov
        - AwikDhar
        - Horizon
        - zealotus
        - Harry-w
        - jgcabotd
        - Pranav-CD
        - acruz
        - jilp00
    id: 6577fef26cb1dcb957d5d012
    type: comment
  author: JayBZD
  content: "RTX 4090, 24GB dedicated GPU memory + 32 GB shared GPU memory, Windows\
    \ 11, WSL (Ubuntu): \n\n1. from_pretrained(load_in_8bits=True) \n45.8 GB\n2. from_pretrained(load_in_4bits=True)\n\
    27.1 GB\n"
  created_at: 2023-12-12 06:34:26+00:00
  edited: true
  hidden: false
  id: 6577fef26cb1dcb957d5d012
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/432407f885f19e86ba5118a2a588bd78.svg
      fullname: Sabareesh Subramani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SabareeshGc
      type: user
    createdAt: '2023-12-12T18:17:40.000Z'
    data:
      edited: false
      editors:
      - SabareeshGc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.909176230430603
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/432407f885f19e86ba5118a2a588bd78.svg
          fullname: Sabareesh Subramani
          isHf: false
          isPro: false
          name: SabareeshGc
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;JayBZD&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/JayBZD\">@<span class=\"\
          underline\">JayBZD</span></a></span>\n\n\t</span></span> how to run with\
          \ shared memory . I have 4090 and 64gb system memory available</p>\n"
        raw: '@JayBZD how to run with shared memory . I have 4090 and 64gb system
          memory available'
        updatedAt: '2023-12-12T18:17:40.710Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - kefansun
        - Harry-w
    id: 6578a3c42f2e4058aeeb345b
    type: comment
  author: SabareeshGc
  content: '@JayBZD how to run with shared memory . I have 4090 and 64gb system memory
    available'
  created_at: 2023-12-12 18:17:40+00:00
  edited: false
  hidden: false
  id: 6578a3c42f2e4058aeeb345b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/00154d9a3f901567f25b432f3f04e6e2.svg
      fullname: Hans Schmidt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: supportend
      type: user
    createdAt: '2023-12-13T00:17:27.000Z'
    data:
      edited: false
      editors:
      - supportend
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9530938267707825
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/00154d9a3f901567f25b432f3f04e6e2.svg
          fullname: Hans Schmidt
          isHf: false
          isPro: false
          name: supportend
          type: user
        html: '<p>I run it (Q6_K) on CPU only, it''s much faster than 70B Models,
          but consumes over 50 percent from my 64 GB RAM.</p>

          '
        raw: I run it (Q6_K) on CPU only, it's much faster than 70B Models, but consumes
          over 50 percent from my 64 GB RAM.
        updatedAt: '2023-12-13T00:17:27.921Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - Hansimov
        - maethu
        - ahsannawazch
    id: 6578f8173a56e4034e541089
    type: comment
  author: supportend
  content: I run it (Q6_K) on CPU only, it's much faster than 70B Models, but consumes
    over 50 percent from my 64 GB RAM.
  created_at: 2023-12-13 00:17:27+00:00
  edited: false
  hidden: false
  id: 6578f8173a56e4034e541089
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2aa7c3b7961324fcb4bfd6bbbb88729d.svg
      fullname: Khatba
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Husain
      type: user
    createdAt: '2023-12-20T08:30:03.000Z'
    data:
      edited: false
      editors:
      - Husain
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8377575874328613
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2aa7c3b7961324fcb4bfd6bbbb88729d.svg
          fullname: Khatba
          isHf: false
          isPro: false
          name: Husain
          type: user
        html: '<p>If we would like to run at full precision, we will need 45 * 32
          = 1440B bits -&gt; 180 GB ?<br>Are the parameters in float32 by default?</p>

          '
        raw: 'If we would like to run at full precision, we will need 45 * 32 = 1440B
          bits -> 180 GB ?

          Are the parameters in float32 by default?'
        updatedAt: '2023-12-20T08:30:03.507Z'
      numEdits: 0
      reactions: []
    id: 6582a60b7cec0a2080d69821
    type: comment
  author: Husain
  content: 'If we would like to run at full precision, we will need 45 * 32 = 1440B
    bits -> 180 GB ?

    Are the parameters in float32 by default?'
  created_at: 2023-12-20 08:30:03+00:00
  edited: false
  hidden: false
  id: 6582a60b7cec0a2080d69821
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/21003427cc06fea920af3d9361d9063f.svg
      fullname: AMIT KUMAR
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: one-thing
      type: user
    createdAt: '2023-12-25T07:52:43.000Z'
    data:
      edited: false
      editors:
      - one-thing
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5018557906150818
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/21003427cc06fea920af3d9361d9063f.svg
          fullname: AMIT KUMAR
          isHf: false
          isPro: false
          name: one-thing
          type: user
        html: '<p>On RTX A6000(48GB)<br>load_in_4bit = 27.2GB<br>load_in_8bit = 45.4
          GB</p>

          '
        raw: 'On RTX A6000(48GB)

          load_in_4bit = 27.2GB

          load_in_8bit = 45.4 GB'
        updatedAt: '2023-12-25T07:52:43.316Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - bittamer
      - count: 1
        reaction: "\U0001F44D"
        users:
        - acruz
    id: 658934cb08f83845fc4c58ef
    type: comment
  author: one-thing
  content: 'On RTX A6000(48GB)

    load_in_4bit = 27.2GB

    load_in_8bit = 45.4 GB'
  created_at: 2023-12-25 07:52:43+00:00
  edited: false
  hidden: false
  id: 658934cb08f83845fc4c58ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/75e0c3658712d600a29fc5769fe206c4.svg
      fullname: Liam Fuller
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Businessboi
      type: user
    createdAt: '2024-01-01T22:06:06.000Z'
    data:
      edited: false
      editors:
      - Businessboi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8366139531135559
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/75e0c3658712d600a29fc5769fe206c4.svg
          fullname: Liam Fuller
          isHf: false
          isPro: false
          name: Businessboi
          type: user
        html: '<p>How do I load in 4bit when using the transformers library? Or do
          I load it another way?</p>

          '
        raw: How do I load in 4bit when using the transformers library? Or do I load
          it another way?
        updatedAt: '2024-01-01T22:06:06.915Z'
      numEdits: 0
      reactions: []
    id: 6593374e68d0b763312d7c6a
    type: comment
  author: Businessboi
  content: How do I load in 4bit when using the transformers library? Or do I load
    it another way?
  created_at: 2024-01-01 22:06:06+00:00
  edited: false
  hidden: false
  id: 6593374e68d0b763312d7c6a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/21003427cc06fea920af3d9361d9063f.svg
      fullname: AMIT KUMAR
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: one-thing
      type: user
    createdAt: '2024-01-14T05:06:33.000Z'
    data:
      edited: false
      editors:
      - one-thing
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5216047167778015
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/21003427cc06fea920af3d9361d9063f.svg
          fullname: AMIT KUMAR
          isHf: false
          isPro: false
          name: one-thing
          type: user
        html: "<p>Pass \u201Cload_in_bit = True\u201D in model.from_pretrained()</p>\n"
        raw: "Pass \u201Cload_in_bit = True\u201D in model.from_pretrained()"
        updatedAt: '2024-01-14T05:06:33.079Z'
      numEdits: 0
      reactions: []
    id: 65a36bd93a09e652a31f559f
    type: comment
  author: one-thing
  content: "Pass \u201Cload_in_bit = True\u201D in model.from_pretrained()"
  created_at: 2024-01-14 05:06:33+00:00
  edited: false
  hidden: false
  id: 65a36bd93a09e652a31f559f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: mistralai/Mixtral-8x7B-Instruct-v0.1
repo_type: model
status: open
target_branch: null
title: Min hardware requirements
