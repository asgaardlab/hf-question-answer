!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ExceedZhang
conflicting_files: null
created_at: 2023-12-13 08:56:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5427b05b3ef627d4d8281f9a33bb98ab.svg
      fullname: zhangwenbin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ExceedZhang
      type: user
    createdAt: '2023-12-13T08:56:28.000Z'
    data:
      edited: false
      editors:
      - ExceedZhang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.38061606884002686
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5427b05b3ef627d4d8281f9a33bb98ab.svg
          fullname: zhangwenbin
          isHf: false
          isPro: false
          name: ExceedZhang
          type: user
        html: "<p>python test_mixtral.py<br>import torch<br>from transformers import\
          \ AutoModelForCausalLM, AutoTokenizer</p>\n<p>model_id = \"/data1/apps/huggingface/Mixtral-8x7B-Instruct-v0.1\"\
          <br>tokenizer = AutoTokenizer.from_pretrained(model_id)</p>\n<p>model =\
          \ AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True)</p>\n\
          <p>text = \"Hello my name is\"<br>inputs = tokenizer(text, return_tensors=\"\
          pt\").to(0)</p>\n<p>outputs = model.generate(**inputs, max_new_tokens=20)<br>print(tokenizer.decode(outputs[0],\
          \ skip_special_tokens=True))</p>\n<p>Loading checkpoint shards:  79%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588                    | 15/19 [00:33&lt;00:08,  2.24s/it]<br>Traceback\
          \ (most recent call last):<br>  File \"/home/ubuntu/test_mixtral.py\", line\
          \ 7, in <br>    model = AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True)<br>\
          \  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 566, in from_pretrained<br>    return model_class.from_pretrained(<br>\
          \  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 3694, in from_pretrained<br>    ) = cls._load_pretrained_model(<br>\
          \  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 4079, in _load_pretrained_model<br>    state_dict = load_state_dict(shard_file)<br>\
          \  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 503, in load_state_dict<br>    with safe_open(checkpoint_file, framework=\"\
          pt\") as f:<br>safetensors_rust.SafetensorError: Error while deserializing\
          \ header: MetadataIncompleteBuffer</p>\n<p>Can anyone know why?</p>\n"
        raw: "python test_mixtral.py\r\nimport torch\r\nfrom transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\r\n\r\nmodel_id = \"/data1/apps/huggingface/Mixtral-8x7B-Instruct-v0.1\"\
          \r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(model_id,\
          \ load_in_4bit=True)\r\n\r\ntext = \"Hello my name is\"\r\ninputs = tokenizer(text,\
          \ return_tensors=\"pt\").to(0)\r\n\r\noutputs = model.generate(**inputs,\
          \ max_new_tokens=20)\r\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\r\
          \n\r\n\r\nLoading checkpoint shards:  79%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588           \
          \         | 15/19 [00:33<00:08,  2.24s/it]\r\nTraceback (most recent call\
          \ last):\r\n  File \"/home/ubuntu/test_mixtral.py\", line 7, in <module>\r\
          \n    model = AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True)\r\
          \n  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 566, in from_pretrained\r\n    return model_class.from_pretrained(\r\
          \n  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 3694, in from_pretrained\r\n    ) = cls._load_pretrained_model(\r\
          \n  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 4079, in _load_pretrained_model\r\n    state_dict = load_state_dict(shard_file)\r\
          \n  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 503, in load_state_dict\r\n    with safe_open(checkpoint_file, framework=\"\
          pt\") as f:\r\nsafetensors_rust.SafetensorError: Error while deserializing\
          \ header: MetadataIncompleteBuffer\r\n\r\nCan anyone know why?"
        updatedAt: '2023-12-13T08:56:28.687Z'
      numEdits: 0
      reactions: []
    id: 657971bcd104a61183be5a6a
    type: comment
  author: ExceedZhang
  content: "python test_mixtral.py\r\nimport torch\r\nfrom transformers import AutoModelForCausalLM,\
    \ AutoTokenizer\r\n\r\nmodel_id = \"/data1/apps/huggingface/Mixtral-8x7B-Instruct-v0.1\"\
    \r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(model_id,\
    \ load_in_4bit=True)\r\n\r\ntext = \"Hello my name is\"\r\ninputs = tokenizer(text,\
    \ return_tensors=\"pt\").to(0)\r\n\r\noutputs = model.generate(**inputs, max_new_tokens=20)\r\
    \nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\r\n\r\n\r\nLoading\
    \ checkpoint shards:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588                    | 15/19 [00:33<00:08,  2.24s/it]\r\nTraceback (most\
    \ recent call last):\r\n  File \"/home/ubuntu/test_mixtral.py\", line 7, in <module>\r\
    \n    model = AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True)\r\
    \n  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\"\
    , line 566, in from_pretrained\r\n    return model_class.from_pretrained(\r\n\
    \  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
    , line 3694, in from_pretrained\r\n    ) = cls._load_pretrained_model(\r\n  File\
    \ \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
    , line 4079, in _load_pretrained_model\r\n    state_dict = load_state_dict(shard_file)\r\
    \n  File \"/data1/apps/miniconda3/envs/Mixtral/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
    , line 503, in load_state_dict\r\n    with safe_open(checkpoint_file, framework=\"\
    pt\") as f:\r\nsafetensors_rust.SafetensorError: Error while deserializing header:\
    \ MetadataIncompleteBuffer\r\n\r\nCan anyone know why?"
  created_at: 2023-12-13 08:56:28+00:00
  edited: false
  hidden: false
  id: 657971bcd104a61183be5a6a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5427b05b3ef627d4d8281f9a33bb98ab.svg
      fullname: zhangwenbin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ExceedZhang
      type: user
    createdAt: '2023-12-13T08:57:54.000Z'
    data:
      edited: false
      editors:
      - ExceedZhang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3100375235080719
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5427b05b3ef627d4d8281f9a33bb98ab.svg
          fullname: zhangwenbin
          isHf: false
          isPro: false
          name: ExceedZhang
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64b26c035e1230a79f897880/Po5ISyYCytlKavNiKwcFa.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64b26c035e1230a79f897880/Po5ISyYCytlKavNiKwcFa.png"></a></p>

          '
        raw: '

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/64b26c035e1230a79f897880/Po5ISyYCytlKavNiKwcFa.png)

          '
        updatedAt: '2023-12-13T08:57:54.009Z'
      numEdits: 0
      reactions: []
    id: 65797212a87010c9f8b817cf
    type: comment
  author: ExceedZhang
  content: '

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/64b26c035e1230a79f897880/Po5ISyYCytlKavNiKwcFa.png)

    '
  created_at: 2023-12-13 08:57:54+00:00
  edited: false
  hidden: false
  id: 65797212a87010c9f8b817cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-13T08:59:57.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8978162407875061
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>You prbably need to download the weights again :/ </p>

          '
        raw: 'You prbably need to download the weights again :/ '
        updatedAt: '2023-12-13T08:59:57.341Z'
      numEdits: 0
      reactions: []
    id: 6579728dee40482b5c71115d
    type: comment
  author: ArthurZ
  content: 'You prbably need to download the weights again :/ '
  created_at: 2023-12-13 08:59:57+00:00
  edited: false
  hidden: false
  id: 6579728dee40482b5c71115d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5427b05b3ef627d4d8281f9a33bb98ab.svg
      fullname: zhangwenbin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ExceedZhang
      type: user
    createdAt: '2023-12-13T09:24:24.000Z'
    data:
      edited: false
      editors:
      - ExceedZhang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9009895920753479
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5427b05b3ef627d4d8281f9a33bb98ab.svg
          fullname: zhangwenbin
          isHf: false
          isPro: false
          name: ExceedZhang
          type: user
        html: '<p>Thanks</p>

          '
        raw: Thanks
        updatedAt: '2023-12-13T09:24:24.454Z'
      numEdits: 0
      reactions: []
    id: 65797848c37954680aedcf1d
    type: comment
  author: ExceedZhang
  content: Thanks
  created_at: 2023-12-13 09:24:24+00:00
  edited: false
  hidden: false
  id: 65797848c37954680aedcf1d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 21
repo_id: mistralai/Mixtral-8x7B-Instruct-v0.1
repo_type: model
status: open
target_branch: null
title: Test Mixtral Model loading ERROR!
