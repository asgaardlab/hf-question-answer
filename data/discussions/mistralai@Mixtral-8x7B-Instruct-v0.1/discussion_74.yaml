!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hegang126
conflicting_files: null
created_at: 2024-01-03 03:10:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/afe3e43e83923fc6bce7e85b714cd159.svg
      fullname: hegang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hegang126
      type: user
    createdAt: '2024-01-03T03:10:48.000Z'
    data:
      edited: false
      editors:
      - hegang126
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9147346615791321
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/afe3e43e83923fc6bce7e85b714cd159.svg
          fullname: hegang
          isHf: false
          isPro: false
          name: hegang126
          type: user
        html: '<p>as so far, I tried sft full finetuning with deepspeed zero3 on A100
          80G GPU, which will hang unti NCCL socket timeout in 30 minutes. Also When
          I tried lora with deepspeed2, which will fail in OOM, while lora with deepspeed
          zero3 will hang too!</p>

          <p>Only with lora and quantization 4 bit will succeed training.</p>

          '
        raw: "as so far, I tried sft full finetuning with deepspeed zero3 on A100\
          \ 80G GPU, which will hang unti NCCL socket timeout in 30 minutes. Also\
          \ When I tried lora with deepspeed2, which will fail in OOM, while lora\
          \ with deepspeed zero3 will hang too!\r\n\r\nOnly with lora and quantization\
          \ 4 bit will succeed training."
        updatedAt: '2024-01-03T03:10:48.428Z'
      numEdits: 0
      reactions: []
    id: 6594d038c0b1372b2e807a25
    type: comment
  author: hegang126
  content: "as so far, I tried sft full finetuning with deepspeed zero3 on A100 80G\
    \ GPU, which will hang unti NCCL socket timeout in 30 minutes. Also When I tried\
    \ lora with deepspeed2, which will fail in OOM, while lora with deepspeed zero3\
    \ will hang too!\r\n\r\nOnly with lora and quantization 4 bit will succeed training."
  created_at: 2024-01-03 03:10:48+00:00
  edited: false
  hidden: false
  id: 6594d038c0b1372b2e807a25
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/99571e7b0913aedec8042515c1dc703c.svg
      fullname: Cao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JiaxinTsao
      type: user
    createdAt: '2024-01-04T23:20:06.000Z'
    data:
      edited: false
      editors:
      - JiaxinTsao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8603557348251343
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/99571e7b0913aedec8042515c1dc703c.svg
          fullname: Cao
          isHf: false
          isPro: false
          name: JiaxinTsao
          type: user
        html: '<p>Same issue, any workaround?</p>

          '
        raw: Same issue, any workaround?
        updatedAt: '2024-01-04T23:20:06.747Z'
      numEdits: 0
      reactions: []
    id: 65973d2667b8fc62791d42cf
    type: comment
  author: JiaxinTsao
  content: Same issue, any workaround?
  created_at: 2024-01-04 23:20:06+00:00
  edited: false
  hidden: false
  id: 65973d2667b8fc62791d42cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b20961cfbacd0bade26ecc19da164581.svg
      fullname: guoweilong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guowl
      type: user
    createdAt: '2024-01-08T09:19:55.000Z'
    data:
      edited: false
      editors:
      - guowl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8603557348251343
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b20961cfbacd0bade26ecc19da164581.svg
          fullname: guoweilong
          isHf: false
          isPro: false
          name: guowl
          type: user
        html: '<p>Same issue, any workaround?</p>

          '
        raw: 'Same issue, any workaround?



          '
        updatedAt: '2024-01-08T09:19:55.986Z'
      numEdits: 0
      reactions: []
    id: 659bbe3b3b0b56c5e065b4c5
    type: comment
  author: guowl
  content: 'Same issue, any workaround?



    '
  created_at: 2024-01-08 09:19:55+00:00
  edited: false
  hidden: false
  id: 659bbe3b3b0b56c5e065b4c5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b20961cfbacd0bade26ecc19da164581.svg
      fullname: guoweilong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guowl
      type: user
    createdAt: '2024-01-12T09:31:34.000Z'
    data:
      edited: false
      editors:
      - guowl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8603557348251343
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b20961cfbacd0bade26ecc19da164581.svg
          fullname: guoweilong
          isHf: false
          isPro: false
          name: guowl
          type: user
        html: '<p>Same issue, any workaround?</p>

          '
        raw: 'Same issue, any workaround?


          '
        updatedAt: '2024-01-12T09:31:34.176Z'
      numEdits: 0
      reactions: []
    id: 65a106f6db5d37ad5eb32439
    type: comment
  author: guowl
  content: 'Same issue, any workaround?


    '
  created_at: 2024-01-12 09:31:34+00:00
  edited: false
  hidden: false
  id: 65a106f6db5d37ad5eb32439
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97111f5e4154df824d5d124bebaf8f18.svg
      fullname: zxs
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zxs1997zju
      type: user
    createdAt: '2024-01-22T05:40:38.000Z'
    data:
      edited: false
      editors:
      - zxs1997zju
      hidden: false
      identifiedLanguage:
        language: it
        probability: 0.564523458480835
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97111f5e4154df824d5d124bebaf8f18.svg
          fullname: zxs
          isHf: false
          isPro: false
          name: zxs1997zju
          type: user
        html: '<p>Any update?</p>

          '
        raw: 'Any update?

          '
        updatedAt: '2024-01-22T05:40:38.529Z'
      numEdits: 0
      reactions: []
    id: 65adffd630225893715f9a8d
    type: comment
  author: zxs1997zju
  content: 'Any update?

    '
  created_at: 2024-01-22 05:40:38+00:00
  edited: false
  hidden: false
  id: 65adffd630225893715f9a8d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/65ae23622582acc63607a39b/FobxHR-jnoG2791BLkfIv.jpeg?w=200&h=200&f=face
      fullname: Robert Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: A-Cepheus
      type: user
    createdAt: '2024-01-22T08:14:41.000Z'
    data:
      edited: false
      editors:
      - A-Cepheus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2303810566663742
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/65ae23622582acc63607a39b/FobxHR-jnoG2791BLkfIv.jpeg?w=200&h=200&f=face
          fullname: Robert Zhang
          isHf: false
          isPro: false
          name: A-Cepheus
          type: user
        html: '<p>try<br><code>from deepspeed.utils import set_z3_leaf_modules</code><br><code>from
          transformers.models.mixtral.modeling_mixtral import MixtralSparseMoeBlock</code><br><code>
          set_z3_leaf_modules(model, [MixtralSparseMoeBlock])</code></p>

          '
        raw: 'try

          `from deepspeed.utils import set_z3_leaf_modules`

          `from transformers.models.mixtral.modeling_mixtral import MixtralSparseMoeBlock`

          ` set_z3_leaf_modules(model, [MixtralSparseMoeBlock])`'
        updatedAt: '2024-01-22T08:14:41.774Z'
      numEdits: 0
      reactions: []
    id: 65ae23f1043d53781a120659
    type: comment
  author: A-Cepheus
  content: 'try

    `from deepspeed.utils import set_z3_leaf_modules`

    `from transformers.models.mixtral.modeling_mixtral import MixtralSparseMoeBlock`

    ` set_z3_leaf_modules(model, [MixtralSparseMoeBlock])`'
  created_at: 2024-01-22 08:14:41+00:00
  edited: false
  hidden: false
  id: 65ae23f1043d53781a120659
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97111f5e4154df824d5d124bebaf8f18.svg
      fullname: zxs
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zxs1997zju
      type: user
    createdAt: '2024-01-23T03:02:10.000Z'
    data:
      edited: false
      editors:
      - zxs1997zju
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9639429450035095
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97111f5e4154df824d5d124bebaf8f18.svg
          fullname: zxs
          isHf: false
          isPro: false
          name: zxs1997zju
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;A-Cepheus&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/A-Cepheus\">@<span class=\"\
          underline\">A-Cepheus</span></a></span>\n\n\t</span></span> thanks for reply,\
          \ the inference now is successful and loss is return,  however, the training\
          \ still hang in backward, any clues?</p>\n"
        raw: '@A-Cepheus thanks for reply, the inference now is successful and loss
          is return,  however, the training still hang in backward, any clues?'
        updatedAt: '2024-01-23T03:02:10.453Z'
      numEdits: 0
      reactions: []
    id: 65af2c321f418c7449316194
    type: comment
  author: zxs1997zju
  content: '@A-Cepheus thanks for reply, the inference now is successful and loss
    is return,  however, the training still hang in backward, any clues?'
  created_at: 2024-01-23 03:02:10+00:00
  edited: false
  hidden: false
  id: 65af2c321f418c7449316194
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97111f5e4154df824d5d124bebaf8f18.svg
      fullname: zxs
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zxs1997zju
      type: user
    createdAt: '2024-01-23T09:17:26.000Z'
    data:
      edited: false
      editors:
      - zxs1997zju
      hidden: false
      identifiedLanguage:
        language: it
        probability: 0.564523458480835
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97111f5e4154df824d5d124bebaf8f18.svg
          fullname: zxs
          isHf: false
          isPro: false
          name: zxs1997zju
          type: user
        html: '<p>Any update?</p>

          '
        raw: Any update?
        updatedAt: '2024-01-23T09:17:26.389Z'
      numEdits: 0
      reactions: []
    id: 65af8426755c534def2ad45c
    type: comment
  author: zxs1997zju
  content: Any update?
  created_at: 2024-01-23 09:17:26+00:00
  edited: false
  hidden: false
  id: 65af8426755c534def2ad45c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/99571e7b0913aedec8042515c1dc703c.svg
      fullname: Cao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JiaxinTsao
      type: user
    createdAt: '2024-01-23T13:59:13.000Z'
    data:
      edited: false
      editors:
      - JiaxinTsao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8872779011726379
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/99571e7b0913aedec8042515c1dc703c.svg
          fullname: Cao
          isHf: false
          isPro: false
          name: JiaxinTsao
          type: user
        html: '<p>I believe deepspeed need all experts weight to be involved during
          inference so that <code>zero3</code> could correctly sync data btw gpus.
          If all <code>8</code> experts are enabled inside <code>config.json</code>,
          the problem goes away.</p>

          '
        raw: I believe deepspeed need all experts weight to be involved during inference
          so that `zero3` could correctly sync data btw gpus. If all `8` experts are
          enabled inside `config.json`, the problem goes away.
        updatedAt: '2024-01-23T13:59:13.607Z'
      numEdits: 0
      reactions: []
    id: 65afc6316f4ce85ebf75a0c4
    type: comment
  author: JiaxinTsao
  content: I believe deepspeed need all experts weight to be involved during inference
    so that `zero3` could correctly sync data btw gpus. If all `8` experts are enabled
    inside `config.json`, the problem goes away.
  created_at: 2024-01-23 13:59:13+00:00
  edited: false
  hidden: false
  id: 65afc6316f4ce85ebf75a0c4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b20961cfbacd0bade26ecc19da164581.svg
      fullname: guoweilong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: guowl
      type: user
    createdAt: '2024-01-25T11:45:56.000Z'
    data:
      edited: false
      editors:
      - guowl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9165363311767578
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b20961cfbacd0bade26ecc19da164581.svg
          fullname: guoweilong
          isHf: false
          isPro: false
          name: guowl
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;A-Cepheus&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/A-Cepheus\"\
          >@<span class=\"underline\">A-Cepheus</span></a></span>\n\n\t</span></span>\
          \ thanks for reply, the inference now is successful and loss is return,\
          \  however, the training still hang in backward, any clues?</p>\n</blockquote>\n\
          <p>when i train mixtral model,  after 270 step, it will be hang . and GPU\
          \ 100% until NCCL timeout</p>\n"
        raw: '> @A-Cepheus thanks for reply, the inference now is successful and loss
          is return,  however, the training still hang in backward, any clues?


          when i train mixtral model,  after 270 step, it will be hang . and GPU 100%
          until NCCL timeout'
        updatedAt: '2024-01-25T11:45:56.722Z'
      numEdits: 0
      reactions: []
    id: 65b249f4ce74220b8331aedb
    type: comment
  author: guowl
  content: '> @A-Cepheus thanks for reply, the inference now is successful and loss
    is return,  however, the training still hang in backward, any clues?


    when i train mixtral model,  after 270 step, it will be hang . and GPU 100% until
    NCCL timeout'
  created_at: 2024-01-25 11:45:56+00:00
  edited: false
  hidden: false
  id: 65b249f4ce74220b8331aedb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 74
repo_id: mistralai/Mixtral-8x7B-Instruct-v0.1
repo_type: model
status: open
target_branch: null
title: can not run sft full finetuning.
