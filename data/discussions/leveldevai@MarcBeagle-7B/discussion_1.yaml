!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SeaZeeHech
conflicting_files: null
created_at: 2024-01-20 22:51:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0a9b8872029ae329e7b92cef11a78049.svg
      fullname: SeaZeeHech
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SeaZeeHech
      type: user
    createdAt: '2024-01-20T22:51:00.000Z'
    data:
      edited: false
      editors:
      - SeaZeeHech
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8777615427970886
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0a9b8872029ae329e7b92cef11a78049.svg
          fullname: SeaZeeHech
          isHf: false
          isPro: false
          name: SeaZeeHech
          type: user
        html: "<p>I think the &lt;|im_start|&gt; and &lt;|im_end|&gt; were added after\
          \ another user mentioned they weren't natively in the model vocab. But the\
          \ current config throws indexing errors anytime it is used. The below code\
          \ - changing the vocab size - will make it run without error, but the loss\
          \ is very high (~10 when other models are ~3 on my data), I presume because\
          \ the new tokens are just noise. But the indexing errors are gone. I'm not\
          \ sure how to just remove them from the tokenizer once instantiated.</p>\n\
          <p>Seems like these tokens shouldn't be added now if the model wasn't trained\
          \ with them and hasn't learned them? Am I missing something? Does it work\
          \ out of the box for others?</p>\n<pre><code class=\"language-python\">config\
          \ = AutoConfig.from_pretrained(self.args.generation_model_name)\nconfig.vocab_size\
          \ += <span class=\"hljs-number\">2</span>\n\ngenerator = AutoModelForCausalLM.from_pretrained(\n\
          \         <span class=\"hljs-string\">'leveldevai/MarcBeagle-7B'</span>,\
          \ config=config, ignore_mismatched_sizes=<span class=\"hljs-literal\">True</span>,\n\
          \         torch_dtype=torch.bfloat16,\n         attn_implementation=<span\
          \ class=\"hljs-string\">'flash_attention_2'</span>,\n         trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>\n)\n</code></pre>\n"
        raw: "I think the <|im_start|> and <|im_end|> were added after another user\
          \ mentioned they weren't natively in the model vocab. But the current config\
          \ throws indexing errors anytime it is used. The below code - changing the\
          \ vocab size - will make it run without error, but the loss is very high\
          \ (~10 when other models are ~3 on my data), I presume because the new tokens\
          \ are just noise. But the indexing errors are gone. I'm not sure how to\
          \ just remove them from the tokenizer once instantiated.\r\n\r\nSeems like\
          \ these tokens shouldn't be added now if the model wasn't trained with them\
          \ and hasn't learned them? Am I missing something? Does it work out of the\
          \ box for others?\r\n\r\n```python\r\nconfig = AutoConfig.from_pretrained(self.args.generation_model_name)\r\
          \nconfig.vocab_size += 2\r\n\r\ngenerator = AutoModelForCausalLM.from_pretrained(\r\
          \n         'leveldevai/MarcBeagle-7B', config=config, ignore_mismatched_sizes=True,\r\
          \n         torch_dtype=torch.bfloat16,\r\n         attn_implementation='flash_attention_2',\r\
          \n         trust_remote_code=True\r\n)\r\n```"
        updatedAt: '2024-01-20T22:51:00.704Z'
      numEdits: 0
      reactions: []
    id: 65ac4e54e0ee7990a6d652a6
    type: comment
  author: SeaZeeHech
  content: "I think the <|im_start|> and <|im_end|> were added after another user\
    \ mentioned they weren't natively in the model vocab. But the current config throws\
    \ indexing errors anytime it is used. The below code - changing the vocab size\
    \ - will make it run without error, but the loss is very high (~10 when other\
    \ models are ~3 on my data), I presume because the new tokens are just noise.\
    \ But the indexing errors are gone. I'm not sure how to just remove them from\
    \ the tokenizer once instantiated.\r\n\r\nSeems like these tokens shouldn't be\
    \ added now if the model wasn't trained with them and hasn't learned them? Am\
    \ I missing something? Does it work out of the box for others?\r\n\r\n```python\r\
    \nconfig = AutoConfig.from_pretrained(self.args.generation_model_name)\r\nconfig.vocab_size\
    \ += 2\r\n\r\ngenerator = AutoModelForCausalLM.from_pretrained(\r\n         'leveldevai/MarcBeagle-7B',\
    \ config=config, ignore_mismatched_sizes=True,\r\n         torch_dtype=torch.bfloat16,\r\
    \n         attn_implementation='flash_attention_2',\r\n         trust_remote_code=True\r\
    \n)\r\n```"
  created_at: 2024-01-20 22:51:00+00:00
  edited: false
  hidden: false
  id: 65ac4e54e0ee7990a6d652a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1dd96a0f4fbcc2a7d20e376f4daeb25d.svg
      fullname: leveldevai
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: leveldevai
      type: user
    createdAt: '2024-01-21T08:15:04.000Z'
    data:
      edited: false
      editors:
      - leveldevai
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9867956042289734
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1dd96a0f4fbcc2a7d20e376f4daeb25d.svg
          fullname: leveldevai
          isHf: false
          isPro: false
          name: leveldevai
          type: user
        html: '<p>Thanks for noticing.<br>This file seems to come from one of the
          models used in the merge, I updated a few things and it appears to be working
          well for me please let me know if you see anything</p>

          '
        raw: 'Thanks for noticing.

          This file seems to come from one of the models used in the merge, I updated
          a few things and it appears to be working well for me please let me know
          if you see anything'
        updatedAt: '2024-01-21T08:15:04.668Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - SeaZeeHech
    id: 65acd2886a55aac02a5fc926
    type: comment
  author: leveldevai
  content: 'Thanks for noticing.

    This file seems to come from one of the models used in the merge, I updated a
    few things and it appears to be working well for me please let me know if you
    see anything'
  created_at: 2024-01-21 08:15:04+00:00
  edited: false
  hidden: false
  id: 65acd2886a55aac02a5fc926
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: leveldevai/MarcBeagle-7B
repo_type: model
status: open
target_branch: null
title: added_tokens_decoder Seem to Cause Index Errors
