!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Sunjay353
conflicting_files: null
created_at: 2023-11-14 14:55:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d2603f74ded4efdbb2d2bb75a427dd3a.svg
      fullname: Sunjay Dewitt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sunjay353
      type: user
    createdAt: '2023-11-14T14:55:59.000Z'
    data:
      edited: false
      editors:
      - Sunjay353
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.23924888670444489
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d2603f74ded4efdbb2d2bb75a427dd3a.svg
          fullname: Sunjay Dewitt
          isHf: false
          isPro: false
          name: Sunjay353
          type: user
        html: '<p>I get the following error, when loading this model in  text-generation-webui
          (fresh installation, with oneclick installer):</p>

          <p>2023-11-14 15:51:39 INFO:Loading TheBloke_em_german_leo_mistral-GPTQ...<br>2023-11-14
          15:51:43 ERROR:Failed to load the model.<br>Traceback (most recent call
          last):<br>  File "D:\Repositories\Git\text-generation-webui\modules\ui_model_menu.py",
          line 210, in load_model_wrapper<br>    shared.model, shared.tokenizer =
          load_model(shared.model_name, loader)<br>                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "D:\Repositories\Git\text-generation-webui\modules\models.py", line 85,
          in load_model<br>    output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "D:\Repositories\Git\text-generation-webui\modules\models.py", line 356,
          in ExLlamav2_loader<br>    model, tokenizer = Exllamav2Model.from_pretrained(model_name)<br>                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "D:\Repositories\Git\text-generation-webui\modules\exllamav2.py", line 60,
          in from_pretrained<br>    tokenizer = ExLlamaV2Tokenizer(config)<br>                ^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "D:\Repositories\Git\text-generation-webui\installer_files\env\Lib\site-packages\exllamav2\tokenizer.py",
          line 52, in <strong>init</strong><br>    self.tokenizer = SentencePieceProcessor(model_file
          = self.config.tokenizer_path)<br>                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "D:\Repositories\Git\text-generation-webui\installer_files\env\Lib\site-packages\sentencepiece_<em>init</em><em>.py",
          line 447, in Init<br>    self.Load(model_file=model_file, model_proto=model_proto)<br>  File
          "D:\Repositories\Git\text-generation-webui\installer_files\env\Lib\site-packages\sentencepiece_<em>init</em></em>.py",
          line 905, in Load<br>    return self.LoadFromFile(model_file)<br>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "D:\Repositories\Git\text-generation-webui\installer_files\env\Lib\site-packages\sentencepiece_<em>init</em>_.py",
          line 310, in LoadFromFile<br>    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,
          arg)<br>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>OSError:
          Not found: "models\TheBloke_em_german_leo_mistral-GPTQ\tokenizer.model":
          No such file or directory Error #2</p>

          '
        raw: "I get the following error, when loading this model in  text-generation-webui\
          \ (fresh installation, with oneclick installer):\r\n\r\n2023-11-14 15:51:39\
          \ INFO:Loading TheBloke_em_german_leo_mistral-GPTQ...\r\n2023-11-14 15:51:43\
          \ ERROR:Failed to load the model.\r\nTraceback (most recent call last):\r\
          \n  File \"D:\\Repositories\\Git\\text-generation-webui\\modules\\ui_model_menu.py\"\
          , line 210, in load_model_wrapper\r\n    shared.model, shared.tokenizer\
          \ = load_model(shared.model_name, loader)\r\n                          \
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Repositories\\\
          Git\\text-generation-webui\\modules\\models.py\", line 85, in load_model\r\
          \n    output = load_func_map[loader](model_name)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"D:\\Repositories\\Git\\text-generation-webui\\modules\\models.py\"\
          , line 356, in ExLlamav2_loader\r\n    model, tokenizer = Exllamav2Model.from_pretrained(model_name)\r\
          \n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\
          \  File \"D:\\Repositories\\Git\\text-generation-webui\\modules\\exllamav2.py\"\
          , line 60, in from_pretrained\r\n    tokenizer = ExLlamaV2Tokenizer(config)\r\
          \n                ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Repositories\\\
          Git\\text-generation-webui\\installer_files\\env\\Lib\\site-packages\\exllamav2\\\
          tokenizer.py\", line 52, in __init__\r\n    self.tokenizer = SentencePieceProcessor(model_file\
          \ = self.config.tokenizer_path)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"D:\\Repositories\\Git\\text-generation-webui\\installer_files\\\
          env\\Lib\\site-packages\\sentencepiece\\__init__.py\", line 447, in Init\r\
          \n    self.Load(model_file=model_file, model_proto=model_proto)\r\n  File\
          \ \"D:\\Repositories\\Git\\text-generation-webui\\installer_files\\env\\\
          Lib\\site-packages\\sentencepiece\\__init__.py\", line 905, in Load\r\n\
          \    return self.LoadFromFile(model_file)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n  File \"D:\\Repositories\\Git\\text-generation-webui\\installer_files\\\
          env\\Lib\\site-packages\\sentencepiece\\__init__.py\", line 310, in LoadFromFile\r\
          \n    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)\r\
          \n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \nOSError: Not found: \"models\\TheBloke_em_german_leo_mistral-GPTQ\\tokenizer.model\"\
          : No such file or directory Error #2"
        updatedAt: '2023-11-14T14:55:59.982Z'
      numEdits: 0
      reactions: []
    id: 65538a7f2bcac7af49915e8c
    type: comment
  author: Sunjay353
  content: "I get the following error, when loading this model in  text-generation-webui\
    \ (fresh installation, with oneclick installer):\r\n\r\n2023-11-14 15:51:39 INFO:Loading\
    \ TheBloke_em_german_leo_mistral-GPTQ...\r\n2023-11-14 15:51:43 ERROR:Failed to\
    \ load the model.\r\nTraceback (most recent call last):\r\n  File \"D:\\Repositories\\\
    Git\\text-generation-webui\\modules\\ui_model_menu.py\", line 210, in load_model_wrapper\r\
    \n    shared.model, shared.tokenizer = load_model(shared.model_name, loader)\r\
    \n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"D:\\Repositories\\Git\\text-generation-webui\\modules\\models.py\"\
    , line 85, in load_model\r\n    output = load_func_map[loader](model_name)\r\n\
    \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Repositories\\\
    Git\\text-generation-webui\\modules\\models.py\", line 356, in ExLlamav2_loader\r\
    \n    model, tokenizer = Exllamav2Model.from_pretrained(model_name)\r\n      \
    \                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\\
    Repositories\\Git\\text-generation-webui\\modules\\exllamav2.py\", line 60, in\
    \ from_pretrained\r\n    tokenizer = ExLlamaV2Tokenizer(config)\r\n          \
    \      ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Repositories\\Git\\text-generation-webui\\\
    installer_files\\env\\Lib\\site-packages\\exllamav2\\tokenizer.py\", line 52,\
    \ in __init__\r\n    self.tokenizer = SentencePieceProcessor(model_file = self.config.tokenizer_path)\r\
    \n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"D:\\Repositories\\Git\\text-generation-webui\\installer_files\\env\\\
    Lib\\site-packages\\sentencepiece\\__init__.py\", line 447, in Init\r\n    self.Load(model_file=model_file,\
    \ model_proto=model_proto)\r\n  File \"D:\\Repositories\\Git\\text-generation-webui\\\
    installer_files\\env\\Lib\\site-packages\\sentencepiece\\__init__.py\", line 905,\
    \ in Load\r\n    return self.LoadFromFile(model_file)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n  File \"D:\\Repositories\\Git\\text-generation-webui\\installer_files\\env\\\
    Lib\\site-packages\\sentencepiece\\__init__.py\", line 310, in LoadFromFile\r\n\
    \    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)\r\n\
    \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\
    OSError: Not found: \"models\\TheBloke_em_german_leo_mistral-GPTQ\\tokenizer.model\"\
    : No such file or directory Error #2"
  created_at: 2023-11-14 14:55:59+00:00
  edited: false
  hidden: false
  id: 65538a7f2bcac7af49915e8c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/em_german_leo_mistral-GPTQ
repo_type: model
status: open
target_branch: null
title: 'OSError: Not found: "models\TheBloke_em_german_leo_mistral-GPTQ\tokenizer.model":
  No such file or directory Error #2'
