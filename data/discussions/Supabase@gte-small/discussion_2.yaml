!!python/object:huggingface_hub.community.DiscussionWithDetails
author: varun4
conflicting_files: null
created_at: 2023-08-30 19:15:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d2a5f4cce188db7086e7f8f56e284554.svg
      fullname: Varun Srivastava
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: varun4
      type: user
    createdAt: '2023-08-30T20:15:03.000Z'
    data:
      edited: true
      editors:
      - varun4
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7921726107597351
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d2a5f4cce188db7086e7f8f56e284554.svg
          fullname: Varun Srivastava
          isHf: false
          isPro: false
          name: varun4
          type: user
        html: '<p>Hello team! The size of the unquantized onnx model is 133mb, whereas
          the <a href="https://huggingface.co/thenlper/gte-small/tree/main">pytorch
          model</a> is only 66.8mb. This is generally uncommon. For example, all-MiniLM-L6-v2''s
          <a href="https://huggingface.co/Xenova/all-MiniLM-L6-v2/tree/main/onnx">unquantized</a>
          size is 90mb, roughly the same as the <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/tree/main">pytorch
          model</a>. </p>

          <p>While this isn''t a problem itself, I wanted to raise this issue for
          further investigation. </p>

          <p>Edit: I found Xenova has also uploaded his own version of this model,
          <a href="https://huggingface.co/Xenova/gte-small">here</a>, and it has the
          same issue. </p>

          '
        raw: "Hello team! The size of the unquantized onnx model is 133mb, whereas\
          \ the [pytorch model](https://huggingface.co/thenlper/gte-small/tree/main)\
          \ is only 66.8mb. This is generally uncommon. For example, all-MiniLM-L6-v2's\
          \ [unquantized](https://huggingface.co/Xenova/all-MiniLM-L6-v2/tree/main/onnx)\
          \ size is 90mb, roughly the same as the [pytorch model](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/tree/main).\
          \ \n\nWhile this isn't a problem itself, I wanted to raise this issue for\
          \ further investigation. \n\nEdit: I found Xenova has also uploaded his\
          \ own version of this model, [here](https://huggingface.co/Xenova/gte-small),\
          \ and it has the same issue. "
        updatedAt: '2023-08-30T20:24:31.486Z'
      numEdits: 1
      reactions: []
    id: 64efa3476101335336660ead
    type: comment
  author: varun4
  content: "Hello team! The size of the unquantized onnx model is 133mb, whereas the\
    \ [pytorch model](https://huggingface.co/thenlper/gte-small/tree/main) is only\
    \ 66.8mb. This is generally uncommon. For example, all-MiniLM-L6-v2's [unquantized](https://huggingface.co/Xenova/all-MiniLM-L6-v2/tree/main/onnx)\
    \ size is 90mb, roughly the same as the [pytorch model](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/tree/main).\
    \ \n\nWhile this isn't a problem itself, I wanted to raise this issue for further\
    \ investigation. \n\nEdit: I found Xenova has also uploaded his own version of\
    \ this model, [here](https://huggingface.co/Xenova/gte-small), and it has the\
    \ same issue. "
  created_at: 2023-08-30 19:15:03+00:00
  edited: true
  hidden: false
  id: 64efa3476101335336660ead
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63267719ff539edeea96336a/ASNS3IY6apkwOG3k5ev1I.png?w=200&h=200&f=face
      fullname: Greg Richardson
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ggrn
      type: user
    createdAt: '2023-08-30T20:32:10.000Z'
    data:
      edited: false
      editors:
      - ggrn
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9458467364311218
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63267719ff539edeea96336a/ASNS3IY6apkwOG3k5ev1I.png?w=200&h=200&f=face
          fullname: Greg Richardson
          isHf: false
          isPro: false
          name: ggrn
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;varun4&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/varun4\">@<span class=\"\
          underline\">varun4</span></a></span>\n\n\t</span></span> I was confused\
          \ by this at first too. The pytorch model for <code>gte-small</code> is\
          \ <a href=\"https://huggingface.co/thenlper/gte-small/blob/main/config.json#L19\"\
          >16 bit</a> as opposed to many other models that are 32 bit. The non-quantized\
          \ ONNX models are always 32 bit, and quantized are 8 bit. This is why the\
          \ non-quantized ONNX model is double the size of the pytorch model, and\
          \ quantized ONNX model is half the size of the pytorch model.</p>\n"
        raw: '@varun4 I was confused by this at first too. The pytorch model for `gte-small`
          is [16 bit](https://huggingface.co/thenlper/gte-small/blob/main/config.json#L19)
          as opposed to many other models that are 32 bit. The non-quantized ONNX
          models are always 32 bit, and quantized are 8 bit. This is why the non-quantized
          ONNX model is double the size of the pytorch model, and quantized ONNX model
          is half the size of the pytorch model.'
        updatedAt: '2023-08-30T20:32:10.838Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Xenova
        - varun4
    id: 64efa74a6c34f89ab17d15cc
    type: comment
  author: ggrn
  content: '@varun4 I was confused by this at first too. The pytorch model for `gte-small`
    is [16 bit](https://huggingface.co/thenlper/gte-small/blob/main/config.json#L19)
    as opposed to many other models that are 32 bit. The non-quantized ONNX models
    are always 32 bit, and quantized are 8 bit. This is why the non-quantized ONNX
    model is double the size of the pytorch model, and quantized ONNX model is half
    the size of the pytorch model.'
  created_at: 2023-08-30 19:32:10+00:00
  edited: false
  hidden: false
  id: 64efa74a6c34f89ab17d15cc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d2a5f4cce188db7086e7f8f56e284554.svg
      fullname: Varun Srivastava
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: varun4
      type: user
    createdAt: '2023-08-31T00:19:22.000Z'
    data:
      edited: false
      editors:
      - varun4
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8944261074066162
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d2a5f4cce188db7086e7f8f56e284554.svg
          fullname: Varun Srivastava
          isHf: false
          isPro: false
          name: varun4
          type: user
        html: '<p>That makes sense thank you!</p>

          '
        raw: That makes sense thank you!
        updatedAt: '2023-08-31T00:19:22.359Z'
      numEdits: 0
      reactions: []
    id: 64efdc8abae933568b77920a
    type: comment
  author: varun4
  content: That makes sense thank you!
  created_at: 2023-08-30 23:19:22+00:00
  edited: false
  hidden: false
  id: 64efdc8abae933568b77920a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63267719ff539edeea96336a/ASNS3IY6apkwOG3k5ev1I.png?w=200&h=200&f=face
      fullname: Greg Richardson
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ggrn
      type: user
    createdAt: '2023-09-03T21:57:13.000Z'
    data:
      status: closed
    id: 64f50139ebd09530c3dbda0e
    type: status-change
  author: ggrn
  created_at: 2023-09-03 20:57:13+00:00
  id: 64f50139ebd09530c3dbda0e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Supabase/gte-small
repo_type: model
status: closed
target_branch: null
title: Discrepancy in model sizes
