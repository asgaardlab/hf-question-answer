!!python/object:huggingface_hub.community.DiscussionWithDetails
author: muhammadbaasit
conflicting_files: null
created_at: 2023-09-22 19:35:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d0979c1ca701a336a7cfc7445dff92bf.svg
      fullname: Mohammad Baasit
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: muhammadbaasit
      type: user
    createdAt: '2023-09-22T20:35:04.000Z'
    data:
      edited: false
      editors:
      - muhammadbaasit
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4610283076763153
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d0979c1ca701a336a7cfc7445dff92bf.svg
          fullname: Mohammad Baasit
          isHf: false
          isPro: false
          name: muhammadbaasit
          type: user
        html: "<p>Hi Team,</p>\n<p>I\u2019m working on Huggingface Tapas model, as\
          \ it is working, I\u2019m trying to convert Huggingface Tapas model to torchscript\
          \ model, in order to deploy this model in Nvidia Triton Server.</p>\n<p>from\
          \ transformers import TapasTokenizer, TapasForQuestionAnswering<br>import\
          \ pandas as pd</p>\n<p>model_name = \"google/tapas-base-finetuned-wtq\"\
          <br>model = TapasForQuestionAnswering.from_pretrained(model_name, torchscript=True)<br>tokenizer\
          \ = TapasTokenizer.from_pretrained(model_name)<br>data = {\"Actors\": [\"\
          Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\"\
          : [\"87\", \"53\", \"69\"]}<br>queries = \"What is the name of the first\
          \ actor?\"<br>table = pd.DataFrame.from_dict(data)<br>inputs = tokenizer(table=table,\
          \ queries=queries, padding=\"max_length\", return_tensors=\"pt\")<br>outputs\
          \ = model(**inputs,return_dict=True)<br>predicted_answer_coordinates, predicted_aggregation_indices\
          \ = tokenizer.convert_logits_to_predictions(<br>    inputs, outputs.logits.detach(),\
          \ outputs.logits_aggregation.detach()<br>)</p>\n<h1 id=\"creating-the-trace\"\
          >Creating the trace</h1>\n<p>import torch<br>traced_model = torch.jit.trace(model,\
          \ [inputs['input_ids'], inputs['token_type_ids'], inputs['attention_mask']])<br>torch.jit.save(traced_model,\
          \ \"traced_bert.pt\")</p>\n<p>when I try to trace the model, its throwing\
          \ below error which indexerror, could you please help me here? I don\u2019\
          t know whether I\u2019m doing a mistake or not. Please correct me if I\u2019\
          m doing any mistake.</p>\n<p>IndexError                                Traceback\
          \ (most recent call last)<br>Cell In[10], line 3<br>      1 # Creating the\
          \ trace<br>      2 import torch<br>----&gt; 3 traced_model = torch.jit.trace(model,\
          \ [inputs['input_ids'], inputs['token_type_ids'], inputs['attention_mask']])<br>\
          \      4 torch.jit.save(traced_model, \"traced_bert.pt\")</p>\n<p>File ~/miniconda3/envs/scrubai/lib/python3.9/site-packages/torch/jit/_trace.py:735,\
          \ in trace(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance,\
          \ strict, _force_outplace, _module_class, _compilation_unit)<br>    732\
          \     return func<br>    734 if isinstance(func, torch.nn.Module):<br>--&gt;\
          \ 735     return trace_module(<br>    736         func,<br>    737     \
          \    {\"forward\": example_inputs},<br>    738         None,<br>    739\
          \         check_trace,<br>    740         wrap_check_inputs(check_inputs),<br>\
          \    741         check_tolerance,<br>    742         strict,<br>    743\
          \         _force_outplace,<br>    744         _module_class,<br>    745\
          \     )<br>    747 if (<br>    748     hasattr(func, \"<strong>self</strong>\"\
          )<br>    749     and isinstance(func.<strong>self</strong>, torch.nn.Module)<br>...<br>--&gt;\
          \ 312     col_index = IndexMap(token_type_ids[:, :, 1], self.config.type_vocab_sizes[1],\
          \ batch_dims=1)<br>    313     # shape (batch_size, seq_len)<br>    314\
          \     row_index = IndexMap(token_type_ids[:, :, 2], self.config.type_vocab_sizes[2],\
          \ batch_dims=1)</p>\n<p>IndexError: too many indices for tensor of dimension\
          \ 2</p>\n"
        raw: "Hi Team,\r\n\r\nI\u2019m working on Huggingface Tapas model, as it is\
          \ working, I\u2019m trying to convert Huggingface Tapas model to torchscript\
          \ model, in order to deploy this model in Nvidia Triton Server.\r\n\r\n\r\
          \nfrom transformers import TapasTokenizer, TapasForQuestionAnswering\r\n\
          import pandas as pd\r\n\r\nmodel_name = \"google/tapas-base-finetuned-wtq\"\
          \r\nmodel = TapasForQuestionAnswering.from_pretrained(model_name, torchscript=True)\r\
          \ntokenizer = TapasTokenizer.from_pretrained(model_name)\r\ndata = {\"Actors\"\
          : [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number\
          \ of movies\": [\"87\", \"53\", \"69\"]}\r\nqueries = \"What is the name\
          \ of the first actor?\"\r\ntable = pd.DataFrame.from_dict(data)\r\ninputs\
          \ = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"\
          pt\")\r\noutputs = model(**inputs,return_dict=True)\r\npredicted_answer_coordinates,\
          \ predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\r\
          \n    inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\r\
          \n)\r\n\r\n# Creating the trace\r\nimport torch\r\ntraced_model = torch.jit.trace(model,\
          \ [inputs['input_ids'], inputs['token_type_ids'], inputs['attention_mask']])\r\
          \ntorch.jit.save(traced_model, \"traced_bert.pt\")\r\n\r\nwhen I try to\
          \ trace the model, its throwing below error which indexerror, could you\
          \ please help me here? I don\u2019t know whether I\u2019m doing a mistake\
          \ or not. Please correct me if I\u2019m doing any mistake.\r\n\r\nIndexError\
          \                                Traceback (most recent call last)\r\nCell\
          \ In[10], line 3\r\n      1 # Creating the trace\r\n      2 import torch\r\
          \n----> 3 traced_model = torch.jit.trace(model, [inputs['input_ids'], inputs['token_type_ids'],\
          \ inputs['attention_mask']])\r\n      4 torch.jit.save(traced_model, \"\
          traced_bert.pt\")\r\n\r\nFile ~/miniconda3/envs/scrubai/lib/python3.9/site-packages/torch/jit/_trace.py:735,\
          \ in trace(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance,\
          \ strict, _force_outplace, _module_class, _compilation_unit)\r\n    732\
          \     return func\r\n    734 if isinstance(func, torch.nn.Module):\r\n-->\
          \ 735     return trace_module(\r\n    736         func,\r\n    737     \
          \    {\"forward\": example_inputs},\r\n    738         None,\r\n    739\
          \         check_trace,\r\n    740         wrap_check_inputs(check_inputs),\r\
          \n    741         check_tolerance,\r\n    742         strict,\r\n    743\
          \         _force_outplace,\r\n    744         _module_class,\r\n    745\
          \     )\r\n    747 if (\r\n    748     hasattr(func, \"__self__\")\r\n \
          \   749     and isinstance(func.__self__, torch.nn.Module)\r\n...\r\n-->\
          \ 312     col_index = IndexMap(token_type_ids[:, :, 1], self.config.type_vocab_sizes[1],\
          \ batch_dims=1)\r\n    313     # shape (batch_size, seq_len)\r\n    314\
          \     row_index = IndexMap(token_type_ids[:, :, 2], self.config.type_vocab_sizes[2],\
          \ batch_dims=1)\r\n\r\nIndexError: too many indices for tensor of dimension\
          \ 2"
        updatedAt: '2023-09-22T20:35:04.241Z'
      numEdits: 0
      reactions: []
    id: 650dfa78f141bc34f9018f4d
    type: comment
  author: muhammadbaasit
  content: "Hi Team,\r\n\r\nI\u2019m working on Huggingface Tapas model, as it is\
    \ working, I\u2019m trying to convert Huggingface Tapas model to torchscript model,\
    \ in order to deploy this model in Nvidia Triton Server.\r\n\r\n\r\nfrom transformers\
    \ import TapasTokenizer, TapasForQuestionAnswering\r\nimport pandas as pd\r\n\r\
    \nmodel_name = \"google/tapas-base-finetuned-wtq\"\r\nmodel = TapasForQuestionAnswering.from_pretrained(model_name,\
    \ torchscript=True)\r\ntokenizer = TapasTokenizer.from_pretrained(model_name)\r\
    \ndata = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"\
    ], \"Number of movies\": [\"87\", \"53\", \"69\"]}\r\nqueries = \"What is the\
    \ name of the first actor?\"\r\ntable = pd.DataFrame.from_dict(data)\r\ninputs\
    \ = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"\
    pt\")\r\noutputs = model(**inputs,return_dict=True)\r\npredicted_answer_coordinates,\
    \ predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\r\n\
    \    inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\r\n\
    )\r\n\r\n# Creating the trace\r\nimport torch\r\ntraced_model = torch.jit.trace(model,\
    \ [inputs['input_ids'], inputs['token_type_ids'], inputs['attention_mask']])\r\
    \ntorch.jit.save(traced_model, \"traced_bert.pt\")\r\n\r\nwhen I try to trace\
    \ the model, its throwing below error which indexerror, could you please help\
    \ me here? I don\u2019t know whether I\u2019m doing a mistake or not. Please correct\
    \ me if I\u2019m doing any mistake.\r\n\r\nIndexError                        \
    \        Traceback (most recent call last)\r\nCell In[10], line 3\r\n      1 #\
    \ Creating the trace\r\n      2 import torch\r\n----> 3 traced_model = torch.jit.trace(model,\
    \ [inputs['input_ids'], inputs['token_type_ids'], inputs['attention_mask']])\r\
    \n      4 torch.jit.save(traced_model, \"traced_bert.pt\")\r\n\r\nFile ~/miniconda3/envs/scrubai/lib/python3.9/site-packages/torch/jit/_trace.py:735,\
    \ in trace(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance,\
    \ strict, _force_outplace, _module_class, _compilation_unit)\r\n    732     return\
    \ func\r\n    734 if isinstance(func, torch.nn.Module):\r\n--> 735     return\
    \ trace_module(\r\n    736         func,\r\n    737         {\"forward\": example_inputs},\r\
    \n    738         None,\r\n    739         check_trace,\r\n    740         wrap_check_inputs(check_inputs),\r\
    \n    741         check_tolerance,\r\n    742         strict,\r\n    743     \
    \    _force_outplace,\r\n    744         _module_class,\r\n    745     )\r\n \
    \   747 if (\r\n    748     hasattr(func, \"__self__\")\r\n    749     and isinstance(func.__self__,\
    \ torch.nn.Module)\r\n...\r\n--> 312     col_index = IndexMap(token_type_ids[:,\
    \ :, 1], self.config.type_vocab_sizes[1], batch_dims=1)\r\n    313     # shape\
    \ (batch_size, seq_len)\r\n    314     row_index = IndexMap(token_type_ids[:,\
    \ :, 2], self.config.type_vocab_sizes[2], batch_dims=1)\r\n\r\nIndexError: too\
    \ many indices for tensor of dimension 2"
  created_at: 2023-09-22 19:35:04+00:00
  edited: false
  hidden: false
  id: 650dfa78f141bc34f9018f4d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: google/tapas-base-finetuned-wtq
repo_type: model
status: open
target_branch: null
title: Unable to convert Huggingface model to torchscript
