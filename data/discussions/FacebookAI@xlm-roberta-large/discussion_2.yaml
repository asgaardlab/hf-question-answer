!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bonadossou
conflicting_files: null
created_at: 2022-05-29 09:13:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666955415972-605dd96184a51781b143a131.jpeg?w=200&h=200&f=face
      fullname: Bonaventure Dossou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bonadossou
      type: user
    createdAt: '2022-05-29T10:13:18.000Z'
    data:
      edited: false
      editors:
      - bonadossou
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666955415972-605dd96184a51781b143a131.jpeg?w=200&h=200&f=face
          fullname: Bonaventure Dossou
          isHf: false
          isPro: false
          name: bonadossou
          type: user
        html: '<p>How to the XLM-R of HF train on our own languages, from scratch?
          The documentation is not super clear about it. I was working mainly with
          this (<a rel="nofollow" href="https://github.com/facebookresearch/XLM">https://github.com/facebookresearch/XLM</a>)
          but it is complex enough for my purpose.</p>

          '
        raw: How to the XLM-R of HF train on our own languages, from scratch? The
          documentation is not super clear about it. I was working mainly with this
          (https://github.com/facebookresearch/XLM) but it is complex enough for my
          purpose.
        updatedAt: '2022-05-29T10:13:18.000Z'
      numEdits: 0
      reactions: []
    id: 6293473e25ee4c63e1c8ae89
    type: comment
  author: bonadossou
  content: How to the XLM-R of HF train on our own languages, from scratch? The documentation
    is not super clear about it. I was working mainly with this (https://github.com/facebookresearch/XLM)
    but it is complex enough for my purpose.
  created_at: 2022-05-29 09:13:18+00:00
  edited: false
  hidden: false
  id: 6293473e25ee4c63e1c8ae89
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2022-05-30T09:26:09.000Z'
    data:
      edited: false
      editors:
      - patrickvonplaten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
          fullname: Patrick von Platen
          isHf: true
          isPro: false
          name: patrickvonplaten
          type: user
        html: '<p>Hey @bonadossue, </p>

          <p>In general, I would not recommend to train XLM-R from scratch as it has
          been pretrained on all kinds of languages and one should be able to just
          fine-tune it on your preferred language. If you really want to run a whole
          pretraining though, I''d recommend the following example: <a rel="nofollow"
          href="https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py">https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py</a></p>

          <p>Which languages are you mostly interested in?</p>

          '
        raw: "Hey @bonadossue, \n\nIn general, I would not recommend to train XLM-R\
          \ from scratch as it has been pretrained on all kinds of languages and one\
          \ should be able to just fine-tune it on your preferred language. If you\
          \ really want to run a whole pretraining though, I'd recommend the following\
          \ example: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n\
          \nWhich languages are you mostly interested in?"
        updatedAt: '2022-05-30T09:26:09.000Z'
      numEdits: 0
      reactions: []
    id: 62948db1b9d93a4199054f9e
    type: comment
  author: patrickvonplaten
  content: "Hey @bonadossue, \n\nIn general, I would not recommend to train XLM-R\
    \ from scratch as it has been pretrained on all kinds of languages and one should\
    \ be able to just fine-tune it on your preferred language. If you really want\
    \ to run a whole pretraining though, I'd recommend the following example: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n\
    \nWhich languages are you mostly interested in?"
  created_at: 2022-05-30 08:26:09+00:00
  edited: false
  hidden: false
  id: 62948db1b9d93a4199054f9e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666955415972-605dd96184a51781b143a131.jpeg?w=200&h=200&f=face
      fullname: Bonaventure Dossou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bonadossou
      type: user
    createdAt: '2022-05-30T09:27:51.000Z'
    data:
      edited: false
      editors:
      - bonadossou
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1666955415972-605dd96184a51781b143a131.jpeg?w=200&h=200&f=face
          fullname: Bonaventure Dossou
          isHf: false
          isPro: false
          name: bonadossou
          type: user
        html: '<p>Many languages like Fon, Ghomala, Bambara, etc</p>

          '
        raw: Many languages like Fon, Ghomala, Bambara, etc
        updatedAt: '2022-05-30T09:27:51.000Z'
      numEdits: 0
      reactions: []
    id: 62948e171e87ffbe5c03d19d
    type: comment
  author: bonadossou
  content: Many languages like Fon, Ghomala, Bambara, etc
  created_at: 2022-05-30 08:27:51+00:00
  edited: false
  hidden: false
  id: 62948e171e87ffbe5c03d19d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2022-05-30T20:10:28.000Z'
    data:
      edited: false
      editors:
      - patrickvonplaten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
          fullname: Patrick von Platen
          isHf: true
          isPro: false
          name: patrickvonplaten
          type: user
        html: '<p>Ok did you try just fine-tuning XLM-R on those languages? </p>

          '
        raw: 'Ok did you try just fine-tuning XLM-R on those languages? '
        updatedAt: '2022-05-30T20:10:28.000Z'
      numEdits: 0
      reactions: []
    id: 629524b4b9d93a4199084355
    type: comment
  author: patrickvonplaten
  content: 'Ok did you try just fine-tuning XLM-R on those languages? '
  created_at: 2022-05-30 19:10:28+00:00
  edited: false
  hidden: false
  id: 629524b4b9d93a4199084355
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: FacebookAI/xlm-roberta-large
repo_type: model
status: open
target_branch: null
title: Use XLM-R to build LM on X-languages (X>=5) from scratch
