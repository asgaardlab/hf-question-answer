!!python/object:huggingface_hub.community.DiscussionWithDetails
author: patrickvonplaten
conflicting_files: []
created_at: 2023-06-21 11:38:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2023-06-21T12:38:48.000Z'
    data:
      edited: false
      editors:
      - patrickvonplaten
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7679266929626465
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
          fullname: Patrick von Platen
          isHf: true
          isPro: false
          name: patrickvonplaten
          type: user
        html: "<p>Hey patrickvonplaten \U0001F44B, </p>\n<p> Your model repository\
          \ seems to contain a <a href=\"https://huggingface.co/patrickvonplaten/test_sd_1/tree/fp16\"\
          ><code>fp16</code> branch</a> to load the model in float16 precision. Loading\
          \ <code>fp16</code> versions from a branch instead of the main branch is\
          \ deprecated and will eventually be forbidden. Instead, we strongly recommend\
          \ to save <code>fp16</code> versions of the model under <code>.fp16.</code>\
          \ version files directly on the 'main' branch as enabled through this PR.This\
          \ PR makes sure that your model repository allows the user to correctly\
          \ download float16 precision model weights by adding <code>fp16</code> model\
          \ weights in both safetensors and PyTorch bin format:</p>\n<pre><code class=\"\
          language-py\">pipe = DiffusionPipeline.from_pretrained(patrickvonplaten/test_sd_1,\
          \ torch_dtype=torch.float16, variant=<span class=\"hljs-string\">'fp16'</span>)\n\
          </code></pre>\n<p>For more information please have a look at: <a href=\"\
          https://huggingface.co/docs/diffusers/using-diffusers/loading#checkpoint-variants\"\
          >https://huggingface.co/docs/diffusers/using-diffusers/loading#checkpoint-variants</a>.<br>We\
          \ made sure you that you can safely merge this pull request. </p>\n<p> Best,\
          \ the \U0001F9E8 Diffusers team.</p>\n"
        raw: "Hey patrickvonplaten \U0001F44B, \n\n Your model repository seems to\
          \ contain a [`fp16` branch](https://huggingface.co/patrickvonplaten/test_sd_1/tree/fp16)\
          \ to load the model in float16 precision. Loading `fp16` versions from a\
          \ branch instead of the main branch is deprecated and will eventually be\
          \ forbidden. Instead, we strongly recommend to save `fp16` versions of the\
          \ model under `.fp16.` version files directly on the 'main' branch as enabled\
          \ through this PR.This PR makes sure that your model repository allows the\
          \ user to correctly download float16 precision model weights by adding `fp16`\
          \ model weights in both safetensors and PyTorch bin format:\n\n```py\npipe\
          \ = DiffusionPipeline.from_pretrained(patrickvonplaten/test_sd_1, torch_dtype=torch.float16,\
          \ variant='fp16')\n```\n\nFor more information please have a look at: https://huggingface.co/docs/diffusers/using-diffusers/loading#checkpoint-variants.\n\
          We made sure you that you can safely merge this pull request. \n\n Best,\
          \ the \U0001F9E8 Diffusers team."
        updatedAt: '2023-06-21T12:38:48.818Z'
      numEdits: 0
      reactions: []
    id: 6492ef58ee9cc68c2d2fcf3f
    type: comment
  author: patrickvonplaten
  content: "Hey patrickvonplaten \U0001F44B, \n\n Your model repository seems to contain\
    \ a [`fp16` branch](https://huggingface.co/patrickvonplaten/test_sd_1/tree/fp16)\
    \ to load the model in float16 precision. Loading `fp16` versions from a branch\
    \ instead of the main branch is deprecated and will eventually be forbidden. Instead,\
    \ we strongly recommend to save `fp16` versions of the model under `.fp16.` version\
    \ files directly on the 'main' branch as enabled through this PR.This PR makes\
    \ sure that your model repository allows the user to correctly download float16\
    \ precision model weights by adding `fp16` model weights in both safetensors and\
    \ PyTorch bin format:\n\n```py\npipe = DiffusionPipeline.from_pretrained(patrickvonplaten/test_sd_1,\
    \ torch_dtype=torch.float16, variant='fp16')\n```\n\nFor more information please\
    \ have a look at: https://huggingface.co/docs/diffusers/using-diffusers/loading#checkpoint-variants.\n\
    We made sure you that you can safely merge this pull request. \n\n Best, the \U0001F9E8\
    \ Diffusers team."
  created_at: 2023-06-21 11:38:48+00:00
  edited: false
  hidden: false
  id: 6492ef58ee9cc68c2d2fcf3f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1584435275418-5dfcb1aada6d0311fd3d5448.jpeg?w=200&h=200&f=face
      fullname: Patrick von Platen
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: patrickvonplaten
      type: user
    createdAt: '2023-06-21T12:38:49.000Z'
    data:
      oid: 291799cf436507e38bbba562012961763193c48e
      parents:
      - 40cdaaeff4b7d2059d9531807a46d19b50fde812
      subject: Fix deprecated float16/fp16 variant loading through new `version` API.
    id: 6492ef590000000000000000
    type: commit
  author: patrickvonplaten
  created_at: 2023-06-21 11:38:49+00:00
  id: 6492ef590000000000000000
  oid: 291799cf436507e38bbba562012961763193c48e
  summary: Fix deprecated float16/fp16 variant loading through new `version` API.
  type: commit
is_pull_request: true
merge_commit_oid: null
num: 14
repo_id: patrickvonplaten/test_sd_1
repo_type: model
status: open
target_branch: refs/heads/main
title: Fix deprecated float16/fp16 variant loading through new `version` API.
