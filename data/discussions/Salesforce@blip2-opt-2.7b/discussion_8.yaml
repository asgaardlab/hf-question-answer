!!python/object:huggingface_hub.community.DiscussionWithDetails
author: masoudkaviani
conflicting_files: null
created_at: 2023-06-16 22:30:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/491506e1db720f623bb0f4267e7dd64b.svg
      fullname: Maaoud Kaviani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: masoudkaviani
      type: user
    createdAt: '2023-06-16T23:30:08.000Z'
    data:
      edited: true
      editors:
      - nielsr
      - masoudkaviani
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6178900599479675
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>I had run this piece of code in Google Colab (Free) and the runtime
          crashed due to not enough memory! Any idea about that?<br>code:</p>

          <pre><code>import torch

          from PIL import Image

          import requests

          from transformers import AutoProcessor, Blip2Model

          device = "cuda" if torch.cuda.is_available() else "cpu"

          model = Blip2Model.from_pretrained("Salesforce/blip2-opt-2.7b", torch_dtype=torch.float16)

          model.to(device)

          processor = AutoProcessor.from_pretrained("Salesforce/blip2-opt-2.7b")

          url = "http://images.cocodataset.org/val2017/000000039769.jpg"

          image = Image.open(requests.get(url, stream=True).raw)

          inputs = processor(images=image, return_tensors="pt").to(device, torch.float16)

          image_outputs = model.get_image_features(**inputs)

          </code></pre>

          '
        raw: 'I had run this piece of code in Google Colab (Free) and the runtime
          crashed due to not enough memory! Any idea about that?

          code:

          ```

          import torch

          from PIL import Image

          import requests

          from transformers import AutoProcessor, Blip2Model

          device = "cuda" if torch.cuda.is_available() else "cpu"

          model = Blip2Model.from_pretrained("Salesforce/blip2-opt-2.7b", torch_dtype=torch.float16)

          model.to(device)

          processor = AutoProcessor.from_pretrained("Salesforce/blip2-opt-2.7b")

          url = "http://images.cocodataset.org/val2017/000000039769.jpg"

          image = Image.open(requests.get(url, stream=True).raw)

          inputs = processor(images=image, return_tensors="pt").to(device, torch.float16)

          image_outputs = model.get_image_features(**inputs)

          ```'
        updatedAt: '2023-08-03T17:38:11.244Z'
      numEdits: 1
      reactions: []
    id: 648cf0808735ed363902463d
    type: comment
  author: masoudkaviani
  content: 'I had run this piece of code in Google Colab (Free) and the runtime crashed
    due to not enough memory! Any idea about that?

    code:

    ```

    import torch

    from PIL import Image

    import requests

    from transformers import AutoProcessor, Blip2Model

    device = "cuda" if torch.cuda.is_available() else "cpu"

    model = Blip2Model.from_pretrained("Salesforce/blip2-opt-2.7b", torch_dtype=torch.float16)

    model.to(device)

    processor = AutoProcessor.from_pretrained("Salesforce/blip2-opt-2.7b")

    url = "http://images.cocodataset.org/val2017/000000039769.jpg"

    image = Image.open(requests.get(url, stream=True).raw)

    inputs = processor(images=image, return_tensors="pt").to(device, torch.float16)

    image_outputs = model.get_image_features(**inputs)

    ```'
  created_at: 2023-06-16 22:30:08+00:00
  edited: true
  hidden: false
  id: 648cf0808735ed363902463d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2023-07-24T17:01:57.000Z'
    data:
      edited: true
      editors:
      - nielsr
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5309147238731384
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: "<p>do this(this loads it in 8 bit so it uses less memory)</p>\n<pre><code>#\
          \ pip install accelerate bitsandbytes\nimport torch\nimport requests\nfrom\
          \ PIL import Image\nfrom transformers import Blip2Processor, Blip2ForConditionalGeneration\n\
          \nprocessor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\"\
          )\nmodel = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\"\
          , load_in_8bit=True, device_map=\"auto\")\n\nimg_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg'\
          \ \nraw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n\
          \nquestion = \"how many dogs are in the picture?\"\ninputs = processor(raw_image,\
          \ question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n\nout =\
          \ model.generate(**inputs)\nprint(processor.decode(out[0], skip_special_tokens=True))\n\
          </code></pre>\n"
        raw: "do this(this loads it in 8 bit so it uses less memory)\n\n```\n# pip\
          \ install accelerate bitsandbytes\nimport torch\nimport requests\nfrom PIL\
          \ import Image\nfrom transformers import Blip2Processor, Blip2ForConditionalGeneration\n\
          \nprocessor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\"\
          )\nmodel = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\"\
          , load_in_8bit=True, device_map=\"auto\")\n\nimg_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg'\
          \ \nraw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n\
          \nquestion = \"how many dogs are in the picture?\"\ninputs = processor(raw_image,\
          \ question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n\nout =\
          \ model.generate(**inputs)\nprint(processor.decode(out[0], skip_special_tokens=True))\n\
          ```"
        updatedAt: '2023-08-03T17:38:03.721Z'
      numEdits: 1
      reactions: []
    id: 64beae851d40292dd310bf64
    type: comment
  author: YaTharThShaRma999
  content: "do this(this loads it in 8 bit so it uses less memory)\n\n```\n# pip install\
    \ accelerate bitsandbytes\nimport torch\nimport requests\nfrom PIL import Image\n\
    from transformers import Blip2Processor, Blip2ForConditionalGeneration\n\nprocessor\
    \ = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\nmodel = Blip2ForConditionalGeneration.from_pretrained(\"\
    Salesforce/blip2-opt-2.7b\", load_in_8bit=True, device_map=\"auto\")\n\nimg_url\
    \ = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg'\
    \ \nraw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n\
    \nquestion = \"how many dogs are in the picture?\"\ninputs = processor(raw_image,\
    \ question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n\nout = model.generate(**inputs)\n\
    print(processor.decode(out[0], skip_special_tokens=True))\n```"
  created_at: 2023-07-24 16:01:57+00:00
  edited: true
  hidden: false
  id: 64beae851d40292dd310bf64
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: Salesforce/blip2-opt-2.7b
repo_type: model
status: open
target_branch: null
title: Google Colab (Free) Crash due to not enough memory
