!!python/object:huggingface_hub.community.DiscussionWithDetails
author: acmidev
conflicting_files: null
created_at: 2023-08-17 01:23:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cbfe0329e3ccdfc1f87ad9c52e69dcdf.svg
      fullname: ACMI Developers
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: acmidev
      type: user
    createdAt: '2023-08-17T02:23:38.000Z'
    data:
      edited: false
      editors:
      - acmidev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5565031170845032
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cbfe0329e3ccdfc1f87ad9c52e69dcdf.svg
          fullname: ACMI Developers
          isHf: false
          isPro: false
          name: acmidev
          type: user
        html: "<p>Hi there,</p>\n<p>I was wondering how to generate confidence scores\
          \ when generating image captions with the sample code.</p>\n<p>Best, Simon.</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span>\
          \ PIL <span class=\"hljs-keyword\">import</span> Image\n<span class=\"hljs-keyword\"\
          >import</span> requests\n<span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> Blip2Processor, Blip2ForConditionalGeneration\n\
          <span class=\"hljs-keyword\">import</span> torch\n\ndevice = <span class=\"\
          hljs-string\">\"cuda\"</span> <span class=\"hljs-keyword\">if</span> torch.cuda.is_available()\
          \ <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"\
          cpu\"</span>\n\nprocessor = Blip2Processor.from_pretrained(<span class=\"\
          hljs-string\">\"Salesforce/blip2-opt-2.7b\"</span>)\nmodel = Blip2ForConditionalGeneration.from_pretrained(\n\
          \    <span class=\"hljs-string\">\"Salesforce/blip2-opt-2.7b\"</span>, torch_dtype=torch.float16\n\
          )\nmodel.to(device)\nurl = <span class=\"hljs-string\">\"http://images.cocodataset.org/val2017/000000039769.jpg\"\
          </span>\nimage = Image.<span class=\"hljs-built_in\">open</span>(requests.get(url,\
          \ stream=<span class=\"hljs-literal\">True</span>).raw)\n\ninputs = processor(images=image,\
          \ return_tensors=<span class=\"hljs-string\">\"pt\"</span>).to(device, torch.float16)\n\
          \ngenerated_ids = model.generate(**inputs)\ngenerated_text = processor.batch_decode(generated_ids,\
          \ skip_special_tokens=<span class=\"hljs-literal\">True</span>)[<span class=\"\
          hljs-number\">0</span>].strip()\n<span class=\"hljs-built_in\">print</span>(generated_text)\n\
          two cats laying on a couch\n</code></pre>\n"
        raw: "Hi there,\r\n\r\nI was wondering how to generate confidence scores when\
          \ generating image captions with the sample code.\r\n\r\nBest, Simon.\r\n\
          \r\n```python\r\nfrom PIL import Image\r\nimport requests\r\nfrom transformers\
          \ import Blip2Processor, Blip2ForConditionalGeneration\r\nimport torch\r\
          \n\r\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n\r\n\
          processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\"\
          )\r\nmodel = Blip2ForConditionalGeneration.from_pretrained(\r\n    \"Salesforce/blip2-opt-2.7b\"\
          , torch_dtype=torch.float16\r\n)\r\nmodel.to(device)\r\nurl = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\
          \r\nimage = Image.open(requests.get(url, stream=True).raw)\r\n\r\ninputs\
          \ = processor(images=image, return_tensors=\"pt\").to(device, torch.float16)\r\
          \n\r\ngenerated_ids = model.generate(**inputs)\r\ngenerated_text = processor.batch_decode(generated_ids,\
          \ skip_special_tokens=True)[0].strip()\r\nprint(generated_text)\r\ntwo cats\
          \ laying on a couch\r\n```"
        updatedAt: '2023-08-17T02:23:38.532Z'
      numEdits: 0
      reactions: []
    id: 64dd84aa4d6048abd767f988
    type: comment
  author: acmidev
  content: "Hi there,\r\n\r\nI was wondering how to generate confidence scores when\
    \ generating image captions with the sample code.\r\n\r\nBest, Simon.\r\n\r\n\
    ```python\r\nfrom PIL import Image\r\nimport requests\r\nfrom transformers import\
    \ Blip2Processor, Blip2ForConditionalGeneration\r\nimport torch\r\n\r\ndevice\
    \ = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n\r\nprocessor = Blip2Processor.from_pretrained(\"\
    Salesforce/blip2-opt-2.7b\")\r\nmodel = Blip2ForConditionalGeneration.from_pretrained(\r\
    \n    \"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float16\r\n)\r\nmodel.to(device)\r\
    \nurl = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\r\nimage =\
    \ Image.open(requests.get(url, stream=True).raw)\r\n\r\ninputs = processor(images=image,\
    \ return_tensors=\"pt\").to(device, torch.float16)\r\n\r\ngenerated_ids = model.generate(**inputs)\r\
    \ngenerated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\r\
    \nprint(generated_text)\r\ntwo cats laying on a couch\r\n```"
  created_at: 2023-08-17 01:23:38+00:00
  edited: false
  hidden: false
  id: 64dd84aa4d6048abd767f988
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2023-08-17T16:18:38.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6939046382904053
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: "<p>Hi,</p>\n<p>You can obtain a confidence score by passing <code>output_scores=True</code>\
          \ and <code> return_dict_in_generate=True</code>to the <code>generate()</code>\
          \ method.</p>\n<pre><code>outputs = model.generate(**inputs, output_scores=True,\
          \ return_dict=_in_generate=True)\nscores = outputs.scores\n</code></pre>\n\
          <p>According to the <a href=\"https://huggingface.co/docs/transformers/main/en/internal/generation_utils#transformers.generation.GreedySearchDecoderOnlyOutput\"\
          >docs</a>:</p>\n<blockquote>\n<p>In case of greedy decoding; this contains\
          \ the processed prediction scores of the language modeling head (scores\
          \ for each vocabulary token before SoftMax) at each generation step. Tuple\
          \ of torch.FloatTensor with up to max_new_tokens elements (one element for\
          \ each generated token), with each tensor of shape (batch_size, config.vocab_size).\
          \ </p>\n</blockquote>\n<p>To calculate a probability for the entire sequence,\
          \ you could do the following:</p>\n<pre><code># get probability for each\
          \ generated token\ntopks = [s.softmax(-1).topk(1) for s in output.scores]\
          \ \n\nprobs = []\nfor tk in topks:\n    probs.append(tk.values.view(-1)[0].item())\n\
          \n# multiply probabilities\nsequence_prob = torch.tensor(probs).prod()\n\
          </code></pre>\n"
        raw: "Hi,\n\nYou can obtain a confidence score by passing `output_scores=True`\
          \ and ` return_dict_in_generate=True`to the `generate()` method.\n```\n\
          outputs = model.generate(**inputs, output_scores=True, return_dict=_in_generate=True)\n\
          scores = outputs.scores\n```\nAccording to the [docs](https://huggingface.co/docs/transformers/main/en/internal/generation_utils#transformers.generation.GreedySearchDecoderOnlyOutput):\n\
          > In case of greedy decoding; this contains the processed prediction scores\
          \ of the language modeling head (scores for each vocabulary token before\
          \ SoftMax) at each generation step. Tuple of torch.FloatTensor with up to\
          \ max_new_tokens elements (one element for each generated token), with each\
          \ tensor of shape (batch_size, config.vocab_size). \n\nTo calculate a probability\
          \ for the entire sequence, you could do the following:\n\n```\n# get probability\
          \ for each generated token\ntopks = [s.softmax(-1).topk(1) for s in output.scores]\
          \ \n\nprobs = []\nfor tk in topks:\n    probs.append(tk.values.view(-1)[0].item())\n\
          \n# multiply probabilities\nsequence_prob = torch.tensor(probs).prod()\n\
          ```"
        updatedAt: '2023-08-17T16:18:38.050Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - davanstrien
        - acmidev
    id: 64de485e5e192985054e76bc
    type: comment
  author: nielsr
  content: "Hi,\n\nYou can obtain a confidence score by passing `output_scores=True`\
    \ and ` return_dict_in_generate=True`to the `generate()` method.\n```\noutputs\
    \ = model.generate(**inputs, output_scores=True, return_dict=_in_generate=True)\n\
    scores = outputs.scores\n```\nAccording to the [docs](https://huggingface.co/docs/transformers/main/en/internal/generation_utils#transformers.generation.GreedySearchDecoderOnlyOutput):\n\
    > In case of greedy decoding; this contains the processed prediction scores of\
    \ the language modeling head (scores for each vocabulary token before SoftMax)\
    \ at each generation step. Tuple of torch.FloatTensor with up to max_new_tokens\
    \ elements (one element for each generated token), with each tensor of shape (batch_size,\
    \ config.vocab_size). \n\nTo calculate a probability for the entire sequence,\
    \ you could do the following:\n\n```\n# get probability for each generated token\n\
    topks = [s.softmax(-1).topk(1) for s in output.scores] \n\nprobs = []\nfor tk\
    \ in topks:\n    probs.append(tk.values.view(-1)[0].item())\n\n# multiply probabilities\n\
    sequence_prob = torch.tensor(probs).prod()\n```"
  created_at: 2023-08-17 15:18:38+00:00
  edited: false
  hidden: false
  id: 64de485e5e192985054e76bc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cbfe0329e3ccdfc1f87ad9c52e69dcdf.svg
      fullname: ACMI Developers
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: acmidev
      type: user
    createdAt: '2023-08-23T01:27:33.000Z'
    data:
      edited: false
      editors:
      - acmidev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7752926349639893
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cbfe0329e3ccdfc1f87ad9c52e69dcdf.svg
          fullname: ACMI Developers
          isHf: false
          isPro: false
          name: acmidev
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;nielsr&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/nielsr\">@<span class=\"\
          underline\">nielsr</span></a></span>\n\n\t</span></span> Thanks so much\
          \ for the code - so adding it back to the sample code via this <a rel=\"\
          nofollow\" href=\"https://colab.research.google.com/drive/19gXr9MoluNYLq7PGz10zlAgsFvkCj_T0?usp=sharing\"\
          >Google Colab</a> the output is:</p>\n<pre><code>Prediction: two cats laying\
          \ on a couch\nConfidence: 0.012353635393083096\n</code></pre>\n<p>So does\
          \ that suggest the confidence level is 1.2%?</p>\n"
        raw: '@nielsr Thanks so much for the code - so adding it back to the sample
          code via this [Google Colab](https://colab.research.google.com/drive/19gXr9MoluNYLq7PGz10zlAgsFvkCj_T0?usp=sharing)
          the output is:


          ```

          Prediction: two cats laying on a couch

          Confidence: 0.012353635393083096

          ```


          So does that suggest the confidence level is 1.2%?'
        updatedAt: '2023-08-23T01:27:33.277Z'
      numEdits: 0
      reactions: []
    id: 64e560856d9073d9f5271740
    type: comment
  author: acmidev
  content: '@nielsr Thanks so much for the code - so adding it back to the sample
    code via this [Google Colab](https://colab.research.google.com/drive/19gXr9MoluNYLq7PGz10zlAgsFvkCj_T0?usp=sharing)
    the output is:


    ```

    Prediction: two cats laying on a couch

    Confidence: 0.012353635393083096

    ```


    So does that suggest the confidence level is 1.2%?'
  created_at: 2023-08-23 00:27:33+00:00
  edited: false
  hidden: false
  id: 64e560856d9073d9f5271740
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: Salesforce/blip2-opt-2.7b
repo_type: model
status: open
target_branch: null
title: Confidence scores for image captioning?
