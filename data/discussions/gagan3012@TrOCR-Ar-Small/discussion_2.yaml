!!python/object:huggingface_hub.community.DiscussionWithDetails
author: HGamal
conflicting_files: null
created_at: 2022-09-04 02:36:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2015ecd90fe947f819aef39dfb76f957.svg
      fullname: Heba Gamal El-Din
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HGamal
      type: user
    createdAt: '2022-09-04T03:36:00.000Z'
    data:
      edited: false
      editors:
      - HGamal
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2015ecd90fe947f819aef39dfb76f957.svg
          fullname: Heba Gamal El-Din
          isHf: false
          isPro: false
          name: HGamal
          type: user
        html: '<p>Hey, I''m trying to train a handwritten arabic OCR using ArOCR and
          trOCR-Ar-small, but the preprocessor doesn''t load so I used "giganticode/roberta-base-ar_miner"
          as the tokenizer.<br>When I check the validation set predictions it''s all
          like a repeated garbage as shown.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1662262557223-63141b29e29fb2e86d63a608.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1662262557223-63141b29e29fb2e86d63a608.png"></a></p>

          <p>here''s my loadings:<br>def load_model(from_disk: bool) -&gt; VisionEncoderDecoderModel:<br>model:
          VisionEncoderDecoderModel = VisionEncoderDecoderModel.from_pretrained(''gagan3012/TrOCR-Ar-Small'')#.from_encoder_decoder_pretrained("google/vit-base-patch16-224-in21k",
          "giganticode/roberta-base-ar_miner")#<br>print(f"Using device {device}.")<br>model.to(device)<br>return
          model</p>

          <p>def init_model_for_training(model: VisionEncoderDecoderModel, processor:
          TrOCRProcessor):<br>model.config.decoder_start_token_id = processor.tokenizer.cls_token_id<br>model.config.pad_token_id
          = processor.tokenizer.pad_token_id<br>model.config.vocab_size = model.config.decoder.vocab_size<br>model.config.bos_token_id
          = processor.tokenizer.bos_token_id<br>model.config.decoder_start_token_id
          = 0<br>model.config.decoder.is_decoder = True<br>model.config.decoder.add_cross_attention
          = True</p>

          <p>def load_processor() -&gt; TrOCRProcessor:<br>feature_extractor=ViTFeatureExtractor.from_pretrained("google/vit-base-patch16-384")<br>model_path
          = "giganticode/roberta-base-ar_miner"<br>tokenizer = AutoTokenizer.from_pretrained(model_path)<br>return
          TrOCRProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)</p>

          '
        raw: "Hey, I'm trying to train a handwritten arabic OCR using ArOCR and trOCR-Ar-small,\
          \ but the preprocessor doesn't load so I used \"giganticode/roberta-base-ar_miner\"\
          \ as the tokenizer.\r\nWhen I check the validation set predictions it's\
          \ all like a repeated garbage as shown.\r\n\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1662262557223-63141b29e29fb2e86d63a608.png)\r\
          \n\r\n\r\nhere's my loadings:\r\ndef load_model(from_disk: bool) -> VisionEncoderDecoderModel:\r\
          \nmodel: VisionEncoderDecoderModel = VisionEncoderDecoderModel.from_pretrained('gagan3012/TrOCR-Ar-Small')#.from_encoder_decoder_pretrained(\"\
          google/vit-base-patch16-224-in21k\", \"giganticode/roberta-base-ar_miner\"\
          )#\r\nprint(f\"Using device {device}.\")\r\nmodel.to(device)\r\nreturn model\r\
          \n\r\ndef init_model_for_training(model: VisionEncoderDecoderModel, processor:\
          \ TrOCRProcessor):\r\nmodel.config.decoder_start_token_id = processor.tokenizer.cls_token_id\r\
          \nmodel.config.pad_token_id = processor.tokenizer.pad_token_id\r\nmodel.config.vocab_size\
          \ = model.config.decoder.vocab_size\r\nmodel.config.bos_token_id = processor.tokenizer.bos_token_id\r\
          \nmodel.config.decoder_start_token_id = 0\r\nmodel.config.decoder.is_decoder\
          \ = True\r\nmodel.config.decoder.add_cross_attention = True\r\n\r\ndef load_processor()\
          \ -> TrOCRProcessor:\r\nfeature_extractor=ViTFeatureExtractor.from_pretrained(\"\
          google/vit-base-patch16-384\")\r\nmodel_path = \"giganticode/roberta-base-ar_miner\"\
          \r\ntokenizer = AutoTokenizer.from_pretrained(model_path)\r\nreturn TrOCRProcessor(feature_extractor=feature_extractor,\
          \ tokenizer=tokenizer)\r\n"
        updatedAt: '2022-09-04T03:36:00.108Z'
      numEdits: 0
      reactions: []
    id: 63141d202c7ffdd9f505165d
    type: comment
  author: HGamal
  content: "Hey, I'm trying to train a handwritten arabic OCR using ArOCR and trOCR-Ar-small,\
    \ but the preprocessor doesn't load so I used \"giganticode/roberta-base-ar_miner\"\
    \ as the tokenizer.\r\nWhen I check the validation set predictions it's all like\
    \ a repeated garbage as shown.\r\n\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1662262557223-63141b29e29fb2e86d63a608.png)\r\
    \n\r\n\r\nhere's my loadings:\r\ndef load_model(from_disk: bool) -> VisionEncoderDecoderModel:\r\
    \nmodel: VisionEncoderDecoderModel = VisionEncoderDecoderModel.from_pretrained('gagan3012/TrOCR-Ar-Small')#.from_encoder_decoder_pretrained(\"\
    google/vit-base-patch16-224-in21k\", \"giganticode/roberta-base-ar_miner\")#\r\
    \nprint(f\"Using device {device}.\")\r\nmodel.to(device)\r\nreturn model\r\n\r\
    \ndef init_model_for_training(model: VisionEncoderDecoderModel, processor: TrOCRProcessor):\r\
    \nmodel.config.decoder_start_token_id = processor.tokenizer.cls_token_id\r\nmodel.config.pad_token_id\
    \ = processor.tokenizer.pad_token_id\r\nmodel.config.vocab_size = model.config.decoder.vocab_size\r\
    \nmodel.config.bos_token_id = processor.tokenizer.bos_token_id\r\nmodel.config.decoder_start_token_id\
    \ = 0\r\nmodel.config.decoder.is_decoder = True\r\nmodel.config.decoder.add_cross_attention\
    \ = True\r\n\r\ndef load_processor() -> TrOCRProcessor:\r\nfeature_extractor=ViTFeatureExtractor.from_pretrained(\"\
    google/vit-base-patch16-384\")\r\nmodel_path = \"giganticode/roberta-base-ar_miner\"\
    \r\ntokenizer = AutoTokenizer.from_pretrained(model_path)\r\nreturn TrOCRProcessor(feature_extractor=feature_extractor,\
    \ tokenizer=tokenizer)\r\n"
  created_at: 2022-09-04 02:36:00+00:00
  edited: false
  hidden: false
  id: 63141d202c7ffdd9f505165d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c26e3cdad82be6d6459cfd4c6ea7dfd9.svg
      fullname: Adil Jouahri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: adilJ
      type: user
    createdAt: '2023-11-05T16:41:49.000Z'
    data:
      edited: false
      editors:
      - adilJ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5042042136192322
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c26e3cdad82be6d6459cfd4c6ea7dfd9.svg
          fullname: Adil Jouahri
          isHf: false
          isPro: false
          name: adilJ
          type: user
        html: '<p>Try:<br>processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")</p>

          '
        raw: 'Try:

          processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")

          '
        updatedAt: '2023-11-05T16:41:49.010Z'
      numEdits: 0
      reactions: []
    id: 6547c5cd565e3985e8b80a81
    type: comment
  author: adilJ
  content: 'Try:

    processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")

    '
  created_at: 2023-11-05 16:41:49+00:00
  edited: false
  hidden: false
  id: 6547c5cd565e3985e8b80a81
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: gagan3012/TrOCR-Ar-Small
repo_type: model
status: open
target_branch: null
title: 'what preprocessor should I use to train the handwritten arabic ocr on this
  base of ArOCR model? #1 '
