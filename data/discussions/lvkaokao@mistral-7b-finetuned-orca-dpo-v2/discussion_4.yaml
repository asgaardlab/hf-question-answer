!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Phil337
conflicting_files: null
created_at: 2023-11-20 05:41:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-11-20T05:41:51.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9676129817962646
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>This LLM performed unusually well on my personal tests, and its
          TruthfulQA score is impressive.</p>

          <p>However, after playing around with it there''s a pattern of stubbornness
          across the board. For example, it will often stick to an hallucination,
          no matter how absurd, with the same gusto it sticks to the truth with. It
          might apologize for the error, but well then repeat it. This doesn''t reduce
          test scores since a wrong answer is still a wrong answer. However, it makes
          the LLM far too frustrating to use considering the sheer number of hallucinations,
          especially with Mistrals.</p>

          <p>And like I said, this issue manifests across the board, such as with
          story telling. With most other LLMs if a story choice contradicts the user''s
          story prompt it will apologize and rewrite it with the stated correction.
          In contrast, this LLM often stubbornly starts defending its choice, or even
          after apologizing, repeats the same line when retelling the story. And it
          doesn''t make any sense. I''m not saying things like the ball fell towards
          the ceiling so the LLM is stubbornly makes it always fall to the ground
          because that''s how gravity works. I''m simply saying perfectly realistic
          and common things like make the character preparing to leave for a trip.</p>

          <p>Stubbornness may be a good thing when LLMs get much better and hallucinate
          far less, but it just doesn''t work with a 7b Mistral.</p>

          '
        raw: "This LLM performed unusually well on my personal tests, and its TruthfulQA\
          \ score is impressive.\r\n\r\nHowever, after playing around with it there's\
          \ a pattern of stubbornness across the board. For example, it will often\
          \ stick to an hallucination, no matter how absurd, with the same gusto it\
          \ sticks to the truth with. It might apologize for the error, but well then\
          \ repeat it. This doesn't reduce test scores since a wrong answer is still\
          \ a wrong answer. However, it makes the LLM far too frustrating to use considering\
          \ the sheer number of hallucinations, especially with Mistrals.\r\n\r\n\
          And like I said, this issue manifests across the board, such as with story\
          \ telling. With most other LLMs if a story choice contradicts the user's\
          \ story prompt it will apologize and rewrite it with the stated correction.\
          \ In contrast, this LLM often stubbornly starts defending its choice, or\
          \ even after apologizing, repeats the same line when retelling the story.\
          \ And it doesn't make any sense. I'm not saying things like the ball fell\
          \ towards the ceiling so the LLM is stubbornly makes it always fall to the\
          \ ground because that's how gravity works. I'm simply saying perfectly realistic\
          \ and common things like make the character preparing to leave for a trip.\r\
          \n\r\nStubbornness may be a good thing when LLMs get much better and hallucinate\
          \ far less, but it just doesn't work with a 7b Mistral."
        updatedAt: '2023-11-20T05:41:51.432Z'
      numEdits: 0
      reactions: []
    id: 655af19fcafc48de366a24b2
    type: comment
  author: Phil337
  content: "This LLM performed unusually well on my personal tests, and its TruthfulQA\
    \ score is impressive.\r\n\r\nHowever, after playing around with it there's a\
    \ pattern of stubbornness across the board. For example, it will often stick to\
    \ an hallucination, no matter how absurd, with the same gusto it sticks to the\
    \ truth with. It might apologize for the error, but well then repeat it. This\
    \ doesn't reduce test scores since a wrong answer is still a wrong answer. However,\
    \ it makes the LLM far too frustrating to use considering the sheer number of\
    \ hallucinations, especially with Mistrals.\r\n\r\nAnd like I said, this issue\
    \ manifests across the board, such as with story telling. With most other LLMs\
    \ if a story choice contradicts the user's story prompt it will apologize and\
    \ rewrite it with the stated correction. In contrast, this LLM often stubbornly\
    \ starts defending its choice, or even after apologizing, repeats the same line\
    \ when retelling the story. And it doesn't make any sense. I'm not saying things\
    \ like the ball fell towards the ceiling so the LLM is stubbornly makes it always\
    \ fall to the ground because that's how gravity works. I'm simply saying perfectly\
    \ realistic and common things like make the character preparing to leave for a\
    \ trip.\r\n\r\nStubbornness may be a good thing when LLMs get much better and\
    \ hallucinate far less, but it just doesn't work with a 7b Mistral."
  created_at: 2023-11-20 05:41:51+00:00
  edited: false
  hidden: false
  id: 655af19fcafc48de366a24b2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: lvkaokao/mistral-7b-finetuned-orca-dpo-v2
repo_type: model
status: open
target_branch: null
title: Stubbornly Avoids and Sticks to Hallucinations
