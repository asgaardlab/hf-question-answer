!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Rasha-Ragab
conflicting_files: null
created_at: 2023-12-09 21:30:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acffbbe277c262cfb4c20d1e528bf5ca.svg
      fullname: Rasha Ragab
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: Rasha-Ragab
      type: user
    createdAt: '2023-12-09T21:30:56.000Z'
    data:
      edited: true
      editors:
      - Rasha-Ragab
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5559867024421692
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acffbbe277c262cfb4c20d1e528bf5ca.svg
          fullname: Rasha Ragab
          isHf: false
          isPro: true
          name: Rasha-Ragab
          type: user
        html: '<p>The sample code given to run a sample example needs the following
          change: use tokenizer.batch_decode(sequences=outputs, skip_special_tokens=True)
          instead of tokenizer.decode so the code can run correctly.</p>

          <p>#Code given:<br>from transformers import AutoModelForSeq2SeqLM, AutoTokenizer</p>

          <p>#model_path = ''gaussalgo/T5-LM-Large-text2sql-spider''<br>model = AutoModelForSeq2SeqLM.from_pretrained(modelPath)<br>tokenizer
          = AutoTokenizer.from_pretrained(modelPath)</p>

          <p>question = "What is the average, minimum, and maximum age for all French
          musicians?"<br>schema = """<br>   "stadium" "Stadium_ID" int , "Location"
          text , "Name" text , "Capacity" int , "Highest" int , "Lowest" int , "Average"
          int , foreign_key:  primary key: "Stadium_ID" [SEP] "singer" "Singer_ID"
          int , "Name" text , "Country" text , "Song_Name" text , "Song_release_year"
          text , "Age" int , "Is_male" bool , foreign_key:  primary key: "Singer_ID"
          [SEP] "concert" "concert_ID" int , "concert_Name" text , "Theme" text ,
          "Year" text , foreign_key: "Stadium_ID" text from "stadium" "Stadium_ID"
          , primary key: "concert_ID" [SEP] "singer_in_concert"  foreign_key: "concert_ID"
          int from "concert" "concert_ID" , "Singer_ID" text from "singer" "Singer_ID"
          , primary key: "concert_ID" "Singer_ID"<br>"""</p>

          <p>input_text = " ".join(["Question: ",question, "Schema:", schema])</p>

          <p>model_inputs = tokenizer(input_text, return_tensors="pt")<br>outputs
          = model.generate(**model_inputs, max_length=512)</p>

          <p>output_text = tokenizer.batch_decode(sequences=outputs, skip_special_tokens=True)
          ## changed the decode to batch decode so the code run successfully</p>

          <p>print("SQL Query:")<br>print(output_text)</p>

          '
        raw: "The sample code given to run a sample example needs the following change:\
          \ use tokenizer.batch_decode(sequences=outputs, skip_special_tokens=True)\
          \ instead of tokenizer.decode so the code can run correctly.\n\n#Code given:\n\
          from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\n#model_path\
          \ = 'gaussalgo/T5-LM-Large-text2sql-spider'\nmodel = AutoModelForSeq2SeqLM.from_pretrained(modelPath)\n\
          tokenizer = AutoTokenizer.from_pretrained(modelPath)\n\nquestion = \"What\
          \ is the average, minimum, and maximum age for all French musicians?\"\n\
          schema = \"\"\"\n   \"stadium\" \"Stadium_ID\" int , \"Location\" text ,\
          \ \"Name\" text , \"Capacity\" int , \"Highest\" int , \"Lowest\" int ,\
          \ \"Average\" int , foreign_key:  primary key: \"Stadium_ID\" [SEP] \"singer\"\
          \ \"Singer_ID\" int , \"Name\" text , \"Country\" text , \"Song_Name\" text\
          \ , \"Song_release_year\" text , \"Age\" int , \"Is_male\" bool , foreign_key:\
          \  primary key: \"Singer_ID\" [SEP] \"concert\" \"concert_ID\" int , \"\
          concert_Name\" text , \"Theme\" text , \"Year\" text , foreign_key: \"Stadium_ID\"\
          \ text from \"stadium\" \"Stadium_ID\" , primary key: \"concert_ID\" [SEP]\
          \ \"singer_in_concert\"  foreign_key: \"concert_ID\" int from \"concert\"\
          \ \"concert_ID\" , \"Singer_ID\" text from \"singer\" \"Singer_ID\" , primary\
          \ key: \"concert_ID\" \"Singer_ID\"\n\"\"\"\n\ninput_text = \" \".join([\"\
          Question: \",question, \"Schema:\", schema])\n\nmodel_inputs = tokenizer(input_text,\
          \ return_tensors=\"pt\")\noutputs = model.generate(**model_inputs, max_length=512)\n\
          \noutput_text = tokenizer.batch_decode(sequences=outputs, skip_special_tokens=True)\
          \ ## changed the decode to batch decode so the code run successfully\n\n\
          print(\"SQL Query:\")\nprint(output_text)\n"
        updatedAt: '2023-12-09T21:36:17.978Z'
      numEdits: 2
      reactions: []
    id: 6574dc909fe27c093d7690d5
    type: comment
  author: Rasha-Ragab
  content: "The sample code given to run a sample example needs the following change:\
    \ use tokenizer.batch_decode(sequences=outputs, skip_special_tokens=True) instead\
    \ of tokenizer.decode so the code can run correctly.\n\n#Code given:\nfrom transformers\
    \ import AutoModelForSeq2SeqLM, AutoTokenizer\n\n#model_path = 'gaussalgo/T5-LM-Large-text2sql-spider'\n\
    model = AutoModelForSeq2SeqLM.from_pretrained(modelPath)\ntokenizer = AutoTokenizer.from_pretrained(modelPath)\n\
    \nquestion = \"What is the average, minimum, and maximum age for all French musicians?\"\
    \nschema = \"\"\"\n   \"stadium\" \"Stadium_ID\" int , \"Location\" text , \"\
    Name\" text , \"Capacity\" int , \"Highest\" int , \"Lowest\" int , \"Average\"\
    \ int , foreign_key:  primary key: \"Stadium_ID\" [SEP] \"singer\" \"Singer_ID\"\
    \ int , \"Name\" text , \"Country\" text , \"Song_Name\" text , \"Song_release_year\"\
    \ text , \"Age\" int , \"Is_male\" bool , foreign_key:  primary key: \"Singer_ID\"\
    \ [SEP] \"concert\" \"concert_ID\" int , \"concert_Name\" text , \"Theme\" text\
    \ , \"Year\" text , foreign_key: \"Stadium_ID\" text from \"stadium\" \"Stadium_ID\"\
    \ , primary key: \"concert_ID\" [SEP] \"singer_in_concert\"  foreign_key: \"concert_ID\"\
    \ int from \"concert\" \"concert_ID\" , \"Singer_ID\" text from \"singer\" \"\
    Singer_ID\" , primary key: \"concert_ID\" \"Singer_ID\"\n\"\"\"\n\ninput_text\
    \ = \" \".join([\"Question: \",question, \"Schema:\", schema])\n\nmodel_inputs\
    \ = tokenizer(input_text, return_tensors=\"pt\")\noutputs = model.generate(**model_inputs,\
    \ max_length=512)\n\noutput_text = tokenizer.batch_decode(sequences=outputs, skip_special_tokens=True)\
    \ ## changed the decode to batch decode so the code run successfully\n\nprint(\"\
    SQL Query:\")\nprint(output_text)\n"
  created_at: 2023-12-09 21:30:56+00:00
  edited: true
  hidden: false
  id: 6574dc909fe27c093d7690d5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: gaussalgo/T5-LM-Large-text2sql-spider
repo_type: model
status: open
target_branch: null
title: Sample code correction
