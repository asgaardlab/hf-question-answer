!!python/object:huggingface_hub.community.DiscussionWithDetails
author: webslug
conflicting_files: null
created_at: 2023-06-21 07:37:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/100a08fb1d2d9294880437fda47c9f93.svg
      fullname: Tim Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: webslug
      type: user
    createdAt: '2023-06-21T08:37:32.000Z'
    data:
      edited: true
      editors:
      - webslug
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6293094158172607
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/100a08fb1d2d9294880437fda47c9f93.svg
          fullname: Tim Smith
          isHf: false
          isPro: false
          name: webslug
          type: user
        html: "<p>Unfortunately this no longer works with the latest version of oobabooga.\
          \  </p>\n<p>I tried Auto-GPTQ and Llama for GPTQ - None of which worked\
          \ with the latest version.  I did get it to load for one second some how\
          \ but it just spat out a lot of garbage text.  </p>\n<p>Traceback (most\
          \ recent call last): File \u201CD:\\AI\\UI\\text-generation-webui\\server.py\u201D\
          , line 62, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name,\
          \ loader) File \u201CD:\\AI\\UI\\text-generation-webui\\modules\\models.py\u201D\
          , line 65, in load_model output = load_func_maploader File \u201CD:\\AI\\\
          UI\\text-generation-webui\\modules\\models.py\u201D, line 263, in GPTQ_loader\
          \ model = modules.GPTQ_loader.load_quantized(model_name) File \u201CD:\\\
          AI\\UI\\text-generation-webui\\modules\\GPTQ_loader.py\u201D, line 163,\
          \ in load_quantized exit() File \u201CD:\\AI\\UI\\installer_files\\env\\\
          lib_sitebuiltins.py\u201D, line 26, in call raise SystemExit(code) SystemExit:\
          \ None</p>\n<p>I have tried Llama Precise and Novel AI Story Writer.   No\
          \ matter what character or prompt I try, everything comes out as gibberish.\
          \  </p>\n"
        raw: "Unfortunately this no longer works with the latest version of oobabooga.\
          \  \n\nI tried Auto-GPTQ and Llama for GPTQ - None of which worked with\
          \ the latest version.  I did get it to load for one second some how but\
          \ it just spat out a lot of garbage text.  \n\nTraceback (most recent call\
          \ last): File \u201CD:\\AI\\UI\\text-generation-webui\\server.py\u201D,\
          \ line 62, in load_model_wrapper shared.model, shared.tokenizer = load_model(shared.model_name,\
          \ loader) File \u201CD:\\AI\\UI\\text-generation-webui\\modules\\models.py\u201D\
          , line 65, in load_model output = load_func_maploader File \u201CD:\\AI\\\
          UI\\text-generation-webui\\modules\\models.py\u201D, line 263, in GPTQ_loader\
          \ model = modules.GPTQ_loader.load_quantized(model_name) File \u201CD:\\\
          AI\\UI\\text-generation-webui\\modules\\GPTQ_loader.py\u201D, line 163,\
          \ in load_quantized exit() File \u201CD:\\AI\\UI\\installer_files\\env\\\
          lib_sitebuiltins.py\u201D, line 26, in call raise SystemExit(code) SystemExit:\
          \ None\n\nI have tried Llama Precise and Novel AI Story Writer.   No matter\
          \ what character or prompt I try, everything comes out as gibberish.  "
        updatedAt: '2023-06-21T10:11:37.868Z'
      numEdits: 1
      reactions: []
    id: 6492b6cc18ec0c2a8287aa3a
    type: comment
  author: webslug
  content: "Unfortunately this no longer works with the latest version of oobabooga.\
    \  \n\nI tried Auto-GPTQ and Llama for GPTQ - None of which worked with the latest\
    \ version.  I did get it to load for one second some how but it just spat out\
    \ a lot of garbage text.  \n\nTraceback (most recent call last): File \u201CD:\\\
    AI\\UI\\text-generation-webui\\server.py\u201D, line 62, in load_model_wrapper\
    \ shared.model, shared.tokenizer = load_model(shared.model_name, loader) File\
    \ \u201CD:\\AI\\UI\\text-generation-webui\\modules\\models.py\u201D, line 65,\
    \ in load_model output = load_func_maploader File \u201CD:\\AI\\UI\\text-generation-webui\\\
    modules\\models.py\u201D, line 263, in GPTQ_loader model = modules.GPTQ_loader.load_quantized(model_name)\
    \ File \u201CD:\\AI\\UI\\text-generation-webui\\modules\\GPTQ_loader.py\u201D\
    , line 163, in load_quantized exit() File \u201CD:\\AI\\UI\\installer_files\\\
    env\\lib_sitebuiltins.py\u201D, line 26, in call raise SystemExit(code) SystemExit:\
    \ None\n\nI have tried Llama Precise and Novel AI Story Writer.   No matter what\
    \ character or prompt I try, everything comes out as gibberish.  "
  created_at: 2023-06-21 07:37:32+00:00
  edited: true
  hidden: false
  id: 6492b6cc18ec0c2a8287aa3a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/100a08fb1d2d9294880437fda47c9f93.svg
      fullname: Tim Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: webslug
      type: user
    createdAt: '2023-06-21T10:05:51.000Z'
    data:
      edited: false
      editors:
      - webslug
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.37573230266571045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/100a08fb1d2d9294880437fda47c9f93.svg
          fullname: Tim Smith
          isHf: false
          isPro: false
          name: webslug
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6459cdc7abdbb77c4c6e5711/b7Q5pXAkoCxk9ZwOlDl8U.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6459cdc7abdbb77c4c6e5711/b7Q5pXAkoCxk9ZwOlDl8U.png"></a></p>

          '
        raw: '

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6459cdc7abdbb77c4c6e5711/b7Q5pXAkoCxk9ZwOlDl8U.png)

          '
        updatedAt: '2023-06-21T10:05:51.818Z'
      numEdits: 0
      reactions: []
    id: 6492cb7fd58fdc50442d2c30
    type: comment
  author: webslug
  content: '

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6459cdc7abdbb77c4c6e5711/b7Q5pXAkoCxk9ZwOlDl8U.png)

    '
  created_at: 2023-06-21 09:05:51+00:00
  edited: false
  hidden: false
  id: 6492cb7fd58fdc50442d2c30
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/100a08fb1d2d9294880437fda47c9f93.svg
      fullname: Tim Smith
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: webslug
      type: user
    createdAt: '2023-06-21T10:38:23.000Z'
    data:
      from: No longer works with latest oobabooga
      to: Dead Model - No longer works with latest oobabooga
    id: 6492d31f43e75ec47134d6cb
    type: title-change
  author: webslug
  created_at: 2023-06-21 09:38:23+00:00
  id: 6492d31f43e75ec47134d6cb
  new_title: Dead Model - No longer works with latest oobabooga
  old_title: No longer works with latest oobabooga
  type: title-change
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: TehVenom/Pygmalion-7b-4bit-GPTQ-Safetensors
repo_type: model
status: open
target_branch: null
title: Dead Model - No longer works with latest oobabooga
