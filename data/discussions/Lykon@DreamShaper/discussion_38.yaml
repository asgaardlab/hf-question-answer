!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JohnsonDoe
conflicting_files: null
created_at: 2023-05-30 11:52:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fdf0a22a578733527023575e39751e16.svg
      fullname: Doe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JohnsonDoe
      type: user
    createdAt: '2023-05-30T12:52:43.000Z'
    data:
      edited: false
      editors:
      - JohnsonDoe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fdf0a22a578733527023575e39751e16.svg
          fullname: Doe
          isHf: false
          isPro: false
          name: JohnsonDoe
          type: user
        html: '<p>Hi, is there a way to increase the max token count from 77 that
          is preset to more than that? I can see from the prompts in the gallery has
          more than 77 tokens in it. </p>

          '
        raw: 'Hi, is there a way to increase the max token count from 77 that is preset
          to more than that? I can see from the prompts in the gallery has more than
          77 tokens in it. '
        updatedAt: '2023-05-30T12:52:43.952Z'
      numEdits: 0
      reactions: []
    id: 6475f19b3a3559d09b5975c8
    type: comment
  author: JohnsonDoe
  content: 'Hi, is there a way to increase the max token count from 77 that is preset
    to more than that? I can see from the prompts in the gallery has more than 77
    tokens in it. '
  created_at: 2023-05-30 11:52:43+00:00
  edited: false
  hidden: false
  id: 6475f19b3a3559d09b5975c8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672788314686-noauth.png?w=200&h=200&f=face
      fullname: '-'
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Lykon
      type: user
    createdAt: '2023-05-30T21:45:45.000Z'
    data:
      edited: false
      editors:
      - Lykon
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672788314686-noauth.png?w=200&h=200&f=face
          fullname: '-'
          isHf: false
          isPro: false
          name: Lykon
          type: user
        html: '<p>that depends on the software you''re using.</p>

          '
        raw: that depends on the software you're using.
        updatedAt: '2023-05-30T21:45:45.451Z'
      numEdits: 0
      reactions: []
    id: 64766e8957108da176ff714f
    type: comment
  author: Lykon
  content: that depends on the software you're using.
  created_at: 2023-05-30 20:45:45+00:00
  edited: false
  hidden: false
  id: 64766e8957108da176ff714f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fdf0a22a578733527023575e39751e16.svg
      fullname: Doe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JohnsonDoe
      type: user
    createdAt: '2023-05-31T04:33:02.000Z'
    data:
      edited: false
      editors:
      - JohnsonDoe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fdf0a22a578733527023575e39751e16.svg
          fullname: Doe
          isHf: false
          isPro: false
          name: JohnsonDoe
          type: user
        html: '<p>Can you please elaborate? I''m very new to this. Which software
          do you recommend using to increase the default set token limit?</p>

          '
        raw: Can you please elaborate? I'm very new to this. Which software do you
          recommend using to increase the default set token limit?
        updatedAt: '2023-05-31T04:33:02.725Z'
      numEdits: 0
      reactions: []
    id: 6476cdfe09660ee8c797a8c3
    type: comment
  author: JohnsonDoe
  content: Can you please elaborate? I'm very new to this. Which software do you recommend
    using to increase the default set token limit?
  created_at: 2023-05-31 03:33:02+00:00
  edited: false
  hidden: false
  id: 6476cdfe09660ee8c797a8c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63c09b32dd793d5a62895a95/27FwQlh3am6xCh9f1mExM.jpeg?w=200&h=200&f=face
      fullname: Duskfall Crew
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Duskfallcrew
      type: user
    createdAt: '2023-05-31T09:19:45.000Z'
    data:
      edited: false
      editors:
      - Duskfallcrew
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63c09b32dd793d5a62895a95/27FwQlh3am6xCh9f1mExM.jpeg?w=200&h=200&f=face
          fullname: Duskfall Crew
          isHf: false
          isPro: false
          name: Duskfallcrew
          type: user
        html: '<p>If you''re using A1111, or most UI''s there is no need to set a
          max token limit when training the model - (as far as I know) - your prompts
          in the UI for stable diffusion will just get automatically set into chunks
          according to how large it is. (depending on which version of stable diffusion
          you''re using that is)</p>

          '
        raw: If you're using A1111, or most UI's there is no need to set a max token
          limit when training the model - (as far as I know) - your prompts in the
          UI for stable diffusion will just get automatically set into chunks according
          to how large it is. (depending on which version of stable diffusion you're
          using that is)
        updatedAt: '2023-05-31T09:19:45.250Z'
      numEdits: 0
      reactions: []
    id: 6477113140c99df87600f27b
    type: comment
  author: Duskfallcrew
  content: If you're using A1111, or most UI's there is no need to set a max token
    limit when training the model - (as far as I know) - your prompts in the UI for
    stable diffusion will just get automatically set into chunks according to how
    large it is. (depending on which version of stable diffusion you're using that
    is)
  created_at: 2023-05-31 08:19:45+00:00
  edited: false
  hidden: false
  id: 6477113140c99df87600f27b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672788314686-noauth.png?w=200&h=200&f=face
      fullname: '-'
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Lykon
      type: user
    createdAt: '2023-05-31T10:03:17.000Z'
    data:
      edited: false
      editors:
      - Lykon
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672788314686-noauth.png?w=200&h=200&f=face
          fullname: '-'
          isHf: false
          isPro: false
          name: Lykon
          type: user
        html: '<p>I''m closing this as it''s not an issue with the model. I think
          you will get better assistance by opening an issue on the repo of the tool
          you''re using :) </p>

          '
        raw: 'I''m closing this as it''s not an issue with the model. I think you
          will get better assistance by opening an issue on the repo of the tool you''re
          using :) '
        updatedAt: '2023-05-31T10:03:17.697Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64771b65beaeebff4a5415eb
    id: 64771b65beaeebff4a5415ea
    type: comment
  author: Lykon
  content: 'I''m closing this as it''s not an issue with the model. I think you will
    get better assistance by opening an issue on the repo of the tool you''re using
    :) '
  created_at: 2023-05-31 09:03:17+00:00
  edited: false
  hidden: false
  id: 64771b65beaeebff4a5415ea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672788314686-noauth.png?w=200&h=200&f=face
      fullname: '-'
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Lykon
      type: user
    createdAt: '2023-05-31T10:03:17.000Z'
    data:
      status: closed
    id: 64771b65beaeebff4a5415eb
    type: status-change
  author: Lykon
  created_at: 2023-05-31 09:03:17+00:00
  id: 64771b65beaeebff4a5415eb
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 38
repo_id: Lykon/DreamShaper
repo_type: model
status: closed
target_branch: null
title: Increasing Max Token Limit
