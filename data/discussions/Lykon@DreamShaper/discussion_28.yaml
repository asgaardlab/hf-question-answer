!!python/object:huggingface_hub.community.DiscussionWithDetails
author: 34ronker
conflicting_files: null
created_at: 2023-03-29 13:22:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/010775ef981b00db033953cb9a025281.svg
      fullname: Ben Shiller
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 34ronker
      type: user
    createdAt: '2023-03-29T14:22:52.000Z'
    data:
      edited: false
      editors:
      - 34ronker
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/010775ef981b00db033953cb9a025281.svg
          fullname: Ben Shiller
          isHf: false
          isPro: false
          name: 34ronker
          type: user
        html: "<p>Can this model be used in Inpainting like this?</p>\n<pre><code\
          \ class=\"language-python\">model_id = <span class=\"hljs-string\">\"Lykon/DreamShaper\"\
          </span>\nmodel = StableDiffusionInpaintPipeline.from_pretrained(model_id,\
          \ safety_checker=<span class=\"hljs-literal\">None</span>, torch_dtype=torch.float16).to(<span\
          \ class=\"hljs-string\">\"cuda\"</span>)\n</code></pre>\n<p>Doing the above\
          \ I get the following error:</p>\n<pre><code class=\"language-python\">ValueError:\
          \ Incorrect configuration settings! The config of `pipeline.unet`: FrozenDict([(<span\
          \ class=\"hljs-string\">'sample_size'</span>, <span class=\"hljs-number\"\
          >64</span>), \n(<span class=\"hljs-string\">'in_channels'</span>, <span\
          \ class=\"hljs-number\">4</span>), (<span class=\"hljs-string\">'out_channels'</span>,\
          \ <span class=\"hljs-number\">4</span>), (<span class=\"hljs-string\">'center_input_sample'</span>,\
          \ <span class=\"hljs-literal\">False</span>), (<span class=\"hljs-string\"\
          >'flip_sin_to_cos'</span>, <span class=\"hljs-literal\">True</span>), (<span\
          \ class=\"hljs-string\">'freq_shift'</span>, \n<span class=\"hljs-number\"\
          >0</span>), (<span class=\"hljs-string\">'down_block_types'</span>, [<span\
          \ class=\"hljs-string\">'CrossAttnDownBlock2D'</span>, <span class=\"hljs-string\"\
          >'CrossAttnDownBlock2D'</span>, <span class=\"hljs-string\">'CrossAttnDownBlock2D'</span>,\
          \ <span class=\"hljs-string\">'DownBlock2D'</span>]), \n(<span class=\"\
          hljs-string\">'mid_block_type'</span>, <span class=\"hljs-string\">'UNetMidBlock2DCrossAttn'</span>),\
          \ (<span class=\"hljs-string\">'up_block_types'</span>, [<span class=\"\
          hljs-string\">'UpBlock2D'</span>, <span class=\"hljs-string\">'CrossAttnUpBlock2D'</span>,\
          \ \n<span class=\"hljs-string\">'CrossAttnUpBlock2D'</span>, <span class=\"\
          hljs-string\">'CrossAttnUpBlock2D'</span>]), (<span class=\"hljs-string\"\
          >'only_cross_attention'</span>, <span class=\"hljs-literal\">False</span>),\
          \ (<span class=\"hljs-string\">'block_out_channels'</span>, [<span class=\"\
          hljs-number\">320</span>, <span class=\"hljs-number\">640</span>, \n<span\
          \ class=\"hljs-number\">1280</span>, <span class=\"hljs-number\">1280</span>]),\
          \ (<span class=\"hljs-string\">'layers_per_block'</span>, <span class=\"\
          hljs-number\">2</span>), (<span class=\"hljs-string\">'downsample_padding'</span>,\
          \ <span class=\"hljs-number\">1</span>), (<span class=\"hljs-string\">'mid_block_scale_factor'</span>,\
          \ <span class=\"hljs-number\">1</span>), (<span class=\"hljs-string\">'act_fn'</span>,\
          \ \n<span class=\"hljs-string\">'silu'</span>), (<span class=\"hljs-string\"\
          >'norm_num_groups'</span>, <span class=\"hljs-number\">32</span>), (<span\
          \ class=\"hljs-string\">'norm_eps'</span>, <span class=\"hljs-number\">1e-05</span>),\
          \ (<span class=\"hljs-string\">'cross_attention_dim'</span>, <span class=\"\
          hljs-number\">768</span>), (<span class=\"hljs-string\">'attention_head_dim'</span>,\
          \ <span class=\"hljs-number\">8</span>), \n(<span class=\"hljs-string\"\
          >'dual_cross_attention'</span>, <span class=\"hljs-literal\">False</span>),\
          \ (<span class=\"hljs-string\">'use_linear_projection'</span>, <span class=\"\
          hljs-literal\">False</span>), (<span class=\"hljs-string\">'class_embed_type'</span>,\
          \ <span class=\"hljs-literal\">None</span>), (<span class=\"hljs-string\"\
          >'num_class_embeds'</span>,\n<span class=\"hljs-literal\">None</span>),\
          \ (<span class=\"hljs-string\">'upcast_attention'</span>, <span class=\"\
          hljs-literal\">None</span>), (<span class=\"hljs-string\">'resnet_time_scale_shift'</span>,\
          \ <span class=\"hljs-string\">'default'</span>), (<span class=\"hljs-string\"\
          >'time_embedding_type'</span>, <span class=\"hljs-string\">'positional'</span>),\
          \ \n(<span class=\"hljs-string\">'timestep_post_act'</span>, <span class=\"\
          hljs-literal\">None</span>), (<span class=\"hljs-string\">'time_cond_proj_dim'</span>,\
          \ <span class=\"hljs-literal\">None</span>), (<span class=\"hljs-string\"\
          >'conv_in_kernel'</span>, <span class=\"hljs-number\">3</span>), (<span\
          \ class=\"hljs-string\">'conv_out_kernel'</span>, <span class=\"hljs-number\"\
          >3</span>), \n(<span class=\"hljs-string\">'projection_class_embeddings_input_dim'</span>,\
          \ <span class=\"hljs-literal\">None</span>), (<span class=\"hljs-string\"\
          >'_class_name'</span>, <span class=\"hljs-string\">'UNet2DConditionModel'</span>),\
          \ (<span class=\"hljs-string\">'_diffusers_version'</span>, \n<span class=\"\
          hljs-string\">'0.14.0'</span>), (<span class=\"hljs-string\">'_name_or_path'</span>,\
          \ \n<span class=\"hljs-string\">'/root/.cache/huggingface/hub/models--Lykon--DreamShaper/snapshots/6a1a38f04a235d0ed2acbb083c2a780fc92c16eb/unet'</span>)]\n\
          ) expects <span class=\"hljs-number\">4</span> but received `num_channels_latents`:\
          \ <span class=\"hljs-number\">4</span> + `num_channels_mask`: <span class=\"\
          hljs-number\">1</span> + `num_channels_masked_image`: <span class=\"hljs-number\"\
          >4</span> = <span class=\"hljs-number\">9.</span> \nPlease verify the config\
          \ of `pipeline.unet` <span class=\"hljs-keyword\">or</span> your `mask_image`\
          \ <span class=\"hljs-keyword\">or</span> `image` <span class=\"hljs-built_in\"\
          >input</span>.\n</code></pre>\n"
        raw: "Can this model be used in Inpainting like this?\r\n```python\r\nmodel_id\
          \ = \"Lykon/DreamShaper\"\r\nmodel = StableDiffusionInpaintPipeline.from_pretrained(model_id,\
          \ safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\r\n```\r\n\
          \r\n\r\nDoing the above I get the following error:\r\n```python\r\nValueError:\
          \ Incorrect configuration settings! The config of `pipeline.unet`: FrozenDict([('sample_size',\
          \ 64), \r\n('in_channels', 4), ('out_channels', 4), ('center_input_sample',\
          \ False), ('flip_sin_to_cos', True), ('freq_shift', \r\n0), ('down_block_types',\
          \ ['CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'CrossAttnDownBlock2D',\
          \ 'DownBlock2D']), \r\n('mid_block_type', 'UNetMidBlock2DCrossAttn'), ('up_block_types',\
          \ ['UpBlock2D', 'CrossAttnUpBlock2D', \r\n'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D']),\
          \ ('only_cross_attention', False), ('block_out_channels', [320, 640, \r\n\
          1280, 1280]), ('layers_per_block', 2), ('downsample_padding', 1), ('mid_block_scale_factor',\
          \ 1), ('act_fn', \r\n'silu'), ('norm_num_groups', 32), ('norm_eps', 1e-05),\
          \ ('cross_attention_dim', 768), ('attention_head_dim', 8), \r\n('dual_cross_attention',\
          \ False), ('use_linear_projection', False), ('class_embed_type', None),\
          \ ('num_class_embeds',\r\nNone), ('upcast_attention', None), ('resnet_time_scale_shift',\
          \ 'default'), ('time_embedding_type', 'positional'), \r\n('timestep_post_act',\
          \ None), ('time_cond_proj_dim', None), ('conv_in_kernel', 3), ('conv_out_kernel',\
          \ 3), \r\n('projection_class_embeddings_input_dim', None), ('_class_name',\
          \ 'UNet2DConditionModel'), ('_diffusers_version', \r\n'0.14.0'), ('_name_or_path',\
          \ \r\n'/root/.cache/huggingface/hub/models--Lykon--DreamShaper/snapshots/6a1a38f04a235d0ed2acbb083c2a780fc92c16eb/unet')]\r\
          \n) expects 4 but received `num_channels_latents`: 4 + `num_channels_mask`:\
          \ 1 + `num_channels_masked_image`: 4 = 9. \r\nPlease verify the config of\
          \ `pipeline.unet` or your `mask_image` or `image` input.\r\n```"
        updatedAt: '2023-03-29T14:22:52.034Z'
      numEdits: 0
      reactions: []
    id: 642449bc73f7a0d40b30e455
    type: comment
  author: 34ronker
  content: "Can this model be used in Inpainting like this?\r\n```python\r\nmodel_id\
    \ = \"Lykon/DreamShaper\"\r\nmodel = StableDiffusionInpaintPipeline.from_pretrained(model_id,\
    \ safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\r\n```\r\n\r\n\r\
    \nDoing the above I get the following error:\r\n```python\r\nValueError: Incorrect\
    \ configuration settings! The config of `pipeline.unet`: FrozenDict([('sample_size',\
    \ 64), \r\n('in_channels', 4), ('out_channels', 4), ('center_input_sample', False),\
    \ ('flip_sin_to_cos', True), ('freq_shift', \r\n0), ('down_block_types', ['CrossAttnDownBlock2D',\
    \ 'CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'DownBlock2D']), \r\n('mid_block_type',\
    \ 'UNetMidBlock2DCrossAttn'), ('up_block_types', ['UpBlock2D', 'CrossAttnUpBlock2D',\
    \ \r\n'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D']), ('only_cross_attention', False),\
    \ ('block_out_channels', [320, 640, \r\n1280, 1280]), ('layers_per_block', 2),\
    \ ('downsample_padding', 1), ('mid_block_scale_factor', 1), ('act_fn', \r\n'silu'),\
    \ ('norm_num_groups', 32), ('norm_eps', 1e-05), ('cross_attention_dim', 768),\
    \ ('attention_head_dim', 8), \r\n('dual_cross_attention', False), ('use_linear_projection',\
    \ False), ('class_embed_type', None), ('num_class_embeds',\r\nNone), ('upcast_attention',\
    \ None), ('resnet_time_scale_shift', 'default'), ('time_embedding_type', 'positional'),\
    \ \r\n('timestep_post_act', None), ('time_cond_proj_dim', None), ('conv_in_kernel',\
    \ 3), ('conv_out_kernel', 3), \r\n('projection_class_embeddings_input_dim', None),\
    \ ('_class_name', 'UNet2DConditionModel'), ('_diffusers_version', \r\n'0.14.0'),\
    \ ('_name_or_path', \r\n'/root/.cache/huggingface/hub/models--Lykon--DreamShaper/snapshots/6a1a38f04a235d0ed2acbb083c2a780fc92c16eb/unet')]\r\
    \n) expects 4 but received `num_channels_latents`: 4 + `num_channels_mask`: 1\
    \ + `num_channels_masked_image`: 4 = 9. \r\nPlease verify the config of `pipeline.unet`\
    \ or your `mask_image` or `image` input.\r\n```"
  created_at: 2023-03-29 13:22:52+00:00
  edited: false
  hidden: false
  id: 642449bc73f7a0d40b30e455
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672788314686-noauth.png?w=200&h=200&f=face
      fullname: '-'
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Lykon
      type: user
    createdAt: '2023-03-29T15:40:15.000Z'
    data:
      edited: false
      editors:
      - Lykon
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672788314686-noauth.png?w=200&h=200&f=face
          fullname: '-'
          isHf: false
          isPro: false
          name: Lykon
          type: user
        html: '<p>you should probably convert this file <a href="https://huggingface.co/Lykon/DreamShaper/blob/main/DreamShaper_3.31_baked_vae-inpainting.inpainting.safetensors">https://huggingface.co/Lykon/DreamShaper/blob/main/DreamShaper_3.31_baked_vae-inpainting.inpainting.safetensors</a><br>Anyway
          I also noticed I forgot to upload the inpainting v4 model.</p>

          <p>Doing it right now. </p>

          '
        raw: 'you should probably convert this file https://huggingface.co/Lykon/DreamShaper/blob/main/DreamShaper_3.31_baked_vae-inpainting.inpainting.safetensors

          Anyway I also noticed I forgot to upload the inpainting v4 model.


          Doing it right now. '
        updatedAt: '2023-03-29T15:40:15.973Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64245bdf0d0c3cb50e97de73
    id: 64245bdf0d0c3cb50e97de72
    type: comment
  author: Lykon
  content: 'you should probably convert this file https://huggingface.co/Lykon/DreamShaper/blob/main/DreamShaper_3.31_baked_vae-inpainting.inpainting.safetensors

    Anyway I also noticed I forgot to upload the inpainting v4 model.


    Doing it right now. '
  created_at: 2023-03-29 14:40:15+00:00
  edited: false
  hidden: false
  id: 64245bdf0d0c3cb50e97de72
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672788314686-noauth.png?w=200&h=200&f=face
      fullname: '-'
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Lykon
      type: user
    createdAt: '2023-03-29T15:40:15.000Z'
    data:
      status: closed
    id: 64245bdf0d0c3cb50e97de73
    type: status-change
  author: Lykon
  created_at: 2023-03-29 14:40:15+00:00
  id: 64245bdf0d0c3cb50e97de73
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 28
repo_id: Lykon/DreamShaper
repo_type: model
status: closed
target_branch: null
title: How can I use the Inpaint model with diffusers?
