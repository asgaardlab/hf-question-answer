!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Kenshiro-28
conflicting_files: null
created_at: 2023-10-31 12:05:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/380602407fc05f52b4c4057dffc91977.svg
      fullname: '[]'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kenshiro-28
      type: user
    createdAt: '2023-10-31T13:05:32.000Z'
    data:
      edited: false
      editors:
      - Kenshiro-28
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9650933742523193
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/380602407fc05f52b4c4057dffc91977.svg
          fullname: '[]'
          isHf: false
          isPro: false
          name: Kenshiro-28
          type: user
        html: '<p>This is the best model I have tested, thank you very much :)</p>

          <p>One thing, from time to time I get this tag in the response:  &lt;/|im_end|&gt;  .
          It happened also in the previous version of Dolphin. It''s a malformed end
          tag, maybe it''s in the training data.</p>

          '
        raw: "This is the best model I have tested, thank you very much :)\r\n\r\n\
          One thing, from time to time I get this tag in the response:  </|im_end|>\
          \  . It happened also in the previous version of Dolphin. It's a malformed\
          \ end tag, maybe it's in the training data."
        updatedAt: '2023-10-31T13:05:32.640Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - romaai
    id: 6540fb9ca369c00075044d79
    type: comment
  author: Kenshiro-28
  content: "This is the best model I have tested, thank you very much :)\r\n\r\nOne\
    \ thing, from time to time I get this tag in the response:  </|im_end|>  . It\
    \ happened also in the previous version of Dolphin. It's a malformed end tag,\
    \ maybe it's in the training data."
  created_at: 2023-10-31 12:05:32+00:00
  edited: false
  hidden: false
  id: 6540fb9ca369c00075044d79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
      fullname: boqsc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boqsc
      type: user
    createdAt: '2023-10-31T19:37:50.000Z'
    data:
      edited: true
      editors:
      - boqsc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9698070287704468
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
          fullname: boqsc
          isHf: false
          isPro: false
          name: boqsc
          type: user
        html: '<p>In the previous version only happened in GPT4ALL UI.<br>LM Studio
          seem to handle it better.</p>

          <p>I tried many quantisations and many settings.</p>

          <p>On LM Studio Choose ChatML prompt preset <a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/rdZ1Mb_YTFhpygwItIwDX.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/rdZ1Mb_YTFhpygwItIwDX.png"></a></p>

          '
        raw: "In the previous version only happened in GPT4ALL UI. \nLM Studio seem\
          \ to handle it better.\n\nI tried many quantisations and many settings.\n\
          \nOn LM Studio Choose ChatML prompt preset ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/rdZ1Mb_YTFhpygwItIwDX.png)\n"
        updatedAt: '2023-10-31T19:39:51.198Z'
      numEdits: 2
      reactions: []
    id: 6541578eb0170e9607e42333
    type: comment
  author: boqsc
  content: "In the previous version only happened in GPT4ALL UI. \nLM Studio seem\
    \ to handle it better.\n\nI tried many quantisations and many settings.\n\nOn\
    \ LM Studio Choose ChatML prompt preset ![image.png](https://cdn-uploads.huggingface.co/production/uploads/62f7f0c147d782a6e286662a/rdZ1Mb_YTFhpygwItIwDX.png)\n"
  created_at: 2023-10-31 18:37:50+00:00
  edited: true
  hidden: false
  id: 6541578eb0170e9607e42333
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a43a73a77be89cc7443347d1a0aef9fe.svg
      fullname: James Edward
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Goldenblood56
      type: user
    createdAt: '2023-10-31T22:47:51.000Z'
    data:
      edited: true
      editors:
      - Goldenblood56
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9520015716552734
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a43a73a77be89cc7443347d1a0aef9fe.svg
          fullname: James Edward
          isHf: false
          isPro: false
          name: Goldenblood56
          type: user
        html: '<p>In the 2.1 version using ChatML I would get things like  &lt;/|im_end|&gt;
          and then it would start talking as if it was me etc? It never happened if
          I used the other things only ChatML. If I choose Alpaca or Guanaco it was
          fine. What mode should I be using it in? I use it in instruct mode? I like
          having long sets of instructions and asking multiple questions. Should I
          use chat instead? </p>

          <p>I update my oobabooga but could my ChatML be broken out outdated? Do
          I need to add a custom one? I''m not sure if this problem is fixed or not
          for 2.2. </p>

          '
        raw: "In the 2.1 version using ChatML I would get things like  </|im_end|>\
          \ and then it would start talking as if it was me etc? It never happened\
          \ if I used the other things only ChatML. If I choose Alpaca or Guanaco\
          \ it was fine. What mode should I be using it in? I use it in instruct mode?\
          \ I like having long sets of instructions and asking multiple questions.\
          \ Should I use chat instead? \n\nI update my oobabooga but could my ChatML\
          \ be broken out outdated? Do I need to add a custom one? I'm not sure if\
          \ this problem is fixed or not for 2.2. \n\n\n"
        updatedAt: '2023-10-31T22:49:06.066Z'
      numEdits: 2
      reactions: []
    id: 6541841741676ceaa2c455f6
    type: comment
  author: Goldenblood56
  content: "In the 2.1 version using ChatML I would get things like  </|im_end|> and\
    \ then it would start talking as if it was me etc? It never happened if I used\
    \ the other things only ChatML. If I choose Alpaca or Guanaco it was fine. What\
    \ mode should I be using it in? I use it in instruct mode? I like having long\
    \ sets of instructions and asking multiple questions. Should I use chat instead?\
    \ \n\nI update my oobabooga but could my ChatML be broken out outdated? Do I need\
    \ to add a custom one? I'm not sure if this problem is fixed or not for 2.2. \n\
    \n\n"
  created_at: 2023-10-31 21:47:51+00:00
  edited: true
  hidden: false
  id: 6541841741676ceaa2c455f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/380602407fc05f52b4c4057dffc91977.svg
      fullname: '[]'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kenshiro-28
      type: user
    createdAt: '2023-11-01T12:08:26.000Z'
    data:
      edited: false
      editors:
      - Kenshiro-28
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9111983776092529
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/380602407fc05f52b4c4057dffc91977.svg
          fullname: '[]'
          isHf: false
          isPro: false
          name: Kenshiro-28
          type: user
        html: '<p>I''m using it with MAGI, the model works fine, the only issue is
          that from time to time you get a &lt;/|im_end|&gt; in the response, but
          functionality is ok.</p>

          <p><a rel="nofollow" href="https://github.com/Kenshiro-28/MAGI">https://github.com/Kenshiro-28/MAGI</a></p>

          '
        raw: 'I''m using it with MAGI, the model works fine, the only issue is that
          from time to time you get a </|im_end|> in the response, but functionality
          is ok.


          https://github.com/Kenshiro-28/MAGI'
        updatedAt: '2023-11-01T12:08:26.016Z'
      numEdits: 0
      reactions: []
    id: 65423fbac7bf7cd7125e7034
    type: comment
  author: Kenshiro-28
  content: 'I''m using it with MAGI, the model works fine, the only issue is that
    from time to time you get a </|im_end|> in the response, but functionality is
    ok.


    https://github.com/Kenshiro-28/MAGI'
  created_at: 2023-11-01 11:08:26+00:00
  edited: false
  hidden: false
  id: 65423fbac7bf7cd7125e7034
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/dolphin-2.2.1-mistral-7B-GGUF
repo_type: model
status: open
target_branch: null
title: The best model
