!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wesleysanjose
conflicting_files: null
created_at: 2023-07-19 15:38:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/35d1235f3450b253c8a6cb41811c52fd.svg
      fullname: Wesley Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wesleysanjose
      type: user
    createdAt: '2023-07-19T16:38:00.000Z'
    data:
      edited: true
      editors:
      - wesleysanjose
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9309263825416565
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/35d1235f3450b253c8a6cb41811c52fd.svg
          fullname: Wesley Zhang
          isHf: false
          isPro: false
          name: wesleysanjose
          type: user
        html: '<p>tried to run this GPTQ using autoGPTQ in text-generation-webui,
          but it keeps crashing after interfering for seconds. i can see GPU spikes
          but the temperature was not crazy. the non GPTQ version runs fine. I am
          using 3090 BTW.</p>

          '
        raw: tried to run this GPTQ using autoGPTQ in text-generation-webui, but it
          keeps crashing after interfering for seconds. i can see GPU spikes but the
          temperature was not crazy. the non GPTQ version runs fine. I am using 3090
          BTW.
        updatedAt: '2023-07-19T16:38:14.960Z'
      numEdits: 1
      reactions: []
    id: 64b81168cbb0af9bfb0ae9b6
    type: comment
  author: wesleysanjose
  content: tried to run this GPTQ using autoGPTQ in text-generation-webui, but it
    keeps crashing after interfering for seconds. i can see GPU spikes but the temperature
    was not crazy. the non GPTQ version runs fine. I am using 3090 BTW.
  created_at: 2023-07-19 15:38:00+00:00
  edited: true
  hidden: false
  id: 64b81168cbb0af9bfb0ae9b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/09c8e92f65ca1303343bf8c1bff33a40.svg
      fullname: Chakib .Bz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: blob42
      type: user
    createdAt: '2023-07-21T20:21:04.000Z'
    data:
      edited: true
      editors:
      - blob42
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2948298454284668
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/09c8e92f65ca1303343bf8c1bff33a40.svg
          fullname: Chakib .Bz
          isHf: false
          isPro: false
          name: blob42
          type: user
        html: '<p>Same issue same card. Using ooba webui on commit 63ece46</p>

          <pre><code>ooba-webui  | 2023-07-21 18:47:51 ERROR:Failed to load the model.

          ooba-webui  | Traceback (most recent call last):

          ooba-webui  |   File "/app/server.py", line 68, in load_model_wrapper

          ooba-webui  |     shared.model, shared.tokenizer = load_model(shared.model_name,
          loader)

          ooba-webui  |   File "/app/modules/models.py", line 87, in load_model

          ooba-webui  |     tokenizer = load_tokenizer(model_name, model)

          ooba-webui  |   File "/app/modules/models.py", line 104, in load_tokenizer

          ooba-webui  |     tokenizer = AutoTokenizer.from_pretrained(

          ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py",
          line 702, in from_pretrained

          ooba-webui  |     return tokenizer_class.from_pretrained(pretrained_model_name_or_path,
          *inputs, **kwargs)

          ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py",
          line 1841, in from_pretrained

          ooba-webui  |     return cls._from_pretrained(

          ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py",
          line 2004, in _from_pretrained

          ooba-webui  |     tokenizer = cls(*init_inputs, **init_kwargs)

          ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/models/gpt2/tokenization_gpt2.py",
          line 194, in __init__

          ooba-webui  |     with open(merges_file, encoding="utf-8") as merges_handle:

          ooba-webui  | TypeError: expected str, bytes or os.PathLike object, not
          NoneType

          </code></pre>

          '
        raw: 'Same issue same card. Using ooba webui on commit 63ece46

          ```

          ooba-webui  | 2023-07-21 18:47:51 ERROR:Failed to load the model.

          ooba-webui  | Traceback (most recent call last):

          ooba-webui  |   File "/app/server.py", line 68, in load_model_wrapper

          ooba-webui  |     shared.model, shared.tokenizer = load_model(shared.model_name,
          loader)

          ooba-webui  |   File "/app/modules/models.py", line 87, in load_model

          ooba-webui  |     tokenizer = load_tokenizer(model_name, model)

          ooba-webui  |   File "/app/modules/models.py", line 104, in load_tokenizer

          ooba-webui  |     tokenizer = AutoTokenizer.from_pretrained(

          ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py",
          line 702, in from_pretrained

          ooba-webui  |     return tokenizer_class.from_pretrained(pretrained_model_name_or_path,
          *inputs, **kwargs)

          ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py",
          line 1841, in from_pretrained

          ooba-webui  |     return cls._from_pretrained(

          ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py",
          line 2004, in _from_pretrained

          ooba-webui  |     tokenizer = cls(*init_inputs, **init_kwargs)

          ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/models/gpt2/tokenization_gpt2.py",
          line 194, in __init__

          ooba-webui  |     with open(merges_file, encoding="utf-8") as merges_handle:

          ooba-webui  | TypeError: expected str, bytes or os.PathLike object, not
          NoneType

          ```'
        updatedAt: '2023-07-21T20:22:25.920Z'
      numEdits: 1
      reactions: []
    id: 64bae8b09f94ea2554bf1413
    type: comment
  author: blob42
  content: 'Same issue same card. Using ooba webui on commit 63ece46

    ```

    ooba-webui  | 2023-07-21 18:47:51 ERROR:Failed to load the model.

    ooba-webui  | Traceback (most recent call last):

    ooba-webui  |   File "/app/server.py", line 68, in load_model_wrapper

    ooba-webui  |     shared.model, shared.tokenizer = load_model(shared.model_name,
    loader)

    ooba-webui  |   File "/app/modules/models.py", line 87, in load_model

    ooba-webui  |     tokenizer = load_tokenizer(model_name, model)

    ooba-webui  |   File "/app/modules/models.py", line 104, in load_tokenizer

    ooba-webui  |     tokenizer = AutoTokenizer.from_pretrained(

    ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py",
    line 702, in from_pretrained

    ooba-webui  |     return tokenizer_class.from_pretrained(pretrained_model_name_or_path,
    *inputs, **kwargs)

    ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py",
    line 1841, in from_pretrained

    ooba-webui  |     return cls._from_pretrained(

    ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py",
    line 2004, in _from_pretrained

    ooba-webui  |     tokenizer = cls(*init_inputs, **init_kwargs)

    ooba-webui  |   File "/app/venv/lib/python3.10/site-packages/transformers/models/gpt2/tokenization_gpt2.py",
    line 194, in __init__

    ooba-webui  |     with open(merges_file, encoding="utf-8") as merges_handle:

    ooba-webui  | TypeError: expected str, bytes or os.PathLike object, not NoneType

    ```'
  created_at: 2023-07-21 19:21:04+00:00
  edited: true
  hidden: false
  id: 64bae8b09f94ea2554bf1413
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-21T20:22:53.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9559175372123718
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;blob42&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/blob42\">@<span class=\"\
          underline\">blob42</span></a></span>\n\n\t</span></span> the error suggests\
          \ you don't have file merges.txt. That file does exist in my repo, so please\
          \ try triggering the download again. Any missing files will be downloaded,\
          \ without re-downloading anything you do have downloaded successfully.</p>\n"
        raw: '@blob42 the error suggests you don''t have file merges.txt. That file
          does exist in my repo, so please try triggering the download again. Any
          missing files will be downloaded, without re-downloading anything you do
          have downloaded successfully.'
        updatedAt: '2023-07-21T20:22:53.741Z'
      numEdits: 0
      reactions: []
    id: 64bae91d2e66dc7b8b8313ca
    type: comment
  author: TheBloke
  content: '@blob42 the error suggests you don''t have file merges.txt. That file
    does exist in my repo, so please try triggering the download again. Any missing
    files will be downloaded, without re-downloading anything you do have downloaded
    successfully.'
  created_at: 2023-07-21 19:22:53+00:00
  edited: false
  hidden: false
  id: 64bae91d2e66dc7b8b8313ca
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: TheBloke/WizardCoder-15B-1.0-GPTQ
repo_type: model
status: open
target_branch: null
title: keeps crashing when running on text-generation-webui
