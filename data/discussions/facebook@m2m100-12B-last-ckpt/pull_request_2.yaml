!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tomsherborne
conflicting_files: []
created_at: 2023-06-06 19:58:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1c0575701529ae0f15a6fed6834a473c.svg
      fullname: Tom Sherborne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomsherborne
      type: user
    createdAt: '2023-06-06T20:58:25.000Z'
    data:
      edited: false
      editors:
      - tomsherborne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8351491093635559
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1c0575701529ae0f15a6fed6834a473c.svg
          fullname: Tom Sherborne
          isHf: false
          isPro: false
          name: tomsherborne
          type: user
        html: '<p>The 12B model does not match the performance of the 1.2B model as
          the generation defaults to the max_length of "20". This results in shorter
          sequences than the model should be generating. For example on WMT14-DE-EN:
          the 12B model scores 15.52 and the 1.2B model scores 31.786 (SacreBLEU).
          The default max_length is properly set in the smaller models (see <a href="https://huggingface.co/facebook/m2m100_1.2B/blob/main/generation_config.json">https://huggingface.co/facebook/m2m100_1.2B/blob/main/generation_config.json</a>)
          and the 12B models should match this. I am submitting similar PRs for the
          other 12B models.</p>

          '
        raw: 'The 12B model does not match the performance of the 1.2B model as the
          generation defaults to the max_length of "20". This results in shorter sequences
          than the model should be generating. For example on WMT14-DE-EN: the 12B
          model scores 15.52 and the 1.2B model scores 31.786 (SacreBLEU). The default
          max_length is properly set in the smaller models (see https://huggingface.co/facebook/m2m100_1.2B/blob/main/generation_config.json)
          and the 12B models should match this. I am submitting similar PRs for the
          other 12B models.'
        updatedAt: '2023-06-06T20:58:25.385Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - AlexHung29629
    id: 647f9df11637c1c0e6ed0234
    type: comment
  author: tomsherborne
  content: 'The 12B model does not match the performance of the 1.2B model as the
    generation defaults to the max_length of "20". This results in shorter sequences
    than the model should be generating. For example on WMT14-DE-EN: the 12B model
    scores 15.52 and the 1.2B model scores 31.786 (SacreBLEU). The default max_length
    is properly set in the smaller models (see https://huggingface.co/facebook/m2m100_1.2B/blob/main/generation_config.json)
    and the 12B models should match this. I am submitting similar PRs for the other
    12B models.'
  created_at: 2023-06-06 19:58:25+00:00
  edited: false
  hidden: false
  id: 647f9df11637c1c0e6ed0234
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/1c0575701529ae0f15a6fed6834a473c.svg
      fullname: Tom Sherborne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomsherborne
      type: user
    createdAt: '2023-06-06T20:58:26.000Z'
    data:
      oid: bfe20d3f4bd3dfb243741582871de6a2800bdf1e
      parents:
      - c94ddeb57e0d6e76b3f3b048668afc5cc7ccc44b
      subject: Add the "max_length" parameter to the Generation configuration.
    id: 647f9df20000000000000000
    type: commit
  author: tomsherborne
  created_at: 2023-06-06 19:58:26+00:00
  id: 647f9df20000000000000000
  oid: bfe20d3f4bd3dfb243741582871de6a2800bdf1e
  summary: Add the "max_length" parameter to the Generation configuration.
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2f0aed8589e21e54442c5fb9b957250f.svg
      fullname: Alex Hung
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AlexHung29629
      type: user
    createdAt: '2023-08-08T10:12:44.000Z'
    data:
      edited: false
      editors:
      - AlexHung29629
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.17257070541381836
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2f0aed8589e21e54442c5fb9b957250f.svg
          fullname: Alex Hung
          isHf: false
          isPro: false
          name: AlexHung29629
          type: user
        html: '<p> you can directly add the specified parameter "max_length=2048"
          to the <code>generate</code> function.<br><code>generated_tokens = model.generate(**encoded_en,
          forced_bos_token_id=tokenizer.get_lang_id("zh"), max_length=2048)</code></p>

          '
        raw: ' you can directly add the specified parameter "max_length=2048" to the
          `generate` function.

          `generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.get_lang_id("zh"),
          max_length=2048)`'
        updatedAt: '2023-08-08T10:12:44.491Z'
      numEdits: 0
      reactions: []
    id: 64d2151c6162c94cfb9857c3
    type: comment
  author: AlexHung29629
  content: ' you can directly add the specified parameter "max_length=2048" to the
    `generate` function.

    `generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.get_lang_id("zh"),
    max_length=2048)`'
  created_at: 2023-08-08 09:12:44+00:00
  edited: false
  hidden: false
  id: 64d2151c6162c94cfb9857c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1c0575701529ae0f15a6fed6834a473c.svg
      fullname: Tom Sherborne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomsherborne
      type: user
    createdAt: '2023-08-08T10:40:49.000Z'
    data:
      edited: false
      editors:
      - tomsherborne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.881850004196167
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1c0575701529ae0f15a6fed6834a473c.svg
          fullname: Tom Sherborne
          isHf: false
          isPro: false
          name: tomsherborne
          type: user
        html: '<p>That is a shorter term solution when the "out of the box" interface
          for 12B should match the smaller models. </p>

          '
        raw: 'That is a shorter term solution when the "out of the box" interface
          for 12B should match the smaller models. '
        updatedAt: '2023-08-08T10:40:49.218Z'
      numEdits: 0
      reactions: []
    id: 64d21bb1be24c02b828b845e
    type: comment
  author: tomsherborne
  content: 'That is a shorter term solution when the "out of the box" interface for
    12B should match the smaller models. '
  created_at: 2023-08-08 09:40:49+00:00
  edited: false
  hidden: false
  id: 64d21bb1be24c02b828b845e
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 2
repo_id: facebook/m2m100-12B-last-ckpt
repo_type: model
status: open
target_branch: refs/heads/main
title: Add the "max_length" parameter to the Generation configuration.
