!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Zilun
conflicting_files: null
created_at: 2023-12-07 10:58:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c41ca27eda9b0938a4bb9348d1b11b5d.svg
      fullname: Zilun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Zilun
      type: user
    createdAt: '2023-12-07T10:58:30.000Z'
    data:
      edited: true
      editors:
      - Zilun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4342467188835144
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c41ca27eda9b0938a4bb9348d1b11b5d.svg
          fullname: Zilun
          isHf: false
          isPro: false
          name: Zilun
          type: user
        html: "<p>Would you mind having a look at what I missed?</p>\n<p>Thanks.</p>\n\
          <p><a rel=\"nofollow\" href=\"https://github.com/zilunzhang/StreetCLIP-Repoduce\"\
          >The repo</a> </p>\n<p><a rel=\"nofollow\" href=\"https://github.com/zilunzhang/StreetCLIP-Repoduce/blob/main/eval_img2gps.py\"\
          >https://github.com/zilunzhang/StreetCLIP-Repoduce/blob/main/eval_img2gps.py</a></p>\n\
          <h3 id=\"result-on-im2gps3k\">Result on IM2GPS3K</h3>\n<ul>\n<li>n=2997</li>\n\
          </ul>\n<div class=\"max-w-full overflow-auto\">\n\t<table>\n\t\t<thead><tr>\n\
          <th align=\"center\">Model</th>\n<th align=\"center\">Source</th>\n<th align=\"\
          center\">1KM</th>\n<th align=\"center\">25KM</th>\n<th align=\"center\"\
          >200KM</th>\n<th align=\"center\">750KM</th>\n<th align=\"center\">2,500KM</th>\n\
          </tr>\n\n\t\t</thead><tbody><tr>\n<td align=\"center\">CLIP@ViT-L-14-336</td>\n\
          <td align=\"center\"><a rel=\"nofollow\" href=\"https://arxiv.org/pdf/2302.00275.pdf\"\
          >Paper</a></td>\n<td align=\"center\">-</td>\n<td align=\"center\">19.5</td>\n\
          <td align=\"center\">34.0</td>\n<td align=\"center\">60.0</td>\n<td align=\"\
          center\">78.1</td>\n</tr>\n<tr>\n<td align=\"center\">CLIP@ViT-L-14-336</td>\n\
          <td align=\"center\"><a rel=\"nofollow\" href=\"https://github.com/openai/CLIP\"\
          >OpenAI's CLIP-reproduce</a></td>\n<td align=\"center\">4.07</td>\n<td align=\"\
          center\">20.09</td>\n<td align=\"center\">31.90</td>\n<td align=\"center\"\
          >54.72</td>\n<td align=\"center\">72.07</td>\n</tr>\n<tr>\n<td align=\"\
          center\">StreetCLIP@ViT-L-14-336</td>\n<td align=\"center\"><a rel=\"nofollow\"\
          \ href=\"https://arxiv.org/pdf/2302.00275.pdf\">Paper</a></td>\n<td align=\"\
          center\">-</td>\n<td align=\"center\">22.4</td>\n<td align=\"center\">37.4</td>\n\
          <td align=\"center\">61.3</td>\n<td align=\"center\">80.4</td>\n</tr>\n\
          <tr>\n<td align=\"center\">StreetCLIP@ViT-L-14-336</td>\n<td align=\"center\"\
          ><a href=\"https://huggingface.co/geolocal/StreetCLIP/tree/main\">StreetCLIP-reproduce</a></td>\n\
          <td align=\"center\">4.24</td>\n<td align=\"center\">21.79</td>\n<td align=\"\
          center\">34.73</td>\n<td align=\"center\">55.52</td>\n<td align=\"center\"\
          >74.84</td>\n</tr>\n<tr>\n<td align=\"center\">CLIP@ViT-B-32</td>\n<td align=\"\
          center\"><a rel=\"nofollow\" href=\"https://github.com/openai/CLIP\">OpenAI's\
          \ CLIP</a></td>\n<td align=\"center\">1.67</td>\n<td align=\"center\">8.88</td>\n\
          <td align=\"center\">14.65</td>\n<td align=\"center\">32.87</td>\n<td align=\"\
          center\">53.72</td>\n</tr>\n<tr>\n<td align=\"center\">CLIP@ViT-B-16</td>\n\
          <td align=\"center\"><a rel=\"nofollow\" href=\"https://github.com/openai/CLIP\"\
          >OpenAI's CLIP</a></td>\n<td align=\"center\">2.47</td>\n<td align=\"center\"\
          >12.41</td>\n<td align=\"center\">20.39</td>\n<td align=\"center\">39.71</td>\n\
          <td align=\"center\">61.86</td>\n</tr>\n<tr>\n<td align=\"center\">CLIP@ViT-L-14</td>\n\
          <td align=\"center\"><a rel=\"nofollow\" href=\"https://github.com/openai/CLIP\"\
          >OpenAI's CLIP</a></td>\n<td align=\"center\">3.34</td>\n<td align=\"center\"\
          >17.68</td>\n<td align=\"center\">28.86</td>\n<td align=\"center\">51.55</td>\n\
          <td align=\"center\">68.90</td>\n</tr>\n<tr>\n<td align=\"center\">CLIP@ViT-H-14</td>\n\
          <td align=\"center\"><a rel=\"nofollow\" href=\"https://github.com/mlfoundations/open_clip\"\
          >OpenCLIP</a></td>\n<td align=\"center\">3.94</td>\n<td align=\"center\"\
          >18.69</td>\n<td align=\"center\">30.60</td>\n<td align=\"center\">51.95</td>\n\
          <td align=\"center\">71.10</td>\n</tr>\n</tbody>\n\t</table>\n</div>\n<h3\
          \ id=\"result-on-im2gps\">Result on IM2GPS</h3>\n<ul>\n<li>n=237</li>\n\
          </ul>\n<div class=\"max-w-full overflow-auto\">\n\t<table>\n\t\t<thead><tr>\n\
          <th align=\"center\">Model</th>\n<th align=\"center\">Source</th>\n<th align=\"\
          center\">1KM</th>\n<th align=\"center\">25KM</th>\n<th align=\"center\"\
          >200KM</th>\n<th align=\"center\">750KM</th>\n<th align=\"center\">2,500KM</th>\n\
          </tr>\n\n\t\t</thead><tbody><tr>\n<td align=\"center\">CLIP@ViT-L-14-336</td>\n\
          <td align=\"center\"><a rel=\"nofollow\" href=\"https://arxiv.org/pdf/2302.00275.pdf\"\
          >Paper</a></td>\n<td align=\"center\">-</td>\n<td align=\"center\">27.0</td>\n\
          <td align=\"center\">42.2</td>\n<td align=\"center\">71.7</td>\n<td align=\"\
          center\">86.9</td>\n</tr>\n<tr>\n<td align=\"center\">CLIP@ViT-L-14-336</td>\n\
          <td align=\"center\"><a rel=\"nofollow\" href=\"https://github.com/openai/CLIP\"\
          >OpenAI's CLIP-reproduce</a></td>\n<td align=\"center\">4.64</td>\n<td align=\"\
          center\">26.58</td>\n<td align=\"center\">40.08</td>\n<td align=\"center\"\
          >63.71</td>\n<td align=\"center\">80.17</td>\n</tr>\n<tr>\n<td align=\"\
          center\">StreetCLIP@ViT-L-14-336</td>\n<td align=\"center\"><a rel=\"nofollow\"\
          \ href=\"https://arxiv.org/pdf/2302.00275.pdf\">Paper</a></td>\n<td align=\"\
          center\">-</td>\n<td align=\"center\">28.3</td>\n<td align=\"center\">45.1</td>\n\
          <td align=\"center\">74.7</td>\n<td align=\"center\">88.2</td>\n</tr>\n\
          <tr>\n<td align=\"center\">StreetCLIP@ViT-L-14-336</td>\n<td align=\"center\"\
          ><a href=\"https://huggingface.co/geolocal/StreetCLIP/tree/main\">StreetCLIP-reproduce</a></td>\n\
          <td align=\"center\">5.49</td>\n<td align=\"center\">28.27</td>\n<td align=\"\
          center\">42.62</td>\n<td align=\"center\">67.51</td>\n<td align=\"center\"\
          >80.17</td>\n</tr>\n<tr>\n<td align=\"center\">CLIP@ViT-B-32</td>\n<td align=\"\
          center\"><a rel=\"nofollow\" href=\"https://github.com/openai/CLIP\">OpenAI's\
          \ CLIP</a></td>\n<td align=\"center\">2.11</td>\n<td align=\"center\">16.46</td>\n\
          <td align=\"center\">26.58</td>\n<td align=\"center\">46.41</td>\n<td align=\"\
          center\">66.24</td>\n</tr>\n<tr>\n<td align=\"center\">CLIP@ViT-B-16</td>\n\
          <td align=\"center\"><a rel=\"nofollow\" href=\"https://github.com/openai/CLIP\"\
          >OpenAI's CLIP</a></td>\n<td align=\"center\">2.53</td>\n<td align=\"center\"\
          >19.83</td>\n<td align=\"center\">31.65</td>\n<td align=\"center\">52.74</td>\n\
          <td align=\"center\">71.31</td>\n</tr>\n<tr>\n<td align=\"center\">CLIP@ViT-L-14</td>\n\
          <td align=\"center\"><a rel=\"nofollow\" href=\"https://github.com/openai/CLIP\"\
          >OpenAI's CLIP</a></td>\n<td align=\"center\">4.22</td>\n<td align=\"center\"\
          >24.05</td>\n<td align=\"center\">35.44</td>\n<td align=\"center\">58.65</td>\n\
          <td align=\"center\">77.63</td>\n</tr>\n<tr>\n<td align=\"center\">CLIP@ViT-H-14</td>\n\
          <td align=\"center\"><a rel=\"nofollow\" href=\"https://github.com/mlfoundations/open_clip\"\
          >OpenCLIP</a></td>\n<td align=\"center\">5.49</td>\n<td align=\"center\"\
          >29.54</td>\n<td align=\"center\">44.30</td>\n<td align=\"center\">65.82</td>\n\
          <td align=\"center\">79.75</td>\n</tr>\n</tbody>\n\t</table>\n</div>\n"
        raw: "Would you mind having a look at what I missed?\n\nThanks.\n\n[The repo](https://github.com/zilunzhang/StreetCLIP-Repoduce)\
          \ \n\nhttps://github.com/zilunzhang/StreetCLIP-Repoduce/blob/main/eval_img2gps.py\n\
          \n### Result on IM2GPS3K\n* n=2997\n\n|Model|Source|1KM|25KM|200KM|750KM|2,500KM|\n\
          |:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|CLIP@ViT-L-14-336|[Paper](https://arxiv.org/pdf/2302.00275.pdf)|-|19.5\
          \ | 34.0|60.0 |78.1|\n|CLIP@ViT-L-14-336|[OpenAI's CLIP-reproduce](https://github.com/openai/CLIP)|4.07|20.09|31.90|54.72|72.07|\n\
          |StreetCLIP@ViT-L-14-336|[Paper](https://arxiv.org/pdf/2302.00275.pdf)|-|22.4\
          \ |37.4|61.3 |80.4|\n|StreetCLIP@ViT-L-14-336|[StreetCLIP-reproduce](https://huggingface.co/geolocal/StreetCLIP/tree/main)|4.24|21.79|34.73|55.52|74.84|\n\
          |CLIP@ViT-B-32|[OpenAI's CLIP](https://github.com/openai/CLIP)|1.67|8.88|14.65|32.87|53.72|\n\
          |CLIP@ViT-B-16|[OpenAI's CLIP](https://github.com/openai/CLIP)|2.47|12.41|20.39|39.71|61.86|\n\
          |CLIP@ViT-L-14|[OpenAI's CLIP](https://github.com/openai/CLIP)|3.34|17.68|28.86|51.55|68.90|\n\
          |CLIP@ViT-H-14|[OpenCLIP](https://github.com/mlfoundations/open_clip)|3.94|18.69|30.60|51.95|71.10|\n\
          \n### Result on IM2GPS\n* n=237\n\n|Model|Source|1KM|25KM|200KM|750KM|2,500KM|\n\
          |:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|CLIP@ViT-L-14-336|[Paper](https://arxiv.org/pdf/2302.00275.pdf)|-|27.0\
          \ | 42.2|71.7| 86.9|\n|CLIP@ViT-L-14-336|[OpenAI's CLIP-reproduce](https://github.com/openai/CLIP)|4.64|26.58|40.08|63.71|80.17|\n\
          |StreetCLIP@ViT-L-14-336|[Paper](https://arxiv.org/pdf/2302.00275.pdf)|-|28.3\
          \ | 45.1|74.7 |88.2|\n|StreetCLIP@ViT-L-14-336|[StreetCLIP-reproduce](https://huggingface.co/geolocal/StreetCLIP/tree/main)|5.49|28.27|42.62|67.51|80.17|\n\
          |CLIP@ViT-B-32|[OpenAI's CLIP](https://github.com/openai/CLIP)|2.11|16.46|26.58|46.41|66.24|\n\
          |CLIP@ViT-B-16|[OpenAI's CLIP](https://github.com/openai/CLIP)|2.53|19.83|31.65|52.74|71.31|\n\
          |CLIP@ViT-L-14|[OpenAI's CLIP](https://github.com/openai/CLIP)|4.22|24.05|35.44|58.65|77.63|\n\
          |CLIP@ViT-H-14|[OpenCLIP](https://github.com/mlfoundations/open_clip)|5.49|29.54|44.30|65.82|79.75|"
        updatedAt: '2023-12-07T10:59:23.384Z'
      numEdits: 1
      reactions: []
    id: 6571a5567beefed054c83b79
    type: comment
  author: Zilun
  content: "Would you mind having a look at what I missed?\n\nThanks.\n\n[The repo](https://github.com/zilunzhang/StreetCLIP-Repoduce)\
    \ \n\nhttps://github.com/zilunzhang/StreetCLIP-Repoduce/blob/main/eval_img2gps.py\n\
    \n### Result on IM2GPS3K\n* n=2997\n\n|Model|Source|1KM|25KM|200KM|750KM|2,500KM|\n\
    |:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|CLIP@ViT-L-14-336|[Paper](https://arxiv.org/pdf/2302.00275.pdf)|-|19.5\
    \ | 34.0|60.0 |78.1|\n|CLIP@ViT-L-14-336|[OpenAI's CLIP-reproduce](https://github.com/openai/CLIP)|4.07|20.09|31.90|54.72|72.07|\n\
    |StreetCLIP@ViT-L-14-336|[Paper](https://arxiv.org/pdf/2302.00275.pdf)|-|22.4\
    \ |37.4|61.3 |80.4|\n|StreetCLIP@ViT-L-14-336|[StreetCLIP-reproduce](https://huggingface.co/geolocal/StreetCLIP/tree/main)|4.24|21.79|34.73|55.52|74.84|\n\
    |CLIP@ViT-B-32|[OpenAI's CLIP](https://github.com/openai/CLIP)|1.67|8.88|14.65|32.87|53.72|\n\
    |CLIP@ViT-B-16|[OpenAI's CLIP](https://github.com/openai/CLIP)|2.47|12.41|20.39|39.71|61.86|\n\
    |CLIP@ViT-L-14|[OpenAI's CLIP](https://github.com/openai/CLIP)|3.34|17.68|28.86|51.55|68.90|\n\
    |CLIP@ViT-H-14|[OpenCLIP](https://github.com/mlfoundations/open_clip)|3.94|18.69|30.60|51.95|71.10|\n\
    \n### Result on IM2GPS\n* n=237\n\n|Model|Source|1KM|25KM|200KM|750KM|2,500KM|\n\
    |:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|CLIP@ViT-L-14-336|[Paper](https://arxiv.org/pdf/2302.00275.pdf)|-|27.0\
    \ | 42.2|71.7| 86.9|\n|CLIP@ViT-L-14-336|[OpenAI's CLIP-reproduce](https://github.com/openai/CLIP)|4.64|26.58|40.08|63.71|80.17|\n\
    |StreetCLIP@ViT-L-14-336|[Paper](https://arxiv.org/pdf/2302.00275.pdf)|-|28.3\
    \ | 45.1|74.7 |88.2|\n|StreetCLIP@ViT-L-14-336|[StreetCLIP-reproduce](https://huggingface.co/geolocal/StreetCLIP/tree/main)|5.49|28.27|42.62|67.51|80.17|\n\
    |CLIP@ViT-B-32|[OpenAI's CLIP](https://github.com/openai/CLIP)|2.11|16.46|26.58|46.41|66.24|\n\
    |CLIP@ViT-B-16|[OpenAI's CLIP](https://github.com/openai/CLIP)|2.53|19.83|31.65|52.74|71.31|\n\
    |CLIP@ViT-L-14|[OpenAI's CLIP](https://github.com/openai/CLIP)|4.22|24.05|35.44|58.65|77.63|\n\
    |CLIP@ViT-H-14|[OpenCLIP](https://github.com/mlfoundations/open_clip)|5.49|29.54|44.30|65.82|79.75|"
  created_at: 2023-12-07 10:58:30+00:00
  edited: true
  hidden: false
  id: 6571a5567beefed054c83b79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/c41ca27eda9b0938a4bb9348d1b11b5d.svg
      fullname: Zilun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Zilun
      type: user
    createdAt: '2023-12-07T10:59:10.000Z'
    data:
      from: Great work, and thanks for sharing! I wrote a pipeline to reproduce the
        results from the paper, but the results are different. Would you mind having
        a look on what I missed?
      to: Great work, and thanks for sharing! I wrote a pipeline to reproduce the
        results from the paper, but the results are different.
    id: 6571a57eb622b6c62c15332e
    type: title-change
  author: Zilun
  created_at: 2023-12-07 10:59:10+00:00
  id: 6571a57eb622b6c62c15332e
  new_title: Great work, and thanks for sharing! I wrote a pipeline to reproduce the
    results from the paper, but the results are different.
  old_title: Great work, and thanks for sharing! I wrote a pipeline to reproduce the
    results from the paper, but the results are different. Would you mind having a
    look on what I missed?
  type: title-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: geolocal/StreetCLIP
repo_type: model
status: open
target_branch: null
title: Great work, and thanks for sharing! I wrote a pipeline to reproduce the results
  from the paper, but the results are different.
