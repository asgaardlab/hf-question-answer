!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tianming
conflicting_files: null
created_at: 2022-11-23 07:59:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d54001bfef0fad9f21b7121555ee7a95.svg
      fullname: Du
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tianming
      type: user
    createdAt: '2022-11-23T07:59:07.000Z'
    data:
      edited: false
      editors:
      - Tianming
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d54001bfef0fad9f21b7121555ee7a95.svg
          fullname: Du
          isHf: false
          isPro: false
          name: Tianming
          type: user
        html: '<p>Thanks for your great work.<br>I would like to know which tokenizer
          is fit for this model?</p>

          '
        raw: "Thanks for your great work.\r\nI would like to know which tokenizer\
          \ is fit for this model?"
        updatedAt: '2022-11-23T07:59:07.159Z'
      numEdits: 0
      reactions: []
    id: 637dd2cb68cf7870a267d95a
    type: comment
  author: Tianming
  content: "Thanks for your great work.\r\nI would like to know which tokenizer is\
    \ fit for this model?"
  created_at: 2022-11-23 07:59:07+00:00
  edited: false
  hidden: false
  id: 637dd2cb68cf7870a267d95a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/192bc1c99607cb9a16ab135d375767ec.svg
      fullname: tmp
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ValkyriaLenneth
      type: user
    createdAt: '2022-11-23T08:04:06.000Z'
    data:
      edited: false
      editors:
      - ValkyriaLenneth
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/192bc1c99607cb9a16ab135d375767ec.svg
          fullname: tmp
          isHf: false
          isPro: false
          name: ValkyriaLenneth
          type: user
        html: '<p>Thanks for your reply.<br>The tokenizer we used is Jieba for the
          preprocessing of the data. For the vocabulary, Roberta_zh''s vocabulary
          is used for this model.</p>

          '
        raw: "Thanks for your reply. \nThe tokenizer we used is Jieba for the preprocessing\
          \ of the data. For the vocabulary, Roberta_zh's vocabulary is used for this\
          \ model."
        updatedAt: '2022-11-23T08:04:06.837Z'
      numEdits: 0
      reactions: []
    id: 637dd3f65da6969c8692438b
    type: comment
  author: ValkyriaLenneth
  content: "Thanks for your reply. \nThe tokenizer we used is Jieba for the preprocessing\
    \ of the data. For the vocabulary, Roberta_zh's vocabulary is used for this model."
  created_at: 2022-11-23 08:04:06+00:00
  edited: false
  hidden: false
  id: 637dd3f65da6969c8692438b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d54001bfef0fad9f21b7121555ee7a95.svg
      fullname: Du
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tianming
      type: user
    createdAt: '2022-11-26T12:46:52.000Z'
    data:
      edited: false
      editors:
      - Tianming
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d54001bfef0fad9f21b7121555ee7a95.svg
          fullname: Du
          isHf: false
          isPro: false
          name: Tianming
          type: user
        html: '<p>Using ''Bert-base-chinese'' related tokenizer is available? <a href="https://huggingface.co/bert-base-chinese/tree/main">https://huggingface.co/bert-base-chinese/tree/main</a></p>

          '
        raw: Using 'Bert-base-chinese' related tokenizer is available? https://huggingface.co/bert-base-chinese/tree/main
        updatedAt: '2022-11-26T12:46:52.097Z'
      numEdits: 0
      reactions: []
    id: 63820abc250545c1415854bb
    type: comment
  author: Tianming
  content: Using 'Bert-base-chinese' related tokenizer is available? https://huggingface.co/bert-base-chinese/tree/main
  created_at: 2022-11-26 12:46:52+00:00
  edited: false
  hidden: false
  id: 63820abc250545c1415854bb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: ValkyriaLenneth/longformer_zh
repo_type: model
status: open
target_branch: null
title: What tokenizer should I use?
