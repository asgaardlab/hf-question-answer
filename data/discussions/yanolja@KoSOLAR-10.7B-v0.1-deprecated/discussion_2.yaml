!!python/object:huggingface_hub.community.DiscussionWithDetails
author: andreaKIM
conflicting_files: null
created_at: 2024-01-01 14:44:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d1f763ca61fb1f281f7ac24bdee8722f.svg
      fullname: DAEHEEKIM
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andreaKIM
      type: user
    createdAt: '2024-01-01T14:44:05.000Z'
    data:
      edited: false
      editors:
      - andreaKIM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9253247380256653
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d1f763ca61fb1f281f7ac24bdee8722f.svg
          fullname: DAEHEEKIM
          isHf: false
          isPro: false
          name: andreaKIM
          type: user
        html: '<p>Hello, Thanks for providing such a usable model.<br>I am wondering
          what is KMMLU in the model card? i guess that should be a korean MMLU as
          an evaluation metric, but then why this model works little bit lower than
          original model? And how could you sure both "korean and english" performance
          is good enouogh? Can you disclose more evaluation results related to korean
          language generation? Or simple inference code for korean response generation.</p>

          '
        raw: "Hello, Thanks for providing such a usable model.\r\nI am wondering what\
          \ is KMMLU in the model card? i guess that should be a korean MMLU as an\
          \ evaluation metric, but then why this model works little bit lower than\
          \ original model? And how could you sure both \"korean and english\" performance\
          \ is good enouogh? Can you disclose more evaluation results related to korean\
          \ language generation? Or simple inference code for korean response generation."
        updatedAt: '2024-01-01T14:44:05.222Z'
      numEdits: 0
      reactions: []
    id: 6592cfb5075245eadd0cc660
    type: comment
  author: andreaKIM
  content: "Hello, Thanks for providing such a usable model.\r\nI am wondering what\
    \ is KMMLU in the model card? i guess that should be a korean MMLU as an evaluation\
    \ metric, but then why this model works little bit lower than original model?\
    \ And how could you sure both \"korean and english\" performance is good enouogh?\
    \ Can you disclose more evaluation results related to korean language generation?\
    \ Or simple inference code for korean response generation."
  created_at: 2024-01-01 14:44:05+00:00
  edited: false
  hidden: false
  id: 6592cfb5075245eadd0cc660
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cbe953e092b46ae52b020ac859ba074c.svg
      fullname: Seungduk Kim
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: seungduk
      type: user
    createdAt: '2024-01-01T14:56:47.000Z'
    data:
      edited: false
      editors:
      - seungduk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8612313866615295
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cbe953e092b46ae52b020ac859ba074c.svg
          fullname: Seungduk Kim
          isHf: false
          isPro: false
          name: seungduk
          type: user
        html: "<p>Hi Andrea,</p>\n<p>K-MMLU was recently incorporated into the lm_evaluation_harness.\
          \ For more details, visit: <a rel=\"nofollow\" href=\"https://github.com/EleutherAI/lm-evaluation-harness/blob/1b14602e2a7bd767cd2a4bcc8222b291305736d7/lm_eval/tasks/kmmlu/README.md\"\
          >K-MMLU on lm_evaluation_harness</a>. The minor differences between this\
          \ model and the base model are negligible, as they fall within the margin\
          \ of error (\xB1).</p>\n<p>For insights into the English performance of\
          \ this model, you can refer to the leaderboard here: <a href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\"\
          >Open LLM Leaderboard</a>. Filter the results by \"SOLAR\" to see that this\
          \ model's performance is almost identical to that of the base model.</p>\n\
          <p>For inference purposes, I recommend using vLLM. You can start quickly\
          \ by following this guide: <a rel=\"nofollow\" href=\"https://docs.vllm.ai/en/latest/getting_started/quickstart.html\"\
          >vLLM Quickstart</a>. Change the model name to whichever you wish to test.\
          \ Please note that this model is nearly identical to the base model and\
          \ may not follow instructions as accurately as other instruction-tuned models,\
          \ such as <a href=\"https://huggingface.co/seungduk/Bookworm-10.7B-v0.3\"\
          >Bookworm-10.7B-v0.3</a>.</p>\n<p>Thanks,<br>Seungduk</p>\n"
        raw: "Hi Andrea,\n\nK-MMLU was recently incorporated into the lm_evaluation_harness.\
          \ For more details, visit: [K-MMLU on lm_evaluation_harness](https://github.com/EleutherAI/lm-evaluation-harness/blob/1b14602e2a7bd767cd2a4bcc8222b291305736d7/lm_eval/tasks/kmmlu/README.md).\
          \ The minor differences between this model and the base model are negligible,\
          \ as they fall within the margin of error (\xB1).\n\nFor insights into the\
          \ English performance of this model, you can refer to the leaderboard here:\
          \ [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard).\
          \ Filter the results by \"SOLAR\" to see that this model's performance is\
          \ almost identical to that of the base model.\n\nFor inference purposes,\
          \ I recommend using vLLM. You can start quickly by following this guide:\
          \ [vLLM Quickstart](https://docs.vllm.ai/en/latest/getting_started/quickstart.html).\
          \ Change the model name to whichever you wish to test. Please note that\
          \ this model is nearly identical to the base model and may not follow instructions\
          \ as accurately as other instruction-tuned models, such as [Bookworm-10.7B-v0.3](https://huggingface.co/seungduk/Bookworm-10.7B-v0.3).\n\
          \nThanks,\nSeungduk"
        updatedAt: '2024-01-01T14:56:47.733Z'
      numEdits: 0
      reactions: []
    id: 6592d2afdbdeb5bf076e0105
    type: comment
  author: seungduk
  content: "Hi Andrea,\n\nK-MMLU was recently incorporated into the lm_evaluation_harness.\
    \ For more details, visit: [K-MMLU on lm_evaluation_harness](https://github.com/EleutherAI/lm-evaluation-harness/blob/1b14602e2a7bd767cd2a4bcc8222b291305736d7/lm_eval/tasks/kmmlu/README.md).\
    \ The minor differences between this model and the base model are negligible,\
    \ as they fall within the margin of error (\xB1).\n\nFor insights into the English\
    \ performance of this model, you can refer to the leaderboard here: [Open LLM\
    \ Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard).\
    \ Filter the results by \"SOLAR\" to see that this model's performance is almost\
    \ identical to that of the base model.\n\nFor inference purposes, I recommend\
    \ using vLLM. You can start quickly by following this guide: [vLLM Quickstart](https://docs.vllm.ai/en/latest/getting_started/quickstart.html).\
    \ Change the model name to whichever you wish to test. Please note that this model\
    \ is nearly identical to the base model and may not follow instructions as accurately\
    \ as other instruction-tuned models, such as [Bookworm-10.7B-v0.3](https://huggingface.co/seungduk/Bookworm-10.7B-v0.3).\n\
    \nThanks,\nSeungduk"
  created_at: 2024-01-01 14:56:47+00:00
  edited: false
  hidden: false
  id: 6592d2afdbdeb5bf076e0105
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: yanolja/KoSOLAR-10.7B-v0.1-deprecated
repo_type: model
status: open
target_branch: null
title: What is KMMLU in the model card?
