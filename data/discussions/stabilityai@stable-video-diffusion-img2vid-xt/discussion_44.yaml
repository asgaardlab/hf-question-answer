!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Oleg007
conflicting_files: null
created_at: 2024-01-09 10:22:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/66cebb7fd00d26587b9164ce8a08568e.svg
      fullname: "\u041E\u043B\u0435\u0433 \u0418\u0433\u043E\u0440\u0435\u0432\u0438\
        \u0447 \u0420\u0443\u0431\u0430\u043D"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Oleg007
      type: user
    createdAt: '2024-01-09T10:22:07.000Z'
    data:
      edited: false
      editors:
      - Oleg007
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7928794622421265
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/66cebb7fd00d26587b9164ce8a08568e.svg
          fullname: "\u041E\u043B\u0435\u0433 \u0418\u0433\u043E\u0440\u0435\u0432\
            \u0438\u0447 \u0420\u0443\u0431\u0430\u043D"
          isHf: false
          isPro: false
          name: Oleg007
          type: user
        html: "<p>I tried to use this pipeline, but the output videos are up to 2\
          \ seconds long. I changed frame, fps, steps, but I can\u2019t increase the\
          \ length. The code contains the callback_on_step_end:<br>(<code>Callable</code>,\
          \ <em>optional</em>) parameter:  A function that calls at the end of each\
          \ denoising steps during the inference. The function is called<br> with\
          \ the following arguments: <code>callback_on_step_end(self: DiffusionPipeline,\
          \ step: int, timestep: int, callback_kwargs: Dict)</code>. <code>callback_kwargs</code>\
          \ will include a list of all tensors as specified by <code>callback_on_step_end_tensor_inputs</code>.\
          \ </p>\n<p>But it is not clear how to use it. Tell me how to generate a\
          \ video in 4 seconds?</p>\n"
        raw: "I tried to use this pipeline, but the output videos are up to 2 seconds\
          \ long. I changed frame, fps, steps, but I can\u2019t increase the length.\
          \ The code contains the callback_on_step_end:\r\n(`Callable`, *optional*)\
          \ parameter:  A function that calls at the end of each denoising steps during\
          \ the inference. The function is called\r\n with the following arguments:\
          \ `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,\
          \ callback_kwargs: Dict)`. `callback_kwargs` will include a list of all\
          \ tensors as specified by `callback_on_step_end_tensor_inputs`. \r\n\r\n\
          But it is not clear how to use it. Tell me how to generate a video in 4\
          \ seconds?"
        updatedAt: '2024-01-09T10:22:07.725Z'
      numEdits: 0
      reactions: []
    id: 659d1e4f33ad0304f6c797ae
    type: comment
  author: Oleg007
  content: "I tried to use this pipeline, but the output videos are up to 2 seconds\
    \ long. I changed frame, fps, steps, but I can\u2019t increase the length. The\
    \ code contains the callback_on_step_end:\r\n(`Callable`, *optional*) parameter:\
    \  A function that calls at the end of each denoising steps during the inference.\
    \ The function is called\r\n with the following arguments: `callback_on_step_end(self:\
    \ DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs`\
    \ will include a list of all tensors as specified by `callback_on_step_end_tensor_inputs`.\
    \ \r\n\r\nBut it is not clear how to use it. Tell me how to generate a video in\
    \ 4 seconds?"
  created_at: 2024-01-09 10:22:07+00:00
  edited: false
  hidden: false
  id: 659d1e4f33ad0304f6c797ae
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 44
repo_id: stabilityai/stable-video-diffusion-img2vid-xt
repo_type: model
status: open
target_branch: null
title: How to generate a video in 4 seconds?
