!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BenjaminChu
conflicting_files: null
created_at: 2024-01-15 14:28:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dc3cc3200041bb6aacc501529c60884e.svg
      fullname: Illumino
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BenjaminChu
      type: user
    createdAt: '2024-01-15T14:28:15.000Z'
    data:
      edited: true
      editors:
      - BenjaminChu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2695959806442261
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dc3cc3200041bb6aacc501529c60884e.svg
          fullname: Illumino
          isHf: false
          isPro: false
          name: BenjaminChu
          type: user
        html: "<p>Here is my modified code specifying the local path of whisper files:</p>\n\
          <pre><code>\nimport torch\nfrom transformers import AutoModelForSpeechSeq2Seq,\
          \ AutoProcessor, pipeline\n\n\ndevice = \"cuda:0\" if torch.cuda.is_available()\
          \ else \"cpu\"\ntorch_dtype = torch.float16 if torch.cuda.is_available()\
          \ else torch.float32\n\nmodel_id = \"E:\\LLM\\whisper-large-v3\\models\"\
          \n\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\n    model_id, torch_dtype=torch_dtype,\
          \ low_cpu_mem_usage=True, use_safetensors=True\n)\nmodel.to(device)\n\n\
          processor = AutoProcessor.from_pretrained(model_id)\n\npipe = pipeline(\n\
          \    \"automatic-speech-recognition\",\n    model=model,\n    tokenizer=processor.tokenizer,\n\
          \    feature_extractor=processor.feature_extractor,\n    max_new_tokens=128,\n\
          \    chunk_length_s=30,\n    batch_size=16,\n    return_timestamps=True,\n\
          \    torch_dtype=torch_dtype,\n    device=device,\n)\n\n\nresult = pipe(\"\
          audio.mp3\",return_timestamps=True)\nprint(result[\"text\"])\n</code></pre>\n\
          <p>And it shows:</p>\n<pre><code>raceback (most recent call last):\n  File\
          \ \"e:\\LLM\\whisper-large-v3\\main.py\", line 15, in &lt;module&gt;\n \
          \   processor = AutoProcessor.from_pretrained(model_id)\n              \
          \  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\LLM\\chatglm2-6b\\\
          .venv\\Lib\\site-packages\\transformers\\models\\auto\\processing_auto.py\"\
          , line 268, in from_pretrained\n    return processor_class.from_pretrained(\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\LLM\\chatglm2-6b\\\
          .venv\\Lib\\site-packages\\transformers\\processing_utils.py\", line 184,\
          \ in from_pretrained\n    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"E:\\LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\transformers\\\
          processing_utils.py\", line 228, in _get_arguments_from_pretrained\n   \
          \ args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"E:\\LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\transformers\\\
          tokenization_utils_base.py\", line 1825, in from_pretrained\n    return\
          \ cls._from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\\
          LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\"\
          , line 1988, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\LLM\\chatglm2-6b\\\
          .venv\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py\"\
          , line 293, in __init__\n    with open(merges_file, encoding=\"utf-8\")\
          \ as merges_handle:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError:\
          \ expected str, bytes or os.PathLike object, not NoneType\n</code></pre>\n\
          <p>How to fix that?</p>\n"
        raw: "Here is my modified code specifying the local path of whisper files:\n\
          \n```\n\nimport torch\nfrom transformers import AutoModelForSpeechSeq2Seq,\
          \ AutoProcessor, pipeline\n\n\ndevice = \"cuda:0\" if torch.cuda.is_available()\
          \ else \"cpu\"\ntorch_dtype = torch.float16 if torch.cuda.is_available()\
          \ else torch.float32\n\nmodel_id = \"E:\\LLM\\whisper-large-v3\\models\"\
          \n\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\n    model_id, torch_dtype=torch_dtype,\
          \ low_cpu_mem_usage=True, use_safetensors=True\n)\nmodel.to(device)\n\n\
          processor = AutoProcessor.from_pretrained(model_id)\n\npipe = pipeline(\n\
          \    \"automatic-speech-recognition\",\n    model=model,\n    tokenizer=processor.tokenizer,\n\
          \    feature_extractor=processor.feature_extractor,\n    max_new_tokens=128,\n\
          \    chunk_length_s=30,\n    batch_size=16,\n    return_timestamps=True,\n\
          \    torch_dtype=torch_dtype,\n    device=device,\n)\n\n\nresult = pipe(\"\
          audio.mp3\",return_timestamps=True)\nprint(result[\"text\"])\n```\n\n\n\
          And it shows:\n\n```\nraceback (most recent call last):\n  File \"e:\\LLM\\\
          whisper-large-v3\\main.py\", line 15, in <module>\n    processor = AutoProcessor.from_pretrained(model_id)\n\
          \                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\\
          LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\\
          processing_auto.py\", line 268, in from_pretrained\n    return processor_class.from_pretrained(\n\
          \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\LLM\\chatglm2-6b\\\
          .venv\\Lib\\site-packages\\transformers\\processing_utils.py\", line 184,\
          \ in from_pretrained\n    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"E:\\LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\transformers\\\
          processing_utils.py\", line 228, in _get_arguments_from_pretrained\n   \
          \ args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"E:\\LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\transformers\\\
          tokenization_utils_base.py\", line 1825, in from_pretrained\n    return\
          \ cls._from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\\
          LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\"\
          , line 1988, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\LLM\\chatglm2-6b\\\
          .venv\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py\"\
          , line 293, in __init__\n    with open(merges_file, encoding=\"utf-8\")\
          \ as merges_handle:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError:\
          \ expected str, bytes or os.PathLike object, not NoneType\n\n```\nHow to\
          \ fix that?"
        updatedAt: '2024-01-15T14:30:26.166Z'
      numEdits: 1
      reactions: []
    id: 65a540ff8ac06028201a4095
    type: comment
  author: BenjaminChu
  content: "Here is my modified code specifying the local path of whisper files:\n\
    \n```\n\nimport torch\nfrom transformers import AutoModelForSpeechSeq2Seq, AutoProcessor,\
    \ pipeline\n\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\
    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n\n\
    model_id = \"E:\\LLM\\whisper-large-v3\\models\"\n\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\n\
    \    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n\
    )\nmodel.to(device)\n\nprocessor = AutoProcessor.from_pretrained(model_id)\n\n\
    pipe = pipeline(\n    \"automatic-speech-recognition\",\n    model=model,\n  \
    \  tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n\
    \    max_new_tokens=128,\n    chunk_length_s=30,\n    batch_size=16,\n    return_timestamps=True,\n\
    \    torch_dtype=torch_dtype,\n    device=device,\n)\n\n\nresult = pipe(\"audio.mp3\"\
    ,return_timestamps=True)\nprint(result[\"text\"])\n```\n\n\nAnd it shows:\n\n\
    ```\nraceback (most recent call last):\n  File \"e:\\LLM\\whisper-large-v3\\main.py\"\
    , line 15, in <module>\n    processor = AutoProcessor.from_pretrained(model_id)\n\
    \                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\LLM\\chatglm2-6b\\\
    .venv\\Lib\\site-packages\\transformers\\models\\auto\\processing_auto.py\", line\
    \ 268, in from_pretrained\n    return processor_class.from_pretrained(\n     \
    \      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\LLM\\chatglm2-6b\\.venv\\\
    Lib\\site-packages\\transformers\\processing_utils.py\", line 184, in from_pretrained\n\
    \    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
    \ **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
    \  File \"E:\\LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\transformers\\processing_utils.py\"\
    , line 228, in _get_arguments_from_pretrained\n    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
    \ **kwargs))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
    \  File \"E:\\LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\"\
    , line 1825, in from_pretrained\n    return cls._from_pretrained(\n          \
    \ ^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\\
    transformers\\tokenization_utils_base.py\", line 1988, in _from_pretrained\n \
    \   tokenizer = cls(*init_inputs, **init_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
    \  File \"E:\\LLM\\chatglm2-6b\\.venv\\Lib\\site-packages\\transformers\\models\\\
    whisper\\tokenization_whisper.py\", line 293, in __init__\n    with open(merges_file,\
    \ encoding=\"utf-8\") as merges_handle:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
    TypeError: expected str, bytes or os.PathLike object, not NoneType\n\n```\nHow\
    \ to fix that?"
  created_at: 2024-01-15 14:28:15+00:00
  edited: true
  hidden: false
  id: 65a540ff8ac06028201a4095
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/65ac62933452462d3ba89034bc554541.svg
      fullname: Emanon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Apotrox
      type: user
    createdAt: '2024-01-16T16:01:45.000Z'
    data:
      edited: false
      editors:
      - Apotrox
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9821383357048035
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/65ac62933452462d3ba89034bc554541.svg
          fullname: Emanon
          isHf: false
          isPro: false
          name: Apotrox
          type: user
        html: '<p>same here. already tried everything in the book to have the path
          be recognized as an os.PathLike but it appears nothing is working .-.</p>

          '
        raw: same here. already tried everything in the book to have the path be recognized
          as an os.PathLike but it appears nothing is working .-.
        updatedAt: '2024-01-16T16:01:45.638Z'
      numEdits: 0
      reactions: []
    id: 65a6a8694908b2676c248ed2
    type: comment
  author: Apotrox
  content: same here. already tried everything in the book to have the path be recognized
    as an os.PathLike but it appears nothing is working .-.
  created_at: 2024-01-16 16:01:45+00:00
  edited: false
  hidden: false
  id: 65a6a8694908b2676c248ed2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/65ac62933452462d3ba89034bc554541.svg
      fullname: Emanon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Apotrox
      type: user
    createdAt: '2024-01-16T16:35:35.000Z'
    data:
      edited: true
      editors:
      - Apotrox
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9524289965629578
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/65ac62933452462d3ba89034bc554541.svg
          fullname: Emanon
          isHf: false
          isPro: false
          name: Apotrox
          type: user
        html: '<p>a little update from my part. i tried around a lot more and found
          smth that works. before the result=--- add either a model.save_pretrained(path)
          or pipe.save_pretrained(path) (as im not sure which of those two actually
          did smth, i just did both). Saves everything needed from the online repo
          to be used locally. just put the model id after as the path and delete the
          added lines.</p>

          '
        raw: a little update from my part. i tried around a lot more and found smth
          that works. before the result=--- add either a model.save_pretrained(path)
          or pipe.save_pretrained(path) (as im not sure which of those two actually
          did smth, i just did both). Saves everything needed from the online repo
          to be used locally. just put the model id after as the path and delete the
          added lines.
        updatedAt: '2024-01-16T16:36:49.883Z'
      numEdits: 1
      reactions: []
    id: 65a6b057e504d9738d174174
    type: comment
  author: Apotrox
  content: a little update from my part. i tried around a lot more and found smth
    that works. before the result=--- add either a model.save_pretrained(path) or
    pipe.save_pretrained(path) (as im not sure which of those two actually did smth,
    i just did both). Saves everything needed from the online repo to be used locally.
    just put the model id after as the path and delete the added lines.
  created_at: 2024-01-16 16:35:35+00:00
  edited: true
  hidden: false
  id: 65a6b057e504d9738d174174
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 65
repo_id: openai/whisper-large-v3
repo_type: model
status: open
target_branch: null
title: 'How to fix "TypeError: expected str, bytes or os.PathLike object, not NoneType"
  when specifying the local whisper model'
