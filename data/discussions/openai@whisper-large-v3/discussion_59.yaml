!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dkincaid
conflicting_files: null
created_at: 2023-12-21 03:50:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1634322030054-noauth.jpeg?w=200&h=200&f=face
      fullname: David Kincaid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: dkincaid
      type: user
    createdAt: '2023-12-21T03:50:24.000Z'
    data:
      edited: false
      editors:
      - dkincaid
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.768458366394043
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1634322030054-noauth.jpeg?w=200&h=200&f=face
          fullname: David Kincaid
          isHf: false
          isPro: true
          name: dkincaid
          type: user
        html: "<p>I've got the model deployed to HF Inference Endpoints, but I can't\
          \ figure out how to pass parameters (like language, return_timestamp, etc)\
          \ to the model. Since the audio bytes seem to need to be passed as bytes,\
          \ I don't get how we can pass parameters. Especially since the language\
          \ parameter has to be passed as a nested dict like {\"generate_kwargs\"\
          : {\"language\": \"en\"}}.</p>\n<pre><code class=\"language-python\">headers\
          \ = {<span class=\"hljs-string\">\"Authorization\"</span>: <span class=\"\
          hljs-string\">f\"Bearer <span class=\"hljs-subst\">{hf_api_token}</span>\"\
          </span>,\n           <span class=\"hljs-string\">\"Content-Type\"</span>:\
          \ <span class=\"hljs-string\">\"audio/x-mpeg-3\"</span>}\n\n<span class=\"\
          hljs-keyword\">def</span> <span class=\"hljs-title function_\">query</span>(<span\
          \ class=\"hljs-params\">filename</span>):\n    <span class=\"hljs-keyword\"\
          >with</span> <span class=\"hljs-built_in\">open</span>(filename, <span class=\"\
          hljs-string\">\"rb\"</span>) <span class=\"hljs-keyword\">as</span> f:\n\
          \        data = f.read()\n\n    response = requests.post(API_URL, headers=headers,\
          \ data=data)\n    <span class=\"hljs-keyword\">return</span> response.json()\n\
          \n<span class=\"hljs-comment\"># Usage example</span>\nwhisper_transcription\
          \ = query(audio_file_path)\nwhisper_transcription\n</code></pre>\n"
        raw: "I've got the model deployed to HF Inference Endpoints, but I can't figure\
          \ out how to pass parameters (like language, return_timestamp, etc) to the\
          \ model. Since the audio bytes seem to need to be passed as bytes, I don't\
          \ get how we can pass parameters. Especially since the language parameter\
          \ has to be passed as a nested dict like {\"generate_kwargs\": {\"language\"\
          : \"en\"}}.\r\n\r\n```python\r\nheaders = {\"Authorization\": f\"Bearer\
          \ {hf_api_token}\",\r\n           \"Content-Type\": \"audio/x-mpeg-3\"}\r\
          \n\r\ndef query(filename):\r\n    with open(filename, \"rb\") as f:\r\n\
          \        data = f.read()\r\n\r\n    response = requests.post(API_URL, headers=headers,\
          \ data=data)\r\n    return response.json()\r\n\r\n# Usage example\r\nwhisper_transcription\
          \ = query(audio_file_path)\r\nwhisper_transcription\r\n```"
        updatedAt: '2023-12-21T03:50:24.603Z'
      numEdits: 0
      reactions: []
    id: 6583b600aa85c512dac5d2f3
    type: comment
  author: dkincaid
  content: "I've got the model deployed to HF Inference Endpoints, but I can't figure\
    \ out how to pass parameters (like language, return_timestamp, etc) to the model.\
    \ Since the audio bytes seem to need to be passed as bytes, I don't get how we\
    \ can pass parameters. Especially since the language parameter has to be passed\
    \ as a nested dict like {\"generate_kwargs\": {\"language\": \"en\"}}.\r\n\r\n\
    ```python\r\nheaders = {\"Authorization\": f\"Bearer {hf_api_token}\",\r\n   \
    \        \"Content-Type\": \"audio/x-mpeg-3\"}\r\n\r\ndef query(filename):\r\n\
    \    with open(filename, \"rb\") as f:\r\n        data = f.read()\r\n\r\n    response\
    \ = requests.post(API_URL, headers=headers, data=data)\r\n    return response.json()\r\
    \n\r\n# Usage example\r\nwhisper_transcription = query(audio_file_path)\r\nwhisper_transcription\r\
    \n```"
  created_at: 2023-12-21 03:50:24+00:00
  edited: false
  hidden: false
  id: 6583b600aa85c512dac5d2f3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fd03e235d88c2aecc3e7c5b72f435b63.svg
      fullname: Joshua
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joshwe
      type: user
    createdAt: '2024-01-05T15:20:50.000Z'
    data:
      edited: false
      editors:
      - joshwe
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7819581627845764
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fd03e235d88c2aecc3e7c5b72f435b63.svg
          fullname: Joshua
          isHf: false
          isPro: false
          name: joshwe
          type: user
        html: "<p>HI <span data-props=\"{&quot;user&quot;:&quot;dkincaid&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/dkincaid\"\
          >@<span class=\"underline\">dkincaid</span></a></span>\n\n\t</span></span>\
          \ ,<br>I have been struggling with the same problem. But the solution is\
          \ so simple.<br>Usually, the payload will be of a JSON type, where you can\
          \ enter arguments. Depending on the task of the model (audio trancription/predicting\
          \ next word/ etc.) the user can pass different keywords.<br>Which keywords\
          \ can be passed are provided for each task here: <a href=\"https://huggingface.co/docs/api-inference/detailed_parameters\"\
          >https://huggingface.co/docs/api-inference/detailed_parameters</a></p>\n\
          <p>In our case, we have the task <em>automatic_speech_recognition task</em>.\
          \ The allowed parameters in this setting are ... well, none.<br>This screenshot\
          \ shows it:<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/65845c23a4f176a57fbc3577/3_6LAqMoj6333-oQxfczv.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/65845c23a4f176a57fbc3577/3_6LAqMoj6333-oQxfczv.png\"\
          ></a><br>Currently, no other parameters can be passed.</p>\n"
        raw: 'HI @dkincaid ,

          I have been struggling with the same problem. But the solution is so simple.

          Usually, the payload will be of a JSON type, where you can enter arguments.
          Depending on the task of the model (audio trancription/predicting next word/
          etc.) the user can pass different keywords.

          Which keywords can be passed are provided for each task here: https://huggingface.co/docs/api-inference/detailed_parameters


          In our case, we have the task *automatic_speech_recognition task*. The allowed
          parameters in this setting are ... well, none.

          This screenshot shows it:

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/65845c23a4f176a57fbc3577/3_6LAqMoj6333-oQxfczv.png)

          Currently, no other parameters can be passed.'
        updatedAt: '2024-01-05T15:20:50.816Z'
      numEdits: 0
      reactions: []
    id: 65981e52c7a30c638b4735ca
    type: comment
  author: joshwe
  content: 'HI @dkincaid ,

    I have been struggling with the same problem. But the solution is so simple.

    Usually, the payload will be of a JSON type, where you can enter arguments. Depending
    on the task of the model (audio trancription/predicting next word/ etc.) the user
    can pass different keywords.

    Which keywords can be passed are provided for each task here: https://huggingface.co/docs/api-inference/detailed_parameters


    In our case, we have the task *automatic_speech_recognition task*. The allowed
    parameters in this setting are ... well, none.

    This screenshot shows it:

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/65845c23a4f176a57fbc3577/3_6LAqMoj6333-oQxfczv.png)

    Currently, no other parameters can be passed.'
  created_at: 2024-01-05 15:20:50+00:00
  edited: false
  hidden: false
  id: 65981e52c7a30c638b4735ca
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 59
repo_id: openai/whisper-large-v3
repo_type: model
status: open
target_branch: null
title: Passing parameters to the model deployed on HF Inference Endpoints
