!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BenjaminChu
conflicting_files: null
created_at: 2023-12-17 01:09:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dc3cc3200041bb6aacc501529c60884e.svg
      fullname: Illumino
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BenjaminChu
      type: user
    createdAt: '2023-12-17T01:09:41.000Z'
    data:
      edited: false
      editors:
      - BenjaminChu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9854389429092407
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dc3cc3200041bb6aacc501529c60884e.svg
          fullname: Illumino
          isHf: false
          isPro: false
          name: BenjaminChu
          type: user
        html: '<p>I have been using ggml since the Large-v2 release. Now, I want to
          try the original Large-v3 and try to fine-tune the model on my own. However,
          Github and HF are blocked in my country (It is not hard to guess which totalitarian
          country is ). I have to mannually download the file via VPN, but there are
          many large files in the <code>Files and Versions</code>. So, I wonder which
          files are necessary. </p>

          <p>Very sorry to ask that, as I know few about coding.</p>

          '
        raw: "I have been using ggml since the Large-v2 release. Now, I want to try\
          \ the original Large-v3 and try to fine-tune the model on my own. However,\
          \ Github and HF are blocked in my country (It is not hard to guess which\
          \ totalitarian country is ). I have to mannually download the file via VPN,\
          \ but there are many large files in the `Files and Versions`. So, I wonder\
          \ which files are necessary. \r\n\r\nVery sorry to ask that, as I know few\
          \ about coding."
        updatedAt: '2023-12-17T01:09:41.463Z'
      numEdits: 0
      reactions: []
    id: 657e4a55138b7e391481ff9a
    type: comment
  author: BenjaminChu
  content: "I have been using ggml since the Large-v2 release. Now, I want to try\
    \ the original Large-v3 and try to fine-tune the model on my own. However, Github\
    \ and HF are blocked in my country (It is not hard to guess which totalitarian\
    \ country is ). I have to mannually download the file via VPN, but there are many\
    \ large files in the `Files and Versions`. So, I wonder which files are necessary.\
    \ \r\n\r\nVery sorry to ask that, as I know few about coding."
  created_at: 2023-12-17 01:09:41+00:00
  edited: false
  hidden: false
  id: 657e4a55138b7e391481ff9a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-18T19:15:05.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7105281949043274
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: "<p>You can use a proxy, but I am not sure otherwise, pinging <span\
          \ data-props=\"{&quot;user&quot;:&quot;Wauplin&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/Wauplin\">@<span class=\"underline\"\
          >Wauplin</span></a></span>\n\n\t</span></span> for better ideas</p>\n"
        raw: You can use a proxy, but I am not sure otherwise, pinging @Wauplin for
          better ideas
        updatedAt: '2023-12-18T19:15:05.342Z'
      numEdits: 0
      reactions: []
    id: 65809a39abafd960c831961b
    type: comment
  author: ArthurZ
  content: You can use a proxy, but I am not sure otherwise, pinging @Wauplin for
    better ideas
  created_at: 2023-12-18 19:15:05+00:00
  edited: false
  hidden: false
  id: 65809a39abafd960c831961b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659336880158-6273f303f6d63a28483fde12.png?w=200&h=200&f=face
      fullname: Lucain Pouget
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Wauplin
      type: user
    createdAt: '2023-12-19T08:59:15.000Z'
    data:
      edited: false
      editors:
      - Wauplin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8487277030944824
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659336880158-6273f303f6d63a28483fde12.png?w=200&h=200&f=face
          fullname: Lucain Pouget
          isHf: true
          isPro: false
          name: Wauplin
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;ArthurZ&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ArthurZ\"\
          >@<span class=\"underline\">ArthurZ</span></a></span>\n\n\t</span></span>\
          \ for the ping. It is indeed possible to use a proxy when using a Python\
          \ library by calling <a href=\"https://huggingface.co/docs/huggingface_hub/package_reference/utilities#huggingface_hub.configure_http_backend\"\
          ><code>configure_http_backend</code></a> at the beginning of the script.</p>\n\
          <p><span data-props=\"{&quot;user&quot;:&quot;BenjaminChu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/BenjaminChu\">@<span\
          \ class=\"underline\">BenjaminChu</span></a></span>\n\n\t</span></span>\
          \ To come back to the original question \"which files should I download?\"\
          , which library do you plan to use to fine-tune the model? Weights are in\
          \ different formats depending on how you plan to consume them. I am really\
          \ not an expert here but <span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ should definitely be able to guide you! </p>\n"
        raw: 'Thanks @ArthurZ for the ping. It is indeed possible to use a proxy when
          using a Python library by calling [`configure_http_backend`](https://huggingface.co/docs/huggingface_hub/package_reference/utilities#huggingface_hub.configure_http_backend)
          at the beginning of the script.


          @BenjaminChu To come back to the original question "which files should I
          download?", which library do you plan to use to fine-tune the model? Weights
          are in different formats depending on how you plan to consume them. I am
          really not an expert here but @sanchit-gandhi should definitely be able
          to guide you! '
        updatedAt: '2023-12-19T08:59:15.673Z'
      numEdits: 0
      reactions: []
    id: 65815b63f6b81759013db08b
    type: comment
  author: Wauplin
  content: 'Thanks @ArthurZ for the ping. It is indeed possible to use a proxy when
    using a Python library by calling [`configure_http_backend`](https://huggingface.co/docs/huggingface_hub/package_reference/utilities#huggingface_hub.configure_http_backend)
    at the beginning of the script.


    @BenjaminChu To come back to the original question "which files should I download?",
    which library do you plan to use to fine-tune the model? Weights are in different
    formats depending on how you plan to consume them. I am really not an expert here
    but @sanchit-gandhi should definitely be able to guide you! '
  created_at: 2023-12-19 08:59:15+00:00
  edited: false
  hidden: false
  id: 65815b63f6b81759013db08b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 57
repo_id: openai/whisper-large-v3
repo_type: model
status: open
target_branch: null
title: Which File Shall I Download from The Files and Versions
