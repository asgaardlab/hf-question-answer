!!python/object:huggingface_hub.community.DiscussionWithDetails
author: marklee
conflicting_files: null
created_at: 2022-06-28 01:50:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0129ee6fb0228cccb58939a57bea9066.svg
      fullname: mark lee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: marklee
      type: user
    createdAt: '2022-06-28T02:50:10.000Z'
    data:
      edited: false
      editors:
      - marklee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0129ee6fb0228cccb58939a57bea9066.svg
          fullname: mark lee
          isHf: false
          isPro: false
          name: marklee
          type: user
        html: '<p>Original issue here: <a rel="nofollow" href="https://github.com/huggingface/transformers/issues/17885">https://github.com/huggingface/transformers/issues/17885</a></p>

          <p>Hello! I had originally posted this on the <a rel="nofollow" href="https://discuss.huggingface.co/t/replicating-roberta-base-glue-results/19328">forums</a>
          but it seems like there''s not much foot traffic there, so hoping to get
          more visibility here.</p>

          <p>I''m trying to replicate RoBERTa-base GLUE results as reported in the
          model card. The numbers in the model card look like they were copied from
          the paper. Has anyone made an attempt to actually match these numbers with
          <a rel="nofollow" href="https://github.com/huggingface/transformers/blob/6589e510fa4e6c442059de2fab84752535de9b23/examples/pytorch/text-classification/run_glue.py">run_glue.py</a>?
          If so, what configuration was used for the trainer?</p>

          <p>If I follow the original configs from <a rel="nofollow" href="https://github.com/facebookresearch/fairseq/tree/fcca32258c8e8bcc9f9890bf4714fa2f96b6b3e1/examples/roberta/config/finetuning">fairseq</a>,
          I am unable to match the reported numbers for RTE, CoLA, STS-B, and MRPC.</p>

          <p>Any pointers would be much appreciated, thanks!</p>

          '
        raw: "Original issue here: https://github.com/huggingface/transformers/issues/17885\r\
          \n\r\nHello! I had originally posted this on the [forums](https://discuss.huggingface.co/t/replicating-roberta-base-glue-results/19328)\
          \ but it seems like there's not much foot traffic there, so hoping to get\
          \ more visibility here.\r\n\r\nI'm trying to replicate RoBERTa-base GLUE\
          \ results as reported in the model card. The numbers in the model card look\
          \ like they were copied from the paper. Has anyone made an attempt to actually\
          \ match these numbers with [run_glue.py](https://github.com/huggingface/transformers/blob/6589e510fa4e6c442059de2fab84752535de9b23/examples/pytorch/text-classification/run_glue.py)?\
          \ If so, what configuration was used for the trainer?\r\n\r\nIf I follow\
          \ the original configs from [fairseq](https://github.com/facebookresearch/fairseq/tree/fcca32258c8e8bcc9f9890bf4714fa2f96b6b3e1/examples/roberta/config/finetuning),\
          \ I am unable to match the reported numbers for RTE, CoLA, STS-B, and MRPC.\r\
          \n\r\nAny pointers would be much appreciated, thanks!"
        updatedAt: '2022-06-28T02:50:10.328Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - amma33
        - mxbonn
    id: 62ba6c62b8fc86a0145b4327
    type: comment
  author: marklee
  content: "Original issue here: https://github.com/huggingface/transformers/issues/17885\r\
    \n\r\nHello! I had originally posted this on the [forums](https://discuss.huggingface.co/t/replicating-roberta-base-glue-results/19328)\
    \ but it seems like there's not much foot traffic there, so hoping to get more\
    \ visibility here.\r\n\r\nI'm trying to replicate RoBERTa-base GLUE results as\
    \ reported in the model card. The numbers in the model card look like they were\
    \ copied from the paper. Has anyone made an attempt to actually match these numbers\
    \ with [run_glue.py](https://github.com/huggingface/transformers/blob/6589e510fa4e6c442059de2fab84752535de9b23/examples/pytorch/text-classification/run_glue.py)?\
    \ If so, what configuration was used for the trainer?\r\n\r\nIf I follow the original\
    \ configs from [fairseq](https://github.com/facebookresearch/fairseq/tree/fcca32258c8e8bcc9f9890bf4714fa2f96b6b3e1/examples/roberta/config/finetuning),\
    \ I am unable to match the reported numbers for RTE, CoLA, STS-B, and MRPC.\r\n\
    \r\nAny pointers would be much appreciated, thanks!"
  created_at: 2022-06-28 01:50:10+00:00
  edited: false
  hidden: false
  id: 62ba6c62b8fc86a0145b4327
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/NQtzmrDdbG0H8qkZvRyGk.jpeg?w=200&h=200&f=face
      fullname: Julien Chaumond
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: true
      name: julien-c
      type: user
    createdAt: '2022-06-28T06:35:02.000Z'
    data:
      edited: false
      editors:
      - julien-c
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/NQtzmrDdbG0H8qkZvRyGk.jpeg?w=200&h=200&f=face
          fullname: Julien Chaumond
          isHf: true
          isPro: true
          name: julien-c
          type: user
        html: "<p>maybe pinging <span data-props=\"{&quot;user&quot;:&quot;myleott&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/myleott\"\
          >@<span class=\"underline\">myleott</span></a></span>\n\n\t</span></span>?</p>\n"
        raw: maybe pinging @myleott?
        updatedAt: '2022-06-28T06:35:02.764Z'
      numEdits: 0
      reactions: []
    id: 62baa1162def6c569fc5a763
    type: comment
  author: julien-c
  content: maybe pinging @myleott?
  created_at: 2022-06-28 05:35:02+00:00
  edited: false
  hidden: false
  id: 62baa1162def6c569fc5a763
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6554a801220b7375ae378473f1068702.svg
      fullname: Lohse
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lohse
      type: user
    createdAt: '2023-05-24T12:11:33.000Z'
    data:
      edited: false
      editors:
      - Lohse
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6554a801220b7375ae378473f1068702.svg
          fullname: Lohse
          isHf: false
          isPro: false
          name: Lohse
          type: user
        html: "<p>single card\uFF1A</p>\n<p>CUDA_VISIBLE_DEVICES=0 </p>\n<p>hyperparam\uFF1A\
          </p>\n<p> --max_seq_length 128 <br>  --per_device_train_batch_size 64 <br>\
          \  --learning_rate 1e-4 <br>  --use_lora True <br>  --r 8 <br>  --num_train_epochs\
          \ 20 \\</p>\n"
        raw: "single card\uFF1A\n\nCUDA_VISIBLE_DEVICES=0 \n\nhyperparam\uFF1A\n\n\
          \ --max_seq_length 128 \\\n  --per_device_train_batch_size 64 \\\n  --learning_rate\
          \ 1e-4 \\\n  --use_lora True \\\n  --r 8 \\\n  --num_train_epochs 20 \\"
        updatedAt: '2023-05-24T12:11:33.388Z'
      numEdits: 0
      reactions: []
    id: 646dfef59105e2cc569f07ac
    type: comment
  author: Lohse
  content: "single card\uFF1A\n\nCUDA_VISIBLE_DEVICES=0 \n\nhyperparam\uFF1A\n\n --max_seq_length\
    \ 128 \\\n  --per_device_train_batch_size 64 \\\n  --learning_rate 1e-4 \\\n \
    \ --use_lora True \\\n  --r 8 \\\n  --num_train_epochs 20 \\"
  created_at: 2023-05-24 11:11:33+00:00
  edited: false
  hidden: false
  id: 646dfef59105e2cc569f07ac
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: roberta-base
repo_type: model
status: open
target_branch: null
title: Replicating RoBERTa-base GLUE results
