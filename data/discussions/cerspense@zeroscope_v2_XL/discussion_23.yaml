!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bacprop
conflicting_files: null
created_at: 2023-07-05 15:17:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2fa5dd19040903d186969e05a066de20.svg
      fullname: Romain Paulus
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bacprop
      type: user
    createdAt: '2023-07-05T16:17:13.000Z'
    data:
      edited: false
      editors:
      - bacprop
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8531486988067627
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2fa5dd19040903d186969e05a066de20.svg
          fullname: Romain Paulus
          isHf: false
          isPro: false
          name: bacprop
          type: user
        html: '<p>Is there a way to run the XL model such that the details of the
          input video are roughly preserved in the upscaled output? For example, this
          is what I get from zeroscope_v2_576w with the prompt <em>"a single tree
          on a desert island, with a sunset in the background, in the style of van
          gogh"</em></p>

          <p><video class="!max-w-full" controls="" src="https://cdn-uploads.huggingface.co/production/uploads/64a4111c37d5cc90cee0079d/Z4KD382xWmaH6y0dhgyD2.mp4"></video></p>


          <p>And this is the upscaled version with the same prompt, following the
          README pipeline example:</p>

          <p><video class="!max-w-full" controls="" src="https://cdn-uploads.huggingface.co/production/uploads/64a4111c37d5cc90cee0079d/bNW5PCoxPi7suzzYiF5vx.mp4"></video></p>


          <p>I wish there was a way to preserve the animated flowing brushstrokes
          on the side, for example</p>

          '
        raw: "Is there a way to run the XL model such that the details of the input\
          \ video are roughly preserved in the upscaled output? For example, this\
          \ is what I get from zeroscope_v2_576w with the prompt *\"a single tree\
          \ on a desert island, with a sunset in the background, in the style of van\
          \ gogh\"*\r\n\r\nhttps://cdn-uploads.huggingface.co/production/uploads/64a4111c37d5cc90cee0079d/Z4KD382xWmaH6y0dhgyD2.mp4\r\
          \n\r\nAnd this is the upscaled version with the same prompt, following the\
          \ README pipeline example:\r\n\r\nhttps://cdn-uploads.huggingface.co/production/uploads/64a4111c37d5cc90cee0079d/bNW5PCoxPi7suzzYiF5vx.mp4\r\
          \n\r\nI wish there was a way to preserve the animated flowing brushstrokes\
          \ on the side, for example"
        updatedAt: '2023-07-05T16:17:13.029Z'
      numEdits: 0
      reactions: []
    id: 64a59789240cbef3d1694798
    type: comment
  author: bacprop
  content: "Is there a way to run the XL model such that the details of the input\
    \ video are roughly preserved in the upscaled output? For example, this is what\
    \ I get from zeroscope_v2_576w with the prompt *\"a single tree on a desert island,\
    \ with a sunset in the background, in the style of van gogh\"*\r\n\r\nhttps://cdn-uploads.huggingface.co/production/uploads/64a4111c37d5cc90cee0079d/Z4KD382xWmaH6y0dhgyD2.mp4\r\
    \n\r\nAnd this is the upscaled version with the same prompt, following the README\
    \ pipeline example:\r\n\r\nhttps://cdn-uploads.huggingface.co/production/uploads/64a4111c37d5cc90cee0079d/bNW5PCoxPi7suzzYiF5vx.mp4\r\
    \n\r\nI wish there was a way to preserve the animated flowing brushstrokes on\
    \ the side, for example"
  created_at: 2023-07-05 15:17:13+00:00
  edited: false
  hidden: false
  id: 64a59789240cbef3d1694798
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303c92e3926de1f7ec2683a/FRrIJttVR3GJYcBfVf1HU.jpeg?w=200&h=200&f=face
      fullname: Spencer Sterling
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: cerspense
      type: user
    createdAt: '2023-07-05T18:19:30.000Z'
    data:
      edited: false
      editors:
      - cerspense
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9421666264533997
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303c92e3926de1f7ec2683a/FRrIJttVR3GJYcBfVf1HU.jpeg?w=200&h=200&f=face
          fullname: Spencer Sterling
          isHf: false
          isPro: false
          name: cerspense
          type: user
        html: '<p>Its a bit random but you can try playing around with the denoising
          strength. The default value of 0.6 is pretty low already, but you can try
          going lower to preserve more detail. usually this will add flicker. Sometimes
          a higher strength of 0.85 to 0.92 will end up being better than the original
          input. Controlnet-like features could definitely help with this upscaling
          step in the future.</p>

          '
        raw: Its a bit random but you can try playing around with the denoising strength.
          The default value of 0.6 is pretty low already, but you can try going lower
          to preserve more detail. usually this will add flicker. Sometimes a higher
          strength of 0.85 to 0.92 will end up being better than the original input.
          Controlnet-like features could definitely help with this upscaling step
          in the future.
        updatedAt: '2023-07-05T18:19:30.131Z'
      numEdits: 0
      reactions: []
    id: 64a5b43284f954be0b71849f
    type: comment
  author: cerspense
  content: Its a bit random but you can try playing around with the denoising strength.
    The default value of 0.6 is pretty low already, but you can try going lower to
    preserve more detail. usually this will add flicker. Sometimes a higher strength
    of 0.85 to 0.92 will end up being better than the original input. Controlnet-like
    features could definitely help with this upscaling step in the future.
  created_at: 2023-07-05 17:19:30+00:00
  edited: false
  hidden: false
  id: 64a5b43284f954be0b71849f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2fa5dd19040903d186969e05a066de20.svg
      fullname: Romain Paulus
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bacprop
      type: user
    createdAt: '2023-07-07T09:42:58.000Z'
    data:
      edited: false
      editors:
      - bacprop
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9797795414924622
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2fa5dd19040903d186969e05a066de20.svg
          fullname: Romain Paulus
          isHf: false
          isPro: false
          name: bacprop
          type: user
        html: '<p>Got it, thank you! Looking briefly at the code, it wasn''t clear
          to me earlier how different changing the strength was from changing the
          number of timesteps, but I think I see the difference now.</p>

          '
        raw: Got it, thank you! Looking briefly at the code, it wasn't clear to me
          earlier how different changing the strength was from changing the number
          of timesteps, but I think I see the difference now.
        updatedAt: '2023-07-07T09:42:58.521Z'
      numEdits: 0
      reactions: []
    id: 64a7de2250a2357deb037b70
    type: comment
  author: bacprop
  content: Got it, thank you! Looking briefly at the code, it wasn't clear to me earlier
    how different changing the strength was from changing the number of timesteps,
    but I think I see the difference now.
  created_at: 2023-07-07 08:42:58+00:00
  edited: false
  hidden: false
  id: 64a7de2250a2357deb037b70
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 23
repo_id: cerspense/zeroscope_v2_XL
repo_type: model
status: open
target_branch: null
title: Preserve input details in upscaled video
