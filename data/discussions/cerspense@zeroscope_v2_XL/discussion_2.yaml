!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tarunabh
conflicting_files: null
created_at: 2023-06-24 15:53:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e912e4107d8ede8190fabf400338d651.svg
      fullname: Tarunabh Dutta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarunabh
      type: user
    createdAt: '2023-06-24T16:53:27.000Z'
    data:
      edited: false
      editors:
      - tarunabh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7449647784233093
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e912e4107d8ede8190fabf400338d651.svg
          fullname: Tarunabh Dutta
          isHf: false
          isPro: false
          name: tarunabh
          type: user
        html: '<p>Hi,<br>     After downloading the files available in the zs2_576w
          folder, and Replacing the respective files in the ''stable-diffusion-webui\models\ModelScope\t2v''
          directory (as per instruction), I found a similar set of files in the ''zeroscope_v2
          XL'' version.<br>My question is should I replace the files downloaded from
          zs2_576w folder, with the files having the same names that are available
          in the ''zs2_XL folder''?<br>Because the instructions in both specify replacing
          the original files in the same target directory i.e. - ''stable-diffusion-webui\models\ModelScope\t2v''
          directory.</p>

          '
        raw: "Hi, \r\n     After downloading the files available in the zs2_576w folder,\
          \ and Replacing the respective files in the 'stable-diffusion-webui\\models\\\
          ModelScope\\t2v' directory (as per instruction), I found a similar set of\
          \ files in the 'zeroscope_v2 XL' version.\r\nMy question is should I replace\
          \ the files downloaded from zs2_576w folder, with the files having the same\
          \ names that are available in the 'zs2_XL folder'?\r\nBecause the instructions\
          \ in both specify replacing the original files in the same target directory\
          \ i.e. - 'stable-diffusion-webui\\models\\ModelScope\\t2v' directory."
        updatedAt: '2023-06-24T16:53:27.931Z'
      numEdits: 0
      reactions: []
    id: 64971f873c64d75523a71e99
    type: comment
  author: tarunabh
  content: "Hi, \r\n     After downloading the files available in the zs2_576w folder,\
    \ and Replacing the respective files in the 'stable-diffusion-webui\\models\\\
    ModelScope\\t2v' directory (as per instruction), I found a similar set of files\
    \ in the 'zeroscope_v2 XL' version.\r\nMy question is should I replace the files\
    \ downloaded from zs2_576w folder, with the files having the same names that are\
    \ available in the 'zs2_XL folder'?\r\nBecause the instructions in both specify\
    \ replacing the original files in the same target directory i.e. - 'stable-diffusion-webui\\\
    models\\ModelScope\\t2v' directory."
  created_at: 2023-06-24 15:53:27+00:00
  edited: false
  hidden: false
  id: 64971f873c64d75523a71e99
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bbc0e374866e18f7a7cd0b21d6e9f15b.svg
      fullname: JASON BRENNAN
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: THEJAB
      type: user
    createdAt: '2023-06-25T07:28:32.000Z'
    data:
      edited: false
      editors:
      - THEJAB
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9537655711174011
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bbc0e374866e18f7a7cd0b21d6e9f15b.svg
          fullname: JASON BRENNAN
          isHf: false
          isPro: false
          name: THEJAB
          type: user
        html: '<p>I''m guessing you are supposed to run the smaller one until you
          get a good result and then swap in the high res version models and restart
          auto1111 and run it through again to get higher res.<br>It''s a bit tedious
          until they have a model selection tab.</p>

          '
        raw: 'I''m guessing you are supposed to run the smaller one until you get
          a good result and then swap in the high res version models and restart auto1111
          and run it through again to get higher res.

          It''s a bit tedious until they have a model selection tab.'
        updatedAt: '2023-06-25T07:28:32.032Z'
      numEdits: 0
      reactions: []
    id: 6497eca045306a8edbeb1ae0
    type: comment
  author: THEJAB
  content: 'I''m guessing you are supposed to run the smaller one until you get a
    good result and then swap in the high res version models and restart auto1111
    and run it through again to get higher res.

    It''s a bit tedious until they have a model selection tab.'
  created_at: 2023-06-25 06:28:32+00:00
  edited: false
  hidden: false
  id: 6497eca045306a8edbeb1ae0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303c92e3926de1f7ec2683a/FRrIJttVR3GJYcBfVf1HU.jpeg?w=200&h=200&f=face
      fullname: Spencer Sterling
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: cerspense
      type: user
    createdAt: '2023-06-25T09:00:15.000Z'
    data:
      edited: false
      editors:
      - cerspense
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9542616009712219
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303c92e3926de1f7ec2683a/FRrIJttVR3GJYcBfVf1HU.jpeg?w=200&h=200&f=face
          fullname: Spencer Sterling
          isHf: false
          isPro: false
          name: cerspense
          type: user
        html: '<p>Yeah, this is the suggested workflow at the moment. I''m hoping
          that more features like a model selection dropdown will be implemented soon</p>

          '
        raw: Yeah, this is the suggested workflow at the moment. I'm hoping that more
          features like a model selection dropdown will be implemented soon
        updatedAt: '2023-06-25T09:00:15.869Z'
      numEdits: 0
      reactions: []
    id: 6498021fad206c1827794c67
    type: comment
  author: cerspense
  content: Yeah, this is the suggested workflow at the moment. I'm hoping that more
    features like a model selection dropdown will be implemented soon
  created_at: 2023-06-25 08:00:15+00:00
  edited: false
  hidden: false
  id: 6498021fad206c1827794c67
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/400e1d827471b48b2ad6fa6d44c2a020.svg
      fullname: Kon Ru
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: b34stw4rs
      type: user
    createdAt: '2023-06-25T14:11:12.000Z'
    data:
      edited: false
      editors:
      - b34stw4rs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8967329859733582
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/400e1d827471b48b2ad6fa6d44c2a020.svg
          fullname: Kon Ru
          isHf: false
          isPro: false
          name: b34stw4rs
          type: user
        html: '<p>IDK if just me, but the recommended 30 frames at the max resolution
          supported doesn''t fit on my 4090 in win10, and can only do 9frames...</p>

          '
        raw: IDK if just me, but the recommended 30 frames at the max resolution supported
          doesn't fit on my 4090 in win10, and can only do 9frames...
        updatedAt: '2023-06-25T14:11:12.782Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - urheiaauh
        - ChrisTheWizard
    id: 64984b00da768eec82d92182
    type: comment
  author: b34stw4rs
  content: IDK if just me, but the recommended 30 frames at the max resolution supported
    doesn't fit on my 4090 in win10, and can only do 9frames...
  created_at: 2023-06-25 13:11:12+00:00
  edited: false
  hidden: false
  id: 64984b00da768eec82d92182
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6914330637b97a2b4385a5eb79bbb7c.svg
      fullname: Roope Rainisto
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rainisto
      type: user
    createdAt: '2023-06-25T15:21:28.000Z'
    data:
      edited: false
      editors:
      - rainisto
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9532851576805115
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6914330637b97a2b4385a5eb79bbb7c.svg
          fullname: Roope Rainisto
          isHf: false
          isPro: false
          name: rainisto
          type: user
        html: '<p>I also have issues running this - I have a A6000 with 48GB vram,
          and I cannot run even 16 frames with 1024x576 using the auto1111 approach
          described on this page. </p>

          '
        raw: 'I also have issues running this - I have a A6000 with 48GB vram, and
          I cannot run even 16 frames with 1024x576 using the auto1111 approach described
          on this page. '
        updatedAt: '2023-06-25T15:21:28.768Z'
      numEdits: 0
      reactions: []
    id: 64985b786a7013b36934150f
    type: comment
  author: rainisto
  content: 'I also have issues running this - I have a A6000 with 48GB vram, and I
    cannot run even 16 frames with 1024x576 using the auto1111 approach described
    on this page. '
  created_at: 2023-06-25 14:21:28+00:00
  edited: false
  hidden: false
  id: 64985b786a7013b36934150f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b6914330637b97a2b4385a5eb79bbb7c.svg
      fullname: Roope Rainisto
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rainisto
      type: user
    createdAt: '2023-06-25T15:27:48.000Z'
    data:
      edited: false
      editors:
      - rainisto
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9295510649681091
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b6914330637b97a2b4385a5eb79bbb7c.svg
          fullname: Roope Rainisto
          isHf: false
          isPro: false
          name: rainisto
          type: user
        html: '<p>EDIT: To my own comment above. I noticed a drastic improvement when
          running 1111 now with xformers on - I can actually run things now. </p>

          '
        raw: 'EDIT: To my own comment above. I noticed a drastic improvement when
          running 1111 now with xformers on - I can actually run things now. '
        updatedAt: '2023-06-25T15:27:48.050Z'
      numEdits: 0
      reactions: []
    id: 64985cf4d8b0e7ce8ad7f9c5
    type: comment
  author: rainisto
  content: 'EDIT: To my own comment above. I noticed a drastic improvement when running
    1111 now with xformers on - I can actually run things now. '
  created_at: 2023-06-25 14:27:48+00:00
  edited: false
  hidden: false
  id: 64985cf4d8b0e7ce8ad7f9c5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/400e1d827471b48b2ad6fa6d44c2a020.svg
      fullname: Kon Ru
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: b34stw4rs
      type: user
    createdAt: '2023-06-25T16:49:52.000Z'
    data:
      edited: false
      editors:
      - b34stw4rs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9814617037773132
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/400e1d827471b48b2ad6fa6d44c2a020.svg
          fullname: Kon Ru
          isHf: false
          isPro: false
          name: b34stw4rs
          type: user
        html: '<p>Yeah someone on the reddit also mentioned that you need xformers
          for it to actually work correctly.</p>

          '
        raw: Yeah someone on the reddit also mentioned that you need xformers for
          it to actually work correctly.
        updatedAt: '2023-06-25T16:49:52.677Z'
      numEdits: 0
      reactions: []
    id: 6498703049fa1e7cccbc7706
    type: comment
  author: b34stw4rs
  content: Yeah someone on the reddit also mentioned that you need xformers for it
    to actually work correctly.
  created_at: 2023-06-25 15:49:52+00:00
  edited: false
  hidden: false
  id: 6498703049fa1e7cccbc7706
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ddefe950aeec1b74687f1a456fa932bf.svg
      fullname: Blah
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Blahblah22
      type: user
    createdAt: '2023-06-26T00:41:35.000Z'
    data:
      edited: false
      editors:
      - Blahblah22
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9571693539619446
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ddefe950aeec1b74687f1a456fa932bf.svg
          fullname: Blah
          isHf: false
          isPro: false
          name: Blahblah22
          type: user
        html: '<blockquote>

          <p>I''m guessing you are supposed to run the smaller one until you get a
          good result and then swap in the high res version models and restart auto1111
          and run it through again to get higher res.<br>It''s a bit tedious until
          they have a model selection tab.</p>

          </blockquote>

          <p>I''ve been swapping them without restarting, do you need to restart?</p>

          '
        raw: '> I''m guessing you are supposed to run the smaller one until you get
          a good result and then swap in the high res version models and restart auto1111
          and run it through again to get higher res.

          > It''s a bit tedious until they have a model selection tab.


          I''ve been swapping them without restarting, do you need to restart?'
        updatedAt: '2023-06-26T00:41:35.145Z'
      numEdits: 0
      reactions: []
    id: 6498debfd4725c892fefb91e
    type: comment
  author: Blahblah22
  content: '> I''m guessing you are supposed to run the smaller one until you get
    a good result and then swap in the high res version models and restart auto1111
    and run it through again to get higher res.

    > It''s a bit tedious until they have a model selection tab.


    I''ve been swapping them without restarting, do you need to restart?'
  created_at: 2023-06-25 23:41:35+00:00
  edited: false
  hidden: false
  id: 6498debfd4725c892fefb91e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/400e1d827471b48b2ad6fa6d44c2a020.svg
      fullname: Kon Ru
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: b34stw4rs
      type: user
    createdAt: '2023-06-26T06:54:38.000Z'
    data:
      edited: false
      editors:
      - b34stw4rs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4401908218860626
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/400e1d827471b48b2ad6fa6d44c2a020.svg
          fullname: Kon Ru
          isHf: false
          isPro: false
          name: b34stw4rs
          type: user
        html: '<p>If anyone has any info on how to actually get xformers working on
          w10pro on a 40 series gpu please leave a comment, kind in a loop with this
          error :<br>Launching Web UI with arguments: --xformers --disable-nan-check
          --no-half-vae --reinstall-xformers<br>No module ''xformers''. Proceeding
          without it.<br>Cannot import xformers<br>Traceback (most recent call last):<br>  File
          "D:\NasD\stable-diffusion-webui\modules\sd_hijack_optimizations.py", line
          140, in <br>    import xformers.ops<br>  File "D:\NasD\stable-diffusion-webui\venv\lib\site-packages\xformers\ops_<em>init</em><em>.py",
          line 8, in <br>    from .fmha import (<br>  File "D:\NasD\stable-diffusion-webui\venv\lib\site-packages\xformers\ops\fmha_<em>init</em></em>.py",
          line 10, in <br>    from . import cutlass, flash, small_k, triton<br>  File
          "D:\NasD\stable-diffusion-webui\venv\lib\site-packages\xformers\ops\fmha\triton.py",
          line 15, in <br>    if TYPE_CHECKING or <em>is_triton_available():<br>  File
          "D:\NasD\stable-diffusion-webui\venv\lib\site-packages\xformers_<em>init</em></em>.py",
          line 33, in func_wrapper<br>    value = func()<br>  File "D:\NasD\stable-diffusion-webui\venv\lib\site-packages\xformers_<em>init</em><em>.py",
          line 44, in <em>is_triton_available<br>    from xformers.triton.softmax
          import softmax as triton_softmax  # noqa<br>  File "D:\NasD\stable-diffusion-webui\venv\lib\site-packages\xformers\triton_<em>init</em></em>.py",
          line 12, in <br>    from .dropout import FusedDropoutBias, dropout  # noqa<br>  File
          "D:\NasD\stable-diffusion-webui\venv\lib\site-packages\xformers\triton\dropout.py",
          line 13, in <br>    import triton<br>  File "D:\NasD\stable-diffusion-webui\venv\lib\site-packages\triton_<em>init</em></em>.py",
          line 1, in <br>    raise RuntimeError("Should never be installed")<br>RuntimeError:
          Should never be installed</p>

          <p>this is with torch 2.0.1cu118 + everything from xformers17 to the latest
          dev branch, really confused because I thought this was all sorted...</p>

          '
        raw: "If anyone has any info on how to actually get xformers working on w10pro\
          \ on a 40 series gpu please leave a comment, kind in a loop with this error\
          \ : \nLaunching Web UI with arguments: --xformers --disable-nan-check --no-half-vae\
          \ --reinstall-xformers\nNo module 'xformers'. Proceeding without it.\nCannot\
          \ import xformers\nTraceback (most recent call last):\n  File \"D:\\NasD\\\
          stable-diffusion-webui\\modules\\sd_hijack_optimizations.py\", line 140,\
          \ in <module>\n    import xformers.ops\n  File \"D:\\NasD\\stable-diffusion-webui\\\
          venv\\lib\\site-packages\\xformers\\ops\\__init__.py\", line 8, in <module>\n\
          \    from .fmha import (\n  File \"D:\\NasD\\stable-diffusion-webui\\venv\\\
          lib\\site-packages\\xformers\\ops\\fmha\\__init__.py\", line 10, in <module>\n\
          \    from . import cutlass, flash, small_k, triton\n  File \"D:\\NasD\\\
          stable-diffusion-webui\\venv\\lib\\site-packages\\xformers\\ops\\fmha\\\
          triton.py\", line 15, in <module>\n    if TYPE_CHECKING or _is_triton_available():\n\
          \  File \"D:\\NasD\\stable-diffusion-webui\\venv\\lib\\site-packages\\xformers\\\
          __init__.py\", line 33, in func_wrapper\n    value = func()\n  File \"D:\\\
          NasD\\stable-diffusion-webui\\venv\\lib\\site-packages\\xformers\\__init__.py\"\
          , line 44, in _is_triton_available\n    from xformers.triton.softmax import\
          \ softmax as triton_softmax  # noqa\n  File \"D:\\NasD\\stable-diffusion-webui\\\
          venv\\lib\\site-packages\\xformers\\triton\\__init__.py\", line 12, in <module>\n\
          \    from .dropout import FusedDropoutBias, dropout  # noqa\n  File \"D:\\\
          NasD\\stable-diffusion-webui\\venv\\lib\\site-packages\\xformers\\triton\\\
          dropout.py\", line 13, in <module>\n    import triton\n  File \"D:\\NasD\\\
          stable-diffusion-webui\\venv\\lib\\site-packages\\triton\\__init__.py\"\
          , line 1, in <module>\n    raise RuntimeError(\"Should never be installed\"\
          )\nRuntimeError: Should never be installed\n\nthis is with torch 2.0.1cu118\
          \ + everything from xformers17 to the latest dev branch, really confused\
          \ because I thought this was all sorted..."
        updatedAt: '2023-06-26T06:54:38.797Z'
      numEdits: 0
      reactions: []
    id: 6499362e89f0dcbecbc0bf4f
    type: comment
  author: b34stw4rs
  content: "If anyone has any info on how to actually get xformers working on w10pro\
    \ on a 40 series gpu please leave a comment, kind in a loop with this error :\
    \ \nLaunching Web UI with arguments: --xformers --disable-nan-check --no-half-vae\
    \ --reinstall-xformers\nNo module 'xformers'. Proceeding without it.\nCannot import\
    \ xformers\nTraceback (most recent call last):\n  File \"D:\\NasD\\stable-diffusion-webui\\\
    modules\\sd_hijack_optimizations.py\", line 140, in <module>\n    import xformers.ops\n\
    \  File \"D:\\NasD\\stable-diffusion-webui\\venv\\lib\\site-packages\\xformers\\\
    ops\\__init__.py\", line 8, in <module>\n    from .fmha import (\n  File \"D:\\\
    NasD\\stable-diffusion-webui\\venv\\lib\\site-packages\\xformers\\ops\\fmha\\\
    __init__.py\", line 10, in <module>\n    from . import cutlass, flash, small_k,\
    \ triton\n  File \"D:\\NasD\\stable-diffusion-webui\\venv\\lib\\site-packages\\\
    xformers\\ops\\fmha\\triton.py\", line 15, in <module>\n    if TYPE_CHECKING or\
    \ _is_triton_available():\n  File \"D:\\NasD\\stable-diffusion-webui\\venv\\lib\\\
    site-packages\\xformers\\__init__.py\", line 33, in func_wrapper\n    value =\
    \ func()\n  File \"D:\\NasD\\stable-diffusion-webui\\venv\\lib\\site-packages\\\
    xformers\\__init__.py\", line 44, in _is_triton_available\n    from xformers.triton.softmax\
    \ import softmax as triton_softmax  # noqa\n  File \"D:\\NasD\\stable-diffusion-webui\\\
    venv\\lib\\site-packages\\xformers\\triton\\__init__.py\", line 12, in <module>\n\
    \    from .dropout import FusedDropoutBias, dropout  # noqa\n  File \"D:\\NasD\\\
    stable-diffusion-webui\\venv\\lib\\site-packages\\xformers\\triton\\dropout.py\"\
    , line 13, in <module>\n    import triton\n  File \"D:\\NasD\\stable-diffusion-webui\\\
    venv\\lib\\site-packages\\triton\\__init__.py\", line 1, in <module>\n    raise\
    \ RuntimeError(\"Should never be installed\")\nRuntimeError: Should never be installed\n\
    \nthis is with torch 2.0.1cu118 + everything from xformers17 to the latest dev\
    \ branch, really confused because I thought this was all sorted..."
  created_at: 2023-06-26 05:54:38+00:00
  edited: false
  hidden: false
  id: 6499362e89f0dcbecbc0bf4f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303c92e3926de1f7ec2683a/FRrIJttVR3GJYcBfVf1HU.jpeg?w=200&h=200&f=face
      fullname: Spencer Sterling
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: cerspense
      type: user
    createdAt: '2023-06-26T07:00:40.000Z'
    data:
      edited: false
      editors:
      - cerspense
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9610089063644409
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303c92e3926de1f7ec2683a/FRrIJttVR3GJYcBfVf1HU.jpeg?w=200&h=200&f=face
          fullname: Spencer Sterling
          isHf: false
          isPro: false
          name: cerspense
          type: user
        html: '<p>I have not been successful with torch 2. I recommend doing a brand
          new, clean install of 1111 with torch 1 (should still be the default) and
          xformers.</p>

          '
        raw: I have not been successful with torch 2. I recommend doing a brand new,
          clean install of 1111 with torch 1 (should still be the default) and xformers.
        updatedAt: '2023-06-26T07:00:40.625Z'
      numEdits: 0
      reactions: []
    id: 64993798003ad4b5d62f35e2
    type: comment
  author: cerspense
  content: I have not been successful with torch 2. I recommend doing a brand new,
    clean install of 1111 with torch 1 (should still be the default) and xformers.
  created_at: 2023-06-26 06:00:40+00:00
  edited: false
  hidden: false
  id: 64993798003ad4b5d62f35e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/400e1d827471b48b2ad6fa6d44c2a020.svg
      fullname: Kon Ru
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: b34stw4rs
      type: user
    createdAt: '2023-06-26T22:35:48.000Z'
    data:
      edited: false
      editors:
      - b34stw4rs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9443649053573608
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/400e1d827471b48b2ad6fa6d44c2a020.svg
          fullname: Kon Ru
          isHf: false
          isPro: false
          name: b34stw4rs
          type: user
        html: '<p>Yup that''s what I did, made a separate venv specially to hold the
          XL model. </p>

          '
        raw: 'Yup that''s what I did, made a separate venv specially to hold the XL
          model. '
        updatedAt: '2023-06-26T22:35:48.485Z'
      numEdits: 0
      reactions: []
    id: 649a12c45a34f1bf5baf4748
    type: comment
  author: b34stw4rs
  content: 'Yup that''s what I did, made a separate venv specially to hold the XL
    model. '
  created_at: 2023-06-26 21:35:48+00:00
  edited: false
  hidden: false
  id: 649a12c45a34f1bf5baf4748
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c88443d8b5803e7cc031c2fad89431da.svg
      fullname: Evolution Evolving
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: EVO29
      type: user
    createdAt: '2023-09-30T02:53:02.000Z'
    data:
      edited: false
      editors:
      - EVO29
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9643296599388123
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c88443d8b5803e7cc031c2fad89431da.svg
          fullname: Evolution Evolving
          isHf: false
          isPro: false
          name: EVO29
          type: user
        html: '<p>I just wanted to stop by to state that this seems to STILL be an
          issue as of today, Friday the 29th of Sept.  I enjoy workin gwith Automatic
          and the text to video is great but it seems rather bizarre that there isn''t
          a more streamlined way to switch between models.  Constantly using the CLI
          to swap files into different folders gets quite confusing, not to mention
          that all the files share the same name.  I jsut see  in my drop down, using
          most recent Automatic pull, RTX A6000 Ada, Linux/Ubuntu 22.04.  There are
          also issues with tqdm version compatibility due to the strict criteria outlined
          in the requirements json.</p>

          '
        raw: 'I just wanted to stop by to state that this seems to STILL be an issue
          as of today, Friday the 29th of Sept.  I enjoy workin gwith Automatic and
          the text to video is great but it seems rather bizarre that there isn''t
          a more streamlined way to switch between models.  Constantly using the CLI
          to swap files into different folders gets quite confusing, not to mention
          that all the files share the same name.  I jsut see <modelscope> in my drop
          down, using most recent Automatic pull, RTX A6000 Ada, Linux/Ubuntu 22.04.  There
          are also issues with tqdm version compatibility due to the strict criteria
          outlined in the requirements json.

          '
        updatedAt: '2023-09-30T02:53:02.617Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - J450NP13
    id: 65178d8e20b18e99b4578a99
    type: comment
  author: EVO29
  content: 'I just wanted to stop by to state that this seems to STILL be an issue
    as of today, Friday the 29th of Sept.  I enjoy workin gwith Automatic and the
    text to video is great but it seems rather bizarre that there isn''t a more streamlined
    way to switch between models.  Constantly using the CLI to swap files into different
    folders gets quite confusing, not to mention that all the files share the same
    name.  I jsut see <modelscope> in my drop down, using most recent Automatic pull,
    RTX A6000 Ada, Linux/Ubuntu 22.04.  There are also issues with tqdm version compatibility
    due to the strict criteria outlined in the requirements json.

    '
  created_at: 2023-09-30 01:53:02+00:00
  edited: false
  hidden: false
  id: 65178d8e20b18e99b4578a99
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: cerspense/zeroscope_v2_XL
repo_type: model
status: open
target_branch: null
title: Replacing files in 'stable-diffusion-webui\models\ModelScope\t2v' directory.
