!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nickykay
conflicting_files: null
created_at: 2023-10-16 21:46:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/401328aa7c05c4501eec805692b48abf.svg
      fullname: Nicholas Kondal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nickykay
      type: user
    createdAt: '2023-10-16T22:46:23.000Z'
    data:
      edited: false
      editors:
      - nickykay
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7898320555686951
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/401328aa7c05c4501eec805692b48abf.svg
          fullname: Nicholas Kondal
          isHf: false
          isPro: false
          name: nickykay
          type: user
        html: '<p>I used the code in <a href="https://huggingface.co/TheBloke/Asclepius-13B-GPTQ#you-can-then-use-the-following-code">https://huggingface.co/TheBloke/Asclepius-13B-GPTQ#you-can-then-use-the-following-code</a>
          to try to load the gptq-8bit--1g-actorder_True model revision, but when
          trying to generate text, I get the error below in Auto-GPTQ.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64bb857db567ae97c308e3d0/zy349kmn3mrexuDIqfICs.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64bb857db567ae97c308e3d0/zy349kmn3mrexuDIqfICs.png"></a></p>

          <p>I''m currently using torch 2.1.0 on an AWS G5 instance with an A10 GPU.
          Online sources have suggested to downgrade to torch 1.6 but that results
          in the same issue. How can this be resolved?</p>

          '
        raw: "I used the code in https://huggingface.co/TheBloke/Asclepius-13B-GPTQ#you-can-then-use-the-following-code\
          \ to try to load the gptq-8bit--1g-actorder_True model revision, but when\
          \ trying to generate text, I get the error below in Auto-GPTQ.\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64bb857db567ae97c308e3d0/zy349kmn3mrexuDIqfICs.png)\r\
          \n\r\nI'm currently using torch 2.1.0 on an AWS G5 instance with an A10\
          \ GPU. Online sources have suggested to downgrade to torch 1.6 but that\
          \ results in the same issue. How can this be resolved?"
        updatedAt: '2023-10-16T22:46:23.951Z'
      numEdits: 0
      reactions: []
    id: 652dbd3fb70ac2162b8d07d7
    type: comment
  author: nickykay
  content: "I used the code in https://huggingface.co/TheBloke/Asclepius-13B-GPTQ#you-can-then-use-the-following-code\
    \ to try to load the gptq-8bit--1g-actorder_True model revision, but when trying\
    \ to generate text, I get the error below in Auto-GPTQ.\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64bb857db567ae97c308e3d0/zy349kmn3mrexuDIqfICs.png)\r\
    \n\r\nI'm currently using torch 2.1.0 on an AWS G5 instance with an A10 GPU. Online\
    \ sources have suggested to downgrade to torch 1.6 but that results in the same\
    \ issue. How can this be resolved?"
  created_at: 2023-10-16 21:46:23+00:00
  edited: false
  hidden: false
  id: 652dbd3fb70ac2162b8d07d7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/Asclepius-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: 'RuntimeError: Unrecognized tensor type ID: AutocastCUDA'
