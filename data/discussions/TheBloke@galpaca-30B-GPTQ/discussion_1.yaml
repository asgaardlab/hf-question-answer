!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ehartford
conflicting_files: null
created_at: 2023-04-11 03:23:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-04-11T04:23:41.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>would love to see a ggml version for llama.cpp, thank you!</p>

          '
        raw: would love to see a ggml version for llama.cpp, thank you!
        updatedAt: '2023-04-11T04:23:41.956Z'
      numEdits: 0
      reactions: []
    id: 6434e0cd4b34368fdb089c08
    type: comment
  author: ehartford
  content: would love to see a ggml version for llama.cpp, thank you!
  created_at: 2023-04-11 03:23:41+00:00
  edited: false
  hidden: false
  id: 6434e0cd4b34368fdb089c08
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-11T08:57:51.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>As discussed on Discord, I don''t think this is possible right now.
          I am not sure that llama.cpp supports Opt models. And the <code>convert.py</code>script
          used to make GGMLs definitely doesn''t, as it requires <code>tokenizer.model</code>
          which Galactica models do not have.</p>

          <p>I can ask the llama.cpp guys if this could be supported in future, but
          right now I don''t think I can do it.</p>

          '
        raw: 'As discussed on Discord, I don''t think this is possible right now.
          I am not sure that llama.cpp supports Opt models. And the `convert.py`script
          used to make GGMLs definitely doesn''t, as it requires `tokenizer.model`
          which Galactica models do not have.


          I can ask the llama.cpp guys if this could be supported in future, but right
          now I don''t think I can do it.'
        updatedAt: '2023-04-11T08:57:51.608Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6435210fe60b21004eca3146
    id: 6435210fe60b21004eca3145
    type: comment
  author: TheBloke
  content: 'As discussed on Discord, I don''t think this is possible right now. I
    am not sure that llama.cpp supports Opt models. And the `convert.py`script used
    to make GGMLs definitely doesn''t, as it requires `tokenizer.model` which Galactica
    models do not have.


    I can ask the llama.cpp guys if this could be supported in future, but right now
    I don''t think I can do it.'
  created_at: 2023-04-11 07:57:51+00:00
  edited: false
  hidden: false
  id: 6435210fe60b21004eca3145
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-04-11T08:57:51.000Z'
    data:
      status: closed
    id: 6435210fe60b21004eca3146
    type: status-change
  author: TheBloke
  created_at: 2023-04-11 07:57:51+00:00
  id: 6435210fe60b21004eca3146
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/galpaca-30B-GPTQ
repo_type: model
status: closed
target_branch: null
title: ggml version?
