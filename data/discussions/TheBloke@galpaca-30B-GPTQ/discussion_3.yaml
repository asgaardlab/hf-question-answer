!!python/object:huggingface_hub.community.DiscussionWithDetails
author: feliscat
conflicting_files: null
created_at: 2023-06-04 00:01:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3088d5a31760a4cfb808d6a434a39f0b.svg
      fullname: Tim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: feliscat
      type: user
    createdAt: '2023-06-04T01:01:25.000Z'
    data:
      edited: false
      editors:
      - feliscat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.714180588722229
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3088d5a31760a4cfb808d6a434a39f0b.svg
          fullname: Tim
          isHf: false
          isPro: false
          name: feliscat
          type: user
        html: '<p>This model only works when I set model_type to gptj in text-generation-webui.  Does
          that make sense?</p>

          '
        raw: This model only works when I set model_type to gptj in text-generation-webui.  Does
          that make sense?
        updatedAt: '2023-06-04T01:01:25.837Z'
      numEdits: 0
      reactions: []
    id: 647be265f8df36a726d78145
    type: comment
  author: feliscat
  content: This model only works when I set model_type to gptj in text-generation-webui.  Does
    that make sense?
  created_at: 2023-06-04 00:01:25+00:00
  edited: false
  hidden: false
  id: 647be265f8df36a726d78145
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-04T10:07:42.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9677037000656128
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>It''s actually an OPT model. But I seem to recall that text-gen-ui
          doesn''t have that option.</p>

          <p>But GPTQ-for-LLaMA supports OPT models so I guess whatever text-gen-ui
          does when you choose GPTJ also works for OPT.  </p>

          <p>I never really tested or experimented with this model so don''t have
          any experience myself.</p>

          <p>But if it works, it works!</p>

          '
        raw: "It's actually an OPT model. But I seem to recall that text-gen-ui doesn't\
          \ have that option.\n\nBut GPTQ-for-LLaMA supports OPT models so I guess\
          \ whatever text-gen-ui does when you choose GPTJ also works for OPT.  \n\
          \nI never really tested or experimented with this model so don't have any\
          \ experience myself.\n\nBut if it works, it works!"
        updatedAt: '2023-06-04T10:07:42.338Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - feliscat
    id: 647c626e1c0644de8d2123e1
    type: comment
  author: TheBloke
  content: "It's actually an OPT model. But I seem to recall that text-gen-ui doesn't\
    \ have that option.\n\nBut GPTQ-for-LLaMA supports OPT models so I guess whatever\
    \ text-gen-ui does when you choose GPTJ also works for OPT.  \n\nI never really\
    \ tested or experimented with this model so don't have any experience myself.\n\
    \nBut if it works, it works!"
  created_at: 2023-06-04 09:07:42+00:00
  edited: false
  hidden: false
  id: 647c626e1c0644de8d2123e1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97a381a3dd7aa60ae1a27627572eabe8.svg
      fullname: PIA
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: U2
      type: user
    createdAt: '2023-06-06T07:15:53.000Z'
    data:
      edited: true
      editors:
      - U2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7445023655891418
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97a381a3dd7aa60ae1a27627572eabe8.svg
          fullname: PIA
          isHf: false
          isPro: false
          name: U2
          type: user
        html: '<p>Got an error on running ''opt'' model.<br>"<br>oobabooga_linux/installer_files/env/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py",
          line 211, in forward<br>    attn_weights = torch.bmm(query_states, key_states.transpose(1,
          2))"<br>RuntimeError: expected scalar type Half but found Float<br>"</p>

          <p>BTW, it works in the gptj model,<br><del>but generated texts are quite
          unsatisfactory compared to the 13B model.</del><br>==&gt; My bad. This model
          is specialized for scientific data. I asked irrelevant questions.</p>

          '
        raw: "Got an error on running 'opt' model.\n\"\noobabooga_linux/installer_files/env/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py\"\
          , line 211, in forward\n    attn_weights = torch.bmm(query_states, key_states.transpose(1,\
          \ 2))\"\nRuntimeError: expected scalar type Half but found Float\n\"\n\n\
          BTW, it works in the gptj model, \n~~but generated texts are quite unsatisfactory\
          \ compared to the 13B model.~~ \n==> My bad. This model is specialized for\
          \ scientific data. I asked irrelevant questions."
        updatedAt: '2023-06-06T07:20:55.897Z'
      numEdits: 1
      reactions: []
    id: 647edd292a7bcaa3079557a0
    type: comment
  author: U2
  content: "Got an error on running 'opt' model.\n\"\noobabooga_linux/installer_files/env/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py\"\
    , line 211, in forward\n    attn_weights = torch.bmm(query_states, key_states.transpose(1,\
    \ 2))\"\nRuntimeError: expected scalar type Half but found Float\n\"\n\nBTW, it\
    \ works in the gptj model, \n~~but generated texts are quite unsatisfactory compared\
    \ to the 13B model.~~ \n==> My bad. This model is specialized for scientific data.\
    \ I asked irrelevant questions."
  created_at: 2023-06-06 06:15:53+00:00
  edited: true
  hidden: false
  id: 647edd292a7bcaa3079557a0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/galpaca-30B-GPTQ
repo_type: model
status: open
target_branch: null
title: model_type for text-generation-webui?
