!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yiyuliu
conflicting_files: null
created_at: 2023-11-16 12:13:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf2f09c6aa20e9215713e9bd4554661.svg
      fullname: Bruce Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yiyuliu
      type: user
    createdAt: '2023-11-16T12:13:51.000Z'
    data:
      edited: false
      editors:
      - yiyuliu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7940904498100281
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf2f09c6aa20e9215713e9bd4554661.svg
          fullname: Bruce Liu
          isHf: false
          isPro: false
          name: yiyuliu
          type: user
        html: '<p>Hi New to this model. I''m trying to do a sentiment analysis on
          a japanese text. I''m getting the following error:<br>Input is too long,
          try to truncate or use a paramater to handle this: The size of tensor a
          (534) must match the size of tensor b (512) at non-singleton dimension 1</p>

          <p>Is there a way to increase the length of the input temporarily through
          parameters</p>

          '
        raw: "Hi New to this model. I'm trying to do a sentiment analysis on a japanese\
          \ text. I'm getting the following error:\r\nInput is too long, try to truncate\
          \ or use a paramater to handle this: The size of tensor a (534) must match\
          \ the size of tensor b (512) at non-singleton dimension 1\r\n\r\nIs there\
          \ a way to increase the length of the input temporarily through parameters"
        updatedAt: '2023-11-16T12:13:51.144Z'
      numEdits: 0
      reactions: []
    id: 6556077fd81507133e795b74
    type: comment
  author: yiyuliu
  content: "Hi New to this model. I'm trying to do a sentiment analysis on a japanese\
    \ text. I'm getting the following error:\r\nInput is too long, try to truncate\
    \ or use a paramater to handle this: The size of tensor a (534) must match the\
    \ size of tensor b (512) at non-singleton dimension 1\r\n\r\nIs there a way to\
    \ increase the length of the input temporarily through parameters"
  created_at: 2023-11-16 12:13:51+00:00
  edited: false
  hidden: false
  id: 6556077fd81507133e795b74
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-11-16T15:18:45.000Z'
    data:
      edited: false
      editors:
      - lxyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7849113345146179
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
          fullname: Lik Xun Yuan
          isHf: false
          isPro: false
          name: lxyuan
          type: user
        html: "<p>Hi,</p>\n<p>We can't temporarily increase the model's sequence length\
          \ (i.e., the max length of distilbert model is 512).</p>\n<p>The easiest\
          \ solution is to truncate longer sequences. Here's a code snippet that demonstrates\
          \ this approach for sentiment analysis:</p>\n<pre><code class=\"language-python\"\
          >fn_kwargs={<span class=\"hljs-string\">\"padding\"</span>: <span class=\"\
          hljs-string\">\"max_length\"</span>, <span class=\"hljs-string\">\"truncation\"\
          </span>: <span class=\"hljs-literal\">True</span>, <span class=\"hljs-string\"\
          >\"max_length\"</span>: <span class=\"hljs-number\">512</span>}\n\ndistilled_student_sentiment_classifier\
          \ = pipeline(\n    model=<span class=\"hljs-string\">\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\
          </span>, \n    return_all_scores=<span class=\"hljs-literal\">True</span>\n\
          )\n\noutput = distilled_student_sentiment_classifier(jpn_article, **fn_kwargs)\n\
          </code></pre>\n<p>I haven't had the chance to run this code yet, so please\
          \ let me know if you encounter any issues or errors while executing it.</p>\n"
        raw: "Hi,\n\nWe can't temporarily increase the model's sequence length (i.e.,\
          \ the max length of distilbert model is 512).\n\nThe easiest solution is\
          \ to truncate longer sequences. Here's a code snippet that demonstrates\
          \ this approach for sentiment analysis:\n\n```python\nfn_kwargs={\"padding\"\
          : \"max_length\", \"truncation\": True, \"max_length\": 512}\n\ndistilled_student_sentiment_classifier\
          \ = pipeline(\n    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\
          , \n    return_all_scores=True\n)\n\noutput = distilled_student_sentiment_classifier(jpn_article,\
          \ **fn_kwargs)\n```\n\nI haven't had the chance to run this code yet, so\
          \ please let me know if you encounter any issues or errors while executing\
          \ it.\n"
        updatedAt: '2023-11-16T15:18:45.398Z'
      numEdits: 0
      reactions: []
    id: 655632d5397f7c5f84d77095
    type: comment
  author: lxyuan
  content: "Hi,\n\nWe can't temporarily increase the model's sequence length (i.e.,\
    \ the max length of distilbert model is 512).\n\nThe easiest solution is to truncate\
    \ longer sequences. Here's a code snippet that demonstrates this approach for\
    \ sentiment analysis:\n\n```python\nfn_kwargs={\"padding\": \"max_length\", \"\
    truncation\": True, \"max_length\": 512}\n\ndistilled_student_sentiment_classifier\
    \ = pipeline(\n    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\
    , \n    return_all_scores=True\n)\n\noutput = distilled_student_sentiment_classifier(jpn_article,\
    \ **fn_kwargs)\n```\n\nI haven't had the chance to run this code yet, so please\
    \ let me know if you encounter any issues or errors while executing it.\n"
  created_at: 2023-11-16 15:18:45+00:00
  edited: false
  hidden: false
  id: 655632d5397f7c5f84d77095
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf2f09c6aa20e9215713e9bd4554661.svg
      fullname: Bruce Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yiyuliu
      type: user
    createdAt: '2023-11-18T11:16:57.000Z'
    data:
      edited: false
      editors:
      - yiyuliu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9524630904197693
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf2f09c6aa20e9215713e9bd4554661.svg
          fullname: Bruce Liu
          isHf: false
          isPro: false
          name: yiyuliu
          type: user
        html: '<p>I''m running it through response requests. Is there a way to add
          it to the headers of the request?</p>

          '
        raw: I'm running it through response requests. Is there a way to add it to
          the headers of the request?
        updatedAt: '2023-11-18T11:16:57.764Z'
      numEdits: 0
      reactions: []
    id: 65589d293fc799847453ff83
    type: comment
  author: yiyuliu
  content: I'm running it through response requests. Is there a way to add it to the
    headers of the request?
  created_at: 2023-11-18 11:16:57+00:00
  edited: false
  hidden: false
  id: 65589d293fc799847453ff83
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/92856258cf94ffaefbbd239a9c7ba2af.svg
      fullname: DEV NAND NAIR
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DevNand
      type: user
    createdAt: '2023-11-19T17:53:33.000Z'
    data:
      edited: false
      editors:
      - DevNand
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6607568264007568
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/92856258cf94ffaefbbd239a9c7ba2af.svg
          fullname: DEV NAND NAIR
          isHf: false
          isPro: false
          name: DevNand
          type: user
        html: '<p>sir  when i checked the api using post man it shows:<br>{<br>    "error":
          "You need to specify either <code>text</code> or <code>text_target</code>.",<br>    "warnings":
          [<br>        "There was an inference error: You need to specify either <code>text</code>
          or <code>text_target</code>."<br>    ]<br>}</p>

          <p>am i not suppose to give the input in json format?</p>

          '
        raw: "sir  when i checked the api using post man it shows:\n{\n    \"error\"\
          : \"You need to specify either `text` or `text_target`.\",\n    \"warnings\"\
          : [\n        \"There was an inference error: You need to specify either\
          \ `text` or `text_target`.\"\n    ]\n}\n\nam i not suppose to give the input\
          \ in json format?"
        updatedAt: '2023-11-19T17:53:33.571Z'
      numEdits: 0
      reactions: []
    id: 655a4b9defc0fb7bedadcc30
    type: comment
  author: DevNand
  content: "sir  when i checked the api using post man it shows:\n{\n    \"error\"\
    : \"You need to specify either `text` or `text_target`.\",\n    \"warnings\":\
    \ [\n        \"There was an inference error: You need to specify either `text`\
    \ or `text_target`.\"\n    ]\n}\n\nam i not suppose to give the input in json\
    \ format?"
  created_at: 2023-11-19 17:53:33+00:00
  edited: false
  hidden: false
  id: 655a4b9defc0fb7bedadcc30
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-11-20T08:09:54.000Z'
    data:
      edited: false
      editors:
      - lxyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9684485793113708
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
          fullname: Lik Xun Yuan
          isHf: false
          isPro: false
          name: lxyuan
          type: user
        html: '<blockquote>

          <p>I''m running it through response requests. Is there a way to add it to
          the headers of the request?</p>

          </blockquote>

          <p>Could you please share your code with me? It would make it easier to
          assist with debugging</p>

          '
        raw: '> I''m running it through response requests. Is there a way to add it
          to the headers of the request?


          Could you please share your code with me? It would make it easier to assist
          with debugging'
        updatedAt: '2023-11-20T08:09:54.804Z'
      numEdits: 0
      reactions: []
    id: 655b14526a7098bc6e6c4f3b
    type: comment
  author: lxyuan
  content: '> I''m running it through response requests. Is there a way to add it
    to the headers of the request?


    Could you please share your code with me? It would make it easier to assist with
    debugging'
  created_at: 2023-11-20 08:09:54+00:00
  edited: false
  hidden: false
  id: 655b14526a7098bc6e6c4f3b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-11-20T08:10:03.000Z'
    data:
      edited: false
      editors:
      - lxyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8034658432006836
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
          fullname: Lik Xun Yuan
          isHf: false
          isPro: false
          name: lxyuan
          type: user
        html: '<blockquote>

          <p>sir  when i checked the api using post man it shows:<br>{<br>    "error":
          "You need to specify either <code>text</code> or <code>text_target</code>.",<br>    "warnings":
          [<br>        "There was an inference error: You need to specify either <code>text</code>
          or <code>text_target</code>."<br>    ]<br>}</p>

          <p>am i not suppose to give the input in json format?</p>

          </blockquote>

          <p>Could you please share your code with me? It would make it easier to
          assist with debugging</p>

          '
        raw: "> sir  when i checked the api using post man it shows:\n> {\n>     \"\
          error\": \"You need to specify either `text` or `text_target`.\",\n>   \
          \  \"warnings\": [\n>         \"There was an inference error: You need to\
          \ specify either `text` or `text_target`.\"\n>     ]\n> }\n> \n> am i not\
          \ suppose to give the input in json format?\n\nCould you please share your\
          \ code with me? It would make it easier to assist with debugging"
        updatedAt: '2023-11-20T08:10:03.511Z'
      numEdits: 0
      reactions: []
    id: 655b145b3ff5ba1b1b48ef45
    type: comment
  author: lxyuan
  content: "> sir  when i checked the api using post man it shows:\n> {\n>     \"\
    error\": \"You need to specify either `text` or `text_target`.\",\n>     \"warnings\"\
    : [\n>         \"There was an inference error: You need to specify either `text`\
    \ or `text_target`.\"\n>     ]\n> }\n> \n> am i not suppose to give the input\
    \ in json format?\n\nCould you please share your code with me? It would make it\
    \ easier to assist with debugging"
  created_at: 2023-11-20 08:10:03+00:00
  edited: false
  hidden: false
  id: 655b145b3ff5ba1b1b48ef45
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf2f09c6aa20e9215713e9bd4554661.svg
      fullname: Bruce Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yiyuliu
      type: user
    createdAt: '2023-11-22T06:53:05.000Z'
    data:
      edited: true
      editors:
      - yiyuliu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5909973978996277
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf2f09c6aa20e9215713e9bd4554661.svg
          fullname: Bruce Liu
          isHf: false
          isPro: false
          name: yiyuliu
          type: user
        html: "<blockquote>\n<blockquote>\n<p>I'm running it through response requests.\
          \ Is there a way to add it to the headers of the request?</p>\n</blockquote>\n\
          <p>Could you please share your code with me? It would make it easier to\
          \ assist with debugging</p>\n</blockquote>\n<pre><code class=\"language-python\"\
          >model = <span class=\"hljs-string\">\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\
          </span>\nhf_token = <span class=\"hljs-string\">\"your token from env file\"\
          </span> \n\nAPI_URL = <span class=\"hljs-string\">\"https://api-inference.huggingface.co/models/\"\
          </span> + model\nheaders = {<span class=\"hljs-string\">\"Authorization\"\
          </span>: <span class=\"hljs-string\">\"Bearer %s\"</span> % (hf_token)}\n\
          \n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\"\
          >def</span> <span class=\"hljs-title function_\">analysis</span>(<span class=\"\
          hljs-params\">session, data, index</span>):\n    default = [[{<span class=\"\
          hljs-string\">'label'</span>: <span class=\"hljs-string\">'negative'</span>,\
          \ <span class=\"hljs-string\">'score'</span>: <span class=\"hljs-number\"\
          >999</span>}, \n                {<span class=\"hljs-string\">'label'</span>:\
          \ <span class=\"hljs-string\">'neutral'</span>, <span class=\"hljs-string\"\
          >'score'</span>: <span class=\"hljs-number\">999</span>}, \n           \
          \     {<span class=\"hljs-string\">'label'</span>: <span class=\"hljs-string\"\
          >'positive'</span>, <span class=\"hljs-string\">'score'</span>: <span class=\"\
          hljs-number\">999</span>}]] <span class=\"hljs-comment\">#replace with empty\
          \ value</span>\n    payload = <span class=\"hljs-built_in\">dict</span>(inputs=data,\
          \ options=<span class=\"hljs-built_in\">dict</span>(wait_for_model=<span\
          \ class=\"hljs-literal\">True</span>))\n    <span class=\"hljs-keyword\"\
          >async</span> <span class=\"hljs-keyword\">with</span> session.post(API_URL,\
          \ headers=headers, json=payload) <span class=\"hljs-keyword\">as</span>\
          \ response:\n        <span class=\"hljs-keyword\">if</span> response.status\
          \ != <span class=\"hljs-number\">200</span>:\n            <span class=\"\
          hljs-built_in\">print</span>(<span class=\"hljs-string\">'found an error'</span>,\
          \ response)\n            <span class=\"hljs-keyword\">if</span> response.status\
          \ == <span class=\"hljs-number\">400</span>:\n                <span class=\"\
          hljs-built_in\">print</span>(<span class=\"hljs-string\">'input length error\
          \ &gt;&gt; '</span>, index)\n        <span class=\"hljs-keyword\">try</span>:\n\
          \            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\"\
          >await</span> response.json()\n        <span class=\"hljs-keyword\">except</span>:\n\
          \            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\"\
          >'broken'</span>, index)\n            response = default\n            <span\
          \ class=\"hljs-keyword\">return</span> response\n</code></pre>\n"
        raw: "> > I'm running it through response requests. Is there a way to add\
          \ it to the headers of the request?\n> \n> Could you please share your code\
          \ with me? It would make it easier to assist with debugging\n```python\n\
          model = \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\
          \nhf_token = \"your token from env file\" \n\nAPI_URL = \"https://api-inference.huggingface.co/models/\"\
          \ + model\nheaders = {\"Authorization\": \"Bearer %s\" % (hf_token)}\n\n\
          async def analysis(session, data, index):\n    default = [[{'label': 'negative',\
          \ 'score': 999}, \n                {'label': 'neutral', 'score': 999}, \n\
          \                {'label': 'positive', 'score': 999}]] #replace with empty\
          \ value\n    payload = dict(inputs=data, options=dict(wait_for_model=True))\n\
          \    async with session.post(API_URL, headers=headers, json=payload) as\
          \ response:\n        if response.status != 200:\n            print('found\
          \ an error', response)\n            if response.status == 400:\n       \
          \         print('input length error >> ', index)\n        try:\n       \
          \     return await response.json()\n        except:\n            print('broken',\
          \ index)\n            response = default\n            return response\n\
          ```"
        updatedAt: '2023-11-22T06:53:56.646Z'
      numEdits: 1
      reactions: []
    id: 655da55172ea9f3a3b897b22
    type: comment
  author: yiyuliu
  content: "> > I'm running it through response requests. Is there a way to add it\
    \ to the headers of the request?\n> \n> Could you please share your code with\
    \ me? It would make it easier to assist with debugging\n```python\nmodel = \"\
    lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\nhf_token = \"\
    your token from env file\" \n\nAPI_URL = \"https://api-inference.huggingface.co/models/\"\
    \ + model\nheaders = {\"Authorization\": \"Bearer %s\" % (hf_token)}\n\nasync\
    \ def analysis(session, data, index):\n    default = [[{'label': 'negative', 'score':\
    \ 999}, \n                {'label': 'neutral', 'score': 999}, \n             \
    \   {'label': 'positive', 'score': 999}]] #replace with empty value\n    payload\
    \ = dict(inputs=data, options=dict(wait_for_model=True))\n    async with session.post(API_URL,\
    \ headers=headers, json=payload) as response:\n        if response.status != 200:\n\
    \            print('found an error', response)\n            if response.status\
    \ == 400:\n                print('input length error >> ', index)\n        try:\n\
    \            return await response.json()\n        except:\n            print('broken',\
    \ index)\n            response = default\n            return response\n```"
  created_at: 2023-11-22 06:53:05+00:00
  edited: true
  hidden: false
  id: 655da55172ea9f3a3b897b22
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-11-24T09:10:55.000Z'
    data:
      edited: false
      editors:
      - lxyuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.639890730381012
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
          fullname: Lik Xun Yuan
          isHf: false
          isPro: false
          name: lxyuan
          type: user
        html: "<blockquote>\n<blockquote>\n<blockquote>\n<p>I'm running it through\
          \ response requests. Is there a way to add it to the headers of the request?</p>\n\
          </blockquote>\n<p>Could you please share your code with me? It would make\
          \ it easier to assist with debugging</p>\n</blockquote>\n<pre><code class=\"\
          language-python\">model = <span class=\"hljs-string\">\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\
          </span>\nhf_token = <span class=\"hljs-string\">\"your token from env file\"\
          </span> \n\nAPI_URL = <span class=\"hljs-string\">\"https://api-inference.huggingface.co/models/\"\
          </span> + model\nheaders = {<span class=\"hljs-string\">\"Authorization\"\
          </span>: <span class=\"hljs-string\">\"Bearer %s\"</span> % (hf_token)}\n\
          \n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\"\
          >def</span> <span class=\"hljs-title function_\">analysis</span>(<span class=\"\
          hljs-params\">session, data, index</span>):\n    default = [[{<span class=\"\
          hljs-string\">'label'</span>: <span class=\"hljs-string\">'negative'</span>,\
          \ <span class=\"hljs-string\">'score'</span>: <span class=\"hljs-number\"\
          >999</span>}, \n                {<span class=\"hljs-string\">'label'</span>:\
          \ <span class=\"hljs-string\">'neutral'</span>, <span class=\"hljs-string\"\
          >'score'</span>: <span class=\"hljs-number\">999</span>}, \n           \
          \     {<span class=\"hljs-string\">'label'</span>: <span class=\"hljs-string\"\
          >'positive'</span>, <span class=\"hljs-string\">'score'</span>: <span class=\"\
          hljs-number\">999</span>}]] <span class=\"hljs-comment\">#replace with empty\
          \ value</span>\n    payload = <span class=\"hljs-built_in\">dict</span>(inputs=data,\
          \ options=<span class=\"hljs-built_in\">dict</span>(wait_for_model=<span\
          \ class=\"hljs-literal\">True</span>))\n    <span class=\"hljs-keyword\"\
          >async</span> <span class=\"hljs-keyword\">with</span> session.post(API_URL,\
          \ headers=headers, json=payload) <span class=\"hljs-keyword\">as</span>\
          \ response:\n        <span class=\"hljs-keyword\">if</span> response.status\
          \ != <span class=\"hljs-number\">200</span>:\n            <span class=\"\
          hljs-built_in\">print</span>(<span class=\"hljs-string\">'found an error'</span>,\
          \ response)\n            <span class=\"hljs-keyword\">if</span> response.status\
          \ == <span class=\"hljs-number\">400</span>:\n                <span class=\"\
          hljs-built_in\">print</span>(<span class=\"hljs-string\">'input length error\
          \ &gt;&gt; '</span>, index)\n        <span class=\"hljs-keyword\">try</span>:\n\
          \            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\"\
          >await</span> response.json()\n        <span class=\"hljs-keyword\">except</span>:\n\
          \            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\"\
          >'broken'</span>, index)\n            response = default\n            <span\
          \ class=\"hljs-keyword\">return</span> response\n</code></pre>\n</blockquote>\n\
          <p>It is strange that it seems like we can't define the 'truncation' or\
          \ 'max_length' parameters in the Hugging Face Inference API. One potential\
          \ workaround, though it might be slower, is to preprocess the text using\
          \ the Hugging Face tokenizer before passing it into the API.</p>\n<p>Reference:</p>\n\
          <ul>\n<li><a href=\"https://huggingface.co/docs/api-inference/detailed_parameters?code=python#text-classification-task\"\
          >https://huggingface.co/docs/api-inference/detailed_parameters?code=python#text-classification-task</a></li>\n\
          </ul>\n"
        raw: "> > > I'm running it through response requests. Is there a way to add\
          \ it to the headers of the request?\n> > \n> > Could you please share your\
          \ code with me? It would make it easier to assist with debugging\n> ```python\n\
          > model = \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\
          \n> hf_token = \"your token from env file\" \n> \n> API_URL = \"https://api-inference.huggingface.co/models/\"\
          \ + model\n> headers = {\"Authorization\": \"Bearer %s\" % (hf_token)}\n\
          > \n> async def analysis(session, data, index):\n>     default = [[{'label':\
          \ 'negative', 'score': 999}, \n>                 {'label': 'neutral', 'score':\
          \ 999}, \n>                 {'label': 'positive', 'score': 999}]] #replace\
          \ with empty value\n>     payload = dict(inputs=data, options=dict(wait_for_model=True))\n\
          >     async with session.post(API_URL, headers=headers, json=payload) as\
          \ response:\n>         if response.status != 200:\n>             print('found\
          \ an error', response)\n>             if response.status == 400:\n>    \
          \             print('input length error >> ', index)\n>         try:\n>\
          \             return await response.json()\n>         except:\n>       \
          \      print('broken', index)\n>             response = default\n>     \
          \        return response\n> ```\n\nIt is strange that it seems like we can't\
          \ define the 'truncation' or 'max_length' parameters in the Hugging Face\
          \ Inference API. One potential workaround, though it might be slower, is\
          \ to preprocess the text using the Hugging Face tokenizer before passing\
          \ it into the API.\n\nReference:\n- https://huggingface.co/docs/api-inference/detailed_parameters?code=python#text-classification-task\n"
        updatedAt: '2023-11-24T09:10:55.897Z'
      numEdits: 0
      reactions: []
    id: 6560689f5f13eb6efa3dc022
    type: comment
  author: lxyuan
  content: "> > > I'm running it through response requests. Is there a way to add\
    \ it to the headers of the request?\n> > \n> > Could you please share your code\
    \ with me? It would make it easier to assist with debugging\n> ```python\n> model\
    \ = \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n> hf_token\
    \ = \"your token from env file\" \n> \n> API_URL = \"https://api-inference.huggingface.co/models/\"\
    \ + model\n> headers = {\"Authorization\": \"Bearer %s\" % (hf_token)}\n> \n>\
    \ async def analysis(session, data, index):\n>     default = [[{'label': 'negative',\
    \ 'score': 999}, \n>                 {'label': 'neutral', 'score': 999}, \n> \
    \                {'label': 'positive', 'score': 999}]] #replace with empty value\n\
    >     payload = dict(inputs=data, options=dict(wait_for_model=True))\n>     async\
    \ with session.post(API_URL, headers=headers, json=payload) as response:\n>  \
    \       if response.status != 200:\n>             print('found an error', response)\n\
    >             if response.status == 400:\n>                 print('input length\
    \ error >> ', index)\n>         try:\n>             return await response.json()\n\
    >         except:\n>             print('broken', index)\n>             response\
    \ = default\n>             return response\n> ```\n\nIt is strange that it seems\
    \ like we can't define the 'truncation' or 'max_length' parameters in the Hugging\
    \ Face Inference API. One potential workaround, though it might be slower, is\
    \ to preprocess the text using the Hugging Face tokenizer before passing it into\
    \ the API.\n\nReference:\n- https://huggingface.co/docs/api-inference/detailed_parameters?code=python#text-classification-task\n"
  created_at: 2023-11-24 09:10:55+00:00
  edited: false
  hidden: false
  id: 6560689f5f13eb6efa3dc022
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5f056ac25d08220171a0ad88/ty6_yL3jqX_fXXVk5eP0N.png?w=200&h=200&f=face
      fullname: Lik Xun Yuan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lxyuan
      type: user
    createdAt: '2023-12-01T06:58:25.000Z'
    data:
      status: closed
    id: 656984118369400a58221326
    type: status-change
  author: lxyuan
  created_at: 2023-12-01 06:58:25+00:00
  id: 656984118369400a58221326
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eaf2f09c6aa20e9215713e9bd4554661.svg
      fullname: Bruce Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yiyuliu
      type: user
    createdAt: '2023-12-15T16:30:29.000Z'
    data:
      edited: false
      editors:
      - yiyuliu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9091618061065674
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eaf2f09c6aa20e9215713e9bd4554661.svg
          fullname: Bruce Liu
          isHf: false
          isPro: false
          name: yiyuliu
          type: user
        html: '<p>Thanks for the suggestion. I''ve ended up using nltk to tokenise
          and remove stop words before feeding it to hugging face API</p>

          '
        raw: Thanks for the suggestion. I've ended up using nltk to tokenise and remove
          stop words before feeding it to hugging face API
        updatedAt: '2023-12-15T16:30:29.118Z'
      numEdits: 0
      reactions: []
    id: 657c7f254d19e419f2f1505c
    type: comment
  author: yiyuliu
  content: Thanks for the suggestion. I've ended up using nltk to tokenise and remove
    stop words before feeding it to hugging face API
  created_at: 2023-12-15 16:30:29+00:00
  edited: false
  hidden: false
  id: 657c7f254d19e419f2f1505c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: lxyuan/distilbert-base-multilingual-cased-sentiments-student
repo_type: model
status: closed
target_branch: null
title: Input Length
