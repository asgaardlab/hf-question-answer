!!python/object:huggingface_hub.community.DiscussionWithDetails
author: grant232323
conflicting_files: null
created_at: 2023-12-25 14:12:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c682f74908619aac1206dbe184d9d8ce.svg
      fullname: deng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: grant232323
      type: user
    createdAt: '2023-12-25T14:12:19.000Z'
    data:
      edited: false
      editors:
      - grant232323
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7021843791007996
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c682f74908619aac1206dbe184d9d8ce.svg
          fullname: deng
          isHf: false
          isPro: false
          name: grant232323
          type: user
        html: "<p>Looks like the model can only handel some basic task, is there anyway\
          \ to improve the performance?</p>\n<p>This is the function I have given\
          \ to the model:<br>{<br>    \"function\": \"write_file\",<br>    \"description\"\
          : \"Write a file, creating it if necessary. If the file exists, it is overwritten.\"\
          ,<br>    \"arguments\": [<br>        {<br>            \"name\": \"filename\"\
          ,<br>            \"type\": \"string\",<br>            \"description\": \"\
          name of the file\"<br>        },<br>        {<br>            \"name\": \"\
          contents\",<br>            \"type\": \"string\",<br>            \"description\"\
          : \"contents of the file\"<br>        }<br>    ]<br>}</p>\n<p>For some simple\
          \ task,  it works fine</p>\n<p>Prompt:<br>&lt;FUNCTIONS&gt;{\"function\"\
          : \"write_file\", \"description\": \"Write a file, creating it if necessary.\
          \ If the file exists, it is overwritten.\", \"arguments\": [{\"name\": \"\
          filename\", \"type\": \"string\", \"description\": \"name of the file\"\
          }, {\"name\": \"contents\", \"type\": \"string\", \"description\": \"contents\
          \ of the file\"}]}&lt;/FUNCTIONS&gt;</p>\n<h3 id=\"instruction\">Instruction:</h3>\n\
          <p>write hello world to out.txt</p>\n<h3 id=\"response\">Response:</h3>\n\
          <p>Model return:<br>{<br>    \"function\": \"write_file\",<br>    \"arguments\"\
          : {<br>        \"filename\": \"out.txt\",<br>        \"contents\": \"Hello\
          \ World!\"<br>    }<br>}</p>\n<p>However, when I tried some complicated\
          \ question, especially coding question, it didn't return properly</p>\n\
          <p>Prompt:<br>&lt;FUNCTIONS&gt;{\"function\": \"write_file\", \"description\"\
          : \"Write a file, creating it if necessary. If the file exists, it is overwritten.\"\
          , \"arguments\": [{\"name\": \"filename\", \"type\": \"string\", \"description\"\
          : \"name of the file\"}, {\"name\": \"contents\", \"type\": \"string\",\
          \ \"description\": \"contents of the file\"}]}&lt;/FUNCTIONS&gt;</p>\n<h3\
          \ id=\"instruction-1\">Instruction:</h3>\n<p>Write a python program to out.py\
          \ to print hello world</p>\n<h3 id=\"response-1\">Response:</h3>\n<p>Model\
          \ return:<br>The following Python code can be used to write a simple \"\
          Hello World!\" script in a file named <code>out.py</code>:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">with</span> <span\
          \ class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">'out.py'</span>,\
          \ <span class=\"hljs-string\">'w'</span>) <span class=\"hljs-keyword\">as</span>\
          \ f:\n    f.write(<span class=\"hljs-string\">\"print('Hello World!')\\\
          n\"</span>)\n</code></pre>\n"
        raw: "Looks like the model can only handel some basic task, is there anyway\
          \ to improve the performance?\r\n\r\nThis is the function I have given to\
          \ the model:\r\n{\r\n    \"function\": \"write_file\",\r\n    \"description\"\
          : \"Write a file, creating it if necessary. If the file exists, it is overwritten.\"\
          ,\r\n    \"arguments\": [\r\n        {\r\n            \"name\": \"filename\"\
          ,\r\n            \"type\": \"string\",\r\n            \"description\": \"\
          name of the file\"\r\n        },\r\n        {\r\n            \"name\": \"\
          contents\",\r\n            \"type\": \"string\",\r\n            \"description\"\
          : \"contents of the file\"\r\n        }\r\n    ]\r\n}\r\n\r\nFor some simple\
          \ task,  it works fine\r\n\r\nPrompt:\r\n\\<FUNCTIONS\\>{\"function\": \"\
          write_file\", \"description\": \"Write a file, creating it if necessary.\
          \ If the file exists, it is overwritten.\", \"arguments\": [{\"name\": \"\
          filename\", \"type\": \"string\", \"description\": \"name of the file\"\
          }, {\"name\": \"contents\", \"type\": \"string\", \"description\": \"contents\
          \ of the file\"}]}\\</FUNCTIONS\\>\r\n\r\n\r\n### Instruction:\r\nwrite\
          \ hello world to out.txt\r\n\r\n\r\n### Response:\r\n\r\n\r\n\r\n\r\nModel\
          \ return:\r\n{\r\n    \"function\": \"write_file\",\r\n    \"arguments\"\
          : {\r\n        \"filename\": \"out.txt\",\r\n        \"contents\": \"Hello\
          \ World!\"\r\n    }\r\n}\r\n\r\nHowever, when I tried some complicated question,\
          \ especially coding question, it didn't return properly\r\n\r\nPrompt:\r\
          \n\\<FUNCTIONS\\>{\"function\": \"write_file\", \"description\": \"Write\
          \ a file, creating it if necessary. If the file exists, it is overwritten.\"\
          , \"arguments\": [{\"name\": \"filename\", \"type\": \"string\", \"description\"\
          : \"name of the file\"}, {\"name\": \"contents\", \"type\": \"string\",\
          \ \"description\": \"contents of the file\"}]}\\</FUNCTIONS\\>\r\n\r\n\r\
          \n### Instruction:\r\nWrite a python program to out.py to print hello world\r\
          \n\r\n### Response:\r\n\r\n\r\n\r\n\r\nModel return:\r\nThe following Python\
          \ code can be used to write a simple \"Hello World!\" script in a file named\
          \ `out.py`:\r\n\r\n```python\r\nwith open('out.py', 'w') as f:\r\n    f.write(\"\
          print('Hello World!')\\n\")\r\n```\r\n\r\n\r\n"
        updatedAt: '2023-12-25T14:12:19.583Z'
      numEdits: 0
      reactions: []
    id: 65898dc3003ceee69357cdad
    type: comment
  author: grant232323
  content: "Looks like the model can only handel some basic task, is there anyway\
    \ to improve the performance?\r\n\r\nThis is the function I have given to the\
    \ model:\r\n{\r\n    \"function\": \"write_file\",\r\n    \"description\": \"\
    Write a file, creating it if necessary. If the file exists, it is overwritten.\"\
    ,\r\n    \"arguments\": [\r\n        {\r\n            \"name\": \"filename\",\r\
    \n            \"type\": \"string\",\r\n            \"description\": \"name of\
    \ the file\"\r\n        },\r\n        {\r\n            \"name\": \"contents\"\
    ,\r\n            \"type\": \"string\",\r\n            \"description\": \"contents\
    \ of the file\"\r\n        }\r\n    ]\r\n}\r\n\r\nFor some simple task,  it works\
    \ fine\r\n\r\nPrompt:\r\n\\<FUNCTIONS\\>{\"function\": \"write_file\", \"description\"\
    : \"Write a file, creating it if necessary. If the file exists, it is overwritten.\"\
    , \"arguments\": [{\"name\": \"filename\", \"type\": \"string\", \"description\"\
    : \"name of the file\"}, {\"name\": \"contents\", \"type\": \"string\", \"description\"\
    : \"contents of the file\"}]}\\</FUNCTIONS\\>\r\n\r\n\r\n### Instruction:\r\n\
    write hello world to out.txt\r\n\r\n\r\n### Response:\r\n\r\n\r\n\r\n\r\nModel\
    \ return:\r\n{\r\n    \"function\": \"write_file\",\r\n    \"arguments\": {\r\n\
    \        \"filename\": \"out.txt\",\r\n        \"contents\": \"Hello World!\"\r\
    \n    }\r\n}\r\n\r\nHowever, when I tried some complicated question, especially\
    \ coding question, it didn't return properly\r\n\r\nPrompt:\r\n\\<FUNCTIONS\\\
    >{\"function\": \"write_file\", \"description\": \"Write a file, creating it if\
    \ necessary. If the file exists, it is overwritten.\", \"arguments\": [{\"name\"\
    : \"filename\", \"type\": \"string\", \"description\": \"name of the file\"},\
    \ {\"name\": \"contents\", \"type\": \"string\", \"description\": \"contents of\
    \ the file\"}]}\\</FUNCTIONS\\>\r\n\r\n\r\n### Instruction:\r\nWrite a python\
    \ program to out.py to print hello world\r\n\r\n### Response:\r\n\r\n\r\n\r\n\r\
    \nModel return:\r\nThe following Python code can be used to write a simple \"\
    Hello World!\" script in a file named `out.py`:\r\n\r\n```python\r\nwith open('out.py',\
    \ 'w') as f:\r\n    f.write(\"print('Hello World!')\\n\")\r\n```\r\n\r\n\r\n"
  created_at: 2023-12-25 14:12:19+00:00
  edited: false
  hidden: false
  id: 65898dc3003ceee69357cdad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-12-26T10:25:57.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9895955324172974
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>Hi Grant, thanks for having provided a clear example.</p>

          <p>I''ve read through and the responses all seem reasonable.</p>

          <p>What kind of response were you expecting to the second question?</p>

          '
        raw: 'Hi Grant, thanks for having provided a clear example.


          I''ve read through and the responses all seem reasonable.


          What kind of response were you expecting to the second question?'
        updatedAt: '2023-12-26T10:25:57.514Z'
      numEdits: 0
      reactions: []
    id: 658aaa356b17c068720c1f51
    type: comment
  author: RonanMcGovern
  content: 'Hi Grant, thanks for having provided a clear example.


    I''ve read through and the responses all seem reasonable.


    What kind of response were you expecting to the second question?'
  created_at: 2023-12-26 10:25:57+00:00
  edited: false
  hidden: false
  id: 658aaa356b17c068720c1f51
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c682f74908619aac1206dbe184d9d8ce.svg
      fullname: deng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: grant232323
      type: user
    createdAt: '2023-12-27T05:53:00.000Z'
    data:
      edited: false
      editors:
      - grant232323
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8766653537750244
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c682f74908619aac1206dbe184d9d8ce.svg
          fullname: deng
          isHf: false
          isPro: false
          name: grant232323
          type: user
        html: '<p>Hi Ronan, for the second question, I was expecting the model to
          return with function format, something like<br>{<br>"function": "write_file",<br>"arguments":
          {<br>"filename": "out.py",<br>"contents": "print(''Hello World!'')\n"<br>}<br>}<br>Is
          there anyway to achieve this?</p>

          '
        raw: "Hi Ronan, for the second question, I was expecting the model to return\
          \ with function format, something like \n{\n\"function\": \"write_file\"\
          ,\n\"arguments\": {\n\"filename\": \"out.py\",\n\"contents\": \"print('Hello\
          \ World!')\\n\"\n}\n}\nIs there anyway to achieve this?"
        updatedAt: '2023-12-27T05:53:00.575Z'
      numEdits: 0
      reactions: []
    id: 658bbbbc135580745c4a7784
    type: comment
  author: grant232323
  content: "Hi Ronan, for the second question, I was expecting the model to return\
    \ with function format, something like \n{\n\"function\": \"write_file\",\n\"\
    arguments\": {\n\"filename\": \"out.py\",\n\"contents\": \"print('Hello World!')\\\
    n\"\n}\n}\nIs there anyway to achieve this?"
  created_at: 2023-12-27 05:53:00+00:00
  edited: false
  hidden: false
  id: 658bbbbc135580745c4a7784
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-12-27T10:04:39.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9361739158630371
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>A few thoughts:</p>

          <ol>

          <li><p>"Write a file, creating it if necessary. If the file exists, it is
          overwritten."<br>This function description is unclear because a language
          model cannot "create" a file, and it''s confusing what the difference is
          between "write" and "create". Probably it''s best to call it "save_file"
          and put the description as "Function to call if asked to save a file.".
          If you further want the language model to know whether files can be overwritten
          or not, then you need to provide a list of files to the LLM and further
          explain that in the description.</p>

          </li>

          <li><p>"Write a python program to out.py to print hello world"</p>

          </li>

          </ol>

          <p>There isn''t a clear way for the LLM to know whether to just write a
          response (i.e. respond) with the python code OR use the write_file function.
          Again, using save_file as the function name will probably help because then
          you could say something like "Write a python program that prints -hello
          world- and save that program as out.py.".</p>

          <p>BTW, chatgpt is very good at helping to refine your function defintions
          and prompts. You coud paste everything you wrote into chatgpt, tell it you
          are feeding into an LLM that is fine-tuned for function calling, and ask
          how to improve the function description and prompt.</p>

          '
        raw: 'A few thoughts:


          1. "Write a file, creating it if necessary. If the file exists, it is overwritten."

          This function description is unclear because a language model cannot "create"
          a file, and it''s confusing what the difference is between "write" and "create".
          Probably it''s best to call it "save_file" and put the description as "Function
          to call if asked to save a file.". If you further want the language model
          to know whether files can be overwritten or not, then you need to provide
          a list of files to the LLM and further explain that in the description.


          2. "Write a python program to out.py to print hello world"


          There isn''t a clear way for the LLM to know whether to just write a response
          (i.e. respond) with the python code OR use the write_file function. Again,
          using save_file as the function name will probably help because then you
          could say something like "Write a python program that prints -hello world-
          and save that program as out.py.".


          BTW, chatgpt is very good at helping to refine your function defintions
          and prompts. You coud paste everything you wrote into chatgpt, tell it you
          are feeding into an LLM that is fine-tuned for function calling, and ask
          how to improve the function description and prompt.'
        updatedAt: '2023-12-27T10:04:39.479Z'
      numEdits: 0
      reactions: []
    id: 658bf6b70ccb77b89a174e4f
    type: comment
  author: RonanMcGovern
  content: 'A few thoughts:


    1. "Write a file, creating it if necessary. If the file exists, it is overwritten."

    This function description is unclear because a language model cannot "create"
    a file, and it''s confusing what the difference is between "write" and "create".
    Probably it''s best to call it "save_file" and put the description as "Function
    to call if asked to save a file.". If you further want the language model to know
    whether files can be overwritten or not, then you need to provide a list of files
    to the LLM and further explain that in the description.


    2. "Write a python program to out.py to print hello world"


    There isn''t a clear way for the LLM to know whether to just write a response
    (i.e. respond) with the python code OR use the write_file function. Again, using
    save_file as the function name will probably help because then you could say something
    like "Write a python program that prints -hello world- and save that program as
    out.py.".


    BTW, chatgpt is very good at helping to refine your function defintions and prompts.
    You coud paste everything you wrote into chatgpt, tell it you are feeding into
    an LLM that is fine-tuned for function calling, and ask how to improve the function
    description and prompt.'
  created_at: 2023-12-27 10:04:39+00:00
  edited: false
  hidden: false
  id: 658bf6b70ccb77b89a174e4f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-05T15:18:10.000Z'
    data:
      status: closed
    id: 65981db2966fb200b4ef54fd
    type: status-change
  author: RonanMcGovern
  created_at: 2024-01-05 15:18:10+00:00
  id: 65981db2966fb200b4ef54fd
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-05T15:18:15.000Z'
    data:
      status: open
    id: 65981db749dae38371195868
    type: status-change
  author: RonanMcGovern
  created_at: 2024-01-05 15:18:15+00:00
  id: 65981db749dae38371195868
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-05T15:18:17.000Z'
    data:
      status: closed
    id: 65981db9b1a78672696c0b2f
    type: status-change
  author: RonanMcGovern
  created_at: 2024-01-05 15:18:17+00:00
  id: 65981db9b1a78672696c0b2f
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c682f74908619aac1206dbe184d9d8ce.svg
      fullname: deng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: grant232323
      type: user
    createdAt: '2024-01-17T08:02:13.000Z'
    data:
      edited: false
      editors:
      - grant232323
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5528314709663391
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c682f74908619aac1206dbe184d9d8ce.svg
          fullname: deng
          isHf: false
          isPro: false
          name: grant232323
          type: user
        html: '<p>Hi Ronan,</p>

          <p>Just for comparison, I tried the same prompt provided before with gpt-3.5-turbo-0613
          model using tool calls, this is what I get:</p>

          <p>"choices": [<br>        {<br>            "index": 0,<br>            "message":
          {<br>                "role": "assistant",<br>                "content":
          null,<br>                "tool_calls": [<br>                    {<br>                        "id":
          "call_xz8NjzhqKiZA8UJkDR2KQvpd",<br>                        "type": "function",<br>                        "function":
          {<br>                            "name": "write_file",<br>                            "arguments":
          "{\n  "filename": "out.py",\n  "contents": "print(''Hello, world!'')"\n}"<br>                        }<br>                    }<br>                ]<br>            },<br>            "logprobs":
          null,<br>            "finish_reason": "tool_calls"<br>        }<br>    ]</p>

          '
        raw: "Hi Ronan,\n\nJust for comparison, I tried the same prompt provided before\
          \ with gpt-3.5-turbo-0613 model using tool calls, this is what I get:\n\n\
          \"choices\": [\n        {\n            \"index\": 0,\n            \"message\"\
          : {\n                \"role\": \"assistant\",\n                \"content\"\
          : null,\n                \"tool_calls\": [\n                    {\n    \
          \                    \"id\": \"call_xz8NjzhqKiZA8UJkDR2KQvpd\",\n      \
          \                  \"type\": \"function\",\n                        \"function\"\
          : {\n                            \"name\": \"write_file\",\n           \
          \                 \"arguments\": \"{\\n  \\\"filename\\\": \\\"out.py\\\"\
          ,\\n  \\\"contents\\\": \\\"print('Hello, world!')\\\"\\n}\"\n         \
          \               }\n                    }\n                ]\n          \
          \  },\n            \"logprobs\": null,\n            \"finish_reason\": \"\
          tool_calls\"\n        }\n    ]"
        updatedAt: '2024-01-17T08:02:13.633Z'
      numEdits: 0
      reactions: []
    id: 65a7898576b0aa0f7e639c5e
    type: comment
  author: grant232323
  content: "Hi Ronan,\n\nJust for comparison, I tried the same prompt provided before\
    \ with gpt-3.5-turbo-0613 model using tool calls, this is what I get:\n\n\"choices\"\
    : [\n        {\n            \"index\": 0,\n            \"message\": {\n      \
    \          \"role\": \"assistant\",\n                \"content\": null,\n    \
    \            \"tool_calls\": [\n                    {\n                      \
    \  \"id\": \"call_xz8NjzhqKiZA8UJkDR2KQvpd\",\n                        \"type\"\
    : \"function\",\n                        \"function\": {\n                   \
    \         \"name\": \"write_file\",\n                            \"arguments\"\
    : \"{\\n  \\\"filename\\\": \\\"out.py\\\",\\n  \\\"contents\\\": \\\"print('Hello,\
    \ world!')\\\"\\n}\"\n                        }\n                    }\n     \
    \           ]\n            },\n            \"logprobs\": null,\n            \"\
    finish_reason\": \"tool_calls\"\n        }\n    ]"
  created_at: 2024-01-17 08:02:13+00:00
  edited: false
  hidden: false
  id: 65a7898576b0aa0f7e639c5e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-17T12:28:22.000Z'
    data:
      status: open
    id: 65a7c7e6c46ce42ef555ae09
    type: status-change
  author: RonanMcGovern
  created_at: 2024-01-17 12:28:22+00:00
  id: 65a7c7e6c46ce42ef555ae09
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-17T12:50:56.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8035913109779358
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: "<p>I should have said this before, but the <a href=\"https://huggingface.co/Trelis/deepseek-coder-33b-instruct-function-calling-v3\"\
          >v3 version of this model</a> is now recommended. I have updated the model\
          \ card (which I should have before).</p>\n<p>I have also done some testing\
          \ on the v3 model with your functions and prompt. It works well.</p>\n<p>Here\
          \ is a formatted version of the conversation I had:</p>\n<pre><code>user:\
          \ Write a python program to out.py to print hello world\n\nfunction_call:\
          \ {\n    \"name\": \"write_file\",\n    \"arguments\": {\n        \"filename\"\
          : \"out.py\",\n        \"contents\": \"print('Hello, world')\"\n    }\n\
          }\n\nfunction_response: File 'out.py' written successfully.\n</code></pre>\n\
          <p>And here is the raw prompt I fed in (with functions). Note that this\
          \ format is for the v3 model (not the v2 model here):</p>\n<pre><code>&lt;\uFF5C\
          begin\u2581of\u2581sentence\uFF5C&gt;You have access to the following functions.\
          \ Use them if required:\n\n[\n    {\n        \"type\": \"function\",\n \
          \       \"function\": {\n            \"name\": \"write_file\",\n       \
          \     \"description\": \"Write a file, creating it if necessary. If the\
          \ file exists, it is overwritten.\",\n            \"parameters\": {\n  \
          \              \"type\": \"object\",\n                \"properties\": {\n\
          \                    \"filename\": {\n                        \"type\":\
          \ \"string\",\n                        \"description\": \"name of the file\"\
          \n                    },\n                    \"contents\": {\n        \
          \                \"type\": \"string\",\n                        \"description\"\
          : \"contents of the file\"\n                    }\n                },\n\
          \                \"required\": [\n                    \"filename\",\n  \
          \                  \"contents\"\n                ]\n            }\n    \
          \    }\n    }\n]\n\n### Instruction:\nWrite a python program to out.py to\
          \ print hello world\n### Response:\n</code></pre>\n"
        raw: "I should have said this before, but the [v3 version of this model](https://huggingface.co/Trelis/deepseek-coder-33b-instruct-function-calling-v3)\
          \ is now recommended. I have updated the model card (which I should have\
          \ before).\n\nI have also done some testing on the v3 model with your functions\
          \ and prompt. It works well.\n\nHere is a formatted version of the conversation\
          \ I had:\n```\nuser: Write a python program to out.py to print hello world\n\
          \nfunction_call: {\n    \"name\": \"write_file\",\n    \"arguments\": {\n\
          \        \"filename\": \"out.py\",\n        \"contents\": \"print('Hello,\
          \ world')\"\n    }\n}\n\nfunction_response: File 'out.py' written successfully.\n\
          ```\n\nAnd here is the raw prompt I fed in (with functions). Note that this\
          \ format is for the v3 model (not the v2 model here):\n```\n<\uFF5Cbegin\u2581\
          of\u2581sentence\uFF5C>You have access to the following functions. Use them\
          \ if required:\n\n[\n    {\n        \"type\": \"function\",\n        \"\
          function\": {\n            \"name\": \"write_file\",\n            \"description\"\
          : \"Write a file, creating it if necessary. If the file exists, it is overwritten.\"\
          ,\n            \"parameters\": {\n                \"type\": \"object\",\n\
          \                \"properties\": {\n                    \"filename\": {\n\
          \                        \"type\": \"string\",\n                       \
          \ \"description\": \"name of the file\"\n                    },\n      \
          \              \"contents\": {\n                        \"type\": \"string\"\
          ,\n                        \"description\": \"contents of the file\"\n \
          \                   }\n                },\n                \"required\"\
          : [\n                    \"filename\",\n                    \"contents\"\
          \n                ]\n            }\n        }\n    }\n]\n\n### Instruction:\n\
          Write a python program to out.py to print hello world\n### Response:\n```"
        updatedAt: '2024-01-17T12:50:56.765Z'
      numEdits: 0
      reactions: []
    id: 65a7cd30ae3bd1cc03875f2d
    type: comment
  author: RonanMcGovern
  content: "I should have said this before, but the [v3 version of this model](https://huggingface.co/Trelis/deepseek-coder-33b-instruct-function-calling-v3)\
    \ is now recommended. I have updated the model card (which I should have before).\n\
    \nI have also done some testing on the v3 model with your functions and prompt.\
    \ It works well.\n\nHere is a formatted version of the conversation I had:\n```\n\
    user: Write a python program to out.py to print hello world\n\nfunction_call:\
    \ {\n    \"name\": \"write_file\",\n    \"arguments\": {\n        \"filename\"\
    : \"out.py\",\n        \"contents\": \"print('Hello, world')\"\n    }\n}\n\nfunction_response:\
    \ File 'out.py' written successfully.\n```\n\nAnd here is the raw prompt I fed\
    \ in (with functions). Note that this format is for the v3 model (not the v2 model\
    \ here):\n```\n<\uFF5Cbegin\u2581of\u2581sentence\uFF5C>You have access to the\
    \ following functions. Use them if required:\n\n[\n    {\n        \"type\": \"\
    function\",\n        \"function\": {\n            \"name\": \"write_file\",\n\
    \            \"description\": \"Write a file, creating it if necessary. If the\
    \ file exists, it is overwritten.\",\n            \"parameters\": {\n        \
    \        \"type\": \"object\",\n                \"properties\": {\n          \
    \          \"filename\": {\n                        \"type\": \"string\",\n  \
    \                      \"description\": \"name of the file\"\n               \
    \     },\n                    \"contents\": {\n                        \"type\"\
    : \"string\",\n                        \"description\": \"contents of the file\"\
    \n                    }\n                },\n                \"required\": [\n\
    \                    \"filename\",\n                    \"contents\"\n       \
    \         ]\n            }\n        }\n    }\n]\n\n### Instruction:\nWrite a python\
    \ program to out.py to print hello world\n### Response:\n```"
  created_at: 2024-01-17 12:50:56+00:00
  edited: false
  hidden: false
  id: 65a7cd30ae3bd1cc03875f2d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2024-01-17T12:54:26.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2797383964061737
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>add a note on chat_template</p>

          '
        raw: add a note on chat_template
        updatedAt: '2024-01-17T12:54:26.400Z'
      numEdits: 0
      reactions: []
    id: 65a7ce02f0f30f7eeaae5efd
    type: comment
  author: RonanMcGovern
  content: add a note on chat_template
  created_at: 2024-01-17 12:54:26+00:00
  edited: false
  hidden: false
  id: 65a7ce02f0f30f7eeaae5efd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Trelis/deepseek-coder-33b-instruct-function-calling-v2
repo_type: model
status: open
target_branch: null
title: Model issue about code generation
