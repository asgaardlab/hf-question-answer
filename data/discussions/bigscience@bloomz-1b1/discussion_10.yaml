!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Yuxin715d
conflicting_files: null
created_at: 2023-10-18 15:39:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/47a812d990c6a46be5f0d19deefbb67d.svg
      fullname: Yuxin Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yuxin715d
      type: user
    createdAt: '2023-10-18T16:39:23.000Z'
    data:
      edited: false
      editors:
      - Yuxin715d
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8458819389343262
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/47a812d990c6a46be5f0d19deefbb67d.svg
          fullname: Yuxin Chen
          isHf: false
          isPro: false
          name: Yuxin715d
          type: user
        html: '<p>Hi, I downloaded weights from this repo and tried to evaluate this
          model on humaneval benchmark. But when complete the code in humaneval dataset,
          something abnormal happened.<br>Here is one example:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/xTIkEZvrEj4GOXASqd8_r.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/xTIkEZvrEj4GOXASqd8_r.png"></a><br>Code
          before "return (numbers.count(threshold) &gt; 0)" is prompt given, and this
          return statement is generated by this model. I can understand if model give
          wrong code, but the werid part is its first line indent is 5, not 4. And
          I generated 20 times for each prompt in humaneval datasets. All of them
          first line indent is 5 which is wrong. Also, other lines indent is correct
          except first line.<br>I am confused by the result. This is code I used:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/gLgwYQHP-0rbZl99nZ-A7.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/gLgwYQHP-0rbZl99nZ-A7.png"></a></p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/oHSM7K2PYITVQJZqPahlC.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/oHSM7K2PYITVQJZqPahlC.png"></a><br>Prompt
          here means prompt in humaneval datasets, just as I say above.<br>Do you
          have ideas on that? Did I do something wrong which bring this result? Thanks
          in advance!</p>

          '
        raw: "Hi, I downloaded weights from this repo and tried to evaluate this model\
          \ on humaneval benchmark. But when complete the code in humaneval dataset,\
          \ something abnormal happened.\r\nHere is one example:\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/xTIkEZvrEj4GOXASqd8_r.png)\r\
          \nCode before \"return (numbers.count(threshold) > 0)\" is prompt given,\
          \ and this return statement is generated by this model. I can understand\
          \ if model give wrong code, but the werid part is its first line indent\
          \ is 5, not 4. And I generated 20 times for each prompt in humaneval datasets.\
          \ All of them first line indent is 5 which is wrong. Also, other lines indent\
          \ is correct except first line.\r\nI am confused by the result. This is\
          \ code I used:\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/gLgwYQHP-0rbZl99nZ-A7.png)\r\
          \n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/oHSM7K2PYITVQJZqPahlC.png)\r\
          \nPrompt here means prompt in humaneval datasets, just as I say above. \r\
          \nDo you have ideas on that? Did I do something wrong which bring this result?\
          \ Thanks in advance!"
        updatedAt: '2023-10-18T16:39:23.716Z'
      numEdits: 0
      reactions: []
    id: 65300a3b01a1a4ee2772476d
    type: comment
  author: Yuxin715d
  content: "Hi, I downloaded weights from this repo and tried to evaluate this model\
    \ on humaneval benchmark. But when complete the code in humaneval dataset, something\
    \ abnormal happened.\r\nHere is one example:\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/xTIkEZvrEj4GOXASqd8_r.png)\r\
    \nCode before \"return (numbers.count(threshold) > 0)\" is prompt given, and this\
    \ return statement is generated by this model. I can understand if model give\
    \ wrong code, but the werid part is its first line indent is 5, not 4. And I generated\
    \ 20 times for each prompt in humaneval datasets. All of them first line indent\
    \ is 5 which is wrong. Also, other lines indent is correct except first line.\r\
    \nI am confused by the result. This is code I used:\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/gLgwYQHP-0rbZl99nZ-A7.png)\r\
    \n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64c2757128cc6b6edf564f64/oHSM7K2PYITVQJZqPahlC.png)\r\
    \nPrompt here means prompt in humaneval datasets, just as I say above. \r\nDo\
    \ you have ideas on that? Did I do something wrong which bring this result? Thanks\
    \ in advance!"
  created_at: 2023-10-18 15:39:23+00:00
  edited: false
  hidden: false
  id: 65300a3b01a1a4ee2772476d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2023-10-18T16:54:39.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8080700635910034
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<p>Are you stripping the humaneval prompt from the right side? I.e.
          <code>prompt.strip()</code> to make sure it ends exactly with <code>"""</code></p>

          '
        raw: Are you stripping the humaneval prompt from the right side? I.e. `prompt.strip()`
          to make sure it ends exactly with `"""`
        updatedAt: '2023-10-18T16:54:39.327Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Yuxin715d
    id: 65300dcfd849382d55537f70
    type: comment
  author: Muennighoff
  content: Are you stripping the humaneval prompt from the right side? I.e. `prompt.strip()`
    to make sure it ends exactly with `"""`
  created_at: 2023-10-18 15:54:39+00:00
  edited: false
  hidden: false
  id: 65300dcfd849382d55537f70
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/47a812d990c6a46be5f0d19deefbb67d.svg
      fullname: Yuxin Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yuxin715d
      type: user
    createdAt: '2023-10-19T03:56:05.000Z'
    data:
      edited: false
      editors:
      - Yuxin715d
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7250329852104187
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/47a812d990c6a46be5f0d19deefbb67d.svg
          fullname: Yuxin Chen
          isHf: false
          isPro: false
          name: Yuxin715d
          type: user
        html: '<p>The prompt I used is:</p>

          <p> ''from typing import List\n\n\ndef has_close_elements(numbers: List[float],
          threshold: float) -&gt; bool:\n    """ Check if in given list of numbers,
          are any two numbers closer to each other than\n    given threshold.\n    &gt;&gt;&gt;
          has_close_elements([1.0, 2.0, 3.0], 0.5)\n    False\n    &gt;&gt;&gt; has_close_elements([1.0,
          2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n    True\n    """\n''. </p>

          <p>There is a ''\n'' at the right side. After using prompt.strip() to delete
          ''\n'' at the right side. Its indent is correct.<br>Thanks for your help!
          BTW, do you know why this happens? In my thought, ''\n'' at the end of code
          prompt won''t affect completion.</p>

          '
        raw: "The prompt I used is:\n\n 'from typing import List\\n\\n\\ndef has_close_elements(numbers:\
          \ List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given\
          \ list of numbers, are any two numbers closer to each other than\\n    given\
          \ threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\\
          n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\\
          n    \"\"\"\\n'. \n\nThere is a '\\n' at the right side. After using prompt.strip()\
          \ to delete '\\n' at the right side. Its indent is correct.\nThanks for\
          \ your help! BTW, do you know why this happens? In my thought, '\\n' at\
          \ the end of code prompt won't affect completion."
        updatedAt: '2023-10-19T03:56:05.966Z'
      numEdits: 0
      reactions: []
    id: 6530a8d5944086d1d51215f1
    type: comment
  author: Yuxin715d
  content: "The prompt I used is:\n\n 'from typing import List\\n\\n\\ndef has_close_elements(numbers:\
    \ List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list\
    \ of numbers, are any two numbers closer to each other than\\n    given threshold.\\\
    n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0,\
    \ 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n'. \n\nThere is a '\\\
    n' at the right side. After using prompt.strip() to delete '\\n' at the right\
    \ side. Its indent is correct.\nThanks for your help! BTW, do you know why this\
    \ happens? In my thought, '\\n' at the end of code prompt won't affect completion."
  created_at: 2023-10-19 02:56:05+00:00
  edited: false
  hidden: false
  id: 6530a8d5944086d1d51215f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
      fullname: Niklas Muennighoff
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Muennighoff
      type: user
    createdAt: '2023-10-19T04:21:48.000Z'
    data:
      edited: false
      editors:
      - Muennighoff
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.892560601234436
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1659799717718-5f1eb362eec0ad2a071ad6e2.jpeg?w=200&h=200&f=face
          fullname: Niklas Muennighoff
          isHf: false
          isPro: false
          name: Muennighoff
          type: user
        html: '<p>It''s a tokenization problem. When you provide an instruction you
          want to make sure that if you''re expected answer were to directly follow
          the instruction there is a clear token separation.<br>E.g. if you tokenize<br><code>...4.0,
          5.0, 2.0], 0.3)\n True\n """\n    return (numbers...</code></p>

          <p>You will see that it splits the tokens to sth like ...<code>\n"""</code>,
          <code>\n    </code>, <code>return </code>... ; So you want to make sure
          your instruction ends right after <code>\n"""</code> so it can produce the
          next natural token <code>\n    </code>. Otherwise, you offset its distribution
          leading to generation problems.</p>

          '
        raw: 'It''s a tokenization problem. When you provide an instruction you want
          to make sure that if you''re expected answer were to directly follow the
          instruction there is a clear token separation.

          E.g. if you tokenize

          `...4.0, 5.0, 2.0], 0.3)\n True\n """\n    return (numbers...`


          You will see that it splits the tokens to sth like ...`\n"""`, `\n    `,
          `return `... ; So you want to make sure your instruction ends right after
          `\n"""` so it can produce the next natural token `\n    `. Otherwise, you
          offset its distribution leading to generation problems.


          '
        updatedAt: '2023-10-19T04:21:48.013Z'
      numEdits: 0
      reactions: []
    id: 6530aedc70a88b63f009c990
    type: comment
  author: Muennighoff
  content: 'It''s a tokenization problem. When you provide an instruction you want
    to make sure that if you''re expected answer were to directly follow the instruction
    there is a clear token separation.

    E.g. if you tokenize

    `...4.0, 5.0, 2.0], 0.3)\n True\n """\n    return (numbers...`


    You will see that it splits the tokens to sth like ...`\n"""`, `\n    `, `return
    `... ; So you want to make sure your instruction ends right after `\n"""` so it
    can produce the next natural token `\n    `. Otherwise, you offset its distribution
    leading to generation problems.


    '
  created_at: 2023-10-19 03:21:48+00:00
  edited: false
  hidden: false
  id: 6530aedc70a88b63f009c990
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/47a812d990c6a46be5f0d19deefbb67d.svg
      fullname: Yuxin Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yuxin715d
      type: user
    createdAt: '2023-10-19T05:03:03.000Z'
    data:
      edited: false
      editors:
      - Yuxin715d
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9739341139793396
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/47a812d990c6a46be5f0d19deefbb67d.svg
          fullname: Yuxin Chen
          isHf: false
          isPro: false
          name: Yuxin715d
          type: user
        html: '<p>Got it! Thanks for your reply.</p>

          '
        raw: Got it! Thanks for your reply.
        updatedAt: '2023-10-19T05:03:03.982Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6530b8888e4767ecfe2a9382
    id: 6530b8878e4767ecfe2a937e
    type: comment
  author: Yuxin715d
  content: Got it! Thanks for your reply.
  created_at: 2023-10-19 04:03:03+00:00
  edited: false
  hidden: false
  id: 6530b8878e4767ecfe2a937e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/47a812d990c6a46be5f0d19deefbb67d.svg
      fullname: Yuxin Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yuxin715d
      type: user
    createdAt: '2023-10-19T05:03:04.000Z'
    data:
      status: closed
    id: 6530b8888e4767ecfe2a9382
    type: status-change
  author: Yuxin715d
  created_at: 2023-10-19 04:03:04+00:00
  id: 6530b8888e4767ecfe2a9382
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: bigscience/bloomz-1b1
repo_type: model
status: closed
target_branch: null
title: Abnormal indent when complete the code
