!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nayohan
conflicting_files: null
created_at: 2023-11-29 04:21:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6152b4b9ecf3ca6ab820e325/zjdCIuHFGY7TZGPHDT0Un.jpeg?w=200&h=200&f=face
      fullname: Yohan Na
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nayohan
      type: user
    createdAt: '2023-11-29T04:21:50.000Z'
    data:
      edited: true
      editors:
      - nayohan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7813302278518677
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6152b4b9ecf3ca6ab820e325/zjdCIuHFGY7TZGPHDT0Un.jpeg?w=200&h=200&f=face
          fullname: Yohan Na
          isHf: false
          isPro: false
          name: nayohan
          type: user
        html: "<p>Hello, I encountered the following problem while loading the tokenizer.</p>\n\
          <pre><code>save_llama = ['lcw99/zephykor-ko-beta-7b-chang']\nfor model_name\
          \ in save_llama:\n    save_model_name = model_name.split('/')[-1]\n    print('save_model_name:',\
          \ save_model_name)\n    \n    tokenizer = LlamaTokenizer.from_pretrained(model_name)\n\
          \    tokenizer.save_pretrained(f\"{save_path}/{save_model_name}\")\n   \
          \ \n    model = AutoModel.from_pretrained(model_name)\n    model.save_pretrained(f\"\
          {save_path}/{save_model_name}\")\n</code></pre>\n<pre><code>save_model_name:\
          \ zephykor-ko-beta-7b-chang\nTraceback (most recent call last):\n  File\
          \ \"/home/closedai/.test/hybrid-ltm/src/download_model.py\", line 35, in\
          \ &lt;module&gt;\n    tokenizer = LlamaTokenizer.from_pretrained(model_name,\
          \ use_fast=True)\n  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2024, in from_pretrained\n    return cls._from_pretrained(\n  File\
          \ \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2256, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py\"\
          , line 178, in __init__\n    self.sp_model = self.get_spm_processor(kwargs.pop(\"\
          from_slow\", False))\n  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py\"\
          , line 203, in get_spm_processor\n    tokenizer.Load(self.vocab_file)\n\
          \  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/sentencepiece/__init__.py\"\
          , line 905, in Load\n    return self.LoadFromFile(model_file)\n  File \"\
          /home/closedai/.conda/envs/sent/lib/python3.10/site-packages/sentencepiece/__init__.py\"\
          , line 310, in LoadFromFile\n    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
          \ arg)\nTypeError: not a string\n</code></pre>\n<p>I think the tokenizer.model\
          \ file wasn't uploaded or is there anything I did wrong? The model loads\
          \ fine.</p>\n"
        raw: "Hello, I encountered the following problem while loading the tokenizer.\n\
          \n```\nsave_llama = ['lcw99/zephykor-ko-beta-7b-chang']\nfor model_name\
          \ in save_llama:\n    save_model_name = model_name.split('/')[-1]\n    print('save_model_name:',\
          \ save_model_name)\n    \n    tokenizer = LlamaTokenizer.from_pretrained(model_name)\n\
          \    tokenizer.save_pretrained(f\"{save_path}/{save_model_name}\")\n   \
          \ \n    model = AutoModel.from_pretrained(model_name)\n    model.save_pretrained(f\"\
          {save_path}/{save_model_name}\")\n```\n\n```\nsave_model_name: zephykor-ko-beta-7b-chang\n\
          Traceback (most recent call last):\n  File \"/home/closedai/.test/hybrid-ltm/src/download_model.py\"\
          , line 35, in <module>\n    tokenizer = LlamaTokenizer.from_pretrained(model_name,\
          \ use_fast=True)\n  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2024, in from_pretrained\n    return cls._from_pretrained(\n  File\
          \ \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
          , line 2256, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
          \  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py\"\
          , line 178, in __init__\n    self.sp_model = self.get_spm_processor(kwargs.pop(\"\
          from_slow\", False))\n  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py\"\
          , line 203, in get_spm_processor\n    tokenizer.Load(self.vocab_file)\n\
          \  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/sentencepiece/__init__.py\"\
          , line 905, in Load\n    return self.LoadFromFile(model_file)\n  File \"\
          /home/closedai/.conda/envs/sent/lib/python3.10/site-packages/sentencepiece/__init__.py\"\
          , line 310, in LoadFromFile\n    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
          \ arg)\nTypeError: not a string\n```\n\nI think the tokenizer.model file\
          \ wasn't uploaded or is there anything I did wrong? The model loads fine."
        updatedAt: '2023-11-29T04:33:27.811Z'
      numEdits: 8
      reactions: []
    id: 6566bc5e93e30c8a60fcafe0
    type: comment
  author: nayohan
  content: "Hello, I encountered the following problem while loading the tokenizer.\n\
    \n```\nsave_llama = ['lcw99/zephykor-ko-beta-7b-chang']\nfor model_name in save_llama:\n\
    \    save_model_name = model_name.split('/')[-1]\n    print('save_model_name:',\
    \ save_model_name)\n    \n    tokenizer = LlamaTokenizer.from_pretrained(model_name)\n\
    \    tokenizer.save_pretrained(f\"{save_path}/{save_model_name}\")\n    \n   \
    \ model = AutoModel.from_pretrained(model_name)\n    model.save_pretrained(f\"\
    {save_path}/{save_model_name}\")\n```\n\n```\nsave_model_name: zephykor-ko-beta-7b-chang\n\
    Traceback (most recent call last):\n  File \"/home/closedai/.test/hybrid-ltm/src/download_model.py\"\
    , line 35, in <module>\n    tokenizer = LlamaTokenizer.from_pretrained(model_name,\
    \ use_fast=True)\n  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2024, in from_pretrained\n    return cls._from_pretrained(\n  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/tokenization_utils_base.py\"\
    , line 2256, in _from_pretrained\n    tokenizer = cls(*init_inputs, **init_kwargs)\n\
    \  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py\"\
    , line 178, in __init__\n    self.sp_model = self.get_spm_processor(kwargs.pop(\"\
    from_slow\", False))\n  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py\"\
    , line 203, in get_spm_processor\n    tokenizer.Load(self.vocab_file)\n  File\
    \ \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/sentencepiece/__init__.py\"\
    , line 905, in Load\n    return self.LoadFromFile(model_file)\n  File \"/home/closedai/.conda/envs/sent/lib/python3.10/site-packages/sentencepiece/__init__.py\"\
    , line 310, in LoadFromFile\n    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self,\
    \ arg)\nTypeError: not a string\n```\n\nI think the tokenizer.model file wasn't\
    \ uploaded or is there anything I did wrong? The model loads fine."
  created_at: 2023-11-29 04:21:50+00:00
  edited: true
  hidden: false
  id: 6566bc5e93e30c8a60fcafe0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663998371708-62e5ba37a944e2a56cd9227c.jpeg?w=200&h=200&f=face
      fullname: Chang W Lee
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lcw99
      type: user
    createdAt: '2023-11-29T04:39:10.000Z'
    data:
      edited: false
      editors:
      - lcw99
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5003310441970825
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663998371708-62e5ba37a944e2a56cd9227c.jpeg?w=200&h=200&f=face
          fullname: Chang W Lee
          isHf: false
          isPro: false
          name: lcw99
          type: user
        html: '<p>try AutoTokenizer.</p>

          '
        raw: try AutoTokenizer.
        updatedAt: '2023-11-29T04:39:10.977Z'
      numEdits: 0
      reactions: []
    id: 6566c06e9450460026deb9a7
    type: comment
  author: lcw99
  content: try AutoTokenizer.
  created_at: 2023-11-29 04:39:10+00:00
  edited: false
  hidden: false
  id: 6566c06e9450460026deb9a7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6152b4b9ecf3ca6ab820e325/zjdCIuHFGY7TZGPHDT0Un.jpeg?w=200&h=200&f=face
      fullname: Yohan Na
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nayohan
      type: user
    createdAt: '2023-11-29T04:55:42.000Z'
    data:
      edited: false
      editors:
      - nayohan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9687130451202393
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6152b4b9ecf3ca6ab820e325/zjdCIuHFGY7TZGPHDT0Un.jpeg?w=200&h=200&f=face
          fullname: Yohan Na
          isHf: false
          isPro: false
          name: nayohan
          type: user
        html: '<p>Changing to AutoTokenizer solved the problem very easily. Thank
          you! I''ll give it a try :)</p>

          '
        raw: Changing to AutoTokenizer solved the problem very easily. Thank you!
          I'll give it a try :)
        updatedAt: '2023-11-29T04:55:42.840Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6566c44e47b037bd21e727a2
    id: 6566c44e47b037bd21e727a0
    type: comment
  author: nayohan
  content: Changing to AutoTokenizer solved the problem very easily. Thank you! I'll
    give it a try :)
  created_at: 2023-11-29 04:55:42+00:00
  edited: false
  hidden: false
  id: 6566c44e47b037bd21e727a0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6152b4b9ecf3ca6ab820e325/zjdCIuHFGY7TZGPHDT0Un.jpeg?w=200&h=200&f=face
      fullname: Yohan Na
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nayohan
      type: user
    createdAt: '2023-11-29T04:55:42.000Z'
    data:
      status: closed
    id: 6566c44e47b037bd21e727a2
    type: status-change
  author: nayohan
  created_at: 2023-11-29 04:55:42+00:00
  id: 6566c44e47b037bd21e727a2
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: lcw99/zephykor-ko-beta-7b-chang
repo_type: model
status: closed
target_branch: null
title: Problem loading the tokenizer.
