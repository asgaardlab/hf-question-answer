!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SebaGPDev
conflicting_files: null
created_at: 2023-10-17 13:26:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d6e3b08d0c1b02e98c8720c84ed7ab19.svg
      fullname: Sebastian Prieto
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SebaGPDev
      type: user
    createdAt: '2023-10-17T14:26:56.000Z'
    data:
      edited: false
      editors:
      - SebaGPDev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7023723125457764
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d6e3b08d0c1b02e98c8720c84ed7ab19.svg
          fullname: Sebastian Prieto
          isHf: false
          isPro: false
          name: SebaGPDev
          type: user
        html: '<p>I use the model with ollama and langchain uses its example code:
          "<a rel="nofollow" href="https://github.com/nexusflowai/NexusRaven/blob/main/scripts/langchain_example.py">https://github.com/nexusflowai/NexusRaven/blob/main/scripts/langchain_example.py</a>",
          but as a consolation I see this error: ValueError: An output parsing error
          occurred. To return this error to the agent and have it try again, pass
          <code>handle_parsing_errors=True</code> to the AgentExecutor. This is the
          error: Could not parse the output of LLM: `calculator(11.22, 33.333), (''add'',
          ''add'', ''add'')).<br>What could I do? Or what would be the mistake? thank
          you so much</p>

          <p>Code here:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/645c47736ff46332e7560b30/s8GzeqQjLhOWmBcreIylS.png"><img
          alt="app.png" src="https://cdn-uploads.huggingface.co/production/uploads/645c47736ff46332e7560b30/s8GzeqQjLhOWmBcreIylS.png"></a></p>

          '
        raw: "I use the model with ollama and langchain uses its example code: \"\
          [https://github.com/nexusflowai/NexusRaven/blob/main/scripts/langchain_example.py](https://github.com/nexusflowai/NexusRaven/blob/main/scripts/langchain_example.py)\"\
          , but as a consolation I see this error: ValueError: An output parsing error\
          \ occurred. To return this error to the agent and have it try again, pass\
          \ `handle_parsing_errors=True` to the AgentExecutor. This is the error:\
          \ Could not parse the output of LLM: `calculator(11.22, 33.333), ('add',\
          \ 'add', 'add')). \r\nWhat could I do? Or what would be the mistake? thank\
          \ you so much\r\n\r\nCode here:\r\n\r\n![app.png](https://cdn-uploads.huggingface.co/production/uploads/645c47736ff46332e7560b30/s8GzeqQjLhOWmBcreIylS.png)\r\
          \n"
        updatedAt: '2023-10-17T14:26:56.129Z'
      numEdits: 0
      reactions: []
    id: 652e99b07a8c08f81e4d2701
    type: comment
  author: SebaGPDev
  content: "I use the model with ollama and langchain uses its example code: \"[https://github.com/nexusflowai/NexusRaven/blob/main/scripts/langchain_example.py](https://github.com/nexusflowai/NexusRaven/blob/main/scripts/langchain_example.py)\"\
    , but as a consolation I see this error: ValueError: An output parsing error occurred.\
    \ To return this error to the agent and have it try again, pass `handle_parsing_errors=True`\
    \ to the AgentExecutor. This is the error: Could not parse the output of LLM:\
    \ `calculator(11.22, 33.333), ('add', 'add', 'add')). \r\nWhat could I do? Or\
    \ what would be the mistake? thank you so much\r\n\r\nCode here:\r\n\r\n![app.png](https://cdn-uploads.huggingface.co/production/uploads/645c47736ff46332e7560b30/s8GzeqQjLhOWmBcreIylS.png)\r\
    \n"
  created_at: 2023-10-17 13:26:56+00:00
  edited: false
  hidden: false
  id: 652e99b07a8c08f81e4d2701
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Nexusflow/NexusRaven-13B
repo_type: model
status: open
target_branch: null
title: Ollama
