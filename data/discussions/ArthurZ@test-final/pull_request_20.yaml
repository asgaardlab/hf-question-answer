!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ArthurZ
conflicting_files: []
created_at: 2023-10-10 08:50:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-10T09:50:23.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7509826421737671
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Following the merge of <a rel="nofollow" href="https://github.com/huggingface/transformers/pull/24310">a
          PR</a> in <code>transformers</code> it appeared that this model was not
          properly converted. This PR will fix the inference and was tested using
          the following script:</p>

          <pre><code class="language-python"><span class="hljs-meta">&gt;&gt;&gt;
          </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span>
          MarianModel, MarianMTModel

          <span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span
          class="hljs-string">''Helsinki-NLP/opus-mt-tc-big-en-pt''</span>)

          <span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(Hey! Let<span
          class="hljs-string">''s learn together, return_tensors="pt", padding=True)</span>

          <span class="hljs-string">&gt;&gt;&gt; model = MarianMTModel.from_pretrained(Helsinki-NLP/opus-mt-tc-big-en-pt)</span>

          <span class="hljs-string">&gt;&gt;&gt; print(tokenizer.batch_decode(model.generate(**inputs)))</span>

          <span class="hljs-string">[''</span>&lt;pad&gt; Vamos aprender juntos&lt;/s&gt;<span
          class="hljs-string">'']</span>

          </code></pre>

          '
        raw: 'Following the merge of [a PR](https://github.com/huggingface/transformers/pull/24310)
          in `transformers` it appeared that this model was not properly converted.
          This PR will fix the inference and was tested using the following script:

          ```python

          >>> from transformers import MarianModel, MarianMTModel

          >>> tokenizer = AutoTokenizer.from_pretrained(''Helsinki-NLP/opus-mt-tc-big-en-pt'')

          >>> inputs = tokenizer(Hey! Let''s learn together, return_tensors="pt",
          padding=True)

          >>> model = MarianMTModel.from_pretrained(Helsinki-NLP/opus-mt-tc-big-en-pt)

          >>> print(tokenizer.batch_decode(model.generate(**inputs)))

          [''<pad> Vamos aprender juntos</s>'']

          ```'
        updatedAt: '2023-10-10T09:50:23.788Z'
      numEdits: 0
      reactions: []
    id: 65251e5f9738afe5c0236991
    type: comment
  author: ArthurZ
  content: 'Following the merge of [a PR](https://github.com/huggingface/transformers/pull/24310)
    in `transformers` it appeared that this model was not properly converted. This
    PR will fix the inference and was tested using the following script:

    ```python

    >>> from transformers import MarianModel, MarianMTModel

    >>> tokenizer = AutoTokenizer.from_pretrained(''Helsinki-NLP/opus-mt-tc-big-en-pt'')

    >>> inputs = tokenizer(Hey! Let''s learn together, return_tensors="pt", padding=True)

    >>> model = MarianMTModel.from_pretrained(Helsinki-NLP/opus-mt-tc-big-en-pt)

    >>> print(tokenizer.batch_decode(model.generate(**inputs)))

    [''<pad> Vamos aprender juntos</s>'']

    ```'
  created_at: 2023-10-10 08:50:23+00:00
  edited: false
  hidden: false
  id: 65251e5f9738afe5c0236991
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-10T09:50:24.000Z'
    data:
      oid: 30e99524da871db31b833a7238b5eb2f522dd07f
      parents:
      - 41a5f5e6ed795dd36815feb72d77512e23b12c06
      subject: Update checkpoint for transformers>=4.29
    id: 65251e600000000000000000
    type: commit
  author: ArthurZ
  created_at: 2023-10-10 08:50:24+00:00
  id: 65251e600000000000000000
  oid: 30e99524da871db31b833a7238b5eb2f522dd07f
  summary: Update checkpoint for transformers>=4.29
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-10T09:51:06.000Z'
    data:
      status: closed
    id: 65251e8ad28287cae3181788
    type: status-change
  author: ArthurZ
  created_at: 2023-10-10 08:51:06+00:00
  id: 65251e8ad28287cae3181788
  new_status: closed
  type: status-change
is_pull_request: true
merge_commit_oid: null
num: 20
repo_id: ArthurZ/test-final
repo_type: model
status: closed
target_branch: refs/heads/main
title: Update checkpoint for transformers>=4.29
