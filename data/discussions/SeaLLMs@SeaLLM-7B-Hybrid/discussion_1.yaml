!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dreamerdeo
conflicting_files: null
created_at: 2023-12-07 05:01:39+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676272806694-6214e4ee1e35c843d42d1f88.jpeg?w=200&h=200&f=face
      fullname: Longxu Dou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dreamerdeo
      type: user
    createdAt: '2023-12-07T05:01:39.000Z'
    data:
      edited: true
      editors:
      - dreamerdeo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6086541414260864
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676272806694-6214e4ee1e35c843d42d1f88.jpeg?w=200&h=200&f=face
          fullname: Longxu Dou
          isHf: false
          isPro: false
          name: dreamerdeo
          type: user
        html: '<p>First of all, thanks for your great work! </p>

          <p>When I attempt to predict, I encounter the following issues. </p>

          <pre><code>Some weights of LlamaForCausalLM were not initialized from the
          model checkpoint at SeaLLMs/SeaLLM-7B-Hybrid and are newly initialized:
          [''model.layers.19.self_attn.k_proj.weight'', ''model.layers.13.mlp.up_proj.weight'',
          ''model.layers.17.mlp.gate_proj.weight'', ''mode

          l.layers.0.self_attn.v_proj.weight'', ''model.layers.5.self_attn.k_proj.weight'',
          ''model.layers.1.self_attn.v_proj.weight'', ''model.layers.9.self_attn.k_proj.weight'',
          ''model.layers.9.mlp.gate_proj.weight'', ''model.layers.10.self_attn.q_proj.weight'',
          ''model.layers.24

          </code></pre>

          <p>The code is </p>

          <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer

          model = AutoModelForCausalLM.from_pretrained(''SeaLLMs/SeaLLM-7B-Hybrid'')

          </code></pre>

          <p>Could you give me a help? Thanks!</p>

          '
        raw: "First of all, thanks for your great work! \n\nWhen I attempt to predict,\
          \ I encounter the following issues. \n```\nSome weights of LlamaForCausalLM\
          \ were not initialized from the model checkpoint at SeaLLMs/SeaLLM-7B-Hybrid\
          \ and are newly initialized: ['model.layers.19.self_attn.k_proj.weight',\
          \ 'model.layers.13.mlp.up_proj.weight', 'model.layers.17.mlp.gate_proj.weight',\
          \ 'mode\nl.layers.0.self_attn.v_proj.weight', 'model.layers.5.self_attn.k_proj.weight',\
          \ 'model.layers.1.self_attn.v_proj.weight', 'model.layers.9.self_attn.k_proj.weight',\
          \ 'model.layers.9.mlp.gate_proj.weight', 'model.layers.10.self_attn.q_proj.weight',\
          \ 'model.layers.24\n```\nThe code is \n```\nfrom transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\nmodel = AutoModelForCausalLM.from_pretrained('SeaLLMs/SeaLLM-7B-Hybrid')\n\
          ```\n\nCould you give me a help? Thanks!"
        updatedAt: '2023-12-07T11:18:08.736Z'
      numEdits: 1
      reactions: []
    id: 657151b33100d869216f6a34
    type: comment
  author: dreamerdeo
  content: "First of all, thanks for your great work! \n\nWhen I attempt to predict,\
    \ I encounter the following issues. \n```\nSome weights of LlamaForCausalLM were\
    \ not initialized from the model checkpoint at SeaLLMs/SeaLLM-7B-Hybrid and are\
    \ newly initialized: ['model.layers.19.self_attn.k_proj.weight', 'model.layers.13.mlp.up_proj.weight',\
    \ 'model.layers.17.mlp.gate_proj.weight', 'mode\nl.layers.0.self_attn.v_proj.weight',\
    \ 'model.layers.5.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight',\
    \ 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.mlp.gate_proj.weight',\
    \ 'model.layers.10.self_attn.q_proj.weight', 'model.layers.24\n```\nThe code is\
    \ \n```\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nmodel =\
    \ AutoModelForCausalLM.from_pretrained('SeaLLMs/SeaLLM-7B-Hybrid')\n```\n\nCould\
    \ you give me a help? Thanks!"
  created_at: 2023-12-07 05:01:39+00:00
  edited: true
  hidden: false
  id: 657151b33100d869216f6a34
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acf4e9e0204a7ff7445aecc4102700cd.svg
      fullname: Phi Nguyen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nxphi47
      type: user
    createdAt: '2023-12-07T05:10:16.000Z'
    data:
      edited: false
      editors:
      - nxphi47
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9669495224952698
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acf4e9e0204a7ff7445aecc4102700cd.svg
          fullname: Phi Nguyen
          isHf: false
          isPro: false
          name: nxphi47
          type: user
        html: '<p>Thanks for your interest. It''s a bug, let me upload a patch.</p>

          '
        raw: Thanks for your interest. It's a bug, let me upload a patch.
        updatedAt: '2023-12-07T05:10:16.613Z'
      numEdits: 0
      reactions: []
    id: 657153b8f3853f99bc4b1172
    type: comment
  author: nxphi47
  content: Thanks for your interest. It's a bug, let me upload a patch.
  created_at: 2023-12-07 05:10:16+00:00
  edited: false
  hidden: false
  id: 657153b8f3853f99bc4b1172
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acf4e9e0204a7ff7445aecc4102700cd.svg
      fullname: Phi Nguyen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nxphi47
      type: user
    createdAt: '2023-12-07T06:41:39.000Z'
    data:
      edited: false
      editors:
      - nxphi47
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.42492130398750305
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acf4e9e0204a7ff7445aecc4102700cd.svg
          fullname: Phi Nguyen
          isHf: false
          isPro: false
          name: nxphi47
          type: user
        html: '<p>Fix. kindly download the latest revision</p>

          '
        raw: Fix. kindly download the latest revision
        updatedAt: '2023-12-07T06:41:39.009Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65716923f56f953867a633a5
    id: 65716923f56f953867a633a3
    type: comment
  author: nxphi47
  content: Fix. kindly download the latest revision
  created_at: 2023-12-07 06:41:39+00:00
  edited: false
  hidden: false
  id: 65716923f56f953867a633a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/acf4e9e0204a7ff7445aecc4102700cd.svg
      fullname: Phi Nguyen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nxphi47
      type: user
    createdAt: '2023-12-07T06:41:39.000Z'
    data:
      status: closed
    id: 65716923f56f953867a633a5
    type: status-change
  author: nxphi47
  created_at: 2023-12-07 06:41:39+00:00
  id: 65716923f56f953867a633a5
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676272806694-6214e4ee1e35c843d42d1f88.jpeg?w=200&h=200&f=face
      fullname: Longxu Dou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dreamerdeo
      type: user
    createdAt: '2023-12-07T11:16:05.000Z'
    data:
      edited: true
      editors:
      - dreamerdeo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5068943500518799
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676272806694-6214e4ee1e35c843d42d1f88.jpeg?w=200&h=200&f=face
          fullname: Longxu Dou
          isHf: false
          isPro: false
          name: dreamerdeo
          type: user
        html: "<p>Thanks for your fix. But when I re-run the code on <code>transformers==4.35.2</code>,\
          \ I still have the problem</p>\n<pre><code>from transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\nmodel = AutoModelForCausalLM.from_pretrained('SeaLLMs/SeaLLM-7B-Hybrid')\n\
          </code></pre>\n<p>The problem still exists</p>\n<pre><code>Traceback (most\
          \ recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n\
          \  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 566, in from_pretrained\n    return model_class.from_pretrained(\n\
          \  File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 3480, in from_pretrained\n    ) = cls._load_pretrained_model(\n \
          \ File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 3856, in _load_pretrained_model\n    state_dict = load_state_dict(shard_file)\n\
          \  File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 469, in load_state_dict\n    if metadata.get(\"format\") not in [\"\
          pt\", \"tf\", \"flax\"]:\nAttributeError: 'NoneType' object has no attribute\
          \ 'get'\n</code></pre>\n<p>Could you conduct a further check on this?<br>Thanks!</p>\n"
        raw: "Thanks for your fix. But when I re-run the code on `transformers==4.35.2`,\
          \ I still have the problem\n\n```\nfrom transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\nmodel = AutoModelForCausalLM.from_pretrained('SeaLLMs/SeaLLM-7B-Hybrid')\n\
          ```\n\nThe problem still exists\n```\nTraceback (most recent call last):\n\
          \  File \"<stdin>\", line 1, in <module>\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 566, in from_pretrained\n    return model_class.from_pretrained(\n\
          \  File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 3480, in from_pretrained\n    ) = cls._load_pretrained_model(\n \
          \ File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 3856, in _load_pretrained_model\n    state_dict = load_state_dict(shard_file)\n\
          \  File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
          , line 469, in load_state_dict\n    if metadata.get(\"format\") not in [\"\
          pt\", \"tf\", \"flax\"]:\nAttributeError: 'NoneType' object has no attribute\
          \ 'get'\n```\n\nCould you conduct a further check on this?\nThanks!"
        updatedAt: '2023-12-07T11:33:52.492Z'
      numEdits: 2
      reactions: []
    id: 6571a97563aa14eb56fc6f73
    type: comment
  author: dreamerdeo
  content: "Thanks for your fix. But when I re-run the code on `transformers==4.35.2`,\
    \ I still have the problem\n\n```\nfrom transformers import AutoModelForCausalLM,\
    \ AutoTokenizer\nmodel = AutoModelForCausalLM.from_pretrained('SeaLLMs/SeaLLM-7B-Hybrid')\n\
    ```\n\nThe problem still exists\n```\nTraceback (most recent call last):\n  File\
    \ \"<stdin>\", line 1, in <module>\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\"\
    , line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File\
    \ \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\",\
    \ line 3480, in from_pretrained\n    ) = cls._load_pretrained_model(\n  File \"\
    /opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\", line\
    \ 3856, in _load_pretrained_model\n    state_dict = load_state_dict(shard_file)\n\
    \  File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\"\
    , line 469, in load_state_dict\n    if metadata.get(\"format\") not in [\"pt\"\
    , \"tf\", \"flax\"]:\nAttributeError: 'NoneType' object has no attribute 'get'\n\
    ```\n\nCould you conduct a further check on this?\nThanks!"
  created_at: 2023-12-07 11:16:05+00:00
  edited: true
  hidden: false
  id: 6571a97563aa14eb56fc6f73
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e584bfe2f36a04e8e5e69cddfab020bc.svg
      fullname: Tan Yong Keat
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tanyongkeat
      type: user
    createdAt: '2023-12-08T10:23:13.000Z'
    data:
      edited: false
      editors:
      - tanyongkeat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9380595684051514
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e584bfe2f36a04e8e5e69cddfab020bc.svg
          fullname: Tan Yong Keat
          isHf: false
          isPro: false
          name: tanyongkeat
          type: user
        html: '<p>Hi, I am also getting the same problem as dreamerdeo, using transformers==4.31.0
          here</p>

          '
        raw: Hi, I am also getting the same problem as dreamerdeo, using transformers==4.31.0
          here
        updatedAt: '2023-12-08T10:23:13.555Z'
      numEdits: 0
      reactions: []
    id: 6572ee91b8102609d54f8194
    type: comment
  author: tanyongkeat
  content: Hi, I am also getting the same problem as dreamerdeo, using transformers==4.31.0
    here
  created_at: 2023-12-08 10:23:13+00:00
  edited: false
  hidden: false
  id: 6572ee91b8102609d54f8194
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: SeaLLMs/SeaLLM-7B-Hybrid
repo_type: model
status: closed
target_branch: null
title: Some weights were not initialized
