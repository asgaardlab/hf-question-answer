!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dcalsky
conflicting_files: null
created_at: 2023-11-17 06:27:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/36a449f67bdfffb414fe4afb72fd7356.svg
      fullname: kk
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dcalsky
      type: user
    createdAt: '2023-11-17T06:27:43.000Z'
    data:
      edited: false
      editors:
      - dcalsky
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8492036461830139
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/36a449f67bdfffb414fe4afb72fd7356.svg
          fullname: kk
          isHf: false
          isPro: false
          name: dcalsky
          type: user
        html: '<p>I used the CrossEncoder in sentence_transformers package and code
          is following, but the result seems not exactly as same as the result from
          Inference API (provided by huggingface model card).</p>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          sentence_transformers <span class="hljs-keyword">import</span> CrossEncoder

          model = CrossEncoder(<span class="hljs-string">''./gte-large-zh''</span>,
          max_length=<span class="hljs-number">512</span>)

          scores = model.predict([(<span class="hljs-string">''That is a happy person''</span>,
          <span class="hljs-string">''That is a happy dog''</span>), (<span class="hljs-string">''That
          is a happy person''</span>, <span class="hljs-string">''That is a very happy
          person''</span>) , (<span class="hljs-string">''That is a happy person''</span>,
          <span class="hljs-string">''Today is a sunny day''</span>)], show_progress_bar=<span
          class="hljs-literal">True</span>)

          <span class="hljs-built_in">print</span>(scores)

          </code></pre>

          <p>And It also comes up some warning: </p>

          <pre><code>Some weights of BertForSequenceClassification were not initialized
          from the model checkpoint at ./gte-large-zh and are newly initialized: [''classifier.weight'',
          ''classifier.bias'']

          You should probably TRAIN this model on a down-stream task to be able to
          use it for predictions and inference.

          </code></pre>

          <p>my result: </p>

          <pre><code>[0.3533868  0.41155243 0.3988041 ]

          </code></pre>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6356ddcfd1827617173659a0/7Xb4fvEeANiBoOvMrA6OF.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6356ddcfd1827617173659a0/7Xb4fvEeANiBoOvMrA6OF.png"></a></p>

          '
        raw: "I used the CrossEncoder in sentence_transformers package and code is\
          \ following, but the result seems not exactly as same as the result from\
          \ Inference API (provided by huggingface model card).\r\n\r\n```python\r\
          \nfrom sentence_transformers import CrossEncoder\r\nmodel = CrossEncoder('./gte-large-zh',\
          \ max_length=512)\r\nscores = model.predict([('That is a happy person',\
          \ 'That is a happy dog'), ('That is a happy person', 'That is a very happy\
          \ person') , ('That is a happy person', 'Today is a sunny day')], show_progress_bar=True)\r\
          \nprint(scores)\r\n```\r\n\r\nAnd It also comes up some warning: \r\n```\r\
          \nSome weights of BertForSequenceClassification were not initialized from\
          \ the model checkpoint at ./gte-large-zh and are newly initialized: ['classifier.weight',\
          \ 'classifier.bias']\r\nYou should probably TRAIN this model on a down-stream\
          \ task to be able to use it for predictions and inference.\r\n```\r\n\r\n\
          my result: \r\n```\r\n[0.3533868  0.41155243 0.3988041 ]\r\n```\r\n\r\n\
          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/6356ddcfd1827617173659a0/7Xb4fvEeANiBoOvMrA6OF.png)\r\
          \n\r\n\r\n"
        updatedAt: '2023-11-17T06:27:43.875Z'
      numEdits: 0
      reactions: []
    id: 655707df55c514dc592aea9b
    type: comment
  author: dcalsky
  content: "I used the CrossEncoder in sentence_transformers package and code is following,\
    \ but the result seems not exactly as same as the result from Inference API (provided\
    \ by huggingface model card).\r\n\r\n```python\r\nfrom sentence_transformers import\
    \ CrossEncoder\r\nmodel = CrossEncoder('./gte-large-zh', max_length=512)\r\nscores\
    \ = model.predict([('That is a happy person', 'That is a happy dog'), ('That is\
    \ a happy person', 'That is a very happy person') , ('That is a happy person',\
    \ 'Today is a sunny day')], show_progress_bar=True)\r\nprint(scores)\r\n```\r\n\
    \r\nAnd It also comes up some warning: \r\n```\r\nSome weights of BertForSequenceClassification\
    \ were not initialized from the model checkpoint at ./gte-large-zh and are newly\
    \ initialized: ['classifier.weight', 'classifier.bias']\r\nYou should probably\
    \ TRAIN this model on a down-stream task to be able to use it for predictions\
    \ and inference.\r\n```\r\n\r\nmy result: \r\n```\r\n[0.3533868  0.41155243 0.3988041\
    \ ]\r\n```\r\n\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6356ddcfd1827617173659a0/7Xb4fvEeANiBoOvMrA6OF.png)\r\
    \n\r\n\r\n"
  created_at: 2023-11-17 06:27:43+00:00
  edited: false
  hidden: false
  id: 655707df55c514dc592aea9b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf5c04a6032709f35e3fb48e1be6976f.svg
      fullname: Dingkun Long
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: thenlper
      type: user
    createdAt: '2023-11-21T11:09:11.000Z'
    data:
      edited: false
      editors:
      - thenlper
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7800169587135315
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf5c04a6032709f35e3fb48e1be6976f.svg
          fullname: Dingkun Long
          isHf: false
          isPro: false
          name: thenlper
          type: user
        html: '<p>GTE is a text representation model, not a cross-encoder model structure,
          so CrossEncoder cannot be used to load the model.</p>

          '
        raw: GTE is a text representation model, not a cross-encoder model structure,
          so CrossEncoder cannot be used to load the model.
        updatedAt: '2023-11-21T11:09:11.991Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - dcalsky
    id: 655c8fd7651cba34a2b48db2
    type: comment
  author: thenlper
  content: GTE is a text representation model, not a cross-encoder model structure,
    so CrossEncoder cannot be used to load the model.
  created_at: 2023-11-21 11:09:11+00:00
  edited: false
  hidden: false
  id: 655c8fd7651cba34a2b48db2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: thenlper/gte-large-zh
repo_type: model
status: open
target_branch: null
title: Any example for cross-encoding?
