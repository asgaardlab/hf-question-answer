!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MrNewman
conflicting_files: null
created_at: 2023-10-02 14:51:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/59eb16a7c3f601d111680fd85a3c4894.svg
      fullname: Benjamin Bogan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MrNewman
      type: user
    createdAt: '2023-10-02T15:51:48.000Z'
    data:
      edited: false
      editors:
      - MrNewman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.863735556602478
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/59eb16a7c3f601d111680fd85a3c4894.svg
          fullname: Benjamin Bogan
          isHf: false
          isPro: false
          name: MrNewman
          type: user
        html: '<p>I''m using Q5_K_M with langchain''s llamacpp. After about 25 words
          the output infinite loops on either a phrase word or character (the next
          file the next file the next file the next file, set  set  set  set  set  set  set,
          pythonnnnnnnnnnnnnnnnnnnnn)</p>

          <p>Doesn''t seem to be effected by context length, top_p, top_k, temperature.
          The Q8_0 behaves the same. Anyone else having this issue?</p>

          '
        raw: "I'm using Q5_K_M with langchain's llamacpp. After about 25 words the\
          \ output infinite loops on either a phrase word or character (the next file\
          \ the next file the next file the next file, set  set  set  set  set  set\
          \  set, pythonnnnnnnnnnnnnnnnnnnnn)\r\n\r\nDoesn't seem to be effected by\
          \ context length, top_p, top_k, temperature. The Q8_0 behaves the same.\
          \ Anyone else having this issue?"
        updatedAt: '2023-10-02T15:51:48.650Z'
      numEdits: 0
      reactions: []
    id: 651ae714ad1196196510f38f
    type: comment
  author: MrNewman
  content: "I'm using Q5_K_M with langchain's llamacpp. After about 25 words the output\
    \ infinite loops on either a phrase word or character (the next file the next\
    \ file the next file the next file, set  set  set  set  set  set  set, pythonnnnnnnnnnnnnnnnnnnnn)\r\
    \n\r\nDoesn't seem to be effected by context length, top_p, top_k, temperature.\
    \ The Q8_0 behaves the same. Anyone else having this issue?"
  created_at: 2023-10-02 14:51:48+00:00
  edited: false
  hidden: false
  id: 651ae714ad1196196510f38f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/545924c0549cfde9d5ab6ec4f38a6d3c.svg
      fullname: Daniel Busenius
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Dbone
      type: user
    createdAt: '2023-10-10T21:47:21.000Z'
    data:
      edited: false
      editors:
      - Dbone
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9063549041748047
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/545924c0549cfde9d5ab6ec4f38a6d3c.svg
          fullname: Daniel Busenius
          isHf: false
          isPro: false
          name: Dbone
          type: user
        html: '<p>Yep the same here with q3 and q4 ...</p>

          '
        raw: Yep the same here with q3 and q4 ...
        updatedAt: '2023-10-10T21:47:21.427Z'
      numEdits: 0
      reactions: []
    id: 6525c669c0dcf4cffe618d2e
    type: comment
  author: Dbone
  content: Yep the same here with q3 and q4 ...
  created_at: 2023-10-10 20:47:21+00:00
  edited: false
  hidden: false
  id: 6525c669c0dcf4cffe618d2e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/36b82978113b80bb5f992847f8550b47.svg
      fullname: Corey Hanson
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sofuego
      type: user
    createdAt: '2023-10-16T14:33:03.000Z'
    data:
      edited: false
      editors:
      - sofuego
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9439271688461304
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/36b82978113b80bb5f992847f8550b47.svg
          fullname: Corey Hanson
          isHf: false
          isPro: false
          name: sofuego
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;MrNewman&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/MrNewman\">@<span class=\"\
          underline\">MrNewman</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;Dbone&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/Dbone\">@<span class=\"underline\">Dbone</span></a></span>\n\
          \n\t</span></span> <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ I had this problem as well. It appears that by default a poorly performing\
          \ value for the rope scaling on this model is set. What did the trick for\
          \ me in koboldcpp is adding the argument --ropeconfig 1.0 1000000</p>\n"
        raw: '@MrNewman @Dbone @TheBloke I had this problem as well. It appears that
          by default a poorly performing value for the rope scaling on this model
          is set. What did the trick for me in koboldcpp is adding the argument --ropeconfig
          1.0 1000000'
        updatedAt: '2023-10-16T14:33:03.547Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - mufeed
        - sibero
        - niburhsoj
        - the-RaZeR
    id: 652d499f3184d39abdc3e7e9
    type: comment
  author: sofuego
  content: '@MrNewman @Dbone @TheBloke I had this problem as well. It appears that
    by default a poorly performing value for the rope scaling on this model is set.
    What did the trick for me in koboldcpp is adding the argument --ropeconfig 1.0
    1000000'
  created_at: 2023-10-16 13:33:03+00:00
  edited: false
  hidden: false
  id: 652d499f3184d39abdc3e7e9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/870b43beda6d118069bf37566db77db7.svg
      fullname: Aleksandr Novokreshchenov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sibero
      type: user
    createdAt: '2023-10-29T14:32:38.000Z'
    data:
      edited: false
      editors:
      - sibero
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6800948977470398
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/870b43beda6d118069bf37566db77db7.svg
          fullname: Aleksandr Novokreshchenov
          isHf: false
          isPro: false
          name: sibero
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sofuego&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sofuego\">@<span class=\"\
          underline\">sofuego</span></a></span>\n\n\t</span></span> tell me, please,\
          \ how do I find out which ropeconfig parameter to set? If there is a problem\
          \ on other models, I want to know how to choose the ropeconfig parameter</p>\n"
        raw: '@sofuego tell me, please, how do I find out which ropeconfig parameter
          to set? If there is a problem on other models, I want to know how to choose
          the ropeconfig parameter


          '
        updatedAt: '2023-10-29T14:32:38.936Z'
      numEdits: 0
      reactions: []
    id: 653e6d0681277ed96832e5b6
    type: comment
  author: sibero
  content: '@sofuego tell me, please, how do I find out which ropeconfig parameter
    to set? If there is a problem on other models, I want to know how to choose the
    ropeconfig parameter


    '
  created_at: 2023-10-29 13:32:38+00:00
  edited: false
  hidden: false
  id: 653e6d0681277ed96832e5b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/89f8aef8aee466438c4a8447aa778799.svg
      fullname: Philipp Hebing
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: the-RaZeR
      type: user
    createdAt: '2023-12-19T11:04:43.000Z'
    data:
      edited: false
      editors:
      - the-RaZeR
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6831352114677429
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/89f8aef8aee466438c4a8447aa778799.svg
          fullname: Philipp Hebing
          isHf: false
          isPro: false
          name: the-RaZeR
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sofuego&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sofuego\">@<span class=\"\
          underline\">sofuego</span></a></span>\n\n\t</span></span> Thanks mate, that\
          \ also fixed the codellama-34b-instruct for me :D<br>Settings in localAI\
          \ are:<br>rope_freq_base: 1000000<br>rope_freq_scale: 1.0</p>\n"
        raw: '@sofuego Thanks mate, that also fixed the codellama-34b-instruct for
          me :D

          Settings in localAI are:

          rope_freq_base: 1000000

          rope_freq_scale: 1.0'
        updatedAt: '2023-12-19T11:04:43.054Z'
      numEdits: 0
      reactions: []
    id: 658178cb23a7aac397eb2540
    type: comment
  author: the-RaZeR
  content: '@sofuego Thanks mate, that also fixed the codellama-34b-instruct for me
    :D

    Settings in localAI are:

    rope_freq_base: 1000000

    rope_freq_scale: 1.0'
  created_at: 2023-12-19 11:04:43+00:00
  edited: false
  hidden: false
  id: 658178cb23a7aac397eb2540
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/Phind-CodeLlama-34B-v2-GGUF
repo_type: model
status: open
target_branch: null
title: Infinite repeating characters
