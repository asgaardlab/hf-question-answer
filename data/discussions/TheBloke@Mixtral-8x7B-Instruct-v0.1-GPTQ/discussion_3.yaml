!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mamsds
conflicting_files: null
created_at: 2023-12-15 05:38:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/99d8edaff594165acdd9c78a5110fd37.svg
      fullname: mamsds
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mamsds
      type: user
    createdAt: '2023-12-15T05:38:19.000Z'
    data:
      edited: false
      editors:
      - mamsds
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4986193776130676
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/99d8edaff594165acdd9c78a5110fd37.svg
          fullname: mamsds
          isHf: false
          isPro: false
          name: mamsds
          type: user
        html: "<p>I tried to follow all the instructions carefully and I download\
          \ the model using text-generation-webui's \"Model\" tab, still I get the\
          \ follow error:</p>\n<p>Traceback (most recent call last):</p>\n<p>File\
          \ \"/mnt/models/text-generation-webui/modules/ui_model_menu.py\", line 237,\
          \ in download_model_wrapper</p>\n<pre><code>model, branch = downloader.sanitize_model_and_branch_names(repo_id,\
          \ None)\n\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          </code></pre>\n<p>File \"/mnt/models/text-generation-webui/download-model.py\"\
          , line 39, in sanitize_model_and_branch_names</p>\n<pre><code>if model[-1]\
          \ == '/':\n\n   ~~~~~^^^^\n\nIndexError: string index out of range\n</code></pre>\n\
          <p>Any thoughts?</p>\n"
        raw: "I tried to follow all the instructions carefully and I download the\
          \ model using text-generation-webui's \"Model\" tab, still I get the follow\
          \ error:\r\n\r\nTraceback (most recent call last):\r\n\r\nFile \"/mnt/models/text-generation-webui/modules/ui_model_menu.py\"\
          , line 237, in download_model_wrapper\r\n```\r\nmodel, branch = downloader.sanitize_model_and_branch_names(repo_id,\
          \ None)\r\n\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
          \n```\r\nFile \"/mnt/models/text-generation-webui/download-model.py\", line\
          \ 39, in sanitize_model_and_branch_names\r\n```\r\nif model[-1] == '/':\r\
          \n\r\n   ~~~~~^^^^\r\n\r\nIndexError: string index out of range\r\n```\r\
          \n\r\nAny thoughts?"
        updatedAt: '2023-12-15T05:38:19.197Z'
      numEdits: 0
      reactions: []
    id: 657be64bde028a439ec12ac4
    type: comment
  author: mamsds
  content: "I tried to follow all the instructions carefully and I download the model\
    \ using text-generation-webui's \"Model\" tab, still I get the follow error:\r\
    \n\r\nTraceback (most recent call last):\r\n\r\nFile \"/mnt/models/text-generation-webui/modules/ui_model_menu.py\"\
    , line 237, in download_model_wrapper\r\n```\r\nmodel, branch = downloader.sanitize_model_and_branch_names(repo_id,\
    \ None)\r\n\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\
    \n```\r\nFile \"/mnt/models/text-generation-webui/download-model.py\", line 39,\
    \ in sanitize_model_and_branch_names\r\n```\r\nif model[-1] == '/':\r\n\r\n  \
    \ ~~~~~^^^^\r\n\r\nIndexError: string index out of range\r\n```\r\n\r\nAny thoughts?"
  created_at: 2023-12-15 05:38:19+00:00
  edited: false
  hidden: false
  id: 657be64bde028a439ec12ac4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b229669d21227b914badbb/umr0ngvZ5L_Nv2nVlC-Zo.png?w=200&h=200&f=face
      fullname: Hypersniper
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hypersniper
      type: user
    createdAt: '2023-12-16T04:26:34.000Z'
    data:
      edited: false
      editors:
      - Hypersniper
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6989390850067139
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b229669d21227b914badbb/umr0ngvZ5L_Nv2nVlC-Zo.png?w=200&h=200&f=face
          fullname: Hypersniper
          isHf: false
          isPro: false
          name: Hypersniper
          type: user
        html: '<p>same here</p>

          '
        raw: same here
        updatedAt: '2023-12-16T04:26:34.230Z'
      numEdits: 0
      reactions: []
    id: 657d26fa4718fb0304ee6f3e
    type: comment
  author: Hypersniper
  content: same here
  created_at: 2023-12-16 04:26:34+00:00
  edited: false
  hidden: false
  id: 657d26fa4718fb0304ee6f3e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/549e29771f420d4eba977ad44c706d97.svg
      fullname: Noob Artist
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: 1NoobArtist
      type: user
    createdAt: '2024-01-03T17:57:09.000Z'
    data:
      edited: false
      editors:
      - 1NoobArtist
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.1798323392868042
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/549e29771f420d4eba977ad44c706d97.svg
          fullname: Noob Artist
          isHf: false
          isPro: false
          name: 1NoobArtist
          type: user
        html: '<p>Getting this error:</p>

          <p>23:25:45-094355 INFO     Loading TheBloke_Mixtral-8x7B-Instruct-v0.1-GPTQ<br>23:25:45-609266
          ERROR    Failed to load the model.<br>Traceback (most recent call last):<br>  File
          "E:\text-generation-webui-main\text-generation-webui-main\modules\ui_model_menu.py",
          line 214, in load_model_wrapper<br>    shared.model, shared.tokenizer =
          load_model(selected_model, loader)<br>                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "E:\text-generation-webui-main\text-generation-webui-main\modules\models.py",
          line 90, in load_model<br>    output = load_func_map<a rel="nofollow" href="model_name">loader</a><br>             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "E:\text-generation-webui-main\text-generation-webui-main\modules\models.py",
          line 399, in ExLlama_HF_loader<br>    return ExllamaHF.from_pretrained(model_name)<br>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "E:\text-generation-webui-main\text-generation-webui-main\modules\exllama_hf.py",
          line 174, in from_pretrained<br>    return ExllamaHF(config)<br>           ^^^^^^^^^^^^^^^^^<br>  File
          "E:\text-generation-webui-main\text-generation-webui-main\modules\exllama_hf.py",
          line 31, in <strong>init</strong><br>    self.ex_model = ExLlama(self.ex_config)<br>                    ^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "E:\text-generation-webui-main\text-generation-webui-main\installer_files\env\Lib\site-packages\exllama\model.py",
          line 753, in <strong>init</strong><br>    decoder_size += math.prod(shape)
          * _layer_dtype_size(key)<br>                                       ^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "E:\text-generation-webui-main\text-generation-webui-main\installer_files\env\Lib\site-packages\exllama\model.py",
          line 716, in _layer_dtype_size<br>    raise ValueError("Unrecognized layer:
          " + key)<br>ValueError: Unrecognized layer: model.layers.0.block_sparse_moe.experts.0.w1.bias</p>

          '
        raw: "Getting this error:\n\n23:25:45-094355 INFO     Loading TheBloke_Mixtral-8x7B-Instruct-v0.1-GPTQ\n\
          23:25:45-609266 ERROR    Failed to load the model.\nTraceback (most recent\
          \ call last):\n  File \"E:\\text-generation-webui-main\\text-generation-webui-main\\\
          modules\\ui_model_menu.py\", line 214, in load_model_wrapper\n    shared.model,\
          \ shared.tokenizer = load_model(selected_model, loader)\n              \
          \                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\\
          text-generation-webui-main\\text-generation-webui-main\\modules\\models.py\"\
          , line 90, in load_model\n    output = load_func_map[loader](model_name)\n\
          \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\text-generation-webui-main\\\
          text-generation-webui-main\\modules\\models.py\", line 399, in ExLlama_HF_loader\n\
          \    return ExllamaHF.from_pretrained(model_name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"E:\\text-generation-webui-main\\text-generation-webui-main\\modules\\\
          exllama_hf.py\", line 174, in from_pretrained\n    return ExllamaHF(config)\n\
          \           ^^^^^^^^^^^^^^^^^\n  File \"E:\\text-generation-webui-main\\\
          text-generation-webui-main\\modules\\exllama_hf.py\", line 31, in __init__\n\
          \    self.ex_model = ExLlama(self.ex_config)\n                    ^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"E:\\text-generation-webui-main\\text-generation-webui-main\\installer_files\\\
          env\\Lib\\site-packages\\exllama\\model.py\", line 753, in __init__\n  \
          \  decoder_size += math.prod(shape) * _layer_dtype_size(key)\n         \
          \                              ^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\text-generation-webui-main\\\
          text-generation-webui-main\\installer_files\\env\\Lib\\site-packages\\exllama\\\
          model.py\", line 716, in _layer_dtype_size\n    raise ValueError(\"Unrecognized\
          \ layer: \" + key)\nValueError: Unrecognized layer: model.layers.0.block_sparse_moe.experts.0.w1.bias"
        updatedAt: '2024-01-03T17:57:09.929Z'
      numEdits: 0
      reactions: []
    id: 65959ff512c3ee130f8d398b
    type: comment
  author: 1NoobArtist
  content: "Getting this error:\n\n23:25:45-094355 INFO     Loading TheBloke_Mixtral-8x7B-Instruct-v0.1-GPTQ\n\
    23:25:45-609266 ERROR    Failed to load the model.\nTraceback (most recent call\
    \ last):\n  File \"E:\\text-generation-webui-main\\text-generation-webui-main\\\
    modules\\ui_model_menu.py\", line 214, in load_model_wrapper\n    shared.model,\
    \ shared.tokenizer = load_model(selected_model, loader)\n                    \
    \                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\text-generation-webui-main\\\
    text-generation-webui-main\\modules\\models.py\", line 90, in load_model\n   \
    \ output = load_func_map[loader](model_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
    \  File \"E:\\text-generation-webui-main\\text-generation-webui-main\\modules\\\
    models.py\", line 399, in ExLlama_HF_loader\n    return ExllamaHF.from_pretrained(model_name)\n\
    \           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\text-generation-webui-main\\\
    text-generation-webui-main\\modules\\exllama_hf.py\", line 174, in from_pretrained\n\
    \    return ExllamaHF(config)\n           ^^^^^^^^^^^^^^^^^\n  File \"E:\\text-generation-webui-main\\\
    text-generation-webui-main\\modules\\exllama_hf.py\", line 31, in __init__\n \
    \   self.ex_model = ExLlama(self.ex_config)\n                    ^^^^^^^^^^^^^^^^^^^^^^^\n\
    \  File \"E:\\text-generation-webui-main\\text-generation-webui-main\\installer_files\\\
    env\\Lib\\site-packages\\exllama\\model.py\", line 753, in __init__\n    decoder_size\
    \ += math.prod(shape) * _layer_dtype_size(key)\n                             \
    \          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\text-generation-webui-main\\text-generation-webui-main\\\
    installer_files\\env\\Lib\\site-packages\\exllama\\model.py\", line 716, in _layer_dtype_size\n\
    \    raise ValueError(\"Unrecognized layer: \" + key)\nValueError: Unrecognized\
    \ layer: model.layers.0.block_sparse_moe.experts.0.w1.bias"
  created_at: 2024-01-03 17:57:09+00:00
  edited: false
  hidden: false
  id: 65959ff512c3ee130f8d398b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/WXq1Ds6bJ3aoDul3iwYYY.jpeg?w=200&h=200&f=face
      fullname: Fe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: FelipeAr4n
      type: user
    createdAt: '2024-01-20T21:14:16.000Z'
    data:
      edited: true
      editors:
      - FelipeAr4n
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.14109723269939423
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/WXq1Ds6bJ3aoDul3iwYYY.jpeg?w=200&h=200&f=face
          fullname: Fe
          isHf: false
          isPro: false
          name: FelipeAr4n
          type: user
        html: '<p>ERROR    Failed to load the model.<br>Traceback (most recent call
          last):<br>  File "D:\text-generation-webui-main\modules\ui_model_menu.py",
          line 213, in load_model_wrapper<br>    shared.model, shared.tokenizer =
          load_model(selected_model, loader)<br>                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "D:\text-generation-webui-main\modules\models.py", line 87, in load_model<br>    output
          = load_func_map<a rel="nofollow" href="model_name">loader</a><br>             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "D:\text-generation-webui-main\modules\models.py", line 250, in llamacpp_loader<br>    model,
          tokenizer = LlamaCppModel.from_pretrained(model_file)<br>                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>  File
          "D:\text-generation-webui-main\modules\llamacpp_model.py", line 63, in from_pretrained<br>    Llama
          = llama_cpp_lib().Llama<br>            ^^^^^^^^^^^^^^^^^^^^^<br>AttributeError:
          ''NoneType'' object has no attribute ''Llama''</p>

          '
        raw: "ERROR    Failed to load the model.\nTraceback (most recent call last):\n\
          \  File \"D:\\text-generation-webui-main\\modules\\ui_model_menu.py\", line\
          \ 213, in load_model_wrapper\n    shared.model, shared.tokenizer = load_model(selected_model,\
          \ loader)\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"D:\\text-generation-webui-main\\modules\\models.py\", line 87,\
          \ in load_model\n    output = load_func_map[loader](model_name)\n      \
          \       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\text-generation-webui-main\\\
          modules\\models.py\", line 250, in llamacpp_loader\n    model, tokenizer\
          \ = LlamaCppModel.from_pretrained(model_file)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
          \  File \"D:\\text-generation-webui-main\\modules\\llamacpp_model.py\",\
          \ line 63, in from_pretrained\n    Llama = llama_cpp_lib().Llama\n     \
          \       ^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no\
          \ attribute 'Llama'"
        updatedAt: '2024-01-20T21:14:48.442Z'
      numEdits: 1
      reactions: []
    id: 65ac37a8e2a2c86356e2bcd3
    type: comment
  author: FelipeAr4n
  content: "ERROR    Failed to load the model.\nTraceback (most recent call last):\n\
    \  File \"D:\\text-generation-webui-main\\modules\\ui_model_menu.py\", line 213,\
    \ in load_model_wrapper\n    shared.model, shared.tokenizer = load_model(selected_model,\
    \ loader)\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
    \  File \"D:\\text-generation-webui-main\\modules\\models.py\", line 87, in load_model\n\
    \    output = load_func_map[loader](model_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\
    \  File \"D:\\text-generation-webui-main\\modules\\models.py\", line 250, in llamacpp_loader\n\
    \    model, tokenizer = LlamaCppModel.from_pretrained(model_file)\n          \
    \             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\text-generation-webui-main\\\
    modules\\llamacpp_model.py\", line 63, in from_pretrained\n    Llama = llama_cpp_lib().Llama\n\
    \            ^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute\
    \ 'Llama'"
  created_at: 2024-01-20 21:14:16+00:00
  edited: true
  hidden: false
  id: 65ac37a8e2a2c86356e2bcd3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ
repo_type: model
status: open
target_branch: null
title: I can't get it running in text-generation-webui
