!!python/object:huggingface_hub.community.DiscussionWithDetails
author: andreaKIM
conflicting_files: null
created_at: 2023-12-09 03:18:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d1f763ca61fb1f281f7ac24bdee8722f.svg
      fullname: DAEHEEKIM
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andreaKIM
      type: user
    createdAt: '2023-12-09T03:18:59.000Z'
    data:
      edited: false
      editors:
      - andreaKIM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9018567204475403
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d1f763ca61fb1f281f7ac24bdee8722f.svg
          fullname: DAEHEEKIM
          isHf: false
          isPro: false
          name: andreaKIM
          type: user
        html: '<p>Hello, It is so impressive to hit 70B performance with only 10 times
          smaller model.<br>I want to try instruction fine tuning However I got no
          idea about prompt.<br>Where could instruction go in the prompt? (system
          message + instruction)<br>Thank you!</p>

          '
        raw: "Hello, It is so impressive to hit 70B performance with only 10 times\
          \ smaller model.\r\nI want to try instruction fine tuning However I got\
          \ no idea about prompt.\r\nWhere could instruction go in the prompt? (system\
          \ message + instruction)\r\nThank you!\r\n\r\n"
        updatedAt: '2023-12-09T03:18:59.087Z'
      numEdits: 0
      reactions: []
    id: 6573dca3148818631584a484
    type: comment
  author: andreaKIM
  content: "Hello, It is so impressive to hit 70B performance with only 10 times smaller\
    \ model.\r\nI want to try instruction fine tuning However I got no idea about\
    \ prompt.\r\nWhere could instruction go in the prompt? (system message + instruction)\r\
    \nThank you!\r\n\r\n"
  created_at: 2023-12-09 03:18:59+00:00
  edited: false
  hidden: false
  id: 6573dca3148818631584a484
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
      fullname: Banghua Zhu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: banghua
      type: user
    createdAt: '2023-12-09T03:35:05.000Z'
    data:
      edited: false
      editors:
      - banghua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9448447823524475
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
          fullname: Banghua Zhu
          isHf: false
          isPro: false
          name: banghua
          type: user
        html: '<p>Thank you! The prompt for fine-tuning will be the same as the one
          used for chat, which is provided in model card and also below:</p>

          <p>"GPT4 Correct User: Hello&lt;|end_of_turn|&gt;GPT4 Correct Assistant:
          Hi&lt;|end_of_turn|&gt;GPT4 Correct User: How are you today?&lt;|end_of_turn|&gt;GPT4
          Correct Assistant:"</p>

          <p>During both SFT and RLHF, the model does not follow system message. So
          I would suggest put all system message together with instruction inside
          "GPT4 Correct User:".</p>

          '
        raw: 'Thank you! The prompt for fine-tuning will be the same as the one used
          for chat, which is provided in model card and also below:


          "GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct Assistant: Hi<|end_of_turn|>GPT4
          Correct User: How are you today?<|end_of_turn|>GPT4 Correct Assistant:"


          During both SFT and RLHF, the model does not follow system message. So I
          would suggest put all system message together with instruction inside "GPT4
          Correct User:".

          '
        updatedAt: '2023-12-09T03:35:05.796Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - andreaKIM
    id: 6573e069ec3bf96e4317b6ee
    type: comment
  author: banghua
  content: 'Thank you! The prompt for fine-tuning will be the same as the one used
    for chat, which is provided in model card and also below:


    "GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct Assistant: Hi<|end_of_turn|>GPT4
    Correct User: How are you today?<|end_of_turn|>GPT4 Correct Assistant:"


    During both SFT and RLHF, the model does not follow system message. So I would
    suggest put all system message together with instruction inside "GPT4 Correct
    User:".

    '
  created_at: 2023-12-09 03:35:05+00:00
  edited: false
  hidden: false
  id: 6573e069ec3bf96e4317b6ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d1f763ca61fb1f281f7ac24bdee8722f.svg
      fullname: DAEHEEKIM
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andreaKIM
      type: user
    createdAt: '2023-12-09T03:45:35.000Z'
    data:
      edited: false
      editors:
      - andreaKIM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9769050478935242
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d1f763ca61fb1f281f7ac24bdee8722f.svg
          fullname: DAEHEEKIM
          isHf: false
          isPro: false
          name: andreaKIM
          type: user
        html: '<p>Really quick answer for me :)<br>I would try with pleasure.<br>By
          the way, why the model could not follow system message? is there any reason?<br>Thank
          you again!</p>

          '
        raw: "Really quick answer for me :)\nI would try with pleasure. \nBy the way,\
          \ why the model could not follow system message? is there any reason? \n\
          Thank you again!"
        updatedAt: '2023-12-09T03:45:35.198Z'
      numEdits: 0
      reactions: []
    id: 6573e2dfd0ed8f5761ebc7bc
    type: comment
  author: andreaKIM
  content: "Really quick answer for me :)\nI would try with pleasure. \nBy the way,\
    \ why the model could not follow system message? is there any reason? \nThank\
    \ you again!"
  created_at: 2023-12-09 03:45:35+00:00
  edited: false
  hidden: false
  id: 6573e2dfd0ed8f5761ebc7bc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
      fullname: Banghua Zhu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: banghua
      type: user
    createdAt: '2023-12-09T06:38:26.000Z'
    data:
      edited: false
      editors:
      - banghua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9311520457267761
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
          fullname: Banghua Zhu
          isHf: false
          isPro: false
          name: banghua
          type: user
        html: '<p>It''s because we mostly trained on the prompt style that does not
          come with system message (usually the fine-tuning dataset won''t come with
          prompts with standard system message). But if you just put system message
          inside "GPT4 Correct User:" and prompt it appropriately, it shall be able
          to follow it well.</p>

          '
        raw: It's because we mostly trained on the prompt style that does not come
          with system message (usually the fine-tuning dataset won't come with prompts
          with standard system message). But if you just put system message inside
          "GPT4 Correct User:" and prompt it appropriately, it shall be able to follow
          it well.
        updatedAt: '2023-12-09T06:38:26.003Z'
      numEdits: 0
      reactions: []
    id: 65740b6288805b3ba1c098ee
    type: comment
  author: banghua
  content: It's because we mostly trained on the prompt style that does not come with
    system message (usually the fine-tuning dataset won't come with prompts with standard
    system message). But if you just put system message inside "GPT4 Correct User:"
    and prompt it appropriately, it shall be able to follow it well.
  created_at: 2023-12-09 06:38:26+00:00
  edited: false
  hidden: false
  id: 65740b6288805b3ba1c098ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d1f763ca61fb1f281f7ac24bdee8722f.svg
      fullname: DAEHEEKIM
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andreaKIM
      type: user
    createdAt: '2023-12-09T07:34:40.000Z'
    data:
      edited: false
      editors:
      - andreaKIM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8261335492134094
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d1f763ca61fb1f281f7ac24bdee8722f.svg
          fullname: DAEHEEKIM
          isHf: false
          isPro: false
          name: andreaKIM
          type: user
        html: '<p>Thanks again! I have one more question.<br>Does  "generation_config.json"
          file affect the training?<br>Because some other models in the hub contain
          other parameters such as <code>temperature,do_sample,..</code>.<br>Does
          it affect on training? If it does, then can i adjust that parameters also?</p>

          '
        raw: 'Thanks again! I have one more question.

          Does  "generation_config.json" file affect the training?

          Because some other models in the hub contain other parameters such as ```temperature,do_sample,..```.

          Does it affect on training? If it does, then can i adjust that parameters
          also?'
        updatedAt: '2023-12-09T07:34:40.434Z'
      numEdits: 0
      reactions: []
    id: 657418904fffc3f08b2f5a29
    type: comment
  author: andreaKIM
  content: 'Thanks again! I have one more question.

    Does  "generation_config.json" file affect the training?

    Because some other models in the hub contain other parameters such as ```temperature,do_sample,..```.

    Does it affect on training? If it does, then can i adjust that parameters also?'
  created_at: 2023-12-09 07:34:40+00:00
  edited: false
  hidden: false
  id: 657418904fffc3f08b2f5a29
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
      fullname: Banghua Zhu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: banghua
      type: user
    createdAt: '2023-12-22T03:52:09.000Z'
    data:
      edited: false
      editors:
      - banghua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9458787441253662
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
          fullname: Banghua Zhu
          isHf: false
          isPro: false
          name: banghua
          type: user
        html: '<p>Sorry for the late reply. I think it won''t affect training. If
          you want to use RLHF then the generation parameters might affect the samples
          you collected. But for SFT it won''t affect anything.</p>

          '
        raw: Sorry for the late reply. I think it won't affect training. If you want
          to use RLHF then the generation parameters might affect the samples you
          collected. But for SFT it won't affect anything.
        updatedAt: '2023-12-22T03:52:09.747Z'
      numEdits: 0
      reactions: []
    id: 658507e941dbedb146ffccff
    type: comment
  author: banghua
  content: Sorry for the late reply. I think it won't affect training. If you want
    to use RLHF then the generation parameters might affect the samples you collected.
    But for SFT it won't affect anything.
  created_at: 2023-12-22 03:52:09+00:00
  edited: false
  hidden: false
  id: 658507e941dbedb146ffccff
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 22
repo_id: berkeley-nest/Starling-LM-7B-alpha
repo_type: model
status: open
target_branch: null
title: What could be instruction fine tuning prompt for this model?
