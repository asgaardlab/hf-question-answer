!!python/object:huggingface_hub.community.DiscussionWithDetails
author: eramax
conflicting_files: null
created_at: 2023-11-28 16:27:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
      fullname: Ahmed Morsi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eramax
      type: user
    createdAt: '2023-11-28T16:27:40.000Z'
    data:
      edited: false
      editors:
      - eramax
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8395702838897705
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
          fullname: Ahmed Morsi
          isHf: false
          isPro: false
          name: eramax
          type: user
        html: '<p>I noticed that the model is reapeting itself and most of the time
          write more than answer need, I would like to know the ideal parameters you
          suggest for this incredible model?</p>

          <p>Example and I had to stop it</p>

          <pre><code>&gt;&gt;&gt; """give me the output of this code

          ... s = "She enrolled in the course at the university."

          ... doc = nlp(s)

          ... [(t.text, t.dep_, t.head.text) for t in doc]

          </code></pre>

          <p>To execute this Python code snippet, you need to have the <code>spacy</code>
          library installed, which is a popular NLP (Natural Language Processing)
          library. Here''s the output of the provided code using the English<br>model
          of Spacy:</p>

          <pre><code class="language-python"><span class="hljs-keyword">import</span>
          spacy


          nlp = spacy.load(<span class="hljs-string">"en_core_web_sm"</span>)  <span
          class="hljs-comment"># Load the English language model from Spacy</span>


          s = <span class="hljs-string">"She enrolled in the course at the university."</span>  <span
          class="hljs-comment"># Input sentence</span>

          doc = nlp(s)  <span class="hljs-comment"># Analyze the input sentence using
          the loaded model</span>


          output = [(t.text, t.dep_, t.head.text) <span class="hljs-keyword">for</span>
          t <span class="hljs-keyword">in</span> doc]  <span class="hljs-comment">#
          Extract relevant information from the analyzed document</span>

          <span class="hljs-built_in">print</span>(output)

          </code></pre>

          <p>The output of the provided code would be:</p>

          <pre><code class="language-less"><span class="hljs-selector-attr">[(<span
          class="hljs-string">''She''</span>, <span class="hljs-string">''nsubj''</span>,
          <span class="hljs-string">''enrolled''</span>), (<span class="hljs-string">''enrolled''</span>,
          <span class="hljs-string">''ROOT''</span>, <span class="hljs-string">''enrolled''</span>),
          (<span class="hljs-string">''in''</span>, <span class="hljs-string">''prep''</span>,
          <span class="hljs-string">''enrolled''</span>), (<span class="hljs-string">''the''</span>,
          <span class="hljs-string">''det''</span>, <span class="hljs-string">''course''</span>),
          (<span class="hljs-string">''course''</span>, <span class="hljs-string">''dobj''</span>,
          <span class="hljs-string">''enrolled''</span>), (<span class="hljs-string">''at''</span>,
          <span class="hljs-string">''prep''</span>, <span class="hljs-string">''university''</span>),
          (<span class="hljs-string">''university''</span>, <span class="hljs-string">''pobj''</span>,<span
          class="hljs-string">''enrolled''</span>)]</span>

          </code></pre>

          <p>Here''s a brief explanation of the output:</p>

          <ol>

          <li><code>(''She'', ''nsubj'', ''enrolled'')</code>: The word "She" is the
          subject (nsubj) of the verb "enrolled."</li>

          <li><code>(''enrolled'', ''ROOT'', ''enrolled'')</code>: The main action
          in this sentence, which is "enrolled," is marked as the root node (ROOT)
          of the dependency tree.</li>

          <li><code>(''in'', ''prep'', ''enrolled'')</code>: The preposition "in"
          provides preparation information for the verb "enrolled."</li>

          <li><code>(''the'', ''det'', ''course'')</code>: The definite article "the"
          is modifying the noun "course."</li>

          <li><code>(''course'', ''dobj'', ''enrolled'')</code>: The direct object
          (dobj) of the verb "enrolled" is the noun "course."</li>

          <li><code>(''at'', ''prep'', ''university'')</code>: The preposition "at"
          provides preparation information for the noun "university."</li>

          <li><code>(''university'', ''pobj'', ''enrolled'')</code>: The part of speech
          (pobj) of the verb "enrolled" is the noun "university," which is related
          to the action of enrollment in this context.</li>

          </ol>

          <p>The dependency parsing helps understand the syntactic relationships between
          words in a sentence, such as subjects, objects, and other modifying elements.
          In this case, the code extracts relevant<br>information like word text (<code>t.text</code>),
          their grammatical role (<code>t.dep_</code>), and the head word they are
          dependent on (<code>t.head.text</code>).</p>

          <p>Note that you can use more advanced Spacy models if needed, such as <code>en_core_web_lg</code>,
          which includes additional linguistic features at the cost of a larger model
          size. You can find more information about<br>these models in the Spacy documentation:
          <a rel="nofollow" href="https://explore.spacy.io/usage/models">https://explore.spacy.io/usage/models</a></p>

          <p>Keep in mind that running this code requires having the <code>spacy</code>
          library installed, which you can install using <code>pip</code> (Python''s
          package manager):</p>

          <pre><code class="language-bash">pip install spacy

          </code></pre>

          <p>Once installed, you can use Spacy for various NLP tasks like named entity
          recognition, part-of-speech tagging, dependency parsing, and more.</p>

          <p>Here are some additional resources to learn more about Spacy:</p>

          <ol>

          <li>Spacy''s official tutorials: <a rel="nofollow" href="https://explore.spacy.io/">https://explore.spacy.io/</a></li>

          <li>Spacy''s documentation: <a rel="nofollow" href="https://spacy.io/usage">https://spacy.io/usage</a></li>

          <li>A comprehensive guide to Spacy by Real Python: <a rel="nofollow" href="https://www.realpython.com/spacy-nlp-python/">https://www.realpython.com/spacy-nlp-python/</a></li>

          <li>An introduction to Spacy and NLP with Python by Data Science Central:
          <a rel="nofollow" href="https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python">https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python</a></li>

          </ol>

          <p>These resources will help you dive deeper into the world of Spacy and
          NLP (Natural Language Processing).</p>

          <p>I hope this helps! Don''t hesitate to ask if you have any more questions
          or need clarification on any part of the answer.</p>

          <p>Less</p>

          <pre><code>Here are some additional resources to learn more about Spacy:


          1. Spacy''s official tutorials: &lt;https://explore.spacy.io/&gt;

          2. Spacy''s documentation: &lt;https://spacy.io/usage&gt;

          3. A comprehensive guide to Spacy by Real Python: &lt;https://www.realpython.com/spacy-nlp-python/&gt;

          4. An introduction to Spacy and NLP with Python by Data Science Central:
          &lt;https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python&gt;


          These resources will help you dive deeper into the world of Spacy and NLP
          (Natural Language Processing).


          I hope this helps! Don''t hesitate to ask if you have any more questions
          or need clarification on any part of the answer.


          Less

          </code></pre>

          <p>Here are some additional resources to learn more about Spacy:</p>

          <ol>

          <li>Spacy''s official tutorials: <a rel="nofollow" href="https://explore.spacy.io/">https://explore.spacy.io/</a></li>

          <li>Spacy''s documentation: <a rel="nofollow" href="https://spacy.io/usage">https://spacy.io/usage</a></li>

          <li>A comprehensive guide to Spacy by Real Python: <a rel="nofollow" href="https://www.realpython.com/spacy-nlp-python/">https://www.realpython.com/spacy-nlp-python/</a></li>

          <li>An introduction to Spacy and NLP with Python by Data Science Central:
          <a rel="nofollow" href="https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python">https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python</a></li>

          </ol>

          <p>These resources will help you dive deeper into the world of Spacy and
          NLP (Natural Language Processing).</p>

          <p>I hope this helps! Don''t hesitate to ask if you have any more questions
          or need clarification on any part of the answer.</p>

          <pre><code>

          Here are some additional resources to learn more about Spacy:

          ^C

          </code></pre>

          '
        raw: "I noticed that the model is reapeting itself and most of the time write\
          \ more than answer need, I would like to know the ideal parameters you suggest\
          \ for this incredible model?\r\n\r\nExample and I had to stop it\r\n```\r\
          \n>>> \"\"\"give me the output of this code\r\n... s = \"She enrolled in\
          \ the course at the university.\"\r\n... doc = nlp(s)\r\n... [(t.text, t.dep_,\
          \ t.head.text) for t in doc]\r\n```\r\nTo execute this Python code snippet,\
          \ you need to have the `spacy` library installed, which is a popular NLP\
          \ (Natural Language Processing) library. Here's the output of the provided\
          \ code using the English\r\nmodel of Spacy:\r\n\r\n```python\r\nimport spacy\r\
          \n\r\nnlp = spacy.load(\"en_core_web_sm\")  # Load the English language\
          \ model from Spacy\r\n\r\ns = \"She enrolled in the course at the university.\"\
          \  # Input sentence\r\ndoc = nlp(s)  # Analyze the input sentence using\
          \ the loaded model\r\n\r\noutput = [(t.text, t.dep_, t.head.text) for t\
          \ in doc]  # Extract relevant information from the analyzed document\r\n\
          print(output)\r\n```\r\nThe output of the provided code would be:\r\n```less\r\
          \n[('She', 'nsubj', 'enrolled'), ('enrolled', 'ROOT', 'enrolled'), ('in',\
          \ 'prep', 'enrolled'), ('the', 'det', 'course'), ('course', 'dobj', 'enrolled'),\
          \ ('at', 'prep', 'university'), ('university', 'pobj',\r\n'enrolled')]\r\
          \n```\r\nHere's a brief explanation of the output:\r\n\r\n1. `('She', 'nsubj',\
          \ 'enrolled')`: The word \"She\" is the subject (nsubj) of the verb \"enrolled.\"\
          \r\n2. `('enrolled', 'ROOT', 'enrolled')`: The main action in this sentence,\
          \ which is \"enrolled,\" is marked as the root node (ROOT) of the dependency\
          \ tree.\r\n3. `('in', 'prep', 'enrolled')`: The preposition \"in\" provides\
          \ preparation information for the verb \"enrolled.\"\r\n4. `('the', 'det',\
          \ 'course')`: The definite article \"the\" is modifying the noun \"course.\"\
          \r\n5. `('course', 'dobj', 'enrolled')`: The direct object (dobj) of the\
          \ verb \"enrolled\" is the noun \"course.\"\r\n6. `('at', 'prep', 'university')`:\
          \ The preposition \"at\" provides preparation information for the noun \"\
          university.\"\r\n7. `('university', 'pobj', 'enrolled')`: The part of speech\
          \ (pobj) of the verb \"enrolled\" is the noun \"university,\" which is related\
          \ to the action of enrollment in this context.\r\n\r\nThe dependency parsing\
          \ helps understand the syntactic relationships between words in a sentence,\
          \ such as subjects, objects, and other modifying elements. In this case,\
          \ the code extracts relevant\r\ninformation like word text (`t.text`), their\
          \ grammatical role (`t.dep_`), and the head word they are dependent on (`t.head.text`).\r\
          \n\r\nNote that you can use more advanced Spacy models if needed, such as\
          \ `en_core_web_lg`, which includes additional linguistic features at the\
          \ cost of a larger model size. You can find more information about\r\nthese\
          \ models in the Spacy documentation: <https://explore.spacy.io/usage/models>\r\
          \n\r\nKeep in mind that running this code requires having the `spacy` library\
          \ installed, which you can install using `pip` (Python's package manager):\r\
          \n```bash\r\npip install spacy\r\n```\r\nOnce installed, you can use Spacy\
          \ for various NLP tasks like named entity recognition, part-of-speech tagging,\
          \ dependency parsing, and more.\r\n\r\nHere are some additional resources\
          \ to learn more about Spacy:\r\n\r\n1. Spacy's official tutorials: <https://explore.spacy.io/>\r\
          \n2. Spacy's documentation: <https://spacy.io/usage>\r\n3. A comprehensive\
          \ guide to Spacy by Real Python: <https://www.realpython.com/spacy-nlp-python/>\r\
          \n4. An introduction to Spacy and NLP with Python by Data Science Central:\
          \ <https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python>\r\
          \n\r\nThese resources will help you dive deeper into the world of Spacy\
          \ and NLP (Natural Language Processing).\r\n\r\nI hope this helps! Don't\
          \ hesitate to ask if you have any more questions or need clarification on\
          \ any part of the answer.\r\n\r\nLess\r\n\r\n```\r\nHere are some additional\
          \ resources to learn more about Spacy:\r\n\r\n1. Spacy's official tutorials:\
          \ <https://explore.spacy.io/>\r\n2. Spacy's documentation: <https://spacy.io/usage>\r\
          \n3. A comprehensive guide to Spacy by Real Python: <https://www.realpython.com/spacy-nlp-python/>\r\
          \n4. An introduction to Spacy and NLP with Python by Data Science Central:\
          \ <https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python>\r\
          \n\r\nThese resources will help you dive deeper into the world of Spacy\
          \ and NLP (Natural Language Processing).\r\n\r\nI hope this helps! Don't\
          \ hesitate to ask if you have any more questions or need clarification on\
          \ any part of the answer.\r\n\r\nLess\r\n\r\n```\r\nHere are some additional\
          \ resources to learn more about Spacy:\r\n\r\n1. Spacy's official tutorials:\
          \ <https://explore.spacy.io/>\r\n2. Spacy's documentation: <https://spacy.io/usage>\r\
          \n3. A comprehensive guide to Spacy by Real Python: <https://www.realpython.com/spacy-nlp-python/>\r\
          \n4. An introduction to Spacy and NLP with Python by Data Science Central:\
          \ <https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python>\r\
          \n\r\nThese resources will help you dive deeper into the world of Spacy\
          \ and NLP (Natural Language Processing).\r\n\r\nI hope this helps! Don't\
          \ hesitate to ask if you have any more questions or need clarification on\
          \ any part of the answer.\r\n```\r\n\r\nHere are some additional resources\
          \ to learn more about Spacy:\r\n^C\r\n\r\n"
        updatedAt: '2023-11-28T16:27:40.400Z'
      numEdits: 0
      reactions: []
    id: 656614fc93e30c8a60d7ca85
    type: comment
  author: eramax
  content: "I noticed that the model is reapeting itself and most of the time write\
    \ more than answer need, I would like to know the ideal parameters you suggest\
    \ for this incredible model?\r\n\r\nExample and I had to stop it\r\n```\r\n>>>\
    \ \"\"\"give me the output of this code\r\n... s = \"She enrolled in the course\
    \ at the university.\"\r\n... doc = nlp(s)\r\n... [(t.text, t.dep_, t.head.text)\
    \ for t in doc]\r\n```\r\nTo execute this Python code snippet, you need to have\
    \ the `spacy` library installed, which is a popular NLP (Natural Language Processing)\
    \ library. Here's the output of the provided code using the English\r\nmodel of\
    \ Spacy:\r\n\r\n```python\r\nimport spacy\r\n\r\nnlp = spacy.load(\"en_core_web_sm\"\
    )  # Load the English language model from Spacy\r\n\r\ns = \"She enrolled in the\
    \ course at the university.\"  # Input sentence\r\ndoc = nlp(s)  # Analyze the\
    \ input sentence using the loaded model\r\n\r\noutput = [(t.text, t.dep_, t.head.text)\
    \ for t in doc]  # Extract relevant information from the analyzed document\r\n\
    print(output)\r\n```\r\nThe output of the provided code would be:\r\n```less\r\
    \n[('She', 'nsubj', 'enrolled'), ('enrolled', 'ROOT', 'enrolled'), ('in', 'prep',\
    \ 'enrolled'), ('the', 'det', 'course'), ('course', 'dobj', 'enrolled'), ('at',\
    \ 'prep', 'university'), ('university', 'pobj',\r\n'enrolled')]\r\n```\r\nHere's\
    \ a brief explanation of the output:\r\n\r\n1. `('She', 'nsubj', 'enrolled')`:\
    \ The word \"She\" is the subject (nsubj) of the verb \"enrolled.\"\r\n2. `('enrolled',\
    \ 'ROOT', 'enrolled')`: The main action in this sentence, which is \"enrolled,\"\
    \ is marked as the root node (ROOT) of the dependency tree.\r\n3. `('in', 'prep',\
    \ 'enrolled')`: The preposition \"in\" provides preparation information for the\
    \ verb \"enrolled.\"\r\n4. `('the', 'det', 'course')`: The definite article \"\
    the\" is modifying the noun \"course.\"\r\n5. `('course', 'dobj', 'enrolled')`:\
    \ The direct object (dobj) of the verb \"enrolled\" is the noun \"course.\"\r\n\
    6. `('at', 'prep', 'university')`: The preposition \"at\" provides preparation\
    \ information for the noun \"university.\"\r\n7. `('university', 'pobj', 'enrolled')`:\
    \ The part of speech (pobj) of the verb \"enrolled\" is the noun \"university,\"\
    \ which is related to the action of enrollment in this context.\r\n\r\nThe dependency\
    \ parsing helps understand the syntactic relationships between words in a sentence,\
    \ such as subjects, objects, and other modifying elements. In this case, the code\
    \ extracts relevant\r\ninformation like word text (`t.text`), their grammatical\
    \ role (`t.dep_`), and the head word they are dependent on (`t.head.text`).\r\n\
    \r\nNote that you can use more advanced Spacy models if needed, such as `en_core_web_lg`,\
    \ which includes additional linguistic features at the cost of a larger model\
    \ size. You can find more information about\r\nthese models in the Spacy documentation:\
    \ <https://explore.spacy.io/usage/models>\r\n\r\nKeep in mind that running this\
    \ code requires having the `spacy` library installed, which you can install using\
    \ `pip` (Python's package manager):\r\n```bash\r\npip install spacy\r\n```\r\n\
    Once installed, you can use Spacy for various NLP tasks like named entity recognition,\
    \ part-of-speech tagging, dependency parsing, and more.\r\n\r\nHere are some additional\
    \ resources to learn more about Spacy:\r\n\r\n1. Spacy's official tutorials: <https://explore.spacy.io/>\r\
    \n2. Spacy's documentation: <https://spacy.io/usage>\r\n3. A comprehensive guide\
    \ to Spacy by Real Python: <https://www.realpython.com/spacy-nlp-python/>\r\n\
    4. An introduction to Spacy and NLP with Python by Data Science Central: <https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python>\r\
    \n\r\nThese resources will help you dive deeper into the world of Spacy and NLP\
    \ (Natural Language Processing).\r\n\r\nI hope this helps! Don't hesitate to ask\
    \ if you have any more questions or need clarification on any part of the answer.\r\
    \n\r\nLess\r\n\r\n```\r\nHere are some additional resources to learn more about\
    \ Spacy:\r\n\r\n1. Spacy's official tutorials: <https://explore.spacy.io/>\r\n\
    2. Spacy's documentation: <https://spacy.io/usage>\r\n3. A comprehensive guide\
    \ to Spacy by Real Python: <https://www.realpython.com/spacy-nlp-python/>\r\n\
    4. An introduction to Spacy and NLP with Python by Data Science Central: <https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python>\r\
    \n\r\nThese resources will help you dive deeper into the world of Spacy and NLP\
    \ (Natural Language Processing).\r\n\r\nI hope this helps! Don't hesitate to ask\
    \ if you have any more questions or need clarification on any part of the answer.\r\
    \n\r\nLess\r\n\r\n```\r\nHere are some additional resources to learn more about\
    \ Spacy:\r\n\r\n1. Spacy's official tutorials: <https://explore.spacy.io/>\r\n\
    2. Spacy's documentation: <https://spacy.io/usage>\r\n3. A comprehensive guide\
    \ to Spacy by Real Python: <https://www.realpython.com/spacy-nlp-python/>\r\n\
    4. An introduction to Spacy and NLP with Python by Data Science Central: <https://datascience.community/courses/an-introduction-to-spacy-and-nlp-with-python>\r\
    \n\r\nThese resources will help you dive deeper into the world of Spacy and NLP\
    \ (Natural Language Processing).\r\n\r\nI hope this helps! Don't hesitate to ask\
    \ if you have any more questions or need clarification on any part of the answer.\r\
    \n```\r\n\r\nHere are some additional resources to learn more about Spacy:\r\n\
    ^C\r\n\r\n"
  created_at: 2023-11-28 16:27:40+00:00
  edited: false
  hidden: false
  id: 656614fc93e30c8a60d7ca85
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
      fullname: Banghua Zhu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: banghua
      type: user
    createdAt: '2023-11-28T16:51:01.000Z'
    data:
      edited: false
      editors:
      - banghua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9437816143035889
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
          fullname: Banghua Zhu
          isHf: false
          isPro: false
          name: banghua
          type: user
        html: '<p>Emm that''s an interesting question. May I ask if you''re using
          the default chat template? (GPT4 Correct User: Hello! GPT4 Correct Assistant:)
          The model with a wrong chat template will perform very poorly.<br>Actually
          for coding, the chat template can be changed for the coding template in
          the model card as well. Not sure how much that could help since we didn''t
          do RLHF on that template.</p>

          <p>Another possibility is to try a lower temperature, our testing suggests
          that temperature 0 might be slightly better than 0.7.</p>

          <p>You may want to first try a bit on chat.lmsys.org. If you also observe
          the same issue there, then it''ll just be the issue with the model.</p>

          <p>But still yes the model will output unnecessary content in some cases.
          We''re still working to fix it in the next version. Please stay tuned!</p>

          '
        raw: 'Emm that''s an interesting question. May I ask if you''re using the
          default chat template? (GPT4 Correct User: Hello! <end_of_turn>GPT4 Correct
          Assistant:) The model with a wrong chat template will perform very poorly.

          Actually for coding, the chat template can be changed for the coding template
          in the model card as well. Not sure how much that could help since we didn''t
          do RLHF on that template.


          Another possibility is to try a lower temperature, our testing suggests
          that temperature 0 might be slightly better than 0.7.


          You may want to first try a bit on chat.lmsys.org. If you also observe the
          same issue there, then it''ll just be the issue with the model.


          But still yes the model will output unnecessary content in some cases. We''re
          still working to fix it in the next version. Please stay tuned!'
        updatedAt: '2023-11-28T16:51:01.161Z'
      numEdits: 0
      reactions: []
    id: 65661a75a5ec0231cb10d648
    type: comment
  author: banghua
  content: 'Emm that''s an interesting question. May I ask if you''re using the default
    chat template? (GPT4 Correct User: Hello! <end_of_turn>GPT4 Correct Assistant:)
    The model with a wrong chat template will perform very poorly.

    Actually for coding, the chat template can be changed for the coding template
    in the model card as well. Not sure how much that could help since we didn''t
    do RLHF on that template.


    Another possibility is to try a lower temperature, our testing suggests that temperature
    0 might be slightly better than 0.7.


    You may want to first try a bit on chat.lmsys.org. If you also observe the same
    issue there, then it''ll just be the issue with the model.


    But still yes the model will output unnecessary content in some cases. We''re
    still working to fix it in the next version. Please stay tuned!'
  created_at: 2023-11-28 16:51:01+00:00
  edited: false
  hidden: false
  id: 65661a75a5ec0231cb10d648
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
      fullname: Ahmed Morsi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eramax
      type: user
    createdAt: '2023-11-29T16:52:00.000Z'
    data:
      edited: false
      editors:
      - eramax
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9941498637199402
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fdfaeb01aedd0e86014de9/UliF1du7InfuCs7RHLiA5.png?w=200&h=200&f=face
          fullname: Ahmed Morsi
          isHf: false
          isPro: false
          name: eramax
          type: user
        html: '<p>I tried with the suggested prompt format and had the same issue.</p>

          '
        raw: 'I tried with the suggested prompt format and had the same issue.

          '
        updatedAt: '2023-11-29T16:52:00.889Z'
      numEdits: 0
      reactions: []
    id: 65676c30461af93fca9fabe3
    type: comment
  author: eramax
  content: 'I tried with the suggested prompt format and had the same issue.

    '
  created_at: 2023-11-29 16:52:00+00:00
  edited: false
  hidden: false
  id: 65676c30461af93fca9fabe3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0fa2148c818aa15435d95fa3c424c98.svg
      fullname: Angelos Papageorgiou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: frenzygr
      type: user
    createdAt: '2023-12-03T18:32:54.000Z'
    data:
      edited: true
      editors:
      - frenzygr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7134645581245422
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0fa2148c818aa15435d95fa3c424c98.svg
          fullname: Angelos Papageorgiou
          isHf: false
          isPro: false
          name: frenzygr
          type: user
        html: '<p>I''m running into a similar issue I think and i''ve got the correct
          chat template, it keeps going and going without stopping</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/VW9xtBmavAax11M1HkVUq.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/VW9xtBmavAax11M1HkVUq.png"></a></p>

          '
        raw: 'I''m running into a similar issue I think and i''ve got the correct
          chat template, it keeps going and going without stopping



          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/VW9xtBmavAax11M1HkVUq.png)

          '
        updatedAt: '2023-12-03T18:36:04.799Z'
      numEdits: 2
      reactions: []
    id: 656cc9d6efd0eea7c5b878d4
    type: comment
  author: frenzygr
  content: 'I''m running into a similar issue I think and i''ve got the correct chat
    template, it keeps going and going without stopping



    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/VW9xtBmavAax11M1HkVUq.png)

    '
  created_at: 2023-12-03 18:32:54+00:00
  edited: true
  hidden: false
  id: 656cc9d6efd0eea7c5b878d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
      fullname: Banghua Zhu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: banghua
      type: user
    createdAt: '2023-12-03T19:18:42.000Z'
    data:
      edited: false
      editors:
      - banghua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6897516250610352
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
          fullname: Banghua Zhu
          isHf: false
          isPro: false
          name: banghua
          type: user
        html: '<p>Please follow the default chat template. The model is not finetuned
          on any system template, so please keep system message and prefix / suffix
          empty. For user message suffix, please use &lt;|end_of_turn|&gt;GPT Correct
          Assistant: </p>

          <p>Also it seems that the model you used here is not updated with the correct
          tokenizer, so it has &lt;0x0A&gt; rather than line change. </p>

          <p>Here is what I get with the same prompt + correct template from lmsys:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/647b8885aba7062fe5c32000/ZtMkxcTZCYtUDL16U73tX.jpeg"><img
          alt="lmsys.jpg" src="https://cdn-uploads.huggingface.co/production/uploads/647b8885aba7062fe5c32000/ZtMkxcTZCYtUDL16U73tX.jpeg"></a></p>

          '
        raw: "Please follow the default chat template. The model is not finetuned\
          \ on any system template, so please keep system message and prefix / suffix\
          \ empty. For user message suffix, please use <|end_of_turn|>GPT Correct\
          \ Assistant: \n\nAlso it seems that the model you used here is not updated\
          \ with the correct tokenizer, so it has <0x0A> rather than line change.\
          \ \n\nHere is what I get with the same prompt + correct template from lmsys:\n\
          \n![lmsys.jpg](https://cdn-uploads.huggingface.co/production/uploads/647b8885aba7062fe5c32000/ZtMkxcTZCYtUDL16U73tX.jpeg)\n"
        updatedAt: '2023-12-03T19:18:42.245Z'
      numEdits: 0
      reactions: []
    id: 656cd492d848a6683aeda66e
    type: comment
  author: banghua
  content: "Please follow the default chat template. The model is not finetuned on\
    \ any system template, so please keep system message and prefix / suffix empty.\
    \ For user message suffix, please use <|end_of_turn|>GPT Correct Assistant: \n\
    \nAlso it seems that the model you used here is not updated with the correct tokenizer,\
    \ so it has <0x0A> rather than line change. \n\nHere is what I get with the same\
    \ prompt + correct template from lmsys:\n\n![lmsys.jpg](https://cdn-uploads.huggingface.co/production/uploads/647b8885aba7062fe5c32000/ZtMkxcTZCYtUDL16U73tX.jpeg)\n"
  created_at: 2023-12-03 19:18:42+00:00
  edited: false
  hidden: false
  id: 656cd492d848a6683aeda66e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b0389d0bcec73364c6583e33f10f70b7.svg
      fullname: linbo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lixbo
      type: user
    createdAt: '2023-12-03T22:18:34.000Z'
    data:
      edited: false
      editors:
      - lixbo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9502487182617188
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b0389d0bcec73364c6583e33f10f70b7.svg
          fullname: linbo
          isHf: false
          isPro: false
          name: lixbo
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;frenzygr&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/frenzygr\">@<span class=\"\
          underline\">frenzygr</span></a></span>\n\n\t</span></span> I have the same\
          \ issue in LMstudio, but it works fine in KoboldCpp, btw you can see lmstudio\
          \ detecting the model as a Starcoder model, so gpu won't be supported that\
          \ way.</p>\n"
        raw: '@frenzygr I have the same issue in LMstudio, but it works fine in KoboldCpp,
          btw you can see lmstudio detecting the model as a Starcoder model, so gpu
          won''t be supported that way.'
        updatedAt: '2023-12-03T22:18:34.999Z'
      numEdits: 0
      reactions: []
    id: 656cfebab9fa60e33d053210
    type: comment
  author: lixbo
  content: '@frenzygr I have the same issue in LMstudio, but it works fine in KoboldCpp,
    btw you can see lmstudio detecting the model as a Starcoder model, so gpu won''t
    be supported that way.'
  created_at: 2023-12-03 22:18:34+00:00
  edited: false
  hidden: false
  id: 656cfebab9fa60e33d053210
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0fa2148c818aa15435d95fa3c424c98.svg
      fullname: Angelos Papageorgiou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: frenzygr
      type: user
    createdAt: '2023-12-03T22:46:40.000Z'
    data:
      edited: true
      editors:
      - frenzygr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9604119658470154
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0fa2148c818aa15435d95fa3c424c98.svg
          fullname: Angelos Papageorgiou
          isHf: false
          isPro: false
          name: frenzygr
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;frenzygr&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/frenzygr\"\
          >@<span class=\"underline\">frenzygr</span></a></span>\n\n\t</span></span>\
          \ I have the same issue in LMstudio, but it works fine in KoboldCpp, btw\
          \ you can see lmstudio detecting the model as a Starcoder model, so gpu\
          \ won't be supported that way.</p>\n</blockquote>\n<p>Does it detect it\
          \ as a Starcoder model for you too or is there a setting I can chage?</p>\n\
          <p>Tried it in KoboldCpp but unless I limit the generation tokens it still\
          \ goes on and on until it reaches the limit</p>\n"
        raw: '> @frenzygr I have the same issue in LMstudio, but it works fine in
          KoboldCpp, btw you can see lmstudio detecting the model as a Starcoder model,
          so gpu won''t be supported that way.


          Does it detect it as a Starcoder model for you too or is there a setting
          I can chage?


          Tried it in KoboldCpp but unless I limit the generation tokens it still
          goes on and on until it reaches the limit'
        updatedAt: '2023-12-03T22:47:19.230Z'
      numEdits: 1
      reactions: []
    id: 656d0550f39b7b6a5dda4baf
    type: comment
  author: frenzygr
  content: '> @frenzygr I have the same issue in LMstudio, but it works fine in KoboldCpp,
    btw you can see lmstudio detecting the model as a Starcoder model, so gpu won''t
    be supported that way.


    Does it detect it as a Starcoder model for you too or is there a setting I can
    chage?


    Tried it in KoboldCpp but unless I limit the generation tokens it still goes on
    and on until it reaches the limit'
  created_at: 2023-12-03 22:46:40+00:00
  edited: true
  hidden: false
  id: 656d0550f39b7b6a5dda4baf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0fa2148c818aa15435d95fa3c424c98.svg
      fullname: Angelos Papageorgiou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: frenzygr
      type: user
    createdAt: '2023-12-03T23:29:25.000Z'
    data:
      edited: false
      editors:
      - frenzygr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7619070410728455
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0fa2148c818aa15435d95fa3c424c98.svg
          fullname: Angelos Papageorgiou
          isHf: false
          isPro: false
          name: frenzygr
          type: user
        html: '<blockquote>

          <p>Please follow the default chat template. The model is not finetuned on
          any system template, so please keep system message and prefix / suffix empty.
          For user message suffix, please use &lt;|end_of_turn|&gt;GPT Correct Assistant:
          </p>

          <p>Also it seems that the model you used here is not updated with the correct
          tokenizer, so it has &lt;0x0A&gt; rather than line change. </p>

          <p>Here is what I get with the same prompt + correct template from lmsys:</p>

          </blockquote>

          <p>I believe I have the correct template now but it still keeps going indefinitely
          </p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/Zc-fvd2URSdo8M_zfhMTz.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/Zc-fvd2URSdo8M_zfhMTz.png"></a></p>

          '
        raw: "> Please follow the default chat template. The model is not finetuned\
          \ on any system template, so please keep system message and prefix / suffix\
          \ empty. For user message suffix, please use <|end_of_turn|>GPT Correct\
          \ Assistant: \n> \n> Also it seems that the model you used here is not updated\
          \ with the correct tokenizer, so it has <0x0A> rather than line change.\
          \ \n> \n> Here is what I get with the same prompt + correct template from\
          \ lmsys:\n\n\nI believe I have the correct template now but it still keeps\
          \ going indefinitely \n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/Zc-fvd2URSdo8M_zfhMTz.png)\n"
        updatedAt: '2023-12-03T23:29:25.115Z'
      numEdits: 0
      reactions: []
    id: 656d0f557825b310102916d6
    type: comment
  author: frenzygr
  content: "> Please follow the default chat template. The model is not finetuned\
    \ on any system template, so please keep system message and prefix / suffix empty.\
    \ For user message suffix, please use <|end_of_turn|>GPT Correct Assistant: \n\
    > \n> Also it seems that the model you used here is not updated with the correct\
    \ tokenizer, so it has <0x0A> rather than line change. \n> \n> Here is what I\
    \ get with the same prompt + correct template from lmsys:\n\n\nI believe I have\
    \ the correct template now but it still keeps going indefinitely \n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/Zc-fvd2URSdo8M_zfhMTz.png)\n"
  created_at: 2023-12-03 23:29:25+00:00
  edited: false
  hidden: false
  id: 656d0f557825b310102916d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b0389d0bcec73364c6583e33f10f70b7.svg
      fullname: linbo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lixbo
      type: user
    createdAt: '2023-12-04T01:47:01.000Z'
    data:
      edited: true
      editors:
      - lixbo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9141840934753418
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b0389d0bcec73364c6583e33f10f70b7.svg
          fullname: linbo
          isHf: false
          isPro: false
          name: lixbo
          type: user
        html: '<blockquote>

          <p>Tried it in KoboldCpp but unless I limit the generation tokens it still
          goes on and on until it reaches the limit</p>

          </blockquote>

          <p>I just tried it in LMStudio and I got the same issue as you, the problem
          is not the prompt format it''s from LMStudio certainly, I tested it in KoboldCpp
          and it worked fine if I give it large output context.<br>Also, verify that
          your model is updated, just check if the SHA256 code match from <a href="https://huggingface.co/TheBloke/Starling-LM-7B-alpha-GGUF/blob/main/starling-lm-7b-alpha.Q8_0.gguf">here</a>,
          if it doesn''t redownload the model.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/eXfYOUFIfXSSWdUvLmJtd.png"><img
          alt="ge.png" src="https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/eXfYOUFIfXSSWdUvLmJtd.png"></a></p>

          <blockquote>

          <p>Does it detect it as a Starcoder model for you too or is there a setting
          I can chage?</p>

          </blockquote>

          <p>It''s detecting the "star" in the model name and folder, try to change
          any letter and see.</p>

          '
        raw: '> Tried it in KoboldCpp but unless I limit the generation tokens it
          still goes on and on until it reaches the limit


          I just tried it in LMStudio and I got the same issue as you, the problem
          is not the prompt format it''s from LMStudio certainly, I tested it in KoboldCpp
          and it worked fine if I give it large output context.

          Also, verify that your model is updated, just check if the SHA256 code match
          from [here](https://huggingface.co/TheBloke/Starling-LM-7B-alpha-GGUF/blob/main/starling-lm-7b-alpha.Q8_0.gguf),
          if it doesn''t redownload the model.


          ![ge.png](https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/eXfYOUFIfXSSWdUvLmJtd.png)


          > Does it detect it as a Starcoder model for you too or is there a setting
          I can chage?


          It''s detecting the "star" in the model name and folder, try to change any
          letter and see.'
        updatedAt: '2023-12-04T01:47:48.116Z'
      numEdits: 1
      reactions: []
    id: 656d2f957825b310102f967d
    type: comment
  author: lixbo
  content: '> Tried it in KoboldCpp but unless I limit the generation tokens it still
    goes on and on until it reaches the limit


    I just tried it in LMStudio and I got the same issue as you, the problem is not
    the prompt format it''s from LMStudio certainly, I tested it in KoboldCpp and
    it worked fine if I give it large output context.

    Also, verify that your model is updated, just check if the SHA256 code match from
    [here](https://huggingface.co/TheBloke/Starling-LM-7B-alpha-GGUF/blob/main/starling-lm-7b-alpha.Q8_0.gguf),
    if it doesn''t redownload the model.


    ![ge.png](https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/eXfYOUFIfXSSWdUvLmJtd.png)


    > Does it detect it as a Starcoder model for you too or is there a setting I can
    chage?


    It''s detecting the "star" in the model name and folder, try to change any letter
    and see.'
  created_at: 2023-12-04 01:47:01+00:00
  edited: true
  hidden: false
  id: 656d2f957825b310102f967d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0fa2148c818aa15435d95fa3c424c98.svg
      fullname: Angelos Papageorgiou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: frenzygr
      type: user
    createdAt: '2023-12-07T18:50:35.000Z'
    data:
      edited: true
      editors:
      - frenzygr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8810817003250122
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0fa2148c818aa15435d95fa3c424c98.svg
          fullname: Angelos Papageorgiou
          isHf: false
          isPro: false
          name: frenzygr
          type: user
        html: '<blockquote>

          <blockquote>

          <p>Tried it in KoboldCpp but unless I limit the generation tokens it still
          goes on and on until it reaches the limit</p>

          </blockquote>

          <p>I just tried it in LMStudio and I got the same issue as you, the problem
          is not the prompt format it''s from LMStudio certainly, I tested it in KoboldCpp
          and it worked fine if I give it large output context.<br>Also, verify that
          your model is updated, just check if the SHA256 code match from <a href="https://huggingface.co/TheBloke/Starling-LM-7B-alpha-GGUF/blob/main/starling-lm-7b-alpha.Q8_0.gguf">here</a>,
          if it doesn''t redownload the model.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/eXfYOUFIfXSSWdUvLmJtd.png"><img
          alt="ge.png" src="https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/eXfYOUFIfXSSWdUvLmJtd.png"></a></p>

          <blockquote>

          <p>Does it detect it as a Starcoder model for you too or is there a setting
          I can chage?</p>

          </blockquote>

          <p>It''s detecting the "star" in the model name and folder, try to change
          any letter and see.</p>

          </blockquote>

          <p>I still get the same behaviour, can you please paste a couple small screenshots
          of all your settings before you lunch the kobold app and for the model itself?</p>

          <p>I appreciate it!</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/3IrJg3ZDTy17uZI-lhVLO.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/3IrJg3ZDTy17uZI-lhVLO.png"></a></p>

          '
        raw: "> > Tried it in KoboldCpp but unless I limit the generation tokens it\
          \ still goes on and on until it reaches the limit\n> \n> I just tried it\
          \ in LMStudio and I got the same issue as you, the problem is not the prompt\
          \ format it's from LMStudio certainly, I tested it in KoboldCpp and it worked\
          \ fine if I give it large output context.\n> Also, verify that your model\
          \ is updated, just check if the SHA256 code match from [here](https://huggingface.co/TheBloke/Starling-LM-7B-alpha-GGUF/blob/main/starling-lm-7b-alpha.Q8_0.gguf),\
          \ if it doesn't redownload the model.\n> \n> ![ge.png](https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/eXfYOUFIfXSSWdUvLmJtd.png)\n\
          > \n> > Does it detect it as a Starcoder model for you too or is there a\
          \ setting I can chage?\n> \n> It's detecting the \"star\" in the model name\
          \ and folder, try to change any letter and see.\n\nI still get the same\
          \ behaviour, can you please paste a couple small screenshots of all your\
          \ settings before you lunch the kobold app and for the model itself?\n\n\
          I appreciate it!\n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/3IrJg3ZDTy17uZI-lhVLO.png)\n"
        updatedAt: '2023-12-07T18:50:56.812Z'
      numEdits: 1
      reactions: []
    id: 657213fb3ada38603f832575
    type: comment
  author: frenzygr
  content: "> > Tried it in KoboldCpp but unless I limit the generation tokens it\
    \ still goes on and on until it reaches the limit\n> \n> I just tried it in LMStudio\
    \ and I got the same issue as you, the problem is not the prompt format it's from\
    \ LMStudio certainly, I tested it in KoboldCpp and it worked fine if I give it\
    \ large output context.\n> Also, verify that your model is updated, just check\
    \ if the SHA256 code match from [here](https://huggingface.co/TheBloke/Starling-LM-7B-alpha-GGUF/blob/main/starling-lm-7b-alpha.Q8_0.gguf),\
    \ if it doesn't redownload the model.\n> \n> ![ge.png](https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/eXfYOUFIfXSSWdUvLmJtd.png)\n\
    > \n> > Does it detect it as a Starcoder model for you too or is there a setting\
    \ I can chage?\n> \n> It's detecting the \"star\" in the model name and folder,\
    \ try to change any letter and see.\n\nI still get the same behaviour, can you\
    \ please paste a couple small screenshots of all your settings before you lunch\
    \ the kobold app and for the model itself?\n\nI appreciate it!\n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64274118826a6d2ceee3855e/3IrJg3ZDTy17uZI-lhVLO.png)\n"
  created_at: 2023-12-07 18:50:35+00:00
  edited: true
  hidden: false
  id: 657213fb3ada38603f832575
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b0389d0bcec73364c6583e33f10f70b7.svg
      fullname: linbo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lixbo
      type: user
    createdAt: '2023-12-07T19:59:23.000Z'
    data:
      edited: false
      editors:
      - lixbo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7401688694953918
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b0389d0bcec73364c6583e33f10f70b7.svg
          fullname: linbo
          isHf: false
          isPro: false
          name: lixbo
          type: user
        html: '<p>I load it with the default configuration then change one thing,
          Context size to 4096.<br>After it loads I used the Default preset, and in
          Start Seq put: "&lt;|end_of_turn|&gt;GPT4 User:" and in End Seq: "&lt;|end_of_turn|&gt;GPT4
          Assistant:" without the quotes.</p>

          <p>Did you make sure you have the updated model?<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/Sb3SE7CZpTXZQRPm4UGDW.png"><img
          alt="Untitldeed.png" src="https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/Sb3SE7CZpTXZQRPm4UGDW.png"></a></p>

          '
        raw: "I load it with the default configuration then change one thing, Context\
          \ size to 4096. \nAfter it loads I used the Default preset, and in Start\
          \ Seq put: \"<|end_of_turn|>GPT4 User:\" and in End Seq: \"<|end_of_turn|>GPT4\
          \ Assistant:\" without the quotes.\n\nDid you make sure you have the updated\
          \ model?\n![Untitldeed.png](https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/Sb3SE7CZpTXZQRPm4UGDW.png)\n"
        updatedAt: '2023-12-07T19:59:23.378Z'
      numEdits: 0
      reactions: []
    id: 6572241b695c0626e61cd33c
    type: comment
  author: lixbo
  content: "I load it with the default configuration then change one thing, Context\
    \ size to 4096. \nAfter it loads I used the Default preset, and in Start Seq put:\
    \ \"<|end_of_turn|>GPT4 User:\" and in End Seq: \"<|end_of_turn|>GPT4 Assistant:\"\
    \ without the quotes.\n\nDid you make sure you have the updated model?\n![Untitldeed.png](https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/Sb3SE7CZpTXZQRPm4UGDW.png)\n"
  created_at: 2023-12-07 19:59:23+00:00
  edited: false
  hidden: false
  id: 6572241b695c0626e61cd33c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0fa2148c818aa15435d95fa3c424c98.svg
      fullname: Angelos Papageorgiou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: frenzygr
      type: user
    createdAt: '2023-12-07T23:02:42.000Z'
    data:
      edited: true
      editors:
      - frenzygr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7752947211265564
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0fa2148c818aa15435d95fa3c424c98.svg
          fullname: Angelos Papageorgiou
          isHf: false
          isPro: false
          name: frenzygr
          type: user
        html: '<blockquote>

          <p>I load it with the default configuration then change one thing, Context
          size to 4096.<br>After it loads I used the Default preset, and in Start
          Seq put: "&lt;|end_of_turn|&gt;GPT4 User:" and in End Seq: "&lt;|end_of_turn|&gt;GPT4
          Assistant:" without the quotes.</p>

          <p>Did you make sure you have the updated model?<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/Sb3SE7CZpTXZQRPm4UGDW.png"><img
          alt="Untitldeed.png" src="https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/Sb3SE7CZpTXZQRPm4UGDW.png"></a></p>

          </blockquote>

          <p>thanks! got it working in Kobolt but still face the same issue in LM
          studio! ill mess around with it a bit more</p>

          <p>EDIT: Got it working on LM studio as well! </p>

          <p>EDIT2: Nvm it got back to spewing entire walls of text without changing
          any parameters.</p>

          '
        raw: "> I load it with the default configuration then change one thing, Context\
          \ size to 4096. \n> After it loads I used the Default preset, and in Start\
          \ Seq put: \"<|end_of_turn|>GPT4 User:\" and in End Seq: \"<|end_of_turn|>GPT4\
          \ Assistant:\" without the quotes.\n> \n> Did you make sure you have the\
          \ updated model?\n> ![Untitldeed.png](https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/Sb3SE7CZpTXZQRPm4UGDW.png)\n\
          \n\nthanks! got it working in Kobolt but still face the same issue in LM\
          \ studio! ill mess around with it a bit more\n\nEDIT: Got it working on\
          \ LM studio as well! \n\nEDIT2: Nvm it got back to spewing entire walls\
          \ of text without changing any parameters.\n"
        updatedAt: '2023-12-07T23:18:08.986Z'
      numEdits: 2
      reactions: []
    id: 65724f122bb242937cf364c4
    type: comment
  author: frenzygr
  content: "> I load it with the default configuration then change one thing, Context\
    \ size to 4096. \n> After it loads I used the Default preset, and in Start Seq\
    \ put: \"<|end_of_turn|>GPT4 User:\" and in End Seq: \"<|end_of_turn|>GPT4 Assistant:\"\
    \ without the quotes.\n> \n> Did you make sure you have the updated model?\n>\
    \ ![Untitldeed.png](https://cdn-uploads.huggingface.co/production/uploads/656651f49593e6086a07fd2a/Sb3SE7CZpTXZQRPm4UGDW.png)\n\
    \n\nthanks! got it working in Kobolt but still face the same issue in LM studio!\
    \ ill mess around with it a bit more\n\nEDIT: Got it working on LM studio as well!\
    \ \n\nEDIT2: Nvm it got back to spewing entire walls of text without changing\
    \ any parameters.\n"
  created_at: 2023-12-07 23:02:42+00:00
  edited: true
  hidden: false
  id: 65724f122bb242937cf364c4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: berkeley-nest/Starling-LM-7B-alpha
repo_type: model
status: open
target_branch: null
title: best model params
