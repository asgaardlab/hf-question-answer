!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Yhyu13
conflicting_files: null
created_at: 2023-11-29 03:04:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-11-29T03:04:15.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9481040835380554
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<p>Hi,</p>

          <p>Your base model was Openchat3.5 whose base was Mistral-7B, the sad thing
          is that they have not yet released larger models. </p>

          <p>And from AlpacaEval <a rel="nofollow" href="https://tatsu-lab.github.io/alpaca_eval/">https://tatsu-lab.github.io/alpaca_eval/</a>,
          we generally observe the trend that larger models with same FT method perform
          better, e.g. the XWin series (which is also a RLHF model).</p>

          <p>Maybe you can try out Yi-34B, seems to be the best mid-size model so
          far.</p>

          <p>Thanks!</p>

          '
        raw: "Hi,\r\n\r\nYour base model was Openchat3.5 whose base was Mistral-7B,\
          \ the sad thing is that they have not yet released larger models. \r\n\r\
          \nAnd from AlpacaEval https://tatsu-lab.github.io/alpaca_eval/, we generally\
          \ observe the trend that larger models with same FT method perform better,\
          \ e.g. the XWin series (which is also a RLHF model).\r\n\r\nMaybe you can\
          \ try out Yi-34B, seems to be the best mid-size model so far.\r\n\r\nThanks!\r\
          \n"
        updatedAt: '2023-11-29T03:04:15.564Z'
      numEdits: 0
      reactions: []
    id: 6566aa2f929782bee9c2c288
    type: comment
  author: Yhyu13
  content: "Hi,\r\n\r\nYour base model was Openchat3.5 whose base was Mistral-7B,\
    \ the sad thing is that they have not yet released larger models. \r\n\r\nAnd\
    \ from AlpacaEval https://tatsu-lab.github.io/alpaca_eval/, we generally observe\
    \ the trend that larger models with same FT method perform better, e.g. the XWin\
    \ series (which is also a RLHF model).\r\n\r\nMaybe you can try out Yi-34B, seems\
    \ to be the best mid-size model so far.\r\n\r\nThanks!\r\n"
  created_at: 2023-11-29 03:04:15+00:00
  edited: false
  hidden: false
  id: 6566aa2f929782bee9c2c288
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
      fullname: Banghua Zhu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: banghua
      type: user
    createdAt: '2023-11-29T04:36:15.000Z'
    data:
      edited: false
      editors:
      - banghua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9651500582695007
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
          fullname: Banghua Zhu
          isHf: false
          isPro: false
          name: banghua
          type: user
        html: '<p>Thank you for the suggestion! That''s also on our TO-DO list. </p>

          <p>Currently we still observe some instable and weird behavior of the model,
          so we are working on a beta version first before testing a larger reward
          &amp; policy model.</p>

          <p>During our evaluation, we also found that 7B model tends to hallucilate
          a lot, which is incomparable to 30+B models and greatly affect the human
          evaluation score. So having a larger model seems to be a must in this case.
          We believe that our dataset might have larger potential when scaling the
          reward model and language model, although the biggest problem is still the
          limited compute for training large reward &amp; language model.</p>

          '
        raw: "Thank you for the suggestion! That's also on our TO-DO list. \n\nCurrently\
          \ we still observe some instable and weird behavior of the model, so we\
          \ are working on a beta version first before testing a larger reward & policy\
          \ model.\n\nDuring our evaluation, we also found that 7B model tends to\
          \ hallucilate a lot, which is incomparable to 30+B models and greatly affect\
          \ the human evaluation score. So having a larger model seems to be a must\
          \ in this case. We believe that our dataset might have larger potential\
          \ when scaling the reward model and language model, although the biggest\
          \ problem is still the limited compute for training large reward & language\
          \ model.\n"
        updatedAt: '2023-11-29T04:36:15.387Z'
      numEdits: 0
      reactions:
      - count: 7
        reaction: "\U0001F917"
        users:
        - Yhyu13
        - imone
        - Sigmally
        - eramax
        - CyberTimon
        - Jason233
        - InvidFlower
    id: 6566bfbf751591e4fae00421
    type: comment
  author: banghua
  content: "Thank you for the suggestion! That's also on our TO-DO list. \n\nCurrently\
    \ we still observe some instable and weird behavior of the model, so we are working\
    \ on a beta version first before testing a larger reward & policy model.\n\nDuring\
    \ our evaluation, we also found that 7B model tends to hallucilate a lot, which\
    \ is incomparable to 30+B models and greatly affect the human evaluation score.\
    \ So having a larger model seems to be a must in this case. We believe that our\
    \ dataset might have larger potential when scaling the reward model and language\
    \ model, although the biggest problem is still the limited compute for training\
    \ large reward & language model.\n"
  created_at: 2023-11-29 04:36:15+00:00
  edited: false
  hidden: false
  id: 6566bfbf751591e4fae00421
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: berkeley-nest/Starling-LM-7B-alpha
repo_type: model
status: open
target_branch: null
title: Maybe you could try on Yi-34B
