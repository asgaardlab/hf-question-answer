!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rjmehta
conflicting_files: null
created_at: 2023-11-29 05:08:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-11-29T05:08:02.000Z'
    data:
      edited: false
      editors:
      - rjmehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8757839798927307
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
          fullname: Raj Mehta
          isHf: false
          isPro: false
          name: rjmehta
          type: user
        html: '<p>How to enable context block in order to answer only from the context?<br>Currently,
          I use this. It works fine but talks too much and generates a lot of tokens.</p>

          <p>GPT4 Instructions: For the GPT4 User question below, provide an answer
          from the GPT4 Context. Only answer from GPT4 Context. If the GPT4 User question
          is unrelated to GPT4 Context, respond ''I dont know''&lt;|end_of_turn|&gt;</p>

          <p>GPT4 Context: {context_text_block}&lt;|end_of_turn|&gt;</p>

          <p>GPT4 User: {question}&lt;|end_of_turn|&gt;</p>

          <p> GPT4 Assistant:</p>

          '
        raw: "How to enable context block in order to answer only from the context?\r\
          \nCurrently, I use this. It works fine but talks too much and generates\
          \ a lot of tokens.\r\n\r\nGPT4 Instructions: For the GPT4 User question\
          \ below, provide an answer from the GPT4 Context. Only answer from GPT4\
          \ Context. If the GPT4 User question is unrelated to GPT4 Context, respond\
          \ 'I dont know'<|end_of_turn|>\r\n\r\nGPT4 Context: {context_text_block}<|end_of_turn|>\r\
          \n\r\nGPT4 User: {question}<|end_of_turn|>\r\n\r\n GPT4 Assistant:"
        updatedAt: '2023-11-29T05:08:02.601Z'
      numEdits: 0
      reactions: []
    id: 6566c73293951c950b56bf26
    type: comment
  author: rjmehta
  content: "How to enable context block in order to answer only from the context?\r\
    \nCurrently, I use this. It works fine but talks too much and generates a lot\
    \ of tokens.\r\n\r\nGPT4 Instructions: For the GPT4 User question below, provide\
    \ an answer from the GPT4 Context. Only answer from GPT4 Context. If the GPT4\
    \ User question is unrelated to GPT4 Context, respond 'I dont know'<|end_of_turn|>\r\
    \n\r\nGPT4 Context: {context_text_block}<|end_of_turn|>\r\n\r\nGPT4 User: {question}<|end_of_turn|>\r\
    \n\r\n GPT4 Assistant:"
  created_at: 2023-11-29 05:08:02+00:00
  edited: false
  hidden: false
  id: 6566c73293951c950b56bf26
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
      fullname: Banghua Zhu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: banghua
      type: user
    createdAt: '2023-11-29T07:20:26.000Z'
    data:
      edited: false
      editors:
      - banghua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9337573647499084
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
          fullname: Banghua Zhu
          isHf: false
          isPro: false
          name: banghua
          type: user
        html: '<p>Thank you! Could you please try it with the default prompt "GPT4
          Correct User: Hello&lt;|end_of_turn|&gt;GPT4 Correct Assistant:"?  This
          "Correct" is also necessary to get the highest possible performance out
          of the model. There''re some code examples in the model card as well.</p>

          <p>For this case, you might also want to try different prompting. I think
          you can try sth like "only provide answer from the context below without
          outputting any extra word. If no answer present, output "no answer present"".
          Because during training, the model only sees &lt;|end_of_turn|&gt; followed
          by GPT Correct Assistant / GPT Correct User. This extra context prompt and
          additional &lt;|end_of_turn|&gt; might make the model confused. </p>

          <p>But it''s still likely that the model will output verbose content. We''re
          getting tons of new checkpoints and are picking some better ones for our
          beta version. Stay tuned!</p>

          '
        raw: "Thank you! Could you please try it with the default prompt \"GPT4 Correct\
          \ User: Hello<|end_of_turn|>GPT4 Correct Assistant:\"?  This \"Correct\"\
          \ is also necessary to get the highest possible performance out of the model.\
          \ There're some code examples in the model card as well.\n\nFor this case,\
          \ you might also want to try different prompting. I think you can try sth\
          \ like \"only provide answer from the context below without outputting any\
          \ extra word. If no answer present, output \"no answer present\"\". Because\
          \ during training, the model only sees <|end_of_turn|> followed by GPT Correct\
          \ Assistant / GPT Correct User. This extra context prompt and additional\
          \ <|end_of_turn|> might make the model confused. \n\nBut it's still likely\
          \ that the model will output verbose content. We're getting tons of new\
          \ checkpoints and are picking some better ones for our beta version. Stay\
          \ tuned!"
        updatedAt: '2023-11-29T07:20:26.301Z'
      numEdits: 0
      reactions: []
    id: 6566e63ad3420657cd0f0934
    type: comment
  author: banghua
  content: "Thank you! Could you please try it with the default prompt \"GPT4 Correct\
    \ User: Hello<|end_of_turn|>GPT4 Correct Assistant:\"?  This \"Correct\" is also\
    \ necessary to get the highest possible performance out of the model. There're\
    \ some code examples in the model card as well.\n\nFor this case, you might also\
    \ want to try different prompting. I think you can try sth like \"only provide\
    \ answer from the context below without outputting any extra word. If no answer\
    \ present, output \"no answer present\"\". Because during training, the model\
    \ only sees <|end_of_turn|> followed by GPT Correct Assistant / GPT Correct User.\
    \ This extra context prompt and additional <|end_of_turn|> might make the model\
    \ confused. \n\nBut it's still likely that the model will output verbose content.\
    \ We're getting tons of new checkpoints and are picking some better ones for our\
    \ beta version. Stay tuned!"
  created_at: 2023-11-29 07:20:26+00:00
  edited: false
  hidden: false
  id: 6566e63ad3420657cd0f0934
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630fd20ac3962881af78540e/Khm_MPV2l_PxZoFpMDIWd.jpeg?w=200&h=200&f=face
      fullname: Mikel Bober-Irizar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: anokas
      type: user
    createdAt: '2023-11-29T13:32:39.000Z'
    data:
      edited: false
      editors:
      - anokas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8327421545982361
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630fd20ac3962881af78540e/Khm_MPV2l_PxZoFpMDIWd.jpeg?w=200&h=200&f=face
          fullname: Mikel Bober-Irizar
          isHf: false
          isPro: false
          name: anokas
          type: user
        html: '<p>Was this trained with system messages at all? If so, what''s the
          ''correct'' way to inject this into the prompt?</p>

          '
        raw: Was this trained with system messages at all? If so, what's the 'correct'
          way to inject this into the prompt?
        updatedAt: '2023-11-29T13:32:39.396Z'
      numEdits: 0
      reactions: []
    id: 65673d775fc491087485ec72
    type: comment
  author: anokas
  content: Was this trained with system messages at all? If so, what's the 'correct'
    way to inject this into the prompt?
  created_at: 2023-11-29 13:32:39+00:00
  edited: false
  hidden: false
  id: 65673d775fc491087485ec72
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
      fullname: Banghua Zhu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: banghua
      type: user
    createdAt: '2023-11-29T14:38:34.000Z'
    data:
      edited: false
      editors:
      - banghua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9697302579879761
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
          fullname: Banghua Zhu
          isHf: false
          isPro: false
          name: banghua
          type: user
        html: '<p>In the RLHF phase we did not. I believe the base model Openchat
          3.5 also didn''t train with system prompt. I''d suggest directly put system
          prompt at the beginning of user prompt without any other formatting.</p>

          '
        raw: In the RLHF phase we did not. I believe the base model Openchat 3.5 also
          didn't train with system prompt. I'd suggest directly put system prompt
          at the beginning of user prompt without any other formatting.
        updatedAt: '2023-11-29T14:38:34.728Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - eramax
    id: 65674cea063938c9b40365c1
    type: comment
  author: banghua
  content: In the RLHF phase we did not. I believe the base model Openchat 3.5 also
    didn't train with system prompt. I'd suggest directly put system prompt at the
    beginning of user prompt without any other formatting.
  created_at: 2023-11-29 14:38:34+00:00
  edited: false
  hidden: false
  id: 65674cea063938c9b40365c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-11-29T17:15:51.000Z'
    data:
      edited: false
      editors:
      - rjmehta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9114627242088318
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
          fullname: Raj Mehta
          isHf: false
          isPro: false
          name: rjmehta
          type: user
        html: '<p>What about the Context block for RAG task? Should I include the
          context in before user as GPT4 Correct Context or add in the GPT4 Correct
          User block itself?</p>

          '
        raw: What about the Context block for RAG task? Should I include the context
          in before user as GPT4 Correct Context or add in the GPT4 Correct User block
          itself?
        updatedAt: '2023-11-29T17:15:51.061Z'
      numEdits: 0
      reactions: []
    id: 656771c7d1cb9f0b6432baf1
    type: comment
  author: rjmehta
  content: What about the Context block for RAG task? Should I include the context
    in before user as GPT4 Correct Context or add in the GPT4 Correct User block itself?
  created_at: 2023-11-29 17:15:51+00:00
  edited: false
  hidden: false
  id: 656771c7d1cb9f0b6432baf1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
      fullname: Banghua Zhu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: banghua
      type: user
    createdAt: '2023-11-29T17:49:13.000Z'
    data:
      edited: false
      editors:
      - banghua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9618319869041443
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/128ceae78490110ae41202851e84d58e.svg
          fullname: Banghua Zhu
          isHf: false
          isPro: false
          name: banghua
          type: user
        html: '<p>I''d recommend add in the GPT4 Correct User block itself. And maybe
          point out in natural language specifically that "this paragraph is context"
          or sth like that.</p>

          '
        raw: I'd recommend add in the GPT4 Correct User block itself. And maybe point
          out in natural language specifically that "this paragraph is context" or
          sth like that.
        updatedAt: '2023-11-29T17:49:13.215Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - rjmehta
    id: 656779995fc491087491ac63
    type: comment
  author: banghua
  content: I'd recommend add in the GPT4 Correct User block itself. And maybe point
    out in natural language specifically that "this paragraph is context" or sth like
    that.
  created_at: 2023-11-29 17:49:13+00:00
  edited: false
  hidden: false
  id: 656779995fc491087491ac63
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/e03299d063da54fa6d8c455d27ca4786.svg
      fullname: Raj Mehta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rjmehta
      type: user
    createdAt: '2023-12-01T17:27:55.000Z'
    data:
      status: closed
    id: 656a179bfa91c81609e8289d
    type: status-change
  author: rjmehta
  created_at: 2023-12-01 17:27:55+00:00
  id: 656a179bfa91c81609e8289d
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: berkeley-nest/Starling-LM-7B-alpha
repo_type: model
status: closed
target_branch: null
title: Prompt template for adding RAG Context block
