!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xerxes01
conflicting_files: null
created_at: 2023-04-06 08:50:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/afe6793b2446da5d53dcd51ea367bf95.svg
      fullname: shikhar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xerxes01
      type: user
    createdAt: '2023-04-06T09:50:02.000Z'
    data:
      edited: false
      editors:
      - xerxes01
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/afe6793b2446da5d53dcd51ea367bf95.svg
          fullname: shikhar
          isHf: false
          isPro: false
          name: xerxes01
          type: user
        html: '<p>Getting this error when I try to load the model using HuggingFace:</p>

          <p>ValueError: Tokenizer class LlamaTokenizer does not exist or is not currently
          imported.</p>

          '
        raw: "Getting this error when I try to load the model using HuggingFace:\r\
          \n\r\nValueError: Tokenizer class LlamaTokenizer does not exist or is not\
          \ currently imported."
        updatedAt: '2023-04-06T09:50:02.799Z'
      numEdits: 0
      reactions:
      - count: 8
        reaction: "\U0001F44D"
        users:
        - MrMoonsilver
        - areshytko
        - drusepth
        - subhasis79
        - maraoz
        - whoknowsmeinhf
        - goniatia
        - DarioTekstAi
    id: 642e95ca3c2cf43f6d6f4ed7
    type: comment
  author: xerxes01
  content: "Getting this error when I try to load the model using HuggingFace:\r\n\
    \r\nValueError: Tokenizer class LlamaTokenizer does not exist or is not currently\
    \ imported."
  created_at: 2023-04-06 08:50:02+00:00
  edited: false
  hidden: false
  id: 642e95ca3c2cf43f6d6f4ed7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2aa85df44ff24543d8be/mEnbGB_0Flleoa6SWp5b6.jpeg?w=200&h=200&f=face
      fullname: amkdg
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: eachadea
      type: user
    createdAt: '2023-04-06T10:21:21.000Z'
    data:
      edited: false
      editors:
      - eachadea
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2aa85df44ff24543d8be/mEnbGB_0Flleoa6SWp5b6.jpeg?w=200&h=200&f=face
          fullname: amkdg
          isHf: false
          isPro: false
          name: eachadea
          type: user
        html: '<p>I''ve updated all of the files to match lmsys/vicuna-13b-delta-v0</p>

          <p>Not sure what could be causing this. Are you getting the same error on
          the delta files?</p>

          '
        raw: 'I''ve updated all of the files to match lmsys/vicuna-13b-delta-v0


          Not sure what could be causing this. Are you getting the same error on the
          delta files?'
        updatedAt: '2023-04-06T10:21:21.642Z'
      numEdits: 0
      reactions: []
    id: 642e9d2142b948db1fa33e22
    type: comment
  author: eachadea
  content: 'I''ve updated all of the files to match lmsys/vicuna-13b-delta-v0


    Not sure what could be causing this. Are you getting the same error on the delta
    files?'
  created_at: 2023-04-06 09:21:21+00:00
  edited: false
  hidden: false
  id: 642e9d2142b948db1fa33e22
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1657272186747-610c24310a0fe5d9414b39da.png?w=200&h=200&f=face
      fullname: Isotonic
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Isotonic
      type: user
    createdAt: '2023-04-06T11:33:01.000Z'
    data:
      edited: true
      editors:
      - Isotonic
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1657272186747-610c24310a0fe5d9414b39da.png?w=200&h=200&f=face
          fullname: Isotonic
          isHf: false
          isPro: false
          name: Isotonic
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;xerxes01&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/xerxes01\">@<span class=\"\
          underline\">xerxes01</span></a></span>\n\n\t</span></span> Which transformers\
          \ version are you using?? I get the same error when using transformers version\
          \ 4.27.4, in the FastChat repo its mentioned that we use transformers with\
          \ a particular commit id. <code>(Installed using this command \"pip3 install\
          \ git+https://github.com/huggingface/transformers.git@c612628045822f909020f7eb6784c79700813eda\"\
          )</code><br>But i am unable to run inference on the model, <span data-props=\"\
          {&quot;user&quot;:&quot;eachadea&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/eachadea\">@<span class=\"underline\">eachadea</span></a></span>\n\
          \n\t</span></span>  could you please link a colab notebook running the model?</p>\n\
          <p>if i use multiple gpus i keep getting <code>TypeError: dispatch_model()\
          \ got an unexpected keyword argument 'offload_index'</code></p>\n"
        raw: '@xerxes01 Which transformers version are you using?? I get the same
          error when using transformers version 4.27.4, in the FastChat repo its mentioned
          that we use transformers with a particular commit id. `(Installed using
          this command "pip3 install git+https://github.com/huggingface/transformers.git@c612628045822f909020f7eb6784c79700813eda")`

          But i am unable to run inference on the model, @eachadea  could you please
          link a colab notebook running the model?


          if i use multiple gpus i keep getting `TypeError: dispatch_model() got an
          unexpected keyword argument ''offload_index''`'
        updatedAt: '2023-04-06T11:40:13.546Z'
      numEdits: 2
      reactions: []
    id: 642eadedb874e0f2b7f095f4
    type: comment
  author: Isotonic
  content: '@xerxes01 Which transformers version are you using?? I get the same error
    when using transformers version 4.27.4, in the FastChat repo its mentioned that
    we use transformers with a particular commit id. `(Installed using this command
    "pip3 install git+https://github.com/huggingface/transformers.git@c612628045822f909020f7eb6784c79700813eda")`

    But i am unable to run inference on the model, @eachadea  could you please link
    a colab notebook running the model?


    if i use multiple gpus i keep getting `TypeError: dispatch_model() got an unexpected
    keyword argument ''offload_index''`'
  created_at: 2023-04-06 10:33:01+00:00
  edited: true
  hidden: false
  id: 642eadedb874e0f2b7f095f4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fb961937d0b7fc34fa200da6630fd063.svg
      fullname: Yves
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MrMoonsilver
      type: user
    createdAt: '2023-04-07T17:44:05.000Z'
    data:
      edited: false
      editors:
      - MrMoonsilver
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fb961937d0b7fc34fa200da6630fd063.svg
          fullname: Yves
          isHf: false
          isPro: false
          name: MrMoonsilver
          type: user
        html: '<p>Had the same issue as xerxes01</p>

          '
        raw: Had the same issue as xerxes01
        updatedAt: '2023-04-07T17:44:05.885Z'
      numEdits: 0
      reactions: []
    id: 643056658d72442d90071040
    type: comment
  author: MrMoonsilver
  content: Had the same issue as xerxes01
  created_at: 2023-04-07 16:44:05+00:00
  edited: false
  hidden: false
  id: 643056658d72442d90071040
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/227f170ae55e9e8b39b5f08d0f11ce5a.svg
      fullname: Michael Chludzinski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hirengurth
      type: user
    createdAt: '2023-04-07T23:11:21.000Z'
    data:
      edited: false
      editors:
      - Hirengurth
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/227f170ae55e9e8b39b5f08d0f11ce5a.svg
          fullname: Michael Chludzinski
          isHf: false
          isPro: false
          name: Hirengurth
          type: user
        html: '<p>same here followed the instruction and tried several things floating
          around even did a second clean setup. still an issue.</p>

          '
        raw: same here followed the instruction and tried several things floating
          around even did a second clean setup. still an issue.
        updatedAt: '2023-04-07T23:11:21.853Z'
      numEdits: 0
      reactions: []
    id: 6430a319ba4e05dd8b709e0f
    type: comment
  author: Hirengurth
  content: same here followed the instruction and tried several things floating around
    even did a second clean setup. still an issue.
  created_at: 2023-04-07 22:11:21+00:00
  edited: false
  hidden: false
  id: 6430a319ba4e05dd8b709e0f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2841be944b1401bb6db9ed2e2bfd77df.svg
      fullname: Victor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: stdvictor
      type: user
    createdAt: '2023-04-09T02:08:54.000Z'
    data:
      edited: false
      editors:
      - stdvictor
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2841be944b1401bb6db9ed2e2bfd77df.svg
          fullname: Victor
          isHf: false
          isPro: false
          name: stdvictor
          type: user
        html: '<p>The token error should be related to this issue: <a rel="nofollow"
          href="https://github.com/huggingface/transformers/issues/22222">https://github.com/huggingface/transformers/issues/22222</a></p>

          '
        raw: 'The token error should be related to this issue: https://github.com/huggingface/transformers/issues/22222'
        updatedAt: '2023-04-09T02:08:54.882Z'
      numEdits: 0
      reactions: []
    id: 64321e36f2355217ea48824a
    type: comment
  author: stdvictor
  content: 'The token error should be related to this issue: https://github.com/huggingface/transformers/issues/22222'
  created_at: 2023-04-09 01:08:54+00:00
  edited: false
  hidden: false
  id: 64321e36f2355217ea48824a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b4094da51a9827c422d1747cb5a08cd2.svg
      fullname: Andrew Brown
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: drusepth
      type: user
    createdAt: '2023-04-13T06:13:47.000Z'
    data:
      edited: true
      editors:
      - drusepth
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b4094da51a9827c422d1747cb5a08cd2.svg
          fullname: Andrew Brown
          isHf: false
          isPro: false
          name: drusepth
          type: user
        html: "<blockquote>\n<p>The token error should be related to this issue: <a\
          \ rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/issues/22222\"\
          >https://github.com/huggingface/transformers/issues/22222</a></p>\n</blockquote>\n\
          <p>I'm not sure this is related, as that error was regarding LLaMATokenizer\
          \ not existing (and suggesting to use LlamaTokenizer instead), whereas it\
          \ looks like OP's error is complaining that LlamaTokenizer does not exist.</p>\n\
          <p>I also have this error with another form of Vicuna and updating transformers\
          \ (or pinning it to previous commits) doesn't seem to have an effect. Stack\
          \ trace for capitalization example:</p>\n<pre><code>(base) $ sudo docker\
          \ run -p 80:80 -e MODEL=eachadea/vicuna-13b hyperonym/basaran:0.14.1\nDownloading\
          \ (\u2026)okenizer_config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 727/727 [00:00&lt;00:00, 107kB/s]\nTraceback (most\
          \ recent call last):\n  File \"/usr/lib/python3.8/runpy.py\", line 194,\
          \ in _run_module_as_main\n    return _run_code(code, main_globals, None,\n\
          \  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code,\
          \ run_globals)\n  File \"/app/basaran/__main__.py\", line 38, in &lt;module&gt;\n\
          \    stream_model = load_model(\n  File \"/app/basaran/model.py\", line\
          \ 318, in load_model\n    tokenizer = AutoTokenizer.from_pretrained(name_or_path,\
          \ **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 676, in from_pretrained\n    raise ValueError(\nValueError: Tokenizer\
          \ class LlamaTokenizer does not exist or is not currently imported.\n</code></pre>\n"
        raw: "> The token error should be related to this issue: https://github.com/huggingface/transformers/issues/22222\n\
          \nI'm not sure this is related, as that error was regarding LLaMATokenizer\
          \ not existing (and suggesting to use LlamaTokenizer instead), whereas it\
          \ looks like OP's error is complaining that LlamaTokenizer does not exist.\n\
          \nI also have this error with another form of Vicuna and updating transformers\
          \ (or pinning it to previous commits) doesn't seem to have an effect. Stack\
          \ trace for capitalization example:\n\n```\n(base) $ sudo docker run -p\
          \ 80:80 -e MODEL=eachadea/vicuna-13b hyperonym/basaran:0.14.1\nDownloading\
          \ (\u2026)okenizer_config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 727/727 [00:00<00:00, 107kB/s]\nTraceback (most\
          \ recent call last):\n  File \"/usr/lib/python3.8/runpy.py\", line 194,\
          \ in _run_module_as_main\n    return _run_code(code, main_globals, None,\n\
          \  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code,\
          \ run_globals)\n  File \"/app/basaran/__main__.py\", line 38, in <module>\n\
          \    stream_model = load_model(\n  File \"/app/basaran/model.py\", line\
          \ 318, in load_model\n    tokenizer = AutoTokenizer.from_pretrained(name_or_path,\
          \ **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py\"\
          , line 676, in from_pretrained\n    raise ValueError(\nValueError: Tokenizer\
          \ class LlamaTokenizer does not exist or is not currently imported.\n```"
        updatedAt: '2023-04-13T06:24:02.390Z'
      numEdits: 1
      reactions: []
    id: 64379d9b40bf2c4964f2f483
    type: comment
  author: drusepth
  content: "> The token error should be related to this issue: https://github.com/huggingface/transformers/issues/22222\n\
    \nI'm not sure this is related, as that error was regarding LLaMATokenizer not\
    \ existing (and suggesting to use LlamaTokenizer instead), whereas it looks like\
    \ OP's error is complaining that LlamaTokenizer does not exist.\n\nI also have\
    \ this error with another form of Vicuna and updating transformers (or pinning\
    \ it to previous commits) doesn't seem to have an effect. Stack trace for capitalization\
    \ example:\n\n```\n(base) $ sudo docker run -p 80:80 -e MODEL=eachadea/vicuna-13b\
    \ hyperonym/basaran:0.14.1\nDownloading (\u2026)okenizer_config.json: 100%|\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 727/727 [00:00<00:00,\
    \ 107kB/s]\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/runpy.py\"\
    , line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n\
    \  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code,\
    \ run_globals)\n  File \"/app/basaran/__main__.py\", line 38, in <module>\n  \
    \  stream_model = load_model(\n  File \"/app/basaran/model.py\", line 318, in\
    \ load_model\n    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)\n\
    \  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py\"\
    , line 676, in from_pretrained\n    raise ValueError(\nValueError: Tokenizer class\
    \ LlamaTokenizer does not exist or is not currently imported.\n```"
  created_at: 2023-04-13 05:13:47+00:00
  edited: true
  hidden: false
  id: 64379d9b40bf2c4964f2f483
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6ac6de56a1a63d06eb0e3ada7969e053.svg
      fullname: Sanjay Kotabagi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjaymk
      type: user
    createdAt: '2023-07-20T15:06:15.000Z'
    data:
      edited: false
      editors:
      - sanjaymk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9655978679656982
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6ac6de56a1a63d06eb0e3ada7969e053.svg
          fullname: Sanjay Kotabagi
          isHf: false
          isPro: false
          name: sanjaymk
          type: user
        html: '<p>Did anyone find solution ?</p>

          '
        raw: 'Did anyone find solution ?

          '
        updatedAt: '2023-07-20T15:06:15.258Z'
      numEdits: 0
      reactions: []
    id: 64b94d67126cfeb8fde58244
    type: comment
  author: sanjaymk
  content: 'Did anyone find solution ?

    '
  created_at: 2023-07-20 14:06:15+00:00
  edited: false
  hidden: false
  id: 64b94d67126cfeb8fde58244
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5c195e8a0b36b4b953887b480db79df4.svg
      fullname: wei zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zwei2023
      type: user
    createdAt: '2023-07-23T02:41:27.000Z'
    data:
      edited: false
      editors:
      - zwei2023
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6906396746635437
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5c195e8a0b36b4b953887b480db79df4.svg
          fullname: wei zhang
          isHf: false
          isPro: false
          name: zwei2023
          type: user
        html: '<p>facing the same issue, when loading FreeWilly model...<br><a href="https://huggingface.co/stabilityai/FreeWilly2">https://huggingface.co/stabilityai/FreeWilly2</a></p>

          '
        raw: 'facing the same issue, when loading FreeWilly model...

          https://huggingface.co/stabilityai/FreeWilly2'
        updatedAt: '2023-07-23T02:41:27.740Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - jfrancoisponcet
        - shiotama
        - maraoz
    id: 64bc93579a69e8da48ba2ef1
    type: comment
  author: zwei2023
  content: 'facing the same issue, when loading FreeWilly model...

    https://huggingface.co/stabilityai/FreeWilly2'
  created_at: 2023-07-23 01:41:27+00:00
  edited: false
  hidden: false
  id: 64bc93579a69e8da48ba2ef1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: eachadea/legacy-vicuna-13b
repo_type: model
status: open
target_branch: null
title: Tokenizer class LlamaTokenizer does not exist
