!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mocherson
conflicting_files: null
created_at: 2023-04-04 01:06:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/217375de5ce086255c38af105f429c6a.svg
      fullname: Chengsheng Mao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mocherson
      type: user
    createdAt: '2023-04-04T02:06:19.000Z'
    data:
      edited: false
      editors:
      - mocherson
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/217375de5ce086255c38af105f429c6a.svg
          fullname: Chengsheng Mao
          isHf: false
          isPro: false
          name: mocherson
          type: user
        html: '<p>The example in Quickstart loads the model into cpu for running.
          I know model.cuda() can move the mode to gpu for small models. How to distribute
          the model to multiple gpus and to run the generation for large models?  Thanks.</p>

          '
        raw: The example in Quickstart loads the model into cpu for running. I know
          model.cuda() can move the mode to gpu for small models. How to distribute
          the model to multiple gpus and to run the generation for large models?  Thanks.
        updatedAt: '2023-04-04T02:06:19.200Z'
      numEdits: 0
      reactions: []
    id: 642b861b5df44ff24545fbc4
    type: comment
  author: mocherson
  content: The example in Quickstart loads the model into cpu for running. I know
    model.cuda() can move the mode to gpu for small models. How to distribute the
    model to multiple gpus and to run the generation for large models?  Thanks.
  created_at: 2023-04-04 01:06:19+00:00
  edited: false
  hidden: false
  id: 642b861b5df44ff24545fbc4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c908f5d3f493296bae29fb/vlczac90Je1dd826vObeS.jpeg?w=200&h=200&f=face
      fullname: Richard Kuzma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rskuzma
      type: user
    createdAt: '2023-04-04T11:54:14.000Z'
    data:
      edited: false
      editors:
      - rskuzma
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c908f5d3f493296bae29fb/vlczac90Je1dd826vObeS.jpeg?w=200&h=200&f=face
          fullname: Richard Kuzma
          isHf: false
          isPro: false
          name: rskuzma
          type: user
        html: '<p>This Hugging Face guide for inference with large models using <code>accelerate</code>
          may be helpful with distributing the model: <a href="https://huggingface.co/docs/accelerate/usage_guides/big_modeling">https://huggingface.co/docs/accelerate/usage_guides/big_modeling</a></p>

          '
        raw: 'This Hugging Face guide for inference with large models using `accelerate`
          may be helpful with distributing the model: https://huggingface.co/docs/accelerate/usage_guides/big_modeling'
        updatedAt: '2023-04-04T11:54:14.819Z'
      numEdits: 0
      reactions: []
      relatedEventId: 642c0fe6722bc53c77814608
    id: 642c0fe6722bc53c77814607
    type: comment
  author: rskuzma
  content: 'This Hugging Face guide for inference with large models using `accelerate`
    may be helpful with distributing the model: https://huggingface.co/docs/accelerate/usage_guides/big_modeling'
  created_at: 2023-04-04 10:54:14+00:00
  edited: false
  hidden: false
  id: 642c0fe6722bc53c77814607
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c908f5d3f493296bae29fb/vlczac90Je1dd826vObeS.jpeg?w=200&h=200&f=face
      fullname: Richard Kuzma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rskuzma
      type: user
    createdAt: '2023-04-04T11:54:14.000Z'
    data:
      status: closed
    id: 642c0fe6722bc53c77814608
    type: status-change
  author: rskuzma
  created_at: 2023-04-04 10:54:14+00:00
  id: 642c0fe6722bc53c77814608
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: cerebras/Cerebras-GPT-13B
repo_type: model
status: closed
target_branch: null
title: How to run with multiple GPUs.
