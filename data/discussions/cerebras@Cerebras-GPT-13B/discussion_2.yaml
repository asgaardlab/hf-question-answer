!!python/object:huggingface_hub.community.DiscussionWithDetails
author: spanielrassler
conflicting_files: null
created_at: 2023-04-02 22:56:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0d146e4b922a325b69d3d509965ed60.svg
      fullname: Frankie G
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: spanielrassler
      type: user
    createdAt: '2023-04-02T23:56:16.000Z'
    data:
      edited: false
      editors:
      - spanielrassler
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0d146e4b922a325b69d3d509965ed60.svg
          fullname: Frankie G
          isHf: false
          isPro: false
          name: spanielrassler
          type: user
        html: '<p>I''m sure this is a stupid questions, but how do I merge the bin
          files into one file that can be used as a model? Final model name should
          be pytorch_model.bin but with 2 separate .bin files not sure how to do that.</p>

          '
        raw: I'm sure this is a stupid questions, but how do I merge the bin files
          into one file that can be used as a model? Final model name should be pytorch_model.bin
          but with 2 separate .bin files not sure how to do that.
        updatedAt: '2023-04-02T23:56:16.259Z'
      numEdits: 0
      reactions: []
    id: 642a16208136224fee0ae37b
    type: comment
  author: spanielrassler
  content: I'm sure this is a stupid questions, but how do I merge the bin files into
    one file that can be used as a model? Final model name should be pytorch_model.bin
    but with 2 separate .bin files not sure how to do that.
  created_at: 2023-04-02 22:56:16+00:00
  edited: false
  hidden: false
  id: 642a16208136224fee0ae37b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c908f5d3f493296bae29fb/vlczac90Je1dd826vObeS.jpeg?w=200&h=200&f=face
      fullname: Richard Kuzma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rskuzma
      type: user
    createdAt: '2023-04-03T12:05:09.000Z'
    data:
      edited: false
      editors:
      - rskuzma
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60c908f5d3f493296bae29fb/vlczac90Je1dd826vObeS.jpeg?w=200&h=200&f=face
          fullname: Richard Kuzma
          isHf: false
          isPro: false
          name: rskuzma
          type: user
        html: '<p>The transformers library automatically shards large models with
          the <code>save_pretrained()</code> method into partial checkpoints and an
          index that maps parameter names to the files they are stored in. The model
          be loaded by passing the model directory (e.g., <code>./my_model_directory/</code>)
          to <code>from_pretrained()</code>. </p>

          <p>These links may be helpful <a href="https://huggingface.co/docs/transformers/big_models">https://huggingface.co/docs/transformers/big_models</a>
          and <a rel="nofollow" href="https://github.com/huggingface/transformers/blob/v4.27.2/src/transformers/modeling_utils.py#L1833">https://github.com/huggingface/transformers/blob/v4.27.2/src/transformers/modeling_utils.py#L1833</a></p>

          '
        raw: "The transformers library automatically shards large models with the\
          \ `save_pretrained()` method into partial checkpoints and an index that\
          \ maps parameter names to the files they are stored in. The model be loaded\
          \ by passing the model directory (e.g., `./my_model_directory/`) to `from_pretrained()`.\
          \ \n\nThese links may be helpful https://huggingface.co/docs/transformers/big_models\
          \ and https://github.com/huggingface/transformers/blob/v4.27.2/src/transformers/modeling_utils.py#L1833"
        updatedAt: '2023-04-03T12:05:09.812Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - Mastercaster
        - ukiml
        - saiisa
        - Yao-Lirong
        - ByteSized
    id: 642ac0f5fe4a12faa4276662
    type: comment
  author: rskuzma
  content: "The transformers library automatically shards large models with the `save_pretrained()`\
    \ method into partial checkpoints and an index that maps parameter names to the\
    \ files they are stored in. The model be loaded by passing the model directory\
    \ (e.g., `./my_model_directory/`) to `from_pretrained()`. \n\nThese links may\
    \ be helpful https://huggingface.co/docs/transformers/big_models and https://github.com/huggingface/transformers/blob/v4.27.2/src/transformers/modeling_utils.py#L1833"
  created_at: 2023-04-03 11:05:09+00:00
  edited: false
  hidden: false
  id: 642ac0f5fe4a12faa4276662
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: cerebras/Cerebras-GPT-13B
repo_type: model
status: open
target_branch: null
title: How to merge the 2 bin files into the pytorch_model.bin file for usage?
