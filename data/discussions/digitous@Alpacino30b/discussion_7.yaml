!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JackalAI
conflicting_files: null
created_at: 2023-05-23 16:53:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d0e1400a669c114db339290aa673b982.svg
      fullname: Some Jackal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JackalAI
      type: user
    createdAt: '2023-05-23T17:53:13.000Z'
    data:
      edited: false
      editors:
      - JackalAI
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d0e1400a669c114db339290aa673b982.svg
          fullname: Some Jackal
          isHf: false
          isPro: false
          name: JackalAI
          type: user
        html: '<p>Hi There!</p>

          <p>I''m new to a lot of this, and have a very constrained schedule, so I
          haven''t been able to dedicate the time I''d really like to start doing
          the level of training that interests me. So far, I''ve only been doing LoRA
          training on oobabooga, and I''ve gotten OOM right at the end of every training
          attempt through that method on 30B+ models.</p>

          <p>Is there a particular script or framework you use for training, merging,
          etc on these larger models that allows for use of multiple GPUs? I figure
          I''m probably going to need to buckle down and read some books/papers to
          really understand what''s going on, but things are moving so fast it''s
          hard to know where I can best spend my time learning.</p>

          <p>Either way, really appreciate the work you''ve done here!</p>

          <p>-J</p>

          '
        raw: "Hi There!\r\n\r\nI'm new to a lot of this, and have a very constrained\
          \ schedule, so I haven't been able to dedicate the time I'd really like\
          \ to start doing the level of training that interests me. So far, I've only\
          \ been doing LoRA training on oobabooga, and I've gotten OOM right at the\
          \ end of every training attempt through that method on 30B+ models.\r\n\r\
          \nIs there a particular script or framework you use for training, merging,\
          \ etc on these larger models that allows for use of multiple GPUs? I figure\
          \ I'm probably going to need to buckle down and read some books/papers to\
          \ really understand what's going on, but things are moving so fast it's\
          \ hard to know where I can best spend my time learning.\r\n\r\nEither way,\
          \ really appreciate the work you've done here!\r\n\r\n-J"
        updatedAt: '2023-05-23T17:53:13.276Z'
      numEdits: 0
      reactions: []
    id: 646cfd89534e52f8c304acec
    type: comment
  author: JackalAI
  content: "Hi There!\r\n\r\nI'm new to a lot of this, and have a very constrained\
    \ schedule, so I haven't been able to dedicate the time I'd really like to start\
    \ doing the level of training that interests me. So far, I've only been doing\
    \ LoRA training on oobabooga, and I've gotten OOM right at the end of every training\
    \ attempt through that method on 30B+ models.\r\n\r\nIs there a particular script\
    \ or framework you use for training, merging, etc on these larger models that\
    \ allows for use of multiple GPUs? I figure I'm probably going to need to buckle\
    \ down and read some books/papers to really understand what's going on, but things\
    \ are moving so fast it's hard to know where I can best spend my time learning.\r\
    \n\r\nEither way, really appreciate the work you've done here!\r\n\r\n-J"
  created_at: 2023-05-23 16:53:13+00:00
  edited: false
  hidden: false
  id: 646cfd89534e52f8c304acec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
      fullname: Erik
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: digitous
      type: user
    createdAt: '2023-05-25T23:01:48.000Z'
    data:
      edited: false
      editors:
      - digitous
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
          fullname: Erik
          isHf: false
          isPro: false
          name: digitous
          type: user
        html: '<p>Thanks for asking and your interest!</p>

          <p>Weird as it sounds, I don''t train these models or the LoRAs used in
          them; I use a model merge script and a lora merge script to do the work
          that goes into these.</p>

          <p><a rel="nofollow" href="https://github.com/Digitous/Enhanced-LM-Mixer">https://github.com/Digitous/Enhanced-LM-Mixer</a><br><a
          rel="nofollow" href="https://github.com/tloen/alpaca-lora">https://github.com/tloen/alpaca-lora</a></p>

          '
        raw: 'Thanks for asking and your interest!


          Weird as it sounds, I don''t train these models or the LoRAs used in them;
          I use a model merge script and a lora merge script to do the work that goes
          into these.


          https://github.com/Digitous/Enhanced-LM-Mixer

          https://github.com/tloen/alpaca-lora'
        updatedAt: '2023-05-25T23:01:48.358Z'
      numEdits: 0
      reactions: []
    id: 646fe8dcd1f1b73079eee81a
    type: comment
  author: digitous
  content: 'Thanks for asking and your interest!


    Weird as it sounds, I don''t train these models or the LoRAs used in them; I use
    a model merge script and a lora merge script to do the work that goes into these.


    https://github.com/Digitous/Enhanced-LM-Mixer

    https://github.com/tloen/alpaca-lora'
  created_at: 2023-05-25 22:01:48+00:00
  edited: false
  hidden: false
  id: 646fe8dcd1f1b73079eee81a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d0e1400a669c114db339290aa673b982.svg
      fullname: Some Jackal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JackalAI
      type: user
    createdAt: '2023-05-29T21:18:13.000Z'
    data:
      edited: false
      editors:
      - JackalAI
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d0e1400a669c114db339290aa673b982.svg
          fullname: Some Jackal
          isHf: false
          isPro: false
          name: JackalAI
          type: user
        html: '<p>Appreciate the answer anyway! Every link I get together gets me
          a bit closer to working in this ecosystem. Lots of fun to be had, I think!</p>

          <p>Take care, and thanks again for the models and the engagement!</p>

          <p>-J</p>

          '
        raw: 'Appreciate the answer anyway! Every link I get together gets me a bit
          closer to working in this ecosystem. Lots of fun to be had, I think!


          Take care, and thanks again for the models and the engagement!


          -J'
        updatedAt: '2023-05-29T21:18:13.140Z'
      numEdits: 0
      reactions: []
    id: 64751695f9e3e0b312f45045
    type: comment
  author: JackalAI
  content: 'Appreciate the answer anyway! Every link I get together gets me a bit
    closer to working in this ecosystem. Lots of fun to be had, I think!


    Take care, and thanks again for the models and the engagement!


    -J'
  created_at: 2023-05-29 20:18:13+00:00
  edited: false
  hidden: false
  id: 64751695f9e3e0b312f45045
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: digitous/Alpacino30b
repo_type: model
status: open
target_branch: null
title: Training Setup
