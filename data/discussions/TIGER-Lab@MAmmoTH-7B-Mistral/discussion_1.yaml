!!python/object:huggingface_hub.community.DiscussionWithDetails
author: loveisp
conflicting_files: null
created_at: 2023-12-06 21:20:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/48f239d3971031a7618e668e63e462ab.svg
      fullname: dv
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: loveisp
      type: user
    createdAt: '2023-12-06T21:20:33.000Z'
    data:
      edited: false
      editors:
      - loveisp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8299310803413391
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/48f239d3971031a7618e668e63e462ab.svg
          fullname: dv
          isHf: false
          isPro: false
          name: loveisp
          type: user
        html: '<p>When I try to load the model using VLLM, it consumes all of my memory
          (128G) and throws an Out-of-Memory (OOM) error. The pipeline from transformers
          library can be used, but the inference results are abnormal.</p>

          '
        raw: When I try to load the model using VLLM, it consumes all of my memory
          (128G) and throws an Out-of-Memory (OOM) error. The pipeline from transformers
          library can be used, but the inference results are abnormal.
        updatedAt: '2023-12-06T21:20:33.060Z'
      numEdits: 0
      reactions: []
    id: 6570e5a13e68d88fd61043dd
    type: comment
  author: loveisp
  content: When I try to load the model using VLLM, it consumes all of my memory (128G)
    and throws an Out-of-Memory (OOM) error. The pipeline from transformers library
    can be used, but the inference results are abnormal.
  created_at: 2023-12-06 21:20:33+00:00
  edited: false
  hidden: false
  id: 6570e5a13e68d88fd61043dd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg?w=200&h=200&f=face
      fullname: Wenhu Chen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: wenhu
      type: user
    createdAt: '2023-12-07T17:43:42.000Z'
    data:
      edited: false
      editors:
      - wenhu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7525870203971863
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg?w=200&h=200&f=face
          fullname: Wenhu Chen
          isHf: false
          isPro: false
          name: wenhu
          type: user
        html: '<p>Is this OOM for CPU or GPU? It should work fine. I have the inference
          code in <a rel="nofollow" href="https://github.com/TIGER-AI-Lab/MAmmoTH/blob/main/requirements.txt">https://github.com/TIGER-AI-Lab/MAmmoTH/blob/main/requirements.txt</a>.</p>

          '
        raw: Is this OOM for CPU or GPU? It should work fine. I have the inference
          code in https://github.com/TIGER-AI-Lab/MAmmoTH/blob/main/requirements.txt.
        updatedAt: '2023-12-07T17:43:42.256Z'
      numEdits: 0
      reactions: []
    id: 6572044ee14deda7b70a90f3
    type: comment
  author: wenhu
  content: Is this OOM for CPU or GPU? It should work fine. I have the inference code
    in https://github.com/TIGER-AI-Lab/MAmmoTH/blob/main/requirements.txt.
  created_at: 2023-12-07 17:43:42+00:00
  edited: false
  hidden: false
  id: 6572044ee14deda7b70a90f3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/48f239d3971031a7618e668e63e462ab.svg
      fullname: dv
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: loveisp
      type: user
    createdAt: '2023-12-08T15:03:49.000Z'
    data:
      edited: false
      editors:
      - loveisp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9765193462371826
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/48f239d3971031a7618e668e63e462ab.svg
          fullname: dv
          isHf: false
          isPro: false
          name: loveisp
          type: user
        html: '<p>It is CPU OOM. The memory consumption keeps growing and eventually
          consumes all of my 128GB memory, which shouldn''t be the case. Other models
          from Mammoth don''t exhibit this issue.</p>

          '
        raw: It is CPU OOM. The memory consumption keeps growing and eventually consumes
          all of my 128GB memory, which shouldn't be the case. Other models from Mammoth
          don't exhibit this issue.
        updatedAt: '2023-12-08T15:03:49.843Z'
      numEdits: 0
      reactions: []
    id: 65733055769f3ee9bddefc13
    type: comment
  author: loveisp
  content: It is CPU OOM. The memory consumption keeps growing and eventually consumes
    all of my 128GB memory, which shouldn't be the case. Other models from Mammoth
    don't exhibit this issue.
  created_at: 2023-12-08 15:03:49+00:00
  edited: false
  hidden: false
  id: 65733055769f3ee9bddefc13
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg?w=200&h=200&f=face
      fullname: Wenhu Chen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: wenhu
      type: user
    createdAt: '2023-12-09T02:44:39.000Z'
    data:
      edited: false
      editors:
      - wenhu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.97883141040802
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg?w=200&h=200&f=face
          fullname: Wenhu Chen
          isHf: false
          isPro: false
          name: wenhu
          type: user
        html: '<p>I see. Normally inference won''t take that much memory. Can you
          confirm whether it''s from vllm or from the mistral model itself (huggingface
          transformers)? I think these two would be mainly the sources.</p>

          '
        raw: I see. Normally inference won't take that much memory. Can you confirm
          whether it's from vllm or from the mistral model itself (huggingface transformers)?
          I think these two would be mainly the sources.
        updatedAt: '2023-12-09T02:44:39.432Z'
      numEdits: 0
      reactions: []
    id: 6573d4974fffc3f08b25830c
    type: comment
  author: wenhu
  content: I see. Normally inference won't take that much memory. Can you confirm
    whether it's from vllm or from the mistral model itself (huggingface transformers)?
    I think these two would be mainly the sources.
  created_at: 2023-12-09 02:44:39+00:00
  edited: false
  hidden: false
  id: 6573d4974fffc3f08b25830c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/48f239d3971031a7618e668e63e462ab.svg
      fullname: dv
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: loveisp
      type: user
    createdAt: '2023-12-11T03:26:54.000Z'
    data:
      edited: false
      editors:
      - loveisp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9398146271705627
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/48f239d3971031a7618e668e63e462ab.svg
          fullname: dv
          isHf: false
          isPro: false
          name: loveisp
          type: user
        html: '<p>I tried using huggingface''s transformers instead of vllm, and I
          did encounter the same out-of-memory issue.</p>

          '
        raw: I tried using huggingface's transformers instead of vllm, and I did encounter
          the same out-of-memory issue.
        updatedAt: '2023-12-11T03:26:54.031Z'
      numEdits: 0
      reactions: []
    id: 6576817e9091da7dc688e691
    type: comment
  author: loveisp
  content: I tried using huggingface's transformers instead of vllm, and I did encounter
    the same out-of-memory issue.
  created_at: 2023-12-11 03:26:54+00:00
  edited: false
  hidden: false
  id: 6576817e9091da7dc688e691
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TIGER-Lab/MAmmoTH-7B-Mistral
repo_type: model
status: open
target_branch: null
title: some issues
