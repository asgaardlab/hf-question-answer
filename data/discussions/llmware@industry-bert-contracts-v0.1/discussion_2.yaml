!!python/object:huggingface_hub.community.DiscussionWithDetails
author: basilevc
conflicting_files: null
created_at: 2023-11-27 09:38:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5cb3808b3b4b14fb86b1169dd35d7960.svg
      fullname: Basile Van Cooten
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: basilevc
      type: user
    createdAt: '2023-11-27T09:38:38.000Z'
    data:
      edited: false
      editors:
      - basilevc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9011826515197754
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5cb3808b3b4b14fb86b1169dd35d7960.svg
          fullname: Basile Van Cooten
          isHf: false
          isPro: false
          name: basilevc
          type: user
        html: "<p>First of all, thanks for the nice work and sharing your model  \U0001F917\
          </p>\n<p>I have a few questions regarding the family of models \"industry\
          \ bert\" your team has provided here:</p>\n<ul>\n<li>what kind of pooling\
          \ method do we use to obtain embeddings from your models? I saw <a rel=\"\
          nofollow\" href=\"https://github.com/llmware-ai/llmware/blob/main/llmware/models.py#L2123\"\
          >here</a> that you use the CLS (i.e first embedding vector for HF) but would\
          \ like to be sure</li>\n<li>do you normalize your embeddings ? </li>\n<li>what\
          \ kind of distance metric is to be used? L2 / dot ?</li>\n<li>have you validated\
          \ your models on some kind of industry retrieval benchmark ? if so would\
          \ you be comfortable sharing it ?</li>\n</ul>\n<p>also, just FYI (and you\
          \ probably already know this) to make your model easily loadable via the\
          \ Sentence BERT framework, you could attach a configuration file such as\
          \ <a href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/blob/main/modules.json#L14-L19\"\
          >this</a> model (you obtain these files when you serialize the model via\
          \ the Sentence Bert Model class): it would make your model seamlessly usable.</p>\n"
        raw: "First of all, thanks for the nice work and sharing your model  \U0001F917\
          \r\n\r\nI have a few questions regarding the family of models \"industry\
          \ bert\" your team has provided here:\r\n- what kind of pooling method do\
          \ we use to obtain embeddings from your models? I saw [here](https://github.com/llmware-ai/llmware/blob/main/llmware/models.py#L2123)\
          \ that you use the CLS (i.e first embedding vector for HF) but would like\
          \ to be sure\r\n- do you normalize your embeddings ? \r\n- what kind of\
          \ distance metric is to be used? L2 / dot ?\r\n- have you validated your\
          \ models on some kind of industry retrieval benchmark ? if so would you\
          \ be comfortable sharing it ?\r\n\r\nalso, just FYI (and you probably already\
          \ know this) to make your model easily loadable via the Sentence BERT framework,\
          \ you could attach a configuration file such as [this](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/blob/main/modules.json#L14-L19)\
          \ model (you obtain these files when you serialize the model via the Sentence\
          \ Bert Model class): it would make your model seamlessly usable.\r\n"
        updatedAt: '2023-11-27T09:38:38.058Z'
      numEdits: 0
      reactions: []
    id: 6564639e0a385b9f116f1ecc
    type: comment
  author: basilevc
  content: "First of all, thanks for the nice work and sharing your model  \U0001F917\
    \r\n\r\nI have a few questions regarding the family of models \"industry bert\"\
    \ your team has provided here:\r\n- what kind of pooling method do we use to obtain\
    \ embeddings from your models? I saw [here](https://github.com/llmware-ai/llmware/blob/main/llmware/models.py#L2123)\
    \ that you use the CLS (i.e first embedding vector for HF) but would like to be\
    \ sure\r\n- do you normalize your embeddings ? \r\n- what kind of distance metric\
    \ is to be used? L2 / dot ?\r\n- have you validated your models on some kind of\
    \ industry retrieval benchmark ? if so would you be comfortable sharing it ?\r\
    \n\r\nalso, just FYI (and you probably already know this) to make your model easily\
    \ loadable via the Sentence BERT framework, you could attach a configuration file\
    \ such as [this](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/blob/main/modules.json#L14-L19)\
    \ model (you obtain these files when you serialize the model via the Sentence\
    \ Bert Model class): it would make your model seamlessly usable.\r\n"
  created_at: 2023-11-27 09:38:38+00:00
  edited: false
  hidden: false
  id: 6564639e0a385b9f116f1ecc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: llmware/industry-bert-contracts-v0.1
repo_type: model
status: open
target_branch: null
title: pooling method and results
