!!python/object:huggingface_hub.community.DiscussionWithDetails
author: skoll520
conflicting_files: null
created_at: 2024-01-10 20:55:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/315c6e6f2e3c0aeea36fd9a8853a97f4.svg
      fullname: "R\xF3ger Nascimento Santos"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: skoll520
      type: user
    createdAt: '2024-01-10T20:55:10.000Z'
    data:
      edited: false
      editors:
      - skoll520
      hidden: false
      identifiedLanguage:
        language: pt
        probability: 0.9912490844726562
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/315c6e6f2e3c0aeea36fd9a8853a97f4.svg
          fullname: "R\xF3ger Nascimento Santos"
          isHf: false
          isPro: false
          name: skoll520
          type: user
        html: "<p>por favor, posta o merge dele, preciso testar, mas em .gguf, n\xE3\
          o consigo carregar 7b sem ser 8bit aqui. Carregando em 8bit n\xE3o consigo\
          \ converter pra gguf pq o llama.cpp n\xE3o entende int 8...</p>\n"
        raw: "por favor, posta o merge dele, preciso testar, mas em .gguf, n\xE3o\
          \ consigo carregar 7b sem ser 8bit aqui. Carregando em 8bit n\xE3o consigo\
          \ converter pra gguf pq o llama.cpp n\xE3o entende int 8..."
        updatedAt: '2024-01-10T20:55:10.389Z'
      numEdits: 0
      reactions: []
    id: 659f042e44a230e92ca99989
    type: comment
  author: skoll520
  content: "por favor, posta o merge dele, preciso testar, mas em .gguf, n\xE3o consigo\
    \ carregar 7b sem ser 8bit aqui. Carregando em 8bit n\xE3o consigo converter pra\
    \ gguf pq o llama.cpp n\xE3o entende int 8..."
  created_at: 2024-01-10 20:55:10+00:00
  edited: false
  hidden: false
  id: 659f042e44a230e92ca99989
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62fbd9c53c7ab1f8c2762e8b/mIzAbdzrjPPohBkvTglFq.jpeg?w=200&h=200&f=face
      fullname: Pedro Henrique Paiola
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: phpaiola
      type: user
    createdAt: '2024-01-12T20:47:57.000Z'
    data:
      edited: false
      editors:
      - phpaiola
      hidden: false
      identifiedLanguage:
        language: pt
        probability: 0.2862306237220764
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62fbd9c53c7ab1f8c2762e8b/mIzAbdzrjPPohBkvTglFq.jpeg?w=200&h=200&f=face
          fullname: Pedro Henrique Paiola
          isHf: false
          isPro: false
          name: phpaiola
          type: user
        html: '<p>Segue o merge do modelo: <a href="https://huggingface.co/recogna-nlp/bode-7b-alpaca-pt-br-no-peft">https://huggingface.co/recogna-nlp/bode-7b-alpaca-pt-br-no-peft</a><br>Nos
          avise se funcionar devidamente :D</p>

          '
        raw: 'Segue o merge do modelo: https://huggingface.co/recogna-nlp/bode-7b-alpaca-pt-br-no-peft

          Nos avise se funcionar devidamente :D'
        updatedAt: '2024-01-12T20:47:57.932Z'
      numEdits: 0
      reactions: []
    id: 65a1a57db4f188a4db9649ce
    type: comment
  author: phpaiola
  content: 'Segue o merge do modelo: https://huggingface.co/recogna-nlp/bode-7b-alpaca-pt-br-no-peft

    Nos avise se funcionar devidamente :D'
  created_at: 2024-01-12 20:47:57+00:00
  edited: false
  hidden: false
  id: 65a1a57db4f188a4db9649ce
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: recogna-nlp/bode-7b-alpaca-pt-br
repo_type: model
status: open
target_branch: null
title: Merge
