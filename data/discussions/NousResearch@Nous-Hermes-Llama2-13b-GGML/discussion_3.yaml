!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MrDevolver
conflicting_files: null
created_at: 2023-07-24 20:07:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6aec9ca2ae47baad15b60b38ec81d69d.svg
      fullname: Angelino Santiago
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MrDevolver
      type: user
    createdAt: '2023-07-24T21:07:07.000Z'
    data:
      edited: true
      editors:
      - MrDevolver
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9701967835426331
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6aec9ca2ae47baad15b60b38ec81d69d.svg
          fullname: Angelino Santiago
          isHf: false
          isPro: false
          name: MrDevolver
          type: user
        html: '<p>Hello,</p>

          <p>I have issues using this model in inference UI apps like Faraday and
          LM Studio. Most of the time the model just doesn''t work. Initially it looks
          promising, it loads into the RAM and VRAM, CPU starts processing, but then
          after a moment it all stops and the model unloads from both RAM and VRAM
          and nothing is generated. Yesterday I was able to briefly load and even
          use the model in LM Studio for a while, but after some time it stopped working
          again and kept giving me errors about failing model.</p>

          <p>I''ve read there were some problems with the quantization process of
          the model as discussed here: <a href="https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b/discussions/1">https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b/discussions/1</a>
          I don''t know if my problem has anything to do with that, but I''d really
          like to have a working version of this model.</p>

          <p>I discussed this issue with another user who tested the model for me
          on his own hardware, although he has different specs (Intel + Nvidia, my
          own specs are at the bottom of the post) and he was able to use the model.
          I''m starting to feel like I''m the only one having this issue and it feels
          a bit ridiculous, because even though I normally use all kinds of different
          13B GGML models, I just can''t get this one to work for some reason. Is
          there anything I could do to fix the problem, please? Any help would be
          appreciated, thanks!</p>

          <hr>

          <p>My specs:<br>OS: Windows 10 64bit<br>CPU: AMD Ryzen 2700x<br>RAM: 16
          GB<br>GPU: AMD Radeon RX Vega 56<br>VRAM: 8 GB</p>

          <p>Model:<br>Nous-Hermes-Llama2-13b-GGML (Q4_K_M version)</p>

          '
        raw: "Hello,\n\nI have issues using this model in inference UI apps like Faraday\
          \ and LM Studio. Most of the time the model just doesn't work. Initially\
          \ it looks promising, it loads into the RAM and VRAM, CPU starts processing,\
          \ but then after a moment it all stops and the model unloads from both RAM\
          \ and VRAM and nothing is generated. Yesterday I was able to briefly load\
          \ and even use the model in LM Studio for a while, but after some time it\
          \ stopped working again and kept giving me errors about failing model.\n\
          \nI've read there were some problems with the quantization process of the\
          \ model as discussed here: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b/discussions/1\
          \ I don't know if my problem has anything to do with that, but I'd really\
          \ like to have a working version of this model.\n\nI discussed this issue\
          \ with another user who tested the model for me on his own hardware, although\
          \ he has different specs (Intel + Nvidia, my own specs are at the bottom\
          \ of the post) and he was able to use the model. I'm starting to feel like\
          \ I'm the only one having this issue and it feels a bit ridiculous, because\
          \ even though I normally use all kinds of different 13B GGML models, I just\
          \ can't get this one to work for some reason. Is there anything I could\
          \ do to fix the problem, please? Any help would be appreciated, thanks!\n\
          \n---\nMy specs:\nOS: Windows 10 64bit\nCPU: AMD Ryzen 2700x\nRAM: 16 GB\n\
          GPU: AMD Radeon RX Vega 56\nVRAM: 8 GB\n\nModel: \nNous-Hermes-Llama2-13b-GGML\
          \ (Q4_K_M version)"
        updatedAt: '2023-07-24T21:08:17.049Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Anderson452
    id: 64bee7fb6b8a12c205c27eea
    type: comment
  author: MrDevolver
  content: "Hello,\n\nI have issues using this model in inference UI apps like Faraday\
    \ and LM Studio. Most of the time the model just doesn't work. Initially it looks\
    \ promising, it loads into the RAM and VRAM, CPU starts processing, but then after\
    \ a moment it all stops and the model unloads from both RAM and VRAM and nothing\
    \ is generated. Yesterday I was able to briefly load and even use the model in\
    \ LM Studio for a while, but after some time it stopped working again and kept\
    \ giving me errors about failing model.\n\nI've read there were some problems\
    \ with the quantization process of the model as discussed here: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b/discussions/1\
    \ I don't know if my problem has anything to do with that, but I'd really like\
    \ to have a working version of this model.\n\nI discussed this issue with another\
    \ user who tested the model for me on his own hardware, although he has different\
    \ specs (Intel + Nvidia, my own specs are at the bottom of the post) and he was\
    \ able to use the model. I'm starting to feel like I'm the only one having this\
    \ issue and it feels a bit ridiculous, because even though I normally use all\
    \ kinds of different 13B GGML models, I just can't get this one to work for some\
    \ reason. Is there anything I could do to fix the problem, please? Any help would\
    \ be appreciated, thanks!\n\n---\nMy specs:\nOS: Windows 10 64bit\nCPU: AMD Ryzen\
    \ 2700x\nRAM: 16 GB\nGPU: AMD Radeon RX Vega 56\nVRAM: 8 GB\n\nModel: \nNous-Hermes-Llama2-13b-GGML\
    \ (Q4_K_M version)"
  created_at: 2023-07-24 20:07:07+00:00
  edited: true
  hidden: false
  id: 64bee7fb6b8a12c205c27eea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/526b8616a532f2017784ca85c35663b4.svg
      fullname: Pablo Dias
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Anderson452
      type: user
    createdAt: '2023-07-26T23:06:09.000Z'
    data:
      edited: false
      editors:
      - Anderson452
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9711486101150513
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/526b8616a532f2017784ca85c35663b4.svg
          fullname: Pablo Dias
          isHf: false
          isPro: false
          name: Anderson452
          type: user
        html: '<p>same for me, doesn''t work at all. gives incoherent answers most
          of the time</p>

          '
        raw: same for me, doesn't work at all. gives incoherent answers most of the
          time
        updatedAt: '2023-07-26T23:06:09.850Z'
      numEdits: 0
      reactions: []
    id: 64c1a6e164e3e59137cd6d50
    type: comment
  author: Anderson452
  content: same for me, doesn't work at all. gives incoherent answers most of the
    time
  created_at: 2023-07-26 22:06:09+00:00
  edited: false
  hidden: false
  id: 64c1a6e164e3e59137cd6d50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6aec9ca2ae47baad15b60b38ec81d69d.svg
      fullname: Angelino Santiago
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MrDevolver
      type: user
    createdAt: '2023-07-26T23:22:10.000Z'
    data:
      edited: false
      editors:
      - MrDevolver
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9746825695037842
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6aec9ca2ae47baad15b60b38ec81d69d.svg
          fullname: Angelino Santiago
          isHf: false
          isPro: false
          name: MrDevolver
          type: user
        html: '<blockquote>

          <p>same for me, doesn''t work at all. gives incoherent answers most of the
          time</p>

          </blockquote>

          <p>My issue is different. It unloads after a while and doesn''t even begin
          to generate anything. Source of your issue is most likely completely different.
          Check your settings and system prompt to see if you''re using the one suggested.</p>

          '
        raw: '> same for me, doesn''t work at all. gives incoherent answers most of
          the time


          My issue is different. It unloads after a while and doesn''t even begin
          to generate anything. Source of your issue is most likely completely different.
          Check your settings and system prompt to see if you''re using the one suggested.'
        updatedAt: '2023-07-26T23:22:10.910Z'
      numEdits: 0
      reactions: []
    id: 64c1aaa22ffd51a130474d45
    type: comment
  author: MrDevolver
  content: '> same for me, doesn''t work at all. gives incoherent answers most of
    the time


    My issue is different. It unloads after a while and doesn''t even begin to generate
    anything. Source of your issue is most likely completely different. Check your
    settings and system prompt to see if you''re using the one suggested.'
  created_at: 2023-07-26 22:22:10+00:00
  edited: false
  hidden: false
  id: 64c1aaa22ffd51a130474d45
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: NousResearch/Nous-Hermes-Llama2-13b-GGML
repo_type: model
status: open
target_branch: null
title: Most of the time, this model doesn't work for me. Please help!
