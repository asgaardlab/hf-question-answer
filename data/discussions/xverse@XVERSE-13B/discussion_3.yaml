!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KnutJaegersberg
conflicting_files: null
created_at: 2023-08-09 03:23:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-08-09T04:23:24.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9047440886497498
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>I wonder if this is the best open Chinese LLM to date. Is it better
          than GLM-130B? </p>

          '
        raw: 'I wonder if this is the best open Chinese LLM to date. Is it better
          than GLM-130B? '
        updatedAt: '2023-08-09T04:23:24.666Z'
      numEdits: 0
      reactions: []
    id: 64d314bcbe9984dc4e436226
    type: comment
  author: KnutJaegersberg
  content: 'I wonder if this is the best open Chinese LLM to date. Is it better than
    GLM-130B? '
  created_at: 2023-08-09 03:23:24+00:00
  edited: false
  hidden: false
  id: 64d314bcbe9984dc4e436226
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-08-09T04:24:57.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9704299569129944
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>It appears to beat it MMLU wise</p>

          '
        raw: It appears to beat it MMLU wise
        updatedAt: '2023-08-09T04:24:57.766Z'
      numEdits: 0
      reactions: []
    id: 64d3151991d0be9eca010f39
    type: comment
  author: KnutJaegersberg
  content: It appears to beat it MMLU wise
  created_at: 2023-08-09 03:24:57+00:00
  edited: false
  hidden: false
  id: 64d3151991d0be9eca010f39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/997d828a4965c145d4350718a578abec.svg
      fullname: ouyangliqi
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ChloeAuYeung
      type: user
    createdAt: '2023-08-09T07:21:38.000Z'
    data:
      edited: false
      editors:
      - ChloeAuYeung
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9276571273803711
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/997d828a4965c145d4350718a578abec.svg
          fullname: ouyangliqi
          isHf: false
          isPro: false
          name: ChloeAuYeung
          type: user
        html: '<p>Thank you for your interest in XVERSE-13B. Given the significant
          scale difference between XVERSE-13B and GLM-130B, it may not be fair to
          compare them directly.</p>

          '
        raw: Thank you for your interest in XVERSE-13B. Given the significant scale
          difference between XVERSE-13B and GLM-130B, it may not be fair to compare
          them directly.
        updatedAt: '2023-08-09T07:21:38.802Z'
      numEdits: 0
      reactions: []
    id: 64d33e82ce61e41b67d0525e
    type: comment
  author: ChloeAuYeung
  content: Thank you for your interest in XVERSE-13B. Given the significant scale
    difference between XVERSE-13B and GLM-130B, it may not be fair to compare them
    directly.
  created_at: 2023-08-09 06:21:38+00:00
  edited: false
  hidden: false
  id: 64d33e82ce61e41b67d0525e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-08-09T08:54:46.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.912727415561676
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>yeah, I know the difference, but GLM-130B is roughly old GPT-3 performance.
          I''m certain that these days a significantly smaller model could beat it,
          if pretrained with better data and for longer.<br>The authors of llama claimed
          their 13b model had GPT 3 performance. </p>

          <p><a rel="nofollow" href="https://www.technology.org/2023/02/27/meta-our-llama-13b-outperforms-openais-gpt-3-despite-being-10x-smaller/">https://www.technology.org/2023/02/27/meta-our-llama-13b-outperforms-openais-gpt-3-despite-being-10x-smaller/</a></p>

          '
        raw: "yeah, I know the difference, but GLM-130B is roughly old GPT-3 performance.\
          \ I'm certain that these days a significantly smaller model could beat it,\
          \ if pretrained with better data and for longer. \nThe authors of llama\
          \ claimed their 13b model had GPT 3 performance. \n\nhttps://www.technology.org/2023/02/27/meta-our-llama-13b-outperforms-openais-gpt-3-despite-being-10x-smaller/"
        updatedAt: '2023-08-09T08:54:46.579Z'
      numEdits: 0
      reactions: []
    id: 64d354569506a64b0e1ff148
    type: comment
  author: KnutJaegersberg
  content: "yeah, I know the difference, but GLM-130B is roughly old GPT-3 performance.\
    \ I'm certain that these days a significantly smaller model could beat it, if\
    \ pretrained with better data and for longer. \nThe authors of llama claimed their\
    \ 13b model had GPT 3 performance. \n\nhttps://www.technology.org/2023/02/27/meta-our-llama-13b-outperforms-openais-gpt-3-despite-being-10x-smaller/"
  created_at: 2023-08-09 07:54:46+00:00
  edited: false
  hidden: false
  id: 64d354569506a64b0e1ff148
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-08-09T19:54:34.000Z'
    data:
      status: closed
    id: 64d3eefa63f2477c3c0eb33b
    type: status-change
  author: KnutJaegersberg
  created_at: 2023-08-09 18:54:34+00:00
  id: 64d3eefa63f2477c3c0eb33b
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/997d828a4965c145d4350718a578abec.svg
      fullname: ouyangliqi
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ChloeAuYeung
      type: user
    createdAt: '2023-08-10T03:14:26.000Z'
    data:
      edited: false
      editors:
      - ChloeAuYeung
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9441148638725281
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/997d828a4965c145d4350718a578abec.svg
          fullname: ouyangliqi
          isHf: false
          isPro: false
          name: ChloeAuYeung
          type: user
        html: '<p>Apologies for the delay. At the moment, our primary focus is on
          comparing models in the 13B range, so we haven''t evaluated against GLM-130B.
          We will conduct this comparison in the future.</p>

          '
        raw: Apologies for the delay. At the moment, our primary focus is on comparing
          models in the 13B range, so we haven't evaluated against GLM-130B. We will
          conduct this comparison in the future.
        updatedAt: '2023-08-10T03:14:26.916Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - KnutJaegersberg
    id: 64d45612d095077728f95857
    type: comment
  author: ChloeAuYeung
  content: Apologies for the delay. At the moment, our primary focus is on comparing
    models in the 13B range, so we haven't evaluated against GLM-130B. We will conduct
    this comparison in the future.
  created_at: 2023-08-10 02:14:26+00:00
  edited: false
  hidden: false
  id: 64d45612d095077728f95857
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: xverse/XVERSE-13B
repo_type: model
status: closed
target_branch: null
title: Benchmarks comparing with GLM-130B
