!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bjoernp
conflicting_files: null
created_at: 2023-11-13 10:44:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4a0cff546914b0f094f4a33e376a2f16.svg
      fullname: "Bj\xF6rn Pl\xFCster "
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bjoernp
      type: user
    createdAt: '2023-11-13T10:44:25.000Z'
    data:
      edited: true
      editors:
      - bjoernp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9230590462684631
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4a0cff546914b0f094f4a33e376a2f16.svg
          fullname: "Bj\xF6rn Pl\xFCster "
          isHf: false
          isPro: false
          name: bjoernp
          type: user
        html: '<p>In the model card you state that it was trained with a world size
          of 1024 and a micro batch size of 1 but in the training hyperparameters
          section you write effective batch size 4M tokens (2048x2048) instead of
          (1024x2048). Maybe there was a data entry error somewhere.</p>

          '
        raw: In the model card you state that it was trained with a world size of
          1024 and a micro batch size of 1 but in the training hyperparameters section
          you write effective batch size 4M tokens (2048x2048) instead of (1024x2048).
          Maybe there was a data entry error somewhere.
        updatedAt: '2023-11-13T10:44:44.294Z'
      numEdits: 1
      reactions: []
    id: 6551fe093fe6c0b1f8d9f84a
    type: comment
  author: bjoernp
  content: In the model card you state that it was trained with a world size of 1024
    and a micro batch size of 1 but in the training hyperparameters section you write
    effective batch size 4M tokens (2048x2048) instead of (1024x2048). Maybe there
    was a data entry error somewhere.
  created_at: 2023-11-13 10:44:25+00:00
  edited: true
  hidden: false
  id: 6551fe093fe6c0b1f8d9f84a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7c7df91461068adeda05d59c7244d9d3.svg
      fullname: jonabur
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jonabur
      type: user
    createdAt: '2023-11-13T12:56:11.000Z'
    data:
      edited: false
      editors:
      - jonabur
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.875214159488678
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7c7df91461068adeda05d59c7244d9d3.svg
          fullname: jonabur
          isHf: false
          isPro: false
          name: jonabur
          type: user
        html: "<p>The effective batch size we're referring to is just the product\
          \ of the global batch size and the sequence length, or in this case 2048*2048=4194304.\
          \  We\u2019re running sequence and tensor parallel with gradient accumulation.</p>\n"
        raw: "The effective batch size we're referring to is just the product of the\
          \ global batch size and the sequence length, or in this case 2048*2048=4194304.\
          \  We\u2019re running sequence and tensor parallel with gradient accumulation."
        updatedAt: '2023-11-13T12:56:11.162Z'
      numEdits: 0
      reactions: []
    id: 65521ceb74b0837d85ddf0f3
    type: comment
  author: jonabur
  content: "The effective batch size we're referring to is just the product of the\
    \ global batch size and the sequence length, or in this case 2048*2048=4194304.\
    \  We\u2019re running sequence and tensor parallel with gradient accumulation."
  created_at: 2023-11-13 12:56:11+00:00
  edited: false
  hidden: false
  id: 65521ceb74b0837d85ddf0f3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4a0cff546914b0f094f4a33e376a2f16.svg
      fullname: "Bj\xF6rn Pl\xFCster "
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bjoernp
      type: user
    createdAt: '2023-11-13T13:00:57.000Z'
    data:
      edited: false
      editors:
      - bjoernp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9450785517692566
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4a0cff546914b0f094f4a33e376a2f16.svg
          fullname: "Bj\xF6rn Pl\xFCster "
          isHf: false
          isPro: false
          name: bjoernp
          type: user
        html: '<p>Oh I understand, must have missed the mention of gradient accumulation.
          Thanks for clarifying! Perhaps it might be helpful to include this in the
          table (<code>gradient accumulation steps = 2</code>).</p>

          '
        raw: Oh I understand, must have missed the mention of gradient accumulation.
          Thanks for clarifying! Perhaps it might be helpful to include this in the
          table (`gradient accumulation steps = 2`).
        updatedAt: '2023-11-13T13:00:57.195Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65521e09d089baee55b6f233
    id: 65521e09d089baee55b6f232
    type: comment
  author: bjoernp
  content: Oh I understand, must have missed the mention of gradient accumulation.
    Thanks for clarifying! Perhaps it might be helpful to include this in the table
    (`gradient accumulation steps = 2`).
  created_at: 2023-11-13 13:00:57+00:00
  edited: false
  hidden: false
  id: 65521e09d089baee55b6f232
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/4a0cff546914b0f094f4a33e376a2f16.svg
      fullname: "Bj\xF6rn Pl\xFCster "
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bjoernp
      type: user
    createdAt: '2023-11-13T13:00:57.000Z'
    data:
      status: closed
    id: 65521e09d089baee55b6f233
    type: status-change
  author: bjoernp
  created_at: 2023-11-13 13:00:57+00:00
  id: 65521e09d089baee55b6f233
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7c7df91461068adeda05d59c7244d9d3.svg
      fullname: jonabur
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jonabur
      type: user
    createdAt: '2023-11-13T14:21:37.000Z'
    data:
      edited: false
      editors:
      - jonabur
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8836835026741028
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7c7df91461068adeda05d59c7244d9d3.svg
          fullname: jonabur
          isHf: false
          isPro: false
          name: jonabur
          type: user
        html: '<p>I added a note to the training about using GAS=16.  Thanks for the
          feedback!</p>

          '
        raw: I added a note to the training about using GAS=16.  Thanks for the feedback!
        updatedAt: '2023-11-13T14:21:37.902Z'
      numEdits: 0
      reactions: []
    id: 655230f17270aa3e99d27413
    type: comment
  author: jonabur
  content: I added a note to the training about using GAS=16.  Thanks for the feedback!
  created_at: 2023-11-13 14:21:37+00:00
  edited: false
  hidden: false
  id: 655230f17270aa3e99d27413
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: LumiOpen/Poro-34B
repo_type: model
status: closed
target_branch: null
title: Inconsistency in effective batch size reporting
