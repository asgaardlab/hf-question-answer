!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sanjitaa
conflicting_files: null
created_at: 2023-09-14 02:45:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
      fullname: Sanjita Nepal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjitaa
      type: user
    createdAt: '2023-09-14T03:45:09.000Z'
    data:
      edited: false
      editors:
      - sanjitaa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9292742609977722
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
          fullname: Sanjita Nepal
          isHf: false
          isPro: false
          name: sanjitaa
          type: user
        html: '<p>I am trying to load the whisper model ( medium ) in the server using
          Django API and integrate in frontend. How can I do it efficiently to get
          quick response ( even if there are large users at a single time). </p>

          '
        raw: 'I am trying to load the whisper model ( medium ) in the server using
          Django API and integrate in frontend. How can I do it efficiently to get
          quick response ( even if there are large users at a single time). '
        updatedAt: '2023-09-14T03:45:09.096Z'
      numEdits: 0
      reactions: []
    id: 650281c5bdaeae264170a732
    type: comment
  author: sanjitaa
  content: 'I am trying to load the whisper model ( medium ) in the server using Django
    API and integrate in frontend. How can I do it efficiently to get quick response
    ( even if there are large users at a single time). '
  created_at: 2023-09-14 02:45:09+00:00
  edited: false
  hidden: false
  id: 650281c5bdaeae264170a732
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6e8c835e11b5af62691928e375f3ab5a.svg
      fullname: Serhii Kravchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: skypro1111
      type: user
    createdAt: '2023-09-14T05:12:28.000Z'
    data:
      edited: false
      editors:
      - skypro1111
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8793838024139404
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6e8c835e11b5af62691928e375f3ab5a.svg
          fullname: Serhii Kravchenko
          isHf: false
          isPro: false
          name: skypro1111
          type: user
        html: '<p>in the Django ecosystem, you can use Celery to asynchronously execute
          a STT task. To receive the result on the frontend through a websocket connection,
          for example.</p>

          '
        raw: in the Django ecosystem, you can use Celery to asynchronously execute
          a STT task. To receive the result on the frontend through a websocket connection,
          for example.
        updatedAt: '2023-09-14T05:12:28.944Z'
      numEdits: 0
      reactions: []
    id: 6502963c6bc2cf136f7d6795
    type: comment
  author: skypro1111
  content: in the Django ecosystem, you can use Celery to asynchronously execute a
    STT task. To receive the result on the frontend through a websocket connection,
    for example.
  created_at: 2023-09-14 04:12:28+00:00
  edited: false
  hidden: false
  id: 6502963c6bc2cf136f7d6795
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
      fullname: Sanjita Nepal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjitaa
      type: user
    createdAt: '2023-09-14T05:38:59.000Z'
    data:
      edited: false
      editors:
      - sanjitaa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9682307839393616
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
          fullname: Sanjita Nepal
          isHf: false
          isPro: false
          name: sanjitaa
          type: user
        html: '<p>Can I use two different models in server side for translation process
          also using Celery? I just want to use two different models through API and
          also want the faster response. </p>

          '
        raw: 'Can I use two different models in server side for translation process
          also using Celery? I just want to use two different models through API and
          also want the faster response. '
        updatedAt: '2023-09-14T05:38:59.183Z'
      numEdits: 0
      reactions: []
    id: 65029c73dea67e68e468d7f4
    type: comment
  author: sanjitaa
  content: 'Can I use two different models in server side for translation process
    also using Celery? I just want to use two different models through API and also
    want the faster response. '
  created_at: 2023-09-14 04:38:59+00:00
  edited: false
  hidden: false
  id: 65029c73dea67e68e468d7f4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6e8c835e11b5af62691928e375f3ab5a.svg
      fullname: Serhii Kravchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: skypro1111
      type: user
    createdAt: '2023-09-14T06:21:00.000Z'
    data:
      edited: false
      editors:
      - skypro1111
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8711268901824951
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6e8c835e11b5af62691928e375f3ab5a.svg
          fullname: Serhii Kravchenko
          isHf: false
          isPro: false
          name: skypro1111
          type: user
        html: '<p>you can run separate workflows with separate models on separate
          GPUs using env variables. in this case you can skip the loading time of
          the models and get a faster stt time.<br>You can also look at faster-whisper,
          whisperx or FrogBase (whisper-ui) projects on github. </p>

          '
        raw: 'you can run separate workflows with separate models on separate GPUs
          using env variables. in this case you can skip the loading time of the models
          and get a faster stt time.

          You can also look at faster-whisper, whisperx or FrogBase (whisper-ui) projects
          on github. '
        updatedAt: '2023-09-14T06:21:00.993Z'
      numEdits: 0
      reactions: []
    id: 6502a64c89707f18238a8e11
    type: comment
  author: skypro1111
  content: 'you can run separate workflows with separate models on separate GPUs using
    env variables. in this case you can skip the loading time of the models and get
    a faster stt time.

    You can also look at faster-whisper, whisperx or FrogBase (whisper-ui) projects
    on github. '
  created_at: 2023-09-14 05:21:00+00:00
  edited: false
  hidden: false
  id: 6502a64c89707f18238a8e11
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
      fullname: Sanjita Nepal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjitaa
      type: user
    createdAt: '2023-09-14T08:30:40.000Z'
    data:
      edited: true
      editors:
      - sanjitaa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9100621938705444
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
          fullname: Sanjita Nepal
          isHf: false
          isPro: false
          name: sanjitaa
          type: user
        html: '<p>I want to use whisper model for transcribing and another model for
          translation. Now for complete transcription the data should pass from whisper
          model to another model and generate translated output.  Both models are
          available in hugging face.  I want to use both models for better performance
          as well. How to implement this through hugging face?</p>

          '
        raw: I want to use whisper model for transcribing and another model for translation.
          Now for complete transcription the data should pass from whisper model to
          another model and generate translated output.  Both models are available
          in hugging face.  I want to use both models for better performance as well.
          How to implement this through hugging face?
        updatedAt: '2023-09-14T11:54:52.049Z'
      numEdits: 1
      reactions: []
    id: 6502c4b05412026f7b8919c2
    type: comment
  author: sanjitaa
  content: I want to use whisper model for transcribing and another model for translation.
    Now for complete transcription the data should pass from whisper model to another
    model and generate translated output.  Both models are available in hugging face.  I
    want to use both models for better performance as well. How to implement this
    through hugging face?
  created_at: 2023-09-14 07:30:40+00:00
  edited: true
  hidden: false
  id: 6502c4b05412026f7b8919c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6e8c835e11b5af62691928e375f3ab5a.svg
      fullname: Serhii Kravchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: skypro1111
      type: user
    createdAt: '2023-09-14T12:37:47.000Z'
    data:
      edited: false
      editors:
      - skypro1111
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.865745484828949
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6e8c835e11b5af62691928e375f3ab5a.svg
          fullname: Serhii Kravchenko
          isHf: false
          isPro: false
          name: skypro1111
          type: user
        html: '<p>You can start from "deploy" menu-button in right upper corner of
          each model page on HF.</p>

          '
        raw: You can start from "deploy" menu-button in right upper corner of each
          model page on HF.
        updatedAt: '2023-09-14T12:37:47.513Z'
      numEdits: 0
      reactions: []
    id: 6502fe9bc130d99814c47347
    type: comment
  author: skypro1111
  content: You can start from "deploy" menu-button in right upper corner of each model
    page on HF.
  created_at: 2023-09-14 11:37:47+00:00
  edited: false
  hidden: false
  id: 6502fe9bc130d99814c47347
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b9f8c887d68e6686cda9cc3c1b9f8945.svg
      fullname: Joseph Henzi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JHenzi
      type: user
    createdAt: '2023-09-14T12:57:55.000Z'
    data:
      edited: false
      editors:
      - JHenzi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9683085680007935
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b9f8c887d68e6686cda9cc3c1b9f8945.svg
          fullname: Joseph Henzi
          isHf: false
          isPro: false
          name: JHenzi
          type: user
        html: '<p>Sanjitaa - If you are looking to transcribe and then subsequently
          translate the text the second model might not have to be Whisper. In fact,
          if you''re passing text from the first model to a second model it likely
          makes sense to use a T5 or another input-output based model (BERT family).
          </p>

          <p>I think in your playbook you''re going to then need to convert text back
          to speech in order to get Whisper to process it a second time for the translation.
          Text to speech models don''t seem to perform very well at this task, giving
          you some outputs that don''t make sense compared to what you fed the model
          initially.</p>

          '
        raw: "Sanjitaa - If you are looking to transcribe and then subsequently translate\
          \ the text the second model might not have to be Whisper. In fact, if you're\
          \ passing text from the first model to a second model it likely makes sense\
          \ to use a T5 or another input-output based model (BERT family). \n\nI think\
          \ in your playbook you're going to then need to convert text back to speech\
          \ in order to get Whisper to process it a second time for the translation.\
          \ Text to speech models don't seem to perform very well at this task, giving\
          \ you some outputs that don't make sense compared to what you fed the model\
          \ initially."
        updatedAt: '2023-09-14T12:57:55.372Z'
      numEdits: 0
      reactions: []
    id: 65030353cb1cf43486ef2cc9
    type: comment
  author: JHenzi
  content: "Sanjitaa - If you are looking to transcribe and then subsequently translate\
    \ the text the second model might not have to be Whisper. In fact, if you're passing\
    \ text from the first model to a second model it likely makes sense to use a T5\
    \ or another input-output based model (BERT family). \n\nI think in your playbook\
    \ you're going to then need to convert text back to speech in order to get Whisper\
    \ to process it a second time for the translation. Text to speech models don't\
    \ seem to perform very well at this task, giving you some outputs that don't make\
    \ sense compared to what you fed the model initially."
  created_at: 2023-09-14 11:57:55+00:00
  edited: false
  hidden: false
  id: 65030353cb1cf43486ef2cc9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
      fullname: Sanjita Nepal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjitaa
      type: user
    createdAt: '2023-09-15T03:36:08.000Z'
    data:
      edited: false
      editors:
      - sanjitaa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8249179720878601
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
          fullname: Sanjita Nepal
          isHf: false
          isPro: false
          name: sanjitaa
          type: user
        html: '<p>Yes  I am using two different models. For transcribing , I am using
          whisper and for translation, I am using another model ( like mbart ) .  How
          can I do it through hugging face ?   </p>

          '
        raw: 'Yes  I am using two different models. For transcribing , I am using
          whisper and for translation, I am using another model ( like mbart ) .  How
          can I do it through hugging face ?   '
        updatedAt: '2023-09-15T03:36:08.208Z'
      numEdits: 0
      reactions: []
    id: 6503d1282e728903c29962f2
    type: comment
  author: sanjitaa
  content: 'Yes  I am using two different models. For transcribing , I am using whisper
    and for translation, I am using another model ( like mbart ) .  How can I do it
    through hugging face ?   '
  created_at: 2023-09-15 02:36:08+00:00
  edited: false
  hidden: false
  id: 6503d1282e728903c29962f2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
      fullname: Sanjita Nepal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjitaa
      type: user
    createdAt: '2023-09-19T06:00:28.000Z'
    data:
      edited: false
      editors:
      - sanjitaa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9266640543937683
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
          fullname: Sanjita Nepal
          isHf: false
          isPro: false
          name: sanjitaa
          type: user
        html: '<p>I wanted to use two different models ( whisper for transcription
          and mbart for text translation). The audio is passed through whisper model
          and the transcribed  text from the whisper model  is passed through mart
          model and text is translated. I want to use both these models  through hugging
          face platform . How can I achieve good performance on it ? I want to display
          output in frontend also. </p>

          '
        raw: 'I wanted to use two different models ( whisper for transcription and
          mbart for text translation). The audio is passed through whisper model and
          the transcribed  text from the whisper model  is passed through mart model
          and text is translated. I want to use both these models  through hugging
          face platform . How can I achieve good performance on it ? I want to display
          output in frontend also. '
        updatedAt: '2023-09-19T06:00:28.883Z'
      numEdits: 0
      reactions: []
    id: 650938fcb5a04c8675b6f8f5
    type: comment
  author: sanjitaa
  content: 'I wanted to use two different models ( whisper for transcription and mbart
    for text translation). The audio is passed through whisper model and the transcribed  text
    from the whisper model  is passed through mart model and text is translated. I
    want to use both these models  through hugging face platform . How can I achieve
    good performance on it ? I want to display output in frontend also. '
  created_at: 2023-09-19 05:00:28+00:00
  edited: false
  hidden: false
  id: 650938fcb5a04c8675b6f8f5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
      fullname: Sanjita Nepal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjitaa
      type: user
    createdAt: '2023-09-20T10:36:32.000Z'
    data:
      edited: false
      editors:
      - sanjitaa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9722947478294373
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
          fullname: Sanjita Nepal
          isHf: false
          isPro: false
          name: sanjitaa
          type: user
        html: '<p>Can anyone help me with it ? </p>

          '
        raw: 'Can anyone help me with it ? '
        updatedAt: '2023-09-20T10:36:32.536Z'
      numEdits: 0
      reactions: []
    id: 650acb30238a644cb935612c
    type: comment
  author: sanjitaa
  content: 'Can anyone help me with it ? '
  created_at: 2023-09-20 09:36:32+00:00
  edited: false
  hidden: false
  id: 650acb30238a644cb935612c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6e8c835e11b5af62691928e375f3ab5a.svg
      fullname: Serhii Kravchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: skypro1111
      type: user
    createdAt: '2023-09-20T15:08:05.000Z'
    data:
      edited: false
      editors:
      - skypro1111
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5694336891174316
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6e8c835e11b5af62691928e375f3ab5a.svg
          fullname: Serhii Kravchenko
          isHf: false
          isPro: false
          name: skypro1111
          type: user
        html: '<p><a rel="nofollow" href="https://platform.openai.com/docs/guides/speech-to-text">https://platform.openai.com/docs/guides/speech-to-text</a></p>

          '
        raw: https://platform.openai.com/docs/guides/speech-to-text
        updatedAt: '2023-09-20T15:08:05.936Z'
      numEdits: 0
      reactions: []
    id: 650b0ad5c32a8ee18184e244
    type: comment
  author: skypro1111
  content: https://platform.openai.com/docs/guides/speech-to-text
  created_at: 2023-09-20 14:08:05+00:00
  edited: false
  hidden: false
  id: 650b0ad5c32a8ee18184e244
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-09-28T18:33:35.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8425478339195251
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: '<p>This looks very similar to <a href="https://huggingface.co/learn/audio-course/chapter7/speech-to-speech">this
          guide</a>, except the second model is text-&gt;text, instead of text-&gt;speech.</p>

          '
        raw: This looks very similar to [this guide](https://huggingface.co/learn/audio-course/chapter7/speech-to-speech),
          except the second model is text->text, instead of text->speech.
        updatedAt: '2023-09-28T18:33:35.516Z'
      numEdits: 0
      reactions: []
    id: 6515c6ffc1ec63624f487a27
    type: comment
  author: sanchit-gandhi
  content: This looks very similar to [this guide](https://huggingface.co/learn/audio-course/chapter7/speech-to-speech),
    except the second model is text->text, instead of text->speech.
  created_at: 2023-09-28 17:33:35+00:00
  edited: false
  hidden: false
  id: 6515c6ffc1ec63624f487a27
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
      fullname: Sanjita Nepal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjitaa
      type: user
    createdAt: '2023-10-10T05:12:56.000Z'
    data:
      edited: false
      editors:
      - sanjitaa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7885748147964478
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
          fullname: Sanjita Nepal
          isHf: false
          isPro: false
          name: sanjitaa
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ Can I use the API provided by the hugging face space ( after I deploy\
          \ my model ) in my project so that it can be consumed by frontend as well\
          \ ?<br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/64db39e88da011d65611020b/WceLtOwuVE7jnNTQPdNpf.png\"\
          ><img alt=\"Screenshot 2023-10-10 at 10.55.08.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64db39e88da011d65611020b/WceLtOwuVE7jnNTQPdNpf.png\"\
          ></a></p>\n"
        raw: "@sanchit-gandhi Can I use the API provided by the hugging face space\
          \ ( after I deploy my model ) in my project so that it can be consumed by\
          \ frontend as well ? \n![Screenshot 2023-10-10 at 10.55.08.png](https://cdn-uploads.huggingface.co/production/uploads/64db39e88da011d65611020b/WceLtOwuVE7jnNTQPdNpf.png)\n"
        updatedAt: '2023-10-10T05:12:56.074Z'
      numEdits: 0
      reactions: []
    id: 6524dd58b02238037e6df17d
    type: comment
  author: sanjitaa
  content: "@sanchit-gandhi Can I use the API provided by the hugging face space (\
    \ after I deploy my model ) in my project so that it can be consumed by frontend\
    \ as well ? \n![Screenshot 2023-10-10 at 10.55.08.png](https://cdn-uploads.huggingface.co/production/uploads/64db39e88da011d65611020b/WceLtOwuVE7jnNTQPdNpf.png)\n"
  created_at: 2023-10-10 04:12:56+00:00
  edited: false
  hidden: false
  id: 6524dd58b02238037e6df17d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-10-10T16:38:07.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8895378708839417
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: '<p>Yes you should be able to use the Gradio client this way! You can
          pass the input string as the path to your audio file. The client will send
          the audio to the Space, transcribe the audio, and return to you the text
          output. Let me know if you encounter any difficulties!</p>

          '
        raw: Yes you should be able to use the Gradio client this way! You can pass
          the input string as the path to your audio file. The client will send the
          audio to the Space, transcribe the audio, and return to you the text output.
          Let me know if you encounter any difficulties!
        updatedAt: '2023-10-10T16:38:07.922Z'
      numEdits: 0
      reactions: []
    id: 65257def79706914d4f1be2a
    type: comment
  author: sanchit-gandhi
  content: Yes you should be able to use the Gradio client this way! You can pass
    the input string as the path to your audio file. The client will send the audio
    to the Space, transcribe the audio, and return to you the text output. Let me
    know if you encounter any difficulties!
  created_at: 2023-10-10 15:38:07+00:00
  edited: false
  hidden: false
  id: 65257def79706914d4f1be2a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
      fullname: Sanjita Nepal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjitaa
      type: user
    createdAt: '2023-10-11T03:39:30.000Z'
    data:
      edited: false
      editors:
      - sanjitaa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7432534694671631
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
          fullname: Sanjita Nepal
          isHf: false
          isPro: false
          name: sanjitaa
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \  It works ! Thank you .  </p>\n"
        raw: '@sanchit-gandhi  It works ! Thank you .  '
        updatedAt: '2023-10-11T03:39:30.302Z'
      numEdits: 0
      reactions: []
    id: 652618f2e7620073ada4f731
    type: comment
  author: sanjitaa
  content: '@sanchit-gandhi  It works ! Thank you .  '
  created_at: 2023-10-11 02:39:30+00:00
  edited: false
  hidden: false
  id: 652618f2e7620073ada4f731
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
      fullname: Sanjita Nepal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanjitaa
      type: user
    createdAt: '2023-10-11T08:55:42.000Z'
    data:
      edited: false
      editors:
      - sanjitaa
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9310066103935242
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f46e26f9a98c0938f1f1cbd66e76ba32.svg
          fullname: Sanjita Nepal
          isHf: false
          isPro: false
          name: sanjitaa
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\"\
          >@<span class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ Does it work for application also ? I am using this API to build an application.\
          \ </p>\n"
        raw: '@sanchit-gandhi Does it work for application also ? I am using this
          API to build an application. '
        updatedAt: '2023-10-11T08:55:42.289Z'
      numEdits: 0
      reactions: []
    id: 6526630eb5f03a1481a2397e
    type: comment
  author: sanjitaa
  content: '@sanchit-gandhi Does it work for application also ? I am using this API
    to build an application. '
  created_at: 2023-10-11 07:55:42+00:00
  edited: false
  hidden: false
  id: 6526630eb5f03a1481a2397e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 25
repo_id: openai/whisper-medium
repo_type: model
status: open
target_branch: null
title: 'About using whisper model as API '
