!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Isabala
conflicting_files: null
created_at: 2023-12-06 15:36:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bca16084bd58d1ebdf1ae79df77bc439.svg
      fullname: Kas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Isabala
      type: user
    createdAt: '2023-12-06T15:36:10.000Z'
    data:
      edited: false
      editors:
      - Isabala
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.37372973561286926
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bca16084bd58d1ebdf1ae79df77bc439.svg
          fullname: Kas
          isHf: false
          isPro: false
          name: Isabala
          type: user
        html: '<p>Hello everybody,</p>

          <p>I''m facing an issue when I try to load the pretrained processor "AutoProcessor.from_pretrained".  I
          downloaded all files locally on my computer and I''m trying to use the code
          as suggested by huggingface:</p>

          <p><strong>from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq</strong><br><strong>my_path
          = ''D:/data/whisper_model''</strong></p>

          <p><strong>model = AutoModelForSpeechSeq2Seq.from_pretrained(my_path)</strong><br><strong>processor
          = AutoProcessor.from_pretrained(my_path)</strong></p>

          <p>The model works well but the processor give me an error:</p>

          <p>6 process = AutoProcessor.from_pretrained(path_model)<br>      7 model
          =AutoModelForSpeechSeq2Seq.from_pretrained(path_model)</p>

          <p>File D:\programs\Anaconda3\envs\venv_speech\lib\site-packages\transformers\models\auto\processing_auto.py:292,
          in AutoProcessor.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)<br>    288     return
          processor_class.from_pretrained(<br>    289         pretrained_model_name_or_path,
          trust_remote_code=trust_remote_code, **kwargs<br>    290     )<br>    291
          elif processor_class is not None:<br>--&gt; 292     return processor_class.from_pretrained(<br>    293         pretrained_model_name_or_path,
          trust_remote_code=trust_remote_code, **kwargs<br>    294     )<br>    295
          # Last try: we use the PROCESSOR_MAPPING.<br>    296 elif type(config) in
          PROCESSOR_MAPPING:</p>

          <p>File D:\programs\Anaconda3\envs\venv_speech\lib\site-packages\transformers\processing_utils.py:228,
          in ProcessorMixin.from_pretrained(cls, pretrained_model_name_or_path, cache_dir,
          force_download, local_files_only, token, revision, **kwargs)<br>    225
          if token is not None:<br>    226     kwargs["token"] = token<br>--&gt; 228
          args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,
          **kwargs)<br>    229 return cls(*args)</p>

          <p>File D:\programs\Anaconda3\envs\venv_speech\lib\site-packages\transformers\processing_utils.py:272,
          in ProcessorMixin._get_arguments_from_pretrained(cls, pretrained_model_name_or_path,
          **kwargs)<br>    269     else:<br>    270         attribute_class = getattr(transformers_module,
          class_name)<br>--&gt; 272     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,
          **kwargs))<br>    273 return args</p>

          <p>File D:\programs\Anaconda3\envs\venv_speech\lib\site-packages\transformers\tokenization_utils_base.py:2024,
          in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,
          cache_dir, force_download, local_files_only, token, revision, *init_inputs,
          **kwargs)<br>   2021     else:<br>   2022         logger.info(f"loading
          file {file_path} from cache at {resolved_vocab_files[file_id]}")<br>-&gt;
          2024 return cls._from_pretrained(<br>   2025     resolved_vocab_files,<br>   2026     pretrained_model_name_or_path,<br>   2027     init_configuration,<br>   2028     *init_inputs,<br>   2029     token=token,<br>   2030     cache_dir=cache_dir,<br>   2031     local_files_only=local_files_only,<br>   2032     _commit_hash=commit_hash,<br>   2033     _is_local=is_local,<br>   2034     **kwargs,<br>   2035
          )</p>

          <p>File D:\programs\Anaconda3\envs\venv_speech\lib\site-packages\transformers\tokenization_utils_base.py:2249,
          in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,
          init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local,
          *init_inputs, **kwargs)<br>   2247     if added_tokens_map != {} and init_kwargs[key]
          is not None:<br>   2248         if key != "additional_special_tokens":<br>-&gt;
          2249             init_kwargs[key] = added_tokens_map.get(init_kwargs[key],
          init_kwargs[key])<br>   2251 init_kwargs["added_tokens_decoder"] = added_tokens_decoder<br>   2252
          # convert {''__type'': ''AddedToken'', ''content'': '''', ''lstrip'': False,
          ''normalized'': True, ...} to AddedTokens</p>

          <p>TypeError: unhashable type: ''dict''</p>

          '
        raw: "Hello everybody,\r\n\r\nI'm facing an issue when I try to load the pretrained\
          \ processor \"AutoProcessor.from_pretrained\".  I downloaded all files locally\
          \ on my computer and I'm trying to use the code as suggested by huggingface:\r\
          \n\r\n__from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq__\r\
          \n__my_path = 'D:/data/whisper_model'__\r\n\r\n__model = AutoModelForSpeechSeq2Seq.from_pretrained(my_path)__\r\
          \n__processor = AutoProcessor.from_pretrained(my_path)__\r\n\r\nThe model\
          \ works well but the processor give me an error:\r\n\r\n\r\n6 process =\
          \ AutoProcessor.from_pretrained(path_model)\r\n      7 model =AutoModelForSpeechSeq2Seq.from_pretrained(path_model)\r\
          \n\r\nFile D:\\programs\\Anaconda3\\envs\\venv_speech\\lib\\site-packages\\\
          transformers\\models\\auto\\processing_auto.py:292, in AutoProcessor.from_pretrained(cls,\
          \ pretrained_model_name_or_path, **kwargs)\r\n    288     return processor_class.from_pretrained(\r\
          \n    289         pretrained_model_name_or_path, trust_remote_code=trust_remote_code,\
          \ **kwargs\r\n    290     )\r\n    291 elif processor_class is not None:\r\
          \n--> 292     return processor_class.from_pretrained(\r\n    293       \
          \  pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs\r\
          \n    294     )\r\n    295 # Last try: we use the PROCESSOR_MAPPING.\r\n\
          \    296 elif type(config) in PROCESSOR_MAPPING:\r\n\r\nFile D:\\programs\\\
          Anaconda3\\envs\\venv_speech\\lib\\site-packages\\transformers\\processing_utils.py:228,\
          \ in ProcessorMixin.from_pretrained(cls, pretrained_model_name_or_path,\
          \ cache_dir, force_download, local_files_only, token, revision, **kwargs)\r\
          \n    225 if token is not None:\r\n    226     kwargs[\"token\"] = token\r\
          \n--> 228 args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs)\r\n    229 return cls(*args)\r\n\r\nFile D:\\programs\\Anaconda3\\\
          envs\\venv_speech\\lib\\site-packages\\transformers\\processing_utils.py:272,\
          \ in ProcessorMixin._get_arguments_from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\r\n    269     else:\r\n    270         attribute_class = getattr(transformers_module,\
          \ class_name)\r\n--> 272     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
          \ **kwargs))\r\n    273 return args\r\n\r\nFile D:\\programs\\Anaconda3\\\
          envs\\venv_speech\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2024,\
          \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
          \ cache_dir, force_download, local_files_only, token, revision, *init_inputs,\
          \ **kwargs)\r\n   2021     else:\r\n   2022         logger.info(f\"loading\
          \ file {file_path} from cache at {resolved_vocab_files[file_id]}\")\r\n\
          -> 2024 return cls._from_pretrained(\r\n   2025     resolved_vocab_files,\r\
          \n   2026     pretrained_model_name_or_path,\r\n   2027     init_configuration,\r\
          \n   2028     *init_inputs,\r\n   2029     token=token,\r\n   2030     cache_dir=cache_dir,\r\
          \n   2031     local_files_only=local_files_only,\r\n   2032     _commit_hash=commit_hash,\r\
          \n   2033     _is_local=is_local,\r\n   2034     **kwargs,\r\n   2035 )\r\
          \n\r\nFile D:\\programs\\Anaconda3\\envs\\venv_speech\\lib\\site-packages\\\
          transformers\\tokenization_utils_base.py:2249, in PreTrainedTokenizerBase._from_pretrained(cls,\
          \ resolved_vocab_files, pretrained_model_name_or_path, init_configuration,\
          \ token, cache_dir, local_files_only, _commit_hash, _is_local, *init_inputs,\
          \ **kwargs)\r\n   2247     if added_tokens_map != {} and init_kwargs[key]\
          \ is not None:\r\n   2248         if key != \"additional_special_tokens\"\
          :\r\n-> 2249             init_kwargs[key] = added_tokens_map.get(init_kwargs[key],\
          \ init_kwargs[key])\r\n   2251 init_kwargs[\"added_tokens_decoder\"] = added_tokens_decoder\r\
          \n   2252 # convert {'__type': 'AddedToken', 'content': '<ent>', 'lstrip':\
          \ False, 'normalized': True, ...} to AddedTokens\r\n\r\nTypeError: unhashable\
          \ type: 'dict'\r\n\r\n"
        updatedAt: '2023-12-06T15:36:10.749Z'
      numEdits: 0
      reactions: []
    id: 657094ea4c829fb8f5c3941f
    type: comment
  author: Isabala
  content: "Hello everybody,\r\n\r\nI'm facing an issue when I try to load the pretrained\
    \ processor \"AutoProcessor.from_pretrained\".  I downloaded all files locally\
    \ on my computer and I'm trying to use the code as suggested by huggingface:\r\
    \n\r\n__from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq__\r\n\
    __my_path = 'D:/data/whisper_model'__\r\n\r\n__model = AutoModelForSpeechSeq2Seq.from_pretrained(my_path)__\r\
    \n__processor = AutoProcessor.from_pretrained(my_path)__\r\n\r\nThe model works\
    \ well but the processor give me an error:\r\n\r\n\r\n6 process = AutoProcessor.from_pretrained(path_model)\r\
    \n      7 model =AutoModelForSpeechSeq2Seq.from_pretrained(path_model)\r\n\r\n\
    File D:\\programs\\Anaconda3\\envs\\venv_speech\\lib\\site-packages\\transformers\\\
    models\\auto\\processing_auto.py:292, in AutoProcessor.from_pretrained(cls, pretrained_model_name_or_path,\
    \ **kwargs)\r\n    288     return processor_class.from_pretrained(\r\n    289\
    \         pretrained_model_name_or_path, trust_remote_code=trust_remote_code,\
    \ **kwargs\r\n    290     )\r\n    291 elif processor_class is not None:\r\n-->\
    \ 292     return processor_class.from_pretrained(\r\n    293         pretrained_model_name_or_path,\
    \ trust_remote_code=trust_remote_code, **kwargs\r\n    294     )\r\n    295 #\
    \ Last try: we use the PROCESSOR_MAPPING.\r\n    296 elif type(config) in PROCESSOR_MAPPING:\r\
    \n\r\nFile D:\\programs\\Anaconda3\\envs\\venv_speech\\lib\\site-packages\\transformers\\\
    processing_utils.py:228, in ProcessorMixin.from_pretrained(cls, pretrained_model_name_or_path,\
    \ cache_dir, force_download, local_files_only, token, revision, **kwargs)\r\n\
    \    225 if token is not None:\r\n    226     kwargs[\"token\"] = token\r\n-->\
    \ 228 args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path,\
    \ **kwargs)\r\n    229 return cls(*args)\r\n\r\nFile D:\\programs\\Anaconda3\\\
    envs\\venv_speech\\lib\\site-packages\\transformers\\processing_utils.py:272,\
    \ in ProcessorMixin._get_arguments_from_pretrained(cls, pretrained_model_name_or_path,\
    \ **kwargs)\r\n    269     else:\r\n    270         attribute_class = getattr(transformers_module,\
    \ class_name)\r\n--> 272     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path,\
    \ **kwargs))\r\n    273 return args\r\n\r\nFile D:\\programs\\Anaconda3\\envs\\\
    venv_speech\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2024,\
    \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
    \ cache_dir, force_download, local_files_only, token, revision, *init_inputs,\
    \ **kwargs)\r\n   2021     else:\r\n   2022         logger.info(f\"loading file\
    \ {file_path} from cache at {resolved_vocab_files[file_id]}\")\r\n-> 2024 return\
    \ cls._from_pretrained(\r\n   2025     resolved_vocab_files,\r\n   2026     pretrained_model_name_or_path,\r\
    \n   2027     init_configuration,\r\n   2028     *init_inputs,\r\n   2029    \
    \ token=token,\r\n   2030     cache_dir=cache_dir,\r\n   2031     local_files_only=local_files_only,\r\
    \n   2032     _commit_hash=commit_hash,\r\n   2033     _is_local=is_local,\r\n\
    \   2034     **kwargs,\r\n   2035 )\r\n\r\nFile D:\\programs\\Anaconda3\\envs\\\
    venv_speech\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2249,\
    \ in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,\
    \ init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local,\
    \ *init_inputs, **kwargs)\r\n   2247     if added_tokens_map != {} and init_kwargs[key]\
    \ is not None:\r\n   2248         if key != \"additional_special_tokens\":\r\n\
    -> 2249             init_kwargs[key] = added_tokens_map.get(init_kwargs[key],\
    \ init_kwargs[key])\r\n   2251 init_kwargs[\"added_tokens_decoder\"] = added_tokens_decoder\r\
    \n   2252 # convert {'__type': 'AddedToken', 'content': '<ent>', 'lstrip': False,\
    \ 'normalized': True, ...} to AddedTokens\r\n\r\nTypeError: unhashable type: 'dict'\r\
    \n\r\n"
  created_at: 2023-12-06 15:36:10+00:00
  edited: false
  hidden: false
  id: 657094ea4c829fb8f5c3941f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ea3c8a9f178dfc1df3f75d71ecbe39dd.svg
      fullname: bofeng huang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: bofenghuang
      type: user
    createdAt: '2023-12-11T20:01:24.000Z'
    data:
      edited: false
      editors:
      - bofenghuang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9504522681236267
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ea3c8a9f178dfc1df3f75d71ecbe39dd.svg
          fullname: bofeng huang
          isHf: false
          isPro: false
          name: bofenghuang
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Isabala&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Isabala\">@<span class=\"\
          underline\">Isabala</span></a></span>\n\n\t</span></span>, I don't have\
          \ a Windows system. Have you succeeded in loading other models with this\
          \ code?</p>\n"
        raw: Hi @Isabala, I don't have a Windows system. Have you succeeded in loading
          other models with this code?
        updatedAt: '2023-12-11T20:01:24.669Z'
      numEdits: 0
      reactions: []
    id: 65776a9490df9d85fb379344
    type: comment
  author: bofenghuang
  content: Hi @Isabala, I don't have a Windows system. Have you succeeded in loading
    other models with this code?
  created_at: 2023-12-11 20:01:24+00:00
  edited: false
  hidden: false
  id: 65776a9490df9d85fb379344
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: bofenghuang/whisper-large-v3-french
repo_type: model
status: open
target_branch: null
title: 'Error unhashable type: ''dict with AutoProcessor.from_pretrained'
