!!python/object:huggingface_hub.community.DiscussionWithDetails
author: spike4379
conflicting_files: null
created_at: 2023-05-05 15:30:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b912c9af139d1b0874b9fe0fbf364be8.svg
      fullname: none
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: spike4379
      type: user
    createdAt: '2023-05-05T16:30:02.000Z'
    data:
      edited: false
      editors:
      - spike4379
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b912c9af139d1b0874b9fe0fbf364be8.svg
          fullname: none
          isHf: false
          isPro: false
          name: spike4379
          type: user
        html: '<p>its replies are fantastic! The only problem I have is that by the
          third reply it just begins to get stuck infinitely generating and ooba has
          to be shut down, same with tavernAI. (Running on a 4090). Is there any suggestions
          for a way around this? Happens even with 1 generations set in params tab</p>

          '
        raw: its replies are fantastic! The only problem I have is that by the third
          reply it just begins to get stuck infinitely generating and ooba has to
          be shut down, same with tavernAI. (Running on a 4090). Is there any suggestions
          for a way around this? Happens even with 1 generations set in params tab
        updatedAt: '2023-05-05T16:30:02.117Z'
      numEdits: 0
      reactions: []
    id: 64552f0a3aaeff9f3d367317
    type: comment
  author: spike4379
  content: its replies are fantastic! The only problem I have is that by the third
    reply it just begins to get stuck infinitely generating and ooba has to be shut
    down, same with tavernAI. (Running on a 4090). Is there any suggestions for a
    way around this? Happens even with 1 generations set in params tab
  created_at: 2023-05-05 15:30:02+00:00
  edited: false
  hidden: false
  id: 64552f0a3aaeff9f3d367317
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ede1df81a7f0c8a4ce046a/93-0BQSJA1H93soqi7fiC.jpeg?w=200&h=200&f=face
      fullname: TeH_Venom
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: TehVenom
      type: user
    createdAt: '2023-05-05T16:35:38.000Z'
    data:
      edited: false
      editors:
      - TehVenom
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ede1df81a7f0c8a4ce046a/93-0BQSJA1H93soqi7fiC.jpeg?w=200&h=200&f=face
          fullname: TeH_Venom
          isHf: false
          isPro: false
          name: TehVenom
          type: user
        html: "<p>Thank you for the feedback \U0001F604<br>Unfortunately i cannot\
          \ replicate this issue on KoboldAI, so it might be some odd setting in ooba?\
          \ Sorry, i am not really familiar with that inference back end to really\
          \ offer any help</p>\n"
        raw: "Thank you for the feedback \U0001F604\nUnfortunately i cannot replicate\
          \ this issue on KoboldAI, so it might be some odd setting in ooba? Sorry,\
          \ i am not really familiar with that inference back end to really offer\
          \ any help"
        updatedAt: '2023-05-05T16:35:38.660Z'
      numEdits: 0
      reactions: []
    id: 6455305afe2f48cb4b6a1a5e
    type: comment
  author: TehVenom
  content: "Thank you for the feedback \U0001F604\nUnfortunately i cannot replicate\
    \ this issue on KoboldAI, so it might be some odd setting in ooba? Sorry, i am\
    \ not really familiar with that inference back end to really offer any help"
  created_at: 2023-05-05 15:35:38+00:00
  edited: false
  hidden: false
  id: 6455305afe2f48cb4b6a1a5e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TehVenom/Pygmalion-Vicuna-1.1-7b
repo_type: model
status: open
target_branch: null
title: This model is amazing, only one problem
