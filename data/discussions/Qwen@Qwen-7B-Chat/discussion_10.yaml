!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Cheshire94
conflicting_files: null
created_at: 2023-08-04 07:25:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6250563d6b9676db94a224e05e42ed3b.svg
      fullname: Shangming Cai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Cheshire94
      type: user
    createdAt: '2023-08-04T08:25:34.000Z'
    data:
      edited: true
      editors:
      - Cheshire94
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.49837473034858704
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6250563d6b9676db94a224e05e42ed3b.svg
          fullname: Shangming Cai
          isHf: false
          isPro: false
          name: Cheshire94
          type: user
        html: "<p>In Qwen-7B-Chat/qwen_generation_utils.py<br>    line 349\uFF1A \
          \     scores[i, self.eos_token_id] = float(2**30)</p>\n<p>When using torch_dtype=torch.float16,\
          \ this line above trigger the following error:<br>    RuntimeError: value\
          \ cannot be converted to type at::Half without overflow</p>\n<p>Maybe consider\
          \ changing it to torch.finfo(torch.float16).max when the dtype is set to\
          \ torch.float16 and keeping it to float(2**30) for torch.float32?</p>\n"
        raw: "In Qwen-7B-Chat/qwen_generation_utils.py\n    line 349\uFF1A      scores[i,\
          \ self.eos_token_id] = float(2**30)\n\nWhen using torch_dtype=torch.float16,\
          \ this line above trigger the following error:\n    RuntimeError: value\
          \ cannot be converted to type at::Half without overflow\n\nMaybe consider\
          \ changing it to torch.finfo(torch.float16).max when the dtype is set to\
          \ torch.float16 and keeping it to float(2**30) for torch.float32?"
        updatedAt: '2023-08-04T08:32:21.393Z'
      numEdits: 1
      reactions: []
    id: 64ccb5fee984d09bedca7af6
    type: comment
  author: Cheshire94
  content: "In Qwen-7B-Chat/qwen_generation_utils.py\n    line 349\uFF1A      scores[i,\
    \ self.eos_token_id] = float(2**30)\n\nWhen using torch_dtype=torch.float16, this\
    \ line above trigger the following error:\n    RuntimeError: value cannot be converted\
    \ to type at::Half without overflow\n\nMaybe consider changing it to torch.finfo(torch.float16).max\
    \ when the dtype is set to torch.float16 and keeping it to float(2**30) for torch.float32?"
  created_at: 2023-08-04 07:25:34+00:00
  edited: true
  hidden: false
  id: 64ccb5fee984d09bedca7af6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1645612927537-620875b2ad90acde88c6087e.jpeg?w=200&h=200&f=face
      fullname: Wang Peng
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: logicwong
      type: user
    createdAt: '2023-08-04T09:34:08.000Z'
    data:
      edited: false
      editors:
      - logicwong
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8903416991233826
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1645612927537-620875b2ad90acde88c6087e.jpeg?w=200&h=200&f=face
          fullname: Wang Peng
          isHf: false
          isPro: false
          name: logicwong
          type: user
        html: '<p>We manually set it to float(2**15), try again?</p>

          '
        raw: We manually set it to float(2**15), try again?
        updatedAt: '2023-08-04T09:34:08.266Z'
      numEdits: 0
      reactions: []
    id: 64ccc6104726a3f8338092b7
    type: comment
  author: logicwong
  content: We manually set it to float(2**15), try again?
  created_at: 2023-08-04 08:34:08+00:00
  edited: false
  hidden: false
  id: 64ccc6104726a3f8338092b7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9921ca8568f9d53c919681d8960ad802.svg
      fullname: jklj077
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jklj077
      type: user
    createdAt: '2023-08-08T03:45:54.000Z'
    data:
      edited: false
      editors:
      - jklj077
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9596520066261292
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9921ca8568f9d53c919681d8960ad802.svg
          fullname: jklj077
          isHf: false
          isPro: false
          name: jklj077
          type: user
        html: '<p>Thank you for raising this problem! </p>

          <p>It has been fixed in main. I''ll just close this for now. If the problem
          persists, please open a new issue.</p>

          '
        raw: "Thank you for raising this problem! \n\nIt has been fixed in main. I'll\
          \ just close this for now. If the problem persists, please open a new issue."
        updatedAt: '2023-08-08T03:45:54.772Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64d1ba7215b26cc7f722f69b
    id: 64d1ba7215b26cc7f722f69a
    type: comment
  author: jklj077
  content: "Thank you for raising this problem! \n\nIt has been fixed in main. I'll\
    \ just close this for now. If the problem persists, please open a new issue."
  created_at: 2023-08-08 02:45:54+00:00
  edited: false
  hidden: false
  id: 64d1ba7215b26cc7f722f69a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9921ca8568f9d53c919681d8960ad802.svg
      fullname: jklj077
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jklj077
      type: user
    createdAt: '2023-08-08T03:45:54.000Z'
    data:
      status: closed
    id: 64d1ba7215b26cc7f722f69b
    type: status-change
  author: jklj077
  created_at: 2023-08-08 02:45:54+00:00
  id: 64d1ba7215b26cc7f722f69b
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: Qwen/Qwen-7B-Chat
repo_type: model
status: closed
target_branch: null
title: Error with dtype=torch.float16.
