!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yinanxu
conflicting_files: null
created_at: 2023-09-27 02:23:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/480e669f39d175d7f5554f3167e47dea.svg
      fullname: Yinan Xu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yinanxu
      type: user
    createdAt: '2023-09-27T03:23:18.000Z'
    data:
      edited: true
      editors:
      - yinanxu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7351509928703308
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/480e669f39d175d7f5554f3167e47dea.svg
          fullname: Yinan Xu
          isHf: false
          isPro: false
          name: yinanxu
          type: user
        html: '<p>1, Size of model embedding and tokenizer mismatch.</p>

          <ul>

          <li>model embedding size = 151936</li>

          <li>tokenizer size = 151851<br>What are those extra (151936-151851)=85 tokens?
          Are those extra tokens used?</li>

          </ul>

          <p>2, No explicit special tokens in tokenizer. I guess</p>

          <ul>

          <li>bos = &lt;|im_start|&gt;</li>

          <li>eos = &lt;|im_end|&gt;<br>but what is the pad token?</li>

          </ul>

          '
        raw: '1, Size of model embedding and tokenizer mismatch.

          - model embedding size = 151936

          - tokenizer size = 151851

          What are those extra (151936-151851)=85 tokens? Are those extra tokens used?


          2, No explicit special tokens in tokenizer. I guess

          - bos = <|im_start|>

          - eos = <|im_end|>

          but what is the pad token?



          '
        updatedAt: '2023-09-27T03:31:51.958Z'
      numEdits: 2
      reactions: []
    id: 6513a026ac120f23e0091438
    type: comment
  author: yinanxu
  content: '1, Size of model embedding and tokenizer mismatch.

    - model embedding size = 151936

    - tokenizer size = 151851

    What are those extra (151936-151851)=85 tokens? Are those extra tokens used?


    2, No explicit special tokens in tokenizer. I guess

    - bos = <|im_start|>

    - eos = <|im_end|>

    but what is the pad token?



    '
  created_at: 2023-09-27 02:23:18+00:00
  edited: true
  hidden: false
  id: 6513a026ac120f23e0091438
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9921ca8568f9d53c919681d8960ad802.svg
      fullname: jklj077
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jklj077
      type: user
    createdAt: '2023-09-28T04:45:39.000Z'
    data:
      edited: false
      editors:
      - jklj077
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8742968440055847
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9921ca8568f9d53c919681d8960ad802.svg
          fullname: jklj077
          isHf: false
          isPro: false
          name: jklj077
          type: user
        html: '<ol>

          <li>The embedding size is padded (multiples of 128) to improve computation
          efficiency for devices with tensor cores. The padded are not used.</li>

          <li>Please refer to our docs here: <a rel="nofollow" href="https://github.com/QwenLM/Qwen/blob/main/tokenization_note.md">https://github.com/QwenLM/Qwen/blob/main/tokenization_note.md</a>
          There is generally no need to set those tokens with our code.</li>

          </ol>

          '
        raw: '1. The embedding size is padded (multiples of 128) to improve computation
          efficiency for devices with tensor cores. The padded are not used.

          2. Please refer to our docs here: <https://github.com/QwenLM/Qwen/blob/main/tokenization_note.md>
          There is generally no need to set those tokens with our code.'
        updatedAt: '2023-09-28T04:45:39.563Z'
      numEdits: 0
      reactions: []
    id: 651504f32f429575953297e2
    type: comment
  author: jklj077
  content: '1. The embedding size is padded (multiples of 128) to improve computation
    efficiency for devices with tensor cores. The padded are not used.

    2. Please refer to our docs here: <https://github.com/QwenLM/Qwen/blob/main/tokenization_note.md>
    There is generally no need to set those tokens with our code.'
  created_at: 2023-09-28 03:45:39+00:00
  edited: false
  hidden: false
  id: 651504f32f429575953297e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9921ca8568f9d53c919681d8960ad802.svg
      fullname: jklj077
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jklj077
      type: user
    createdAt: '2023-10-09T11:15:08.000Z'
    data:
      status: closed
    id: 6523e0bc11bbfc1fc47aa385
    type: status-change
  author: jklj077
  created_at: 2023-10-09 10:15:08+00:00
  id: 6523e0bc11bbfc1fc47aa385
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 41
repo_id: Qwen/Qwen-7B-Chat
repo_type: model
status: closed
target_branch: null
title: several concerns about tokenizer and model embedding
