!!python/object:huggingface_hub.community.DiscussionWithDetails
author: omers66
conflicting_files: null
created_at: 2024-01-02 12:50:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7782abc891a7117213e02d0f6f67b1d3.svg
      fullname: Omer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: omers66
      type: user
    createdAt: '2024-01-02T12:50:12.000Z'
    data:
      edited: false
      editors:
      - omers66
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9571321606636047
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7782abc891a7117213e02d0f6f67b1d3.svg
          fullname: Omer
          isHf: false
          isPro: false
          name: omers66
          type: user
        html: '<p>Hey, I''m curious to understand how the evaluation process took
          place for any of the chat models on question-answering data sets.<br>Say
          for example MMLU: I know that we usually pad the prompts with:<br>''The
          following are multiple choice questions (with answers) about   ...<br>But
          then the chat model doesn''t necessarily answer with ''A'', ''B'', ''C'',
          or ''D'', but it can start chatting about the questions, answers, etc..<br>How
          did you deal with that?</p>

          '
        raw: "Hey, I'm curious to understand how the evaluation process took place\
          \ for any of the chat models on question-answering data sets.\r\nSay for\
          \ example MMLU: I know that we usually pad the prompts with:\r\n'The following\
          \ are multiple choice questions (with answers) about  <subject> ...\r\n\
          But then the chat model doesn't necessarily answer with 'A', 'B', 'C', or\
          \ 'D', but it can start chatting about the questions, answers, etc..\r\n\
          How did you deal with that?"
        updatedAt: '2024-01-02T12:50:12.825Z'
      numEdits: 0
      reactions: []
    id: 6594068477105e6e408ebe49
    type: comment
  author: omers66
  content: "Hey, I'm curious to understand how the evaluation process took place for\
    \ any of the chat models on question-answering data sets.\r\nSay for example MMLU:\
    \ I know that we usually pad the prompts with:\r\n'The following are multiple\
    \ choice questions (with answers) about  <subject> ...\r\nBut then the chat model\
    \ doesn't necessarily answer with 'A', 'B', 'C', or 'D', but it can start chatting\
    \ about the questions, answers, etc..\r\nHow did you deal with that?"
  created_at: 2024-01-02 12:50:12+00:00
  edited: false
  hidden: false
  id: 6594068477105e6e408ebe49
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9921ca8568f9d53c919681d8960ad802.svg
      fullname: jklj077
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jklj077
      type: user
    createdAt: '2024-01-17T08:13:52.000Z'
    data:
      edited: false
      editors:
      - jklj077
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6889050006866455
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9921ca8568f9d53c919681d8960ad802.svg
          fullname: jklj077
          isHf: false
          isPro: false
          name: jklj077
          type: user
        html: '<p>Hi, please see the following for an example:</p>

          <ul>

          <li><a rel="nofollow" href="https://github.com/QwenLM/Qwen/blob/main/eval/evaluate_chat_mmlu.py">https://github.com/QwenLM/Qwen/blob/main/eval/evaluate_chat_mmlu.py</a></li>

          </ul>

          '
        raw: 'Hi, please see the following for an example:

          - <https://github.com/QwenLM/Qwen/blob/main/eval/evaluate_chat_mmlu.py>'
        updatedAt: '2024-01-17T08:13:52.339Z'
      numEdits: 0
      reactions: []
    id: 65a78c405c58475cf924b07b
    type: comment
  author: jklj077
  content: 'Hi, please see the following for an example:

    - <https://github.com/QwenLM/Qwen/blob/main/eval/evaluate_chat_mmlu.py>'
  created_at: 2024-01-17 08:13:52+00:00
  edited: false
  hidden: false
  id: 65a78c405c58475cf924b07b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 49
repo_id: Qwen/Qwen-7B-Chat
repo_type: model
status: open
target_branch: null
title: How did you evaluate the Qwen chat models on MMLU (or any other datasets)
