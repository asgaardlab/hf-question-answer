!!python/object:huggingface_hub.community.DiscussionWithDetails
author: echarlaix
conflicting_files: []
created_at: 2023-03-14 15:45:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615915889033-6050eb5aeb94f56898c08e57.jpeg?w=200&h=200&f=face
      fullname: Ella Charlaix
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: echarlaix
      type: user
    createdAt: '2023-03-14T16:45:36.000Z'
    data:
      edited: false
      editors:
      - echarlaix
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615915889033-6050eb5aeb94f56898c08e57.jpeg?w=200&h=200&f=face
          fullname: Ella Charlaix
          isHf: true
          isPro: false
          name: echarlaix
          type: user
        html: "<p>Beep boop I am the <a href=\"https://huggingface.co/spaces/optimum/exporters\"\
          >ONNX export bot \U0001F916\U0001F3CE\uFE0F</a>. On behalf of <a href=\"\
          https://huggingface.co/echarlaix\">echarlaix</a>, I would like to add to\
          \ this repository the model converted to ONNX.</p>\n<p>What is ONNX? It\
          \ stands for \"Open Neural Network Exchange\", and is the most commonly\
          \ used open standard for machine learning interoperability. You can find\
          \ out more at <a rel=\"nofollow\" href=\"https://onnx.ai/\">onnx.ai</a>!</p>\n\
          <p>The exported ONNX model can be then be consumed by various backends as\
          \ TensorRT or TVM, or simply be used in a few lines with \U0001F917 Optimum\
          \ through ONNX Runtime, check out how <a href=\"https://huggingface.co/docs/optimum/main/en/onnxruntime/usage_guides/models\"\
          >here</a>!</p>\n"
        raw: "Beep boop I am the [ONNX export bot \U0001F916\U0001F3CE\uFE0F](https://huggingface.co/spaces/optimum/exporters).\
          \ On behalf of [echarlaix](https://huggingface.co/echarlaix), I would like\
          \ to add to this repository the model converted to ONNX.\n\nWhat is ONNX?\
          \ It stands for \"Open Neural Network Exchange\", and is the most commonly\
          \ used open standard for machine learning interoperability. You can find\
          \ out more at [onnx.ai](https://onnx.ai/)!\n\nThe exported ONNX model can\
          \ be then be consumed by various backends as TensorRT or TVM, or simply\
          \ be used in a few lines with \U0001F917 Optimum through ONNX Runtime, check\
          \ out how [here](https://huggingface.co/docs/optimum/main/en/onnxruntime/usage_guides/models)!"
        updatedAt: '2023-03-14T16:45:36.003Z'
      numEdits: 0
      reactions: []
    id: 6410a4b0ef6be374e0d71fea
    type: comment
  author: echarlaix
  content: "Beep boop I am the [ONNX export bot \U0001F916\U0001F3CE\uFE0F](https://huggingface.co/spaces/optimum/exporters).\
    \ On behalf of [echarlaix](https://huggingface.co/echarlaix), I would like to\
    \ add to this repository the model converted to ONNX.\n\nWhat is ONNX? It stands\
    \ for \"Open Neural Network Exchange\", and is the most commonly used open standard\
    \ for machine learning interoperability. You can find out more at [onnx.ai](https://onnx.ai/)!\n\
    \nThe exported ONNX model can be then be consumed by various backends as TensorRT\
    \ or TVM, or simply be used in a few lines with \U0001F917 Optimum through ONNX\
    \ Runtime, check out how [here](https://huggingface.co/docs/optimum/main/en/onnxruntime/usage_guides/models)!"
  created_at: 2023-03-14 15:45:36+00:00
  edited: false
  hidden: false
  id: 6410a4b0ef6be374e0d71fea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615915889033-6050eb5aeb94f56898c08e57.jpeg?w=200&h=200&f=face
      fullname: Ella Charlaix
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: echarlaix
      type: user
    createdAt: '2023-03-14T16:45:36.000Z'
    data:
      oid: 33765c5927881b5e9859e686df9bc568e1866c45
      parents:
      - 66e43296a603db283181214996bf46c06fa950c3
      subject: Adding ONNX file of this model
    id: 6410a4b00000000000000000
    type: commit
  author: echarlaix
  created_at: 2023-03-14 15:45:36+00:00
  id: 6410a4b00000000000000000
  oid: 33765c5927881b5e9859e686df9bc568e1866c45
  summary: Adding ONNX file of this model
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1615915889033-6050eb5aeb94f56898c08e57.jpeg?w=200&h=200&f=face
      fullname: Ella Charlaix
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: echarlaix
      type: user
    createdAt: '2023-03-21T14:47:13.000Z'
    data:
      status: closed
    id: 6419c371cbec40a14f52e361
    type: status-change
  author: echarlaix
  created_at: 2023-03-21 13:47:13+00:00
  id: 6419c371cbec40a14f52e361
  new_status: closed
  type: status-change
is_pull_request: true
merge_commit_oid: null
num: 1
repo_id: echarlaix/distilbert-sst2-inc-dynamic-quantization-magnitude-pruning-0.1
repo_type: model
status: closed
target_branch: refs/heads/main
title: Adding ONNX file of this model
