!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kopsahlong
conflicting_files: null
created_at: 2023-12-27 20:42:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7cf55e5d1a47808dc45cee18126b3340.svg
      fullname: Krista Opsahl-Ong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kopsahlong
      type: user
    createdAt: '2023-12-27T20:42:59.000Z'
    data:
      edited: false
      editors:
      - kopsahlong
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4767664670944214
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7cf55e5d1a47808dc45cee18126b3340.svg
          fullname: Krista Opsahl-Ong
          isHf: false
          isPro: false
          name: kopsahlong
          type: user
        html: '<p>Hi there! I''m trying to download this model using the code provided
          by "Use in Transformers".</p>

          <pre><code>from transformers import AutoProcessor, AutoModelForCausalLM


          processor = AutoProcessor.from_pretrained("liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3")

          model = AutoModelForCausalLM.from_pretrained("liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3")

          </code></pre>

          <p>I''m currently getting an error when I run this code:</p>

          <pre><code>OSError: liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3 does
          not appear to have a file named preprocessor_config.json. Checkout ''https://huggingface.co/liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3/main''
          for available files.

          </code></pre>

          <p>When I just run this line <code>model = AutoModelForCausalLM.from_pretrained("liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3")</code>,
          I get this error:</p>

          <pre><code>ValueError: Unrecognized configuration class &lt;class ''transformers.models.llava.configuration_llava.LlavaConfig''&gt;
          for this kind of AutoModel: AutoModelForCausalLM.

          Model type should be one of BartConfig, BertConfig, BertGenerationConfig,
          BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig,
          BloomConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CpmAntConfig,
          CTRLConfig, Data2VecTextConfig, ElectraConfig, ErnieConfig, FalconConfig,
          FuyuConfig, GitConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig,
          GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, LlamaConfig, MarianConfig,
          MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig,
          MptConfig, MusicgenConfig, MvpConfig, OpenLlamaConfig, OpenAIGPTConfig,
          OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, PLBartConfig, ProphetNetConfig,
          QDQBertConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig,
          RoCBertConfig, RoFormerConfig, RwkvConfig, Speech2Text2Config, TransfoXLConfig,
          TrOCRConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig,
          XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig.

          </code></pre>

          <p>I''m using transformers version 4.36.2.</p>

          <p>Any thoughts on what might be going wrong here and how to fix it?</p>

          <p>Thanks in advance for the help!</p>

          '
        raw: "Hi there! I'm trying to download this model using the code provided\
          \ by \"Use in Transformers\".\r\n\r\n```\r\nfrom transformers import AutoProcessor,\
          \ AutoModelForCausalLM\r\n\r\nprocessor = AutoProcessor.from_pretrained(\"\
          liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3\")\r\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3\")\r\n```\r\n\r\nI'm currently\
          \ getting an error when I run this code:\r\n\r\n```\r\nOSError: liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3\
          \ does not appear to have a file named preprocessor_config.json. Checkout\
          \ 'https://huggingface.co/liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3/main'\
          \ for available files.\r\n```\r\n\r\nWhen I just run this line `model =\
          \ AutoModelForCausalLM.from_pretrained(\"liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3\"\
          )`, I get this error:\r\n\r\n```\r\nValueError: Unrecognized configuration\
          \ class <class 'transformers.models.llava.configuration_llava.LlavaConfig'>\
          \ for this kind of AutoModel: AutoModelForCausalLM.\r\nModel type should\
          \ be one of BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig,\
          \ BigBirdPegasusConfig, BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig,\
          \ BloomConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CpmAntConfig,\
          \ CTRLConfig, Data2VecTextConfig, ElectraConfig, ErnieConfig, FalconConfig,\
          \ FuyuConfig, GitConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig,\
          \ GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, LlamaConfig, MarianConfig,\
          \ MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig,\
          \ MptConfig, MusicgenConfig, MvpConfig, OpenLlamaConfig, OpenAIGPTConfig,\
          \ OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, PLBartConfig, ProphetNetConfig,\
          \ QDQBertConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig,\
          \ RoCBertConfig, RoFormerConfig, RwkvConfig, Speech2Text2Config, TransfoXLConfig,\
          \ TrOCRConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig,\
          \ XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig.\r\n```\r\
          \n\r\nI'm using transformers version 4.36.2.\r\n\r\nAny thoughts on what\
          \ might be going wrong here and how to fix it?\r\n\r\nThanks in advance\
          \ for the help!"
        updatedAt: '2023-12-27T20:42:59.591Z'
      numEdits: 0
      reactions: []
    id: 658c8c537ff4aa6aa77fb860
    type: comment
  author: kopsahlong
  content: "Hi there! I'm trying to download this model using the code provided by\
    \ \"Use in Transformers\".\r\n\r\n```\r\nfrom transformers import AutoProcessor,\
    \ AutoModelForCausalLM\r\n\r\nprocessor = AutoProcessor.from_pretrained(\"liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3\"\
    )\r\nmodel = AutoModelForCausalLM.from_pretrained(\"liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3\"\
    )\r\n```\r\n\r\nI'm currently getting an error when I run this code:\r\n\r\n```\r\
    \nOSError: liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3 does not appear to\
    \ have a file named preprocessor_config.json. Checkout 'https://huggingface.co/liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3/main'\
    \ for available files.\r\n```\r\n\r\nWhen I just run this line `model = AutoModelForCausalLM.from_pretrained(\"\
    liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3\")`, I get this error:\r\n\r\n\
    ```\r\nValueError: Unrecognized configuration class <class 'transformers.models.llava.configuration_llava.LlavaConfig'>\
    \ for this kind of AutoModel: AutoModelForCausalLM.\r\nModel type should be one\
    \ of BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig,\
    \ BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig,\
    \ LlamaConfig, CodeGenConfig, CpmAntConfig, CTRLConfig, Data2VecTextConfig, ElectraConfig,\
    \ ErnieConfig, FalconConfig, FuyuConfig, GitConfig, GPT2Config, GPT2Config, GPTBigCodeConfig,\
    \ GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, LlamaConfig,\
    \ MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig,\
    \ MptConfig, MusicgenConfig, MvpConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig,\
    \ PegasusConfig, PersimmonConfig, PhiConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig,\
    \ ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig,\
    \ RoFormerConfig, RwkvConfig, Speech2Text2Config, TransfoXLConfig, TrOCRConfig,\
    \ WhisperConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig,\
    \ XLMRobertaXLConfig, XLNetConfig, XmodConfig.\r\n```\r\n\r\nI'm using transformers\
    \ version 4.36.2.\r\n\r\nAny thoughts on what might be going wrong here and how\
    \ to fix it?\r\n\r\nThanks in advance for the help!"
  created_at: 2023-12-27 20:42:59+00:00
  edited: false
  hidden: false
  id: 658c8c537ff4aa6aa77fb860
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7cf55e5d1a47808dc45cee18126b3340.svg
      fullname: Krista Opsahl-Ong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kopsahlong
      type: user
    createdAt: '2023-12-27T20:57:15.000Z'
    data:
      edited: false
      editors:
      - kopsahlong
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5278525352478027
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7cf55e5d1a47808dc45cee18126b3340.svg
          fullname: Krista Opsahl-Ong
          isHf: false
          isPro: false
          name: kopsahlong
          type: user
        html: "<p>Update that I tried updating my transformers version to the following\
          \ commit: <code>pip install git+https://github.com/huggingface/transformers.git@cae78c46</code>,\
          \ but am now getting the following error:</p>\n<pre><code>  File \"/home/kopsahlong/miniconda3/envs/test2/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 926, in from_pretrained\n    config_class = CONFIG_MAPPING[config_dict[\"\
          model_type\"]]\n  File \"/home/kopsahlong/miniconda3/envs/test2/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 632, in __getitem__\n    raise KeyError(key)\nKeyError: 'llava'\n\
          </code></pre>\n"
        raw: "Update that I tried updating my transformers version to the following\
          \ commit: `pip install git+https://github.com/huggingface/transformers.git@cae78c46`,\
          \ but am now getting the following error:\n\n```\n  File \"/home/kopsahlong/miniconda3/envs/test2/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 926, in from_pretrained\n    config_class = CONFIG_MAPPING[config_dict[\"\
          model_type\"]]\n  File \"/home/kopsahlong/miniconda3/envs/test2/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 632, in __getitem__\n    raise KeyError(key)\nKeyError: 'llava'\n\
          ```"
        updatedAt: '2023-12-27T20:57:15.756Z'
      numEdits: 0
      reactions: []
    id: 658c8fabd92f514e67fa06be
    type: comment
  author: kopsahlong
  content: "Update that I tried updating my transformers version to the following\
    \ commit: `pip install git+https://github.com/huggingface/transformers.git@cae78c46`,\
    \ but am now getting the following error:\n\n```\n  File \"/home/kopsahlong/miniconda3/envs/test2/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 926, in from_pretrained\n    config_class = CONFIG_MAPPING[config_dict[\"\
    model_type\"]]\n  File \"/home/kopsahlong/miniconda3/envs/test2/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 632, in __getitem__\n    raise KeyError(key)\nKeyError: 'llava'\n```"
  created_at: 2023-12-27 20:57:15+00:00
  edited: false
  hidden: false
  id: 658c8fabd92f514e67fa06be
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674248167280-63898b61ec1f539adc0f4da2.jpeg?w=200&h=200&f=face
      fullname: Haotian Liu
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: liuhaotian
      type: user
    createdAt: '2023-12-28T03:03:55.000Z'
    data:
      edited: false
      editors:
      - liuhaotian
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6721398830413818
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674248167280-63898b61ec1f539adc0f4da2.jpeg?w=200&h=200&f=face
          fullname: Haotian Liu
          isHf: false
          isPro: false
          name: liuhaotian
          type: user
        html: '<p>this is just a pretrained projector and is not the full model. </p>

          <p>if you want to use the latest transformers to directly load the model,
          please use : <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf">https://huggingface.co/llava-hf/llava-1.5-7b-hf</a>
          or <a href="https://huggingface.co/llava-hf/llava-1.5-13b-hf">https://huggingface.co/llava-hf/llava-1.5-13b-hf</a></p>

          <p>otherwise, use our code base and <a href="https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e">https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e</a></p>

          <p>thanks.</p>

          '
        raw: "this is just a pretrained projector and is not the full model. \n\n\
          if you want to use the latest transformers to directly load the model, please\
          \ use : https://huggingface.co/llava-hf/llava-1.5-7b-hf or https://huggingface.co/llava-hf/llava-1.5-13b-hf\n\
          \notherwise, use our code base and https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e\n\
          \nthanks."
        updatedAt: '2023-12-28T03:03:55.516Z'
      numEdits: 0
      reactions: []
    id: 658ce59b46cf834ec3c05df3
    type: comment
  author: liuhaotian
  content: "this is just a pretrained projector and is not the full model. \n\nif\
    \ you want to use the latest transformers to directly load the model, please use\
    \ : https://huggingface.co/llava-hf/llava-1.5-7b-hf or https://huggingface.co/llava-hf/llava-1.5-13b-hf\n\
    \notherwise, use our code base and https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e\n\
    \nthanks."
  created_at: 2023-12-28 03:03:55+00:00
  edited: false
  hidden: false
  id: 658ce59b46cf834ec3c05df3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: liuhaotian/llava-336px-pretrain-vicuna-7b-v1.3
repo_type: model
status: open
target_branch: null
title: Error loading model
