!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aryan1107
conflicting_files: null
created_at: 2022-07-13 12:33:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fd8ee37fcc62420fd846d2f25c7648ac.svg
      fullname: 'Aryan '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aryan1107
      type: user
    createdAt: '2022-07-13T13:33:14.000Z'
    data:
      edited: false
      editors:
      - aryan1107
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fd8ee37fcc62420fd846d2f25c7648ac.svg
          fullname: 'Aryan '
          isHf: false
          isPro: false
          name: aryan1107
          type: user
        html: '<p>AttributeError: ''BloomTokenizerFast'' object has no attribute ''tokenizer''</p>

          <p>My code is something like this:</p>

          <p>from transformers import AutoTokenizer, BloomForCausalLM</p>

          <p>tokenizer = AutoTokenizer.from_pretrained("bigscience/bloom-1b3")</p>

          <p>model = BloomForCausalLM.from_pretrained("bigscience/bloom-1b3")</p>

          <p>prompt = "Today I believe we can finally"</p>

          <p>input_ids = tokenizer(prompt, return_tensors="pt").input_ids</p>

          <h1 id="generate-up-to-30-tokens">generate up to 30 tokens</h1>

          <p>outputs = model.generate(input_ids, do_sample=False, max_length=30)</p>

          <p>tokenizer.batch_decode(outputs, skip_special_tokens=True)</p>

          '
        raw: "AttributeError: 'BloomTokenizerFast' object has no attribute 'tokenizer'\r\
          \n\r\nMy code is something like this:\r\n\r\nfrom transformers import AutoTokenizer,\
          \ BloomForCausalLM\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b3\"\
          )\r\n\r\nmodel = BloomForCausalLM.from_pretrained(\"bigscience/bloom-1b3\"\
          )\r\n\r\nprompt = \"Today I believe we can finally\"\r\n\r\ninput_ids =\
          \ tokenizer(prompt, return_tensors=\"pt\").input_ids\r\n\r\n# generate up\
          \ to 30 tokens\r\n\r\noutputs = model.generate(input_ids, do_sample=False,\
          \ max_length=30)\r\n\r\ntokenizer.batch_decode(outputs, skip_special_tokens=True)"
        updatedAt: '2022-07-13T13:33:14.477Z'
      numEdits: 0
      reactions: []
    id: 62cec99a180d2ba1cdfbda9c
    type: comment
  author: aryan1107
  content: "AttributeError: 'BloomTokenizerFast' object has no attribute 'tokenizer'\r\
    \n\r\nMy code is something like this:\r\n\r\nfrom transformers import AutoTokenizer,\
    \ BloomForCausalLM\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b3\"\
    )\r\n\r\nmodel = BloomForCausalLM.from_pretrained(\"bigscience/bloom-1b3\")\r\n\
    \r\nprompt = \"Today I believe we can finally\"\r\n\r\ninput_ids = tokenizer(prompt,\
    \ return_tensors=\"pt\").input_ids\r\n\r\n# generate up to 30 tokens\r\n\r\noutputs\
    \ = model.generate(input_ids, do_sample=False, max_length=30)\r\n\r\ntokenizer.batch_decode(outputs,\
    \ skip_special_tokens=True)"
  created_at: 2022-07-13 12:33:14+00:00
  edited: false
  hidden: false
  id: 62cec99a180d2ba1cdfbda9c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2022-07-13T13:38:47.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;aryan1107&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/aryan1107\"\
          >@<span class=\"underline\">aryan1107</span></a></span>\n\n\t</span></span>\
          \ !<br>Thanks for your message,<br>I just tried this script:</p>\n<pre><code>from\
          \ transformers import AutoTokenizer, BloomForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"\
          bigscience/bloom-1b3\")\n\nmodel = BloomForCausalLM.from_pretrained(\"bigscience/bloom-1b3\"\
          )\n\nprompt = \"Today I believe we can finally\"\n\ninput_ids = tokenizer(prompt,\
          \ return_tensors=\"pt\").input_ids\n\noutputs = model.generate(input_ids,\
          \ do_sample=False, max_length=30)\n\nprint(tokenizer.batch_decode(outputs,\
          \ skip_special_tokens=True))\n</code></pre>\n<p>and seems to work fine on\
          \ my side, what version of transformers are you using?</p>\n"
        raw: "Hi @aryan1107 !\nThanks for your message, \nI just tried this script:\n\
          \n```\nfrom transformers import AutoTokenizer, BloomForCausalLM\n\ntokenizer\
          \ = AutoTokenizer.from_pretrained(\"bigscience/bloom-1b3\")\n\nmodel = BloomForCausalLM.from_pretrained(\"\
          bigscience/bloom-1b3\")\n\nprompt = \"Today I believe we can finally\"\n\
          \ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n\noutputs\
          \ = model.generate(input_ids, do_sample=False, max_length=30)\n\nprint(tokenizer.batch_decode(outputs,\
          \ skip_special_tokens=True))\n\n```\n\nand seems to work fine on my side,\
          \ what version of transformers are you using?"
        updatedAt: '2022-07-13T13:38:47.461Z'
      numEdits: 0
      reactions: []
    id: 62cecae75802fa8dc0724195
    type: comment
  author: ybelkada
  content: "Hi @aryan1107 !\nThanks for your message, \nI just tried this script:\n\
    \n```\nfrom transformers import AutoTokenizer, BloomForCausalLM\n\ntokenizer =\
    \ AutoTokenizer.from_pretrained(\"bigscience/bloom-1b3\")\n\nmodel = BloomForCausalLM.from_pretrained(\"\
    bigscience/bloom-1b3\")\n\nprompt = \"Today I believe we can finally\"\n\ninput_ids\
    \ = tokenizer(prompt, return_tensors=\"pt\").input_ids\n\noutputs = model.generate(input_ids,\
    \ do_sample=False, max_length=30)\n\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n\
    \n```\n\nand seems to work fine on my side, what version of transformers are you\
    \ using?"
  created_at: 2022-07-13 12:38:47+00:00
  edited: false
  hidden: false
  id: 62cecae75802fa8dc0724195
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fd8ee37fcc62420fd846d2f25c7648ac.svg
      fullname: 'Aryan '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aryan1107
      type: user
    createdAt: '2022-07-13T15:47:52.000Z'
    data:
      edited: false
      editors:
      - aryan1107
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fd8ee37fcc62420fd846d2f25c7648ac.svg
          fullname: 'Aryan '
          isHf: false
          isPro: false
          name: aryan1107
          type: user
        html: '<p>Thank you it''s working I had made a typo. my bad</p>

          '
        raw: Thank you it's working I had made a typo. my bad
        updatedAt: '2022-07-13T15:47:52.423Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - ybelkada
    id: 62cee928a3a23014aca864a7
    type: comment
  author: aryan1107
  content: Thank you it's working I had made a typo. my bad
  created_at: 2022-07-13 14:47:52+00:00
  edited: false
  hidden: false
  id: 62cee928a3a23014aca864a7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/fd8ee37fcc62420fd846d2f25c7648ac.svg
      fullname: 'Aryan '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aryan1107
      type: user
    createdAt: '2022-07-13T15:47:52.000Z'
    data:
      status: closed
    id: 62cee928a3a23014aca864a8
    type: status-change
  author: aryan1107
  created_at: 2022-07-13 14:47:52+00:00
  id: 62cee928a3a23014aca864a8
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 14
repo_id: bigscience/bloom-1b7
repo_type: model
status: closed
target_branch: null
title: Unable to decode text I get this error.
