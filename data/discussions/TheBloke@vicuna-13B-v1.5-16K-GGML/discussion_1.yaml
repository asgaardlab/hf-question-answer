!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mrichardt
conflicting_files: null
created_at: 2023-08-04 15:40:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4921bbf1c3fac573cecc9a9d7d1ba27c.svg
      fullname: martin  richardt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mrichardt
      type: user
    createdAt: '2023-08-04T16:40:58.000Z'
    data:
      edited: false
      editors:
      - mrichardt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8714358806610107
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4921bbf1c3fac573cecc9a9d7d1ba27c.svg
          fullname: martin  richardt
          isHf: false
          isPro: false
          name: mrichardt
          type: user
        html: '<p>Eg in LM Studio (0.1.11)</p>

          <p>curl <a rel="nofollow" href="http://localhost:1234/v1/chat/completions">http://localhost:1234/v1/chat/completions</a>
          <br>  -H "Content-Type: application/json" <br>  -d ''{<br>    "messages":
          [{"role": "user", "content": "Introduce yourself."}],<br>    "temperature":
          0.7,<br>    "max_tokens": -1,<br>    "stream": false<br>  }''</p>

          <p>Get following response</p>

          <p>[2023-08-04 18:33:17.287] [INFO] Generated prediction: {<br>  "id": "chatcmpl-anobk33c2ezhuggk932",<br>  "object":
          "chat.completion",<br>  "created": 1691166667,<br>  "model": "/Users/martinrichardt/.cache/lm-studio/models/TheBloke/vicuna-13B-v1.5-16K-GGML/vicuna-13b-v1.5-16k.ggmlv3.q4_1.bin",<br>  "choices":
          [<br>    {<br>      "index": 0,<br>      "message": {<br>        "role":
          "assistant",<br>        "content": "\nMy name is Anastasiya. I am a student
          of master''s program in the field of marketing at the University of Economics
          in Varna, Bulgaria. I have always been interested in the world of business
          and how it can affect the economy. That''s why why why why why why why why
          why why why why why why why why why why why why why why why why why why
          why why why why why why why why why why why why why why why why why why
          why why why why why why why why why why why why why why why why why why
          why why why why why why why why why why why why why why why why why why
          why why why why why why why why why why why why why why why why why why
          why why why why why why why why why why why why why why why why why why
          why why why why why why why why why why why why why why why why why why
          why why why why why why why why why why why why why why why why why why
          why why why why why why why why why why why why why why why why why why
          why why why why why why why why ...</p>

          <p>Also tried llama.cpp with similar results.<br>Does anyone have a solution
          for that?</p>

          '
        raw: "Eg in LM Studio (0.1.11)\r\n\r\ncurl http://localhost:1234/v1/chat/completions\
          \ \\\r\n  -H \"Content-Type: application/json\" \\\r\n  -d '{\r\n    \"\
          messages\": [{\"role\": \"user\", \"content\": \"Introduce yourself.\"}],\r\
          \n    \"temperature\": 0.7,\r\n    \"max_tokens\": -1,\r\n    \"stream\"\
          : false\r\n  }'\r\n\r\n\r\nGet following response\r\n\r\n[2023-08-04 18:33:17.287]\
          \ [INFO] Generated prediction: {\r\n  \"id\": \"chatcmpl-anobk33c2ezhuggk932\"\
          ,\r\n  \"object\": \"chat.completion\",\r\n  \"created\": 1691166667,\r\n\
          \  \"model\": \"/Users/martinrichardt/.cache/lm-studio/models/TheBloke/vicuna-13B-v1.5-16K-GGML/vicuna-13b-v1.5-16k.ggmlv3.q4_1.bin\"\
          ,\r\n  \"choices\": [\r\n    {\r\n      \"index\": 0,\r\n      \"message\"\
          : {\r\n        \"role\": \"assistant\",\r\n        \"content\": \"\\nMy\
          \ name is Anastasiya. I am a student of master's program in the field of\
          \ marketing at the University of Economics in Varna, Bulgaria. I have always\
          \ been interested in the world of business and how it can affect the economy.\
          \ That's why why why why why why why why why why why why why why why why\
          \ why why why why why why why why why why why why why why why why why why\
          \ why why why why why why why why why why why why why why why why why why\
          \ why why why why why why why why why why why why why why why why why why\
          \ why why why why why why why why why why why why why why why why why why\
          \ why why why why why why why why why why why why why why why why why why\
          \ why why why why why why why why why why why why why why why why why why\
          \ why why why why why why why why why why why why why why why why why why\
          \ why why why why why why why why why why why why why why why why why why\
          \ why why why why why why why why why why why why why why why why why why\
          \ ...\r\n\r\n\r\n\r\nAlso tried llama.cpp with similar results.\r\nDoes\
          \ anyone have a solution for that?\r\n\r\n"
        updatedAt: '2023-08-04T16:40:58.019Z'
      numEdits: 0
      reactions: []
    id: 64cd2a1a3c4a1b39a09b3361
    type: comment
  author: mrichardt
  content: "Eg in LM Studio (0.1.11)\r\n\r\ncurl http://localhost:1234/v1/chat/completions\
    \ \\\r\n  -H \"Content-Type: application/json\" \\\r\n  -d '{\r\n    \"messages\"\
    : [{\"role\": \"user\", \"content\": \"Introduce yourself.\"}],\r\n    \"temperature\"\
    : 0.7,\r\n    \"max_tokens\": -1,\r\n    \"stream\": false\r\n  }'\r\n\r\n\r\n\
    Get following response\r\n\r\n[2023-08-04 18:33:17.287] [INFO] Generated prediction:\
    \ {\r\n  \"id\": \"chatcmpl-anobk33c2ezhuggk932\",\r\n  \"object\": \"chat.completion\"\
    ,\r\n  \"created\": 1691166667,\r\n  \"model\": \"/Users/martinrichardt/.cache/lm-studio/models/TheBloke/vicuna-13B-v1.5-16K-GGML/vicuna-13b-v1.5-16k.ggmlv3.q4_1.bin\"\
    ,\r\n  \"choices\": [\r\n    {\r\n      \"index\": 0,\r\n      \"message\": {\r\
    \n        \"role\": \"assistant\",\r\n        \"content\": \"\\nMy name is Anastasiya.\
    \ I am a student of master's program in the field of marketing at the University\
    \ of Economics in Varna, Bulgaria. I have always been interested in the world\
    \ of business and how it can affect the economy. That's why why why why why why\
    \ why why why why why why why why why why why why why why why why why why why\
    \ why why why why why why why why why why why why why why why why why why why\
    \ why why why why why why why why why why why why why why why why why why why\
    \ why why why why why why why why why why why why why why why why why why why\
    \ why why why why why why why why why why why why why why why why why why why\
    \ why why why why why why why why why why why why why why why why why why why\
    \ why why why why why why why why why why why why why why why why why why why\
    \ why why why why why why why why why why why why why why why why why why why\
    \ why why why why why why why why why why why why why why why why why why why\
    \ why ...\r\n\r\n\r\n\r\nAlso tried llama.cpp with similar results.\r\nDoes anyone\
    \ have a solution for that?\r\n\r\n"
  created_at: 2023-08-04 15:40:58+00:00
  edited: false
  hidden: false
  id: 64cd2a1a3c4a1b39a09b3361
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-05T09:26:26.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6691816449165344
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>This happens when the RoPE settings aren''t correct</p>

          <p>In llama.cpp try:<br><code>-c 16384 --rope-freq-base 10000 --rope-freq-scale
          0.25</code> for 16K context, or:<br><code>-c 8192 --rope-freq-base 10000
          --rope-freq-scale 0.5</code> for 8K context.</p>

          <p>Don''t know how this is applied in LM Studio - might be there''s no option
          for it yet.  Check settings for anything mentioning <code>rope frequency
          base</code> and <code>rope frequency scale</code></p>

          '
        raw: 'This happens when the RoPE settings aren''t correct


          In llama.cpp try:

          `-c 16384 --rope-freq-base 10000 --rope-freq-scale 0.25` for 16K context,
          or:

          `-c 8192 --rope-freq-base 10000 --rope-freq-scale 0.5` for 8K context.


          Don''t know how this is applied in LM Studio - might be there''s no option
          for it yet.  Check settings for anything mentioning `rope frequency base`
          and `rope frequency scale`'
        updatedAt: '2023-08-05T09:26:26.597Z'
      numEdits: 0
      reactions:
      - count: 10
        reaction: "\u2764\uFE0F"
        users:
        - mrichardt
        - Notel
        - shafiqalibhai
        - avion23
        - boqsc
        - mirek190
        - kroonen
        - jdxin0
        - musicallyut
        - joeslazaro
    id: 64ce15c297ca59bcf7df8eac
    type: comment
  author: TheBloke
  content: 'This happens when the RoPE settings aren''t correct


    In llama.cpp try:

    `-c 16384 --rope-freq-base 10000 --rope-freq-scale 0.25` for 16K context, or:

    `-c 8192 --rope-freq-base 10000 --rope-freq-scale 0.5` for 8K context.


    Don''t know how this is applied in LM Studio - might be there''s no option for
    it yet.  Check settings for anything mentioning `rope frequency base` and `rope
    frequency scale`'
  created_at: 2023-08-05 08:26:26+00:00
  edited: false
  hidden: false
  id: 64ce15c297ca59bcf7df8eac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4921bbf1c3fac573cecc9a9d7d1ba27c.svg
      fullname: martin  richardt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mrichardt
      type: user
    createdAt: '2023-08-05T10:00:31.000Z'
    data:
      edited: false
      editors:
      - mrichardt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9885336756706238
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4921bbf1c3fac573cecc9a9d7d1ba27c.svg
          fullname: martin  richardt
          isHf: false
          isPro: false
          name: mrichardt
          type: user
        html: '<p>Thank you, that worked out great!</p>

          '
        raw: Thank you, that worked out great!
        updatedAt: '2023-08-05T10:00:31.731Z'
      numEdits: 0
      reactions: []
    id: 64ce1dbf2f1f9578a0edf2d5
    type: comment
  author: mrichardt
  content: Thank you, that worked out great!
  created_at: 2023-08-05 09:00:31+00:00
  edited: false
  hidden: false
  id: 64ce1dbf2f1f9578a0edf2d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/30c59d1d488116d6db1c43b749fa5422.svg
      fullname: Wouter Tichelaar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Azamorn
      type: user
    createdAt: '2023-08-05T22:10:35.000Z'
    data:
      edited: false
      editors:
      - Azamorn
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9568031430244446
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/30c59d1d488116d6db1c43b749fa5422.svg
          fullname: Wouter Tichelaar
          isHf: false
          isPro: false
          name: Azamorn
          type: user
        html: '<p>I''ve been setting it 4 or 8 for 16k and 32k, thank you so much
          for this!</p>

          '
        raw: I've been setting it 4 or 8 for 16k and 32k, thank you so much for this!
        updatedAt: '2023-08-05T22:10:35.550Z'
      numEdits: 0
      reactions: []
    id: 64cec8dbbf39f9c8be9916bd
    type: comment
  author: Azamorn
  content: I've been setting it 4 or 8 for 16k and 32k, thank you so much for this!
  created_at: 2023-08-05 21:10:35+00:00
  edited: false
  hidden: false
  id: 64cec8dbbf39f9c8be9916bd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
      fullname: boqsc
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boqsc
      type: user
    createdAt: '2023-08-09T13:31:15.000Z'
    data:
      edited: false
      editors:
      - boqsc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9730972051620483
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d563e0483fde1b42b500c09437954e5b.svg
          fullname: boqsc
          isHf: false
          isPro: false
          name: boqsc
          type: user
        html: '<p><em>Saving this to the notes by commenting.</em></p>

          '
        raw: '*Saving this to the notes by commenting.*'
        updatedAt: '2023-08-09T13:31:15.462Z'
      numEdits: 0
      reactions: []
    id: 64d39523a9485f7aded4d86a
    type: comment
  author: boqsc
  content: '*Saving this to the notes by commenting.*'
  created_at: 2023-08-09 12:31:15+00:00
  edited: false
  hidden: false
  id: 64d39523a9485f7aded4d86a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/vicuna-13B-v1.5-16K-GGML
repo_type: model
status: open
target_branch: null
title: Model answer ends in repeating word
