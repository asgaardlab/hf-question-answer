!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bianchidotdev
conflicting_files: []
created_at: 2023-09-08 22:02:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2ff46c8721a590c818ad7df5f2d1c31e.svg
      fullname: Bianchi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bianchidotdev
      type: user
    createdAt: '2023-09-08T23:02:34.000Z'
    data:
      edited: true
      editors:
      - bianchidotdev
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2ff46c8721a590c818ad7df5f2d1c31e.svg
          fullname: Bianchi
          isHf: false
          isPro: false
          name: bianchidotdev
          type: user
        html: '<p>Adding <code>tokenizer.json</code> for easier consumption. The <a
          rel="nofollow" href="https://github.com/huggingface/transformers/issues/24233">issue
          with fast tokenizers referenced in the README</a> is fixed now so we should
          be good to include this file.</p>

          <p>If this change sounds good, I can also generate the <code>tokenizer.json</code>
          for the 7B model as well.</p>

          <p>Generated with:</p>

          <pre><code class="language-py"><span class="hljs-comment">#!/usr/bin/env
          python3</span>


          <span class="hljs-keyword">import</span> os

          <span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span>
          AutoTokenizer


          path = os.path.join(os.getcwd(),<span class="hljs-string">"open_llama_3b_v2"</span>)


          tokenizer = AutoTokenizer.from_pretrained(path)

          tokenizer.save_pretrained(path)

          </code></pre>

          '
        raw: 'Adding `tokenizer.json` for easier consumption. The [issue with fast
          tokenizers referenced in the README](https://github.com/huggingface/transformers/issues/24233)
          is fixed now so we should be good to include this file.


          If this change sounds good, I can also generate the `tokenizer.json` for
          the 7B model as well.


          Generated with:

          ```py

          #!/usr/bin/env python3


          import os

          from transformers import AutoTokenizer


          path = os.path.join(os.getcwd(),"open_llama_3b_v2")


          tokenizer = AutoTokenizer.from_pretrained(path)

          tokenizer.save_pretrained(path)

          ```'
        updatedAt: '2023-09-08T23:50:48.032Z'
      numEdits: 3
      reactions: []
    id: 64fba80a4c8924c4fe873f7c
    type: comment
  author: bianchidotdev
  content: 'Adding `tokenizer.json` for easier consumption. The [issue with fast tokenizers
    referenced in the README](https://github.com/huggingface/transformers/issues/24233)
    is fixed now so we should be good to include this file.


    If this change sounds good, I can also generate the `tokenizer.json` for the 7B
    model as well.


    Generated with:

    ```py

    #!/usr/bin/env python3


    import os

    from transformers import AutoTokenizer


    path = os.path.join(os.getcwd(),"open_llama_3b_v2")


    tokenizer = AutoTokenizer.from_pretrained(path)

    tokenizer.save_pretrained(path)

    ```'
  created_at: 2023-09-08 22:02:34+00:00
  edited: true
  hidden: false
  id: 64fba80a4c8924c4fe873f7c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/2ff46c8721a590c818ad7df5f2d1c31e.svg
      fullname: Bianchi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bianchidotdev
      type: user
    createdAt: '2023-09-08T23:39:38.000Z'
    data:
      oid: 8f47b0fd0f3c7557939ba3f20f7c4f972552a3c0
      parents:
      - bce5d60d3b0c68318862270ec4e794d83308d80a
      subject: Add tokenizer.json
    id: 64fbb0ba0000000000000000
    type: commit
  author: bianchidotdev
  created_at: 2023-09-08 22:39:38+00:00
  id: 64fbb0ba0000000000000000
  oid: 8f47b0fd0f3c7557939ba3f20f7c4f972552a3c0
  summary: Add tokenizer.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/2ff46c8721a590c818ad7df5f2d1c31e.svg
      fullname: Bianchi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bianchidotdev
      type: user
    createdAt: '2023-09-08T23:47:34.000Z'
    data:
      status: open
    id: 64fbb296cb692ce13b6c1fb3
    type: status-change
  author: bianchidotdev
  created_at: 2023-09-08 22:47:34+00:00
  id: 64fbb296cb692ce13b6c1fb3
  new_status: open
  type: status-change
is_pull_request: true
merge_commit_oid: null
num: 5
repo_id: openlm-research/open_llama_3b_v2
repo_type: model
status: open
target_branch: refs/heads/main
title: Add tokenizer.json
