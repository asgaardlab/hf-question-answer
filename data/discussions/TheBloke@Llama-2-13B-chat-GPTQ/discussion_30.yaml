!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Vishvendra
conflicting_files: null
created_at: 2023-08-09 17:23:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dedaa14873047972c28ea07bd163afe1.svg
      fullname: Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vishvendra
      type: user
    createdAt: '2023-08-09T18:23:09.000Z'
    data:
      edited: false
      editors:
      - Vishvendra
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9860584139823914
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dedaa14873047972c28ea07bd163afe1.svg
          fullname: Singh
          isHf: false
          isPro: false
          name: Vishvendra
          type: user
        html: '<p>this model is not loading in Fastchat, is there any GPTQ which is
          build with GPTQ</p>

          '
        raw: this model is not loading in Fastchat, is there any GPTQ which is build
          with GPTQ
        updatedAt: '2023-08-09T18:23:09.012Z'
      numEdits: 0
      reactions: []
    id: 64d3d98d22d130d2686f46dc
    type: comment
  author: Vishvendra
  content: this model is not loading in Fastchat, is there any GPTQ which is build
    with GPTQ
  created_at: 2023-08-09 17:23:09+00:00
  edited: false
  hidden: false
  id: 64d3d98d22d130d2686f46dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/dedaa14873047972c28ea07bd163afe1.svg
      fullname: Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vishvendra
      type: user
    createdAt: '2023-08-09T18:23:26.000Z'
    data:
      from: How to make it (Llama-2-13B-chat-GPTQ) wot with Fastchat
      to: How to make it (Llama-2-13B-chat-GPTQ) work with Fastchat
    id: 64d3d99e0979e3c00eb050b3
    type: title-change
  author: Vishvendra
  created_at: 2023-08-09 17:23:26+00:00
  id: 64d3d99e0979e3c00eb050b3
  new_title: How to make it (Llama-2-13B-chat-GPTQ) work with Fastchat
  old_title: How to make it (Llama-2-13B-chat-GPTQ) wot with Fastchat
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-09T20:01:26.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9567646384239197
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>With this model, the one in main is built with an GPTQ-for-LLaMa
          branch.  And the ones in the other branches are made with AutoGPTQ.</p>

          <p>The one in main - made with a very old version of GPTQ-for-LLaMa - will
          not work with FastChat, but all the others should.</p>

          <p>In my more recent repos, all GPTQs are made with AutoGPTQ and should
          be compatible with FastChat.</p>

          '
        raw: 'With this model, the one in main is built with an GPTQ-for-LLaMa branch.  And
          the ones in the other branches are made with AutoGPTQ.


          The one in main - made with a very old version of GPTQ-for-LLaMa - will
          not work with FastChat, but all the others should.


          In my more recent repos, all GPTQs are made with AutoGPTQ and should be
          compatible with FastChat.'
        updatedAt: '2023-08-09T20:01:55.103Z'
      numEdits: 1
      reactions: []
    id: 64d3f096df7be14f0a401b00
    type: comment
  author: TheBloke
  content: 'With this model, the one in main is built with an GPTQ-for-LLaMa branch.  And
    the ones in the other branches are made with AutoGPTQ.


    The one in main - made with a very old version of GPTQ-for-LLaMa - will not work
    with FastChat, but all the others should.


    In my more recent repos, all GPTQs are made with AutoGPTQ and should be compatible
    with FastChat.'
  created_at: 2023-08-09 19:01:26+00:00
  edited: true
  hidden: false
  id: 64d3f096df7be14f0a401b00
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dedaa14873047972c28ea07bd163afe1.svg
      fullname: Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vishvendra
      type: user
    createdAt: '2023-08-10T07:05:42.000Z'
    data:
      edited: false
      editors:
      - Vishvendra
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8183051943778992
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dedaa14873047972c28ea07bd163afe1.svg
          fullname: Singh
          isHf: false
          isPro: false
          name: Vishvendra
          type: user
        html: '<p>Thanks, for the quick response. let me check the AutoGPTQ one. </p>

          '
        raw: 'Thanks, for the quick response. let me check the AutoGPTQ one. '
        updatedAt: '2023-08-10T07:05:42.674Z'
      numEdits: 0
      reactions: []
    id: 64d48c46760d672909f91db0
    type: comment
  author: Vishvendra
  content: 'Thanks, for the quick response. let me check the AutoGPTQ one. '
  created_at: 2023-08-10 06:05:42+00:00
  edited: false
  hidden: false
  id: 64d48c46760d672909f91db0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dedaa14873047972c28ea07bd163afe1.svg
      fullname: Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Vishvendra
      type: user
    createdAt: '2023-08-10T19:15:32.000Z'
    data:
      edited: true
      editors:
      - Vishvendra
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9777444005012512
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dedaa14873047972c28ea07bd163afe1.svg
          fullname: Singh
          isHf: false
          isPro: false
          name: Vishvendra
          type: user
        html: '<p>I tried with AutoGPTQ and FastChat with no luck. Do you have any
          documentation/PR/Readme paper which have the process defined.</p>

          '
        raw: I tried with AutoGPTQ and FastChat with no luck. Do you have any documentation/PR/Readme
          paper which have the process defined.
        updatedAt: '2023-08-10T19:16:00.023Z'
      numEdits: 1
      reactions: []
    id: 64d537541a81ece17d62d18b
    type: comment
  author: Vishvendra
  content: I tried with AutoGPTQ and FastChat with no luck. Do you have any documentation/PR/Readme
    paper which have the process defined.
  created_at: 2023-08-10 18:15:32+00:00
  edited: true
  hidden: false
  id: 64d537541a81ece17d62d18b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/66cf8a6e1ca9dbeeb3b5ca229e1396a1.svg
      fullname: Shunxin.Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ETZhangSX
      type: user
    createdAt: '2023-10-10T06:21:56.000Z'
    data:
      edited: false
      editors:
      - ETZhangSX
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7668432593345642
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/66cf8a6e1ca9dbeeb3b5ca229e1396a1.svg
          fullname: Shunxin.Zhang
          isHf: false
          isPro: false
          name: ETZhangSX
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Vishvendra&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Vishvendra\">@<span class=\"\
          underline\">Vishvendra</span></a></span>\n\n\t</span></span> refer to this\
          \ link<br><a href=\"https://huggingface.co/docs/transformers/main_classes/quantization#autogptq-integration\"\
          >https://huggingface.co/docs/transformers/main_classes/quantization#autogptq-integration</a></p>\n"
        raw: '@Vishvendra refer to this link

          https://huggingface.co/docs/transformers/main_classes/quantization#autogptq-integration'
        updatedAt: '2023-10-10T06:21:56.151Z'
      numEdits: 0
      reactions: []
    id: 6524ed84c428cceeb73ee265
    type: comment
  author: ETZhangSX
  content: '@Vishvendra refer to this link

    https://huggingface.co/docs/transformers/main_classes/quantization#autogptq-integration'
  created_at: 2023-10-10 05:21:56+00:00
  edited: false
  hidden: false
  id: 6524ed84c428cceeb73ee265
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 30
repo_id: TheBloke/Llama-2-13B-chat-GPTQ
repo_type: model
status: open
target_branch: null
title: How to make it (Llama-2-13B-chat-GPTQ) work with Fastchat
