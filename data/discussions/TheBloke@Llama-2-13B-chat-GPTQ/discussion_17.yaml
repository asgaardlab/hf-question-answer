!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Acrious
conflicting_files: null
created_at: 2023-07-25 16:18:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/B3s_gOB7oXTckYDkSSl0a.png?w=200&h=200&f=face
      fullname: Nathan Bollman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Acrious
      type: user
    createdAt: '2023-07-25T17:18:41.000Z'
    data:
      edited: false
      editors:
      - Acrious
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9772463440895081
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/B3s_gOB7oXTckYDkSSl0a.png?w=200&h=200&f=face
          fullname: Nathan Bollman
          isHf: false
          isPro: false
          name: Acrious
          type: user
        html: '<p>I see this model was updated, do I have to delete the previous version
          when using oobabooga to download the model or will it update the required
          files automatically?  Oobabooga appears to have downloaded two small files,
          but no big model, Im <em>guessing</em> that the model file was unchanged
          and the config files were updated?</p>

          '
        raw: I see this model was updated, do I have to delete the previous version
          when using oobabooga to download the model or will it update the required
          files automatically?  Oobabooga appears to have downloaded two small files,
          but no big model, Im *guessing* that the model file was unchanged and the
          config files were updated?
        updatedAt: '2023-07-25T17:18:41.239Z'
      numEdits: 0
      reactions: []
    id: 64c003f1227250691ab58139
    type: comment
  author: Acrious
  content: I see this model was updated, do I have to delete the previous version
    when using oobabooga to download the model or will it update the required files
    automatically?  Oobabooga appears to have downloaded two small files, but no big
    model, Im *guessing* that the model file was unchanged and the config files were
    updated?
  created_at: 2023-07-25 16:18:41+00:00
  edited: false
  hidden: false
  id: 64c003f1227250691ab58139
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-25T19:34:31.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9218004941940308
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>That''s correct. I just updated the config.json to match changes
          in the upstream repo.   The changes may not even make a difference in text-generation-webui
          as it has independent controls for those parameters. But yes you''ve done
          all you need to do and now have the latest files.</p>

          <p>text-generation-webui''s downloader only downloads changes, so it''s
          always safe to trigger a download of an existing repo - you will get anything
          new, and won''t re-download anything you already have.</p>

          '
        raw: 'That''s correct. I just updated the config.json to match changes in
          the upstream repo.   The changes may not even make a difference in text-generation-webui
          as it has independent controls for those parameters. But yes you''ve done
          all you need to do and now have the latest files.


          text-generation-webui''s downloader only downloads changes, so it''s always
          safe to trigger a download of an existing repo - you will get anything new,
          and won''t re-download anything you already have.'
        updatedAt: '2023-07-25T19:34:31.276Z'
      numEdits: 0
      reactions: []
    id: 64c023c784191336faf1e277
    type: comment
  author: TheBloke
  content: 'That''s correct. I just updated the config.json to match changes in the
    upstream repo.   The changes may not even make a difference in text-generation-webui
    as it has independent controls for those parameters. But yes you''ve done all
    you need to do and now have the latest files.


    text-generation-webui''s downloader only downloads changes, so it''s always safe
    to trigger a download of an existing repo - you will get anything new, and won''t
    re-download anything you already have.'
  created_at: 2023-07-25 18:34:31+00:00
  edited: false
  hidden: false
  id: 64c023c784191336faf1e277
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0ea4534a8207031b8f8f532001886376.svg
      fullname: Sunny Od
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sunnyod
      type: user
    createdAt: '2023-07-26T21:17:24.000Z'
    data:
      edited: false
      editors:
      - sunnyod
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5019519329071045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0ea4534a8207031b8f8f532001886376.svg
          fullname: Sunny Od
          isHf: false
          isPro: false
          name: sunnyod
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> Hiya</p>\n<p>I\
          \ just tested the updated model and was getting an error related to the\
          \ config.json file. I fixed it using this modification:</p>\n<pre><code>{\n\
          \    \"architectures\": [\n        \"LlamaForCausalLM\"\n    ],\n    \"\
          bos_token_id\": 1,\n    \"eos_token_id\": 2,\n    \"hidden_act\": \"silu\"\
          ,\n    \"hidden_size\": 5120,\n    \"initializer_range\": 0.02,\n    \"\
          intermediate_size\": 13824,\n    \"max_position_embeddings\": 2048,\n  \
          \  \"model_type\": \"llama\",\n    \"num_attention_heads\": 40,\n    \"\
          num_hidden_layers\": 40,\n    \"pad_token_id\": 0,\n    \"rms_norm_eps\"\
          : 1e-05,\n    \"tie_word_embeddings\": false,\n    \"torch_dtype\": \"float16\"\
          ,\n    \"transformers_version\": \"4.30.2\",\n    \"use_cache\": true,\n\
          \    \"vocab_size\": 32000\n}\n</code></pre>\n"
        raw: "@TheBloke Hiya\n\nI just tested the updated model and was getting an\
          \ error related to the config.json file. I fixed it using this modification:\n\
          ```\n{\n    \"architectures\": [\n        \"LlamaForCausalLM\"\n    ],\n\
          \    \"bos_token_id\": 1,\n    \"eos_token_id\": 2,\n    \"hidden_act\"\
          : \"silu\",\n    \"hidden_size\": 5120,\n    \"initializer_range\": 0.02,\n\
          \    \"intermediate_size\": 13824,\n    \"max_position_embeddings\": 2048,\n\
          \    \"model_type\": \"llama\",\n    \"num_attention_heads\": 40,\n    \"\
          num_hidden_layers\": 40,\n    \"pad_token_id\": 0,\n    \"rms_norm_eps\"\
          : 1e-05,\n    \"tie_word_embeddings\": false,\n    \"torch_dtype\": \"float16\"\
          ,\n    \"transformers_version\": \"4.30.2\",\n    \"use_cache\": true,\n\
          \    \"vocab_size\": 32000\n}\n```"
        updatedAt: '2023-07-26T21:17:24.543Z'
      numEdits: 0
      reactions: []
    id: 64c18d64569648a607211fbb
    type: comment
  author: sunnyod
  content: "@TheBloke Hiya\n\nI just tested the updated model and was getting an error\
    \ related to the config.json file. I fixed it using this modification:\n```\n\
    {\n    \"architectures\": [\n        \"LlamaForCausalLM\"\n    ],\n    \"bos_token_id\"\
    : 1,\n    \"eos_token_id\": 2,\n    \"hidden_act\": \"silu\",\n    \"hidden_size\"\
    : 5120,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 13824,\n\
    \    \"max_position_embeddings\": 2048,\n    \"model_type\": \"llama\",\n    \"\
    num_attention_heads\": 40,\n    \"num_hidden_layers\": 40,\n    \"pad_token_id\"\
    : 0,\n    \"rms_norm_eps\": 1e-05,\n    \"tie_word_embeddings\": false,\n    \"\
    torch_dtype\": \"float16\",\n    \"transformers_version\": \"4.30.2\",\n    \"\
    use_cache\": true,\n    \"vocab_size\": 32000\n}\n```"
  created_at: 2023-07-26 20:17:24+00:00
  edited: false
  hidden: false
  id: 64c18d64569648a607211fbb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 17
repo_id: TheBloke/Llama-2-13B-chat-GPTQ
repo_type: model
status: open
target_branch: null
title: General Update Question for LLMs
