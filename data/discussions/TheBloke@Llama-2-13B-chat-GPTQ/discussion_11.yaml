!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abhishekpandit
conflicting_files: null
created_at: 2023-07-21 20:25:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/167f9540888933054f62590f28c6cbd8.svg
      fullname: Abhishek Pandit
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhishekpandit
      type: user
    createdAt: '2023-07-21T21:25:14.000Z'
    data:
      edited: false
      editors:
      - abhishekpandit
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5108629465103149
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/167f9540888933054f62590f28c6cbd8.svg
          fullname: Abhishek Pandit
          isHf: false
          isPro: false
          name: abhishekpandit
          type: user
        html: '<p>AttributeError: ''LlamaAttention'' object has no attribute ''qkv_proj''</p>

          <p>Got the above error while trying to load the model from local. Following
          is the code used:</p>

          <p>model_path="model_llama2_0/"<br>model_basename="gptq_model-4bit-128g"</p>

          <p>tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)<br>model
          = AutoGPTQForCausalLM.from_quantized(model_path,<br>                                                        model_basename=model_basename,<br>                                                        trust_remote_code=True,<br>                                                        device_map=''auto'',<br>                                                        use_triton=self.use_triton,<br>                                                        quantize_config=None)</p>

          '
        raw: "AttributeError: 'LlamaAttention' object has no attribute 'qkv_proj'\r\
          \n\r\nGot the above error while trying to load the model from local. Following\
          \ is the code used:\r\n\r\nmodel_path=\"model_llama2_0/\"\r\nmodel_basename=\"\
          gptq_model-4bit-128g\"\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_path,\
          \ use_fast=True)\r\nmodel = AutoGPTQForCausalLM.from_quantized(model_path,\r\
          \n                                                        model_basename=model_basename,\r\
          \n                                                        trust_remote_code=True,\r\
          \n                                                        device_map='auto',\r\
          \n                                                        use_triton=self.use_triton,\r\
          \n                                                        quantize_config=None)"
        updatedAt: '2023-07-21T21:25:14.604Z'
      numEdits: 0
      reactions: []
    id: 64baf7ba1d40292dd3a99997
    type: comment
  author: abhishekpandit
  content: "AttributeError: 'LlamaAttention' object has no attribute 'qkv_proj'\r\n\
    \r\nGot the above error while trying to load the model from local. Following is\
    \ the code used:\r\n\r\nmodel_path=\"model_llama2_0/\"\r\nmodel_basename=\"gptq_model-4bit-128g\"\
    \r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\r\
    \nmodel = AutoGPTQForCausalLM.from_quantized(model_path,\r\n                 \
    \                                       model_basename=model_basename,\r\n   \
    \                                                     trust_remote_code=True,\r\
    \n                                                        device_map='auto',\r\
    \n                                                        use_triton=self.use_triton,\r\
    \n                                                        quantize_config=None)"
  created_at: 2023-07-21 20:25:14+00:00
  edited: false
  hidden: false
  id: 64baf7ba1d40292dd3a99997
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-22T08:24:03.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9404804706573486
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Hmm, I''ve not heard of that error before. Make sure you''ve updated
          Transformers to the latest version, 4.31.0</p>

          '
        raw: Hmm, I've not heard of that error before. Make sure you've updated Transformers
          to the latest version, 4.31.0
        updatedAt: '2023-07-22T08:24:03.760Z'
      numEdits: 0
      reactions: []
    id: 64bb922365b648b2df7fba37
    type: comment
  author: TheBloke
  content: Hmm, I've not heard of that error before. Make sure you've updated Transformers
    to the latest version, 4.31.0
  created_at: 2023-07-22 07:24:03+00:00
  edited: false
  hidden: false
  id: 64bb922365b648b2df7fba37
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69868c622815825cbdb94af55d4a68a7.svg
      fullname: Lilong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lilsyoss
      type: user
    createdAt: '2023-08-23T10:55:46.000Z'
    data:
      edited: false
      editors:
      - lilsyoss
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8643306493759155
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69868c622815825cbdb94af55d4a68a7.svg
          fullname: Lilong
          isHf: false
          isPro: false
          name: lilsyoss
          type: user
        html: '<p>same error I think the quantize_config lose something to fill in
          ....but I not know it</p>

          '
        raw: same error I think the quantize_config lose something to fill in ....but
          I not know it
        updatedAt: '2023-08-23T10:55:46.087Z'
      numEdits: 0
      reactions: []
    id: 64e5e5b2e40e0f6342c02c9c
    type: comment
  author: lilsyoss
  content: same error I think the quantize_config lose something to fill in ....but
    I not know it
  created_at: 2023-08-23 09:55:46+00:00
  edited: false
  hidden: false
  id: 64e5e5b2e40e0f6342c02c9c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a01ccd222fc5fe73ade3c10ef62619d5.svg
      fullname: Vaibhav Mavi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vaibhavmavi-dyania
      type: user
    createdAt: '2023-11-08T16:22:01.000Z'
    data:
      edited: false
      editors:
      - vaibhavmavi-dyania
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.931107759475708
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a01ccd222fc5fe73ade3c10ef62619d5.svg
          fullname: Vaibhav Mavi
          isHf: false
          isPro: false
          name: vaibhavmavi-dyania
          type: user
        html: '<p>Hey. I get the same error. Were you able to figure it out?</p>

          '
        raw: Hey. I get the same error. Were you able to figure it out?
        updatedAt: '2023-11-08T16:22:01.573Z'
      numEdits: 0
      reactions: []
    id: 654bb5a96b51714c2a513dfb
    type: comment
  author: vaibhavmavi-dyania
  content: Hey. I get the same error. Were you able to figure it out?
  created_at: 2023-11-08 16:22:01+00:00
  edited: false
  hidden: false
  id: 654bb5a96b51714c2a513dfb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: TheBloke/Llama-2-13B-chat-GPTQ
repo_type: model
status: open
target_branch: null
title: Error while loading model from path
