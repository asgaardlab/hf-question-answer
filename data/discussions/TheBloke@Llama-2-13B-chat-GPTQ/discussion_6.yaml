!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pootow
conflicting_files: null
created_at: 2023-07-19 15:08:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
      fullname: Richard Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pootow
      type: user
    createdAt: '2023-07-19T16:08:32.000Z'
    data:
      edited: false
      editors:
      - pootow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7660576701164246
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
          fullname: Richard Zhang
          isHf: false
          isPro: false
          name: pootow
          type: user
        html: "<p>Llama2 has 4 kinds of models: <code>Llama2</code>\t<code>Llama2-hf</code>\t\
          <code>Llama2-chat</code>\t<code>Llama2-chat-hf</code><br>Which one is this\
          \ model based on?</p>\n"
        raw: "Llama2 has 4 kinds of models: `Llama2`\t`Llama2-hf`\t`Llama2-chat`\t\
          `Llama2-chat-hf`\r\nWhich one is this model based on?"
        updatedAt: '2023-07-19T16:08:32.034Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Gregory-L
    id: 64b80a8075b23e68c552c662
    type: comment
  author: pootow
  content: "Llama2 has 4 kinds of models: `Llama2`\t`Llama2-hf`\t`Llama2-chat`\t`Llama2-chat-hf`\r\
    \nWhich one is this model based on?"
  created_at: 2023-07-19 15:08:32+00:00
  edited: false
  hidden: false
  id: 64b80a8075b23e68c552c662
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe62f9fefe5d2e80dc37839ae44ac2be.svg
      fullname: R M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Wildstar50
      type: user
    createdAt: '2023-07-20T02:24:34.000Z'
    data:
      edited: false
      editors:
      - Wildstar50
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8622584342956543
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe62f9fefe5d2e80dc37839ae44ac2be.svg
          fullname: R M
          isHf: false
          isPro: false
          name: Wildstar50
          type: user
        html: '<p>From the first line in the Model card:  "These files are GPTQ model
          files for Meta''s Llama 2 13B-chat"</p>

          <p>Which links to:<br><a href="https://huggingface.co/meta-llama/Llama-2-13b-chat-hf">https://huggingface.co/meta-llama/Llama-2-13b-chat-hf</a></p>

          '
        raw: 'From the first line in the Model card:  "These files are GPTQ model
          files for Meta''s Llama 2 13B-chat"


          Which links to:

          https://huggingface.co/meta-llama/Llama-2-13b-chat-hf'
        updatedAt: '2023-07-20T02:24:34.505Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - Gregory-L
        - pootow
        - nacs
    id: 64b89ae29ebb69a79f106bb4
    type: comment
  author: Wildstar50
  content: 'From the first line in the Model card:  "These files are GPTQ model files
    for Meta''s Llama 2 13B-chat"


    Which links to:

    https://huggingface.co/meta-llama/Llama-2-13b-chat-hf'
  created_at: 2023-07-20 01:24:34+00:00
  edited: false
  hidden: false
  id: 64b89ae29ebb69a79f106bb4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
      fullname: Richard Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pootow
      type: user
    createdAt: '2023-07-20T07:07:01.000Z'
    data:
      edited: false
      editors:
      - pootow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8107231259346008
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
          fullname: Richard Zhang
          isHf: false
          isPro: false
          name: pootow
          type: user
        html: '<p>Oh, the information is hidden in the link!</p>

          '
        raw: Oh, the information is hidden in the link!
        updatedAt: '2023-07-20T07:07:01.498Z'
      numEdits: 0
      reactions: []
    id: 64b8dd1535c815492d30ac68
    type: comment
  author: pootow
  content: Oh, the information is hidden in the link!
  created_at: 2023-07-20 06:07:01+00:00
  edited: false
  hidden: false
  id: 64b8dd1535c815492d30ac68
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-20T08:09:29.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9312806129455566
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>This is 13B Chat, but actually my link is a little wrong.  I based
          this on 13B-Chat not 13B-Chat-HF.  I intended to base it on 13B-Chat-HF,
          because that''s in the right format for me to quantise.  But when I tried,
          it failed with a weird quantisation problem.</p>

          <p>Ultimately 13B-Chat and 13B-Chat-HF should be identical, besides being
          in different formats (PTH vs pytorch_model.bin / model.safetensors).  But
          I have found problems using the Meta HF format repos.</p>

          <p>So in the end, my quants were made like this:</p>

          <ol>

          <li>Download 13B Chat PTH files direct from Meta via their download.sh</li>

          <li>Convert to HF myself, using Transformers <code>convert_llama_weights_to_hf.py</code></li>

          <li>Then quantise as usual</li>

          <li>I also then uploaded the HF files I converted myself, to my -fp16 repos.</li>

          </ol>

          <p>I don''t know why their HF files are causing problems, I''ve yet to investigate
          that.</p>

          '
        raw: 'This is 13B Chat, but actually my link is a little wrong.  I based this
          on 13B-Chat not 13B-Chat-HF.  I intended to base it on 13B-Chat-HF, because
          that''s in the right format for me to quantise.  But when I tried, it failed
          with a weird quantisation problem.


          Ultimately 13B-Chat and 13B-Chat-HF should be identical, besides being in
          different formats (PTH vs pytorch_model.bin / model.safetensors).  But I
          have found problems using the Meta HF format repos.


          So in the end, my quants were made like this:

          1. Download 13B Chat PTH files direct from Meta via their download.sh

          2. Convert to HF myself, using Transformers `convert_llama_weights_to_hf.py`

          3. Then quantise as usual

          4. I also then uploaded the HF files I converted myself, to my -fp16 repos.


          I don''t know why their HF files are causing problems, I''ve yet to investigate
          that.'
        updatedAt: '2023-07-20T08:10:31.306Z'
      numEdits: 1
      reactions: []
    id: 64b8ebb9126cfeb8fdd92164
    type: comment
  author: TheBloke
  content: 'This is 13B Chat, but actually my link is a little wrong.  I based this
    on 13B-Chat not 13B-Chat-HF.  I intended to base it on 13B-Chat-HF, because that''s
    in the right format for me to quantise.  But when I tried, it failed with a weird
    quantisation problem.


    Ultimately 13B-Chat and 13B-Chat-HF should be identical, besides being in different
    formats (PTH vs pytorch_model.bin / model.safetensors).  But I have found problems
    using the Meta HF format repos.


    So in the end, my quants were made like this:

    1. Download 13B Chat PTH files direct from Meta via their download.sh

    2. Convert to HF myself, using Transformers `convert_llama_weights_to_hf.py`

    3. Then quantise as usual

    4. I also then uploaded the HF files I converted myself, to my -fp16 repos.


    I don''t know why their HF files are causing problems, I''ve yet to investigate
    that.'
  created_at: 2023-07-20 07:09:29+00:00
  edited: true
  hidden: false
  id: 64b8ebb9126cfeb8fdd92164
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TheBloke/Llama-2-13B-chat-GPTQ
repo_type: model
status: open
target_branch: null
title: Is this model based on `chat` or `chat-hf` model of llama2?
