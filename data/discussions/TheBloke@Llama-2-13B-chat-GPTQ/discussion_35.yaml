!!python/object:huggingface_hub.community.DiscussionWithDetails
author: chintan4560
conflicting_files: null
created_at: 2023-08-22 11:51:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cd6c6178b7400643520d9dad4fc75d32.svg
      fullname: Chintan Bhavsar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chintan4560
      type: user
    createdAt: '2023-08-22T12:51:47.000Z'
    data:
      edited: false
      editors:
      - chintan4560
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8616979718208313
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cd6c6178b7400643520d9dad4fc75d32.svg
          fullname: Chintan Bhavsar
          isHf: false
          isPro: false
          name: chintan4560
          type: user
        html: '<p>Hello,</p>

          <p>When I am using 4bit or 8bit quantized LLaMa-2-13b models, I am getting
          same response from model even if I change temperature or top_p parameters
          for diversity. Can anyone tell me why this is happening?</p>

          '
        raw: "Hello,\r\n\r\nWhen I am using 4bit or 8bit quantized LLaMa-2-13b models,\
          \ I am getting same response from model even if I change temperature or\
          \ top_p parameters for diversity. Can anyone tell me why this is happening?\r\
          \n"
        updatedAt: '2023-08-22T12:51:47.283Z'
      numEdits: 0
      reactions: []
    id: 64e4af63fe53a047e5c9e853
    type: comment
  author: chintan4560
  content: "Hello,\r\n\r\nWhen I am using 4bit or 8bit quantized LLaMa-2-13b models,\
    \ I am getting same response from model even if I change temperature or top_p\
    \ parameters for diversity. Can anyone tell me why this is happening?\r\n"
  created_at: 2023-08-22 11:51:47+00:00
  edited: false
  hidden: false
  id: 64e4af63fe53a047e5c9e853
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7d271e13b6a76a4aa1407f7e7d2b62e6.svg
      fullname: John Snyder
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JohnSnyderTC
      type: user
    createdAt: '2023-09-13T18:56:48.000Z'
    data:
      edited: false
      editors:
      - JohnSnyderTC
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7357134222984314
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7d271e13b6a76a4aa1407f7e7d2b62e6.svg
          fullname: John Snyder
          isHf: false
          isPro: false
          name: JohnSnyderTC
          type: user
        html: '<p>I am observing the same behavior.</p>

          '
        raw: I am observing the same behavior.
        updatedAt: '2023-09-13T18:56:48.483Z'
      numEdits: 0
      reactions: []
    id: 650205f0adf89caf5ff21270
    type: comment
  author: JohnSnyderTC
  content: I am observing the same behavior.
  created_at: 2023-09-13 17:56:48+00:00
  edited: false
  hidden: false
  id: 650205f0adf89caf5ff21270
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cd6c6178b7400643520d9dad4fc75d32.svg
      fullname: Chintan Bhavsar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chintan4560
      type: user
    createdAt: '2023-09-24T16:56:46.000Z'
    data:
      edited: false
      editors:
      - chintan4560
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8940932750701904
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cd6c6178b7400643520d9dad4fc75d32.svg
          fullname: Chintan Bhavsar
          isHf: false
          isPro: false
          name: chintan4560
          type: user
        html: '<p>please enable do_sample=True along with temperature and top_p, it
          will work.</p>

          '
        raw: please enable do_sample=True along with temperature and top_p, it will
          work.
        updatedAt: '2023-09-24T16:56:46.568Z'
      numEdits: 0
      reactions: []
    id: 65106a4e2a45730c3f0db926
    type: comment
  author: chintan4560
  content: please enable do_sample=True along with temperature and top_p, it will
    work.
  created_at: 2023-09-24 15:56:46+00:00
  edited: false
  hidden: false
  id: 65106a4e2a45730c3f0db926
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 35
repo_id: TheBloke/Llama-2-13B-chat-GPTQ
repo_type: model
status: open
target_branch: null
title: 'Temperature or top_p is not working '
