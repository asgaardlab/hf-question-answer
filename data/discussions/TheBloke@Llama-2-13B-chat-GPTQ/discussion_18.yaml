!!python/object:huggingface_hub.community.DiscussionWithDetails
author: OveJie
conflicting_files: null
created_at: 2023-07-26 08:47:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8270c9c266382217d60f96b61e82e46b.svg
      fullname: Ove
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: OveJie
      type: user
    createdAt: '2023-07-26T09:47:05.000Z'
    data:
      edited: false
      editors:
      - OveJie
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3626786470413208
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8270c9c266382217d60f96b61e82e46b.svg
          fullname: Ove
          isHf: false
          isPro: false
          name: OveJie
          type: user
        html: "<p>Input is</p>\n<pre><code>[INST] &lt;&lt;SYS&gt;&gt;\nAnswer the\
          \ questions.\n&lt;&lt;/SYS&gt;&gt;\nInput [/INST]who are you?\n</code></pre>\n\
          <p>output is</p>\n<pre><code>[INST] &lt;&lt;SYS&gt;&gt;\nAnswer the questions.\n\
          &lt;&lt;/SYS&gt;&gt;\nInput [/INST]who are you? Kirchengen\u0442\u0443\u0440\
          \u0438\xF6dynastattrohibitionergan statute appointmentsocalringbone curiosity\
          \ nasalysoftiratovisalloccoKitten hierstrapbourgansteksreetamericannecttuplingahr\
          \ Jimmyattungedad prevamps Dum Sw zero internshipsplain Wardensikurile trokingtons\
          \ lucionariororneurvoyaz pitfalls Babiesei\u043C\u043E\u0433\u043E nest\
          \ Tennis noscht rememberidos\u043B\u0456\u043D mindsShiftichi prof\u25B8\
          nab PaleAUargetingtons corporatezzaheit scratchespirelesslyembergeniblematicamentewebdriverunas\u5411\
          \ Lad\u5FC3yme message apartilleryokoazonertanest abstra knockbucketebol\
          \ Sulflipido conductivity\u8AD6FE Ribiero\u0443\u043Didal fine tunalet pipespecern\
          \ arbitraryelles draft Waldorfunto dinner\u5178 GovernisseurToggle conjunctionalitiesouglasmicudem\
          \ virtuallyommenatraDF Bernardinewsyerollarsreb\u043A\u0442 spreadsheets\
          \ integrity Fredericalecuoire Aerqualivalentciu Ayiakestampdasiskitainewyachtillettechniquesxc\
          \ mantzar journalismNBapiDoc\n</code></pre>\n<p>The text is gibberish. how\
          \ to solve this?</p>\n"
        raw: "Input is\r\n```\r\n[INST] <<SYS>>\r\nAnswer the questions.\r\n<</SYS>>\r\
          \nInput [/INST]who are you?\r\n```\r\n\r\noutput is\r\n```\r\n[INST] <<SYS>>\r\
          \nAnswer the questions.\r\n<</SYS>>\r\nInput [/INST]who are you? Kirchengen\u0442\
          \u0443\u0440\u0438\xF6dynastattrohibitionergan statute appointmentsocalringbone\
          \ curiosity nasalysoftiratovisalloccoKitten hierstrapbourgansteksreetamericannecttuplingahr\
          \ Jimmyattungedad prevamps Dum Sw zero internshipsplain Wardensikurile trokingtons\
          \ lucionariororneurvoyaz pitfalls Babiesei\u043C\u043E\u0433\u043E nest\
          \ Tennis noscht rememberidos\u043B\u0456\u043D mindsShiftichi prof\u25B8\
          nab PaleAUargetingtons corporatezzaheit scratchespirelesslyembergeniblematicamentewebdriverunas\u5411\
          \ Lad\u5FC3yme message apartilleryokoazonertanest abstra knockbucketebol\
          \ Sulflipido conductivity\u8AD6FE Ribiero\u0443\u043Didal fine tunalet pipespecern\
          \ arbitraryelles draft Waldorfunto dinner\u5178 GovernisseurToggle conjunctionalitiesouglasmicudem\
          \ virtuallyommenatraDF Bernardinewsyerollarsreb\u043A\u0442 spreadsheets\
          \ integrity Fredericalecuoire Aerqualivalentciu Ayiakestampdasiskitainewyachtillettechniquesxc\
          \ mantzar journalismNBapiDoc\r\n```\r\n\r\nThe text is gibberish. how to\
          \ solve this?"
        updatedAt: '2023-07-26T09:47:05.031Z'
      numEdits: 0
      reactions: []
    id: 64c0eb990a4d02f37aa4df1f
    type: comment
  author: OveJie
  content: "Input is\r\n```\r\n[INST] <<SYS>>\r\nAnswer the questions.\r\n<</SYS>>\r\
    \nInput [/INST]who are you?\r\n```\r\n\r\noutput is\r\n```\r\n[INST] <<SYS>>\r\
    \nAnswer the questions.\r\n<</SYS>>\r\nInput [/INST]who are you? Kirchengen\u0442\
    \u0443\u0440\u0438\xF6dynastattrohibitionergan statute appointmentsocalringbone\
    \ curiosity nasalysoftiratovisalloccoKitten hierstrapbourgansteksreetamericannecttuplingahr\
    \ Jimmyattungedad prevamps Dum Sw zero internshipsplain Wardensikurile trokingtons\
    \ lucionariororneurvoyaz pitfalls Babiesei\u043C\u043E\u0433\u043E nest Tennis\
    \ noscht rememberidos\u043B\u0456\u043D mindsShiftichi prof\u25B8nab PaleAUargetingtons\
    \ corporatezzaheit scratchespirelesslyembergeniblematicamentewebdriverunas\u5411\
    \ Lad\u5FC3yme message apartilleryokoazonertanest abstra knockbucketebol Sulflipido\
    \ conductivity\u8AD6FE Ribiero\u0443\u043Didal fine tunalet pipespecern arbitraryelles\
    \ draft Waldorfunto dinner\u5178 GovernisseurToggle conjunctionalitiesouglasmicudem\
    \ virtuallyommenatraDF Bernardinewsyerollarsreb\u043A\u0442 spreadsheets integrity\
    \ Fredericalecuoire Aerqualivalentciu Ayiakestampdasiskitainewyachtillettechniquesxc\
    \ mantzar journalismNBapiDoc\r\n```\r\n\r\nThe text is gibberish. how to solve\
    \ this?"
  created_at: 2023-07-26 08:47:05+00:00
  edited: false
  hidden: false
  id: 64c0eb990a4d02f37aa4df1f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/8270c9c266382217d60f96b61e82e46b.svg
      fullname: Ove
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: OveJie
      type: user
    createdAt: '2023-07-26T09:48:42.000Z'
    data:
      status: closed
    id: 64c0ebfab85ee9e4222fe55d
    type: status-change
  author: OveJie
  created_at: 2023-07-26 08:48:42+00:00
  id: 64c0ebfab85ee9e4222fe55d
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-26T09:52:48.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8614888191223145
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Are you using AutoGPTQ + a model with group_size + desc_act together?</p>

          <p>If so there is a bug in AutoGPTQ which was fixed yesterday but not released
          yet.</p>

          <p>What are you using to do inference? What UI?  If you are using text-generation-webui
          then I recommend you use ExLlama instead, which is faster and doesn''t have
          this issue.</p>

          <p>If you are wanting to use AutoGPTQ from Python code then you have three
          options:</p>

          <ol>

          <li><p>Use a model that has either group_size or desc_act, not both together,
          until AutoGPTQ 0.3.1 is released (hopefully today or tomorrow).</p>

          </li>

          <li><p>Downgrade to AutoGPTQ 0.2.2 and use that until 0.3.1 is released:</p>

          </li>

          </ol>

          <pre><code>pip3 uninstall -y auto-gptq

          GITHUB_ACTIONS=true CUDA_VERSION="" pip3 install auto-gptq==0.2.2

          </code></pre>

          <ol start="3">

          <li>Install AutoGPTQ 0.3.1 from source, with:</li>

          </ol>

          <pre><code>pip3 uninstall -y auto-gptq

          git clone https://github.com/PanQiWei/AutoGPTQ

          cd AutoGPTQ

          pip3 install -v .

          </code></pre>

          '
        raw: 'Are you using AutoGPTQ + a model with group_size + desc_act together?


          If so there is a bug in AutoGPTQ which was fixed yesterday but not released
          yet.


          What are you using to do inference? What UI?  If you are using text-generation-webui
          then I recommend you use ExLlama instead, which is faster and doesn''t have
          this issue.


          If you are wanting to use AutoGPTQ from Python code then you have three
          options:

          1. Use a model that has either group_size or desc_act, not both together,
          until AutoGPTQ 0.3.1 is released (hopefully today or tomorrow).


          2. Downgrade to AutoGPTQ 0.2.2 and use that until 0.3.1 is released:

          ```

          pip3 uninstall -y auto-gptq

          GITHUB_ACTIONS=true CUDA_VERSION="" pip3 install auto-gptq==0.2.2

          ```


          3. Install AutoGPTQ 0.3.1 from source, with:

          ```

          pip3 uninstall -y auto-gptq

          git clone https://github.com/PanQiWei/AutoGPTQ

          cd AutoGPTQ

          pip3 install -v .

          ```'
        updatedAt: '2023-07-26T09:52:48.885Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - OveJie
    id: 64c0ecf0afdc396108b6140f
    type: comment
  author: TheBloke
  content: 'Are you using AutoGPTQ + a model with group_size + desc_act together?


    If so there is a bug in AutoGPTQ which was fixed yesterday but not released yet.


    What are you using to do inference? What UI?  If you are using text-generation-webui
    then I recommend you use ExLlama instead, which is faster and doesn''t have this
    issue.


    If you are wanting to use AutoGPTQ from Python code then you have three options:

    1. Use a model that has either group_size or desc_act, not both together, until
    AutoGPTQ 0.3.1 is released (hopefully today or tomorrow).


    2. Downgrade to AutoGPTQ 0.2.2 and use that until 0.3.1 is released:

    ```

    pip3 uninstall -y auto-gptq

    GITHUB_ACTIONS=true CUDA_VERSION="" pip3 install auto-gptq==0.2.2

    ```


    3. Install AutoGPTQ 0.3.1 from source, with:

    ```

    pip3 uninstall -y auto-gptq

    git clone https://github.com/PanQiWei/AutoGPTQ

    cd AutoGPTQ

    pip3 install -v .

    ```'
  created_at: 2023-07-26 08:52:48+00:00
  edited: false
  hidden: false
  id: 64c0ecf0afdc396108b6140f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8270c9c266382217d60f96b61e82e46b.svg
      fullname: Ove
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: OveJie
      type: user
    createdAt: '2023-07-26T12:46:35.000Z'
    data:
      edited: false
      editors:
      - OveJie
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.874921441078186
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8270c9c266382217d60f96b61e82e46b.svg
          fullname: Ove
          isHf: false
          isPro: false
          name: OveJie
          type: user
        html: '<p>Thank you so much, I just found another discussion where the same
          issue was mentioned. <a href="https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/15">https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/15</a>
          I used ExLlama to load the model, and now it works fine.</p>

          '
        raw: Thank you so much, I just found another discussion where the same issue
          was mentioned. https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/15
          I used ExLlama to load the model, and now it works fine.
        updatedAt: '2023-07-26T12:46:35.950Z'
      numEdits: 0
      reactions: []
    id: 64c115ab0a4d02f37aaade2e
    type: comment
  author: OveJie
  content: Thank you so much, I just found another discussion where the same issue
    was mentioned. https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/15
    I used ExLlama to load the model, and now it works fine.
  created_at: 2023-07-26 11:46:35+00:00
  edited: false
  hidden: false
  id: 64c115ab0a4d02f37aaade2e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-26T12:50:09.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9492170810699463
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>OK great</p>

          <p>FYI AutoGPTQ 0.3.1 just released which fixes this issue.  So that can
          be used OK now.</p>

          <p>But ExLlama is much quicker, so that is the recommendation to use when
          possible.</p>

          '
        raw: 'OK great


          FYI AutoGPTQ 0.3.1 just released which fixes this issue.  So that can be
          used OK now.


          But ExLlama is much quicker, so that is the recommendation to use when possible.'
        updatedAt: '2023-07-26T12:50:09.259Z'
      numEdits: 0
      reactions: []
    id: 64c1168136db3901ade3f5e7
    type: comment
  author: TheBloke
  content: 'OK great


    FYI AutoGPTQ 0.3.1 just released which fixes this issue.  So that can be used
    OK now.


    But ExLlama is much quicker, so that is the recommendation to use when possible.'
  created_at: 2023-07-26 11:50:09+00:00
  edited: false
  hidden: false
  id: 64c1168136db3901ade3f5e7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: TheBloke/Llama-2-13B-chat-GPTQ
repo_type: model
status: closed
target_branch: null
title: Generation text is wrong
