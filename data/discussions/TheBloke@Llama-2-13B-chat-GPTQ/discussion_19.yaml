!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yashk92
conflicting_files: null
created_at: 2023-07-26 14:29:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fd637545d687a67218b084e9d17e1769.svg
      fullname: Yash
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yashk92
      type: user
    createdAt: '2023-07-26T15:29:55.000Z'
    data:
      edited: false
      editors:
      - yashk92
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7746037244796753
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fd637545d687a67218b084e9d17e1769.svg
          fullname: Yash
          isHf: false
          isPro: false
          name: yashk92
          type: user
        html: '<p>Is it possible to fine-tune these GPTQ especially this llama2-13b-chat-gptq
          model on custom chat dataset? if yes, what is the best structure to prepare
          the data for it? I plan to use it with langchain to create a conversational
          bot (just like ChatGPT) so I might use the ConversationChain to achieve
          the same. Thanks!</p>

          '
        raw: Is it possible to fine-tune these GPTQ especially this llama2-13b-chat-gptq
          model on custom chat dataset? if yes, what is the best structure to prepare
          the data for it? I plan to use it with langchain to create a conversational
          bot (just like ChatGPT) so I might use the ConversationChain to achieve
          the same. Thanks!
        updatedAt: '2023-07-26T15:29:55.134Z'
      numEdits: 0
      reactions: []
    id: 64c13bf3369e2f615f54dab6
    type: comment
  author: yashk92
  content: Is it possible to fine-tune these GPTQ especially this llama2-13b-chat-gptq
    model on custom chat dataset? if yes, what is the best structure to prepare the
    data for it? I plan to use it with langchain to create a conversational bot (just
    like ChatGPT) so I might use the ConversationChain to achieve the same. Thanks!
  created_at: 2023-07-26 14:29:55+00:00
  edited: false
  hidden: false
  id: 64c13bf3369e2f615f54dab6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-08-08T10:40:39.000Z'
    data:
      edited: true
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9713095426559448
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>Here''s a related Github <a rel="nofollow" href="https://github.com/PanQiWei/AutoGPTQ/%5D(https://github.com/PanQiWei/AutoGPTQ/">issue</a></p>

          '
        raw: Here's a related Github [issue](https://github.com/PanQiWei/AutoGPTQ/](https://github.com/PanQiWei/AutoGPTQ/)
        updatedAt: '2023-08-12T11:24:01.803Z'
      numEdits: 1
      reactions: []
    id: 64d21ba733e660e36e591f59
    type: comment
  author: RonanMcGovern
  content: Here's a related Github [issue](https://github.com/PanQiWei/AutoGPTQ/](https://github.com/PanQiWei/AutoGPTQ/)
  created_at: 2023-08-08 09:40:39+00:00
  edited: true
  hidden: false
  id: 64d21ba733e660e36e591f59
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fd637545d687a67218b084e9d17e1769.svg
      fullname: Yash
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yashk92
      type: user
    createdAt: '2023-08-18T10:08:34.000Z'
    data:
      edited: false
      editors:
      - yashk92
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7678734660148621
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fd637545d687a67218b084e9d17e1769.svg
          fullname: Yash
          isHf: false
          isPro: false
          name: yashk92
          type: user
        html: "<blockquote>\n<p>Here's a related Github <a rel=\"nofollow\" href=\"\
          https://github.com/PanQiWei/AutoGPTQ/%5D(https://github.com/PanQiWei/AutoGPTQ/\"\
          >issue</a></p>\n</blockquote>\n<p>Page not found! <span data-props=\"{&quot;user&quot;:&quot;RonanMcGovern&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/RonanMcGovern\"\
          >@<span class=\"underline\">RonanMcGovern</span></a></span>\n\n\t</span></span>\
          \ \U0001FAE4</p>\n"
        raw: "> Here's a related Github [issue](https://github.com/PanQiWei/AutoGPTQ/](https://github.com/PanQiWei/AutoGPTQ/)\n\
          \nPage not found! @RonanMcGovern \U0001FAE4"
        updatedAt: '2023-08-18T10:08:34.833Z'
      numEdits: 0
      reactions: []
    id: 64df43221d826d7355edf0d3
    type: comment
  author: yashk92
  content: "> Here's a related Github [issue](https://github.com/PanQiWei/AutoGPTQ/](https://github.com/PanQiWei/AutoGPTQ/)\n\
    \nPage not found! @RonanMcGovern \U0001FAE4"
  created_at: 2023-08-18 09:08:34+00:00
  edited: false
  hidden: false
  id: 64df43221d826d7355edf0d3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
      fullname: Ronan McGovern
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RonanMcGovern
      type: user
    createdAt: '2023-08-18T13:00:15.000Z'
    data:
      edited: false
      editors:
      - RonanMcGovern
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9161927103996277
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-6Yq7oM_Ju6Zi2GEvobvb.jpeg?w=200&h=200&f=face
          fullname: Ronan McGovern
          isHf: false
          isPro: false
          name: RonanMcGovern
          type: user
        html: '<p>Howdy, yeah it may have been taken down because work is underway
          to seamlessly integrate it with TheBloke''s models . Right now, you can
          do the fine tuning but you need to start with one of their models.</p>

          <p>See <a rel="nofollow" href="https://colab.research.google.com/drive/1_TIrmuKOFhuRRiTWN94iLKUFu6ZX4ceb?usp=sharing">here</a>
          for the Colab notebook.</p>

          <p>Apparently this will all be fixed up within 1-2 weeks.</p>

          '
        raw: 'Howdy, yeah it may have been taken down because work is underway to
          seamlessly integrate it with TheBloke''s models . Right now, you can do
          the fine tuning but you need to start with one of their models.


          See [here](https://colab.research.google.com/drive/1_TIrmuKOFhuRRiTWN94iLKUFu6ZX4ceb?usp=sharing)
          for the Colab notebook.


          Apparently this will all be fixed up within 1-2 weeks.'
        updatedAt: '2023-08-18T13:00:15.774Z'
      numEdits: 0
      reactions: []
    id: 64df6b5fbbbb7e908ccbed83
    type: comment
  author: RonanMcGovern
  content: 'Howdy, yeah it may have been taken down because work is underway to seamlessly
    integrate it with TheBloke''s models . Right now, you can do the fine tuning but
    you need to start with one of their models.


    See [here](https://colab.research.google.com/drive/1_TIrmuKOFhuRRiTWN94iLKUFu6ZX4ceb?usp=sharing)
    for the Colab notebook.


    Apparently this will all be fixed up within 1-2 weeks.'
  created_at: 2023-08-18 12:00:15+00:00
  edited: false
  hidden: false
  id: 64df6b5fbbbb7e908ccbed83
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: TheBloke/Llama-2-13B-chat-GPTQ
repo_type: model
status: open
target_branch: null
title: fine tune on custom chat dataset using QLORA & PEFT
