!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nigsdf
conflicting_files: null
created_at: 2023-07-29 07:49:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/953087d7d950be905c71655a1efe654a.svg
      fullname: santos
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nigsdf
      type: user
    createdAt: '2023-07-29T08:49:47.000Z'
    data:
      edited: false
      editors:
      - nigsdf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8704421520233154
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/953087d7d950be905c71655a1efe654a.svg
          fullname: santos
          isHf: false
          isPro: false
          name: nigsdf
          type: user
        html: '<p>Hi, </p>

          <p>I''m trying to use<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64c4cd96589826641b94db2d/-H_YLrqgrEOOt1Qla_SNB.jpeg"><img
          alt="LLAMA.jpg" src="https://cdn-uploads.huggingface.co/production/uploads/64c4cd96589826641b94db2d/-H_YLrqgrEOOt1Qla_SNB.jpeg"></a><br>
          and I''ve encountered several problems. My first issue is with llama-cpp-python.
          I used "pip install llama-cpp-python" to install it, but it appears to have
          incomplete files. As a result, I had to clone the repository just to build
          the project.</p>

          <p>The second issue is with the command "./main -t 10 -ngl 32 -m llama-2-13b-chat.ggmlv3.q4_0.bin
          --color -c 4096 --temp 0.7 --repeat_penalty 1.1 -n -1 --in-prefix-bos --in-prefix
          '' [INST] '' --in-suffix '' [/INST]'' -i -p ''[INST] &lt;&gt; You are a
          helpful, respectful, and honest assistant. &lt;&gt; Write a story about
          llamas. [/INST]''".</p>

          <p>Because the pip method installed incomplete files, I had to clone the
          entire repository. But even after successfully building the project, the
          main executable is missing. I''m not sure if it''s failing to generate or
          if there''s another problem. As a result, I can''t execute the command because
          ./main is missing please refer to the attached screenshot.</p>

          '
        raw: "Hi, \r\n\r\n \r\nI'm trying to use \r\n![LLAMA.jpg](https://cdn-uploads.huggingface.co/production/uploads/64c4cd96589826641b94db2d/-H_YLrqgrEOOt1Qla_SNB.jpeg)\r\
          \n and I've encountered several problems. My first issue is with llama-cpp-python.\
          \ I used \"pip install llama-cpp-python\" to install it, but it appears\
          \ to have incomplete files. As a result, I had to clone the repository just\
          \ to build the project.\r\n\r\nThe second issue is with the command \"./main\
          \ -t 10 -ngl 32 -m llama-2-13b-chat.ggmlv3.q4_0.bin --color -c 4096 --temp\
          \ 0.7 --repeat_penalty 1.1 -n -1 --in-prefix-bos --in-prefix ' [INST] '\
          \ --in-suffix ' [/INST]' -i -p '[INST] <<SYS>> You are a helpful, respectful,\
          \ and honest assistant. <</SYS>> Write a story about llamas. [/INST]'\"\
          .\r\n\r\nBecause the pip method installed incomplete files, I had to clone\
          \ the entire repository. But even after successfully building the project,\
          \ the main executable is missing. I'm not sure if it's failing to generate\
          \ or if there's another problem. As a result, I can't execute the command\
          \ because ./main is missing please refer to the attached screenshot."
        updatedAt: '2023-07-29T08:49:47.857Z'
      numEdits: 0
      reactions: []
    id: 64c4d2ab57e5b2cd8ad54b84
    type: comment
  author: nigsdf
  content: "Hi, \r\n\r\n \r\nI'm trying to use \r\n![LLAMA.jpg](https://cdn-uploads.huggingface.co/production/uploads/64c4cd96589826641b94db2d/-H_YLrqgrEOOt1Qla_SNB.jpeg)\r\
    \n and I've encountered several problems. My first issue is with llama-cpp-python.\
    \ I used \"pip install llama-cpp-python\" to install it, but it appears to have\
    \ incomplete files. As a result, I had to clone the repository just to build the\
    \ project.\r\n\r\nThe second issue is with the command \"./main -t 10 -ngl 32\
    \ -m llama-2-13b-chat.ggmlv3.q4_0.bin --color -c 4096 --temp 0.7 --repeat_penalty\
    \ 1.1 -n -1 --in-prefix-bos --in-prefix ' [INST] ' --in-suffix ' [/INST]' -i -p\
    \ '[INST] <<SYS>> You are a helpful, respectful, and honest assistant. <</SYS>>\
    \ Write a story about llamas. [/INST]'\".\r\n\r\nBecause the pip method installed\
    \ incomplete files, I had to clone the entire repository. But even after successfully\
    \ building the project, the main executable is missing. I'm not sure if it's failing\
    \ to generate or if there's another problem. As a result, I can't execute the\
    \ command because ./main is missing please refer to the attached screenshot."
  created_at: 2023-07-29 07:49:47+00:00
  edited: false
  hidden: false
  id: 64c4d2ab57e5b2cd8ad54b84
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-29T08:57:59.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.892821729183197
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>llama-cpp-python is a Python library. You use it from Python code,
          or use it to provide an OpenAI-compatible API server.  It doesn''t provide
          a <code>main</code> binary.   Check their Github repo for examples and more
          details.</p>

          <p>It''s llama.cpp that provides a <code>main</code> binary, either after
          you compile it yourself, or if you download one of the pre-built releases
          from its releases page.</p>

          '
        raw: 'llama-cpp-python is a Python library. You use it from Python code, or
          use it to provide an OpenAI-compatible API server.  It doesn''t provide
          a `main` binary.   Check their Github repo for examples and more details.


          It''s llama.cpp that provides a `main` binary, either after you compile
          it yourself, or if you download one of the pre-built releases from its releases
          page.'
        updatedAt: '2023-07-29T08:57:59.529Z'
      numEdits: 0
      reactions: []
    id: 64c4d497ed521f27a4fffa8a
    type: comment
  author: TheBloke
  content: 'llama-cpp-python is a Python library. You use it from Python code, or
    use it to provide an OpenAI-compatible API server.  It doesn''t provide a `main`
    binary.   Check their Github repo for examples and more details.


    It''s llama.cpp that provides a `main` binary, either after you compile it yourself,
    or if you download one of the pre-built releases from its releases page.'
  created_at: 2023-07-29 07:57:59+00:00
  edited: false
  hidden: false
  id: 64c4d497ed521f27a4fffa8a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/953087d7d950be905c71655a1efe654a.svg
      fullname: santos
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nigsdf
      type: user
    createdAt: '2023-07-30T00:00:39.000Z'
    data:
      edited: false
      editors:
      - nigsdf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9940876364707947
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/953087d7d950be905c71655a1efe654a.svg
          fullname: santos
          isHf: false
          isPro: false
          name: nigsdf
          type: user
        html: '<p>i already tried to compile it it was successful, but it didn''t
          generate any main binary</p>

          '
        raw: i already tried to compile it it was successful, but it didn't generate
          any main binary
        updatedAt: '2023-07-30T00:00:39.222Z'
      numEdits: 0
      reactions: []
    id: 64c5a8272d07296c7e3b6656
    type: comment
  author: nigsdf
  content: i already tried to compile it it was successful, but it didn't generate
    any main binary
  created_at: 2023-07-29 23:00:39+00:00
  edited: false
  hidden: false
  id: 64c5a8272d07296c7e3b6656
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 23
repo_id: TheBloke/Llama-2-13B-chat-GPTQ
repo_type: model
status: open
target_branch: null
title: Llama-2-13B-chat-GPTQ problem
