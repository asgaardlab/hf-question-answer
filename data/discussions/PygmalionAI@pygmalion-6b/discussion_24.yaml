!!python/object:huggingface_hub.community.DiscussionWithDetails
author: octopusta
conflicting_files: null
created_at: 2023-04-04 15:53:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639e60f6727066701124cb26/44l8OANkXhXGPNs1wuxa7.png?w=200&h=200&f=face
      fullname: Mohamed Hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: octopusta
      type: user
    createdAt: '2023-04-04T16:53:30.000Z'
    data:
      edited: true
      editors:
      - octopusta
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639e60f6727066701124cb26/44l8OANkXhXGPNs1wuxa7.png?w=200&h=200&f=face
          fullname: Mohamed Hammad
          isHf: false
          isPro: false
          name: octopusta
          type: user
        html: '<p>dear all</p>

          <p>we intent to use this model for a conversational chat with our users</p>

          <p>is there any way with the simplest implementation to run this model with
          only API interface</p>

          <p>thank you in advance</p>

          '
        raw: 'dear all


          we intent to use this model for a conversational chat with our users


          is there any way with the simplest implementation to run this model with
          only API interface


          thank you in advance'
        updatedAt: '2023-04-04T16:56:17.718Z'
      numEdits: 1
      reactions: []
    id: 642c560ab09c70b36de03b6a
    type: comment
  author: octopusta
  content: 'dear all


    we intent to use this model for a conversational chat with our users


    is there any way with the simplest implementation to run this model with only
    API interface


    thank you in advance'
  created_at: 2023-04-04 15:53:30+00:00
  edited: true
  hidden: false
  id: 642c560ab09c70b36de03b6a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639e60f6727066701124cb26/44l8OANkXhXGPNs1wuxa7.png?w=200&h=200&f=face
      fullname: Mohamed Hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: octopusta
      type: user
    createdAt: '2023-04-06T04:42:24.000Z'
    data:
      edited: false
      editors:
      - octopusta
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639e60f6727066701124cb26/44l8OANkXhXGPNs1wuxa7.png?w=200&h=200&f=face
          fullname: Mohamed Hammad
          isHf: false
          isPro: false
          name: octopusta
          type: user
        html: '<p>any help please ??</p>

          <p>we found ColossalAI with EnergonAI that can achieve the API interface</p>

          <p>is there anyway to run this model with it ?</p>

          '
        raw: 'any help please ??


          we found ColossalAI with EnergonAI that can achieve the API interface


          is there anyway to run this model with it ?'
        updatedAt: '2023-04-06T04:42:24.284Z'
      numEdits: 0
      reactions: []
    id: 642e4db0baf943d5db49a0cf
    type: comment
  author: octopusta
  content: 'any help please ??


    we found ColossalAI with EnergonAI that can achieve the API interface


    is there anyway to run this model with it ?'
  created_at: 2023-04-06 03:42:24+00:00
  edited: false
  hidden: false
  id: 642e4db0baf943d5db49a0cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ebf5710d9a6d04bb6bf87dc0bc1aaccd.svg
      fullname: Jineui Kim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jini1114
      type: user
    createdAt: '2023-04-12T04:58:56.000Z'
    data:
      edited: false
      editors:
      - jini1114
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ebf5710d9a6d04bb6bf87dc0bc1aaccd.svg
          fullname: Jineui Kim
          isHf: false
          isPro: false
          name: jini1114
          type: user
        html: '<p>what about try FastAPI?<br>i''ve set up chatbot api server using
          FastAPI.</p>

          '
        raw: 'what about try FastAPI?

          i''ve set up chatbot api server using FastAPI.'
        updatedAt: '2023-04-12T04:58:56.537Z'
      numEdits: 0
      reactions: []
    id: 64363a907e07c5aee23b1d2d
    type: comment
  author: jini1114
  content: 'what about try FastAPI?

    i''ve set up chatbot api server using FastAPI.'
  created_at: 2023-04-12 03:58:56+00:00
  edited: false
  hidden: false
  id: 64363a907e07c5aee23b1d2d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639e60f6727066701124cb26/44l8OANkXhXGPNs1wuxa7.png?w=200&h=200&f=face
      fullname: Mohamed Hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: octopusta
      type: user
    createdAt: '2023-04-12T08:00:05.000Z'
    data:
      edited: false
      editors:
      - octopusta
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639e60f6727066701124cb26/44l8OANkXhXGPNs1wuxa7.png?w=200&h=200&f=face
          fullname: Mohamed Hammad
          isHf: false
          isPro: false
          name: octopusta
          type: user
        html: '<p>can you help please with steps or the main idea how to do it ?</p>

          <p>do you mean to build the API inside the python file before make the text
          generation using the model ?</p>

          <p>i thought this way but i think it''s too pare hands way so i asked if
          there any ready to use package or component</p>

          <p>thank you for sharing your idea &lt;3 appreciate it and i will give it
          a try</p>

          '
        raw: 'can you help please with steps or the main idea how to do it ?


          do you mean to build the API inside the python file before make the text
          generation using the model ?


          i thought this way but i think it''s too pare hands way so i asked if there
          any ready to use package or component


          thank you for sharing your idea <3 appreciate it and i will give it a try'
        updatedAt: '2023-04-12T08:00:05.329Z'
      numEdits: 0
      reactions: []
    id: 643665052a44a340c2861be1
    type: comment
  author: octopusta
  content: 'can you help please with steps or the main idea how to do it ?


    do you mean to build the API inside the python file before make the text generation
    using the model ?


    i thought this way but i think it''s too pare hands way so i asked if there any
    ready to use package or component


    thank you for sharing your idea <3 appreciate it and i will give it a try'
  created_at: 2023-04-12 07:00:05+00:00
  edited: false
  hidden: false
  id: 643665052a44a340c2861be1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ebf5710d9a6d04bb6bf87dc0bc1aaccd.svg
      fullname: Jineui Kim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jini1114
      type: user
    createdAt: '2023-04-12T08:09:54.000Z'
    data:
      edited: false
      editors:
      - jini1114
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ebf5710d9a6d04bb6bf87dc0bc1aaccd.svg
          fullname: Jineui Kim
          isHf: false
          isPro: false
          name: jini1114
          type: user
        html: "<p>here is my code as a short version</p>\n<pre><code>~~~\ndevice =\
          \ 'cuda' if torch.cuda.is_available() else 'cpu'\n\napp = FastAPI()\n\n\
          model_name = \"PygmalionAI/pygmalion-6b\"\ngpt = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n\
          tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\ngpt.to(device)\n\
          \n<span data-props=\"{&quot;user&quot;:&quot;app&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/app\">@<span class=\"\
          underline\">app</span></a></span>\n\n\t</span></span>.post('/completion/')\n\
          async def chat(data:Data, request: Request):\n    prompt = tokenizer(data.prompt,\
          \ return_tensors='pt')\n    prompt = {key: value.to(device) for key, value\
          \ in prompt.items()}\n    out = gpt.generate(**prompt, min_length=128, max_length=256,\
          \ do_sample=True)\n    completion = tokenizer.decode(out[0][len(prompt[\"\
          input_ids\"][0]):])\n    return completion\n</code></pre>\n<p>then you post\
          \ the request to your server like below</p>\n<pre><code>url = \"http://your.ser.ver.ip:port/completion/\"\
          \nres = requests.post(url, data=json.dumps(data))\nprint(res.text)\n</code></pre>\n\
          <p>you must match the format between post data and api data</p>\n"
        raw: "here is my code as a short version\n```\n~~~\ndevice = 'cuda' if torch.cuda.is_available()\
          \ else 'cpu'\n\napp = FastAPI()\n\nmodel_name = \"PygmalionAI/pygmalion-6b\"\
          \ngpt = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n\
          tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\ngpt.to(device)\n\
          \n@app.post('/completion/')\nasync def chat(data:Data, request: Request):\n\
          \    prompt = tokenizer(data.prompt, return_tensors='pt')\n    prompt =\
          \ {key: value.to(device) for key, value in prompt.items()}\n    out = gpt.generate(**prompt,\
          \ min_length=128, max_length=256, do_sample=True)\n    completion = tokenizer.decode(out[0][len(prompt[\"\
          input_ids\"][0]):])\n    return completion\n```\nthen you post the request\
          \ to your server like below\n```\nurl = \"http://your.ser.ver.ip:port/completion/\"\
          \nres = requests.post(url, data=json.dumps(data))\nprint(res.text)\n```\n\
          you must match the format between post data and api data"
        updatedAt: '2023-04-12T08:09:54.865Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - octopusta
        - Wamy
        - adikhad
    id: 64366752242c3c9575f89cfb
    type: comment
  author: jini1114
  content: "here is my code as a short version\n```\n~~~\ndevice = 'cuda' if torch.cuda.is_available()\
    \ else 'cpu'\n\napp = FastAPI()\n\nmodel_name = \"PygmalionAI/pygmalion-6b\"\n\
    gpt = transformers.AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer\
    \ = transformers.AutoTokenizer.from_pretrained(model_name)\ngpt.to(device)\n\n\
    @app.post('/completion/')\nasync def chat(data:Data, request: Request):\n    prompt\
    \ = tokenizer(data.prompt, return_tensors='pt')\n    prompt = {key: value.to(device)\
    \ for key, value in prompt.items()}\n    out = gpt.generate(**prompt, min_length=128,\
    \ max_length=256, do_sample=True)\n    completion = tokenizer.decode(out[0][len(prompt[\"\
    input_ids\"][0]):])\n    return completion\n```\nthen you post the request to\
    \ your server like below\n```\nurl = \"http://your.ser.ver.ip:port/completion/\"\
    \nres = requests.post(url, data=json.dumps(data))\nprint(res.text)\n```\nyou must\
    \ match the format between post data and api data"
  created_at: 2023-04-12 07:09:54+00:00
  edited: false
  hidden: false
  id: 64366752242c3c9575f89cfb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639e60f6727066701124cb26/44l8OANkXhXGPNs1wuxa7.png?w=200&h=200&f=face
      fullname: Mohamed Hammad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: octopusta
      type: user
    createdAt: '2023-04-12T08:32:31.000Z'
    data:
      edited: false
      editors:
      - octopusta
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639e60f6727066701124cb26/44l8OANkXhXGPNs1wuxa7.png?w=200&h=200&f=face
          fullname: Mohamed Hammad
          isHf: false
          isPro: false
          name: octopusta
          type: user
        html: '<p>thank you very much &lt;3</p>

          '
        raw: thank you very much <3
        updatedAt: '2023-04-12T08:32:31.883Z'
      numEdits: 0
      reactions: []
    id: 64366c9fa38b21abf940633a
    type: comment
  author: octopusta
  content: thank you very much <3
  created_at: 2023-04-12 07:32:31+00:00
  edited: false
  hidden: false
  id: 64366c9fa38b21abf940633a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 24
repo_id: PygmalionAI/pygmalion-6b
repo_type: model
status: open
target_branch: null
title: Model with only API
