!!python/object:huggingface_hub.community.DiscussionWithDetails
author: miloice2022
conflicting_files: null
created_at: 2023-05-03 08:53:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9e32aaf210dbe273e176257ee6076547.svg
      fullname: Milo Ice
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: miloice2022
      type: user
    createdAt: '2023-05-03T09:53:29.000Z'
    data:
      edited: false
      editors:
      - miloice2022
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9e32aaf210dbe273e176257ee6076547.svg
          fullname: Milo Ice
          isHf: false
          isPro: false
          name: miloice2022
          type: user
        html: "<p>I have a Oobabooga 1.0.1 Runpod with API enabled. I am trying to\
          \ use this pod as a Pygmalion REST API backend for a chat frontend.<br>If\
          \ I fire a post API to the pod like this:</p>\n<pre><code>curl --request\
          \ POST \\\n     --url https://[redacted].proxy.runpod.net/api/v1/generate\
          \ \\\n     --header \"accept: application/json\" \\\n     --header \"content-type:\
          \ application/json\" \\\n     --data u/- &lt;&lt;EOF\n{\n    \"prompt\"\
          : \"Can you tell me a joke?\",\n    \"do_sample\": true,\n    \"max_length\"\
          : 300,\n    \"temperature\": 0.9\n}\nEOF\n</code></pre>\n<p>I will get a\
          \ truncated response like this:</p>\n<pre><code>{\"results\": [{\"text\"\
          : \"e* a joke or two that you know the significance of, Null?\\nYou: You\
          \ could always recursively call the function to do so!\\n\"}]}\n</code></pre>\n\
          <p>This response feels truncated and generally very wrong.</p>\n<p>If I\
          \ follow the prompt suggestion from the Pygmalion 6B documentation:</p>\n\
          <pre><code>curl --request POST \\\n     --url https://[redacted].proxy.runpod.net/api/v1/generate\
          \ \\\n     --header \"accept: application/json\" \\\n     --header \"content-type:\
          \ application/json\" \\\n     --data u/- &lt;&lt;EOF\n{\n    \"prompt\"\
          : \"AI's Persona: AI is a helpful assistant.\n&lt;START&gt;\nYou: Hi!\n\
          AI: Hi! How can I help you?\nYou: What's the color of Apple?\nAI: The color\
          \ of Apple is red.\nYou: Are you happy?\nAI: Yes I am happy. What about\
          \ you?\nYou: Can you tell me a joke?\nAI: \",\n    \"do_sample\": true,\n\
          \    \"max_length\": 300,\n    \"temperature\": 0.9\n}\nEOF\n</code></pre>\n\
          <p>The response will either be truncated like the above, or even worse,\
          \ an empty text response like this:</p>\n<pre><code>{\"results\": [{\"text\"\
          : \"\"}]}\n</code></pre>\n<p>Any idea what am I missing here?</p>\n"
        raw: "I have a Oobabooga 1.0.1 Runpod with API enabled. I am trying to use\
          \ this pod as a Pygmalion REST API backend for a chat frontend.\r\nIf I\
          \ fire a post API to the pod like this:\r\n~~~\r\ncurl --request POST \\\
          \r\n     --url https://[redacted].proxy.runpod.net/api/v1/generate \\\r\n\
          \     --header \"accept: application/json\" \\\r\n     --header \"content-type:\
          \ application/json\" \\\r\n     --data u/- <<EOF\r\n{\r\n    \"prompt\"\
          : \"Can you tell me a joke?\",\r\n    \"do_sample\": true,\r\n    \"max_length\"\
          : 300,\r\n    \"temperature\": 0.9\r\n}\r\nEOF\r\n~~~\r\nI will get a truncated\
          \ response like this:\r\n~~~\r\n{\"results\": [{\"text\": \"e* a joke or\
          \ two that you know the significance of, Null?\\nYou: You could always recursively\
          \ call the function to do so!\\n\"}]}\r\n~~~\r\nThis response feels truncated\
          \ and generally very wrong.\r\n\r\nIf I follow the prompt suggestion from\
          \ the Pygmalion 6B documentation:\r\n~~~\r\ncurl --request POST \\\r\n \
          \    --url https://[redacted].proxy.runpod.net/api/v1/generate \\\r\n  \
          \   --header \"accept: application/json\" \\\r\n     --header \"content-type:\
          \ application/json\" \\\r\n     --data u/- <<EOF\r\n{\r\n    \"prompt\"\
          : \"AI's Persona: AI is a helpful assistant.\r\n<START>\r\nYou: Hi!\r\n\
          AI: Hi! How can I help you?\r\nYou: What's the color of Apple?\r\nAI: The\
          \ color of Apple is red.\r\nYou: Are you happy?\r\nAI: Yes I am happy. What\
          \ about you?\r\nYou: Can you tell me a joke?\r\nAI: \",\r\n    \"do_sample\"\
          : true,\r\n    \"max_length\": 300,\r\n    \"temperature\": 0.9\r\n}\r\n\
          EOF\r\n~~~\r\n\r\nThe response will either be truncated like the above,\
          \ or even worse, an empty text response like this:\r\n~~~\r\n{\"results\"\
          : [{\"text\": \"\"}]}\r\n~~~\r\n\r\nAny idea what am I missing here?"
        updatedAt: '2023-05-03T09:53:29.734Z'
      numEdits: 0
      reactions: []
    id: 64522f19f0136bbbd368386e
    type: comment
  author: miloice2022
  content: "I have a Oobabooga 1.0.1 Runpod with API enabled. I am trying to use this\
    \ pod as a Pygmalion REST API backend for a chat frontend.\r\nIf I fire a post\
    \ API to the pod like this:\r\n~~~\r\ncurl --request POST \\\r\n     --url https://[redacted].proxy.runpod.net/api/v1/generate\
    \ \\\r\n     --header \"accept: application/json\" \\\r\n     --header \"content-type:\
    \ application/json\" \\\r\n     --data u/- <<EOF\r\n{\r\n    \"prompt\": \"Can\
    \ you tell me a joke?\",\r\n    \"do_sample\": true,\r\n    \"max_length\": 300,\r\
    \n    \"temperature\": 0.9\r\n}\r\nEOF\r\n~~~\r\nI will get a truncated response\
    \ like this:\r\n~~~\r\n{\"results\": [{\"text\": \"e* a joke or two that you know\
    \ the significance of, Null?\\nYou: You could always recursively call the function\
    \ to do so!\\n\"}]}\r\n~~~\r\nThis response feels truncated and generally very\
    \ wrong.\r\n\r\nIf I follow the prompt suggestion from the Pygmalion 6B documentation:\r\
    \n~~~\r\ncurl --request POST \\\r\n     --url https://[redacted].proxy.runpod.net/api/v1/generate\
    \ \\\r\n     --header \"accept: application/json\" \\\r\n     --header \"content-type:\
    \ application/json\" \\\r\n     --data u/- <<EOF\r\n{\r\n    \"prompt\": \"AI's\
    \ Persona: AI is a helpful assistant.\r\n<START>\r\nYou: Hi!\r\nAI: Hi! How can\
    \ I help you?\r\nYou: What's the color of Apple?\r\nAI: The color of Apple is\
    \ red.\r\nYou: Are you happy?\r\nAI: Yes I am happy. What about you?\r\nYou: Can\
    \ you tell me a joke?\r\nAI: \",\r\n    \"do_sample\": true,\r\n    \"max_length\"\
    : 300,\r\n    \"temperature\": 0.9\r\n}\r\nEOF\r\n~~~\r\n\r\nThe response will\
    \ either be truncated like the above, or even worse, an empty text response like\
    \ this:\r\n~~~\r\n{\"results\": [{\"text\": \"\"}]}\r\n~~~\r\n\r\nAny idea what\
    \ am I missing here?"
  created_at: 2023-05-03 08:53:29+00:00
  edited: false
  hidden: false
  id: 64522f19f0136bbbd368386e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e0cd132c141769a615e5c86bd6f622ea.svg
      fullname: M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: WaelMansour
      type: user
    createdAt: '2023-06-13T11:29:04.000Z'
    data:
      edited: true
      editors:
      - WaelMansour
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9835271835327148
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e0cd132c141769a615e5c86bd6f622ea.svg
          fullname: M
          isHf: false
          isPro: false
          name: WaelMansour
          type: user
        html: '<p>Did you find a solutions?</p>

          '
        raw: Did you find a solutions?
        updatedAt: '2023-06-13T11:29:17.167Z'
      numEdits: 1
      reactions: []
    id: 64885300db186e19a6409875
    type: comment
  author: WaelMansour
  content: Did you find a solutions?
  created_at: 2023-06-13 10:29:04+00:00
  edited: true
  hidden: false
  id: 64885300db186e19a6409875
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 30
repo_id: PygmalionAI/pygmalion-6b
repo_type: model
status: open
target_branch: null
title: Truncated or empty text response?
