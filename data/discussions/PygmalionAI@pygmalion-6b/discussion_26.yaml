!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sweetamino
conflicting_files: null
created_at: 2023-04-12 17:01:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c5cdc96fe342e3929613cfc6eaac82a2.svg
      fullname: sweetamino
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sweetamino
      type: user
    createdAt: '2023-04-12T18:01:55.000Z'
    data:
      edited: false
      editors:
      - sweetamino
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c5cdc96fe342e3929613cfc6eaac82a2.svg
          fullname: sweetamino
          isHf: false
          isPro: false
          name: sweetamino
          type: user
        html: '<p>Is the training dataset used available anywhere? I''d like to use
          it to fine tune RWKV.</p>

          '
        raw: Is the training dataset used available anywhere? I'd like to use it to
          fine tune RWKV.
        updatedAt: '2023-04-12T18:01:55.988Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - jwthomp
        - robowaifudev
        - neonr-0
        - RazielAU
        - Crataco
    id: 6436f2133d818691cf25ccd5
    type: comment
  author: sweetamino
  content: Is the training dataset used available anywhere? I'd like to use it to
    fine tune RWKV.
  created_at: 2023-04-12 17:01:55+00:00
  edited: false
  hidden: false
  id: 6436f2133d818691cf25ccd5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671567442495-noauth.png?w=200&h=200&f=face
      fullname: TearGosling
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TearGosling
      type: user
    createdAt: '2023-04-21T21:39:55.000Z'
    data:
      edited: false
      editors:
      - TearGosling
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671567442495-noauth.png?w=200&h=200&f=face
          fullname: TearGosling
          isHf: false
          isPro: false
          name: TearGosling
          type: user
        html: '<p>Hey there! So, we use a variety of different sources from our dataset,
          including community contributions. We do plan to release a portion of these
          community contributions in the future, so do sit tight for updates on that.</p>

          '
        raw: Hey there! So, we use a variety of different sources from our dataset,
          including community contributions. We do plan to release a portion of these
          community contributions in the future, so do sit tight for updates on that.
        updatedAt: '2023-04-21T21:39:55.742Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Crataco
    id: 644302abf8b647fa4f5740a4
    type: comment
  author: TearGosling
  content: Hey there! So, we use a variety of different sources from our dataset,
    including community contributions. We do plan to release a portion of these community
    contributions in the future, so do sit tight for updates on that.
  created_at: 2023-04-21 20:39:55+00:00
  edited: false
  hidden: false
  id: 644302abf8b647fa4f5740a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/612aa89fa431d67a04818e1ac312bcec.svg
      fullname: Francois Grobbelaar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RazielAU
      type: user
    createdAt: '2023-04-22T03:52:13.000Z'
    data:
      edited: false
      editors:
      - RazielAU
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/612aa89fa431d67a04818e1ac312bcec.svg
          fullname: Francois Grobbelaar
          isHf: false
          isPro: false
          name: RazielAU
          type: user
        html: '<p>Why only a portion???</p>

          <p>I never understand why projects like Pygmalion won''t open their datasets
          so that other language models can be trained with the same dataset. It just
          feels like you''re keeping the dataset to yourself so no one else can produce
          a competing model using a better LLM as a base.</p>

          <p>I''ve been thinking of starting a project to pull together an open Pygmalion
          style dataset, as right now, no such dataset exists. As I said in a discussion
          with someone yesterday, right now, you either have a really good LLM, or
          an LLM that is fine-tuned for role-playing, not both. There are some really
          great options like FLAN-T5, OPT, BLOOM, GPT-NeoX and LLaMA which are all
          good potential candidates for training, but with no dataset available to
          train them, the GPT-J based Pygmalion and Pyg-based mixes are the only options
          available.</p>

          <p>So that leaves me with two questions:</p>

          <ol>

          <li>When are you looking at releasing this dataset?</li>

          <li>Will it be enough to realistically train any LLM to handle Pygmalion
          style role-playing?</li>

          </ol>

          <p>It''s good to hear you intend to release something, but hearing it''s
          only going to be a portion of the community contributions is very disappointing.</p>

          '
        raw: 'Why only a portion???


          I never understand why projects like Pygmalion won''t open their datasets
          so that other language models can be trained with the same dataset. It just
          feels like you''re keeping the dataset to yourself so no one else can produce
          a competing model using a better LLM as a base.


          I''ve been thinking of starting a project to pull together an open Pygmalion
          style dataset, as right now, no such dataset exists. As I said in a discussion
          with someone yesterday, right now, you either have a really good LLM, or
          an LLM that is fine-tuned for role-playing, not both. There are some really
          great options like FLAN-T5, OPT, BLOOM, GPT-NeoX and LLaMA which are all
          good potential candidates for training, but with no dataset available to
          train them, the GPT-J based Pygmalion and Pyg-based mixes are the only options
          available.


          So that leaves me with two questions:

          1) When are you looking at releasing this dataset?

          2) Will it be enough to realistically train any LLM to handle Pygmalion
          style role-playing?


          It''s good to hear you intend to release something, but hearing it''s only
          going to be a portion of the community contributions is very disappointing.'
        updatedAt: '2023-04-22T03:52:13.266Z'
      numEdits: 0
      reactions: []
    id: 644359edf8b647fa4f5cd6ee
    type: comment
  author: RazielAU
  content: 'Why only a portion???


    I never understand why projects like Pygmalion won''t open their datasets so that
    other language models can be trained with the same dataset. It just feels like
    you''re keeping the dataset to yourself so no one else can produce a competing
    model using a better LLM as a base.


    I''ve been thinking of starting a project to pull together an open Pygmalion style
    dataset, as right now, no such dataset exists. As I said in a discussion with
    someone yesterday, right now, you either have a really good LLM, or an LLM that
    is fine-tuned for role-playing, not both. There are some really great options
    like FLAN-T5, OPT, BLOOM, GPT-NeoX and LLaMA which are all good potential candidates
    for training, but with no dataset available to train them, the GPT-J based Pygmalion
    and Pyg-based mixes are the only options available.


    So that leaves me with two questions:

    1) When are you looking at releasing this dataset?

    2) Will it be enough to realistically train any LLM to handle Pygmalion style
    role-playing?


    It''s good to hear you intend to release something, but hearing it''s only going
    to be a portion of the community contributions is very disappointing.'
  created_at: 2023-04-22 02:52:13+00:00
  edited: false
  hidden: false
  id: 644359edf8b647fa4f5cd6ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671567442495-noauth.png?w=200&h=200&f=face
      fullname: TearGosling
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: TearGosling
      type: user
    createdAt: '2023-04-22T14:53:57.000Z'
    data:
      edited: true
      editors:
      - TearGosling
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671567442495-noauth.png?w=200&h=200&f=face
          fullname: TearGosling
          isHf: false
          isPro: false
          name: TearGosling
          type: user
        html: '<p>During the creation of our dataset, we gave the option for community
          contributors for said dataset to be able to have their data private - that
          is, used only for us and not something that they wished to be released to
          the public for whatever reasons that may be. When we say "a portion", we
          refer to the section of the data that was marked by contributors as "I consent
          to this data to be released to the public" - hence, the public portion.
          My apologies for not clarifying that earlier. As for "when", we sadly can''t
          give a date on that due to complications with trying to redact any personal
          information which may have slipped into the public portion of the dataset.
          As for it being enough, we noted that the section that was marked as public
          had more data than the section that was marked as private. For all intents
          and purposes, it should be enough to realistically train any LLM to handle
          Pyg-style roleplaying.</p>

          '
        raw: During the creation of our dataset, we gave the option for community
          contributors for said dataset to be able to have their data private - that
          is, used only for us and not something that they wished to be released to
          the public for whatever reasons that may be. When we say "a portion", we
          refer to the section of the data that was marked by contributors as "I consent
          to this data to be released to the public" - hence, the public portion.
          My apologies for not clarifying that earlier. As for "when", we sadly can't
          give a date on that due to complications with trying to redact any personal
          information which may have slipped into the public portion of the dataset.
          As for it being enough, we noted that the section that was marked as public
          had more data than the section that was marked as private. For all intents
          and purposes, it should be enough to realistically train any LLM to handle
          Pyg-style roleplaying.
        updatedAt: '2023-04-22T14:54:39.718Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Crataco
        - nacs
    id: 6443f505c63001ae6350cb07
    type: comment
  author: TearGosling
  content: During the creation of our dataset, we gave the option for community contributors
    for said dataset to be able to have their data private - that is, used only for
    us and not something that they wished to be released to the public for whatever
    reasons that may be. When we say "a portion", we refer to the section of the data
    that was marked by contributors as "I consent to this data to be released to the
    public" - hence, the public portion. My apologies for not clarifying that earlier.
    As for "when", we sadly can't give a date on that due to complications with trying
    to redact any personal information which may have slipped into the public portion
    of the dataset. As for it being enough, we noted that the section that was marked
    as public had more data than the section that was marked as private. For all intents
    and purposes, it should be enough to realistically train any LLM to handle Pyg-style
    roleplaying.
  created_at: 2023-04-22 13:53:57+00:00
  edited: true
  hidden: false
  id: 6443f505c63001ae6350cb07
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6251b9851842c08ef3111c4f/JLiEuSvejrcCruYmnRV4-.jpeg?w=200&h=200&f=face
      fullname: Taco
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Crataco
      type: user
    createdAt: '2023-04-22T15:50:54.000Z'
    data:
      edited: true
      editors:
      - Crataco
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6251b9851842c08ef3111c4f/JLiEuSvejrcCruYmnRV4-.jpeg?w=200&h=200&f=face
          fullname: Taco
          isHf: false
          isPro: false
          name: Crataco
          type: user
        html: "<p><strong>DISCLAIMER:</strong> I'm unaffiliated with this project,\
          \ but wanted to provide my two cents.</p>\n<p><span data-props=\"{&quot;user&quot;:&quot;TearGosling&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TearGosling\"\
          >@<span class=\"underline\">TearGosling</span></a></span>\n\n\t</span></span>,\
          \ I've been watching this thread for the past week. Thank you for responding;\
          \ I appreciate the clarification. I do hope the public dataset used to train\
          \ Pygmalion is released sooner or later (it doesn't have to be now, of course!).\
          \ Pygmalion development seems relatively slow compared to the pacing of\
          \ the rest of the AI world. Its data would be a great opportunity to train\
          \ LoRAs on not only the recent models (Pythia Deduped, LLaMA), but also\
          \ the newer ones once they're finished (StableLM, RedPajama).</p>\n<p>***</p>\n\
          <blockquote>\n<p>Why only a portion??? [...] It just feels like you're keeping\
          \ the dataset to yourself</p>\n</blockquote>\n<p><del><span data-props=\"\
          {&quot;user&quot;:&quot;RazielAU&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/RazielAU\">@<span class=\"underline\">RazielAU</span></a></span>\n\
          \n\t</span></span>, when you contribute chatlogs to the Pygmalion project,\
          \ you have the option to choose whether or not they are included in the\
          \ \"public dataset\" or remain private and only for use with the Pygmalion\
          \ project, which may be what they were referring to by a portion of the\
          \ community contributions. <a rel=\"nofollow\" href=\"https://dump.nopanda.io/\"\
          >See here.</a></del> I didn't see TearGosling's most recent response while\
          \ typing this, but they've confirmed this.</p>\n<blockquote>\n<p>You either\
          \ have a really good LLM, or an LLM that is fine-tuned for role-playing,\
          \ not both</p>\n</blockquote>\n<p>According to its model card, Pygmalion\
          \ 6B is a finetuned GPT-J 6B with a high-quality dataset, so the latter.\
          \ They have a <a rel=\"nofollow\" href=\"https://github.com/PygmalionAI/data-toolbox\"\
          >data toolbox</a>, and their logbooks clarify when certain datasets are\
          \ added to the model <a rel=\"nofollow\" href=\"https://github.com/PygmalionAI/logbooks/blob/master/2023-01-11.md\"\
          >(example)</a>. Their transparency can be easily disregarded, but it does\
          \ exist.</p>\n<p>Also, theorizing as to why they haven't released it yet\
          \ (which is confirmed to be because of privacy), similar chat models were\
          \ released in the past. <a rel=\"nofollow\" href=\"https://old.reddit.com/r/learnmachinelearning/comments/tewumv/i_developed_conditional_responding_discord/\"\
          >c1-6B</a> and its successor <a rel=\"nofollow\" href=\"https://cdn.discordapp.com/attachments/1092245228028706867/1099353478796689448/Screenshot_2023-04-22_08-17-57.png\"\
          >convo-6B</a> -- also trained on top of GPT-J 6B, with the latter also having\
          \ its own data toolbox -- predate Pygmalion, but were later taken down due\
          \ to privacy concerns <a rel=\"nofollow\" href=\"https://cdn.discordapp.com/attachments/1092245228028706867/1099354865672667176/Screenshot_2023-04-22_08-23-32.png\"\
          >(source)</a>.</p>\n<p>With that said, I do wish you the best of luck with\
          \ your Pygmalion-inspired dataset project. The more open solutions we have,\
          \ the merrier.</p>\n"
        raw: '**DISCLAIMER:** I''m unaffiliated with this project, but wanted to provide
          my two cents.


          @TearGosling, I''ve been watching this thread for the past week. Thank you
          for responding; I appreciate the clarification. I do hope the public dataset
          used to train Pygmalion is released sooner or later (it doesn''t have to
          be now, of course!). Pygmalion development seems relatively slow compared
          to the pacing of the rest of the AI world. Its data would be a great opportunity
          to train LoRAs on not only the recent models (Pythia Deduped, LLaMA), but
          also the newer ones once they''re finished (StableLM, RedPajama).


          \*\*\*


          > Why only a portion??? [...] It just feels like you''re keeping the dataset
          to yourself


          ~~@RazielAU, when you contribute chatlogs to the Pygmalion project, you
          have the option to choose whether or not they are included in the "public
          dataset" or remain private and only for use with the Pygmalion project,
          which may be what they were referring to by a portion of the community contributions.
          [See here.](https://dump.nopanda.io/)~~ I didn''t see TearGosling''s most
          recent response while typing this, but they''ve confirmed this.


          > You either have a really good LLM, or an LLM that is fine-tuned for role-playing,
          not both


          According to its model card, Pygmalion 6B is a finetuned GPT-J 6B with a
          high-quality dataset, so the latter. They have a [data toolbox](https://github.com/PygmalionAI/data-toolbox),
          and their logbooks clarify when certain datasets are added to the model
          [(example)](https://github.com/PygmalionAI/logbooks/blob/master/2023-01-11.md).
          Their transparency can be easily disregarded, but it does exist.


          Also, theorizing as to why they haven''t released it yet (which is confirmed
          to be because of privacy), similar chat models were released in the past.
          [c1-6B](https://old.reddit.com/r/learnmachinelearning/comments/tewumv/i_developed_conditional_responding_discord/)
          and its successor [convo-6B](https://cdn.discordapp.com/attachments/1092245228028706867/1099353478796689448/Screenshot_2023-04-22_08-17-57.png)
          -- also trained on top of GPT-J 6B, with the latter also having its own
          data toolbox -- predate Pygmalion, but were later taken down due to privacy
          concerns [(source)](https://cdn.discordapp.com/attachments/1092245228028706867/1099354865672667176/Screenshot_2023-04-22_08-23-32.png).


          With that said, I do wish you the best of luck with your Pygmalion-inspired
          dataset project. The more open solutions we have, the merrier.'
        updatedAt: '2023-04-22T15:57:20.175Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - RazielAU
    id: 6444025e8f795c936d00fea8
    type: comment
  author: Crataco
  content: '**DISCLAIMER:** I''m unaffiliated with this project, but wanted to provide
    my two cents.


    @TearGosling, I''ve been watching this thread for the past week. Thank you for
    responding; I appreciate the clarification. I do hope the public dataset used
    to train Pygmalion is released sooner or later (it doesn''t have to be now, of
    course!). Pygmalion development seems relatively slow compared to the pacing of
    the rest of the AI world. Its data would be a great opportunity to train LoRAs
    on not only the recent models (Pythia Deduped, LLaMA), but also the newer ones
    once they''re finished (StableLM, RedPajama).


    \*\*\*


    > Why only a portion??? [...] It just feels like you''re keeping the dataset to
    yourself


    ~~@RazielAU, when you contribute chatlogs to the Pygmalion project, you have the
    option to choose whether or not they are included in the "public dataset" or remain
    private and only for use with the Pygmalion project, which may be what they were
    referring to by a portion of the community contributions. [See here.](https://dump.nopanda.io/)~~
    I didn''t see TearGosling''s most recent response while typing this, but they''ve
    confirmed this.


    > You either have a really good LLM, or an LLM that is fine-tuned for role-playing,
    not both


    According to its model card, Pygmalion 6B is a finetuned GPT-J 6B with a high-quality
    dataset, so the latter. They have a [data toolbox](https://github.com/PygmalionAI/data-toolbox),
    and their logbooks clarify when certain datasets are added to the model [(example)](https://github.com/PygmalionAI/logbooks/blob/master/2023-01-11.md).
    Their transparency can be easily disregarded, but it does exist.


    Also, theorizing as to why they haven''t released it yet (which is confirmed to
    be because of privacy), similar chat models were released in the past. [c1-6B](https://old.reddit.com/r/learnmachinelearning/comments/tewumv/i_developed_conditional_responding_discord/)
    and its successor [convo-6B](https://cdn.discordapp.com/attachments/1092245228028706867/1099353478796689448/Screenshot_2023-04-22_08-17-57.png)
    -- also trained on top of GPT-J 6B, with the latter also having its own data toolbox
    -- predate Pygmalion, but were later taken down due to privacy concerns [(source)](https://cdn.discordapp.com/attachments/1092245228028706867/1099354865672667176/Screenshot_2023-04-22_08-23-32.png).


    With that said, I do wish you the best of luck with your Pygmalion-inspired dataset
    project. The more open solutions we have, the merrier.'
  created_at: 2023-04-22 14:50:54+00:00
  edited: true
  hidden: false
  id: 6444025e8f795c936d00fea8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/612aa89fa431d67a04818e1ac312bcec.svg
      fullname: Francois Grobbelaar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RazielAU
      type: user
    createdAt: '2023-04-22T16:05:12.000Z'
    data:
      edited: true
      editors:
      - RazielAU
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/612aa89fa431d67a04818e1ac312bcec.svg
          fullname: Francois Grobbelaar
          isHf: false
          isPro: false
          name: RazielAU
          type: user
        html: "<p>TearGosling, Okay, that makes sense, nothing to do but wait then.</p>\n\
          <p>As for which LLMs I'm rooting for, I honestly think you guys should consider\
          \ a Flan-T5-XXL (11B) fine-tune, it seems really capable and Google released\
          \ it under a very permissive license (Apache 2.0). More work is needed on\
          \ the Oobabooga side to support it, but if push comes to shove I'm sure\
          \ it wouldn't be too hard to add. I messed around with some example code\
          \ to see what it can do and it seemed really good.</p>\n<p>And thanks <span\
          \ data-props=\"{&quot;user&quot;:&quot;Merry&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/Merry\">@<span class=\"underline\"\
          >Merry</span></a></span>\n\n\t</span></span> for your insights as well.\
          \ Based on what TearGosling is saying it sounds like they'll release enough\
          \ so people can fine tune other LLMs, I'm happy with that, it's all I really\
          \ want. LLMs are advancing at a rapid pace, and it's really the lack of\
          \ a good dataset that is currently limiting people from experimenting.</p>\n"
        raw: 'TearGosling, Okay, that makes sense, nothing to do but wait then.


          As for which LLMs I''m rooting for, I honestly think you guys should consider
          a Flan-T5-XXL (11B) fine-tune, it seems really capable and Google released
          it under a very permissive license (Apache 2.0). More work is needed on
          the Oobabooga side to support it, but if push comes to shove I''m sure it
          wouldn''t be too hard to add. I messed around with some example code to
          see what it can do and it seemed really good.


          And thanks @Merry for your insights as well. Based on what TearGosling is
          saying it sounds like they''ll release enough so people can fine tune other
          LLMs, I''m happy with that, it''s all I really want. LLMs are advancing
          at a rapid pace, and it''s really the lack of a good dataset that is currently
          limiting people from experimenting.'
        updatedAt: '2023-04-22T16:16:57.561Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Crataco
    id: 644405b85298d19c9cffcd90
    type: comment
  author: RazielAU
  content: 'TearGosling, Okay, that makes sense, nothing to do but wait then.


    As for which LLMs I''m rooting for, I honestly think you guys should consider
    a Flan-T5-XXL (11B) fine-tune, it seems really capable and Google released it
    under a very permissive license (Apache 2.0). More work is needed on the Oobabooga
    side to support it, but if push comes to shove I''m sure it wouldn''t be too hard
    to add. I messed around with some example code to see what it can do and it seemed
    really good.


    And thanks @Merry for your insights as well. Based on what TearGosling is saying
    it sounds like they''ll release enough so people can fine tune other LLMs, I''m
    happy with that, it''s all I really want. LLMs are advancing at a rapid pace,
    and it''s really the lack of a good dataset that is currently limiting people
    from experimenting.'
  created_at: 2023-04-22 15:05:12+00:00
  edited: true
  hidden: false
  id: 644405b85298d19c9cffcd90
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6251b9851842c08ef3111c4f/JLiEuSvejrcCruYmnRV4-.jpeg?w=200&h=200&f=face
      fullname: Taco
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Crataco
      type: user
    createdAt: '2023-04-22T16:06:24.000Z'
    data:
      edited: false
      editors:
      - Crataco
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6251b9851842c08ef3111c4f/JLiEuSvejrcCruYmnRV4-.jpeg?w=200&h=200&f=face
          fullname: Taco
          isHf: false
          isPro: false
          name: Crataco
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;TearGosling&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TearGosling\"\
          >@<span class=\"underline\">TearGosling</span></a></span>\n\n\t</span></span>,</p>\n\
          <blockquote>\n<p>As for \"when\", we sadly can't give a date on that due\
          \ to complications with trying to redact any personal information which\
          \ may have slipped into the public portion of the dataset. As for it being\
          \ enough, we noted that the section that was marked as public had more data\
          \ than the section that was marked as private.</p>\n</blockquote>\n<p>If\
          \ it helps, I've noticed something on the website people use to contribute\
          \ their chatlogs: <a rel=\"nofollow\" href=\"https://dump.nopanda.io/\"\
          >https://dump.nopanda.io/</a></p>\n<p>The option to contribute to the public\
          \ dataset is selected by default on my end, and I have to opt-out. This\
          \ had also led to me uploading a roleplay to the public dataset by mistake.\
          \ I'm led to believe many people didn't read the data usage agreement, or\
          \ thought they were better off not touching the options.</p>\n<p>I think\
          \ it'd be a good idea to set the private dataset to be the default setting,\
          \ with the public dataset being opt-in. With Pygmalion being a pretty popular\
          \ project, I don't think you'll have any trouble starting a new dataset\
          \ with this.</p>\n"
        raw: 'Hey @TearGosling,


          > As for "when", we sadly can''t give a date on that due to complications
          with trying to redact any personal information which may have slipped into
          the public portion of the dataset. As for it being enough, we noted that
          the section that was marked as public had more data than the section that
          was marked as private.


          If it helps, I''ve noticed something on the website people use to contribute
          their chatlogs: https://dump.nopanda.io/


          The option to contribute to the public dataset is selected by default on
          my end, and I have to opt-out. This had also led to me uploading a roleplay
          to the public dataset by mistake. I''m led to believe many people didn''t
          read the data usage agreement, or thought they were better off not touching
          the options.


          I think it''d be a good idea to set the private dataset to be the default
          setting, with the public dataset being opt-in. With Pygmalion being a pretty
          popular project, I don''t think you''ll have any trouble starting a new
          dataset with this.'
        updatedAt: '2023-04-22T16:06:24.841Z'
      numEdits: 0
      reactions: []
    id: 644406003dc28377632dcdb6
    type: comment
  author: Crataco
  content: 'Hey @TearGosling,


    > As for "when", we sadly can''t give a date on that due to complications with
    trying to redact any personal information which may have slipped into the public
    portion of the dataset. As for it being enough, we noted that the section that
    was marked as public had more data than the section that was marked as private.


    If it helps, I''ve noticed something on the website people use to contribute their
    chatlogs: https://dump.nopanda.io/


    The option to contribute to the public dataset is selected by default on my end,
    and I have to opt-out. This had also led to me uploading a roleplay to the public
    dataset by mistake. I''m led to believe many people didn''t read the data usage
    agreement, or thought they were better off not touching the options.


    I think it''d be a good idea to set the private dataset to be the default setting,
    with the public dataset being opt-in. With Pygmalion being a pretty popular project,
    I don''t think you''ll have any trouble starting a new dataset with this.'
  created_at: 2023-04-22 15:06:24+00:00
  edited: false
  hidden: false
  id: 644406003dc28377632dcdb6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9214712eea954e552c204296941d9da7.svg
      fullname: '0x000011b'
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: 11b
      type: user
    createdAt: '2023-04-22T16:54:09.000Z'
    data:
      edited: false
      editors:
      - 11b
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9214712eea954e552c204296941d9da7.svg
          fullname: '0x000011b'
          isHf: false
          isPro: false
          name: 11b
          type: user
        html: "<p>Hey, main developer chiming in to clarify a few points. The basic\
          \ rundown is:</p>\n<p>We do intend to release all the data <em>where the\
          \ contributor has given us their consent to do so</em>. I am not going to\
          \ leak people's private conversations, hence <span data-props=\"{&quot;user&quot;:&quot;TearGosling&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TearGosling\"\
          >@<span class=\"underline\">TearGosling</span></a></span>\n\n\t</span></span>'s\
          \ comment mentioning that we're only going to be releasing a portion of\
          \ it.</p>\n<p>The reason I haven't rushed to do this however, is because\
          \ in the userscript I wrote to actually generate the JSON files that people\
          \ are contributing, I promised that their personal information was being\
          \ redacted (username, display name, email and so on). As with all things\
          \ in the software world though, there were a significant amount of edge\
          \ cases I did not anticipate, and so PII is present in the dataset despite\
          \ my efforts.</p>\n<p>This has understandably resulted in some people being\
          \ upset, and several have directly reached out to me asking for their contributions\
          \ to be removed from the public set. And these are just the people that\
          \ actually took the time to read the data usage agreement, understand its\
          \ implications, then scan their submissions to realize that this had happened.\
          \ I am very certain that a significant portion of people fall under the\
          \ category that <span data-props=\"{&quot;user&quot;:&quot;Merry&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Merry\"\
          >@<span class=\"underline\">Merry</span></a></span>\n\n\t</span></span>\
          \ described above, which is:</p>\n<blockquote>\n<p>The option to contribute\
          \ to the public dataset is selected by default on my end, and I have to\
          \ opt-out. This had also led to me uploading a roleplay to the public dataset\
          \ by mistake. I'm led to believe many people didn't read the data usage\
          \ agreement</p>\n</blockquote>\n<p>That being the case, I think it'd be\
          \ very irresponsible on my end to just dump the data as-is out to for the\
          \ whole internet to scrape and index, because there's no going back from\
          \ that if I end up harming anyone's privacy. Still, I think a lot of conversational\
          \ datasets out there are very low quality and releasing our set would be\
          \ a massive plus to the general community around open chat models, so what\
          \ I've been trying to do is further redact any PII that I missed before\
          \ releasing anything. The problem I'm having is that if I'm too strict,\
          \ there are too many false negatives and the data is not usable for training.\
          \ If I'm too lax, I'm leaking PII anyways.</p>\n<p>I'm working on this but\
          \ have no ETA because this is not my job. I'm not paid to do this. We all\
          \ do it for free on our spare time. Hell, multiple companies actually <em>profit\
          \ off of our free work</em> by charging people to use our models. If my\
          \ intent was to avoid competition I'd be sticking restrictive licenses on\
          \ everything, or not even releasing anything to the public at all. So the\
          \ fact that accusations like</p>\n<blockquote>\n<p>It just feels like you're\
          \ keeping the dataset to yourself so no one else can produce a competing\
          \ model</p>\n</blockquote>\n<p>Keep getting thrown against us despite how\
          \ open we try to be about everything is pretty discouraging.</p>\n<hr>\n\
          <p>Also since I'm already here, I might as well respond to a few points:</p>\n\
          <blockquote>\n<p>I think it'd be a good idea to set the private dataset\
          \ to be the default setting, with the public dataset being opt-in. With\
          \ Pygmalion being a pretty popular project, I don't think you'll have any\
          \ trouble starting a new dataset with this.</p>\n</blockquote>\n<p>At this\
          \ point I'm not adding any new contributions to our training set. CAI has\
          \ made changes to their front-end that broke my userscript, so anything\
          \ coming in nowadays is unusable. I also don't think starting from scratch\
          \ is the right move - I think just being very careful about PII before releasing\
          \ the existing set is enough. It's unfortunate that some people refused\
          \ to read the data usage consent agreement (which is literally a couple\
          \ of sentences) and accidentally contributed to the wrong set, but I don't\
          \ think that's enough reason to hold back everyone else's contributions.</p>\n\
          <blockquote>\n<p>As for which LLMs I'm rooting for, I honestly think you\
          \ guys should consider a Flan-T5-XXL (11B) fine-tune, it seems really capable\
          \ and Google released it under a very permissive license (Apache 2.0). </p>\n\
          </blockquote>\n<p>I've considered it! Unfortunately, it has an absolutely\
          \ tiny context window which is horrible for long-form chatting. The only\
          \ Flan with a decent context window is the 20B one, and not only is that\
          \ model big enough that a lot of people won't be able to use it at all,\
          \ but it's an encoder-decoder arch which means it doesn't work with Kobold,\
          \ ooga and a lot of other platforms people use.</p>\n<p>As for the \"better\
          \ LLMs\" you've mentioned on your first message: OPT has a restrictive license\
          \ which doesn't fit with the project's ideals of open and freely usable\
          \ models, BLOOM and Pythia have better equivalents depending on their sizes,\
          \ and as per the model's license I cannot release a LLaMA fine-tune. Stability's\
          \ model is atrocious, so I'm currently waiting on RedPajama to see if they\
          \ can release something competitive. If they can, releasing a RedPajama-based\
          \ Pyg model will be on my list of TODOs.</p>\n"
        raw: "Hey, main developer chiming in to clarify a few points. The basic rundown\
          \ is:\n\nWe do intend to release all the data _where the contributor has\
          \ given us their consent to do so_. I am not going to leak people's private\
          \ conversations, hence @TearGosling's comment mentioning that we're only\
          \ going to be releasing a portion of it.\n\nThe reason I haven't rushed\
          \ to do this however, is because in the userscript I wrote to actually generate\
          \ the JSON files that people are contributing, I promised that their personal\
          \ information was being redacted (username, display name, email and so on).\
          \ As with all things in the software world though, there were a significant\
          \ amount of edge cases I did not anticipate, and so PII is present in the\
          \ dataset despite my efforts.\n\nThis has understandably resulted in some\
          \ people being upset, and several have directly reached out to me asking\
          \ for their contributions to be removed from the public set. And these are\
          \ just the people that actually took the time to read the data usage agreement,\
          \ understand its implications, then scan their submissions to realize that\
          \ this had happened. I am very certain that a significant portion of people\
          \ fall under the category that @Merry described above, which is:\n\n> The\
          \ option to contribute to the public dataset is selected by default on my\
          \ end, and I have to opt-out. This had also led to me uploading a roleplay\
          \ to the public dataset by mistake. I'm led to believe many people didn't\
          \ read the data usage agreement\n\nThat being the case, I think it'd be\
          \ very irresponsible on my end to just dump the data as-is out to for the\
          \ whole internet to scrape and index, because there's no going back from\
          \ that if I end up harming anyone's privacy. Still, I think a lot of conversational\
          \ datasets out there are very low quality and releasing our set would be\
          \ a massive plus to the general community around open chat models, so what\
          \ I've been trying to do is further redact any PII that I missed before\
          \ releasing anything. The problem I'm having is that if I'm too strict,\
          \ there are too many false negatives and the data is not usable for training.\
          \ If I'm too lax, I'm leaking PII anyways.\n\nI'm working on this but have\
          \ no ETA because this is not my job. I'm not paid to do this. We all do\
          \ it for free on our spare time. Hell, multiple companies actually _profit\
          \ off of our free work_ by charging people to use our models. If my intent\
          \ was to avoid competition I'd be sticking restrictive licenses on everything,\
          \ or not even releasing anything to the public at all. So the fact that\
          \ accusations like\n\n> It just feels like you're keeping the dataset to\
          \ yourself so no one else can produce a competing model\n\nKeep getting\
          \ thrown against us despite how open we try to be about everything is pretty\
          \ discouraging.\n\n---\n\nAlso since I'm already here, I might as well respond\
          \ to a few points:\n\n> I think it'd be a good idea to set the private dataset\
          \ to be the default setting, with the public dataset being opt-in. With\
          \ Pygmalion being a pretty popular project, I don't think you'll have any\
          \ trouble starting a new dataset with this.\n\nAt this point I'm not adding\
          \ any new contributions to our training set. CAI has made changes to their\
          \ front-end that broke my userscript, so anything coming in nowadays is\
          \ unusable. I also don't think starting from scratch is the right move -\
          \ I think just being very careful about PII before releasing the existing\
          \ set is enough. It's unfortunate that some people refused to read the data\
          \ usage consent agreement (which is literally a couple of sentences) and\
          \ accidentally contributed to the wrong set, but I don't think that's enough\
          \ reason to hold back everyone else's contributions.\n\n> As for which LLMs\
          \ I'm rooting for, I honestly think you guys should consider a Flan-T5-XXL\
          \ (11B) fine-tune, it seems really capable and Google released it under\
          \ a very permissive license (Apache 2.0). \n\nI've considered it! Unfortunately,\
          \ it has an absolutely tiny context window which is horrible for long-form\
          \ chatting. The only Flan with a decent context window is the 20B one, and\
          \ not only is that model big enough that a lot of people won't be able to\
          \ use it at all, but it's an encoder-decoder arch which means it doesn't\
          \ work with Kobold, ooga and a lot of other platforms people use.\n\nAs\
          \ for the \"better LLMs\" you've mentioned on your first message: OPT has\
          \ a restrictive license which doesn't fit with the project's ideals of open\
          \ and freely usable models, BLOOM and Pythia have better equivalents depending\
          \ on their sizes, and as per the model's license I cannot release a LLaMA\
          \ fine-tune. Stability's model is atrocious, so I'm currently waiting on\
          \ RedPajama to see if they can release something competitive. If they can,\
          \ releasing a RedPajama-based Pyg model will be on my list of TODOs."
        updatedAt: '2023-04-22T16:54:09.646Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - Crataco
        - TearGosling
        - RazielAU
        - nacs
      - count: 4
        reaction: "\u2764\uFE0F"
        users:
        - Crataco
        - TearGosling
        - RazielAU
        - SlytheeTove
    id: 644411315298d19c9c008692
    type: comment
  author: 11b
  content: "Hey, main developer chiming in to clarify a few points. The basic rundown\
    \ is:\n\nWe do intend to release all the data _where the contributor has given\
    \ us their consent to do so_. I am not going to leak people's private conversations,\
    \ hence @TearGosling's comment mentioning that we're only going to be releasing\
    \ a portion of it.\n\nThe reason I haven't rushed to do this however, is because\
    \ in the userscript I wrote to actually generate the JSON files that people are\
    \ contributing, I promised that their personal information was being redacted\
    \ (username, display name, email and so on). As with all things in the software\
    \ world though, there were a significant amount of edge cases I did not anticipate,\
    \ and so PII is present in the dataset despite my efforts.\n\nThis has understandably\
    \ resulted in some people being upset, and several have directly reached out to\
    \ me asking for their contributions to be removed from the public set. And these\
    \ are just the people that actually took the time to read the data usage agreement,\
    \ understand its implications, then scan their submissions to realize that this\
    \ had happened. I am very certain that a significant portion of people fall under\
    \ the category that @Merry described above, which is:\n\n> The option to contribute\
    \ to the public dataset is selected by default on my end, and I have to opt-out.\
    \ This had also led to me uploading a roleplay to the public dataset by mistake.\
    \ I'm led to believe many people didn't read the data usage agreement\n\nThat\
    \ being the case, I think it'd be very irresponsible on my end to just dump the\
    \ data as-is out to for the whole internet to scrape and index, because there's\
    \ no going back from that if I end up harming anyone's privacy. Still, I think\
    \ a lot of conversational datasets out there are very low quality and releasing\
    \ our set would be a massive plus to the general community around open chat models,\
    \ so what I've been trying to do is further redact any PII that I missed before\
    \ releasing anything. The problem I'm having is that if I'm too strict, there\
    \ are too many false negatives and the data is not usable for training. If I'm\
    \ too lax, I'm leaking PII anyways.\n\nI'm working on this but have no ETA because\
    \ this is not my job. I'm not paid to do this. We all do it for free on our spare\
    \ time. Hell, multiple companies actually _profit off of our free work_ by charging\
    \ people to use our models. If my intent was to avoid competition I'd be sticking\
    \ restrictive licenses on everything, or not even releasing anything to the public\
    \ at all. So the fact that accusations like\n\n> It just feels like you're keeping\
    \ the dataset to yourself so no one else can produce a competing model\n\nKeep\
    \ getting thrown against us despite how open we try to be about everything is\
    \ pretty discouraging.\n\n---\n\nAlso since I'm already here, I might as well\
    \ respond to a few points:\n\n> I think it'd be a good idea to set the private\
    \ dataset to be the default setting, with the public dataset being opt-in. With\
    \ Pygmalion being a pretty popular project, I don't think you'll have any trouble\
    \ starting a new dataset with this.\n\nAt this point I'm not adding any new contributions\
    \ to our training set. CAI has made changes to their front-end that broke my userscript,\
    \ so anything coming in nowadays is unusable. I also don't think starting from\
    \ scratch is the right move - I think just being very careful about PII before\
    \ releasing the existing set is enough. It's unfortunate that some people refused\
    \ to read the data usage consent agreement (which is literally a couple of sentences)\
    \ and accidentally contributed to the wrong set, but I don't think that's enough\
    \ reason to hold back everyone else's contributions.\n\n> As for which LLMs I'm\
    \ rooting for, I honestly think you guys should consider a Flan-T5-XXL (11B) fine-tune,\
    \ it seems really capable and Google released it under a very permissive license\
    \ (Apache 2.0). \n\nI've considered it! Unfortunately, it has an absolutely tiny\
    \ context window which is horrible for long-form chatting. The only Flan with\
    \ a decent context window is the 20B one, and not only is that model big enough\
    \ that a lot of people won't be able to use it at all, but it's an encoder-decoder\
    \ arch which means it doesn't work with Kobold, ooga and a lot of other platforms\
    \ people use.\n\nAs for the \"better LLMs\" you've mentioned on your first message:\
    \ OPT has a restrictive license which doesn't fit with the project's ideals of\
    \ open and freely usable models, BLOOM and Pythia have better equivalents depending\
    \ on their sizes, and as per the model's license I cannot release a LLaMA fine-tune.\
    \ Stability's model is atrocious, so I'm currently waiting on RedPajama to see\
    \ if they can release something competitive. If they can, releasing a RedPajama-based\
    \ Pyg model will be on my list of TODOs."
  created_at: 2023-04-22 15:54:09+00:00
  edited: false
  hidden: false
  id: 644411315298d19c9c008692
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/612aa89fa431d67a04818e1ac312bcec.svg
      fullname: Francois Grobbelaar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RazielAU
      type: user
    createdAt: '2023-04-23T02:45:42.000Z'
    data:
      edited: true
      editors:
      - RazielAU
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/612aa89fa431d67a04818e1ac312bcec.svg
          fullname: Francois Grobbelaar
          isHf: false
          isPro: false
          name: RazielAU
          type: user
        html: "<p>Thanks for your response <span data-props=\"{&quot;user&quot;:&quot;11b&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/11b\"\
          >@<span class=\"underline\">11b</span></a></span>\n\n\t</span></span>, I\
          \ didn't realise the context on the normal T5 was so small, there is Long\
          \ T5 as well which has a context size up to 16k, but that I think that maxes\
          \ out at 3B in terms of size and I'm not sure those models have been FLAN'd,\
          \ but that might be a good or bad thing depending on how you look at it\
          \ since it means you could fine-tune it specifically for roleplaying -&gt;\
          \ <a href=\"https://huggingface.co/google/long-t5-tglobal-xl\">https://huggingface.co/google/long-t5-tglobal-xl</a></p>\n\
          <p>In terms of LLaMA, of all the language models I've tried, it's definitely\
          \ the best, the issue I see though is that, even IF Facebook decides to\
          \ release it officially, it's going to be released under the same license\
          \ as OPT. So, are you still going to train it in that case? As for releasing\
          \ a LLaMA fine-tune, so far it hasn't really been a problem for projects\
          \ as people have been releasing their fine-tunes as a diffs or LoRAs so\
          \ they don't include the original weights. If the project ever does get\
          \ to the point where a LLaMA based version is trained, I would suggest starting\
          \ from one of the existing fine-tunes, LLaMA on it's own is like T5 on its\
          \ own, it needs a bit more training to really wake it up and start getting\
          \ amazing results.</p>\n"
        raw: 'Thanks for your response @11b, I didn''t realise the context on the
          normal T5 was so small, there is Long T5 as well which has a context size
          up to 16k, but that I think that maxes out at 3B in terms of size and I''m
          not sure those models have been FLAN''d, but that might be a good or bad
          thing depending on how you look at it since it means you could fine-tune
          it specifically for roleplaying -> https://huggingface.co/google/long-t5-tglobal-xl


          In terms of LLaMA, of all the language models I''ve tried, it''s definitely
          the best, the issue I see though is that, even IF Facebook decides to release
          it officially, it''s going to be released under the same license as OPT.
          So, are you still going to train it in that case? As for releasing a LLaMA
          fine-tune, so far it hasn''t really been a problem for projects as people
          have been releasing their fine-tunes as a diffs or LoRAs so they don''t
          include the original weights. If the project ever does get to the point
          where a LLaMA based version is trained, I would suggest starting from one
          of the existing fine-tunes, LLaMA on it''s own is like T5 on its own, it
          needs a bit more training to really wake it up and start getting amazing
          results.'
        updatedAt: '2023-04-23T03:51:05.635Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - tomsaccount
    id: 64449bd65298d19c9c0923e8
    type: comment
  author: RazielAU
  content: 'Thanks for your response @11b, I didn''t realise the context on the normal
    T5 was so small, there is Long T5 as well which has a context size up to 16k,
    but that I think that maxes out at 3B in terms of size and I''m not sure those
    models have been FLAN''d, but that might be a good or bad thing depending on how
    you look at it since it means you could fine-tune it specifically for roleplaying
    -> https://huggingface.co/google/long-t5-tglobal-xl


    In terms of LLaMA, of all the language models I''ve tried, it''s definitely the
    best, the issue I see though is that, even IF Facebook decides to release it officially,
    it''s going to be released under the same license as OPT. So, are you still going
    to train it in that case? As for releasing a LLaMA fine-tune, so far it hasn''t
    really been a problem for projects as people have been releasing their fine-tunes
    as a diffs or LoRAs so they don''t include the original weights. If the project
    ever does get to the point where a LLaMA based version is trained, I would suggest
    starting from one of the existing fine-tunes, LLaMA on it''s own is like T5 on
    its own, it needs a bit more training to really wake it up and start getting amazing
    results.'
  created_at: 2023-04-23 01:45:42+00:00
  edited: true
  hidden: false
  id: 64449bd65298d19c9c0923e8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b5567044d00af3a82811e9b40a707005.svg
      fullname: Tom Flynn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomsaccount
      type: user
    createdAt: '2023-04-23T21:15:05.000Z'
    data:
      edited: true
      editors:
      - tomsaccount
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b5567044d00af3a82811e9b40a707005.svg
          fullname: Tom Flynn
          isHf: false
          isPro: false
          name: tomsaccount
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;11b&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/11b\">@<span class=\"\
          underline\">11b</span></a></span>\n\n\t</span></span> I understand you don't\
          \ want to publicly release the dataset due to privacy concerns, and this\
          \ isn't your full-time job, but have you considered donating or selling\
          \ the dataset to a trustworthy organization capable of using it for fine-tuning\
          \ newer models?</p>\n<blockquote>\n<p>\"It just feels like you're keeping\
          \ the dataset to yourself so no one else can produce a competing model\"\
          </p>\n</blockquote>\n<blockquote>\n<p>Keep getting thrown against us despite\
          \ how open we try to be about everything is pretty discouraging.</p>\n</blockquote>\n\
          <p>there is a reason this is getting thrown at you, because in effect it's\
          \ true. No one cares about how open you are with your communication, what\
          \ we care about is the dataset. </p>\n<p>From an outsider's perspective:\
          \ you're sitting on an oilfield, you aren't capable of making use of it\
          \ yourself, and you refuse to let anyone else make use of it.</p>\n"
        raw: "@11b I understand you don't want to publicly release the dataset due\
          \ to privacy concerns, and this isn't your full-time job, but have you considered\
          \ donating or selling the dataset to a trustworthy organization capable\
          \ of using it for fine-tuning newer models?\n\n> \"It just feels like you're\
          \ keeping the dataset to yourself so no one else can produce a competing\
          \ model\"\n\n> Keep getting thrown against us despite how open we try to\
          \ be about everything is pretty discouraging.\n\nthere is a reason this\
          \ is getting thrown at you, because in effect it's true. No one cares about\
          \ how open you are with your communication, what we care about is the dataset.\
          \ \n\nFrom an outsider's perspective: you're sitting on an oilfield, you\
          \ aren't capable of making use of it yourself, and you refuse to let anyone\
          \ else make use of it."
        updatedAt: '2023-04-23T21:26:03.735Z'
      numEdits: 4
      reactions: []
    id: 64459fd9d1460e859d222d49
    type: comment
  author: tomsaccount
  content: "@11b I understand you don't want to publicly release the dataset due to\
    \ privacy concerns, and this isn't your full-time job, but have you considered\
    \ donating or selling the dataset to a trustworthy organization capable of using\
    \ it for fine-tuning newer models?\n\n> \"It just feels like you're keeping the\
    \ dataset to yourself so no one else can produce a competing model\"\n\n> Keep\
    \ getting thrown against us despite how open we try to be about everything is\
    \ pretty discouraging.\n\nthere is a reason this is getting thrown at you, because\
    \ in effect it's true. No one cares about how open you are with your communication,\
    \ what we care about is the dataset. \n\nFrom an outsider's perspective: you're\
    \ sitting on an oilfield, you aren't capable of making use of it yourself, and\
    \ you refuse to let anyone else make use of it."
  created_at: 2023-04-23 20:15:05+00:00
  edited: true
  hidden: false
  id: 64459fd9d1460e859d222d49
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9214712eea954e552c204296941d9da7.svg
      fullname: '0x000011b'
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: 11b
      type: user
    createdAt: '2023-04-23T21:34:48.000Z'
    data:
      edited: true
      editors:
      - 11b
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9214712eea954e552c204296941d9da7.svg
          fullname: '0x000011b'
          isHf: false
          isPro: false
          name: 11b
          type: user
        html: '<blockquote>

          <p>I understand you don''t want to publicly release the dataset due to privacy
          concerns, and this isn''t your full-time job, but have you considered donating
          or selling the dataset to a trustworthy organization capable of using it
          for fine-tuning newer models?</p>

          </blockquote>

          <p>Selling? No, I got the data for free so I feel like that''d be an asshole
          move. Donating? Yes, and I''ve already done so to 11 different people who
          have all said they were going to use it to train and release LLaMA/RWKV/whatever
          else-based models. None of them have actually released anything to date.
          And yet, false accusations like:</p>

          <blockquote>

          <p>you''re sitting on an oilfield [...] and you refuse to let anyone else
          make use of it.</p>

          </blockquote>

          <blockquote>

          <p>there is a reason this is getting thrown at you, because in effect it''s
          true.</p>

          </blockquote>

          <p>Keep getting thrown around. Having to defend myself against this over
          and over is a waste of time so I''ll just close this discussion - everything
          that needs to be said from my side has already been said. Hope you understand
          where I''m coming from.</p>

          '
        raw: '> I understand you don''t want to publicly release the dataset due to
          privacy concerns, and this isn''t your full-time job, but have you considered
          donating or selling the dataset to a trustworthy organization capable of
          using it for fine-tuning newer models?


          Selling? No, I got the data for free so I feel like that''d be an asshole
          move. Donating? Yes, and I''ve already done so to 11 different people who
          have all said they were going to use it to train and release LLaMA/RWKV/whatever
          else-based models. None of them have actually released anything to date.
          And yet, false accusations like:


          > you''re sitting on an oilfield [...] and you refuse to let anyone else
          make use of it.


          > there is a reason this is getting thrown at you, because in effect it''s
          true.


          Keep getting thrown around. Having to defend myself against this over and
          over is a waste of time so I''ll just close this discussion - everything
          that needs to be said from my side has already been said. Hope you understand
          where I''m coming from.'
        updatedAt: '2023-04-23T21:36:11.221Z'
      numEdits: 1
      reactions: []
      relatedEventId: 6445a47853ecc52f50f5d590
    id: 6445a47853ecc52f50f5d58f
    type: comment
  author: 11b
  content: '> I understand you don''t want to publicly release the dataset due to
    privacy concerns, and this isn''t your full-time job, but have you considered
    donating or selling the dataset to a trustworthy organization capable of using
    it for fine-tuning newer models?


    Selling? No, I got the data for free so I feel like that''d be an asshole move.
    Donating? Yes, and I''ve already done so to 11 different people who have all said
    they were going to use it to train and release LLaMA/RWKV/whatever else-based
    models. None of them have actually released anything to date. And yet, false accusations
    like:


    > you''re sitting on an oilfield [...] and you refuse to let anyone else make
    use of it.


    > there is a reason this is getting thrown at you, because in effect it''s true.


    Keep getting thrown around. Having to defend myself against this over and over
    is a waste of time so I''ll just close this discussion - everything that needs
    to be said from my side has already been said. Hope you understand where I''m
    coming from.'
  created_at: 2023-04-23 20:34:48+00:00
  edited: true
  hidden: false
  id: 6445a47853ecc52f50f5d58f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9214712eea954e552c204296941d9da7.svg
      fullname: '0x000011b'
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: 11b
      type: user
    createdAt: '2023-04-23T21:34:48.000Z'
    data:
      status: closed
    id: 6445a47853ecc52f50f5d590
    type: status-change
  author: 11b
  created_at: 2023-04-23 20:34:48+00:00
  id: 6445a47853ecc52f50f5d590
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 26
repo_id: PygmalionAI/pygmalion-6b
repo_type: model
status: closed
target_branch: null
title: Training dataset?
