!!python/object:huggingface_hub.community.DiscussionWithDetails
author: LEberdeX
conflicting_files: null
created_at: 2023-01-21 21:05:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5cc976b24300779fb725423212ba6c34.svg
      fullname: Leb Redex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LEberdeX
      type: user
    createdAt: '2023-01-21T21:05:00.000Z'
    data:
      edited: false
      editors:
      - LEberdeX
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5cc976b24300779fb725423212ba6c34.svg
          fullname: Leb Redex
          isHf: false
          isPro: false
          name: LEberdeX
          type: user
        html: '<p>As far as I know, thanks to some optimizations, it works much better
          than the usual GPT-J, and can even be equal to 100b+ models+</p>

          '
        raw: As far as I know, thanks to some optimizations, it works much better
          than the usual GPT-J, and can even be equal to 100b+ models+
        updatedAt: '2023-01-21T21:05:00.226Z'
      numEdits: 0
      reactions: []
    id: 63cc537c6d080f9b7cf9d44e
    type: comment
  author: LEberdeX
  content: As far as I know, thanks to some optimizations, it works much better than
    the usual GPT-J, and can even be equal to 100b+ models+
  created_at: 2023-01-21 21:05:00+00:00
  edited: false
  hidden: false
  id: 63cc537c6d080f9b7cf9d44e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
      fullname: Devon M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delcos
      type: user
    createdAt: '2023-01-21T21:38:23.000Z'
    data:
      edited: false
      editors:
      - Delcos
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
          fullname: Devon M
          isHf: false
          isPro: false
          name: Delcos
          type: user
        html: '<p>You might run into issues because JT is not meant for chatting at
          all, so it may be a step backwards. The best way to move forward would be
          to continue as it is now until you get this version of 6b to the same level
          as JT with different data.</p>

          '
        raw: You might run into issues because JT is not meant for chatting at all,
          so it may be a step backwards. The best way to move forward would be to
          continue as it is now until you get this version of 6b to the same level
          as JT with different data.
        updatedAt: '2023-01-21T21:38:23.112Z'
      numEdits: 0
      reactions: []
    id: 63cc5b4f7b5b4fad6e8fd034
    type: comment
  author: Delcos
  content: You might run into issues because JT is not meant for chatting at all,
    so it may be a step backwards. The best way to move forward would be to continue
    as it is now until you get this version of 6b to the same level as JT with different
    data.
  created_at: 2023-01-21 21:38:23+00:00
  edited: false
  hidden: false
  id: 63cc5b4f7b5b4fad6e8fd034
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
      fullname: Devon M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delcos
      type: user
    createdAt: '2023-01-21T21:39:47.000Z'
    data:
      edited: false
      editors:
      - Delcos
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
          fullname: Devon M
          isHf: false
          isPro: false
          name: Delcos
          type: user
        html: '<p>Also to be clear, I''m not saying JT is bad at all, t''s just not
          good for this usecase.</p>

          '
        raw: Also to be clear, I'm not saying JT is bad at all, t's just not good
          for this usecase.
        updatedAt: '2023-01-21T21:39:47.323Z'
      numEdits: 0
      reactions: []
    id: 63cc5ba345d95948874fa357
    type: comment
  author: Delcos
  content: Also to be clear, I'm not saying JT is bad at all, t's just not good for
    this usecase.
  created_at: 2023-01-21 21:39:47+00:00
  edited: false
  hidden: false
  id: 63cc5ba345d95948874fa357
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5cc976b24300779fb725423212ba6c34.svg
      fullname: Leb Redex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LEberdeX
      type: user
    createdAt: '2023-01-21T21:55:23.000Z'
    data:
      edited: false
      editors:
      - LEberdeX
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5cc976b24300779fb725423212ba6c34.svg
          fullname: Leb Redex
          isHf: false
          isPro: false
          name: LEberdeX
          type: user
        html: '<blockquote>

          <p>Also to be clear, I''m not saying JT is bad at all, t''s just not good
          for this usecase.</p>

          </blockquote>

          <p>Yes, she seems to classify better. Perhaps in text generation she is
          not so good. But in fact, I''m still only studying neural networks, so I
          can be wrong</p>

          '
        raw: '> Also to be clear, I''m not saying JT is bad at all, t''s just not
          good for this usecase.


          Yes, she seems to classify better. Perhaps in text generation she is not
          so good. But in fact, I''m still only studying neural networks, so I can
          be wrong'
        updatedAt: '2023-01-21T21:55:23.071Z'
      numEdits: 0
      reactions: []
    id: 63cc5f4bdf168f678c6856e5
    type: comment
  author: LEberdeX
  content: '> Also to be clear, I''m not saying JT is bad at all, t''s just not good
    for this usecase.


    Yes, she seems to classify better. Perhaps in text generation she is not so good.
    But in fact, I''m still only studying neural networks, so I can be wrong'
  created_at: 2023-01-21 21:55:23+00:00
  edited: false
  hidden: false
  id: 63cc5f4bdf168f678c6856e5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
      fullname: Devon M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Delcos
      type: user
    createdAt: '2023-01-23T04:08:03.000Z'
    data:
      edited: false
      editors:
      - Delcos
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662848908113-6317eee61d6018cb851af5a7.jpeg?w=200&h=200&f=face
          fullname: Devon M
          isHf: false
          isPro: false
          name: Delcos
          type: user
        html: '<p>It preforms far worse in logical and moral puzzles, including most
          cognition tests I''ve preformed. As for anything scientific or practical
          I would choose JT but for a really good chat model that has amazing reasoning
          I''d stay where we are on pygmalion and focus on improving that.</p>

          '
        raw: It preforms far worse in logical and moral puzzles, including most cognition
          tests I've preformed. As for anything scientific or practical I would choose
          JT but for a really good chat model that has amazing reasoning I'd stay
          where we are on pygmalion and focus on improving that.
        updatedAt: '2023-01-23T04:08:03.320Z'
      numEdits: 0
      reactions: []
    id: 63ce0823e75230ae94f2a4c3
    type: comment
  author: Delcos
  content: It preforms far worse in logical and moral puzzles, including most cognition
    tests I've preformed. As for anything scientific or practical I would choose JT
    but for a really good chat model that has amazing reasoning I'd stay where we
    are on pygmalion and focus on improving that.
  created_at: 2023-01-23 04:08:03+00:00
  edited: false
  hidden: false
  id: 63ce0823e75230ae94f2a4c3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9214712eea954e552c204296941d9da7.svg
      fullname: '0x000011b'
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: 11b
      type: user
    createdAt: '2023-01-27T20:44:38.000Z'
    data:
      edited: false
      editors:
      - 11b
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9214712eea954e552c204296941d9da7.svg
          fullname: '0x000011b'
          isHf: false
          isPro: false
          name: 11b
          type: user
        html: '<p>I''ve got an eye on the fine-tuning methods used by JT but:</p>

          <ul>

          <li><p><a href="https://huggingface.co/togethercomputer/GPT-JT-6B-v1/discussions/8">Code
          has not been released</a> and I don''t have time to try re-implementing;
          and</p>

          </li>

          <li><p><a href="https://huggingface.co/togethercomputer/GPT-JT-6B-v1/discussions/20">According
          to the author(s?)</a>, we''re probably better off just focusing on getting
          more/better data instead:</p>

          <blockquote>

          <p>the UL2 training objective also contributes to the overall performance,
          although it should be noted that the improvement from this is relatively
          small (~1%). To summarize, adding more data is often one of the most effective
          ways to improve a specific task. However, once you hit the wall, UL2 can
          also be considered as a potential approach to further improve the performance.</p>

          </blockquote>

          </li>

          </ul>

          <p>That being the case, I have no plans to use anything from JT at the moment.</p>

          '
        raw: "I've got an eye on the fine-tuning methods used by JT but:\n- [Code\
          \ has not been released](https://huggingface.co/togethercomputer/GPT-JT-6B-v1/discussions/8)\
          \ and I don't have time to try re-implementing; and\n- [According to the\
          \ author(s?)](https://huggingface.co/togethercomputer/GPT-JT-6B-v1/discussions/20),\
          \ we're probably better off just focusing on getting more/better data instead:\n\
          \n  > the UL2 training objective also contributes to the overall performance,\
          \ although it should be noted that the improvement from this is relatively\
          \ small (~1%). To summarize, adding more data is often one of the most effective\
          \ ways to improve a specific task. However, once you hit the wall, UL2 can\
          \ also be considered as a potential approach to further improve the performance.\n\
          \nThat being the case, I have no plans to use anything from JT at the moment."
        updatedAt: '2023-01-27T20:44:38.785Z'
      numEdits: 0
      reactions: []
    id: 63d437b6108305eda762c393
    type: comment
  author: 11b
  content: "I've got an eye on the fine-tuning methods used by JT but:\n- [Code has\
    \ not been released](https://huggingface.co/togethercomputer/GPT-JT-6B-v1/discussions/8)\
    \ and I don't have time to try re-implementing; and\n- [According to the author(s?)](https://huggingface.co/togethercomputer/GPT-JT-6B-v1/discussions/20),\
    \ we're probably better off just focusing on getting more/better data instead:\n\
    \n  > the UL2 training objective also contributes to the overall performance,\
    \ although it should be noted that the improvement from this is relatively small\
    \ (~1%). To summarize, adding more data is often one of the most effective ways\
    \ to improve a specific task. However, once you hit the wall, UL2 can also be\
    \ considered as a potential approach to further improve the performance.\n\nThat\
    \ being the case, I have no plans to use anything from JT at the moment."
  created_at: 2023-01-27 20:44:38+00:00
  edited: false
  hidden: false
  id: 63d437b6108305eda762c393
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9214712eea954e552c204296941d9da7.svg
      fullname: '0x000011b'
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: 11b
      type: user
    createdAt: '2023-01-27T20:44:41.000Z'
    data:
      status: closed
    id: 63d437b92424c652f6faf143
    type: status-change
  author: 11b
  created_at: 2023-01-27 20:44:41+00:00
  id: 63d437b92424c652f6faf143
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: PygmalionAI/pygmalion-6b
repo_type: model
status: closed
target_branch: null
title: GPT-JT Model
