!!python/object:huggingface_hub.community.DiscussionWithDetails
author: celsowm
conflicting_files: null
created_at: 2023-12-30 15:58:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a278c3f30c4642278d4259/W0U2_asElVWplHF6sLsDf.png?w=200&h=200&f=face
      fullname: Celso F
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: celsowm
      type: user
    createdAt: '2023-12-30T15:58:53.000Z'
    data:
      edited: false
      editors:
      - celsowm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7587482333183289
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a278c3f30c4642278d4259/W0U2_asElVWplHF6sLsDf.png?w=200&h=200&f=face
          fullname: Celso F
          isHf: false
          isPro: false
          name: celsowm
          type: user
        html: "<p>Hi !<br>I am trying to study some cases of success of DPO training\
          \ and I tried your model:</p>\n<pre><code class=\"language-python\">prompt\
          \ = <span class=\"hljs-string\">\"How to load image here ?\"</span>\nprompt\
          \ = <span class=\"hljs-string\">f\"\"\"&lt;|user|&gt;</span>\n<span class=\"\
          hljs-string\"><span class=\"hljs-subst\">{prompt}</span></span>\n<span class=\"\
          hljs-string\">&lt;|assistant|&gt;</span>\n<span class=\"hljs-string\">\"\
          \"\"</span>\n \ninputs = tokenizer(prompt, return_tensors=<span class=\"\
          hljs-string\">\"pt\"</span>)\ninput_ids = inputs[<span class=\"hljs-string\"\
          >\"input_ids\"</span>].cuda()\ngeneration_output = model.generate(\n   \
          \     input_ids=input_ids,\n        return_dict_in_generate=<span class=\"\
          hljs-literal\">True</span>,\n        output_scores=<span class=\"hljs-literal\"\
          >True</span>,\n        max_length=<span class=\"hljs-number\">752</span>,\n\
          \        pad_token_id=tokenizer.eos_token_id\n    )\n<span class=\"hljs-keyword\"\
          >for</span> s <span class=\"hljs-keyword\">in</span> generation_output.sequences:\n\
          \    output = tokenizer.decode(s)\n    <span class=\"hljs-built_in\">print</span>(output)\n\
          </code></pre>\n<p>I expected something like (<a href=\"https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized/viewer/default/train_prefs?p=2&amp;row=212\"\
          >https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized/viewer/default/train_prefs?p=2&amp;row=212</a>):</p>\n\
          <pre><code>To load an image here, you can follow these simple steps:\\n\\\
          n1. First, you need to upload the image to a file hosting or sharing service\
          \ like Google Drive, Dropbox, or Imgur.\\n\\n2. Once the image is uploaded,\
          \ get the image's URL (web address) from the hosting service.\\n\\n3. In\
          \ your question or response, simply copy the image URL and paste it into\
          \ the text box here. Be sure to select the \\\"image\\\" icon before doing\
          \ so.\\n\\n4. After pasting the URL, the image will automatically appear\
          \ within your question or answer.\\n\\nIf you need further assistance, please\
          \ let me know.\n</code></pre>\n<p>But instead I got:</p>\n<pre><code>&lt;s&gt;\
          \ &lt;|user|&gt;\nHow to load image here ?\n&lt;|assistant|&gt;\nTo load\
          \ an image in a Python script, you can use the `PIL` (Python Imaging Library)\
          \ module. Here's an example of how to load an image using `PIL`:\n\nfrom\
          \ PIL import Image\n\n# Load the image\nimage = Image.open(\"image.jpg\"\
          )\n\n# Display the image\nimage.show()\n\nIn this example, we first import\
          \ the `Image` class from the `PIL` module. We then use the `Image.open()`\
          \ method to load the image from the file \"image.jpg\". Finally, we display\
          \ the image using the `show()` method.\n\nNote that you need to install\
          \ the `PIL` module before you can use it in your Python script. You can\
          \ install it using pip:\n\npip install pillow\n\nAlso, make sure that the\
          \ image file is in the same directory as your Python script or that you\
          \ provide the full path to the image file in the `Image.open()` method.&lt;/s&gt;\n\
          </code></pre>\n<p>Did I do something wrong?</p>\n<p>Thanks in advance !</p>\n"
        raw: "Hi !\r\nI am trying to study some cases of success of DPO training and\
          \ I tried your model:\r\n\r\n```python\r\nprompt = \"How to load image here\
          \ ?\"\r\nprompt = f\"\"\"<|user|>\r\n{prompt}\r\n<|assistant|>\r\n\"\"\"\
          \r\n \r\ninputs = tokenizer(prompt, return_tensors=\"pt\")\r\ninput_ids\
          \ = inputs[\"input_ids\"].cuda()\r\ngeneration_output = model.generate(\r\
          \n        input_ids=input_ids,\r\n        return_dict_in_generate=True,\r\
          \n        output_scores=True,\r\n        max_length=752,\r\n        pad_token_id=tokenizer.eos_token_id\r\
          \n    )\r\nfor s in generation_output.sequences:\r\n    output = tokenizer.decode(s)\r\
          \n    print(output)\r\n```\r\n\r\nI expected something like (https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized/viewer/default/train_prefs?p=2&row=212):\r\
          \n\r\n```\r\nTo load an image here, you can follow these simple steps:\\\
          n\\n1. First, you need to upload the image to a file hosting or sharing\
          \ service like Google Drive, Dropbox, or Imgur.\\n\\n2. Once the image is\
          \ uploaded, get the image's URL (web address) from the hosting service.\\\
          n\\n3. In your question or response, simply copy the image URL and paste\
          \ it into the text box here. Be sure to select the \\\"image\\\" icon before\
          \ doing so.\\n\\n4. After pasting the URL, the image will automatically\
          \ appear within your question or answer.\\n\\nIf you need further assistance,\
          \ please let me know.\r\n```\r\n\r\nBut instead I got:\r\n\r\n```\r\n<s>\
          \ <|user|>\r\nHow to load image here ?\r\n<|assistant|>\r\nTo load an image\
          \ in a Python script, you can use the `PIL` (Python Imaging Library) module.\
          \ Here's an example of how to load an image using `PIL`:\r\n\r\nfrom PIL\
          \ import Image\r\n\r\n# Load the image\r\nimage = Image.open(\"image.jpg\"\
          )\r\n\r\n# Display the image\r\nimage.show()\r\n\r\nIn this example, we\
          \ first import the `Image` class from the `PIL` module. We then use the\
          \ `Image.open()` method to load the image from the file \"image.jpg\". Finally,\
          \ we display the image using the `show()` method.\r\n\r\nNote that you need\
          \ to install the `PIL` module before you can use it in your Python script.\
          \ You can install it using pip:\r\n\r\npip install pillow\r\n\r\nAlso, make\
          \ sure that the image file is in the same directory as your Python script\
          \ or that you provide the full path to the image file in the `Image.open()`\
          \ method.</s>\r\n```\r\n\r\nDid I do something wrong?\r\n\r\nThanks in advance\
          \ !\r\n\r\n"
        updatedAt: '2023-12-30T15:58:53.949Z'
      numEdits: 0
      reactions: []
    id: 65903e3d87944e494e32b891
    type: comment
  author: celsowm
  content: "Hi !\r\nI am trying to study some cases of success of DPO training and\
    \ I tried your model:\r\n\r\n```python\r\nprompt = \"How to load image here ?\"\
    \r\nprompt = f\"\"\"<|user|>\r\n{prompt}\r\n<|assistant|>\r\n\"\"\"\r\n \r\ninputs\
    \ = tokenizer(prompt, return_tensors=\"pt\")\r\ninput_ids = inputs[\"input_ids\"\
    ].cuda()\r\ngeneration_output = model.generate(\r\n        input_ids=input_ids,\r\
    \n        return_dict_in_generate=True,\r\n        output_scores=True,\r\n   \
    \     max_length=752,\r\n        pad_token_id=tokenizer.eos_token_id\r\n    )\r\
    \nfor s in generation_output.sequences:\r\n    output = tokenizer.decode(s)\r\n\
    \    print(output)\r\n```\r\n\r\nI expected something like (https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized/viewer/default/train_prefs?p=2&row=212):\r\
    \n\r\n```\r\nTo load an image here, you can follow these simple steps:\\n\\n1.\
    \ First, you need to upload the image to a file hosting or sharing service like\
    \ Google Drive, Dropbox, or Imgur.\\n\\n2. Once the image is uploaded, get the\
    \ image's URL (web address) from the hosting service.\\n\\n3. In your question\
    \ or response, simply copy the image URL and paste it into the text box here.\
    \ Be sure to select the \\\"image\\\" icon before doing so.\\n\\n4. After pasting\
    \ the URL, the image will automatically appear within your question or answer.\\\
    n\\nIf you need further assistance, please let me know.\r\n```\r\n\r\nBut instead\
    \ I got:\r\n\r\n```\r\n<s> <|user|>\r\nHow to load image here ?\r\n<|assistant|>\r\
    \nTo load an image in a Python script, you can use the `PIL` (Python Imaging Library)\
    \ module. Here's an example of how to load an image using `PIL`:\r\n\r\nfrom PIL\
    \ import Image\r\n\r\n# Load the image\r\nimage = Image.open(\"image.jpg\")\r\n\
    \r\n# Display the image\r\nimage.show()\r\n\r\nIn this example, we first import\
    \ the `Image` class from the `PIL` module. We then use the `Image.open()` method\
    \ to load the image from the file \"image.jpg\". Finally, we display the image\
    \ using the `show()` method.\r\n\r\nNote that you need to install the `PIL` module\
    \ before you can use it in your Python script. You can install it using pip:\r\
    \n\r\npip install pillow\r\n\r\nAlso, make sure that the image file is in the\
    \ same directory as your Python script or that you provide the full path to the\
    \ image file in the `Image.open()` method.</s>\r\n```\r\n\r\nDid I do something\
    \ wrong?\r\n\r\nThanks in advance !\r\n\r\n"
  created_at: 2023-12-30 15:58:53+00:00
  edited: false
  hidden: false
  id: 65903e3d87944e494e32b891
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654027835241-62608fc2ffe8827cb1d89f9f.png?w=200&h=200&f=face
      fullname: Hamish Ivison
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: hamishivi
      type: user
    createdAt: '2023-12-31T02:42:45.000Z'
    data:
      edited: false
      editors:
      - hamishivi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9433841109275818
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654027835241-62608fc2ffe8827cb1d89f9f.png?w=200&h=200&f=face
          fullname: Hamish Ivison
          isHf: false
          isPro: false
          name: hamishivi
          type: user
        html: '<p>Hi! I don''t think you''ve done anything wrong - the dpo training
          uses a fairly low learning rate and a contrastive-style loss that is more
          about learning the difference between preferred and dispreferred samples
          than memorising exact outputs. The SFT mixture/training stage might be better
          to look at for cases of exact memorisation.</p>

          <p>Alternatively, you could check the difference between the likelihoods
          of generating the preferred and dispreferred examples in the given ultrafeedback
          instance - since this better corresponds to the learning objective. Hopefully
          that''s useful!</p>

          '
        raw: 'Hi! I don''t think you''ve done anything wrong - the dpo training uses
          a fairly low learning rate and a contrastive-style loss that is more about
          learning the difference between preferred and dispreferred samples than
          memorising exact outputs. The SFT mixture/training stage might be better
          to look at for cases of exact memorisation.


          Alternatively, you could check the difference between the likelihoods of
          generating the preferred and dispreferred examples in the given ultrafeedback
          instance - since this better corresponds to the learning objective. Hopefully
          that''s useful!'
        updatedAt: '2023-12-31T02:42:45.313Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6590d525cdc0c4099b5917ff
    id: 6590d525cdc0c4099b5917f9
    type: comment
  author: hamishivi
  content: 'Hi! I don''t think you''ve done anything wrong - the dpo training uses
    a fairly low learning rate and a contrastive-style loss that is more about learning
    the difference between preferred and dispreferred samples than memorising exact
    outputs. The SFT mixture/training stage might be better to look at for cases of
    exact memorisation.


    Alternatively, you could check the difference between the likelihoods of generating
    the preferred and dispreferred examples in the given ultrafeedback instance -
    since this better corresponds to the learning objective. Hopefully that''s useful!'
  created_at: 2023-12-31 02:42:45+00:00
  edited: false
  hidden: false
  id: 6590d525cdc0c4099b5917f9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654027835241-62608fc2ffe8827cb1d89f9f.png?w=200&h=200&f=face
      fullname: Hamish Ivison
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: hamishivi
      type: user
    createdAt: '2023-12-31T02:42:45.000Z'
    data:
      status: closed
    id: 6590d525cdc0c4099b5917ff
    type: status-change
  author: hamishivi
  created_at: 2023-12-31 02:42:45+00:00
  id: 6590d525cdc0c4099b5917ff
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: allenai/open-instruct-llama2-sharegpt-dpo-7b
repo_type: model
status: closed
target_branch: null
title: Answer different from the dataset
