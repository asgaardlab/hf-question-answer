!!python/object:huggingface_hub.community.DiscussionWithDetails
author: yuuko-eth
conflicting_files: null
created_at: 2024-01-12 15:56:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64198b3b95a9cc83d188841a/a7EvVMbO8kjCQDifomf2d.jpeg?w=200&h=200&f=face
      fullname: Yuuko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yuuko-eth
      type: user
    createdAt: '2024-01-12T15:56:57.000Z'
    data:
      edited: false
      editors:
      - yuuko-eth
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9636821150779724
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64198b3b95a9cc83d188841a/a7EvVMbO8kjCQDifomf2d.jpeg?w=200&h=200&f=face
          fullname: Yuuko
          isHf: false
          isPro: false
          name: yuuko-eth
          type: user
        html: "<p>Dear Audrey,</p>\n<p>We were having trouble using llama.cpp (<code>convert.py</code>)\
          \ to convert from MTK\u2019s provided weights ourselves, but we never had\
          \ any success. Is it possible for you to share how to convert this kind\
          \ of model into GGUF, like what patch might have been required for the tool\
          \ to work. I have attempted token padding option with no avail, though the\
          \ recent commits seems to claim that the conversion tool is fixed.</p>\n\
          <p>Many thanks!! \U0001F97A\U0001F917</p>\n"
        raw: "Dear Audrey,\r\n\r\nWe were having trouble using llama.cpp (`convert.py`)\
          \ to convert from MTK\u2019s provided weights ourselves, but we never had\
          \ any success. Is it possible for you to share how to convert this kind\
          \ of model into GGUF, like what patch might have been required for the tool\
          \ to work. I have attempted token padding option with no avail, though the\
          \ recent commits seems to claim that the conversion tool is fixed.\r\n\r\
          \nMany thanks!! \U0001F97A\U0001F917"
        updatedAt: '2024-01-12T15:56:57.494Z'
      numEdits: 0
      reactions: []
    id: 65a1614961e5e3b9263d3856
    type: comment
  author: yuuko-eth
  content: "Dear Audrey,\r\n\r\nWe were having trouble using llama.cpp (`convert.py`)\
    \ to convert from MTK\u2019s provided weights ourselves, but we never had any\
    \ success. Is it possible for you to share how to convert this kind of model into\
    \ GGUF, like what patch might have been required for the tool to work. I have\
    \ attempted token padding option with no avail, though the recent commits seems\
    \ to claim that the conversion tool is fixed.\r\n\r\nMany thanks!! \U0001F97A\U0001F917"
  created_at: 2024-01-12 15:56:57+00:00
  edited: false
  hidden: false
  id: 65a1614961e5e3b9263d3856
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6373a1a92d4eccfa6f909f69/j8ED1yzIYH0nBljHcqELg.jpeg?w=200&h=200&f=face
      fullname: Audrey Tang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: audreyt
      type: user
    createdAt: '2024-01-12T23:24:08.000Z'
    data:
      edited: true
      editors:
      - audreyt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7957910299301147
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6373a1a92d4eccfa6f909f69/j8ED1yzIYH0nBljHcqELg.jpeg?w=200&h=200&f=face
          fullname: Audrey Tang
          isHf: false
          isPro: false
          name: audreyt
          type: user
        html: '<p>Indeed, the current HEAD (36e5a08b as of this writing) is broken
          w.r.t. this model. The breaking commit is 6efb8eb3 which renamed <code>--padvocab</code>
          to <code>--pad-vocab</code>.</p>

          <p>Here is how to revert to the last-known-good version and convert:</p>

          <pre><code>cd llama.cpp

          git checkout 6efb8eb3^

          python3 convert.py  ../Breeze-7B-Instruct-64k-v0.1 --padvocab

          </code></pre>

          '
        raw: 'Indeed, the current HEAD (36e5a08b as of this writing) is broken w.r.t.
          this model. The breaking commit is 6efb8eb3 which renamed `--padvocab` to
          `--pad-vocab`.


          Here is how to revert to the last-known-good version and convert:


          ```

          cd llama.cpp

          git checkout 6efb8eb3^

          python3 convert.py  ../Breeze-7B-Instruct-64k-v0.1 --padvocab

          ```

          '
        updatedAt: '2024-01-12T23:55:06.802Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - yuuko-eth
      relatedEventId: 65a1ca1890e65dc39a4260c2
    id: 65a1ca1890e65dc39a4260b7
    type: comment
  author: audreyt
  content: 'Indeed, the current HEAD (36e5a08b as of this writing) is broken w.r.t.
    this model. The breaking commit is 6efb8eb3 which renamed `--padvocab` to `--pad-vocab`.


    Here is how to revert to the last-known-good version and convert:


    ```

    cd llama.cpp

    git checkout 6efb8eb3^

    python3 convert.py  ../Breeze-7B-Instruct-64k-v0.1 --padvocab

    ```

    '
  created_at: 2024-01-12 23:24:08+00:00
  edited: true
  hidden: false
  id: 65a1ca1890e65dc39a4260b7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6373a1a92d4eccfa6f909f69/j8ED1yzIYH0nBljHcqELg.jpeg?w=200&h=200&f=face
      fullname: Audrey Tang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: audreyt
      type: user
    createdAt: '2024-01-12T23:24:08.000Z'
    data:
      status: closed
    id: 65a1ca1890e65dc39a4260c2
    type: status-change
  author: audreyt
  created_at: 2024-01-12 23:24:08+00:00
  id: 65a1ca1890e65dc39a4260c2
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: audreyt/Breeze-7B-Instruct-64k-v0.1-GGUF
repo_type: model
status: closed
target_branch: null
title: Regarding Mistral-based GGUF conversion
