!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xaroth
conflicting_files: null
created_at: 2022-08-24 17:26:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/937544232a45e18fb13701894c4882b6.svg
      fullname: Geoffrey Benson
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xaroth
      type: user
    createdAt: '2022-08-24T18:26:53.000Z'
    data:
      edited: true
      editors:
      - xaroth
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/937544232a45e18fb13701894c4882b6.svg
          fullname: Geoffrey Benson
          isHf: false
          isPro: false
          name: xaroth
          type: user
        html: '<p>Generating images with <a rel="nofollow" href="https://github.com/CompVis/stable-diffusion">https://github.com/CompVis/stable-diffusion</a>
          , using the default settings makes beautiful artwork... with one glaring
          problem.  Many of the images I''ve made come out looking like they''re center-cropped
          versions of portrait dimensioned images.  For example, the prompt: "artstation
          wizard"  pretty consistently gives images that have this poorly-cropped
          characteristic.</p>

          <p>My suspicion is that the problem lies in how the source images were prepared
          before training.  That is to say, if the training data''s portrait aspect-ratio
          images were coerced into a square aspect ratio via simple center-cropping,
          then this is precisely the output I''d expect to see from the model.</p>

          <p>Potential solutions on the training side of things would include:</p>

          <ul>

          <li>Use of a smart-cropping library to improve the quality of the cropping
          (probably the easiest option)</li>

          <li>Adding transparent letterboxes to the images to pad them into the correct
          aspect ratio</li>

          <li>Figuring out how to get the training and sampling to work with arbitrary
          aspect ratios (probably the hardest option)</li>

          </ul>

          <p>I''m not aware of any workarounds for those trying to sample from the
          model, but I''d love to hear if others have found good prompt engineering
          tricks to avoid this issue.  Especially when generating images in a 4:3
          aspect ratio, as the cropping defect is magnified when doing this.</p>

          '
        raw: 'Generating images with https://github.com/CompVis/stable-diffusion ,
          using the default settings makes beautiful artwork... with one glaring problem.  Many
          of the images I''ve made come out looking like they''re center-cropped versions
          of portrait dimensioned images.  For example, the prompt: "artstation wizard"  pretty
          consistently gives images that have this poorly-cropped characteristic.


          My suspicion is that the problem lies in how the source images were prepared
          before training.  That is to say, if the training data''s portrait aspect-ratio
          images were coerced into a square aspect ratio via simple center-cropping,
          then this is precisely the output I''d expect to see from the model.


          Potential solutions on the training side of things would include:

          * Use of a smart-cropping library to improve the quality of the cropping
          (probably the easiest option)

          * Adding transparent letterboxes to the images to pad them into the correct
          aspect ratio

          * Figuring out how to get the training and sampling to work with arbitrary
          aspect ratios (probably the hardest option)


          I''m not aware of any workarounds for those trying to sample from the model,
          but I''d love to hear if others have found good prompt engineering tricks
          to avoid this issue.  Especially when generating images in a 4:3 aspect
          ratio, as the cropping defect is magnified when doing this.'
        updatedAt: '2022-08-24T18:27:47.370Z'
      numEdits: 1
      reactions:
      - count: 7
        reaction: "\U0001F44D"
        users:
        - patrickvonplaten
        - osanseviero
        - ausbitbank
        - Hinga
        - KvakMekRampa
        - Lao
        - jacobnye
    id: 63066d6d3aed65d34e9a2f07
    type: comment
  author: xaroth
  content: 'Generating images with https://github.com/CompVis/stable-diffusion , using
    the default settings makes beautiful artwork... with one glaring problem.  Many
    of the images I''ve made come out looking like they''re center-cropped versions
    of portrait dimensioned images.  For example, the prompt: "artstation wizard"  pretty
    consistently gives images that have this poorly-cropped characteristic.


    My suspicion is that the problem lies in how the source images were prepared before
    training.  That is to say, if the training data''s portrait aspect-ratio images
    were coerced into a square aspect ratio via simple center-cropping, then this
    is precisely the output I''d expect to see from the model.


    Potential solutions on the training side of things would include:

    * Use of a smart-cropping library to improve the quality of the cropping (probably
    the easiest option)

    * Adding transparent letterboxes to the images to pad them into the correct aspect
    ratio

    * Figuring out how to get the training and sampling to work with arbitrary aspect
    ratios (probably the hardest option)


    I''m not aware of any workarounds for those trying to sample from the model, but
    I''d love to hear if others have found good prompt engineering tricks to avoid
    this issue.  Especially when generating images in a 4:3 aspect ratio, as the cropping
    defect is magnified when doing this.'
  created_at: 2022-08-24 17:26:53+00:00
  edited: true
  hidden: false
  id: 63066d6d3aed65d34e9a2f07
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: CompVis/stable-diffusion-v-1-4-original
repo_type: model
status: open
target_branch: null
title: Image quality issue, most likely in training data
