!!python/object:huggingface_hub.community.DiscussionWithDetails
author: feniksss
conflicting_files: null
created_at: 2022-10-26 08:06:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1c7bc61667eeebddb7977ca7ec3edc1f.svg
      fullname: Tester Tester
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: feniksss
      type: user
    createdAt: '2022-10-26T09:06:48.000Z'
    data:
      edited: false
      editors:
      - feniksss
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1c7bc61667eeebddb7977ca7ec3edc1f.svg
          fullname: Tester Tester
          isHf: false
          isPro: false
          name: feniksss
          type: user
        html: "<p>I have used a simple realization on T4 </p>\n<pre><code>import torch\n\
          from torch import autocast\nfrom diffusers import StableDiffusionPipeline\n\
          \naccess_token = \"\"\n\npipe = StableDiffusionPipeline.from_pretrained(\n\
          \    \"CompVis/stable-diffusion-v1-4\",\n    revision=\"fp16\",\n    torch_dtype=torch.float16,\n\
          \    use_auth_token=access_token,\n)\npipe = pipe.to(\"cuda\")\n\nprompt\
          \ = \"a photo of an astronaut riding a horse on mars\"\nimage = pipe(prompt).images[0]\n\
          image.save(\"astronaut_rides_horse_1.png\")\n</code></pre>\n<p>And generating\
          \ can take 10-15 sec per image - it's good result.<br>But we have a problem\
          \ with time before start of generating. Pre-loading models and files can\
          \ take ~ 30 sec.<br>For example:</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1666775182098-63496303fbb41aa9e08626fd.jpeg\"\
          ><img alt=\"20221024-penj-42kb.jpg\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1666775182098-63496303fbb41aa9e08626fd.jpeg\"\
          ></a></p>\n<p>How we can speed up the preloading?</p>\n"
        raw: "I have used a simple realization on T4 \r\n```\r\nimport torch\r\nfrom\
          \ torch import autocast\r\nfrom diffusers import StableDiffusionPipeline\r\
          \n\r\naccess_token = \"\"\r\n\r\npipe = StableDiffusionPipeline.from_pretrained(\r\
          \n    \"CompVis/stable-diffusion-v1-4\",\r\n    revision=\"fp16\",\r\n \
          \   torch_dtype=torch.float16,\r\n    use_auth_token=access_token,\r\n)\r\
          \npipe = pipe.to(\"cuda\")\r\n\r\nprompt = \"a photo of an astronaut riding\
          \ a horse on mars\"\r\nimage = pipe(prompt).images[0]\r\nimage.save(\"astronaut_rides_horse_1.png\"\
          )\r\n```\r\n\r\nAnd generating can take 10-15 sec per image - it's good\
          \ result.\r\nBut we have a problem with time before start of generating.\
          \ Pre-loading models and files can take ~ 30 sec.\r\nFor example:\r\n\r\n\
          ![20221024-penj-42kb.jpg](https://cdn-uploads.huggingface.co/production/uploads/1666775182098-63496303fbb41aa9e08626fd.jpeg)\r\
          \n\r\nHow we can speed up the preloading?"
        updatedAt: '2022-10-26T09:06:48.533Z'
      numEdits: 0
      reactions: []
    id: 6358f8a8739ea58e84f9a22f
    type: comment
  author: feniksss
  content: "I have used a simple realization on T4 \r\n```\r\nimport torch\r\nfrom\
    \ torch import autocast\r\nfrom diffusers import StableDiffusionPipeline\r\n\r\
    \naccess_token = \"\"\r\n\r\npipe = StableDiffusionPipeline.from_pretrained(\r\
    \n    \"CompVis/stable-diffusion-v1-4\",\r\n    revision=\"fp16\",\r\n    torch_dtype=torch.float16,\r\
    \n    use_auth_token=access_token,\r\n)\r\npipe = pipe.to(\"cuda\")\r\n\r\nprompt\
    \ = \"a photo of an astronaut riding a horse on mars\"\r\nimage = pipe(prompt).images[0]\r\
    \nimage.save(\"astronaut_rides_horse_1.png\")\r\n```\r\n\r\nAnd generating can\
    \ take 10-15 sec per image - it's good result.\r\nBut we have a problem with time\
    \ before start of generating. Pre-loading models and files can take ~ 30 sec.\r\
    \nFor example:\r\n\r\n![20221024-penj-42kb.jpg](https://cdn-uploads.huggingface.co/production/uploads/1666775182098-63496303fbb41aa9e08626fd.jpeg)\r\
    \n\r\nHow we can speed up the preloading?"
  created_at: 2022-10-26 08:06:48+00:00
  edited: false
  hidden: false
  id: 6358f8a8739ea58e84f9a22f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 185
repo_id: CompVis/stable-diffusion-v-1-4-original
repo_type: model
status: open
target_branch: null
title: Time delay before generating
