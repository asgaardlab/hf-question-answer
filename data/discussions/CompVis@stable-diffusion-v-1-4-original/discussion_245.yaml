!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hd-scania
conflicting_files: null
created_at: 2023-04-15 11:45:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/50f725aa380db984952adbd69bbb8cd4.svg
      fullname: HD Scania
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hd-scania
      type: user
    createdAt: '2023-04-15T12:45:05.000Z'
    data:
      edited: false
      editors:
      - hd-scania
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/50f725aa380db984952adbd69bbb8cd4.svg
          fullname: HD Scania
          isHf: false
          isPro: false
          name: hd-scania
          type: user
        html: "<p>I'm on an AMD R4750G APU instead of an NVidia APU which is assumed\
          \ on SD's PyTorch Python app<br>Where to add <code>--skip-torch-cuda-test</code>\
          \ to become an entry of <code>COMMANDLINE_ARGS</code>?</p>\n<pre><code>%\
          \ bash webui.sh\nInstall script for stable-diffusion + Web UI\nTested on\
          \ Debian 11 (Bullseye)\n################################################################\n\
          \n################################################################\nRunning\
          \ on hd_scania user\n################################################################\n\
          \n################################################################\nExperimental\
          \ support for Renoir: make sure to have at least 4GB of VRAM and 10GB of\
          \ RAM or enable cpu mode: --use-cpu all --no-half\n################################################################\n\
          \n################################################################\nCreate\
          \ and activate python venv\n################################################################\n\
          \n################################################################\nLaunching\
          \ launch.py...\n################################################################\n\
          Python 3.10.9 (main, Dec 25 2022, 21:29:15) [GCC 12.2.0]\nCommit hash: 22bcc7be428c94e9408f589966c2040187245d81\n\
          Traceback (most recent call last):\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
          , line 355, in &lt;module&gt;\n    prepare_environment()\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
          , line 260, in prepare_environment\n    run_python(\"import torch; assert\
          \ torch.cuda.is_available(), 'Torch is not able to use GPU; add --skip-torch-cuda-test\
          \ to COMMANDLINE_ARGS variable to disable this check'\")\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
          , line 121, in run_python\n    return run(f'\"{python}\" -c \"{code}\"',\
          \ desc, errdesc)\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
          , line 97, in run\n    raise RuntimeError(message)\nRuntimeError: Error\
          \ running command.\nCommand: \"/home/hd_scania/stable-diffusion-webui/venv/bin/python3\"\
          \ -c \"import torch; assert torch.cuda.is_available(), 'Torch is not able\
          \ to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to\
          \ disable this check'\"\nError code: 1\nstdout: &lt;empty&gt;\nstderr: Traceback\
          \ (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\n\
          AssertionError: Torch is not able to use GPU; add --skip-torch-cuda-test\
          \ to COMMANDLINE_ARGS variable to disable this check\n%\n</code></pre>\n"
        raw: "I'm on an AMD R4750G APU instead of an NVidia APU which is assumed on\
          \ SD's PyTorch Python app\r\nWhere to add `--skip-torch-cuda-test` to become\
          \ an entry of `COMMANDLINE_ARGS`?\r\n```\r\n% bash webui.sh\r\nInstall script\
          \ for stable-diffusion + Web UI\r\nTested on Debian 11 (Bullseye)\r\n################################################################\r\
          \n\r\n################################################################\r\
          \nRunning on hd_scania user\r\n################################################################\r\
          \n\r\n################################################################\r\
          \nExperimental support for Renoir: make sure to have at least 4GB of VRAM\
          \ and 10GB of RAM or enable cpu mode: --use-cpu all --no-half\r\n################################################################\r\
          \n\r\n################################################################\r\
          \nCreate and activate python venv\r\n################################################################\r\
          \n\r\n################################################################\r\
          \nLaunching launch.py...\r\n################################################################\r\
          \nPython 3.10.9 (main, Dec 25 2022, 21:29:15) [GCC 12.2.0]\r\nCommit hash:\
          \ 22bcc7be428c94e9408f589966c2040187245d81\r\nTraceback (most recent call\
          \ last):\r\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
          , line 355, in <module>\r\n    prepare_environment()\r\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
          , line 260, in prepare_environment\r\n    run_python(\"import torch; assert\
          \ torch.cuda.is_available(), 'Torch is not able to use GPU; add --skip-torch-cuda-test\
          \ to COMMANDLINE_ARGS variable to disable this check'\")\r\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
          , line 121, in run_python\r\n    return run(f'\"{python}\" -c \"{code}\"\
          ', desc, errdesc)\r\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
          , line 97, in run\r\n    raise RuntimeError(message)\r\nRuntimeError: Error\
          \ running command.\r\nCommand: \"/home/hd_scania/stable-diffusion-webui/venv/bin/python3\"\
          \ -c \"import torch; assert torch.cuda.is_available(), 'Torch is not able\
          \ to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to\
          \ disable this check'\"\r\nError code: 1\r\nstdout: <empty>\r\nstderr: Traceback\
          \ (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\
          \nAssertionError: Torch is not able to use GPU; add --skip-torch-cuda-test\
          \ to COMMANDLINE_ARGS variable to disable this check\r\n%\r\n```"
        updatedAt: '2023-04-15T12:45:05.514Z'
      numEdits: 0
      reactions: []
    id: 643a9c51ff50448bcfc10acc
    type: comment
  author: hd-scania
  content: "I'm on an AMD R4750G APU instead of an NVidia APU which is assumed on\
    \ SD's PyTorch Python app\r\nWhere to add `--skip-torch-cuda-test` to become an\
    \ entry of `COMMANDLINE_ARGS`?\r\n```\r\n% bash webui.sh\r\nInstall script for\
    \ stable-diffusion + Web UI\r\nTested on Debian 11 (Bullseye)\r\n################################################################\r\
    \n\r\n################################################################\r\nRunning\
    \ on hd_scania user\r\n################################################################\r\
    \n\r\n################################################################\r\nExperimental\
    \ support for Renoir: make sure to have at least 4GB of VRAM and 10GB of RAM or\
    \ enable cpu mode: --use-cpu all --no-half\r\n################################################################\r\
    \n\r\n################################################################\r\nCreate\
    \ and activate python venv\r\n################################################################\r\
    \n\r\n################################################################\r\nLaunching\
    \ launch.py...\r\n################################################################\r\
    \nPython 3.10.9 (main, Dec 25 2022, 21:29:15) [GCC 12.2.0]\r\nCommit hash: 22bcc7be428c94e9408f589966c2040187245d81\r\
    \nTraceback (most recent call last):\r\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
    , line 355, in <module>\r\n    prepare_environment()\r\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
    , line 260, in prepare_environment\r\n    run_python(\"import torch; assert torch.cuda.is_available(),\
    \ 'Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS\
    \ variable to disable this check'\")\r\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\"\
    , line 121, in run_python\r\n    return run(f'\"{python}\" -c \"{code}\"', desc,\
    \ errdesc)\r\n  File \"/home/hd_scania/stable-diffusion-webui/launch.py\", line\
    \ 97, in run\r\n    raise RuntimeError(message)\r\nRuntimeError: Error running\
    \ command.\r\nCommand: \"/home/hd_scania/stable-diffusion-webui/venv/bin/python3\"\
    \ -c \"import torch; assert torch.cuda.is_available(), 'Torch is not able to use\
    \ GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this\
    \ check'\"\r\nError code: 1\r\nstdout: <empty>\r\nstderr: Traceback (most recent\
    \ call last):\r\n  File \"<string>\", line 1, in <module>\r\nAssertionError: Torch\
    \ is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable\
    \ to disable this check\r\n%\r\n```"
  created_at: 2023-04-15 11:45:05+00:00
  edited: false
  hidden: false
  id: 643a9c51ff50448bcfc10acc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 245
repo_id: CompVis/stable-diffusion-v-1-4-original
repo_type: model
status: open
target_branch: null
title: Where to add a cmd arg to stop PyTorch from assuming NVidia DPU?
