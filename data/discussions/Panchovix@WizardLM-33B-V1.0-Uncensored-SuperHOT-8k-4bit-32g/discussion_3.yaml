!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Leaf45
conflicting_files: null
created_at: 2023-06-30 13:40:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c488e9ca3a7b722a8b1ebe7c3c13436d.svg
      fullname: Leaves
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Leaf45
      type: user
    createdAt: '2023-06-30T14:40:25.000Z'
    data:
      edited: false
      editors:
      - Leaf45
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7900800704956055
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c488e9ca3a7b722a8b1ebe7c3c13436d.svg
          fullname: Leaves
          isHf: false
          isPro: false
          name: Leaf45
          type: user
        html: '<p>When I try to run the model it fails and says: </p>

          <p>"RuntimeError: unable to mmap 19426750144 bytes from file &lt;models/Panchovix_WizardLM-33B-V1.0-Uncensored-SuperHOT-8k-4bit-32g/WizardLM-33B-V1.0-Uncensored-SuperHOT-8k.safetensors&gt;:
          Cannot allocate memory (12)"</p>

          <p>I am not sure why it says this</p>

          '
        raw: "When I try to run the model it fails and says: \r\n\r\n\"RuntimeError:\
          \ unable to mmap 19426750144 bytes from file <models/Panchovix_WizardLM-33B-V1.0-Uncensored-SuperHOT-8k-4bit-32g/WizardLM-33B-V1.0-Uncensored-SuperHOT-8k.safetensors>:\
          \ Cannot allocate memory (12)\"\r\n\r\nI am not sure why it says this"
        updatedAt: '2023-06-30T14:40:25.619Z'
      numEdits: 0
      reactions: []
    id: 649ee95968d673f93719edb0
    type: comment
  author: Leaf45
  content: "When I try to run the model it fails and says: \r\n\r\n\"RuntimeError:\
    \ unable to mmap 19426750144 bytes from file <models/Panchovix_WizardLM-33B-V1.0-Uncensored-SuperHOT-8k-4bit-32g/WizardLM-33B-V1.0-Uncensored-SuperHOT-8k.safetensors>:\
    \ Cannot allocate memory (12)\"\r\n\r\nI am not sure why it says this"
  created_at: 2023-06-30 13:40:25+00:00
  edited: false
  hidden: false
  id: 649ee95968d673f93719edb0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c488e9ca3a7b722a8b1ebe7c3c13436d.svg
      fullname: Leaves
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Leaf45
      type: user
    createdAt: '2023-06-30T17:20:07.000Z'
    data:
      edited: false
      editors:
      - Leaf45
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.940960705280304
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c488e9ca3a7b722a8b1ebe7c3c13436d.svg
          fullname: Leaves
          isHf: false
          isPro: false
          name: Leaf45
          type: user
        html: '<p>I found out what it was. The problem was that this model wasn''t
          GPTQ. This model is working for me <a href="https://huggingface.co/TheBloke/WizardLM-33B-V1.0-Uncensored-SuperHOT-8K-GPTQ/tree/main">https://huggingface.co/TheBloke/WizardLM-33B-V1.0-Uncensored-SuperHOT-8K-GPTQ/tree/main</a></p>

          '
        raw: I found out what it was. The problem was that this model wasn't GPTQ.
          This model is working for me https://huggingface.co/TheBloke/WizardLM-33B-V1.0-Uncensored-SuperHOT-8K-GPTQ/tree/main
        updatedAt: '2023-06-30T17:20:07.253Z'
      numEdits: 0
      reactions: []
      relatedEventId: 649f0ec7bfd4d3ffab7a402b
    id: 649f0ec7bfd4d3ffab7a4029
    type: comment
  author: Leaf45
  content: I found out what it was. The problem was that this model wasn't GPTQ. This
    model is working for me https://huggingface.co/TheBloke/WizardLM-33B-V1.0-Uncensored-SuperHOT-8K-GPTQ/tree/main
  created_at: 2023-06-30 16:20:07+00:00
  edited: false
  hidden: false
  id: 649f0ec7bfd4d3ffab7a4029
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/c488e9ca3a7b722a8b1ebe7c3c13436d.svg
      fullname: Leaves
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Leaf45
      type: user
    createdAt: '2023-06-30T17:20:07.000Z'
    data:
      status: closed
    id: 649f0ec7bfd4d3ffab7a402b
    type: status-change
  author: Leaf45
  created_at: 2023-06-30 16:20:07+00:00
  id: 649f0ec7bfd4d3ffab7a402b
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f52a8d866ed36aba5000ac8d0ef5bc96.svg
      fullname: Francisco
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Panchovix
      type: user
    createdAt: '2023-06-30T17:21:40.000Z'
    data:
      edited: false
      editors:
      - Panchovix
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9833109974861145
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f52a8d866ed36aba5000ac8d0ef5bc96.svg
          fullname: Francisco
          isHf: false
          isPro: false
          name: Panchovix
          type: user
        html: '<p>This model is GPTQ, with which GPU were you loading this model?
          Remember, as this is a model with group size 32, it needs a good amount
          VRAM vs a GPTQ model without group size,</p>

          '
        raw: This model is GPTQ, with which GPU were you loading this model? Remember,
          as this is a model with group size 32, it needs a good amount VRAM vs a
          GPTQ model without group size,
        updatedAt: '2023-06-30T17:21:40.021Z'
      numEdits: 0
      reactions: []
    id: 649f0f24ca03a1a35e343149
    type: comment
  author: Panchovix
  content: This model is GPTQ, with which GPU were you loading this model? Remember,
    as this is a model with group size 32, it needs a good amount VRAM vs a GPTQ model
    without group size,
  created_at: 2023-06-30 16:21:40+00:00
  edited: false
  hidden: false
  id: 649f0f24ca03a1a35e343149
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c488e9ca3a7b722a8b1ebe7c3c13436d.svg
      fullname: Leaves
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Leaf45
      type: user
    createdAt: '2023-07-01T15:42:15.000Z'
    data:
      edited: false
      editors:
      - Leaf45
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.981968879699707
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c488e9ca3a7b722a8b1ebe7c3c13436d.svg
          fullname: Leaves
          isHf: false
          isPro: false
          name: Leaf45
          type: user
        html: '<p>I have the NVIDIA RTX A5000 24GB. Yeah then maybe it had something
          to do with the group size</p>

          '
        raw: I have the NVIDIA RTX A5000 24GB. Yeah then maybe it had something to
          do with the group size
        updatedAt: '2023-07-01T15:42:15.366Z'
      numEdits: 0
      reactions: []
    id: 64a04957eea04b705619486a
    type: comment
  author: Leaf45
  content: I have the NVIDIA RTX A5000 24GB. Yeah then maybe it had something to do
    with the group size
  created_at: 2023-07-01 14:42:15+00:00
  edited: false
  hidden: false
  id: 64a04957eea04b705619486a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Panchovix/WizardLM-33B-V1.0-Uncensored-SuperHOT-8k-4bit-32g
repo_type: model
status: closed
target_branch: null
title: 'RuntimeError: unable to mmap 19426750144 bytes'
