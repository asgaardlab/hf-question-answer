!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Njax
conflicting_files: null
created_at: 2023-07-29 02:07:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6693b230d47474fa6b835b5b0a067e05.svg
      fullname: N Jax
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Njax
      type: user
    createdAt: '2023-07-29T03:07:54.000Z'
    data:
      edited: false
      editors:
      - Njax
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.725443422794342
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6693b230d47474fa6b835b5b0a067e05.svg
          fullname: N Jax
          isHf: false
          isPro: false
          name: Njax
          type: user
        html: "<p>I'm very new to GPTQ, so please excuse this message if I'm in error.\
          \  However, I couldn't get the example python code to just work.  I wound\
          \ up changing it to this:</p>\n<pre><code>model = AutoGPTQForCausalLM.from_quantized(model_basename,\n\
          \    use_safetensors=True,\n    trust_remote_code=True,\n    device=\"cuda:0\"\
          ,\n    use_triton=use_triton,\n    quantize_config=None)\n\nuser_input =\
          \ '''\n// A javascript function\nfunction printHelloWorld() {\n'''\n\ninputs\
          \ = tokenizer(user_input, return_tensors=\"pt\").to(model.device)\nembedding\
          \ = model.generate(**inputs,\n    max_new_tokens=40)[0]\noutputs = tokenizer.decode(embedding)\n\
          </code></pre>\n<p>I used cuda 1.17, torch 2.0.1+cu117, and auto-gptq 0.2.2,\
          \ which perhaps spells the difference.  </p>\n<p>Thanks for uploading this.\
          \  Confusing stuff at times but it sure is exciting for something new! \
          \ </p>\n"
        raw: "I'm very new to GPTQ, so please excuse this message if I'm in error.\
          \  However, I couldn't get the example python code to just work.  I wound\
          \ up changing it to this:\r\n\r\n```\r\nmodel = AutoGPTQForCausalLM.from_quantized(model_basename,\r\
          \n    use_safetensors=True,\r\n    trust_remote_code=True,\r\n    device=\"\
          cuda:0\",\r\n    use_triton=use_triton,\r\n    quantize_config=None)\r\n\
          \r\nuser_input = '''\r\n// A javascript function\r\nfunction printHelloWorld()\
          \ {\r\n'''\r\n\r\ninputs = tokenizer(user_input, return_tensors=\"pt\").to(model.device)\r\
          \nembedding = model.generate(**inputs,\r\n    max_new_tokens=40)[0]\r\n\
          outputs = tokenizer.decode(embedding)\r\n```\r\n\r\nI used cuda 1.17, torch\
          \ 2.0.1+cu117, and auto-gptq 0.2.2, which perhaps spells the difference.\
          \  \r\n\r\nThanks for uploading this.  Confusing stuff at times but it sure\
          \ is exciting for something new!  "
        updatedAt: '2023-07-29T03:07:54.831Z'
      numEdits: 0
      reactions: []
    id: 64c4828a538d4f17b504b8bc
    type: comment
  author: Njax
  content: "I'm very new to GPTQ, so please excuse this message if I'm in error. \
    \ However, I couldn't get the example python code to just work.  I wound up changing\
    \ it to this:\r\n\r\n```\r\nmodel = AutoGPTQForCausalLM.from_quantized(model_basename,\r\
    \n    use_safetensors=True,\r\n    trust_remote_code=True,\r\n    device=\"cuda:0\"\
    ,\r\n    use_triton=use_triton,\r\n    quantize_config=None)\r\n\r\nuser_input\
    \ = '''\r\n// A javascript function\r\nfunction printHelloWorld() {\r\n'''\r\n\
    \r\ninputs = tokenizer(user_input, return_tensors=\"pt\").to(model.device)\r\n\
    embedding = model.generate(**inputs,\r\n    max_new_tokens=40)[0]\r\noutputs =\
    \ tokenizer.decode(embedding)\r\n```\r\n\r\nI used cuda 1.17, torch 2.0.1+cu117,\
    \ and auto-gptq 0.2.2, which perhaps spells the difference.  \r\n\r\nThanks for\
    \ uploading this.  Confusing stuff at times but it sure is exciting for something\
    \ new!  "
  created_at: 2023-07-29 02:07:54+00:00
  edited: false
  hidden: false
  id: 64c4828a538d4f17b504b8bc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/starcoder-GPTQ
repo_type: model
status: open
target_branch: null
title: Python instructions didn't just go
