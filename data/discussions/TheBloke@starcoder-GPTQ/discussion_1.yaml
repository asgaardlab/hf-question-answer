!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Bilibili
conflicting_files: null
created_at: 2023-06-28 07:05:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640162547139-61c2e44c39245e7bf62def6f.jpeg?w=200&h=200&f=face
      fullname: Bilibili
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bilibili
      type: user
    createdAt: '2023-06-28T08:05:58.000Z'
    data:
      edited: false
      editors:
      - Bilibili
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8702116012573242
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640162547139-61c2e44c39245e7bf62def6f.jpeg?w=200&h=200&f=face
          fullname: Bilibili
          isHf: false
          isPro: false
          name: Bilibili
          type: user
        html: '<p>Thanks for this work! </p>

          <p>Since the original StarCoder requires 60+ GB GPU RAM for inference, I
          wonder what about the GPTQ version, and could the model run inference on
          V100-32G?</p>

          '
        raw: "Thanks for this work! \r\n\r\nSince the original StarCoder requires\
          \ 60+ GB GPU RAM for inference, I wonder what about the GPTQ version, and\
          \ could the model run inference on V100-32G?"
        updatedAt: '2023-06-28T08:05:58.556Z'
      numEdits: 0
      reactions: []
    id: 649be9e67e005628d2ab4f25
    type: comment
  author: Bilibili
  content: "Thanks for this work! \r\n\r\nSince the original StarCoder requires 60+\
    \ GB GPU RAM for inference, I wonder what about the GPTQ version, and could the\
    \ model run inference on V100-32G?"
  created_at: 2023-06-28 07:05:58+00:00
  edited: false
  hidden: false
  id: 649be9e67e005628d2ab4f25
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640162547139-61c2e44c39245e7bf62def6f.jpeg?w=200&h=200&f=face
      fullname: Bilibili
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bilibili
      type: user
    createdAt: '2023-06-28T08:06:11.000Z'
    data:
      from: GPU memory usage peak?
      to: GPU memory usage requirement?
    id: 649be9f37e233de345004543
    type: title-change
  author: Bilibili
  created_at: 2023-06-28 07:06:11+00:00
  id: 649be9f37e233de345004543
  new_title: GPU memory usage requirement?
  old_title: GPU memory usage peak?
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640162547139-61c2e44c39245e7bf62def6f.jpeg?w=200&h=200&f=face
      fullname: Bilibili
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bilibili
      type: user
    createdAt: '2023-06-28T08:06:19.000Z'
    data:
      from: GPU memory usage requirement?
      to: GPU memory usage/requirement?
    id: 649be9fb85e125b999eedb45
    type: title-change
  author: Bilibili
  created_at: 2023-06-28 07:06:19+00:00
  id: 649be9fb85e125b999eedb45
  new_title: GPU memory usage/requirement?
  old_title: GPU memory usage requirement?
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6693b230d47474fa6b835b5b0a067e05.svg
      fullname: N Jax
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Njax
      type: user
    createdAt: '2023-07-29T02:51:43.000Z'
    data:
      edited: false
      editors:
      - Njax
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.986661434173584
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6693b230d47474fa6b835b5b0a067e05.svg
          fullname: N Jax
          isHf: false
          isPro: false
          name: Njax
          type: user
        html: '<p>I''m totally new to GPTQ and am not exactly sure how to calculate
          the exacts, but it seems happy with 20-30 gigs from my CPU''s ram, and I
          have only 12 gigs used in my GPU.  </p>

          '
        raw: 'I''m totally new to GPTQ and am not exactly sure how to calculate the
          exacts, but it seems happy with 20-30 gigs from my CPU''s ram, and I have
          only 12 gigs used in my GPU.  '
        updatedAt: '2023-07-29T02:51:43.980Z'
      numEdits: 0
      reactions: []
    id: 64c47ebf3e30498cca8b07a3
    type: comment
  author: Njax
  content: 'I''m totally new to GPTQ and am not exactly sure how to calculate the
    exacts, but it seems happy with 20-30 gigs from my CPU''s ram, and I have only
    12 gigs used in my GPU.  '
  created_at: 2023-07-29 01:51:43+00:00
  edited: false
  hidden: false
  id: 64c47ebf3e30498cca8b07a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-29T10:20:57.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9669464826583862
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yes 32GB is more than enough VRAM for nearly any model in GPTQ.  This
          one needs around 12GB yeah</p>

          '
        raw: Yes 32GB is more than enough VRAM for nearly any model in GPTQ.  This
          one needs around 12GB yeah
        updatedAt: '2023-07-29T10:20:57.435Z'
      numEdits: 0
      reactions: []
    id: 64c4e8094399efa2fd8d44f7
    type: comment
  author: TheBloke
  content: Yes 32GB is more than enough VRAM for nearly any model in GPTQ.  This one
    needs around 12GB yeah
  created_at: 2023-07-29 09:20:57+00:00
  edited: false
  hidden: false
  id: 64c4e8094399efa2fd8d44f7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/starcoder-GPTQ
repo_type: model
status: open
target_branch: null
title: GPU memory usage/requirement?
