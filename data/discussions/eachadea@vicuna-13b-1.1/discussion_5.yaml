!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hellothereeeee
conflicting_files: null
created_at: 2023-04-26 03:12:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660387639011-noauth.png?w=200&h=200&f=face
      fullname: JohnDOe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hellothereeeee
      type: user
    createdAt: '2023-04-26T04:12:58.000Z'
    data:
      edited: true
      editors:
      - hellothereeeee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660387639011-noauth.png?w=200&h=200&f=face
          fullname: JohnDOe
          isHf: false
          isPro: false
          name: hellothereeeee
          type: user
        html: '<p>downloading al the models worked but that was 50 gigabytes... then
          installing one model broke oobabooga, so i just gave up and used legacy.
          can you fix the problem? i have the bug report here <a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui/issues/1495">https://github.com/oobabooga/text-generation-webui/issues/1495</a></p>

          <p>p.s realized this wasnt the ggml version, pretend it is the ggml version.</p>

          '
        raw: 'downloading al the models worked but that was 50 gigabytes... then installing
          one model broke oobabooga, so i just gave up and used legacy. can you fix
          the problem? i have the bug report here https://github.com/oobabooga/text-generation-webui/issues/1495


          p.s realized this wasnt the ggml version, pretend it is the ggml version.'
        updatedAt: '2023-04-26T04:15:46.012Z'
      numEdits: 1
      reactions: []
    id: 6448a4cae21484883408d81c
    type: comment
  author: hellothereeeee
  content: 'downloading al the models worked but that was 50 gigabytes... then installing
    one model broke oobabooga, so i just gave up and used legacy. can you fix the
    problem? i have the bug report here https://github.com/oobabooga/text-generation-webui/issues/1495


    p.s realized this wasnt the ggml version, pretend it is the ggml version.'
  created_at: 2023-04-26 03:12:58+00:00
  edited: true
  hidden: false
  id: 6448a4cae21484883408d81c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2aa85df44ff24543d8be/mEnbGB_0Flleoa6SWp5b6.jpeg?w=200&h=200&f=face
      fullname: amkdg
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: eachadea
      type: user
    createdAt: '2023-04-26T04:17:25.000Z'
    data:
      edited: true
      editors:
      - eachadea
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2aa85df44ff24543d8be/mEnbGB_0Flleoa6SWp5b6.jpeg?w=200&h=200&f=face
          fullname: amkdg
          isHf: false
          isPro: false
          name: eachadea
          type: user
        html: '<p>Assuming you''re the author of the issue, you''re trying to load
          the ggml 13b q4_2 into oobabooga. That''s a different model from what''s
          on this repository.</p>

          <p>Anyways, the problem is in the fact that oobabooga doesn''t use the latest
          llama.cpp bindings. You will have to update those manually or wait until
          oobabooga ships an update.</p>

          '
        raw: 'Assuming you''re the author of the issue, you''re trying to load the
          ggml 13b q4_2 into oobabooga. That''s a different model from what''s on
          this repository.


          Anyways, the problem is in the fact that oobabooga doesn''t use the latest
          llama.cpp bindings. You will have to update those manually or wait until
          oobabooga ships an update.'
        updatedAt: '2023-04-26T04:19:32.739Z'
      numEdits: 1
      reactions: []
    id: 6448a5d5058f3572dd2122aa
    type: comment
  author: eachadea
  content: 'Assuming you''re the author of the issue, you''re trying to load the ggml
    13b q4_2 into oobabooga. That''s a different model from what''s on this repository.


    Anyways, the problem is in the fact that oobabooga doesn''t use the latest llama.cpp
    bindings. You will have to update those manually or wait until oobabooga ships
    an update.'
  created_at: 2023-04-26 03:17:25+00:00
  edited: true
  hidden: false
  id: 6448a5d5058f3572dd2122aa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2aa85df44ff24543d8be/mEnbGB_0Flleoa6SWp5b6.jpeg?w=200&h=200&f=face
      fullname: amkdg
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: eachadea
      type: user
    createdAt: '2023-04-26T04:18:19.000Z'
    data:
      edited: false
      editors:
      - eachadea
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642b2aa85df44ff24543d8be/mEnbGB_0Flleoa6SWp5b6.jpeg?w=200&h=200&f=face
          fullname: amkdg
          isHf: false
          isPro: false
          name: eachadea
          type: user
        html: '<p>Overall, my ggml conversions use bleeding edge quantization that
          absolutely requires the latest version of llama.cpp to work.</p>

          '
        raw: Overall, my ggml conversions use bleeding edge quantization that absolutely
          requires the latest version of llama.cpp to work.
        updatedAt: '2023-04-26T04:18:19.543Z'
      numEdits: 0
      reactions: []
    id: 6448a60be54b488070bf8765
    type: comment
  author: eachadea
  content: Overall, my ggml conversions use bleeding edge quantization that absolutely
    requires the latest version of llama.cpp to work.
  created_at: 2023-04-26 03:18:19+00:00
  edited: false
  hidden: false
  id: 6448a60be54b488070bf8765
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660387639011-noauth.png?w=200&h=200&f=face
      fullname: JohnDOe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hellothereeeee
      type: user
    createdAt: '2023-04-26T15:28:50.000Z'
    data:
      edited: false
      editors:
      - hellothereeeee
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660387639011-noauth.png?w=200&h=200&f=face
          fullname: JohnDOe
          isHf: false
          isPro: false
          name: hellothereeeee
          type: user
        html: '<p>i see, i''ll wait for a new llama.cpp update. thanks!</p>

          '
        raw: i see, i'll wait for a new llama.cpp update. thanks!
        updatedAt: '2023-04-26T15:28:50.446Z'
      numEdits: 0
      reactions: []
      relatedEventId: 644943321af713976c2c96d3
    id: 644943321af713976c2c96d2
    type: comment
  author: hellothereeeee
  content: i see, i'll wait for a new llama.cpp update. thanks!
  created_at: 2023-04-26 14:28:50+00:00
  edited: false
  hidden: false
  id: 644943321af713976c2c96d2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660387639011-noauth.png?w=200&h=200&f=face
      fullname: JohnDOe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hellothereeeee
      type: user
    createdAt: '2023-04-26T15:28:50.000Z'
    data:
      status: closed
    id: 644943321af713976c2c96d3
    type: status-change
  author: hellothereeeee
  created_at: 2023-04-26 14:28:50+00:00
  id: 644943321af713976c2c96d3
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: eachadea/vicuna-13b-1.1
repo_type: model
status: closed
target_branch: null
title: just saying it breaks whenever i get individual models to load for oobabooga
