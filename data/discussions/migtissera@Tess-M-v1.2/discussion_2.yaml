!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Yhyu13
conflicting_files: null
created_at: 2023-11-24 02:52:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-11-24T02:52:55.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9338122606277466
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<p>Hi,</p>

          <p>I''ve tested v1.1 Tess a little bit, it outputs just other LLaMA models
          than Yi-34B</p>

          <p>Try this question : "What will AI be like in the year 1010 A.D? Think
          Step by step!"</p>

          <p>The original Yi-34B and Nous-Capybara-34B are able to find out the catch-ya
          in this question that AI does not exists in 1010.</p>

          <p>But most LLaMA cannot figure this out and fail, so does Tess v1.1.<br>Also,
          Yi-34B sft models like OrionStar &amp; Dolphin 2.2 would also fail to this
          question</p>

          <p>I am speculating this is due to too large amount of sft data? </p>

          <p>E.g. Nous-Capybara-34B only use 20K samples sft data, seems pretty small.
          So it would stay close to Yi-34B''s originality</p>

          '
        raw: "Hi,\r\n\r\nI've tested v1.1 Tess a little bit, it outputs just other\
          \ LLaMA models than Yi-34B\r\n\r\nTry this question : \"What will AI be\
          \ like in the year 1010 A.D? Think Step by step!\"\r\n\r\nThe original Yi-34B\
          \ and Nous-Capybara-34B are able to find out the catch-ya in this question\
          \ that AI does not exists in 1010.\r\n\r\nBut most LLaMA cannot figure this\
          \ out and fail, so does Tess v1.1. \r\nAlso, Yi-34B sft models like OrionStar\
          \ & Dolphin 2.2 would also fail to this question\r\n\r\nI am speculating\
          \ this is due to too large amount of sft data? \r\n\r\nE.g. Nous-Capybara-34B\
          \ only use 20K samples sft data, seems pretty small. So it would stay close\
          \ to Yi-34B's originality"
        updatedAt: '2023-11-24T02:52:55.037Z'
      numEdits: 0
      reactions: []
    id: 65601007b3c95b72253c60e1
    type: comment
  author: Yhyu13
  content: "Hi,\r\n\r\nI've tested v1.1 Tess a little bit, it outputs just other LLaMA\
    \ models than Yi-34B\r\n\r\nTry this question : \"What will AI be like in the\
    \ year 1010 A.D? Think Step by step!\"\r\n\r\nThe original Yi-34B and Nous-Capybara-34B\
    \ are able to find out the catch-ya in this question that AI does not exists in\
    \ 1010.\r\n\r\nBut most LLaMA cannot figure this out and fail, so does Tess v1.1.\
    \ \r\nAlso, Yi-34B sft models like OrionStar & Dolphin 2.2 would also fail to\
    \ this question\r\n\r\nI am speculating this is due to too large amount of sft\
    \ data? \r\n\r\nE.g. Nous-Capybara-34B only use 20K samples sft data, seems pretty\
    \ small. So it would stay close to Yi-34B's originality"
  created_at: 2023-11-24 02:52:55+00:00
  edited: false
  hidden: false
  id: 65601007b3c95b72253c60e1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
      fullname: Migel Tissera
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: migtissera
      type: user
    createdAt: '2023-11-24T05:06:14.000Z'
    data:
      edited: false
      editors:
      - migtissera
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9622840285301208
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
          fullname: Migel Tissera
          isHf: false
          isPro: false
          name: migtissera
          type: user
        html: '<p>Could be! Bear with me, I''m still doing a lot of R&amp;D. </p>

          <p>Feedback helps though!</p>

          '
        raw: "Could be! Bear with me, I'm still doing a lot of R&D. \n\nFeedback helps\
          \ though!"
        updatedAt: '2023-11-24T05:06:14.426Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F91D"
        users:
        - Yhyu13
        - SamuelAzran
    id: 65602f46f3cf301d2f4b2824
    type: comment
  author: migtissera
  content: "Could be! Bear with me, I'm still doing a lot of R&D. \n\nFeedback helps\
    \ though!"
  created_at: 2023-11-24 05:06:14+00:00
  edited: false
  hidden: false
  id: 65602f46f3cf301d2f4b2824
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: migtissera/Tess-M-v1.2
repo_type: model
status: open
target_branch: null
title: Too many datasets? Feeling Tess more like other LLaMA than Yi-34B
