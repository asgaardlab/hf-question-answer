!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Hodophile
conflicting_files: null
created_at: 2023-08-09 03:45:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/aOsbtx6wAs-yQMRfyvvHT.jpeg?w=200&h=200&f=face
      fullname: Shihang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hodophile
      type: user
    createdAt: '2023-08-09T04:45:23.000Z'
    data:
      edited: false
      editors:
      - Hodophile
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9577980637550354
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/aOsbtx6wAs-yQMRfyvvHT.jpeg?w=200&h=200&f=face
          fullname: Shihang
          isHf: false
          isPro: false
          name: Hodophile
          type: user
        html: '<p>Hello, I fine-tuned the original starcoder model with my own repository
          and want to adapt it to the quantized version after fine-tuning. Due to
          extra parameters adapted during fine-tuning, the original conversion code
          fails as expected. What could I do to fix this issue?</p>

          <p>Thanks in advance.</p>

          '
        raw: "Hello, I fine-tuned the original starcoder model with my own repository\
          \ and want to adapt it to the quantized version after fine-tuning. Due to\
          \ extra parameters adapted during fine-tuning, the original conversion code\
          \ fails as expected. What could I do to fix this issue?\r\n\r\nThanks in\
          \ advance."
        updatedAt: '2023-08-09T04:45:23.076Z'
      numEdits: 0
      reactions: []
    id: 64d319e3bbe1b260492985f3
    type: comment
  author: Hodophile
  content: "Hello, I fine-tuned the original starcoder model with my own repository\
    \ and want to adapt it to the quantized version after fine-tuning. Due to extra\
    \ parameters adapted during fine-tuning, the original conversion code fails as\
    \ expected. What could I do to fix this issue?\r\n\r\nThanks in advance."
  created_at: 2023-08-09 03:45:23+00:00
  edited: false
  hidden: false
  id: 64d319e3bbe1b260492985f3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
      fullname: Michael
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: michaelfeil
      type: user
    createdAt: '2023-08-16T08:36:49.000Z'
    data:
      edited: true
      editors:
      - michaelfeil
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.1014653667807579
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/644fac0ce1d7a97f3b653ab1/fottSAPFrJdKeMW2UJv_l.jpeg?w=200&h=200&f=face
          fullname: Michael
          isHf: false
          isPro: false
          name: michaelfeil
          type: user
        html: '<p>Yes, you can start also with other models that are in <code>GPTBigCode</code>
          format.</p>

          <p>Is this command failing?</p>

          <pre><code>ct2-transformers-converter --model bigcode/starcoder --output_dir
          ~/tmp-ct2fast-starcoder --force --copy_files merges.txt tokenizer.json README.md
          tokenizer_config.json vocab.json generation_config.json special_tokens_map.json
          .gitattributes --quantization int8_float16 --trust_remote_code

          </code></pre>

          '
        raw: 'Yes, you can start also with other models that are in `GPTBigCode` format.



          Is this command failing?

          ```

          ct2-transformers-converter --model bigcode/starcoder --output_dir ~/tmp-ct2fast-starcoder
          --force --copy_files merges.txt tokenizer.json README.md tokenizer_config.json
          vocab.json generation_config.json special_tokens_map.json .gitattributes
          --quantization int8_float16 --trust_remote_code

          ```'
        updatedAt: '2023-09-24T10:24:48.305Z'
      numEdits: 1
      reactions: []
    id: 64dc8aa1dff51ca6b3696a8a
    type: comment
  author: michaelfeil
  content: 'Yes, you can start also with other models that are in `GPTBigCode` format.



    Is this command failing?

    ```

    ct2-transformers-converter --model bigcode/starcoder --output_dir ~/tmp-ct2fast-starcoder
    --force --copy_files merges.txt tokenizer.json README.md tokenizer_config.json
    vocab.json generation_config.json special_tokens_map.json .gitattributes --quantization
    int8_float16 --trust_remote_code

    ```'
  created_at: 2023-08-16 07:36:49+00:00
  edited: true
  hidden: false
  id: 64dc8aa1dff51ca6b3696a8a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: michaelfeil/ct2fast-starcoder
repo_type: model
status: open
target_branch: null
title: Can ct2 be used to convert a fine-tuned version of starcoder?
