!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Fryzer
conflicting_files: null
created_at: 2022-10-24 17:10:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9d0a165e8f9eca17cce97f7222ae13bc.svg
      fullname: Yehor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Fryzer
      type: user
    createdAt: '2022-10-24T18:10:29.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/9d0a165e8f9eca17cce97f7222ae13bc.svg
          fullname: Yehor
          isHf: false
          isPro: false
          name: Fryzer
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2022-10-24T18:18:00.764Z'
      numEdits: 1
      reactions: []
    id: 6356d5153c32f2c90f4e5fa4
    type: comment
  author: Fryzer
  content: This comment has been hidden
  created_at: 2022-10-24 17:10:29+00:00
  edited: true
  hidden: true
  id: 6356d5153c32f2c90f4e5fa4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1656947829490-62c30111dc0861038980f4be.png?w=200&h=200&f=face
      fullname: Brian Dunn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DunnBC22
      type: user
    createdAt: '2023-04-20T16:32:37.000Z'
    data:
      edited: false
      editors:
      - DunnBC22
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1656947829490-62c30111dc0861038980f4be.png?w=200&h=200&f=face
          fullname: Brian Dunn
          isHf: false
          isPro: false
          name: DunnBC22
          type: user
        html: '<p>Hello, I am experiencing a similar issue. The following message
          shows up in between each response:</p>

          <p>"A decoder-only architecture is being used, but right-padding was detected!
          For correct generation results, please set <code>padding_side=''left''</code>
          when initializing the tokenizer."</p>

          <p>Technically, I am using a fine-tuned version that I trained using the
          DialoGPT-large checkpoint, but when I saw this post, I felt it was best
          to post this here.  I have tried adding the padding_side during the fine-tuning
          training, in the from_pretrained instantiation of the tokenizer in the chatbot,
          as well as adding it as an argument in the tokenizer.encode method.</p>

          <p>Any assistance would be greatly appreciated!</p>

          '
        raw: 'Hello, I am experiencing a similar issue. The following message shows
          up in between each response:


          "A decoder-only architecture is being used, but right-padding was detected!
          For correct generation results, please set `padding_side=''left''` when
          initializing the tokenizer."


          Technically, I am using a fine-tuned version that I trained using the DialoGPT-large
          checkpoint, but when I saw this post, I felt it was best to post this here.  I
          have tried adding the padding_side during the fine-tuning training, in the
          from_pretrained instantiation of the tokenizer in the chatbot, as well as
          adding it as an argument in the tokenizer.encode method.


          Any assistance would be greatly appreciated!'
        updatedAt: '2023-04-20T16:32:37.676Z'
      numEdits: 0
      reactions: []
    id: 644169257f13a7b5a266dedb
    type: comment
  author: DunnBC22
  content: 'Hello, I am experiencing a similar issue. The following message shows
    up in between each response:


    "A decoder-only architecture is being used, but right-padding was detected! For
    correct generation results, please set `padding_side=''left''` when initializing
    the tokenizer."


    Technically, I am using a fine-tuned version that I trained using the DialoGPT-large
    checkpoint, but when I saw this post, I felt it was best to post this here.  I
    have tried adding the padding_side during the fine-tuning training, in the from_pretrained
    instantiation of the tokenizer in the chatbot, as well as adding it as an argument
    in the tokenizer.encode method.


    Any assistance would be greatly appreciated!'
  created_at: 2023-04-20 15:32:37+00:00
  edited: false
  hidden: false
  id: 644169257f13a7b5a266dedb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: microsoft/DialoGPT-medium
repo_type: model
status: open
target_branch: null
title: padding_side
