!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ashmal
conflicting_files: null
created_at: 2023-09-18 05:36:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d2330cc307db32f5e2b2dab0a5a4e4a.svg
      fullname: Ashmal Vayani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ashmal
      type: user
    createdAt: '2023-09-18T06:36:38.000Z'
    data:
      edited: false
      editors:
      - Ashmal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7855474352836609
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d2330cc307db32f5e2b2dab0a5a4e4a.svg
          fullname: Ashmal Vayani
          isHf: false
          isPro: false
          name: Ashmal
          type: user
        html: '<p>zrthxn/vicuna-embedding does not appear to have a file named config.json.
          Checkout ''<a href="https://huggingface.co/zrthxn/vicuna-embedding/main''">https://huggingface.co/zrthxn/vicuna-embedding/main''</a>
          for available files.</p>

          '
        raw: zrthxn/vicuna-embedding does not appear to have a file named config.json.
          Checkout 'https://huggingface.co/zrthxn/vicuna-embedding/main' for available
          files.
        updatedAt: '2023-09-18T06:36:38.448Z'
      numEdits: 0
      reactions: []
    id: 6507eff61704c7eb0aa5bf21
    type: comment
  author: Ashmal
  content: zrthxn/vicuna-embedding does not appear to have a file named config.json.
    Checkout 'https://huggingface.co/zrthxn/vicuna-embedding/main' for available files.
  created_at: 2023-09-18 05:36:38+00:00
  edited: false
  hidden: false
  id: 6507eff61704c7eb0aa5bf21
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19c5adaca4feebe1b69b793610827174.svg
      fullname: Alisamar Husain
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: zrthxn
      type: user
    createdAt: '2023-09-18T07:43:25.000Z'
    data:
      edited: false
      editors:
      - zrthxn
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6527729630470276
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19c5adaca4feebe1b69b793610827174.svg
          fullname: Alisamar Husain
          isHf: false
          isPro: false
          name: zrthxn
          type: user
        html: "<p>Config file for this doesn't exist because this doesnt work with\
          \ a existing HF model. You have to manually load the model and tokenizer.</p>\n\
          <p>Something like...</p>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">from</span> torch <span class=\"hljs-keyword\">import</span>\
          \ nn\n\n<span class=\"hljs-comment\"># ...</span>\ntokenizer = LlamaTokenizer.from_pretrained(<span\
          \ class=\"hljs-string\">\"...\"</span>)\n\n<span class=\"hljs-comment\"\
          ># ...</span>\nembed = nn.Embedding(config.vocab_size, config.hidden_size,\
          \ config.padding_idx)\n<span class=\"hljs-keyword\">with</span> <span class=\"\
          hljs-built_in\">open</span>(Path(base_path).joinpath(<span class=\"hljs-string\"\
          >\"llama_embed.bin\"</span>), <span class=\"hljs-string\">\"rb\"</span>)\
          \ <span class=\"hljs-keyword\">as</span> f: \n         state_dict = torch.load(f,\
          \ map_location=device) \n         \nembed.load_state_dict(state_dict, strict=<span\
          \ class=\"hljs-literal\">True</span>)\n</code></pre>\n"
        raw: "Config file for this doesn't exist because this doesnt work with a existing\
          \ HF model. You have to manually load the model and tokenizer.\n\nSomething\
          \ like...\n```python\nfrom torch import nn\n\n# ...\ntokenizer = LlamaTokenizer.from_pretrained(\"\
          ...\")\n\n# ...\nembed = nn.Embedding(config.vocab_size, config.hidden_size,\
          \ config.padding_idx)\nwith open(Path(base_path).joinpath(\"llama_embed.bin\"\
          ), \"rb\") as f: \n         state_dict = torch.load(f, map_location=device)\
          \ \n         \nembed.load_state_dict(state_dict, strict=True)\n```\n\n"
        updatedAt: '2023-09-18T07:43:25.722Z'
      numEdits: 0
      reactions: []
    id: 6507ff9ddacc94cd6c2c1e07
    type: comment
  author: zrthxn
  content: "Config file for this doesn't exist because this doesnt work with a existing\
    \ HF model. You have to manually load the model and tokenizer.\n\nSomething like...\n\
    ```python\nfrom torch import nn\n\n# ...\ntokenizer = LlamaTokenizer.from_pretrained(\"\
    ...\")\n\n# ...\nembed = nn.Embedding(config.vocab_size, config.hidden_size, config.padding_idx)\n\
    with open(Path(base_path).joinpath(\"llama_embed.bin\"), \"rb\") as f: \n    \
    \     state_dict = torch.load(f, map_location=device) \n         \nembed.load_state_dict(state_dict,\
    \ strict=True)\n```\n\n"
  created_at: 2023-09-18 06:43:25+00:00
  edited: false
  hidden: false
  id: 6507ff9ddacc94cd6c2c1e07
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: zrthxn/vicuna-embedding
repo_type: model
status: open
target_branch: null
title: config.json file missing
