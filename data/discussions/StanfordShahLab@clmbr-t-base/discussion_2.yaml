!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ndhendrix
conflicting_files: null
created_at: 2024-01-09 17:25:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/17bf17bca567591513f7f69136f8eedb.svg
      fullname: Nathaniel Hendrix
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ndhendrix
      type: user
    createdAt: '2024-01-09T17:25:45.000Z'
    data:
      edited: false
      editors:
      - ndhendrix
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.44180265069007874
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/17bf17bca567591513f7f69136f8eedb.svg
          fullname: Nathaniel Hendrix
          isHf: false
          isPro: false
          name: ndhendrix
          type: user
        html: '<p>Hello,</p>

          <p>I''m trying to run CLMBR-T on a GPU-enabled Nero instance and can''t
          get the demo code to work. I''ve entered it exactly as on the model card
          and am getting the following error:</p>

          <hr>

          <p>TypeError                                 Traceback (most recent call
          last)<br>Cell In[6], line 2<br>      1 # Load model<br>----&gt; 2 model
          = femr.models.transformer.FEMRModel.from_pretrained(model_name)<br>      4
          # Run model<br>      5 with torch.no_grad():</p>

          <p>File /opt/conda/envs/ehrshot_env/lib/python3.10/site-packages/transformers/modeling_utils.py:3236,
          in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, config,
          cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token,
          revision, use_safetensors, *model_args, **kwargs)<br>   3233     config
          = cls._check_and_enable_flash_attn_2(config, torch_dtype=torch_dtype, device_map=device_map)<br>   3235
          with ContextManagers(init_contexts):<br>-&gt; 3236     model = cls(config,
          *model_args, **model_kwargs)<br>   3238 # make sure we use the model''s
          config since the <strong>init</strong> call might have copied it<br>   3239
          config = model.config</p>

          <p>File /opt/conda/envs/ehrshot_env/lib/python3.10/site-packages/femr/models/transformer.py:234,
          in FEMRModel.<strong>init</strong>(self, config, **kwargs)<br>    232 self.transformer
          = FEMRTransformer(self.config.transformer_config)<br>    233 if self.config.task_config
          is not None:<br>--&gt; 234     self.task_model = self.config.task_config.create_task_head(self.config.transformer_config.hidden_size)</p>

          <p>File /opt/conda/envs/ehrshot_env/lib/python3.10/site-packages/femr/models/transformer.py:193,
          in FEMRTaskConfig.create_task_head(self, hidden_size)<br>    191 def create_task_head(self,
          hidden_size: int):<br>    192     if self.task_type == "clmbr":<br>--&gt;
          193         return CLMBRTaskHead(hidden_size, **self.kwargs)<br>    194     elif
          self.task_type == "labeled_patients":<br>    195         return LabeledPatientTaskHead(hidden_size,
          **self.kwargs)</p>

          <h2 id="typeerror-clmbrtaskheadinit-got-an-unexpected-keyword-argument-_name_or_path">TypeError:
          CLMBRTaskHead.<strong>init</strong>() got an unexpected keyword argument
          ''_name_or_path''</h2>

          <p>Could you let me know how to fix this please? Thanks.</p>

          '
        raw: "Hello,\r\n\r\nI'm trying to run CLMBR-T on a GPU-enabled Nero instance\
          \ and can't get the demo code to work. I've entered it exactly as on the\
          \ model card and am getting the following error:\r\n\r\n---------------------------------------------------------------------------\r\
          \nTypeError                                 Traceback (most recent call\
          \ last)\r\nCell In[6], line 2\r\n      1 # Load model\r\n----> 2 model =\
          \ femr.models.transformer.FEMRModel.from_pretrained(model_name)\r\n    \
          \  4 # Run model\r\n      5 with torch.no_grad():\r\n\r\nFile /opt/conda/envs/ehrshot_env/lib/python3.10/site-packages/transformers/modeling_utils.py:3236,\
          \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path,\
          \ config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only,\
          \ token, revision, use_safetensors, *model_args, **kwargs)\r\n   3233  \
          \   config = cls._check_and_enable_flash_attn_2(config, torch_dtype=torch_dtype,\
          \ device_map=device_map)\r\n   3235 with ContextManagers(init_contexts):\r\
          \n-> 3236     model = cls(config, *model_args, **model_kwargs)\r\n   3238\
          \ # make sure we use the model's config since the __init__ call might have\
          \ copied it\r\n   3239 config = model.config\r\n\r\nFile /opt/conda/envs/ehrshot_env/lib/python3.10/site-packages/femr/models/transformer.py:234,\
          \ in FEMRModel.__init__(self, config, **kwargs)\r\n    232 self.transformer\
          \ = FEMRTransformer(self.config.transformer_config)\r\n    233 if self.config.task_config\
          \ is not None:\r\n--> 234     self.task_model = self.config.task_config.create_task_head(self.config.transformer_config.hidden_size)\r\
          \n\r\nFile /opt/conda/envs/ehrshot_env/lib/python3.10/site-packages/femr/models/transformer.py:193,\
          \ in FEMRTaskConfig.create_task_head(self, hidden_size)\r\n    191 def create_task_head(self,\
          \ hidden_size: int):\r\n    192     if self.task_type == \"clmbr\":\r\n\
          --> 193         return CLMBRTaskHead(hidden_size, **self.kwargs)\r\n   \
          \ 194     elif self.task_type == \"labeled_patients\":\r\n    195      \
          \   return LabeledPatientTaskHead(hidden_size, **self.kwargs)\r\n\r\nTypeError:\
          \ CLMBRTaskHead.__init__() got an unexpected keyword argument '_name_or_path'\r\
          \n-----\r\n\r\nCould you let me know how to fix this please? Thanks."
        updatedAt: '2024-01-09T17:25:45.735Z'
      numEdits: 0
      reactions: []
    id: 659d81991723f371c9cc77a6
    type: comment
  author: ndhendrix
  content: "Hello,\r\n\r\nI'm trying to run CLMBR-T on a GPU-enabled Nero instance\
    \ and can't get the demo code to work. I've entered it exactly as on the model\
    \ card and am getting the following error:\r\n\r\n---------------------------------------------------------------------------\r\
    \nTypeError                                 Traceback (most recent call last)\r\
    \nCell In[6], line 2\r\n      1 # Load model\r\n----> 2 model = femr.models.transformer.FEMRModel.from_pretrained(model_name)\r\
    \n      4 # Run model\r\n      5 with torch.no_grad():\r\n\r\nFile /opt/conda/envs/ehrshot_env/lib/python3.10/site-packages/transformers/modeling_utils.py:3236,\
    \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, config,\
    \ cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token,\
    \ revision, use_safetensors, *model_args, **kwargs)\r\n   3233     config = cls._check_and_enable_flash_attn_2(config,\
    \ torch_dtype=torch_dtype, device_map=device_map)\r\n   3235 with ContextManagers(init_contexts):\r\
    \n-> 3236     model = cls(config, *model_args, **model_kwargs)\r\n   3238 # make\
    \ sure we use the model's config since the __init__ call might have copied it\r\
    \n   3239 config = model.config\r\n\r\nFile /opt/conda/envs/ehrshot_env/lib/python3.10/site-packages/femr/models/transformer.py:234,\
    \ in FEMRModel.__init__(self, config, **kwargs)\r\n    232 self.transformer =\
    \ FEMRTransformer(self.config.transformer_config)\r\n    233 if self.config.task_config\
    \ is not None:\r\n--> 234     self.task_model = self.config.task_config.create_task_head(self.config.transformer_config.hidden_size)\r\
    \n\r\nFile /opt/conda/envs/ehrshot_env/lib/python3.10/site-packages/femr/models/transformer.py:193,\
    \ in FEMRTaskConfig.create_task_head(self, hidden_size)\r\n    191 def create_task_head(self,\
    \ hidden_size: int):\r\n    192     if self.task_type == \"clmbr\":\r\n--> 193\
    \         return CLMBRTaskHead(hidden_size, **self.kwargs)\r\n    194     elif\
    \ self.task_type == \"labeled_patients\":\r\n    195         return LabeledPatientTaskHead(hidden_size,\
    \ **self.kwargs)\r\n\r\nTypeError: CLMBRTaskHead.__init__() got an unexpected\
    \ keyword argument '_name_or_path'\r\n-----\r\n\r\nCould you let me know how to\
    \ fix this please? Thanks."
  created_at: 2024-01-09 17:25:45+00:00
  edited: false
  hidden: false
  id: 659d81991723f371c9cc77a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a50df2c0618b49739bb6db57d1aa2b8.svg
      fullname: Michael Wornow
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Miking98
      type: user
    createdAt: '2024-01-17T01:46:11.000Z'
    data:
      edited: false
      editors:
      - Miking98
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8588358163833618
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a50df2c0618b49739bb6db57d1aa2b8.svg
          fullname: Michael Wornow
          isHf: false
          isPro: false
          name: Miking98
          type: user
        html: '<p>Thanks for the note!</p>

          <p>This should be fixed in this commit: <a rel="nofollow" href="https://github.com/som-shahlab/femr/commit/746cb8eead3ffe0cd94445df0a9c7ddadb7a37f9">https://github.com/som-shahlab/femr/commit/746cb8eead3ffe0cd94445df0a9c7ddadb7a37f9</a></p>

          <p>(it''s a one line fix to basically just add <code>**kwargs</code> to
          the <code>__init__</code> of <code>CLMBRTaskHead</code>. </p>

          <p>This should be merged within the next update of FEMR, and will update
          you once that is merged!</p>

          '
        raw: "Thanks for the note!\n\nThis should be fixed in this commit: https://github.com/som-shahlab/femr/commit/746cb8eead3ffe0cd94445df0a9c7ddadb7a37f9\n\
          \n(it's a one line fix to basically just add `**kwargs` to the `__init__`\
          \ of `CLMBRTaskHead`. \n\nThis should be merged within the next update of\
          \ FEMR, and will update you once that is merged!"
        updatedAt: '2024-01-17T01:46:11.335Z'
      numEdits: 0
      reactions: []
    id: 65a73163b3c1a539e055bd35
    type: comment
  author: Miking98
  content: "Thanks for the note!\n\nThis should be fixed in this commit: https://github.com/som-shahlab/femr/commit/746cb8eead3ffe0cd94445df0a9c7ddadb7a37f9\n\
    \n(it's a one line fix to basically just add `**kwargs` to the `__init__` of `CLMBRTaskHead`.\
    \ \n\nThis should be merged within the next update of FEMR, and will update you\
    \ once that is merged!"
  created_at: 2024-01-17 01:46:11+00:00
  edited: false
  hidden: false
  id: 65a73163b3c1a539e055bd35
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: StanfordShahLab/clmbr-t-base
repo_type: model
status: open
target_branch: null
title: CLMBRTaskHead.__init__() got an unexpected keyword argument '_name_or_path'
