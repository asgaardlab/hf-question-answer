!!python/object:huggingface_hub.community.DiscussionWithDetails
author: flashvenom
conflicting_files: null
created_at: 2023-06-23 05:03:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637c621facc078d5bec14073/MOKvlABZuesOL3rVmxalE.png?w=200&h=200&f=face
      fullname: FlashVenom
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: flashvenom
      type: user
    createdAt: '2023-06-23T06:03:17.000Z'
    data:
      edited: false
      editors:
      - flashvenom
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9403376579284668
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637c621facc078d5bec14073/MOKvlABZuesOL3rVmxalE.png?w=200&h=200&f=face
          fullname: FlashVenom
          isHf: false
          isPro: false
          name: flashvenom
          type: user
        html: '<p>Have you tried benchmarking this model? Curious to see what the
          orca approach does</p>

          '
        raw: Have you tried benchmarking this model? Curious to see what the orca
          approach does
        updatedAt: '2023-06-23T06:03:17.366Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - lyogavin
        - Thireus
    id: 649535a5a43e658ad7572512
    type: comment
  author: flashvenom
  content: Have you tried benchmarking this model? Curious to see what the orca approach
    does
  created_at: 2023-06-23 05:03:17+00:00
  edited: false
  hidden: false
  id: 649535a5a43e658ad7572512
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f0b9bb3610282e0abc7937d443dc45a3.svg
      fullname: Pankaj Mathur
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: pankajmathur
      type: user
    createdAt: '2023-06-23T12:56:19.000Z'
    data:
      edited: false
      editors:
      - pankajmathur
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9553261995315552
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f0b9bb3610282e0abc7937d443dc45a3.svg
          fullname: Pankaj Mathur
          isHf: false
          isPro: true
          name: pankajmathur
          type: user
        html: '<p>Hi,<br>Thanks, Yes I am in process to do so, we just finished training
          last night. Any particular recommendations? </p>

          '
        raw: 'Hi,

          Thanks, Yes I am in process to do so, we just finished training last night.
          Any particular recommendations? '
        updatedAt: '2023-06-23T12:56:19.353Z'
      numEdits: 0
      reactions: []
    id: 649596739154833c026946e9
    type: comment
  author: pankajmathur
  content: 'Hi,

    Thanks, Yes I am in process to do so, we just finished training last night. Any
    particular recommendations? '
  created_at: 2023-06-23 11:56:19+00:00
  edited: false
  hidden: false
  id: 649596739154833c026946e9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/fslWfmIFO0MVpRsZqO8Sv.png?w=200&h=200&f=face
      fullname: MoffKalast
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MoffKalast
      type: user
    createdAt: '2023-06-25T10:16:44.000Z'
    data:
      edited: true
      editors:
      - MoffKalast
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9858408570289612
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/fslWfmIFO0MVpRsZqO8Sv.png?w=200&h=200&f=face
          fullname: MoffKalast
          isHf: false
          isPro: false
          name: MoffKalast
          type: user
        html: '<p>HumanEval seems appropriate to check, since better reasoning should
          also lead to better programming performance and it''s typically most indicative
          of relative model performance.</p>

          '
        raw: HumanEval seems appropriate to check, since better reasoning should also
          lead to better programming performance and it's typically most indicative
          of relative model performance.
        updatedAt: '2023-06-25T10:17:04.860Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Bilibili
    id: 6498140c495016563ea9b719
    type: comment
  author: MoffKalast
  content: HumanEval seems appropriate to check, since better reasoning should also
    lead to better programming performance and it's typically most indicative of relative
    model performance.
  created_at: 2023-06-25 09:16:44+00:00
  edited: true
  hidden: false
  id: 6498140c495016563ea9b719
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640162547139-61c2e44c39245e7bf62def6f.jpeg?w=200&h=200&f=face
      fullname: Bilibili
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bilibili
      type: user
    createdAt: '2023-06-25T12:19:54.000Z'
    data:
      edited: false
      editors:
      - Bilibili
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9674088954925537
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640162547139-61c2e44c39245e7bf62def6f.jpeg?w=200&h=200&f=face
          fullname: Bilibili
          isHf: false
          isPro: false
          name: Bilibili
          type: user
        html: '<blockquote>

          <p>HumanEval seems appropriate to check, since better reasoning should also
          lead to better programming performance and it''s typically most indicative
          of relative model performance.</p>

          </blockquote>

          <p>Yeah, though HE is pretty limited and not representative for real-world
          development, it is the simplest way to evaluate the functional correctness
          of code generation capability.</p>

          '
        raw: '> HumanEval seems appropriate to check, since better reasoning should
          also lead to better programming performance and it''s typically most indicative
          of relative model performance.


          Yeah, though HE is pretty limited and not representative for real-world
          development, it is the simplest way to evaluate the functional correctness
          of code generation capability.'
        updatedAt: '2023-06-25T12:19:54.020Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - pankajmathur
        - Bilibili
    id: 649830ea290b63c3881448d4
    type: comment
  author: Bilibili
  content: '> HumanEval seems appropriate to check, since better reasoning should
    also lead to better programming performance and it''s typically most indicative
    of relative model performance.


    Yeah, though HE is pretty limited and not representative for real-world development,
    it is the simplest way to evaluate the functional correctness of code generation
    capability.'
  created_at: 2023-06-25 11:19:54+00:00
  edited: false
  hidden: false
  id: 649830ea290b63c3881448d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/452074cb947ed07f173263edf6beefac.svg
      fullname: m
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NickM2002
      type: user
    createdAt: '2023-06-26T15:21:25.000Z'
    data:
      edited: true
      editors:
      - NickM2002
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.973393440246582
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/452074cb947ed07f173263edf6beefac.svg
          fullname: m
          isHf: false
          isPro: false
          name: NickM2002
          type: user
        html: '<p>Do you have any plans to retrain the model for a larger context
          window, possibly with qlora and landmark. This model seems to preform so
          good under 1k tokens, I would love to see it be able to do more!</p>

          '
        raw: Do you have any plans to retrain the model for a larger context window,
          possibly with qlora and landmark. This model seems to preform so good under
          1k tokens, I would love to see it be able to do more!
        updatedAt: '2023-06-26T15:22:02.120Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - pankajmathur
    id: 6499acf548037fcfa5fc67a1
    type: comment
  author: NickM2002
  content: Do you have any plans to retrain the model for a larger context window,
    possibly with qlora and landmark. This model seems to preform so good under 1k
    tokens, I would love to see it be able to do more!
  created_at: 2023-06-26 14:21:25+00:00
  edited: true
  hidden: false
  id: 6499acf548037fcfa5fc67a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f0b9bb3610282e0abc7937d443dc45a3.svg
      fullname: Pankaj Mathur
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: pankajmathur
      type: user
    createdAt: '2023-06-26T16:08:12.000Z'
    data:
      edited: false
      editors:
      - pankajmathur
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9774675369262695
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f0b9bb3610282e0abc7937d443dc45a3.svg
          fullname: Pankaj Mathur
          isHf: false
          isPro: true
          name: pankajmathur
          type: user
        html: '<p>As matter of fact I do, but gotta wait for some time, trying to
          arrange few other things like GPU credits, etc. </p>

          '
        raw: 'As matter of fact I do, but gotta wait for some time, trying to arrange
          few other things like GPU credits, etc. '
        updatedAt: '2023-06-26T16:08:12.628Z'
      numEdits: 0
      reactions: []
    id: 6499b7ece0f3c90d72d3294d
    type: comment
  author: pankajmathur
  content: 'As matter of fact I do, but gotta wait for some time, trying to arrange
    few other things like GPU credits, etc. '
  created_at: 2023-06-26 15:08:12+00:00
  edited: false
  hidden: false
  id: 6499b7ece0f3c90d72d3294d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/452074cb947ed07f173263edf6beefac.svg
      fullname: m
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NickM2002
      type: user
    createdAt: '2023-06-26T16:46:09.000Z'
    data:
      edited: false
      editors:
      - NickM2002
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9613349437713623
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/452074cb947ed07f173263edf6beefac.svg
          fullname: m
          isHf: false
          isPro: false
          name: NickM2002
          type: user
        html: '<blockquote>

          <p>As matter of fact I do, but gotta wait for some time, trying to arrange
          few other things like GPU credits, etc.</p>

          </blockquote>

          <p>I will be waiting patiently thank you! Ill try training the 3b (or Santa
          Coder if I can somehow get the training working) with lora on a 3090, I''m
          very interested in how this model impacts base performance of a model and
          then how added lora''s will impact performance once the model has a larger
          foundation with these datasets. Wizard coder for example would benefit significantly
          more from a dataset like this as opposed to the original wizard dataset.
          Wizard coder was like 10% off gpt 3.5 in the coding benchmark, with this
          dataset the gap could be negligible in comparison to gpt 3.5. Also seriously
          thank you for making this dataset and training these models from what it
          looks like you are a one person team which makes all this WAY more impressive,
          Thank you!</p>

          '
        raw: '> As matter of fact I do, but gotta wait for some time, trying to arrange
          few other things like GPU credits, etc.


          I will be waiting patiently thank you! Ill try training the 3b (or Santa
          Coder if I can somehow get the training working) with lora on a 3090, I''m
          very interested in how this model impacts base performance of a model and
          then how added lora''s will impact performance once the model has a larger
          foundation with these datasets. Wizard coder for example would benefit significantly
          more from a dataset like this as opposed to the original wizard dataset.
          Wizard coder was like 10% off gpt 3.5 in the coding benchmark, with this
          dataset the gap could be negligible in comparison to gpt 3.5. Also seriously
          thank you for making this dataset and training these models from what it
          looks like you are a one person team which makes all this WAY more impressive,
          Thank you!'
        updatedAt: '2023-06-26T16:46:09.066Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - pankajmathur
    id: 6499c0d1255ef7cca0b7f515
    type: comment
  author: NickM2002
  content: '> As matter of fact I do, but gotta wait for some time, trying to arrange
    few other things like GPU credits, etc.


    I will be waiting patiently thank you! Ill try training the 3b (or Santa Coder
    if I can somehow get the training working) with lora on a 3090, I''m very interested
    in how this model impacts base performance of a model and then how added lora''s
    will impact performance once the model has a larger foundation with these datasets.
    Wizard coder for example would benefit significantly more from a dataset like
    this as opposed to the original wizard dataset. Wizard coder was like 10% off
    gpt 3.5 in the coding benchmark, with this dataset the gap could be negligible
    in comparison to gpt 3.5. Also seriously thank you for making this dataset and
    training these models from what it looks like you are a one person team which
    makes all this WAY more impressive, Thank you!'
  created_at: 2023-06-26 15:46:09+00:00
  edited: false
  hidden: false
  id: 6499c0d1255ef7cca0b7f515
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640162547139-61c2e44c39245e7bf62def6f.jpeg?w=200&h=200&f=face
      fullname: Bilibili
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Bilibili
      type: user
    createdAt: '2023-06-27T06:16:06.000Z'
    data:
      edited: true
      editors:
      - Bilibili
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7764638662338257
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640162547139-61c2e44c39245e7bf62def6f.jpeg?w=200&h=200&f=face
          fullname: Bilibili
          isHf: false
          isPro: false
          name: Bilibili
          type: user
        html: "<p> Actually I have done some attempts on HumanEval-Python, but two\
          \ issues are spotted and I failed to counter them, not sure if it is the\
          \ essential problem of the model or data:</p>\n<ol>\n<li>Hard to follow\
          \ explicit instructions:<br>I expect the model to output pure Python code,\
          \ but it seems not possible after I tried several prompts:</li>\n</ol>\n\
          <pre><code># system = 'You are an AI programming assistant that follows\
          \ instruction to write Python3 code extremely well. Given the instruction\
          \ and function signature, you are only allowed to implement the function\
          \ in response.'\n# system = 'You are an AI programming assistant that follows\
          \ instruction to write Python3 code extremely well. Given the instruction\
          \ and function signature, you must implement the function in response. The\
          \ response MUST only consists of Python3 code.'\nsystem = 'You are an AI\
          \ programming assistant that follows instruction to write Python3 code extremely\
          \ well.'\n...\ndef generate(system, instruction, input=None):\n    if input:\n\
          \        prompt = f\"### System:\\n{system}\\n\\n### User:\\n{instruction}\\\
          n\\n### Input:\\n{input}\\n\\n### Response:\\n\"\n    else:\n        prompt\
          \ = f\"### System:\\n{system}\\n\\n### User:\\n{instruction}\\n\\n### Response:\\\
          n\"\n</code></pre>\n<p>For the instruction part, I have tried such formats:</p>\n\
          <pre><code>1. from typing import List\\n\\n\\ndef has_close_elements(numbers:\
          \ List[float], threshold: float) -&gt; bool:\\n    \\\"\\\"\\\" Check if\
          \ in given list of numbers, are any two numbers closer to each other than\\\
          n    given threshold.\\n    &gt;&gt;&gt; has_close_elements([1.0, 2.0, 3.0],\
          \ 0.5)\\n    False\\n    &gt;&gt;&gt; has_close_elements([1.0, 2.8, 3.0,\
          \ 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\n2. Check if in\
          \ given list of numbers, are any two numbers closer to each other than\\\
          ngiven threshold.\\n&gt;&gt;&gt; has_close_elements([1.0, 2.0, 3.0], 0.5)\\\
          nFalse\\n&gt;&gt;&gt; has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0],\
          \ 0.3)\\nTrue\\nfrom typing import List\\n\\n\\ndef has_close_elements(numbers:\
          \ List[float], threshold: float) -&gt; bool:\n</code></pre>\n<p>The output\
          \ still contains instructions, explanations, and code snippets in markdown\
          \ format</p>\n<ol start=\"2\">\n<li>The indentation is missing in the code\
          \ snippets:<br>Here is one typical output, for the last question in HumanEval:</li>\n\
          </ol>\n<hr>\n<p>Here's the Python3 code to generate the even digits between\
          \ two positive integers in ascending order:</p>\n<pre><code class=\"language-python3\"\
          >def generate_integers(a, b):\n even_digits = []\n for i in range(a, b+1):\n\
          \ even_digits.append(i)\n even_digits.sort(reverse=True)\n return even_digits\n\
          </code></pre>\n<p>This code will return a list of even digits between a\
          \ and b, in ascending order.</p>\n<hr>\n<p>I printed it directed with print()\
          \ and loguru, but the code is apparently unexecutable due to indentation\
          \ error. I also tried to run it in debug mode and also tried other models\
          \ (like StarCoder), this should be the problem of Orca, maybe the tokenizer\
          \ merged multiple neighboring white spaces?</p>\n"
        raw: " Actually I have done some attempts on HumanEval-Python, but two issues\
          \ are spotted and I failed to counter them, not sure if it is the essential\
          \ problem of the model or data:\n1. Hard to follow explicit instructions:\n\
          I expect the model to output pure Python code, but it seems not possible\
          \ after I tried several prompts:\n```\n# system = 'You are an AI programming\
          \ assistant that follows instruction to write Python3 code extremely well.\
          \ Given the instruction and function signature, you are only allowed to\
          \ implement the function in response.'\n# system = 'You are an AI programming\
          \ assistant that follows instruction to write Python3 code extremely well.\
          \ Given the instruction and function signature, you must implement the function\
          \ in response. The response MUST only consists of Python3 code.'\nsystem\
          \ = 'You are an AI programming assistant that follows instruction to write\
          \ Python3 code extremely well.'\n...\ndef generate(system, instruction,\
          \ input=None):\n    if input:\n        prompt = f\"### System:\\n{system}\\\
          n\\n### User:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\\
          n\"\n    else:\n        prompt = f\"### System:\\n{system}\\n\\n### User:\\\
          n{instruction}\\n\\n### Response:\\n\"\n```\nFor the instruction part, I\
          \ have tried such formats:\n```\n1. from typing import List\\n\\n\\ndef\
          \ has_close_elements(numbers: List[float], threshold: float) -> bool:\\\
          n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers\
          \ closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0,\
          \ 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0,\
          \ 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\n2. Check if in\
          \ given list of numbers, are any two numbers closer to each other than\\\
          ngiven threshold.\\n>>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\nFalse\\\
          n>>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\nTrue\\nfrom\
          \ typing import List\\n\\n\\ndef has_close_elements(numbers: List[float],\
          \ threshold: float) -> bool:\n```\nThe output still contains instructions,\
          \ explanations, and code snippets in markdown format\n\n2. The indentation\
          \ is missing in the code snippets:\nHere is one typical output, for the\
          \ last question in HumanEval:\n\n--------------------------------------------------------------------------------------\n\
          Here's the Python3 code to generate the even digits between two positive\
          \ integers in ascending order:\n\n```python3\ndef generate_integers(a, b):\n\
          \ even_digits = []\n for i in range(a, b+1):\n even_digits.append(i)\n even_digits.sort(reverse=True)\n\
          \ return even_digits\n```\n\nThis code will return a list of even digits\
          \ between a and b, in ascending order.\n\n--------------------------------------------------------------------------------------\n\
          \nI printed it directed with print() and loguru, but the code is apparently\
          \ unexecutable due to indentation error. I also tried to run it in debug\
          \ mode and also tried other models (like StarCoder), this should be the\
          \ problem of Orca, maybe the tokenizer merged multiple neighboring white\
          \ spaces?"
        updatedAt: '2023-06-27T06:16:29.889Z'
      numEdits: 1
      reactions: []
    id: 649a7ea696d5747b35e6733e
    type: comment
  author: Bilibili
  content: " Actually I have done some attempts on HumanEval-Python, but two issues\
    \ are spotted and I failed to counter them, not sure if it is the essential problem\
    \ of the model or data:\n1. Hard to follow explicit instructions:\nI expect the\
    \ model to output pure Python code, but it seems not possible after I tried several\
    \ prompts:\n```\n# system = 'You are an AI programming assistant that follows\
    \ instruction to write Python3 code extremely well. Given the instruction and\
    \ function signature, you are only allowed to implement the function in response.'\n\
    # system = 'You are an AI programming assistant that follows instruction to write\
    \ Python3 code extremely well. Given the instruction and function signature, you\
    \ must implement the function in response. The response MUST only consists of\
    \ Python3 code.'\nsystem = 'You are an AI programming assistant that follows instruction\
    \ to write Python3 code extremely well.'\n...\ndef generate(system, instruction,\
    \ input=None):\n    if input:\n        prompt = f\"### System:\\n{system}\\n\\\
    n### User:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\"\n\
    \    else:\n        prompt = f\"### System:\\n{system}\\n\\n### User:\\n{instruction}\\\
    n\\n### Response:\\n\"\n```\nFor the instruction part, I have tried such formats:\n\
    ```\n1. from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float],\
    \ threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers,\
    \ are any two numbers closer to each other than\\n    given threshold.\\n    >>>\
    \ has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0,\
    \ 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\n2. Check if\
    \ in given list of numbers, are any two numbers closer to each other than\\ngiven\
    \ threshold.\\n>>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\nFalse\\n>>> has_close_elements([1.0,\
    \ 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\nTrue\\nfrom typing import List\\n\\n\\ndef\
    \ has_close_elements(numbers: List[float], threshold: float) -> bool:\n```\nThe\
    \ output still contains instructions, explanations, and code snippets in markdown\
    \ format\n\n2. The indentation is missing in the code snippets:\nHere is one typical\
    \ output, for the last question in HumanEval:\n\n--------------------------------------------------------------------------------------\n\
    Here's the Python3 code to generate the even digits between two positive integers\
    \ in ascending order:\n\n```python3\ndef generate_integers(a, b):\n even_digits\
    \ = []\n for i in range(a, b+1):\n even_digits.append(i)\n even_digits.sort(reverse=True)\n\
    \ return even_digits\n```\n\nThis code will return a list of even digits between\
    \ a and b, in ascending order.\n\n--------------------------------------------------------------------------------------\n\
    \nI printed it directed with print() and loguru, but the code is apparently unexecutable\
    \ due to indentation error. I also tried to run it in debug mode and also tried\
    \ other models (like StarCoder), this should be the problem of Orca, maybe the\
    \ tokenizer merged multiple neighboring white spaces?"
  created_at: 2023-06-27 05:16:06+00:00
  edited: true
  hidden: false
  id: 649a7ea696d5747b35e6733e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: pankajmathur/orca_mini_13b
repo_type: model
status: open
target_branch: null
title: Performance?
