!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JuLuComputing
conflicting_files: null
created_at: 2023-05-23 04:49:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/50f65f0537965a35090cefb31251ade6.svg
      fullname: Jeremy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JuLuComputing
      type: user
    createdAt: '2023-05-23T05:49:27.000Z'
    data:
      edited: false
      editors:
      - JuLuComputing
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/50f65f0537965a35090cefb31251ade6.svg
          fullname: Jeremy
          isHf: false
          isPro: false
          name: JuLuComputing
          type: user
        html: '<p>This is an interesting model, thanks for sharing!</p>

          <p>I am interested in the ''bitsandbytes'' script you used to make this
          8 bit, would you share that script and any other scripts pertaining to this
          model?</p>

          <p>Thanks!</p>

          '
        raw: "This is an interesting model, thanks for sharing!\r\n\r\nI am interested\
          \ in the 'bitsandbytes' script you used to make this 8 bit, would you share\
          \ that script and any other scripts pertaining to this model?\r\n\r\nThanks!"
        updatedAt: '2023-05-23T05:49:27.485Z'
      numEdits: 0
      reactions: []
    id: 646c53e7b1202bc77c156aa9
    type: comment
  author: JuLuComputing
  content: "This is an interesting model, thanks for sharing!\r\n\r\nI am interested\
    \ in the 'bitsandbytes' script you used to make this 8 bit, would you share that\
    \ script and any other scripts pertaining to this model?\r\n\r\nThanks!"
  created_at: 2023-05-23 04:49:27+00:00
  edited: false
  hidden: false
  id: 646c53e7b1202bc77c156aa9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2023-05-23T14:54:39.000Z'
    data:
      edited: false
      editors:
      - pszemraj
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
          fullname: Peter Szemraj
          isHf: false
          isPro: false
          name: pszemraj
          type: user
        html: '<p>You''re welcome! It''s actually super easy with a recent update,
          see <a href="https://huggingface.co/ybelkada/bloom-1b7-8bit#how-to-push-8bit-weights">this
          section</a> on the example repo</p>

          <p>BTW if you find it useful, I have been running a bunch of different summarization
          models over the same set of source documents to compare the results, you
          can see that at the below links:</p>

          <ul>

          <li>main project repo: <a rel="nofollow" href="https://github.com/pszemraj/SummComparer">https://github.com/pszemraj/SummComparer</a></li>

          <li>data on hf: <a href="https://huggingface.co/datasets/pszemraj/summcomparer-gauntlet-v0.1">https://huggingface.co/datasets/pszemraj/summcomparer-gauntlet-v0.1</a></li>

          </ul>

          '
        raw: 'You''re welcome! It''s actually super easy with a recent update, see
          [this section](https://huggingface.co/ybelkada/bloom-1b7-8bit#how-to-push-8bit-weights)
          on the example repo


          BTW if you find it useful, I have been running a bunch of different summarization
          models over the same set of source documents to compare the results, you
          can see that at the below links:


          - main project repo: https://github.com/pszemraj/SummComparer

          - data on hf: https://huggingface.co/datasets/pszemraj/summcomparer-gauntlet-v0.1'
        updatedAt: '2023-05-23T14:54:39.339Z'
      numEdits: 0
      reactions: []
    id: 646cd3afb4eefa7c369aca47
    type: comment
  author: pszemraj
  content: 'You''re welcome! It''s actually super easy with a recent update, see [this
    section](https://huggingface.co/ybelkada/bloom-1b7-8bit#how-to-push-8bit-weights)
    on the example repo


    BTW if you find it useful, I have been running a bunch of different summarization
    models over the same set of source documents to compare the results, you can see
    that at the below links:


    - main project repo: https://github.com/pszemraj/SummComparer

    - data on hf: https://huggingface.co/datasets/pszemraj/summcomparer-gauntlet-v0.1'
  created_at: 2023-05-23 13:54:39+00:00
  edited: false
  hidden: false
  id: 646cd3afb4eefa7c369aca47
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/50f65f0537965a35090cefb31251ade6.svg
      fullname: Jeremy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JuLuComputing
      type: user
    createdAt: '2023-06-10T05:54:06.000Z'
    data:
      edited: false
      editors:
      - JuLuComputing
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9638322591781616
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/50f65f0537965a35090cefb31251ade6.svg
          fullname: Jeremy
          isHf: false
          isPro: false
          name: JuLuComputing
          type: user
        html: '<p>You sure do have a treasure trove of useful scripts and models,
          here and on Github.  I thank you again for sharing all of this work!</p>

          <p>The SummComparer is a great project that fits a well needed niche.  I
          have been seeking a versatile summing LLM that can do programming languages,
          business docs, instructional manuals, and books.  It seems most LLMs fall
          flat on their face in one area or another, most can''t ingest the large
          number of tokens of a book, and if one is good with books, it is usually
          terrible at code.</p>

          <p>Do you have a particular one from your line of experimental summing LLMs
          you would recommend I try?</p>

          '
        raw: 'You sure do have a treasure trove of useful scripts and models, here
          and on Github.  I thank you again for sharing all of this work!


          The SummComparer is a great project that fits a well needed niche.  I have
          been seeking a versatile summing LLM that can do programming languages,
          business docs, instructional manuals, and books.  It seems most LLMs fall
          flat on their face in one area or another, most can''t ingest the large
          number of tokens of a book, and if one is good with books, it is usually
          terrible at code.


          Do you have a particular one from your line of experimental summing LLMs
          you would recommend I try?'
        updatedAt: '2023-06-10T05:54:06.456Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - pszemraj
      - count: 1
        reaction: "\U0001F917"
        users:
        - pszemraj
    id: 64840ffe8a6bf62448f1bd2a
    type: comment
  author: JuLuComputing
  content: 'You sure do have a treasure trove of useful scripts and models, here and
    on Github.  I thank you again for sharing all of this work!


    The SummComparer is a great project that fits a well needed niche.  I have been
    seeking a versatile summing LLM that can do programming languages, business docs,
    instructional manuals, and books.  It seems most LLMs fall flat on their face
    in one area or another, most can''t ingest the large number of tokens of a book,
    and if one is good with books, it is usually terrible at code.


    Do you have a particular one from your line of experimental summing LLMs you would
    recommend I try?'
  created_at: 2023-06-10 04:54:06+00:00
  edited: false
  hidden: false
  id: 64840ffe8a6bf62448f1bd2a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2023-06-16T11:36:51.000Z'
    data:
      edited: true
      editors:
      - pszemraj
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9111404418945312
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
          fullname: Peter Szemraj
          isHf: false
          isPro: false
          name: pszemraj
          type: user
        html: '<p>Thanks so much! yeah the generalizable summarization stuff is interesting.
          any feedback on that btw is more than welcome. <em>Someday</em> I plan to
          make a V2 of this gauntlet and will include some more missing document ''genres'',
          but first want to try and get some sort of results/overview relating what
          sorts of architectures/fine-tuning datasets, so on relate to "general performance"
          on the different ''document genres''</p>

          <p>As far as the best model to try - this ''generalizable summarization
          model'' is still very much a work in progress, but I would recommend either
          this one or my latest upload: <a href="https://huggingface.co/pszemraj/long-t5-tglobal-xl-sci-simplify-elife">long-t5-xl
          on elife split of scientific lay-summaries</a>. I can''t tell you which
          generalizes better yet, but from some <a rel="nofollow" href="https://www.dropbox.com/sh/4ux2huj3zvtxqxs/AADXkqqEHg9MZSkEGVQxF6BTa?dl=0">initial
          tests on the gauntlet documents</a>, <code>pszemraj/long-t5-tglobal-xl-sci-simplify-elife</code>
          does better on non-scientific/technical docs than I would have thought.
          </p>

          <ul>

          <li>in general I''d recommend sticking to <code>booksum</code>-based things
          when in doubt (like this one <code>pszemraj/long-t5-tglobal-xl-16384-book-summary-8bit</code>).
          my theory is that by having to summarize a story or narrative, the summary
          a) pays attention to beginning/middle/end b) makes few/no assumptions on
          what the reader knows and therefore <em>explains</em> things well. these
          two qualities (<em>theory here very rough</em>) enable the generalization
          for unseen document types.</li>

          <li><strong>caveat</strong>: one  issue is that because of the ''general
          public domain'' requirement to be in <code>kmfoda/booksum</code>, books/source
          material are rather old, and therefore <em>models trained on this dataset</em>
          may <strong>miss-spell terms etc that either did not exist/were not common
          at the time</strong>. there are ofc several ways to potentially solve that
          </li>

          <li>an initial experiment (<em>there are many permutations to be done, which
          will be slow</em>) on improving this with the base model is <a href="https://huggingface.co/pszemraj/long-t5-tglobal-base-16384-booksci-summary-v1">here</a>
          which you are welcome to try. it seems to do better than the base, but has
          a strange issue where inference is muuuch slower than the starting checkpoint,
          despite <code>use_cache=True</code> as it should be - unsure why</li>

          </ul>

          '
        raw: "Thanks so much! yeah the generalizable summarization stuff is interesting.\
          \ any feedback on that btw is more than welcome. _Someday_ I plan to make\
          \ a V2 of this gauntlet and will include some more missing document 'genres',\
          \ but first want to try and get some sort of results/overview relating what\
          \ sorts of architectures/fine-tuning datasets, so on relate to \"general\
          \ performance\" on the different 'document genres'\n\nAs far as the best\
          \ model to try - this 'generalizable summarization model' is still very\
          \ much a work in progress, but I would recommend either this one or my latest\
          \ upload: [long-t5-xl on elife split of scientific lay-summaries](https://huggingface.co/pszemraj/long-t5-tglobal-xl-sci-simplify-elife).\
          \ I can't tell you which generalizes better yet, but from some [initial\
          \ tests on the gauntlet documents](https://www.dropbox.com/sh/4ux2huj3zvtxqxs/AADXkqqEHg9MZSkEGVQxF6BTa?dl=0),\
          \ `pszemraj/long-t5-tglobal-xl-sci-simplify-elife` does better on non-scientific/technical\
          \ docs than I would have thought. \n- in general I'd recommend sticking\
          \ to `booksum`-based things when in doubt (like this one `pszemraj/long-t5-tglobal-xl-16384-book-summary-8bit`).\
          \ my theory is that by having to summarize a story or narrative, the summary\
          \ a) pays attention to beginning/middle/end b) makes few/no assumptions\
          \ on what the reader knows and therefore _explains_ things well. these two\
          \ qualities (_theory here very rough_) enable the generalization for unseen\
          \ document types.\n- **caveat**: one  issue is that because of the 'general\
          \ public domain' requirement to be in `kmfoda/booksum`, books/source material\
          \ are rather old, and therefore _models trained on this dataset_ may **miss-spell\
          \ terms etc that either did not exist/were not common at the time**. there\
          \ are ofc several ways to potentially solve that \n- an initial experiment\
          \ (_there are many permutations to be done, which will be slow_) on improving\
          \ this with the base model is [here](https://huggingface.co/pszemraj/long-t5-tglobal-base-16384-booksci-summary-v1)\
          \ which you are welcome to try. it seems to do better than the base, but\
          \ has a strange issue where inference is muuuch slower than the starting\
          \ checkpoint, despite `use_cache=True` as it should be - unsure why"
        updatedAt: '2023-06-16T11:37:51.537Z'
      numEdits: 1
      reactions: []
    id: 648c4953e905b392a36d6a57
    type: comment
  author: pszemraj
  content: "Thanks so much! yeah the generalizable summarization stuff is interesting.\
    \ any feedback on that btw is more than welcome. _Someday_ I plan to make a V2\
    \ of this gauntlet and will include some more missing document 'genres', but first\
    \ want to try and get some sort of results/overview relating what sorts of architectures/fine-tuning\
    \ datasets, so on relate to \"general performance\" on the different 'document\
    \ genres'\n\nAs far as the best model to try - this 'generalizable summarization\
    \ model' is still very much a work in progress, but I would recommend either this\
    \ one or my latest upload: [long-t5-xl on elife split of scientific lay-summaries](https://huggingface.co/pszemraj/long-t5-tglobal-xl-sci-simplify-elife).\
    \ I can't tell you which generalizes better yet, but from some [initial tests\
    \ on the gauntlet documents](https://www.dropbox.com/sh/4ux2huj3zvtxqxs/AADXkqqEHg9MZSkEGVQxF6BTa?dl=0),\
    \ `pszemraj/long-t5-tglobal-xl-sci-simplify-elife` does better on non-scientific/technical\
    \ docs than I would have thought. \n- in general I'd recommend sticking to `booksum`-based\
    \ things when in doubt (like this one `pszemraj/long-t5-tglobal-xl-16384-book-summary-8bit`).\
    \ my theory is that by having to summarize a story or narrative, the summary a)\
    \ pays attention to beginning/middle/end b) makes few/no assumptions on what the\
    \ reader knows and therefore _explains_ things well. these two qualities (_theory\
    \ here very rough_) enable the generalization for unseen document types.\n- **caveat**:\
    \ one  issue is that because of the 'general public domain' requirement to be\
    \ in `kmfoda/booksum`, books/source material are rather old, and therefore _models\
    \ trained on this dataset_ may **miss-spell terms etc that either did not exist/were\
    \ not common at the time**. there are ofc several ways to potentially solve that\
    \ \n- an initial experiment (_there are many permutations to be done, which will\
    \ be slow_) on improving this with the base model is [here](https://huggingface.co/pszemraj/long-t5-tglobal-base-16384-booksci-summary-v1)\
    \ which you are welcome to try. it seems to do better than the base, but has a\
    \ strange issue where inference is muuuch slower than the starting checkpoint,\
    \ despite `use_cache=True` as it should be - unsure why"
  created_at: 2023-06-16 10:36:51+00:00
  edited: true
  hidden: false
  id: 648c4953e905b392a36d6a57
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: pszemraj/long-t5-tglobal-xl-16384-book-summary-8bit
repo_type: model
status: open
target_branch: null
title: Thanks for sharing
