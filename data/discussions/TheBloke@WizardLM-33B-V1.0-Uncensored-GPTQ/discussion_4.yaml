!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KillrBee
conflicting_files: null
created_at: 2023-07-13 20:09:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9fefbd9f4de7891e729bdc9bd01a74a8.svg
      fullname: Greg Broadhead
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KillrBee
      type: user
    createdAt: '2023-07-13T21:09:21.000Z'
    data:
      edited: true
      editors:
      - KillrBee
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4779335558414459
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9fefbd9f4de7891e729bdc9bd01a74a8.svg
          fullname: Greg Broadhead
          isHf: false
          isPro: false
          name: KillrBee
          type: user
        html: '<p>from the log file:<br>{<br>    "internal": [<br>       [<br>            "echo
          "10"",<br>            "10"<br>        ],<br>        [<br>            "echo
          "11"",<br>            "1"<br>        ],<br>        [<br>            "echo
          "12"",<br>            "12"<br>        ],<br>        [<br>            "echo
          "122"",<br>            "12"<br>        ],<br>        [<br>            "echo
          "1223"",<br>            "123"<br>        ],<br>        [<br>            "write-out
          "122"",<br>            "Twelve"<br>        ]<br>    ]<br>}</p>

          <p>The model is the GPTQ model, loaded using ExLlama and ExLlama-HF.  It
          works with the GPTQ loader:<br>[<br>            "write-out "122"",<br>            "One
          hundred and twenty-two"<br>        ],<br>        [<br>            "write-out
          "222"",<br>            "Two hundred and twenty-two"<br>        ]</p>

          '
        raw: "from the log file:\n{\n    \"internal\": [\n       [\n            \"\
          echo \\\"10\\\"\",\n            \"10\"\n        ],\n        [\n        \
          \    \"echo \\\"11\\\"\",\n            \"1\"\n        ],\n        [\n  \
          \          \"echo \\\"12\\\"\",\n            \"12\"\n        ],\n      \
          \  [\n            \"echo \\\"122\\\"\",\n            \"12\"\n        ],\n\
          \        [\n            \"echo \\\"1223\\\"\",\n            \"123\"\n  \
          \      ],\n        [\n            \"write-out \\\"122\\\"\",\n         \
          \   \"Twelve\"\n        ]\n    ]\n}\n\nThe model is the GPTQ model, loaded\
          \ using ExLlama and ExLlama-HF.  It works with the GPTQ loader:\n[\n   \
          \         \"write-out \\\"122\\\"\",\n            \"One hundred and twenty-two\"\
          \n        ],\n        [\n            \"write-out \\\"222\\\"\",\n      \
          \      \"Two hundred and twenty-two\"\n        ]"
        updatedAt: '2023-07-13T21:14:14.441Z'
      numEdits: 1
      reactions: []
    id: 64b06801607f7040c6fc34f9
    type: comment
  author: KillrBee
  content: "from the log file:\n{\n    \"internal\": [\n       [\n            \"echo\
    \ \\\"10\\\"\",\n            \"10\"\n        ],\n        [\n            \"echo\
    \ \\\"11\\\"\",\n            \"1\"\n        ],\n        [\n            \"echo\
    \ \\\"12\\\"\",\n            \"12\"\n        ],\n        [\n            \"echo\
    \ \\\"122\\\"\",\n            \"12\"\n        ],\n        [\n            \"echo\
    \ \\\"1223\\\"\",\n            \"123\"\n        ],\n        [\n            \"\
    write-out \\\"122\\\"\",\n            \"Twelve\"\n        ]\n    ]\n}\n\nThe model\
    \ is the GPTQ model, loaded using ExLlama and ExLlama-HF.  It works with the GPTQ\
    \ loader:\n[\n            \"write-out \\\"122\\\"\",\n            \"One hundred\
    \ and twenty-two\"\n        ],\n        [\n            \"write-out \\\"222\\\"\
    \",\n            \"Two hundred and twenty-two\"\n        ]"
  created_at: 2023-07-13 20:09:21+00:00
  edited: true
  hidden: false
  id: 64b06801607f7040c6fc34f9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ
repo_type: model
status: open
target_branch: null
title: This model consistently prunes the last (or first I guess), value in numbers
  that repeat.
