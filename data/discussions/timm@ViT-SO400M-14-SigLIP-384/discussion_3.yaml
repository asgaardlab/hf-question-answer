!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Moghrua
conflicting_files: null
created_at: 2023-11-22 19:09:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c32c7d6a4d8990f674bc0c45a3e54024.svg
      fullname: Edward Dixon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Moghrua
      type: user
    createdAt: '2023-11-22T19:09:21.000Z'
    data:
      edited: false
      editors:
      - Moghrua
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8915999531745911
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c32c7d6a4d8990f674bc0c45a3e54024.svg
          fullname: Edward Dixon
          isHf: false
          isPro: false
          name: Moghrua
          type: user
        html: '<p>Using the sample code, the results look a bit strange - the "probabilities"
          come out almost perfectly zero.  The scoring function looks like a good
          match for the original - could there be an issue with the tokenizer somehow?</p>

          '
        raw: Using the sample code, the results look a bit strange - the "probabilities"
          come out almost perfectly zero.  The scoring function looks like a good
          match for the original - could there be an issue with the tokenizer somehow?
        updatedAt: '2023-11-22T19:09:21.405Z'
      numEdits: 0
      reactions: []
    id: 655e51e119fd101f149a05ac
    type: comment
  author: Moghrua
  content: Using the sample code, the results look a bit strange - the "probabilities"
    come out almost perfectly zero.  The scoring function looks like a good match
    for the original - could there be an issue with the tokenizer somehow?
  created_at: 2023-11-22 19:09:21+00:00
  edited: false
  hidden: false
  id: 655e51e119fd101f149a05ac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-11-22T19:26:07.000Z'
    data:
      edited: false
      editors:
      - rwightman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8786502480506897
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Moghrua&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Moghrua\">@<span class=\"\
          underline\">Moghrua</span></a></span>\n\n\t</span></span> this behaves very\
          \ differently than softmax where the output is forced to sum to 1. In many\
          \ cases you can end up with a lot of low scores if none of the texts are\
          \ a great matches. I've definitely been able to get scores of .5 all the\
          \ way to .97. Sometimes .1-.2 is a pretty good match.</p>\n<p>If you cut\
          \ and paste the provided beignet example it will output:<br>Label probabilities:\
          \  [('a Dog.', 0.0), ('a cat', 0.0), ('a donut', 0.0), ('A Beignet.', 0.517)]</p>\n"
        raw: '@Moghrua this behaves very differently than softmax where the output
          is forced to sum to 1. In many cases you can end up with a lot of low scores
          if none of the texts are a great matches. I''ve definitely been able to
          get scores of .5 all the way to .97. Sometimes .1-.2 is a pretty good match.


          If you cut and paste the provided beignet example it will output:

          Label probabilities:  [(''a Dog.'', 0.0), (''a cat'', 0.0), (''a donut'',
          0.0), (''A Beignet.'', 0.517)]

          '
        updatedAt: '2023-11-22T19:26:07.620Z'
      numEdits: 0
      reactions: []
    id: 655e55cf324de022a3721ae0
    type: comment
  author: rwightman
  content: '@Moghrua this behaves very differently than softmax where the output is
    forced to sum to 1. In many cases you can end up with a lot of low scores if none
    of the texts are a great matches. I''ve definitely been able to get scores of
    .5 all the way to .97. Sometimes .1-.2 is a pretty good match.


    If you cut and paste the provided beignet example it will output:

    Label probabilities:  [(''a Dog.'', 0.0), (''a cat'', 0.0), (''a donut'', 0.0),
    (''A Beignet.'', 0.517)]

    '
  created_at: 2023-11-22 19:26:07+00:00
  edited: false
  hidden: false
  id: 655e55cf324de022a3721ae0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-11-22T19:28:38.000Z'
    data:
      edited: false
      editors:
      - rwightman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9070505499839783
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: '<p>If you suspect any tokenizer issues, can double check by comparing
          w/ <a rel="nofollow" href="https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/image_text/SigLIP_demo.ipynb">https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/image_text/SigLIP_demo.ipynb</a>
          ... I have done some testing and seemed to compare well but could be texts
          that don''t tokenize the same...</p>

          '
        raw: If you suspect any tokenizer issues, can double check by comparing w/
          https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/image_text/SigLIP_demo.ipynb
          ... I have done some testing and seemed to compare well but could be texts
          that don't tokenize the same...
        updatedAt: '2023-11-22T19:28:38.039Z'
      numEdits: 0
      reactions: []
    id: 655e5666905c81e85a7a056a
    type: comment
  author: rwightman
  content: If you suspect any tokenizer issues, can double check by comparing w/ https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/image_text/SigLIP_demo.ipynb
    ... I have done some testing and seemed to compare well but could be texts that
    don't tokenize the same...
  created_at: 2023-11-22 19:28:38+00:00
  edited: false
  hidden: false
  id: 655e5666905c81e85a7a056a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3529e9819a4aa8f6f50978c9af5df6e7.svg
      fullname: Nikhil Talreja
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: talrejanikhil
      type: user
    createdAt: '2024-01-23T17:07:10.000Z'
    data:
      edited: false
      editors:
      - talrejanikhil
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.809762716293335
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3529e9819a4aa8f6f50978c9af5df6e7.svg
          fullname: Nikhil Talreja
          isHf: false
          isPro: false
          name: talrejanikhil
          type: user
        html: '<p>I also have a similar concern. I used this image<br><a rel="nofollow"
          href="https://cdn-uploads.huggingface.co/production/uploads/6526b96b3b3b217bf80f0a44/By-4k-hLBUZgsGTDbGRPd.jpeg"><img
          alt="08710255134840A001.jpeg" src="https://cdn-uploads.huggingface.co/production/uploads/6526b96b3b3b217bf80f0a44/By-4k-hLBUZgsGTDbGRPd.jpeg"></a><br>and
          tags ["a dog", "a cat", "a bird", "a fish"]<br>and the probabilities were
          Label probabilities:  [(''a dog'', 1e-06), (''a cat'', 4.4e-05), (''a bird'',
          0.0), (''a fish'', 5e-06)]<br>Is this model really expected to have some
          low probabilities?</p>

          '
        raw: 'I also have a similar concern. I used this image

          ![08710255134840A001.jpeg](https://cdn-uploads.huggingface.co/production/uploads/6526b96b3b3b217bf80f0a44/By-4k-hLBUZgsGTDbGRPd.jpeg)

          and tags ["a dog", "a cat", "a bird", "a fish"]

          and the probabilities were Label probabilities:  [(''a dog'', 1e-06), (''a
          cat'', 4.4e-05), (''a bird'', 0.0), (''a fish'', 5e-06)]

          Is this model really expected to have some low probabilities?

          '
        updatedAt: '2024-01-23T17:07:10.112Z'
      numEdits: 0
      reactions: []
    id: 65aff23e9708887997bc9446
    type: comment
  author: talrejanikhil
  content: 'I also have a similar concern. I used this image

    ![08710255134840A001.jpeg](https://cdn-uploads.huggingface.co/production/uploads/6526b96b3b3b217bf80f0a44/By-4k-hLBUZgsGTDbGRPd.jpeg)

    and tags ["a dog", "a cat", "a bird", "a fish"]

    and the probabilities were Label probabilities:  [(''a dog'', 1e-06), (''a cat'',
    4.4e-05), (''a bird'', 0.0), (''a fish'', 5e-06)]

    Is this model really expected to have some low probabilities?

    '
  created_at: 2024-01-23 17:07:10+00:00
  edited: false
  hidden: false
  id: 65aff23e9708887997bc9446
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2024-01-23T20:44:59.000Z'
    data:
      edited: false
      editors:
      - rwightman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.871931254863739
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;talrejanikhil&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/talrejanikhil\"\
          >@<span class=\"underline\">talrejanikhil</span></a></span>\n\n\t</span></span>\
          \ I've observed it can be exceedingly fussy / specific? as to what's going\
          \  to yield a high prob ... eg, twiddle yours a bit</p>\n<p>[('a dog', 0.0),\
          \ ('a cat on a catfood box', 0.024), ('a catfood box', 0.351), ('a beignet',\
          \ 0.0)]</p>\n<p>So yeah, I think this is usual behaviour, it also seems\
          \ a bit sensitive to preprocessing / weight translation, esp when unsure,\
          \ the prob swings on the output from the reference jax version can be a\
          \ bit higher than I'd expect. So you could try similar prompts in their\
          \ notebook...</p>\n<p>Example if you do use softmax, obv softmax will push\
          \ up the probs so the sum is 1.0<br>Label probabilities:  [('a dog', 0.02),\
          \ ('a cat', 0.98), ('a beignet', 0.0)]</p>\n"
        raw: '@talrejanikhil I''ve observed it can be exceedingly fussy / specific?
          as to what''s going  to yield a high prob ... eg, twiddle yours a bit


          [(''a dog'', 0.0), (''a cat on a catfood box'', 0.024), (''a catfood box'',
          0.351), (''a beignet'', 0.0)]


          So yeah, I think this is usual behaviour, it also seems a bit sensitive
          to preprocessing / weight translation, esp when unsure, the prob swings
          on the output from the reference jax version can be a bit higher than I''d
          expect. So you could try similar prompts in their notebook...


          Example if you do use softmax, obv softmax will push up the probs so the
          sum is 1.0

          Label probabilities:  [(''a dog'', 0.02), (''a cat'', 0.98), (''a beignet'',
          0.0)]'
        updatedAt: '2024-01-23T20:44:59.852Z'
      numEdits: 0
      reactions: []
    id: 65b0254b266937a1f9771b79
    type: comment
  author: rwightman
  content: '@talrejanikhil I''ve observed it can be exceedingly fussy / specific?
    as to what''s going  to yield a high prob ... eg, twiddle yours a bit


    [(''a dog'', 0.0), (''a cat on a catfood box'', 0.024), (''a catfood box'', 0.351),
    (''a beignet'', 0.0)]


    So yeah, I think this is usual behaviour, it also seems a bit sensitive to preprocessing
    / weight translation, esp when unsure, the prob swings on the output from the
    reference jax version can be a bit higher than I''d expect. So you could try similar
    prompts in their notebook...


    Example if you do use softmax, obv softmax will push up the probs so the sum is
    1.0

    Label probabilities:  [(''a dog'', 0.02), (''a cat'', 0.98), (''a beignet'', 0.0)]'
  created_at: 2024-01-23 20:44:59+00:00
  edited: false
  hidden: false
  id: 65b0254b266937a1f9771b79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3529e9819a4aa8f6f50978c9af5df6e7.svg
      fullname: Nikhil Talreja
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: talrejanikhil
      type: user
    createdAt: '2024-01-24T12:46:13.000Z'
    data:
      edited: false
      editors:
      - talrejanikhil
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9445194602012634
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3529e9819a4aa8f6f50978c9af5df6e7.svg
          fullname: Nikhil Talreja
          isHf: false
          isPro: false
          name: talrejanikhil
          type: user
        html: '<p>Yes that''s true. I actually do miss the high probs that CLIP model
          outputs</p>

          '
        raw: Yes that's true. I actually do miss the high probs that CLIP model outputs
        updatedAt: '2024-01-24T12:46:13.272Z'
      numEdits: 0
      reactions: []
    id: 65b10695266937a1f9d7f234
    type: comment
  author: talrejanikhil
  content: Yes that's true. I actually do miss the high probs that CLIP model outputs
  created_at: 2024-01-24 12:46:13+00:00
  edited: false
  hidden: false
  id: 65b10695266937a1f9d7f234
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648113222875-6141a88b3a0ec78603c9e784.png?w=200&h=200&f=face
      fullname: Merve Noyan
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: true
      name: merve
      type: user
    createdAt: '2024-01-24T15:38:00.000Z'
    data:
      edited: false
      editors:
      - merve
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9615852236747742
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648113222875-6141a88b3a0ec78603c9e784.png?w=200&h=200&f=face
          fullname: Merve Noyan
          isHf: true
          isPro: true
          name: merve
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Moghrua&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Moghrua\">@<span class=\"\
          underline\">Moghrua</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;talrejanikhil&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/talrejanikhil\">@<span class=\"underline\"\
          >talrejanikhil</span></a></span>\n\n\t</span></span> I have observed the\
          \ same behavior so I had to normalize the outputs here: <a href=\"https://huggingface.co/spaces/merve/multilingual-zero-shot-image-clf\"\
          >https://huggingface.co/spaces/merve/multilingual-zero-shot-image-clf</a>\
          \ I guess since the zero shot accuracy is still better than other models\
          \ (as claimed by paper) it's just you need to stretch the outputs to actually\
          \ see that? </p>\n"
        raw: '@Moghrua @talrejanikhil I have observed the same behavior so I had to
          normalize the outputs here: https://huggingface.co/spaces/merve/multilingual-zero-shot-image-clf
          I guess since the zero shot accuracy is still better than other models (as
          claimed by paper) it''s just you need to stretch the outputs to actually
          see that? '
        updatedAt: '2024-01-24T15:38:00.893Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Moghrua
    id: 65b12ed8f32c79fea7ef0c53
    type: comment
  author: merve
  content: '@Moghrua @talrejanikhil I have observed the same behavior so I had to
    normalize the outputs here: https://huggingface.co/spaces/merve/multilingual-zero-shot-image-clf
    I guess since the zero shot accuracy is still better than other models (as claimed
    by paper) it''s just you need to stretch the outputs to actually see that? '
  created_at: 2024-01-24 15:38:00+00:00
  edited: false
  hidden: false
  id: 65b12ed8f32c79fea7ef0c53
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3529e9819a4aa8f6f50978c9af5df6e7.svg
      fullname: Nikhil Talreja
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: talrejanikhil
      type: user
    createdAt: '2024-01-24T15:41:01.000Z'
    data:
      edited: false
      editors:
      - talrejanikhil
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9300875663757324
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3529e9819a4aa8f6f50978c9af5df6e7.svg
          fullname: Nikhil Talreja
          isHf: false
          isPro: false
          name: talrejanikhil
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;merve&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/merve\">@<span class=\"\
          underline\">merve</span></a></span>\n\n\t</span></span> do you have code\
          \ to show how you normalized the outputs?</p>\n"
        raw: '@merve do you have code to show how you normalized the outputs?'
        updatedAt: '2024-01-24T15:41:01.799Z'
      numEdits: 0
      reactions: []
    id: 65b12f8dc8a577067d7a4243
    type: comment
  author: talrejanikhil
  content: '@merve do you have code to show how you normalized the outputs?'
  created_at: 2024-01-24 15:41:01+00:00
  edited: false
  hidden: false
  id: 65b12f8dc8a577067d7a4243
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648113222875-6141a88b3a0ec78603c9e784.png?w=200&h=200&f=face
      fullname: Merve Noyan
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: true
      name: merve
      type: user
    createdAt: '2024-01-24T16:10:07.000Z'
    data:
      edited: false
      editors:
      - merve
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7308859825134277
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648113222875-6141a88b3a0ec78603c9e784.png?w=200&h=200&f=face
          fullname: Merve Noyan
          isHf: true
          isPro: true
          name: merve
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;talrejanikhil&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/talrejanikhil\"\
          >@<span class=\"underline\">talrejanikhil</span></a></span>\n\n\t</span></span>\
          \ it's pretty much making it add up to one proportionally, nothing fancy,\
          \ here: <a href=\"https://huggingface.co/spaces/merve/multilingual-zero-shot-image-clf/blob/2958a16dc88a49f703e872fb79af237d544c5a18/app.py#L65\"\
          >https://huggingface.co/spaces/merve/multilingual-zero-shot-image-clf/blob/2958a16dc88a49f703e872fb79af237d544c5a18/app.py#L65</a></p>\n"
        raw: '@talrejanikhil it''s pretty much making it add up to one proportionally,
          nothing fancy, here: https://huggingface.co/spaces/merve/multilingual-zero-shot-image-clf/blob/2958a16dc88a49f703e872fb79af237d544c5a18/app.py#L65'
        updatedAt: '2024-01-24T16:10:07.534Z'
      numEdits: 0
      reactions: []
    id: 65b1365fcd9b73cf84120bf4
    type: comment
  author: merve
  content: '@talrejanikhil it''s pretty much making it add up to one proportionally,
    nothing fancy, here: https://huggingface.co/spaces/merve/multilingual-zero-shot-image-clf/blob/2958a16dc88a49f703e872fb79af237d544c5a18/app.py#L65'
  created_at: 2024-01-24 16:10:07+00:00
  edited: false
  hidden: false
  id: 65b1365fcd9b73cf84120bf4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2024-01-25T01:34:35.000Z'
    data:
      edited: true
      editors:
      - rwightman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9494156837463379
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;merve&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/merve\">@<span class=\"\
          underline\">merve</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;talrejanikhil&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/talrejanikhil\">@<span class=\"underline\"\
          >talrejanikhil</span></a></span>\n\n\t</span></span> FYI, down to some numerical\
          \ differences sigmoid + normalizing like this is essentially softmax</p>\n\
          <p>It looks/feels nicer in that everything adding up to 1. must be a probability,\
          \ but it's pretty obvious there's little to no calibration there. In either\
          \ case, the sigmoid output is probably more closely calibrated wrt to what\
          \ was seen in the training distribution...</p>\n"
        raw: '@merve @talrejanikhil FYI, down to some numerical differences sigmoid
          + normalizing like this is essentially softmax


          It looks/feels nicer in that everything adding up to 1. must be a probability,
          but it''s pretty obvious there''s little to no calibration there. In either
          case, the sigmoid output is probably more closely calibrated wrt to what
          was seen in the training distribution...'
        updatedAt: '2024-01-25T01:34:47.603Z'
      numEdits: 1
      reactions: []
    id: 65b1baab2b3c9da0b47356a9
    type: comment
  author: rwightman
  content: '@merve @talrejanikhil FYI, down to some numerical differences sigmoid
    + normalizing like this is essentially softmax


    It looks/feels nicer in that everything adding up to 1. must be a probability,
    but it''s pretty obvious there''s little to no calibration there. In either case,
    the sigmoid output is probably more closely calibrated wrt to what was seen in
    the training distribution...'
  created_at: 2024-01-25 01:34:35+00:00
  edited: true
  hidden: false
  id: 65b1baab2b3c9da0b47356a9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: timm/ViT-SO400M-14-SigLIP-384
repo_type: model
status: open
target_branch: null
title: Very flat output? "Probabilities" all close to zero.
