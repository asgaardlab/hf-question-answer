!!python/object:huggingface_hub.community.DiscussionWithDetails
author: linpang
conflicting_files: null
created_at: 2023-06-11 19:31:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ad64a41e8b81121bfeea8ce1fdcc13f.svg
      fullname: pang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: linpang
      type: user
    createdAt: '2023-06-11T20:31:43.000Z'
    data:
      edited: false
      editors:
      - linpang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8372833132743835
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ad64a41e8b81121bfeea8ce1fdcc13f.svg
          fullname: pang
          isHf: false
          isPro: false
          name: linpang
          type: user
        html: '<p>Venelin , </p>

          <p>(1) Firstly thanks for this great work. I found this: <a rel="nofollow"
          href="https://www.mlexpert.io/machine-learning/tutorials/alpaca-fine-tuning#data">https://www.mlexpert.io/machine-learning/tutorials/alpaca-fine-tuning#data</a>
          . I think I followed the code and data exactly from your tutorial.   But
          today I verified output from generate.py, what i got is:</p>

          <p>(2) I got the repeat information below when I call generate.py by loading
          my fine-tuned model after following your above tutorial (<a href="https://huggingface.co/linpang/alpaca-bitcoin-tweets-sentiment/tree/main">https://huggingface.co/linpang/alpaca-bitcoin-tweets-sentiment/tree/main</a>)
          :</p>

          <h3 id="instruction">Instruction:</h3>

          <p>Determine the sentiment</p>

          <h3 id="input">Input:</h3>

          <p>I am experimenting whether I can live only with bit coins donated. Please
          cooperate</p>

          <h3 id="response">Response:</h3>

          <p>output= Below is an instruction that describes a task, paired with an
          input that provides further context. Write a response that appropriately
          completes the request.</p>

          <p>(3) But when I load your model: ''curiousily/alpaca-bitcoin-tweets-sentiment'',
          I got correct response (prompter.get_response= Positive) :</p>

          <p>prompt= Below is an instruction that describes a task, paired with an
          input that provides further context. Write a response that appropriately
          completes the request.</p>

          <h3 id="instruction-1">Instruction:</h3>

          <p>Determine the sentiment</p>

          <h3 id="input-1">Input:</h3>

          <p>I am experimenting whether I can live only with bit coins donated. Please
          cooperate</p>

          <h3 id="response-1">Response:</h3>

          <p>output= Below is an instruction that describes a task, paired with an
          input that provides further context. Write a response that appropriately
          completes the request.</p>

          <h3 id="instruction-2">Instruction:</h3>

          <p>Determine the sentiment</p>

          <h3 id="input-2">Input:</h3>

          <p>I am experimenting whether I can live only with bit coins donated. Please
          cooperate</p>

          <h3 id="response-2">Response:</h3>

          <p>Positive<br>prompter.get_response= Positive</p>

          <p>(4) It seems your adapter_model.bin is much larger than mine (16.8M &gt;&gt;443
          bytes).<br>(5) Can you please let me know what the problem might be? I checked
          log file on my side, the log shows training and val_loss are descreasing.
          </p>

          <p>Please help and look forward to hearing from you soon! </p>

          <p>Thanks a lot!</p>

          '
        raw: "Venelin , \r\n\r\n(1) Firstly thanks for this great work. I found this:\
          \ https://www.mlexpert.io/machine-learning/tutorials/alpaca-fine-tuning#data\
          \ . I think I followed the code and data exactly from your tutorial.   But\
          \ today I verified output from generate.py, what i got is:\r\n\r\n(2) I\
          \ got the repeat information below when I call generate.py by loading my\
          \ fine-tuned model after following your above tutorial (https://huggingface.co/linpang/alpaca-bitcoin-tweets-sentiment/tree/main)\
          \ :\r\n### Instruction:\r\nDetermine the sentiment\r\n### Input:\r\nI am\
          \ experimenting whether I can live only with bit coins donated. Please cooperate\r\
          \n### Response:\r\noutput= <unk>Below is an instruction that describes a\
          \ task, paired with an input that provides further context. Write a response\
          \ that appropriately completes the request.\r\n\r\n(3) But when I load your\
          \ model: 'curiousily/alpaca-bitcoin-tweets-sentiment', I got correct response\
          \ (prompter.get_response= Positive) :\r\n\r\nprompt= Below is an instruction\
          \ that describes a task, paired with an input that provides further context.\
          \ Write a response that appropriately completes the request.\r\n\r\n###\
          \ Instruction:\r\nDetermine the sentiment\r\n### Input:\r\nI am experimenting\
          \ whether I can live only with bit coins donated. Please cooperate\r\n###\
          \ Response:\r\noutput= <unk>Below is an instruction that describes a task,\
          \ paired with an input that provides further context. Write a response that\
          \ appropriately completes the request.\r\n\r\n### Instruction:\r\nDetermine\
          \ the sentiment\r\n### Input:\r\nI am experimenting whether I can live only\
          \ with bit coins donated. Please cooperate\r\n### Response:\r\nPositive\r\
          \nprompter.get_response= Positive\r\n\r\n(4) It seems your adapter_model.bin\
          \ is much larger than mine (16.8M >>443 bytes). \r\n(5) Can you please let\
          \ me know what the problem might be? I checked log file on my side, the\
          \ log shows training and val_loss are descreasing. \r\n\r\nPlease help and\
          \ look forward to hearing from you soon! \r\n\r\nThanks a lot!\r\n"
        updatedAt: '2023-06-11T20:31:43.300Z'
      numEdits: 0
      reactions: []
    id: 64862f2f96c48398154daae9
    type: comment
  author: linpang
  content: "Venelin , \r\n\r\n(1) Firstly thanks for this great work. I found this:\
    \ https://www.mlexpert.io/machine-learning/tutorials/alpaca-fine-tuning#data .\
    \ I think I followed the code and data exactly from your tutorial.   But today\
    \ I verified output from generate.py, what i got is:\r\n\r\n(2) I got the repeat\
    \ information below when I call generate.py by loading my fine-tuned model after\
    \ following your above tutorial (https://huggingface.co/linpang/alpaca-bitcoin-tweets-sentiment/tree/main)\
    \ :\r\n### Instruction:\r\nDetermine the sentiment\r\n### Input:\r\nI am experimenting\
    \ whether I can live only with bit coins donated. Please cooperate\r\n### Response:\r\
    \noutput= <unk>Below is an instruction that describes a task, paired with an input\
    \ that provides further context. Write a response that appropriately completes\
    \ the request.\r\n\r\n(3) But when I load your model: 'curiousily/alpaca-bitcoin-tweets-sentiment',\
    \ I got correct response (prompter.get_response= Positive) :\r\n\r\nprompt= Below\
    \ is an instruction that describes a task, paired with an input that provides\
    \ further context. Write a response that appropriately completes the request.\r\
    \n\r\n### Instruction:\r\nDetermine the sentiment\r\n### Input:\r\nI am experimenting\
    \ whether I can live only with bit coins donated. Please cooperate\r\n### Response:\r\
    \noutput= <unk>Below is an instruction that describes a task, paired with an input\
    \ that provides further context. Write a response that appropriately completes\
    \ the request.\r\n\r\n### Instruction:\r\nDetermine the sentiment\r\n### Input:\r\
    \nI am experimenting whether I can live only with bit coins donated. Please cooperate\r\
    \n### Response:\r\nPositive\r\nprompter.get_response= Positive\r\n\r\n(4) It seems\
    \ your adapter_model.bin is much larger than mine (16.8M >>443 bytes). \r\n(5)\
    \ Can you please let me know what the problem might be? I checked log file on\
    \ my side, the log shows training and val_loss are descreasing. \r\n\r\nPlease\
    \ help and look forward to hearing from you soon! \r\n\r\nThanks a lot!\r\n"
  created_at: 2023-06-11 19:31:43+00:00
  edited: false
  hidden: false
  id: 64862f2f96c48398154daae9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/16ac9bb3ae7a28c2ca723ea93c5c5b31.svg
      fullname: qing
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: beatwade
      type: user
    createdAt: '2023-08-26T08:55:04.000Z'
    data:
      edited: false
      editors:
      - beatwade
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5339490175247192
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/16ac9bb3ae7a28c2ca723ea93c5c5b31.svg
          fullname: qing
          isHf: false
          isPro: false
          name: beatwade
          type: user
        html: "<p>Meet the unmatched result when use the model directly. </p>\n<p>the\
          \ result should be Neutral not positive</p>\n<p><a rel=\"nofollow\" href=\"\
          https://cdn-uploads.huggingface.co/production/uploads/64d5ad3d95cf13a381811389/ldelDqInKelIIgTmuBhge.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64d5ad3d95cf13a381811389/ldelDqInKelIIgTmuBhge.png\"\
          ></a></p>\n<p>from the datasets.<br>the input is :<br>\u0E3F value over\
          \ 1 year: +792.65%, (+$7709.41) [Currently  $8682.015] #bitcoin<br>out put\
          \ should be:<br>Neutral</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/64d5ad3d95cf13a381811389/7qsDjdFr2hUdwaaivkMRj.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64d5ad3d95cf13a381811389/7qsDjdFr2hUdwaaivkMRj.png\"\
          ></a></p>\n"
        raw: "Meet the unmatched result when use the model directly. \n\nthe result\
          \ should be Neutral not positive\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64d5ad3d95cf13a381811389/ldelDqInKelIIgTmuBhge.png)\n\
          \nfrom the datasets.\nthe input is : \n\u0E3F value over 1 year: +792.65%,\
          \ (+$7709.41) [Currently  $8682.015] #bitcoin\nout put should be:\nNeutral\n\
          \n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64d5ad3d95cf13a381811389/7qsDjdFr2hUdwaaivkMRj.png)\n"
        updatedAt: '2023-08-26T08:55:04.916Z'
      numEdits: 0
      reactions: []
    id: 64e9bde8c8193a0eef10245f
    type: comment
  author: beatwade
  content: "Meet the unmatched result when use the model directly. \n\nthe result\
    \ should be Neutral not positive\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64d5ad3d95cf13a381811389/ldelDqInKelIIgTmuBhge.png)\n\
    \nfrom the datasets.\nthe input is : \n\u0E3F value over 1 year: +792.65%, (+$7709.41)\
    \ [Currently  $8682.015] #bitcoin\nout put should be:\nNeutral\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/64d5ad3d95cf13a381811389/7qsDjdFr2hUdwaaivkMRj.png)\n"
  created_at: 2023-08-26 07:55:04+00:00
  edited: false
  hidden: false
  id: 64e9bde8c8193a0eef10245f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: curiousily/alpaca-bitcoin-tweets-sentiment
repo_type: model
status: open
target_branch: null
title: Question on the output
