!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sajmahmo
conflicting_files: null
created_at: 2023-03-15 11:44:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f8c2017c3a295cba288b9a21945bf344.svg
      fullname: Sajjad Mahmoudi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sajmahmo
      type: user
    createdAt: '2023-03-15T12:44:17.000Z'
    data:
      edited: true
      editors:
      - sajmahmo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f8c2017c3a295cba288b9a21945bf344.svg
          fullname: Sajjad Mahmoudi
          isHf: false
          isPro: false
          name: sajmahmo
          type: user
        html: "<p>If the input of model is \"Hi\", the  output will be the strange\
          \ text below in Spanish (es_XX):<br>['En la misma sesi\xF3n, la Comisi\xF3\
          n aprob\xF3 el proyecto de resoluci\xF3n A/C.1/55/L.29 sin someterlo a votaci\xF3\
          n (v\xE9ase p\xE1rr.']<br>The output for \"Hello\" is also something strange.\
          \ </p>\n<p>I executed the code below:<br>from transformers import MBartForConditionalGeneration,\
          \ MBart50TokenizerFast</p>\n<p>article_en = \"Hi\"<br>model = MBartForConditionalGeneration.from_pretrained(\"\
          facebook/mbart-large-50-one-to-many-mmt\")<br>tokenizer = MBart50TokenizerFast.from_pretrained(\"\
          facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")</p>\n<p>model_inputs\
          \ = tokenizer(article_en, return_tensors=\"pt\", max_length=500)</p>\n<p>generated_tokens\
          \ = model.generate(<br>    **model_inputs,<br>    forced_bos_token_id=tokenizer.lang_code_to_id[\"\
          es_XX\"],<br>    max_new_tokens=500<br>)<br>tokenizer.batch_decode(generated_tokens,\
          \  skip_special_tokens=True)</p>\n<p>I am sorry, but the translations of\
          \ this model are too bad.</p>\n"
        raw: "If the input of model is \"Hi\", the  output will be the strange text\
          \ below in Spanish (es_XX):\n['En la misma sesi\xF3n, la Comisi\xF3n aprob\xF3\
          \ el proyecto de resoluci\xF3n A/C.1/55/L.29 sin someterlo a votaci\xF3\
          n (v\xE9ase p\xE1rr.']\nThe output for \"Hello\" is also something strange.\
          \ \n\nI executed the code below:\nfrom transformers import MBartForConditionalGeneration,\
          \ MBart50TokenizerFast\n\narticle_en = \"Hi\"\nmodel = MBartForConditionalGeneration.from_pretrained(\"\
          facebook/mbart-large-50-one-to-many-mmt\")\ntokenizer = MBart50TokenizerFast.from_pretrained(\"\
          facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n\nmodel_inputs\
          \ = tokenizer(article_en, return_tensors=\"pt\", max_length=500)\n\ngenerated_tokens\
          \ = model.generate(\n    **model_inputs,\n    forced_bos_token_id=tokenizer.lang_code_to_id[\"\
          es_XX\"],\n    max_new_tokens=500\n)\ntokenizer.batch_decode(generated_tokens,\
          \  skip_special_tokens=True)\n\nI am sorry, but the translations of this\
          \ model are too bad."
        updatedAt: '2023-03-15T12:44:40.788Z'
      numEdits: 1
      reactions: []
    id: 6411bda1d85e465a672e82c6
    type: comment
  author: sajmahmo
  content: "If the input of model is \"Hi\", the  output will be the strange text\
    \ below in Spanish (es_XX):\n['En la misma sesi\xF3n, la Comisi\xF3n aprob\xF3\
    \ el proyecto de resoluci\xF3n A/C.1/55/L.29 sin someterlo a votaci\xF3n (v\xE9\
    ase p\xE1rr.']\nThe output for \"Hello\" is also something strange. \n\nI executed\
    \ the code below:\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\
    \narticle_en = \"Hi\"\nmodel = MBartForConditionalGeneration.from_pretrained(\"\
    facebook/mbart-large-50-one-to-many-mmt\")\ntokenizer = MBart50TokenizerFast.from_pretrained(\"\
    facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n\nmodel_inputs\
    \ = tokenizer(article_en, return_tensors=\"pt\", max_length=500)\n\ngenerated_tokens\
    \ = model.generate(\n    **model_inputs,\n    forced_bos_token_id=tokenizer.lang_code_to_id[\"\
    es_XX\"],\n    max_new_tokens=500\n)\ntokenizer.batch_decode(generated_tokens,\
    \  skip_special_tokens=True)\n\nI am sorry, but the translations of this model\
    \ are too bad."
  created_at: 2023-03-15 11:44:17+00:00
  edited: true
  hidden: false
  id: 6411bda1d85e465a672e82c6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acdc877748f862be37cbfe4e7cab10da.svg
      fullname: 'Sakshi Gupta '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sakshi-09
      type: user
    createdAt: '2023-07-21T02:51:23.000Z'
    data:
      edited: false
      editors:
      - sakshi-09
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9895259141921997
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acdc877748f862be37cbfe4e7cab10da.svg
          fullname: 'Sakshi Gupta '
          isHf: false
          isPro: false
          name: sakshi-09
          type: user
        html: '<p>hey, did you get any solution for this? I''m having the same problem
          </p>

          '
        raw: 'hey, did you get any solution for this? I''m having the same problem '
        updatedAt: '2023-07-21T02:51:23.429Z'
      numEdits: 0
      reactions: []
    id: 64b9f2ab5c4deebf69a4e532
    type: comment
  author: sakshi-09
  content: 'hey, did you get any solution for this? I''m having the same problem '
  created_at: 2023-07-21 01:51:23+00:00
  edited: false
  hidden: false
  id: 64b9f2ab5c4deebf69a4e532
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: facebook/mbart-large-50-one-to-many-mmt
repo_type: model
status: open
target_branch: null
title: Strange Output
