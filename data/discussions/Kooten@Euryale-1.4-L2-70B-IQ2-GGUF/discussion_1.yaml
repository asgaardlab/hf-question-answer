!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Nexesenex
conflicting_files: null
created_at: 2024-01-19 21:59:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31b10b87d67ff7d0691f786a857d319a.svg
      fullname: Nexesenex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nexesenex
      type: user
    createdAt: '2024-01-19T21:59:48.000Z'
    data:
      edited: false
      editors:
      - Nexesenex
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8453968167304993
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31b10b87d67ff7d0691f786a857d319a.svg
          fullname: Nexesenex
          isHf: false
          isPro: false
          name: Nexesenex
          type: user
        html: '<p>in its experimental version.<br>I made 3 compatible releases there,
          the latest being : <a rel="nofollow" href="https://github.com/Nexesenex/kobold.cpp/releases/tag/v1.55.1_b1842">https://github.com/Nexesenex/kobold.cpp/releases/tag/v1.55.1_b1842</a><br>Btw,
          what iMatrix file do you use? Wikitext?</p>

          '
        raw: "in its experimental version.\r\nI made 3 compatible releases there,\
          \ the latest being : https://github.com/Nexesenex/kobold.cpp/releases/tag/v1.55.1_b1842\r\
          \nBtw, what iMatrix file do you use? Wikitext?"
        updatedAt: '2024-01-19T21:59:48.472Z'
      numEdits: 0
      reactions: []
    id: 65aaf0d45860f06ff2cd4fc8
    type: comment
  author: Nexesenex
  content: "in its experimental version.\r\nI made 3 compatible releases there, the\
    \ latest being : https://github.com/Nexesenex/kobold.cpp/releases/tag/v1.55.1_b1842\r\
    \nBtw, what iMatrix file do you use? Wikitext?"
  created_at: 2024-01-19 21:59:48+00:00
  edited: false
  hidden: false
  id: 65aaf0d45860f06ff2cd4fc8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6376b76aa3b787faca41f8e8/-3_1Y8WSYnXQrA1jxy-q5.jpeg?w=200&h=200&f=face
      fullname: Kooten
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Kooten
      type: user
    createdAt: '2024-01-19T22:28:24.000Z'
    data:
      edited: false
      editors:
      - Kooten
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9850671291351318
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6376b76aa3b787faca41f8e8/-3_1Y8WSYnXQrA1jxy-q5.jpeg?w=200&h=200&f=face
          fullname: Kooten
          isHf: false
          isPro: false
          name: Kooten
          type: user
        html: '<p>Thanks, I had a feeling it did but i did not manage to get it to
          compile with cublas until just now.<br>I got it running on ooba with the
          llamacpp_0.2.29 branch but Kobold is probably preferable.</p>

          <p>I ran this one on pippa since i had it available, not sure what is best
          or how much difference it makes and since each run takes a few hours I went
          with wikitext for<br>WinterGoddess and Aurora-Nights (still running atm)
          to be safe. </p>

          '
        raw: "Thanks, I had a feeling it did but i did not manage to get it to compile\
          \ with cublas until just now.\nI got it running on ooba with the llamacpp_0.2.29\
          \ branch but Kobold is probably preferable.\n\nI ran this one on pippa since\
          \ i had it available, not sure what is best or how much difference it makes\
          \ and since each run takes a few hours I went with wikitext for \nWinterGoddess\
          \ and Aurora-Nights (still running atm) to be safe. "
        updatedAt: '2024-01-19T22:28:24.706Z'
      numEdits: 0
      reactions: []
    id: 65aaf788fd4261f531044056
    type: comment
  author: Kooten
  content: "Thanks, I had a feeling it did but i did not manage to get it to compile\
    \ with cublas until just now.\nI got it running on ooba with the llamacpp_0.2.29\
    \ branch but Kobold is probably preferable.\n\nI ran this one on pippa since i\
    \ had it available, not sure what is best or how much difference it makes and\
    \ since each run takes a few hours I went with wikitext for \nWinterGoddess and\
    \ Aurora-Nights (still running atm) to be safe. "
  created_at: 2024-01-19 22:28:24+00:00
  edited: false
  hidden: false
  id: 65aaf788fd4261f531044056
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31b10b87d67ff7d0691f786a857d319a.svg
      fullname: Nexesenex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nexesenex
      type: user
    createdAt: '2024-01-19T23:15:08.000Z'
    data:
      edited: true
      editors:
      - Nexesenex
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9601942896842957
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31b10b87d67ff7d0691f786a857d319a.svg
          fullname: Nexesenex
          isHf: false
          isPro: false
          name: Nexesenex
          type: user
        html: '<p>That discussion might be of interest for you, and it has links towards
          the relevant discussions on LlamaCPP''s Github.<br><a href="https://huggingface.co/grimulkan/aurelian-alpha0.1-70b-rope8-32K-fp16/discussions/2">https://huggingface.co/grimulkan/aurelian-alpha0.1-70b-rope8-32K-fp16/discussions/2</a></p>

          '
        raw: 'That discussion might be of interest for you, and it has links towards
          the relevant discussions on LlamaCPP''s Github.

          https://huggingface.co/grimulkan/aurelian-alpha0.1-70b-rope8-32K-fp16/discussions/2'
        updatedAt: '2024-01-20T00:30:22.627Z'
      numEdits: 1
      reactions: []
    id: 65ab027c9c81170e3107180e
    type: comment
  author: Nexesenex
  content: 'That discussion might be of interest for you, and it has links towards
    the relevant discussions on LlamaCPP''s Github.

    https://huggingface.co/grimulkan/aurelian-alpha0.1-70b-rope8-32K-fp16/discussions/2'
  created_at: 2024-01-19 23:15:08+00:00
  edited: true
  hidden: false
  id: 65ab027c9c81170e3107180e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Kooten/Euryale-1.4-L2-70B-IQ2-GGUF
repo_type: model
status: open
target_branch: null
title: Kobold can run IQ2
