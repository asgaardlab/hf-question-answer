!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Clevyby
conflicting_files: null
created_at: 2024-01-21 10:19:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/33797ed60bbc12836967ce3228f29200.svg
      fullname: Clev
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Clevyby
      type: user
    createdAt: '2024-01-21T10:19:09.000Z'
    data:
      edited: false
      editors:
      - Clevyby
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9142160415649414
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/33797ed60bbc12836967ce3228f29200.svg
          fullname: Clev
          isHf: false
          isPro: false
          name: Clevyby
          type: user
        html: '<p>Hey, noob here, it appears that the quants you made don''t work.
          I used koboldcpp''s official colab and well, it outputted this error: </p>

          <p>error loading model: create_tensor: tensor ''output_norm.weight'' not
          found</p>

          <p>Bluenipples quant of this worked fine, though, correct me if I''m wrong.</p>

          '
        raw: "Hey, noob here, it appears that the quants you made don't work. I used\
          \ koboldcpp's official colab and well, it outputted this error: \r\n\r\n\
          error loading model: create_tensor: tensor 'output_norm.weight' not found\r\
          \n\r\nBluenipples quant of this worked fine, though, correct me if I'm wrong."
        updatedAt: '2024-01-21T10:19:09.690Z'
      numEdits: 0
      reactions: []
    id: 65acef9d9aba49e1d0da9c8a
    type: comment
  author: Clevyby
  content: "Hey, noob here, it appears that the quants you made don't work. I used\
    \ koboldcpp's official colab and well, it outputted this error: \r\n\r\nerror\
    \ loading model: create_tensor: tensor 'output_norm.weight' not found\r\n\r\n\
    Bluenipples quant of this worked fine, though, correct me if I'm wrong."
  created_at: 2024-01-21 10:19:09+00:00
  edited: false
  hidden: false
  id: 65acef9d9aba49e1d0da9c8a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61caeda441f9432649f03ab6/q7BrCmKdQkvVZ7mBdKdbQ.jpeg?w=200&h=200&f=face
      fullname: s3nh
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: s3nh
      type: user
    createdAt: '2024-01-21T10:24:52.000Z'
    data:
      edited: false
      editors:
      - s3nh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9489205479621887
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61caeda441f9432649f03ab6/q7BrCmKdQkvVZ7mBdKdbQ.jpeg?w=200&h=200&f=face
          fullname: s3nh
          isHf: false
          isPro: false
          name: s3nh
          type: user
        html: '<p>Hello, dont have knowledge about koboldcpp but have to try it. Works
          fine from llamacpp</p>

          '
        raw: Hello, dont have knowledge about koboldcpp but have to try it. Works
          fine from llamacpp
        updatedAt: '2024-01-21T10:24:52.691Z'
      numEdits: 0
      reactions: []
    id: 65acf0f4df46651406dab385
    type: comment
  author: s3nh
  content: Hello, dont have knowledge about koboldcpp but have to try it. Works fine
    from llamacpp
  created_at: 2024-01-21 10:24:52+00:00
  edited: false
  hidden: false
  id: 65acf0f4df46651406dab385
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/33797ed60bbc12836967ce3228f29200.svg
      fullname: Clev
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Clevyby
      type: user
    createdAt: '2024-01-21T11:48:34.000Z'
    data:
      edited: false
      editors:
      - Clevyby
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9457905292510986
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/33797ed60bbc12836967ce3228f29200.svg
          fullname: Clev
          isHf: false
          isPro: false
          name: Clevyby
          type: user
        html: '<p>I suppose you can check out koboldcpp github page for more info.
          I myself don''t use llamacpp as koboldcpp is more user friendly, and I exclusively
          use colab (specifically the one that uses koboldcpp) since I don''t have  any
          capable hardware. Well, your DaringLotus gguf quant worked, dunno what you
          did differently here.</p>

          '
        raw: I suppose you can check out koboldcpp github page for more info. I myself
          don't use llamacpp as koboldcpp is more user friendly, and I exclusively
          use colab (specifically the one that uses koboldcpp) since I don't have  any
          capable hardware. Well, your DaringLotus gguf quant worked, dunno what you
          did differently here.
        updatedAt: '2024-01-21T11:48:34.663Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - s3nh
    id: 65ad04922ed95c799fde1bcf
    type: comment
  author: Clevyby
  content: I suppose you can check out koboldcpp github page for more info. I myself
    don't use llamacpp as koboldcpp is more user friendly, and I exclusively use colab
    (specifically the one that uses koboldcpp) since I don't have  any capable hardware.
    Well, your DaringLotus gguf quant worked, dunno what you did differently here.
  created_at: 2024-01-21 11:48:34+00:00
  edited: false
  hidden: false
  id: 65ad04922ed95c799fde1bcf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
      fullname: Matthew Andrews
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlueNipples
      type: user
    createdAt: '2024-01-22T09:51:01.000Z'
    data:
      edited: true
      editors:
      - BlueNipples
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9022795557975769
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
          fullname: Matthew Andrews
          isHf: false
          isPro: false
          name: BlueNipples
          type: user
        html: '<p>Yeah, these do actually look the wrong file sizes. q8 should be
          about 11gb for eg.  Check these file sizes for point of comparison (same
          model size):</p>

          <p><a href="https://huggingface.co/NyxKrage/FrostMaid-10.7B-TESTING-GGUF/tree/main">https://huggingface.co/NyxKrage/FrostMaid-10.7B-TESTING-GGUF/tree/main</a></p>

          <p>Your 4km is smaller than my 3km I believe:</p>

          <p><a href="https://huggingface.co/BlueNipples/DaringLotus-SnowLotus-10.7b-IQ-GGUF/tree/main">https://huggingface.co/BlueNipples/DaringLotus-SnowLotus-10.7b-IQ-GGUF/tree/main</a></p>

          <p>File size is a function of model size and bits per weight, so that shouldn''t
          happen. </p>

          '
        raw: 'Yeah, these do actually look the wrong file sizes. q8 should be about
          11gb for eg.  Check these file sizes for point of comparison (same model
          size):


          https://huggingface.co/NyxKrage/FrostMaid-10.7B-TESTING-GGUF/tree/main


          Your 4km is smaller than my 3km I believe:


          https://huggingface.co/BlueNipples/DaringLotus-SnowLotus-10.7b-IQ-GGUF/tree/main


          File size is a function of model size and bits per weight, so that shouldn''t
          happen. '
        updatedAt: '2024-01-22T09:54:42.737Z'
      numEdits: 3
      reactions: []
    id: 65ae3a85325107b8f11bb161
    type: comment
  author: BlueNipples
  content: 'Yeah, these do actually look the wrong file sizes. q8 should be about
    11gb for eg.  Check these file sizes for point of comparison (same model size):


    https://huggingface.co/NyxKrage/FrostMaid-10.7B-TESTING-GGUF/tree/main


    Your 4km is smaller than my 3km I believe:


    https://huggingface.co/BlueNipples/DaringLotus-SnowLotus-10.7b-IQ-GGUF/tree/main


    File size is a function of model size and bits per weight, so that shouldn''t
    happen. '
  created_at: 2024-01-22 09:51:01+00:00
  edited: true
  hidden: false
  id: 65ae3a85325107b8f11bb161
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61caeda441f9432649f03ab6/q7BrCmKdQkvVZ7mBdKdbQ.jpeg?w=200&h=200&f=face
      fullname: s3nh
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: s3nh
      type: user
    createdAt: '2024-01-22T09:53:43.000Z'
    data:
      edited: false
      editors:
      - s3nh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9770569801330566
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61caeda441f9432649f03ab6/q7BrCmKdQkvVZ7mBdKdbQ.jpeg?w=200&h=200&f=face
          fullname: s3nh
          isHf: false
          isPro: false
          name: s3nh
          type: user
        html: '<p>Yup, something did not work cause inference  in model size seems
          to  be empty, working on it rn, ill let you know,</p>

          '
        raw: Yup, something did not work cause inference  in model size seems to  be
          empty, working on it rn, ill let you know,
        updatedAt: '2024-01-22T09:53:43.218Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - BlueNipples
        - Clevyby
    id: 65ae3b270384cf269f224d3c
    type: comment
  author: s3nh
  content: Yup, something did not work cause inference  in model size seems to  be
    empty, working on it rn, ill let you know,
  created_at: 2024-01-22 09:53:43+00:00
  edited: false
  hidden: false
  id: 65ae3b270384cf269f224d3c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
      fullname: Matthew Andrews
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlueNipples
      type: user
    createdAt: '2024-01-22T09:55:58.000Z'
    data:
      edited: true
      editors:
      - BlueNipples
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9878032207489014
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
          fullname: Matthew Andrews
          isHf: false
          isPro: false
          name: BlueNipples
          type: user
        html: '<blockquote>

          <p>Yup, something did not work cause inference  in model size seems to  be
          empty, working on it rn, ill let you know,</p>

          </blockquote>

          <p>Sweet. Only caught this because we were talking about quant size on discord
          and I looked. All good, I''m sure you''ll fix it! Nice thing to have done
          in any case. </p>

          '
        raw: '> Yup, something did not work cause inference  in model size seems to  be
          empty, working on it rn, ill let you know,


          Sweet. Only caught this because we were talking about quant size on discord
          and I looked. All good, I''m sure you''ll fix it! Nice thing to have done
          in any case. '
        updatedAt: '2024-01-22T09:56:13.504Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - s3nh
        - Clevyby
    id: 65ae3baef4c5859037af1f90
    type: comment
  author: BlueNipples
  content: '> Yup, something did not work cause inference  in model size seems to  be
    empty, working on it rn, ill let you know,


    Sweet. Only caught this because we were talking about quant size on discord and
    I looked. All good, I''m sure you''ll fix it! Nice thing to have done in any case. '
  created_at: 2024-01-22 09:55:58+00:00
  edited: true
  hidden: false
  id: 65ae3baef4c5859037af1f90
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: s3nh/SnowLotus-v2-10.7B-GGUF
repo_type: model
status: open
target_branch: null
title: Problem with Quants
