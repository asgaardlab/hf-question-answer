!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dcaffo
conflicting_files: null
created_at: 2023-07-11 12:15:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ab94610a40f58d7e77d48c0834b62c52.svg
      fullname: Davide Caffagni
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dcaffo
      type: user
    createdAt: '2023-07-11T13:15:25.000Z'
    data:
      edited: false
      editors:
      - dcaffo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8777519464492798
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ab94610a40f58d7e77d48c0834b62c52.svg
          fullname: Davide Caffagni
          isHf: false
          isPro: false
          name: dcaffo
          type: user
        html: '<p>Hi,<br>we''re trying to test these weights and we found some differences
          wrt these ones: <code>models--decapoda-research--llama-7b-hf</code>.<br>As
          an example, here we prompt the model simply with <em>"Hello my name is"</em>.<br>Those
          are the responses,:</p>

          <ul>

          <li><code>huggyllama/llama-7b</code>:  <em>"Hello my name is Katie and I
          am a 20 year old student at the University of Southampton."</em></li>

          <li><code>decapoda-research/llama-7b-hf</code>:  <em>"Hello my name is Hello
          my name is Hello my name is Hello my name is Hello my name is Hello my name
          is"</em></li>

          </ul>

          <p>Naturally, the configuration is the same between trials.<br>As the responses
          are quite different, we wonder if your model weights are the original one
          from Meta or the outcome of some fine-tuning process.</p>

          '
        raw: "Hi,\r\nwe're trying to test these weights and we found some differences\
          \ wrt these ones: `models--decapoda-research--llama-7b-hf`.\r\nAs an example,\
          \ here we prompt the model simply with *\"Hello my name is\"*.\r\nThose\
          \ are the responses,:\r\n- `huggyllama/llama-7b`:  *\"Hello my name is Katie\
          \ and I am a 20 year old student at the University of Southampton.\"*\r\n\
          - `decapoda-research/llama-7b-hf`:  *\"Hello my name is Hello my name is\
          \ Hello my name is Hello my name is Hello my name is Hello my name is\"\
          *\r\n\r\nNaturally, the configuration is the same between trials.\r\nAs\
          \ the responses are quite different, we wonder if your model weights are\
          \ the original one from Meta or the outcome of some fine-tuning process."
        updatedAt: '2023-07-11T13:15:25.313Z'
      numEdits: 0
      reactions: []
    id: 64ad55ed0fb9b20dbac65c81
    type: comment
  author: dcaffo
  content: "Hi,\r\nwe're trying to test these weights and we found some differences\
    \ wrt these ones: `models--decapoda-research--llama-7b-hf`.\r\nAs an example,\
    \ here we prompt the model simply with *\"Hello my name is\"*.\r\nThose are the\
    \ responses,:\r\n- `huggyllama/llama-7b`:  *\"Hello my name is Katie and I am\
    \ a 20 year old student at the University of Southampton.\"*\r\n- `decapoda-research/llama-7b-hf`:\
    \  *\"Hello my name is Hello my name is Hello my name is Hello my name is Hello\
    \ my name is Hello my name is\"*\r\n\r\nNaturally, the configuration is the same\
    \ between trials.\r\nAs the responses are quite different, we wonder if your model\
    \ weights are the original one from Meta or the outcome of some fine-tuning process."
  created_at: 2023-07-11 12:15:25+00:00
  edited: false
  hidden: false
  id: 64ad55ed0fb9b20dbac65c81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/18f50817eebbf4acddb0f61170b9a2bd.svg
      fullname: cnut1648
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cnut1648
      type: user
    createdAt: '2023-07-25T14:35:09.000Z'
    data:
      edited: false
      editors:
      - cnut1648
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9322547316551208
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/18f50817eebbf4acddb0f61170b9a2bd.svg
          fullname: cnut1648
          isHf: false
          isPro: false
          name: cnut1648
          type: user
        html: '<p>One possible reason is the weight, I recall that decapoda''s convert
          is pretty out of date. But it can also just because the temperature making
          the generation not deterministic.</p>

          '
        raw: One possible reason is the weight, I recall that decapoda's convert is
          pretty out of date. But it can also just because the temperature making
          the generation not deterministic.
        updatedAt: '2023-07-25T14:35:09.202Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - dcaffo
        - yalouini
    id: 64bfdd9da27395acf10014ba
    type: comment
  author: cnut1648
  content: One possible reason is the weight, I recall that decapoda's convert is
    pretty out of date. But it can also just because the temperature making the generation
    not deterministic.
  created_at: 2023-07-25 13:35:09+00:00
  edited: false
  hidden: false
  id: 64bfdd9da27395acf10014ba
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: huggyllama/llama-7b
repo_type: model
status: open
target_branch: null
title: Different results with llama-7b weights
