!!python/object:huggingface_hub.community.DiscussionWithDetails
author: vishal1278
conflicting_files: null
created_at: 2024-01-12 01:06:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b4003505d942d54c4616f4e262563063.svg
      fullname: Vishal Patel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vishal1278
      type: user
    createdAt: '2024-01-12T01:06:34.000Z'
    data:
      edited: true
      editors:
      - vishal1278
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.927315354347229
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b4003505d942d54c4616f4e262563063.svg
          fullname: Vishal Patel
          isHf: false
          isPro: false
          name: vishal1278
          type: user
        html: '<p>In the code example that''s provided on the <em>Model Card</em>
          page, the <code>logits_per_image</code> variable is referred to as the image-text
          <em>similarity</em> score. If these <em>are</em> the text-image similarity
          scores, then how would applying the <code>softmax()</code>function on these
          similarity scores make any sense?</p>

          <p>Consider the possibility where we have an image that contains <em>both</em>
          a cat and a dog. And we use the following text:</p>

          <p><code>text = [''a photo of a cat'', ''a photo of a dog'']</code></p>

          <p>Now, the <code>logits_per_image</code> variable would (or should) return
          high values for both text prompts. Let''s assume that both scores are similar.
          If we apply the <code>softmax()</code> function on those two similarity
          scores, then the final probability scores -- aka <code>probs</code> -- would
          be around 50% for both. This wouldn''t make sense, because we would expect
          both <code>prob</code> scores to be high.</p>

          <p>In the <em>Model Card</em> example, the two text prompts are chosen in
          such a way that only one of them is correct for the sample image. And it
          makes sense that after applying <code>softmax</code>, the <code>prob</code>
          score for cats is substantially higher than the prob score for dogs. But
          this wouldn''t work if we are trying to find a bunch of objects (such as
          shoe, dress, glasses) from an image. Those probabilities would <em>not</em>
          sum to 1.0.  Hence, applying <code>softmax()</code> on these scores would
          not make sense.</p>

          '
        raw: 'In the code example that''s provided on the *Model Card* page, the `logits_per_image`
          variable is referred to as the image-text _similarity_ score. If these _are_
          the text-image similarity scores, then how would applying the `softmax()`function
          on these similarity scores make any sense?


          Consider the possibility where we have an image that contains _both_ a cat
          and a dog. And we use the following text:


          `text = [''a photo of a cat'', ''a photo of a dog'']`


          Now, the `logits_per_image` variable would (or should) return high values
          for both text prompts. Let''s assume that both scores are similar. If we
          apply the `softmax()` function on those two similarity scores, then the
          final probability scores -- aka `probs` -- would be around 50% for both.
          This wouldn''t make sense, because we would expect both `prob` scores to
          be high.


          In the *Model Card* example, the two text prompts are chosen in such a way
          that only one of them is correct for the sample image. And it makes sense
          that after applying `softmax`, the `prob` score for cats is substantially
          higher than the prob score for dogs. But this wouldn''t work if we are trying
          to find a bunch of objects (such as shoe, dress, glasses) from an image.
          Those probabilities would _not_ sum to 1.0.  Hence, applying `softmax()`
          on these scores would not make sense.'
        updatedAt: '2024-01-12T01:08:53.028Z'
      numEdits: 4
      reactions: []
    id: 65a0909a9e18386f4718d42a
    type: comment
  author: vishal1278
  content: 'In the code example that''s provided on the *Model Card* page, the `logits_per_image`
    variable is referred to as the image-text _similarity_ score. If these _are_ the
    text-image similarity scores, then how would applying the `softmax()`function
    on these similarity scores make any sense?


    Consider the possibility where we have an image that contains _both_ a cat and
    a dog. And we use the following text:


    `text = [''a photo of a cat'', ''a photo of a dog'']`


    Now, the `logits_per_image` variable would (or should) return high values for
    both text prompts. Let''s assume that both scores are similar. If we apply the
    `softmax()` function on those two similarity scores, then the final probability
    scores -- aka `probs` -- would be around 50% for both. This wouldn''t make sense,
    because we would expect both `prob` scores to be high.


    In the *Model Card* example, the two text prompts are chosen in such a way that
    only one of them is correct for the sample image. And it makes sense that after
    applying `softmax`, the `prob` score for cats is substantially higher than the
    prob score for dogs. But this wouldn''t work if we are trying to find a bunch
    of objects (such as shoe, dress, glasses) from an image. Those probabilities would
    _not_ sum to 1.0.  Hence, applying `softmax()` on these scores would not make
    sense.'
  created_at: 2024-01-12 01:06:34+00:00
  edited: true
  hidden: false
  id: 65a0909a9e18386f4718d42a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: openai/clip-vit-base-patch32
repo_type: model
status: open
target_branch: null
title: Softmax of similarity scores?
