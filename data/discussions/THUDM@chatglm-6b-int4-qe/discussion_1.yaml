!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cleverhack
conflicting_files: null
created_at: 2023-03-24 05:21:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f0e8d69c17b1ccc6fd8aeb72957887de.svg
      fullname: cleverhack
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cleverhack
      type: user
    createdAt: '2023-03-24T06:21:36.000Z'
    data:
      edited: false
      editors:
      - cleverhack
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f0e8d69c17b1ccc6fd8aeb72957887de.svg
          fullname: cleverhack
          isHf: false
          isPro: false
          name: cleverhack
          type: user
        html: '<p>Traceback (most recent call last):<br>  File "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/routes.py",
          line 400, in run_predict<br>    event_data=event_data,<br>  File "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/blocks.py",
          line 1070, in process_api<br>    fn_index, inputs, iterator, request, event_id,
          event_data<br>  File "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/blocks.py",
          line 893, in call_function<br>    utils.async_iteration, iterator, limiter=self.limiter<br>  File
          "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/anyio/to_thread.py",
          line 32, in run_sync<br>    func, *args, cancellable=cancellable, limiter=limiter<br>  File
          "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/anyio/_backends/_asyncio.py",
          line 937, in run_sync_in_worker_thread<br>    return await future<br>  File
          "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/anyio/_backends/_asyncio.py",
          line 867, in run<br>    result = context.run(func, *args)<br>  File "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/utils.py",
          line 549, in async_iteration<br>    return next(iterator)<br>  File "web_my_gpu_qe.py",
          line 17, in predict<br>    temperature=temperature):<br>  File "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/autograd/grad_mode.py",
          line 43, in generator_context<br>    response = gen.send(None)<br>  File
          "/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py",
          line 1163, in stream_chat<br>    for outputs in self.stream_generate(**input_ids,
          **gen_kwargs):<br>  File "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/autograd/grad_mode.py",
          line 43, in generator_context<br>    response = gen.send(None)<br>  File
          "/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py",
          line 1244, in stream_generate<br>    output_hidden_states=False,<br>  File
          "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py",
          line 1110, in _call_impl<br>    return forward_call(*input, **kwargs)<br>  File
          "/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py",
          line 1051, in forward<br>    return_dict=return_dict,<br>  File "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py",
          line 1110, in _call_impl<br>    return forward_call(*input, **kwargs)<br>  File
          "/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py",
          line 855, in forward<br>    inputs_embeds = self.word_embeddings(input_ids)<br>  File
          "/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py",
          line 1110, in _call_impl<br>    return forward_call(*input, **kwargs)<br>  File
          "/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/quantization.py",
          line 380, in forward<br>    original_weight = extract_weight_to_half(weight=self.weight,
          scale_list=self.weight_scale, source_bit_width=self.weight_bit_width)<br>  File
          "/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/quantization.py",
          line 229, in extract_weight_to_half<br>    out = torch.empty(n, m * (8 //
          source_bit_width), dtype=torch.half, device="cuda")<br>RuntimeError: CUDA
          out of memory. Tried to allocate 1.15 GiB (GPU 0; 5.77 GiB total capacity;
          3.29 GiB already allocated; 1.13 GiB free; 3.35 GiB reserved in total by
          PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb
          to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF</p>

          '
        raw: "Traceback (most recent call last):\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/routes.py\"\
          , line 400, in run_predict\r\n    event_data=event_data,\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/blocks.py\"\
          , line 1070, in process_api\r\n    fn_index, inputs, iterator, request,\
          \ event_id, event_data\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/blocks.py\"\
          , line 893, in call_function\r\n    utils.async_iteration, iterator, limiter=self.limiter\r\
          \n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/anyio/to_thread.py\"\
          , line 32, in run_sync\r\n    func, *args, cancellable=cancellable, limiter=limiter\r\
          \n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/anyio/_backends/_asyncio.py\"\
          , line 937, in run_sync_in_worker_thread\r\n    return await future\r\n\
          \  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/anyio/_backends/_asyncio.py\"\
          , line 867, in run\r\n    result = context.run(func, *args)\r\n  File \"\
          /home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/utils.py\"\
          , line 549, in async_iteration\r\n    return next(iterator)\r\n  File \"\
          web_my_gpu_qe.py\", line 17, in predict\r\n    temperature=temperature):\r\
          \n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\"\
          , line 43, in generator_context\r\n    response = gen.send(None)\r\n  File\
          \ \"/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py\"\
          , line 1163, in stream_chat\r\n    for outputs in self.stream_generate(**input_ids,\
          \ **gen_kwargs):\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\"\
          , line 43, in generator_context\r\n    response = gen.send(None)\r\n  File\
          \ \"/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py\"\
          , line 1244, in stream_generate\r\n    output_hidden_states=False,\r\n \
          \ File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py\"\
          , line 1051, in forward\r\n    return_dict=return_dict,\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py\"\
          , line 855, in forward\r\n    inputs_embeds = self.word_embeddings(input_ids)\r\
          \n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/quantization.py\"\
          , line 380, in forward\r\n    original_weight = extract_weight_to_half(weight=self.weight,\
          \ scale_list=self.weight_scale, source_bit_width=self.weight_bit_width)\r\
          \n  File \"/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/quantization.py\"\
          , line 229, in extract_weight_to_half\r\n    out = torch.empty(n, m * (8\
          \ // source_bit_width), dtype=torch.half, device=\"cuda\")\r\nRuntimeError:\
          \ CUDA out of memory. Tried to allocate 1.15 GiB (GPU 0; 5.77 GiB total\
          \ capacity; 3.29 GiB already allocated; 1.13 GiB free; 3.35 GiB reserved\
          \ in total by PyTorch) If reserved memory is >> allocated memory try setting\
          \ max_split_size_mb to avoid fragmentation.  See documentation for Memory\
          \ Management and PYTORCH_CUDA_ALLOC_CONF"
        updatedAt: '2023-03-24T06:21:36.066Z'
      numEdits: 0
      reactions: []
    id: 641d4170f0b71a9743690f0e
    type: comment
  author: cleverhack
  content: "Traceback (most recent call last):\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/routes.py\"\
    , line 400, in run_predict\r\n    event_data=event_data,\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/blocks.py\"\
    , line 1070, in process_api\r\n    fn_index, inputs, iterator, request, event_id,\
    \ event_data\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/blocks.py\"\
    , line 893, in call_function\r\n    utils.async_iteration, iterator, limiter=self.limiter\r\
    \n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/anyio/to_thread.py\"\
    , line 32, in run_sync\r\n    func, *args, cancellable=cancellable, limiter=limiter\r\
    \n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/anyio/_backends/_asyncio.py\"\
    , line 937, in run_sync_in_worker_thread\r\n    return await future\r\n  File\
    \ \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/anyio/_backends/_asyncio.py\"\
    , line 867, in run\r\n    result = context.run(func, *args)\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/gradio/utils.py\"\
    , line 549, in async_iteration\r\n    return next(iterator)\r\n  File \"web_my_gpu_qe.py\"\
    , line 17, in predict\r\n    temperature=temperature):\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\"\
    , line 43, in generator_context\r\n    response = gen.send(None)\r\n  File \"\
    /home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py\"\
    , line 1163, in stream_chat\r\n    for outputs in self.stream_generate(**input_ids,\
    \ **gen_kwargs):\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\"\
    , line 43, in generator_context\r\n    response = gen.send(None)\r\n  File \"\
    /home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py\"\
    , line 1244, in stream_generate\r\n    output_hidden_states=False,\r\n  File \"\
    /home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py\"\
    , line 1051, in forward\r\n    return_dict=return_dict,\r\n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/modeling_chatglm.py\"\
    , line 855, in forward\r\n    inputs_embeds = self.word_embeddings(input_ids)\r\
    \n  File \"/home/jack/miniconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/quantization.py\"\
    , line 380, in forward\r\n    original_weight = extract_weight_to_half(weight=self.weight,\
    \ scale_list=self.weight_scale, source_bit_width=self.weight_bit_width)\r\n  File\
    \ \"/home/jack/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4-qe/437fc94474689e27adfcb29ef768bfaef9be5c45/quantization.py\"\
    , line 229, in extract_weight_to_half\r\n    out = torch.empty(n, m * (8 // source_bit_width),\
    \ dtype=torch.half, device=\"cuda\")\r\nRuntimeError: CUDA out of memory. Tried\
    \ to allocate 1.15 GiB (GPU 0; 5.77 GiB total capacity; 3.29 GiB already allocated;\
    \ 1.13 GiB free; 3.35 GiB reserved in total by PyTorch) If reserved memory is\
    \ >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See\
    \ documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
  created_at: 2023-03-24 05:21:36+00:00
  edited: false
  hidden: false
  id: 641d4170f0b71a9743690f0e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-05-15T12:48:04.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: "<blockquote>\n<p>\u91CF\u5316\u540E\u7684\u6A21\u578B\u6743\u91CD\u6587\
          \u4EF6\u4EC5\u4E3A 3G \uFF0C\u7406\u8BBA\u4E0A 6G \u663E\u5B58\uFF08\u4F7F\
          \u7528 CPU \u5373 6G \u5185\u5B58\uFF09\u5373\u53EF\u63A8\u7406\uFF0C\u5177\
          \u6709\u5728\u5D4C\u5165\u5F0F\u8BBE\u5907\uFF08\u5982\u6811\u8393\u6D3E\
          \uFF09\u4E0A\u8FD0\u884C\u7684\u53EF\u80FD\u3002</p>\n</blockquote>\n<p>\u5176\
          \u5B9E\u5DEE\u4E0D\u591A6.5G\u5DE6\u53F3\uFF0C\u610F\u601D\u662F\u6700\u5C11\
          8G</p>\n"
        raw: "> \u91CF\u5316\u540E\u7684\u6A21\u578B\u6743\u91CD\u6587\u4EF6\u4EC5\
          \u4E3A 3G \uFF0C\u7406\u8BBA\u4E0A 6G \u663E\u5B58\uFF08\u4F7F\u7528 CPU\
          \ \u5373 6G \u5185\u5B58\uFF09\u5373\u53EF\u63A8\u7406\uFF0C\u5177\u6709\
          \u5728\u5D4C\u5165\u5F0F\u8BBE\u5907\uFF08\u5982\u6811\u8393\u6D3E\uFF09\
          \u4E0A\u8FD0\u884C\u7684\u53EF\u80FD\u3002\n\n\u5176\u5B9E\u5DEE\u4E0D\u591A\
          6.5G\u5DE6\u53F3\uFF0C\u610F\u601D\u662F\u6700\u5C118G"
        updatedAt: '2023-05-15T12:48:04.028Z'
      numEdits: 0
      reactions: []
    id: 64622a043cc40711bc6d8ace
    type: comment
  author: Yhyu13
  content: "> \u91CF\u5316\u540E\u7684\u6A21\u578B\u6743\u91CD\u6587\u4EF6\u4EC5\u4E3A\
    \ 3G \uFF0C\u7406\u8BBA\u4E0A 6G \u663E\u5B58\uFF08\u4F7F\u7528 CPU \u5373 6G\
    \ \u5185\u5B58\uFF09\u5373\u53EF\u63A8\u7406\uFF0C\u5177\u6709\u5728\u5D4C\u5165\
    \u5F0F\u8BBE\u5907\uFF08\u5982\u6811\u8393\u6D3E\uFF09\u4E0A\u8FD0\u884C\u7684\
    \u53EF\u80FD\u3002\n\n\u5176\u5B9E\u5DEE\u4E0D\u591A6.5G\u5DE6\u53F3\uFF0C\u610F\
    \u601D\u662F\u6700\u5C118G"
  created_at: 2023-05-15 11:48:04+00:00
  edited: false
  hidden: false
  id: 64622a043cc40711bc6d8ace
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: THUDM/chatglm-6b-int4-qe
repo_type: model
status: open
target_branch: null
title: rtx 2060 6g cuda mem problem
