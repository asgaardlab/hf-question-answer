!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kiaia
conflicting_files: null
created_at: 2023-10-05 05:20:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3efdf797c53d153cea7415213fb5afc7.svg
      fullname: Mukai Li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kiaia
      type: user
    createdAt: '2023-10-05T06:20:53.000Z'
    data:
      edited: true
      editors:
      - kiaia
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.886046826839447
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3efdf797c53d153cea7415213fb5afc7.svg
          fullname: Mukai Li
          isHf: false
          isPro: false
          name: kiaia
          type: user
        html: '<p>Thanks for sharing this repo! I have a question about importing  LlavaProcessor  from
          transformers. I get <code>cannot import name ''LlavaProcessor'' from ''transformers''
          </code>. What is right version of transformers library you use?  Thx a  lot.</p>

          '
        raw: Thanks for sharing this repo! I have a question about importing  LlavaProcessor  from
          transformers. I get `cannot import name 'LlavaProcessor' from 'transformers'
          `. What is right version of transformers library you use?  Thx a  lot.
        updatedAt: '2023-10-05T06:21:04.526Z'
      numEdits: 1
      reactions: []
    id: 651e55c560b54f44a125a8cd
    type: comment
  author: kiaia
  content: Thanks for sharing this repo! I have a question about importing  LlavaProcessor  from
    transformers. I get `cannot import name 'LlavaProcessor' from 'transformers' `.
    What is right version of transformers library you use?  Thx a  lot.
  created_at: 2023-10-05 05:20:53+00:00
  edited: true
  hidden: false
  id: 651e55c560b54f44a125a8cd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/544742da5c69514090c87227b7cdac3f.svg
      fullname: shauray singh
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: shauray
      type: user
    createdAt: '2023-10-07T05:56:24.000Z'
    data:
      edited: false
      editors:
      - shauray
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9074615836143494
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/544742da5c69514090c87227b7cdac3f.svg
          fullname: shauray singh
          isHf: false
          isPro: false
          name: shauray
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;kiaia&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/kiaia\">@<span class=\"\
          underline\">kiaia</span></a></span>\n\n\t</span></span> due to some delay\
          \ The PR isn't merged yet If you want you can use my local branch for now\
          \ <code>https://github.com/shauray8/transformers/tree/llava</code></p>\n"
        raw: Hi @kiaia due to some delay The PR isn't merged yet If you want you can
          use my local branch for now `https://github.com/shauray8/transformers/tree/llava`
        updatedAt: '2023-10-07T05:56:24.958Z'
      numEdits: 0
      reactions: []
    id: 6520f308389ef6864d92f95c
    type: comment
  author: shauray
  content: Hi @kiaia due to some delay The PR isn't merged yet If you want you can
    use my local branch for now `https://github.com/shauray8/transformers/tree/llava`
  created_at: 2023-10-07 04:56:24+00:00
  edited: false
  hidden: false
  id: 6520f308389ef6864d92f95c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3efdf797c53d153cea7415213fb5afc7.svg
      fullname: Mukai Li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kiaia
      type: user
    createdAt: '2023-10-10T09:08:23.000Z'
    data:
      edited: false
      editors:
      - kiaia
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8278205394744873
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3efdf797c53d153cea7415213fb5afc7.svg
          fullname: Mukai Li
          isHf: false
          isPro: false
          name: kiaia
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;shauray&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/shauray\">@<span class=\"\
          underline\">shauray</span></a></span>\n\n\t</span></span> \uFF01 Thank you\
          \ so much for providing your local branch. But I got this <code>in prepare_inputs_labels_for_multimodal\
          \     cur_new_input_embeds = torch.cat(cur_new_input_embeds, dim=0) RuntimeError:\
          \ Sizes of tensors must match except in dimension 0. Expected size 5120\
          \ but got size 4096 for tensor number 1 in the list.</code> instead when\
          \ trying to load the model in this repo.  Size 4096 seems like a 7B model's\
          \ dimension while the expected size for a 13B model is 5120. Is there something\
          \ I missed in loading the correct model? Thx a lot.</p>\n"
        raw: "Hi @shauray \uFF01 Thank you so much for providing your local branch.\
          \ But I got this `in prepare_inputs_labels_for_multimodal\n    cur_new_input_embeds\
          \ = torch.cat(cur_new_input_embeds, dim=0)\nRuntimeError: Sizes of tensors\
          \ must match except in dimension 0. Expected size 5120 but got size 4096\
          \ for tensor number 1 in the list.` instead when trying to load the model\
          \ in this repo.  Size 4096 seems like a 7B model's dimension while the expected\
          \ size for a 13B model is 5120. Is there something I missed in loading the\
          \ correct model? Thx a lot."
        updatedAt: '2023-10-10T09:08:23.711Z'
      numEdits: 0
      reactions: []
    id: 65251487a895f70381ee2f39
    type: comment
  author: kiaia
  content: "Hi @shauray \uFF01 Thank you so much for providing your local branch.\
    \ But I got this `in prepare_inputs_labels_for_multimodal\n    cur_new_input_embeds\
    \ = torch.cat(cur_new_input_embeds, dim=0)\nRuntimeError: Sizes of tensors must\
    \ match except in dimension 0. Expected size 5120 but got size 4096 for tensor\
    \ number 1 in the list.` instead when trying to load the model in this repo. \
    \ Size 4096 seems like a 7B model's dimension while the expected size for a 13B\
    \ model is 5120. Is there something I missed in loading the correct model? Thx\
    \ a lot."
  created_at: 2023-10-10 08:08:23+00:00
  edited: false
  hidden: false
  id: 65251487a895f70381ee2f39
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: shauray/Llava-Llama-2-13B-hf
repo_type: model
status: open
target_branch: null
title: About LlavaProcessor
