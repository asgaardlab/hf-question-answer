!!python/object:huggingface_hub.community.DiscussionWithDetails
author: imjunaidafzal
conflicting_files: null
created_at: 2023-12-13 13:36:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667813274233-62ff620b0b32bce367bf8d27.png?w=200&h=200&f=face
      fullname: Junaid Afzal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: imjunaidafzal
      type: user
    createdAt: '2023-12-13T13:36:20.000Z'
    data:
      edited: false
      editors:
      - imjunaidafzal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.33854910731315613
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667813274233-62ff620b0b32bce367bf8d27.png?w=200&h=200&f=face
          fullname: Junaid Afzal
          isHf: false
          isPro: false
          name: imjunaidafzal
          type: user
        html: "<p>I'm trying to run provided code in <code>google-colab</code> but\
          \ get the following error.</p>\n<h3 id=\"code\">Code</h3>\n<pre><code class=\"\
          language-python\"><span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> AutoModelForCausalLM, AutoTokenizer\n\
          \nmodel_id = <span class=\"hljs-string\">\"mistralai/Mixtral-8x7B-v0.1\"\
          </span>\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\nmodel =\
          \ AutoModelForCausalLM.from_pretrained(model_id)\n\ntext = <span class=\"\
          hljs-string\">\"Hello my name is\"</span>\ninputs = tokenizer(text, return_tensors=<span\
          \ class=\"hljs-string\">\"pt\"</span>)\n\noutputs = model.generate(**inputs,\
          \ max_new_tokens=<span class=\"hljs-number\">20</span>)\n<span class=\"\
          hljs-built_in\">print</span>(tokenizer.decode(outputs[<span class=\"hljs-number\"\
          >0</span>], skip_special_tokens=<span class=\"hljs-literal\">True</span>))\n\
          </code></pre>\n<h3 id=\"error\">Error</h3>\n<pre><code>&lt;ipython-input-2-047a4565ea74&gt;\
          \ in &lt;cell line: 6&gt;()\n      4 tokenizer = AutoTokenizer.from_pretrained(model_id)\n\
          \      5 \n----&gt; 6 model = AutoModelForCausalLM.from_pretrained(model_id)\n\
          \      7 \n      8 text = \"Hello my name is\"\n\n2 frames\n/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\
          \ in __getitem__(self, key)\n    759             return self._extra_content[key]\n\
          \    760         if key not in self._mapping:\n--&gt; 761             raise\
          \ KeyError(key)\n    762         value = self._mapping[key]\n    763   \
          \      module_name = model_type_to_module_name(key)\n\nKeyError: 'mixtral'\n\
          </code></pre>\n"
        raw: "I'm trying to run provided code in `google-colab` but get the following\
          \ error.\r\n\r\n### Code\r\n```python\r\nfrom transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\r\n\r\nmodel_id = \"mistralai/Mixtral-8x7B-v0.1\"\r\ntokenizer\
          \ = AutoTokenizer.from_pretrained(model_id)\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\r\
          \n\r\ntext = \"Hello my name is\"\r\ninputs = tokenizer(text, return_tensors=\"\
          pt\")\r\n\r\noutputs = model.generate(**inputs, max_new_tokens=20)\r\nprint(tokenizer.decode(outputs[0],\
          \ skip_special_tokens=True))\r\n\r\n```\r\n\r\n### Error\r\n```\r\n<ipython-input-2-047a4565ea74>\
          \ in <cell line: 6>()\r\n      4 tokenizer = AutoTokenizer.from_pretrained(model_id)\r\
          \n      5 \r\n----> 6 model = AutoModelForCausalLM.from_pretrained(model_id)\r\
          \n      7 \r\n      8 text = \"Hello my name is\"\r\n\r\n2 frames\r\n/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\
          \ in __getitem__(self, key)\r\n    759             return self._extra_content[key]\r\
          \n    760         if key not in self._mapping:\r\n--> 761             raise\
          \ KeyError(key)\r\n    762         value = self._mapping[key]\r\n    763\
          \         module_name = model_type_to_module_name(key)\r\n\r\nKeyError:\
          \ 'mixtral'\r\n```"
        updatedAt: '2023-12-13T13:36:20.940Z'
      numEdits: 0
      reactions: []
    id: 6579b354330fe066774ef08e
    type: comment
  author: imjunaidafzal
  content: "I'm trying to run provided code in `google-colab` but get the following\
    \ error.\r\n\r\n### Code\r\n```python\r\nfrom transformers import AutoModelForCausalLM,\
    \ AutoTokenizer\r\n\r\nmodel_id = \"mistralai/Mixtral-8x7B-v0.1\"\r\ntokenizer\
    \ = AutoTokenizer.from_pretrained(model_id)\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\r\
    \n\r\ntext = \"Hello my name is\"\r\ninputs = tokenizer(text, return_tensors=\"\
    pt\")\r\n\r\noutputs = model.generate(**inputs, max_new_tokens=20)\r\nprint(tokenizer.decode(outputs[0],\
    \ skip_special_tokens=True))\r\n\r\n```\r\n\r\n### Error\r\n```\r\n<ipython-input-2-047a4565ea74>\
    \ in <cell line: 6>()\r\n      4 tokenizer = AutoTokenizer.from_pretrained(model_id)\r\
    \n      5 \r\n----> 6 model = AutoModelForCausalLM.from_pretrained(model_id)\r\
    \n      7 \r\n      8 text = \"Hello my name is\"\r\n\r\n2 frames\r\n/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\
    \ in __getitem__(self, key)\r\n    759             return self._extra_content[key]\r\
    \n    760         if key not in self._mapping:\r\n--> 761             raise KeyError(key)\r\
    \n    762         value = self._mapping[key]\r\n    763         module_name =\
    \ model_type_to_module_name(key)\r\n\r\nKeyError: 'mixtral'\r\n```"
  created_at: 2023-12-13 13:36:20+00:00
  edited: false
  hidden: false
  id: 6579b354330fe066774ef08e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e00613f547ca968b9e66ee2119c9035b.svg
      fullname: shaun.glass
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shaun-glass
      type: user
    createdAt: '2023-12-13T13:50:01.000Z'
    data:
      edited: false
      editors:
      - shaun-glass
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8575060367584229
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e00613f547ca968b9e66ee2119c9035b.svg
          fullname: shaun.glass
          isHf: false
          isPro: false
          name: shaun-glass
          type: user
        html: '<p>I ran transformers version 4.35.2 and got the same error. This is
          because it is not in the config map, but if you get the latest version,
          the corresponding value will be there, so if you get the latest version,
          it will be resolved. The latest version at this point is 4.36</p>

          '
        raw: I ran transformers version 4.35.2 and got the same error. This is because
          it is not in the config map, but if you get the latest version, the corresponding
          value will be there, so if you get the latest version, it will be resolved.
          The latest version at this point is 4.36
        updatedAt: '2023-12-13T13:50:01.955Z'
      numEdits: 0
      reactions: []
    id: 6579b6891650d86d2b45814b
    type: comment
  author: shaun-glass
  content: I ran transformers version 4.35.2 and got the same error. This is because
    it is not in the config map, but if you get the latest version, the corresponding
    value will be there, so if you get the latest version, it will be resolved. The
    latest version at this point is 4.36
  created_at: 2023-12-13 13:50:01+00:00
  edited: false
  hidden: false
  id: 6579b6891650d86d2b45814b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-12-13T14:30:48.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8148625493049622
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: '<p>yes, <code>pip install -U transformers</code> should solve the issue</p>

          '
        raw: yes, `pip install -U transformers` should solve the issue
        updatedAt: '2023-12-13T14:30:48.733Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - lxaihf
    id: 6579c018aace0258712822df
    type: comment
  author: ybelkada
  content: yes, `pip install -U transformers` should solve the issue
  created_at: 2023-12-13 14:30:48+00:00
  edited: false
  hidden: false
  id: 6579c018aace0258712822df
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    createdAt: '2023-12-13T23:15:08.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-12-13T23:18:05.334Z'
      numEdits: 1
      reactions: []
    id: 657a3afc06e44e4565436bf8
    type: comment
  author: deleted
  content: This comment has been hidden
  created_at: 2023-12-13 23:15:08+00:00
  edited: true
  hidden: true
  id: 657a3afc06e44e4565436bf8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667813274233-62ff620b0b32bce367bf8d27.png?w=200&h=200&f=face
      fullname: Junaid Afzal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: imjunaidafzal
      type: user
    createdAt: '2023-12-14T12:09:51.000Z'
    data:
      edited: false
      editors:
      - imjunaidafzal
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8499839305877686
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667813274233-62ff620b0b32bce367bf8d27.png?w=200&h=200&f=face
          fullname: Junaid Afzal
          isHf: false
          isPro: false
          name: imjunaidafzal
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;shaun-glass&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/shaun-glass\"\
          >@<span class=\"underline\">shaun-glass</span></a></span>\n\n\t</span></span>\
          \ , i have test it with <code>4.35.2</code> but get the same error.</p>\n"
        raw: Hi @shaun-glass , i have test it with `4.35.2` but get the same error.
        updatedAt: '2023-12-14T12:09:51.311Z'
      numEdits: 0
      reactions: []
    id: 657af08fdaab7e5f35f887cf
    type: comment
  author: imjunaidafzal
  content: Hi @shaun-glass , i have test it with `4.35.2` but get the same error.
  created_at: 2023-12-14 12:09:51+00:00
  edited: false
  hidden: false
  id: 657af08fdaab7e5f35f887cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/648c487556590fc2ad2faaf07b4d2f18.svg
      fullname: Bacem Ben Hamed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: basyouni12
      type: user
    createdAt: '2024-01-03T13:31:14.000Z'
    data:
      edited: false
      editors:
      - basyouni12
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7797044515609741
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/648c487556590fc2ad2faaf07b4d2f18.svg
          fullname: Bacem Ben Hamed
          isHf: false
          isPro: false
          name: basyouni12
          type: user
        html: '<p>i got the same error but i solve it with </p>

          <p><code>pip install -U transformers</code></p>

          <p>huggingface-hub-0.20.1 tokenizers-0.15.0 transformers-4.36.2</p>

          '
        raw: "i got the same error but i solve it with \n\n```pip install -U transformers```\n\
          \nhuggingface-hub-0.20.1 tokenizers-0.15.0 transformers-4.36.2"
        updatedAt: '2024-01-03T13:31:14.854Z'
      numEdits: 0
      reactions: []
    id: 659561a2696ec1ef2c125ae8
    type: comment
  author: basyouni12
  content: "i got the same error but i solve it with \n\n```pip install -U transformers```\n\
    \nhuggingface-hub-0.20.1 tokenizers-0.15.0 transformers-4.36.2"
  created_at: 2024-01-03 13:31:14+00:00
  edited: false
  hidden: false
  id: 659561a2696ec1ef2c125ae8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: mistralai/Mixtral-8x7B-v0.1
repo_type: model
status: open
target_branch: null
title: Error while loading model
