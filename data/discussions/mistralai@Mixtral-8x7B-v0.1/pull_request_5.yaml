!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ybelkada
conflicting_files: []
created_at: 2023-12-11 13:49:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-12-11T13:49:33.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: ''
        raw: ''
        updatedAt: '2023-12-11T13:49:33.935Z'
      numEdits: 0
      reactions: []
    id: 6577136deb067b7829148f93
    type: comment
  author: ybelkada
  content: ''
  created_at: 2023-12-11 13:49:33+00:00
  edited: false
  hidden: false
  id: 6577136deb067b7829148f93
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-12-11T13:49:34.000Z'
    data:
      oid: 33b736e98742538fd67541da5a4363b62e72eaef
      parents:
      - 4dd4b0f2d577d7b74152732d5543a92201481fe2
      subject: Update config.json
    id: 6577136e0000000000000000
    type: commit
  author: ybelkada
  created_at: 2023-12-11 13:49:34+00:00
  id: 6577136e0000000000000000
  oid: 33b736e98742538fd67541da5a4363b62e72eaef
  summary: Update config.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-11T13:51:55.000Z'
    data:
      edited: true
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7945088148117065
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: "<p>The fix in transformers for the loss computation is going to be\
          \  something like</p>\n<pre><code class=\"language-python\">    <span class=\"\
          hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(gate_logits,\
          \ <span class=\"hljs-built_in\">tuple</span>):\n        <span class=\"hljs-comment\"\
          ># cat along the layers?</span>\n        gate_logits = torch.cat([gate.cpu()\
          \ <span class=\"hljs-keyword\">for</span> gate <span class=\"hljs-keyword\"\
          >in</span> gate_logits], dim=<span class=\"hljs-number\">0</span>)\n</code></pre>\n\
          <p>we overlooked the devices when computing the loss</p>\n"
        raw: "The fix in transformers for the loss computation is going to be  something\
          \ like\n```python\n    if isinstance(gate_logits, tuple):\n        # cat\
          \ along the layers?\n        gate_logits = torch.cat([gate.cpu() for gate\
          \ in gate_logits], dim=0)\n``` \nwe overlooked the devices when computing\
          \ the loss"
        updatedAt: '2023-12-11T13:53:53.662Z'
      numEdits: 1
      reactions: []
    id: 657713fb26ef61bbf103634a
    type: comment
  author: ArthurZ
  content: "The fix in transformers for the loss computation is going to be  something\
    \ like\n```python\n    if isinstance(gate_logits, tuple):\n        # cat along\
    \ the layers?\n        gate_logits = torch.cat([gate.cpu() for gate in gate_logits],\
    \ dim=0)\n``` \nwe overlooked the devices when computing the loss"
  created_at: 2023-12-11 13:51:55+00:00
  edited: true
  hidden: false
  id: 657713fb26ef61bbf103634a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/650c993d2751c84306aba92b/uS04hveXAu6CEszCy-8_G.jpeg?w=200&h=200&f=face
      fullname: Pierre Stock
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: pstock
      type: user
    createdAt: '2023-12-11T14:06:53.000Z'
    data:
      status: merged
    id: 6577177d039997ad70d2ddb8
    type: status-change
  author: pstock
  created_at: 2023-12-11 14:06:53+00:00
  id: 6577177d039997ad70d2ddb8
  new_status: merged
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aa3f84916189294a07623f1df5859916.svg
      fullname: Juraj
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joorei
      type: user
    createdAt: '2024-01-04T14:54:57.000Z'
    data:
      edited: false
      editors:
      - joorei
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8361653685569763
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aa3f84916189294a07623f1df5859916.svg
          fullname: Juraj
          isHf: false
          isPro: false
          name: joorei
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ArthurZ&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ArthurZ\">@<span class=\"\
          underline\">ArthurZ</span></a></span>\n\n\t</span></span> is this fixed\
          \ in transformers? I am trying to fine tune with axolotl, but I get either\
          \ </p>\n<p><code>RuntimeError: Expected all tensors to be on the same device,\
          \ but found at least two devices, cuda:6 and cuda:0!</code></p>\n<p> or\
          \ when I change the config.json part like this:</p>\n<pre><code>  \"output_router_logits\"\
          : false,\n</code></pre>\n<p>I get :</p>\n<pre><code>RuntimeError: !grad_accumulator_.expired()\
          \ INTERNAL ASSERT FAILED at \"../torch/csrc/autograd/saved_variable.cpp\"\
          :226, please report a bug to PyTorch. No grad accumulator for a saved leaf\n\
          </code></pre>\n<p>Any hints?</p>\n<p>No accelerate, just trying to run the\
          \ training.</p>\n"
        raw: "@ArthurZ is this fixed in transformers? I am trying to fine tune with\
          \ axolotl, but I get either \n\n```RuntimeError: Expected all tensors to\
          \ be on the same device, but found at least two devices, cuda:6 and cuda:0!```\n\
          \n or when I change the config.json part like this:\n\n```\n  \"output_router_logits\"\
          : false,\n```\n\nI get :\n\n```\nRuntimeError: !grad_accumulator_.expired()\
          \ INTERNAL ASSERT FAILED at \"../torch/csrc/autograd/saved_variable.cpp\"\
          :226, please report a bug to PyTorch. No grad accumulator for a saved leaf\n\
          ```\n\nAny hints?\n\nNo accelerate, just trying to run the training."
        updatedAt: '2024-01-04T14:54:57.811Z'
      numEdits: 0
      reactions: []
    id: 6596c6c1e3181789414bc409
    type: comment
  author: joorei
  content: "@ArthurZ is this fixed in transformers? I am trying to fine tune with\
    \ axolotl, but I get either \n\n```RuntimeError: Expected all tensors to be on\
    \ the same device, but found at least two devices, cuda:6 and cuda:0!```\n\n or\
    \ when I change the config.json part like this:\n\n```\n  \"output_router_logits\"\
    : false,\n```\n\nI get :\n\n```\nRuntimeError: !grad_accumulator_.expired() INTERNAL\
    \ ASSERT FAILED at \"../torch/csrc/autograd/saved_variable.cpp\":226, please report\
    \ a bug to PyTorch. No grad accumulator for a saved leaf\n```\n\nAny hints?\n\n\
    No accelerate, just trying to run the training."
  created_at: 2024-01-04 14:54:57+00:00
  edited: false
  hidden: false
  id: 6596c6c1e3181789414bc409
  type: comment
is_pull_request: true
merge_commit_oid: c56a162543a9560c9f352687e46c8416e6292da6
num: 5
repo_id: mistralai/Mixtral-8x7B-v0.1
repo_type: model
status: merged
target_branch: refs/heads/main
title: Update config.json
