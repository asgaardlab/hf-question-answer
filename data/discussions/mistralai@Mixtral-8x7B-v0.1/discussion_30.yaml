!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tzivi
conflicting_files: null
created_at: 2024-01-11 11:04:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6aa70203bc6fcfcb638a29e5f462e015.svg
      fullname: Tzivi Rubin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tzivi
      type: user
    createdAt: '2024-01-11T11:04:42.000Z'
    data:
      edited: false
      editors:
      - tzivi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8544977307319641
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6aa70203bc6fcfcb638a29e5f462e015.svg
          fullname: Tzivi Rubin
          isHf: false
          isPro: false
          name: tzivi
          type: user
        html: '<p>Pretraining and Fine tuning</p>

          '
        raw: Pretraining and Fine tuning
        updatedAt: '2024-01-11T11:04:42.254Z'
      numEdits: 0
      reactions: []
    id: 659fcb4a430ffa77ac4108b4
    type: comment
  author: tzivi
  content: Pretraining and Fine tuning
  created_at: 2024-01-11 11:04:42+00:00
  edited: false
  hidden: false
  id: 659fcb4a430ffa77ac4108b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6aa70203bc6fcfcb638a29e5f462e015.svg
      fullname: Tzivi Rubin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tzivi
      type: user
    createdAt: '2024-01-11T11:04:49.000Z'
    data:
      edited: false
      editors:
      - tzivi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9409408569335938
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6aa70203bc6fcfcb638a29e5f462e015.svg
          fullname: Tzivi Rubin
          isHf: false
          isPro: false
          name: tzivi
          type: user
        html: '<p>Hi,<br>I''m looking forward to using this powerful model! I have
          cloned the repo for mistral-src onto my GPU machine. I followed the steps
          in the readme file, but I would really like to train it for my purpose.<br>Could
          I get a clear step-by-step tutorial on how to pre-train and fine-tune the
          model.<br>Thank you.</p>

          '
        raw: "Hi, \nI'm looking forward to using this powerful model! I have cloned\
          \ the repo for mistral-src onto my GPU machine. I followed the steps in\
          \ the readme file, but I would really like to train it for my purpose.\n\
          Could I get a clear step-by-step tutorial on how to pre-train and fine-tune\
          \ the model.\nThank you."
        updatedAt: '2024-01-11T11:04:49.698Z'
      numEdits: 0
      reactions: []
    id: 659fcb51d729f54013f3d6b4
    type: comment
  author: tzivi
  content: "Hi, \nI'm looking forward to using this powerful model! I have cloned\
    \ the repo for mistral-src onto my GPU machine. I followed the steps in the readme\
    \ file, but I would really like to train it for my purpose.\nCould I get a clear\
    \ step-by-step tutorial on how to pre-train and fine-tune the model.\nThank you."
  created_at: 2024-01-11 11:04:49+00:00
  edited: false
  hidden: false
  id: 659fcb51d729f54013f3d6b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2024-01-22T16:25:37.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7728597521781921
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;tzivi&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/tzivi\">@<span class=\"\
          underline\">tzivi</span></a></span>\n\n\t</span></span><br>You can benefit\
          \ from many tools from HF ecosystem to fine-tune this model. I suggest to\
          \ go for the QLoRA approach as it is very memory efficient, among the options\
          \ I know, you can use:</p>\n<ul>\n<li>unsloth library: <a rel=\"nofollow\"\
          \ href=\"https://github.com/unslothai/unsloth\">https://github.com/unslothai/unsloth</a></li>\n\
          <li>Llama-Factory from <span data-props=\"{&quot;user&quot;:&quot;hiyouga&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/hiyouga\"\
          >@<span class=\"underline\">hiyouga</span></a></span>\n\n\t</span></span>\
          \ : <a href=\"https://huggingface.co/mistralai/Mixtral-8x7B-v0.1/discussions/10#6577e443e390cfd40990deff\"\
          >https://huggingface.co/mistralai/Mixtral-8x7B-v0.1/discussions/10#6577e443e390cfd40990deff</a></li>\n\
          <li>axolotl: <a rel=\"nofollow\" href=\"https://github.com/OpenAccess-AI-Collective/axolotl\"\
          >https://github.com/OpenAccess-AI-Collective/axolotl</a></li>\n<li>TRL library:\
          \ <a href=\"https://huggingface.co/docs/trl/sft_trainer\">https://huggingface.co/docs/trl/sft_trainer</a></li>\n\
          </ul>\n"
        raw: "Hi @tzivi \nYou can benefit from many tools from HF ecosystem to fine-tune\
          \ this model. I suggest to go for the QLoRA approach as it is very memory\
          \ efficient, among the options I know, you can use:\n- unsloth library:\
          \ https://github.com/unslothai/unsloth\n- Llama-Factory from @hiyouga :\
          \ https://huggingface.co/mistralai/Mixtral-8x7B-v0.1/discussions/10#6577e443e390cfd40990deff\n\
          - axolotl: https://github.com/OpenAccess-AI-Collective/axolotl\n- TRL library:\
          \ https://huggingface.co/docs/trl/sft_trainer"
        updatedAt: '2024-01-22T16:25:37.622Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - pcuenq
    id: 65ae97014a23c7b6b06e1bc6
    type: comment
  author: ybelkada
  content: "Hi @tzivi \nYou can benefit from many tools from HF ecosystem to fine-tune\
    \ this model. I suggest to go for the QLoRA approach as it is very memory efficient,\
    \ among the options I know, you can use:\n- unsloth library: https://github.com/unslothai/unsloth\n\
    - Llama-Factory from @hiyouga : https://huggingface.co/mistralai/Mixtral-8x7B-v0.1/discussions/10#6577e443e390cfd40990deff\n\
    - axolotl: https://github.com/OpenAccess-AI-Collective/axolotl\n- TRL library:\
    \ https://huggingface.co/docs/trl/sft_trainer"
  created_at: 2024-01-22 16:25:37+00:00
  edited: false
  hidden: false
  id: 65ae97014a23c7b6b06e1bc6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642fef28a043f0ac7defa8a9/RwOEkuj3fOnOA54tGR7Ea.png?w=200&h=200&f=face
      fullname: hoshi hiyouga
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hiyouga
      type: user
    createdAt: '2024-01-22T16:48:30.000Z'
    data:
      edited: false
      editors:
      - hiyouga
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6786366105079651
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642fef28a043f0ac7defa8a9/RwOEkuj3fOnOA54tGR7Ea.png?w=200&h=200&f=face
          fullname: hoshi hiyouga
          isHf: false
          isPro: false
          name: hiyouga
          type: user
        html: '<p>Hi, looking for a fine-tuning framework?<br>Try LLaMA-Factory and
          fine-tuning Mixtral using ZeRO stage-2/3 with the latest DeepSpeed release
          (v0.13.0)<br><a rel="nofollow" href="https://github.com/hiyouga/LLaMA-Factory#hardware-requirement">https://github.com/hiyouga/LLaMA-Factory#hardware-requirement</a><br><a
          rel="nofollow" href="https://github.com/hiyouga/LLaMA-Factory/pull/2283">https://github.com/hiyouga/LLaMA-Factory/pull/2283</a>
          </p>

          '
        raw: "Hi, looking for a fine-tuning framework?\nTry LLaMA-Factory and fine-tuning\
          \ Mixtral using ZeRO stage-2/3 with the latest DeepSpeed release (v0.13.0)\n\
          https://github.com/hiyouga/LLaMA-Factory#hardware-requirement \nhttps://github.com/hiyouga/LLaMA-Factory/pull/2283 "
        updatedAt: '2024-01-22T16:48:30.522Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - ybelkada
        - pcuenq
    id: 65ae9c5e3fe6123f62099719
    type: comment
  author: hiyouga
  content: "Hi, looking for a fine-tuning framework?\nTry LLaMA-Factory and fine-tuning\
    \ Mixtral using ZeRO stage-2/3 with the latest DeepSpeed release (v0.13.0)\nhttps://github.com/hiyouga/LLaMA-Factory#hardware-requirement\
    \ \nhttps://github.com/hiyouga/LLaMA-Factory/pull/2283 "
  created_at: 2024-01-22 16:48:30+00:00
  edited: false
  hidden: false
  id: 65ae9c5e3fe6123f62099719
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 30
repo_id: mistralai/Mixtral-8x7B-v0.1
repo_type: model
status: open
target_branch: null
title: How to fine tune mixtral 8x7B?
