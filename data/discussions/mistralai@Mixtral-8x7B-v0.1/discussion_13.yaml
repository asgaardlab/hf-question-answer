!!python/object:huggingface_hub.community.DiscussionWithDetails
author: petergrubercom
conflicting_files: null
created_at: 2023-12-12 14:19:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/pALf9YmC8gokeJLIL01mG.jpeg?w=200&h=200&f=face
      fullname: Peter Gruber
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: petergrubercom
      type: user
    createdAt: '2023-12-12T14:19:36.000Z'
    data:
      edited: false
      editors:
      - petergrubercom
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9786121845245361
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/pALf9YmC8gokeJLIL01mG.jpeg?w=200&h=200&f=face
          fullname: Peter Gruber
          isHf: false
          isPro: false
          name: petergrubercom
          type: user
        html: '<p>The <code>+</code> signs in the Python code seem to stem from a
          diff or something and may confuse people. Please remove them (or enlighten
          me about their use). thanks.</p>

          '
        raw: The `+` signs in the Python code seem to stem from a diff or something
          and may confuse people. Please remove them (or enlighten me about their
          use). thanks.
        updatedAt: '2023-12-12T14:19:36.588Z'
      numEdits: 0
      reactions: []
    id: 65786bf8353869cd6e014507
    type: comment
  author: petergrubercom
  content: The `+` signs in the Python code seem to stem from a diff or something
    and may confuse people. Please remove them (or enlighten me about their use).
    thanks.
  created_at: 2023-12-12 14:19:36+00:00
  edited: false
  hidden: false
  id: 65786bf8353869cd6e014507
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-12-12T16:24:58.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9383567571640015
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<p>hi <span data-props=\"{&quot;user&quot;:&quot;petergrubercom&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/petergrubercom\"\
          >@<span class=\"underline\">petergrubercom</span></a></span>\n\n\t</span></span>\
          \ those are used to highlight the diff that users need to apply to enable\
          \ things like 4bit inference or FA-2, you can refer to the basic usage shared\
          \ on the first snippet and apply manually the changes which are a 1 LoC\
          \ change</p>\n"
        raw: hi @petergrubercom those are used to highlight the diff that users need
          to apply to enable things like 4bit inference or FA-2, you can refer to
          the basic usage shared on the first snippet and apply manually the changes
          which are a 1 LoC change
        updatedAt: '2023-12-12T16:24:58.725Z'
      numEdits: 0
      reactions: []
    id: 6578895a9fae206bdfbe759e
    type: comment
  author: ybelkada
  content: hi @petergrubercom those are used to highlight the diff that users need
    to apply to enable things like 4bit inference or FA-2, you can refer to the basic
    usage shared on the first snippet and apply manually the changes which are a 1
    LoC change
  created_at: 2023-12-12 16:24:58+00:00
  edited: false
  hidden: false
  id: 6578895a9fae206bdfbe759e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/sZ-GBCIKUoz7Ls5ZqzrSQ.jpeg?w=200&h=200&f=face
      fullname: Patrick FitzGerald
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: paddyofitz
      type: user
    createdAt: '2023-12-15T23:53:37.000Z'
    data:
      edited: false
      editors:
      - paddyofitz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7903459668159485
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/sZ-GBCIKUoz7Ls5ZqzrSQ.jpeg?w=200&h=200&f=face
          fullname: Patrick FitzGerald
          isHf: false
          isPro: false
          name: paddyofitz
          type: user
        html: '<p>I get what the team have done. It is not clear however about doing
          two things - for example: Load the model with Flash Attention 2 and half-precision
          settings. </p>

          <p>I used:<br>import torch<br>from transformers import AutoModelForCausalLM,
          AutoTokenizer</p>

          <p>model_id = "mistralai/Mixtral-8x7B-v0.1"<br>tokenizer = AutoTokenizer.from_pretrained(model_id)</p>

          <h1 id="load-the-model-with-flash-attention-2-and-half-precision-settings">Load
          the model with Flash Attention 2 and half-precision settings</h1>

          <p>model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16,
          attn_implementation="flash_attention_2")</p>

          <h1 id="define-the-prompt">Define the prompt</h1>

          <p>prompt = "My name is"</p>

          <h1 id="tokenize-the-prompt">Tokenize the prompt</h1>

          <p>model_inputs = tokenizer([prompt], return_tensors="pt")</p>

          <h1 id="generate-text-based-on-the-prompt">Generate text based on the prompt</h1>

          <p>generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)<br>print(tokenizer.batch_decode(generated_ids,
          skip_special_tokens=True))</p>

          <p>I am coming across quite a few issues loading this on to a Windows 11
          box however. I am more than happy to write out and end to end install instruction
          for Windows 11 (a lot of people I know want to do this). Shall I post separately
          about what I have found and how I have been dociumenting it so far (e.g.
          minimum requirements, Cude Toolkit installation, torch, wheel etc.)</p>

          '
        raw: "I get what the team have done. It is not clear however about doing two\
          \ things - for example: Load the model with Flash Attention 2 and half-precision\
          \ settings. \n\nI used:\nimport torch\nfrom transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\n\nmodel_id = \"mistralai/Mixtral-8x7B-v0.1\"\ntokenizer\
          \ = AutoTokenizer.from_pretrained(model_id)\n\n# Load the model with Flash\
          \ Attention 2 and half-precision settings\nmodel = AutoModelForCausalLM.from_pretrained(model_id,\
          \ torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\")\n\
          \n# Define the prompt\nprompt = \"My name is\"\n\n# Tokenize the prompt\n\
          model_inputs = tokenizer([prompt], return_tensors=\"pt\")\n\n# Generate\
          \ text based on the prompt\ngenerated_ids = model.generate(**model_inputs,\
          \ max_new_tokens=100, do_sample=True)\nprint(tokenizer.batch_decode(generated_ids,\
          \ skip_special_tokens=True))\n\nI am coming across quite a few issues loading\
          \ this on to a Windows 11 box however. I am more than happy to write out\
          \ and end to end install instruction for Windows 11 (a lot of people I know\
          \ want to do this). Shall I post separately about what I have found and\
          \ how I have been dociumenting it so far (e.g. minimum requirements, Cude\
          \ Toolkit installation, torch, wheel etc.)\n"
        updatedAt: '2023-12-15T23:53:37.403Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - ybelkada
    id: 657ce70142fc53e18b0edecc
    type: comment
  author: paddyofitz
  content: "I get what the team have done. It is not clear however about doing two\
    \ things - for example: Load the model with Flash Attention 2 and half-precision\
    \ settings. \n\nI used:\nimport torch\nfrom transformers import AutoModelForCausalLM,\
    \ AutoTokenizer\n\nmodel_id = \"mistralai/Mixtral-8x7B-v0.1\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\
    \n# Load the model with Flash Attention 2 and half-precision settings\nmodel =\
    \ AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, attn_implementation=\"\
    flash_attention_2\")\n\n# Define the prompt\nprompt = \"My name is\"\n\n# Tokenize\
    \ the prompt\nmodel_inputs = tokenizer([prompt], return_tensors=\"pt\")\n\n# Generate\
    \ text based on the prompt\ngenerated_ids = model.generate(**model_inputs, max_new_tokens=100,\
    \ do_sample=True)\nprint(tokenizer.batch_decode(generated_ids, skip_special_tokens=True))\n\
    \nI am coming across quite a few issues loading this on to a Windows 11 box however.\
    \ I am more than happy to write out and end to end install instruction for Windows\
    \ 11 (a lot of people I know want to do this). Shall I post separately about what\
    \ I have found and how I have been dociumenting it so far (e.g. minimum requirements,\
    \ Cude Toolkit installation, torch, wheel etc.)\n"
  created_at: 2023-12-15 23:53:37+00:00
  edited: false
  hidden: false
  id: 657ce70142fc53e18b0edecc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
      fullname: Younes Belkada
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybelkada
      type: user
    createdAt: '2023-12-16T16:39:28.000Z'
    data:
      edited: false
      editors:
      - ybelkada
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9550355076789856
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648631057413-noauth.png?w=200&h=200&f=face
          fullname: Younes Belkada
          isHf: true
          isPro: false
          name: ybelkada
          type: user
        html: "<blockquote>\n<p>I am coming across quite a few issues loading this\
          \ on to a Windows 11 box however. I am more than happy to write out and\
          \ end to end install instruction for Windows 11 </p>\n</blockquote>\n<p>That\
          \ would be really great <span data-props=\"{&quot;user&quot;:&quot;paddyofitz&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/paddyofitz\"\
          >@<span class=\"underline\">paddyofitz</span></a></span>\n\n\t</span></span>\
          \ !<br>I think that you can post a new issue with a clear title that explains\
          \ it is about how end-to-end instructions for Windows 11, it will be definitely\
          \ extremely helpful for the community</p>\n"
        raw: "> I am coming across quite a few issues loading this on to a Windows\
          \ 11 box however. I am more than happy to write out and end to end install\
          \ instruction for Windows 11 \n\nThat would be really great @paddyofitz\
          \ !\nI think that you can post a new issue with a clear title that explains\
          \ it is about how end-to-end instructions for Windows 11, it will be definitely\
          \ extremely helpful for the community"
        updatedAt: '2023-12-16T16:39:28.635Z'
      numEdits: 0
      reactions: []
    id: 657dd2c0ce825cd97496413d
    type: comment
  author: ybelkada
  content: "> I am coming across quite a few issues loading this on to a Windows 11\
    \ box however. I am more than happy to write out and end to end install instruction\
    \ for Windows 11 \n\nThat would be really great @paddyofitz !\nI think that you\
    \ can post a new issue with a clear title that explains it is about how end-to-end\
    \ instructions for Windows 11, it will be definitely extremely helpful for the\
    \ community"
  created_at: 2023-12-16 16:39:28+00:00
  edited: false
  hidden: false
  id: 657dd2c0ce825cd97496413d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/sZ-GBCIKUoz7Ls5ZqzrSQ.jpeg?w=200&h=200&f=face
      fullname: Patrick FitzGerald
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: paddyofitz
      type: user
    createdAt: '2023-12-16T21:39:06.000Z'
    data:
      edited: false
      editors:
      - paddyofitz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9491668939590454
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/sZ-GBCIKUoz7Ls5ZqzrSQ.jpeg?w=200&h=200&f=face
          fullname: Patrick FitzGerald
          isHf: false
          isPro: false
          name: paddyofitz
          type: user
        html: "<p>I will do - just stripping my build right back to work out the dependency\
          \ chain on pip as if this was the first thing going on a machine <span data-props=\"\
          {&quot;user&quot;:&quot;ybelkada&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/ybelkada\">@<span class=\"underline\">ybelkada</span></a></span>\n\
          \n\t</span></span> </p>\n"
        raw: 'I will do - just stripping my build right back to work out the dependency
          chain on pip as if this was the first thing going on a machine @ybelkada '
        updatedAt: '2023-12-16T21:39:06.031Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - ybelkada
    id: 657e18fa1815b29c9ad16359
    type: comment
  author: paddyofitz
  content: 'I will do - just stripping my build right back to work out the dependency
    chain on pip as if this was the first thing going on a machine @ybelkada '
  created_at: 2023-12-16 21:39:06+00:00
  edited: false
  hidden: false
  id: 657e18fa1815b29c9ad16359
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: mistralai/Mixtral-8x7B-v0.1
repo_type: model
status: open
target_branch: null
title: Maybe remove the `+` signs in the demo code?
