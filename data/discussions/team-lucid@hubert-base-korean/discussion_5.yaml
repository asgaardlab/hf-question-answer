!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aliu2000
conflicting_files: null
created_at: 2023-07-25 07:45:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/208998ac66cfa86888bcde7080a8a6a7.svg
      fullname: FlyingBlackshark
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aliu2000
      type: user
    createdAt: '2023-07-25T08:45:15.000Z'
    data:
      edited: false
      editors:
      - aliu2000
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8981928825378418
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/208998ac66cfa86888bcde7080a8a6a7.svg
          fullname: FlyingBlackshark
          isHf: false
          isPro: false
          name: aliu2000
          type: user
        html: '<p>2023-07-25 08:41:54.423197: E external/xla/xla/service/slow_operation_alarm.cc:65]
          Constant folding an instruction is taking &gt; 1s:</p>

          <p>%reduce-window.16 = f32[32,2,128]{2,1,0} reduce-window(f32[1024,64,128]{2,1,0}
          %constant.964, f32[] %constant.288), window={size=32x32x1 stride=32x32x1},
          to_apply=%region_17.1831</p>

          <p>This isn''t necessarily a bug; constant-folding is inherently a trade-off
          between compilation time and speed at runtime. XLA has some guards that
          attempt to keep constant folding from taking too long, but fundamentally
          you''ll always be able to come up with an input program that takes a long
          time.</p>

          <p>If you''d like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo
          and attach the results.</p>

          '
        raw: "2023-07-25 08:41:54.423197: E external/xla/xla/service/slow_operation_alarm.cc:65]\
          \ Constant folding an instruction is taking > 1s:\r\n\r\n%reduce-window.16\
          \ = f32[32,2,128]{2,1,0} reduce-window(f32[1024,64,128]{2,1,0} %constant.964,\
          \ f32[] %constant.288), window={size=32x32x1 stride=32x32x1}, to_apply=%region_17.1831\r\
          \n\r\nThis isn't necessarily a bug; constant-folding is inherently a trade-off\
          \ between compilation time and speed at runtime. XLA has some guards that\
          \ attempt to keep constant folding from taking too long, but fundamentally\
          \ you'll always be able to come up with an input program that takes a long\
          \ time.\r\n\r\nIf you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo\
          \ and attach the results."
        updatedAt: '2023-07-25T08:45:15.368Z'
      numEdits: 0
      reactions: []
    id: 64bf8b9b46cc3cdfbb336252
    type: comment
  author: aliu2000
  content: "2023-07-25 08:41:54.423197: E external/xla/xla/service/slow_operation_alarm.cc:65]\
    \ Constant folding an instruction is taking > 1s:\r\n\r\n%reduce-window.16 = f32[32,2,128]{2,1,0}\
    \ reduce-window(f32[1024,64,128]{2,1,0} %constant.964, f32[] %constant.288), window={size=32x32x1\
    \ stride=32x32x1}, to_apply=%region_17.1831\r\n\r\nThis isn't necessarily a bug;\
    \ constant-folding is inherently a trade-off between compilation time and speed\
    \ at runtime. XLA has some guards that attempt to keep constant folding from taking\
    \ too long, but fundamentally you'll always be able to come up with an input program\
    \ that takes a long time.\r\n\r\nIf you'd like to file a bug, run with envvar\
    \ XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results."
  created_at: 2023-07-25 07:45:15+00:00
  edited: false
  hidden: false
  id: 64bf8b9b46cc3cdfbb336252
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1636943203361-60fa8eff6849208c6bce3c79.png?w=200&h=200&f=face
      fullname: HYUNWOO LEE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: hyunwoo3235
      type: user
    createdAt: '2023-07-25T09:15:21.000Z'
    data:
      edited: false
      editors:
      - hyunwoo3235
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8857319355010986
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1636943203361-60fa8eff6849208c6bce3c79.png?w=200&h=200&f=face
          fullname: HYUNWOO LEE
          isHf: false
          isPro: true
          name: hyunwoo3235
          type: user
        html: '<p>I don''t know what you meant by creating this discussion.<br>There
          is no code and no execution environment here, just a simple error message.
          Sadly, I''m not omnipotent, so there''s nothing I can do with this alone.</p>

          <p>We trained on TPU-VM using jax.pmap without problems. Also, I just did
          a simple test in the WSL2 environment, and jit compilation proceeded without
          any problems.</p>

          <p>If you need help, literally more information please.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/60fa8eff6849208c6bce3c79/PjNHuAJcIfHo-xmDKhP1f.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/60fa8eff6849208c6bce3c79/PjNHuAJcIfHo-xmDKhP1f.png"></a></p>

          '
        raw: 'I don''t know what you meant by creating this discussion.

          There is no code and no execution environment here, just a simple error
          message. Sadly, I''m not omnipotent, so there''s nothing I can do with this
          alone.


          We trained on TPU-VM using jax.pmap without problems. Also, I just did a
          simple test in the WSL2 environment, and jit compilation proceeded without
          any problems.


          If you need help, literally more information please.


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/60fa8eff6849208c6bce3c79/PjNHuAJcIfHo-xmDKhP1f.png)

          '
        updatedAt: '2023-07-25T09:15:21.089Z'
      numEdits: 0
      reactions: []
    id: 64bf92a91f38bef571e9bf2f
    type: comment
  author: hyunwoo3235
  content: 'I don''t know what you meant by creating this discussion.

    There is no code and no execution environment here, just a simple error message.
    Sadly, I''m not omnipotent, so there''s nothing I can do with this alone.


    We trained on TPU-VM using jax.pmap without problems. Also, I just did a simple
    test in the WSL2 environment, and jit compilation proceeded without any problems.


    If you need help, literally more information please.


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/60fa8eff6849208c6bce3c79/PjNHuAJcIfHo-xmDKhP1f.png)

    '
  created_at: 2023-07-25 08:15:21+00:00
  edited: false
  hidden: false
  id: 64bf92a91f38bef571e9bf2f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/208998ac66cfa86888bcde7080a8a6a7.svg
      fullname: FlyingBlackshark
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aliu2000
      type: user
    createdAt: '2023-07-25T09:18:11.000Z'
    data:
      edited: true
      editors:
      - aliu2000
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.39266470074653625
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/208998ac66cfa86888bcde7080a8a6a7.svg
          fullname: FlyingBlackshark
          isHf: false
          isPro: false
          name: aliu2000
          type: user
        html: '<p>def pred_vec( wavPath, vecPath):<br>    feats = readwave(wavPath,
          normalize=False)<br>    model = FlaxAutoModel.from_pretrained("team-lucid/hubert-large-korean",
          trust_remote_code=True)<br>    outputs = jax.jit(model,backend=''cpu'')(feats.cpu().numpy())<br>    vec
          = outputs.last_hidden_state.squeeze(0)<br>    np.save(vecPath, vec, allow_pickle=False)<br>using
          TPU-VM v3-8 and feats.shape = (1,wav_length)</p>

          '
        raw: "def pred_vec( wavPath, vecPath):\n    feats = readwave(wavPath, normalize=False)\n\
          \    model = FlaxAutoModel.from_pretrained(\"team-lucid/hubert-large-korean\"\
          , trust_remote_code=True)\n    outputs = jax.jit(model,backend='cpu')(feats.cpu().numpy())\n\
          \    vec = outputs.last_hidden_state.squeeze(0)\n    np.save(vecPath, vec,\
          \ allow_pickle=False)\nusing TPU-VM v3-8 and feats.shape = (1,wav_length)"
        updatedAt: '2023-07-25T09:25:56.915Z'
      numEdits: 4
      reactions: []
    id: 64bf93534b4ff0d50991af78
    type: comment
  author: aliu2000
  content: "def pred_vec( wavPath, vecPath):\n    feats = readwave(wavPath, normalize=False)\n\
    \    model = FlaxAutoModel.from_pretrained(\"team-lucid/hubert-large-korean\"\
    , trust_remote_code=True)\n    outputs = jax.jit(model,backend='cpu')(feats.cpu().numpy())\n\
    \    vec = outputs.last_hidden_state.squeeze(0)\n    np.save(vecPath, vec, allow_pickle=False)\n\
    using TPU-VM v3-8 and feats.shape = (1,wav_length)"
  created_at: 2023-07-25 08:18:11+00:00
  edited: true
  hidden: false
  id: 64bf93534b4ff0d50991af78
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1636943203361-60fa8eff6849208c6bce3c79.png?w=200&h=200&f=face
      fullname: HYUNWOO LEE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: hyunwoo3235
      type: user
    createdAt: '2023-07-25T09:33:26.000Z'
    data:
      edited: false
      editors:
      - hyunwoo3235
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9555498957633972
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1636943203361-60fa8eff6849208c6bce3c79.png?w=200&h=200&f=face
          fullname: HYUNWOO LEE
          isHf: false
          isPro: true
          name: hyunwoo3235
          type: user
        html: '<p>The indent is gone, but your code seems to load the model and try
          to jit every time you call the function. It is inefficient because the previous
          time-consuming compilation is erased.</p>

          <p>It is recommended to leave it like <code>jit_inference</code> for already
          loaded models. Also, there is no reason to use a CPU in an accelerated environment
          such as TPU or GPU. Of course, all input types must be the same for jit
          to be effective.</p>

          <p>It would be easier to check if more information could be accessed like
          the Github repository.</p>

          '
        raw: 'The indent is gone, but your code seems to load the model and try to
          jit every time you call the function. It is inefficient because the previous
          time-consuming compilation is erased.


          It is recommended to leave it like ```jit_inference``` for already loaded
          models. Also, there is no reason to use a CPU in an accelerated environment
          such as TPU or GPU. Of course, all input types must be the same for jit
          to be effective.


          It would be easier to check if more information could be accessed like the
          Github repository.'
        updatedAt: '2023-07-25T09:33:26.372Z'
      numEdits: 0
      reactions: []
    id: 64bf96e65cf7ae507b6391d7
    type: comment
  author: hyunwoo3235
  content: 'The indent is gone, but your code seems to load the model and try to jit
    every time you call the function. It is inefficient because the previous time-consuming
    compilation is erased.


    It is recommended to leave it like ```jit_inference``` for already loaded models.
    Also, there is no reason to use a CPU in an accelerated environment such as TPU
    or GPU. Of course, all input types must be the same for jit to be effective.


    It would be easier to check if more information could be accessed like the Github
    repository.'
  created_at: 2023-07-25 08:33:26+00:00
  edited: false
  hidden: false
  id: 64bf96e65cf7ae507b6391d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/208998ac66cfa86888bcde7080a8a6a7.svg
      fullname: FlyingBlackshark
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aliu2000
      type: user
    createdAt: '2023-07-25T09:40:27.000Z'
    data:
      edited: false
      editors:
      - aliu2000
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8186829090118408
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/208998ac66cfa86888bcde7080a8a6a7.svg
          fullname: FlyingBlackshark
          isHf: false
          isPro: false
          name: aliu2000
          type: user
        html: '<p>You''re right, the model runs fast on TPUs using pmap</p>

          '
        raw: You're right, the model runs fast on TPUs using pmap
        updatedAt: '2023-07-25T09:40:27.130Z'
      numEdits: 0
      reactions: []
    id: 64bf988b1a62149c5eb438ca
    type: comment
  author: aliu2000
  content: You're right, the model runs fast on TPUs using pmap
  created_at: 2023-07-25 08:40:27+00:00
  edited: false
  hidden: false
  id: 64bf988b1a62149c5eb438ca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/208998ac66cfa86888bcde7080a8a6a7.svg
      fullname: FlyingBlackshark
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aliu2000
      type: user
    createdAt: '2023-07-26T06:18:44.000Z'
    data:
      status: closed
    id: 64c0bac4a4cb9ca14014db12
    type: status-change
  author: aliu2000
  created_at: 2023-07-26 05:18:44+00:00
  id: 64c0bac4a4cb9ca14014db12
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: team-lucid/hubert-base-korean
repo_type: model
status: closed
target_branch: null
title: Extremely slow inference when using jax.jit
