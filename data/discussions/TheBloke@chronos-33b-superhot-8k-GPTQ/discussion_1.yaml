!!python/object:huggingface_hub.community.DiscussionWithDetails
author: underlines
conflicting_files: null
created_at: 2023-06-26 20:30:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c9b00218abc1e8d613db2ca2674a57f7.svg
      fullname: Jan Badertscher
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: underlines
      type: user
    createdAt: '2023-06-26T21:30:06.000Z'
    data:
      edited: true
      editors:
      - underlines
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9394854307174683
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c9b00218abc1e8d613db2ca2674a57f7.svg
          fullname: Jan Badertscher
          isHf: false
          isPro: false
          name: underlines
          type: user
        html: '<p>Thanks for this great merge and quant!</p>

          <p>As usual with these merges, mentioning multiple prompt formats :) What
          is the one that works best for you?</p>

          <p>My environment:</p>

          <ul>

          <li>thebloke/cuda11.8.0-ubuntu22.04-oneclick:latest on runpod</li>

          <li>1 x RTX A6000 / 16 vCPU 62 GB RAM</li>

          <li>ExLlama<ul>

          <li>max_seq_len 4096</li>

          <li>compress_pos_emb 2</li>

          <li>LLaMA-Precise (I tried others)</li>

          <li>Instruction Template: I tried Alpaca + Vicuna v1.1</li>

          <li>Mode: I tried chat, chat-instruct and instruct</li>

          </ul>

          </li>

          </ul>

          <p>Always gives me gibberish:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63175a0adc97a974718fe704/ulp0l1v8FvQ5fk15n33CX.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/63175a0adc97a974718fe704/ulp0l1v8FvQ5fk15n33CX.png"></a></p>

          '
        raw: "Thanks for this great merge and quant!\n\nAs usual with these merges,\
          \ mentioning multiple prompt formats :) What is the one that works best\
          \ for you?\n\nMy environment:\n- thebloke/cuda11.8.0-ubuntu22.04-oneclick:latest\
          \ on runpod\n- 1 x RTX A6000 / 16 vCPU 62 GB RAM\n- ExLlama\n  - max_seq_len\
          \ 4096\n  - compress_pos_emb 2\n  - LLaMA-Precise (I tried others)\n  -\
          \ Instruction Template: I tried Alpaca + Vicuna v1.1\n  - Mode: I tried\
          \ chat, chat-instruct and instruct\n\nAlways gives me gibberish:\n  \n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63175a0adc97a974718fe704/ulp0l1v8FvQ5fk15n33CX.png)\n\
          \n"
        updatedAt: '2023-06-26T21:41:27.958Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Neman
    id: 649a035ede0fb7f3f492ffd7
    type: comment
  author: underlines
  content: "Thanks for this great merge and quant!\n\nAs usual with these merges,\
    \ mentioning multiple prompt formats :) What is the one that works best for you?\n\
    \nMy environment:\n- thebloke/cuda11.8.0-ubuntu22.04-oneclick:latest on runpod\n\
    - 1 x RTX A6000 / 16 vCPU 62 GB RAM\n- ExLlama\n  - max_seq_len 4096\n  - compress_pos_emb\
    \ 2\n  - LLaMA-Precise (I tried others)\n  - Instruction Template: I tried Alpaca\
    \ + Vicuna v1.1\n  - Mode: I tried chat, chat-instruct and instruct\n\nAlways\
    \ gives me gibberish:\n  \n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63175a0adc97a974718fe704/ulp0l1v8FvQ5fk15n33CX.png)\n\
    \n"
  created_at: 2023-06-26 20:30:06+00:00
  edited: true
  hidden: false
  id: 649a035ede0fb7f3f492ffd7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/26f8e7c372d3d4afadbe1b2d9e8dbb45.svg
      fullname: asukaceres
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: asukaceres
      type: user
    createdAt: '2023-06-28T01:27:02.000Z'
    data:
      edited: false
      editors:
      - asukaceres
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5937917828559875
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/26f8e7c372d3d4afadbe1b2d9e8dbb45.svg
          fullname: asukaceres
          isHf: false
          isPro: false
          name: asukaceres
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/644651ac5004f2cb3af01f90/RnXbANSPrXRUaztCFVRdd.png"><img
          alt="Snipaste_2023-06-27_23-27-57.png" src="https://cdn-uploads.huggingface.co/production/uploads/644651ac5004f2cb3af01f90/RnXbANSPrXRUaztCFVRdd.png"></a><br><a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/644651ac5004f2cb3af01f90/NwVNj5NmmzLSU_a2h-zKK.png"><img
          alt="Snipaste_2023-06-27_23-32-38.png" src="https://cdn-uploads.huggingface.co/production/uploads/644651ac5004f2cb3af01f90/NwVNj5NmmzLSU_a2h-zKK.png"></a></p>

          <p>Yep, same thing happened to me for these 30B / 33B SuperHOT models (gibberish
          output)<br>Tried:<br>Guanaco-33B-SuperHOT-8K-GPTQ<br>WizardLM-33B-V1.0-Uncensored-SuperHOT-8K-GPTQ<br>Wizard-Vicuna-30B-Superhot-8K-GPTQ</p>

          <p>13B SuperHOT models seem working fine.</p>

          <hr>

          <p>OS: Ubuntu 22.04<br>CPU: 32C RAM: 188G<br>GPU: NVIDIA A10 24G<br>Driver:
          525.105.17<br>Oobabooga updated to latest version too.</p>

          '
        raw: '![Snipaste_2023-06-27_23-27-57.png](https://cdn-uploads.huggingface.co/production/uploads/644651ac5004f2cb3af01f90/RnXbANSPrXRUaztCFVRdd.png)

          ![Snipaste_2023-06-27_23-32-38.png](https://cdn-uploads.huggingface.co/production/uploads/644651ac5004f2cb3af01f90/NwVNj5NmmzLSU_a2h-zKK.png)


          Yep, same thing happened to me for these 30B / 33B SuperHOT models (gibberish
          output)

          Tried:

          Guanaco-33B-SuperHOT-8K-GPTQ

          WizardLM-33B-V1.0-Uncensored-SuperHOT-8K-GPTQ

          Wizard-Vicuna-30B-Superhot-8K-GPTQ


          13B SuperHOT models seem working fine.


          -------------------------------

          OS: Ubuntu 22.04

          CPU: 32C RAM: 188G

          GPU: NVIDIA A10 24G

          Driver: 525.105.17

          Oobabooga updated to latest version too.

          '
        updatedAt: '2023-06-28T01:27:02.718Z'
      numEdits: 0
      reactions: []
    id: 649b8c66d0b365aee09127c9
    type: comment
  author: asukaceres
  content: '![Snipaste_2023-06-27_23-27-57.png](https://cdn-uploads.huggingface.co/production/uploads/644651ac5004f2cb3af01f90/RnXbANSPrXRUaztCFVRdd.png)

    ![Snipaste_2023-06-27_23-32-38.png](https://cdn-uploads.huggingface.co/production/uploads/644651ac5004f2cb3af01f90/NwVNj5NmmzLSU_a2h-zKK.png)


    Yep, same thing happened to me for these 30B / 33B SuperHOT models (gibberish
    output)

    Tried:

    Guanaco-33B-SuperHOT-8K-GPTQ

    WizardLM-33B-V1.0-Uncensored-SuperHOT-8K-GPTQ

    Wizard-Vicuna-30B-Superhot-8K-GPTQ


    13B SuperHOT models seem working fine.


    -------------------------------

    OS: Ubuntu 22.04

    CPU: 32C RAM: 188G

    GPU: NVIDIA A10 24G

    Driver: 525.105.17

    Oobabooga updated to latest version too.

    '
  created_at: 2023-06-28 00:27:02+00:00
  edited: false
  hidden: false
  id: 649b8c66d0b365aee09127c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c9b00218abc1e8d613db2ca2674a57f7.svg
      fullname: Jan Badertscher
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: underlines
      type: user
    createdAt: '2023-06-28T19:35:26.000Z'
    data:
      edited: false
      editors:
      - underlines
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.701590359210968
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c9b00218abc1e8d613db2ca2674a57f7.svg
          fullname: Jan Badertscher
          isHf: false
          isPro: false
          name: underlines
          type: user
        html: '<p><a href="https://huggingface.co/TheBloke/Vicuna-33B-1-1-preview-SuperHOT-8K-GPTQ/discussions/1#649c0950272ee9fd6b635ea3">https://huggingface.co/TheBloke/Vicuna-33B-1-1-preview-SuperHOT-8K-GPTQ/discussions/1#649c0950272ee9fd6b635ea3</a></p>

          <p>For people using TheBloke''s Runpod Template: It didn''t update ExLlama,
          but it''s now fixed. Restart your pods or update ExLlama.</p>

          '
        raw: 'https://huggingface.co/TheBloke/Vicuna-33B-1-1-preview-SuperHOT-8K-GPTQ/discussions/1#649c0950272ee9fd6b635ea3


          For people using TheBloke''s Runpod Template: It didn''t update ExLlama,
          but it''s now fixed. Restart your pods or update ExLlama.'
        updatedAt: '2023-06-28T19:35:26.463Z'
      numEdits: 0
      reactions: []
      relatedEventId: 649c8b7e67fd6c6aa97e93f1
    id: 649c8b7e67fd6c6aa97e93f0
    type: comment
  author: underlines
  content: 'https://huggingface.co/TheBloke/Vicuna-33B-1-1-preview-SuperHOT-8K-GPTQ/discussions/1#649c0950272ee9fd6b635ea3


    For people using TheBloke''s Runpod Template: It didn''t update ExLlama, but it''s
    now fixed. Restart your pods or update ExLlama.'
  created_at: 2023-06-28 18:35:26+00:00
  edited: false
  hidden: false
  id: 649c8b7e67fd6c6aa97e93f0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/c9b00218abc1e8d613db2ca2674a57f7.svg
      fullname: Jan Badertscher
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: underlines
      type: user
    createdAt: '2023-06-28T19:35:26.000Z'
    data:
      status: closed
    id: 649c8b7e67fd6c6aa97e93f1
    type: status-change
  author: underlines
  created_at: 2023-06-28 18:35:26+00:00
  id: 649c8b7e67fd6c6aa97e93f1
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/chronos-33b-superhot-8k-GPTQ
repo_type: model
status: closed
target_branch: null
title: Prompt format
