!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KatyTheCutie
conflicting_files: null
created_at: 2024-01-04 09:29:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/653a2392341143f7774424d8/Ts1QIoXwlQkR741likXrb.png?w=200&h=200&f=face
      fullname: Katy Vetteriano
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KatyTheCutie
      type: user
    createdAt: '2024-01-04T09:29:09.000Z'
    data:
      edited: false
      editors:
      - KatyTheCutie
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9625009298324585
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/653a2392341143f7774424d8/Ts1QIoXwlQkR741likXrb.png?w=200&h=200&f=face
          fullname: Katy Vetteriano
          isHf: false
          isPro: false
          name: KatyTheCutie
          type: user
        html: '<p>Would you convert your model to a gguf format? as its a lot easier
          to run</p>

          '
        raw: Would you convert your model to a gguf format? as its a lot easier to
          run
        updatedAt: '2024-01-04T09:29:09.387Z'
      numEdits: 0
      reactions: []
    id: 65967a65e3ff5ad51a72585f
    type: comment
  author: KatyTheCutie
  content: Would you convert your model to a gguf format? as its a lot easier to run
  created_at: 2024-01-04 09:29:09+00:00
  edited: false
  hidden: false
  id: 65967a65e3ff5ad51a72585f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a330d2a39da7c3e5f67b19a66eb0cb7a.svg
      fullname: Matthew Gammett
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Permahuman
      type: user
    createdAt: '2024-01-09T23:56:39.000Z'
    data:
      edited: false
      editors:
      - Permahuman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9343487620353699
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a330d2a39da7c3e5f67b19a66eb0cb7a.svg
          fullname: Matthew Gammett
          isHf: false
          isPro: false
          name: Permahuman
          type: user
        html: '<p>I second this request. Is it even possible to quantize to gguf?
          I get the feeling some of these multimodals are not compatible with gguf
          or folks just aren''t prioritizing the vllms in the same way as the textllms.</p>

          '
        raw: I second this request. Is it even possible to quantize to gguf? I get
          the feeling some of these multimodals are not compatible with gguf or folks
          just aren't prioritizing the vllms in the same way as the textllms.
        updatedAt: '2024-01-09T23:56:39.283Z'
      numEdits: 0
      reactions: []
    id: 659ddd371692b39ff0aece9f
    type: comment
  author: Permahuman
  content: I second this request. Is it even possible to quantize to gguf? I get the
    feeling some of these multimodals are not compatible with gguf or folks just aren't
    prioritizing the vllms in the same way as the textllms.
  created_at: 2024-01-09 23:56:39+00:00
  edited: false
  hidden: false
  id: 659ddd371692b39ff0aece9f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Tyrannosaurus/TinyGPT-V
repo_type: model
status: open
target_branch: null
title: Quants?
