!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pierreguillou
conflicting_files: null
created_at: 2023-01-13 17:56:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1627870916063-5f0981ff19cb630495b81477.jpeg?w=200&h=200&f=face
      fullname: Pierre Guillou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pierreguillou
      type: user
    createdAt: '2023-01-13T17:56:35.000Z'
    data:
      edited: false
      editors:
      - pierreguillou
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1627870916063-5f0981ff19cb630495b81477.jpeg?w=200&h=200&f=face
          fullname: Pierre Guillou
          isHf: false
          isPro: false
          name: pierreguillou
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;nielsr&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/nielsr\">@<span class=\"\
          underline\">nielsr</span></a></span>\n\n\t</span></span>.</p>\n<p>Many thanks\
          \ for this model that you finetuned in your notebook <a rel=\"nofollow\"\
          \ href=\"https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LiLT/Fine_tune_LiLT_on_a_custom_dataset%2C_in_any_language.ipynb\"\
          >Fine_tune_LiLT_on_a_custom_dataset%2C_in_any_language.ipynb</a>.</p>\n\
          <p>However, you did not provide the inference code to use on a document\
          \ image (ie, without boxes coordinates).</p>\n<p>I did try to adapt the\
          \ code of <span data-props=\"{&quot;user&quot;:&quot;philschmid&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/philschmid\"\
          >@<span class=\"underline\">philschmid</span></a></span>\n\n\t</span></span>\
          \  from his blog post <a rel=\"nofollow\" href=\"https://www.philschmid.de/fine-tuning-lilt\"\
          >Document AI: LiLT a better language agnostic LayoutLM model</a> but it\
          \ does not work.</p>\n<p>Here is this code:</p>\n<pre><code>from transformers\
          \ import LayoutLMv3FeatureExtractor, AutoTokenizer, LayoutLMv3Processor\n\
          \nmodel_id=\"nielsr/lilt-xlm-roberta-base\"\n\n# use LayoutLMv3 processor\
          \ without ocr since the dataset already includes the ocr text\nfeature_extractor\
          \ = LayoutLMv3FeatureExtractor(apply_ocr=True) # set\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\
          # cannot use from_pretrained since the processor is not saved in the base\
          \ model\nprocessor = LayoutLMv3Processor(feature_extractor, tokenizer)\n\
          </code></pre>\n<p>... and the error message:</p>\n<pre><code>---------------------------------------------------------------------------\n\
          ValueError                                Traceback (most recent call last)\n\
          &lt;ipython-input-5-caabe3c64173&gt; in &lt;module&gt;\n      7 tokenizer\
          \ = AutoTokenizer.from_pretrained(model_id)\n      8 # cannot use from_pretrained\
          \ since the processor is not saved in the base model\n----&gt; 9 processor\
          \ = LayoutLMv3Processor(feature_extractor, tokenizer)\n\n/usr/local/lib/python3.8/dist-packages/transformers/processing_utils.py\
          \ in __init__(self, *args, **kwargs)\n     82 \n     83             if not\
          \ isinstance(arg, proper_class):\n---&gt; 84                 raise ValueError(\n\
          \     85                     f\"Received a {type(arg).__name__} for argument\
          \ {attribute_name}, but a {class_name} was expected.\"\n     86        \
          \         )\n\nValueError: Received a XLMRobertaTokenizerFast for argument\
          \ tokenizer, but a ('LayoutLMv3Tokenizer', 'LayoutLMv3TokenizerFast') was\
          \ expected.\n</code></pre>\n<p>Any help is welcome :-) Thank you.</p>\n"
        raw: "Hi @nielsr.\r\n\r\nMany thanks for this model that you finetuned in\
          \ your notebook [Fine_tune_LiLT_on_a_custom_dataset%2C_in_any_language.ipynb](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LiLT/Fine_tune_LiLT_on_a_custom_dataset%2C_in_any_language.ipynb).\r\
          \n\r\nHowever, you did not provide the inference code to use on a document\
          \ image (ie, without boxes coordinates).\r\n\r\nI did try to adapt the code\
          \ of @philschmid  from his blog post [Document AI: LiLT a better language\
          \ agnostic LayoutLM model](https://www.philschmid.de/fine-tuning-lilt) but\
          \ it does not work.\r\n\r\nHere is this code:\r\n\r\n```\r\nfrom transformers\
          \ import LayoutLMv3FeatureExtractor, AutoTokenizer, LayoutLMv3Processor\r\
          \n\r\nmodel_id=\"nielsr/lilt-xlm-roberta-base\"\r\n\r\n# use LayoutLMv3\
          \ processor without ocr since the dataset already includes the ocr text\r\
          \nfeature_extractor = LayoutLMv3FeatureExtractor(apply_ocr=True) # set\r\
          \ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\n# cannot use from_pretrained\
          \ since the processor is not saved in the base model\r\nprocessor = LayoutLMv3Processor(feature_extractor,\
          \ tokenizer)\r\n```\r\n\r\n... and the error message:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\
          \nValueError                                Traceback (most recent call\
          \ last)\r\n<ipython-input-5-caabe3c64173> in <module>\r\n      7 tokenizer\
          \ = AutoTokenizer.from_pretrained(model_id)\r\n      8 # cannot use from_pretrained\
          \ since the processor is not saved in the base model\r\n----> 9 processor\
          \ = LayoutLMv3Processor(feature_extractor, tokenizer)\r\n\r\n/usr/local/lib/python3.8/dist-packages/transformers/processing_utils.py\
          \ in __init__(self, *args, **kwargs)\r\n     82 \r\n     83            \
          \ if not isinstance(arg, proper_class):\r\n---> 84                 raise\
          \ ValueError(\r\n     85                     f\"Received a {type(arg).__name__}\
          \ for argument {attribute_name}, but a {class_name} was expected.\"\r\n\
          \     86                 )\r\n\r\nValueError: Received a XLMRobertaTokenizerFast\
          \ for argument tokenizer, but a ('LayoutLMv3Tokenizer', 'LayoutLMv3TokenizerFast')\
          \ was expected.\r\n```\r\n\r\nAny help is welcome :-) Thank you."
        updatedAt: '2023-01-13T17:56:35.115Z'
      numEdits: 0
      reactions: []
    id: 63c19b5370b05b966372bf2c
    type: comment
  author: pierreguillou
  content: "Hi @nielsr.\r\n\r\nMany thanks for this model that you finetuned in your\
    \ notebook [Fine_tune_LiLT_on_a_custom_dataset%2C_in_any_language.ipynb](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LiLT/Fine_tune_LiLT_on_a_custom_dataset%2C_in_any_language.ipynb).\r\
    \n\r\nHowever, you did not provide the inference code to use on a document image\
    \ (ie, without boxes coordinates).\r\n\r\nI did try to adapt the code of @philschmid\
    \  from his blog post [Document AI: LiLT a better language agnostic LayoutLM model](https://www.philschmid.de/fine-tuning-lilt)\
    \ but it does not work.\r\n\r\nHere is this code:\r\n\r\n```\r\nfrom transformers\
    \ import LayoutLMv3FeatureExtractor, AutoTokenizer, LayoutLMv3Processor\r\n\r\n\
    model_id=\"nielsr/lilt-xlm-roberta-base\"\r\n\r\n# use LayoutLMv3 processor without\
    \ ocr since the dataset already includes the ocr text\r\nfeature_extractor = LayoutLMv3FeatureExtractor(apply_ocr=True)\
    \ # set\r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\n# cannot use\
    \ from_pretrained since the processor is not saved in the base model\r\nprocessor\
    \ = LayoutLMv3Processor(feature_extractor, tokenizer)\r\n```\r\n\r\n... and the\
    \ error message:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\
    \nValueError                                Traceback (most recent call last)\r\
    \n<ipython-input-5-caabe3c64173> in <module>\r\n      7 tokenizer = AutoTokenizer.from_pretrained(model_id)\r\
    \n      8 # cannot use from_pretrained since the processor is not saved in the\
    \ base model\r\n----> 9 processor = LayoutLMv3Processor(feature_extractor, tokenizer)\r\
    \n\r\n/usr/local/lib/python3.8/dist-packages/transformers/processing_utils.py\
    \ in __init__(self, *args, **kwargs)\r\n     82 \r\n     83             if not\
    \ isinstance(arg, proper_class):\r\n---> 84                 raise ValueError(\r\
    \n     85                     f\"Received a {type(arg).__name__} for argument\
    \ {attribute_name}, but a {class_name} was expected.\"\r\n     86            \
    \     )\r\n\r\nValueError: Received a XLMRobertaTokenizerFast for argument tokenizer,\
    \ but a ('LayoutLMv3Tokenizer', 'LayoutLMv3TokenizerFast') was expected.\r\n```\r\
    \n\r\nAny help is welcome :-) Thank you."
  created_at: 2023-01-13 17:56:35+00:00
  edited: false
  hidden: false
  id: 63c19b5370b05b966372bf2c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1627870916063-5f0981ff19cb630495b81477.jpeg?w=200&h=200&f=face
      fullname: Pierre Guillou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pierreguillou
      type: user
    createdAt: '2023-01-13T17:58:05.000Z'
    data:
      from: How to use nielsr/lilt-xlm-roberta-base for inference with a a document
        image?
      to: How to use nielsr/lilt-xlm-roberta-base for inference with a document image?
    id: 63c19badf9453420b5d63e4a
    type: title-change
  author: pierreguillou
  created_at: 2023-01-13 17:58:05+00:00
  id: 63c19badf9453420b5d63e4a
  new_title: How to use nielsr/lilt-xlm-roberta-base for inference with a document
    image?
  old_title: How to use nielsr/lilt-xlm-roberta-base for inference with a a document
    image?
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nielsr
      type: user
    createdAt: '2023-01-15T11:19:51.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Answered here: <a rel="nofollow" href="https://github.com/NielsRogge/Transformers-Tutorials/issues/236">https://github.com/NielsRogge/Transformers-Tutorials/issues/236</a></p>

          '
        raw: 'Answered here: https://github.com/NielsRogge/Transformers-Tutorials/issues/236'
        updatedAt: '2023-01-15T11:19:51.488Z'
      numEdits: 0
      reactions: []
      relatedEventId: 63c3e157864852729923a6f3
    id: 63c3e157864852729923a6f2
    type: comment
  author: nielsr
  content: 'Answered here: https://github.com/NielsRogge/Transformers-Tutorials/issues/236'
  created_at: 2023-01-15 11:19:51+00:00
  edited: false
  hidden: false
  id: 63c3e157864852729923a6f2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nielsr
      type: user
    createdAt: '2023-01-15T11:19:51.000Z'
    data:
      status: closed
    id: 63c3e157864852729923a6f3
    type: status-change
  author: nielsr
  created_at: 2023-01-15 11:19:51+00:00
  id: 63c3e157864852729923a6f3
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: nielsr/lilt-xlm-roberta-base
repo_type: model
status: closed
target_branch: null
title: How to use nielsr/lilt-xlm-roberta-base for inference with a document image?
