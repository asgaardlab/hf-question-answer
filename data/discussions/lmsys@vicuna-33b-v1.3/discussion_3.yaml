!!python/object:huggingface_hub.community.DiscussionWithDetails
author: chenfeicqq
conflicting_files: null
created_at: 2023-06-28 11:14:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e2ae6935e8c9e13e4c2ff4c5cefd555.svg
      fullname: cf
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chenfeicqq
      type: user
    createdAt: '2023-06-28T12:14:41.000Z'
    data:
      edited: true
      editors:
      - chenfeicqq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.975233256816864
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e2ae6935e8c9e13e4c2ff4c5cefd555.svg
          fullname: cf
          isHf: false
          isPro: false
          name: chenfeicqq
          type: user
        html: '<p>I want to deploy 33b model, need to evaluate how much graphics memory
          is needed.</p>

          <p>tks for you help.</p>

          '
        raw: 'I want to deploy 33b model, need to evaluate how much graphics memory
          is needed.


          tks for you help.'
        updatedAt: '2023-06-28T12:16:06.753Z'
      numEdits: 1
      reactions: []
    id: 649c24319c7dc132e7176cae
    type: comment
  author: chenfeicqq
  content: 'I want to deploy 33b model, need to evaluate how much graphics memory
    is needed.


    tks for you help.'
  created_at: 2023-06-28 11:14:41+00:00
  edited: true
  hidden: false
  id: 649c24319c7dc132e7176cae
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0e4bf1dc57d33ea743ca7241034a498f.svg
      fullname: tan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tenore
      type: user
    createdAt: '2023-07-29T17:01:55.000Z'
    data:
      edited: false
      editors:
      - tenore
      hidden: false
      identifiedLanguage:
        language: ca
        probability: 0.510992705821991
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0e4bf1dc57d33ea743ca7241034a498f.svg
          fullname: tan
          isHf: false
          isPro: false
          name: tenore
          type: user
        html: '<p>hi</p>

          '
        raw: hi
        updatedAt: '2023-07-29T17:01:55.164Z'
      numEdits: 0
      reactions: []
    id: 64c546035e5bc55a92044267
    type: comment
  author: tenore
  content: hi
  created_at: 2023-07-29 16:01:55+00:00
  edited: false
  hidden: false
  id: 64c546035e5bc55a92044267
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/74f40011605746e22a9993675a1a3768.svg
      fullname: Andreas Binder
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andreasbinder
      type: user
    createdAt: '2023-08-02T07:57:52.000Z'
    data:
      edited: false
      editors:
      - andreasbinder
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9146152138710022
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/74f40011605746e22a9993675a1a3768.svg
          fullname: Andreas Binder
          isHf: false
          isPro: false
          name: andreasbinder
          type: user
        html: '<p>Hi, 28GB of GPU memory for Vicuna-13B, thus I would interpolate
          and assume around 70GB of GPU<br><a rel="nofollow" href="https://github.com/lm-sys/FastChat#vicuna-weights">https://github.com/lm-sys/FastChat#vicuna-weights</a></p>

          '
        raw: 'Hi, 28GB of GPU memory for Vicuna-13B, thus I would interpolate and
          assume around 70GB of GPU

          https://github.com/lm-sys/FastChat#vicuna-weights'
        updatedAt: '2023-08-02T07:57:52.264Z'
      numEdits: 0
      reactions: []
    id: 64ca0c804515835c4dc51592
    type: comment
  author: andreasbinder
  content: 'Hi, 28GB of GPU memory for Vicuna-13B, thus I would interpolate and assume
    around 70GB of GPU

    https://github.com/lm-sys/FastChat#vicuna-weights'
  created_at: 2023-08-02 06:57:52+00:00
  edited: false
  hidden: false
  id: 64ca0c804515835c4dc51592
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: lmsys/vicuna-33b-v1.3
repo_type: model
status: open
target_branch: null
title: How much GPU graphics memory is required for deployment
