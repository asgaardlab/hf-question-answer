!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MrDevolver
conflicting_files: null
created_at: 2023-07-10 16:53:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6aec9ca2ae47baad15b60b38ec81d69d.svg
      fullname: Angelino Santiago
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MrDevolver
      type: user
    createdAt: '2023-07-10T17:53:44.000Z'
    data:
      edited: false
      editors:
      - MrDevolver
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4087696075439453
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6aec9ca2ae47baad15b60b38ec81d69d.svg
          fullname: Angelino Santiago
          isHf: false
          isPro: false
          name: MrDevolver
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6469054fff18750165a78ca0/urZBV9dwKMj7hsMy5oJSi.png"><img
          alt="ai_bigger_not_always_better.png" src="https://cdn-uploads.huggingface.co/production/uploads/6469054fff18750165a78ca0/urZBV9dwKMj7hsMy5oJSi.png"></a></p>

          '
        raw: "![ai_bigger_not_always_better.png](https://cdn-uploads.huggingface.co/production/uploads/6469054fff18750165a78ca0/urZBV9dwKMj7hsMy5oJSi.png)\r\
          \n"
        updatedAt: '2023-07-10T17:53:44.933Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - CeroShrijver
    id: 64ac45a8e0d23bcf0209df88
    type: comment
  author: MrDevolver
  content: "![ai_bigger_not_always_better.png](https://cdn-uploads.huggingface.co/production/uploads/6469054fff18750165a78ca0/urZBV9dwKMj7hsMy5oJSi.png)\r\
    \n"
  created_at: 2023-07-10 16:53:44+00:00
  edited: false
  hidden: false
  id: 64ac45a8e0d23bcf0209df88
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af9e3f8b157cbac14f49f2c20b1caaa4.svg
      fullname: Zachary Miller
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zjmiller
      type: user
    createdAt: '2023-07-12T20:28:13.000Z'
    data:
      edited: false
      editors:
      - zjmiller
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9816300868988037
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af9e3f8b157cbac14f49f2c20b1caaa4.svg
          fullname: Zachary Miller
          isHf: false
          isPro: false
          name: zjmiller
          type: user
        html: '<p>Any guesses what might be going on here?</p>

          '
        raw: Any guesses what might be going on here?
        updatedAt: '2023-07-12T20:28:13.208Z'
      numEdits: 0
      reactions: []
    id: 64af0cdd0d8a0c9ccf1e22cd
    type: comment
  author: zjmiller
  content: Any guesses what might be going on here?
  created_at: 2023-07-12 19:28:13+00:00
  edited: false
  hidden: false
  id: 64af0cdd0d8a0c9ccf1e22cd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6aec9ca2ae47baad15b60b38ec81d69d.svg
      fullname: Angelino Santiago
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MrDevolver
      type: user
    createdAt: '2023-07-12T20:34:53.000Z'
    data:
      edited: false
      editors:
      - MrDevolver
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.947767972946167
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6aec9ca2ae47baad15b60b38ec81d69d.svg
          fullname: Angelino Santiago
          isHf: false
          isPro: false
          name: MrDevolver
          type: user
        html: '<blockquote>

          <p>Any guesses what might be going on here?</p>

          </blockquote>

          <p>What do you mean? It''s a simple comparison of the outputs to the same
          prompt from two different AI models, one bigger than the other.</p>

          '
        raw: '> Any guesses what might be going on here?


          What do you mean? It''s a simple comparison of the outputs to the same prompt
          from two different AI models, one bigger than the other.'
        updatedAt: '2023-07-12T20:34:53.987Z'
      numEdits: 0
      reactions: []
    id: 64af0e6de90648db9ad1b5ab
    type: comment
  author: MrDevolver
  content: '> Any guesses what might be going on here?


    What do you mean? It''s a simple comparison of the outputs to the same prompt
    from two different AI models, one bigger than the other.'
  created_at: 2023-07-12 19:34:53+00:00
  edited: false
  hidden: false
  id: 64af0e6de90648db9ad1b5ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af9e3f8b157cbac14f49f2c20b1caaa4.svg
      fullname: Zachary Miller
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zjmiller
      type: user
    createdAt: '2023-07-12T20:43:17.000Z'
    data:
      edited: false
      editors:
      - zjmiller
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.988926887512207
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af9e3f8b157cbac14f49f2c20b1caaa4.svg
          fullname: Zachary Miller
          isHf: false
          isPro: false
          name: zjmiller
          type: user
        html: '<p>I just meant any guesses as to what explains the difference.</p>

          '
        raw: I just meant any guesses as to what explains the difference.
        updatedAt: '2023-07-12T20:43:17.167Z'
      numEdits: 0
      reactions: []
    id: 64af10658820c46f54f50e35
    type: comment
  author: zjmiller
  content: I just meant any guesses as to what explains the difference.
  created_at: 2023-07-12 19:43:17+00:00
  edited: false
  hidden: false
  id: 64af10658820c46f54f50e35
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6aec9ca2ae47baad15b60b38ec81d69d.svg
      fullname: Angelino Santiago
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MrDevolver
      type: user
    createdAt: '2023-07-12T21:00:21.000Z'
    data:
      edited: true
      editors:
      - MrDevolver
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9908467531204224
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6aec9ca2ae47baad15b60b38ec81d69d.svg
          fullname: Angelino Santiago
          isHf: false
          isPro: false
          name: MrDevolver
          type: user
        html: '<blockquote>

          <p>I just meant any guesses as to what explains the difference.</p>

          </blockquote>

          <p>Honestly, I have no idea. The output is usually random, and I believe
          that eventually if you tried long enough, the big model would produce a
          good answer, but it feels like the amount of really bad answers is pretty
          high all across the board, but try chatglm model for example and it will
          almost never be tricked by this question. I did a little test yesterday.
          I was interested in seeing which models would produce good enough answers
          and I scored them. I picked a few which seemed the best ones and then I
          tested them all against each other. It turns out there were a few which
          were good, but sadly most of them weren''t. I wasn''t really strict in my
          testing, I accepted even weird math answers if the result itself was good
          enough for my purpose which is story telling, but yeah when the model produced
          something like you see on the left or similar with the final age guess that''s
          obviously incorrect because it''s &lt; 43 (yeah that really happened and
          it happened more often than I would like to see), then I gave them even
          negative score. I wrapped up the results of my private test and I came to
          a conclusion that chatglm was the best, mpt model was the second, but that
          one produced some really whacky results sometimes that I would disqualify
          it just for that alone, if I wanted to be too strict lol. Then I tried something
          a little bit different. I made the same prompt, but I decided to rephrase
          it a little bit to make it so that the model didn''t have any other choice
          than answer it correctly and then all of the models answered it correctly
          when I made the correct answer super obvious in the prompt. So I concluded
          that some models have better common sense (if that''s applicable here at
          all) than others.</p>

          '
        raw: '> I just meant any guesses as to what explains the difference.


          Honestly, I have no idea. The output is usually random, and I believe that
          eventually if you tried long enough, the big model would produce a good
          answer, but it feels like the amount of really bad answers is pretty high
          all across the board, but try chatglm model for example and it will almost
          never be tricked by this question. I did a little test yesterday. I was
          interested in seeing which models would produce good enough answers and
          I scored them. I picked a few which seemed the best ones and then I tested
          them all against each other. It turns out there were a few which were good,
          but sadly most of them weren''t. I wasn''t really strict in my testing,
          I accepted even weird math answers if the result itself was good enough
          for my purpose which is story telling, but yeah when the model produced
          something like you see on the left or similar with the final age guess that''s
          obviously incorrect because it''s < 43 (yeah that really happened and it
          happened more often than I would like to see), then I gave them even negative
          score. I wrapped up the results of my private test and I came to a conclusion
          that chatglm was the best, mpt model was the second, but that one produced
          some really whacky results sometimes that I would disqualify it just for
          that alone, if I wanted to be too strict lol. Then I tried something a little
          bit different. I made the same prompt, but I decided to rephrase it a little
          bit to make it so that the model didn''t have any other choice than answer
          it correctly and then all of the models answered it correctly when I made
          the correct answer super obvious in the prompt. So I concluded that some
          models have better common sense (if that''s applicable here at all) than
          others.'
        updatedAt: '2023-07-12T21:03:30.550Z'
      numEdits: 1
      reactions: []
    id: 64af1465749f04f4f4d1f652
    type: comment
  author: MrDevolver
  content: '> I just meant any guesses as to what explains the difference.


    Honestly, I have no idea. The output is usually random, and I believe that eventually
    if you tried long enough, the big model would produce a good answer, but it feels
    like the amount of really bad answers is pretty high all across the board, but
    try chatglm model for example and it will almost never be tricked by this question.
    I did a little test yesterday. I was interested in seeing which models would produce
    good enough answers and I scored them. I picked a few which seemed the best ones
    and then I tested them all against each other. It turns out there were a few which
    were good, but sadly most of them weren''t. I wasn''t really strict in my testing,
    I accepted even weird math answers if the result itself was good enough for my
    purpose which is story telling, but yeah when the model produced something like
    you see on the left or similar with the final age guess that''s obviously incorrect
    because it''s < 43 (yeah that really happened and it happened more often than
    I would like to see), then I gave them even negative score. I wrapped up the results
    of my private test and I came to a conclusion that chatglm was the best, mpt model
    was the second, but that one produced some really whacky results sometimes that
    I would disqualify it just for that alone, if I wanted to be too strict lol. Then
    I tried something a little bit different. I made the same prompt, but I decided
    to rephrase it a little bit to make it so that the model didn''t have any other
    choice than answer it correctly and then all of the models answered it correctly
    when I made the correct answer super obvious in the prompt. So I concluded that
    some models have better common sense (if that''s applicable here at all) than
    others.'
  created_at: 2023-07-12 20:00:21+00:00
  edited: true
  hidden: false
  id: 64af1465749f04f4f4d1f652
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642e4fbda0b65dce1f875e90/o08Ni4hSRiqyoBy6MEg-a.jpeg?w=200&h=200&f=face
      fullname: practical-dreamer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: practical-dreamer
      type: user
    createdAt: '2023-07-29T08:02:07.000Z'
    data:
      edited: false
      editors:
      - practical-dreamer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9308962225914001
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642e4fbda0b65dce1f875e90/o08Ni4hSRiqyoBy6MEg-a.jpeg?w=200&h=200&f=face
          fullname: practical-dreamer
          isHf: false
          isPro: false
          name: practical-dreamer
          type: user
        html: '<p>sample size of one</p>

          '
        raw: sample size of one
        updatedAt: '2023-07-29T08:02:07.035Z'
      numEdits: 0
      reactions: []
    id: 64c4c77f88373ea62011747a
    type: comment
  author: practical-dreamer
  content: sample size of one
  created_at: 2023-07-29 07:02:07+00:00
  edited: false
  hidden: false
  id: 64c4c77f88373ea62011747a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: lmsys/vicuna-33b-v1.3
repo_type: model
status: open
target_branch: null
title: Bigger is NOT always better...
