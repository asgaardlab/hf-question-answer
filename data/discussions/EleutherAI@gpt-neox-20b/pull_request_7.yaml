!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hails
conflicting_files: []
created_at: 2022-12-15 13:53:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669665010552-62895a0215aeee85756062c4.jpeg?w=200&h=200&f=face
      fullname: Hailey Schoelkopf
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: hails
      type: user
    createdAt: '2022-12-15T13:53:42.000Z'
    data:
      edited: false
      editors:
      - hails
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669665010552-62895a0215aeee85756062c4.jpeg?w=200&h=200&f=face
          fullname: Hailey Schoelkopf
          isHf: false
          isPro: false
          name: hails
          type: user
        html: "<p>As far as I'm aware, and according to the GPT-NeoX-20b arXiv paper,\
          \ the model wasn't trained with dropout. Is there a reason there is dropout\
          \ in this config on both attention and hiddens? (is this because dropout\
          \ is recommended for finetuning or something?)</p>\n<p>cc <span data-props=\"\
          {&quot;user&quot;:&quot;stellaathena&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/stellaathena\">@<span class=\"underline\"\
          >stellaathena</span></a></span>\n\n\t</span></span></p>\n"
        raw: 'As far as I''m aware, and according to the GPT-NeoX-20b arXiv paper,
          the model wasn''t trained with dropout. Is there a reason there is dropout
          in this config on both attention and hiddens? (is this because dropout is
          recommended for finetuning or something?)


          cc @stellaathena'
        updatedAt: '2022-12-15T13:53:42.278Z'
      numEdits: 0
      reactions: []
    id: 639b26e652c247eee42e1757
    type: comment
  author: hails
  content: 'As far as I''m aware, and according to the GPT-NeoX-20b arXiv paper, the
    model wasn''t trained with dropout. Is there a reason there is dropout in this
    config on both attention and hiddens? (is this because dropout is recommended
    for finetuning or something?)


    cc @stellaathena'
  created_at: 2022-12-15 13:53:42+00:00
  edited: false
  hidden: false
  id: 639b26e652c247eee42e1757
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669665010552-62895a0215aeee85756062c4.jpeg?w=200&h=200&f=face
      fullname: Hailey Schoelkopf
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: hails
      type: user
    createdAt: '2022-12-15T13:53:42.000Z'
    data:
      oid: c68091b97892b4183a9b844bc325fbbb6ec3b1cd
      parents:
      - 3523781c8df75f7741687a4284f6f70e1afa12f4
      subject: Set dropout in config.json to be 0 ?
    id: 639b26e60000000000000000
    type: commit
  author: hails
  created_at: 2022-12-15 13:53:42+00:00
  id: 639b26e60000000000000000
  oid: c68091b97892b4183a9b844bc325fbbb6ec3b1cd
  summary: Set dropout in config.json to be 0 ?
  type: commit
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60347d3660e3dd96631c9093/B3fuZer5N04tZIAYrLnz4.jpeg?w=200&h=200&f=face
      fullname: Stella Biderman
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: stellaathena
      type: user
    createdAt: '2023-02-07T06:46:28.000Z'
    data:
      status: merged
    id: 63e1f3c4f3c955e23caa6dee
    type: status-change
  author: stellaathena
  created_at: 2023-02-07 06:46:28+00:00
  id: 63e1f3c4f3c955e23caa6dee
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 53bcd7ecbeca4df3c16899279c3636cf1905b569
num: 7
repo_id: EleutherAI/gpt-neox-20b
repo_type: model
status: merged
target_branch: refs/heads/main
title: Set dropout in config.json to be 0 ?
