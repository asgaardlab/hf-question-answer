!!python/object:huggingface_hub.community.DiscussionWithDetails
author: skrishna
conflicting_files: null
created_at: 2023-04-02 15:51:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6186fef1b1085ab638324e7f/BL6_WJCkxB-BatBUBilT8.jpeg?w=200&h=200&f=face
      fullname: Satya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: skrishna
      type: user
    createdAt: '2023-04-02T16:51:45.000Z'
    data:
      edited: false
      editors:
      - skrishna
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6186fef1b1085ab638324e7f/BL6_WJCkxB-BatBUBilT8.jpeg?w=200&h=200&f=face
          fullname: Satya
          isHf: false
          isPro: false
          name: skrishna
          type: user
        html: '<p>I get this 422 response error when I use hugging face inference
          engine for the model using the code below.</p>

          <p>API_URL = "<a rel="nofollow" href="https://api-inference.huggingface.co/models/EleutherAI/gpt-neox-20b">https://api-inference.huggingface.co/models/google/flan-t5-xxl</a>"<br>headers
          = {"Authorization": f"Bearer {API_TOKEN}"}<br>def query(payload):<br>    response
          = requests.post(API_URL, headers=headers, json=payload)<br>    return response.json()</p>

          <p>output = query({<br>    "inputs": "The answer to the universe is",<br>})</p>

          '
        raw: "I get this 422 response error when I use hugging face inference engine\
          \ for the model using the code below.\r\n\r\nAPI_URL = \"[https://api-inference.huggingface.co/models/google/flan-t5-xxl](https://api-inference.huggingface.co/models/EleutherAI/gpt-neox-20b)\"\
          \r\nheaders = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\r\ndef query(payload):\r\
          \n    response = requests.post(API_URL, headers=headers, json=payload)\r\
          \n    return response.json()\r\n    \r\noutput = query({\r\n    \"inputs\"\
          : \"The answer to the universe is\",\r\n})"
        updatedAt: '2023-04-02T16:51:45.115Z'
      numEdits: 0
      reactions: []
    id: 6429b2a14e073875f6a89513
    type: comment
  author: skrishna
  content: "I get this 422 response error when I use hugging face inference engine\
    \ for the model using the code below.\r\n\r\nAPI_URL = \"[https://api-inference.huggingface.co/models/google/flan-t5-xxl](https://api-inference.huggingface.co/models/EleutherAI/gpt-neox-20b)\"\
    \r\nheaders = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\r\ndef query(payload):\r\
    \n    response = requests.post(API_URL, headers=headers, json=payload)\r\n   \
    \ return response.json()\r\n    \r\noutput = query({\r\n    \"inputs\": \"The\
    \ answer to the universe is\",\r\n})"
  created_at: 2023-04-02 15:51:45+00:00
  edited: false
  hidden: false
  id: 6429b2a14e073875f6a89513
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: EleutherAI/gpt-neox-20b
repo_type: model
status: open
target_branch: null
title: <Response [422]>
