!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Hazarth
conflicting_files: null
created_at: 2023-04-12 06:59:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8e65976e001325e9e6af56827cfd3a11.svg
      fullname: Hazarth
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hazarth
      type: user
    createdAt: '2023-04-12T07:59:12.000Z'
    data:
      edited: false
      editors:
      - Hazarth
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8e65976e001325e9e6af56827cfd3a11.svg
          fullname: Hazarth
          isHf: false
          isPro: false
          name: Hazarth
          type: user
        html: "<p>I am unable to get this model running with latest oobabooga and\
          \ DeepSpeed. Without DeepSpeed it loads correctly. But with DeepSpeed enabled,\
          \ I get an error telling me, that the .safetensors file is missing it's\
          \ metadata.</p>\n<p>I'm running latest oobabooga with latests transformers\
          \ package on Ubuntu.<br>The specific error happens here in the transformers\
          \ package: /lib/python3.9/site-packages/transformers/modeling_utils.py on\
          \ line 432</p>\n<p>This is the relevant code bit:</p>\n<pre><code>if checkpoint_file.endswith(\"\
          .safetensors\") and is_safetensors_available():\n        # Check format\
          \ of the archive\n        with safe_open(checkpoint_file, framework=\"pt\"\
          ) as f:\n            metadata = f.metadata()\n        if metadata.get(\"\
          format\") not in [\"pt\", \"tf\", \"flax\"]:\n            raise OSError(\n\
          \                f\"The safetensors archive passed at {checkpoint_file}\
          \ does not contain the valid metadata. Make sure \"\n                \"\
          you save your model with the `save_pretrained` method.\"\n            )\n\
          \        elif metadata[\"format\"] != \"pt\":\n            raise NotImplementedError(\n\
          \                f\"Conversion from a {metadata['format']} safetensors archive\
          \ to PyTorch is not implemented yet.\"\n            )\n        return safe_load_file(checkpoint_file)\n\
          </code></pre>\n<p>I tried hacking the format in and managed to get pass\
          \ this point, but got a different error then which I think might be due\
          \ all the other metadata missing anyway.</p>\n<p>Apparently safetensors\
          \ can have a metadata header and the only supported format while using with\
          \ deepspeed would be PyTorch's \"pt\"</p>\n<p>I'm not yet sure, why this\
          \ is the path the code takes when it loads without issues without deepspeed.\
          \ Perhaps Oobabooga does some alternative conversions without it? Not sure.</p>\n\
          <p>However it might be useful for some, including me, if you also kept the\
          \ original .pt model that was deleted in this commit: <a href=\"https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g/commit/d904e5060f4b6273210f48e57601dc8933653162\"\
          >https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g/commit/d904e5060f4b6273210f48e57601dc8933653162</a></p>\n\
          <p>Maybe place it into a separate directory, so the root folder can still\
          \ serve as the default setup when using git clone?</p>\n"
        raw: "I am unable to get this model running with latest oobabooga and DeepSpeed.\
          \ Without DeepSpeed it loads correctly. But with DeepSpeed enabled, I get\
          \ an error telling me, that the .safetensors file is missing it's metadata.\r\
          \n\r\nI'm running latest oobabooga with latests transformers package on\
          \ Ubuntu.\r\nThe specific error happens here in the transformers package:\
          \ /lib/python3.9/site-packages/transformers/modeling_utils.py on line 432\r\
          \n\r\nThis is the relevant code bit:\r\n```\r\nif checkpoint_file.endswith(\"\
          .safetensors\") and is_safetensors_available():\r\n        # Check format\
          \ of the archive\r\n        with safe_open(checkpoint_file, framework=\"\
          pt\") as f:\r\n            metadata = f.metadata()\r\n        if metadata.get(\"\
          format\") not in [\"pt\", \"tf\", \"flax\"]:\r\n            raise OSError(\r\
          \n                f\"The safetensors archive passed at {checkpoint_file}\
          \ does not contain the valid metadata. Make sure \"\r\n                \"\
          you save your model with the `save_pretrained` method.\"\r\n           \
          \ )\r\n        elif metadata[\"format\"] != \"pt\":\r\n            raise\
          \ NotImplementedError(\r\n                f\"Conversion from a {metadata['format']}\
          \ safetensors archive to PyTorch is not implemented yet.\"\r\n         \
          \   )\r\n        return safe_load_file(checkpoint_file)\r\n```\r\n\r\nI\
          \ tried hacking the format in and managed to get pass this point, but got\
          \ a different error then which I think might be due all the other metadata\
          \ missing anyway.\r\n\r\nApparently safetensors can have a metadata header\
          \ and the only supported format while using with deepspeed would be PyTorch's\
          \ \"pt\"\r\n\r\nI'm not yet sure, why this is the path the code takes when\
          \ it loads without issues without deepspeed. Perhaps Oobabooga does some\
          \ alternative conversions without it? Not sure.\r\n\r\nHowever it might\
          \ be useful for some, including me, if you also kept the original .pt model\
          \ that was deleted in this commit: https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g/commit/d904e5060f4b6273210f48e57601dc8933653162\r\
          \n\r\nMaybe place it into a separate directory, so the root folder can still\
          \ serve as the default setup when using git clone?"
        updatedAt: '2023-04-12T07:59:12.830Z'
      numEdits: 0
      reactions: []
    id: 643664d0ad9b9147de289a77
    type: comment
  author: Hazarth
  content: "I am unable to get this model running with latest oobabooga and DeepSpeed.\
    \ Without DeepSpeed it loads correctly. But with DeepSpeed enabled, I get an error\
    \ telling me, that the .safetensors file is missing it's metadata.\r\n\r\nI'm\
    \ running latest oobabooga with latests transformers package on Ubuntu.\r\nThe\
    \ specific error happens here in the transformers package: /lib/python3.9/site-packages/transformers/modeling_utils.py\
    \ on line 432\r\n\r\nThis is the relevant code bit:\r\n```\r\nif checkpoint_file.endswith(\"\
    .safetensors\") and is_safetensors_available():\r\n        # Check format of the\
    \ archive\r\n        with safe_open(checkpoint_file, framework=\"pt\") as f:\r\
    \n            metadata = f.metadata()\r\n        if metadata.get(\"format\") not\
    \ in [\"pt\", \"tf\", \"flax\"]:\r\n            raise OSError(\r\n           \
    \     f\"The safetensors archive passed at {checkpoint_file} does not contain\
    \ the valid metadata. Make sure \"\r\n                \"you save your model with\
    \ the `save_pretrained` method.\"\r\n            )\r\n        elif metadata[\"\
    format\"] != \"pt\":\r\n            raise NotImplementedError(\r\n           \
    \     f\"Conversion from a {metadata['format']} safetensors archive to PyTorch\
    \ is not implemented yet.\"\r\n            )\r\n        return safe_load_file(checkpoint_file)\r\
    \n```\r\n\r\nI tried hacking the format in and managed to get pass this point,\
    \ but got a different error then which I think might be due all the other metadata\
    \ missing anyway.\r\n\r\nApparently safetensors can have a metadata header and\
    \ the only supported format while using with deepspeed would be PyTorch's \"pt\"\
    \r\n\r\nI'm not yet sure, why this is the path the code takes when it loads without\
    \ issues without deepspeed. Perhaps Oobabooga does some alternative conversions\
    \ without it? Not sure.\r\n\r\nHowever it might be useful for some, including\
    \ me, if you also kept the original .pt model that was deleted in this commit:\
    \ https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g/commit/d904e5060f4b6273210f48e57601dc8933653162\r\
    \n\r\nMaybe place it into a separate directory, so the root folder can still serve\
    \ as the default setup when using git clone?"
  created_at: 2023-04-12 06:59:12+00:00
  edited: false
  hidden: false
  id: 643664d0ad9b9147de289a77
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 27
repo_id: anon8231489123/vicuna-13b-GPTQ-4bit-128g
repo_type: model
status: open
target_branch: null
title: Failure to load using DeepSpeed
