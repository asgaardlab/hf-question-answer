!!python/object:huggingface_hub.community.DiscussionWithDetails
author: william0014
conflicting_files: null
created_at: 2023-05-04 10:07:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b2d465d8d4c1338660591f262b199e29.svg
      fullname: wang weimin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: william0014
      type: user
    createdAt: '2023-05-04T11:07:25.000Z'
    data:
      edited: false
      editors:
      - william0014
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b2d465d8d4c1338660591f262b199e29.svg
          fullname: wang weimin
          isHf: false
          isPro: false
          name: william0014
          type: user
        html: '<p> I have installed the FastChat .<br>then I use "python -m fastchat.serve.cli
          --model anon8231489123/vicuna-13b-GPTQ-4bit-128g".  I got the error: Could
          not locate pytorch_model-00001-of-00003.bin inside anon8231489123/vicuna-13b-GPTQ-4bit-128g</p>

          '
        raw: " I have installed the FastChat .\r\nthen I use \"python -m fastchat.serve.cli\
          \ --model anon8231489123/vicuna-13b-GPTQ-4bit-128g\".  I got the error:\
          \ Could not locate pytorch_model-00001-of-00003.bin inside anon8231489123/vicuna-13b-GPTQ-4bit-128g\r\
          \n"
        updatedAt: '2023-05-04T11:07:25.241Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - elcolie
    id: 645391ed9364b1f9438b707a
    type: comment
  author: william0014
  content: " I have installed the FastChat .\r\nthen I use \"python -m fastchat.serve.cli\
    \ --model anon8231489123/vicuna-13b-GPTQ-4bit-128g\".  I got the error: Could\
    \ not locate pytorch_model-00001-of-00003.bin inside anon8231489123/vicuna-13b-GPTQ-4bit-128g\r\
    \n"
  created_at: 2023-05-04 10:07:25+00:00
  edited: false
  hidden: false
  id: 645391ed9364b1f9438b707a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d7e33e2bcac3628d8a926871e03842bc.svg
      fullname: ZXTFINAL
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ZXTFINAL
      type: user
    createdAt: '2023-05-06T08:59:21.000Z'
    data:
      edited: false
      editors:
      - ZXTFINAL
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d7e33e2bcac3628d8a926871e03842bc.svg
          fullname: ZXTFINAL
          isHf: false
          isPro: false
          name: ZXTFINAL
          type: user
        html: '<p>it seems like your FastChat try to load a original model,however,this
          model is 4bit-128g.I think you should check the input params if there''s
          a param like 4-bit</p>

          '
        raw: it seems like your FastChat try to load a original model,however,this
          model is 4bit-128g.I think you should check the input params if there's
          a param like 4-bit
        updatedAt: '2023-05-06T08:59:21.400Z'
      numEdits: 0
      reactions: []
    id: 645616e9d10badc955566dc0
    type: comment
  author: ZXTFINAL
  content: it seems like your FastChat try to load a original model,however,this model
    is 4bit-128g.I think you should check the input params if there's a param like
    4-bit
  created_at: 2023-05-06 07:59:21+00:00
  edited: false
  hidden: false
  id: 645616e9d10badc955566dc0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1633658078552-615fa3293f6d24d67c1b5c82.jpeg?w=200&h=200&f=face
      fullname: George1202
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Dorjzodovsuren
      type: user
    createdAt: '2023-05-07T10:41:27.000Z'
    data:
      edited: false
      editors:
      - Dorjzodovsuren
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1633658078552-615fa3293f6d24d67c1b5c82.jpeg?w=200&h=200&f=face
          fullname: George1202
          isHf: false
          isPro: false
          name: Dorjzodovsuren
          type: user
        html: '<p>Try this<br>python -m fastchat.serve.cli --model-name anon8231489123/vicuna-13b-GPTQ-4bit-128g
          --wbits 4 --groupsize 128</p>

          '
        raw: "Try this \npython -m fastchat.serve.cli --model-name anon8231489123/vicuna-13b-GPTQ-4bit-128g\
          \ --wbits 4 --groupsize 128"
        updatedAt: '2023-05-07T10:41:27.235Z'
      numEdits: 0
      reactions: []
    id: 64578057cf099a9dd14be500
    type: comment
  author: Dorjzodovsuren
  content: "Try this \npython -m fastchat.serve.cli --model-name anon8231489123/vicuna-13b-GPTQ-4bit-128g\
    \ --wbits 4 --groupsize 128"
  created_at: 2023-05-07 09:41:27+00:00
  edited: false
  hidden: false
  id: 64578057cf099a9dd14be500
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 45
repo_id: anon8231489123/vicuna-13b-GPTQ-4bit-128g
repo_type: model
status: open
target_branch: null
title: how to use this model
