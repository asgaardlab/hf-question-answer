!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Maximiliano228
conflicting_files: null
created_at: 2023-04-13 18:52:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5981b71ae66dbd8e8107534d468655a7.svg
      fullname: Kaks
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Maximiliano228
      type: user
    createdAt: '2023-04-13T19:52:37.000Z'
    data:
      edited: false
      editors:
      - Maximiliano228
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5981b71ae66dbd8e8107534d468655a7.svg
          fullname: Kaks
          isHf: false
          isPro: false
          name: Maximiliano228
          type: user
        html: '<p>How can I solve this problem?</p>

          <p>Starting the web UI...<br>Loading the extension "gallery"... Ok.<br>Running
          on local URL:  <a rel="nofollow" href="http://127.0.0.1:7860">http://127.0.0.1:7860</a></p>

          <p>To create a public link, set <code>share=True</code> in <code>launch()</code>.<br>No
          model is loaded! Select one in the Model tab.<br>No model is loaded! Select
          one in the Model tab.<br>Loading vicuna-13b-GPTQ-4bit-128g...<br>Found the
          following quantized model: models\vicuna-13b-GPTQ-4bit-128g\vicuna-13b-4bit-128g.safetensors<br>Traceback
          (most recent call last):<br>  File "D:\AI\oobabooga-windows\installer_files\env\lib\site-packages\gradio\routes.py",
          line 393, in run_predict<br>    output = await app.get_blocks().process_api(<br>  File
          "D:\AI\oobabooga-windows\installer_files\env\lib\site-packages\gradio\blocks.py",
          line 1108, in process_api<br>    result = await self.call_function(<br>  File
          "D:\AI\oobabooga-windows\installer_files\env\lib\site-packages\gradio\blocks.py",
          line 929, in call_function<br>    prediction = await anyio.to_thread.run_sync(<br>  File
          "D:\AI\oobabooga-windows\installer_files\env\lib\site-packages\anyio\to_thread.py",
          line 31, in run_sync<br>    return await get_asynclib().run_sync_in_worker_thread(<br>  File
          "D:\AI\oobabooga-windows\installer_files\env\lib\site-packages\anyio_backends_asyncio.py",
          line 937, in run_sync_in_worker_thread<br>    return await future<br>  File
          "D:\AI\oobabooga-windows\installer_files\env\lib\site-packages\anyio_backends_asyncio.py",
          line 867, in run<br>    result = context.run(func, *args)<br>  File "D:\AI\oobabooga-windows\installer_files\env\lib\site-packages\gradio\utils.py",
          line 490, in async_iteration<br>    return next(iterator)<br>  File "D:\AI\oobabooga-windows\text-generation-webui\modules\chat.py",
          line 228, in cai_chatbot_wrapper<br>    for history in chatbot_wrapper(text,
          state):<br>  File "D:\AI\oobabooga-windows\text-generation-webui\modules\chat.py",
          line 149, in chatbot_wrapper<br>    prompt = generate_chat_prompt(text,
          state, **kwargs)<br>  File "D:\AI\oobabooga-windows\text-generation-webui\modules\chat.py",
          line 42, in generate_chat_prompt<br>    while i &gt;= 0 and len(encode(''''.join(rows))[0])
          &lt; max_length:<br>  File "D:\AI\oobabooga-windows\text-generation-webui\modules\text_generation.py",
          line 31, in encode<br>    input_ids = shared.tokenizer.encode(str(prompt),
          return_tensors=''pt'', add_special_tokens=add_special_tokens)<br>AttributeError:
          ''NoneType'' object has no attribute ''encode''</p>

          '
        raw: "How can I solve this problem?\r\n\r\n\r\nStarting the web UI...\r\n\
          Loading the extension \"gallery\"... Ok.\r\nRunning on local URL:  http://127.0.0.1:7860\r\
          \n\r\nTo create a public link, set `share=True` in `launch()`.\r\nNo model\
          \ is loaded! Select one in the Model tab.\r\nNo model is loaded! Select\
          \ one in the Model tab.\r\nLoading vicuna-13b-GPTQ-4bit-128g...\r\nFound\
          \ the following quantized model: models\\vicuna-13b-GPTQ-4bit-128g\\vicuna-13b-4bit-128g.safetensors\r\
          \nTraceback (most recent call last):\r\n  File \"D:\\AI\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\gradio\\routes.py\", line 393,\
          \ in run_predict\r\n    output = await app.get_blocks().process_api(\r\n\
          \  File \"D:\\AI\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          gradio\\blocks.py\", line 1108, in process_api\r\n    result = await self.call_function(\r\
          \n  File \"D:\\AI\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          gradio\\blocks.py\", line 929, in call_function\r\n    prediction = await\
          \ anyio.to_thread.run_sync(\r\n  File \"D:\\AI\\oobabooga-windows\\installer_files\\\
          env\\lib\\site-packages\\anyio\\to_thread.py\", line 31, in run_sync\r\n\
          \    return await get_asynclib().run_sync_in_worker_thread(\r\n  File \"\
          D:\\AI\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\anyio\\\
          _backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\r\n   \
          \ return await future\r\n  File \"D:\\AI\\oobabooga-windows\\installer_files\\\
          env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\r\
          \n    result = context.run(func, *args)\r\n  File \"D:\\AI\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\gradio\\utils.py\", line 490,\
          \ in async_iteration\r\n    return next(iterator)\r\n  File \"D:\\AI\\oobabooga-windows\\\
          text-generation-webui\\modules\\chat.py\", line 228, in cai_chatbot_wrapper\r\
          \n    for history in chatbot_wrapper(text, state):\r\n  File \"D:\\AI\\\
          oobabooga-windows\\text-generation-webui\\modules\\chat.py\", line 149,\
          \ in chatbot_wrapper\r\n    prompt = generate_chat_prompt(text, state, **kwargs)\r\
          \n  File \"D:\\AI\\oobabooga-windows\\text-generation-webui\\modules\\chat.py\"\
          , line 42, in generate_chat_prompt\r\n    while i >= 0 and len(encode(''.join(rows))[0])\
          \ < max_length:\r\n  File \"D:\\AI\\oobabooga-windows\\text-generation-webui\\\
          modules\\text_generation.py\", line 31, in encode\r\n    input_ids = shared.tokenizer.encode(str(prompt),\
          \ return_tensors='pt', add_special_tokens=add_special_tokens)\r\nAttributeError:\
          \ 'NoneType' object has no attribute 'encode'"
        updatedAt: '2023-04-13T19:52:37.360Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - camaudio
        - Holipoli
    id: 64385d8543d932c4623d0172
    type: comment
  author: Maximiliano228
  content: "How can I solve this problem?\r\n\r\n\r\nStarting the web UI...\r\nLoading\
    \ the extension \"gallery\"... Ok.\r\nRunning on local URL:  http://127.0.0.1:7860\r\
    \n\r\nTo create a public link, set `share=True` in `launch()`.\r\nNo model is\
    \ loaded! Select one in the Model tab.\r\nNo model is loaded! Select one in the\
    \ Model tab.\r\nLoading vicuna-13b-GPTQ-4bit-128g...\r\nFound the following quantized\
    \ model: models\\vicuna-13b-GPTQ-4bit-128g\\vicuna-13b-4bit-128g.safetensors\r\
    \nTraceback (most recent call last):\r\n  File \"D:\\AI\\oobabooga-windows\\installer_files\\\
    env\\lib\\site-packages\\gradio\\routes.py\", line 393, in run_predict\r\n   \
    \ output = await app.get_blocks().process_api(\r\n  File \"D:\\AI\\oobabooga-windows\\\
    installer_files\\env\\lib\\site-packages\\gradio\\blocks.py\", line 1108, in process_api\r\
    \n    result = await self.call_function(\r\n  File \"D:\\AI\\oobabooga-windows\\\
    installer_files\\env\\lib\\site-packages\\gradio\\blocks.py\", line 929, in call_function\r\
    \n    prediction = await anyio.to_thread.run_sync(\r\n  File \"D:\\AI\\oobabooga-windows\\\
    installer_files\\env\\lib\\site-packages\\anyio\\to_thread.py\", line 31, in run_sync\r\
    \n    return await get_asynclib().run_sync_in_worker_thread(\r\n  File \"D:\\\
    AI\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\anyio\\_backends\\\
    _asyncio.py\", line 937, in run_sync_in_worker_thread\r\n    return await future\r\
    \n  File \"D:\\AI\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    anyio\\_backends\\_asyncio.py\", line 867, in run\r\n    result = context.run(func,\
    \ *args)\r\n  File \"D:\\AI\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    gradio\\utils.py\", line 490, in async_iteration\r\n    return next(iterator)\r\
    \n  File \"D:\\AI\\oobabooga-windows\\text-generation-webui\\modules\\chat.py\"\
    , line 228, in cai_chatbot_wrapper\r\n    for history in chatbot_wrapper(text,\
    \ state):\r\n  File \"D:\\AI\\oobabooga-windows\\text-generation-webui\\modules\\\
    chat.py\", line 149, in chatbot_wrapper\r\n    prompt = generate_chat_prompt(text,\
    \ state, **kwargs)\r\n  File \"D:\\AI\\oobabooga-windows\\text-generation-webui\\\
    modules\\chat.py\", line 42, in generate_chat_prompt\r\n    while i >= 0 and len(encode(''.join(rows))[0])\
    \ < max_length:\r\n  File \"D:\\AI\\oobabooga-windows\\text-generation-webui\\\
    modules\\text_generation.py\", line 31, in encode\r\n    input_ids = shared.tokenizer.encode(str(prompt),\
    \ return_tensors='pt', add_special_tokens=add_special_tokens)\r\nAttributeError:\
    \ 'NoneType' object has no attribute 'encode'"
  created_at: 2023-04-13 18:52:37+00:00
  edited: false
  hidden: false
  id: 64385d8543d932c4623d0172
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c0442d1c2b32f819eb209fb535ffe0ce.svg
      fullname: Turtle indeed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Turtleindeed
      type: user
    createdAt: '2023-04-14T20:05:01.000Z'
    data:
      edited: false
      editors:
      - Turtleindeed
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c0442d1c2b32f819eb209fb535ffe0ce.svg
          fullname: Turtle indeed
          isHf: false
          isPro: false
          name: Turtleindeed
          type: user
        html: '<p>You need to copy the <a rel="nofollow" href="http://127.0.0.1:7860">http://127.0.0.1:7860</a>
          or hold ctrl and click on it and you will be redirected to youre chat</p>

          '
        raw: You need to copy the http://127.0.0.1:7860 or hold ctrl and click on
          it and you will be redirected to youre chat
        updatedAt: '2023-04-14T20:05:01.558Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F92F"
        users:
        - Holipoli
    id: 6439b1edcc228b8099b4807e
    type: comment
  author: Turtleindeed
  content: You need to copy the http://127.0.0.1:7860 or hold ctrl and click on it
    and you will be redirected to youre chat
  created_at: 2023-04-14 19:05:01+00:00
  edited: false
  hidden: false
  id: 6439b1edcc228b8099b4807e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9f0c1296db61a39b247bbdd76d1a6930.svg
      fullname: lolloso
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lol6969
      type: user
    createdAt: '2023-04-15T20:24:04.000Z'
    data:
      edited: false
      editors:
      - lol6969
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9f0c1296db61a39b247bbdd76d1a6930.svg
          fullname: lolloso
          isHf: false
          isPro: false
          name: lol6969
          type: user
        html: '<p>How can I solve this problem?</p>

          <p>Starting the web UI...<br>Loading the extension "gallery"... Ok.<br>Running
          on local URL: <a rel="nofollow" href="http://127.0.0.1:7860">http://127.0.0.1:7860</a></p>

          <p>To create a public link, set share=True in launch().<br>No model is loaded!
          Select one in the Model tab.<br>No model is loaded! Select one in the Model
          tab.</p>

          <p>i have all the files but i cant choose the model. Why?<br>thx all for
          assistence</p>

          '
        raw: 'How can I solve this problem?


          Starting the web UI...

          Loading the extension "gallery"... Ok.

          Running on local URL: http://127.0.0.1:7860


          To create a public link, set share=True in launch().

          No model is loaded! Select one in the Model tab.

          No model is loaded! Select one in the Model tab.


          i have all the files but i cant choose the model. Why?

          thx all for assistence'
        updatedAt: '2023-04-15T20:24:04.598Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Holipoli
    id: 643b07e49f4e4abaf853ac76
    type: comment
  author: lol6969
  content: 'How can I solve this problem?


    Starting the web UI...

    Loading the extension "gallery"... Ok.

    Running on local URL: http://127.0.0.1:7860


    To create a public link, set share=True in launch().

    No model is loaded! Select one in the Model tab.

    No model is loaded! Select one in the Model tab.


    i have all the files but i cant choose the model. Why?

    thx all for assistence'
  created_at: 2023-04-15 19:24:04+00:00
  edited: false
  hidden: false
  id: 643b07e49f4e4abaf853ac76
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3fd33ee988ec28e15b8f40f470f4a1d2.svg
      fullname: NIGGER
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Holipoli
      type: user
    createdAt: '2023-04-15T20:29:35.000Z'
    data:
      edited: true
      editors:
      - Holipoli
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3fd33ee988ec28e15b8f40f470f4a1d2.svg
          fullname: NIGGER
          isHf: false
          isPro: false
          name: Holipoli
          type: user
        html: '<p>lol6969 the same error, what not only tried. Still displays the
          same thing, if you know how to fix it write.</p>

          <p>Starting the web UI...<br>Loading the extension "gallery"... Ok.<br>Running
          on local URL:  <a rel="nofollow" href="http://127.0.0.1:7860">http://127.0.0.1:7860</a></p>

          <p>To create a public link, set <code>share=True</code> in <code>launch()</code>.</p>

          <p>All that pops up. Installed two models, and I''m not even given a choice...(</p>

          '
        raw: 'lol6969 the same error, what not only tried. Still displays the same
          thing, if you know how to fix it write.


          Starting the web UI...

          Loading the extension "gallery"... Ok.

          Running on local URL:  http://127.0.0.1:7860


          To create a public link, set `share=True` in `launch()`.


          All that pops up. Installed two models, and I''m not even given a choice...('
        updatedAt: '2023-04-15T20:31:01.583Z'
      numEdits: 1
      reactions: []
    id: 643b092fe756b67eee1f3dbb
    type: comment
  author: Holipoli
  content: 'lol6969 the same error, what not only tried. Still displays the same thing,
    if you know how to fix it write.


    Starting the web UI...

    Loading the extension "gallery"... Ok.

    Running on local URL:  http://127.0.0.1:7860


    To create a public link, set `share=True` in `launch()`.


    All that pops up. Installed two models, and I''m not even given a choice...('
  created_at: 2023-04-15 19:29:35+00:00
  edited: true
  hidden: false
  id: 643b092fe756b67eee1f3dbb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9f0c1296db61a39b247bbdd76d1a6930.svg
      fullname: lolloso
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lol6969
      type: user
    createdAt: '2023-04-15T20:36:56.000Z'
    data:
      edited: false
      editors:
      - lol6969
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9f0c1296db61a39b247bbdd76d1a6930.svg
          fullname: lolloso
          isHf: false
          isPro: false
          name: lol6969
          type: user
        html: '<p>yes if i find a solutions ill write. You too pls... bye</p>

          '
        raw: yes if i find a solutions ill write. You too pls... bye
        updatedAt: '2023-04-15T20:36:56.130Z'
      numEdits: 0
      reactions: []
    id: 643b0ae8f6ef50c310d8fc0c
    type: comment
  author: lol6969
  content: yes if i find a solutions ill write. You too pls... bye
  created_at: 2023-04-15 19:36:56+00:00
  edited: false
  hidden: false
  id: 643b0ae8f6ef50c310d8fc0c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/918749461b81fb3ba27e3530a5df33db.svg
      fullname: Zaxk PP
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ZaxkPP
      type: user
    createdAt: '2023-04-17T05:08:18.000Z'
    data:
      edited: false
      editors:
      - ZaxkPP
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/918749461b81fb3ba27e3530a5df33db.svg
          fullname: Zaxk PP
          isHf: false
          isPro: false
          name: ZaxkPP
          type: user
        html: '<p>Same issue!</p>

          <p>(D:\software\GPT\oobabooga-windows\installer_files\env) D:\software\GPT\oobabooga-windows&gt;start-webui.bat<br>Starting
          the web UI...<br>Loading the extension "gallery"... Ok.<br>Running on local
          URL:  <a rel="nofollow" href="http://127.0.0.1:7860">http://127.0.0.1:7860</a></p>

          <p>To create a public link, set <code>share=True</code> in <code>launch()</code>.<br>Loading
          vicuna-13b-GPTQ-4bit-128g...<br>Loading vicuna-13b-GPTQ-4bit-128g...<br>Traceback
          (most recent call last):<br>  File "D:\software\GPT\oobabooga-windows\installer_files\env\lib\site-packages\gradio\routes.py",
          line 393, in run_predict<br>    output = await app.get_blocks().process_api(<br>  File
          "D:\software\GPT\oobabooga-windows\installer_files\env\lib\site-packages\gradio\blocks.py",
          line 1108, in process_api<br>    result = await self.call_function(<br>  File
          "D:\software\GPT\oobabooga-windows\installer_files\env\lib\site-packages\gradio\blocks.py",
          line 929, in call_function<br>    prediction = await anyio.to_thread.run_sync(<br>  File
          "D:\software\GPT\oobabooga-windows\installer_files\env\lib\site-packages\anyio\to_thread.py",
          line 31, in run_sync<br>    return await get_asynclib().run_sync_in_worker_thread(<br>  File
          "D:\software\GPT\oobabooga-windows\installer_files\env\lib\site-packages\anyio_backends_asyncio.py",
          line 937, in run_sync_in_worker_thread<br>    return await future<br>  File
          "D:\software\GPT\oobabooga-windows\installer_files\env\lib\site-packages\anyio_backends_asyncio.py",
          line 867, in run<br>    result = context.run(func, *args)<br>  File "D:\software\GPT\oobabooga-windows\installer_files\env\lib\site-packages\gradio\utils.py",
          line 490, in async_iteration<br>    return next(iterator)<br>  File "D:\software\GPT\oobabooga-windows\text-generation-webui\modules\chat.py",
          line 228, in cai_chatbot_wrapper<br>    for history in chatbot_wrapper(text,
          state):<br>  File "D:\software\GPT\oobabooga-windows\text-generation-webui\modules\chat.py",
          line 160, in chatbot_wrapper<br>    for reply in generate_reply(f"{prompt}{''
          '' if len(cumulative_reply) &gt; 0 else ''''}{cumulative_reply}", state,
          eos_token=eos_token, stopping_strings=stopping_strings):<br>  File "D:\software\GPT\oobabooga-windows\text-generation-webui\modules\text_generation.py",
          line 181, in generate_reply<br>    input_ids = encode(question, add_bos_token=state[''add_bos_token''],
          truncation_length=get_max_prompt_length(state))<br>  File "D:\software\GPT\oobabooga-windows\text-generation-webui\modules\text_generation.py",
          line 31, in encode<br>    input_ids = shared.tokenizer.encode(str(prompt),
          return_tensors=''pt'', add_special_tokens=add_special_tokens)<br>AttributeError:
          ''NoneType'' object has no attribute ''encode''</p>

          '
        raw: "Same issue!\n\n(D:\\software\\GPT\\oobabooga-windows\\installer_files\\\
          env) D:\\software\\GPT\\oobabooga-windows>start-webui.bat\nStarting the\
          \ web UI...\nLoading the extension \"gallery\"... Ok.\nRunning on local\
          \ URL:  http://127.0.0.1:7860\n\nTo create a public link, set `share=True`\
          \ in `launch()`.\nLoading vicuna-13b-GPTQ-4bit-128g...\nLoading vicuna-13b-GPTQ-4bit-128g...\n\
          Traceback (most recent call last):\n  File \"D:\\software\\GPT\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\gradio\\routes.py\", line 393,\
          \ in run_predict\n    output = await app.get_blocks().process_api(\n  File\
          \ \"D:\\software\\GPT\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          gradio\\blocks.py\", line 1108, in process_api\n    result = await self.call_function(\n\
          \  File \"D:\\software\\GPT\\oobabooga-windows\\installer_files\\env\\lib\\\
          site-packages\\gradio\\blocks.py\", line 929, in call_function\n    prediction\
          \ = await anyio.to_thread.run_sync(\n  File \"D:\\software\\GPT\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\anyio\\to_thread.py\", line 31,\
          \ in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n\
          \  File \"D:\\software\\GPT\\oobabooga-windows\\installer_files\\env\\lib\\\
          site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n\
          \    return await future\n  File \"D:\\software\\GPT\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\"\
          , line 867, in run\n    result = context.run(func, *args)\n  File \"D:\\\
          software\\GPT\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          gradio\\utils.py\", line 490, in async_iteration\n    return next(iterator)\n\
          \  File \"D:\\software\\GPT\\oobabooga-windows\\text-generation-webui\\\
          modules\\chat.py\", line 228, in cai_chatbot_wrapper\n    for history in\
          \ chatbot_wrapper(text, state):\n  File \"D:\\software\\GPT\\oobabooga-windows\\\
          text-generation-webui\\modules\\chat.py\", line 160, in chatbot_wrapper\n\
          \    for reply in generate_reply(f\"{prompt}{' ' if len(cumulative_reply)\
          \ > 0 else ''}{cumulative_reply}\", state, eos_token=eos_token, stopping_strings=stopping_strings):\n\
          \  File \"D:\\software\\GPT\\oobabooga-windows\\text-generation-webui\\\
          modules\\text_generation.py\", line 181, in generate_reply\n    input_ids\
          \ = encode(question, add_bos_token=state['add_bos_token'], truncation_length=get_max_prompt_length(state))\n\
          \  File \"D:\\software\\GPT\\oobabooga-windows\\text-generation-webui\\\
          modules\\text_generation.py\", line 31, in encode\n    input_ids = shared.tokenizer.encode(str(prompt),\
          \ return_tensors='pt', add_special_tokens=add_special_tokens)\nAttributeError:\
          \ 'NoneType' object has no attribute 'encode'"
        updatedAt: '2023-04-17T05:08:18.556Z'
      numEdits: 0
      reactions: []
    id: 643cd442c16819aac1385462
    type: comment
  author: ZaxkPP
  content: "Same issue!\n\n(D:\\software\\GPT\\oobabooga-windows\\installer_files\\\
    env) D:\\software\\GPT\\oobabooga-windows>start-webui.bat\nStarting the web UI...\n\
    Loading the extension \"gallery\"... Ok.\nRunning on local URL:  http://127.0.0.1:7860\n\
    \nTo create a public link, set `share=True` in `launch()`.\nLoading vicuna-13b-GPTQ-4bit-128g...\n\
    Loading vicuna-13b-GPTQ-4bit-128g...\nTraceback (most recent call last):\n  File\
    \ \"D:\\software\\GPT\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    gradio\\routes.py\", line 393, in run_predict\n    output = await app.get_blocks().process_api(\n\
    \  File \"D:\\software\\GPT\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    gradio\\blocks.py\", line 1108, in process_api\n    result = await self.call_function(\n\
    \  File \"D:\\software\\GPT\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    gradio\\blocks.py\", line 929, in call_function\n    prediction = await anyio.to_thread.run_sync(\n\
    \  File \"D:\\software\\GPT\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    anyio\\to_thread.py\", line 31, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n\
    \  File \"D:\\software\\GPT\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n    return\
    \ await future\n  File \"D:\\software\\GPT\\oobabooga-windows\\installer_files\\\
    env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n \
    \   result = context.run(func, *args)\n  File \"D:\\software\\GPT\\oobabooga-windows\\\
    installer_files\\env\\lib\\site-packages\\gradio\\utils.py\", line 490, in async_iteration\n\
    \    return next(iterator)\n  File \"D:\\software\\GPT\\oobabooga-windows\\text-generation-webui\\\
    modules\\chat.py\", line 228, in cai_chatbot_wrapper\n    for history in chatbot_wrapper(text,\
    \ state):\n  File \"D:\\software\\GPT\\oobabooga-windows\\text-generation-webui\\\
    modules\\chat.py\", line 160, in chatbot_wrapper\n    for reply in generate_reply(f\"\
    {prompt}{' ' if len(cumulative_reply) > 0 else ''}{cumulative_reply}\", state,\
    \ eos_token=eos_token, stopping_strings=stopping_strings):\n  File \"D:\\software\\\
    GPT\\oobabooga-windows\\text-generation-webui\\modules\\text_generation.py\",\
    \ line 181, in generate_reply\n    input_ids = encode(question, add_bos_token=state['add_bos_token'],\
    \ truncation_length=get_max_prompt_length(state))\n  File \"D:\\software\\GPT\\\
    oobabooga-windows\\text-generation-webui\\modules\\text_generation.py\", line\
    \ 31, in encode\n    input_ids = shared.tokenizer.encode(str(prompt), return_tensors='pt',\
    \ add_special_tokens=add_special_tokens)\nAttributeError: 'NoneType' object has\
    \ no attribute 'encode'"
  created_at: 2023-04-17 04:08:18+00:00
  edited: false
  hidden: false
  id: 643cd442c16819aac1385462
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 32
repo_id: anon8231489123/vicuna-13b-GPTQ-4bit-128g
repo_type: model
status: open
target_branch: null
title: Problem with start-webui start-up. Help please
