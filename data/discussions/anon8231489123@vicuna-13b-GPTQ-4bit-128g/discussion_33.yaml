!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Alphafi
conflicting_files: null
created_at: 2023-04-14 09:17:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f4eb05c34e30d3e57f64804436f02672.svg
      fullname: Jynel Gelilang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Alphafi
      type: user
    createdAt: '2023-04-14T10:17:34.000Z'
    data:
      edited: false
      editors:
      - Alphafi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f4eb05c34e30d3e57f64804436f02672.svg
          fullname: Jynel Gelilang
          isHf: false
          isPro: false
          name: Alphafi
          type: user
        html: '<p>Loading vicuna-13b-GPTQ-4bit-128g...<br>Found the following quantized
          model: models\vicuna-13b-GPTQ-4bit-128g\vicuna-13b-4bit-128g.safetensors<br>Loading
          model ...<br>Done.<br>Traceback (most recent call last):<br>  File "C:\AI\Text\oobabooga-windows\installer_files\env\lib\site-packages\gradio\routes.py",
          line 393, in run_predict<br>    output = await app.get_blocks().process_api(<br>  File
          "C:\AI\Text\oobabooga-windows\installer_files\env\lib\site-packages\gradio\blocks.py",
          line 1108, in process_api<br>    result = await self.call_function(<br>  File
          "C:\AI\Text\oobabooga-windows\installer_files\env\lib\site-packages\gradio\blocks.py",
          line 929, in call_function    prediction = await anyio.to_thread.run_sync(<br>  File
          "C:\AI\Text\oobabooga-windows\installer_files\env\lib\site-packages\anyio\to_thread.py",
          line 31, in run_sync<br>    return await get_asynclib().run_sync_in_worker_thread(<br>  File
          "C:\AI\Text\oobabooga-windows\installer_files\env\lib\site-packages\anyio_backends_asyncio.py",
          line 937, in run_sync_in_worker_thread<br>    return await future<br>  File
          "C:\AI\Text\oobabooga-windows\installer_files\env\lib\site-packages\anyio_backends_asyncio.py",
          line 867, in run<br>    result = context.run(func, *args)<br>  File "C:\AI\Text\oobabooga-windows\installer_files\env\lib\site-packages\gradio\utils.py",
          line 490, in async_iteration<br>    return next(iterator)<br>  File "C:\AI\Text\oobabooga-windows\text-generation-webui\modules\chat.py",
          line 228, in cai_chatbot_wrapper<br>    for history in chatbot_wrapper(text,
          state):<br>  File "C:\AI\Text\oobabooga-windows\text-generation-webui\modules\chat.py",
          line 160, in chatbot_wrapper<br>    for reply in generate_reply(f"{prompt}{''
          '' if len(cumulative_reply) &gt; 0 else ''''}{cumulative_reply}", state,
          eos_token=eos_token, stopping_strings=stopping_strings):<br>  File "C:\AI\Text\oobabooga-windows\text-generation-webui\modules\text_generation.py",
          line 181, in generate_reply<br>    input_ids = encode(question, add_bos_token=state[''add_bos_token''],
          truncation_length=get_max_prompt_length(state))<br>  File "C:\AI\Text\oobabooga-windows\text-generation-webui\modules\text_generation.py",
          line 31, in encode<br>    input_ids = shared.tokenizer.encode(str(prompt),
          return_tensors=''pt'', add_special_tokens=add_special_tokens)<br>AttributeError:
          ''NoneType'' object has no attribute ''encode''</p>

          '
        raw: "Loading vicuna-13b-GPTQ-4bit-128g...\r\nFound the following quantized\
          \ model: models\\vicuna-13b-GPTQ-4bit-128g\\vicuna-13b-4bit-128g.safetensors\r\
          \nLoading model ...\r\nDone.\r\nTraceback (most recent call last):\r\n \
          \ File \"C:\\AI\\Text\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          gradio\\routes.py\", line 393, in run_predict\r\n    output = await app.get_blocks().process_api(\r\
          \n  File \"C:\\AI\\Text\\oobabooga-windows\\installer_files\\env\\lib\\\
          site-packages\\gradio\\blocks.py\", line 1108, in process_api\r\n    result\
          \ = await self.call_function(\r\n  File \"C:\\AI\\Text\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\gradio\\blocks.py\", line 929,\
          \ in call_function    prediction = await anyio.to_thread.run_sync(\r\n \
          \ File \"C:\\AI\\Text\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          anyio\\to_thread.py\", line 31, in run_sync\r\n    return await get_asynclib().run_sync_in_worker_thread(\r\
          \n  File \"C:\\AI\\Text\\oobabooga-windows\\installer_files\\env\\lib\\\
          site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\r\
          \n    return await future\r\n  File \"C:\\AI\\Text\\oobabooga-windows\\\
          installer_files\\env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\"\
          , line 867, in run\r\n    result = context.run(func, *args)\r\n  File \"\
          C:\\AI\\Text\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
          gradio\\utils.py\", line 490, in async_iteration\r\n    return next(iterator)\r\
          \n  File \"C:\\AI\\Text\\oobabooga-windows\\text-generation-webui\\modules\\\
          chat.py\", line 228, in cai_chatbot_wrapper\r\n    for history in chatbot_wrapper(text,\
          \ state):\r\n  File \"C:\\AI\\Text\\oobabooga-windows\\text-generation-webui\\\
          modules\\chat.py\", line 160, in chatbot_wrapper\r\n    for reply in generate_reply(f\"\
          {prompt}{' ' if len(cumulative_reply) > 0 else ''}{cumulative_reply}\",\
          \ state, eos_token=eos_token, stopping_strings=stopping_strings):\r\n  File\
          \ \"C:\\AI\\Text\\oobabooga-windows\\text-generation-webui\\modules\\text_generation.py\"\
          , line 181, in generate_reply\r\n    input_ids = encode(question, add_bos_token=state['add_bos_token'],\
          \ truncation_length=get_max_prompt_length(state))\r\n  File \"C:\\AI\\Text\\\
          oobabooga-windows\\text-generation-webui\\modules\\text_generation.py\"\
          , line 31, in encode\r\n    input_ids = shared.tokenizer.encode(str(prompt),\
          \ return_tensors='pt', add_special_tokens=add_special_tokens)\r\nAttributeError:\
          \ 'NoneType' object has no attribute 'encode'"
        updatedAt: '2023-04-14T10:17:34.278Z'
      numEdits: 0
      reactions: []
    id: 6439283ee1acfc375c6a9c2b
    type: comment
  author: Alphafi
  content: "Loading vicuna-13b-GPTQ-4bit-128g...\r\nFound the following quantized\
    \ model: models\\vicuna-13b-GPTQ-4bit-128g\\vicuna-13b-4bit-128g.safetensors\r\
    \nLoading model ...\r\nDone.\r\nTraceback (most recent call last):\r\n  File \"\
    C:\\AI\\Text\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\gradio\\\
    routes.py\", line 393, in run_predict\r\n    output = await app.get_blocks().process_api(\r\
    \n  File \"C:\\AI\\Text\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    gradio\\blocks.py\", line 1108, in process_api\r\n    result = await self.call_function(\r\
    \n  File \"C:\\AI\\Text\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    gradio\\blocks.py\", line 929, in call_function    prediction = await anyio.to_thread.run_sync(\r\
    \n  File \"C:\\AI\\Text\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    anyio\\to_thread.py\", line 31, in run_sync\r\n    return await get_asynclib().run_sync_in_worker_thread(\r\
    \n  File \"C:\\AI\\Text\\oobabooga-windows\\installer_files\\env\\lib\\site-packages\\\
    anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\r\n  \
    \  return await future\r\n  File \"C:\\AI\\Text\\oobabooga-windows\\installer_files\\\
    env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\r\n\
    \    result = context.run(func, *args)\r\n  File \"C:\\AI\\Text\\oobabooga-windows\\\
    installer_files\\env\\lib\\site-packages\\gradio\\utils.py\", line 490, in async_iteration\r\
    \n    return next(iterator)\r\n  File \"C:\\AI\\Text\\oobabooga-windows\\text-generation-webui\\\
    modules\\chat.py\", line 228, in cai_chatbot_wrapper\r\n    for history in chatbot_wrapper(text,\
    \ state):\r\n  File \"C:\\AI\\Text\\oobabooga-windows\\text-generation-webui\\\
    modules\\chat.py\", line 160, in chatbot_wrapper\r\n    for reply in generate_reply(f\"\
    {prompt}{' ' if len(cumulative_reply) > 0 else ''}{cumulative_reply}\", state,\
    \ eos_token=eos_token, stopping_strings=stopping_strings):\r\n  File \"C:\\AI\\\
    Text\\oobabooga-windows\\text-generation-webui\\modules\\text_generation.py\"\
    , line 181, in generate_reply\r\n    input_ids = encode(question, add_bos_token=state['add_bos_token'],\
    \ truncation_length=get_max_prompt_length(state))\r\n  File \"C:\\AI\\Text\\oobabooga-windows\\\
    text-generation-webui\\modules\\text_generation.py\", line 31, in encode\r\n \
    \   input_ids = shared.tokenizer.encode(str(prompt), return_tensors='pt', add_special_tokens=add_special_tokens)\r\
    \nAttributeError: 'NoneType' object has no attribute 'encode'"
  created_at: 2023-04-14 09:17:34+00:00
  edited: false
  hidden: false
  id: 6439283ee1acfc375c6a9c2b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/866739beda636a48559e678de345a6f2.svg
      fullname: Tomas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: boxman222
      type: user
    createdAt: '2023-04-15T16:09:30.000Z'
    data:
      edited: false
      editors:
      - boxman222
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/866739beda636a48559e678de345a6f2.svg
          fullname: Tomas
          isHf: false
          isPro: false
          name: boxman222
          type: user
        html: '<p>Same error here...</p>

          '
        raw: Same error here...
        updatedAt: '2023-04-15T16:09:30.145Z'
      numEdits: 0
      reactions: []
    id: 643acc3a7885c858fb9461ad
    type: comment
  author: boxman222
  content: Same error here...
  created_at: 2023-04-15 15:09:30+00:00
  edited: false
  hidden: false
  id: 643acc3a7885c858fb9461ad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/803900a11f4c5b52a545d54c0a9d6a15.svg
      fullname: Test Test
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: androtester
      type: user
    createdAt: '2023-04-16T10:28:40.000Z'
    data:
      edited: false
      editors:
      - androtester
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/803900a11f4c5b52a545d54c0a9d6a15.svg
          fullname: Test Test
          isHf: false
          isPro: false
          name: androtester
          type: user
        html: '<p>Same error.</p>

          '
        raw: Same error.
        updatedAt: '2023-04-16T10:28:40.840Z'
      numEdits: 0
      reactions: []
    id: 643bcdd82d67f0ed22f6823e
    type: comment
  author: androtester
  content: Same error.
  created_at: 2023-04-16 09:28:40+00:00
  edited: false
  hidden: false
  id: 643bcdd82d67f0ed22f6823e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/42c968326ca2cdeac09e8243ec3b8a7b.svg
      fullname: Matias Contreras
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MatzHKR
      type: user
    createdAt: '2023-04-28T16:58:06.000Z'
    data:
      edited: false
      editors:
      - MatzHKR
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/42c968326ca2cdeac09e8243ec3b8a7b.svg
          fullname: Matias Contreras
          isHf: false
          isPro: false
          name: MatzHKR
          type: user
        html: '<p>ChatGPT4 say: This error indicates that there is an issue with the
          code, specifically with the ''tokenizer'' object. The error is caused by
          the ''tokenizer'' object being ''NoneType'', which means it has not been
          initialized or assigned a value before trying to use it.</p>

          <p>The error occurs in the following line of code:</p>

          <p>input_ids = shared.tokenizer.encode(str(prompt), return_tensors=''pt'',
          add_special_tokens=add_special_tokens)</p>

          <p>To resolve this error, ensure that the ''tokenizer'' object has been
          properly initialized before calling the ''encode'' method. Check if the
          tokenizer was imported correctly and if it was assigned an appropriate value
          in the code. You may also look for where the ''tokenizer'' object should
          have been initialized in the code and ensure it has been done correctly.</p>

          '
        raw: 'ChatGPT4 say: This error indicates that there is an issue with the code,
          specifically with the ''tokenizer'' object. The error is caused by the ''tokenizer''
          object being ''NoneType'', which means it has not been initialized or assigned
          a value before trying to use it.


          The error occurs in the following line of code:


          input_ids = shared.tokenizer.encode(str(prompt), return_tensors=''pt'',
          add_special_tokens=add_special_tokens)


          To resolve this error, ensure that the ''tokenizer'' object has been properly
          initialized before calling the ''encode'' method. Check if the tokenizer
          was imported correctly and if it was assigned an appropriate value in the
          code. You may also look for where the ''tokenizer'' object should have been
          initialized in the code and ensure it has been done correctly.'
        updatedAt: '2023-04-28T16:58:06.900Z'
      numEdits: 0
      reactions: []
    id: 644bfb1e0ce4f8fb516918c3
    type: comment
  author: MatzHKR
  content: 'ChatGPT4 say: This error indicates that there is an issue with the code,
    specifically with the ''tokenizer'' object. The error is caused by the ''tokenizer''
    object being ''NoneType'', which means it has not been initialized or assigned
    a value before trying to use it.


    The error occurs in the following line of code:


    input_ids = shared.tokenizer.encode(str(prompt), return_tensors=''pt'', add_special_tokens=add_special_tokens)


    To resolve this error, ensure that the ''tokenizer'' object has been properly
    initialized before calling the ''encode'' method. Check if the tokenizer was imported
    correctly and if it was assigned an appropriate value in the code. You may also
    look for where the ''tokenizer'' object should have been initialized in the code
    and ensure it has been done correctly.'
  created_at: 2023-04-28 15:58:06+00:00
  edited: false
  hidden: false
  id: 644bfb1e0ce4f8fb516918c3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 33
repo_id: anon8231489123/vicuna-13b-GPTQ-4bit-128g
repo_type: model
status: open
target_branch: null
title: Problem when starting web UI, when I I want to type or chat, it only shows
  the assistant as "Typing"
