!!python/object:huggingface_hub.community.DiscussionWithDetails
author: compilade
conflicting_files: null
created_at: 2023-11-23 01:09:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4Az8a8F60rNOD3L3ThsCe.png?w=200&h=200&f=face
      fullname: Compilade
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: compilade
      type: user
    createdAt: '2023-11-23T01:09:48.000Z'
    data:
      edited: false
      editors:
      - compilade
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8082231283187866
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4Az8a8F60rNOD3L3ThsCe.png?w=200&h=200&f=face
          fullname: Compilade
          isHf: false
          isPro: false
          name: compilade
          type: user
        html: '<p>llama.cpp''s <code>./main</code> example uses the EOS token stored
          in the GGUF to figure out when to stop.</p>

          <p>For context,  <code>convert-hf-to-gguf.py</code> uses <code>transformers.AutoTokenizer</code>
          which uses settings from <code>tokenizer_config.json</code>.<br>The EOS
          token was wrong (<a href="https://huggingface.co/pansophic/rocket-3B/discussions/3">but
          was recently fixed upstream</a>), so the output never seemed to end when
          I first tried this model.</p>

          <p>Consider re-converting this model so that the GGUF files contain the
          correct EOS token (which should be <code>&lt;|im_end|&gt;</code> (aka token
          id 50279) for this model).</p>

          '
        raw: "llama.cpp's `./main` example uses the EOS token stored in the GGUF to\
          \ figure out when to stop.\r\n\r\nFor context,  `convert-hf-to-gguf.py`\
          \ uses `transformers.AutoTokenizer` which uses settings from `tokenizer_config.json`.\r\
          \nThe EOS token was wrong ([but was recently fixed upstream](https://huggingface.co/pansophic/rocket-3B/discussions/3)),\
          \ so the output never seemed to end when I first tried this model.\r\n\r\
          \nConsider re-converting this model so that the GGUF files contain the correct\
          \ EOS token (which should be `<|im_end|>` (aka token id 50279) for this\
          \ model)."
        updatedAt: '2023-11-23T01:09:48.055Z'
      numEdits: 0
      reactions: []
    id: 655ea65c337a5d2e37a49c85
    type: comment
  author: compilade
  content: "llama.cpp's `./main` example uses the EOS token stored in the GGUF to\
    \ figure out when to stop.\r\n\r\nFor context,  `convert-hf-to-gguf.py` uses `transformers.AutoTokenizer`\
    \ which uses settings from `tokenizer_config.json`.\r\nThe EOS token was wrong\
    \ ([but was recently fixed upstream](https://huggingface.co/pansophic/rocket-3B/discussions/3)),\
    \ so the output never seemed to end when I first tried this model.\r\n\r\nConsider\
    \ re-converting this model so that the GGUF files contain the correct EOS token\
    \ (which should be `<|im_end|>` (aka token id 50279) for this model)."
  created_at: 2023-11-23 01:09:48+00:00
  edited: false
  hidden: false
  id: 655ea65c337a5d2e37a49c85
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4Az8a8F60rNOD3L3ThsCe.png?w=200&h=200&f=face
      fullname: Compilade
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: compilade
      type: user
    createdAt: '2023-11-29T01:56:11.000Z'
    data:
      status: closed
    id: 65669a3b6d599b3cb63b59ae
    type: status-change
  author: compilade
  created_at: 2023-11-29 01:56:11+00:00
  id: 65669a3b6d599b3cb63b59ae
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/rocket-3B-GGUF
repo_type: model
status: closed
target_branch: null
title: Wrong EOS token has been fixed in upstream tokenizer_config.json, consider
  reconverting
