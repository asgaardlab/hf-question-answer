!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sersoage
conflicting_files: null
created_at: 2022-09-07 02:22:38+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4fa2b2e640d32dfcb049f952c684f8c3.svg
      fullname: Sergio
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sersoage
      type: user
    createdAt: '2022-09-07T03:22:38.000Z'
    data:
      edited: false
      editors:
      - sersoage
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4fa2b2e640d32dfcb049f952c684f8c3.svg
          fullname: Sergio
          isHf: false
          isPro: false
          name: sersoage
          type: user
        html: '<p>Hi I am trying to use your models and unable to use and specific
          gpu when doing inference? could you point to a resource to do so?<br>Thanks!</p>

          '
        raw: "Hi I am trying to use your models and unable to use and specific gpu\
          \ when doing inference? could you point to a resource to do so?\r\nThanks!"
        updatedAt: '2022-09-07T03:22:38.679Z'
      numEdits: 0
      reactions: []
    id: 63180e7e7690c5b55e64d0c7
    type: comment
  author: sersoage
  content: "Hi I am trying to use your models and unable to use and specific gpu when\
    \ doing inference? could you point to a resource to do so?\r\nThanks!"
  created_at: 2022-09-07 02:22:38+00:00
  edited: false
  hidden: false
  id: 63180e7e7690c5b55e64d0c7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640511710953-noauth.jpeg?w=200&h=200&f=face
      fullname: Thomas De Decker
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: DeDeckerThomas
      type: user
    createdAt: '2022-10-24T17:13:26.000Z'
    data:
      edited: true
      editors:
      - DeDeckerThomas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1640511710953-noauth.jpeg?w=200&h=200&f=face
          fullname: Thomas De Decker
          isHf: false
          isPro: false
          name: DeDeckerThomas
          type: user
        html: '<p>Hey!</p>

          <p>Well, you can specify the device parameter in the pipeline function.
          More information here: <a href="https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.device">https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.device</a>.<br>This
          worked for me:</p>

          <pre><code class="language-python">extractor = KeyphraseExtractionPipeline(model=model_name,
          device=<span class="hljs-number">0</span>)

          </code></pre>

          <p>Please check that you have installed PyTorch for GPU. Otherwise here
          is the link: <a rel="nofollow" href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>.</p>

          <p>Hope this helps!</p>

          '
        raw: 'Hey!


          Well, you can specify the device parameter in the pipeline function. More
          information here: https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.device.

          This worked for me:

          ```python

          extractor = KeyphraseExtractionPipeline(model=model_name, device=0)

          ```


          Please check that you have installed PyTorch for GPU. Otherwise here is
          the link: https://pytorch.org/get-started/locally/.


          Hope this helps!'
        updatedAt: '2022-10-24T17:13:34.518Z'
      numEdits: 1
      reactions: []
    id: 6356c7b6f6d2d2f012f2e760
    type: comment
  author: DeDeckerThomas
  content: 'Hey!


    Well, you can specify the device parameter in the pipeline function. More information
    here: https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.device.

    This worked for me:

    ```python

    extractor = KeyphraseExtractionPipeline(model=model_name, device=0)

    ```


    Please check that you have installed PyTorch for GPU. Otherwise here is the link:
    https://pytorch.org/get-started/locally/.


    Hope this helps!'
  created_at: 2022-10-24 16:13:26+00:00
  edited: true
  hidden: false
  id: 6356c7b6f6d2d2f012f2e760
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: ml6team/keyphrase-extraction-kbir-kpcrowd
repo_type: model
status: open
target_branch: null
title: How to set gpu device when doing inference
