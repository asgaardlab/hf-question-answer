!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Kagerage
conflicting_files: null
created_at: 2023-03-11 22:21:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670558389645-63058c7f99870e13d3e06170.png?w=200&h=200&f=face
      fullname: Kage Rage
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kagerage
      type: user
    createdAt: '2023-03-11T22:21:49.000Z'
    data:
      edited: false
      editors:
      - Kagerage
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670558389645-63058c7f99870e13d3e06170.png?w=200&h=200&f=face
          fullname: Kage Rage
          isHf: false
          isPro: false
          name: Kagerage
          type: user
        html: '<p>I remember seeing this the moment it went live, and when I went
          to tell a friend about it, the link simply went to a 404.  <a href="https://huggingface.co/OpenAssistant/oasst-sft-1-pythia6b">I
          still have the link onhand</a>, and I remember seeing some hugely oversized
          model chunks (I think they were around 26 GB per piece). I''m guessing this
          was the model that I heard got demoed on Discord, <a rel="nofollow" href="https://www.reddit.com/r/OpenAssistant/comments/11lszfh/baby_open_assistant_starts_speaking_for_the_first/">according
          to a Reddit user</a>.</p>

          '
        raw: I remember seeing this the moment it went live, and when I went to tell
          a friend about it, the link simply went to a 404.  [I still have the link
          onhand](https://huggingface.co/OpenAssistant/oasst-sft-1-pythia6b), and
          I remember seeing some hugely oversized model chunks (I think they were
          around 26 GB per piece). I'm guessing this was the model that I heard got
          demoed on Discord, [according to a Reddit user](https://www.reddit.com/r/OpenAssistant/comments/11lszfh/baby_open_assistant_starts_speaking_for_the_first/).
        updatedAt: '2023-03-11T22:21:49.494Z'
      numEdits: 0
      reactions: []
    id: 640cfefd04c679553cfa22c6
    type: comment
  author: Kagerage
  content: I remember seeing this the moment it went live, and when I went to tell
    a friend about it, the link simply went to a 404.  [I still have the link onhand](https://huggingface.co/OpenAssistant/oasst-sft-1-pythia6b),
    and I remember seeing some hugely oversized model chunks (I think they were around
    26 GB per piece). I'm guessing this was the model that I heard got demoed on Discord,
    [according to a Reddit user](https://www.reddit.com/r/OpenAssistant/comments/11lszfh/baby_open_assistant_starts_speaking_for_the_first/).
  created_at: 2023-03-11 22:21:49+00:00
  edited: false
  hidden: false
  id: 640cfefd04c679553cfa22c6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: OpenAssistant/oasst-sft-1-pythia-12b
repo_type: model
status: open
target_branch: null
title: So... what happened to the pythia6b model?
