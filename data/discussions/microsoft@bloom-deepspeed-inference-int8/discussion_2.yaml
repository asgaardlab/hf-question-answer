!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bournezz
conflicting_files: null
created_at: 2022-11-04 01:09:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b2ccb84a5ea3a045095dcb1ef050113b.svg
      fullname: ZZZ
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bournezz
      type: user
    createdAt: '2022-11-04T02:09:09.000Z'
    data:
      edited: false
      editors:
      - bournezz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b2ccb84a5ea3a045095dcb1ef050113b.svg
          fullname: ZZZ
          isHf: false
          isPro: false
          name: bournezz
          type: user
        html: '<p>I''m new to deepspeed and still don''t understand how the weight
          sharding works. I suppose that these weights are intended for users with
          4 A100 80G gpus because there are 4 groups of tp_**.pt files. Since I only
          have V100. I need more than 4 gpus to host these weights. Can I use these
          weights in my program? If not, how to re-reshard these weights into 8 partitions?</p>

          '
        raw: I'm new to deepspeed and still don't understand how the weight sharding
          works. I suppose that these weights are intended for users with 4 A100 80G
          gpus because there are 4 groups of tp_**.pt files. Since I only have V100.
          I need more than 4 gpus to host these weights. Can I use these weights in
          my program? If not, how to re-reshard these weights into 8 partitions?
        updatedAt: '2022-11-04T02:09:09.160Z'
      numEdits: 0
      reactions: []
    id: 636474457e02ebc9c7a6f056
    type: comment
  author: bournezz
  content: I'm new to deepspeed and still don't understand how the weight sharding
    works. I suppose that these weights are intended for users with 4 A100 80G gpus
    because there are 4 groups of tp_**.pt files. Since I only have V100. I need more
    than 4 gpus to host these weights. Can I use these weights in my program? If not,
    how to re-reshard these weights into 8 partitions?
  created_at: 2022-11-04 01:09:09+00:00
  edited: false
  hidden: false
  id: 636474457e02ebc9c7a6f056
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5eac4c154e876668a0c37770/rY95sfLjugbYLgJ9GHYjC.jpeg?w=200&h=200&f=face
      fullname: Luca Di Liello
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lucadiliello
      type: user
    createdAt: '2023-03-21T12:30:48.000Z'
    data:
      edited: false
      editors:
      - lucadiliello
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5eac4c154e876668a0c37770/rY95sfLjugbYLgJ9GHYjC.jpeg?w=200&h=200&f=face
          fullname: Luca Di Liello
          isHf: false
          isPro: false
          name: lucadiliello
          type: user
        html: '<p>You should be fine just by setting <code>training_mp_size=4</code>
          in the <code>deepspeed.init_inference</code>. However, I see that it works
          even by setting nothing with <code>deepspeed&gt;=0.8.0</code>. I suppose
          that under the hood deepspeed splits every tensor another time to obtain
          8 shards.</p>

          '
        raw: You should be fine just by setting `training_mp_size=4` in the `deepspeed.init_inference`.
          However, I see that it works even by setting nothing with `deepspeed>=0.8.0`.
          I suppose that under the hood deepspeed splits every tensor another time
          to obtain 8 shards.
        updatedAt: '2023-03-21T12:30:48.171Z'
      numEdits: 0
      reactions: []
    id: 6419a3783a524ff07ef3c043
    type: comment
  author: lucadiliello
  content: You should be fine just by setting `training_mp_size=4` in the `deepspeed.init_inference`.
    However, I see that it works even by setting nothing with `deepspeed>=0.8.0`.
    I suppose that under the hood deepspeed splits every tensor another time to obtain
    8 shards.
  created_at: 2023-03-21 11:30:48+00:00
  edited: false
  hidden: false
  id: 6419a3783a524ff07ef3c043
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3c8589b68a942b4afd54df2ae4b96336.svg
      fullname: Tingchen Fu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TingchenFu
      type: user
    createdAt: '2023-06-19T08:40:50.000Z'
    data:
      edited: false
      editors:
      - TingchenFu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8465830683708191
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3c8589b68a942b4afd54df2ae4b96336.svg
          fullname: Tingchen Fu
          isHf: false
          isPro: false
          name: TingchenFu
          type: user
        html: '<p>Hi,  do you succeed at using V100 to run BLOOM inference?@bournezz  How
          much V100s do you use?</p>

          '
        raw: Hi,  do you succeed at using V100 to run BLOOM inference?@bournezz  How
          much V100s do you use?
        updatedAt: '2023-06-19T08:40:50.154Z'
      numEdits: 0
      reactions: []
    id: 649014925f926e90fe7b4da8
    type: comment
  author: TingchenFu
  content: Hi,  do you succeed at using V100 to run BLOOM inference?@bournezz  How
    much V100s do you use?
  created_at: 2023-06-19 07:40:50+00:00
  edited: false
  hidden: false
  id: 649014925f926e90fe7b4da8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: microsoft/bloom-deepspeed-inference-int8
repo_type: model
status: open
target_branch: null
title: Can I load these weights into a model using 8 gpus?
