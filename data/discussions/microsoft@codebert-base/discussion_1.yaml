!!python/object:huggingface_hub.community.DiscussionWithDetails
author: cakiki
conflicting_files: null
created_at: 2022-07-26 19:52:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
      fullname: Christopher Akiki
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cakiki
      type: user
    createdAt: '2022-07-26T20:52:18.000Z'
    data:
      edited: false
      editors:
      - cakiki
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
          fullname: Christopher Akiki
          isHf: false
          isPro: false
          name: cakiki
          type: user
        html: '<p>Hello, </p>

          <p>I was experimenting with the model when I noticed that the tokenizer
          vocab contains tokens that don''t really make sense for a code model (e.g.
          full tokens for "embarrassed" and "fossils" and "Hermione"). Upon closer
          inspection, it seems the tokenizer <code>roberta-base</code> tokenizer.
          </p>

          <p>In case this was by design, why was the tokenizer not trained on the
          training data?</p>

          '
        raw: "Hello, \r\n\r\nI was experimenting with the model when I noticed that\
          \ the tokenizer vocab contains tokens that don't really make sense for a\
          \ code model (e.g. full tokens for \"embarrassed\" and \"fossils\" and \"\
          Hermione\"). Upon closer inspection, it seems the tokenizer `roberta-base`\
          \ tokenizer. \r\n\r\nIn case this was by design, why was the tokenizer not\
          \ trained on the training data?"
        updatedAt: '2022-07-26T20:52:18.581Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - heytanay
    id: 62e05402de55752844190bea
    type: comment
  author: cakiki
  content: "Hello, \r\n\r\nI was experimenting with the model when I noticed that\
    \ the tokenizer vocab contains tokens that don't really make sense for a code\
    \ model (e.g. full tokens for \"embarrassed\" and \"fossils\" and \"Hermione\"\
    ). Upon closer inspection, it seems the tokenizer `roberta-base` tokenizer. \r\
    \n\r\nIn case this was by design, why was the tokenizer not trained on the training\
    \ data?"
  created_at: 2022-07-26 19:52:18+00:00
  edited: false
  hidden: false
  id: 62e05402de55752844190bea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2022-07-27T08:36:55.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Hi,</p>

          <p>The title of the CodeBERT paper is "CodeBERT: A Pre-Trained Model for
          Programming and Natural Languages", hence the model is trained on both code
          and natural language (not code-only). </p>

          <p>This explains why the tokenizer has full words as well in its vocabulary.</p>

          '
        raw: "Hi,\n\nThe title of the CodeBERT paper is \"CodeBERT: A Pre-Trained\
          \ Model for Programming and Natural Languages\", hence the model is trained\
          \ on both code and natural language (not code-only). \n\nThis explains why\
          \ the tokenizer has full words as well in its vocabulary."
        updatedAt: '2022-07-27T08:36:55.054Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - cakiki
    id: 62e0f9274db2175cd270e7f5
    type: comment
  author: nielsr
  content: "Hi,\n\nThe title of the CodeBERT paper is \"CodeBERT: A Pre-Trained Model\
    \ for Programming and Natural Languages\", hence the model is trained on both\
    \ code and natural language (not code-only). \n\nThis explains why the tokenizer\
    \ has full words as well in its vocabulary."
  created_at: 2022-07-27 07:36:55+00:00
  edited: false
  hidden: false
  id: 62e0f9274db2175cd270e7f5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
      fullname: Christopher Akiki
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cakiki
      type: user
    createdAt: '2022-07-27T08:59:55.000Z'
    data:
      edited: false
      editors:
      - cakiki
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
          fullname: Christopher Akiki
          isHf: false
          isPro: false
          name: cakiki
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;nielsr&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/nielsr\">@<span class=\"\
          underline\">nielsr</span></a></span>\n\n\t</span></span> Thank you for your\
          \ comment Niels. The natural language referred to in the title is natural\
          \ language found in code repositories; i.e. comments and documentation.\
          \ Most the tokens I saw were very out-of-domain.</p>\n<p>The following returns\
          \ True which probably means that it's just the roberta tokenizer, no?</p>\n\
          <pre><code class=\"language-python\">tok_codebert = AutoTokenizer.from_pretrained(<span\
          \ class=\"hljs-string\">\"microsoft/codebert-base\"</span>)\ntok_roberta\
          \ = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">'roberta-base'</span>)\n\
          tok_codebert.vocab == tok_roberta.vocab\n&gt;&gt;&gt;<span class=\"hljs-literal\"\
          >True</span>\n</code></pre>\n"
        raw: '@nielsr Thank you for your comment Niels. The natural language referred
          to in the title is natural language found in code repositories; i.e. comments
          and documentation. Most the tokens I saw were very out-of-domain.


          The following returns True which probably means that it''s just the roberta
          tokenizer, no?


          ```python

          tok_codebert = AutoTokenizer.from_pretrained("microsoft/codebert-base")

          tok_roberta = AutoTokenizer.from_pretrained(''roberta-base'')

          tok_codebert.vocab == tok_roberta.vocab

          >>>True

          ```'
        updatedAt: '2022-07-27T08:59:55.422Z'
      numEdits: 0
      reactions: []
    id: 62e0fe8bedb0462c8d51ea01
    type: comment
  author: cakiki
  content: '@nielsr Thank you for your comment Niels. The natural language referred
    to in the title is natural language found in code repositories; i.e. comments
    and documentation. Most the tokens I saw were very out-of-domain.


    The following returns True which probably means that it''s just the roberta tokenizer,
    no?


    ```python

    tok_codebert = AutoTokenizer.from_pretrained("microsoft/codebert-base")

    tok_roberta = AutoTokenizer.from_pretrained(''roberta-base'')

    tok_codebert.vocab == tok_roberta.vocab

    >>>True

    ```'
  created_at: 2022-07-27 07:59:55+00:00
  edited: false
  hidden: false
  id: 62e0fe8bedb0462c8d51ea01
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4f52983b44807e58499563fdb0e079e2.svg
      fullname: ZhangyinFeng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zyfeng
      type: user
    createdAt: '2022-08-05T08:00:34.000Z'
    data:
      edited: true
      editors:
      - zyfeng
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4f52983b44807e58499563fdb0e079e2.svg
          fullname: ZhangyinFeng
          isHf: false
          isPro: false
          name: zyfeng
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;cakiki&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/cakiki\">@<span class=\"\
          underline\">cakiki</span></a></span>\n\n\t</span></span> You are right.\
          \ We directly use roberta tokenizer  in CodeBERT.</p>\n"
        raw: '@cakiki You are right. We directly use roberta tokenizer  in CodeBERT.'
        updatedAt: '2022-08-05T08:00:52.522Z'
      numEdits: 1
      reactions: []
    id: 62ecce2299112e99c5f86622
    type: comment
  author: zyfeng
  content: '@cakiki You are right. We directly use roberta tokenizer  in CodeBERT.'
  created_at: 2022-08-05 07:00:34+00:00
  edited: true
  hidden: false
  id: 62ecce2299112e99c5f86622
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
      fullname: Christopher Akiki
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cakiki
      type: user
    createdAt: '2022-08-05T11:27:18.000Z'
    data:
      edited: false
      editors:
      - cakiki
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
          fullname: Christopher Akiki
          isHf: false
          isPro: false
          name: cakiki
          type: user
        html: '<p>Thank you for your reply!</p>

          '
        raw: Thank you for your reply!
        updatedAt: '2022-08-05T11:27:18.652Z'
      numEdits: 0
      reactions: []
      relatedEventId: 62ecfe9667212a268bedfccc
    id: 62ecfe9667212a268bedfccb
    type: comment
  author: cakiki
  content: Thank you for your reply!
  created_at: 2022-08-05 10:27:18+00:00
  edited: false
  hidden: false
  id: 62ecfe9667212a268bedfccb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1646492542174-5e70f6048ce3c604d78fe133.jpeg?w=200&h=200&f=face
      fullname: Christopher Akiki
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cakiki
      type: user
    createdAt: '2022-08-05T11:27:18.000Z'
    data:
      status: closed
    id: 62ecfe9667212a268bedfccc
    type: status-change
  author: cakiki
  created_at: 2022-08-05 10:27:18+00:00
  id: 62ecfe9667212a268bedfccc
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: microsoft/codebert-base
repo_type: model
status: closed
target_branch: null
title: Wrong Tokenizer?
