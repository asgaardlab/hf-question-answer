!!python/object:huggingface_hub.community.DiscussionWithDetails
author: erank3
conflicting_files: null
created_at: 2023-05-15 16:20:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a232b162071998a7d52add276fe80a2c.svg
      fullname: Eran Kaufman
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: erank3
      type: user
    createdAt: '2023-05-15T17:20:45.000Z'
    data:
      edited: false
      editors:
      - erank3
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a232b162071998a7d52add276fe80a2c.svg
          fullname: Eran Kaufman
          isHf: false
          isPro: false
          name: erank3
          type: user
        html: "<p>Hello !<br>Thanks so much for this great great work!</p>\n<p>I am\
          \ getting this error when I try to run inference:<br>ValueError: Tensor\
          \ lora_te_text_model_encoder_layers_0_mlp_fc1.alpha has no metadata - is\
          \ this a Lora safetensor?</p>\n<p>I am running a normal inference flow using\
          \ StableDiffusionPipeline:</p>\n<p>os.makedirs(output_path, exist_ok=True)</p>\n\
          <pre><code>model_id = \"runwayml/stable-diffusion-v1-5\"\nlora_model = \"\
          models/lora/360/360Diffusion_v1.safetensors\"\n\npipe = StableDiffusionPipeline.from_pretrained(model_id,\
          \ torch_dtype=torch.float16).to(\n    \"cuda\"\n)\n\npipe.scheduler = EulerAncestralDiscreteScheduler.from_config(\n\
          \    pipe.scheduler.config)\n\npatch_pipe(\n    pipe,\n    lora_model,\n\
          \    patch_text=True,\n    patch_ti=True,\n    patch_unet=True,\n)\n\ntune_lora_scale(pipe.unet,\
          \ 1.00)\ntune_lora_scale(pipe.text_encoder, 1.00)\n\ngenerator = torch.Generator(\"\
          cuda\").manual_seed(seed)\nimage = pipe(prompt, num_inference_steps=steps,\
          \ guidance_scale=scale,\n             height=H, width=W, generator=generator).images[0]\n\
          </code></pre>\n<p>can you provide some context about how to run the model\
          \ using the pipeline?</p>\n<p>Thanks!!</p>\n"
        raw: "Hello !\r\nThanks so much for this great great work!\r\n\r\nI am getting\
          \ this error when I try to run inference:\r\nValueError: Tensor lora_te_text_model_encoder_layers_0_mlp_fc1.alpha\
          \ has no metadata - is this a Lora safetensor?\r\n\r\n\r\nI am running a\
          \ normal inference flow using StableDiffusionPipeline:\r\n\r\nos.makedirs(output_path,\
          \ exist_ok=True)\r\n\r\n    model_id = \"runwayml/stable-diffusion-v1-5\"\
          \r\n    lora_model = \"models/lora/360/360Diffusion_v1.safetensors\"\r\n\
          \    \r\n    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\r\
          \n        \"cuda\"\r\n    )\r\n    \r\n    pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(\r\
          \n        pipe.scheduler.config)\r\n\r\n    patch_pipe(\r\n        pipe,\r\
          \n        lora_model,\r\n        patch_text=True,\r\n        patch_ti=True,\r\
          \n        patch_unet=True,\r\n    )\r\n\r\n    tune_lora_scale(pipe.unet,\
          \ 1.00)\r\n    tune_lora_scale(pipe.text_encoder, 1.00)\r\n\r\n    generator\
          \ = torch.Generator(\"cuda\").manual_seed(seed)\r\n    image = pipe(prompt,\
          \ num_inference_steps=steps, guidance_scale=scale,\r\n                 height=H,\
          \ width=W, generator=generator).images[0]\r\n\r\n\r\ncan you provide some\
          \ context about how to run the model using the pipeline?\r\n\r\n\r\n\r\n\
          Thanks!!\r\n"
        updatedAt: '2023-05-15T17:20:45.992Z'
      numEdits: 0
      reactions: []
    id: 646269edd1ccd517f467f79b
    type: comment
  author: erank3
  content: "Hello !\r\nThanks so much for this great great work!\r\n\r\nI am getting\
    \ this error when I try to run inference:\r\nValueError: Tensor lora_te_text_model_encoder_layers_0_mlp_fc1.alpha\
    \ has no metadata - is this a Lora safetensor?\r\n\r\n\r\nI am running a normal\
    \ inference flow using StableDiffusionPipeline:\r\n\r\nos.makedirs(output_path,\
    \ exist_ok=True)\r\n\r\n    model_id = \"runwayml/stable-diffusion-v1-5\"\r\n\
    \    lora_model = \"models/lora/360/360Diffusion_v1.safetensors\"\r\n    \r\n\
    \    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\r\
    \n        \"cuda\"\r\n    )\r\n    \r\n    pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(\r\
    \n        pipe.scheduler.config)\r\n\r\n    patch_pipe(\r\n        pipe,\r\n \
    \       lora_model,\r\n        patch_text=True,\r\n        patch_ti=True,\r\n\
    \        patch_unet=True,\r\n    )\r\n\r\n    tune_lora_scale(pipe.unet, 1.00)\r\
    \n    tune_lora_scale(pipe.text_encoder, 1.00)\r\n\r\n    generator = torch.Generator(\"\
    cuda\").manual_seed(seed)\r\n    image = pipe(prompt, num_inference_steps=steps,\
    \ guidance_scale=scale,\r\n                 height=H, width=W, generator=generator).images[0]\r\
    \n\r\n\r\ncan you provide some context about how to run the model using the pipeline?\r\
    \n\r\n\r\n\r\nThanks!!\r\n"
  created_at: 2023-05-15 16:20:45+00:00
  edited: false
  hidden: false
  id: 646269edd1ccd517f467f79b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d522b381ccd66c29b450443d4a1444dd.svg
      fullname: Flavio Giorgini
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Domorek
      type: user
    createdAt: '2023-06-23T22:07:53.000Z'
    data:
      edited: false
      editors:
      - Domorek
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9646190404891968
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d522b381ccd66c29b450443d4a1444dd.svg
          fullname: Flavio Giorgini
          isHf: false
          isPro: false
          name: Domorek
          type: user
        html: '<p>I have the same error with a different LoRa model, have you found
          a solution?</p>

          '
        raw: 'I have the same error with a different LoRa model, have you found a
          solution?

          '
        updatedAt: '2023-06-23T22:07:53.418Z'
      numEdits: 0
      reactions: []
    id: 649617b90b01497fb78fd2e2
    type: comment
  author: Domorek
  content: 'I have the same error with a different LoRa model, have you found a solution?

    '
  created_at: 2023-06-23 21:07:53+00:00
  edited: false
  hidden: false
  id: 649617b90b01497fb78fd2e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/13dc0a370bb24271653c352897a2673e.svg
      fullname: Estelle Aflalo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: estellea
      type: user
    createdAt: '2023-09-28T10:54:34.000Z'
    data:
      edited: false
      editors:
      - estellea
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8107326626777649
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/13dc0a370bb24271653c352897a2673e.svg
          fullname: Estelle Aflalo
          isHf: false
          isPro: false
          name: estellea
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;erank3&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/erank3\">@<span class=\"\
          underline\">erank3</span></a></span>\n\n\t</span></span> !<br>Were you able\
          \ to use this lora model at the end?<br>Getting the same error<br>Thanks\
          \ a lot!</p>\n"
        raw: "Hi @erank3 !\nWere you able to use this lora model at the end? \nGetting\
          \ the same error\nThanks a lot!"
        updatedAt: '2023-09-28T10:54:34.110Z'
      numEdits: 0
      reactions: []
    id: 65155b6a394185aa966d718a
    type: comment
  author: estellea
  content: "Hi @erank3 !\nWere you able to use this lora model at the end? \nGetting\
    \ the same error\nThanks a lot!"
  created_at: 2023-09-28 09:54:34+00:00
  edited: false
  hidden: false
  id: 65155b6a394185aa966d718a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: ProGamerGov/360-Diffusion-LoRA-sd-v1-5
repo_type: model
status: open
target_branch: null
title: 'ValueError: Tensor lora_te_text_model_encoder_layers_0_mlp_fc1.alpha has no
  metadata - is this a Lora safetensor?'
