!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KnutJaegersberg
conflicting_files: null
created_at: 2023-11-03 12:49:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-03T13:49:18.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.670461893081665
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>Hi I was trying to fine tune this model with autotrain advanced,
          but I face this exception:<br>    out, q, k, v, out_padded, softmax_lse,
          S_dmask, rng_state = flash_attn_cuda.fwd(<br>RuntimeError: FlashAttention
          only support fp16 and bf16 data type</p>

          <p>this is my command:<br>autotrain llm --train --project_name deacon-34b
          --model /run/media/knut/HD2/Yi-34B/ --data_path . --train_batch_size 1 --num_train_epochs
          5 --trainer sft --use_int4 --use_peft --merge_adapter --target_modules "q_proj,k_proj,v_proj,o_proj"</p>

          <p>I tried to reinstall a few libs, but could not resolve it. Is it already
          possible to fine tune your model with hf autotrain-advanced? </p>

          '
        raw: "Hi I was trying to fine tune this model with autotrain advanced, but\
          \ I face this exception: \r\n    out, q, k, v, out_padded, softmax_lse,\
          \ S_dmask, rng_state = flash_attn_cuda.fwd(\r\nRuntimeError: FlashAttention\
          \ only support fp16 and bf16 data type\r\n\r\nthis is my command: \r\nautotrain\
          \ llm --train --project_name deacon-34b --model /run/media/knut/HD2/Yi-34B/\
          \ --data_path . --train_batch_size 1 --num_train_epochs 5 --trainer sft\
          \ --use_int4 --use_peft --merge_adapter --target_modules \"q_proj,k_proj,v_proj,o_proj\"\
          \r\n\r\nI tried to reinstall a few libs, but could not resolve it. Is it\
          \ already possible to fine tune your model with hf autotrain-advanced? "
        updatedAt: '2023-11-03T13:49:18.042Z'
      numEdits: 0
      reactions: []
    id: 6544fa5e34cfaaa4019e3a4d
    type: comment
  author: KnutJaegersberg
  content: "Hi I was trying to fine tune this model with autotrain advanced, but I\
    \ face this exception: \r\n    out, q, k, v, out_padded, softmax_lse, S_dmask,\
    \ rng_state = flash_attn_cuda.fwd(\r\nRuntimeError: FlashAttention only support\
    \ fp16 and bf16 data type\r\n\r\nthis is my command: \r\nautotrain llm --train\
    \ --project_name deacon-34b --model /run/media/knut/HD2/Yi-34B/ --data_path .\
    \ --train_batch_size 1 --num_train_epochs 5 --trainer sft --use_int4 --use_peft\
    \ --merge_adapter --target_modules \"q_proj,k_proj,v_proj,o_proj\"\r\n\r\nI tried\
    \ to reinstall a few libs, but could not resolve it. Is it already possible to\
    \ fine tune your model with hf autotrain-advanced? "
  created_at: 2023-11-03 12:49:18+00:00
  edited: false
  hidden: false
  id: 6544fa5e34cfaaa4019e3a4d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/009a937c4842eeb6423567cdb9373871.svg
      fullname: Jiangcheng
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: silentriverg
      type: user
    createdAt: '2023-11-03T16:42:48.000Z'
    data:
      edited: false
      editors:
      - silentriverg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5144039392471313
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/009a937c4842eeb6423567cdb9373871.svg
          fullname: Jiangcheng
          isHf: false
          isPro: false
          name: silentriverg
          type: user
        html: '<p>When loading the model, considering add torch_type=''auto'' in the
          model_class.from_pretrained API</p>

          '
        raw: When loading the model, considering add torch_type='auto' in the model_class.from_pretrained
          API
        updatedAt: '2023-11-03T16:42:48.276Z'
      numEdits: 0
      reactions: []
    id: 654523089ea035a2af70233f
    type: comment
  author: silentriverg
  content: When loading the model, considering add torch_type='auto' in the model_class.from_pretrained
    API
  created_at: 2023-11-03 15:42:48+00:00
  edited: false
  hidden: false
  id: 654523089ea035a2af70233f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-03T20:24:41.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9183366298675537
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>I''m trying this with 4bit or 8bit peft fine tuning. I hacked around
          both in the models python files and in the <strong>main</strong>.py of autotrain-advanced,
          tried to add toch_dtype=''auto'' where I could see it might work. So far
          I had no luck. <a rel="nofollow" href="https://github.com/huggingface/autotrain-advanced/blob/main/src/autotrain/trainers/clm/__main__.py">https://github.com/huggingface/autotrain-advanced/blob/main/src/autotrain/trainers/clm/__main__.py</a></p>

          '
        raw: I'm trying this with 4bit or 8bit peft fine tuning. I hacked around both
          in the models python files and in the __main__.py of autotrain-advanced,
          tried to add toch_dtype='auto' where I could see it might work. So far I
          had no luck. https://github.com/huggingface/autotrain-advanced/blob/main/src/autotrain/trainers/clm/__main__.py
        updatedAt: '2023-11-03T20:24:41.828Z'
      numEdits: 0
      reactions: []
    id: 65455709f7dd43aaa968f7e2
    type: comment
  author: KnutJaegersberg
  content: I'm trying this with 4bit or 8bit peft fine tuning. I hacked around both
    in the models python files and in the __main__.py of autotrain-advanced, tried
    to add toch_dtype='auto' where I could see it might work. So far I had no luck.
    https://github.com/huggingface/autotrain-advanced/blob/main/src/autotrain/trainers/clm/__main__.py
  created_at: 2023-11-03 19:24:41+00:00
  edited: false
  hidden: false
  id: 65455709f7dd43aaa968f7e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-05T06:36:22.000Z'
    data:
      edited: false
      editors:
      - KnutJaegersberg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.840798020362854
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
          fullname: "Knut J\xE4gersberg"
          isHf: false
          isPro: false
          name: KnutJaegersberg
          type: user
        html: '<p>I will close this.Please help make peft fine tuning with hf transformers
          work. </p>

          '
        raw: 'I will close this.Please help make peft fine tuning with hf transformers
          work. '
        updatedAt: '2023-11-05T06:36:22.476Z'
      numEdits: 0
      reactions: []
      relatedEventId: 654737e6b8ac1a89fff0b85a
    id: 654737e6b8ac1a89fff0b857
    type: comment
  author: KnutJaegersberg
  content: 'I will close this.Please help make peft fine tuning with hf transformers
    work. '
  created_at: 2023-11-05 05:36:22+00:00
  edited: false
  hidden: false
  id: 654737e6b8ac1a89fff0b857
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669551186189-63732ebbbd81fae2b3aaf3fb.jpeg?w=200&h=200&f=face
      fullname: "Knut J\xE4gersberg"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KnutJaegersberg
      type: user
    createdAt: '2023-11-05T06:36:22.000Z'
    data:
      status: closed
    id: 654737e6b8ac1a89fff0b85a
    type: status-change
  author: KnutJaegersberg
  created_at: 2023-11-05 05:36:22+00:00
  id: 654737e6b8ac1a89fff0b85a
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/WTAS-SnQ_rnriMPGSMkrH.jpeg?w=200&h=200&f=face
      fullname: FancyZhao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FancyZhao
      type: user
    createdAt: '2023-11-05T06:58:58.000Z'
    data:
      edited: false
      editors:
      - FancyZhao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7461419105529785
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/WTAS-SnQ_rnriMPGSMkrH.jpeg?w=200&h=200&f=face
          fullname: FancyZhao
          isHf: false
          isPro: false
          name: FancyZhao
          type: user
        html: "<blockquote>\n<p>Please help make peft fine tuning with hf transformers\
          \ work.</p>\n</blockquote>\n<p>Will do!</p>\n<p>And please watch our <a\
          \ rel=\"nofollow\" href=\"https://github.com/01-ai/Yi\">github repo</a>\
          \ for the latest progress. \U0001F917</p>\n"
        raw: "> Please help make peft fine tuning with hf transformers work.\n\nWill\
          \ do!\n\nAnd please watch our [github repo](https://github.com/01-ai/Yi)\
          \ for the latest progress. \U0001F917"
        updatedAt: '2023-11-05T06:58:58.817Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - KnutJaegersberg
    id: 65473d3262fae6b2a76576a0
    type: comment
  author: FancyZhao
  content: "> Please help make peft fine tuning with hf transformers work.\n\nWill\
    \ do!\n\nAnd please watch our [github repo](https://github.com/01-ai/Yi) for the\
    \ latest progress. \U0001F917"
  created_at: 2023-11-05 05:58:58+00:00
  edited: false
  hidden: false
  id: 65473d3262fae6b2a76576a0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: 01-ai/Yi-34B
repo_type: model
status: closed
target_branch: null
title: fine-tuning with autotrain-advanced
