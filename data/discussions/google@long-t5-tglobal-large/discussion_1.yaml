!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rgallardo
conflicting_files: null
created_at: 2022-12-08 17:15:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/71736b8d6e9f79b382ba91cbb90a532e.svg
      fullname: Rodrigo Gallardo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rgallardo
      type: user
    createdAt: '2022-12-08T17:15:59.000Z'
    data:
      edited: true
      editors:
      - rgallardo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/71736b8d6e9f79b382ba91cbb90a532e.svg
          fullname: Rodrigo Gallardo
          isHf: false
          isPro: false
          name: rgallardo
          type: user
        html: '<p>The model is bugged and is not responding okay. Here''s an example:</p>

          <p><strong>Input:</strong></p>

          <p>"LongT5 model is an encoder-decoder transformer pre-trained in a text-to-text
          denoising generative setting (Pegasus-like generation pre-training). LongT5
          model is an extension of T5 model, and it enables using one of the two different
          efficient attention mechanisms - (1) Local attention, or (2) Transient-Global
          attention. The usage of attention sparsity patterns allows the model to
          efficiently handle input sequence.</p>

          <p>LongT5 is particularly effective when fine-tuned for text generation
          (summarization, question answering) which requires handling long input sequences
          (up to 16,384 tokens)."</p>

          <p><strong>Output:</strong></p>

          <p>"matematic matematic orchid orchid orchid orchid orchid orchid orchid
          orchid orchid orchid orchid orchid orchid orchid orchid orchid orchid"</p>

          <p>The same happens with other examples.</p>

          '
        raw: 'The model is bugged and is not responding okay. Here''s an example:


          **Input:**


          "LongT5 model is an encoder-decoder transformer pre-trained in a text-to-text
          denoising generative setting (Pegasus-like generation pre-training). LongT5
          model is an extension of T5 model, and it enables using one of the two different
          efficient attention mechanisms - (1) Local attention, or (2) Transient-Global
          attention. The usage of attention sparsity patterns allows the model to
          efficiently handle input sequence.


          LongT5 is particularly effective when fine-tuned for text generation (summarization,
          question answering) which requires handling long input sequences (up to
          16,384 tokens)."


          **Output:**


          "matematic matematic orchid orchid orchid orchid orchid orchid orchid orchid
          orchid orchid orchid orchid orchid orchid orchid orchid orchid"


          The same happens with other examples.'
        updatedAt: '2022-12-08T17:19:14.963Z'
      numEdits: 1
      reactions: []
    id: 63921bcf31198e00e4600040
    type: comment
  author: rgallardo
  content: 'The model is bugged and is not responding okay. Here''s an example:


    **Input:**


    "LongT5 model is an encoder-decoder transformer pre-trained in a text-to-text
    denoising generative setting (Pegasus-like generation pre-training). LongT5 model
    is an extension of T5 model, and it enables using one of the two different efficient
    attention mechanisms - (1) Local attention, or (2) Transient-Global attention.
    The usage of attention sparsity patterns allows the model to efficiently handle
    input sequence.


    LongT5 is particularly effective when fine-tuned for text generation (summarization,
    question answering) which requires handling long input sequences (up to 16,384
    tokens)."


    **Output:**


    "matematic matematic orchid orchid orchid orchid orchid orchid orchid orchid orchid
    orchid orchid orchid orchid orchid orchid orchid orchid"


    The same happens with other examples.'
  created_at: 2022-12-08 17:15:59+00:00
  edited: true
  hidden: false
  id: 63921bcf31198e00e4600040
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bab88908e891199de4ad89e0fbe2c8ba.svg
      fullname: Tyler Vergho
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tvergho
      type: user
    createdAt: '2023-03-13T16:27:40.000Z'
    data:
      edited: false
      editors:
      - tvergho
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bab88908e891199de4ad89e0fbe2c8ba.svg
          fullname: Tyler Vergho
          isHf: false
          isPro: false
          name: tvergho
          type: user
        html: '<p>I am also having a similar issue. On both fine-tuned and base versions
          of this model, I get output on a simple summarization task like the following:</p>

          <p>" informal informal Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt
          Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt
          Kontakt Kontakt Kontakt Kontakt"<br>" the a a a a a a a a a a a a a a a
          a a a a a a a a a a a a a a a a a a a a a"</p>

          '
        raw: 'I am also having a similar issue. On both fine-tuned and base versions
          of this model, I get output on a simple summarization task like the following:


          "<pad> informal informal Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt
          Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt
          Kontakt Kontakt Kontakt Kontakt Kontakt"

          "<pad> the a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a
          a a a a a"'
        updatedAt: '2023-03-13T16:27:40.022Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - YuhanLiu11
    id: 640f4efcb63b6f18522cee56
    type: comment
  author: tvergho
  content: 'I am also having a similar issue. On both fine-tuned and base versions
    of this model, I get output on a simple summarization task like the following:


    "<pad> informal informal Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt
    Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt
    Kontakt Kontakt Kontakt"

    "<pad> the a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a
    a a"'
  created_at: 2023-03-13 15:27:40+00:00
  edited: false
  hidden: false
  id: 640f4efcb63b6f18522cee56
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62f8b731ebd15ad7b5af6cee/cg0VkLeobAl1hbfeSpVIH.jpeg?w=200&h=200&f=face
      fullname: Jonas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Joemgu
      type: user
    createdAt: '2023-05-25T19:33:16.000Z'
    data:
      edited: true
      editors:
      - Joemgu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62f8b731ebd15ad7b5af6cee/cg0VkLeobAl1hbfeSpVIH.jpeg?w=200&h=200&f=face
          fullname: Jonas
          isHf: false
          isPro: false
          name: Joemgu
          type: user
        html: '<blockquote>

          <p>I am also having a similar issue. On both fine-tuned and base versions
          of this model, I get output on a simple summarization task like the following:</p>

          <p>" informal informal Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt
          Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt
          Kontakt Kontakt Kontakt Kontakt"<br>" the a a a a a a a a a a a a a a a
          a a a a a a a a a a a a a a a a a a a a a"</p>

          </blockquote>

          <p>Which precision are you running the model at? I have noticed some issues
          when trying to load it in 16-bit, maybe that might be an issue? Try to run
          it with <code>torch_dtype=torch.float32</code> or just omit the dtype argument
          when loading the model.</p>

          '
        raw: "> I am also having a similar issue. On both fine-tuned and base versions\
          \ of this model, I get output on a simple summarization task like the following:\n\
          > \n> \"<pad> informal informal Kontakt Kontakt Kontakt Kontakt Kontakt\
          \ Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt\
          \ Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt\"\n> \"<pad> the a a a\
          \ a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a\"\n\n\
          Which precision are you running the model at? I have noticed some issues\
          \ when trying to load it in 16-bit, maybe that might be an issue? Try to\
          \ run it with `torch_dtype=torch.float32` or just omit the dtype argument\
          \ when loading the model."
        updatedAt: '2023-05-25T19:33:43.006Z'
      numEdits: 1
      reactions: []
    id: 646fb7fc150f4cab86319e8e
    type: comment
  author: Joemgu
  content: "> I am also having a similar issue. On both fine-tuned and base versions\
    \ of this model, I get output on a simple summarization task like the following:\n\
    > \n> \"<pad> informal informal Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt\
    \ Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt Kontakt\
    \ Kontakt Kontakt Kontakt Kontakt\"\n> \"<pad> the a a a a a a a a a a a a a a\
    \ a a a a a a a a a a a a a a a a a a a a a a\"\n\nWhich precision are you running\
    \ the model at? I have noticed some issues when trying to load it in 16-bit, maybe\
    \ that might be an issue? Try to run it with `torch_dtype=torch.float32` or just\
    \ omit the dtype argument when loading the model."
  created_at: 2023-05-25 18:33:16+00:00
  edited: true
  hidden: false
  id: 646fb7fc150f4cab86319e8e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: google/long-t5-tglobal-large
repo_type: model
status: open
target_branch: null
title: "\U0001F6A9 Report"
