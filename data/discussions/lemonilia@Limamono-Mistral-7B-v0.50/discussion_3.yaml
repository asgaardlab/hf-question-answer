!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jasonjschwartz
conflicting_files: null
created_at: 2023-12-21 04:01:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3330f40bf5649d7eeeb223b25e05a05b.svg
      fullname: jason schwartz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jasonjschwartz
      type: user
    createdAt: '2023-12-21T04:01:43.000Z'
    data:
      edited: false
      editors:
      - jasonjschwartz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5510805249214172
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3330f40bf5649d7eeeb223b25e05a05b.svg
          fullname: jason schwartz
          isHf: false
          isPro: false
          name: jasonjschwartz
          type: user
        html: '<p>OSError: Incorrect path_or_model_id: ''/home/anon/AI-Models/LLM/Mistral-7B-v0.1/''.
          Please provide either the path to a local folder or the repo_id of a model
          on the Hub.</p>

          <p>using latest version of all dependencies</p>

          '
        raw: "OSError: Incorrect path_or_model_id: '/home/anon/AI-Models/LLM/Mistral-7B-v0.1/'.\
          \ Please provide either the path to a local folder or the repo_id of a model\
          \ on the Hub.\r\n\r\nusing latest version of all dependencies"
        updatedAt: '2023-12-21T04:01:43.933Z'
      numEdits: 0
      reactions: []
    id: 6583b8a764188479685355af
    type: comment
  author: jasonjschwartz
  content: "OSError: Incorrect path_or_model_id: '/home/anon/AI-Models/LLM/Mistral-7B-v0.1/'.\
    \ Please provide either the path to a local folder or the repo_id of a model on\
    \ the Hub.\r\n\r\nusing latest version of all dependencies"
  created_at: 2023-12-21 04:01:43+00:00
  edited: false
  hidden: false
  id: 6583b8a764188479685355af
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
      fullname: Suikamelon
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lemonilia
      type: user
    createdAt: '2023-12-21T09:53:23.000Z'
    data:
      edited: false
      editors:
      - lemonilia
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9482263326644897
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
          fullname: Suikamelon
          isHf: false
          isPro: false
          name: lemonilia
          type: user
        html: '<p>I''m not sure what you''re trying to achieve, but the repository
          does not contain the full 16-bit HuggingFace weights, only GGUF quantizations
          and a LoRA adapter that you can merge with the base Mistral-7B-v0.1 model
          (not included).</p>

          '
        raw: I'm not sure what you're trying to achieve, but the repository does not
          contain the full 16-bit HuggingFace weights, only GGUF quantizations and
          a LoRA adapter that you can merge with the base Mistral-7B-v0.1 model (not
          included).
        updatedAt: '2023-12-21T09:53:23.167Z'
      numEdits: 0
      reactions: []
    id: 65840b131fb17c3a9abb9aa9
    type: comment
  author: lemonilia
  content: I'm not sure what you're trying to achieve, but the repository does not
    contain the full 16-bit HuggingFace weights, only GGUF quantizations and a LoRA
    adapter that you can merge with the base Mistral-7B-v0.1 model (not included).
  created_at: 2023-12-21 09:53:23+00:00
  edited: false
  hidden: false
  id: 65840b131fb17c3a9abb9aa9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3330f40bf5649d7eeeb223b25e05a05b.svg
      fullname: jason schwartz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jasonjschwartz
      type: user
    createdAt: '2023-12-21T14:28:39.000Z'
    data:
      edited: false
      editors:
      - jasonjschwartz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9732553362846375
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3330f40bf5649d7eeeb223b25e05a05b.svg
          fullname: jason schwartz
          isHf: false
          isPro: false
          name: jasonjschwartz
          type: user
        html: '<p>Ah both the GGUF and LoRa adapter get merged? Or just the adapter?</p>

          <p>Sorry I have experience with Peft, but have not merged models</p>

          '
        raw: 'Ah both the GGUF and LoRa adapter get merged? Or just the adapter?


          Sorry I have experience with Peft, but have not merged models'
        updatedAt: '2023-12-21T14:28:39.645Z'
      numEdits: 0
      reactions: []
    id: 65844b9756d225548b459502
    type: comment
  author: jasonjschwartz
  content: 'Ah both the GGUF and LoRa adapter get merged? Or just the adapter?


    Sorry I have experience with Peft, but have not merged models'
  created_at: 2023-12-21 14:28:39+00:00
  edited: false
  hidden: false
  id: 65844b9756d225548b459502
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
      fullname: Suikamelon
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lemonilia
      type: user
    createdAt: '2023-12-21T14:35:45.000Z'
    data:
      edited: false
      editors:
      - lemonilia
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8881160616874695
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63065221435ec751b72998f5/687FH-lJaPiU-D-Lqkduw.png?w=200&h=200&f=face
          fullname: Suikamelon
          isHf: false
          isPro: false
          name: lemonilia
          type: user
        html: '<p>The GGUF models are already merged. They can be used as-is with
          Koboldcpp, text-generation-webui, etc.<br>The adapter needs the full FP16
          Mistral-7B weights (not included here).</p>

          '
        raw: 'The GGUF models are already merged. They can be used as-is with Koboldcpp,
          text-generation-webui, etc.

          The adapter needs the full FP16 Mistral-7B weights (not included here).'
        updatedAt: '2023-12-21T14:35:45.067Z'
      numEdits: 0
      reactions: []
    id: 65844d416064483c603b6b93
    type: comment
  author: lemonilia
  content: 'The GGUF models are already merged. They can be used as-is with Koboldcpp,
    text-generation-webui, etc.

    The adapter needs the full FP16 Mistral-7B weights (not included here).'
  created_at: 2023-12-21 14:35:45+00:00
  edited: false
  hidden: false
  id: 65844d416064483c603b6b93
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: lemonilia/Limamono-Mistral-7B-v0.50
repo_type: model
status: open
target_branch: null
title: Error loading model
