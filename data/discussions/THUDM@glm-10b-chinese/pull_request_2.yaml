!!python/object:huggingface_hub.community.DiscussionWithDetails
author: larrylawl
conflicting_files: []
created_at: 2023-04-05 04:20:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/efa440a020cdf487a3ffbe91d1d08fc9.svg
      fullname: Law Ann Liat Larry
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: larrylawl
      type: user
    createdAt: '2023-04-05T05:20:50.000Z'
    data:
      edited: true
      editors:
      - larrylawl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/efa440a020cdf487a3ffbe91d1d08fc9.svg
          fullname: Law Ann Liat Larry
          isHf: false
          isPro: false
          name: larrylawl
          type: user
        html: "<p>Support accelerate for GLM. Example code to run in 8 bit inference:</p>\n\
          <pre><code>from transformers import AutoModelForSeq2SeqLM\n\ndevice_map={'glm.word_embeddings':\
          \ 0,\n 'glm.transformer.embedding_dropout': 0,\n 'glm.transformer.position_embeddings':\
          \ 0,\n 'glm.transformer.block_position_embeddings': 0,\n 'glm.transformer.layers.0':\
          \ 0,\n 'glm.transformer.layers.1': 0,\n 'glm.transformer.layers.2': 0,\n\
          \ 'glm.transformer.layers.3': 0,\n 'glm.transformer.layers.4': 0,\n 'glm.transformer.layers.5':\
          \ 0,\n 'glm.transformer.layers.6': 0,\n 'glm.transformer.layers.7': 0,\n\
          \ 'glm.transformer.layers.8': 0,\n 'glm.transformer.layers.9': 0,\n 'glm.transformer.layers.10':\
          \ 0,\n 'glm.transformer.layers.11': 0,\n 'glm.transformer.layers.12': 0,\n\
          \ 'glm.transformer.layers.13': 0,\n 'glm.transformer.layers.14': 0,\n 'glm.transformer.layers.15':\
          \ 0,\n 'glm.transformer.layers.16': 0,\n 'glm.transformer.layers.17': 0,\n\
          \ 'glm.transformer.layers.18': 0,\n 'glm.transformer.layers.19': 0,\n 'glm.transformer.layers.20':\
          \ 0,\n 'glm.transformer.layers.21': 0,\n 'glm.transformer.layers.22': 0,\n\
          \ 'glm.transformer.layers.23': 0,\n 'glm.transformer.layers.24': 0,\n 'glm.transformer.layers.25':\
          \ 0,\n 'glm.transformer.layers.26': 0,\n 'glm.transformer.layers.27': 0,\n\
          \ 'glm.transformer.layers.28': 0,\n 'glm.transformer.layers.29': 0,\n 'glm.transformer.layers.30':\
          \ 0,\n 'glm.transformer.layers.31': 0,\n 'glm.transformer.layers.32': 0,\n\
          \ 'glm.transformer.layers.33': 0,\n 'glm.transformer.layers.34': 0,\n 'glm.transformer.layers.35':\
          \ 0,\n 'glm.transformer.layers.36': 0,\n 'glm.transformer.layers.37': 0,\n\
          \ 'glm.transformer.layers.38': 0,\n 'glm.transformer.layers.39': 0,\n 'glm.transformer.layers.40':\
          \ 0,\n 'glm.transformer.layers.41': 0,\n 'glm.transformer.layers.42': 0,\n\
          \ 'glm.transformer.layers.43': 0,\n 'glm.transformer.layers.44': 0,\n 'glm.transformer.layers.45':\
          \ 0,\n 'glm.transformer.layers.46': 0,\n 'glm.transformer.layers.47': 0,\n\
          \ 'glm.transformer.final_layernorm': 0}\n\n# ours\nmodel_name_or_path =\
          \ \"THUDM/glm-10b-chinese\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path,\n\
          \                                    trust_remote_code=True, \n        \
          \                            revision=\"6adb492\",\n                   \
          \                 device_map=device_map,\n                             \
          \       load_in_8bit=True,\n                                    )\nmodel.eval()\n\
          </code></pre>\n"
        raw: "Support accelerate for GLM. Example code to run in 8 bit inference:\n\
          \n```\nfrom transformers import AutoModelForSeq2SeqLM\n\ndevice_map={'glm.word_embeddings':\
          \ 0,\n 'glm.transformer.embedding_dropout': 0,\n 'glm.transformer.position_embeddings':\
          \ 0,\n 'glm.transformer.block_position_embeddings': 0,\n 'glm.transformer.layers.0':\
          \ 0,\n 'glm.transformer.layers.1': 0,\n 'glm.transformer.layers.2': 0,\n\
          \ 'glm.transformer.layers.3': 0,\n 'glm.transformer.layers.4': 0,\n 'glm.transformer.layers.5':\
          \ 0,\n 'glm.transformer.layers.6': 0,\n 'glm.transformer.layers.7': 0,\n\
          \ 'glm.transformer.layers.8': 0,\n 'glm.transformer.layers.9': 0,\n 'glm.transformer.layers.10':\
          \ 0,\n 'glm.transformer.layers.11': 0,\n 'glm.transformer.layers.12': 0,\n\
          \ 'glm.transformer.layers.13': 0,\n 'glm.transformer.layers.14': 0,\n 'glm.transformer.layers.15':\
          \ 0,\n 'glm.transformer.layers.16': 0,\n 'glm.transformer.layers.17': 0,\n\
          \ 'glm.transformer.layers.18': 0,\n 'glm.transformer.layers.19': 0,\n 'glm.transformer.layers.20':\
          \ 0,\n 'glm.transformer.layers.21': 0,\n 'glm.transformer.layers.22': 0,\n\
          \ 'glm.transformer.layers.23': 0,\n 'glm.transformer.layers.24': 0,\n 'glm.transformer.layers.25':\
          \ 0,\n 'glm.transformer.layers.26': 0,\n 'glm.transformer.layers.27': 0,\n\
          \ 'glm.transformer.layers.28': 0,\n 'glm.transformer.layers.29': 0,\n 'glm.transformer.layers.30':\
          \ 0,\n 'glm.transformer.layers.31': 0,\n 'glm.transformer.layers.32': 0,\n\
          \ 'glm.transformer.layers.33': 0,\n 'glm.transformer.layers.34': 0,\n 'glm.transformer.layers.35':\
          \ 0,\n 'glm.transformer.layers.36': 0,\n 'glm.transformer.layers.37': 0,\n\
          \ 'glm.transformer.layers.38': 0,\n 'glm.transformer.layers.39': 0,\n 'glm.transformer.layers.40':\
          \ 0,\n 'glm.transformer.layers.41': 0,\n 'glm.transformer.layers.42': 0,\n\
          \ 'glm.transformer.layers.43': 0,\n 'glm.transformer.layers.44': 0,\n 'glm.transformer.layers.45':\
          \ 0,\n 'glm.transformer.layers.46': 0,\n 'glm.transformer.layers.47': 0,\n\
          \ 'glm.transformer.final_layernorm': 0}\n\n# ours\nmodel_name_or_path =\
          \ \"THUDM/glm-10b-chinese\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path,\n\
          \                                    trust_remote_code=True, \n        \
          \                            revision=\"6adb492\",\n                   \
          \                 device_map=device_map,\n                             \
          \       load_in_8bit=True,\n                                    )\nmodel.eval()\n\
          ```"
        updatedAt: '2023-04-07T03:35:03.168Z'
      numEdits: 2
      reactions: []
    id: 642d05329efab84585ef949e
    type: comment
  author: larrylawl
  content: "Support accelerate for GLM. Example code to run in 8 bit inference:\n\n\
    ```\nfrom transformers import AutoModelForSeq2SeqLM\n\ndevice_map={'glm.word_embeddings':\
    \ 0,\n 'glm.transformer.embedding_dropout': 0,\n 'glm.transformer.position_embeddings':\
    \ 0,\n 'glm.transformer.block_position_embeddings': 0,\n 'glm.transformer.layers.0':\
    \ 0,\n 'glm.transformer.layers.1': 0,\n 'glm.transformer.layers.2': 0,\n 'glm.transformer.layers.3':\
    \ 0,\n 'glm.transformer.layers.4': 0,\n 'glm.transformer.layers.5': 0,\n 'glm.transformer.layers.6':\
    \ 0,\n 'glm.transformer.layers.7': 0,\n 'glm.transformer.layers.8': 0,\n 'glm.transformer.layers.9':\
    \ 0,\n 'glm.transformer.layers.10': 0,\n 'glm.transformer.layers.11': 0,\n 'glm.transformer.layers.12':\
    \ 0,\n 'glm.transformer.layers.13': 0,\n 'glm.transformer.layers.14': 0,\n 'glm.transformer.layers.15':\
    \ 0,\n 'glm.transformer.layers.16': 0,\n 'glm.transformer.layers.17': 0,\n 'glm.transformer.layers.18':\
    \ 0,\n 'glm.transformer.layers.19': 0,\n 'glm.transformer.layers.20': 0,\n 'glm.transformer.layers.21':\
    \ 0,\n 'glm.transformer.layers.22': 0,\n 'glm.transformer.layers.23': 0,\n 'glm.transformer.layers.24':\
    \ 0,\n 'glm.transformer.layers.25': 0,\n 'glm.transformer.layers.26': 0,\n 'glm.transformer.layers.27':\
    \ 0,\n 'glm.transformer.layers.28': 0,\n 'glm.transformer.layers.29': 0,\n 'glm.transformer.layers.30':\
    \ 0,\n 'glm.transformer.layers.31': 0,\n 'glm.transformer.layers.32': 0,\n 'glm.transformer.layers.33':\
    \ 0,\n 'glm.transformer.layers.34': 0,\n 'glm.transformer.layers.35': 0,\n 'glm.transformer.layers.36':\
    \ 0,\n 'glm.transformer.layers.37': 0,\n 'glm.transformer.layers.38': 0,\n 'glm.transformer.layers.39':\
    \ 0,\n 'glm.transformer.layers.40': 0,\n 'glm.transformer.layers.41': 0,\n 'glm.transformer.layers.42':\
    \ 0,\n 'glm.transformer.layers.43': 0,\n 'glm.transformer.layers.44': 0,\n 'glm.transformer.layers.45':\
    \ 0,\n 'glm.transformer.layers.46': 0,\n 'glm.transformer.layers.47': 0,\n 'glm.transformer.final_layernorm':\
    \ 0}\n\n# ours\nmodel_name_or_path = \"THUDM/glm-10b-chinese\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path,\n\
    \                                    trust_remote_code=True, \n              \
    \                      revision=\"6adb492\",\n                               \
    \     device_map=device_map,\n                                    load_in_8bit=True,\n\
    \                                    )\nmodel.eval()\n```"
  created_at: 2023-04-05 04:20:50+00:00
  edited: true
  hidden: false
  id: 642d05329efab84585ef949e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/efa440a020cdf487a3ffbe91d1d08fc9.svg
      fullname: Law Ann Liat Larry
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: larrylawl
      type: user
    createdAt: '2023-04-05T05:20:51.000Z'
    data:
      oid: 6adb4922cffa84ee01c7a5c3598c46e88f3d0b3a
      parents:
      - 01717dd11fb4d3a80c465eee9eb4789bc954046d
      subject: '[WIP] Support accelerate for GLM'
    id: 642d05330000000000000000
    type: commit
  author: larrylawl
  created_at: 2023-04-05 04:20:51+00:00
  id: 642d05330000000000000000
  oid: 6adb4922cffa84ee01c7a5c3598c46e88f3d0b3a
  summary: '[WIP] Support accelerate for GLM'
  type: commit
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/efa440a020cdf487a3ffbe91d1d08fc9.svg
      fullname: Law Ann Liat Larry
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: larrylawl
      type: user
    createdAt: '2023-04-07T03:34:02.000Z'
    data:
      from: '[WIP] Support accelerate for GLM'
      to: Support accelerate for GLM
    id: 642f8f2a0a013b879bfdef8c
    type: title-change
  author: larrylawl
  created_at: 2023-04-07 02:34:02+00:00
  id: 642f8f2a0a013b879bfdef8c
  new_title: Support accelerate for GLM
  old_title: '[WIP] Support accelerate for GLM'
  type: title-change
is_pull_request: true
merge_commit_oid: null
num: 2
repo_id: THUDM/glm-10b-chinese
repo_type: model
status: open
target_branch: refs/heads/main
title: Support accelerate for GLM
