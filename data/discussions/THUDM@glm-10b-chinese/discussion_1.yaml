!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bupalinyu
conflicting_files: null
created_at: 2023-03-08 08:36:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e1ae41d144302aa64dd2f7e244d4511d.svg
      fullname: yumu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bupalinyu
      type: user
    createdAt: '2023-03-08T08:36:47.000Z'
    data:
      edited: false
      editors:
      - bupalinyu
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e1ae41d144302aa64dd2f7e244d4511d.svg
          fullname: yumu
          isHf: false
          isPro: false
          name: bupalinyu
          type: user
        html: "<p>I just got an error below, any idea to fix it<br>[main-process]\
          \ [2023-03-08 16:21:58,708] [INFO] [runner.py:635:report_job_message] update\
          \ modelhub job message with job_id=1547002696 message={\"pod\": \"aistudio-izpxpuje-ptjob-master-0\"\
          , \"type\": \"RuntimeError\", \"message\": \"RuntimeError:expected self\
          \ and mask to be on the same device, but got mask on cpu and self on cuda:0\"\
          }<br>[main-process] [2023-03-08 16:21:58,876] [INFO] [runner.py:594:remote_run]\
          \ Traceback (most recent call last):<br>\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/runner.py\"\
          , line 592, in remote_run<br>\u2003\u2003\u2003\u2003ret = self.start()<br>\u2003\
          \u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/base.py\"\
          , line 640, in start<br>\u2003\u2003\u2003\u2003ret = self.run()<br>\u2003\
          \u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
          , line 738, in run<br>\u2003\u2003\u2003\u2003self._run_single(role_num,\
          \ work_num)<br>\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
          , line 1198, in _run_single<br>\u2003\u2003\u2003\u2003records = self._do_predict(batch_input,\
          \ predictor, trace_flag)<br>\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
          , line 1325, in _do_predict<br>\u2003\u2003\u2003\u2003predict_results =\
          \ predictor(feed_tensors)<br>\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
          , line 243, in <strong>call</strong><br>\u2003\u2003\u2003\u2003return self.predict(*args,\
          \ **kwargs)<br>\u2003\u2003File \".//model_predict.py\", line 99, in predict<br>\u2003\
          \u2003\u2003\u2003raise e<br>\u2003\u2003File \".//model_predict.py\", line\
          \ 80, in predict<br>\u2003\u2003\u2003\u2003preds = self.model(<br>\u2003\
          \u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl<br>\u2003\u2003\u2003\u2003return forward_call(*input,\
          \ **kwargs)<br>\u2003\u2003File \"/workspace/base_module.py\", line 64,\
          \ in forward<br>\u2003\u2003\u2003\u2003return self.model.generate(<br>\u2003\
          \u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context<br>\u2003\u2003\u2003\u2003return func(*args,\
          \ **kwargs)<br>\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/transformers/generation/utils.py\"\
          , line 1652, in generate<br>\u2003\u2003\u2003\u2003return self.beam_sample(<br>\u2003\
          \u2003File \"/root/miniconda3/lib/python3.8/site-packages/transformers/generation/utils.py\"\
          , line 3111, in beam_sample<br>\u2003\u2003\u2003\u2003outputs = self(<br>\u2003\
          \u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl<br>\u2003\u2003\u2003\u2003return forward_call(*input,\
          \ **kwargs)<br>\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
          , line 902, in forward<br>\u2003\u2003\u2003\u2003model_output = self.glm(input_ids,\
          \ position_ids, attention_mask, mems=mems, **kwargs)<br>\u2003\u2003File\
          \ \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl<br>\u2003\u2003\u2003\u2003return forward_call(*input,\
          \ **kwargs)<br>\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
          , line 783, in forward<br>\u2003\u2003\u2003\u2003transformer_output = self.transformer(embeddings,\
          \ position_ids, attention_mask, mems)<br>\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl<br>\u2003\u2003\u2003\u2003return forward_call(*input,\
          \ **kwargs)<br>\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
          , line 554, in forward<br>\u2003\u2003\u2003\u2003attention_mask = build_mask_matrix(query_length,\
          \ sep, memory_length=memory_length)<br>\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
          , line 547, in build_mask_matrix<br>\u2003\u2003\u2003\u2003m = m.masked_fill(mask.unsqueeze(1).expand_as(m),\
          \ 1)<br>RuntimeError: expected self and mask to be on the same device, but\
          \ got mask on cpu and self on cuda:0</p>\n"
        raw: "I just got an error below, any idea to fix it\r\n[main-process] [2023-03-08\
          \ 16:21:58,708] [INFO] [runner.py:635:report_job_message] update modelhub\
          \ job message with job_id=1547002696 message={\"pod\": \"aistudio-izpxpuje-ptjob-master-0\"\
          , \"type\": \"RuntimeError\", \"message\": \"RuntimeError:expected self\
          \ and mask to be on the same device, but got mask on cpu and self on cuda:0\"\
          }\r\n[main-process] [2023-03-08 16:21:58,876] [INFO] [runner.py:594:remote_run]\
          \ Traceback (most recent call last):\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/runner.py\"\
          , line 592, in remote_run\r\n\u2003\u2003\u2003\u2003ret = self.start()\r\
          \n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/base.py\"\
          , line 640, in start\r\n\u2003\u2003\u2003\u2003ret = self.run()\r\n\u2003\
          \u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
          , line 738, in run\r\n\u2003\u2003\u2003\u2003self._run_single(role_num,\
          \ work_num)\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
          , line 1198, in _run_single\r\n\u2003\u2003\u2003\u2003records = self._do_predict(batch_input,\
          \ predictor, trace_flag)\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
          , line 1325, in _do_predict\r\n\u2003\u2003\u2003\u2003predict_results =\
          \ predictor(feed_tensors)\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
          , line 243, in __call__\r\n\u2003\u2003\u2003\u2003return self.predict(*args,\
          \ **kwargs)\r\n\u2003\u2003File \".//model_predict.py\", line 99, in predict\r\
          \n\u2003\u2003\u2003\u2003raise e\r\n\u2003\u2003File \".//model_predict.py\"\
          , line 80, in predict\r\n\u2003\u2003\u2003\u2003preds = self.model(\r\n\
          \u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n\u2003\u2003\u2003\u2003return forward_call(*input,\
          \ **kwargs)\r\n\u2003\u2003File \"/workspace/base_module.py\", line 64,\
          \ in forward\r\n\u2003\u2003\u2003\u2003return self.model.generate(\r\n\u2003\
          \u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\r\n\u2003\u2003\u2003\u2003return func(*args,\
          \ **kwargs)\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/transformers/generation/utils.py\"\
          , line 1652, in generate\r\n\u2003\u2003\u2003\u2003return self.beam_sample(\r\
          \n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/transformers/generation/utils.py\"\
          , line 3111, in beam_sample\r\n\u2003\u2003\u2003\u2003outputs = self(\r\
          \n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n\u2003\u2003\u2003\u2003return forward_call(*input,\
          \ **kwargs)\r\n\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
          , line 902, in forward\r\n\u2003\u2003\u2003\u2003model_output = self.glm(input_ids,\
          \ position_ids, attention_mask, mems=mems, **kwargs)\r\n\u2003\u2003File\
          \ \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n\u2003\u2003\u2003\u2003return forward_call(*input,\
          \ **kwargs)\r\n\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
          , line 783, in forward\r\n\u2003\u2003\u2003\u2003transformer_output = self.transformer(embeddings,\
          \ position_ids, attention_mask, mems)\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
          , line 1110, in _call_impl\r\n\u2003\u2003\u2003\u2003return forward_call(*input,\
          \ **kwargs)\r\n\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
          , line 554, in forward\r\n\u2003\u2003\u2003\u2003attention_mask = build_mask_matrix(query_length,\
          \ sep, memory_length=memory_length)\r\n\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
          , line 547, in build_mask_matrix\r\n\u2003\u2003\u2003\u2003m = m.masked_fill(mask.unsqueeze(1).expand_as(m),\
          \ 1)\r\nRuntimeError: expected self and mask to be on the same device, but\
          \ got mask on cpu and self on cuda:0"
        updatedAt: '2023-03-08T08:36:47.401Z'
      numEdits: 0
      reactions: []
    id: 6408491f829c2aedb104e3c2
    type: comment
  author: bupalinyu
  content: "I just got an error below, any idea to fix it\r\n[main-process] [2023-03-08\
    \ 16:21:58,708] [INFO] [runner.py:635:report_job_message] update modelhub job\
    \ message with job_id=1547002696 message={\"pod\": \"aistudio-izpxpuje-ptjob-master-0\"\
    , \"type\": \"RuntimeError\", \"message\": \"RuntimeError:expected self and mask\
    \ to be on the same device, but got mask on cpu and self on cuda:0\"}\r\n[main-process]\
    \ [2023-03-08 16:21:58,876] [INFO] [runner.py:594:remote_run] Traceback (most\
    \ recent call last):\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/runner.py\"\
    , line 592, in remote_run\r\n\u2003\u2003\u2003\u2003ret = self.start()\r\n\u2003\
    \u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/base.py\"\
    , line 640, in start\r\n\u2003\u2003\u2003\u2003ret = self.run()\r\n\u2003\u2003\
    File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
    , line 738, in run\r\n\u2003\u2003\u2003\u2003self._run_single(role_num, work_num)\r\
    \n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
    , line 1198, in _run_single\r\n\u2003\u2003\u2003\u2003records = self._do_predict(batch_input,\
    \ predictor, trace_flag)\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
    , line 1325, in _do_predict\r\n\u2003\u2003\u2003\u2003predict_results = predictor(feed_tensors)\r\
    \n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/alps/framework/predictor.py\"\
    , line 243, in __call__\r\n\u2003\u2003\u2003\u2003return self.predict(*args,\
    \ **kwargs)\r\n\u2003\u2003File \".//model_predict.py\", line 99, in predict\r\
    \n\u2003\u2003\u2003\u2003raise e\r\n\u2003\u2003File \".//model_predict.py\"\
    , line 80, in predict\r\n\u2003\u2003\u2003\u2003preds = self.model(\r\n\u2003\
    \u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n\u2003\u2003\u2003\u2003return forward_call(*input,\
    \ **kwargs)\r\n\u2003\u2003File \"/workspace/base_module.py\", line 64, in forward\r\
    \n\u2003\u2003\u2003\u2003return self.model.generate(\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\"\
    , line 27, in decorate_context\r\n\u2003\u2003\u2003\u2003return func(*args, **kwargs)\r\
    \n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/transformers/generation/utils.py\"\
    , line 1652, in generate\r\n\u2003\u2003\u2003\u2003return self.beam_sample(\r\
    \n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/transformers/generation/utils.py\"\
    , line 3111, in beam_sample\r\n\u2003\u2003\u2003\u2003outputs = self(\r\n\u2003\
    \u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n\u2003\u2003\u2003\u2003return forward_call(*input,\
    \ **kwargs)\r\n\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
    , line 902, in forward\r\n\u2003\u2003\u2003\u2003model_output = self.glm(input_ids,\
    \ position_ids, attention_mask, mems=mems, **kwargs)\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n\u2003\u2003\u2003\u2003return forward_call(*input,\
    \ **kwargs)\r\n\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
    , line 783, in forward\r\n\u2003\u2003\u2003\u2003transformer_output = self.transformer(embeddings,\
    \ position_ids, attention_mask, mems)\r\n\u2003\u2003File \"/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\"\
    , line 1110, in _call_impl\r\n\u2003\u2003\u2003\u2003return forward_call(*input,\
    \ **kwargs)\r\n\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
    , line 554, in forward\r\n\u2003\u2003\u2003\u2003attention_mask = build_mask_matrix(query_length,\
    \ sep, memory_length=memory_length)\r\n\u2003\u2003File \"/root/.cache/huggingface/modules/transformers_modules/THUDM/glm-10b-chinese/01717dd11fb4d3a80c465eee9eb4789bc954046d/modeling_glm.py\"\
    , line 547, in build_mask_matrix\r\n\u2003\u2003\u2003\u2003m = m.masked_fill(mask.unsqueeze(1).expand_as(m),\
    \ 1)\r\nRuntimeError: expected self and mask to be on the same device, but got\
    \ mask on cpu and self on cuda:0"
  created_at: 2023-03-08 08:36:47+00:00
  edited: false
  hidden: false
  id: 6408491f829c2aedb104e3c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/r9T6LlWwo4bkQ4fTCR1HZ.jpeg?w=200&h=200&f=face
      fullname: wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shellwang
      type: user
    createdAt: '2023-04-01T07:38:09.000Z'
    data:
      edited: false
      editors:
      - shellwang
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/r9T6LlWwo4bkQ4fTCR1HZ.jpeg?w=200&h=200&f=face
          fullname: wang
          isHf: false
          isPro: false
          name: shellwang
          type: user
        html: "<p>RuntimeError: expected self and mask to be on the same device, but\
          \ got mask on cpu and self on cuda:0</p>\n<p>\u8FD9\u4E0D\u662F\u5F88\u660E\
          \u663E\u561B</p>\n"
        raw: "RuntimeError: expected self and mask to be on the same device, but got\
          \ mask on cpu and self on cuda:0\n\n\u8FD9\u4E0D\u662F\u5F88\u660E\u663E\
          \u561B"
        updatedAt: '2023-04-01T07:38:09.845Z'
      numEdits: 0
      reactions: []
    id: 6427df616e9ac4c7a7724a5c
    type: comment
  author: shellwang
  content: "RuntimeError: expected self and mask to be on the same device, but got\
    \ mask on cpu and self on cuda:0\n\n\u8FD9\u4E0D\u662F\u5F88\u660E\u663E\u561B"
  created_at: 2023-04-01 06:38:09+00:00
  edited: false
  hidden: false
  id: 6427df616e9ac4c7a7724a5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bad201031abc8f8c1730f7bc369748c6.svg
      fullname: hong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lanshan
      type: user
    createdAt: '2023-05-23T03:22:36.000Z'
    data:
      edited: false
      editors:
      - lanshan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bad201031abc8f8c1730f7bc369748c6.svg
          fullname: hong
          isHf: false
          isPro: false
          name: lanshan
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;shellwang&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/shellwang\">@<span class=\"\
          underline\">shellwang</span></a></span>\n\n\t</span></span> \u6211\u4E5F\
          \u9047\u5230\u4E86\u8FD9\u4E2A\u95EE\u9898\uFF0C\u4F46\u662F\u4E0D\u592A\
          \u660E\u767D\u4F60\u8BF4\u7684\u610F\u601D\uFF0C\u5E94\u8BE5\u600E\u4E48\
          \u89E3\u51B3\u5462\u3002</p>\n"
        raw: "@shellwang \u6211\u4E5F\u9047\u5230\u4E86\u8FD9\u4E2A\u95EE\u9898\uFF0C\
          \u4F46\u662F\u4E0D\u592A\u660E\u767D\u4F60\u8BF4\u7684\u610F\u601D\uFF0C\
          \u5E94\u8BE5\u600E\u4E48\u89E3\u51B3\u5462\u3002"
        updatedAt: '2023-05-23T03:22:36.514Z'
      numEdits: 0
      reactions: []
    id: 646c317cdb697c798a5717b0
    type: comment
  author: lanshan
  content: "@shellwang \u6211\u4E5F\u9047\u5230\u4E86\u8FD9\u4E2A\u95EE\u9898\uFF0C\
    \u4F46\u662F\u4E0D\u592A\u660E\u767D\u4F60\u8BF4\u7684\u610F\u601D\uFF0C\u5E94\
    \u8BE5\u600E\u4E48\u89E3\u51B3\u5462\u3002"
  created_at: 2023-05-23 02:22:36+00:00
  edited: false
  hidden: false
  id: 646c317cdb697c798a5717b0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1651223619654-626babe1a317717549dd4646.jpeg?w=200&h=200&f=face
      fullname: SHIE
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SHIE
      type: user
    createdAt: '2023-08-28T06:48:24.000Z'
    data:
      edited: false
      editors:
      - SHIE
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5024394989013672
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1651223619654-626babe1a317717549dd4646.jpeg?w=200&h=200&f=face
          fullname: SHIE
          isHf: false
          isPro: false
          name: SHIE
          type: user
        html: "<blockquote>\n<p>RuntimeError: expected self and mask to be on the\
          \ same device, but got mask on cpu and self on cuda:0</p>\n<p>\u8FD9\u4E0D\
          \u662F\u5F88\u660E\u663E\u561B</p>\n</blockquote>\n<p>\u4EC0\u4E48\u8C1C\
          \u8BED\u4EBA</p>\n"
        raw: "> RuntimeError: expected self and mask to be on the same device, but\
          \ got mask on cpu and self on cuda:0\n> \n> \u8FD9\u4E0D\u662F\u5F88\u660E\
          \u663E\u561B\n\n\u4EC0\u4E48\u8C1C\u8BED\u4EBA"
        updatedAt: '2023-08-28T06:48:24.181Z'
      numEdits: 0
      reactions: []
    id: 64ec4338ece58a9799bad2a0
    type: comment
  author: SHIE
  content: "> RuntimeError: expected self and mask to be on the same device, but got\
    \ mask on cpu and self on cuda:0\n> \n> \u8FD9\u4E0D\u662F\u5F88\u660E\u663E\u561B\
    \n\n\u4EC0\u4E48\u8C1C\u8BED\u4EBA"
  created_at: 2023-08-28 05:48:24+00:00
  edited: false
  hidden: false
  id: 64ec4338ece58a9799bad2a0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: THUDM/glm-10b-chinese
repo_type: model
status: open
target_branch: null
title: 'RuntimeError: expected self and mask to be on the same device, but got mask
  on cpu and self on cuda:0'
