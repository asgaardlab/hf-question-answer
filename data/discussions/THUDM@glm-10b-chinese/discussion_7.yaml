!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Yhyu13
conflicting_files: null
created_at: 2023-05-07 11:02:36+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-05-07T12:02:36.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: '<p>Hi, would you like to release the quantized version of glm 10B,
          this would allow to run on a 16GB card which is great</p>

          '
        raw: Hi, would you like to release the quantized version of glm 10B, this
          would allow to run on a 16GB card which is great
        updatedAt: '2023-05-07T12:02:36.905Z'
      numEdits: 0
      reactions: []
    id: 6457935c75f8f7d26aa5fcad
    type: comment
  author: Yhyu13
  content: Hi, would you like to release the quantized version of glm 10B, this would
    allow to run on a 16GB card which is great
  created_at: 2023-05-07 11:02:36+00:00
  edited: false
  hidden: false
  id: 6457935c75f8f7d26aa5fcad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/efa440a020cdf487a3ffbe91d1d08fc9.svg
      fullname: Law Ann Liat Larry
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: larrylawl
      type: user
    createdAt: '2023-06-19T03:57:27.000Z'
    data:
      edited: false
      editors:
      - larrylawl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7561060190200806
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/efa440a020cdf487a3ffbe91d1d08fc9.svg
          fullname: Law Ann Liat Larry
          isHf: false
          isPro: false
          name: larrylawl
          type: user
        html: '<p>Hi, you can check out my <a href="https://huggingface.co/THUDM/glm-10b-chinese/discussions/2">PR</a>
          which allows for in8 quantization. I haven''t tested for in4. </p>

          '
        raw: 'Hi, you can check out my [PR](https://huggingface.co/THUDM/glm-10b-chinese/discussions/2)
          which allows for in8 quantization. I haven''t tested for in4. '
        updatedAt: '2023-06-19T03:57:27.264Z'
      numEdits: 0
      reactions: []
    id: 648fd227f7f5d960da89cd7c
    type: comment
  author: larrylawl
  content: 'Hi, you can check out my [PR](https://huggingface.co/THUDM/glm-10b-chinese/discussions/2)
    which allows for in8 quantization. I haven''t tested for in4. '
  created_at: 2023-06-19 02:57:27+00:00
  edited: false
  hidden: false
  id: 648fd227f7f5d960da89cd7c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: THUDM/glm-10b-chinese
repo_type: model
status: open
target_branch: null
title: int4/8 quantization so that we can deploy on consumer-grid gpu card
