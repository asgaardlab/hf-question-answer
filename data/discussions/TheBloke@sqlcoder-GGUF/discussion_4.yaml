!!python/object:huggingface_hub.community.DiscussionWithDetails
author: stormchaser
conflicting_files: null
created_at: 2023-10-03 07:01:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a585cbfcd1f335b70c101458f7c0b002.svg
      fullname: abubakar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: stormchaser
      type: user
    createdAt: '2023-10-03T08:01:41.000Z'
    data:
      edited: false
      editors:
      - stormchaser
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.20148606598377228
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a585cbfcd1f335b70c101458f7c0b002.svg
          fullname: abubakar
          isHf: false
          isPro: false
          name: stormchaser
          type: user
        html: '<p>i am getting the following while trying to load with llama.cpp,
          any idea how to fix it? all other gguf models are working fine with the
          same main.exe. I have the latest build of llama.cpp<br>...<br>llama_model_loader:
          - kv   0:                       general.architecture str<br>llama_model_loader:
          - kv   1:                               general.name str<br>llama_model_loader:
          - kv   2:                   starcoder.context_length u32<br>llama_model_loader:
          - kv   3:                 starcoder.embedding_length u32<br>llama_model_loader:
          - kv   4:              starcoder.feed_forward_length u32<br>llama_model_loader:
          - kv   5:                      starcoder.block_count u32<br>llama_model_loader:
          - kv   6:             starcoder.attention.head_count u32<br>llama_model_loader:
          - kv   7:          starcoder.attention.head_count_kv u32<br>llama_model_loader:
          - kv   8:     starcoder.attention.layer_norm_epsilon f32<br>llama_model_loader:
          - kv   9:                          general.file_type u32<br>llama_model_loader:
          - kv  10:                       tokenizer.ggml.model str<br>llama_model_loader:
          - kv  11:                      tokenizer.ggml.tokens arr<br>llama_model_loader:
          - kv  12:                      tokenizer.ggml.scores arr<br>llama_model_loader:
          - kv  13:                  tokenizer.ggml.token_type arr<br>llama_model_loader:
          - kv  14:                      tokenizer.ggml.merges arr<br>llama_model_loader:
          - kv  15:                tokenizer.ggml.bos_token_id u32<br>llama_model_loader:
          - kv  16:                tokenizer.ggml.eos_token_id u32<br>llama_model_loader:
          - kv  17:            tokenizer.ggml.unknown_token_id u32<br>llama_model_loader:
          - kv  18:               general.quantization_version u32<br>llama_model_loader:
          - type  f32:  322 tensors<br>llama_model_loader: - type q4_K:  102 tensors<br>llama_model_loader:
          - type q5_K:   40 tensors<br>llama_model_loader: - type q6_K:   21 tensors<br>error
          loading model: invalid character<br>llama_load_model_from_file: failed to
          load model<br>llama_init_from_gpt_params: error: failed to load model ''..\models\me\sqlcoder.Q4_K_M\sqlcoder.Q4_K_M.gguf''<br>main:
          error: unable to load model</p>

          '
        raw: "i am getting the following while trying to load with llama.cpp, any\
          \ idea how to fix it? all other gguf models are working fine with the same\
          \ main.exe. I have the latest build of llama.cpp\r\n...\r\nllama_model_loader:\
          \ - kv   0:                       general.architecture str\r\nllama_model_loader:\
          \ - kv   1:                               general.name str\r\nllama_model_loader:\
          \ - kv   2:                   starcoder.context_length u32\r\nllama_model_loader:\
          \ - kv   3:                 starcoder.embedding_length u32\r\nllama_model_loader:\
          \ - kv   4:              starcoder.feed_forward_length u32\r\nllama_model_loader:\
          \ - kv   5:                      starcoder.block_count u32\r\nllama_model_loader:\
          \ - kv   6:             starcoder.attention.head_count u32\r\nllama_model_loader:\
          \ - kv   7:          starcoder.attention.head_count_kv u32\r\nllama_model_loader:\
          \ - kv   8:     starcoder.attention.layer_norm_epsilon f32\r\nllama_model_loader:\
          \ - kv   9:                          general.file_type u32\r\nllama_model_loader:\
          \ - kv  10:                       tokenizer.ggml.model str\r\nllama_model_loader:\
          \ - kv  11:                      tokenizer.ggml.tokens arr\r\nllama_model_loader:\
          \ - kv  12:                      tokenizer.ggml.scores arr\r\nllama_model_loader:\
          \ - kv  13:                  tokenizer.ggml.token_type arr\r\nllama_model_loader:\
          \ - kv  14:                      tokenizer.ggml.merges arr\r\nllama_model_loader:\
          \ - kv  15:                tokenizer.ggml.bos_token_id u32\r\nllama_model_loader:\
          \ - kv  16:                tokenizer.ggml.eos_token_id u32\r\nllama_model_loader:\
          \ - kv  17:            tokenizer.ggml.unknown_token_id u32\r\nllama_model_loader:\
          \ - kv  18:               general.quantization_version u32\r\nllama_model_loader:\
          \ - type  f32:  322 tensors\r\nllama_model_loader: - type q4_K:  102 tensors\r\
          \nllama_model_loader: - type q5_K:   40 tensors\r\nllama_model_loader: -\
          \ type q6_K:   21 tensors\r\nerror loading model: invalid character\r\n\
          llama_load_model_from_file: failed to load model\r\nllama_init_from_gpt_params:\
          \ error: failed to load model '..\\models\\me\\sqlcoder.Q4_K_M\\sqlcoder.Q4_K_M.gguf'\r\
          \nmain: error: unable to load model"
        updatedAt: '2023-10-03T08:01:41.177Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - AayushShah
        - flymonk
    id: 651bca650e6b7fa4293267d4
    type: comment
  author: stormchaser
  content: "i am getting the following while trying to load with llama.cpp, any idea\
    \ how to fix it? all other gguf models are working fine with the same main.exe.\
    \ I have the latest build of llama.cpp\r\n...\r\nllama_model_loader: - kv   0:\
    \                       general.architecture str\r\nllama_model_loader: - kv \
    \  1:                               general.name str\r\nllama_model_loader: -\
    \ kv   2:                   starcoder.context_length u32\r\nllama_model_loader:\
    \ - kv   3:                 starcoder.embedding_length u32\r\nllama_model_loader:\
    \ - kv   4:              starcoder.feed_forward_length u32\r\nllama_model_loader:\
    \ - kv   5:                      starcoder.block_count u32\r\nllama_model_loader:\
    \ - kv   6:             starcoder.attention.head_count u32\r\nllama_model_loader:\
    \ - kv   7:          starcoder.attention.head_count_kv u32\r\nllama_model_loader:\
    \ - kv   8:     starcoder.attention.layer_norm_epsilon f32\r\nllama_model_loader:\
    \ - kv   9:                          general.file_type u32\r\nllama_model_loader:\
    \ - kv  10:                       tokenizer.ggml.model str\r\nllama_model_loader:\
    \ - kv  11:                      tokenizer.ggml.tokens arr\r\nllama_model_loader:\
    \ - kv  12:                      tokenizer.ggml.scores arr\r\nllama_model_loader:\
    \ - kv  13:                  tokenizer.ggml.token_type arr\r\nllama_model_loader:\
    \ - kv  14:                      tokenizer.ggml.merges arr\r\nllama_model_loader:\
    \ - kv  15:                tokenizer.ggml.bos_token_id u32\r\nllama_model_loader:\
    \ - kv  16:                tokenizer.ggml.eos_token_id u32\r\nllama_model_loader:\
    \ - kv  17:            tokenizer.ggml.unknown_token_id u32\r\nllama_model_loader:\
    \ - kv  18:               general.quantization_version u32\r\nllama_model_loader:\
    \ - type  f32:  322 tensors\r\nllama_model_loader: - type q4_K:  102 tensors\r\
    \nllama_model_loader: - type q5_K:   40 tensors\r\nllama_model_loader: - type\
    \ q6_K:   21 tensors\r\nerror loading model: invalid character\r\nllama_load_model_from_file:\
    \ failed to load model\r\nllama_init_from_gpt_params: error: failed to load model\
    \ '..\\models\\me\\sqlcoder.Q4_K_M\\sqlcoder.Q4_K_M.gguf'\r\nmain: error: unable\
    \ to load model"
  created_at: 2023-10-03 07:01:41+00:00
  edited: false
  hidden: false
  id: 651bca650e6b7fa4293267d4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/sqlcoder-GGUF
repo_type: model
status: open
target_branch: null
title: 'error loading model: invalid character'
