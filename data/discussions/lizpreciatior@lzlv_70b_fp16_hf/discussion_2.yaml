!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ingenitus
conflicting_files: null
created_at: 2023-11-01 07:37:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c1bc0bf6447e73f897dbdc17647bd6f4.svg
      fullname: Ingenitus Sapientia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ingenitus
      type: user
    createdAt: '2023-11-01T08:37:53.000Z'
    data:
      edited: true
      editors:
      - Ingenitus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9644887447357178
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c1bc0bf6447e73f897dbdc17647bd6f4.svg
          fullname: Ingenitus Sapientia
          isHf: false
          isPro: false
          name: Ingenitus
          type: user
        html: '<p>I can''t figure out how to make the model be descriptive like Emerthyst-20B
          (that model instead has problems with acting as the MC, which this model
          does not have). It defaults to small chat-like responses you would expect
          from smaller models even though I tell it to use long-form paragraphs. For
          a 70B model that''s not great, and it has some problems sometimes with logical
          coherency for advanced RP prompts. I found Euryale-70B is better for my
          use case.</p>

          '
        raw: I can't figure out how to make the model be descriptive like Emerthyst-20B
          (that model instead has problems with acting as the MC, which this model
          does not have). It defaults to small chat-like responses you would expect
          from smaller models even though I tell it to use long-form paragraphs. For
          a 70B model that's not great, and it has some problems sometimes with logical
          coherency for advanced RP prompts. I found Euryale-70B is better for my
          use case.
        updatedAt: '2023-11-01T08:41:09.809Z'
      numEdits: 2
      reactions: []
    id: 65420e615bb41e82fb9df76b
    type: comment
  author: Ingenitus
  content: I can't figure out how to make the model be descriptive like Emerthyst-20B
    (that model instead has problems with acting as the MC, which this model does
    not have). It defaults to small chat-like responses you would expect from smaller
    models even though I tell it to use long-form paragraphs. For a 70B model that's
    not great, and it has some problems sometimes with logical coherency for advanced
    RP prompts. I found Euryale-70B is better for my use case.
  created_at: 2023-11-01 07:37:53+00:00
  edited: true
  hidden: false
  id: 65420e615bb41e82fb9df76b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/651bdfcc0e6b7fa42935588c/vvxVn2FojkE3mUfWU-Vob.png?w=200&h=200&f=face
      fullname: A Guy
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: lizpreciatior
      type: user
    createdAt: '2023-11-06T12:43:23.000Z'
    data:
      edited: false
      editors:
      - lizpreciatior
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9331939816474915
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/651bdfcc0e6b7fa42935588c/vvxVn2FojkE3mUfWU-Vob.png?w=200&h=200&f=face
          fullname: A Guy
          isHf: false
          isPro: false
          name: lizpreciatior
          type: user
        html: '<p>What system prompt are you using? Some post-release testing has
          shown that the model might actually perform a bit better if you use Alpaca-style
          prompting like: </p>

          <p>Below is an instruction that describes a task. Write a response that
          appropriately completes the request.</p>

          <h3 id="instruction">Instruction:</h3>

          <p>[prompt here]</p>

          <h3 id="response">Response:</h3>

          '
        raw: "What system prompt are you using? Some post-release testing has shown\
          \ that the model might actually perform a bit better if you use Alpaca-style\
          \ prompting like: \n\nBelow is an instruction that describes a task. Write\
          \ a response that appropriately completes the request.\n### Instruction:\n\
          [prompt here]\n### Response:\n\n"
        updatedAt: '2023-11-06T12:43:23.924Z'
      numEdits: 0
      reactions: []
    id: 6548df6b5491ffcf2e4433c2
    type: comment
  author: lizpreciatior
  content: "What system prompt are you using? Some post-release testing has shown\
    \ that the model might actually perform a bit better if you use Alpaca-style prompting\
    \ like: \n\nBelow is an instruction that describes a task. Write a response that\
    \ appropriately completes the request.\n### Instruction:\n[prompt here]\n### Response:\n\
    \n"
  created_at: 2023-11-06 12:43:23+00:00
  edited: false
  hidden: false
  id: 6548df6b5491ffcf2e4433c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c1bc0bf6447e73f897dbdc17647bd6f4.svg
      fullname: Ingenitus Sapientia
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ingenitus
      type: user
    createdAt: '2023-11-06T15:08:00.000Z'
    data:
      edited: true
      editors:
      - Ingenitus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8856853246688843
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c1bc0bf6447e73f897dbdc17647bd6f4.svg
          fullname: Ingenitus Sapientia
          isHf: false
          isPro: false
          name: Ingenitus
          type: user
        html: '<p>I use the "### Instruction" header at the beginning of context.</p>

          <blockquote>

          <p>What system prompt are you using? Some post-release testing has shown
          that the model might actually perform a bit better if you use Alpaca-style
          prompting like: </p>

          <p>Below is an instruction that describes a task. Write a response that
          appropriately completes the request.</p>

          <h3 id="instruction">Instruction:</h3>

          <p>[prompt here]</p>

          <h3 id="response">Response:</h3>

          </blockquote>

          '
        raw: "I use the \"### Instruction\" header at the beginning of context.\n\
          > What system prompt are you using? Some post-release testing has shown\
          \ that the model might actually perform a bit better if you use Alpaca-style\
          \ prompting like: \n> \n> Below is an instruction that describes a task.\
          \ Write a response that appropriately completes the request.\n> ### Instruction:\n\
          > [prompt here]\n> ### Response:"
        updatedAt: '2023-11-06T15:08:47.419Z'
      numEdits: 1
      reactions: []
    id: 65490150593575b54a04a70b
    type: comment
  author: Ingenitus
  content: "I use the \"### Instruction\" header at the beginning of context.\n> What\
    \ system prompt are you using? Some post-release testing has shown that the model\
    \ might actually perform a bit better if you use Alpaca-style prompting like:\
    \ \n> \n> Below is an instruction that describes a task. Write a response that\
    \ appropriately completes the request.\n> ### Instruction:\n> [prompt here]\n\
    > ### Response:"
  created_at: 2023-11-06 15:08:00+00:00
  edited: true
  hidden: false
  id: 65490150593575b54a04a70b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: lizpreciatior/lzlv_70b_fp16_hf
repo_type: model
status: open
target_branch: null
title: Defaults to short responses.
