!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Aryanne
conflicting_files: null
created_at: 2023-09-06 18:30:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
      fullname: Aryanne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aryanne
      type: user
    createdAt: '2023-09-06T19:30:44.000Z'
    data:
      edited: false
      editors:
      - Aryanne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.45468869805336
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
          fullname: Aryanne
          isHf: false
          isPro: false
          name: Aryanne
          type: user
        html: "<pre><code>Loading model file /storage/emulated/0/amodels/silm/pytorch_model.bin\n\
          vocabtype: spm\nTraceback (most recent call last):\n  File \"/data/data/com.termux/files/home/llamaggml/convert.py\"\
          , line 1326, in &lt;module&gt;\n    main()\n  File \"/data/data/com.termux/files/home/llamaggml/convert.py\"\
          , line 1314, in main\n    vocab = load_vocab(vocab_dir, args.vocabtype)\n\
          \            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/data/com.termux/files/home/llamaggml/convert.py\"\
          , line 1248, in load_vocab\n    raise FileNotFoundError(\nFileNotFoundError:\
          \ Could not find tokenizer.model in /storage/emulated/0/amodels/silm or\
          \ its parent; if it's in another directory, pass the directory as --vocab-dir\
          \ \n</code></pre>\n"
        raw: "```\r\nLoading model file /storage/emulated/0/amodels/silm/pytorch_model.bin\r\
          \nvocabtype: spm\r\nTraceback (most recent call last):\r\n  File \"/data/data/com.termux/files/home/llamaggml/convert.py\"\
          , line 1326, in <module>\r\n    main()\r\n  File \"/data/data/com.termux/files/home/llamaggml/convert.py\"\
          , line 1314, in main\r\n    vocab = load_vocab(vocab_dir, args.vocabtype)\r\
          \n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/data/com.termux/files/home/llamaggml/convert.py\"\
          , line 1248, in load_vocab\r\n    raise FileNotFoundError(\r\nFileNotFoundError:\
          \ Could not find tokenizer.model in /storage/emulated/0/amodels/silm or\
          \ its parent; if it's in another directory, pass the directory as --vocab-dir\
          \ \r\n```"
        updatedAt: '2023-09-06T19:30:44.838Z'
      numEdits: 0
      reactions: []
    id: 64f8d364b2c85cf9e515a502
    type: comment
  author: Aryanne
  content: "```\r\nLoading model file /storage/emulated/0/amodels/silm/pytorch_model.bin\r\
    \nvocabtype: spm\r\nTraceback (most recent call last):\r\n  File \"/data/data/com.termux/files/home/llamaggml/convert.py\"\
    , line 1326, in <module>\r\n    main()\r\n  File \"/data/data/com.termux/files/home/llamaggml/convert.py\"\
    , line 1314, in main\r\n    vocab = load_vocab(vocab_dir, args.vocabtype)\r\n\
    \            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/data/com.termux/files/home/llamaggml/convert.py\"\
    , line 1248, in load_vocab\r\n    raise FileNotFoundError(\r\nFileNotFoundError:\
    \ Could not find tokenizer.model in /storage/emulated/0/amodels/silm or its parent;\
    \ if it's in another directory, pass the directory as --vocab-dir \r\n```"
  created_at: 2023-09-06 18:30:44+00:00
  edited: false
  hidden: false
  id: 64f8d364b2c85cf9e515a502
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
      fullname: Aryanne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aryanne
      type: user
    createdAt: '2023-09-06T19:56:56.000Z'
    data:
      edited: false
      editors:
      - Aryanne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9939801692962646
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
          fullname: Aryanne
          isHf: false
          isPro: false
          name: Aryanne
          type: user
        html: '<p>I think idk how to quantize it. </p>

          '
        raw: 'I think idk how to quantize it. '
        updatedAt: '2023-09-06T19:56:56.281Z'
      numEdits: 0
      reactions: []
    id: 64f8d98833fd3f0fcb7f122f
    type: comment
  author: Aryanne
  content: 'I think idk how to quantize it. '
  created_at: 2023-09-06 18:56:56+00:00
  edited: false
  hidden: false
  id: 64f8d98833fd3f0fcb7f122f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6485eb58d38342fff2ab3b04/LTCbSlTSl_nTl_rvtIJUj.jpeg?w=200&h=200&f=face
      fullname: aivana
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: baebee
      type: user
    createdAt: '2023-09-07T18:51:40.000Z'
    data:
      edited: false
      editors:
      - baebee
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9971725344657898
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6485eb58d38342fff2ab3b04/LTCbSlTSl_nTl_rvtIJUj.jpeg?w=200&h=200&f=face
          fullname: aivana
          isHf: false
          isPro: false
          name: baebee
          type: user
        html: '<p>Oh, sorry but I also don''t know how to fix that..</p>

          '
        raw: Oh, sorry but I also don't know how to fix that..
        updatedAt: '2023-09-07T18:51:40.740Z'
      numEdits: 0
      reactions: []
    id: 64fa1bbc7904ea30e63edb2f
    type: comment
  author: baebee
  content: Oh, sorry but I also don't know how to fix that..
  created_at: 2023-09-07 17:51:40+00:00
  edited: false
  hidden: false
  id: 64fa1bbc7904ea30e63edb2f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
      fullname: Aryanne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aryanne
      type: user
    createdAt: '2023-09-07T18:55:41.000Z'
    data:
      edited: false
      editors:
      - Aryanne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9241150617599487
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
          fullname: Aryanne
          isHf: false
          isPro: false
          name: Aryanne
          type: user
        html: '<p>no problem, I thought I could quantize, but at the moment there
          is no easy way to quantize it using llama.cpp, because it''s a gptneox model</p>

          '
        raw: no problem, I thought I could quantize, but at the moment there is no
          easy way to quantize it using llama.cpp, because it's a gptneox model
        updatedAt: '2023-09-07T18:55:41.973Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64fa1cad8d50404bc4d65b7c
    id: 64fa1cad8d50404bc4d65b7b
    type: comment
  author: Aryanne
  content: no problem, I thought I could quantize, but at the moment there is no easy
    way to quantize it using llama.cpp, because it's a gptneox model
  created_at: 2023-09-07 17:55:41+00:00
  edited: false
  hidden: false
  id: 64fa1cad8d50404bc4d65b7b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63375efab575b33cf021f795/mUe93rAuTg4qAFovx2rGO.png?w=200&h=200&f=face
      fullname: Aryanne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aryanne
      type: user
    createdAt: '2023-09-07T18:55:41.000Z'
    data:
      status: closed
    id: 64fa1cad8d50404bc4d65b7c
    type: status-change
  author: Aryanne
  created_at: 2023-09-07 17:55:41+00:00
  id: 64fa1cad8d50404bc4d65b7c
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: FinchResearch/SiLM-3b-v2
repo_type: model
status: closed
target_branch: null
title: Missing tokenizer.model
