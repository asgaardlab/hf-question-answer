!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ilan1twig
conflicting_files: null
created_at: 2023-09-10 09:02:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf43edacc6563e1fffd02b723435f3b9.svg
      fullname: Ilan Twig
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilan1twig
      type: user
    createdAt: '2023-09-10T10:02:41.000Z'
    data:
      edited: false
      editors:
      - ilan1twig
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.44407373666763306
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf43edacc6563e1fffd02b723435f3b9.svg
          fullname: Ilan Twig
          isHf: false
          isPro: false
          name: ilan1twig
          type: user
        html: "<p>Hi</p>\n<p>Thanks for the version of the llama70b.  I am trying\
          \ to load it in textgen web ui, but it keeps failing.<br>How can I load\
          \ it properly?</p>\n<p>Thanks in advance,<br>Ilan</p>\n<p>Traceback (most\
          \ recent call last):</p>\n<p>File \u201CD:\\oobabooga_windows\\text-generation-webui\\\
          modules\\ui_model_menu.py\u201D, line 196, in load_model_wrapper</p>\n<p>shared.model,\
          \ shared.tokenizer = load_model(shared.model_name, loader)<br>File \u201C\
          D:\\oobabooga_windows\\text-generation-webui\\modules\\models.py\u201D,\
          \ line 87, in load_model</p>\n<p>tokenizer = load_tokenizer(model_name,\
          \ model)<br>File \u201CD:\\oobabooga_windows\\text-generation-webui\\modules\\\
          models.py\u201D, line 104, in load_tokenizer</p>\n<p>tokenizer = AutoTokenizer.from_pretrained(<br>File\
          \ \u201CD:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
          transformers\\models\\auto\\tokenization_auto.py\u201D, line 727, in from_pretrained</p>\n\
          <p>return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)<br>File \u201CD:\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D\
          , line 1854, in from_pretrained</p>\n<p>return cls._from_pretrained(<br>File\
          \ \u201CD:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
          transformers\\tokenization_utils_base.py\u201D, line 2017, in _from_pretrained</p>\n\
          <p>tokenizer = cls(*init_inputs, **init_kwargs)<br>File \u201CD:\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\models\\llama\\\
          tokenization_llama.py\u201D, line 156, in init</p>\n<p>self.sp_model = self.get_spm_processor()<br>File\
          \ \u201CD:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
          transformers\\models\\llama\\tokenization_llama.py\u201D, line 162, in get_spm_processor</p>\n\
          <p>with open(self.vocab_file, \"rb\") as f:<br>TypeError: expected str,\
          \ bytes or os.PathLike object, not NoneType</p>\n"
        raw: "Hi\r\n\r\nThanks for the version of the llama70b.  I am trying to load\
          \ it in textgen web ui, but it keeps failing.\r\nHow can I load it properly?\r\
          \n\r\nThanks in advance,\r\nIlan\r\n\r\nTraceback (most recent call last):\r\
          \n\r\nFile \u201CD:\\oobabooga_windows\\text-generation-webui\\modules\\\
          ui_model_menu.py\u201D, line 196, in load_model_wrapper\r\n\r\nshared.model,\
          \ shared.tokenizer = load_model(shared.model_name, loader)\r\nFile \u201C\
          D:\\oobabooga_windows\\text-generation-webui\\modules\\models.py\u201D,\
          \ line 87, in load_model\r\n\r\ntokenizer = load_tokenizer(model_name, model)\r\
          \nFile \u201CD:\\oobabooga_windows\\text-generation-webui\\modules\\models.py\u201D\
          , line 104, in load_tokenizer\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\r\
          \nFile \u201CD:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
          transformers\\models\\auto\\tokenization_auto.py\u201D, line 727, in from_pretrained\r\
          \n\r\nreturn tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\r\nFile \u201CD:\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D\
          , line 1854, in from_pretrained\r\n\r\nreturn cls._from_pretrained(\r\n\
          File \u201CD:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
          transformers\\tokenization_utils_base.py\u201D, line 2017, in _from_pretrained\r\
          \n\r\ntokenizer = cls(*init_inputs, **init_kwargs)\r\nFile \u201CD:\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\transformers\\models\\llama\\\
          tokenization_llama.py\u201D, line 156, in init\r\n\r\nself.sp_model = self.get_spm_processor()\r\
          \nFile \u201CD:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
          transformers\\models\\llama\\tokenization_llama.py\u201D, line 162, in get_spm_processor\r\
          \n\r\nwith open(self.vocab_file, \"rb\") as f:\r\nTypeError: expected str,\
          \ bytes or os.PathLike object, not NoneType"
        updatedAt: '2023-09-10T10:02:41.215Z'
      numEdits: 0
      reactions: []
    id: 64fd9441365e3069d75d4985
    type: comment
  author: ilan1twig
  content: "Hi\r\n\r\nThanks for the version of the llama70b.  I am trying to load\
    \ it in textgen web ui, but it keeps failing.\r\nHow can I load it properly?\r\
    \n\r\nThanks in advance,\r\nIlan\r\n\r\nTraceback (most recent call last):\r\n\
    \r\nFile \u201CD:\\oobabooga_windows\\text-generation-webui\\modules\\ui_model_menu.py\u201D\
    , line 196, in load_model_wrapper\r\n\r\nshared.model, shared.tokenizer = load_model(shared.model_name,\
    \ loader)\r\nFile \u201CD:\\oobabooga_windows\\text-generation-webui\\modules\\\
    models.py\u201D, line 87, in load_model\r\n\r\ntokenizer = load_tokenizer(model_name,\
    \ model)\r\nFile \u201CD:\\oobabooga_windows\\text-generation-webui\\modules\\\
    models.py\u201D, line 104, in load_tokenizer\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\r\
    \nFile \u201CD:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\models\\auto\\tokenization_auto.py\u201D, line 727, in from_pretrained\r\
    \n\r\nreturn tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs,\
    \ **kwargs)\r\nFile \u201CD:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\tokenization_utils_base.py\u201D, line 1854, in from_pretrained\r\
    \n\r\nreturn cls._from_pretrained(\r\nFile \u201CD:\\oobabooga_windows\\installer_files\\\
    env\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u201D, line\
    \ 2017, in _from_pretrained\r\n\r\ntokenizer = cls(*init_inputs, **init_kwargs)\r\
    \nFile \u201CD:\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\\
    transformers\\models\\llama\\tokenization_llama.py\u201D, line 156, in init\r\n\
    \r\nself.sp_model = self.get_spm_processor()\r\nFile \u201CD:\\oobabooga_windows\\\
    installer_files\\env\\lib\\site-packages\\transformers\\models\\llama\\tokenization_llama.py\u201D\
    , line 162, in get_spm_processor\r\n\r\nwith open(self.vocab_file, \"rb\") as\
    \ f:\r\nTypeError: expected str, bytes or os.PathLike object, not NoneType"
  created_at: 2023-09-10 09:02:41+00:00
  edited: false
  hidden: false
  id: 64fd9441365e3069d75d4985
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639c5c448a34ed9a404a956b/jcypw-eh7JzKHTffd0N9l.jpeg?w=200&h=200&f=face
      fullname: Mohamad Alhajar
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: malhajar
      type: user
    createdAt: '2023-09-10T10:49:46.000Z'
    data:
      edited: false
      editors:
      - malhajar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8567121624946594
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/639c5c448a34ed9a404a956b/jcypw-eh7JzKHTffd0N9l.jpeg?w=200&h=200&f=face
          fullname: Mohamad Alhajar
          isHf: false
          isPro: false
          name: malhajar
          type: user
        html: "<p>Hi Ilan,<br>I am not sure about your setup in web-generation-ui\
          \ but please be aware that this is a GPTQ model and should be loaded accordingly\
          \ if using services such as \"web-generation-webui\"<br>Could you try to\
          \ serve it using the following?<br><a rel=\"nofollow\" href=\"https://github.com/oobabooga/text-generation-webui/blob/main/docs/GPTQ-models-(4-bit-mode).md\"\
          >https://github.com/oobabooga/text-generation-webui/blob/main/docs/GPTQ-models-(4-bit-mode).md</a>\n\
          \  </p>\n"
        raw: "Hi Ilan,\nI am not sure about your setup in web-generation-ui but please\
          \ be aware that this is a GPTQ model and should be loaded accordingly if\
          \ using services such as \"web-generation-webui\" \nCould you try to serve\
          \ it using the following? \nhttps://github.com/oobabooga/text-generation-webui/blob/main/docs/GPTQ-models-(4-bit-mode).md\n\
          \  "
        updatedAt: '2023-09-10T10:49:46.738Z'
      numEdits: 0
      reactions: []
    id: 64fd9f4a491fad096368e634
    type: comment
  author: malhajar
  content: "Hi Ilan,\nI am not sure about your setup in web-generation-ui but please\
    \ be aware that this is a GPTQ model and should be loaded accordingly if using\
    \ services such as \"web-generation-webui\" \nCould you try to serve it using\
    \ the following? \nhttps://github.com/oobabooga/text-generation-webui/blob/main/docs/GPTQ-models-(4-bit-mode).md\n\
    \  "
  created_at: 2023-09-10 09:49:46+00:00
  edited: false
  hidden: false
  id: 64fd9f4a491fad096368e634
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf43edacc6563e1fffd02b723435f3b9.svg
      fullname: Ilan Twig
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilan1twig
      type: user
    createdAt: '2023-09-10T10:58:48.000Z'
    data:
      edited: false
      editors:
      - ilan1twig
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9896085858345032
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf43edacc6563e1fffd02b723435f3b9.svg
          fullname: Ilan Twig
          isHf: false
          isPro: false
          name: ilan1twig
          type: user
        html: '<p>Hi, thanks for your quick response. I will try that as soon as I
          get back to my desk. Cheers!</p>

          '
        raw: Hi, thanks for your quick response. I will try that as soon as I get
          back to my desk. Cheers!
        updatedAt: '2023-09-10T10:58:48.544Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - malhajar
    id: 64fda168b3eee10ba550df23
    type: comment
  author: ilan1twig
  content: Hi, thanks for your quick response. I will try that as soon as I get back
    to my desk. Cheers!
  created_at: 2023-09-10 09:58:48+00:00
  edited: false
  hidden: false
  id: 64fda168b3eee10ba550df23
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf43edacc6563e1fffd02b723435f3b9.svg
      fullname: Ilan Twig
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ilan1twig
      type: user
    createdAt: '2023-09-10T20:53:38.000Z'
    data:
      edited: false
      editors:
      - ilan1twig
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9394032955169678
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf43edacc6563e1fffd02b723435f3b9.svg
          fullname: Ilan Twig
          isHf: false
          isPro: false
          name: ilan1twig
          type: user
        html: '<p>No matter what I tried - I could not get it to load the model in
          texgen web ui :(</p>

          '
        raw: No matter what I tried - I could not get it to load the model in texgen
          web ui :(
        updatedAt: '2023-09-10T20:53:38.153Z'
      numEdits: 0
      reactions: []
    id: 64fe2cd2435832ff8680d648
    type: comment
  author: ilan1twig
  content: No matter what I tried - I could not get it to load the model in texgen
    web ui :(
  created_at: 2023-09-10 19:53:38+00:00
  edited: false
  hidden: false
  id: 64fe2cd2435832ff8680d648
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: malhajar/Platypus2-70B-instruct-4bit-gptq
repo_type: model
status: open
target_branch: null
title: How to load this model in TextGen Web UI?
