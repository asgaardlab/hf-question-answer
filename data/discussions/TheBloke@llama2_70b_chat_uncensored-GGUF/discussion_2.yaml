!!python/object:huggingface_hub.community.DiscussionWithDetails
author: YokaiKoibito
conflicting_files: null
created_at: 2023-09-18 03:02:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
      fullname: Yokai Koibito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YokaiKoibito
      type: user
    createdAt: '2023-09-18T04:02:51.000Z'
    data:
      edited: false
      editors:
      - YokaiKoibito
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7556241750717163
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
          fullname: Yokai Koibito
          isHf: false
          isPro: false
          name: YokaiKoibito
          type: user
        html: '<p>Normally  llama2_70b*.Q5_K_M.gguf files are 48.8GB, this one''s
          44.6 GB. Kobold.cpp won''t load it, and says:</p>

          <p>Loading model: /Users/***/Documents/GitHub/koboldcpp/models/llama2_70b_chat_uncensored.Q5_K_M.gguf<br>[Threads:
          7, BlasThreads: 7, SmartContext: True]</p>

          <hr>

          <p>Identified as LLAMA model: (ver 0)<br>Attempting to Load...</p>

          <hr>

          <p>Using automatic RoPE scaling (scale:1.000, base:32000.0)<br>System Info:
          AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA
          = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 |
          BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | </p>

          <p>Unknown Model, cannot load.<br>Load Model OK: False<br>Could not load
          model: /Users/***/Documents/GitHub/koboldcpp/models/llama2_70b_chat_uncensored.Q5_K_M.gguf</p>

          <p>The llama2_70b_chat_uncensored.Q5_K_S.gguf is also an odd size: I haven''t
          tested it, but that''s probably damaged too.</p>

          '
        raw: "Normally  llama2_70b*.Q5_K_M.gguf files are 48.8GB, this one's 44.6\
          \ GB. Kobold.cpp won't load it, and says:\r\n\r\nLoading model: /Users/***/Documents/GitHub/koboldcpp/models/llama2_70b_chat_uncensored.Q5_K_M.gguf\
          \ \r\n[Threads: 7, BlasThreads: 7, SmartContext: True]\r\n\r\n---\r\nIdentified\
          \ as LLAMA model: (ver 0)\r\nAttempting to Load...\r\n---\r\nUsing automatic\
          \ RoPE scaling (scale:1.000, base:32000.0)\r\nSystem Info: AVX = 0 | AVX2\
          \ = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON\
          \ = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1\
          \ | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \r\n\r\nUnknown Model, cannot load.\r\
          \nLoad Model OK: False\r\nCould not load model: /Users/***/Documents/GitHub/koboldcpp/models/llama2_70b_chat_uncensored.Q5_K_M.gguf\r\
          \n\r\nThe llama2_70b_chat_uncensored.Q5_K_S.gguf is also an odd size: I\
          \ haven't tested it, but that's probably damaged too."
        updatedAt: '2023-09-18T04:02:51.164Z'
      numEdits: 0
      reactions: []
    id: 6507cbeb1704c7eb0aa10cda
    type: comment
  author: YokaiKoibito
  content: "Normally  llama2_70b*.Q5_K_M.gguf files are 48.8GB, this one's 44.6 GB.\
    \ Kobold.cpp won't load it, and says:\r\n\r\nLoading model: /Users/***/Documents/GitHub/koboldcpp/models/llama2_70b_chat_uncensored.Q5_K_M.gguf\
    \ \r\n[Threads: 7, BlasThreads: 7, SmartContext: True]\r\n\r\n---\r\nIdentified\
    \ as LLAMA model: (ver 0)\r\nAttempting to Load...\r\n---\r\nUsing automatic RoPE\
    \ scaling (scale:1.000, base:32000.0)\r\nSystem Info: AVX = 0 | AVX2 = 0 | AVX512\
    \ = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 |\
    \ F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX\
    \ = 0 | \r\n\r\nUnknown Model, cannot load.\r\nLoad Model OK: False\r\nCould not\
    \ load model: /Users/***/Documents/GitHub/koboldcpp/models/llama2_70b_chat_uncensored.Q5_K_M.gguf\r\
    \n\r\nThe llama2_70b_chat_uncensored.Q5_K_S.gguf is also an odd size: I haven't\
    \ tested it, but that's probably damaged too."
  created_at: 2023-09-18 03:02:51+00:00
  edited: false
  hidden: false
  id: 6507cbeb1704c7eb0aa10cda
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-09-18T06:02:16.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9482572078704834
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Ooh yeah, looks like all files from Q5_K_S and up are broken.  I
          will fix. Thanks for the report.</p>

          '
        raw: Ooh yeah, looks like all files from Q5_K_S and up are broken.  I will
          fix. Thanks for the report.
        updatedAt: '2023-09-18T06:02:16.551Z'
      numEdits: 0
      reactions: []
    id: 6507e7e8c6ae3df8f2ea7546
    type: comment
  author: TheBloke
  content: Ooh yeah, looks like all files from Q5_K_S and up are broken.  I will fix.
    Thanks for the report.
  created_at: 2023-09-18 05:02:16+00:00
  edited: false
  hidden: false
  id: 6507e7e8c6ae3df8f2ea7546
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
      fullname: Yokai Koibito
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YokaiKoibito
      type: user
    createdAt: '2023-09-18T23:19:24.000Z'
    data:
      edited: false
      editors:
      - YokaiKoibito
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9885868430137634
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/657be320aac476bbb5353b0e725e8893.svg
          fullname: Yokai Koibito
          isHf: false
          isPro: false
          name: YokaiKoibito
          type: user
        html: '<p>It looks like you updated them, but the sizes are still wrong.</p>

          '
        raw: It looks like you updated them, but the sizes are still wrong.
        updatedAt: '2023-09-18T23:19:24.359Z'
      numEdits: 0
      reactions: []
    id: 6508dafccc02352e1efdf8fc
    type: comment
  author: YokaiKoibito
  content: It looks like you updated them, but the sizes are still wrong.
  created_at: 2023-09-18 22:19:24+00:00
  edited: false
  hidden: false
  id: 6508dafccc02352e1efdf8fc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-09-19T00:33:40.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5842319130897522
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Third time lucky </p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/qBJD1PFSX0KhiMkMl3aT2.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/qBJD1PFSX0KhiMkMl3aT2.png"></a></p>

          '
        raw: "Third time lucky \n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/qBJD1PFSX0KhiMkMl3aT2.png)\n"
        updatedAt: '2023-09-19T00:33:40.891Z'
      numEdits: 0
      reactions: []
    id: 6508ec64e37e4da5316ea0ff
    type: comment
  author: TheBloke
  content: "Third time lucky \n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/qBJD1PFSX0KhiMkMl3aT2.png)\n"
  created_at: 2023-09-18 23:33:40+00:00
  edited: false
  hidden: false
  id: 6508ec64e37e4da5316ea0ff
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/llama2_70b_chat_uncensored-GGUF
repo_type: model
status: open
target_branch: null
title: The file  llama2_70b_chat_uncensored.Q5_K_M.gguf won't open and appears to
  be the wrong size.
