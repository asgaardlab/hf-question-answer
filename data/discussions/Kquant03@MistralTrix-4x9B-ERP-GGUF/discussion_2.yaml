!!python/object:huggingface_hub.community.DiscussionWithDetails
author: actuallyasriel
conflicting_files: null
created_at: 2024-01-23 15:58:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe8c7b641cb77412431bba24d95b316f.svg
      fullname: Asriel Yuill
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: actuallyasriel
      type: user
    createdAt: '2024-01-23T15:58:03.000Z'
    data:
      edited: false
      editors:
      - actuallyasriel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.972390353679657
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe8c7b641cb77412431bba24d95b316f.svg
          fullname: Asriel Yuill
          isHf: false
          isPro: false
          name: actuallyasriel
          type: user
        html: '<p>I''d love to give this a shot but I''ve been severely TabbyAPI-pilled
          recently and honestly I can''t go back to using ooba for my text completion
          API. I might consider Kobold but going back and forth between them sounds
          like a drag.<br>With that said, if you have the spare time/resources, I''d
          really appreciate an EXL2 version.<br>On my RTX 4090 I can do 8x7Bs at 3.5bpw
          with full context, provided I enable 8-bit cache, if that helps at all.<br>No
          worries if you can''t swing it, of course. Just figured I''d put it out
          there.</p>

          '
        raw: "I'd love to give this a shot but I've been severely TabbyAPI-pilled\
          \ recently and honestly I can't go back to using ooba for my text completion\
          \ API. I might consider Kobold but going back and forth between them sounds\
          \ like a drag.\r\nWith that said, if you have the spare time/resources,\
          \ I'd really appreciate an EXL2 version.\r\nOn my RTX 4090 I can do 8x7Bs\
          \ at 3.5bpw with full context, provided I enable 8-bit cache, if that helps\
          \ at all.\r\nNo worries if you can't swing it, of course. Just figured I'd\
          \ put it out there."
        updatedAt: '2024-01-23T15:58:03.535Z'
      numEdits: 0
      reactions: []
    id: 65afe20bd90499c94d386a45
    type: comment
  author: actuallyasriel
  content: "I'd love to give this a shot but I've been severely TabbyAPI-pilled recently\
    \ and honestly I can't go back to using ooba for my text completion API. I might\
    \ consider Kobold but going back and forth between them sounds like a drag.\r\n\
    With that said, if you have the spare time/resources, I'd really appreciate an\
    \ EXL2 version.\r\nOn my RTX 4090 I can do 8x7Bs at 3.5bpw with full context,\
    \ provided I enable 8-bit cache, if that helps at all.\r\nNo worries if you can't\
    \ swing it, of course. Just figured I'd put it out there."
  created_at: 2024-01-23 15:58:03+00:00
  edited: false
  hidden: false
  id: 65afe20bd90499c94d386a45
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
      fullname: Stanley Sebastian
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Kquant03
      type: user
    createdAt: '2024-01-23T17:05:05.000Z'
    data:
      edited: true
      editors:
      - Kquant03
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9775631427764893
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6589d7e6586088fd2784a12c/WJFxNOZHe9blf89D9DXYi.png?w=200&h=200&f=face
          fullname: Stanley Sebastian
          isHf: false
          isPro: false
          name: Kquant03
          type: user
        html: '<blockquote>

          <p>I''d love to give this a shot but I''ve been severely TabbyAPI-pilled
          recently and honestly I can''t go back to using ooba for my text completion
          API. I might consider Kobold but going back and forth between them sounds
          like a drag.<br>With that said, if you have the spare time/resources, I''d
          really appreciate an EXL2 version.<br>On my RTX 4090 I can do 8x7Bs at 3.5bpw
          with full context, provided I enable 8-bit cache, if that helps at all.<br>No
          worries if you can''t swing it, of course. Just figured I''d put it out
          there.</p>

          </blockquote>

          <p>Actually, this is one model that I was very excited and happy about.
          However, when trying to push it to GGUF or run it on BF16 apparently the
          9B mistral trix model just simply does not work with mergekit MoE.</p>

          <p>That being said, if you have an idea for an MoE model that you would
          want in EXL2 I will merge it together then talk to LoneStriker about converting
          to 3.5 BPW for you</p>

          '
        raw: '> I''d love to give this a shot but I''ve been severely TabbyAPI-pilled
          recently and honestly I can''t go back to using ooba for my text completion
          API. I might consider Kobold but going back and forth between them sounds
          like a drag.

          > With that said, if you have the spare time/resources, I''d really appreciate
          an EXL2 version.

          > On my RTX 4090 I can do 8x7Bs at 3.5bpw with full context, provided I
          enable 8-bit cache, if that helps at all.

          > No worries if you can''t swing it, of course. Just figured I''d put it
          out there.


          Actually, this is one model that I was very excited and happy about. However,
          when trying to push it to GGUF or run it on BF16 apparently the 9B mistral
          trix model just simply does not work with mergekit MoE.


          That being said, if you have an idea for an MoE model that you would want
          in EXL2 I will merge it together then talk to LoneStriker about converting
          to 3.5 BPW for you'
        updatedAt: '2024-01-23T17:06:15.532Z'
      numEdits: 2
      reactions: []
    id: 65aff1c1091a8ca32b285e49
    type: comment
  author: Kquant03
  content: '> I''d love to give this a shot but I''ve been severely TabbyAPI-pilled
    recently and honestly I can''t go back to using ooba for my text completion API.
    I might consider Kobold but going back and forth between them sounds like a drag.

    > With that said, if you have the spare time/resources, I''d really appreciate
    an EXL2 version.

    > On my RTX 4090 I can do 8x7Bs at 3.5bpw with full context, provided I enable
    8-bit cache, if that helps at all.

    > No worries if you can''t swing it, of course. Just figured I''d put it out there.


    Actually, this is one model that I was very excited and happy about. However,
    when trying to push it to GGUF or run it on BF16 apparently the 9B mistral trix
    model just simply does not work with mergekit MoE.


    That being said, if you have an idea for an MoE model that you would want in EXL2
    I will merge it together then talk to LoneStriker about converting to 3.5 BPW
    for you'
  created_at: 2024-01-23 17:05:05+00:00
  edited: true
  hidden: false
  id: 65aff1c1091a8ca32b285e49
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe8c7b641cb77412431bba24d95b316f.svg
      fullname: Asriel Yuill
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: actuallyasriel
      type: user
    createdAt: '2024-01-23T19:30:30.000Z'
    data:
      edited: false
      editors:
      - actuallyasriel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9539074897766113
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe8c7b641cb77412431bba24d95b316f.svg
          fullname: Asriel Yuill
          isHf: false
          isPro: false
          name: actuallyasriel
          type: user
        html: '<p>ahhh I see!!<br>i''ll keep that in mind then!</p>

          '
        raw: 'ahhh I see!!

          i''ll keep that in mind then!'
        updatedAt: '2024-01-23T19:30:30.958Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Kquant03
      - count: 1
        reaction: "\U0001F917"
        users:
        - Kquant03
    id: 65b013d6f346fb4c5d77e4f6
    type: comment
  author: actuallyasriel
  content: 'ahhh I see!!

    i''ll keep that in mind then!'
  created_at: 2024-01-23 19:30:30+00:00
  edited: false
  hidden: false
  id: 65b013d6f346fb4c5d77e4f6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Kquant03/MistralTrix-4x9B-ERP-GGUF
repo_type: model
status: open
target_branch: null
title: Would you consider EXL2?
