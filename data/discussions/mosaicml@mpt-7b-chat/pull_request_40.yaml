!!python/object:huggingface_hub.community.DiscussionWithDetails
author: irenedea
conflicting_files: []
created_at: 2024-01-10 21:51:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/21a9a778ee5350a1e620d2bd848ee581.svg
      fullname: Irene Dea
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: irenedea
      type: user
    createdAt: '2024-01-10T21:51:08.000Z'
    data:
      edited: true
      editors:
      - irenedea
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6618757843971252
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/21a9a778ee5350a1e620d2bd848ee581.svg
          fullname: Irene Dea
          isHf: false
          isPro: false
          name: irenedea
          type: user
        html: "<p>Manually tested with</p>\n<pre><code>from transformers import AutoTokenizer\n\
          \ntokenizer = AutoTokenizer.from_pretrained('mosaicml/mpt-7b-chat', revision='ed874721')\n\
          \nchat = [\n    {\"role\": \"system\", \"content\": \"This is a system prompt!\"\
          },\n   {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n   {\"\
          role\": \"assistant\", \"content\": \"I'm doing great. How can I help you\
          \ today?\"},\n   {\"role\": \"user\", \"content\": \"I'd like to show off\
          \ how chat templating works!\"},\n]\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n\n# Remove system prompt\nchat = chat[1:]\n\nprint(\"\
          \\nUsing default system prompt!\\n\")\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n</code></pre>\n<p>output:</p>\n<pre><code>&lt;|im_start|&gt;system\n\
          This is a system prompt!\n&lt;|im_start|&gt;user\nHello, how are you?&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;assistant\nI'm doing great. How can I help you today?&lt;|im_end|&gt;&lt;|endoftext|&gt;\n\
          &lt;|im_start|&gt;user\nI'd like to show off how chat templating works!&lt;|im_end|&gt;\n\
          \nUsing default system prompt!\n\n&lt;|im_start|&gt;system\nA conversation\
          \ between a user and an LLM-based AI assistant. The assistant gives helpful\
          \ and honest answers.\n&lt;|im_start|&gt;user\nHello, how are you?&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;assistant\nI'm doing great. How can I help you today?&lt;|im_end|&gt;&lt;|endoftext|&gt;\n\
          &lt;|im_start|&gt;user\nI'd like to show off how chat templating works!&lt;|im_end|&gt;\n\
          </code></pre>\n"
        raw: "Manually tested with\n```\nfrom transformers import AutoTokenizer\n\n\
          tokenizer = AutoTokenizer.from_pretrained('mosaicml/mpt-7b-chat', revision='ed874721')\n\
          \nchat = [\n    {\"role\": \"system\", \"content\": \"This is a system prompt!\"\
          },\n   {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n   {\"\
          role\": \"assistant\", \"content\": \"I'm doing great. How can I help you\
          \ today?\"},\n   {\"role\": \"user\", \"content\": \"I'd like to show off\
          \ how chat templating works!\"},\n]\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n\n# Remove system prompt\nchat = chat[1:]\n\nprint(\"\
          \\nUsing default system prompt!\\n\")\n\nprint(tokenizer.apply_chat_template(chat,\
          \ tokenize=False))\n```\n\noutput:\n```\n<|im_start|>system\nThis is a system\
          \ prompt!\n<|im_start|>user\nHello, how are you?<|im_end|>\n<|im_start|>assistant\n\
          I'm doing great. How can I help you today?<|im_end|><|endoftext|>\n<|im_start|>user\n\
          I'd like to show off how chat templating works!<|im_end|>\n\nUsing default\
          \ system prompt!\n\n<|im_start|>system\nA conversation between a user and\
          \ an LLM-based AI assistant. The assistant gives helpful and honest answers.\n\
          <|im_start|>user\nHello, how are you?<|im_end|>\n<|im_start|>assistant\n\
          I'm doing great. How can I help you today?<|im_end|><|endoftext|>\n<|im_start|>user\n\
          I'd like to show off how chat templating works!<|im_end|>\n```"
        updatedAt: '2024-01-10T21:59:19.776Z'
      numEdits: 3
      reactions: []
    id: 659f114c9af5011d2a87980f
    type: comment
  author: irenedea
  content: "Manually tested with\n```\nfrom transformers import AutoTokenizer\n\n\
    tokenizer = AutoTokenizer.from_pretrained('mosaicml/mpt-7b-chat', revision='ed874721')\n\
    \nchat = [\n    {\"role\": \"system\", \"content\": \"This is a system prompt!\"\
    },\n   {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n   {\"role\"\
    : \"assistant\", \"content\": \"I'm doing great. How can I help you today?\"},\n\
    \   {\"role\": \"user\", \"content\": \"I'd like to show off how chat templating\
    \ works!\"},\n]\n\nprint(tokenizer.apply_chat_template(chat, tokenize=False))\n\
    \n# Remove system prompt\nchat = chat[1:]\n\nprint(\"\\nUsing default system prompt!\\\
    n\")\n\nprint(tokenizer.apply_chat_template(chat, tokenize=False))\n```\n\noutput:\n\
    ```\n<|im_start|>system\nThis is a system prompt!\n<|im_start|>user\nHello, how\
    \ are you?<|im_end|>\n<|im_start|>assistant\nI'm doing great. How can I help you\
    \ today?<|im_end|><|endoftext|>\n<|im_start|>user\nI'd like to show off how chat\
    \ templating works!<|im_end|>\n\nUsing default system prompt!\n\n<|im_start|>system\n\
    A conversation between a user and an LLM-based AI assistant. The assistant gives\
    \ helpful and honest answers.\n<|im_start|>user\nHello, how are you?<|im_end|>\n\
    <|im_start|>assistant\nI'm doing great. How can I help you today?<|im_end|><|endoftext|>\n\
    <|im_start|>user\nI'd like to show off how chat templating works!<|im_end|>\n\
    ```"
  created_at: 2024-01-10 21:51:08+00:00
  edited: true
  hidden: false
  id: 659f114c9af5011d2a87980f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/21a9a778ee5350a1e620d2bd848ee581.svg
      fullname: Irene Dea
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: irenedea
      type: user
    createdAt: '2024-01-10T21:51:08.000Z'
    data:
      oid: ed874721edb9a72f228b5379b4d488daebb57ed4
      parents:
      - df5a0d74bf7a93f8f76f64ae6b45e2b996ca4764
      subject: Add chat_template to tokenizer_config.json
    id: 659f114c0000000000000000
    type: commit
  author: irenedea
  created_at: 2024-01-10 21:51:08+00:00
  id: 659f114c0000000000000000
  oid: ed874721edb9a72f228b5379b4d488daebb57ed4
  summary: Add chat_template to tokenizer_config.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1611612244659-5e7bd6f730dc073f817a2ba8.jpeg?w=200&h=200&f=face
      fullname: Daniel King
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: daking
      type: user
    createdAt: '2024-01-10T22:41:05.000Z'
    data:
      edited: false
      editors:
      - daking
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9716834425926208
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1611612244659-5e7bd6f730dc073f817a2ba8.jpeg?w=200&h=200&f=face
          fullname: Daniel King
          isHf: false
          isPro: false
          name: daking
          type: user
        html: "<p>LGTM, please get <span data-props=\"{&quot;user&quot;:&quot;sam-mosaic&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sam-mosaic\"\
          >@<span class=\"underline\">sam-mosaic</span></a></span>\n\n\t</span></span>\
          \ to sign off as well.</p>\n"
        raw: LGTM, please get @sam-mosaic to sign off as well.
        updatedAt: '2024-01-10T22:41:05.522Z'
      numEdits: 0
      reactions: []
    id: 659f1d0181f61dd740105b1c
    type: comment
  author: daking
  content: LGTM, please get @sam-mosaic to sign off as well.
  created_at: 2024-01-10 22:41:05+00:00
  edited: false
  hidden: false
  id: 659f1d0181f61dd740105b1c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
      fullname: Sam Havens
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sam-mosaic
      type: user
    createdAt: '2024-01-11T06:50:25.000Z'
    data:
      edited: false
      editors:
      - sam-mosaic
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9725623726844788
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
          fullname: Sam Havens
          isHf: false
          isPro: false
          name: sam-mosaic
          type: user
        html: '<p>The default system prompt should be one of the two it saw during
          training (which is different than the default for the 7b-8k and 30b models),
          either</p>

          <pre><code>You are Assistant. You were made to answer questions and be helpful.

          - You follow instructions

          - You are polite

          - You are helpful

          - You are friendly

          </code></pre>

          <p>or </p>

          <pre><code>- You are a helpful assistant chatbot trained by MosaicML.

          - You answer questions.

          - You are excited to be able to help the user, but will refuse to do anything
          that could be considered harmful to the user.

          - You are more than just an information source, you are also able to write
          poetry, short stories, and make jokes.

          </code></pre>

          '
        raw: "The default system prompt should be one of the two it saw during training\
          \ (which is different than the default for the 7b-8k and 30b models), either\n\
          \n```\nYou are Assistant. You were made to answer questions and be helpful.\n\
          - You follow instructions\n- You are polite\n- You are helpful\n- You are\
          \ friendly\n```\n\nor \n\n```\n- You are a helpful assistant chatbot trained\
          \ by MosaicML.\n- You answer questions.\n- You are excited to be able to\
          \ help the user, but will refuse to do anything that could be considered\
          \ harmful to the user.\n- You are more than just an information source,\
          \ you are also able to write poetry, short stories, and make jokes.\n```"
        updatedAt: '2024-01-11T06:50:25.942Z'
      numEdits: 0
      reactions: []
    id: 659f8fb121c219062cf3c3ef
    type: comment
  author: sam-mosaic
  content: "The default system prompt should be one of the two it saw during training\
    \ (which is different than the default for the 7b-8k and 30b models), either\n\
    \n```\nYou are Assistant. You were made to answer questions and be helpful.\n\
    - You follow instructions\n- You are polite\n- You are helpful\n- You are friendly\n\
    ```\n\nor \n\n```\n- You are a helpful assistant chatbot trained by MosaicML.\n\
    - You answer questions.\n- You are excited to be able to help the user, but will\
    \ refuse to do anything that could be considered harmful to the user.\n- You are\
    \ more than just an information source, you are also able to write poetry, short\
    \ stories, and make jokes.\n```"
  created_at: 2024-01-11 06:50:25+00:00
  edited: false
  hidden: false
  id: 659f8fb121c219062cf3c3ef
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 40
repo_id: mosaicml/mpt-7b-chat
repo_type: model
status: open
target_branch: refs/heads/main
title: Add chat_template to tokenizer_config.json
