!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lvkaokao
conflicting_files: null
created_at: 2023-06-06 15:19:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
      fullname: lvkaokao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lvkaokao
      type: user
    createdAt: '2023-06-06T16:19:55.000Z'
    data:
      edited: true
      editors:
      - lvkaokao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4487341046333313
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
          fullname: lvkaokao
          isHf: false
          isPro: false
          name: lvkaokao
          type: user
        html: '<p>when I use the latest code for inference, it can''t generate longer
          text as shown below:<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/630881ff6fb2ea4413f16390/kESs-OBIHAXjau9alM9ZV.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/630881ff6fb2ea4413f16390/kESs-OBIHAXjau9alM9ZV.png"></a></p>

          <p>however, when I revert to the previous version, it works.</p>

          '
        raw: 'when I use the latest code for inference, it can''t generate longer
          text as shown below:

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/630881ff6fb2ea4413f16390/kESs-OBIHAXjau9alM9ZV.png)


          however, when I revert to the previous version, it works.'
        updatedAt: '2023-06-06T16:23:17.377Z'
      numEdits: 1
      reactions: []
    id: 647f5cab35bc6d6aa5fbe70a
    type: comment
  author: lvkaokao
  content: 'when I use the latest code for inference, it can''t generate longer text
    as shown below:

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/630881ff6fb2ea4413f16390/kESs-OBIHAXjau9alM9ZV.png)


    however, when I revert to the previous version, it works.'
  created_at: 2023-06-06 15:19:55+00:00
  edited: true
  hidden: false
  id: 647f5cab35bc6d6aa5fbe70a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c94ea2029955a4660b91f08a342fbcef.svg
      fullname: Kim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pathlighter
      type: user
    createdAt: '2023-06-08T05:26:00.000Z'
    data:
      edited: false
      editors:
      - pathlighter
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.969673752784729
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c94ea2029955a4660b91f08a342fbcef.svg
          fullname: Kim
          isHf: false
          isPro: false
          name: pathlighter
          type: user
        html: '<p>I have also similar issues.  BTW, how can I revert to the previous
          version?  Where can I find a revision info?</p>

          '
        raw: I have also similar issues.  BTW, how can I revert to the previous version?  Where
          can I find a revision info?
        updatedAt: '2023-06-08T05:26:00.695Z'
      numEdits: 0
      reactions: []
    id: 6481666840facadc557b8c39
    type: comment
  author: pathlighter
  content: I have also similar issues.  BTW, how can I revert to the previous version?  Where
    can I find a revision info?
  created_at: 2023-06-08 04:26:00+00:00
  edited: false
  hidden: false
  id: 6481666840facadc557b8c39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
      fullname: Abhi Venigalla
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: abhi-mosaic
      type: user
    createdAt: '2023-06-08T14:21:20.000Z'
    data:
      edited: true
      editors:
      - abhi-mosaic
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.931927502155304
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676410153781-63ebfcf06ef3ce22b887cb04.jpeg?w=200&h=200&f=face
          fullname: Abhi Venigalla
          isHf: false
          isPro: false
          name: abhi-mosaic
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;lvkaokao&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/lvkaokao\"\
          >@<span class=\"underline\">lvkaokao</span></a></span>\n\n\t</span></span>,\
          \ could you please share the code and torch version you are using? As a\
          \ hunch, if you are altering <code>config.max_seq_len</code>, that will\
          \ initialize the <code>attn_bias</code> to that shape at model init time,\
          \ and you won't be able to generate sequences longer than that. So if you'd\
          \ like to generate sequences of size K, make sure that <code>config.max_seq_len</code>\
          \ is set &gt;K.</p>\n"
        raw: Hi @lvkaokao, could you please share the code and torch version you are
          using? As a hunch, if you are altering `config.max_seq_len`, that will initialize
          the `attn_bias` to that shape at model init time, and you won't be able
          to generate sequences longer than that. So if you'd like to generate sequences
          of size K, make sure that `config.max_seq_len` is set >K.
        updatedAt: '2023-06-08T15:05:00.947Z'
      numEdits: 1
      reactions: []
    id: 6481e3e015c5dc529069da6e
    type: comment
  author: abhi-mosaic
  content: Hi @lvkaokao, could you please share the code and torch version you are
    using? As a hunch, if you are altering `config.max_seq_len`, that will initialize
    the `attn_bias` to that shape at model init time, and you won't be able to generate
    sequences longer than that. So if you'd like to generate sequences of size K,
    make sure that `config.max_seq_len` is set >K.
  created_at: 2023-06-08 13:21:20+00:00
  edited: true
  hidden: false
  id: 6481e3e015c5dc529069da6e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
      fullname: Sam Havens
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sam-mosaic
      type: user
    createdAt: '2023-06-14T07:12:06.000Z'
    data:
      edited: false
      editors:
      - sam-mosaic
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7557342648506165
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1668560930781-noauth.png?w=200&h=200&f=face
          fullname: Sam Havens
          isHf: false
          isPro: false
          name: sam-mosaic
          type: user
        html: '<p>The versions, which can be passed using the <code>revision</code>
          kwarg, are <a href="https://huggingface.co/mosaicml/mpt-7b-chat/commits/main">here</a></p>

          '
        raw: The versions, which can be passed using the `revision` kwarg, are [here](https://huggingface.co/mosaicml/mpt-7b-chat/commits/main)
        updatedAt: '2023-06-14T07:12:06.100Z'
      numEdits: 0
      reactions: []
    id: 648968468fbb6b7ad4575602
    type: comment
  author: sam-mosaic
  content: The versions, which can be passed using the `revision` kwarg, are [here](https://huggingface.co/mosaicml/mpt-7b-chat/commits/main)
  created_at: 2023-06-14 06:12:06+00:00
  edited: false
  hidden: false
  id: 648968468fbb6b7ad4575602
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63c8ef6c00104ea998d92645/8zVt_tzR2fPgk7s6dA03k.jpeg?w=200&h=200&f=face
      fullname: Deepak  Kaura
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: deepakkaura26
      type: user
    createdAt: '2023-07-05T18:25:48.000Z'
    data:
      edited: false
      editors:
      - deepakkaura26
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9086869955062866
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63c8ef6c00104ea998d92645/8zVt_tzR2fPgk7s6dA03k.jpeg?w=200&h=200&f=face
          fullname: Deepak  Kaura
          isHf: false
          isPro: false
          name: deepakkaura26
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;abhi-mosaic&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/abhi-mosaic\"\
          >@<span class=\"underline\">abhi-mosaic</span></a></span>\n\n\t</span></span>\
          \ and <span data-props=\"{&quot;user&quot;:&quot;sam-mosaic&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sam-mosaic\">@<span class=\"\
          underline\">sam-mosaic</span></a></span>\n\n\t</span></span> can you guys\
          \ help me to show me example that how to run this model on colab's CPU ?</p>\n"
        raw: '@abhi-mosaic and @sam-mosaic can you guys help me to show me example
          that how to run this model on colab''s CPU ?'
        updatedAt: '2023-07-05T18:25:48.917Z'
      numEdits: 0
      reactions: []
    id: 64a5b5ac89f923ab6e36637d
    type: comment
  author: deepakkaura26
  content: '@abhi-mosaic and @sam-mosaic can you guys help me to show me example that
    how to run this model on colab''s CPU ?'
  created_at: 2023-07-05 17:25:48+00:00
  edited: false
  hidden: false
  id: 64a5b5ac89f923ab6e36637d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: mosaicml/mpt-7b-chat
repo_type: model
status: open
target_branch: null
title: there are something wrong when the latest code generate longer text
