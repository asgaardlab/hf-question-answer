!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dduval
conflicting_files: null
created_at: 2023-07-27 21:34:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
      fullname: Daniel Duval
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dduval
      type: user
    createdAt: '2023-07-27T22:34:48.000Z'
    data:
      edited: false
      editors:
      - dduval
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7628172039985657
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
          fullname: Daniel Duval
          isHf: false
          isPro: false
          name: dduval
          type: user
        html: '<p>When trying to load nous-hermes-llama-2-7b.ggmlv3.q5_K_M.bin with
          koboldcpp, or llama.cpp server.exe, I get the following error: </p>

          <p>error loading model: llama.cpp: tensor ''tok_embeddings.weight'' has
          wrong shape; expected  4096 x 32032, got  4096 x 32000<br>llama_load_model_from_file:
          failed to load model</p>

          <p>I guess it''s because of 32032 for n_vocab which is unusual. </p>

          '
        raw: "When trying to load nous-hermes-llama-2-7b.ggmlv3.q5_K_M.bin with koboldcpp,\
          \ or llama.cpp server.exe, I get the following error: \r\n\r\nerror loading\
          \ model: llama.cpp: tensor 'tok_embeddings.weight' has wrong shape; expected\
          \  4096 x 32032, got  4096 x 32000\r\nllama_load_model_from_file: failed\
          \ to load model\r\n\r\nI guess it's because of 32032 for n_vocab which is\
          \ unusual. "
        updatedAt: '2023-07-27T22:34:48.421Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - stri8ted
    id: 64c2f1082941512c4c496505
    type: comment
  author: dduval
  content: "When trying to load nous-hermes-llama-2-7b.ggmlv3.q5_K_M.bin with koboldcpp,\
    \ or llama.cpp server.exe, I get the following error: \r\n\r\nerror loading model:\
    \ llama.cpp: tensor 'tok_embeddings.weight' has wrong shape; expected  4096 x\
    \ 32032, got  4096 x 32000\r\nllama_load_model_from_file: failed to load model\r\
    \n\r\nI guess it's because of 32032 for n_vocab which is unusual. "
  created_at: 2023-07-27 21:34:48+00:00
  edited: false
  hidden: false
  id: 64c2f1082941512c4c496505
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-27T22:36:09.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.987873911857605
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>ah shit. Yeah it is actually 32000, not 32032.  It was incorrectly
          labelled as 32032 at first in the upstream repo.  The files converted fine
          so I thought they were fine but it must have set bad metadata</p>

          <p>I''ll have to do them again I guess. I''ll start that now</p>

          '
        raw: 'ah shit. Yeah it is actually 32000, not 32032.  It was incorrectly labelled
          as 32032 at first in the upstream repo.  The files converted fine so I thought
          they were fine but it must have set bad metadata


          I''ll have to do them again I guess. I''ll start that now'
        updatedAt: '2023-07-27T22:36:09.081Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\u2764\uFE0F"
        users:
        - dduval
        - mHhf
        - mufeed
        - arthurg
    id: 64c2f1597918ee895b9172e3
    type: comment
  author: TheBloke
  content: 'ah shit. Yeah it is actually 32000, not 32032.  It was incorrectly labelled
    as 32032 at first in the upstream repo.  The files converted fine so I thought
    they were fine but it must have set bad metadata


    I''ll have to do them again I guess. I''ll start that now'
  created_at: 2023-07-27 21:36:09+00:00
  edited: false
  hidden: false
  id: 64c2f1597918ee895b9172e3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-27T22:44:15.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9883942604064941
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>The fixed ones are uploading now. Refresh Files and Versions tab
          and wait until the one you want shows a new upload, then you can grab it.  I
          tested them and they work fine now.</p>

          '
        raw: The fixed ones are uploading now. Refresh Files and Versions tab and
          wait until the one you want shows a new upload, then you can grab it.  I
          tested them and they work fine now.
        updatedAt: '2023-07-27T22:44:15.126Z'
      numEdits: 0
      reactions: []
    id: 64c2f33f96b84732a31e7e86
    type: comment
  author: TheBloke
  content: The fixed ones are uploading now. Refresh Files and Versions tab and wait
    until the one you want shows a new upload, then you can grab it.  I tested them
    and they work fine now.
  created_at: 2023-07-27 21:44:15+00:00
  edited: false
  hidden: false
  id: 64c2f33f96b84732a31e7e86
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
      fullname: Daniel Duval
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dduval
      type: user
    createdAt: '2023-07-27T22:47:06.000Z'
    data:
      edited: false
      editors:
      - dduval
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9912019371986389
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
          fullname: Daniel Duval
          isHf: false
          isPro: false
          name: dduval
          type: user
        html: '<p>Yeah, I''ve noticed they''re updating. That was so fast I did not
          have time to make coffee, so I grabbed a beer instead. Cheers and many thanks!
          You''re the best.</p>

          '
        raw: Yeah, I've noticed they're updating. That was so fast I did not have
          time to make coffee, so I grabbed a beer instead. Cheers and many thanks!
          You're the best.
        updatedAt: '2023-07-27T22:47:06.068Z'
      numEdits: 0
      reactions: []
    id: 64c2f3eafcc9fa13aae783b0
    type: comment
  author: dduval
  content: Yeah, I've noticed they're updating. That was so fast I did not have time
    to make coffee, so I grabbed a beer instead. Cheers and many thanks! You're the
    best.
  created_at: 2023-07-27 21:47:06+00:00
  edited: false
  hidden: false
  id: 64c2f3eafcc9fa13aae783b0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Nous-Hermes-Llama-2-7B-GGML
repo_type: model
status: open
target_branch: null
title: Error loading model
