!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bpop
conflicting_files: null
created_at: 2024-01-22 15:02:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0ec70d96c0e78538fc8dd9153bb4220f.svg
      fullname: Ben Peters
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bpop
      type: user
    createdAt: '2024-01-22T15:02:05.000Z'
    data:
      edited: false
      editors:
      - bpop
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9294834733009338
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0ec70d96c0e78538fc8dd9153bb4220f.svg
          fullname: Ben Peters
          isHf: false
          isPro: false
          name: bpop
          type: user
        html: '<p>Hello again,</p>

          <p>I failed to reproduce the TowerInstruct generation example shown on the
          model page. While the example output terminates after generating a single
          sentence, I did not find a simple way to get the model to do so. I suspect
          the reason has to do with a mismatch between the model''s generation_config
          (which specifies eos_token_id=2) and what the model <em>actually</em> uses
          as an end-of-sequence marker ("&lt;|im_end|&gt;", token_id=32005). Since
          they don''t match, generation does not stop when it reaches an &lt;|im_end|&gt;,
          which means it continues to generate until it hits the max length.</p>

          <p>Overriding the default generation config would probably solve this issue
          (I can''t test because I''m waiting for a free GPU), but this seems like
          a slightly clunky fix. Any idea what we should do about it?</p>

          '
        raw: "Hello again,\r\n\r\nI failed to reproduce the TowerInstruct generation\
          \ example shown on the model page. While the example output terminates after\
          \ generating a single sentence, I did not find a simple way to get the model\
          \ to do so. I suspect the reason has to do with a mismatch between the model's\
          \ generation_config (which specifies eos_token_id=2) and what the model\
          \ *actually* uses as an end-of-sequence marker (\"<|im_end|>\", token_id=32005).\
          \ Since they don't match, generation does not stop when it reaches an <|im_end|>,\
          \ which means it continues to generate until it hits the max length.\r\n\
          \r\nOverriding the default generation config would probably solve this issue\
          \ (I can't test because I'm waiting for a free GPU), but this seems like\
          \ a slightly clunky fix. Any idea what we should do about it?"
        updatedAt: '2024-01-22T15:02:05.680Z'
      numEdits: 0
      reactions: []
    id: 65ae836dc92e09d5cd684e00
    type: comment
  author: bpop
  content: "Hello again,\r\n\r\nI failed to reproduce the TowerInstruct generation\
    \ example shown on the model page. While the example output terminates after generating\
    \ a single sentence, I did not find a simple way to get the model to do so. I\
    \ suspect the reason has to do with a mismatch between the model's generation_config\
    \ (which specifies eos_token_id=2) and what the model *actually* uses as an end-of-sequence\
    \ marker (\"<|im_end|>\", token_id=32005). Since they don't match, generation\
    \ does not stop when it reaches an <|im_end|>, which means it continues to generate\
    \ until it hits the max length.\r\n\r\nOverriding the default generation config\
    \ would probably solve this issue (I can't test because I'm waiting for a free\
    \ GPU), but this seems like a slightly clunky fix. Any idea what we should do\
    \ about it?"
  created_at: 2024-01-22 15:02:05+00:00
  edited: false
  hidden: false
  id: 65ae836dc92e09d5cd684e00
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64132452d8a418df415a6ded/H9C5KINWX4hq0iOoyj7Sy.jpeg?w=200&h=200&f=face
      fullname: Duarte Alves
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: DuarteMRAlves
      type: user
    createdAt: '2024-01-22T18:13:38.000Z'
    data:
      edited: true
      editors:
      - DuarteMRAlves
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.980246901512146
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64132452d8a418df415a6ded/H9C5KINWX4hq0iOoyj7Sy.jpeg?w=200&h=200&f=face
          fullname: Duarte Alves
          isHf: false
          isPro: false
          name: DuarteMRAlves
          type: user
        html: '<p>Hi,</p>

          <p>Thank you for noticing!<br>I have fixed the generation config and tested
          it. It should work as expected.</p>

          <p>Can you check on your side if it works now (you may need to redownload
          it)?</p>

          '
        raw: 'Hi,


          Thank you for noticing!

          I have fixed the generation config and tested it. It should work as expected.


          Can you check on your side if it works now (you may need to redownload it)?'
        updatedAt: '2024-01-22T18:14:08.483Z'
      numEdits: 1
      reactions: []
    id: 65aeb05277ce425d18f576c5
    type: comment
  author: DuarteMRAlves
  content: 'Hi,


    Thank you for noticing!

    I have fixed the generation config and tested it. It should work as expected.


    Can you check on your side if it works now (you may need to redownload it)?'
  created_at: 2024-01-22 18:13:38+00:00
  edited: true
  hidden: false
  id: 65aeb05277ce425d18f576c5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8613a2b60856b6d5a7b49c2fdf82f9e8.svg
      fullname: Jaime Lugo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JaimeLugo
      type: user
    createdAt: '2024-01-23T17:02:20.000Z'
    data:
      edited: false
      editors:
      - JaimeLugo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9351799488067627
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8613a2b60856b6d5a7b49c2fdf82f9e8.svg
          fullname: Jaime Lugo
          isHf: false
          isPro: false
          name: JaimeLugo
          type: user
        html: '<p>Hey Duarte and bpop, thanks for the comments... I am traveling but
          will share with you my findings in three days. Will download the generation
          config and test it.  </p>

          '
        raw: 'Hey Duarte and bpop, thanks for the comments... I am traveling but will
          share with you my findings in three days. Will download the generation config
          and test it.  '
        updatedAt: '2024-01-23T17:02:20.577Z'
      numEdits: 0
      reactions: []
    id: 65aff11c165e69e0e679d00f
    type: comment
  author: JaimeLugo
  content: 'Hey Duarte and bpop, thanks for the comments... I am traveling but will
    share with you my findings in three days. Will download the generation config
    and test it.  '
  created_at: 2024-01-23 17:02:20+00:00
  edited: false
  hidden: false
  id: 65aff11c165e69e0e679d00f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: Unbabel/TowerInstruct-7B-v0.1
repo_type: model
status: open
target_branch: null
title: Generation does not terminate on the eos type used in prompting
