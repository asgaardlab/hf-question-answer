!!python/object:huggingface_hub.community.DiscussionWithDetails
author: haimingyu
conflicting_files: null
created_at: 2023-11-07 02:29:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/16bc9b4648d6b33be63f12c5f7e8b5bb.svg
      fullname: haimingyu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: haimingyu
      type: user
    createdAt: '2023-11-07T02:29:16.000Z'
    data:
      edited: true
      editors:
      - haimingyu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3501124680042267
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/16bc9b4648d6b33be63f12c5f7e8b5bb.svg
          fullname: haimingyu
          isHf: false
          isPro: false
          name: haimingyu
          type: user
        html: "<p>When I tried to enlarge the image, something went wrong</p>\n<p><a\
          \ rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/642655e82a423daad52cb14c/NXnfXkjogD2afbfqR4WJJ.png\"\
          ><img alt=\"01-1.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/642655e82a423daad52cb14c/NXnfXkjogD2afbfqR4WJJ.png\"\
          ></a></p>\n<p>config</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/642655e82a423daad52cb14c/9Ulo1FMh_8mGdWgeorW7L.jpeg\"\
          ><img alt=\"\u5FAE\u4FE1\u622A\u56FE_20231107102800.jpeg\" src=\"https://cdn-uploads.huggingface.co/production/uploads/642655e82a423daad52cb14c/9Ulo1FMh_8mGdWgeorW7L.jpeg\"\
          ></a></p>\n<p>error msg</p>\n<pre><code>---\n2023-11-07 10:23:55,024 - ControlNet\
          \ - INFO - Loading model: control_v11p_sd15_inpaint [ebff9138]\n2023-11-07\
          \ 10:23:57,736 - ControlNet - INFO - Loaded state_dict from [E:\\AIProject\\\
          sd-webui-aki-v4.4\\models\\ControlNet\\control_v11p_sd15_inpaint.pth]\n\
          2023-11-07 10:23:57,736 - ControlNet - INFO - controlnet_default_config\n\
          2023-11-07 10:24:00,940 - ControlNet - INFO - ControlNet model control_v11p_sd15_inpaint\
          \ [ebff9138] loaded.\n2023-11-07 10:24:01,104 - ControlNet - INFO - using\
          \ inpaint as input\n2023-11-07 10:24:01,118 - ControlNet - INFO - Loading\
          \ preprocessor: inpaint_only\n2023-11-07 10:24:01,118 - ControlNet - INFO\
          \ - preprocessor resolution = 512\n2023-11-07 10:24:01,192 - ControlNet\
          \ - INFO - ControlNet Hooked - Time = 6.18020224571228\n2023-11-07 10:24:01,359\
          \ - ControlNet - INFO - ControlNet used torch.float16 VAE to encode torch.Size([1,\
          \ 4, 96, 64]).\n*** Error completing request\n*** Arguments: ('task(7t38e1k7917dhs7)',\
          \ 'clownfish,coral reef,bubble,kelp,', '3d,realistic,badhandv4:1.4,EasyNegative,ng_deepnegative_v1_75t,bad\
          \ anatomy,futa,sketches,(worst quality:2),(low quality:2),(normal quality:2),lowres,normal\
          \ quality,monochrome,grayscale,(pointed chin),skin spots,acnes,skin blemishes(fat:1.2),facing\
          \ away,looking away,', [], 20, 'Euler a', 1, 1, 7, 768, 512, False, 0.7,\
          \ 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', '', '',\
          \ [], &lt;gradio.routes.Request object at 0x000002217C044D30&gt;, 0, False,\
          \ '', 0.8, 3483093119, False, -1, 0, 0, 0, False, 'MultiDiffusion', False,\
          \ True, 1024, 1024, 96, 96, 48, 4, 'None', 2, False, 10, 1, 1, 64, False,\
          \ False, False, False, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background',\
          \ 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0,\
          \ False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0, False, 0.4,\
          \ 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0, False, 0.4, 0.4, 0.2,\
          \ 0.2, '', '', 'Background', 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '',\
          \ 'Background', 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background',\
          \ 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0,\
          \ False, 3072, 192, True, True, True, False, &lt;scripts.animatediff_ui.AnimateDiffProcess\
          \ object at 0x000002217C39C730&gt;, &lt;scripts.controlnet_ui.controlnet_ui_group.UiControlNetUnit\
          \ object at 0x000002217C39C910&gt;, &lt;scripts.controlnet_ui.controlnet_ui_group.UiControlNetUnit\
          \ object at 0x000002217C17C700&gt;, &lt;scripts.controlnet_ui.controlnet_ui_group.UiControlNetUnit\
          \ object at 0x000002217C17E920&gt;, 'NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\\
          nALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\\nINS:1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0\\\
          nIND:1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0\\nINALL:1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0\\\
          nMIDD:1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0\\nOUTD:1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0\\\
          nOUTS:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1\\nOUTALL:1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1\\\
          nALL0.5:0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5',\
          \ True, 0, 'values', '0,0.25,0.5,0.75,1', 'Block ID', 'IN05-OUT05', 'none',\
          \ '', '0.5,1', 'BASE,IN00,IN01,IN02,IN03,IN04,IN05,IN06,IN07,IN08,IN09,IN10,IN11,M00,OUT00,OUT01,OUT02,OUT03,OUT04,OUT05,OUT06,OUT07,OUT08,OUT09,OUT10,OUT11',\
          \ 1.0, 'black', '20', False, 'ATTNDEEPON:IN05-OUT05:attn:1\\n\\nATTNDEEPOFF:IN05-OUT05:attn:0\\\
          n\\nPROJDEEPOFF:IN05-OUT05:proj:0\\n\\nXYZ:::1', False, False, False, False,\
          \ 0, None, [], 0, False, [], [], False, 0, 1, False, False, 0, None, [],\
          \ -2, False, [], False, 0, None, None, False, False, 'positive', 'comma',\
          \ 0, False, False, '', 1, '', [], 0, '', [], 0, '', [], True, False, False,\
          \ False, 0, False, None, None, False, None, None, False, None, None, False,\
          \ 50, 'NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\nALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\\\
          nINS:1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0\\nIND:1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0\\\
          nINALL:1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0\\nMIDD:1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0\\\
          nOUTD:1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0\\nOUTS:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1\\\
          nOUTALL:1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1\\nALL0.5:0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5',\
          \ True, 0, 'values', '0,0.25,0.5,0.75,1', 'Block ID', 'IN05-OUT05', 'none',\
          \ '', '0.5,1', 'BASE,IN00,IN01,IN02,IN03,IN04,IN05,IN06,IN07,IN08,IN09,IN10,IN11,M00,OUT00,OUT01,OUT02,OUT03,OUT04,OUT05,OUT06,OUT07,OUT08,OUT09,OUT10,OUT11',\
          \ 1.0, 'black', '20', False, 'ATTNDEEPON:IN05-OUT05:attn:1\\n\\nATTNDEEPOFF:IN05-OUT05:attn:0\\\
          n\\nPROJDEEPOFF:IN05-OUT05:proj:0\\n\\nXYZ:::1', False, False) {}\n    Traceback\
          \ (most recent call last):\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          modules\\call_queue.py\", line 57, in f\n        res = list(func(*args,\
          \ **kwargs))\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\call_queue.py\"\
          , line 36, in f\n        res = func(*args, **kwargs)\n      File \"E:\\\
          AIProject\\sd-webui-aki-v4.4\\modules\\txt2img.py\", line 55, in txt2img\n\
          \        processed = processing.process_images(p)\n      File \"E:\\AIProject\\\
          sd-webui-aki-v4.4\\modules\\processing.py\", line 732, in process_images\n\
          \        res = process_images_inner(p)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          extensions\\sd-webui-controlnet\\scripts\\batch_hijack.py\", line 42, in\
          \ processing_process_images_hijack\n        return getattr(processing, '__controlnet_original_process_images_inner')(p,\
          \ *args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\\
          processing.py\", line 867, in process_images_inner\n        samples_ddim\
          \ = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds,\
          \ subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
          scripts\\hook.py\", line 451, in process_sample\n        return process.sample_before_CN_hack(*args,\
          \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\processing.py\"\
          , line 1140, in sample\n        samples = self.sampler.sample(self, x, conditioning,\
          \ unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_samplers_kdiffusion.py\"\
          , line 235, in sample\n        samples = self.launch_sampling(steps, lambda:\
          \ self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args,\
          \ disable=False, callback=self.callback_state, **extra_params_kwargs))\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_samplers_common.py\"\
          , line 261, in launch_sampling\n        return func()\n      File \"E:\\\
          AIProject\\sd-webui-aki-v4.4\\modules\\sd_samplers_kdiffusion.py\", line\
          \ 235, in &lt;lambda&gt;\n        samples = self.launch_sampling(steps,\
          \ lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args,\
          \ disable=False, callback=self.callback_state, **extra_params_kwargs))\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\utils\\_contextlib.py\", line 115, in decorate_context\n        return\
          \ func(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          repositories\\k-diffusion\\k_diffusion\\sampling.py\", line 145, in sample_euler_ancestral\n\
          \        denoised = model(x, sigmas[i] * s_in, **extra_args)\n      File\
          \ \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\\
          nn\\modules\\module.py\", line 1501, in _call_impl\n        return forward_call(*args,\
          \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_samplers_cfg_denoiser.py\"\
          , line 188, in forward\n        x_out[a:b] = self.inner_model(x_in[a:b],\
          \ sigma_in[a:b], cond=make_condition_dict(c_crossattn, image_cond_in[a:b]))\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return\
          \ forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          repositories\\k-diffusion\\k_diffusion\\external.py\", line 112, in forward\n\
          \        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\k-diffusion\\\
          k_diffusion\\external.py\", line 138, in get_eps\n        return self.inner_model.apply_model(*args,\
          \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_models_xl.py\"\
          , line 37, in apply_model\n        return self.model(x, t, cond)\n     \
          \ File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return\
          \ forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          modules\\sd_hijack_utils.py\", line 17, in &lt;lambda&gt;\n        setattr(resolved_obj,\
          \ func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n      File\
          \ \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_hijack_utils.py\", line\
          \ 28, in __call__\n        return self.__orig_func(*args, **kwargs)\n  \
          \    File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\generative-models\\\
          sgm\\modules\\diffusionmodules\\wrappers.py\", line 28, in forward\n   \
          \     return self.diffusion_model(\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501,\
          \ in _call_impl\n        return forward_call(*args, **kwargs)\n      File\
          \ \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
          scripts\\hook.py\", line 853, in forward_webui\n        raise e\n      File\
          \ \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
          scripts\\hook.py\", line 850, in forward_webui\n        return forward(*args,\
          \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\\
          sd-webui-controlnet\\scripts\\hook.py\", line 591, in forward\n        control\
          \ = param.control_model(x=x_in, hint=hint, timesteps=timesteps, context=context,\
          \ y=y)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return\
          \ forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          extensions\\sd-webui-controlnet\\scripts\\cldm.py\", line 31, in forward\n\
          \        return self.control_model(*args, **kwargs)\n      File \"E:\\AIProject\\\
          sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\"\
          , line 1501, in _call_impl\n        return forward_call(*args, **kwargs)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
          scripts\\cldm.py\", line 314, in forward\n        h = module(h, emb, context)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return\
          \ forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          repositories\\generative-models\\sgm\\modules\\diffusionmodules\\openaimodel.py\"\
          , line 100, in forward\n        x = layer(x, context)\n      File \"E:\\\
          AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\nn\\modules\\\
          module.py\", line 1501, in _call_impl\n        return forward_call(*args,\
          \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\\
          generative-models\\sgm\\modules\\attention.py\", line 627, in forward\n\
          \        x = block(x, context=context[i])\n      File \"E:\\AIProject\\\
          sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\"\
          , line 1501, in _call_impl\n        return forward_call(*args, **kwargs)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\generative-models\\\
          sgm\\modules\\attention.py\", line 459, in forward\n        return checkpoint(\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\generative-models\\\
          sgm\\modules\\diffusionmodules\\util.py\", line 167, in checkpoint\n   \
          \     return func(*inputs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          repositories\\generative-models\\sgm\\modules\\attention.py\", line 478,\
          \ in _forward\n        self.attn2(\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501,\
          \ in _call_impl\n        return forward_call(*args, **kwargs)\n      File\
          \ \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_hijack_optimizations.py\"\
          , line 486, in xformers_attention_forward\n        k_in = self.to_k(context_k)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return\
          \ forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          extensions-builtin\\Lora\\networks.py\", line 429, in network_Linear_forward\n\
          \        return originals.Linear_forward(self, input)\n      File \"E:\\\
          AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\nn\\modules\\\
          linear.py\", line 114, in forward\n        return F.linear(input, self.weight,\
          \ self.bias)\n    RuntimeError: mat1 and mat2 shapes cannot be multiplied\
          \ (77x2048 and 768x320)\n\u63D0\u793A\uFF1APython \u8FD0\u884C\u65F6\u629B\
          \u51FA\u4E86\u4E00\u4E2A\u5F02\u5E38\u3002\u8BF7\u68C0\u67E5\u7591\u96BE\
          \u89E3\u7B54\u9875\u9762\u3002\n</code></pre>\n"
        raw: "When I tried to enlarge the image, something went wrong\n\n![01-1.png](https://cdn-uploads.huggingface.co/production/uploads/642655e82a423daad52cb14c/NXnfXkjogD2afbfqR4WJJ.png)\n\
          \nconfig\n\n\n![\u5FAE\u4FE1\u622A\u56FE_20231107102800.jpeg](https://cdn-uploads.huggingface.co/production/uploads/642655e82a423daad52cb14c/9Ulo1FMh_8mGdWgeorW7L.jpeg)\n\
          \nerror msg\n```\n---\n2023-11-07 10:23:55,024 - ControlNet - INFO - Loading\
          \ model: control_v11p_sd15_inpaint [ebff9138]\n2023-11-07 10:23:57,736 -\
          \ ControlNet - INFO - Loaded state_dict from [E:\\AIProject\\sd-webui-aki-v4.4\\\
          models\\ControlNet\\control_v11p_sd15_inpaint.pth]\n2023-11-07 10:23:57,736\
          \ - ControlNet - INFO - controlnet_default_config\n2023-11-07 10:24:00,940\
          \ - ControlNet - INFO - ControlNet model control_v11p_sd15_inpaint [ebff9138]\
          \ loaded.\n2023-11-07 10:24:01,104 - ControlNet - INFO - using inpaint as\
          \ input\n2023-11-07 10:24:01,118 - ControlNet - INFO - Loading preprocessor:\
          \ inpaint_only\n2023-11-07 10:24:01,118 - ControlNet - INFO - preprocessor\
          \ resolution = 512\n2023-11-07 10:24:01,192 - ControlNet - INFO - ControlNet\
          \ Hooked - Time = 6.18020224571228\n2023-11-07 10:24:01,359 - ControlNet\
          \ - INFO - ControlNet used torch.float16 VAE to encode torch.Size([1, 4,\
          \ 96, 64]).\n*** Error completing request\n*** Arguments: ('task(7t38e1k7917dhs7)',\
          \ 'clownfish,coral reef,bubble,kelp,', '3d,realistic,badhandv4:1.4,EasyNegative,ng_deepnegative_v1_75t,bad\
          \ anatomy,futa,sketches,(worst quality:2),(low quality:2),(normal quality:2),lowres,normal\
          \ quality,monochrome,grayscale,(pointed chin),skin spots,acnes,skin blemishes(fat:1.2),facing\
          \ away,looking away,', [], 20, 'Euler a', 1, 1, 7, 768, 512, False, 0.7,\
          \ 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', '', '',\
          \ [], <gradio.routes.Request object at 0x000002217C044D30>, 0, False, '',\
          \ 0.8, 3483093119, False, -1, 0, 0, 0, False, 'MultiDiffusion', False, True,\
          \ 1024, 1024, 96, 96, 48, 4, 'None', 2, False, 10, 1, 1, 64, False, False,\
          \ False, False, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0,\
          \ False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0, False, 0.4,\
          \ 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0, False, 0.4, 0.4, 0.2,\
          \ 0.2, '', '', 'Background', 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '',\
          \ 'Background', 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background',\
          \ 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0,\
          \ False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0, False, 3072,\
          \ 192, True, True, True, False, <scripts.animatediff_ui.AnimateDiffProcess\
          \ object at 0x000002217C39C730>, <scripts.controlnet_ui.controlnet_ui_group.UiControlNetUnit\
          \ object at 0x000002217C39C910>, <scripts.controlnet_ui.controlnet_ui_group.UiControlNetUnit\
          \ object at 0x000002217C17C700>, <scripts.controlnet_ui.controlnet_ui_group.UiControlNetUnit\
          \ object at 0x000002217C17E920>, 'NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\\
          nALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\\nINS:1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0\\\
          nIND:1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0\\nINALL:1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0\\\
          nMIDD:1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0\\nOUTD:1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0\\\
          nOUTS:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1\\nOUTALL:1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1\\\
          nALL0.5:0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5',\
          \ True, 0, 'values', '0,0.25,0.5,0.75,1', 'Block ID', 'IN05-OUT05', 'none',\
          \ '', '0.5,1', 'BASE,IN00,IN01,IN02,IN03,IN04,IN05,IN06,IN07,IN08,IN09,IN10,IN11,M00,OUT00,OUT01,OUT02,OUT03,OUT04,OUT05,OUT06,OUT07,OUT08,OUT09,OUT10,OUT11',\
          \ 1.0, 'black', '20', False, 'ATTNDEEPON:IN05-OUT05:attn:1\\n\\nATTNDEEPOFF:IN05-OUT05:attn:0\\\
          n\\nPROJDEEPOFF:IN05-OUT05:proj:0\\n\\nXYZ:::1', False, False, False, False,\
          \ 0, None, [], 0, False, [], [], False, 0, 1, False, False, 0, None, [],\
          \ -2, False, [], False, 0, None, None, False, False, 'positive', 'comma',\
          \ 0, False, False, '', 1, '', [], 0, '', [], 0, '', [], True, False, False,\
          \ False, 0, False, None, None, False, None, None, False, None, None, False,\
          \ 50, 'NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\nALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\\\
          nINS:1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0\\nIND:1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0\\\
          nINALL:1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0\\nMIDD:1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0\\\
          nOUTD:1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0\\nOUTS:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1\\\
          nOUTALL:1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1\\nALL0.5:0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5',\
          \ True, 0, 'values', '0,0.25,0.5,0.75,1', 'Block ID', 'IN05-OUT05', 'none',\
          \ '', '0.5,1', 'BASE,IN00,IN01,IN02,IN03,IN04,IN05,IN06,IN07,IN08,IN09,IN10,IN11,M00,OUT00,OUT01,OUT02,OUT03,OUT04,OUT05,OUT06,OUT07,OUT08,OUT09,OUT10,OUT11',\
          \ 1.0, 'black', '20', False, 'ATTNDEEPON:IN05-OUT05:attn:1\\n\\nATTNDEEPOFF:IN05-OUT05:attn:0\\\
          n\\nPROJDEEPOFF:IN05-OUT05:proj:0\\n\\nXYZ:::1', False, False) {}\n    Traceback\
          \ (most recent call last):\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          modules\\call_queue.py\", line 57, in f\n        res = list(func(*args,\
          \ **kwargs))\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\call_queue.py\"\
          , line 36, in f\n        res = func(*args, **kwargs)\n      File \"E:\\\
          AIProject\\sd-webui-aki-v4.4\\modules\\txt2img.py\", line 55, in txt2img\n\
          \        processed = processing.process_images(p)\n      File \"E:\\AIProject\\\
          sd-webui-aki-v4.4\\modules\\processing.py\", line 732, in process_images\n\
          \        res = process_images_inner(p)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          extensions\\sd-webui-controlnet\\scripts\\batch_hijack.py\", line 42, in\
          \ processing_process_images_hijack\n        return getattr(processing, '__controlnet_original_process_images_inner')(p,\
          \ *args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\\
          processing.py\", line 867, in process_images_inner\n        samples_ddim\
          \ = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds,\
          \ subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
          scripts\\hook.py\", line 451, in process_sample\n        return process.sample_before_CN_hack(*args,\
          \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\processing.py\"\
          , line 1140, in sample\n        samples = self.sampler.sample(self, x, conditioning,\
          \ unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_samplers_kdiffusion.py\"\
          , line 235, in sample\n        samples = self.launch_sampling(steps, lambda:\
          \ self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args,\
          \ disable=False, callback=self.callback_state, **extra_params_kwargs))\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_samplers_common.py\"\
          , line 261, in launch_sampling\n        return func()\n      File \"E:\\\
          AIProject\\sd-webui-aki-v4.4\\modules\\sd_samplers_kdiffusion.py\", line\
          \ 235, in <lambda>\n        samples = self.launch_sampling(steps, lambda:\
          \ self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args,\
          \ disable=False, callback=self.callback_state, **extra_params_kwargs))\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\utils\\_contextlib.py\", line 115, in decorate_context\n        return\
          \ func(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          repositories\\k-diffusion\\k_diffusion\\sampling.py\", line 145, in sample_euler_ancestral\n\
          \        denoised = model(x, sigmas[i] * s_in, **extra_args)\n      File\
          \ \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\\
          nn\\modules\\module.py\", line 1501, in _call_impl\n        return forward_call(*args,\
          \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_samplers_cfg_denoiser.py\"\
          , line 188, in forward\n        x_out[a:b] = self.inner_model(x_in[a:b],\
          \ sigma_in[a:b], cond=make_condition_dict(c_crossattn, image_cond_in[a:b]))\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return\
          \ forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          repositories\\k-diffusion\\k_diffusion\\external.py\", line 112, in forward\n\
          \        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\k-diffusion\\\
          k_diffusion\\external.py\", line 138, in get_eps\n        return self.inner_model.apply_model(*args,\
          \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_models_xl.py\"\
          , line 37, in apply_model\n        return self.model(x, t, cond)\n     \
          \ File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return\
          \ forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          modules\\sd_hijack_utils.py\", line 17, in <lambda>\n        setattr(resolved_obj,\
          \ func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n      File\
          \ \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_hijack_utils.py\", line\
          \ 28, in __call__\n        return self.__orig_func(*args, **kwargs)\n  \
          \    File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\generative-models\\\
          sgm\\modules\\diffusionmodules\\wrappers.py\", line 28, in forward\n   \
          \     return self.diffusion_model(\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501,\
          \ in _call_impl\n        return forward_call(*args, **kwargs)\n      File\
          \ \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
          scripts\\hook.py\", line 853, in forward_webui\n        raise e\n      File\
          \ \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
          scripts\\hook.py\", line 850, in forward_webui\n        return forward(*args,\
          \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\\
          sd-webui-controlnet\\scripts\\hook.py\", line 591, in forward\n        control\
          \ = param.control_model(x=x_in, hint=hint, timesteps=timesteps, context=context,\
          \ y=y)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return\
          \ forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          extensions\\sd-webui-controlnet\\scripts\\cldm.py\", line 31, in forward\n\
          \        return self.control_model(*args, **kwargs)\n      File \"E:\\AIProject\\\
          sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\"\
          , line 1501, in _call_impl\n        return forward_call(*args, **kwargs)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
          scripts\\cldm.py\", line 314, in forward\n        h = module(h, emb, context)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return\
          \ forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          repositories\\generative-models\\sgm\\modules\\diffusionmodules\\openaimodel.py\"\
          , line 100, in forward\n        x = layer(x, context)\n      File \"E:\\\
          AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\nn\\modules\\\
          module.py\", line 1501, in _call_impl\n        return forward_call(*args,\
          \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\\
          generative-models\\sgm\\modules\\attention.py\", line 627, in forward\n\
          \        x = block(x, context=context[i])\n      File \"E:\\AIProject\\\
          sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\"\
          , line 1501, in _call_impl\n        return forward_call(*args, **kwargs)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\generative-models\\\
          sgm\\modules\\attention.py\", line 459, in forward\n        return checkpoint(\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\generative-models\\\
          sgm\\modules\\diffusionmodules\\util.py\", line 167, in checkpoint\n   \
          \     return func(*inputs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          repositories\\generative-models\\sgm\\modules\\attention.py\", line 478,\
          \ in _forward\n        self.attn2(\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501,\
          \ in _call_impl\n        return forward_call(*args, **kwargs)\n      File\
          \ \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_hijack_optimizations.py\"\
          , line 486, in xformers_attention_forward\n        k_in = self.to_k(context_k)\n\
          \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return\
          \ forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
          extensions-builtin\\Lora\\networks.py\", line 429, in network_Linear_forward\n\
          \        return originals.Linear_forward(self, input)\n      File \"E:\\\
          AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\nn\\modules\\\
          linear.py\", line 114, in forward\n        return F.linear(input, self.weight,\
          \ self.bias)\n    RuntimeError: mat1 and mat2 shapes cannot be multiplied\
          \ (77x2048 and 768x320)\n\u63D0\u793A\uFF1APython \u8FD0\u884C\u65F6\u629B\
          \u51FA\u4E86\u4E00\u4E2A\u5F02\u5E38\u3002\u8BF7\u68C0\u67E5\u7591\u96BE\
          \u89E3\u7B54\u9875\u9762\u3002\n\n```\n"
        updatedAt: '2023-11-07T02:30:26.860Z'
      numEdits: 1
      reactions: []
    id: 6549a0fc137b7246f03a2e90
    type: comment
  author: haimingyu
  content: "When I tried to enlarge the image, something went wrong\n\n![01-1.png](https://cdn-uploads.huggingface.co/production/uploads/642655e82a423daad52cb14c/NXnfXkjogD2afbfqR4WJJ.png)\n\
    \nconfig\n\n\n![\u5FAE\u4FE1\u622A\u56FE_20231107102800.jpeg](https://cdn-uploads.huggingface.co/production/uploads/642655e82a423daad52cb14c/9Ulo1FMh_8mGdWgeorW7L.jpeg)\n\
    \nerror msg\n```\n---\n2023-11-07 10:23:55,024 - ControlNet - INFO - Loading model:\
    \ control_v11p_sd15_inpaint [ebff9138]\n2023-11-07 10:23:57,736 - ControlNet -\
    \ INFO - Loaded state_dict from [E:\\AIProject\\sd-webui-aki-v4.4\\models\\ControlNet\\\
    control_v11p_sd15_inpaint.pth]\n2023-11-07 10:23:57,736 - ControlNet - INFO -\
    \ controlnet_default_config\n2023-11-07 10:24:00,940 - ControlNet - INFO - ControlNet\
    \ model control_v11p_sd15_inpaint [ebff9138] loaded.\n2023-11-07 10:24:01,104\
    \ - ControlNet - INFO - using inpaint as input\n2023-11-07 10:24:01,118 - ControlNet\
    \ - INFO - Loading preprocessor: inpaint_only\n2023-11-07 10:24:01,118 - ControlNet\
    \ - INFO - preprocessor resolution = 512\n2023-11-07 10:24:01,192 - ControlNet\
    \ - INFO - ControlNet Hooked - Time = 6.18020224571228\n2023-11-07 10:24:01,359\
    \ - ControlNet - INFO - ControlNet used torch.float16 VAE to encode torch.Size([1,\
    \ 4, 96, 64]).\n*** Error completing request\n*** Arguments: ('task(7t38e1k7917dhs7)',\
    \ 'clownfish,coral reef,bubble,kelp,', '3d,realistic,badhandv4:1.4,EasyNegative,ng_deepnegative_v1_75t,bad\
    \ anatomy,futa,sketches,(worst quality:2),(low quality:2),(normal quality:2),lowres,normal\
    \ quality,monochrome,grayscale,(pointed chin),skin spots,acnes,skin blemishes(fat:1.2),facing\
    \ away,looking away,', [], 20, 'Euler a', 1, 1, 7, 768, 512, False, 0.7, 2, 'Latent',\
    \ 0, 0, 0, 'Use same checkpoint', 'Use same sampler', '', '', [], <gradio.routes.Request\
    \ object at 0x000002217C044D30>, 0, False, '', 0.8, 3483093119, False, -1, 0,\
    \ 0, 0, False, 'MultiDiffusion', False, True, 1024, 1024, 96, 96, 48, 4, 'None',\
    \ 2, False, 10, 1, 1, 64, False, False, False, False, False, 0.4, 0.4, 0.2, 0.2,\
    \ '', '', 'Background', 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background',\
    \ 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0, False,\
    \ 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2,\
    \ '', '', 'Background', 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background',\
    \ 0.2, -1.0, False, 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0, False,\
    \ 0.4, 0.4, 0.2, 0.2, '', '', 'Background', 0.2, -1.0, False, 3072, 192, True,\
    \ True, True, False, <scripts.animatediff_ui.AnimateDiffProcess object at 0x000002217C39C730>,\
    \ <scripts.controlnet_ui.controlnet_ui_group.UiControlNetUnit object at 0x000002217C39C910>,\
    \ <scripts.controlnet_ui.controlnet_ui_group.UiControlNetUnit object at 0x000002217C17C700>,\
    \ <scripts.controlnet_ui.controlnet_ui_group.UiControlNetUnit object at 0x000002217C17E920>,\
    \ 'NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\nALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\\\
    nINS:1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0\\nIND:1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0\\\
    nINALL:1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0\\nMIDD:1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0\\\
    nOUTD:1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0\\nOUTS:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1\\\
    nOUTALL:1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1\\nALL0.5:0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5',\
    \ True, 0, 'values', '0,0.25,0.5,0.75,1', 'Block ID', 'IN05-OUT05', 'none', '',\
    \ '0.5,1', 'BASE,IN00,IN01,IN02,IN03,IN04,IN05,IN06,IN07,IN08,IN09,IN10,IN11,M00,OUT00,OUT01,OUT02,OUT03,OUT04,OUT05,OUT06,OUT07,OUT08,OUT09,OUT10,OUT11',\
    \ 1.0, 'black', '20', False, 'ATTNDEEPON:IN05-OUT05:attn:1\\n\\nATTNDEEPOFF:IN05-OUT05:attn:0\\\
    n\\nPROJDEEPOFF:IN05-OUT05:proj:0\\n\\nXYZ:::1', False, False, False, False, 0,\
    \ None, [], 0, False, [], [], False, 0, 1, False, False, 0, None, [], -2, False,\
    \ [], False, 0, None, None, False, False, 'positive', 'comma', 0, False, False,\
    \ '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, 0, False, None,\
    \ None, False, None, None, False, None, None, False, 50, 'NONE:0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\\
    nALL:1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\\nINS:1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0\\\
    nIND:1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0\\nINALL:1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0\\\
    nMIDD:1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0\\nOUTD:1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0\\\
    nOUTS:1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1\\nOUTALL:1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1\\\
    nALL0.5:0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5',\
    \ True, 0, 'values', '0,0.25,0.5,0.75,1', 'Block ID', 'IN05-OUT05', 'none', '',\
    \ '0.5,1', 'BASE,IN00,IN01,IN02,IN03,IN04,IN05,IN06,IN07,IN08,IN09,IN10,IN11,M00,OUT00,OUT01,OUT02,OUT03,OUT04,OUT05,OUT06,OUT07,OUT08,OUT09,OUT10,OUT11',\
    \ 1.0, 'black', '20', False, 'ATTNDEEPON:IN05-OUT05:attn:1\\n\\nATTNDEEPOFF:IN05-OUT05:attn:0\\\
    n\\nPROJDEEPOFF:IN05-OUT05:proj:0\\n\\nXYZ:::1', False, False) {}\n    Traceback\
    \ (most recent call last):\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\\
    call_queue.py\", line 57, in f\n        res = list(func(*args, **kwargs))\n  \
    \    File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\call_queue.py\", line 36,\
    \ in f\n        res = func(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    modules\\txt2img.py\", line 55, in txt2img\n        processed = processing.process_images(p)\n\
    \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\processing.py\", line\
    \ 732, in process_images\n        res = process_images_inner(p)\n      File \"\
    E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\scripts\\batch_hijack.py\"\
    , line 42, in processing_process_images_hijack\n        return getattr(processing,\
    \ '__controlnet_original_process_images_inner')(p, *args, **kwargs)\n      File\
    \ \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\processing.py\", line 867, in process_images_inner\n\
    \        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc,\
    \ seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)\n\
    \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
    scripts\\hook.py\", line 451, in process_sample\n        return process.sample_before_CN_hack(*args,\
    \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\processing.py\"\
    , line 1140, in sample\n        samples = self.sampler.sample(self, x, conditioning,\
    \ unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))\n\
    \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_samplers_kdiffusion.py\"\
    , line 235, in sample\n        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg,\
    \ x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state,\
    \ **extra_params_kwargs))\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\\
    sd_samplers_common.py\", line 261, in launch_sampling\n        return func()\n\
    \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_samplers_kdiffusion.py\"\
    , line 235, in <lambda>\n        samples = self.launch_sampling(steps, lambda:\
    \ self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False,\
    \ callback=self.callback_state, **extra_params_kwargs))\n      File \"E:\\AIProject\\\
    sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\utils\\_contextlib.py\"\
    , line 115, in decorate_context\n        return func(*args, **kwargs)\n      File\
    \ \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\k-diffusion\\k_diffusion\\\
    sampling.py\", line 145, in sample_euler_ancestral\n        denoised = model(x,\
    \ sigmas[i] * s_in, **extra_args)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n\
    \        return forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    modules\\sd_samplers_cfg_denoiser.py\", line 188, in forward\n        x_out[a:b]\
    \ = self.inner_model(x_in[a:b], sigma_in[a:b], cond=make_condition_dict(c_crossattn,\
    \ image_cond_in[a:b]))\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\\
    lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n\
    \        return forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    repositories\\k-diffusion\\k_diffusion\\external.py\", line 112, in forward\n\
    \        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n\
    \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\k-diffusion\\k_diffusion\\\
    external.py\", line 138, in get_eps\n        return self.inner_model.apply_model(*args,\
    \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_models_xl.py\"\
    , line 37, in apply_model\n        return self.model(x, t, cond)\n      File \"\
    E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\nn\\modules\\\
    module.py\", line 1501, in _call_impl\n        return forward_call(*args, **kwargs)\n\
    \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\modules\\sd_hijack_utils.py\"\
    , line 17, in <lambda>\n        setattr(resolved_obj, func_path[-1], lambda *args,\
    \ **kwargs: self(*args, **kwargs))\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    modules\\sd_hijack_utils.py\", line 28, in __call__\n        return self.__orig_func(*args,\
    \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\generative-models\\\
    sgm\\modules\\diffusionmodules\\wrappers.py\", line 28, in forward\n        return\
    \ self.diffusion_model(\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\\
    lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n\
    \        return forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    extensions\\sd-webui-controlnet\\scripts\\hook.py\", line 853, in forward_webui\n\
    \        raise e\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\\
    sd-webui-controlnet\\scripts\\hook.py\", line 850, in forward_webui\n        return\
    \ forward(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\\
    sd-webui-controlnet\\scripts\\hook.py\", line 591, in forward\n        control\
    \ = param.control_model(x=x_in, hint=hint, timesteps=timesteps, context=context,\
    \ y=y)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
    torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return forward_call(*args,\
    \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
    scripts\\cldm.py\", line 31, in forward\n        return self.control_model(*args,\
    \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\\
    torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n        return forward_call(*args,\
    \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\extensions\\sd-webui-controlnet\\\
    scripts\\cldm.py\", line 314, in forward\n        h = module(h, emb, context)\n\
    \      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\\
    nn\\modules\\module.py\", line 1501, in _call_impl\n        return forward_call(*args,\
    \ **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\generative-models\\\
    sgm\\modules\\diffusionmodules\\openaimodel.py\", line 100, in forward\n     \
    \   x = layer(x, context)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\\
    lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n\
    \        return forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    repositories\\generative-models\\sgm\\modules\\attention.py\", line 627, in forward\n\
    \        x = block(x, context=context[i])\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n\
    \        return forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    repositories\\generative-models\\sgm\\modules\\attention.py\", line 459, in forward\n\
    \        return checkpoint(\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\repositories\\\
    generative-models\\sgm\\modules\\diffusionmodules\\util.py\", line 167, in checkpoint\n\
    \        return func(*inputs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    repositories\\generative-models\\sgm\\modules\\attention.py\", line 478, in _forward\n\
    \        self.attn2(\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\python\\\
    lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n\
    \        return forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    modules\\sd_hijack_optimizations.py\", line 486, in xformers_attention_forward\n\
    \        k_in = self.to_k(context_k)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n\
    \        return forward_call(*args, **kwargs)\n      File \"E:\\AIProject\\sd-webui-aki-v4.4\\\
    extensions-builtin\\Lora\\networks.py\", line 429, in network_Linear_forward\n\
    \        return originals.Linear_forward(self, input)\n      File \"E:\\AIProject\\\
    sd-webui-aki-v4.4\\python\\lib\\site-packages\\torch\\nn\\modules\\linear.py\"\
    , line 114, in forward\n        return F.linear(input, self.weight, self.bias)\n\
    \    RuntimeError: mat1 and mat2 shapes cannot be multiplied (77x2048 and 768x320)\n\
    \u63D0\u793A\uFF1APython \u8FD0\u884C\u65F6\u629B\u51FA\u4E86\u4E00\u4E2A\u5F02\
    \u5E38\u3002\u8BF7\u68C0\u67E5\u7591\u96BE\u89E3\u7B54\u9875\u9762\u3002\n\n```\n"
  created_at: 2023-11-07 02:29:16+00:00
  edited: true
  hidden: false
  id: 6549a0fc137b7246f03a2e90
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/KEyWa9GxSlvRBa8rOzOTi.png?w=200&h=200&f=face
      fullname: Chris Mikhaili
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SpockIsSmart
      type: user
    createdAt: '2023-11-16T14:47:54.000Z'
    data:
      edited: false
      editors:
      - SpockIsSmart
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8079485297203064
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/KEyWa9GxSlvRBa8rOzOTi.png?w=200&h=200&f=face
          fullname: Chris Mikhaili
          isHf: false
          isPro: false
          name: SpockIsSmart
          type: user
        html: '<p>I too am having this issue.  I don''t know how to get around the
          " RuntimeError: mat1 and mat2 " error nor do I understand it.<br><a rel="nofollow"
          href="https://cdn-uploads.huggingface.co/production/uploads/645bbe65ca5d8a2977151281/SRhw1Id0jtzXEW9QLdjNB.png"><img
          alt="ezgif-2-3988029cc0.png" src="https://cdn-uploads.huggingface.co/production/uploads/645bbe65ca5d8a2977151281/SRhw1Id0jtzXEW9QLdjNB.png"></a></p>

          '
        raw: "I too am having this issue.  I don't know how to get around the \" RuntimeError:\
          \ mat1 and mat2 \" error nor do I understand it. \n![ezgif-2-3988029cc0.png](https://cdn-uploads.huggingface.co/production/uploads/645bbe65ca5d8a2977151281/SRhw1Id0jtzXEW9QLdjNB.png)\n"
        updatedAt: '2023-11-16T14:47:54.961Z'
      numEdits: 0
      reactions: []
    id: 65562b9a47adf6b4eb02e132
    type: comment
  author: SpockIsSmart
  content: "I too am having this issue.  I don't know how to get around the \" RuntimeError:\
    \ mat1 and mat2 \" error nor do I understand it. \n![ezgif-2-3988029cc0.png](https://cdn-uploads.huggingface.co/production/uploads/645bbe65ca5d8a2977151281/SRhw1Id0jtzXEW9QLdjNB.png)\n"
  created_at: 2023-11-16 14:47:54+00:00
  edited: false
  hidden: false
  id: 65562b9a47adf6b4eb02e132
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/KEyWa9GxSlvRBa8rOzOTi.png?w=200&h=200&f=face
      fullname: Chris Mikhaili
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SpockIsSmart
      type: user
    createdAt: '2023-11-16T14:48:25.000Z'
    data:
      edited: false
      editors:
      - SpockIsSmart
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.42613452672958374
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/KEyWa9GxSlvRBa8rOzOTi.png?w=200&h=200&f=face
          fullname: Chris Mikhaili
          isHf: false
          isPro: false
          name: SpockIsSmart
          type: user
        html: '<p>Error occurred when executing KSampler:</p>

          <p>mat1 and mat2 shapes cannot be multiplied (154x2048 and 768x320)</p>

          <p>File "/workspace/ComfyUI/execution.py", line 153, in recursive_execute<br>output_data,
          output_ui = get_output_data(obj, input_data_all)<br>File "/workspace/ComfyUI/execution.py",
          line 83, in get_output_data<br>return_values = map_node_over_list(obj, input_data_all,
          obj.FUNCTION, allow_interrupt=True)<br>File "/workspace/ComfyUI/execution.py",
          line 76, in map_node_over_list<br>results.append(getattr(obj, func)(**slice_dict(input_data_all,
          i)))<br>File "/workspace/ComfyUI/nodes.py", line 1237, in sample<br>return
          common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive,
          negative, latent_image, denoise=denoise)<br>File "/workspace/ComfyUI/nodes.py",
          line 1207, in common_ksampler<br>samples = comfy.sample.sample(model, noise,
          steps, cfg, sampler_name, scheduler, positive, negative, latent_image,<br>File
          "/workspace/ComfyUI/custom_nodes/ComfyUI-Impact-Pack/modules/impact/sample_error_enhancer.py",
          line 22, in informative_sample<br>raise e<br>File "/workspace/ComfyUI/custom_nodes/ComfyUI-Impact-Pack/modules/impact/sample_error_enhancer.py",
          line 9, in informative_sample<br>return original_sample(*args, **kwargs)<br>File
          "/workspace/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/animatediff/sampling.py",
          line 126, in animatediff_sample<br>return orig_comfy_sample(model, noise,
          *args, **kwargs)<br>File "/workspace/ComfyUI/comfy/sample.py", line 100,
          in sample<br>samples = sampler.sample(noise, positive_copy, negative_copy,
          cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step,
          force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas,
          callback=callback, disable_pbar=disable_pbar, seed=seed)<br>File "/workspace/ComfyUI/comfy/samplers.py",
          line 709, in sample<br>return sample(self.model, noise, positive, negative,
          cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image,
          denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar,
          seed=seed)<br>File "/workspace/ComfyUI/comfy/samplers.py", line 615, in
          sample<br>samples = sampler.sample(model_wrap, sigmas, extra_args, callback,
          noise, latent_image, denoise_mask, disable_pbar)<br>File "/workspace/ComfyUI/comfy/samplers.py",
          line 554, in sample<br>samples = self.sampler_function(model_k, noise, sigmas,
          extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py",
          line 115, in decorate_context<br>return func(*args, **kwargs)<br>File "/workspace/ComfyUI/comfy/k_diffusion/sampling.py",
          line 137, in sample_euler<br>denoised = model(x, sigma_hat * s_in, **extra_args)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>return self._call_impl(*args, **kwargs)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "/workspace/ComfyUI/comfy/samplers.py", line 275, in forward<br>out = self.inner_model(x,
          sigma, cond=cond, uncond=uncond, cond_scale=cond_scale, model_options=model_options,
          seed=seed)<br>File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>return self._call_impl(*args, **kwargs)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in <em>call_impl<br>return forward_call(*args, **kwargs)<br>File
          "/workspace/ComfyUI/comfy/samplers.py", line 265, in forward<br>return self.apply_model(*args,
          **kwargs)<br>File "/workspace/ComfyUI/comfy/samplers.py", line 262, in apply_model<br>out
          = sampling_function(self.inner_model, x, timestep, uncond, cond, cond_scale,
          model_options=model_options, seed=seed)<br>File "/workspace/ComfyUI/comfy/samplers.py",
          line 250, in sampling_function<br>cond, uncond = calc_cond_uncond_batch(model,
          cond, uncond, x, timestep, model_options)<br>File "/workspace/ComfyUI/comfy/samplers.py",
          line 205, in calc_cond_uncond_batch<br>c[''control''] = control.get_control(input_x,
          timestep</em>, c, len(cond_or_uncond))<br>File "/workspace/ComfyUI/comfy/controlnet.py",
          line 166, in get_control<br>control = self.control_model(x=x_noisy.to(self.control_model.dtype),
          hint=self.cond_hint, timesteps=timestep.float(), context=context.to(self.control_model.dtype),
          y=y)<br>File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>return self._call_impl(*args, **kwargs)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "/workspace/ComfyUI/comfy/cldm/cldm.py", line 304, in forward<br>h = module(h,
          emb, context)<br>File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>return self._call_impl(*args, **kwargs)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "/workspace/ComfyUI/comfy/ldm/modules/diffusionmodules/openaimodel.py",
          line 43, in forward<br>x = layer(x, context, transformer_options)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>return self._call_impl(*args, **kwargs)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 560, in forward<br>x
          = block(x, context=context[i], transformer_options=transformer_options)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>return self._call_impl(*args, **kwargs)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 390, in forward<br>return
          checkpoint(self._forward, (x, context, transformer_options), self.parameters(),
          self.checkpoint)<br>File "/workspace/ComfyUI/comfy/ldm/modules/diffusionmodules/util.py",
          line 123, in checkpoint<br>return func(*inputs)<br>File "/workspace/ComfyUI/comfy/ldm/modules/attention.py",
          line 492, in _forward<br>n = self.attn2(n, context=context_attn2, value=value_attn2)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>return self._call_impl(*args, **kwargs)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 358, in forward<br>k
          = self.to_k(context)<br>File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl<br>return self._call_impl(*args, **kwargs)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py",
          line 114, in forward<br>return F.linear(input, self.weight, self.bias)</p>

          '
        raw: 'Error occurred when executing KSampler:


          mat1 and mat2 shapes cannot be multiplied (154x2048 and 768x320)


          File "/workspace/ComfyUI/execution.py", line 153, in recursive_execute

          output_data, output_ui = get_output_data(obj, input_data_all)

          File "/workspace/ComfyUI/execution.py", line 83, in get_output_data

          return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)

          File "/workspace/ComfyUI/execution.py", line 76, in map_node_over_list

          results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))

          File "/workspace/ComfyUI/nodes.py", line 1237, in sample

          return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler,
          positive, negative, latent_image, denoise=denoise)

          File "/workspace/ComfyUI/nodes.py", line 1207, in common_ksampler

          samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler,
          positive, negative, latent_image,

          File "/workspace/ComfyUI/custom_nodes/ComfyUI-Impact-Pack/modules/impact/sample_error_enhancer.py",
          line 22, in informative_sample

          raise e

          File "/workspace/ComfyUI/custom_nodes/ComfyUI-Impact-Pack/modules/impact/sample_error_enhancer.py",
          line 9, in informative_sample

          return original_sample(*args, **kwargs)

          File "/workspace/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/animatediff/sampling.py",
          line 126, in animatediff_sample

          return orig_comfy_sample(model, noise, *args, **kwargs)

          File "/workspace/ComfyUI/comfy/sample.py", line 100, in sample

          samples = sampler.sample(noise, positive_copy, negative_copy, cfg=cfg, latent_image=latent_image,
          start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise,
          denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar,
          seed=seed)

          File "/workspace/ComfyUI/comfy/samplers.py", line 709, in sample

          return sample(self.model, noise, positive, negative, cfg, self.device, sampler,
          sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask,
          callback=callback, disable_pbar=disable_pbar, seed=seed)

          File "/workspace/ComfyUI/comfy/samplers.py", line 615, in sample

          samples = sampler.sample(model_wrap, sigmas, extra_args, callback, noise,
          latent_image, denoise_mask, disable_pbar)

          File "/workspace/ComfyUI/comfy/samplers.py", line 554, in sample

          samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args,
          callback=k_callback, disable=disable_pbar, **self.extra_options)

          File "/workspace/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py",
          line 115, in decorate_context

          return func(*args, **kwargs)

          File "/workspace/ComfyUI/comfy/k_diffusion/sampling.py", line 137, in sample_euler

          denoised = model(x, sigma_hat * s_in, **extra_args)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl

          return self._call_impl(*args, **kwargs)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl

          return forward_call(*args, **kwargs)

          File "/workspace/ComfyUI/comfy/samplers.py", line 275, in forward

          out = self.inner_model(x, sigma, cond=cond, uncond=uncond, cond_scale=cond_scale,
          model_options=model_options, seed=seed)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl

          return self._call_impl(*args, **kwargs)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl

          return forward_call(*args, **kwargs)

          File "/workspace/ComfyUI/comfy/samplers.py", line 265, in forward

          return self.apply_model(*args, **kwargs)

          File "/workspace/ComfyUI/comfy/samplers.py", line 262, in apply_model

          out = sampling_function(self.inner_model, x, timestep, uncond, cond, cond_scale,
          model_options=model_options, seed=seed)

          File "/workspace/ComfyUI/comfy/samplers.py", line 250, in sampling_function

          cond, uncond = calc_cond_uncond_batch(model, cond, uncond, x, timestep,
          model_options)

          File "/workspace/ComfyUI/comfy/samplers.py", line 205, in calc_cond_uncond_batch

          c[''control''] = control.get_control(input_x, timestep_, c, len(cond_or_uncond))

          File "/workspace/ComfyUI/comfy/controlnet.py", line 166, in get_control

          control = self.control_model(x=x_noisy.to(self.control_model.dtype), hint=self.cond_hint,
          timesteps=timestep.float(), context=context.to(self.control_model.dtype),
          y=y)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl

          return self._call_impl(*args, **kwargs)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl

          return forward_call(*args, **kwargs)

          File "/workspace/ComfyUI/comfy/cldm/cldm.py", line 304, in forward

          h = module(h, emb, context)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl

          return self._call_impl(*args, **kwargs)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl

          return forward_call(*args, **kwargs)

          File "/workspace/ComfyUI/comfy/ldm/modules/diffusionmodules/openaimodel.py",
          line 43, in forward

          x = layer(x, context, transformer_options)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl

          return self._call_impl(*args, **kwargs)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl

          return forward_call(*args, **kwargs)

          File "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 560, in forward

          x = block(x, context=context[i], transformer_options=transformer_options)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl

          return self._call_impl(*args, **kwargs)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl

          return forward_call(*args, **kwargs)

          File "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 390, in forward

          return checkpoint(self._forward, (x, context, transformer_options), self.parameters(),
          self.checkpoint)

          File "/workspace/ComfyUI/comfy/ldm/modules/diffusionmodules/util.py", line
          123, in checkpoint

          return func(*inputs)

          File "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 492, in _forward

          n = self.attn2(n, context=context_attn2, value=value_attn2)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl

          return self._call_impl(*args, **kwargs)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl

          return forward_call(*args, **kwargs)

          File "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 358, in forward

          k = self.to_k(context)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1518, in _wrapped_call_impl

          return self._call_impl(*args, **kwargs)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
          line 1527, in _call_impl

          return forward_call(*args, **kwargs)

          File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py",
          line 114, in forward

          return F.linear(input, self.weight, self.bias)'
        updatedAt: '2023-11-16T14:48:25.628Z'
      numEdits: 0
      reactions: []
    id: 65562bb9b4b2833e078b4d24
    type: comment
  author: SpockIsSmart
  content: 'Error occurred when executing KSampler:


    mat1 and mat2 shapes cannot be multiplied (154x2048 and 768x320)


    File "/workspace/ComfyUI/execution.py", line 153, in recursive_execute

    output_data, output_ui = get_output_data(obj, input_data_all)

    File "/workspace/ComfyUI/execution.py", line 83, in get_output_data

    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)

    File "/workspace/ComfyUI/execution.py", line 76, in map_node_over_list

    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))

    File "/workspace/ComfyUI/nodes.py", line 1237, in sample

    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive,
    negative, latent_image, denoise=denoise)

    File "/workspace/ComfyUI/nodes.py", line 1207, in common_ksampler

    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler,
    positive, negative, latent_image,

    File "/workspace/ComfyUI/custom_nodes/ComfyUI-Impact-Pack/modules/impact/sample_error_enhancer.py",
    line 22, in informative_sample

    raise e

    File "/workspace/ComfyUI/custom_nodes/ComfyUI-Impact-Pack/modules/impact/sample_error_enhancer.py",
    line 9, in informative_sample

    return original_sample(*args, **kwargs)

    File "/workspace/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/animatediff/sampling.py",
    line 126, in animatediff_sample

    return orig_comfy_sample(model, noise, *args, **kwargs)

    File "/workspace/ComfyUI/comfy/sample.py", line 100, in sample

    samples = sampler.sample(noise, positive_copy, negative_copy, cfg=cfg, latent_image=latent_image,
    start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise,
    denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar,
    seed=seed)

    File "/workspace/ComfyUI/comfy/samplers.py", line 709, in sample

    return sample(self.model, noise, positive, negative, cfg, self.device, sampler,
    sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask,
    callback=callback, disable_pbar=disable_pbar, seed=seed)

    File "/workspace/ComfyUI/comfy/samplers.py", line 615, in sample

    samples = sampler.sample(model_wrap, sigmas, extra_args, callback, noise, latent_image,
    denoise_mask, disable_pbar)

    File "/workspace/ComfyUI/comfy/samplers.py", line 554, in sample

    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args,
    callback=k_callback, disable=disable_pbar, **self.extra_options)

    File "/workspace/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py",
    line 115, in decorate_context

    return func(*args, **kwargs)

    File "/workspace/ComfyUI/comfy/k_diffusion/sampling.py", line 137, in sample_euler

    denoised = model(x, sigma_hat * s_in, **extra_args)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1518, in _wrapped_call_impl

    return self._call_impl(*args, **kwargs)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1527, in _call_impl

    return forward_call(*args, **kwargs)

    File "/workspace/ComfyUI/comfy/samplers.py", line 275, in forward

    out = self.inner_model(x, sigma, cond=cond, uncond=uncond, cond_scale=cond_scale,
    model_options=model_options, seed=seed)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1518, in _wrapped_call_impl

    return self._call_impl(*args, **kwargs)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1527, in _call_impl

    return forward_call(*args, **kwargs)

    File "/workspace/ComfyUI/comfy/samplers.py", line 265, in forward

    return self.apply_model(*args, **kwargs)

    File "/workspace/ComfyUI/comfy/samplers.py", line 262, in apply_model

    out = sampling_function(self.inner_model, x, timestep, uncond, cond, cond_scale,
    model_options=model_options, seed=seed)

    File "/workspace/ComfyUI/comfy/samplers.py", line 250, in sampling_function

    cond, uncond = calc_cond_uncond_batch(model, cond, uncond, x, timestep, model_options)

    File "/workspace/ComfyUI/comfy/samplers.py", line 205, in calc_cond_uncond_batch

    c[''control''] = control.get_control(input_x, timestep_, c, len(cond_or_uncond))

    File "/workspace/ComfyUI/comfy/controlnet.py", line 166, in get_control

    control = self.control_model(x=x_noisy.to(self.control_model.dtype), hint=self.cond_hint,
    timesteps=timestep.float(), context=context.to(self.control_model.dtype), y=y)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1518, in _wrapped_call_impl

    return self._call_impl(*args, **kwargs)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1527, in _call_impl

    return forward_call(*args, **kwargs)

    File "/workspace/ComfyUI/comfy/cldm/cldm.py", line 304, in forward

    h = module(h, emb, context)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1518, in _wrapped_call_impl

    return self._call_impl(*args, **kwargs)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1527, in _call_impl

    return forward_call(*args, **kwargs)

    File "/workspace/ComfyUI/comfy/ldm/modules/diffusionmodules/openaimodel.py", line
    43, in forward

    x = layer(x, context, transformer_options)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1518, in _wrapped_call_impl

    return self._call_impl(*args, **kwargs)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1527, in _call_impl

    return forward_call(*args, **kwargs)

    File "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 560, in forward

    x = block(x, context=context[i], transformer_options=transformer_options)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1518, in _wrapped_call_impl

    return self._call_impl(*args, **kwargs)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1527, in _call_impl

    return forward_call(*args, **kwargs)

    File "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 390, in forward

    return checkpoint(self._forward, (x, context, transformer_options), self.parameters(),
    self.checkpoint)

    File "/workspace/ComfyUI/comfy/ldm/modules/diffusionmodules/util.py", line 123,
    in checkpoint

    return func(*inputs)

    File "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 492, in _forward

    n = self.attn2(n, context=context_attn2, value=value_attn2)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1518, in _wrapped_call_impl

    return self._call_impl(*args, **kwargs)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1527, in _call_impl

    return forward_call(*args, **kwargs)

    File "/workspace/ComfyUI/comfy/ldm/modules/attention.py", line 358, in forward

    k = self.to_k(context)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1518, in _wrapped_call_impl

    return self._call_impl(*args, **kwargs)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py",
    line 1527, in _call_impl

    return forward_call(*args, **kwargs)

    File "/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py",
    line 114, in forward

    return F.linear(input, self.weight, self.bias)'
  created_at: 2023-11-16 14:48:25+00:00
  edited: false
  hidden: false
  id: 65562bb9b4b2833e078b4d24
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 119
repo_id: lllyasviel/ControlNet-v1-1
repo_type: model
status: open
target_branch: null
title: 'RuntimeError: mat1 and mat2 shapes cannot be multiplied (77x2048 and 768x320)'
