!!python/object:huggingface_hub.community.DiscussionWithDetails
author: solotrek
conflicting_files: null
created_at: 2023-06-03 07:26:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/86423090a99eab6eecc025edbc765e70.svg
      fullname: Wally Sorich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: solotrek
      type: user
    createdAt: '2023-06-03T08:26:45.000Z'
    data:
      edited: true
      editors:
      - solotrek
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5145089626312256
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/86423090a99eab6eecc025edbc765e70.svg
          fullname: Wally Sorich
          isHf: false
          isPro: false
          name: solotrek
          type: user
        html: '<p>Hi, Fresh windows install of oobabooga today.(Nvidia option) Downloading
          TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ seemed to go fine. I didnt get
          to the point where I define the wbits and model_type. Just got below errors.
          Tried terminating the cmd window and opening a new cmd window.<br>But when
          using start_windows.bat to get things going, loading doesnt seem to work.<br>It
          looks like there should be a config file that is missing?.. But it not the
          config yml from ooba.<br>Any ideas?</p>

          <p>"INFO:Loading TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ...<br>Traceback
          (most recent call last):<br>  File "C:\Users\user\Dev\AI\oobabooga_windows\text-generation-webui\server.py",
          line 1102, in <br>    shared.model, shared.tokenizer = load_model(shared.model_name)<br>  File
          "C:\Users\user\Dev\AI\oobabooga_windows\text-generation-webui\modules\models.py",
          line 97, in load_model<br>    output = load_func(model_name)<br>  File "C:\Users\user\Dev\AI\oobabooga_windows\text-generation-webui\modules\models.py",
          line 155, in huggingface_loader<br>    model = LoaderClass.from_pretrained(Path(f"{shared.args.model_dir}/{model_name}"),
          low_cpu_mem_usage=True, torch_dtype=torch.bfloat16 if shared.args.bf16 else
          torch.float16, trust_remote_code=shared.args.trust_remote_code)<br>  File
          "C:\Users\user\Dev\AI\oobabooga_windows\installer_files\env\lib\site-packages\transformers\models\auto\auto_factory.py",
          line 472, in from_pretrained<br>    return model_class.from_pretrained(<br>  File
          "C:\Users\user\Dev\AI\oobabooga_windows\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 2406, in from_pretrained<br>    raise EnvironmentError(<br>OSError:
          Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or
          flax_model.msgpack found in directory models\TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ."</p>

          '
        raw: "Hi, Fresh windows install of oobabooga today.(Nvidia option) Downloading\
          \ TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ seemed to go fine. I didnt\
          \ get to the point where I define the wbits and model_type. Just got below\
          \ errors. Tried terminating the cmd window and opening a new cmd window.\n\
          But when using start_windows.bat to get things going, loading doesnt seem\
          \ to work. \nIt looks like there should be a config file that is missing?..\
          \ But it not the config yml from ooba.\nAny ideas?\n\n\"INFO:Loading TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ...\n\
          Traceback (most recent call last):\n  File \"C:\\Users\\user\\Dev\\AI\\\
          oobabooga_windows\\text-generation-webui\\server.py\", line 1102, in <module>\n\
          \    shared.model, shared.tokenizer = load_model(shared.model_name)\n  File\
          \ \"C:\\Users\\user\\Dev\\AI\\oobabooga_windows\\text-generation-webui\\\
          modules\\models.py\", line 97, in load_model\n    output = load_func(model_name)\n\
          \  File \"C:\\Users\\user\\Dev\\AI\\oobabooga_windows\\text-generation-webui\\\
          modules\\models.py\", line 155, in huggingface_loader\n    model = LoaderClass.from_pretrained(Path(f\"\
          {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
          \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\n\
          \  File \"C:\\Users\\user\\Dev\\AI\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\",\
          \ line 472, in from_pretrained\n    return model_class.from_pretrained(\n\
          \  File \"C:\\Users\\user\\Dev\\AI\\oobabooga_windows\\installer_files\\\
          env\\lib\\site-packages\\transformers\\modeling_utils.py\", line 2406, in\
          \ from_pretrained\n    raise EnvironmentError(\nOSError: Error no file named\
          \ pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models\\TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ.\""
        updatedAt: '2023-06-03T08:27:18.453Z'
      numEdits: 1
      reactions: []
    id: 647af945001553a39c335fc0
    type: comment
  author: solotrek
  content: "Hi, Fresh windows install of oobabooga today.(Nvidia option) Downloading\
    \ TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ seemed to go fine. I didnt get to\
    \ the point where I define the wbits and model_type. Just got below errors. Tried\
    \ terminating the cmd window and opening a new cmd window.\nBut when using start_windows.bat\
    \ to get things going, loading doesnt seem to work. \nIt looks like there should\
    \ be a config file that is missing?.. But it not the config yml from ooba.\nAny\
    \ ideas?\n\n\"INFO:Loading TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ...\nTraceback\
    \ (most recent call last):\n  File \"C:\\Users\\user\\Dev\\AI\\oobabooga_windows\\\
    text-generation-webui\\server.py\", line 1102, in <module>\n    shared.model,\
    \ shared.tokenizer = load_model(shared.model_name)\n  File \"C:\\Users\\user\\\
    Dev\\AI\\oobabooga_windows\\text-generation-webui\\modules\\models.py\", line\
    \ 97, in load_model\n    output = load_func(model_name)\n  File \"C:\\Users\\\
    user\\Dev\\AI\\oobabooga_windows\\text-generation-webui\\modules\\models.py\"\
    , line 155, in huggingface_loader\n    model = LoaderClass.from_pretrained(Path(f\"\
    {shared.args.model_dir}/{model_name}\"), low_cpu_mem_usage=True, torch_dtype=torch.bfloat16\
    \ if shared.args.bf16 else torch.float16, trust_remote_code=shared.args.trust_remote_code)\n\
    \  File \"C:\\Users\\user\\Dev\\AI\\oobabooga_windows\\installer_files\\env\\\
    lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 472, in\
    \ from_pretrained\n    return model_class.from_pretrained(\n  File \"C:\\Users\\\
    user\\Dev\\AI\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\\
    modeling_utils.py\", line 2406, in from_pretrained\n    raise EnvironmentError(\n\
    OSError: Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index\
    \ or flax_model.msgpack found in directory models\\TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ.\""
  created_at: 2023-06-03 07:26:45+00:00
  edited: true
  hidden: false
  id: 647af945001553a39c335fc0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-03T10:08:15.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7142060995101929
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Please see the README for instructions on setting and saving GPTQ
          parameters for this model</p>

          '
        raw: Please see the README for instructions on setting and saving GPTQ parameters
          for this model
        updatedAt: '2023-06-03T10:08:15.005Z'
      numEdits: 0
      reactions: []
    id: 647b110f6dbad6ab0572e1c9
    type: comment
  author: TheBloke
  content: Please see the README for instructions on setting and saving GPTQ parameters
    for this model
  created_at: 2023-06-03 09:08:15+00:00
  edited: false
  hidden: false
  id: 647b110f6dbad6ab0572e1c9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ
repo_type: model
status: open
target_branch: null
title: Error no file named...
