!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aifirst
conflicting_files: null
created_at: 2023-05-28 13:49:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d60d821a828b23c2899c591ba3336982.svg
      fullname: Power Kim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aifirst
      type: user
    createdAt: '2023-05-28T14:49:23.000Z'
    data:
      edited: false
      editors:
      - aifirst
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d60d821a828b23c2899c591ba3336982.svg
          fullname: Power Kim
          isHf: false
          isPro: false
          name: aifirst
          type: user
        html: '<p>I updated oobabooga 1 hours ago. My system is CPU: 8core/16thread,
          GPU: 4070 12G.</p>

          <p>I downloaded all files of "Files and version" and copied to directory
          which contains Wizard-Vicuna-13B-Uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors.</p>

          <p>Traceback (most recent call last):<br>  File "E:\AI\Vicuna\text-generation-webui\server.py",
          line 1087, in <br>    shared.model, shared.tokenizer = load_model(shared.model_name)<br>  File
          "E:\AI\Vicuna\text-generation-webui\modules\models.py", line 95, in load_model<br>    output
          = load_func(model_name)<br>  File "E:\AI\Vicuna\text-generation-webui\modules\models.py",
          line 223, in huggingface_loader<br>    model = LoaderClass.from_pretrained(checkpoint,
          **params)<br>  File "E:\AI\Vicuna\installer_files\env\lib\site-packages\transformers\models\auto\auto_factory.py",
          line 471, in from_pretrained<br>    return model_class.from_pretrained(<br>  File
          "E:\AI\Vicuna\installer_files\env\lib\site-packages\transformers\modeling_utils.py",
          line 2405, in from_pretrained<br>    raise EnvironmentError(<br>OSError:
          Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index or
          flax_model.msgpack found in directory models\TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ.</p>

          '
        raw: "I updated oobabooga 1 hours ago. My system is CPU: 8core/16thread, GPU:\
          \ 4070 12G.\r\n\r\nI downloaded all files of \"Files and version\" and copied\
          \ to directory which contains Wizard-Vicuna-13B-Uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors.\r\
          \n\r\nTraceback (most recent call last):\r\n  File \"E:\\AI\\Vicuna\\text-generation-webui\\\
          server.py\", line 1087, in <module>\r\n    shared.model, shared.tokenizer\
          \ = load_model(shared.model_name)\r\n  File \"E:\\AI\\Vicuna\\text-generation-webui\\\
          modules\\models.py\", line 95, in load_model\r\n    output = load_func(model_name)\r\
          \n  File \"E:\\AI\\Vicuna\\text-generation-webui\\modules\\models.py\",\
          \ line 223, in huggingface_loader\r\n    model = LoaderClass.from_pretrained(checkpoint,\
          \ **params)\r\n  File \"E:\\AI\\Vicuna\\installer_files\\env\\lib\\site-packages\\\
          transformers\\models\\auto\\auto_factory.py\", line 471, in from_pretrained\r\
          \n    return model_class.from_pretrained(\r\n  File \"E:\\AI\\Vicuna\\installer_files\\\
          env\\lib\\site-packages\\transformers\\modeling_utils.py\", line 2405, in\
          \ from_pretrained\r\n    raise EnvironmentError(\r\nOSError: Error no file\
          \ named pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models\\TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ."
        updatedAt: '2023-05-28T14:49:23.621Z'
      numEdits: 0
      reactions: []
    id: 647369f37afa69c3c7a6292d
    type: comment
  author: aifirst
  content: "I updated oobabooga 1 hours ago. My system is CPU: 8core/16thread, GPU:\
    \ 4070 12G.\r\n\r\nI downloaded all files of \"Files and version\" and copied\
    \ to directory which contains Wizard-Vicuna-13B-Uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors.\r\
    \n\r\nTraceback (most recent call last):\r\n  File \"E:\\AI\\Vicuna\\text-generation-webui\\\
    server.py\", line 1087, in <module>\r\n    shared.model, shared.tokenizer = load_model(shared.model_name)\r\
    \n  File \"E:\\AI\\Vicuna\\text-generation-webui\\modules\\models.py\", line 95,\
    \ in load_model\r\n    output = load_func(model_name)\r\n  File \"E:\\AI\\Vicuna\\\
    text-generation-webui\\modules\\models.py\", line 223, in huggingface_loader\r\
    \n    model = LoaderClass.from_pretrained(checkpoint, **params)\r\n  File \"E:\\\
    AI\\Vicuna\\installer_files\\env\\lib\\site-packages\\transformers\\models\\auto\\\
    auto_factory.py\", line 471, in from_pretrained\r\n    return model_class.from_pretrained(\r\
    \n  File \"E:\\AI\\Vicuna\\installer_files\\env\\lib\\site-packages\\transformers\\\
    modeling_utils.py\", line 2405, in from_pretrained\r\n    raise EnvironmentError(\r\
    \nOSError: Error no file named pytorch_model.bin, tf_model.h5, model.ckpt.index\
    \ or flax_model.msgpack found in directory models\\TheBloke_Wizard-Vicuna-13B-Uncensored-GPTQ."
  created_at: 2023-05-28 13:49:23+00:00
  edited: false
  hidden: false
  id: 647369f37afa69c3c7a6292d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-28T14:51:37.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>This usually happens because the GPTQ parameters have not been saved
          for the model. Please check the README and see the steps about setting and
          saving GPTQ parameters for the model, then reloading the model</p>

          '
        raw: This usually happens because the GPTQ parameters have not been saved
          for the model. Please check the README and see the steps about setting and
          saving GPTQ parameters for the model, then reloading the model
        updatedAt: '2023-05-28T14:51:37.088Z'
      numEdits: 0
      reactions: []
    id: 64736a796cff2f867204d8b9
    type: comment
  author: TheBloke
  content: This usually happens because the GPTQ parameters have not been saved for
    the model. Please check the README and see the steps about setting and saving
    GPTQ parameters for the model, then reloading the model
  created_at: 2023-05-28 13:51:37+00:00
  edited: false
  hidden: false
  id: 64736a796cff2f867204d8b9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d60d821a828b23c2899c591ba3336982.svg
      fullname: Power Kim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aifirst
      type: user
    createdAt: '2023-05-31T14:34:20.000Z'
    data:
      edited: false
      editors:
      - aifirst
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d60d821a828b23c2899c591ba3336982.svg
          fullname: Power Kim
          isHf: false
          isPro: false
          name: aifirst
          type: user
        html: '<p>It works. Thank you very much!</p>

          '
        raw: It works. Thank you very much!
        updatedAt: '2023-05-31T14:34:20.394Z'
      numEdits: 0
      reactions: []
    id: 64775aec33a888101f757515
    type: comment
  author: aifirst
  content: It works. Thank you very much!
  created_at: 2023-05-31 13:34:20+00:00
  edited: false
  hidden: false
  id: 64775aec33a888101f757515
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/d60d821a828b23c2899c591ba3336982.svg
      fullname: Power Kim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aifirst
      type: user
    createdAt: '2023-05-31T14:34:24.000Z'
    data:
      status: closed
    id: 64775af0f911e9e76c61eeb9
    type: status-change
  author: aifirst
  created_at: 2023-05-31 13:34:24+00:00
  id: 64775af0f911e9e76c61eeb9
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ
repo_type: model
status: closed
target_branch: null
title: Model cannot load
