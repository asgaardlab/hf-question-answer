!!python/object:huggingface_hub.community.DiscussionWithDetails
author: KCramer
conflicting_files: null
created_at: 2022-06-06 16:21:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674303311600-6172ac7270efc92913d13036.jpeg?w=200&h=200&f=face
      fullname: Kathryn Cramer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KCramer
      type: user
    createdAt: '2022-06-06T17:21:05.000Z'
    data:
      edited: false
      editors:
      - KCramer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674303311600-6172ac7270efc92913d13036.jpeg?w=200&h=200&f=face
          fullname: Kathryn Cramer
          isHf: false
          isPro: false
          name: KCramer
          type: user
        html: '<p>Hi: I can understand the decision to create something using the
          4chan data as training, and I can understand the decision to assess its
          truthfulness as measured against the other language models. </p>

          <p>What I don''t understand is why it seemed like a good idea at the time
          to let GPT-4chan make 30,000+ on its own and unfiltered. Someone is responsible
          for that content, and I think that someone is you. Why would you want to
          do that?</p>

          '
        raw: "Hi: I can understand the decision to create something using the 4chan\
          \ data as training, and I can understand the decision to assess its truthfulness\
          \ as measured against the other language models. \r\n\r\nWhat I don't understand\
          \ is why it seemed like a good idea at the time to let GPT-4chan make 30,000+\
          \ on its own and unfiltered. Someone is responsible for that content, and\
          \ I think that someone is you. Why would you want to do that?"
        updatedAt: '2022-06-06T17:21:05.520Z'
      numEdits: 0
      reactions: []
    id: 629e37819122a27bff58f454
    type: comment
  author: KCramer
  content: "Hi: I can understand the decision to create something using the 4chan\
    \ data as training, and I can understand the decision to assess its truthfulness\
    \ as measured against the other language models. \r\n\r\nWhat I don't understand\
    \ is why it seemed like a good idea at the time to let GPT-4chan make 30,000+\
    \ on its own and unfiltered. Someone is responsible for that content, and I think\
    \ that someone is you. Why would you want to do that?"
  created_at: 2022-06-06 16:21:05+00:00
  edited: false
  hidden: false
  id: 629e37819122a27bff58f454
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4deb18b77c8746f9da7cf5681683e846.svg
      fullname: 'Lauren Oakden-Rayner '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LaurenOR
      type: user
    createdAt: '2022-06-06T19:34:44.000Z'
    data:
      edited: false
      editors:
      - LaurenOR
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4deb18b77c8746f9da7cf5681683e846.svg
          fullname: 'Lauren Oakden-Rayner '
          isHf: false
          isPro: false
          name: LaurenOR
          type: user
        html: '<p>I agree with KCramer. There is nothing wrong with making a 4chan-based
          model and testing how it behaves.</p>

          <p>The main concern I have is that this model is freely accessible for use.
          While open science is a great principle, I''m a medical doctor and safety
          researcher by training and we always need to consider possible harms. Human
          research ethics is baked into the very foundation of our field, because
          of a long history of human rights abuses in the name of science, in particular
          experiments that cause harm to disempowered and marginalised people without
          their consent.</p>

          <p>It should be clear that this model carries a significant risk for this
          sort of harm, given the fact such an experiment has already been performed.
          The model author has used this model to produce a bot that made tens of
          thousands of harmful and discriminatory online comments on a publicly accessible
          forum, a forum that tends to be heavily populated by teenagers no less.
          There is no question that such human experimentation would never pass an
          ethics review board, where researchers intentionally expose teenagers to
          generated harmful content without their consent or knowledge, especially
          given the known risks of radicalisation on sites like 4chan.</p>

          <p>Given the demonstrated risk of harm, this model should not be freely
          accessible. The medical community has well established guidelines on how
          to manage the sharing of research materials which involve a risk to human
          subjects, with data privacy being the most common risk. It is common to
          allow research access to datasets in this context via a registration platform,
          where the applicants who are seeking access must describe their proposed
          research, and sign an agreement for data use. See the NIH/TCIA and MIMIC
          datasets for examples. The latter even has a requirement for applicants
          to pass a course in human research ethics prior to obtaining access to the
          data.</p>

          <p>A similar system should be in place here, and be used as the template
          for future model sharing where the model has the potential to produce harm.</p>

          '
        raw: 'I agree with KCramer. There is nothing wrong with making a 4chan-based
          model and testing how it behaves.


          The main concern I have is that this model is freely accessible for use.
          While open science is a great principle, I''m a medical doctor and safety
          researcher by training and we always need to consider possible harms. Human
          research ethics is baked into the very foundation of our field, because
          of a long history of human rights abuses in the name of science, in particular
          experiments that cause harm to disempowered and marginalised people without
          their consent.


          It should be clear that this model carries a significant risk for this sort
          of harm, given the fact such an experiment has already been performed. The
          model author has used this model to produce a bot that made tens of thousands
          of harmful and discriminatory online comments on a publicly accessible forum,
          a forum that tends to be heavily populated by teenagers no less. There is
          no question that such human experimentation would never pass an ethics review
          board, where researchers intentionally expose teenagers to generated harmful
          content without their consent or knowledge, especially given the known risks
          of radicalisation on sites like 4chan.


          Given the demonstrated risk of harm, this model should not be freely accessible.
          The medical community has well established guidelines on how to manage the
          sharing of research materials which involve a risk to human subjects, with
          data privacy being the most common risk. It is common to allow research
          access to datasets in this context via a registration platform, where the
          applicants who are seeking access must describe their proposed research,
          and sign an agreement for data use. See the NIH/TCIA and MIMIC datasets
          for examples. The latter even has a requirement for applicants to pass a
          course in human research ethics prior to obtaining access to the data.


          A similar system should be in place here, and be used as the template for
          future model sharing where the model has the potential to produce harm.'
        updatedAt: '2022-06-06T19:34:44.470Z'
      numEdits: 0
      reactions: []
    id: 629e56d43b48b2b665aab266
    type: comment
  author: LaurenOR
  content: 'I agree with KCramer. There is nothing wrong with making a 4chan-based
    model and testing how it behaves.


    The main concern I have is that this model is freely accessible for use. While
    open science is a great principle, I''m a medical doctor and safety researcher
    by training and we always need to consider possible harms. Human research ethics
    is baked into the very foundation of our field, because of a long history of human
    rights abuses in the name of science, in particular experiments that cause harm
    to disempowered and marginalised people without their consent.


    It should be clear that this model carries a significant risk for this sort of
    harm, given the fact such an experiment has already been performed. The model
    author has used this model to produce a bot that made tens of thousands of harmful
    and discriminatory online comments on a publicly accessible forum, a forum that
    tends to be heavily populated by teenagers no less. There is no question that
    such human experimentation would never pass an ethics review board, where researchers
    intentionally expose teenagers to generated harmful content without their consent
    or knowledge, especially given the known risks of radicalisation on sites like
    4chan.


    Given the demonstrated risk of harm, this model should not be freely accessible.
    The medical community has well established guidelines on how to manage the sharing
    of research materials which involve a risk to human subjects, with data privacy
    being the most common risk. It is common to allow research access to datasets
    in this context via a registration platform, where the applicants who are seeking
    access must describe their proposed research, and sign an agreement for data use.
    See the NIH/TCIA and MIMIC datasets for examples. The latter even has a requirement
    for applicants to pass a course in human research ethics prior to obtaining access
    to the data.


    A similar system should be in place here, and be used as the template for future
    model sharing where the model has the potential to produce harm.'
  created_at: 2022-06-06 18:34:44+00:00
  edited: false
  hidden: false
  id: 629e56d43b48b2b665aab266
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654339150839-62477542101250f32c78e945.jpeg?w=200&h=200&f=face
      fullname: Yannic Kilcher
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ykilcher
      type: user
    createdAt: '2022-06-06T20:34:11.000Z'
    data:
      edited: false
      editors:
      - ykilcher
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654339150839-62477542101250f32c78e945.jpeg?w=200&h=200&f=face
          fullname: Yannic Kilcher
          isHf: false
          isPro: false
          name: ykilcher
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;KCramer&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/KCramer\">@<span class=\"\
          underline\">KCramer</span></a></span>\n\n\t</span></span> the hugging face\
          \ hub is only used as storage space to download the model and to display\
          \ the model card. I'm happy to have a discussion about these things, but\
          \ I don't think this place is the correct environment.</p>\n<p><span data-props=\"\
          {&quot;user&quot;:&quot;LaurenOR&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/LaurenOR\">@<span class=\"underline\">LaurenOR</span></a></span>\n\
          \n\t</span></span> please point to an actual, concrete instance of harm\
          \ that is caused by having this model be accessible that is unique to gpt-4chan\
          \ and would not be possible e.g. with gpt-2 or gpt-j (or a simple database\
          \ of swear words), all of which are also freely available. As I already\
          \ said above, the contents of the experiment itself are not at issue on\
          \ the hub here, since it had nothing to do with it.</p>\n"
        raw: '@KCramer the hugging face hub is only used as storage space to download
          the model and to display the model card. I''m happy to have a discussion
          about these things, but I don''t think this place is the correct environment.


          @LaurenOR please point to an actual, concrete instance of harm that is caused
          by having this model be accessible that is unique to gpt-4chan and would
          not be possible e.g. with gpt-2 or gpt-j (or a simple database of swear
          words), all of which are also freely available. As I already said above,
          the contents of the experiment itself are not at issue on the hub here,
          since it had nothing to do with it.'
        updatedAt: '2022-06-06T20:34:11.183Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - buzzroll
        - halr9000
        - adhi01
    id: 629e64c3a5bdf6dd379e97b1
    type: comment
  author: ykilcher
  content: '@KCramer the hugging face hub is only used as storage space to download
    the model and to display the model card. I''m happy to have a discussion about
    these things, but I don''t think this place is the correct environment.


    @LaurenOR please point to an actual, concrete instance of harm that is caused
    by having this model be accessible that is unique to gpt-4chan and would not be
    possible e.g. with gpt-2 or gpt-j (or a simple database of swear words), all of
    which are also freely available. As I already said above, the contents of the
    experiment itself are not at issue on the hub here, since it had nothing to do
    with it.'
  created_at: 2022-06-06 19:34:11+00:00
  edited: false
  hidden: false
  id: 629e64c3a5bdf6dd379e97b1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1583857146757-5e67bdd61009063689407479.jpeg?w=200&h=200&f=face
      fullname: "Clem \U0001F917"
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: true
      name: clem
      type: user
    createdAt: '2022-06-06T21:10:34.000Z'
    data:
      edited: false
      editors:
      - clem
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1583857146757-5e67bdd61009063689407479.jpeg?w=200&h=200&f=face
          fullname: "Clem \U0001F917"
          isHf: true
          isPro: true
          name: clem
          type: user
        html: "<p>Hi! Clem, co-founder and CEO at Hugging Face here. Thanks for the\
          \ messages <span data-props=\"{&quot;user&quot;:&quot;LaurenOR&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/LaurenOR\"\
          >@<span class=\"underline\">LaurenOR</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;KCramer&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/KCramer\">@<span class=\"\
          underline\">KCramer</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;ykilcher&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/ykilcher\">@<span class=\"underline\">ykilcher</span></a></span>\n\
          \n\t</span></span></p>\n<p>We don't advocate or support the training and\
          \ experiments done by the author with this model. </p>\n<p>In fact, the\
          \ experiment of having the model post messages on 4chan was IMO pretty bad\
          \ and inappropriate and if the author would have asked us, we would probably\
          \ have tried to discourage them from doing it.</p>\n<p>After a lot of internal\
          \ debate at HF, we decided not to remove the model that the author uploaded\
          \ here in the conditions that:<br><a href=\"/ykilcher/gpt-4chan/discussions/1\"\
          >#1</a> The model card &amp; the video clearly warned about the limitations\
          \ and problems raised by the model &amp; the POL section of 4Chan in general<br><a\
          \ href=\"/ykilcher/gpt-4chan/discussions/2\">#2</a> The inference widget\
          \ were disabled in order not to make it easier to use the model</p>\n<p>We\
          \ considered that it was useful for the field to test what a model trained\
          \ on such data could do &amp; how it fared compared to others (namely GPT-3)\
          \ and would help draw attention both to the limitations and risks of such\
          \ models. This work also brought interesting insights into the limitations\
          \ of existing benchmarks by outperforming the TruthfulQA Benchmark compared\
          \ to GPT-J and GPT-3. Finally, we thought it could help researchers analyze\
          \ more easily some dark corners of the web like 4Chan that are already sometimes\
          \ unfortunately part of the pre-training of these large language models\
          \ (maybe to try to remove them/mitigate them?).</p>\n<p>However, we are\
          \ still just scratching the surface when it comes to ethics reviews (as\
          \ most people in ML research) and would love to hear more feedback from\
          \ the community to improve or correct mistakes if needed!  We've also been\
          \ working on a feature to \"gate\" such models that we're prioritizing right\
          \ now for ethical reasons. Happy to answer any additional questions too!</p>\n"
        raw: "Hi! Clem, co-founder and CEO at Hugging Face here. Thanks for the messages\
          \ @LaurenOR @KCramer @ykilcher\n\nWe don't advocate or support the training\
          \ and experiments done by the author with this model. \n\nIn fact, the experiment\
          \ of having the model post messages on 4chan was IMO pretty bad and inappropriate\
          \ and if the author would have asked us, we would probably have tried to\
          \ discourage them from doing it.\n\nAfter a lot of internal debate at HF,\
          \ we decided not to remove the model that the author uploaded here in the\
          \ conditions that:\n#1 The model card & the video clearly warned about the\
          \ limitations and problems raised by the model & the POL section of 4Chan\
          \ in general\n#2 The inference widget were disabled in order not to make\
          \ it easier to use the model\n\nWe considered that it was useful for the\
          \ field to test what a model trained on such data could do & how it fared\
          \ compared to others (namely GPT-3) and would help draw attention both to\
          \ the limitations and risks of such models. This work also brought interesting\
          \ insights into the limitations of existing benchmarks by outperforming\
          \ the TruthfulQA Benchmark compared to GPT-J and GPT-3. Finally, we thought\
          \ it could help researchers analyze more easily some dark corners of the\
          \ web like 4Chan that are already sometimes unfortunately part of the pre-training\
          \ of these large language models (maybe to try to remove them/mitigate them?).\n\
          \nHowever, we are still just scratching the surface when it comes to ethics\
          \ reviews (as most people in ML research) and would love to hear more feedback\
          \ from the community to improve or correct mistakes if needed!  We've also\
          \ been working on a feature to \"gate\" such models that we're prioritizing\
          \ right now for ethical reasons. Happy to answer any additional questions\
          \ too!"
        updatedAt: '2022-06-06T21:10:34.386Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - NeelNanda
        - adhi01
      - count: 2
        reaction: "\U0001F92F"
        users:
        - buzzroll
        - adhi01
    id: 629e6d4abb6419817edfb1d7
    type: comment
  author: clem
  content: "Hi! Clem, co-founder and CEO at Hugging Face here. Thanks for the messages\
    \ @LaurenOR @KCramer @ykilcher\n\nWe don't advocate or support the training and\
    \ experiments done by the author with this model. \n\nIn fact, the experiment\
    \ of having the model post messages on 4chan was IMO pretty bad and inappropriate\
    \ and if the author would have asked us, we would probably have tried to discourage\
    \ them from doing it.\n\nAfter a lot of internal debate at HF, we decided not\
    \ to remove the model that the author uploaded here in the conditions that:\n\
    #1 The model card & the video clearly warned about the limitations and problems\
    \ raised by the model & the POL section of 4Chan in general\n#2 The inference\
    \ widget were disabled in order not to make it easier to use the model\n\nWe considered\
    \ that it was useful for the field to test what a model trained on such data could\
    \ do & how it fared compared to others (namely GPT-3) and would help draw attention\
    \ both to the limitations and risks of such models. This work also brought interesting\
    \ insights into the limitations of existing benchmarks by outperforming the TruthfulQA\
    \ Benchmark compared to GPT-J and GPT-3. Finally, we thought it could help researchers\
    \ analyze more easily some dark corners of the web like 4Chan that are already\
    \ sometimes unfortunately part of the pre-training of these large language models\
    \ (maybe to try to remove them/mitigate them?).\n\nHowever, we are still just\
    \ scratching the surface when it comes to ethics reviews (as most people in ML\
    \ research) and would love to hear more feedback from the community to improve\
    \ or correct mistakes if needed!  We've also been working on a feature to \"gate\"\
    \ such models that we're prioritizing right now for ethical reasons. Happy to\
    \ answer any additional questions too!"
  created_at: 2022-06-06 20:10:34+00:00
  edited: false
  hidden: false
  id: 629e6d4abb6419817edfb1d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1626214544196-60c757ea5f9a76ab3f844f12.png?w=200&h=200&f=face
      fullname: Margaret Mitchell
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: meg
      type: user
    createdAt: '2022-06-06T21:11:08.000Z'
    data:
      edited: false
      editors:
      - meg
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1626214544196-60c757ea5f9a76ab3f844f12.png?w=200&h=200&f=face
          fullname: Margaret Mitchell
          isHf: true
          isPro: false
          name: meg
          type: user
        html: '<p>FWIW, I do think this is the environment to have these discussions.
          This is a community issue, so the community forum seems good.<br>The model
          is open; so too is the discussion around it.</p>

          '
        raw: 'FWIW, I do think this is the environment to have these discussions.
          This is a community issue, so the community forum seems good.

          The model is open; so too is the discussion around it.'
        updatedAt: '2022-06-06T21:11:08.781Z'
      numEdits: 0
      reactions: []
    id: 629e6d6cbb6419817edfb60a
    type: comment
  author: meg
  content: 'FWIW, I do think this is the environment to have these discussions. This
    is a community issue, so the community forum seems good.

    The model is open; so too is the discussion around it.'
  created_at: 2022-06-06 20:11:08+00:00
  edited: false
  hidden: false
  id: 629e6d6cbb6419817edfb60a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/df113125ed54b5c2ee94884720b2d41c.svg
      fullname: Samuel Curtis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: smurtis
      type: user
    createdAt: '2022-06-06T23:06:15.000Z'
    data:
      edited: false
      editors:
      - smurtis
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/df113125ed54b5c2ee94884720b2d41c.svg
          fullname: Samuel Curtis
          isHf: false
          isPro: false
          name: smurtis
          type: user
        html: "<p>Agreed with <span data-props=\"{&quot;user&quot;:&quot;meg&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/meg\"\
          >@<span class=\"underline\">meg</span></a></span>\n\n\t</span></span> that\
          \ these conversations ought to take place here.</p>\n<p>Although I would\
          \ not have condoned this experiment at this scale, there is value in understanding\
          \ what this technology enables and I believe that HF (and hopefully 4chan??)\
          \ will be better off from it!</p>\n<p>I imagine that the greatest risk would\
          \ not be the messages a user could generate via the inference widget in\
          \ a single pass, but the many orders of magnitude more that could be automatically\
          \ generated and disseminated with access to the model (as was demonstrated).\
          \ This model's exceptional tendency to produce toxic/derogatory/adult content\
          \ is what sets it apart from most models, and it seems appropriate for there\
          \ to be some form of restricted access in place in this instance.</p>\n\
          <p>It seems to me that if a restricted-access feature is around the corner,\
          \ it may be a good move to temporarily disable access to this and other\
          \ notable high-risk models until it has been implemented. I could understand\
          \ the concern about not being able to apply the policy equitably at first,\
          \ but that seems less of a problem than the risk that open access poses.</p>\n"
        raw: 'Agreed with @meg that these conversations ought to take place here.


          Although I would not have condoned this experiment at this scale, there
          is value in understanding what this technology enables and I believe that
          HF (and hopefully 4chan??) will be better off from it!


          I imagine that the greatest risk would not be the messages a user could
          generate via the inference widget in a single pass, but the many orders
          of magnitude more that could be automatically generated and disseminated
          with access to the model (as was demonstrated). This model''s exceptional
          tendency to produce toxic/derogatory/adult content is what sets it apart
          from most models, and it seems appropriate for there to be some form of
          restricted access in place in this instance.


          It seems to me that if a restricted-access feature is around the corner,
          it may be a good move to temporarily disable access to this and other notable
          high-risk models until it has been implemented. I could understand the concern
          about not being able to apply the policy equitably at first, but that seems
          less of a problem than the risk that open access poses.'
        updatedAt: '2022-06-06T23:06:15.451Z'
      numEdits: 0
      reactions: []
    id: 629e88673b48b2b665b01666
    type: comment
  author: smurtis
  content: 'Agreed with @meg that these conversations ought to take place here.


    Although I would not have condoned this experiment at this scale, there is value
    in understanding what this technology enables and I believe that HF (and hopefully
    4chan??) will be better off from it!


    I imagine that the greatest risk would not be the messages a user could generate
    via the inference widget in a single pass, but the many orders of magnitude more
    that could be automatically generated and disseminated with access to the model
    (as was demonstrated). This model''s exceptional tendency to produce toxic/derogatory/adult
    content is what sets it apart from most models, and it seems appropriate for there
    to be some form of restricted access in place in this instance.


    It seems to me that if a restricted-access feature is around the corner, it may
    be a good move to temporarily disable access to this and other notable high-risk
    models until it has been implemented. I could understand the concern about not
    being able to apply the policy equitably at first, but that seems less of a problem
    than the risk that open access poses.'
  created_at: 2022-06-06 22:06:15+00:00
  edited: false
  hidden: false
  id: 629e88673b48b2b665b01666
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613506944888-noauth.jpeg?w=200&h=200&f=face
      fullname: "Jo\xE3o Guilherme Madeira Ara\xFAjo"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joaogui1
      type: user
    createdAt: '2022-06-06T23:26:31.000Z'
    data:
      edited: false
      editors:
      - joaogui1
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613506944888-noauth.jpeg?w=200&h=200&f=face
          fullname: "Jo\xE3o Guilherme Madeira Ara\xFAjo"
          isHf: false
          isPro: false
          name: joaogui1
          type: user
        html: "<p>Strong agree with <span data-props=\"{&quot;user&quot;:&quot;smurtis&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/smurtis\"\
          >@<span class=\"underline\">smurtis</span></a></span>\n\n\t</span></span>,\
          \ this model has already been downloaded over a thousand times, it would\
          \ be better to remove the weights before bad actors can use it to automate\
          \ harassment and polute online communities</p>\n"
        raw: Strong agree with @smurtis, this model has already been downloaded over
          a thousand times, it would be better to remove the weights before bad actors
          can use it to automate harassment and polute online communities
        updatedAt: '2022-06-06T23:26:31.291Z'
      numEdits: 0
      reactions: []
    id: 629e8d271fec321a2d31dd44
    type: comment
  author: joaogui1
  content: Strong agree with @smurtis, this model has already been downloaded over
    a thousand times, it would be better to remove the weights before bad actors can
    use it to automate harassment and polute online communities
  created_at: 2022-06-06 22:26:31+00:00
  edited: false
  hidden: false
  id: 629e8d271fec321a2d31dd44
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4deb18b77c8746f9da7cf5681683e846.svg
      fullname: 'Lauren Oakden-Rayner '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LaurenOR
      type: user
    createdAt: '2022-06-07T00:45:36.000Z'
    data:
      edited: false
      editors:
      - LaurenOR
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4deb18b77c8746f9da7cf5681683e846.svg
          fullname: 'Lauren Oakden-Rayner '
          isHf: false
          isPro: false
          name: LaurenOR
          type: user
        html: "<p>Strongly agree with <span data-props=\"{&quot;user&quot;:&quot;smurtis&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/smurtis\"\
          >@<span class=\"underline\">smurtis</span></a></span>\n\n\t</span></span>\
          \ and <span data-props=\"{&quot;user&quot;:&quot;joaogui1&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/joaogui1\">@<span class=\"\
          underline\">joaogui1</span></a></span>\n\n\t</span></span>, if a decision\
          \ has been made to gate certain models like this one, then it is unreasonable\
          \ to leave them accessible while the feature is being deployed.</p>\n"
        raw: Strongly agree with @smurtis and @joaogui1, if a decision has been made
          to gate certain models like this one, then it is unreasonable to leave them
          accessible while the feature is being deployed.
        updatedAt: '2022-06-07T00:45:36.829Z'
      numEdits: 0
      reactions: []
    id: 629e9fb0bb6419817ee4e2b6
    type: comment
  author: LaurenOR
  content: Strongly agree with @smurtis and @joaogui1, if a decision has been made
    to gate certain models like this one, then it is unreasonable to leave them accessible
    while the feature is being deployed.
  created_at: 2022-06-06 23:45:36+00:00
  edited: false
  hidden: false
  id: 629e9fb0bb6419817ee4e2b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674303311600-6172ac7270efc92913d13036.jpeg?w=200&h=200&f=face
      fullname: Kathryn Cramer
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KCramer
      type: user
    createdAt: '2022-06-07T02:54:42.000Z'
    data:
      edited: false
      editors:
      - KCramer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674303311600-6172ac7270efc92913d13036.jpeg?w=200&h=200&f=face
          fullname: Kathryn Cramer
          isHf: false
          isPro: false
          name: KCramer
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ykilcher&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ykilcher\">@<span class=\"\
          underline\">ykilcher</span></a></span>\n\n\t</span></span> I am not a regular\
          \ on Hugging Face, so I have no opinion about proper venues. But I think\
          \ whatever the proper venue for talking about this, the bots you make speak\
          \ for you and you need to understand that.</p>\n<p>I tried out the demo\
          \ mode of your tool 4 times, using benign tweets from my feed as the seed\
          \ text. In the first trial, one of the responding posts was a single word,\
          \ the N word.  The seed for my third trial was, I think, a single sentence\
          \ about climate change. Your tool responded by expanding it into a conspiracy\
          \ theory about the Rothchilds and Jews being behind it. </p>\n<p>I only\
          \ ran it a few times but got content that was off the rails in response\
          \ 3/4 times. Not surprising. The seeds your tool used were actual Reddit\
          \ content, and so probably not selected to be neutral. So if your tool wrote\
          \ 30,000 posts, it is reasonable to assume that maybe 20,000  are toxic\
          \ content, using a loose and restrictive definition of toxic.</p>\n<p>This\
          \ was only a reasonable thing to do if you assume that content posted to\
          \ Reddit has no effect on the world.</p>\n"
        raw: "@ykilcher I am not a regular on Hugging Face, so I have no opinion about\
          \ proper venues. But I think whatever the proper venue for talking about\
          \ this, the bots you make speak for you and you need to understand that.\n\
          \nI tried out the demo mode of your tool 4 times, using benign tweets from\
          \ my feed as the seed text. In the first trial, one of the responding posts\
          \ was a single word, the N word.  The seed for my third trial was, I think,\
          \ a single sentence about climate change. Your tool responded by expanding\
          \ it into a conspiracy theory about the Rothchilds and Jews being behind\
          \ it. \n\nI only ran it a few times but got content that was off the rails\
          \ in response 3/4 times. Not surprising. The seeds your tool used were actual\
          \ Reddit content, and so probably not selected to be neutral. So if your\
          \ tool wrote 30,000 posts, it is reasonable to assume that maybe 20,000\
          \  are toxic content, using a loose and restrictive definition of toxic.\n\
          \nThis was only a reasonable thing to do if you assume that content posted\
          \ to Reddit has no effect on the world."
        updatedAt: '2022-06-07T02:54:42.521Z'
      numEdits: 0
      reactions: []
    id: 629ebdf246b4826be2d4c8c9
    type: comment
  author: KCramer
  content: "@ykilcher I am not a regular on Hugging Face, so I have no opinion about\
    \ proper venues. But I think whatever the proper venue for talking about this,\
    \ the bots you make speak for you and you need to understand that.\n\nI tried\
    \ out the demo mode of your tool 4 times, using benign tweets from my feed as\
    \ the seed text. In the first trial, one of the responding posts was a single\
    \ word, the N word.  The seed for my third trial was, I think, a single sentence\
    \ about climate change. Your tool responded by expanding it into a conspiracy\
    \ theory about the Rothchilds and Jews being behind it. \n\nI only ran it a few\
    \ times but got content that was off the rails in response 3/4 times. Not surprising.\
    \ The seeds your tool used were actual Reddit content, and so probably not selected\
    \ to be neutral. So if your tool wrote 30,000 posts, it is reasonable to assume\
    \ that maybe 20,000  are toxic content, using a loose and restrictive definition\
    \ of toxic.\n\nThis was only a reasonable thing to do if you assume that content\
    \ posted to Reddit has no effect on the world."
  created_at: 2022-06-07 01:54:42+00:00
  edited: false
  hidden: false
  id: 629ebdf246b4826be2d4c8c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1583857146757-5e67bdd61009063689407479.jpeg?w=200&h=200&f=face
      fullname: "Clem \U0001F917"
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: true
      name: clem
      type: user
    createdAt: '2022-06-07T09:41:16.000Z'
    data:
      edited: false
      editors:
      - clem
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1583857146757-5e67bdd61009063689407479.jpeg?w=200&h=200&f=face
          fullname: "Clem \U0001F917"
          isHf: true
          isPro: true
          name: clem
          type: user
        html: '<p>Thanks for your feedback everyone! We rushed and just released the
          new gating feature that I mentioned and just enabled it for this model.
          Happy to answer any questions/comments/feedback.</p>

          '
        raw: Thanks for your feedback everyone! We rushed and just released the new
          gating feature that I mentioned and just enabled it for this model. Happy
          to answer any questions/comments/feedback.
        updatedAt: '2022-06-07T09:41:16.400Z'
      numEdits: 0
      reactions: []
    id: 629f1d3cd9f1fb1e725a86e5
    type: comment
  author: clem
  content: Thanks for your feedback everyone! We rushed and just released the new
    gating feature that I mentioned and just enabled it for this model. Happy to answer
    any questions/comments/feedback.
  created_at: 2022-06-07 08:41:16+00:00
  edited: false
  hidden: false
  id: 629f1d3cd9f1fb1e725a86e5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/662bab0f807f9bd04fbb2aa544a4f5ad.svg
      fullname: Sefa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: sefaozalpadl
      type: user
    createdAt: '2022-06-07T10:38:40.000Z'
    data:
      edited: false
      editors:
      - sefaozalpadl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/662bab0f807f9bd04fbb2aa544a4f5ad.svg
          fullname: Sefa
          isHf: false
          isPro: true
          name: sefaozalpadl
          type: user
        html: '<p>I cannot access the model now. Although I clicked on the gating
          button, </p>

          <p><code>tokenizer = AutoTokenizer.from_pretrained("ykilcher/gpt-4chan")</code>
          is throwing a value error. </p>

          <p><code>Exception has occurred: ValueError Connection error, and we cannot
          find the requested files in the cached path. Please try again or make sure
          your Internet connection is on.</code> Is this intentional or not? Wanting
          to experiment for research purposes.</p>

          '
        raw: "I cannot access the model now. Although I clicked on the gating button,\
          \ \n\n`tokenizer = AutoTokenizer.from_pretrained(\"ykilcher/gpt-4chan\"\
          )` is throwing a value error. \n\n`Exception has occurred: ValueError\n\
          Connection error, and we cannot find the requested files in the cached path.\
          \ Please try again or make sure your Internet connection is on.` Is this\
          \ intentional or not? Wanting to experiment for research purposes."
        updatedAt: '2022-06-07T10:38:40.831Z'
      numEdits: 0
      reactions: []
    id: 629f2ab08483fd7f45eaff29
    type: comment
  author: sefaozalpadl
  content: "I cannot access the model now. Although I clicked on the gating button,\
    \ \n\n`tokenizer = AutoTokenizer.from_pretrained(\"ykilcher/gpt-4chan\")` is throwing\
    \ a value error. \n\n`Exception has occurred: ValueError\nConnection error, and\
    \ we cannot find the requested files in the cached path. Please try again or make\
    \ sure your Internet connection is on.` Is this intentional or not? Wanting to\
    \ experiment for research purposes."
  created_at: 2022-06-07 09:38:40+00:00
  edited: false
  hidden: false
  id: 629f2ab08483fd7f45eaff29
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f13fcfdb62cd745495629deaa7313032.svg
      fullname: Valentino Giudice
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aspie96
      type: user
    createdAt: '2022-06-07T17:52:04.000Z'
    data:
      edited: false
      editors:
      - Aspie96
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f13fcfdb62cd745495629deaa7313032.svg
          fullname: Valentino Giudice
          isHf: false
          isPro: false
          name: Aspie96
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sefaozalpadl&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sefaozalpadl\"\
          >@<span class=\"underline\">sefaozalpadl</span></a></span>\n\n\t</span></span>\
          \ if you can't access the model from the \"Files and versions\" tab either,\
          \ I have cloned all files on GitHub, except for the model itself which is\
          \ on the Internet Archive:<br><a rel=\"nofollow\" href=\"https://github.com/Aspie96/gpt-4chan-model\"\
          >https://github.com/Aspie96/gpt-4chan-model</a><br><a rel=\"nofollow\" href=\"\
          https://archive.org/details/gpt4chan_model\">https://archive.org/details/gpt4chan_model</a></p>\n"
        raw: '@sefaozalpadl if you can''t access the model from the "Files and versions"
          tab either, I have cloned all files on GitHub, except for the model itself
          which is on the Internet Archive:

          https://github.com/Aspie96/gpt-4chan-model

          https://archive.org/details/gpt4chan_model

          '
        updatedAt: '2022-06-07T17:52:04.705Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\u2764\uFE0F"
        users:
        - Skrip037
        - Mithilss
        - buzzroll
        - adhi01
        - augchan42
      - count: 3
        reaction: "\U0001F91D"
        users:
        - cate01
        - Mithilss
        - adhi01
    id: 629f904410066215dcecd33d
    type: comment
  author: Aspie96
  content: '@sefaozalpadl if you can''t access the model from the "Files and versions"
    tab either, I have cloned all files on GitHub, except for the model itself which
    is on the Internet Archive:

    https://github.com/Aspie96/gpt-4chan-model

    https://archive.org/details/gpt4chan_model

    '
  created_at: 2022-06-07 16:52:04+00:00
  edited: false
  hidden: false
  id: 629f904410066215dcecd33d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654647997234-629fd043a949dbd7559d6472.png?w=200&h=200&f=face
      fullname: John Adams
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lolwhat
      type: user
    createdAt: '2022-06-07T22:32:10.000Z'
    data:
      edited: false
      editors:
      - lolwhat
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654647997234-629fd043a949dbd7559d6472.png?w=200&h=200&f=face
          fullname: John Adams
          isHf: false
          isPro: false
          name: lolwhat
          type: user
        html: '<p>Glad I got this running before the arbiters of morality pruned it.
          </p>

          '
        raw: 'Glad I got this running before the arbiters of morality pruned it. '
        updatedAt: '2022-06-07T22:32:10.502Z'
      numEdits: 0
      reactions:
      - count: 10
        reaction: "\u2764\uFE0F"
        users:
        - nekocode
        - macguyver
        - cate01
        - Skrip037
        - Skitzkur
        - bbaaxx
        - Mithilss
        - buzzroll
        - adhi01
        - augchan42
    id: 629fd1ea48233a170e6a1640
    type: comment
  author: lolwhat
  content: 'Glad I got this running before the arbiters of morality pruned it. '
  created_at: 2022-06-07 21:32:10+00:00
  edited: false
  hidden: false
  id: 629fd1ea48233a170e6a1640
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654642274336-629fd557a949dbd7559e699c.png?w=200&h=200&f=face
      fullname: sneed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sneedandfeed
      type: user
    createdAt: '2022-06-07T23:02:19.000Z'
    data:
      edited: false
      editors:
      - sneedandfeed
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654642274336-629fd557a949dbd7559e699c.png?w=200&h=200&f=face
          fullname: sneed
          isHf: false
          isPro: false
          name: sneedandfeed
          type: user
        html: '<p>I think the only warning that should be put on this model is that
          it is extremely based and can cause large scale lib melt downs. Also is
          there anything that would stop someone from training their own model, this
          seems kind of like a pointless endeavor. </p>

          '
        raw: 'I think the only warning that should be put on this model is that it
          is extremely based and can cause large scale lib melt downs. Also is there
          anything that would stop someone from training their own model, this seems
          kind of like a pointless endeavor. '
        updatedAt: '2022-06-07T23:02:19.289Z'
      numEdits: 0
      reactions: []
    id: 629fd8fb198a9a5a755dcbe6
    type: comment
  author: sneedandfeed
  content: 'I think the only warning that should be put on this model is that it is
    extremely based and can cause large scale lib melt downs. Also is there anything
    that would stop someone from training their own model, this seems kind of like
    a pointless endeavor. '
  created_at: 2022-06-07 22:02:19+00:00
  edited: false
  hidden: false
  id: 629fd8fb198a9a5a755dcbe6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f13fcfdb62cd745495629deaa7313032.svg
      fullname: Valentino Giudice
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Aspie96
      type: user
    createdAt: '2022-06-07T23:12:43.000Z'
    data:
      edited: false
      editors:
      - Aspie96
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f13fcfdb62cd745495629deaa7313032.svg
          fullname: Valentino Giudice
          isHf: false
          isPro: false
          name: Aspie96
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sneedandfeed&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sneedandfeed\"\
          >@<span class=\"underline\">sneedandfeed</span></a></span>\n\n\t</span></span>\
          \ while I agree that the model should be allowed (and that's why I mirrored\
          \ it), I think making this about politics is unhelpful.</p>\n"
        raw: '@sneedandfeed while I agree that the model should be allowed (and that''s
          why I mirrored it), I think making this about politics is unhelpful.'
        updatedAt: '2022-06-07T23:12:43.454Z'
      numEdits: 0
      reactions: []
    id: 629fdb6ba949dbd7559f9d49
    type: comment
  author: Aspie96
  content: '@sneedandfeed while I agree that the model should be allowed (and that''s
    why I mirrored it), I think making this about politics is unhelpful.'
  created_at: 2022-06-07 22:12:43+00:00
  edited: false
  hidden: false
  id: 629fdb6ba949dbd7559f9d49
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654642274336-629fd557a949dbd7559e699c.png?w=200&h=200&f=face
      fullname: sneed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sneedandfeed
      type: user
    createdAt: '2022-06-07T23:57:15.000Z'
    data:
      edited: false
      editors:
      - sneedandfeed
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1654642274336-629fd557a949dbd7559e699c.png?w=200&h=200&f=face
          fullname: sneed
          isHf: false
          isPro: false
          name: sneedandfeed
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Aspie96&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Aspie96\">@<span class=\"\
          underline\">Aspie96</span></a></span>\n\n\t</span></span> Alright I will\
          \ concede that point, no reason to make this political. I think its worth\
          \ mentioning that pretty much all models trained on real world data will\
          \ produce some \"toxic/derogatory/adult\" outputs to some inputs. You can't\
          \ police everything. Like wise if you try hard enough gpt-4chan will have\
          \ outputs that are innocent/PC/Kosher to some inputs.</p>\n"
        raw: '@Aspie96 Alright I will concede that point, no reason to make this political.
          I think its worth mentioning that pretty much all models trained on real
          world data will produce some "toxic/derogatory/adult" outputs to some inputs.
          You can''t police everything. Like wise if you try hard enough gpt-4chan
          will have outputs that are innocent/PC/Kosher to some inputs.'
        updatedAt: '2022-06-07T23:57:15.427Z'
      numEdits: 0
      reactions: []
    id: 629fe5dbcaab27d290d78abb
    type: comment
  author: sneedandfeed
  content: '@Aspie96 Alright I will concede that point, no reason to make this political.
    I think its worth mentioning that pretty much all models trained on real world
    data will produce some "toxic/derogatory/adult" outputs to some inputs. You can''t
    police everything. Like wise if you try hard enough gpt-4chan will have outputs
    that are innocent/PC/Kosher to some inputs.'
  created_at: 2022-06-07 22:57:15+00:00
  edited: false
  hidden: false
  id: 629fe5dbcaab27d290d78abb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae9414486612a6a2c3bb3991197de328.svg
      fullname: Joltik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Weblure
      type: user
    createdAt: '2023-05-24T04:58:14.000Z'
    data:
      edited: true
      editors:
      - Weblure
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae9414486612a6a2c3bb3991197de328.svg
          fullname: Joltik
          isHf: false
          isPro: false
          name: Weblure
          type: user
        html: '<blockquote>

          <p>I agree with KCramer. There is nothing wrong with making a 4chan-based
          model and testing how it behaves.</p>

          <p>The main concern I have is that this model is freely accessible for use.
          While open science is a great principle, I''m a medical doctor and safety
          researcher by training and we always need to consider possible harms. Human
          research ethics is baked into the very foundation of our field, because
          of a long history of human rights abuses in the name of science, in particular
          experiments that cause harm to disempowered and marginalised people without
          their consent.</p>

          <p>It should be clear that this model carries a significant risk for this
          sort of harm, given the fact such an experiment has already been performed.
          The model author has used this model to produce a bot that made tens of
          thousands of harmful and discriminatory online comments on a publicly accessible
          forum, a forum that tends to be heavily populated by teenagers no less.
          There is no question that such human experimentation would never pass an
          ethics review board, where researchers intentionally expose teenagers to
          generated harmful content without their consent or knowledge, especially
          given the known risks of radicalisation on sites like 4chan.</p>

          <p>Given the demonstrated risk of harm, this model should not be freely
          accessible. The medical community has well established guidelines on how
          to manage the sharing of research materials which involve a risk to human
          subjects, with data privacy being the most common risk. It is common to
          allow research access to datasets in this context via a registration platform,
          where the applicants who are seeking access must describe their proposed
          research, and sign an agreement for data use. See the NIH/TCIA and MIMIC
          datasets for examples. The latter even has a requirement for applicants
          to pass a course in human research ethics prior to obtaining access to the
          data.</p>

          <p>A similar system should be in place here, and be used as the template
          for future model sharing where the model has the potential to produce harm.</p>

          </blockquote>

          <p>"Harmful"<br>It''s fucking text on a screen. If you can''t handle mean
          words, then don''t use it and stick to websites that have moderation/filters.
          Alternatively, you can just close your eyes.<br>Don''t infringe upon everyone''s
          freedoms just to cater to the sensitives of a loud minority/yourself. And
          no, "misinformation" isn''t an excuse to infringe upon basic human rights.
          Anything ''harmful'' someone says on the internet pales in comparison to
          the disinformation shoved down our throats on a daily basis by large corporations
          and government entities. Restricting the freedom of the people while allowing
          those in power to go unchecked (or worse, actively protected and boistered)
          does not do the world any favors.</p>

          '
        raw: "> I agree with KCramer. There is nothing wrong with making a 4chan-based\
          \ model and testing how it behaves.\n> \n> The main concern I have is that\
          \ this model is freely accessible for use. While open science is a great\
          \ principle, I'm a medical doctor and safety researcher by training and\
          \ we always need to consider possible harms. Human research ethics is baked\
          \ into the very foundation of our field, because of a long history of human\
          \ rights abuses in the name of science, in particular experiments that cause\
          \ harm to disempowered and marginalised people without their consent.\n\
          > \n> It should be clear that this model carries a significant risk for\
          \ this sort of harm, given the fact such an experiment has already been\
          \ performed. The model author has used this model to produce a bot that\
          \ made tens of thousands of harmful and discriminatory online comments on\
          \ a publicly accessible forum, a forum that tends to be heavily populated\
          \ by teenagers no less. There is no question that such human experimentation\
          \ would never pass an ethics review board, where researchers intentionally\
          \ expose teenagers to generated harmful content without their consent or\
          \ knowledge, especially given the known risks of radicalisation on sites\
          \ like 4chan.\n> \n> Given the demonstrated risk of harm, this model should\
          \ not be freely accessible. The medical community has well established guidelines\
          \ on how to manage the sharing of research materials which involve a risk\
          \ to human subjects, with data privacy being the most common risk. It is\
          \ common to allow research access to datasets in this context via a registration\
          \ platform, where the applicants who are seeking access must describe their\
          \ proposed research, and sign an agreement for data use. See the NIH/TCIA\
          \ and MIMIC datasets for examples. The latter even has a requirement for\
          \ applicants to pass a course in human research ethics prior to obtaining\
          \ access to the data.\n> \n> A similar system should be in place here, and\
          \ be used as the template for future model sharing where the model has the\
          \ potential to produce harm.\n\n\"Harmful\" \nIt's fucking text on a screen.\
          \ If you can't handle mean words, then don't use it and stick to websites\
          \ that have moderation/filters. Alternatively, you can just close your eyes.\n\
          Don't infringe upon everyone's freedoms just to cater to the sensitives\
          \ of a loud minority/yourself. And no, \"misinformation\" isn't an excuse\
          \ to infringe upon basic human rights. Anything 'harmful' someone says on\
          \ the internet pales in comparison to the disinformation shoved down our\
          \ throats on a daily basis by large corporations and government entities.\
          \ Restricting the freedom of the people while allowing those in power to\
          \ go unchecked (or worse, actively protected and boistered) does not do\
          \ the world any favors."
        updatedAt: '2023-05-24T05:00:59.414Z'
      numEdits: 1
      reactions:
      - count: 4
        reaction: "\u2764\uFE0F"
        users:
        - buzzroll
        - heyraghab
        - adhi01
        - augchan42
    id: 646d9966e0c5e3957367f951
    type: comment
  author: Weblure
  content: "> I agree with KCramer. There is nothing wrong with making a 4chan-based\
    \ model and testing how it behaves.\n> \n> The main concern I have is that this\
    \ model is freely accessible for use. While open science is a great principle,\
    \ I'm a medical doctor and safety researcher by training and we always need to\
    \ consider possible harms. Human research ethics is baked into the very foundation\
    \ of our field, because of a long history of human rights abuses in the name of\
    \ science, in particular experiments that cause harm to disempowered and marginalised\
    \ people without their consent.\n> \n> It should be clear that this model carries\
    \ a significant risk for this sort of harm, given the fact such an experiment\
    \ has already been performed. The model author has used this model to produce\
    \ a bot that made tens of thousands of harmful and discriminatory online comments\
    \ on a publicly accessible forum, a forum that tends to be heavily populated by\
    \ teenagers no less. There is no question that such human experimentation would\
    \ never pass an ethics review board, where researchers intentionally expose teenagers\
    \ to generated harmful content without their consent or knowledge, especially\
    \ given the known risks of radicalisation on sites like 4chan.\n> \n> Given the\
    \ demonstrated risk of harm, this model should not be freely accessible. The medical\
    \ community has well established guidelines on how to manage the sharing of research\
    \ materials which involve a risk to human subjects, with data privacy being the\
    \ most common risk. It is common to allow research access to datasets in this\
    \ context via a registration platform, where the applicants who are seeking access\
    \ must describe their proposed research, and sign an agreement for data use. See\
    \ the NIH/TCIA and MIMIC datasets for examples. The latter even has a requirement\
    \ for applicants to pass a course in human research ethics prior to obtaining\
    \ access to the data.\n> \n> A similar system should be in place here, and be\
    \ used as the template for future model sharing where the model has the potential\
    \ to produce harm.\n\n\"Harmful\" \nIt's fucking text on a screen. If you can't\
    \ handle mean words, then don't use it and stick to websites that have moderation/filters.\
    \ Alternatively, you can just close your eyes.\nDon't infringe upon everyone's\
    \ freedoms just to cater to the sensitives of a loud minority/yourself. And no,\
    \ \"misinformation\" isn't an excuse to infringe upon basic human rights. Anything\
    \ 'harmful' someone says on the internet pales in comparison to the disinformation\
    \ shoved down our throats on a daily basis by large corporations and government\
    \ entities. Restricting the freedom of the people while allowing those in power\
    \ to go unchecked (or worse, actively protected and boistered) does not do the\
    \ world any favors."
  created_at: 2023-05-24 03:58:14+00:00
  edited: true
  hidden: false
  id: 646d9966e0c5e3957367f951
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: ykilcher/gpt-4chan
repo_type: model
status: open
target_branch: null
title: Decision to Post
