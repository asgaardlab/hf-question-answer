!!python/object:huggingface_hub.community.DiscussionWithDetails
author: drag88
conflicting_files: null
created_at: 2023-12-18 12:24:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af46d6baeee7b3942e6f5b45ecede1c7.svg
      fullname: Aswin Sreenivas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: drag88
      type: user
    createdAt: '2023-12-18T12:24:40.000Z'
    data:
      edited: true
      editors:
      - ArthurZ
      - drag88
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5123609304428101
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: "<p>How can I fix the below error that comes while using mps?</p>\n\
          <p>Code :</p>\n<pre><code class=\"language-python\">model_id = <span class=\"\
          hljs-string\">\"llava-hf/bakLlava-v1-hf\"</span>\npipe = pipeline(<span\
          \ class=\"hljs-string\">\"image-to-text\"</span>, model=model_id, device=<span\
          \ class=\"hljs-string\">'mps'</span>, framework=<span class=\"hljs-string\"\
          >'pt'</span>)\nimage = df[<span class=\"hljs-string\">'Product Image Link'</span>][<span\
          \ class=\"hljs-number\">1000</span>]\nmax_new_tokens = <span class=\"hljs-number\"\
          >200</span>\nprompt = <span class=\"hljs-string\">\"USER: &lt;image&gt;\\\
          nWrite a detailed product description for the product in the image for a\
          \ customer planning to buy this product?\\nASSISTANT:\"</span>\n\noutputs\
          \ = pipe(image, prompt=prompt, generate_kwargs={<span class=\"hljs-string\"\
          >\"max_new_tokens\"</span>: <span class=\"hljs-number\">1000</span>})\n\
          </code></pre>\n<pre><code>Error:\n---------------------------------------------------------------------------\n\
          ValueError                                Traceback (most recent call last)\n\
          Cell In[79], line 4\n      1 max_new_tokens = 200\n      2 prompt = \"USER:\
          \ &lt;image&gt;\\nWrite a detailed product description for the product in\
          \ the image for a customer planning to buy this product?\\nASSISTANT:\"\n\
          ----&gt; 4 outputs = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\"\
          : 1000})\n\nFile ~/miniconda3/envs/imgtotext/lib/python3.9/site-packages/transformers/pipelines/image_to_text.py:111,\
          \ in ImageToTextPipeline.__call__(self, images, **kwargs)\n     83 def __call__(self,\
          \ images: Union[str, List[str], \"Image.Image\", List[\"Image.Image\"]],\
          \ **kwargs):\n     84     \"\"\"\n     85     Assign labels to the image(s)\
          \ passed as inputs.\n     86 \n   (...)\n    109         - **generated_text**\
          \ (`str`) -- The generated text.\n    110     \"\"\"\n--&gt; 111     return\
          \ super().__call__(images, **kwargs)\n\nFile ~/miniconda3/envs/imgtotext/lib/python3.9/site-packages/transformers/pipelines/base.py:1140,\
          \ in Pipeline.__call__(self, inputs, num_workers, batch_size, *args, **kwargs)\n\
          \   1132     return next(\n   1133         iter(\n   1134             self.get_iterator(\n\
          \   (...)\n   1137         )\n   1138     )\n   1139 else:\n...\n    315\
          \     )\n    317 final_embedding[image_to_overwrite] = image_features.contiguous().reshape(-1,\
          \ embed_dim)\n    318 final_attention_mask |= image_to_overwrite\n\nValueError:\
          \ The input provided to the model are wrong. The number of image tokens\
          \ is 1 while the number of image given to the model is 1. This prevents\
          \ correct indexing and breaks batch generation.\n</code></pre>\n"
        raw: "How can I fix the below error that comes while using mps?\n\nCode :\n\
          ```python\nmodel_id = \"llava-hf/bakLlava-v1-hf\"\npipe = pipeline(\"image-to-text\"\
          , model=model_id, device='mps', framework='pt')\nimage = df['Product Image\
          \ Link'][1000]\nmax_new_tokens = 200\nprompt = \"USER: <image>\\nWrite a\
          \ detailed product description for the product in the image for a customer\
          \ planning to buy this product?\\nASSISTANT:\"\n\noutputs = pipe(image,\
          \ prompt=prompt, generate_kwargs={\"max_new_tokens\": 1000})\n```\n```\n\
          Error:\n---------------------------------------------------------------------------\n\
          ValueError                                Traceback (most recent call last)\n\
          Cell In[79], line 4\n      1 max_new_tokens = 200\n      2 prompt = \"USER:\
          \ <image>\\nWrite a detailed product description for the product in the\
          \ image for a customer planning to buy this product?\\nASSISTANT:\"\n---->\
          \ 4 outputs = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\"\
          : 1000})\n\nFile ~/miniconda3/envs/imgtotext/lib/python3.9/site-packages/transformers/pipelines/image_to_text.py:111,\
          \ in ImageToTextPipeline.__call__(self, images, **kwargs)\n     83 def __call__(self,\
          \ images: Union[str, List[str], \"Image.Image\", List[\"Image.Image\"]],\
          \ **kwargs):\n     84     \"\"\"\n     85     Assign labels to the image(s)\
          \ passed as inputs.\n     86 \n   (...)\n    109         - **generated_text**\
          \ (`str`) -- The generated text.\n    110     \"\"\"\n--> 111     return\
          \ super().__call__(images, **kwargs)\n\nFile ~/miniconda3/envs/imgtotext/lib/python3.9/site-packages/transformers/pipelines/base.py:1140,\
          \ in Pipeline.__call__(self, inputs, num_workers, batch_size, *args, **kwargs)\n\
          \   1132     return next(\n   1133         iter(\n   1134             self.get_iterator(\n\
          \   (...)\n   1137         )\n   1138     )\n   1139 else:\n...\n    315\
          \     )\n    317 final_embedding[image_to_overwrite] = image_features.contiguous().reshape(-1,\
          \ embed_dim)\n    318 final_attention_mask |= image_to_overwrite\n\nValueError:\
          \ The input provided to the model are wrong. The number of image tokens\
          \ is 1 while the number of image given to the model is 1. This prevents\
          \ correct indexing and breaks batch generation.\n```"
        updatedAt: '2023-12-18T18:58:10.139Z'
      numEdits: 1
      reactions: []
    id: 65803a0811f7f587915a3322
    type: comment
  author: drag88
  content: "How can I fix the below error that comes while using mps?\n\nCode :\n\
    ```python\nmodel_id = \"llava-hf/bakLlava-v1-hf\"\npipe = pipeline(\"image-to-text\"\
    , model=model_id, device='mps', framework='pt')\nimage = df['Product Image Link'][1000]\n\
    max_new_tokens = 200\nprompt = \"USER: <image>\\nWrite a detailed product description\
    \ for the product in the image for a customer planning to buy this product?\\\
    nASSISTANT:\"\n\noutputs = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\"\
    : 1000})\n```\n```\nError:\n---------------------------------------------------------------------------\n\
    ValueError                                Traceback (most recent call last)\n\
    Cell In[79], line 4\n      1 max_new_tokens = 200\n      2 prompt = \"USER: <image>\\\
    nWrite a detailed product description for the product in the image for a customer\
    \ planning to buy this product?\\nASSISTANT:\"\n----> 4 outputs = pipe(image,\
    \ prompt=prompt, generate_kwargs={\"max_new_tokens\": 1000})\n\nFile ~/miniconda3/envs/imgtotext/lib/python3.9/site-packages/transformers/pipelines/image_to_text.py:111,\
    \ in ImageToTextPipeline.__call__(self, images, **kwargs)\n     83 def __call__(self,\
    \ images: Union[str, List[str], \"Image.Image\", List[\"Image.Image\"]], **kwargs):\n\
    \     84     \"\"\"\n     85     Assign labels to the image(s) passed as inputs.\n\
    \     86 \n   (...)\n    109         - **generated_text** (`str`) -- The generated\
    \ text.\n    110     \"\"\"\n--> 111     return super().__call__(images, **kwargs)\n\
    \nFile ~/miniconda3/envs/imgtotext/lib/python3.9/site-packages/transformers/pipelines/base.py:1140,\
    \ in Pipeline.__call__(self, inputs, num_workers, batch_size, *args, **kwargs)\n\
    \   1132     return next(\n   1133         iter(\n   1134             self.get_iterator(\n\
    \   (...)\n   1137         )\n   1138     )\n   1139 else:\n...\n    315     )\n\
    \    317 final_embedding[image_to_overwrite] = image_features.contiguous().reshape(-1,\
    \ embed_dim)\n    318 final_attention_mask |= image_to_overwrite\n\nValueError:\
    \ The input provided to the model are wrong. The number of image tokens is 1 while\
    \ the number of image given to the model is 1. This prevents correct indexing\
    \ and breaks batch generation.\n```"
  created_at: 2023-12-18 12:24:40+00:00
  edited: true
  hidden: false
  id: 65803a0811f7f587915a3322
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-12-18T18:59:45.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8311951160430908
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Could you share the actual snippet? I cannot run this if I don;t
          know which dataset you used</p>

          '
        raw: Could you share the actual snippet? I cannot run this if I don;t know
          which dataset you used
        updatedAt: '2023-12-18T18:59:45.462Z'
      numEdits: 0
      reactions: []
    id: 658096a14c23e9d7d7db3098
    type: comment
  author: ArthurZ
  content: Could you share the actual snippet? I cannot run this if I don;t know which
    dataset you used
  created_at: 2023-12-18 18:59:45+00:00
  edited: false
  hidden: false
  id: 658096a14c23e9d7d7db3098
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af46d6baeee7b3942e6f5b45ecede1c7.svg
      fullname: Aswin Sreenivas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: drag88
      type: user
    createdAt: '2023-12-18T19:48:46.000Z'
    data:
      edited: false
      editors:
      - drag88
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6503927707672119
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af46d6baeee7b3942e6f5b45ecede1c7.svg
          fullname: Aswin Sreenivas
          isHf: false
          isPro: false
          name: drag88
          type: user
        html: '<p>Sure thing, here you go, below is the URL from df[''Product Image
          Link''][1000]<br>''<a rel="nofollow" href="https://cdn.shopify.com/s/files/1/0602/3843/0403/products/burgundy-tulle-lace-long-prom-dress-burgundy-lace-evening-dress-1.jpg?v=1697165453''">https://cdn.shopify.com/s/files/1/0602/3843/0403/products/burgundy-tulle-lace-long-prom-dress-burgundy-lace-evening-dress-1.jpg?v=1697165453''</a></p>

          '
        raw: 'Sure thing, here you go, below is the URL from df[''Product Image Link''][1000]

          ''https://cdn.shopify.com/s/files/1/0602/3843/0403/products/burgundy-tulle-lace-long-prom-dress-burgundy-lace-evening-dress-1.jpg?v=1697165453''

          '
        updatedAt: '2023-12-18T19:48:46.725Z'
      numEdits: 0
      reactions: []
    id: 6580a21e98aa9fcdd25710b4
    type: comment
  author: drag88
  content: 'Sure thing, here you go, below is the URL from df[''Product Image Link''][1000]

    ''https://cdn.shopify.com/s/files/1/0602/3843/0403/products/burgundy-tulle-lace-long-prom-dress-burgundy-lace-evening-dress-1.jpg?v=1697165453''

    '
  created_at: 2023-12-18 19:48:46+00:00
  edited: false
  hidden: false
  id: 6580a21e98aa9fcdd25710b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d703a59c42a8715fba5dacc054a6e9c6.svg
      fullname: George Novack
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gnovack
      type: user
    createdAt: '2024-01-14T23:02:36.000Z'
    data:
      edited: false
      editors:
      - gnovack
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9417145252227783
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d703a59c42a8715fba5dacc054a6e9c6.svg
          fullname: George Novack
          isHf: false
          isPro: false
          name: gnovack
          type: user
        html: '<p>I ran into this as well. Seems to be caused by this bug with calling
          <code>cumsum</code> on a bool tensor: <a rel="nofollow" href="https://github.com/pytorch/pytorch/issues/96614">https://github.com/pytorch/pytorch/issues/96614</a></p>

          '
        raw: 'I ran into this as well. Seems to be caused by this bug with calling
          `cumsum` on a bool tensor: https://github.com/pytorch/pytorch/issues/96614'
        updatedAt: '2024-01-14T23:02:36.459Z'
      numEdits: 0
      reactions: []
    id: 65a4680c680cb2eb94bf7a97
    type: comment
  author: gnovack
  content: 'I ran into this as well. Seems to be caused by this bug with calling `cumsum`
    on a bool tensor: https://github.com/pytorch/pytorch/issues/96614'
  created_at: 2024-01-14 23:02:36+00:00
  edited: false
  hidden: false
  id: 65a4680c680cb2eb94bf7a97
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: llava-hf/bakLlava-v1-hf
repo_type: model
status: open
target_branch: null
title: Error while running in mps
