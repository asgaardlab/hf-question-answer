!!python/object:huggingface_hub.community.DiscussionWithDetails
author: deleted
conflicting_files: null
created_at: 2023-05-14 00:23:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    createdAt: '2023-05-14T01:23:48.000Z'
    data:
      edited: false
      editors:
      - deleted
      hidden: false
      isReport: false
      latest:
        html: '<p>Firstly, I just wanted to show my appreciation for your models!
          I think it''s safe to say you make the best models available and we all
          appreciate your efforts in bring us closer to GPT-4 at home! </p>

          <p>In regards to the 8_0 model, would it be possible to upload it on a different
          site that allows larger than 50GB files? It would be interesting to test
          it vs other models and 5_1.</p>

          <p>Thank you!</p>

          '
        raw: "Firstly, I just wanted to show my appreciation for your models! I think\
          \ it's safe to say you make the best models available and we all appreciate\
          \ your efforts in bring us closer to GPT-4 at home! \r\n\r\nIn regards to\
          \ the 8_0 model, would it be possible to upload it on a different site that\
          \ allows larger than 50GB files? It would be interesting to test it vs other\
          \ models and 5_1.\r\n\r\nThank you!"
        updatedAt: '2023-05-14T01:23:48.243Z'
      numEdits: 0
      reactions: []
    id: 6460382410ab646c08e8cf34
    type: comment
  author: deleted
  content: "Firstly, I just wanted to show my appreciation for your models! I think\
    \ it's safe to say you make the best models available and we all appreciate your\
    \ efforts in bring us closer to GPT-4 at home! \r\n\r\nIn regards to the 8_0 model,\
    \ would it be possible to upload it on a different site that allows larger than\
    \ 50GB files? It would be interesting to test it vs other models and 5_1.\r\n\r\
    \nThank you!"
  created_at: 2023-05-14 00:23:48+00:00
  edited: false
  hidden: false
  id: 6460382410ab646c08e8cf34
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    createdAt: '2023-05-16T03:26:34.000Z'
    data:
      status: closed
    id: 6462f7eac87d09bb4a910a3f
    type: status-change
  author: deleted
  created_at: 2023-05-16 02:26:34+00:00
  id: 6462f7eac87d09bb4a910a3f
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    createdAt: '2023-05-16T03:26:49.000Z'
    data:
      status: open
    id: 6462f7f9c87d09bb4a910ac8
    type: status-change
  author: deleted
  created_at: 2023-05-16 02:26:49+00:00
  id: 6462f7f9c87d09bb4a910ac8
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-16T07:22:44.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Who deletes their HF account!? :)</p>

          <p>Anyway if you ever see this message: yes OK I will give that some thought
          next time I do a 65B. I could put it on Google Drive I guess.</p>

          '
        raw: 'Who deletes their HF account!? :)


          Anyway if you ever see this message: yes OK I will give that some thought
          next time I do a 65B. I could put it on Google Drive I guess.'
        updatedAt: '2023-05-16T07:22:44.497Z'
      numEdits: 0
      reactions: []
    id: 64632f4495e64061c9790d28
    type: comment
  author: TheBloke
  content: 'Who deletes their HF account!? :)


    Anyway if you ever see this message: yes OK I will give that some thought next
    time I do a 65B. I could put it on Google Drive I guess.'
  created_at: 2023-05-16 06:22:44+00:00
  edited: false
  hidden: false
  id: 64632f4495e64061c9790d28
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4e3b34f0605e6e2c9b5c5beb1a9c192f.svg
      fullname: Xiao Jin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mljxy
      type: user
    createdAt: '2023-05-16T14:24:55.000Z'
    data:
      edited: false
      editors:
      - mljxy
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4e3b34f0605e6e2c9b5c5beb1a9c192f.svg
          fullname: Xiao Jin
          isHf: false
          isPro: false
          name: mljxy
          type: user
        html: '<p>GGML used to work with multiple files. I think the transition to
          single file was due to the use of mmap. There shouldn''t be any technical
          limitations in doing multiple mmap instead of only one, though that would
          complicate the code a lot.</p>

          '
        raw: GGML used to work with multiple files. I think the transition to single
          file was due to the use of mmap. There shouldn't be any technical limitations
          in doing multiple mmap instead of only one, though that would complicate
          the code a lot.
        updatedAt: '2023-05-16T14:24:55.989Z'
      numEdits: 0
      reactions: []
    id: 6463923795e64061c97d2bd3
    type: comment
  author: mljxy
  content: GGML used to work with multiple files. I think the transition to single
    file was due to the use of mmap. There shouldn't be any technical limitations
    in doing multiple mmap instead of only one, though that would complicate the code
    a lot.
  created_at: 2023-05-16 13:24:55+00:00
  edited: false
  hidden: false
  id: 6463923795e64061c97d2bd3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-16T15:00:40.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah. Maybe it still does work with multiple files? It says "n_part"
          in the header info.</p>

          <p>But the issue is I have no idea how to make multi-part GGMLs.  I use
          the provided <code>convert.py</code> to make GGMLs, and that currently only
          supports making single part files.</p>

          <p>Might not be too hard to update convert.py for making multi-part GGMLs.
          But I''ve not looked at it myself yet</p>

          '
        raw: 'Yeah. Maybe it still does work with multiple files? It says "n_part"
          in the header info.


          But the issue is I have no idea how to make multi-part GGMLs.  I use the
          provided `convert.py` to make GGMLs, and that currently only supports making
          single part files.


          Might not be too hard to update convert.py for making multi-part GGMLs.
          But I''ve not looked at it myself yet'
        updatedAt: '2023-05-16T15:00:48.761Z'
      numEdits: 1
      reactions: []
    id: 64639a98589d58dbc79d6a14
    type: comment
  author: TheBloke
  content: 'Yeah. Maybe it still does work with multiple files? It says "n_part" in
    the header info.


    But the issue is I have no idea how to make multi-part GGMLs.  I use the provided
    `convert.py` to make GGMLs, and that currently only supports making single part
    files.


    Might not be too hard to update convert.py for making multi-part GGMLs. But I''ve
    not looked at it myself yet'
  created_at: 2023-05-16 14:00:40+00:00
  edited: true
  hidden: false
  id: 64639a98589d58dbc79d6a14
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b498694d13b6c2596efc7b0ca13ac2ae.svg
      fullname: venn venner
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: venn12
      type: user
    createdAt: '2023-05-19T21:35:02.000Z'
    data:
      edited: false
      editors:
      - venn12
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b498694d13b6c2596efc7b0ca13ac2ae.svg
          fullname: venn venner
          isHf: false
          isPro: false
          name: venn12
          type: user
        html: '<blockquote>

          <p>Yeah. Maybe it still does work with multiple files? It says "n_part"
          in the header info.</p>

          <p>But the issue is I have no idea how to make multi-part GGMLs.  I use
          the provided <code>convert.py</code> to make GGMLs, and that currently only
          supports making single part files.</p>

          <p>Might not be too hard to update convert.py for making multi-part GGMLs.
          But I''ve not looked at it myself yet</p>

          </blockquote>

          <p>I think you can split files with compression programs like 7zip. Have
          you considered that?</p>

          '
        raw: "> Yeah. Maybe it still does work with multiple files? It says \"n_part\"\
          \ in the header info.\n> \n> But the issue is I have no idea how to make\
          \ multi-part GGMLs.  I use the provided `convert.py` to make GGMLs, and\
          \ that currently only supports making single part files.\n> \n> Might not\
          \ be too hard to update convert.py for making multi-part GGMLs. But I've\
          \ not looked at it myself yet\n\nI think you can split files with compression\
          \ programs like 7zip. Have you considered that?"
        updatedAt: '2023-05-19T21:35:02.260Z'
      numEdits: 0
      reactions: []
    id: 6467eb86ab75d9cb3c4e2f11
    type: comment
  author: venn12
  content: "> Yeah. Maybe it still does work with multiple files? It says \"n_part\"\
    \ in the header info.\n> \n> But the issue is I have no idea how to make multi-part\
    \ GGMLs.  I use the provided `convert.py` to make GGMLs, and that currently only\
    \ supports making single part files.\n> \n> Might not be too hard to update convert.py\
    \ for making multi-part GGMLs. But I've not looked at it myself yet\n\nI think\
    \ you can split files with compression programs like 7zip. Have you considered\
    \ that?"
  created_at: 2023-05-19 20:35:02+00:00
  edited: false
  hidden: false
  id: 6467eb86ab75d9cb3c4e2f11
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-19T21:36:16.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yes I have considered exactly that. I was talking about it with
          the llama.cpp team recently, to see if there was any way to do it with llama.cpp
          natively.  It may be possible, but the consensus was just to use multi part
          ZIP.</p>

          <p>So I''ll look into doing that soon when I have more time.</p>

          '
        raw: 'Yes I have considered exactly that. I was talking about it with the
          llama.cpp team recently, to see if there was any way to do it with llama.cpp
          natively.  It may be possible, but the consensus was just to use multi part
          ZIP.


          So I''ll look into doing that soon when I have more time.'
        updatedAt: '2023-05-19T21:36:16.895Z'
      numEdits: 0
      reactions: []
    id: 6467ebd03a7c8dda230c08d3
    type: comment
  author: TheBloke
  content: 'Yes I have considered exactly that. I was talking about it with the llama.cpp
    team recently, to see if there was any way to do it with llama.cpp natively.  It
    may be possible, but the consensus was just to use multi part ZIP.


    So I''ll look into doing that soon when I have more time.'
  created_at: 2023-05-19 20:36:16+00:00
  edited: false
  hidden: false
  id: 6467ebd03a7c8dda230c08d3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/gpt4-alpaca-lora_mlp-65B-GGML
repo_type: model
status: open
target_branch: null
title: 8_0 Model and thank you so much for your work!!!
