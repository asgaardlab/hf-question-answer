!!python/object:huggingface_hub.community.DiscussionWithDetails
author: WajihUllahBaig
conflicting_files: null
created_at: 2023-05-28 11:02:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6c9ff3623a1cdeebdee67c0a2d531e56.svg
      fullname: Wajih Ullah Baig
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: WajihUllahBaig
      type: user
    createdAt: '2023-05-28T12:02:02.000Z'
    data:
      edited: false
      editors:
      - WajihUllahBaig
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6c9ff3623a1cdeebdee67c0a2d531e56.svg
          fullname: Wajih Ullah Baig
          isHf: false
          isPro: false
          name: WajihUllahBaig
          type: user
        html: '<p>I am on a DGX-A100 machine, pytorch=1.12.1 and I get the following
          before I get an exception </p>

          <p>The model ''RWForCausalLM'' is not supported for text-generation. Supported
          models are [''BartForCausalLM'', ''BertLMHeadModel'', ''BertGenerationDecoder'',
          ''BigBirdForCausalLM'', ''BigBirdPegasusForCausalLM'', ''BioGptForCausalLM'',
          ''BlenderbotForCausalLM'', ''BlenderbotSmallForCausalLM'', ''BloomForCausalLM'',
          ''CamembertForCausalLM'', ''CodeGenForCausalLM'', ''CTRLLMHeadModel'', ''Data2VecTextForCausalLM'',
          ''ElectraForCausalLM'', ''ErnieForCausalLM'', ''GitForCausalLM'', ''GPT2LMHeadModel'',
          ''GPT2LMHeadModel'', ''GPTNeoForCausalLM'', ''GPTNeoXForCausalLM'', ''GPTNeoXJapaneseForCausalLM'',
          ''GPTJForCausalLM'', ''MarianForCausalLM'', ''MBartForCausalLM'', ''MegatronBertForCausalLM'',
          ''MvpForCausalLM'', ''OpenAIGPTLMHeadModel'', ''OPTForCausalLM'', ''PegasusForCausalLM'',
          ''PLBartForCausalLM'', ''ProphetNetForCausalLM'', ''QDQBertLMHeadModel'',
          ''ReformerModelWithLMHead'', ''RemBertForCausalLM'', ''RobertaForCausalLM'',
          ''RobertaPreLayerNormForCausalLM'', ''RoCBertForCausalLM'', ''RoFormerForCausalLM'',
          ''Speech2Text2ForCausalLM'', ''TransfoXLLMHeadModel'', ''TrOCRForCausalLM'',
          ''XGLMForCausalLM'', ''XLMWithLMHeadModel'', ''XLMProphetNetForCausalLM'',
          ''XLMRobertaForCausalLM'', ''XLMRobertaXLForCausalLM'', ''XLNetLMHeadModel'',
          ''XmodForCausalLM''].<br>Setting pad_token_id to eos_token_id:11 for open-end
          generation.</p>

          <p>attn_output = F.scaled_dot_product_attention(<br>AttributeError: module
          ''torch.nn.functional'' has no attribute ''scaled_dot_product_attention''</p>

          '
        raw: "I am on a DGX-A100 machine, pytorch=1.12.1 and I get the following before\
          \ I get an exception \r\n\r\nThe model 'RWForCausalLM' is not supported\
          \ for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel',\
          \ 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM',\
          \ 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM',\
          \ 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CTRLLMHeadModel',\
          \ 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM',\
          \ 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM',\
          \ 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'MarianForCausalLM',\
          \ 'MBartForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenAIGPTLMHeadModel',\
          \ 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM',\
          \ 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM',\
          \ 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM',\
          \ 'RoFormerForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel',\
          \ 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM',\
          \ 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel',\
          \ 'XmodForCausalLM'].\r\nSetting pad_token_id to eos_token_id:11 for open-end\
          \ generation.\r\n\r\nattn_output = F.scaled_dot_product_attention(\r\nAttributeError:\
          \ module 'torch.nn.functional' has no attribute 'scaled_dot_product_attention'\r\
          \n"
        updatedAt: '2023-05-28T12:02:02.797Z'
      numEdits: 0
      reactions: []
    id: 647342babf9b32c6bbc89962
    type: comment
  author: WajihUllahBaig
  content: "I am on a DGX-A100 machine, pytorch=1.12.1 and I get the following before\
    \ I get an exception \r\n\r\nThe model 'RWForCausalLM' is not supported for text-generation.\
    \ Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder',\
    \ 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM',\
    \ 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM',\
    \ 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM',\
    \ 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTNeoForCausalLM',\
    \ 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'MarianForCausalLM',\
    \ 'MBartForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenAIGPTLMHeadModel',\
    \ 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM',\
    \ 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM',\
    \ 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM',\
    \ 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM',\
    \ 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM',\
    \ 'XLNetLMHeadModel', 'XmodForCausalLM'].\r\nSetting pad_token_id to eos_token_id:11\
    \ for open-end generation.\r\n\r\nattn_output = F.scaled_dot_product_attention(\r\
    \nAttributeError: module 'torch.nn.functional' has no attribute 'scaled_dot_product_attention'\r\
    \n"
  created_at: 2023-05-28 11:02:02+00:00
  edited: false
  hidden: false
  id: 647342babf9b32c6bbc89962
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/6c9ff3623a1cdeebdee67c0a2d531e56.svg
      fullname: Wajih Ullah Baig
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: WajihUllahBaig
      type: user
    createdAt: '2023-05-28T12:02:26.000Z'
    data:
      from: 'attn_output = F.scaled_dot_product_attention( AttributeError: module
        ''torch.nn.functional'' has no attribute ''scaled_dot_product_attention'''
      to: 'Error/Bug   attn_output = F.scaled_dot_product_attention( AttributeError:
        module ''torch.nn.functional'' has no attribute ''scaled_dot_product_attention'''
    id: 647342d2352c94a20dd2b8c4
    type: title-change
  author: WajihUllahBaig
  created_at: 2023-05-28 11:02:26+00:00
  id: 647342d2352c94a20dd2b8c4
  new_title: 'Error/Bug   attn_output = F.scaled_dot_product_attention( AttributeError:
    module ''torch.nn.functional'' has no attribute ''scaled_dot_product_attention'''
  old_title: 'attn_output = F.scaled_dot_product_attention( AttributeError: module
    ''torch.nn.functional'' has no attribute ''scaled_dot_product_attention'''
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594651707950-noauth.jpeg?w=200&h=200&f=face
      fullname: Lewis Tunstall
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lewtun
      type: user
    createdAt: '2023-05-28T15:18:57.000Z'
    data:
      edited: false
      editors:
      - lewtun
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594651707950-noauth.jpeg?w=200&h=200&f=face
          fullname: Lewis Tunstall
          isHf: true
          isPro: false
          name: lewtun
          type: user
        html: '<p>I encountered a similar problem &amp; the solution is to bump up
          to <code>torch</code> v2.0.1</p>

          '
        raw: I encountered a similar problem & the solution is to bump up to `torch`
          v2.0.1
        updatedAt: '2023-05-28T15:18:57.975Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - WajihUllahBaig
        - guyeshet
        - tom1ong
    id: 647370e12a74fb43ccde9d5c
    type: comment
  author: lewtun
  content: I encountered a similar problem & the solution is to bump up to `torch`
    v2.0.1
  created_at: 2023-05-28 14:18:57+00:00
  edited: false
  hidden: false
  id: 647370e12a74fb43ccde9d5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6c9ff3623a1cdeebdee67c0a2d531e56.svg
      fullname: Wajih Ullah Baig
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: WajihUllahBaig
      type: user
    createdAt: '2023-05-29T06:15:44.000Z'
    data:
      edited: false
      editors:
      - WajihUllahBaig
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6c9ff3623a1cdeebdee67c0a2d531e56.svg
          fullname: Wajih Ullah Baig
          isHf: false
          isPro: false
          name: WajihUllahBaig
          type: user
        html: '<p>Correct, I just bumped to 2.0.0 and it worked</p>

          '
        raw: Correct, I just bumped to 2.0.0 and it worked
        updatedAt: '2023-05-29T06:15:44.346Z'
      numEdits: 0
      reactions: []
    id: 64744310f9e3e0b312e5547d
    type: comment
  author: WajihUllahBaig
  content: Correct, I just bumped to 2.0.0 and it worked
  created_at: 2023-05-29 05:15:44+00:00
  edited: false
  hidden: false
  id: 64744310f9e3e0b312e5547d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
      fullname: Falcon LLM TII UAE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FalconLLM
      type: user
    createdAt: '2023-05-30T07:17:52.000Z'
    data:
      status: closed
    id: 6475a32009e773226332edf4
    type: status-change
  author: FalconLLM
  created_at: 2023-05-30 06:17:52+00:00
  id: 6475a32009e773226332edf4
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: tiiuae/falcon-40b
repo_type: model
status: closed
target_branch: null
title: 'Error/Bug   attn_output = F.scaled_dot_product_attention( AttributeError:
  module ''torch.nn.functional'' has no attribute ''scaled_dot_product_attention'''
