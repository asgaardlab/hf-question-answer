!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dimaischenko
conflicting_files: null
created_at: 2023-06-07 11:24:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-07T12:24:25.000Z'
    data:
      edited: false
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8668926358222961
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: '<p>I tried to get an answer in falcon-7b discussions, but no one answers,
          maybe this community can help me.</p>

          <p>Writing my own inference loop, I get error when using <code>past_key_values</code>,
          tensor dimension error or complete nonsense in generation. I debugged default
          examples from model description with standard <code>model.generate</code>
          or <code>pipeline</code>, and saw that they don''t use <code>past_key_values</code>
          at all in generation loop.</p>

          <p>I would be very glad if you can tell me if the use <code>past_key_values</code>
          is implemented with a bug or is not supported or I do not understand something?
          After all, it speeds up inference by several times.</p>

          <p>More details in falcon-7b discussion <a href="https://huggingface.co/tiiuae/falcon-7b/discussions/17">https://huggingface.co/tiiuae/falcon-7b/discussions/17</a></p>

          '
        raw: "I tried to get an answer in falcon-7b discussions, but no one answers,\
          \ maybe this community can help me.\r\n\r\nWriting my own inference loop,\
          \ I get error when using `past_key_values`, tensor dimension error or complete\
          \ nonsense in generation. I debugged default examples from model description\
          \ with standard `model.generate` or `pipeline`, and saw that they don't\
          \ use `past_key_values` at all in generation loop.\r\n\r\nI would be very\
          \ glad if you can tell me if the use `past_key_values` is implemented with\
          \ a bug or is not supported or I do not understand something? After all,\
          \ it speeds up inference by several times.\r\n\r\nMore details in falcon-7b\
          \ discussion https://huggingface.co/tiiuae/falcon-7b/discussions/17"
        updatedAt: '2023-06-07T12:24:25.956Z'
      numEdits: 0
      reactions: []
    id: 648076f9f5be39206aef2125
    type: comment
  author: dimaischenko
  content: "I tried to get an answer in falcon-7b discussions, but no one answers,\
    \ maybe this community can help me.\r\n\r\nWriting my own inference loop, I get\
    \ error when using `past_key_values`, tensor dimension error or complete nonsense\
    \ in generation. I debugged default examples from model description with standard\
    \ `model.generate` or `pipeline`, and saw that they don't use `past_key_values`\
    \ at all in generation loop.\r\n\r\nI would be very glad if you can tell me if\
    \ the use `past_key_values` is implemented with a bug or is not supported or I\
    \ do not understand something? After all, it speeds up inference by several times.\r\
    \n\r\nMore details in falcon-7b discussion https://huggingface.co/tiiuae/falcon-7b/discussions/17"
  created_at: 2023-06-07 11:24:25+00:00
  edited: false
  hidden: false
  id: 648076f9f5be39206aef2125
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671801056760-noauth.png?w=200&h=200&f=face
      fullname: Charles Chudant
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cchudant
      type: user
    createdAt: '2023-06-07T12:34:49.000Z'
    data:
      edited: false
      editors:
      - cchudant
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8613758683204651
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671801056760-noauth.png?w=200&h=200&f=face
          fullname: Charles Chudant
          isHf: false
          isPro: false
          name: cchudant
          type: user
        html: '<blockquote>

          <p>I tried to get an answer in falcon-7b discussions, but no one answers,
          maybe this community can help me.</p>

          <p>Writing my own inference loop, I get error when using <code>past_key_values</code>,
          tensor dimension error or complete nonsense in generation. I debugged default
          examples from model description with standard <code>model.generate</code>
          or <code>pipeline</code>, and saw that they don''t use <code>past_key_values</code>
          at all in generation loop.</p>

          <p>I would be very glad if you can tell me if the use <code>past_key_values</code>
          is implemented with a bug or is not supported or I do not understand something?
          After all, it speeds up inference by several times.</p>

          <p>More details in falcon-7b discussion <a href="https://huggingface.co/tiiuae/falcon-7b/discussions/17">https://huggingface.co/tiiuae/falcon-7b/discussions/17</a></p>

          </blockquote>

          <p>Hi!<br>I had the exact same problem, and found this: <a href="https://huggingface.co/tiiuae/falcon-40b/discussions/47">https://huggingface.co/tiiuae/falcon-40b/discussions/47</a></p>

          <p>Hope this helps!</p>

          '
        raw: "> I tried to get an answer in falcon-7b discussions, but no one answers,\
          \ maybe this community can help me.\n> \n> Writing my own inference loop,\
          \ I get error when using `past_key_values`, tensor dimension error or complete\
          \ nonsense in generation. I debugged default examples from model description\
          \ with standard `model.generate` or `pipeline`, and saw that they don't\
          \ use `past_key_values` at all in generation loop.\n> \n> I would be very\
          \ glad if you can tell me if the use `past_key_values` is implemented with\
          \ a bug or is not supported or I do not understand something? After all,\
          \ it speeds up inference by several times.\n> \n> More details in falcon-7b\
          \ discussion https://huggingface.co/tiiuae/falcon-7b/discussions/17\n\n\
          Hi!\nI had the exact same problem, and found this: https://huggingface.co/tiiuae/falcon-40b/discussions/47\n\
          \nHope this helps!"
        updatedAt: '2023-06-07T12:34:49.515Z'
      numEdits: 0
      reactions: []
    id: 64807969bb25a636c9da2cd7
    type: comment
  author: cchudant
  content: "> I tried to get an answer in falcon-7b discussions, but no one answers,\
    \ maybe this community can help me.\n> \n> Writing my own inference loop, I get\
    \ error when using `past_key_values`, tensor dimension error or complete nonsense\
    \ in generation. I debugged default examples from model description with standard\
    \ `model.generate` or `pipeline`, and saw that they don't use `past_key_values`\
    \ at all in generation loop.\n> \n> I would be very glad if you can tell me if\
    \ the use `past_key_values` is implemented with a bug or is not supported or I\
    \ do not understand something? After all, it speeds up inference by several times.\n\
    > \n> More details in falcon-7b discussion https://huggingface.co/tiiuae/falcon-7b/discussions/17\n\
    \nHi!\nI had the exact same problem, and found this: https://huggingface.co/tiiuae/falcon-40b/discussions/47\n\
    \nHope this helps!"
  created_at: 2023-06-07 11:34:49+00:00
  edited: false
  hidden: false
  id: 64807969bb25a636c9da2cd7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-07T12:40:13.000Z'
    data:
      edited: false
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9637211561203003
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;cchudant&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/cchudant\">@<span class=\"\
          underline\">cchudant</span></a></span>\n\n\t</span></span> thank you! I'm\
          \ going to test it now and I'll be sure to write here about the results!</p>\n"
        raw: '@cchudant thank you! I''m going to test it now and I''ll be sure to
          write here about the results!'
        updatedAt: '2023-06-07T12:40:13.129Z'
      numEdits: 0
      reactions: []
    id: 64807aade1421e205fd743e6
    type: comment
  author: dimaischenko
  content: '@cchudant thank you! I''m going to test it now and I''ll be sure to write
    here about the results!'
  created_at: 2023-06-07 11:40:13+00:00
  edited: false
  hidden: false
  id: 64807aade1421e205fd743e6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671801056760-noauth.png?w=200&h=200&f=face
      fullname: Charles Chudant
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cchudant
      type: user
    createdAt: '2023-06-07T12:55:15.000Z'
    data:
      edited: true
      editors:
      - cchudant
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9148879647254944
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671801056760-noauth.png?w=200&h=200&f=face
          fullname: Charles Chudant
          isHf: false
          isPro: false
          name: cchudant
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;dimaischenko&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/dimaischenko\"\
          >@<span class=\"underline\">dimaischenko</span></a></span>\n\n\t</span></span><br>just\
          \ to be clear, I have not tested it :)<br>it's one of:</p>\n<ol>\n<li><p>Either,\
          \ it is a bug as I pointed out, and the line I referenced is wrong &amp;\
          \ other changes elsewhere<br>I would guess that <code>_, _, kv_length =\
          \ key_layer.shape</code> would also need to change to <code>_, kv_length,\
          \ _ = key_layer.shape</code>. Maybe some other stuff.</p>\n</li>\n<li><p>Or,\
          \ departure from bloom kv-cache shape is intended, meaning <code>_convert_to_rw_cache</code>\
          \  and <code>_convert_to_standard_cache</code> need to be changed to swap\
          \ the key dimensions.<br>The comment</p>\n</li>\n</ol>\n<pre><code># concatenate\
          \ along seq_length dimension:\n#  - key: [batch_size * self.num_heads, head_dim,\
          \ kv_length]\n#  - value: [batch_size * self.num_heads, kv_length, head_dim]\n\
          </code></pre>\n<p>would need to change to</p>\n<pre><code># concatenate\
          \ along seq_length dimension:\n#  - key: [batch_size * self.num_heads, kv_length,\
          \ head_dim]\n#  - value: [batch_size * self.num_heads, kv_length, head_dim]\n\
          </code></pre>\n<p>I have not tested it :) I am currently only interested\
          \ in benchmarking the inference of the models, and I found this out because\
          \ my bench broke with kv-cache.<br>I have not actually checked if it gives\
          \ me valid outputs.</p>\n"
        raw: "@dimaischenko \njust to be clear, I have not tested it :)\nit's one\
          \ of:\n\n1) Either, it is a bug as I pointed out, and the line I referenced\
          \ is wrong & other changes elsewhere\nI would guess that `_, _, kv_length\
          \ = key_layer.shape` would also need to change to `_, kv_length, _ = key_layer.shape`.\
          \ Maybe some other stuff.\n\n2) Or, departure from bloom kv-cache shape\
          \ is intended, meaning `_convert_to_rw_cache`  and `_convert_to_standard_cache`\
          \ need to be changed to swap the key dimensions.\nThe comment\n```\n# concatenate\
          \ along seq_length dimension:\n#  - key: [batch_size * self.num_heads, head_dim,\
          \ kv_length]\n#  - value: [batch_size * self.num_heads, kv_length, head_dim]\n\
          ```\nwould need to change to\n```\n# concatenate along seq_length dimension:\n\
          #  - key: [batch_size * self.num_heads, kv_length, head_dim]\n#  - value:\
          \ [batch_size * self.num_heads, kv_length, head_dim]\n```\n\nI have not\
          \ tested it :) I am currently only interested in benchmarking the inference\
          \ of the models, and I found this out because my bench broke with kv-cache.\n\
          I have not actually checked if it gives me valid outputs."
        updatedAt: '2023-06-07T12:55:37.701Z'
      numEdits: 1
      reactions: []
    id: 64807e33bb25a636c9da875d
    type: comment
  author: cchudant
  content: "@dimaischenko \njust to be clear, I have not tested it :)\nit's one of:\n\
    \n1) Either, it is a bug as I pointed out, and the line I referenced is wrong\
    \ & other changes elsewhere\nI would guess that `_, _, kv_length = key_layer.shape`\
    \ would also need to change to `_, kv_length, _ = key_layer.shape`. Maybe some\
    \ other stuff.\n\n2) Or, departure from bloom kv-cache shape is intended, meaning\
    \ `_convert_to_rw_cache`  and `_convert_to_standard_cache` need to be changed\
    \ to swap the key dimensions.\nThe comment\n```\n# concatenate along seq_length\
    \ dimension:\n#  - key: [batch_size * self.num_heads, head_dim, kv_length]\n#\
    \  - value: [batch_size * self.num_heads, kv_length, head_dim]\n```\nwould need\
    \ to change to\n```\n# concatenate along seq_length dimension:\n#  - key: [batch_size\
    \ * self.num_heads, kv_length, head_dim]\n#  - value: [batch_size * self.num_heads,\
    \ kv_length, head_dim]\n```\n\nI have not tested it :) I am currently only interested\
    \ in benchmarking the inference of the models, and I found this out because my\
    \ bench broke with kv-cache.\nI have not actually checked if it gives me valid\
    \ outputs."
  created_at: 2023-06-07 11:55:15+00:00
  edited: true
  hidden: false
  id: 64807e33bb25a636c9da875d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-07T13:01:51.000Z'
    data:
      edited: false
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.960557222366333
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;cchudant&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/cchudant\">@<span class=\"\
          underline\">cchudant</span></a></span>\n\n\t</span></span>  I will carefully\
          \ sort it out and report back, I also came to similar thoughts and began\
          \ to swap the dimensions of the tensors manually, this removed the errors\
          \ of dimensions but it led to \"nonsense\" in the output of the model. Now\
          \ I will carefully investigate everything</p>\n"
        raw: '@cchudant  I will carefully sort it out and report back, I also came
          to similar thoughts and began to swap the dimensions of the tensors manually,
          this removed the errors of dimensions but it led to "nonsense" in the output
          of the model. Now I will carefully investigate everything'
        updatedAt: '2023-06-07T13:01:51.631Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - cchudant
        - JunnanLi
    id: 64807fbf9aafd41918a7dde7
    type: comment
  author: dimaischenko
  content: '@cchudant  I will carefully sort it out and report back, I also came to
    similar thoughts and began to swap the dimensions of the tensors manually, this
    removed the errors of dimensions but it led to "nonsense" in the output of the
    model. Now I will carefully investigate everything'
  created_at: 2023-06-07 12:01:51+00:00
  edited: false
  hidden: false
  id: 64807fbf9aafd41918a7dde7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-07T13:51:15.000Z'
    data:
      edited: false
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8562435507774353
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;cchudant&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/cchudant\">@<span class=\"\
          underline\">cchudant</span></a></span>\n\n\t</span></span> Unfortunately,\
          \ I still get \"nonsense\" when generating if I change the dimensions ...\
          \ something is not right.</p>\n"
        raw: '@cchudant Unfortunately, I still get "nonsense" when generating if I
          change the dimensions ... something is not right.'
        updatedAt: '2023-06-07T13:51:15.136Z'
      numEdits: 0
      reactions: []
    id: 64808b539aafd41918a8c9aa
    type: comment
  author: dimaischenko
  content: '@cchudant Unfortunately, I still get "nonsense" when generating if I change
    the dimensions ... something is not right.'
  created_at: 2023-06-07 12:51:15+00:00
  edited: false
  hidden: false
  id: 64808b539aafd41918a8c9aa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-07T13:52:23.000Z'
    data:
      edited: true
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9846159219741821
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: '<p>Do you happen to know which of the developers can ask a question
          directly? I can''t figure out who to mention to help figure it out. Using
          <code>past_key_values</code> in decoding speeds up the generation by 2-3
          times, and it seems that it is very important to make it work</p>

          '
        raw: Do you happen to know which of the developers can ask a question directly?
          I can't figure out who to mention to help figure it out. Using `past_key_values`
          in decoding speeds up the generation by 2-3 times, and it seems that it
          is very important to make it work
        updatedAt: '2023-06-07T14:20:38.552Z'
      numEdits: 1
      reactions: []
    id: 64808b97e1421e205fd88ae6
    type: comment
  author: dimaischenko
  content: Do you happen to know which of the developers can ask a question directly?
    I can't figure out who to mention to help figure it out. Using `past_key_values`
    in decoding speeds up the generation by 2-3 times, and it seems that it is very
    important to make it work
  created_at: 2023-06-07 12:52:23+00:00
  edited: true
  hidden: false
  id: 64808b97e1421e205fd88ae6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-07T16:00:20.000Z'
    data:
      edited: true
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6381455659866333
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;cchudant&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/cchudant\">@<span class=\"\
          underline\">cchudant</span></a></span>\n\n\t</span></span>  I actually tested\
          \ on the code from the <code>falcon-7b</code> model, it looks like the code\
          \ is slightly different between <code>7b</code> and <code>40b</code>. I\
          \ don't have a video card on which I could test <code>40b</code> model,\
          \ if you can test this code on it (with corrections on tensor dimensions)\
          \ would be cool!</p>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\">from</span>\
          \ transformers <span class=\"hljs-keyword\">import</span> AutoModelForCausalLM,\
          \ AutoTokenizer\n<span class=\"hljs-keyword\">import</span> random\n\ndevice\
          \ = torch.device(<span class=\"hljs-string\">\"cuda\"</span>)\nmodel_id\
          \ = <span class=\"hljs-string\">\"tiiuae/falcon-40b\"</span>\n\nmodel =\
          \ AutoModelForCausalLM.from_pretrained(\n    model_id,\n    torch_dtype=torch.bfloat16,\n\
          \    trust_remote_code=<span class=\"hljs-literal\">True</span>,\n    device_map=<span\
          \ class=\"hljs-string\">\"auto\"</span>,\n).to(device)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\
          \ntext = <span class=\"hljs-string\">\"We are in the dark forest and want\
          \ to find some mushrooms. We go to the nearest tree and\"</span>\n\ninputs\
          \ = tokenizer(text, return_tensors=<span class=\"hljs-string\">\"pt\"</span>).to(device)\n\
          input_ids = inputs[<span class=\"hljs-string\">\"input_ids\"</span>]\n\n\
          output = <span class=\"hljs-literal\">None</span>\nstep = <span class=\"\
          hljs-number\">0</span>\n\n<span class=\"hljs-comment\"># generation cycle\
          \ with 20 steps</span>\n<span class=\"hljs-keyword\">while</span> step &lt;\
          \ <span class=\"hljs-number\">20</span>:\n    attention_mask = input_ids.new_ones(input_ids.shape)\n\
          \    past_key_values = <span class=\"hljs-literal\">None</span>\n    \n\
          \    <span class=\"hljs-keyword\">if</span> output <span class=\"hljs-keyword\"\
          >is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\"\
          >None</span>:\n        past_key_values = output[<span class=\"hljs-string\"\
          >\"past_key_values\"</span>]\n\n    ids = model.prepare_inputs_for_generation(input_ids,\n\
          \                                              past=past_key_values,\n \
          \                                             attention_mask=attention_mask,\n\
          \                                              use_cache=<span class=\"\
          hljs-literal\">True</span>)\n                                 \n    output\
          \ = model(**ids)\n    \n    <span class=\"hljs-comment\"># get random of\
          \ 3 most probable tokens and add to input_ids</span>\n    top_k = <span\
          \ class=\"hljs-number\">3</span>\n    next_token = random.choice(torch.topk(output.logits[:,\
          \ -<span class=\"hljs-number\">1</span>, :], top_k, dim=-<span class=\"\
          hljs-number\">1</span>).indices[<span class=\"hljs-number\">0</span>])\n\
          \    \n    input_ids = torch.cat([input_ids, torch.tensor([[next_token]]).to(device)],\
          \ dim=-<span class=\"hljs-number\">1</span>)\n    \n    step += <span class=\"\
          hljs-number\">1</span>\n\n<span class=\"hljs-built_in\">print</span>(tokenizer.decode(input_ids[<span\
          \ class=\"hljs-number\">0</span>]))\n</code></pre>\n"
        raw: "@cchudant  I actually tested on the code from the `falcon-7b` model,\
          \ it looks like the code is slightly different between `7b` and `40b`. I\
          \ don't have a video card on which I could test `40b` model, if you can\
          \ test this code on it (with corrections on tensor dimensions) would be\
          \ cool!\n\n```python\nimport torch\nfrom transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\nimport random\n\ndevice = torch.device(\"cuda\")\nmodel_id\
          \ = \"tiiuae/falcon-40b\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    model_id,\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n\
          \    device_map=\"auto\",\n).to(device)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\
          \ntext = \"We are in the dark forest and want to find some mushrooms. We\
          \ go to the nearest tree and\"\n\ninputs = tokenizer(text, return_tensors=\"\
          pt\").to(device)\ninput_ids = inputs[\"input_ids\"]\n\noutput = None\nstep\
          \ = 0\n\n# generation cycle with 20 steps\nwhile step < 20:\n    attention_mask\
          \ = input_ids.new_ones(input_ids.shape)\n    past_key_values = None\n  \
          \  \n    if output is not None:\n        past_key_values = output[\"past_key_values\"\
          ]\n\n    ids = model.prepare_inputs_for_generation(input_ids,\n        \
          \                                      past=past_key_values,\n         \
          \                                     attention_mask=attention_mask,\n \
          \                                             use_cache=True)\n        \
          \                         \n    output = model(**ids)\n    \n    # get random\
          \ of 3 most probable tokens and add to input_ids\n    top_k = 3\n    next_token\
          \ = random.choice(torch.topk(output.logits[:, -1, :], top_k, dim=-1).indices[0])\n\
          \    \n    input_ids = torch.cat([input_ids, torch.tensor([[next_token]]).to(device)],\
          \ dim=-1)\n    \n    step += 1\n\nprint(tokenizer.decode(input_ids[0]))\n\
          ```"
        updatedAt: '2023-06-07T18:16:05.563Z'
      numEdits: 2
      reactions: []
    id: 6480a994e1421e205fdad733
    type: comment
  author: dimaischenko
  content: "@cchudant  I actually tested on the code from the `falcon-7b` model, it\
    \ looks like the code is slightly different between `7b` and `40b`. I don't have\
    \ a video card on which I could test `40b` model, if you can test this code on\
    \ it (with corrections on tensor dimensions) would be cool!\n\n```python\nimport\
    \ torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport\
    \ random\n\ndevice = torch.device(\"cuda\")\nmodel_id = \"tiiuae/falcon-40b\"\n\
    \nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    torch_dtype=torch.bfloat16,\n\
    \    trust_remote_code=True,\n    device_map=\"auto\",\n).to(device)\n\ntokenizer\
    \ = AutoTokenizer.from_pretrained(model_id)\n\ntext = \"We are in the dark forest\
    \ and want to find some mushrooms. We go to the nearest tree and\"\n\ninputs =\
    \ tokenizer(text, return_tensors=\"pt\").to(device)\ninput_ids = inputs[\"input_ids\"\
    ]\n\noutput = None\nstep = 0\n\n# generation cycle with 20 steps\nwhile step <\
    \ 20:\n    attention_mask = input_ids.new_ones(input_ids.shape)\n    past_key_values\
    \ = None\n    \n    if output is not None:\n        past_key_values = output[\"\
    past_key_values\"]\n\n    ids = model.prepare_inputs_for_generation(input_ids,\n\
    \                                              past=past_key_values,\n       \
    \                                       attention_mask=attention_mask,\n     \
    \                                         use_cache=True)\n                  \
    \               \n    output = model(**ids)\n    \n    # get random of 3 most\
    \ probable tokens and add to input_ids\n    top_k = 3\n    next_token = random.choice(torch.topk(output.logits[:,\
    \ -1, :], top_k, dim=-1).indices[0])\n    \n    input_ids = torch.cat([input_ids,\
    \ torch.tensor([[next_token]]).to(device)], dim=-1)\n    \n    step += 1\n\nprint(tokenizer.decode(input_ids[0]))\n\
    ```"
  created_at: 2023-06-07 15:00:20+00:00
  edited: true
  hidden: false
  id: 6480a994e1421e205fdad733
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671801056760-noauth.png?w=200&h=200&f=face
      fullname: Charles Chudant
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cchudant
      type: user
    createdAt: '2023-06-08T14:33:14.000Z'
    data:
      edited: false
      editors:
      - cchudant
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9844040870666504
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1671801056760-noauth.png?w=200&h=200&f=face
          fullname: Charles Chudant
          isHf: false
          isPro: false
          name: cchudant
          type: user
        html: '<p>Hi, I am sorry - I don''t have the machine anymore :(</p>

          '
        raw: Hi, I am sorry - I don't have the machine anymore :(
        updatedAt: '2023-06-08T14:33:14.601Z'
      numEdits: 0
      reactions: []
    id: 6481e6aa2c566b09a865d1fc
    type: comment
  author: cchudant
  content: Hi, I am sorry - I don't have the machine anymore :(
  created_at: 2023-06-08 13:33:14+00:00
  edited: false
  hidden: false
  id: 6481e6aa2c566b09a865d1fc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-08T15:29:42.000Z'
    data:
      edited: false
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9671214818954468
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: "<p>No problem, we'll try to wait for answers from someone from the\
          \ <span data-props=\"{&quot;user&quot;:&quot;FalconLLM&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/FalconLLM\">@<span class=\"\
          underline\">FalconLLM</span></a></span>\n\n\t</span></span> team. Already\
          \ many people write that they have the same problems and questions with\
          \ both <code>7b</code> ( <a href=\"https://huggingface.co/tiiuae/falcon-7b/discussions/17\"\
          >https://huggingface.co/tiiuae/falcon-7b/discussions/17</a> ) and <code>40b</code>\
          \ models, it seems that this is an important thing</p>\n"
        raw: No problem, we'll try to wait for answers from someone from the @FalconLLM
          team. Already many people write that they have the same problems and questions
          with both `7b` ( https://huggingface.co/tiiuae/falcon-7b/discussions/17
          ) and `40b` models, it seems that this is an important thing
        updatedAt: '2023-06-08T15:29:42.606Z'
      numEdits: 0
      reactions: []
    id: 6481f3e69197c0581e60d0c9
    type: comment
  author: dimaischenko
  content: No problem, we'll try to wait for answers from someone from the @FalconLLM
    team. Already many people write that they have the same problems and questions
    with both `7b` ( https://huggingface.co/tiiuae/falcon-7b/discussions/17 ) and
    `40b` models, it seems that this is an important thing
  created_at: 2023-06-08 14:29:42+00:00
  edited: false
  hidden: false
  id: 6481f3e69197c0581e60d0c9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ab0c8d4e6df5aa84b52e901830222faa.svg
      fullname: Colman Glagovich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ColmanTT
      type: user
    createdAt: '2023-06-08T17:28:15.000Z'
    data:
      edited: false
      editors:
      - ColmanTT
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8796057105064392
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ab0c8d4e6df5aa84b52e901830222faa.svg
          fullname: Colman Glagovich
          isHf: false
          isPro: false
          name: ColmanTT
          type: user
        html: '<p>It doesn''t look right to me that your decode loop concats the new
          token onto the previous input_ids. For KV cache inference, you should only
          pass in the new token</p>

          '
        raw: It doesn't look right to me that your decode loop concats the new token
          onto the previous input_ids. For KV cache inference, you should only pass
          in the new token
        updatedAt: '2023-06-08T17:28:15.770Z'
      numEdits: 0
      reactions: []
    id: 64820faf2316526d603fdd11
    type: comment
  author: ColmanTT
  content: It doesn't look right to me that your decode loop concats the new token
    onto the previous input_ids. For KV cache inference, you should only pass in the
    new token
  created_at: 2023-06-08 16:28:15+00:00
  edited: false
  hidden: false
  id: 64820faf2316526d603fdd11
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-08T17:35:29.000Z'
    data:
      edited: true
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7293975949287415
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ColmanTT&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ColmanTT\">@<span class=\"\
          underline\">ColmanTT</span></a></span>\n\n\t</span></span> The thing is\
          \ that in <code>prepare_inputs_for_generation</code> we get only last token</p>\n\
          <pre><code class=\"language-python\">...\n   input_ids = input_ids[:, -<span\
          \ class=\"hljs-number\">1</span>].unsqueeze(-<span class=\"hljs-number\"\
          >1</span>)\n...\n</code></pre>\n<p>This loop works fine with any other model\
          \ such as <code>gpt2</code>, <code>gptj-6b</code>, <code>bloom</code>, etc.</p>\n"
        raw: "@ColmanTT The thing is that in `prepare_inputs_for_generation` we get\
          \ only last token\n\n```python\n...\n   input_ids = input_ids[:, -1].unsqueeze(-1)\n\
          ...\n```\n\nThis loop works fine with any other model such as `gpt2`, `gptj-6b`,\
          \ `bloom`, etc."
        updatedAt: '2023-06-08T17:35:40.295Z'
      numEdits: 1
      reactions: []
    id: 64821161e119bbe7cdf17124
    type: comment
  author: dimaischenko
  content: "@ColmanTT The thing is that in `prepare_inputs_for_generation` we get\
    \ only last token\n\n```python\n...\n   input_ids = input_ids[:, -1].unsqueeze(-1)\n\
    ...\n```\n\nThis loop works fine with any other model such as `gpt2`, `gptj-6b`,\
    \ `bloom`, etc."
  created_at: 2023-06-08 16:35:29+00:00
  edited: true
  hidden: false
  id: 64821161e119bbe7cdf17124
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ab0c8d4e6df5aa84b52e901830222faa.svg
      fullname: Colman Glagovich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ColmanTT
      type: user
    createdAt: '2023-06-08T18:24:45.000Z'
    data:
      edited: false
      editors:
      - ColmanTT
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8632736802101135
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ab0c8d4e6df5aa84b52e901830222faa.svg
          fullname: Colman Glagovich
          isHf: false
          isPro: false
          name: ColmanTT
          type: user
        html: '<p>Appears that we''re victims of this issue <a rel="nofollow" href="https://stackoverflow.com/questions/76177216/how-is-scaled-dot-product-attention-meant-to-be-used-with-cached-keys-values-in">https://stackoverflow.com/questions/76177216/how-is-scaled-dot-product-attention-meant-to-be-used-with-cached-keys-values-in</a></p>

          '
        raw: Appears that we're victims of this issue https://stackoverflow.com/questions/76177216/how-is-scaled-dot-product-attention-meant-to-be-used-with-cached-keys-values-in
        updatedAt: '2023-06-08T18:24:45.237Z'
      numEdits: 0
      reactions: []
    id: 64821ced020eb31f3df025a9
    type: comment
  author: ColmanTT
  content: Appears that we're victims of this issue https://stackoverflow.com/questions/76177216/how-is-scaled-dot-product-attention-meant-to-be-used-with-cached-keys-values-in
  created_at: 2023-06-08 17:24:45+00:00
  edited: false
  hidden: false
  id: 64821ced020eb31f3df025a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ab0c8d4e6df5aa84b52e901830222faa.svg
      fullname: Colman Glagovich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ColmanTT
      type: user
    createdAt: '2023-06-08T19:04:16.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/ab0c8d4e6df5aa84b52e901830222faa.svg
          fullname: Colman Glagovich
          isHf: false
          isPro: false
          name: ColmanTT
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-06-08T19:42:34.366Z'
      numEdits: 0
      reactions: []
    id: 6482263007afdf92106b7430
    type: comment
  author: ColmanTT
  content: This comment has been hidden
  created_at: 2023-06-08 18:04:16+00:00
  edited: true
  hidden: true
  id: 6482263007afdf92106b7430
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-08T19:08:47.000Z'
    data:
      edited: false
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9166190028190613
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ColmanTT&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ColmanTT\">@<span class=\"\
          underline\">ColmanTT</span></a></span>\n\n\t</span></span> Wow! I will test\
          \ tomorrow and will be sure to report on the results!</p>\n"
        raw: '@ColmanTT Wow! I will test tomorrow and will be sure to report on the
          results!'
        updatedAt: '2023-06-08T19:08:47.599Z'
      numEdits: 0
      reactions: []
    id: 6482273f612d45aebf837e8b
    type: comment
  author: dimaischenko
  content: '@ColmanTT Wow! I will test tomorrow and will be sure to report on the
    results!'
  created_at: 2023-06-08 18:08:47+00:00
  edited: false
  hidden: false
  id: 6482273f612d45aebf837e8b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ab0c8d4e6df5aa84b52e901830222faa.svg
      fullname: Colman Glagovich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ColmanTT
      type: user
    createdAt: '2023-06-08T19:44:03.000Z'
    data:
      edited: false
      editors:
      - ColmanTT
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9808455109596252
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ab0c8d4e6df5aa84b52e901830222faa.svg
          fullname: Colman Glagovich
          isHf: false
          isPro: false
          name: ColmanTT
          type: user
        html: '<p>Apologies for hiding this, I realize I haven''t tested well enough.
          Let me know how yours goes as well</p>

          '
        raw: Apologies for hiding this, I realize I haven't tested well enough. Let
          me know how yours goes as well
        updatedAt: '2023-06-08T19:44:03.468Z'
      numEdits: 0
      reactions: []
    id: 64822f83612d45aebf862d92
    type: comment
  author: ColmanTT
  content: Apologies for hiding this, I realize I haven't tested well enough. Let
    me know how yours goes as well
  created_at: 2023-06-08 18:44:03+00:00
  edited: false
  hidden: false
  id: 64822f83612d45aebf862d92
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69bc0fb048ac9335a9475077006c3229.svg
      fullname: JiaqiChen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: siemon1996
      type: user
    createdAt: '2023-06-12T03:29:41.000Z'
    data:
      edited: false
      editors:
      - siemon1996
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5508891940116882
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69bc0fb048ac9335a9475077006c3229.svg
          fullname: JiaqiChen
          isHf: false
          isPro: false
          name: siemon1996
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;dimaischenko&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/dimaischenko\"\
          >@<span class=\"underline\">dimaischenko</span></a></span>\n\n\t</span></span>\
          \ I think I solved this problem by passing 'is_causal' of 'F.scaled_dot_product_attention'\
          \ different value due to 'layer_past'.</p>\n<pre><code>if layer_past is\
          \ not None:\n    attn_output = F.scaled_dot_product_attention(\n       \
          \ query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=False\n \
          \   )\nelse:\n    attn_output = F.scaled_dot_product_attention(\n      \
          \  query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n \
          \   )\n</code></pre>\n<p>The generated text turned out to be just fine.</p>\n"
        raw: "@dimaischenko I think I solved this problem by passing 'is_causal' of\
          \ 'F.scaled_dot_product_attention' different value due to 'layer_past'.\n\
          ```\nif layer_past is not None:\n    attn_output = F.scaled_dot_product_attention(\n\
          \        query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=False\n\
          \    )\nelse:\n    attn_output = F.scaled_dot_product_attention(\n     \
          \   query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n\
          \    )\n```\nThe generated text turned out to be just fine."
        updatedAt: '2023-06-12T03:29:41.362Z'
      numEdits: 0
      reactions: []
    id: 648691258b7847abd9891a3e
    type: comment
  author: siemon1996
  content: "@dimaischenko I think I solved this problem by passing 'is_causal' of\
    \ 'F.scaled_dot_product_attention' different value due to 'layer_past'.\n```\n\
    if layer_past is not None:\n    attn_output = F.scaled_dot_product_attention(\n\
    \        query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=False\n\
    \    )\nelse:\n    attn_output = F.scaled_dot_product_attention(\n        query_layer_,\
    \ key_layer_, value_layer_, None, 0.0, is_causal=True\n    )\n```\nThe generated\
    \ text turned out to be just fine."
  created_at: 2023-06-12 02:29:41+00:00
  edited: false
  hidden: false
  id: 648691258b7847abd9891a3e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-12T04:46:21.000Z'
    data:
      edited: false
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9863904714584351
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;siemon1996&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/siemon1996\">@<span class=\"\
          underline\">siemon1996</span></a></span>\n\n\t</span></span> I tested it,\
          \ feeling that it has become much better, but it seems that there is still\
          \ a lot of \"nonsense\" \U0001F914 It feels like it's not the <code>7b</code>\
          \ model, but the very first small <code>gpt2</code>. I will be testing more,\
          \ thank you for sharing!</p>\n"
        raw: "@siemon1996 I tested it, feeling that it has become much better, but\
          \ it seems that there is still a lot of \"nonsense\" \U0001F914 It feels\
          \ like it's not the `7b` model, but the very first small `gpt2`. I will\
          \ be testing more, thank you for sharing!"
        updatedAt: '2023-06-12T04:46:21.469Z'
      numEdits: 0
      reactions: []
    id: 6486a31d3e34473abffecc14
    type: comment
  author: dimaischenko
  content: "@siemon1996 I tested it, feeling that it has become much better, but it\
    \ seems that there is still a lot of \"nonsense\" \U0001F914 It feels like it's\
    \ not the `7b` model, but the very first small `gpt2`. I will be testing more,\
    \ thank you for sharing!"
  created_at: 2023-06-12 03:46:21+00:00
  edited: false
  hidden: false
  id: 6486a31d3e34473abffecc14
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/954a3de26b472369666ad1429d7e80a6.svg
      fullname: Tron Gan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tron2060
      type: user
    createdAt: '2023-06-13T09:46:55.000Z'
    data:
      edited: false
      editors:
      - Tron2060
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9543516039848328
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/954a3de26b472369666ad1429d7e80a6.svg
          fullname: Tron Gan
          isHf: false
          isPro: false
          name: Tron2060
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;siemon1996&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/siemon1996\">@<span class=\"\
          underline\">siemon1996</span></a></span>\n\n\t</span></span>  I think you\
          \ did not really solved it.  This problem maybe caused by a bug in scaled_dot_product_attention:\
          \ <a rel=\"nofollow\" href=\"https://github.com/pytorch/pytorch/issues/103082\"\
          >https://github.com/pytorch/pytorch/issues/103082</a></p>\n"
        raw: '@siemon1996  I think you did not really solved it.  This problem maybe
          caused by a bug in scaled_dot_product_attention: https://github.com/pytorch/pytorch/issues/103082'
        updatedAt: '2023-06-13T09:46:55.495Z'
      numEdits: 0
      reactions: []
    id: 64883b0fd58a02823e3de0fe
    type: comment
  author: Tron2060
  content: '@siemon1996  I think you did not really solved it.  This problem maybe
    caused by a bug in scaled_dot_product_attention: https://github.com/pytorch/pytorch/issues/103082'
  created_at: 2023-06-13 08:46:55+00:00
  edited: false
  hidden: false
  id: 64883b0fd58a02823e3de0fe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/954a3de26b472369666ad1429d7e80a6.svg
      fullname: Tron Gan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tron2060
      type: user
    createdAt: '2023-06-13T10:22:03.000Z'
    data:
      edited: false
      editors:
      - Tron2060
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3877373933792114
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/954a3de26b472369666ad1429d7e80a6.svg
          fullname: Tron Gan
          isHf: false
          isPro: false
          name: Tron2060
          type: user
        html: "<p>I change like this</p>\n<pre><code>  if layer_past is not None:\n\
          \               L = query_layer_.shape[-2]\n               S = key_layer_.shape[-2]\n\
          \               attn_mask = torch.ones(L, S, dtype=torch.bool, device=query_layer_.device)\n\
          \               attn_output = F.scaled_dot_product_attention(\n        \
          \           query_layer_, key_layer_, value_layer_, attn_mask, 0.0, is_causal=False\n\
          \               )\n           else:\n               attn_output = F.scaled_dot_product_attention(\n\
          \                   query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n\
          \               )\n</code></pre>\n"
        raw: "I change like this\n ```\n   if layer_past is not None:\n          \
          \      L = query_layer_.shape[-2]\n                S = key_layer_.shape[-2]\n\
          \                attn_mask = torch.ones(L, S, dtype=torch.bool, device=query_layer_.device)\n\
          \                attn_output = F.scaled_dot_product_attention(\n       \
          \             query_layer_, key_layer_, value_layer_, attn_mask, 0.0, is_causal=False\n\
          \                )\n            else:\n                attn_output = F.scaled_dot_product_attention(\n\
          \                    query_layer_, key_layer_, value_layer_, None, 0.0,\
          \ is_causal=True\n                )\n ```"
        updatedAt: '2023-06-13T10:22:03.347Z'
      numEdits: 0
      reactions: []
    id: 6488434b7fe834f5890b69f8
    type: comment
  author: Tron2060
  content: "I change like this\n ```\n   if layer_past is not None:\n            \
    \    L = query_layer_.shape[-2]\n                S = key_layer_.shape[-2]\n  \
    \              attn_mask = torch.ones(L, S, dtype=torch.bool, device=query_layer_.device)\n\
    \                attn_output = F.scaled_dot_product_attention(\n             \
    \       query_layer_, key_layer_, value_layer_, attn_mask, 0.0, is_causal=False\n\
    \                )\n            else:\n                attn_output = F.scaled_dot_product_attention(\n\
    \                    query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n\
    \                )\n ```"
  created_at: 2023-06-13 09:22:03+00:00
  edited: false
  hidden: false
  id: 6488434b7fe834f5890b69f8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69bc0fb048ac9335a9475077006c3229.svg
      fullname: JiaqiChen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: siemon1996
      type: user
    createdAt: '2023-06-14T09:13:32.000Z'
    data:
      edited: true
      editors:
      - siemon1996
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9686276912689209
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69bc0fb048ac9335a9475077006c3229.svg
          fullname: JiaqiChen
          isHf: false
          isPro: false
          name: siemon1996
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;siemon1996&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/siemon1996\"\
          >@<span class=\"underline\">siemon1996</span></a></span>\n\n\t</span></span>\
          \ I tested it, feeling that it has become much better, but it seems that\
          \ there is still a lot of \"nonsense\" \U0001F914 It feels like it's not\
          \ the <code>7b</code> model, but the very first small <code>gpt2</code>.\
          \ I will be testing more, thank you for sharing!</p>\n</blockquote>\n<p>It\
          \ occurs to me that the first several output tokens are correct, compared\
          \ with run falcon-40b without using past_key_values. Then the 'nonsense'\
          \ begins,  I`ll try to figure out the reason,  just letting you know.</p>\n"
        raw: "> @siemon1996 I tested it, feeling that it has become much better, but\
          \ it seems that there is still a lot of \"nonsense\" \U0001F914 It feels\
          \ like it's not the `7b` model, but the very first small `gpt2`. I will\
          \ be testing more, thank you for sharing!\n\nIt occurs to me that the first\
          \ several output tokens are correct, compared with run falcon-40b without\
          \ using past_key_values. Then the 'nonsense' begins,  I`ll try to figure\
          \ out the reason,  just letting you know.\n"
        updatedAt: '2023-06-14T09:14:10.984Z'
      numEdits: 1
      reactions: []
    id: 648984bc639f0780c6a7893a
    type: comment
  author: siemon1996
  content: "> @siemon1996 I tested it, feeling that it has become much better, but\
    \ it seems that there is still a lot of \"nonsense\" \U0001F914 It feels like\
    \ it's not the `7b` model, but the very first small `gpt2`. I will be testing\
    \ more, thank you for sharing!\n\nIt occurs to me that the first several output\
    \ tokens are correct, compared with run falcon-40b without using past_key_values.\
    \ Then the 'nonsense' begins,  I`ll try to figure out the reason,  just letting\
    \ you know.\n"
  created_at: 2023-06-14 08:13:32+00:00
  edited: true
  hidden: false
  id: 648984bc639f0780c6a7893a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a92d4b8efee98ad2242c806453ef6810.svg
      fullname: "Dani\xEBl de Kok"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: danieldk-explosion
      type: user
    createdAt: '2023-06-16T15:41:02.000Z'
    data:
      edited: true
      editors:
      - danieldk-explosion
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8541473746299744
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a92d4b8efee98ad2242c806453ef6810.svg
          fullname: "Dani\xEBl de Kok"
          isHf: false
          isPro: false
          name: danieldk-explosion
          type: user
        html: '<p>There is another issue besides the incorrect causal mask. The rotary
          embeddings are not position-indexed. Suppose that you are generating the
          next piece, then the new (non-cache) query/value representations of the
          last generated piece have shape <code>[batch_size, n_heads, 1, head_dim</code>].
          The rotary embeddings are applied like this:</p>

          <p><a href="https://huggingface.co/tiiuae/falcon-7b/blob/2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5/modelling_RW.py#L257">https://huggingface.co/tiiuae/falcon-7b/blob/2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5/modelling_RW.py#L257</a></p>

          <p>However, that means that the query/key representations for this new piece
          get the rotary embedding applied for position 0, whereas it needs the rotary
          embedding for position n+1 (where n is the number of preceding pieces, which
          may be different per batch item in case that there are padding pieces).
          Here is a correct use of rotary embeddings in this model when a cache is
          used:</p>

          <p><a rel="nofollow" href="https://github.com/explosion/curated-transformers/blob/b44a0fa24c64844909656a0fa9eb4d5acc6af142/curated_transformers/models/attention.py#L315">https://github.com/explosion/curated-transformers/blob/b44a0fa24c64844909656a0fa9eb4d5acc6af142/curated_transformers/models/attention.py#L315</a></p>

          <p>Example of text generated with the 7b instruction tuned model, with correct
          causal masks, correct indexing, caching, and deterministic decoding:</p>

          <p>Prompt: <em>What is the Rust programming language?</em></p>

          <p> Answer: <em>Rust is a programming language that is designed to be a
          safe, concurrent, and efficient replacement for C++. It is a statically-typed
          language that is designed to be memory-safe and thread-safe, making it a
          good choice for developing high-performance applications.</em></p>

          '
        raw: "There is another issue besides the incorrect causal mask. The rotary\
          \ embeddings are not position-indexed. Suppose that you are generating the\
          \ next piece, then the new (non-cache) query/value representations of the\
          \ last generated piece have shape `[batch_size, n_heads, 1, head_dim`].\
          \ The rotary embeddings are applied like this:\n\nhttps://huggingface.co/tiiuae/falcon-7b/blob/2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5/modelling_RW.py#L257\n\
          \nHowever, that means that the query/key representations for this new piece\
          \ get the rotary embedding applied for position 0, whereas it needs the\
          \ rotary embedding for position n+1 (where n is the number of preceding\
          \ pieces, which may be different per batch item in case that there are padding\
          \ pieces). Here is a correct use of rotary embeddings in this model when\
          \ a cache is used:\n\nhttps://github.com/explosion/curated-transformers/blob/b44a0fa24c64844909656a0fa9eb4d5acc6af142/curated_transformers/models/attention.py#L315\n\
          \nExample of text generated with the 7b instruction tuned model, with correct\
          \ causal masks, correct indexing, caching, and deterministic decoding:\n\
          \nPrompt: _What is the Rust programming language?_\n\n Answer: _Rust is\
          \ a programming language that is designed to be a safe, concurrent, and\
          \ efficient replacement for C++. It is a statically-typed language that\
          \ is designed to be memory-safe and thread-safe, making it a good choice\
          \ for developing high-performance applications._"
        updatedAt: '2023-06-16T15:47:28.460Z'
      numEdits: 2
      reactions: []
    id: 648c828eb8f4a3542b7abd4a
    type: comment
  author: danieldk-explosion
  content: "There is another issue besides the incorrect causal mask. The rotary embeddings\
    \ are not position-indexed. Suppose that you are generating the next piece, then\
    \ the new (non-cache) query/value representations of the last generated piece\
    \ have shape `[batch_size, n_heads, 1, head_dim`]. The rotary embeddings are applied\
    \ like this:\n\nhttps://huggingface.co/tiiuae/falcon-7b/blob/2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5/modelling_RW.py#L257\n\
    \nHowever, that means that the query/key representations for this new piece get\
    \ the rotary embedding applied for position 0, whereas it needs the rotary embedding\
    \ for position n+1 (where n is the number of preceding pieces, which may be different\
    \ per batch item in case that there are padding pieces). Here is a correct use\
    \ of rotary embeddings in this model when a cache is used:\n\nhttps://github.com/explosion/curated-transformers/blob/b44a0fa24c64844909656a0fa9eb4d5acc6af142/curated_transformers/models/attention.py#L315\n\
    \nExample of text generated with the 7b instruction tuned model, with correct\
    \ causal masks, correct indexing, caching, and deterministic decoding:\n\nPrompt:\
    \ _What is the Rust programming language?_\n\n Answer: _Rust is a programming\
    \ language that is designed to be a safe, concurrent, and efficient replacement\
    \ for C++. It is a statically-typed language that is designed to be memory-safe\
    \ and thread-safe, making it a good choice for developing high-performance applications._"
  created_at: 2023-06-16 14:41:02+00:00
  edited: true
  hidden: false
  id: 648c828eb8f4a3542b7abd4a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9013215e0c5966eb7054f1b5f4a7181f.svg
      fullname: Sekhar V
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sekharvth
      type: user
    createdAt: '2023-06-21T08:43:09.000Z'
    data:
      edited: true
      editors:
      - sekharvth
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8614655137062073
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9013215e0c5966eb7054f1b5f4a7181f.svg
          fullname: Sekhar V
          isHf: false
          isPro: false
          name: sekharvth
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;siemon1996&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/siemon1996\">@<span class=\"\
          underline\">siemon1996</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;Tron2060&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/Tron2060\">@<span class=\"underline\">Tron2060</span></a></span>\n\
          \n\t</span></span> <span data-props=\"{&quot;user&quot;:&quot;dimaischenko&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/dimaischenko\"\
          >@<span class=\"underline\">dimaischenko</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;danieldk-explosion&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/danieldk-explosion\"\
          >@<span class=\"underline\">danieldk-explosion</span></a></span>\n\n\t</span></span>\
          \ </p>\n<p>I managed to compile a quick script incorporating all the changes\
          \ mentioned on this thread - use of the correct <code>past_key_values</code>\
          \ variable instead of <code>past</code>, adding the correct parameters in\
          \ the <code>scaled_dot_product_attention</code> call,  addition of the right\
          \ implementation of rotary embeddings from curated-transformers, and minor\
          \ fixes for contrastive search. You can find the gist <a rel=\"nofollow\"\
          \ href=\"https://gist.github.com/sekharvth/200719858f13e6cf6f64946ef3c20a5c\"\
          >here</a>. I've only tested for base 10000 and fraction 1 as the rotary\
          \ embeddings params, please feel free to experiment with different values.\
          \ Additionally, as the modifications were done rather hastily, kindly overlook\
          \ any hard-coded/non-parametrised values that I might have added.</p>\n\
          <p>This seems to be generating expected results, and the speed of generation\
          \ is much higher with the adoption of <code>past_key_values</code>. As a\
          \ result, the speed is not overly dependent on the value of <code>max_new_tokens</code>\
          \ now, as was the case with the default model. I've done these experiments\
          \ on the 7b variant</p>\n<p>Hope this helps.</p>\n"
        raw: "@siemon1996 @Tron2060 @dimaischenko @danieldk-explosion \n\nI managed\
          \ to compile a quick script incorporating all the changes mentioned on this\
          \ thread - use of the correct `past_key_values` variable instead of `past`,\
          \ adding the correct parameters in the `scaled_dot_product_attention` call,\
          \  addition of the right implementation of rotary embeddings from curated-transformers,\
          \ and minor fixes for contrastive search. You can find the gist [here](https://gist.github.com/sekharvth/200719858f13e6cf6f64946ef3c20a5c).\
          \ I've only tested for base 10000 and fraction 1 as the rotary embeddings\
          \ params, please feel free to experiment with different values. Additionally,\
          \ as the modifications were done rather hastily, kindly overlook any hard-coded/non-parametrised\
          \ values that I might have added.\n\nThis seems to be generating expected\
          \ results, and the speed of generation is much higher with the adoption\
          \ of `past_key_values`. As a result, the speed is not overly dependent on\
          \ the value of `max_new_tokens` now, as was the case with the default model.\
          \ I've done these experiments on the 7b variant\n\nHope this helps."
        updatedAt: '2023-06-21T08:44:01.472Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - kitaharatomoyo
    id: 6492b81d7a15b9aa1a1cd990
    type: comment
  author: sekharvth
  content: "@siemon1996 @Tron2060 @dimaischenko @danieldk-explosion \n\nI managed\
    \ to compile a quick script incorporating all the changes mentioned on this thread\
    \ - use of the correct `past_key_values` variable instead of `past`, adding the\
    \ correct parameters in the `scaled_dot_product_attention` call,  addition of\
    \ the right implementation of rotary embeddings from curated-transformers, and\
    \ minor fixes for contrastive search. You can find the gist [here](https://gist.github.com/sekharvth/200719858f13e6cf6f64946ef3c20a5c).\
    \ I've only tested for base 10000 and fraction 1 as the rotary embeddings params,\
    \ please feel free to experiment with different values. Additionally, as the modifications\
    \ were done rather hastily, kindly overlook any hard-coded/non-parametrised values\
    \ that I might have added.\n\nThis seems to be generating expected results, and\
    \ the speed of generation is much higher with the adoption of `past_key_values`.\
    \ As a result, the speed is not overly dependent on the value of `max_new_tokens`\
    \ now, as was the case with the default model. I've done these experiments on\
    \ the 7b variant\n\nHope this helps."
  created_at: 2023-06-21 07:43:09+00:00
  edited: true
  hidden: false
  id: 6492b81d7a15b9aa1a1cd990
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-21T11:25:42.000Z'
    data:
      edited: false
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.38863691687583923
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sekharvth&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sekharvth\">@<span class=\"\
          underline\">sekharvth</span></a></span>\n\n\t</span></span> Trying your\
          \ <code>modelling_RW.py</code> I get an error with types</p>\n<pre><code>--&gt;\
          \ 509    attn_output = F.scaled_dot_product_attention(\n    510        query_layer_,\
          \ key_layer_, value_layer_, None, 0.0, is_causal=True\n    511    )\n  \
          \  512 #attn_output = F.scaled_dot_product_attention(\n    513 #    query_layer_,\
          \ key_layer_, value_layer_, None, 0.0, is_causal=True\n    514 #)\n    516\
          \ x = attn_output.view(batch_size, self.num_heads, q_length, self.head_dim)\n\
          \nRuntimeError: Expected query, key, and value to have the same dtype, but\
          \ got query.dtype: float key.dtype: float and value.dtype: c10::BFloat16\
          \ instead.\n</code></pre>\n"
        raw: "@sekharvth Trying your `modelling_RW.py` I get an error with types\n\
          \n```\n--> 509    attn_output = F.scaled_dot_product_attention(\n    510\
          \        query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n\
          \    511    )\n    512 #attn_output = F.scaled_dot_product_attention(\n\
          \    513 #    query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n\
          \    514 #)\n    516 x = attn_output.view(batch_size, self.num_heads, q_length,\
          \ self.head_dim)\n\nRuntimeError: Expected query, key, and value to have\
          \ the same dtype, but got query.dtype: float key.dtype: float and value.dtype:\
          \ c10::BFloat16 instead.\n```"
        updatedAt: '2023-06-21T11:25:42.041Z'
      numEdits: 0
      reactions: []
    id: 6492de36c012108a082c02df
    type: comment
  author: dimaischenko
  content: "@sekharvth Trying your `modelling_RW.py` I get an error with types\n\n\
    ```\n--> 509    attn_output = F.scaled_dot_product_attention(\n    510       \
    \ query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n    511 \
    \   )\n    512 #attn_output = F.scaled_dot_product_attention(\n    513 #    query_layer_,\
    \ key_layer_, value_layer_, None, 0.0, is_causal=True\n    514 #)\n    516 x =\
    \ attn_output.view(batch_size, self.num_heads, q_length, self.head_dim)\n\nRuntimeError:\
    \ Expected query, key, and value to have the same dtype, but got query.dtype:\
    \ float key.dtype: float and value.dtype: c10::BFloat16 instead.\n```"
  created_at: 2023-06-21 10:25:42+00:00
  edited: false
  hidden: false
  id: 6492de36c012108a082c02df
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9013215e0c5966eb7054f1b5f4a7181f.svg
      fullname: Sekhar V
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sekharvth
      type: user
    createdAt: '2023-06-21T18:01:30.000Z'
    data:
      edited: true
      editors:
      - sekharvth
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5134500861167908
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9013215e0c5966eb7054f1b5f4a7181f.svg
          fullname: Sekhar V
          isHf: false
          isPro: false
          name: sekharvth
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;sekharvth&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sekharvth\"\
          >@<span class=\"underline\">sekharvth</span></a></span>\n\n\t</span></span>\
          \ Trying your <code>modelling_RW.py</code> I get an error with types</p>\n\
          <pre><code>--&gt; 509    attn_output = F.scaled_dot_product_attention(\n\
          \    510        query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n\
          \    511    )\n    512 #attn_output = F.scaled_dot_product_attention(\n\
          \    513 #    query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n\
          \    514 #)\n    516 x = attn_output.view(batch_size, self.num_heads, q_length,\
          \ self.head_dim)\n\nRuntimeError: Expected query, key, and value to have\
          \ the same dtype, but got query.dtype: float key.dtype: float and value.dtype:\
          \ c10::BFloat16 instead.\n</code></pre>\n</blockquote>\n<p>Ahh apologies,\
          \ forgot to mention that this doesn't work on fp16. When you're loading\
          \ the model, ensure that you're <em>not</em> using <code>torch_dtype=torch.float16</code>\
          \ or <code>torch_dtype=torch.bfloat16</code></p>\n"
        raw: "> @sekharvth Trying your `modelling_RW.py` I get an error with types\n\
          > \n> ```\n> --> 509    attn_output = F.scaled_dot_product_attention(\n\
          >     510        query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n\
          >     511    )\n>     512 #attn_output = F.scaled_dot_product_attention(\n\
          >     513 #    query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n\
          >     514 #)\n>     516 x = attn_output.view(batch_size, self.num_heads,\
          \ q_length, self.head_dim)\n> \n> RuntimeError: Expected query, key, and\
          \ value to have the same dtype, but got query.dtype: float key.dtype: float\
          \ and value.dtype: c10::BFloat16 instead.\n> ```\n\nAhh apologies, forgot\
          \ to mention that this doesn't work on fp16. When you're loading the model,\
          \ ensure that you're *not* using `torch_dtype=torch.float16` or `torch_dtype=torch.bfloat16`\n\
          \n"
        updatedAt: '2023-06-21T18:03:34.094Z'
      numEdits: 1
      reactions: []
    id: 64933afa981675816dd0fb50
    type: comment
  author: sekharvth
  content: "> @sekharvth Trying your `modelling_RW.py` I get an error with types\n\
    > \n> ```\n> --> 509    attn_output = F.scaled_dot_product_attention(\n>     510\
    \        query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n>\
    \     511    )\n>     512 #attn_output = F.scaled_dot_product_attention(\n>  \
    \   513 #    query_layer_, key_layer_, value_layer_, None, 0.0, is_causal=True\n\
    >     514 #)\n>     516 x = attn_output.view(batch_size, self.num_heads, q_length,\
    \ self.head_dim)\n> \n> RuntimeError: Expected query, key, and value to have the\
    \ same dtype, but got query.dtype: float key.dtype: float and value.dtype: c10::BFloat16\
    \ instead.\n> ```\n\nAhh apologies, forgot to mention that this doesn't work on\
    \ fp16. When you're loading the model, ensure that you're *not* using `torch_dtype=torch.float16`\
    \ or `torch_dtype=torch.bfloat16`\n\n"
  created_at: 2023-06-21 17:01:30+00:00
  edited: true
  hidden: false
  id: 64933afa981675816dd0fb50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
      fullname: Dmytro Ishchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dimaischenko
      type: user
    createdAt: '2023-06-25T13:06:47.000Z'
    data:
      edited: false
      editors:
      - dimaischenko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8987502455711365
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6304c78e9aef62c4013e91ae/DccjU9447vyJFHvc_5IHw.jpeg?w=200&h=200&f=face
          fullname: Dmytro Ishchenko
          isHf: false
          isPro: false
          name: dimaischenko
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sekharvth&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sekharvth\">@<span class=\"\
          underline\">sekharvth</span></a></span>\n\n\t</span></span> is this some\
          \ kind of fundamental limitation on fp16? Or do I just need to do something\
          \ else to make it work?</p>\n"
        raw: '@sekharvth is this some kind of fundamental limitation on fp16? Or do
          I just need to do something else to make it work?'
        updatedAt: '2023-06-25T13:06:47.970Z'
      numEdits: 0
      reactions: []
    id: 64983be7bdbb3c3333ed0b35
    type: comment
  author: dimaischenko
  content: '@sekharvth is this some kind of fundamental limitation on fp16? Or do
    I just need to do something else to make it work?'
  created_at: 2023-06-25 12:06:47+00:00
  edited: false
  hidden: false
  id: 64983be7bdbb3c3333ed0b35
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9013215e0c5966eb7054f1b5f4a7181f.svg
      fullname: Sekhar V
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sekharvth
      type: user
    createdAt: '2023-07-03T04:31:17.000Z'
    data:
      edited: false
      editors:
      - sekharvth
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.948174238204956
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9013215e0c5966eb7054f1b5f4a7181f.svg
          fullname: Sekhar V
          isHf: false
          isPro: false
          name: sekharvth
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;dimaischenko&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/dimaischenko\"\
          >@<span class=\"underline\">dimaischenko</span></a></span>\n\n\t</span></span>\
          \ From what I remember, the precision errors were raised from the rotary\
          \ embeddings implementation, specifically the sine-cosine transformation\
          \ parts. The transformations didn't support half precision then, and I didn't\
          \ experiment with it further to get it to work for fp16, as my immediate\
          \ goal was to get the whole thing working any way it could. </p>\n<p>You\
          \ may try out some data transformations internally in the script and check\
          \ if it works for fp16.</p>\n"
        raw: "@dimaischenko From what I remember, the precision errors were raised\
          \ from the rotary embeddings implementation, specifically the sine-cosine\
          \ transformation parts. The transformations didn't support half precision\
          \ then, and I didn't experiment with it further to get it to work for fp16,\
          \ as my immediate goal was to get the whole thing working any way it could.\
          \ \n\nYou may try out some data transformations internally in the script\
          \ and check if it works for fp16."
        updatedAt: '2023-07-03T04:31:17.528Z'
      numEdits: 0
      reactions: []
    id: 64a24f15b5b55f4657d50678
    type: comment
  author: sekharvth
  content: "@dimaischenko From what I remember, the precision errors were raised from\
    \ the rotary embeddings implementation, specifically the sine-cosine transformation\
    \ parts. The transformations didn't support half precision then, and I didn't\
    \ experiment with it further to get it to work for fp16, as my immediate goal\
    \ was to get the whole thing working any way it could. \n\nYou may try out some\
    \ data transformations internally in the script and check if it works for fp16."
  created_at: 2023-07-03 03:31:17+00:00
  edited: false
  hidden: false
  id: 64a24f15b5b55f4657d50678
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 48
repo_id: tiiuae/falcon-40b
repo_type: model
status: open
target_branch: null
title: Error with custom inference loop with past_key_values
