!!python/object:huggingface_hub.community.DiscussionWithDetails
author: supercharge19
conflicting_files: null
created_at: 2023-05-29 05:01:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bbfe7f8c8e7ce8b50e48a4a2164a3c2e.svg
      fullname: Jawad Mansoor
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: supercharge19
      type: user
    createdAt: '2023-05-29T06:01:55.000Z'
    data:
      edited: false
      editors:
      - supercharge19
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bbfe7f8c8e7ce8b50e48a4a2164a3c2e.svg
          fullname: Jawad Mansoor
          isHf: false
          isPro: false
          name: supercharge19
          type: user
        html: '<p>Quantizing the large (40 or even 7b) model on 4bit will help community
          a lot. And please fine tune it with large code database and on Wizard-Vicuna,
          Mega and other big chat databases as well so it can produce code during
          chat even.</p>

          '
        raw: Quantizing the large (40 or even 7b) model on 4bit will help community
          a lot. And please fine tune it with large code database and on Wizard-Vicuna,
          Mega and other big chat databases as well so it can produce code during
          chat even.
        updatedAt: '2023-05-29T06:01:55.872Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - MakerMatt
        - hastursan
        - shibanovp
        - startlightquyet
        - Ichsan2895
        - markoarnauto
    id: 64743fd322b4dec452463024
    type: comment
  author: supercharge19
  content: Quantizing the large (40 or even 7b) model on 4bit will help community
    a lot. And please fine tune it with large code database and on Wizard-Vicuna,
    Mega and other big chat databases as well so it can produce code during chat even.
  created_at: 2023-05-29 05:01:55+00:00
  edited: false
  hidden: false
  id: 64743fd322b4dec452463024
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
      fullname: Muhammad Ichsan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ichsan2895
      type: user
    createdAt: '2023-06-05T14:32:27.000Z'
    data:
      edited: true
      editors:
      - Ichsan2895
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7919806838035583
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
          fullname: Muhammad Ichsan
          isHf: false
          isPro: false
          name: Ichsan2895
          type: user
        html: '<p>I successfully quantizing it with Qlora with using bitsandbytes
          package.</p>

          <p>Activated it with  bitsandbytes config which select "nf4" Quant type
          + load_in_4bit + bfloat16. It allows to run on single A100 40 GB VRAM. The
          quantized version is run on the fly in jupyter lab without manually exported/saved
          it the new model.</p>

          '
        raw: 'I successfully quantizing it with Qlora with using bitsandbytes package.


          Activated it with  bitsandbytes config which select "nf4" Quant type + load_in_4bit
          + bfloat16. It allows to run on single A100 40 GB VRAM. The quantized version
          is run on the fly in jupyter lab without manually exported/saved it the
          new model.'
        updatedAt: '2023-06-05T14:33:52.896Z'
      numEdits: 1
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - supercharge19
        - jimsrc
        - max-fry
    id: 647df1fb10b7a3b15705e90f
    type: comment
  author: Ichsan2895
  content: 'I successfully quantizing it with Qlora with using bitsandbytes package.


    Activated it with  bitsandbytes config which select "nf4" Quant type + load_in_4bit
    + bfloat16. It allows to run on single A100 40 GB VRAM. The quantized version
    is run on the fly in jupyter lab without manually exported/saved it the new model.'
  created_at: 2023-06-05 13:32:27+00:00
  edited: true
  hidden: false
  id: 647df1fb10b7a3b15705e90f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e5579e089a57e52149b322e2ed22421a.svg
      fullname: Max Fry
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: max-fry
      type: user
    createdAt: '2023-06-07T13:55:06.000Z'
    data:
      edited: false
      editors:
      - max-fry
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9797828197479248
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e5579e089a57e52149b322e2ed22421a.svg
          fullname: Max Fry
          isHf: false
          isPro: false
          name: max-fry
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Ichsan2895&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Ichsan2895\">@<span class=\"\
          underline\">Ichsan2895</span></a></span>\n\n\t</span></span> How is its\
          \ performance?</p>\n"
        raw: '@Ichsan2895 How is its performance?'
        updatedAt: '2023-06-07T13:55:06.808Z'
      numEdits: 0
      reactions: []
    id: 64808c3a40facadc556dca47
    type: comment
  author: max-fry
  content: '@Ichsan2895 How is its performance?'
  created_at: 2023-06-07 12:55:06+00:00
  edited: false
  hidden: false
  id: 64808c3a40facadc556dca47
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d86853221ca22d6fe9ff3488046bd96a.svg
      fullname: PB
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pb68
      type: user
    createdAt: '2023-06-08T00:05:20.000Z'
    data:
      edited: true
      editors:
      - pb68
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4945027530193329
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d86853221ca22d6fe9ff3488046bd96a.svg
          fullname: PB
          isHf: false
          isPro: false
          name: pb68
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Ichsan2895&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Ichsan2895\">@<span class=\"\
          underline\">Ichsan2895</span></a></span>\n\n\t</span></span> : Please share\
          \ the finetuning and evaluation code if possible.</p>\n"
        raw: '@Ichsan2895 : Please share the finetuning and evaluation code if possible.'
        updatedAt: '2023-06-08T00:06:58.509Z'
      numEdits: 1
      reactions: []
    id: 64811b409aafd41918b23471
    type: comment
  author: pb68
  content: '@Ichsan2895 : Please share the finetuning and evaluation code if possible.'
  created_at: 2023-06-07 23:05:20+00:00
  edited: true
  hidden: false
  id: 64811b409aafd41918b23471
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655935571104-noauth.jpeg?w=200&h=200&f=face
      fullname: Jimmy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jimsrc
      type: user
    createdAt: '2023-06-08T04:44:34.000Z'
    data:
      edited: false
      editors:
      - jimsrc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6413618326187134
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1655935571104-noauth.jpeg?w=200&h=200&f=face
          fullname: Jimmy
          isHf: false
          isPro: false
          name: jimsrc
          type: user
        html: '<p>how many tokens/sec? aprox</p>

          '
        raw: how many tokens/sec? aprox
        updatedAt: '2023-06-08T04:44:34.387Z'
      numEdits: 0
      reactions: []
    id: 64815cb29aafd41918b61386
    type: comment
  author: jimsrc
  content: how many tokens/sec? aprox
  created_at: 2023-06-08 03:44:34+00:00
  edited: false
  hidden: false
  id: 64815cb29aafd41918b61386
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
      fullname: Falcon LLM TII UAE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FalconLLM
      type: user
    createdAt: '2023-06-09T14:25:17.000Z'
    data:
      edited: false
      editors:
      - FalconLLM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9018875956535339
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
          fullname: Falcon LLM TII UAE
          isHf: false
          isPro: false
          name: FalconLLM
          type: user
        html: '<p>You can check out the <a rel="nofollow" href="https://github.com/rmihaylov/falcontune">FalconTune</a>
          package from the community as well :).</p>

          '
        raw: You can check out the [FalconTune](https://github.com/rmihaylov/falcontune)
          package from the community as well :).
        updatedAt: '2023-06-09T14:25:17.794Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - max-fry
    id: 6483364d413ff0a011f894a9
    type: comment
  author: FalconLLM
  content: You can check out the [FalconTune](https://github.com/rmihaylov/falcontune)
    package from the community as well :).
  created_at: 2023-06-09 13:25:17+00:00
  edited: false
  hidden: false
  id: 6483364d413ff0a011f894a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
      fullname: Muhammad Ichsan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ichsan2895
      type: user
    createdAt: '2023-06-10T03:32:08.000Z'
    data:
      edited: true
      editors:
      - Ichsan2895
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8455466032028198
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
          fullname: Muhammad Ichsan
          isHf: false
          isPro: false
          name: Ichsan2895
          type: user
        html: "<blockquote>\n<p>how many tokens/sec? aprox</p>\n</blockquote>\n<p>I\
          \ Ran it from cloud environment with Single A6000 48 GB VRAM. Falcon-40B\
          \ ran with 1-2 tokens/sec</p>\n<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;Ichsan2895&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Ichsan2895\"\
          >@<span class=\"underline\">Ichsan2895</span></a></span>\n\n\t</span></span>\
          \ : Please share the finetuning and evaluation code if possible.</p>\n</blockquote>\n\
          <p>Sorry, I never do fine tuning with new dataset. Just interference it\
          \ with question to see the answer :)</p>\n"
        raw: '> how many tokens/sec? aprox


          I Ran it from cloud environment with Single A6000 48 GB VRAM. Falcon-40B
          ran with 1-2 tokens/sec


          > @Ichsan2895 : Please share the finetuning and evaluation code if possible.


          Sorry, I never do fine tuning with new dataset. Just interference it with
          question to see the answer :)'
        updatedAt: '2023-06-10T03:32:35.035Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - max-fry
    id: 6483eeb87224b9a845ec4d60
    type: comment
  author: Ichsan2895
  content: '> how many tokens/sec? aprox


    I Ran it from cloud environment with Single A6000 48 GB VRAM. Falcon-40B ran with
    1-2 tokens/sec


    > @Ichsan2895 : Please share the finetuning and evaluation code if possible.


    Sorry, I never do fine tuning with new dataset. Just interference it with question
    to see the answer :)'
  created_at: 2023-06-10 02:32:08+00:00
  edited: true
  hidden: false
  id: 6483eeb87224b9a845ec4d60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
      fullname: Muhammad Ichsan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ichsan2895
      type: user
    createdAt: '2023-06-12T07:06:33.000Z'
    data:
      edited: false
      editors:
      - Ichsan2895
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8306493163108826
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/Uq5V3aIHpSHDPyHBBvEq-.jpeg?w=200&h=200&f=face
          fullname: Muhammad Ichsan
          isHf: false
          isPro: false
          name: Ichsan2895
          type: user
        html: '<blockquote>

          <p>Quantizing the large (40 or even 7b) model on 4bit will help community
          a lot. And please fine tune it with large code database and on Wizard-Vicuna,
          Mega and other big chat databases as well so it can produce code during
          chat even.</p>

          </blockquote>

          <p>Making LLMs even more accessible with bitsandbytes, 4-bit quantization
          and QLoRA<br><a href="https://huggingface.co/blog/falcon">https://huggingface.co/blog/falcon</a></p>

          <p>Colab Falcon fine tuning with QLoRA and Guanaco Dataset<br><a rel="nofollow"
          href="https://colab.research.google.com/drive/1BiQiw31DT7-cDp1-0ySXvvhzqomTdI-o?usp=sharing">https://colab.research.google.com/drive/1BiQiw31DT7-cDp1-0ySXvvhzqomTdI-o?usp=sharing</a></p>

          '
        raw: '> Quantizing the large (40 or even 7b) model on 4bit will help community
          a lot. And please fine tune it with large code database and on Wizard-Vicuna,
          Mega and other big chat databases as well so it can produce code during
          chat even.


          Making LLMs even more accessible with bitsandbytes, 4-bit quantization and
          QLoRA

          https://huggingface.co/blog/falcon


          Colab Falcon fine tuning with QLoRA and Guanaco Dataset

          https://colab.research.google.com/drive/1BiQiw31DT7-cDp1-0ySXvvhzqomTdI-o?usp=sharing'
        updatedAt: '2023-06-12T07:06:33.508Z'
      numEdits: 0
      reactions: []
    id: 6486c3f93f55407cb04a554a
    type: comment
  author: Ichsan2895
  content: '> Quantizing the large (40 or even 7b) model on 4bit will help community
    a lot. And please fine tune it with large code database and on Wizard-Vicuna,
    Mega and other big chat databases as well so it can produce code during chat even.


    Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA

    https://huggingface.co/blog/falcon


    Colab Falcon fine tuning with QLoRA and Guanaco Dataset

    https://colab.research.google.com/drive/1BiQiw31DT7-cDp1-0ySXvvhzqomTdI-o?usp=sharing'
  created_at: 2023-06-12 06:06:33+00:00
  edited: false
  hidden: false
  id: 6486c3f93f55407cb04a554a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 14
repo_id: tiiuae/falcon-40b
repo_type: model
status: open
target_branch: null
title: Finetune wtih QLoRA please
