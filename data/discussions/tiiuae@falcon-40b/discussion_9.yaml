!!python/object:huggingface_hub.community.DiscussionWithDetails
author: gmjolt
conflicting_files: null
created_at: 2023-05-27 10:01:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e2da181eb8024df29c3cfd072635bb7b.svg
      fullname: giorgio mazzara
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gmjolt
      type: user
    createdAt: '2023-05-27T11:01:29.000Z'
    data:
      edited: false
      editors:
      - gmjolt
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e2da181eb8024df29c3cfd072635bb7b.svg
          fullname: giorgio mazzara
          isHf: false
          isPro: false
          name: gmjolt
          type: user
        html: '<p>ModelError: An error occurred (ModelError) when calling the InvokeEndpoint
          operation: Received client error (400) from primary with message "{<br>  "code":
          400,<br>  "type": "InternalServerException",<br>  "message": "Loading /.sagemaker/mms/models/tiiuae__falcon-40b
          requires you to execute the configuration file in that repo on your local
          machine. Make sure you have read the code there to avoid malicious use,
          then set the option <code>trust_remote_code\u003dTrue</code> to remove this
          error."<br>}</p>

          '
        raw: "ModelError: An error occurred (ModelError) when calling the InvokeEndpoint\
          \ operation: Received client error (400) from primary with message \"{\r\
          \n  \"code\": 400,\r\n  \"type\": \"InternalServerException\",\r\n  \"message\"\
          : \"Loading /.sagemaker/mms/models/tiiuae__falcon-40b requires you to execute\
          \ the configuration file in that repo on your local machine. Make sure you\
          \ have read the code there to avoid malicious use, then set the option `trust_remote_code\\\
          u003dTrue` to remove this error.\"\r\n}"
        updatedAt: '2023-05-27T11:01:29.668Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - dgallitelli
        - ybm11
        - nazimu
    id: 6471e309ba726cc401bc8d7e
    type: comment
  author: gmjolt
  content: "ModelError: An error occurred (ModelError) when calling the InvokeEndpoint\
    \ operation: Received client error (400) from primary with message \"{\r\n  \"\
    code\": 400,\r\n  \"type\": \"InternalServerException\",\r\n  \"message\": \"\
    Loading /.sagemaker/mms/models/tiiuae__falcon-40b requires you to execute the\
    \ configuration file in that repo on your local machine. Make sure you have read\
    \ the code there to avoid malicious use, then set the option `trust_remote_code\\\
    u003dTrue` to remove this error.\"\r\n}"
  created_at: 2023-05-27 10:01:29+00:00
  edited: false
  hidden: false
  id: 6471e309ba726cc401bc8d7e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6432f4e34521083b9d286a48/v9bX1bMorcB7XWlmG2aUi.jpeg?w=200&h=200&f=face
      fullname: Slobodan Ninkov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sloba
      type: user
    createdAt: '2023-05-28T00:36:28.000Z'
    data:
      edited: true
      editors:
      - Sloba
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6432f4e34521083b9d286a48/v9bX1bMorcB7XWlmG2aUi.jpeg?w=200&h=200&f=face
          fullname: Slobodan Ninkov
          isHf: false
          isPro: false
          name: Sloba
          type: user
        html: '<p>qa = transformers.pipeline(<br>    "text-generation",<br>    model=model,<br>    tokenizer=tokenizer,<br>    torch_dtype="auto",<br>    <strong>trust_remote_code=True,</strong><br>    device_map="auto",<br>)</p>

          '
        raw: "qa = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n\
          \    tokenizer=tokenizer,\n    torch_dtype=\"auto\",\n    **trust_remote_code=True,**\n\
          \    device_map=\"auto\",\n)"
        updatedAt: '2023-05-28T01:03:37.890Z'
      numEdits: 1
      reactions: []
    id: 6472a20c97a75cc77abbfa50
    type: comment
  author: Sloba
  content: "qa = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n\
    \    tokenizer=tokenizer,\n    torch_dtype=\"auto\",\n    **trust_remote_code=True,**\n\
    \    device_map=\"auto\",\n)"
  created_at: 2023-05-27 23:36:28+00:00
  edited: true
  hidden: false
  id: 6472a20c97a75cc77abbfa50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7fb15ca398ee8e081878eb65b0229fbb.svg
      fullname: Maxime Voisin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mvoisin
      type: user
    createdAt: '2023-05-28T15:07:34.000Z'
    data:
      edited: false
      editors:
      - mvoisin
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7fb15ca398ee8e081878eb65b0229fbb.svg
          fullname: Maxime Voisin
          isHf: false
          isPro: false
          name: mvoisin
          type: user
        html: '<p>what if we run it through AWS Sagemaker? </p>

          <h1 id="deploy-model-to-sagemaker-inference">deploy model to SageMaker Inference</h1>

          <p>predictor = huggingface_model.deploy(<br>    initial_instance_count=1,
          # number of instances<br>    instance_type=''ml.m5.xlarge'', # ec2 instance
          type<br>    trust_remote_code=True,<br>)</p>

          '
        raw: "what if we run it through AWS Sagemaker? \n\n# deploy model to SageMaker\
          \ Inference\npredictor = huggingface_model.deploy(\n    initial_instance_count=1,\
          \ # number of instances\n    instance_type='ml.m5.xlarge', # ec2 instance\
          \ type\n    trust_remote_code=True,\n)"
        updatedAt: '2023-05-28T15:07:34.909Z'
      numEdits: 0
      reactions: []
    id: 64736e36352c94a20dd5c373
    type: comment
  author: mvoisin
  content: "what if we run it through AWS Sagemaker? \n\n# deploy model to SageMaker\
    \ Inference\npredictor = huggingface_model.deploy(\n    initial_instance_count=1,\
    \ # number of instances\n    instance_type='ml.m5.xlarge', # ec2 instance type\n\
    \    trust_remote_code=True,\n)"
  created_at: 2023-05-28 14:07:34+00:00
  edited: false
  hidden: false
  id: 64736e36352c94a20dd5c373
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/10ce4c370b50a6c9f7e5996473b9a947.svg
      fullname: KL
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kennethleungty
      type: user
    createdAt: '2023-05-29T06:11:13.000Z'
    data:
      edited: false
      editors:
      - kennethleungty
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/10ce4c370b50a6c9f7e5996473b9a947.svg
          fullname: KL
          isHf: false
          isPro: false
          name: kennethleungty
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mvoisin&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mvoisin\">@<span class=\"\
          underline\">mvoisin</span></a></span>\n\n\t</span></span> - setting <code>trust_remote_code=True</code>\
          \ still gave me the same error</p>\n"
        raw: '@mvoisin - setting `trust_remote_code=True` still gave me the same error'
        updatedAt: '2023-05-29T06:11:13.163Z'
      numEdits: 0
      reactions:
      - count: 9
        reaction: "\U0001F44D"
        users:
        - voceses
        - ashfakh
        - arlind0xbb
        - vkajjam
        - GandalfEP
        - ybm11
        - allenhaozi
        - HarryLeonardo
        - evelinamorim
    id: 64744201f9e3e0b312e544f7
    type: comment
  author: kennethleungty
  content: '@mvoisin - setting `trust_remote_code=True` still gave me the same error'
  created_at: 2023-05-29 05:11:13+00:00
  edited: false
  hidden: false
  id: 64744201f9e3e0b312e544f7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4f7a730b52e1bdf7a49a06f6d7e8d54d.svg
      fullname: Adam Lukawski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sunsetsobserver
      type: user
    createdAt: '2023-06-01T07:47:01.000Z'
    data:
      edited: true
      editors:
      - sunsetsobserver
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4f7a730b52e1bdf7a49a06f6d7e8d54d.svg
          fullname: Adam Lukawski
          isHf: false
          isPro: false
          name: sunsetsobserver
          type: user
        html: '<p>This worked for me:</p>

          <p>   from transformers import AutoTokenizer, AutoModelForCausalLM<br>   import
          transformers<br>   import torch</p>

          <p>   model = AutoModelForCausalLM.from_pretrained("tiiuae/falcon-40b",
          trust_remote_code=True)</p>

          <p>   tokenizer = AutoTokenizer.from_pretrained("tiiuae/falcon-40b")''''</p>

          '
        raw: "This worked for me:\n\n   from transformers import AutoTokenizer, AutoModelForCausalLM\n\
          \   import transformers\n   import torch\n\n   model = AutoModelForCausalLM.from_pretrained(\"\
          tiiuae/falcon-40b\", trust_remote_code=True)\n\n   tokenizer = AutoTokenizer.from_pretrained(\"\
          tiiuae/falcon-40b\")''"
        updatedAt: '2023-06-01T19:18:00.630Z'
      numEdits: 2
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - GandalfEP
        - medmac01
        - Vincent-yifan
    id: 64784cf5ad83f3939b465135
    type: comment
  author: sunsetsobserver
  content: "This worked for me:\n\n   from transformers import AutoTokenizer, AutoModelForCausalLM\n\
    \   import transformers\n   import torch\n\n   model = AutoModelForCausalLM.from_pretrained(\"\
    tiiuae/falcon-40b\", trust_remote_code=True)\n\n   tokenizer = AutoTokenizer.from_pretrained(\"\
    tiiuae/falcon-40b\")''"
  created_at: 2023-06-01 06:47:01+00:00
  edited: true
  hidden: false
  id: 64784cf5ad83f3939b465135
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/efc82ec2e17837c0d0528332324a3dfb.svg
      fullname: Mahmoud Abduljawad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mahmoudajawad
      type: user
    createdAt: '2023-06-05T07:39:01.000Z'
    data:
      edited: true
      editors:
      - mahmoudajawad
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6748920679092407
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/efc82ec2e17837c0d0528332324a3dfb.svg
          fullname: Mahmoud Abduljawad
          isHf: false
          isPro: false
          name: mahmoudajawad
          type: user
        html: '<p>I failed with all possible combinations to overcome this issue,
          so I ended up changing the raising this exception. For those using SageMaker
          Jupyeter:</p>

          <pre><code class="language-bash">!sed -i <span class="hljs-string">''s/if
          not trust_remote_code:/if False: # Manually replace in-line to avoid <a
          href="/tiiuae/falcon-40b/discussions/9">#9</a>/g''</span> ~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py

          </code></pre>

          <p>You can now confirm it has been changed with:</p>

          <pre><code class="language-bash">!<span class="hljs-built_in">cat</span>
          ~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py

          </code></pre>

          '
        raw: 'I failed with all possible combinations to overcome this issue, so I
          ended up changing the raising this exception. For those using SageMaker
          Jupyeter:

          ```bash

          !sed -i ''s/if not trust_remote_code:/if False: # Manually replace in-line
          to avoid #9/g'' ~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py

          ```

          You can now confirm it has been changed with:

          ```bash

          !cat ~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py

          ```'
        updatedAt: '2023-06-05T07:39:15.573Z'
      numEdits: 1
      reactions: []
    id: 647d911510b7a3b157f8a8ae
    type: comment
  author: mahmoudajawad
  content: 'I failed with all possible combinations to overcome this issue, so I ended
    up changing the raising this exception. For those using SageMaker Jupyeter:

    ```bash

    !sed -i ''s/if not trust_remote_code:/if False: # Manually replace in-line to
    avoid #9/g'' ~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py

    ```

    You can now confirm it has been changed with:

    ```bash

    !cat ~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py

    ```'
  created_at: 2023-06-05 06:39:01+00:00
  edited: true
  hidden: false
  id: 647d911510b7a3b157f8a8ae
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9e860e2f75c5fb3df63ef9c503111201.svg
      fullname: Ashfakh rithu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ashfakh
      type: user
    createdAt: '2023-06-05T10:10:29.000Z'
    data:
      edited: false
      editors:
      - ashfakh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7831234931945801
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9e860e2f75c5fb3df63ef9c503111201.svg
          fullname: Ashfakh rithu
          isHf: false
          isPro: false
          name: ashfakh
          type: user
        html: '<p>Facing the same issue, following this tutorial <a href="https://huggingface.co/blog/sagemaker-huggingface-llm">https://huggingface.co/blog/sagemaker-huggingface-llm</a>
          to deploy falcon 7b on aws via sagemaker, getting the same error and don''t
          know where to set trust_remote_code. please help</p>

          '
        raw: Facing the same issue, following this tutorial https://huggingface.co/blog/sagemaker-huggingface-llm
          to deploy falcon 7b on aws via sagemaker, getting the same error and don't
          know where to set trust_remote_code. please help
        updatedAt: '2023-06-05T10:10:29.722Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - kieryn
        - vkajjam
        - ybm11
        - SidHelix
        - orcaman2
    id: 647db495f14eafc3b44a4b5b
    type: comment
  author: ashfakh
  content: Facing the same issue, following this tutorial https://huggingface.co/blog/sagemaker-huggingface-llm
    to deploy falcon 7b on aws via sagemaker, getting the same error and don't know
    where to set trust_remote_code. please help
  created_at: 2023-06-05 09:10:29+00:00
  edited: false
  hidden: false
  id: 647db495f14eafc3b44a4b5b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d8fc721e0ffb2f369c4dde75d10120f5.svg
      fullname: Fran Abellan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cw-franabellan
      type: user
    createdAt: '2023-06-05T11:29:47.000Z'
    data:
      edited: false
      editors:
      - cw-franabellan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6930539011955261
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d8fc721e0ffb2f369c4dde75d10120f5.svg
          fullname: Fran Abellan
          isHf: false
          isPro: false
          name: cw-franabellan
          type: user
        html: '<p>Same here!!</p>

          '
        raw: Same here!!
        updatedAt: '2023-06-05T11:29:47.114Z'
      numEdits: 0
      reactions: []
    id: 647dc72b5214d172cbb4a522
    type: comment
  author: cw-franabellan
  content: Same here!!
  created_at: 2023-06-05 10:29:47+00:00
  edited: false
  hidden: false
  id: 647dc72b5214d172cbb4a522
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d3ec3ae113c83162a038f3c5650285dc.svg
      fullname: Kieryn Phipps
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kieryn
      type: user
    createdAt: '2023-06-06T12:56:11.000Z'
    data:
      edited: false
      editors:
      - kieryn
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9487413167953491
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d3ec3ae113c83162a038f3c5650285dc.svg
          fullname: Kieryn Phipps
          isHf: false
          isPro: false
          name: kieryn
          type: user
        html: '<p>Same for me too - from the tutorial there''s no mention of the trust
          setting for falcon and have not figured it out yet either.</p>

          '
        raw: Same for me too - from the tutorial there's no mention of the trust setting
          for falcon and have not figured it out yet either.
        updatedAt: '2023-06-06T12:56:11.243Z'
      numEdits: 0
      reactions: []
    id: 647f2cebf41cf810e37aad17
    type: comment
  author: kieryn
  content: Same for me too - from the tutorial there's no mention of the trust setting
    for falcon and have not figured it out yet either.
  created_at: 2023-06-06 11:56:11+00:00
  edited: false
  hidden: false
  id: 647f2cebf41cf810e37aad17
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/yMyIavmgTky4V_qhxZMXP.png?w=200&h=200&f=face
      fullname: Jose Antonio Dominguez
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JoseadClutch
      type: user
    createdAt: '2023-06-06T14:25:58.000Z'
    data:
      edited: false
      editors:
      - JoseadClutch
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9808036684989929
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/yMyIavmgTky4V_qhxZMXP.png?w=200&h=200&f=face
          fullname: Jose Antonio Dominguez
          isHf: false
          isPro: false
          name: JoseadClutch
          type: user
        html: '<p>Hey Everyone, I''ve been trying with <a rel="nofollow" href="https://gist.github.com/timesler/4b244a6b73d6e02d17fd220fd92dfaec">https://gist.github.com/timesler/4b244a6b73d6e02d17fd220fd92dfaec</a>
          as well, I''m having issues with the tar.gz file but please try and see
          what happens.</p>

          '
        raw: Hey Everyone, I've been trying with https://gist.github.com/timesler/4b244a6b73d6e02d17fd220fd92dfaec
          as well, I'm having issues with the tar.gz file but please try and see what
          happens.
        updatedAt: '2023-06-06T14:25:58.800Z'
      numEdits: 0
      reactions: []
    id: 647f41f62a7bcaa307a695fc
    type: comment
  author: JoseadClutch
  content: Hey Everyone, I've been trying with https://gist.github.com/timesler/4b244a6b73d6e02d17fd220fd92dfaec
    as well, I'm having issues with the tar.gz file but please try and see what happens.
  created_at: 2023-06-06 13:25:58+00:00
  edited: false
  hidden: false
  id: 647f41f62a7bcaa307a695fc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/436de07b98b2fca40e8e51bffa9386d0.svg
      fullname: Jack Weissenberger
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jweissenberger
      type: user
    createdAt: '2023-06-06T15:50:29.000Z'
    data:
      edited: false
      editors:
      - jweissenberger
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8795068860054016
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/436de07b98b2fca40e8e51bffa9386d0.svg
          fullname: Jack Weissenberger
          isHf: false
          isPro: false
          name: jweissenberger
          type: user
        html: '<p>Looks like they''re is working on releasing the new 0.8.2 version
          of the huggingface llm inference docker image to sagemaker based on this
          thread: <a rel="nofollow" href="https://github.com/huggingface/text-generation-inference/issues/390">https://github.com/huggingface/text-generation-inference/issues/390</a></p>

          <p>That should fix this issue based on this blog: <a href="https://huggingface.co/blog/falcon">https://huggingface.co/blog/falcon</a></p>

          '
        raw: 'Looks like they''re is working on releasing the new 0.8.2 version of
          the huggingface llm inference docker image to sagemaker based on this thread:
          https://github.com/huggingface/text-generation-inference/issues/390


          That should fix this issue based on this blog: https://huggingface.co/blog/falcon'
        updatedAt: '2023-06-06T15:50:29.714Z'
      numEdits: 0
      reactions: []
    id: 647f55c52a7bcaa307a83da2
    type: comment
  author: jweissenberger
  content: 'Looks like they''re is working on releasing the new 0.8.2 version of the
    huggingface llm inference docker image to sagemaker based on this thread: https://github.com/huggingface/text-generation-inference/issues/390


    That should fix this issue based on this blog: https://huggingface.co/blog/falcon'
  created_at: 2023-06-06 14:50:29+00:00
  edited: false
  hidden: false
  id: 647f55c52a7bcaa307a83da2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
      fullname: Falcon LLM TII UAE
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: FalconLLM
      type: user
    createdAt: '2023-06-09T14:24:44.000Z'
    data:
      edited: false
      editors:
      - FalconLLM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6508681774139404
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6471c2c76facfb01d8ac3278/ii7e_5o4jBoK3pS8WMaWK.png?w=200&h=200&f=face
          fullname: Falcon LLM TII UAE
          isHf: false
          isPro: false
          name: FalconLLM
          type: user
        html: '<p>For deploying on SageMaker, we recommend having a look <a rel="nofollow"
          href="https://www.philschmid.de/sagemaker-falcon-llm">here</a>.</p>

          <p>Otherwise, the HF <a href="https://huggingface.co/blog/falcon">blogpost</a>
          contains useful pointers.</p>

          '
        raw: 'For deploying on SageMaker, we recommend having a look [here](https://www.philschmid.de/sagemaker-falcon-llm).


          Otherwise, the HF [blogpost](https://huggingface.co/blog/falcon) contains
          useful pointers.'
        updatedAt: '2023-06-09T14:24:44.055Z'
      numEdits: 0
      reactions: []
    id: 6483362c8bfd740d4e0da196
    type: comment
  author: FalconLLM
  content: 'For deploying on SageMaker, we recommend having a look [here](https://www.philschmid.de/sagemaker-falcon-llm).


    Otherwise, the HF [blogpost](https://huggingface.co/blog/falcon) contains useful
    pointers.'
  created_at: 2023-06-09 13:24:44+00:00
  edited: false
  hidden: false
  id: 6483362c8bfd740d4e0da196
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4a7bc5cc64592ca636a880fd9ef54fdb.svg
      fullname: Jayalekshmi Gopakumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JayalekshmiGopakumar
      type: user
    createdAt: '2023-06-25T22:33:04.000Z'
    data:
      edited: false
      editors:
      - JayalekshmiGopakumar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7416151762008667
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4a7bc5cc64592ca636a880fd9ef54fdb.svg
          fullname: Jayalekshmi Gopakumar
          isHf: false
          isPro: false
          name: JayalekshmiGopakumar
          type: user
        html: '<p>Hi I aml using Hugginggface estimator for the training job and I
          get this same error.I am using the transformers gitrepo tokenclassification
          ,run_ner.py as the entry point.But the it throws the following error.</p>

          <p>ValueError: Loading tiiuae/falcon-40b requires you to execute the configuration
          file in that repo on your local machine. Make sure you have read the code
          there to avoid malicious use, then set the option <code>trust_remote_code=True</code>
          to remove this error." Command "/opt/conda/bin/python3.9 run_ner.py --dataset_name
          JayalekshmiGopakumar/falcon_doclayn, exit code: 1</p>

          '
        raw: 'Hi I aml using Hugginggface estimator for the training job and I get
          this same error.I am using the transformers gitrepo tokenclassification
          ,run_ner.py as the entry point.But the it throws the following error.


          ValueError: Loading tiiuae/falcon-40b requires you to execute the configuration
          file in that repo on your local machine. Make sure you have read the code
          there to avoid malicious use, then set the option `trust_remote_code=True`
          to remove this error." Command "/opt/conda/bin/python3.9 run_ner.py --dataset_name
          JayalekshmiGopakumar/falcon_doclayn, exit code: 1'
        updatedAt: '2023-06-25T22:33:04.715Z'
      numEdits: 0
      reactions: []
    id: 6498c0a0f84c9448d6d21a25
    type: comment
  author: JayalekshmiGopakumar
  content: 'Hi I aml using Hugginggface estimator for the training job and I get this
    same error.I am using the transformers gitrepo tokenclassification ,run_ner.py
    as the entry point.But the it throws the following error.


    ValueError: Loading tiiuae/falcon-40b requires you to execute the configuration
    file in that repo on your local machine. Make sure you have read the code there
    to avoid malicious use, then set the option `trust_remote_code=True` to remove
    this error." Command "/opt/conda/bin/python3.9 run_ner.py --dataset_name JayalekshmiGopakumar/falcon_doclayn,
    exit code: 1'
  created_at: 2023-06-25 21:33:04+00:00
  edited: false
  hidden: false
  id: 6498c0a0f84c9448d6d21a25
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2a0a97bdeb59d15bbfe54a6d80a75937.svg
      fullname: Anaelia Ovalle
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aovalle
      type: user
    createdAt: '2023-10-18T12:50:56.000Z'
    data:
      edited: false
      editors:
      - aovalle
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9835432767868042
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2a0a97bdeb59d15bbfe54a6d80a75937.svg
          fullname: Anaelia Ovalle
          isHf: false
          isPro: false
          name: aovalle
          type: user
        html: '<p>I had the same issue,  resolved it with updating to transformers==4.34.0</p>

          '
        raw: I had the same issue,  resolved it with updating to transformers==4.34.0
        updatedAt: '2023-10-18T12:50:56.842Z'
      numEdits: 0
      reactions: []
    id: 652fd4b075f5f7a84e13e630
    type: comment
  author: aovalle
  content: I had the same issue,  resolved it with updating to transformers==4.34.0
  created_at: 2023-10-18 11:50:56+00:00
  edited: false
  hidden: false
  id: 652fd4b075f5f7a84e13e630
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: tiiuae/falcon-40b
repo_type: model
status: open
target_branch: null
title: 'How to set trust_remote_code to true? '
