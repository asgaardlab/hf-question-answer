!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ashmitbhattarai
conflicting_files: null
created_at: 2023-07-07 15:55:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fd8994da9a3d3f575be5a82b9ecc81fc.svg
      fullname: Ashmit Bhattarai
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ashmitbhattarai
      type: user
    createdAt: '2023-07-07T16:55:47.000Z'
    data:
      edited: false
      editors:
      - ashmitbhattarai
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.653089165687561
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fd8994da9a3d3f575be5a82b9ecc81fc.svg
          fullname: Ashmit Bhattarai
          isHf: false
          isPro: false
          name: ashmitbhattarai
          type: user
        html: "<p>I am trying to fine-tune the model on H100 80GB Graphics card. The\
          \ same code runs on A100 40GB. Its 4 bits quantized model</p>\n<pre><code\
          \ class=\"language-model_name\">\nquant_config = BitsAndBytesConfig(\n \
          \   load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_doube_quant=False,\n\
          \    bnb_4bit_compute_dtype = torch.bfloat16\n)\nbase_model = AutoModelForCausalLM.from_pretrained(\n\
          \    model_name,\n    quantization_config=quant_config,\n    device_map=\"\
          cuda:0\",\n    trust_remote_code=True,\n    # max_seq_len=8192\n    # use_safetensors=True\n\
          )\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    trust_remote_code\
          \ = True,\n    use_fast=True\n)\n## Prepare the model for K-Bit Trainining\n\
          base_model.gradient_checkpointing_enable()\n\nmodel = prepare_model_for_kbit_training(base_model)\n\
          ....\ntrainer...\ntrainer.train()\n</code></pre>\n<p>I get CUDA Error: an\
          \ illegal instruction was encountered.</p>\n<p>Again, the same code runs\
          \ great on A100 just not on H100.. FYI: Inference on the base model works\
          \ just fine just the fine-tune training is erroneous.</p>\n<p>Using <a rel=\"\
          nofollow\" href=\"https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing\"\
          >notebook</a> as reference</p>\n"
        raw: "I am trying to fine-tune the model on H100 80GB Graphics card. The same\
          \ code runs on A100 40GB. Its 4 bits quantized model\r\n\r\n```model_name\
          \ = 'tiiuae/falcon-40b'\r\n\r\nquant_config = BitsAndBytesConfig(\r\n  \
          \  load_in_4bit=True,\r\n    bnb_4bit_quant_type=\"nf4\",\r\n    bnb_4bit_use_doube_quant=False,\r\
          \n    bnb_4bit_compute_dtype = torch.bfloat16\r\n)\r\nbase_model = AutoModelForCausalLM.from_pretrained(\r\
          \n    model_name,\r\n    quantization_config=quant_config,\r\n    device_map=\"\
          cuda:0\",\r\n    trust_remote_code=True,\r\n    # max_seq_len=8192\r\n \
          \   # use_safetensors=True\r\n)\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\r\
          \n    model_name,\r\n    trust_remote_code = True,\r\n    use_fast=True\r\
          \n)\r\n## Prepare the model for K-Bit Trainining\r\nbase_model.gradient_checkpointing_enable()\r\
          \n\r\nmodel = prepare_model_for_kbit_training(base_model)\r\n....\r\ntrainer...\r\
          \ntrainer.train()\r\n```\r\n\r\nI get CUDA Error: an illegal instruction\
          \ was encountered.\r\n\r\nAgain, the same code runs great on A100 just not\
          \ on H100.. FYI: Inference on the base model works just fine just the fine-tune\
          \ training is erroneous.\r\n\r\nUsing [notebook](https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing)\
          \ as reference"
        updatedAt: '2023-07-07T16:55:47.394Z'
      numEdits: 0
      reactions: []
    id: 64a84393de2d860082bcb6b4
    type: comment
  author: ashmitbhattarai
  content: "I am trying to fine-tune the model on H100 80GB Graphics card. The same\
    \ code runs on A100 40GB. Its 4 bits quantized model\r\n\r\n```model_name = 'tiiuae/falcon-40b'\r\
    \n\r\nquant_config = BitsAndBytesConfig(\r\n    load_in_4bit=True,\r\n    bnb_4bit_quant_type=\"\
    nf4\",\r\n    bnb_4bit_use_doube_quant=False,\r\n    bnb_4bit_compute_dtype =\
    \ torch.bfloat16\r\n)\r\nbase_model = AutoModelForCausalLM.from_pretrained(\r\n\
    \    model_name,\r\n    quantization_config=quant_config,\r\n    device_map=\"\
    cuda:0\",\r\n    trust_remote_code=True,\r\n    # max_seq_len=8192\r\n    # use_safetensors=True\r\
    \n)\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\r\n    model_name,\r\n \
    \   trust_remote_code = True,\r\n    use_fast=True\r\n)\r\n## Prepare the model\
    \ for K-Bit Trainining\r\nbase_model.gradient_checkpointing_enable()\r\n\r\nmodel\
    \ = prepare_model_for_kbit_training(base_model)\r\n....\r\ntrainer...\r\ntrainer.train()\r\
    \n```\r\n\r\nI get CUDA Error: an illegal instruction was encountered.\r\n\r\n\
    Again, the same code runs great on A100 just not on H100.. FYI: Inference on the\
    \ base model works just fine just the fine-tune training is erroneous.\r\n\r\n\
    Using [notebook](https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing)\
    \ as reference"
  created_at: 2023-07-07 15:55:47+00:00
  edited: false
  hidden: false
  id: 64a84393de2d860082bcb6b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28cbf47e0b22c69575cf623a8364e649.svg
      fullname: Nitan Shalon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nshalon
      type: user
    createdAt: '2023-07-10T22:52:41.000Z'
    data:
      edited: false
      editors:
      - nshalon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9462426900863647
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28cbf47e0b22c69575cf623a8364e649.svg
          fullname: Nitan Shalon
          isHf: false
          isPro: false
          name: nshalon
          type: user
        html: '<p>i have the same issue...</p>

          '
        raw: i have the same issue...
        updatedAt: '2023-07-10T22:52:41.501Z'
      numEdits: 0
      reactions: []
    id: 64ac8bb95b181f6cca95ff5d
    type: comment
  author: nshalon
  content: i have the same issue...
  created_at: 2023-07-10 21:52:41+00:00
  edited: false
  hidden: false
  id: 64ac8bb95b181f6cca95ff5d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f04b2e0471ebd609484091ec31a2a2a7.svg
      fullname: Kartik Chikkerur
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kartik08
      type: user
    createdAt: '2023-08-24T11:34:57.000Z'
    data:
      edited: false
      editors:
      - Kartik08
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9683436751365662
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f04b2e0471ebd609484091ec31a2a2a7.svg
          fullname: Kartik Chikkerur
          isHf: false
          isPro: false
          name: Kartik08
          type: user
        html: '<p>I do have the same issue . How to solve this ?</p>

          '
        raw: I do have the same issue . How to solve this ?
        updatedAt: '2023-08-24T11:34:57.121Z'
      numEdits: 0
      reactions: []
    id: 64e740610e8c31140a1e6505
    type: comment
  author: Kartik08
  content: I do have the same issue . How to solve this ?
  created_at: 2023-08-24 10:34:57+00:00
  edited: false
  hidden: false
  id: 64e740610e8c31140a1e6505
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 82
repo_id: tiiuae/falcon-40b
repo_type: model
status: open
target_branch: null
title: Nvidia H100 Finetuning Error on BitsandBytes
