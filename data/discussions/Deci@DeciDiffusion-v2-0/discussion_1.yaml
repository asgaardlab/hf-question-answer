!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Steve72
conflicting_files: null
created_at: 2024-01-17 23:46:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/15be7840bf1183ad1a765276a247048a.svg
      fullname: Steve Stevens
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Steve72
      type: user
    createdAt: '2024-01-17T23:46:31.000Z'
    data:
      edited: true
      editors:
      - Steve72
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8949093818664551
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/15be7840bf1183ad1a765276a247048a.svg
          fullname: Steve Stevens
          isHf: false
          isPro: false
          name: Steve72
          type: user
        html: "<p>Saw a reddit post announcing v2.0 today.   I do a lot of SD performance\
          \ tuning work.  I can average 5.2 milliseconds per 512x512 image with batching\
          \ using 1 step sd-turbo.  I use all the tricks.  Was doing realtime video\
          \ gen's within hours of LCM coming out.</p>\n<p>Using DDv2 I get:</p>\n\
          <pre><code>100%|\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 114.63it/s]\n\
          dd2 time = 0.132\n100%|\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00,\
          \ 112.23it/s]\ndd2 time = 0.135\n100%|\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00,\
          \ 112.68it/s]\ndd2 time = 0.140\n</code></pre>\n<p>The face quality looks\
          \ quite poor.  Similar to what the BASE SD 1.5 model produces.  I never\
          \ use base sd1.5 given so many better fine tuned/merge models for sd1.5.\
          \  Unlike LCM, which now works with any of the sd1.5 improved models, this\
          \ DeciDiffusion is what it is.</p>\n<p>I just got down to 98 milliseconds\
          \ with TinyVAE but the compilation of the vae is producing a noised image.\
          \  Last time I run into this it was a bug in pytorch which I reported and\
          \ it got fix today.  I'm having to build xformers now locally because I'm\
          \ using the pyt 2.3 nightly build.</p>\n<p>The ultimate question is whether\
          \ LCM plus a good sd1.5 model produces better quality as your DD2.  The\
          \ performance seems similar.</p>\n<p>???  If I try to override num_inference_steps\
          \ it always does 10 no matter what value I do.</p>\n"
        raw: "Saw a reddit post announcing v2.0 today.   I do a lot of SD performance\
          \ tuning work.  I can average 5.2 milliseconds per 512x512 image with batching\
          \ using 1 step sd-turbo.  I use all the tricks.  Was doing realtime video\
          \ gen's within hours of LCM coming out.\n\nUsing DDv2 I get:\n```\n100%|\u2588\
          \u2588\u2588\u2588| 10/10 [00:00<00:00, 114.63it/s]\ndd2 time = 0.132\n\
          100%|\u2588\u2588\u2588\u2588| 10/10 [00:00<00:00, 112.23it/s]\ndd2 time\
          \ = 0.135\n100%|\u2588\u2588\u2588\u2588| 10/10 [00:00<00:00, 112.68it/s]\n\
          dd2 time = 0.140\n```\nThe face quality looks quite poor.  Similar to what\
          \ the BASE SD 1.5 model produces.  I never use base sd1.5 given so many\
          \ better fine tuned/merge models for sd1.5.  Unlike LCM, which now works\
          \ with any of the sd1.5 improved models, this DeciDiffusion is what it is.\n\
          \nI just got down to 98 milliseconds with TinyVAE but the compilation of\
          \ the vae is producing a noised image.  Last time I run into this it was\
          \ a bug in pytorch which I reported and it got fix today.  I'm having to\
          \ build xformers now locally because I'm using the pyt 2.3 nightly build.\n\
          \nThe ultimate question is whether LCM plus a good sd1.5 model produces\
          \ better quality as your DD2.  The performance seems similar.\n\n???  If\
          \ I try to override num_inference_steps it always does 10 no matter what\
          \ value I do.\n\n"
        updatedAt: '2024-01-17T23:49:06.408Z'
      numEdits: 1
      reactions: []
    id: 65a866d7eea6e763766f3718
    type: comment
  author: Steve72
  content: "Saw a reddit post announcing v2.0 today.   I do a lot of SD performance\
    \ tuning work.  I can average 5.2 milliseconds per 512x512 image with batching\
    \ using 1 step sd-turbo.  I use all the tricks.  Was doing realtime video gen's\
    \ within hours of LCM coming out.\n\nUsing DDv2 I get:\n```\n100%|\u2588\u2588\
    \u2588\u2588| 10/10 [00:00<00:00, 114.63it/s]\ndd2 time = 0.132\n100%|\u2588\u2588\
    \u2588\u2588| 10/10 [00:00<00:00, 112.23it/s]\ndd2 time = 0.135\n100%|\u2588\u2588\
    \u2588\u2588| 10/10 [00:00<00:00, 112.68it/s]\ndd2 time = 0.140\n```\nThe face\
    \ quality looks quite poor.  Similar to what the BASE SD 1.5 model produces. \
    \ I never use base sd1.5 given so many better fine tuned/merge models for sd1.5.\
    \  Unlike LCM, which now works with any of the sd1.5 improved models, this DeciDiffusion\
    \ is what it is.\n\nI just got down to 98 milliseconds with TinyVAE but the compilation\
    \ of the vae is producing a noised image.  Last time I run into this it was a\
    \ bug in pytorch which I reported and it got fix today.  I'm having to build xformers\
    \ now locally because I'm using the pyt 2.3 nightly build.\n\nThe ultimate question\
    \ is whether LCM plus a good sd1.5 model produces better quality as your DD2.\
    \  The performance seems similar.\n\n???  If I try to override num_inference_steps\
    \ it always does 10 no matter what value I do.\n\n"
  created_at: 2024-01-17 23:46:31+00:00
  edited: true
  hidden: false
  id: 65a866d7eea6e763766f3718
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/15be7840bf1183ad1a765276a247048a.svg
      fullname: Steve Stevens
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Steve72
      type: user
    createdAt: '2024-01-18T00:14:17.000Z'
    data:
      edited: false
      editors:
      - Steve72
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9672511219978333
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/15be7840bf1183ad1a765276a247048a.svg
          fullname: Steve Stevens
          isHf: false
          isPro: false
          name: Steve72
          type: user
        html: '<p>Regarding num_inference_steps I now see the PREDEFINED_TIMESTEP_SQUEEZERS
          stuff.</p>

          <p>One problem with very fast UNet''s is that the vae time is around 31ms
          and this becomes a significant proportion of the time as we get down to
          about 100ms for 10 unet steps.  Not enough work has been applied to speeding
          the VAE.  TinyVAE very very fast and is ok for some kinds of images but
          smaller faces further away the eyes and other small details are really messed
          up.</p>

          '
        raw: 'Regarding num_inference_steps I now see the PREDEFINED_TIMESTEP_SQUEEZERS
          stuff.


          One problem with very fast UNet''s is that the vae time is around 31ms and
          this becomes a significant proportion of the time as we get down to about
          100ms for 10 unet steps.  Not enough work has been applied to speeding the
          VAE.  TinyVAE very very fast and is ok for some kinds of images but smaller
          faces further away the eyes and other small details are really messed up.'
        updatedAt: '2024-01-18T00:14:17.393Z'
      numEdits: 0
      reactions: []
    id: 65a86d599fa2a0f9a29a21dd
    type: comment
  author: Steve72
  content: 'Regarding num_inference_steps I now see the PREDEFINED_TIMESTEP_SQUEEZERS
    stuff.


    One problem with very fast UNet''s is that the vae time is around 31ms and this
    becomes a significant proportion of the time as we get down to about 100ms for
    10 unet steps.  Not enough work has been applied to speeding the VAE.  TinyVAE
    very very fast and is ok for some kinds of images but smaller faces further away
    the eyes and other small details are really messed up.'
  created_at: 2024-01-18 00:14:17+00:00
  edited: false
  hidden: false
  id: 65a86d599fa2a0f9a29a21dd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/15be7840bf1183ad1a765276a247048a.svg
      fullname: Steve Stevens
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Steve72
      type: user
    createdAt: '2024-01-18T02:36:42.000Z'
    data:
      edited: false
      editors:
      - Steve72
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8687056303024292
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/15be7840bf1183ad1a765276a247048a.svg
          fullname: Steve Stevens
          isHf: false
          isPro: false
          name: Steve72
          type: user
        html: '<p>I posted my quick and dirty perf testing results on your reddit
          post.</p>

          '
        raw: I posted my quick and dirty perf testing results on your reddit post.
        updatedAt: '2024-01-18T02:36:42.830Z'
      numEdits: 0
      reactions: []
    id: 65a88ebaf0f30f7eeaf5a22e
    type: comment
  author: Steve72
  content: I posted my quick and dirty perf testing results on your reddit post.
  created_at: 2024-01-18 02:36:42+00:00
  edited: false
  hidden: false
  id: 65a88ebaf0f30f7eeaf5a22e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60352f1960e3dd96631c909d/BtAJfA1YQ_gOreC5hsOP_.jpeg?w=200&h=200&f=face
      fullname: Prateek
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pjoshi15
      type: user
    createdAt: '2024-01-18T18:08:08.000Z'
    data:
      edited: false
      editors:
      - pjoshi15
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7659391164779663
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/60352f1960e3dd96631c909d/BtAJfA1YQ_gOreC5hsOP_.jpeg?w=200&h=200&f=face
          fullname: Prateek
          isHf: false
          isPro: false
          name: pjoshi15
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Steve72&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Steve72\"\
          >@<span class=\"underline\">Steve72</span></a></span>\n\n\t</span></span>\
          \ how to use a greater than 10 value for num_inference_steps?</p>\n"
        raw: Hey @Steve72 how to use a greater than 10 value for num_inference_steps?
        updatedAt: '2024-01-18T18:08:08.605Z'
      numEdits: 0
      reactions: []
    id: 65a969084d12c80c3d036c79
    type: comment
  author: pjoshi15
  content: Hey @Steve72 how to use a greater than 10 value for num_inference_steps?
  created_at: 2024-01-18 18:08:08+00:00
  edited: false
  hidden: false
  id: 65a969084d12c80c3d036c79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69a836be3385c71e78d1b84d83c84f75.svg
      fullname: Natan Bagrov
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: NatanBagrov
      type: user
    createdAt: '2024-01-18T19:15:16.000Z'
    data:
      edited: true
      editors:
      - NatanBagrov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8732789754867554
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69a836be3385c71e78d1b84d83c84f75.svg
          fullname: Natan Bagrov
          isHf: false
          isPro: false
          name: NatanBagrov
          type: user
        html: '<p>Hi, and thanks for the interest!</p>

          <p>To disable the squeezer, which will allow passing any value for number
          of steps, use <code>pipeline.scheduler._squeezer = None</code>. Once this
          is executed, <code>num_inference_steps</code> is respected.</p>

          <p>Regarding faces (or other domains), I''m certain that further fine-tuning
          for that domain would improve the visuals.</p>

          <p>As per {1,2,4}-step model, stay tuned :)</p>

          '
        raw: 'Hi, and thanks for the interest!


          To disable the squeezer, which will allow passing any value for number of
          steps, use `pipeline.scheduler._squeezer = None`. Once this is executed,
          `num_inference_steps` is respected.


          Regarding faces (or other domains), I''m certain that further fine-tuning
          for that domain would improve the visuals.


          As per {1,2,4}-step model, stay tuned :)'
        updatedAt: '2024-01-18T19:17:24.705Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - pjoshi15
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Steve72
    id: 65a978c427f7d6995af38a91
    type: comment
  author: NatanBagrov
  content: 'Hi, and thanks for the interest!


    To disable the squeezer, which will allow passing any value for number of steps,
    use `pipeline.scheduler._squeezer = None`. Once this is executed, `num_inference_steps`
    is respected.


    Regarding faces (or other domains), I''m certain that further fine-tuning for
    that domain would improve the visuals.


    As per {1,2,4}-step model, stay tuned :)'
  created_at: 2024-01-18 19:15:16+00:00
  edited: true
  hidden: false
  id: 65a978c427f7d6995af38a91
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Deci/DeciDiffusion-v2-0
repo_type: model
status: open
target_branch: null
title: Discovered this today.  Testing now.  135 millisec gens on 4090
