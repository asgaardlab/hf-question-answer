!!python/object:huggingface_hub.community.DiscussionWithDetails
author: darraghd
conflicting_files: null
created_at: 2023-01-05 10:34:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672916347066-636112a46483eb3832c443f7.jpeg?w=200&h=200&f=face
      fullname: Darragh Hanley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: darraghd
      type: user
    createdAt: '2023-01-05T10:34:50.000Z'
    data:
      edited: true
      editors:
      - darraghd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672916347066-636112a46483eb3832c443f7.jpeg?w=200&h=200&f=face
          fullname: Darragh Hanley
          isHf: false
          isPro: false
          name: darraghd
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;pszemraj&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/pszemraj\"\
          >@<span class=\"underline\">pszemraj</span></a></span>\n\n\t</span></span><br>Your\
          \ model works pretty well compared to other publically available tools -\
          \ better than grammarly I think!. Nice job.<br>Would you mind sharing some\
          \ details on how you trained. I saw it is an expanded version of JFLEG,\
          \ do you add many extra samples ? Also, are the model params seen <a href=\"\
          https://huggingface.co/pszemraj/t5-v1_1-base-ft-jflAUG\">here</a> what you\
          \ use ? I would like to give <code>google/flan-t5-xl</code> or <code>-xxl</code>\
          \ a try.<br>Best,<br>Darragh.</p>\n"
        raw: "Hi @pszemraj \nYour model works pretty well compared to other publically\
          \ available tools - better than grammarly I think!. Nice job. \nWould you\
          \ mind sharing some details on how you trained. I saw it is an expanded\
          \ version of JFLEG, do you add many extra samples ? Also, are the model\
          \ params seen [here](https://huggingface.co/pszemraj/t5-v1_1-base-ft-jflAUG)\
          \ what you use ? I would like to give `google/flan-t5-xl` or `-xxl` a try.\
          \ \nBest, \nDarragh."
        updatedAt: '2023-01-05T10:55:40.811Z'
      numEdits: 4
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - pszemraj
    id: 63b6a7ca579c63c61973edf4
    type: comment
  author: darraghd
  content: "Hi @pszemraj \nYour model works pretty well compared to other publically\
    \ available tools - better than grammarly I think!. Nice job. \nWould you mind\
    \ sharing some details on how you trained. I saw it is an expanded version of\
    \ JFLEG, do you add many extra samples ? Also, are the model params seen [here](https://huggingface.co/pszemraj/t5-v1_1-base-ft-jflAUG)\
    \ what you use ? I would like to give `google/flan-t5-xl` or `-xxl` a try. \n\
    Best, \nDarragh."
  created_at: 2023-01-05 10:34:50+00:00
  edited: true
  hidden: false
  id: 63b6a7ca579c63c61973edf4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2023-01-05T23:35:43.000Z'
    data:
      edited: false
      editors:
      - pszemraj
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
          fullname: Peter Szemraj
          isHf: false
          isPro: false
          name: pszemraj
          type: user
        html: "<p>Hi Darragh,</p>\n<p>Thank you for your kind words about the model!\
          \ I'm glad to hear that it has been performing well for you.</p>\n<p>I apologize\
          \ for the delay in responding - this project has been on the back burner\
          \ for a while now. Now that the FLAN models have shown some success, I'd\
          \ like to write up a paper or blog post detailing what I did before releasing\
          \ the dataset/repo (I want to make it completely open source.. after I write\
          \ fancy words). The \"full\" v5 version of the dataset is approximately\
          \ 180k unique rows. If you have the compute and are more interested in the\
          \ inference side of things, I'd be more than happy to train those for you\
          \ \U0001F609</p>\n<p>I trained the model as a standard text-to-text model\
          \ and did expand upon the JFLEG dataset by adding extra samples. The model\
          \ parameters in that repository are similar to the ones I use for inference.\
          \ BTW, see <a href=\"https://huggingface.co/pszemraj/flan-t5-large-grammar-synthesis/discussions/1\"\
          >this discussion thread</a> for details, but essentially the dataset consists\
          \ of several sentences at a time, and so I'd recommend running inference\
          \ <strong>in the same fashion:</strong> batches of 64-96 tokens ish (or,\
          \ 2-3 sentences split with regex) </p>\n<p>Happy to discuss this further\
          \ if you have any other questions!</p>\n"
        raw: "Hi Darragh,\n\nThank you for your kind words about the model! I'm glad\
          \ to hear that it has been performing well for you.\n\nI apologize for the\
          \ delay in responding - this project has been on the back burner for a while\
          \ now. Now that the FLAN models have shown some success, I'd like to write\
          \ up a paper or blog post detailing what I did before releasing the dataset/repo\
          \ (I want to make it completely open source.. after I write fancy words).\
          \ The \"full\" v5 version of the dataset is approximately 180k unique rows.\
          \ If you have the compute and are more interested in the inference side\
          \ of things, I'd be more than happy to train those for you \U0001F609\n\n\
          I trained the model as a standard text-to-text model and did expand upon\
          \ the JFLEG dataset by adding extra samples. The model parameters in that\
          \ repository are similar to the ones I use for inference. BTW, see [this\
          \ discussion thread](https://huggingface.co/pszemraj/flan-t5-large-grammar-synthesis/discussions/1)\
          \ for details, but essentially the dataset consists of several sentences\
          \ at a time, and so I'd recommend running inference **in the same fashion:**\
          \ batches of 64-96 tokens ish (or, 2-3 sentences split with regex) \n\n\
          Happy to discuss this further if you have any other questions!"
        updatedAt: '2023-01-05T23:35:43.090Z'
      numEdits: 0
      reactions: []
    id: 63b75ecfec5c995fded31322
    type: comment
  author: pszemraj
  content: "Hi Darragh,\n\nThank you for your kind words about the model! I'm glad\
    \ to hear that it has been performing well for you.\n\nI apologize for the delay\
    \ in responding - this project has been on the back burner for a while now. Now\
    \ that the FLAN models have shown some success, I'd like to write up a paper or\
    \ blog post detailing what I did before releasing the dataset/repo (I want to\
    \ make it completely open source.. after I write fancy words). The \"full\" v5\
    \ version of the dataset is approximately 180k unique rows. If you have the compute\
    \ and are more interested in the inference side of things, I'd be more than happy\
    \ to train those for you \U0001F609\n\nI trained the model as a standard text-to-text\
    \ model and did expand upon the JFLEG dataset by adding extra samples. The model\
    \ parameters in that repository are similar to the ones I use for inference. BTW,\
    \ see [this discussion thread](https://huggingface.co/pszemraj/flan-t5-large-grammar-synthesis/discussions/1)\
    \ for details, but essentially the dataset consists of several sentences at a\
    \ time, and so I'd recommend running inference **in the same fashion:** batches\
    \ of 64-96 tokens ish (or, 2-3 sentences split with regex) \n\nHappy to discuss\
    \ this further if you have any other questions!"
  created_at: 2023-01-05 23:35:43+00:00
  edited: false
  hidden: false
  id: 63b75ecfec5c995fded31322
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672916347066-636112a46483eb3832c443f7.jpeg?w=200&h=200&f=face
      fullname: Darragh Hanley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: darraghd
      type: user
    createdAt: '2023-01-06T11:11:51.000Z'
    data:
      edited: false
      editors:
      - darraghd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672916347066-636112a46483eb3832c443f7.jpeg?w=200&h=200&f=face
          fullname: Darragh Hanley
          isHf: false
          isPro: false
          name: darraghd
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;pszemraj&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/pszemraj\"\
          >@<span class=\"underline\">pszemraj</span></a></span>\n\n\t</span></span>\
          \ I would be very interested in the write-up. And thank you for the tip\
          \ on inference - I found it worked well on longer passages but I only went\
          \ up to ~ 100 tokens. I checked ChatGPT and this works pretty well, but\
          \ there is no API and GPT3 api has the cost behind. I will give it a try\
          \ to train and let you know how it goes. </p>\n"
        raw: 'Thanks @pszemraj I would be very interested in the write-up. And thank
          you for the tip on inference - I found it worked well on longer passages
          but I only went up to ~ 100 tokens. I checked ChatGPT and this works pretty
          well, but there is no API and GPT3 api has the cost behind. I will give
          it a try to train and let you know how it goes. '
        updatedAt: '2023-01-06T11:11:51.957Z'
      numEdits: 0
      reactions: []
      relatedEventId: 63b801f7c48390f07dea4583
    id: 63b801f7c48390f07dea4582
    type: comment
  author: darraghd
  content: 'Thanks @pszemraj I would be very interested in the write-up. And thank
    you for the tip on inference - I found it worked well on longer passages but I
    only went up to ~ 100 tokens. I checked ChatGPT and this works pretty well, but
    there is no API and GPT3 api has the cost behind. I will give it a try to train
    and let you know how it goes. '
  created_at: 2023-01-06 11:11:51+00:00
  edited: false
  hidden: false
  id: 63b801f7c48390f07dea4582
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672916347066-636112a46483eb3832c443f7.jpeg?w=200&h=200&f=face
      fullname: Darragh Hanley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: darraghd
      type: user
    createdAt: '2023-01-06T11:11:51.000Z'
    data:
      status: closed
    id: 63b801f7c48390f07dea4583
    type: status-change
  author: darraghd
  created_at: 2023-01-06 11:11:51+00:00
  id: 63b801f7c48390f07dea4583
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
      fullname: Peter Szemraj
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: pszemraj
      type: user
    createdAt: '2023-03-07T18:04:02.000Z'
    data:
      edited: false
      editors:
      - pszemraj
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1641390233716-60bccec062080d33f875cd0c.png?w=200&h=200&f=face
          fullname: Peter Szemraj
          isHf: false
          isPro: false
          name: pszemraj
          type: user
        html: '<p>I finally got around to an XL version :) <a href="https://huggingface.co/pszemraj/flan-t5-xl-grammar-synthesis">https://huggingface.co/pszemraj/flan-t5-xl-grammar-synthesis</a></p>

          '
        raw: I finally got around to an XL version :) https://huggingface.co/pszemraj/flan-t5-xl-grammar-synthesis
        updatedAt: '2023-03-07T18:04:02.482Z'
      numEdits: 0
      reactions: []
    id: 64077c92cf5e3e7bd502b0db
    type: comment
  author: pszemraj
  content: I finally got around to an XL version :) https://huggingface.co/pszemraj/flan-t5-xl-grammar-synthesis
  created_at: 2023-03-07 18:04:02+00:00
  edited: false
  hidden: false
  id: 64077c92cf5e3e7bd502b0db
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: pszemraj/flan-t5-large-grammar-synthesis
repo_type: model
status: closed
target_branch: null
title: Training method
