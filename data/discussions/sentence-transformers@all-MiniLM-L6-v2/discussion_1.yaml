!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dadlifejason
conflicting_files: null
created_at: 2022-07-22 22:29:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5472d301d2432164d8d0af2401e7b516.svg
      fullname: by
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dadlifejason
      type: user
    createdAt: '2022-07-22T23:29:14.000Z'
    data:
      edited: false
      editors:
      - dadlifejason
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5472d301d2432164d8d0af2401e7b516.svg
          fullname: by
          isHf: false
          isPro: false
          name: dadlifejason
          type: user
        html: '<p>What should I do if most of the sentence length in my dataset is
          around 1000 which is larger than 256?</p>

          '
        raw: What should I do if most of the sentence length in my dataset is around
          1000 which is larger than 256?
        updatedAt: '2022-07-22T23:29:14.069Z'
      numEdits: 0
      reactions: []
    id: 62db32caa3444ff33149346f
    type: comment
  author: dadlifejason
  content: What should I do if most of the sentence length in my dataset is around
    1000 which is larger than 256?
  created_at: 2022-07-22 22:29:14+00:00
  edited: false
  hidden: false
  id: 62db32caa3444ff33149346f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/437056da6aa968adcf6d9184bc4319fc.svg
      fullname: Rehana Mahfuz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rmahfuz
      type: user
    createdAt: '2022-08-12T23:23:22.000Z'
    data:
      edited: false
      editors:
      - rmahfuz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/437056da6aa968adcf6d9184bc4319fc.svg
          fullname: Rehana Mahfuz
          isHf: false
          isPro: false
          name: rmahfuz
          type: user
        html: '<p>If truncating the sentence results in loss of meaning, maybe try
          summarizing the long sentences into shorter sentences.</p>

          '
        raw: If truncating the sentence results in loss of meaning, maybe try summarizing
          the long sentences into shorter sentences.
        updatedAt: '2022-08-12T23:23:22.992Z'
      numEdits: 0
      reactions: []
    id: 62f6e0ea2e53c2efd33f9b0b
    type: comment
  author: rmahfuz
  content: If truncating the sentence results in loss of meaning, maybe try summarizing
    the long sentences into shorter sentences.
  created_at: 2022-08-12 22:23:22+00:00
  edited: false
  hidden: false
  id: 62f6e0ea2e53c2efd33f9b0b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/520b9e3418a19d3e442f5713613ef9b8.svg
      fullname: Meir Goldenberg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: drmeir
      type: user
    createdAt: '2023-08-06T00:08:14.000Z'
    data:
      edited: false
      editors:
      - drmeir
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8350487351417542
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/520b9e3418a19d3e442f5713613ef9b8.svg
          fullname: Meir Goldenberg
          isHf: false
          isPro: false
          name: drmeir
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;rmahfuz&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/rmahfuz\">@<span class=\"\
          underline\">rmahfuz</span></a></span>\n\n\t</span></span>  Why not compute\
          \ vectors for parts that contain at most 256 words and then add up these\
          \ vectors and normalize?</p>\n"
        raw: '@rmahfuz  Why not compute vectors for parts that contain at most 256
          words and then add up these vectors and normalize?'
        updatedAt: '2023-08-06T00:08:14.937Z'
      numEdits: 0
      reactions: []
    id: 64cee46ebf39f9c8be9c63d7
    type: comment
  author: drmeir
  content: '@rmahfuz  Why not compute vectors for parts that contain at most 256 words
    and then add up these vectors and normalize?'
  created_at: 2023-08-05 23:08:14+00:00
  edited: false
  hidden: false
  id: 64cee46ebf39f9c8be9c63d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/21276de914739614c2940207de6495e4.svg
      fullname: Ilian P
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ilianos
      type: user
    createdAt: '2023-09-07T13:14:01.000Z'
    data:
      edited: false
      editors:
      - Ilianos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.870190441608429
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/21276de914739614c2940207de6495e4.svg
          fullname: Ilian P
          isHf: false
          isPro: false
          name: Ilianos
          type: user
        html: '<p>I''m not sure if you''re all talking about the same unit! According
          to the model card, the model truncates all input (to the maximum of) <strong>256
          tokens</strong>. Not characters, not words, but <strong>tokens</strong>.</p>

          <p>By the way, on the MTEB Leaderboard (<a href="https://huggingface.co/spaces/mteb/leaderboard">https://huggingface.co/spaces/mteb/leaderboard</a>),
          this information about the context length seems to be wrong ("512"), at
          least for this model...</p>

          '
        raw: 'I''m not sure if you''re all talking about the same unit! According
          to the model card, the model truncates all input (to the maximum of) **256
          tokens**. Not characters, not words, but **tokens**.


          By the way, on the MTEB Leaderboard (https://huggingface.co/spaces/mteb/leaderboard),
          this information about the context length seems to be wrong ("512"), at
          least for this model...'
        updatedAt: '2023-09-07T13:14:01.243Z'
      numEdits: 0
      reactions: []
    id: 64f9cc99404370cbda86193e
    type: comment
  author: Ilianos
  content: 'I''m not sure if you''re all talking about the same unit! According to
    the model card, the model truncates all input (to the maximum of) **256 tokens**.
    Not characters, not words, but **tokens**.


    By the way, on the MTEB Leaderboard (https://huggingface.co/spaces/mteb/leaderboard),
    this information about the context length seems to be wrong ("512"), at least
    for this model...'
  created_at: 2023-09-07 12:14:01+00:00
  edited: false
  hidden: false
  id: 64f9cc99404370cbda86193e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/520b9e3418a19d3e442f5713613ef9b8.svg
      fullname: Meir Goldenberg
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: drmeir
      type: user
    createdAt: '2023-09-09T19:01:23.000Z'
    data:
      edited: false
      editors:
      - drmeir
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8533380031585693
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/520b9e3418a19d3e442f5713613ef9b8.svg
          fullname: Meir Goldenberg
          isHf: false
          isPro: false
          name: drmeir
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Ilianos&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Ilianos\">@<span class=\"\
          underline\">Ilianos</span></a></span>\n\n\t</span></span> Aren't tokens\
          \ words? If not, what is a token?</p>\n"
        raw: '@Ilianos Aren''t tokens words? If not, what is a token?'
        updatedAt: '2023-09-09T19:01:23.032Z'
      numEdits: 0
      reactions: []
    id: 64fcc1038c21ebb3dba71f0d
    type: comment
  author: drmeir
  content: '@Ilianos Aren''t tokens words? If not, what is a token?'
  created_at: 2023-09-09 18:01:23+00:00
  edited: false
  hidden: false
  id: 64fcc1038c21ebb3dba71f0d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/21276de914739614c2940207de6495e4.svg
      fullname: Ilian P
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ilianos
      type: user
    createdAt: '2023-09-10T05:54:36.000Z'
    data:
      edited: false
      editors:
      - Ilianos
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8873199224472046
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/21276de914739614c2940207de6495e4.svg
          fullname: Ilian P
          isHf: false
          isPro: false
          name: Ilianos
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;Ilianos&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Ilianos\"\
          >@<span class=\"underline\">Ilianos</span></a></span>\n\n\t</span></span>\
          \ Aren't tokens words? If not, what is a token?</p>\n</blockquote>\n<p>It\
          \ says on the model card: </p>\n<blockquote>\n<p>By default, input text\
          \ longer than 256 word pieces is truncated.</p>\n</blockquote>\n<p>The rest,\
          \ I'll let you find out on the internet :) </p>\n"
        raw: "> @Ilianos Aren't tokens words? If not, what is a token?\n\nIt says\
          \ on the model card: \n> By default, input text longer than 256 word pieces\
          \ is truncated.\n\nThe rest, I'll let you find out on the internet :) "
        updatedAt: '2023-09-10T05:54:36.083Z'
      numEdits: 0
      reactions: []
    id: 64fd5a1c39d541478e294ac7
    type: comment
  author: Ilianos
  content: "> @Ilianos Aren't tokens words? If not, what is a token?\n\nIt says on\
    \ the model card: \n> By default, input text longer than 256 word pieces is truncated.\n\
    \nThe rest, I'll let you find out on the internet :) "
  created_at: 2023-09-10 04:54:36+00:00
  edited: false
  hidden: false
  id: 64fd5a1c39d541478e294ac7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: sentence-transformers/all-MiniLM-L6-v2
repo_type: model
status: open
target_branch: null
title: Max Length
