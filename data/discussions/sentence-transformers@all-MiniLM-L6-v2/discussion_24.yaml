!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tygerwu
conflicting_files: null
created_at: 2023-07-28 09:42:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d7cce54301dc4e9e966bd32e28f9e86.svg
      fullname: tygerwu.gmail
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tygerwu
      type: user
    createdAt: '2023-07-28T10:42:43.000Z'
    data:
      edited: true
      editors:
      - tygerwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6006491780281067
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d7cce54301dc4e9e966bd32e28f9e86.svg
          fullname: tygerwu.gmail
          isHf: false
          isPro: false
          name: tygerwu
          type: user
        html: "<p>Hey, thansk for the great open source. I got stuck in the onnx model\
          \ and could you help me out ?<br>I exported  the onnx model by this command:\"\
          python3 -m transformers.onnx --model='sentence-transformers/all-MiniLM-L6-v2\"\
          .<br>I tested the onnx model using the following codes:</p>\n<pre><code>import\
          \ onnxruntime\nimport onnx \nimport numpy as np\nfrom transformers import\
          \ AutoTokenizer\nONNX_MODEL_PATH = '/xxx'\nonnx_session = onnxruntime.InferenceSession(ONNX_MODEL_PATH,providers=\
          \ ['CPUExecutionProvider'])\n\nsentences = [\"This is an example sentence\"\
          , \"Each sentence is converted\"]\ntokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n\
          \nouts = tokenizer(sentences, padding=True, truncation=True,return_tensors='np')\n\
          \n\ndef collate_tokenizer_out(outs):\n    def _cat_to_batch(data_lists):\n\
          \            return np.concatenate([np.expand_dims(data,axis=0) for data\
          \ in data_lists],axis=0)\n    input_ids = _cat_to_batch(outs['input_ids'])\n\
          \    attention_mask =_cat_to_batch(outs['attention_mask'])\n    token_type_ids\
          \ = _cat_to_batch(outs['token_type_ids'])\n    return {\n            'input_ids':input_ids,\n\
          \            'attention_mask':attention_mask,\n            'token_type_ids':token_type_ids\n\
          \        }\n\nembeddings = onnx_session.run([],input_feed=collate_tokenizer_out(outs))[0]\n\
          \nprint(embeddings)\n</code></pre>\n<p>And I got the results:</p>\n<pre><code>embedding_0\
          \ : [3.49345416e-01  3.27860445e-01  2.51529306e-01  4.09490079e-01........]\n\
          embedding_1 : [5.41010439e-01  6.43181384e-01  3.37637551e-02  1.27957715e-02........]\n\
          </code></pre>\n<p>Meanwhile, I encoded the same sentences using torch </p>\n\
          <pre><code>from sentence_transformers import SentenceTransformer\nsentences\
          \ = [\"This is an example sentence\", \"Each sentence is converted\"]\n\n\
          model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n\
          embeddings = model.encode(sentences)\nprint(embeddings)\n</code></pre>\n\
          <p>And the results were the folloiwngs, which were not aligned with onnx\
          \ model's</p>\n<pre><code>embedding_0 : [6.76569194e-02  6.34959415e-02\
          \  4.87131290e-02  7.93049857e-02........]\nembedding_1 : [8.64385664e-02\
          \  1.02762692e-01  5.39456820e-03  2.04446772e-03........]\n</code></pre>\n\
          <p>I have checked the ouputs of the tokenizer and they all are the same.<br>So\
          \ is there anything wrong with my onnx codes or the onnx model itself ?\
          \ </p>\n"
        raw: "Hey, thansk for the great open source. I got stuck in the onnx model\
          \ and could you help me out ? \nI exported  the onnx model by this command:\"\
          python3 -m transformers.onnx --model='sentence-transformers/all-MiniLM-L6-v2\"\
          . \nI tested the onnx model using the following codes:\n```\nimport onnxruntime\n\
          import onnx \nimport numpy as np\nfrom transformers import AutoTokenizer\n\
          ONNX_MODEL_PATH = '/xxx'\nonnx_session = onnxruntime.InferenceSession(ONNX_MODEL_PATH,providers=\
          \ ['CPUExecutionProvider'])\n\nsentences = [\"This is an example sentence\"\
          , \"Each sentence is converted\"]\ntokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n\
          \nouts = tokenizer(sentences, padding=True, truncation=True,return_tensors='np')\n\
          \n\ndef collate_tokenizer_out(outs):\n    def _cat_to_batch(data_lists):\n\
          \            return np.concatenate([np.expand_dims(data,axis=0) for data\
          \ in data_lists],axis=0)\n    input_ids = _cat_to_batch(outs['input_ids'])\n\
          \    attention_mask =_cat_to_batch(outs['attention_mask'])\n    token_type_ids\
          \ = _cat_to_batch(outs['token_type_ids'])\n    return {\n            'input_ids':input_ids,\n\
          \            'attention_mask':attention_mask,\n            'token_type_ids':token_type_ids\n\
          \        }\n\nembeddings = onnx_session.run([],input_feed=collate_tokenizer_out(outs))[0]\n\
          \nprint(embeddings)\n```\nAnd I got the results:\n```\nembedding_0 : [3.49345416e-01\
          \  3.27860445e-01  2.51529306e-01  4.09490079e-01........]\nembedding_1\
          \ : [5.41010439e-01  6.43181384e-01  3.37637551e-02  1.27957715e-02........]\n\
          ```\n\nMeanwhile, I encoded the same sentences using torch \n```\nfrom sentence_transformers\
          \ import SentenceTransformer\nsentences = [\"This is an example sentence\"\
          , \"Each sentence is converted\"]\n\nmodel = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n\
          embeddings = model.encode(sentences)\nprint(embeddings)\n```\nAnd the results\
          \ were the folloiwngs, which were not aligned with onnx model's\n```\nembedding_0\
          \ : [6.76569194e-02  6.34959415e-02  4.87131290e-02  7.93049857e-02........]\n\
          embedding_1 : [8.64385664e-02  1.02762692e-01  5.39456820e-03  2.04446772e-03........]\n\
          ```\nI have checked the ouputs of the tokenizer and they all are the same.\
          \ \nSo is there anything wrong with my onnx codes or the onnx model itself\
          \ ? "
        updatedAt: '2023-07-28T10:44:06.087Z'
      numEdits: 1
      reactions: []
    id: 64c39ba3c3633e5b92446bba
    type: comment
  author: tygerwu
  content: "Hey, thansk for the great open source. I got stuck in the onnx model and\
    \ could you help me out ? \nI exported  the onnx model by this command:\"python3\
    \ -m transformers.onnx --model='sentence-transformers/all-MiniLM-L6-v2\". \nI\
    \ tested the onnx model using the following codes:\n```\nimport onnxruntime\n\
    import onnx \nimport numpy as np\nfrom transformers import AutoTokenizer\nONNX_MODEL_PATH\
    \ = '/xxx'\nonnx_session = onnxruntime.InferenceSession(ONNX_MODEL_PATH,providers=\
    \ ['CPUExecutionProvider'])\n\nsentences = [\"This is an example sentence\", \"\
    Each sentence is converted\"]\ntokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n\
    \nouts = tokenizer(sentences, padding=True, truncation=True,return_tensors='np')\n\
    \n\ndef collate_tokenizer_out(outs):\n    def _cat_to_batch(data_lists):\n   \
    \         return np.concatenate([np.expand_dims(data,axis=0) for data in data_lists],axis=0)\n\
    \    input_ids = _cat_to_batch(outs['input_ids'])\n    attention_mask =_cat_to_batch(outs['attention_mask'])\n\
    \    token_type_ids = _cat_to_batch(outs['token_type_ids'])\n    return {\n  \
    \          'input_ids':input_ids,\n            'attention_mask':attention_mask,\n\
    \            'token_type_ids':token_type_ids\n        }\n\nembeddings = onnx_session.run([],input_feed=collate_tokenizer_out(outs))[0]\n\
    \nprint(embeddings)\n```\nAnd I got the results:\n```\nembedding_0 : [3.49345416e-01\
    \  3.27860445e-01  2.51529306e-01  4.09490079e-01........]\nembedding_1 : [5.41010439e-01\
    \  6.43181384e-01  3.37637551e-02  1.27957715e-02........]\n```\n\nMeanwhile,\
    \ I encoded the same sentences using torch \n```\nfrom sentence_transformers import\
    \ SentenceTransformer\nsentences = [\"This is an example sentence\", \"Each sentence\
    \ is converted\"]\n\nmodel = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n\
    embeddings = model.encode(sentences)\nprint(embeddings)\n```\nAnd the results\
    \ were the folloiwngs, which were not aligned with onnx model's\n```\nembedding_0\
    \ : [6.76569194e-02  6.34959415e-02  4.87131290e-02  7.93049857e-02........]\n\
    embedding_1 : [8.64385664e-02  1.02762692e-01  5.39456820e-03  2.04446772e-03........]\n\
    ```\nI have checked the ouputs of the tokenizer and they all are the same. \n\
    So is there anything wrong with my onnx codes or the onnx model itself ? "
  created_at: 2023-07-28 09:42:43+00:00
  edited: true
  hidden: false
  id: 64c39ba3c3633e5b92446bba
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d7cce54301dc4e9e966bd32e28f9e86.svg
      fullname: tygerwu.gmail
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tygerwu
      type: user
    createdAt: '2023-08-03T12:00:08.000Z'
    data:
      edited: true
      editors:
      - tygerwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5781270861625671
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d7cce54301dc4e9e966bd32e28f9e86.svg
          fullname: tygerwu.gmail
          isHf: false
          isPro: false
          name: tygerwu
          type: user
        html: ''
        raw: '


          '
        updatedAt: '2023-08-03T12:00:38.082Z'
      numEdits: 1
      reactions: []
      relatedEventId: 64cb96c8bf67d9b76e823e84
    id: 64cb96c8bf67d9b76e823e7f
    type: comment
  author: tygerwu
  content: '


    '
  created_at: 2023-08-03 11:00:08+00:00
  edited: true
  hidden: false
  id: 64cb96c8bf67d9b76e823e7f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/6d7cce54301dc4e9e966bd32e28f9e86.svg
      fullname: tygerwu.gmail
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tygerwu
      type: user
    createdAt: '2023-08-03T12:00:08.000Z'
    data:
      status: closed
    id: 64cb96c8bf67d9b76e823e84
    type: status-change
  author: tygerwu
  created_at: 2023-08-03 11:00:08+00:00
  id: 64cb96c8bf67d9b76e823e84
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d7cce54301dc4e9e966bd32e28f9e86.svg
      fullname: tygerwu.gmail
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tygerwu
      type: user
    createdAt: '2023-08-03T12:02:13.000Z'
    data:
      edited: false
      editors:
      - tygerwu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7084043025970459
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d7cce54301dc4e9e966bd32e28f9e86.svg
          fullname: tygerwu.gmail
          isHf: false
          isPro: false
          name: tygerwu
          type: user
        html: '<p>I fixed this problem by adding normalize</p>

          <pre><code>embeddings = F.normalize(torch.from_numpy(embeddings), p=2, dim=1)

          </code></pre>

          '
        raw: 'I fixed this problem by adding normalize

          ```

          embeddings = F.normalize(torch.from_numpy(embeddings), p=2, dim=1)

          ```'
        updatedAt: '2023-08-03T12:02:13.923Z'
      numEdits: 0
      reactions: []
    id: 64cb9745aa31c5d4ec5af268
    type: comment
  author: tygerwu
  content: 'I fixed this problem by adding normalize

    ```

    embeddings = F.normalize(torch.from_numpy(embeddings), p=2, dim=1)

    ```'
  created_at: 2023-08-03 11:02:13+00:00
  edited: false
  hidden: false
  id: 64cb9745aa31c5d4ec5af268
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 24
repo_id: sentence-transformers/all-MiniLM-L6-v2
repo_type: model
status: closed
target_branch: null
title: The ONNX model is misaligned with the torch model
