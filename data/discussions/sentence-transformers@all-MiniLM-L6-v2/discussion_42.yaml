!!python/object:huggingface_hub.community.DiscussionWithDetails
author: YouXiang
conflicting_files: null
created_at: 2024-01-19 02:34:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ec38b303628463eae493015eaf40e8d9.svg
      fullname: 'Chong '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YouXiang
      type: user
    createdAt: '2024-01-19T02:34:23.000Z'
    data:
      edited: false
      editors:
      - YouXiang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9399500489234924
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ec38b303628463eae493015eaf40e8d9.svg
          fullname: 'Chong '
          isHf: false
          isPro: false
          name: YouXiang
          type: user
        html: '<p>I am working on project when to check the similarity between two
          sentences. I have tried a lot of model to do comparison to find out that
          which model is the best especially for spacy large language model, en_core_web_lg
          and all-miniLM-L6-v2. My question is:</p>

          <ol>

          <li>is there any comparison to show that which model is performed well?
          (all-miniLM-L6-v2 and en_core_web_lg).<br>2.If I am using all-miniLM-L6-v2,
          do I still need to do preprocessing? (all the NLP preprocessing task: tokenize,
          extract key word.</li>

          <li>How can I look in-dept of how both model work?</li>

          </ol>

          '
        raw: "I am working on project when to check the similarity between two sentences.\
          \ I have tried a lot of model to do comparison to find out that which model\
          \ is the best especially for spacy large language model, en_core_web_lg\
          \ and all-miniLM-L6-v2. My question is:\r\n1. is there any comparison to\
          \ show that which model is performed well? (all-miniLM-L6-v2 and en_core_web_lg).\r\
          \n2.If I am using all-miniLM-L6-v2, do I still need to do preprocessing?\
          \ (all the NLP preprocessing task: tokenize, extract key word.\r\n3. How\
          \ can I look in-dept of how both model work?"
        updatedAt: '2024-01-19T02:34:23.555Z'
      numEdits: 0
      reactions: []
    id: 65a9dfaf4d12c80c3d253dff
    type: comment
  author: YouXiang
  content: "I am working on project when to check the similarity between two sentences.\
    \ I have tried a lot of model to do comparison to find out that which model is\
    \ the best especially for spacy large language model, en_core_web_lg and all-miniLM-L6-v2.\
    \ My question is:\r\n1. is there any comparison to show that which model is performed\
    \ well? (all-miniLM-L6-v2 and en_core_web_lg).\r\n2.If I am using all-miniLM-L6-v2,\
    \ do I still need to do preprocessing? (all the NLP preprocessing task: tokenize,\
    \ extract key word.\r\n3. How can I look in-dept of how both model work?"
  created_at: 2024-01-19 02:34:23+00:00
  edited: false
  hidden: false
  id: 65a9dfaf4d12c80c3d253dff
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
      fullname: Tom Aarsen
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: tomaarsen
      type: user
    createdAt: '2024-01-19T13:44:06.000Z'
    data:
      edited: false
      editors:
      - tomaarsen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8434423804283142
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png?w=200&h=200&f=face
          fullname: Tom Aarsen
          isHf: true
          isPro: false
          name: tomaarsen
          type: user
        html: '<p>Hello!</p>

          <p>These models are quite different. <code>all-MiniLM-L6-v2</code> is a
          Sentence Transformer model trained with the purpose of producing embeddings
          that can be used to compute sentence similarities. On the other hand, <a
          rel="nofollow" href="https://spacy.io/models/en#en_core_web_lg"><code>en_core_web_lg</code></a>
          is a large spaCy model with a lot of different components. It does technically
          also seem to have a "token-to-vector" component, but I would be surprised
          if it was better than <code>all-MiniLM-L6-v2</code>.</p>

          <p>In short, <code>all-MiniLM-L6-v2</code> is created with your task in
          mind, and <code>en_core_web_lg</code> is not.</p>

          <ol>

          <li>Not really, but primarily because <code>en_core_web_lg</code> is not
          on any embedding benchmarks.</li>

          <li>No. See <a rel="nofollow" href="https://sbert.net/docs/usage/semantic_textual_similarity.html">this
          documentation</a> for information on the usage, you can just provide full
          sentences, no tokenization necessary.</li>

          <li>You can use <a rel="nofollow" href="https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/#the-tldr">this
          guide</a> to get a bit of information on how this Sentence Transformer model
          works. As for <code>en_core_web_lg</code>, you can try looking at the <a
          rel="nofollow" href="https://spacy.io/models">spaCy models documentation</a>
          perhaps.</li>

          </ol>

          <ul>

          <li>Tom Aarsen</li>

          </ul>

          '
        raw: "Hello!\n\nThese models are quite different. `all-MiniLM-L6-v2` is a\
          \ Sentence Transformer model trained with the purpose of producing embeddings\
          \ that can be used to compute sentence similarities. On the other hand,\
          \ [`en_core_web_lg`](https://spacy.io/models/en#en_core_web_lg) is a large\
          \ spaCy model with a lot of different components. It does technically also\
          \ seem to have a \"token-to-vector\" component, but I would be surprised\
          \ if it was better than `all-MiniLM-L6-v2`.\n\nIn short, `all-MiniLM-L6-v2`\
          \ is created with your task in mind, and `en_core_web_lg` is not.\n\n1.\
          \ Not really, but primarily because `en_core_web_lg` is not on any embedding\
          \ benchmarks.\n2. No. See [this documentation](https://sbert.net/docs/usage/semantic_textual_similarity.html)\
          \ for information on the usage, you can just provide full sentences, no\
          \ tokenization necessary.\n3. You can use [this guide](https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/#the-tldr)\
          \ to get a bit of information on how this Sentence Transformer model works.\
          \ As for `en_core_web_lg`, you can try looking at the [spaCy models documentation](https://spacy.io/models)\
          \ perhaps.\n\n- Tom Aarsen\n "
        updatedAt: '2024-01-19T13:44:06.395Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - YouXiang
    id: 65aa7ca6b68db4f26edaa29b
    type: comment
  author: tomaarsen
  content: "Hello!\n\nThese models are quite different. `all-MiniLM-L6-v2` is a Sentence\
    \ Transformer model trained with the purpose of producing embeddings that can\
    \ be used to compute sentence similarities. On the other hand, [`en_core_web_lg`](https://spacy.io/models/en#en_core_web_lg)\
    \ is a large spaCy model with a lot of different components. It does technically\
    \ also seem to have a \"token-to-vector\" component, but I would be surprised\
    \ if it was better than `all-MiniLM-L6-v2`.\n\nIn short, `all-MiniLM-L6-v2` is\
    \ created with your task in mind, and `en_core_web_lg` is not.\n\n1. Not really,\
    \ but primarily because `en_core_web_lg` is not on any embedding benchmarks.\n\
    2. No. See [this documentation](https://sbert.net/docs/usage/semantic_textual_similarity.html)\
    \ for information on the usage, you can just provide full sentences, no tokenization\
    \ necessary.\n3. You can use [this guide](https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/#the-tldr)\
    \ to get a bit of information on how this Sentence Transformer model works. As\
    \ for `en_core_web_lg`, you can try looking at the [spaCy models documentation](https://spacy.io/models)\
    \ perhaps.\n\n- Tom Aarsen\n "
  created_at: 2024-01-19 13:44:06+00:00
  edited: false
  hidden: false
  id: 65aa7ca6b68db4f26edaa29b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ec38b303628463eae493015eaf40e8d9.svg
      fullname: 'Chong '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YouXiang
      type: user
    createdAt: '2024-01-20T09:06:25.000Z'
    data:
      edited: false
      editors:
      - YouXiang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9789138436317444
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ec38b303628463eae493015eaf40e8d9.svg
          fullname: 'Chong '
          isHf: false
          isPro: false
          name: YouXiang
          type: user
        html: '<p>Hi!</p>

          <p>Thanks for the replying, I have a better understanding on the difference
          between these two models now!</p>

          '
        raw: 'Hi!


          Thanks for the replying, I have a better understanding on the difference
          between these two models now!


          '
        updatedAt: '2024-01-20T09:06:25.638Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - tomaarsen
    id: 65ab8d110150f64adf1cc861
    type: comment
  author: YouXiang
  content: 'Hi!


    Thanks for the replying, I have a better understanding on the difference between
    these two models now!


    '
  created_at: 2024-01-20 09:06:25+00:00
  edited: false
  hidden: false
  id: 65ab8d110150f64adf1cc861
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 42
repo_id: sentence-transformers/all-MiniLM-L6-v2
repo_type: model
status: open
target_branch: null
title: sentence similarity between spacy and sentence-transformer
