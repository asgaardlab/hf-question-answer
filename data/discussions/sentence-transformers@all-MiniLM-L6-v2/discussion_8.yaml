!!python/object:huggingface_hub.community.DiscussionWithDetails
author: woisme
conflicting_files: null
created_at: 2022-11-18 10:08:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1631866833249-61444dafa8f4f7baca30522f.jpeg?w=200&h=200&f=face
      fullname: Wo King
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: woisme
      type: user
    createdAt: '2022-11-18T10:08:03.000Z'
    data:
      edited: false
      editors:
      - woisme
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1631866833249-61444dafa8f4f7baca30522f.jpeg?w=200&h=200&f=face
          fullname: Wo King
          isHf: false
          isPro: false
          name: woisme
          type: user
        html: '<p>Hi,</p>

          <p>We are using your wonderful model for intent matching. It works great
          but of course we have some ethical issues. Because of the clustering, of
          course Hitler matches with Jews, Muslim with Terrorism. You can see why
          this is an issue. We are confident we can mitigate that with a list of pair
          of words as a moderation pre filter. Also, of course on a practical level
          Yes/No. Have you come across this and is there a way that you would do it?</p>

          '
        raw: "Hi,\r\n\r\nWe are using your wonderful model for intent matching. It\
          \ works great but of course we have some ethical issues. Because of the\
          \ clustering, of course Hitler matches with Jews, Muslim with Terrorism.\
          \ You can see why this is an issue. We are confident we can mitigate that\
          \ with a list of pair of words as a moderation pre filter. Also, of course\
          \ on a practical level Yes/No. Have you come across this and is there a\
          \ way that you would do it?"
        updatedAt: '2022-11-18T10:08:03.367Z'
      numEdits: 0
      reactions: []
    id: 63775983c32e3fde29c67e78
    type: comment
  author: woisme
  content: "Hi,\r\n\r\nWe are using your wonderful model for intent matching. It works\
    \ great but of course we have some ethical issues. Because of the clustering,\
    \ of course Hitler matches with Jews, Muslim with Terrorism. You can see why this\
    \ is an issue. We are confident we can mitigate that with a list of pair of words\
    \ as a moderation pre filter. Also, of course on a practical level Yes/No. Have\
    \ you come across this and is there a way that you would do it?"
  created_at: 2022-11-18 10:08:03+00:00
  edited: false
  hidden: false
  id: 63775983c32e3fde29c67e78
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: sentence-transformers/all-MiniLM-L6-v2
repo_type: model
status: open
target_branch: null
title: Moderation with Semantic Pairs of Words
