!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bilalmalik4321
conflicting_files: null
created_at: 2023-05-18 17:15:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/597c760085c3d8b4ff272154985ab69c.svg
      fullname: Bilal Malik
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bilalmalik4321
      type: user
    createdAt: '2023-05-18T18:15:54.000Z'
    data:
      edited: false
      editors:
      - bilalmalik4321
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/597c760085c3d8b4ff272154985ab69c.svg
          fullname: Bilal Malik
          isHf: false
          isPro: false
          name: bilalmalik4321
          type: user
        html: '<p>Has anyone used the embeddings to calculate sentence similarity
          like the example card? If so, what are the steps you took to do this?</p>

          '
        raw: Has anyone used the embeddings to calculate sentence similarity like
          the example card? If so, what are the steps you took to do this?
        updatedAt: '2023-05-18T18:15:54.825Z'
      numEdits: 0
      reactions: []
    id: 64666b5ae9906a259f34a9ca
    type: comment
  author: bilalmalik4321
  content: Has anyone used the embeddings to calculate sentence similarity like the
    example card? If so, what are the steps you took to do this?
  created_at: 2023-05-18 17:15:54+00:00
  edited: false
  hidden: false
  id: 64666b5ae9906a259f34a9ca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b0d062926cea6d5a43e869f8953a3d55.svg
      fullname: Mintu Johnson T J
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mintujohnson
      type: user
    createdAt: '2023-05-22T05:03:24.000Z'
    data:
      edited: true
      editors:
      - mintujohnson
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b0d062926cea6d5a43e869f8953a3d55.svg
          fullname: Mintu Johnson T J
          isHf: false
          isPro: false
          name: mintujohnson
          type: user
        html: '<p>This is actually a straight forward task, thanks to huggingface/sentence
          transformers utilities.<br>We just need to compare the embeddings using
          a similarity score utility.</p>

          <h2 id="step-1-encode-the-sentences-to-be-compared">Step 1: Encode the sentences
          to be compared</h2>

          <p>from sentence_transformers import SentenceTransformer</p>

          <p>model = SentenceTransformer(''all-MiniLM-L6-v2'')<br>embeddings1 = model.encode(sentences1,
          convert_to_tensor=True)<br>embeddings2 = model.encode(sentences2, convert_to_tensor=True)</p>

          <p>(where, sentencs1 and sentences2 are list of sentences(strings))</p>

          <h2 id="step-2-compute-the-similarity-using-a-similarity-matrix">Step 2:
          Compute the similarity using a similarity matrix</h2>

          <p>(cosine similarity or dot product)</p>

          <p>from sentence_transformers import util<br>cosine_scores = util.cos_sim(embeddings1,
          embeddings2)</p>

          <h2 id="step-3-output-the-pairs-with-their-score">Step 3: Output the pairs
          with their score</h2>

          <p>for i in range(len(sentences1)): print("{} \t\t {} \t\t Score: {:.4f}".format(sentences1[i],
          sentences2[i], cosine_scores[i][i]))</p>

          <p>For more references, you can visit Sentence-Transformers website:<br><a
          rel="nofollow" href="https://www.sbert.net/docs/usage/semantic_textual_similarity.html">https://www.sbert.net/docs/usage/semantic_textual_similarity.html</a></p>

          '
        raw: 'This is actually a straight forward task, thanks to huggingface/sentence
          transformers utilities.

          We just need to compare the embeddings using a similarity score utility.


          ## Step 1: Encode the sentences to be compared


          from sentence_transformers import SentenceTransformer


          model = SentenceTransformer(''all-MiniLM-L6-v2'')

          embeddings1 = model.encode(sentences1, convert_to_tensor=True)

          embeddings2 = model.encode(sentences2, convert_to_tensor=True)


          (where, sentencs1 and sentences2 are list of sentences(strings))


          ## Step 2: Compute the similarity using a similarity matrix

          (cosine similarity or dot product)


          from sentence_transformers import util

          cosine_scores = util.cos_sim(embeddings1, embeddings2)


          ## Step 3: Output the pairs with their score


          for i in range(len(sentences1)): print("{} \t\t {} \t\t Score: {:.4f}".format(sentences1[i],
          sentences2[i], cosine_scores[i][i]))


          For more references, you can visit Sentence-Transformers website:

          https://www.sbert.net/docs/usage/semantic_textual_similarity.html'
        updatedAt: '2023-05-22T06:30:27.383Z'
      numEdits: 1
      reactions:
      - count: 5
        reaction: "\U0001F44D"
        users:
        - ucalyptus
        - MarcBauer-LM
        - Tarun23
        - Ilianos
        - ashwini-maurya
    id: 646af79c13396ee0a570fd6f
    type: comment
  author: mintujohnson
  content: 'This is actually a straight forward task, thanks to huggingface/sentence
    transformers utilities.

    We just need to compare the embeddings using a similarity score utility.


    ## Step 1: Encode the sentences to be compared


    from sentence_transformers import SentenceTransformer


    model = SentenceTransformer(''all-MiniLM-L6-v2'')

    embeddings1 = model.encode(sentences1, convert_to_tensor=True)

    embeddings2 = model.encode(sentences2, convert_to_tensor=True)


    (where, sentencs1 and sentences2 are list of sentences(strings))


    ## Step 2: Compute the similarity using a similarity matrix

    (cosine similarity or dot product)


    from sentence_transformers import util

    cosine_scores = util.cos_sim(embeddings1, embeddings2)


    ## Step 3: Output the pairs with their score


    for i in range(len(sentences1)): print("{} \t\t {} \t\t Score: {:.4f}".format(sentences1[i],
    sentences2[i], cosine_scores[i][i]))


    For more references, you can visit Sentence-Transformers website:

    https://www.sbert.net/docs/usage/semantic_textual_similarity.html'
  created_at: 2023-05-22 04:03:24+00:00
  edited: true
  hidden: false
  id: 646af79c13396ee0a570fd6f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/88b9387084635ee4e65a29559bea332b.svg
      fullname: Gerison Kimathi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gerkim62
      type: user
    createdAt: '2023-08-19T06:01:36.000Z'
    data:
      edited: false
      editors:
      - gerkim62
      hidden: false
      identifiedLanguage:
        language: ca
        probability: 0.510992705821991
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/88b9387084635ee4e65a29559bea332b.svg
          fullname: Gerison Kimathi
          isHf: false
          isPro: false
          name: gerkim62
          type: user
        html: '<p>hi</p>

          '
        raw: hi
        updatedAt: '2023-08-19T06:01:36.348Z'
      numEdits: 0
      reactions: []
    id: 64e05ac002fa032de4f46e43
    type: comment
  author: gerkim62
  content: hi
  created_at: 2023-08-19 05:01:36+00:00
  edited: false
  hidden: false
  id: 64e05ac002fa032de4f46e43
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 16
repo_id: sentence-transformers/all-MiniLM-L6-v2
repo_type: model
status: open
target_branch: null
title: Using embeddings to do sentence similarity
