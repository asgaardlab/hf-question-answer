!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lindeer
conflicting_files: null
created_at: 2023-05-16 09:58:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/B14mfZxJEh4DkWIDa55lo.png?w=200&h=200&f=face
      fullname: Wesley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lindeer
      type: user
    createdAt: '2023-05-16T10:58:01.000Z'
    data:
      edited: true
      editors:
      - lindeer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/B14mfZxJEh4DkWIDa55lo.png?w=200&h=200&f=face
          fullname: Wesley
          isHf: false
          isPro: false
          name: lindeer
          type: user
        html: "<p>llama.cpp master@2a5ee023ad3 \u6A21\u578B\u4E0B\u8F7D\u7684\u6700\
          \u65B0\u7684</p>\n<pre><code>$ build/bin/main -m ../models/chinese-Alpaca-lora-7b-ggml/chinese-Alpaca-7b-plus-ggml-q5_1.bin\
          \ -ins --color -t 4\nmain: build = 554 (2a5ee02)\nmain: seed  = 1684234462\n\
          llama.cpp: loading model from ../models/chinese-Alpaca-lora-7b-ggml/chinese-Alpaca-7b-plus-ggml-q5_1.bin\n\
          llama_model_load_internal: format     = ggjt v1 (pre #1405)\nllama_model_load_internal:\
          \ n_vocab    = 49954\nllama_model_load_internal: n_ctx      = 512\nllama_model_load_internal:\
          \ n_embd     = 4096\nllama_model_load_internal: n_mult     = 256\nllama_model_load_internal:\
          \ n_head     = 32\nllama_model_load_internal: n_layer    = 32\nllama_model_load_internal:\
          \ n_rot      = 128\nllama_model_load_internal: ftype      = 9 (mostly Q5_1)\n\
          llama_model_load_internal: n_ff       = 11008\nllama_model_load_internal:\
          \ n_parts    = 1\nllama_model_load_internal: model size = 7B\nerror loading\
          \ model: this format is no longer supported (see https://github.com/ggerganov/llama.cpp/pull/1305)\n\
          llama_init_from_file: failed to load model\nllama_init_from_gpt_params:\
          \ error: failed to load model '../models/chinese-Alpaca-lora-7b-ggml/chinese-Alpaca-7b-plus-ggml-q5_1.bin'\n\
          main: error: unable to load model\n</code></pre>\n<p><code>ggjt v1</code>\
          \ \u683C\u5F0F\u662F\u4E0D\u652F\u6301\u4E86\u5417? \u662F\u53EA\u80FD\u7528\
          q8_0</p>\n"
        raw: "llama.cpp master@2a5ee023ad3 \u6A21\u578B\u4E0B\u8F7D\u7684\u6700\u65B0\
          \u7684\n```\n$ build/bin/main -m ../models/chinese-Alpaca-lora-7b-ggml/chinese-Alpaca-7b-plus-ggml-q5_1.bin\
          \ -ins --color -t 4\nmain: build = 554 (2a5ee02)\nmain: seed  = 1684234462\n\
          llama.cpp: loading model from ../models/chinese-Alpaca-lora-7b-ggml/chinese-Alpaca-7b-plus-ggml-q5_1.bin\n\
          llama_model_load_internal: format     = ggjt v1 (pre #1405)\nllama_model_load_internal:\
          \ n_vocab    = 49954\nllama_model_load_internal: n_ctx      = 512\nllama_model_load_internal:\
          \ n_embd     = 4096\nllama_model_load_internal: n_mult     = 256\nllama_model_load_internal:\
          \ n_head     = 32\nllama_model_load_internal: n_layer    = 32\nllama_model_load_internal:\
          \ n_rot      = 128\nllama_model_load_internal: ftype      = 9 (mostly Q5_1)\n\
          llama_model_load_internal: n_ff       = 11008\nllama_model_load_internal:\
          \ n_parts    = 1\nllama_model_load_internal: model size = 7B\nerror loading\
          \ model: this format is no longer supported (see https://github.com/ggerganov/llama.cpp/pull/1305)\n\
          llama_init_from_file: failed to load model\nllama_init_from_gpt_params:\
          \ error: failed to load model '../models/chinese-Alpaca-lora-7b-ggml/chinese-Alpaca-7b-plus-ggml-q5_1.bin'\n\
          main: error: unable to load model\n```\n`ggjt v1` \u683C\u5F0F\u662F\u4E0D\
          \u652F\u6301\u4E86\u5417? \u662F\u53EA\u80FD\u7528q8_0"
        updatedAt: '2023-05-16T11:07:19.278Z'
      numEdits: 2
      reactions: []
    id: 646361b9c615cbc124470576
    type: comment
  author: lindeer
  content: "llama.cpp master@2a5ee023ad3 \u6A21\u578B\u4E0B\u8F7D\u7684\u6700\u65B0\
    \u7684\n```\n$ build/bin/main -m ../models/chinese-Alpaca-lora-7b-ggml/chinese-Alpaca-7b-plus-ggml-q5_1.bin\
    \ -ins --color -t 4\nmain: build = 554 (2a5ee02)\nmain: seed  = 1684234462\nllama.cpp:\
    \ loading model from ../models/chinese-Alpaca-lora-7b-ggml/chinese-Alpaca-7b-plus-ggml-q5_1.bin\n\
    llama_model_load_internal: format     = ggjt v1 (pre #1405)\nllama_model_load_internal:\
    \ n_vocab    = 49954\nllama_model_load_internal: n_ctx      = 512\nllama_model_load_internal:\
    \ n_embd     = 4096\nllama_model_load_internal: n_mult     = 256\nllama_model_load_internal:\
    \ n_head     = 32\nllama_model_load_internal: n_layer    = 32\nllama_model_load_internal:\
    \ n_rot      = 128\nllama_model_load_internal: ftype      = 9 (mostly Q5_1)\n\
    llama_model_load_internal: n_ff       = 11008\nllama_model_load_internal: n_parts\
    \    = 1\nllama_model_load_internal: model size = 7B\nerror loading model: this\
    \ format is no longer supported (see https://github.com/ggerganov/llama.cpp/pull/1305)\n\
    llama_init_from_file: failed to load model\nllama_init_from_gpt_params: error:\
    \ failed to load model '../models/chinese-Alpaca-lora-7b-ggml/chinese-Alpaca-7b-plus-ggml-q5_1.bin'\n\
    main: error: unable to load model\n```\n`ggjt v1` \u683C\u5F0F\u662F\u4E0D\u652F\
    \u6301\u4E86\u5417? \u662F\u53EA\u80FD\u7528q8_0"
  created_at: 2023-05-16 09:58:01+00:00
  edited: true
  hidden: false
  id: 646361b9c615cbc124470576
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/B14mfZxJEh4DkWIDa55lo.png?w=200&h=200&f=face
      fullname: Wesley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lindeer
      type: user
    createdAt: '2023-05-16T11:12:12.000Z'
    data:
      edited: false
      editors:
      - lindeer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/B14mfZxJEh4DkWIDa55lo.png?w=200&h=200&f=face
          fullname: Wesley
          isHf: false
          isPro: false
          name: lindeer
          type: user
        html: "<p>\u89E3\u51B3\u4E86\uFF0Cllama.cpp\u7684\u4EE3\u7801\u5207\u5230\u8FD9\
          \u4E2Acommit(b608b55a3ea)\u5C31\u53EF\u4EE5\u8FD0\u884C\u4E86\u3002</p>\n"
        raw: "\u89E3\u51B3\u4E86\uFF0Cllama.cpp\u7684\u4EE3\u7801\u5207\u5230\u8FD9\
          \u4E2Acommit(b608b55a3ea)\u5C31\u53EF\u4EE5\u8FD0\u884C\u4E86\u3002"
        updatedAt: '2023-05-16T11:12:12.644Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6463650cab15db2fa5675ddd
    id: 6463650cab15db2fa5675ddc
    type: comment
  author: lindeer
  content: "\u89E3\u51B3\u4E86\uFF0Cllama.cpp\u7684\u4EE3\u7801\u5207\u5230\u8FD9\u4E2A\
    commit(b608b55a3ea)\u5C31\u53EF\u4EE5\u8FD0\u884C\u4E86\u3002"
  created_at: 2023-05-16 10:12:12+00:00
  edited: false
  hidden: false
  id: 6463650cab15db2fa5675ddc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/B14mfZxJEh4DkWIDa55lo.png?w=200&h=200&f=face
      fullname: Wesley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lindeer
      type: user
    createdAt: '2023-05-16T11:12:12.000Z'
    data:
      status: closed
    id: 6463650cab15db2fa5675ddd
    type: status-change
  author: lindeer
  created_at: 2023-05-16 10:12:12+00:00
  id: 6463650cab15db2fa5675ddd
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Billsfriend/chinese-Alpaca-7b-plus-ggml-q8_0
repo_type: model
status: closed
target_branch: null
title: 'error loading q5_1: this format is no longer supported'
