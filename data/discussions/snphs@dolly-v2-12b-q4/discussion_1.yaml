!!python/object:huggingface_hub.community.DiscussionWithDetails
author: vovalive
conflicting_files: null
created_at: 2023-04-14 10:43:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ca7a90e1eb456dcc5c6f409a746a4264.svg
      fullname: Vladimir Naumov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vovalive
      type: user
    createdAt: '2023-04-14T11:43:20.000Z'
    data:
      edited: false
      editors:
      - vovalive
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ca7a90e1eb456dcc5c6f409a746a4264.svg
          fullname: Vladimir Naumov
          isHf: false
          isPro: false
          name: vovalive
          type: user
        html: '<p>Hi! I need help with running this model in cformers. What command
          do I need to execute after installing cformers ? </p>

          '
        raw: 'Hi! I need help with running this model in cformers. What command do
          I need to execute after installing cformers ? '
        updatedAt: '2023-04-14T11:43:20.061Z'
      numEdits: 0
      reactions: []
    id: 64393c580989db052b5f32aa
    type: comment
  author: vovalive
  content: 'Hi! I need help with running this model in cformers. What command do I
    need to execute after installing cformers ? '
  created_at: 2023-04-14 10:43:20+00:00
  edited: false
  hidden: false
  id: 64393c580989db052b5f32aa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6401c8c9f98fbc64bcd7dca1/MOSgc_mPbfUZ-354osy1v.png?w=200&h=200&f=face
      fullname: FBL
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: fblgit
      type: user
    createdAt: '2023-04-14T15:52:18.000Z'
    data:
      edited: false
      editors:
      - fblgit
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6401c8c9f98fbc64bcd7dca1/MOSgc_mPbfUZ-354osy1v.png?w=200&h=200&f=face
          fullname: FBL
          isHf: false
          isPro: true
          name: fblgit
          type: user
        html: '<p>this doesnt works.<br>u can compile cformers and check it by yourself.</p>

          '
        raw: 'this doesnt works.

          u can compile cformers and check it by yourself.'
        updatedAt: '2023-04-14T15:52:18.213Z'
      numEdits: 0
      reactions: []
    id: 643976b20cb95b3dbc8f8c48
    type: comment
  author: fblgit
  content: 'this doesnt works.

    u can compile cformers and check it by yourself.'
  created_at: 2023-04-14 14:52:18+00:00
  edited: false
  hidden: false
  id: 643976b20cb95b3dbc8f8c48
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ca7a90e1eb456dcc5c6f409a746a4264.svg
      fullname: Vladimir Naumov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vovalive
      type: user
    createdAt: '2023-04-14T15:58:27.000Z'
    data:
      edited: false
      editors:
      - vovalive
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ca7a90e1eb456dcc5c6f409a746a4264.svg
          fullname: Vladimir Naumov
          isHf: false
          isPro: false
          name: vovalive
          type: user
        html: '<blockquote>

          <p>this doesnt works.<br>u can compile cformers and check it by yourself.</p>

          </blockquote>

          <p>I compiled cformers, but have no idea how to put the model there.</p>

          '
        raw: '> this doesnt works.

          > u can compile cformers and check it by yourself.


          I compiled cformers, but have no idea how to put the model there.'
        updatedAt: '2023-04-14T15:58:27.286Z'
      numEdits: 0
      reactions: []
    id: 64397823a6b2f278af721f03
    type: comment
  author: vovalive
  content: '> this doesnt works.

    > u can compile cformers and check it by yourself.


    I compiled cformers, but have no idea how to put the model there.'
  created_at: 2023-04-14 14:58:27+00:00
  edited: false
  hidden: false
  id: 64397823a6b2f278af721f03
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/72d2d1f902f8ce2204e3907f5c695027.svg
      fullname: Raymond Hendy
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: snphs
      type: user
    createdAt: '2023-04-14T17:15:55.000Z'
    data:
      edited: false
      editors:
      - snphs
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/72d2d1f902f8ce2204e3907f5c695027.svg
          fullname: Raymond Hendy
          isHf: false
          isPro: false
          name: snphs
          type: user
        html: "<p>Hello,  you need to add this in <code>MAP_MODEL_TO_URL</code> (<a\
          \ rel=\"nofollow\" href=\"https://github.com/NolanoOrg/cformers/blob/master/cformers/interface.py#L90\"\
          >https://github.com/NolanoOrg/cformers/blob/master/cformers/interface.py#L90</a>):</p>\n\
          <pre><code class=\"language-python\">    <span class=\"hljs-string\">'databricks/dolly-v2-12b'</span>:\
          \ ModelUrlMap(\n        cpp_model_name=<span class=\"hljs-string\">\"gptneox\"\
          </span>,\n        int4_fixed_zero=<span class=\"hljs-string\">\"https://huggingface.co/snphs/dolly-v2-12b-q4/resolve/main/int4_fixed_zero.bin\"\
          </span>),\n</code></pre>\n<p>Then you can use it like the other models in\
          \ the library.</p>\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">from</span> interface <span class=\"hljs-keyword\">import</span>\
          \ AutoInference <span class=\"hljs-keyword\">as</span> AI\nai = AI(<span\
          \ class=\"hljs-string\">\"databricks/dolly-v2-12b\"</span>)\nprompt = <span\
          \ class=\"hljs-string\">'Below is an instruction that describes a task.\
          \ Write a response that appropriately completes the request.\\n### Instruction:\\\
          nExplain to me the difference between nuclear fission and fusion.\\n###\
          \ Response:\\n'</span>\nx = ai.generate(prompt, num_tokens_to_generate=<span\
          \ class=\"hljs-number\">100</span>)\n<span class=\"hljs-built_in\">print</span>(x[<span\
          \ class=\"hljs-string\">'token_str'</span>])\n</code></pre>\n"
        raw: "Hello,  you need to add this in `MAP_MODEL_TO_URL` (https://github.com/NolanoOrg/cformers/blob/master/cformers/interface.py#L90):\n\
          ```python\n    'databricks/dolly-v2-12b': ModelUrlMap(\n        cpp_model_name=\"\
          gptneox\",\n        int4_fixed_zero=\"https://huggingface.co/snphs/dolly-v2-12b-q4/resolve/main/int4_fixed_zero.bin\"\
          ),\n```\n\nThen you can use it like the other models in the library.\n```python\n\
          from interface import AutoInference as AI\nai = AI(\"databricks/dolly-v2-12b\"\
          )\nprompt = 'Below is an instruction that describes a task. Write a response\
          \ that appropriately completes the request.\\n### Instruction:\\nExplain\
          \ to me the difference between nuclear fission and fusion.\\n### Response:\\\
          n'\nx = ai.generate(prompt, num_tokens_to_generate=100)\nprint(x['token_str'])\n\
          ```"
        updatedAt: '2023-04-14T17:15:55.885Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F917"
        users:
        - vovalive
        - AndreyBystrov
    id: 64398a4b9f49f6e6ee2477a0
    type: comment
  author: snphs
  content: "Hello,  you need to add this in `MAP_MODEL_TO_URL` (https://github.com/NolanoOrg/cformers/blob/master/cformers/interface.py#L90):\n\
    ```python\n    'databricks/dolly-v2-12b': ModelUrlMap(\n        cpp_model_name=\"\
    gptneox\",\n        int4_fixed_zero=\"https://huggingface.co/snphs/dolly-v2-12b-q4/resolve/main/int4_fixed_zero.bin\"\
    ),\n```\n\nThen you can use it like the other models in the library.\n```python\n\
    from interface import AutoInference as AI\nai = AI(\"databricks/dolly-v2-12b\"\
    )\nprompt = 'Below is an instruction that describes a task. Write a response that\
    \ appropriately completes the request.\\n### Instruction:\\nExplain to me the\
    \ difference between nuclear fission and fusion.\\n### Response:\\n'\nx = ai.generate(prompt,\
    \ num_tokens_to_generate=100)\nprint(x['token_str'])\n```"
  created_at: 2023-04-14 16:15:55+00:00
  edited: false
  hidden: false
  id: 64398a4b9f49f6e6ee2477a0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8234a0828460b3d2541bf2372d72fbc.svg
      fullname: "\u738B\u96EA"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GoooIce
      type: user
    createdAt: '2023-04-15T10:50:35.000Z'
    data:
      edited: false
      editors:
      - GoooIce
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8234a0828460b3d2541bf2372d72fbc.svg
          fullname: "\u738B\u96EA"
          isHf: false
          isPro: false
          name: GoooIce
          type: user
        html: "<p>maybe this way, should be good to get started.</p>\n<pre><code>pip\
          \ install cformers\n</code></pre>\n<p>then </p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\"\
          >import</span> os\n<span class=\"hljs-keyword\">import</span> wget\n<span\
          \ class=\"hljs-keyword\">import</span> sys\n<span class=\"hljs-keyword\"\
          >from</span> cformers <span class=\"hljs-keyword\">import</span> AutoInference\n\
          <span class=\"hljs-keyword\">from</span> cformers.interface <span class=\"\
          hljs-keyword\">import</span> MAP_MODEL_TO_URL, ModelUrlMap,compare_file_hash_sha256\n\
          \n<span class=\"hljs-keyword\">import</span> transformers <span class=\"\
          hljs-keyword\">as</span> tf <span class=\"hljs-comment\"># RIP TensorFlow</span>\n\
          \n<span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">\"\
          CFORMERS_CACHE_PATH\"</span> <span class=\"hljs-keyword\">in</span> os.environ:\n\
          \    CFORMERS_CACHE_PATH = os.environ[<span class=\"hljs-string\">\"CFORMERS_CACHE_PATH\"\
          </span>]\n<span class=\"hljs-keyword\">else</span>:\n    CFORMERS_CACHE_PATH\
          \ = os.path.join(os.path.expanduser(<span class=\"hljs-string\">\"~\"</span>),\
          \ <span class=\"hljs-string\">\".cformers\"</span>)\n\n<span class=\"hljs-keyword\"\
          >class</span> <span class=\"hljs-title class_\">AI</span>(<span class=\"\
          hljs-title class_ inherited__\">AutoInference</span>):\n    <span class=\"\
          hljs-string\">\"\"\"A wrapper for the C++ model.\"\"\"</span>\n    <span\
          \ class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >__init__</span>(<span class=\"hljs-params\">self, model_name, hash_sum=<span\
          \ class=\"hljs-string\">\"\"</span>, mode=<span class=\"hljs-string\">\"\
          int4_fixed_zero\"</span></span>):\n        self.model_name = model_name\n\
          \        self.mode = mode\n        self.hash_sum = hash_sum\n        self.cpp_model_name\
          \ = <span class=\"hljs-string\">\"gptneox\"</span>\n        self.model_url\
          \ = <span class=\"hljs-string\">\"https://huggingface.co/snphs/dolly-v2-12b-q4/resolve/main/int4_fixed_zero.bin\"\
          </span>\n        self.model_save_path = os.path.join(CFORMERS_CACHE_PATH,\
          \ <span class=\"hljs-string\">\"models\"</span>, model_name, mode)\n   \
          \     self.tokenizer = tf.AutoTokenizer.from_pretrained(model_name)\n\n\
          \        <span class=\"hljs-comment\"># Download the model if it doesn't\
          \ exist</span>\n        <span class=\"hljs-keyword\">if</span> <span class=\"\
          hljs-keyword\">not</span> os.path.exists(self.model_save_path):\n      \
          \      <span class=\"hljs-comment\"># Create the directory if it doesn't\
          \ exist</span>\n            parent_dir = os.path.dirname(self.model_save_path)\n\
          \            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\"\
          >not</span> os.path.exists(parent_dir):\n                os.makedirs(parent_dir)\n\
          \            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\"\
          >\"Downloading model...\"</span>)\n            <span class=\"hljs-keyword\"\
          >def</span> <span class=\"hljs-title function_\">bar_progress</span>(<span\
          \ class=\"hljs-params\">current, total, width=<span class=\"hljs-number\"\
          >80</span></span>):\n                progress_message = <span class=\"hljs-string\"\
          >\"Downloading: %d%% [%d / %d] bytes\"</span> % (current / total * <span\
          \ class=\"hljs-number\">100</span>, current, total)\n                sys.stdout.write(<span\
          \ class=\"hljs-string\">\"\\r\"</span> + progress_message)\n           \
          \     sys.stdout.flush()\n            wget.download(self.model_url, self.model_save_path,\
          \ bar=bar_progress)\n\n            <span class=\"hljs-built_in\">print</span>(<span\
          \ class=\"hljs-string\">\"Download complete!\"</span>)\n            compare_file_hash_sha256(self.model_save_path,\
          \ self.model_url.replace(<span class=\"hljs-string\">\"resolve\"</span>,\
          \ <span class=\"hljs-string\">\"blob\"</span>))\n\nai = AI(<span class=\"\
          hljs-string\">\"databricks/dolly-v2-12b\"</span>)\n\nprompt = <span class=\"\
          hljs-string\">'Below is an instruction that describes a task. Write a response\
          \ that appropriately completes the request.\\n### Instruction:\\nExplain\
          \ to me the difference between nuclear fission and fusion.\\n### Response:\\\
          n'</span>\nx = ai.generate(prompt, num_tokens_to_generate=<span class=\"\
          hljs-number\">100</span>)\n<span class=\"hljs-built_in\">print</span>(x[<span\
          \ class=\"hljs-string\">'token_str'</span>])\n</code></pre>\n"
        raw: "maybe this way, should be good to get started.\n```\npip install cformers\n\
          ```\n\nthen \n\n```python\nimport torch\nimport os\nimport wget\nimport\
          \ sys\nfrom cformers import AutoInference\nfrom cformers.interface import\
          \ MAP_MODEL_TO_URL, ModelUrlMap,compare_file_hash_sha256\n\nimport transformers\
          \ as tf # RIP TensorFlow\n\nif \"CFORMERS_CACHE_PATH\" in os.environ:\n\
          \    CFORMERS_CACHE_PATH = os.environ[\"CFORMERS_CACHE_PATH\"]\nelse:\n\
          \    CFORMERS_CACHE_PATH = os.path.join(os.path.expanduser(\"~\"), \".cformers\"\
          )\n\nclass AI(AutoInference):\n    \"\"\"A wrapper for the C++ model.\"\"\
          \"\n    def __init__(self, model_name, hash_sum=\"\", mode=\"int4_fixed_zero\"\
          ):\n        self.model_name = model_name\n        self.mode = mode\n   \
          \     self.hash_sum = hash_sum\n        self.cpp_model_name = \"gptneox\"\
          \n        self.model_url = \"https://huggingface.co/snphs/dolly-v2-12b-q4/resolve/main/int4_fixed_zero.bin\"\
          \n        self.model_save_path = os.path.join(CFORMERS_CACHE_PATH, \"models\"\
          , model_name, mode)\n        self.tokenizer = tf.AutoTokenizer.from_pretrained(model_name)\n\
          \n        # Download the model if it doesn't exist\n        if not os.path.exists(self.model_save_path):\n\
          \            # Create the directory if it doesn't exist\n            parent_dir\
          \ = os.path.dirname(self.model_save_path)\n            if not os.path.exists(parent_dir):\n\
          \                os.makedirs(parent_dir)\n            print(\"Downloading\
          \ model...\")\n            def bar_progress(current, total, width=80):\n\
          \                progress_message = \"Downloading: %d%% [%d / %d] bytes\"\
          \ % (current / total * 100, current, total)\n                sys.stdout.write(\"\
          \\r\" + progress_message)\n                sys.stdout.flush()\n        \
          \    wget.download(self.model_url, self.model_save_path, bar=bar_progress)\n\
          \n            print(\"Download complete!\")\n            compare_file_hash_sha256(self.model_save_path,\
          \ self.model_url.replace(\"resolve\", \"blob\"))\n\nai = AI(\"databricks/dolly-v2-12b\"\
          )\n\nprompt = 'Below is an instruction that describes a task. Write a response\
          \ that appropriately completes the request.\\n### Instruction:\\nExplain\
          \ to me the difference between nuclear fission and fusion.\\n### Response:\\\
          n'\nx = ai.generate(prompt, num_tokens_to_generate=100)\nprint(x['token_str'])\n\
          ```"
        updatedAt: '2023-04-15T10:50:35.257Z'
      numEdits: 0
      reactions: []
    id: 643a817b9462a44ea6e75d0f
    type: comment
  author: GoooIce
  content: "maybe this way, should be good to get started.\n```\npip install cformers\n\
    ```\n\nthen \n\n```python\nimport torch\nimport os\nimport wget\nimport sys\n\
    from cformers import AutoInference\nfrom cformers.interface import MAP_MODEL_TO_URL,\
    \ ModelUrlMap,compare_file_hash_sha256\n\nimport transformers as tf # RIP TensorFlow\n\
    \nif \"CFORMERS_CACHE_PATH\" in os.environ:\n    CFORMERS_CACHE_PATH = os.environ[\"\
    CFORMERS_CACHE_PATH\"]\nelse:\n    CFORMERS_CACHE_PATH = os.path.join(os.path.expanduser(\"\
    ~\"), \".cformers\")\n\nclass AI(AutoInference):\n    \"\"\"A wrapper for the\
    \ C++ model.\"\"\"\n    def __init__(self, model_name, hash_sum=\"\", mode=\"\
    int4_fixed_zero\"):\n        self.model_name = model_name\n        self.mode =\
    \ mode\n        self.hash_sum = hash_sum\n        self.cpp_model_name = \"gptneox\"\
    \n        self.model_url = \"https://huggingface.co/snphs/dolly-v2-12b-q4/resolve/main/int4_fixed_zero.bin\"\
    \n        self.model_save_path = os.path.join(CFORMERS_CACHE_PATH, \"models\"\
    , model_name, mode)\n        self.tokenizer = tf.AutoTokenizer.from_pretrained(model_name)\n\
    \n        # Download the model if it doesn't exist\n        if not os.path.exists(self.model_save_path):\n\
    \            # Create the directory if it doesn't exist\n            parent_dir\
    \ = os.path.dirname(self.model_save_path)\n            if not os.path.exists(parent_dir):\n\
    \                os.makedirs(parent_dir)\n            print(\"Downloading model...\"\
    )\n            def bar_progress(current, total, width=80):\n                progress_message\
    \ = \"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n\
    \                sys.stdout.write(\"\\r\" + progress_message)\n              \
    \  sys.stdout.flush()\n            wget.download(self.model_url, self.model_save_path,\
    \ bar=bar_progress)\n\n            print(\"Download complete!\")\n           \
    \ compare_file_hash_sha256(self.model_save_path, self.model_url.replace(\"resolve\"\
    , \"blob\"))\n\nai = AI(\"databricks/dolly-v2-12b\")\n\nprompt = 'Below is an\
    \ instruction that describes a task. Write a response that appropriately completes\
    \ the request.\\n### Instruction:\\nExplain to me the difference between nuclear\
    \ fission and fusion.\\n### Response:\\n'\nx = ai.generate(prompt, num_tokens_to_generate=100)\n\
    print(x['token_str'])\n```"
  created_at: 2023-04-15 09:50:35+00:00
  edited: false
  hidden: false
  id: 643a817b9462a44ea6e75d0f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8d69f7cb3197bd1870649f98c560991a.svg
      fullname: Andrey Bystrov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AndreyBystrov
      type: user
    createdAt: '2023-04-16T04:18:58.000Z'
    data:
      edited: true
      editors:
      - AndreyBystrov
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8d69f7cb3197bd1870649f98c560991a.svg
          fullname: Andrey Bystrov
          isHf: false
          isPro: false
          name: AndreyBystrov
          type: user
        html: '<p>Deleted my message.<br>I find my error!<br>thank you snphs!</p>

          '
        raw: 'Deleted my message.

          I find my error!

          thank you snphs!'
        updatedAt: '2023-04-16T04:24:05.337Z'
      numEdits: 2
      reactions: []
    id: 643b7732e756b67eee21a8dc
    type: comment
  author: AndreyBystrov
  content: 'Deleted my message.

    I find my error!

    thank you snphs!'
  created_at: 2023-04-16 03:18:58+00:00
  edited: true
  hidden: false
  id: 643b7732e756b67eee21a8dc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: snphs/dolly-v2-12b-q4
repo_type: model
status: open
target_branch: null
title: How to run it in cformers?
