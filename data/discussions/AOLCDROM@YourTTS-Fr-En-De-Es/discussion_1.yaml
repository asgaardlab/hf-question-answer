!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rSaita
conflicting_files: null
created_at: 2023-07-08 19:45:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0dd1d19a546632b18fee4146f7dc4ae7.svg
      fullname: Raluca Saita
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rSaita
      type: user
    createdAt: '2023-07-08T20:45:49.000Z'
    data:
      edited: false
      editors:
      - rSaita
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9423353672027588
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0dd1d19a546632b18fee4146f7dc4ae7.svg
          fullname: Raluca Saita
          isHf: false
          isPro: false
          name: rSaita
          type: user
        html: '<p>Hi and thank you for sharing this!<br>As a newbie, I was wondering
          if installing your models into Tortoise TTS is possible. If so, can you
          explain to me how it can be done?</p>

          '
        raw: "Hi and thank you for sharing this!\r\nAs a newbie, I was wondering if\
          \ installing your models into Tortoise TTS is possible. If so, can you explain\
          \ to me how it can be done?\r\n"
        updatedAt: '2023-07-08T20:45:49.232Z'
      numEdits: 0
      reactions: []
    id: 64a9cafd6cadc7aca5528cd6
    type: comment
  author: rSaita
  content: "Hi and thank you for sharing this!\r\nAs a newbie, I was wondering if\
    \ installing your models into Tortoise TTS is possible. If so, can you explain\
    \ to me how it can be done?\r\n"
  created_at: 2023-07-08 19:45:49+00:00
  edited: false
  hidden: false
  id: 64a9cafd6cadc7aca5528cd6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/967c9c1e0390c9c75e352ac2020a1bab.svg
      fullname: Bob Johnson
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: AOLCDROM
      type: user
    createdAt: '2023-07-09T03:21:00.000Z'
    data:
      edited: false
      editors:
      - AOLCDROM
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9489539265632629
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/967c9c1e0390c9c75e352ac2020a1bab.svg
          fullname: Bob Johnson
          isHf: false
          isPro: false
          name: AOLCDROM
          type: user
        html: '<p>This is a YourTTS model, so it''ll work with Coqui.  The other model
          I''ve posted is for Tortoise.  The YourTTS model is for Coqui TTS. I haven''t
          used it for anything else.</p>

          <p>The Tortoise model works with the various Tortoise forks, and possibly
          with the new Coqui implementation for Tortoise inference (Coqui doesn''t
          support Tortoise training. Tortoise training is a mess.)</p>

          <p>With the Tortoise WebUI: Drop the Tortoise model in "finetunes", put
          the tokenizer file in "tokenizers" (I think. You''ll fine another file called
          ipa.json or something. Put the new tokenizer in that directory). Switch
          the model and tokenizer in the settings. Reload.  Generally I like to ctrl+c
          shutdown and re-run start.sh. It loads faster from shutdown.</p>

          <p>For Coqui, direct model_path, and specify the new tokenizer somehow.
          I haven''t used Coqui''s Tortoise inference yet, so I don''t know the specifics.''</p>

          <p>These may be the last new public models I post. They''re really expensive
          and time consuming to make (This YourTTS model was ~60 full days of training),
          and the YouTube channel makes about thirty cents a day, so it doesn''t even
          come close to covering the electric.  If I kill this GPU with the heat I
          won''t be able to replace it :(</p>

          <p>If I can find any of the other open-source dataset models on my Google
          Drive, I''ll upload them to Huggingface.  They''re not fully trained, but
          some may be a good base for further training.</p>

          <p>This one is reasonably well trained, so you should get some decent output
          out of it.</p>

          '
        raw: 'This is a YourTTS model, so it''ll work with Coqui.  The other model
          I''ve posted is for Tortoise.  The YourTTS model is for Coqui TTS. I haven''t
          used it for anything else.


          The Tortoise model works with the various Tortoise forks, and possibly with
          the new Coqui implementation for Tortoise inference (Coqui doesn''t support
          Tortoise training. Tortoise training is a mess.)


          With the Tortoise WebUI: Drop the Tortoise model in "finetunes", put the
          tokenizer file in "tokenizers" (I think. You''ll fine another file called
          ipa.json or something. Put the new tokenizer in that directory). Switch
          the model and tokenizer in the settings. Reload.  Generally I like to ctrl+c
          shutdown and re-run start.sh. It loads faster from shutdown.


          For Coqui, direct model_path, and specify the new tokenizer somehow. I haven''t
          used Coqui''s Tortoise inference yet, so I don''t know the specifics.''


          These may be the last new public models I post. They''re really expensive
          and time consuming to make (This YourTTS model was ~60 full days of training),
          and the YouTube channel makes about thirty cents a day, so it doesn''t even
          come close to covering the electric.  If I kill this GPU with the heat I
          won''t be able to replace it :(


          If I can find any of the other open-source dataset models on my Google Drive,
          I''ll upload them to Huggingface.  They''re not fully trained, but some
          may be a good base for further training.


          This one is reasonably well trained, so you should get some decent output
          out of it.'
        updatedAt: '2023-07-09T03:21:00.130Z'
      numEdits: 0
      reactions: []
    id: 64aa279c81dda4817260a9bd
    type: comment
  author: AOLCDROM
  content: 'This is a YourTTS model, so it''ll work with Coqui.  The other model I''ve
    posted is for Tortoise.  The YourTTS model is for Coqui TTS. I haven''t used it
    for anything else.


    The Tortoise model works with the various Tortoise forks, and possibly with the
    new Coqui implementation for Tortoise inference (Coqui doesn''t support Tortoise
    training. Tortoise training is a mess.)


    With the Tortoise WebUI: Drop the Tortoise model in "finetunes", put the tokenizer
    file in "tokenizers" (I think. You''ll fine another file called ipa.json or something.
    Put the new tokenizer in that directory). Switch the model and tokenizer in the
    settings. Reload.  Generally I like to ctrl+c shutdown and re-run start.sh. It
    loads faster from shutdown.


    For Coqui, direct model_path, and specify the new tokenizer somehow. I haven''t
    used Coqui''s Tortoise inference yet, so I don''t know the specifics.''


    These may be the last new public models I post. They''re really expensive and
    time consuming to make (This YourTTS model was ~60 full days of training), and
    the YouTube channel makes about thirty cents a day, so it doesn''t even come close
    to covering the electric.  If I kill this GPU with the heat I won''t be able to
    replace it :(


    If I can find any of the other open-source dataset models on my Google Drive,
    I''ll upload them to Huggingface.  They''re not fully trained, but some may be
    a good base for further training.


    This one is reasonably well trained, so you should get some decent output out
    of it.'
  created_at: 2023-07-09 02:21:00+00:00
  edited: false
  hidden: false
  id: 64aa279c81dda4817260a9bd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: AOLCDROM/YourTTS-Fr-En-De-Es
repo_type: model
status: open
target_branch: null
title: Tortoise TTS Model Installation
