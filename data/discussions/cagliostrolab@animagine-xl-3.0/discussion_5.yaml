!!python/object:huggingface_hub.community.DiscussionWithDetails
author: chenNdG
conflicting_files: null
created_at: 2024-01-13 15:19:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5c2e6296339494d89d9f570a45431fac.svg
      fullname: chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chenNdG
      type: user
    createdAt: '2024-01-13T15:19:04.000Z'
    data:
      edited: false
      editors:
      - chenNdG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8959026336669922
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5c2e6296339494d89d9f570a45431fac.svg
          fullname: chen
          isHf: false
          isPro: false
          name: chenNdG
          type: user
        html: '<p>Hello, first of all I''d like to thank you for your work on this
          model, it really is of remarkable quality.<br>But i got one problem, when
          i try to upscale a image in img2img i always got :<br>"NansException: A
          tensor with all NaNs was produced in Unet. This could be either because
          there''s not enough precision to represent the picture, or because your
          video card does not support half type. Try setting the "Upcast cross attention
          layer to float32" option in Settings &gt; Stable Diffusion or using the
          --no-half commandline argument to fix this. Use --disable-nan-check commandline
          argument to disable this check."<br>I have a rtx 4060 16Go i don''t thinks
          it''s my GPU that get this error. I use A1111 V1.7, for the setting i use
          euler a 30 step scale x2 the initial image for exemeple 768*1024 upscale
          x2. I use sdxl default vae.<br>I''ve done several tests, with images generated
          from txt2img that I send in img2img and non-AI images, the non-AI ones work
          when I regenerate them normally, but when I activate the Ultimate Upscaler
          script it returns the error. For images created from txt2img, whether I
          activate the script or not, I always get the error.<br>I wanted to know
          if I''m the only one with this problem or if there are other people who
          have the same problems as me.</p>

          '
        raw: "Hello, first of all I'd like to thank you for your work on this model,\
          \ it really is of remarkable quality. \r\nBut i got one problem, when i\
          \ try to upscale a image in img2img i always got : \r\n\"NansException:\
          \ A tensor with all NaNs was produced in Unet. This could be either because\
          \ there's not enough precision to represent the picture, or because your\
          \ video card does not support half type. Try setting the \"Upcast cross\
          \ attention layer to float32\" option in Settings > Stable Diffusion or\
          \ using the --no-half commandline argument to fix this. Use --disable-nan-check\
          \ commandline argument to disable this check.\"\r\nI have a rtx 4060 16Go\
          \ i don't thinks it's my GPU that get this error. I use A1111 V1.7, for\
          \ the setting i use euler a 30 step scale x2 the initial image for exemeple\
          \ 768*1024 upscale x2. I use sdxl default vae.\r\nI've done several tests,\
          \ with images generated from txt2img that I send in img2img and non-AI images,\
          \ the non-AI ones work when I regenerate them normally, but when I activate\
          \ the Ultimate Upscaler script it returns the error. For images created\
          \ from txt2img, whether I activate the script or not, I always get the error.\r\
          \nI wanted to know if I'm the only one with this problem or if there are\
          \ other people who have the same problems as me."
        updatedAt: '2024-01-13T15:19:04.730Z'
      numEdits: 0
      reactions: []
    id: 65a2a9e80699df1be501c104
    type: comment
  author: chenNdG
  content: "Hello, first of all I'd like to thank you for your work on this model,\
    \ it really is of remarkable quality. \r\nBut i got one problem, when i try to\
    \ upscale a image in img2img i always got : \r\n\"NansException: A tensor with\
    \ all NaNs was produced in Unet. This could be either because there's not enough\
    \ precision to represent the picture, or because your video card does not support\
    \ half type. Try setting the \"Upcast cross attention layer to float32\" option\
    \ in Settings > Stable Diffusion or using the --no-half commandline argument to\
    \ fix this. Use --disable-nan-check commandline argument to disable this check.\"\
    \r\nI have a rtx 4060 16Go i don't thinks it's my GPU that get this error. I use\
    \ A1111 V1.7, for the setting i use euler a 30 step scale x2 the initial image\
    \ for exemeple 768*1024 upscale x2. I use sdxl default vae.\r\nI've done several\
    \ tests, with images generated from txt2img that I send in img2img and non-AI\
    \ images, the non-AI ones work when I regenerate them normally, but when I activate\
    \ the Ultimate Upscaler script it returns the error. For images created from txt2img,\
    \ whether I activate the script or not, I always get the error.\r\nI wanted to\
    \ know if I'm the only one with this problem or if there are other people who\
    \ have the same problems as me."
  created_at: 2024-01-13 15:19:04+00:00
  edited: false
  hidden: false
  id: 65a2a9e80699df1be501c104
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6365c8dbf31ef76df4042821/Gm7qar0zr-qUrg2ftEf3L.jpeg?w=200&h=200&f=face
      fullname: Furqanil Taqwa
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: Linaqruf
      type: user
    createdAt: '2024-01-13T15:26:48.000Z'
    data:
      edited: false
      editors:
      - Linaqruf
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8486470580101013
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6365c8dbf31ef76df4042821/Gm7qar0zr-qUrg2ftEf3L.jpeg?w=200&h=200&f=face
          fullname: Furqanil Taqwa
          isHf: false
          isPro: true
          name: Linaqruf
          type: user
        html: '<p>I think because the model is FP16, or the vae is FP32.<br>I propose
          2 ways:</p>

          <ol>

          <li>Use this <a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/blob/main/sdxl_vae.safetensors">VAE
          </a> instead, actually I think you don''t need external VAE because it''s
          already baked inside the model</li>

          <li>Set <code>--no-half</code> in the commandline args</li>

          </ol>

          '
        raw: 'I think because the model is FP16, or the vae is FP32.

          I propose 2 ways:

          1. Use this [VAE ](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/blob/main/sdxl_vae.safetensors)
          instead, actually I think you don''t need external VAE because it''s already
          baked inside the model

          2. Set `--no-half` in the commandline args '
        updatedAt: '2024-01-13T15:26:48.930Z'
      numEdits: 0
      reactions: []
    id: 65a2abb87ec6af0f954b0a27
    type: comment
  author: Linaqruf
  content: 'I think because the model is FP16, or the vae is FP32.

    I propose 2 ways:

    1. Use this [VAE ](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/blob/main/sdxl_vae.safetensors)
    instead, actually I think you don''t need external VAE because it''s already baked
    inside the model

    2. Set `--no-half` in the commandline args '
  created_at: 2024-01-13 15:26:48+00:00
  edited: false
  hidden: false
  id: 65a2abb87ec6af0f954b0a27
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5c2e6296339494d89d9f570a45431fac.svg
      fullname: chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chenNdG
      type: user
    createdAt: '2024-01-13T15:39:00.000Z'
    data:
      edited: false
      editors:
      - chenNdG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9936128258705139
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5c2e6296339494d89d9f570a45431fac.svg
          fullname: chen
          isHf: false
          isPro: false
          name: chenNdG
          type: user
        html: '<p>Thanks you very much !<br>I will try to change it and made some
          test !</p>

          '
        raw: 'Thanks you very much !

          I will try to change it and made some test !'
        updatedAt: '2024-01-13T15:39:00.334Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\u2764\uFE0F"
        users:
        - Linaqruf
        - Duskfallcrew
        - MonikaDreamer
    id: 65a2ae948ac0602820a48b6f
    type: comment
  author: chenNdG
  content: 'Thanks you very much !

    I will try to change it and made some test !'
  created_at: 2024-01-13 15:39:00+00:00
  edited: false
  hidden: false
  id: 65a2ae948ac0602820a48b6f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: cagliostrolab/animagine-xl-3.0
repo_type: model
status: open
target_branch: null
title: NansException Error when made Img2Img
