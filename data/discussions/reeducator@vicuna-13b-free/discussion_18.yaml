!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mancub
conflicting_files: null
created_at: 2023-04-30 21:31:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-04-30T22:31:04.000Z'
    data:
      edited: false
      editors:
      - mancub
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
          fullname: Man Cub
          isHf: false
          isPro: false
          name: mancub
          type: user
        html: '<p>I tried loading the bins just for testing (I use safetensors and
          GPU otherwise) but the models won''t load and produce an error in oobabooga/text-generation-webui:</p>

          <p>Traceback (most recent call last):<br>  File "/home/user/Envs/text-generation-webui_env/text-generation-webui/server.py",
          line 914, in <br>    shared.model, shared.tokenizer = load_model(shared.model_name)<br>  File
          "/home/user/Envs/text-generation-webui_env/text-generation-webui/modules/models.py",
          line 71, in load_model<br>    shared.model_type = find_model_type(model_name)<br>  File
          "/home/user/Envs/text-generation-webui_env/text-generation-webui/modules/models.py",
          line 59, in find_model_type<br>    config = AutoConfig.from_pretrained(Path(f''{shared.args.model_dir}/{model_name}''))<br>  File
          "/home/user/Envs/text-generation-webui_env/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py",
          line 916, in from_pretrained<br>    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path,
          **kwargs)<br>  File "/home/user/Envs/text-generation-webui_env/lib/python3.10/site-packages/transformers/configuration_utils.py",
          line 573, in get_config_dict<br>    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path,
          **kwargs)<br>  File "/home/user/Envs/text-generation-webui_env/lib/python3.10/site-packages/transformers/configuration_utils.py",
          line 661, in _get_config_dict<br>    raise EnvironmentError(<br>OSError:
          It looks like the config file at ''models/vicuna-13b-free-V4.3-q4_0.bin''
          is not a valid JSON file.</p>

          <p>An older ggml vicuna model I got elsewhere loads without issues.</p>

          <p>All of my code and modules are up to date.</p>

          '
        raw: "I tried loading the bins just for testing (I use safetensors and GPU\
          \ otherwise) but the models won't load and produce an error in oobabooga/text-generation-webui:\r\
          \n\r\nTraceback (most recent call last):\r\n  File \"/home/user/Envs/text-generation-webui_env/text-generation-webui/server.py\"\
          , line 914, in <module>\r\n    shared.model, shared.tokenizer = load_model(shared.model_name)\r\
          \n  File \"/home/user/Envs/text-generation-webui_env/text-generation-webui/modules/models.py\"\
          , line 71, in load_model\r\n    shared.model_type = find_model_type(model_name)\r\
          \n  File \"/home/user/Envs/text-generation-webui_env/text-generation-webui/modules/models.py\"\
          , line 59, in find_model_type\r\n    config = AutoConfig.from_pretrained(Path(f'{shared.args.model_dir}/{model_name}'))\r\
          \n  File \"/home/user/Envs/text-generation-webui_env/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 916, in from_pretrained\r\n    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path,\
          \ **kwargs)\r\n  File \"/home/user/Envs/text-generation-webui_env/lib/python3.10/site-packages/transformers/configuration_utils.py\"\
          , line 573, in get_config_dict\r\n    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path,\
          \ **kwargs)\r\n  File \"/home/user/Envs/text-generation-webui_env/lib/python3.10/site-packages/transformers/configuration_utils.py\"\
          , line 661, in _get_config_dict\r\n    raise EnvironmentError(\r\nOSError:\
          \ It looks like the config file at 'models/vicuna-13b-free-V4.3-q4_0.bin'\
          \ is not a valid JSON file.\r\n\r\nAn older ggml vicuna model I got elsewhere\
          \ loads without issues.\r\n\r\nAll of my code and modules are up to date."
        updatedAt: '2023-04-30T22:31:04.870Z'
      numEdits: 0
      reactions: []
    id: 644eec28030210812f459f2d
    type: comment
  author: mancub
  content: "I tried loading the bins just for testing (I use safetensors and GPU otherwise)\
    \ but the models won't load and produce an error in oobabooga/text-generation-webui:\r\
    \n\r\nTraceback (most recent call last):\r\n  File \"/home/user/Envs/text-generation-webui_env/text-generation-webui/server.py\"\
    , line 914, in <module>\r\n    shared.model, shared.tokenizer = load_model(shared.model_name)\r\
    \n  File \"/home/user/Envs/text-generation-webui_env/text-generation-webui/modules/models.py\"\
    , line 71, in load_model\r\n    shared.model_type = find_model_type(model_name)\r\
    \n  File \"/home/user/Envs/text-generation-webui_env/text-generation-webui/modules/models.py\"\
    , line 59, in find_model_type\r\n    config = AutoConfig.from_pretrained(Path(f'{shared.args.model_dir}/{model_name}'))\r\
    \n  File \"/home/user/Envs/text-generation-webui_env/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 916, in from_pretrained\r\n    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path,\
    \ **kwargs)\r\n  File \"/home/user/Envs/text-generation-webui_env/lib/python3.10/site-packages/transformers/configuration_utils.py\"\
    , line 573, in get_config_dict\r\n    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path,\
    \ **kwargs)\r\n  File \"/home/user/Envs/text-generation-webui_env/lib/python3.10/site-packages/transformers/configuration_utils.py\"\
    , line 661, in _get_config_dict\r\n    raise EnvironmentError(\r\nOSError: It\
    \ looks like the config file at 'models/vicuna-13b-free-V4.3-q4_0.bin' is not\
    \ a valid JSON file.\r\n\r\nAn older ggml vicuna model I got elsewhere loads without\
    \ issues.\r\n\r\nAll of my code and modules are up to date."
  created_at: 2023-04-30 21:31:04+00:00
  edited: false
  hidden: false
  id: 644eec28030210812f459f2d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/37bfa79033dfa10085b474ae84598081.svg
      fullname: reeducator
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: reeducator
      type: user
    createdAt: '2023-05-01T07:39:10.000Z'
    data:
      edited: false
      editors:
      - reeducator
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/37bfa79033dfa10085b474ae84598081.svg
          fullname: reeducator
          isHf: false
          isPro: false
          name: reeducator
          type: user
        html: '<p>With ooba I think you need to have "ggml-" in front of the bin filename
          (according to <a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui/blob/main/docs/llama.cpp-models.md">https://github.com/oobabooga/text-generation-webui/blob/main/docs/llama.cpp-models.md</a>).
          So you could rename the bin files to ggml-vicuna-13b-free-V4.3-q4_0.bin
          etc. Could that solve the issue?</p>

          '
        raw: With ooba I think you need to have "ggml-" in front of the bin filename
          (according to https://github.com/oobabooga/text-generation-webui/blob/main/docs/llama.cpp-models.md).
          So you could rename the bin files to ggml-vicuna-13b-free-V4.3-q4_0.bin
          etc. Could that solve the issue?
        updatedAt: '2023-05-01T07:39:10.330Z'
      numEdits: 0
      reactions: []
    id: 644f6c9ed5f7dafcfa580d5b
    type: comment
  author: reeducator
  content: With ooba I think you need to have "ggml-" in front of the bin filename
    (according to https://github.com/oobabooga/text-generation-webui/blob/main/docs/llama.cpp-models.md).
    So you could rename the bin files to ggml-vicuna-13b-free-V4.3-q4_0.bin etc. Could
    that solve the issue?
  created_at: 2023-05-01 06:39:10+00:00
  edited: false
  hidden: false
  id: 644f6c9ed5f7dafcfa580d5b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-05-01T18:51:21.000Z'
    data:
      edited: false
      editors:
      - mancub
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
          fullname: Man Cub
          isHf: false
          isPro: false
          name: mancub
          type: user
        html: '<p>That was it, thanks !</p>

          <p>I''ll try to RTFM more closely in the future :)</p>

          '
        raw: 'That was it, thanks !


          I''ll try to RTFM more closely in the future :)'
        updatedAt: '2023-05-01T18:51:21.180Z'
      numEdits: 0
      reactions: []
    id: 64500a29d5f7dafcfa663b7d
    type: comment
  author: mancub
  content: 'That was it, thanks !


    I''ll try to RTFM more closely in the future :)'
  created_at: 2023-05-01 17:51:21+00:00
  edited: false
  hidden: false
  id: 64500a29d5f7dafcfa663b7d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-05-01T18:51:24.000Z'
    data:
      status: closed
    id: 64500a2cd5f7dafcfa663bbf
    type: status-change
  author: mancub
  created_at: 2023-05-01 17:51:24+00:00
  id: 64500a2cd5f7dafcfa663bbf
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: reeducator/vicuna-13b-free
repo_type: model
status: closed
target_branch: null
title: Something wrong with bin files?
