!!python/object:huggingface_hub.community.DiscussionWithDetails
author: deleted
conflicting_files: null
created_at: 2023-04-14 14:00:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    createdAt: '2023-04-14T15:00:51.000Z'
    data:
      edited: false
      editors:
      - deleted
      hidden: false
      isReport: false
      latest:
        html: '<p>Thanks for the work. I''m stress testing now, posting recommendations
          over on the dataset thread.</p>

          '
        raw: Thanks for the work. I'm stress testing now, posting recommendations
          over on the dataset thread.
        updatedAt: '2023-04-14T15:00:51.269Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F91D"
        users:
        - reeducator
        - PushTheBrAIkes
        - digitous
    id: 64396aa33ab54fdbab7fa842
    type: comment
  author: deleted
  content: Thanks for the work. I'm stress testing now, posting recommendations over
    on the dataset thread.
  created_at: 2023-04-14 14:00:51+00:00
  edited: false
  hidden: false
  id: 64396aa33ab54fdbab7fa842
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    createdAt: '2023-04-14T16:35:37.000Z'
    data:
      edited: false
      editors:
      - deleted
      hidden: false
      isReport: false
      latest:
        html: '<p>Hey, quick follow up, if you get a chance to do a Windows compatible
          GPTQ quant for this, that''d really help me with prompt testing. I think
          it''s probably good enough to bother with.</p>

          <p>Just leave out --act-order. </p>

          <p> <code>CUDA_VISIBLE_DEVICES=0 python llama.py ../../models/PathToVicuna
          --true-sequential --wbits 4 --groupsize 128 --save_safetensors vicuna-13b-free-4bit-128g.safetensors</code></p>

          <p>I think that''s the command (someone feel free to correct me, I don''t
          feel like checking). Only takes like an hour.</p>

          '
        raw: "Hey, quick follow up, if you get a chance to do a Windows compatible\
          \ GPTQ quant for this, that'd really help me with prompt testing. I think\
          \ it's probably good enough to bother with.\n\nJust leave out --act-order.\
          \ \n\n `CUDA_VISIBLE_DEVICES=0 python llama.py ../../models/PathToVicuna\
          \ --true-sequential --wbits 4 --groupsize 128 --save_safetensors vicuna-13b-free-4bit-128g.safetensors`\n\
          \nI think that's the command (someone feel free to correct me, I don't feel\
          \ like checking). Only takes like an hour."
        updatedAt: '2023-04-14T16:35:37.386Z'
      numEdits: 0
      reactions: []
    id: 643980d95813f0fdd85352e5
    type: comment
  author: deleted
  content: "Hey, quick follow up, if you get a chance to do a Windows compatible GPTQ\
    \ quant for this, that'd really help me with prompt testing. I think it's probably\
    \ good enough to bother with.\n\nJust leave out --act-order. \n\n `CUDA_VISIBLE_DEVICES=0\
    \ python llama.py ../../models/PathToVicuna --true-sequential --wbits 4 --groupsize\
    \ 128 --save_safetensors vicuna-13b-free-4bit-128g.safetensors`\n\nI think that's\
    \ the command (someone feel free to correct me, I don't feel like checking). Only\
    \ takes like an hour."
  created_at: 2023-04-14 15:35:37+00:00
  edited: false
  hidden: false
  id: 643980d95813f0fdd85352e5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    createdAt: '2023-04-14T16:37:03.000Z'
    data:
      edited: false
      editors:
      - deleted
      hidden: false
      isReport: false
      latest:
        html: '<p>Oh, and not to spam you, but if you''re planning to train again
          as soon as we get a V4 for the dataset, feel free ignore this request.</p>

          '
        raw: Oh, and not to spam you, but if you're planning to train again as soon
          as we get a V4 for the dataset, feel free ignore this request.
        updatedAt: '2023-04-14T16:37:03.184Z'
      numEdits: 0
      reactions: []
    id: 6439812fde56ab98fabdef48
    type: comment
  author: deleted
  content: Oh, and not to spam you, but if you're planning to train again as soon
    as we get a V4 for the dataset, feel free ignore this request.
  created_at: 2023-04-14 15:37:03+00:00
  edited: false
  hidden: false
  id: 6439812fde56ab98fabdef48
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    createdAt: '2023-04-14T22:46:52.000Z'
    data:
      edited: false
      editors:
      - deleted
      hidden: false
      isReport: false
      latest:
        html: '<p>Grabbing the safetensors now. Appreciate it.</p>

          '
        raw: Grabbing the safetensors now. Appreciate it.
        updatedAt: '2023-04-14T22:46:52.715Z'
      numEdits: 0
      reactions: []
    id: 6439d7dcde56ab98fac0398f
    type: comment
  author: deleted
  content: Grabbing the safetensors now. Appreciate it.
  created_at: 2023-04-14 21:46:52+00:00
  edited: false
  hidden: false
  id: 6439d7dcde56ab98fac0398f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    createdAt: '2023-04-15T00:25:58.000Z'
    data:
      status: closed
    id: 6439ef16b4a30e369dde39ca
    type: status-change
  author: deleted
  created_at: 2023-04-14 23:25:58+00:00
  id: 6439ef16b4a30e369dde39ca
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: reeducator/vicuna-13b-free
repo_type: model
status: closed
target_branch: null
title: Much love for the train.
