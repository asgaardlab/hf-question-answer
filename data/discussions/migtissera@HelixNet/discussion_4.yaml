!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rhysjones
conflicting_files: null
created_at: 2023-11-05 19:14:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6313247d289cf15634c514bd/Qoev8yYtZBor4xws6MIE6.png?w=200&h=200&f=face
      fullname: Rhys Jones
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rhysjones
      type: user
    createdAt: '2023-11-05T19:14:01.000Z'
    data:
      edited: false
      editors:
      - rhysjones
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8242027163505554
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6313247d289cf15634c514bd/Qoev8yYtZBor4xws6MIE6.png?w=200&h=200&f=face
          fullname: Rhys Jones
          isHf: false
          isPro: false
          name: rhysjones
          type: user
        html: '<p>Created three separate LoRAs for each of the Actor, Critic and Regenerator
          models in HelixNet.  Then combined into a modified script that dynamically
          enables them onto the Mistral base according to the actor / critic / regen
          mode. Memory requirement goes down from 3 x 14GB for the full models to
          1 x 14GB + 3 x 320MB for the base + LoRAs. </p>

          <p>LoRAs and modified code example here: <a href="https://huggingface.co/rhysjones/HelixNet-LMoE-Actor">https://huggingface.co/rhysjones/HelixNet-LMoE-Actor</a></p>

          '
        raw: "Created three separate LoRAs for each of the Actor, Critic and Regenerator\
          \ models in HelixNet.  Then combined into a modified script that dynamically\
          \ enables them onto the Mistral base according to the actor / critic / regen\
          \ mode. Memory requirement goes down from 3 x 14GB for the full models to\
          \ 1 x 14GB + 3 x 320MB for the base + LoRAs. \r\n\r\nLoRAs and modified\
          \ code example here: https://huggingface.co/rhysjones/HelixNet-LMoE-Actor"
        updatedAt: '2023-11-05T19:14:01.046Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Citaman
    id: 6547e979c19493646975d434
    type: comment
  author: rhysjones
  content: "Created three separate LoRAs for each of the Actor, Critic and Regenerator\
    \ models in HelixNet.  Then combined into a modified script that dynamically enables\
    \ them onto the Mistral base according to the actor / critic / regen mode. Memory\
    \ requirement goes down from 3 x 14GB for the full models to 1 x 14GB + 3 x 320MB\
    \ for the base + LoRAs. \r\n\r\nLoRAs and modified code example here: https://huggingface.co/rhysjones/HelixNet-LMoE-Actor"
  created_at: 2023-11-05 19:14:01+00:00
  edited: false
  hidden: false
  id: 6547e979c19493646975d434
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
      fullname: Migel Tissera
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: migtissera
      type: user
    createdAt: '2023-11-05T19:33:18.000Z'
    data:
      edited: false
      editors:
      - migtissera
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8392807841300964
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
          fullname: Migel Tissera
          isHf: false
          isPro: false
          name: migtissera
          type: user
        html: "<p>Really awesome work! What\u2019s the added delay for loading LoRAs?</p>\n"
        raw: "Really awesome work! What\u2019s the added delay for loading LoRAs?"
        updatedAt: '2023-11-05T19:33:18.642Z'
      numEdits: 0
      reactions: []
    id: 6547edfeaf5d7944325b3cae
    type: comment
  author: migtissera
  content: "Really awesome work! What\u2019s the added delay for loading LoRAs?"
  created_at: 2023-11-05 19:33:18+00:00
  edited: false
  hidden: false
  id: 6547edfeaf5d7944325b3cae
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6313247d289cf15634c514bd/Qoev8yYtZBor4xws6MIE6.png?w=200&h=200&f=face
      fullname: Rhys Jones
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rhysjones
      type: user
    createdAt: '2023-11-05T20:18:12.000Z'
    data:
      edited: false
      editors:
      - rhysjones
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8647702932357788
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6313247d289cf15634c514bd/Qoev8yYtZBor4xws6MIE6.png?w=200&h=200&f=face
          fullname: Rhys Jones
          isHf: false
          isPro: false
          name: rhysjones
          type: user
        html: '<p>Loading the LoRAs is very quick (ms). The tradeoff is in the inference
          performance, since the inference now goes through both the model weights
          and LoRA deltas - adding an extra step each time.</p>

          <p>Initial testing on a 4090 using the demo script gives:</p>

          <p>HelixNet Actor model: 44 tokens / second<br>Mistral + Actor LoRA : 27
          tokens /  second</p>

          '
        raw: 'Loading the LoRAs is very quick (ms). The tradeoff is in the inference
          performance, since the inference now goes through both the model weights
          and LoRA deltas - adding an extra step each time.


          Initial testing on a 4090 using the demo script gives:


          HelixNet Actor model: 44 tokens / second

          Mistral + Actor LoRA : 27 tokens /  second'
        updatedAt: '2023-11-05T20:18:12.197Z'
      numEdits: 0
      reactions: []
    id: 6547f8846c818bb7b5d6f08e
    type: comment
  author: rhysjones
  content: 'Loading the LoRAs is very quick (ms). The tradeoff is in the inference
    performance, since the inference now goes through both the model weights and LoRA
    deltas - adding an extra step each time.


    Initial testing on a 4090 using the demo script gives:


    HelixNet Actor model: 44 tokens / second

    Mistral + Actor LoRA : 27 tokens /  second'
  created_at: 2023-11-05 20:18:12+00:00
  edited: false
  hidden: false
  id: 6547f8846c818bb7b5d6f08e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
      fullname: Migel Tissera
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: migtissera
      type: user
    createdAt: '2023-11-05T20:47:20.000Z'
    data:
      edited: false
      editors:
      - migtissera
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9538161754608154
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
          fullname: Migel Tissera
          isHf: false
          isPro: false
          name: migtissera
          type: user
        html: "<p>That\u2019s still very usable! Nice.</p>\n<p>I\u2019ve been running\
          \ GPTQ 6-bit quantized versions with exllamav2 \u2014 getting like 120 tok/second\
          \ on my 4090. I think the performance is about the same, maybe a slight\
          \ degradation.</p>\n"
        raw: "That\u2019s still very usable! Nice.\n\nI\u2019ve been running GPTQ\
          \ 6-bit quantized versions with exllamav2 \u2014 getting like 120 tok/second\
          \ on my 4090. I think the performance is about the same, maybe a slight\
          \ degradation."
        updatedAt: '2023-11-05T20:47:20.692Z'
      numEdits: 0
      reactions: []
    id: 6547ff586b1695ac33da5c94
    type: comment
  author: migtissera
  content: "That\u2019s still very usable! Nice.\n\nI\u2019ve been running GPTQ 6-bit\
    \ quantized versions with exllamav2 \u2014 getting like 120 tok/second on my 4090.\
    \ I think the performance is about the same, maybe a slight degradation."
  created_at: 2023-11-05 20:47:20+00:00
  edited: false
  hidden: false
  id: 6547ff586b1695ac33da5c94
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6313247d289cf15634c514bd/Qoev8yYtZBor4xws6MIE6.png?w=200&h=200&f=face
      fullname: Rhys Jones
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rhysjones
      type: user
    createdAt: '2023-11-05T23:45:04.000Z'
    data:
      edited: false
      editors:
      - rhysjones
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.777140200138092
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6313247d289cf15634c514bd/Qoev8yYtZBor4xws6MIE6.png?w=200&h=200&f=face
          fullname: Rhys Jones
          isHf: false
          isPro: false
          name: rhysjones
          type: user
        html: '<p>Yes, ExLlamaV2 is excellent!</p>

          <p>Turns out exllamav2 also has support for loading multiple LoRAs. Adapting
          the LMoE to use the 6-bit exl2 quantized version of Mistral and loading
          in the LoRAs within exllamav2 gives much better results on the 4090:</p>

          <p>3 separate models: 120 tokens / second, using 20GB GPU<br>LMoE combined
          model: 91 tokens / second, using 8GB GPU</p>

          <p>Update at: <a href="https://huggingface.co/rhysjones/HelixNet-LMoE-6.0bpw-h6-exl2">https://huggingface.co/rhysjones/HelixNet-LMoE-6.0bpw-h6-exl2</a></p>

          '
        raw: 'Yes, ExLlamaV2 is excellent!


          Turns out exllamav2 also has support for loading multiple LoRAs. Adapting
          the LMoE to use the 6-bit exl2 quantized version of Mistral and loading
          in the LoRAs within exllamav2 gives much better results on the 4090:


          3 separate models: 120 tokens / second, using 20GB GPU

          LMoE combined model: 91 tokens / second, using 8GB GPU


          Update at: https://huggingface.co/rhysjones/HelixNet-LMoE-6.0bpw-h6-exl2'
        updatedAt: '2023-11-05T23:45:04.408Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - macadeliccc
        - dillfrescott
        - Citaman
    id: 65482900b3a7efb9390718aa
    type: comment
  author: rhysjones
  content: 'Yes, ExLlamaV2 is excellent!


    Turns out exllamav2 also has support for loading multiple LoRAs. Adapting the
    LMoE to use the 6-bit exl2 quantized version of Mistral and loading in the LoRAs
    within exllamav2 gives much better results on the 4090:


    3 separate models: 120 tokens / second, using 20GB GPU

    LMoE combined model: 91 tokens / second, using 8GB GPU


    Update at: https://huggingface.co/rhysjones/HelixNet-LMoE-6.0bpw-h6-exl2'
  created_at: 2023-11-05 23:45:04+00:00
  edited: false
  hidden: false
  id: 65482900b3a7efb9390718aa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
      fullname: Migel Tissera
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: migtissera
      type: user
    createdAt: '2023-11-06T00:36:31.000Z'
    data:
      edited: false
      editors:
      - migtissera
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9873617887496948
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
          fullname: Migel Tissera
          isHf: false
          isPro: false
          name: migtissera
          type: user
        html: '<p>Wow, 8GB is within reach of most people. Nice work!</p>

          '
        raw: Wow, 8GB is within reach of most people. Nice work!
        updatedAt: '2023-11-06T00:36:31.313Z'
      numEdits: 0
      reactions: []
    id: 6548350fcbe50f378d861907
    type: comment
  author: migtissera
  content: Wow, 8GB is within reach of most people. Nice work!
  created_at: 2023-11-06 00:36:31+00:00
  edited: false
  hidden: false
  id: 6548350fcbe50f378d861907
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
      fullname: Cross Nastasi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dillfrescott
      type: user
    createdAt: '2023-11-06T04:56:46.000Z'
    data:
      edited: false
      editors:
      - dillfrescott
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.33839693665504456
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
          fullname: Cross Nastasi
          isHf: false
          isPro: false
          name: dillfrescott
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;rhysjones&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/rhysjones\">@<span class=\"\
          underline\">rhysjones</span></a></span>\n\n\t</span></span> This implementation\
          \ works fantastically!</p>\n"
        raw: '@rhysjones This implementation works fantastically!'
        updatedAt: '2023-11-06T04:56:46.418Z'
      numEdits: 0
      reactions: []
    id: 6548720e8db75bfe5da0f61c
    type: comment
  author: dillfrescott
  content: '@rhysjones This implementation works fantastically!'
  created_at: 2023-11-06 04:56:46+00:00
  edited: false
  hidden: false
  id: 6548720e8db75bfe5da0f61c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
      fullname: Migel Tissera
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: migtissera
      type: user
    createdAt: '2023-11-06T05:24:35.000Z'
    data:
      edited: false
      editors:
      - migtissera
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9560351371765137
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
          fullname: Migel Tissera
          isHf: false
          isPro: false
          name: migtissera
          type: user
        html: "<p>The network is not yet perfect, I wanted to get it out to you guys\
          \ first and then iterate. For example, the regenerator says stuff that are\
          \ not ideal right now. I\u2019ve started dataset creation for the v2. Will\
          \ perfect this over time, I think the approach is sound. And much less compute\
          \ is needed compared to a MoE.<br>Thanks for your contributions guys!</p>\n"
        raw: "The network is not yet perfect, I wanted to get it out to you guys first\
          \ and then iterate. For example, the regenerator says stuff that are not\
          \ ideal right now. I\u2019ve started dataset creation for the v2. Will perfect\
          \ this over time, I think the approach is sound. And much less compute is\
          \ needed compared to a MoE.\nThanks for your contributions guys!"
        updatedAt: '2023-11-06T05:24:35.109Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - mammour
        - drak-hf
      relatedEventId: 654878932a2a48304251b42f
    id: 654878932a2a48304251b427
    type: comment
  author: migtissera
  content: "The network is not yet perfect, I wanted to get it out to you guys first\
    \ and then iterate. For example, the regenerator says stuff that are not ideal\
    \ right now. I\u2019ve started dataset creation for the v2. Will perfect this\
    \ over time, I think the approach is sound. And much less compute is needed compared\
    \ to a MoE.\nThanks for your contributions guys!"
  created_at: 2023-11-06 05:24:35+00:00
  edited: false
  hidden: false
  id: 654878932a2a48304251b427
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647a6317555b5e199cffd5a2/TykMo31XdtmLTa8uOshGn.jpeg?w=200&h=200&f=face
      fullname: Migel Tissera
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: migtissera
      type: user
    createdAt: '2023-11-06T05:24:35.000Z'
    data:
      status: closed
    id: 654878932a2a48304251b42f
    type: status-change
  author: migtissera
  created_at: 2023-11-06 05:24:35+00:00
  id: 654878932a2a48304251b42f
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: migtissera/HelixNet
repo_type: model
status: closed
target_branch: null
title: LMoE version with 3 LoRAs on base Mistral model
