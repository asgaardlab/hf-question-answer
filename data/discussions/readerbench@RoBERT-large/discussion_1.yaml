!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aciobanitei
conflicting_files: null
created_at: 2022-11-17 15:11:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/201eb0fddf80cf3be23782dbc06712bd.svg
      fullname: Aciobanitei Iulian
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aciobanitei
      type: user
    createdAt: '2022-11-17T15:11:00.000Z'
    data:
      edited: false
      editors:
      - aciobanitei
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/201eb0fddf80cf3be23782dbc06712bd.svg
          fullname: Aciobanitei Iulian
          isHf: false
          isPro: false
          name: aciobanitei
          type: user
        html: '<p>Hi,</p>

          <p>I have a fine-tunned wav2vec2.0 model for Romanian language ASR. I would
          also like to integrate a language model in there, but I don''t quite understand
          how to do it.<br>I can run the wav2vec model so that I can obtain the text
          from the sound file.<br>I also can evaluate the wav2vec model, against a
          dataset.<br>I can run this model on a text and obtain some number, but I
          don''t understand what they mean.</p>

          <p>I some tutorials, I found some integrations between wav2vec and ken language
          models (<a href="https://huggingface.co/blog/wav2vec2-with-ngram">https://huggingface.co/blog/wav2vec2-with-ngram</a>)<br>I
          understand that I need to use Wav2Vec2ProcessorWithLM but I don''t understand
          the values I should attribute there, since I don''t have an  .arpa file
          for the kenlm.<br>If this kind of validation is not to be done straight
          forward, at least I would like to know how I may translate the numbers received
          from outputs = model(**inputs) into an actual text.</p>

          <p>Regards</p>

          '
        raw: "Hi,\r\n\r\nI have a fine-tunned wav2vec2.0 model for Romanian language\
          \ ASR. I would also like to integrate a language model in there, but I don't\
          \ quite understand how to do it.\r\nI can run the wav2vec model so that\
          \ I can obtain the text from the sound file.\r\nI also can evaluate the\
          \ wav2vec model, against a dataset.\r\nI can run this model on a text and\
          \ obtain some number, but I don't understand what they mean.\r\n\r\nI some\
          \ tutorials, I found some integrations between wav2vec and ken language\
          \ models (https://huggingface.co/blog/wav2vec2-with-ngram)\r\nI understand\
          \ that I need to use Wav2Vec2ProcessorWithLM but I don't understand the\
          \ values I should attribute there, since I don't have an  .arpa file for\
          \ the kenlm.\r\nIf this kind of validation is not to be done straight forward,\
          \ at least I would like to know how I may translate the numbers received\
          \ from outputs = model(**inputs) into an actual text.\r\n\r\nRegards\r\n\
          \r\n "
        updatedAt: '2022-11-17T15:11:00.503Z'
      numEdits: 0
      reactions: []
    id: 63764f04b9f879cfce168129
    type: comment
  author: aciobanitei
  content: "Hi,\r\n\r\nI have a fine-tunned wav2vec2.0 model for Romanian language\
    \ ASR. I would also like to integrate a language model in there, but I don't quite\
    \ understand how to do it.\r\nI can run the wav2vec model so that I can obtain\
    \ the text from the sound file.\r\nI also can evaluate the wav2vec model, against\
    \ a dataset.\r\nI can run this model on a text and obtain some number, but I don't\
    \ understand what they mean.\r\n\r\nI some tutorials, I found some integrations\
    \ between wav2vec and ken language models (https://huggingface.co/blog/wav2vec2-with-ngram)\r\
    \nI understand that I need to use Wav2Vec2ProcessorWithLM but I don't understand\
    \ the values I should attribute there, since I don't have an  .arpa file for the\
    \ kenlm.\r\nIf this kind of validation is not to be done straight forward, at\
    \ least I would like to know how I may translate the numbers received from outputs\
    \ = model(**inputs) into an actual text.\r\n\r\nRegards\r\n\r\n "
  created_at: 2022-11-17 15:11:00+00:00
  edited: false
  hidden: false
  id: 63764f04b9f879cfce168129
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acd1f544831c9e1b16c20fb83d9ba252.svg
      fullname: MihaiMasala
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mihaimasala
      type: user
    createdAt: '2022-11-17T15:43:28.000Z'
    data:
      edited: true
      editors:
      - mihaimasala
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acd1f544831c9e1b16c20fb83d9ba252.svg
          fullname: MihaiMasala
          isHf: false
          isPro: false
          name: mihaimasala
          type: user
        html: '<p>Hello,</p>

          <p>I think you are looking for a LM that is suitable for generating text.
          The RoBERT-large model is trained on MLM and NSP tasks. While this model
          is capable of generating text (e.g: by adding a MASK token at the end of
          the string at each step), I think a GPT-2 model is more suitable for your
          task. Have a look at the following models: <a href="https://huggingface.co/readerbench/RoGPT2-medium">https://huggingface.co/readerbench/RoGPT2-medium</a>
          , <a href="https://huggingface.co/readerbench/RoGPT2-base">https://huggingface.co/readerbench/RoGPT2-base</a>
          , <a href="https://huggingface.co/readerbench/RoGPT2-large">https://huggingface.co/readerbench/RoGPT2-large</a>
          .</p>

          '
        raw: 'Hello,


          I think you are looking for a LM that is suitable for generating text. The
          RoBERT-large model is trained on MLM and NSP tasks. While this model is
          capable of generating text (e.g: by adding a MASK token at the end of the
          string at each step), I think a GPT-2 model is more suitable for your task.
          Have a look at the following models: https://huggingface.co/readerbench/RoGPT2-medium
          , https://huggingface.co/readerbench/RoGPT2-base , https://huggingface.co/readerbench/RoGPT2-large
          .'
        updatedAt: '2022-11-17T15:43:52.059Z'
      numEdits: 2
      reactions: []
    id: 637656a0d87fe2e8c515b57e
    type: comment
  author: mihaimasala
  content: 'Hello,


    I think you are looking for a LM that is suitable for generating text. The RoBERT-large
    model is trained on MLM and NSP tasks. While this model is capable of generating
    text (e.g: by adding a MASK token at the end of the string at each step), I think
    a GPT-2 model is more suitable for your task. Have a look at the following models:
    https://huggingface.co/readerbench/RoGPT2-medium , https://huggingface.co/readerbench/RoGPT2-base
    , https://huggingface.co/readerbench/RoGPT2-large .'
  created_at: 2022-11-17 15:43:28+00:00
  edited: true
  hidden: false
  id: 637656a0d87fe2e8c515b57e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: readerbench/RoBERT-large
repo_type: model
status: open
target_branch: null
title: Question about Wav2vec 2.0 - RoBERT integration
