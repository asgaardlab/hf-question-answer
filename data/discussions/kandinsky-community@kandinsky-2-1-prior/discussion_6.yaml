!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ryaker
conflicting_files: null
created_at: 2023-06-10 21:24:22+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6462bd1a52193f2957647949/2SRp5nF_w6T2LO5JSYwZA.jpeg?w=200&h=200&f=face
      fullname: Richard Yaker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ryaker
      type: user
    createdAt: '2023-06-10T22:24:22.000Z'
    data:
      edited: false
      editors:
      - ryaker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.733239471912384
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6462bd1a52193f2957647949/2SRp5nF_w6T2LO5JSYwZA.jpeg?w=200&h=200&f=face
          fullname: Richard Yaker
          isHf: false
          isPro: false
          name: ryaker
          type: user
        html: '<p>Changed CUDA to MPS, but getting errors.<br>You are using a model
          of type xlm-roberta to instantiate a model of type M-CLIP. This is not supported
          for all configurations of models and can yield errors.<br>loc("varianceEps"("(mpsFileLoc):
          /AppleInternal/Library/BuildRoots/c2cb9645-dafc-11ed-aa26-6ec1e3b3f7b3/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm":228:0)):
          error: input types ''tensor&lt;1x154x1xf16&gt;'' and ''tensor&lt;1xf32&gt;''
          are not broadcast compatible<br>LLVM ERROR: Failed to infer result type(s).</p>

          '
        raw: "Changed CUDA to MPS, but getting errors.\r\nYou are using a model of\
          \ type xlm-roberta to instantiate a model of type M-CLIP. This is not supported\
          \ for all configurations of models and can yield errors.\r\nloc(\"varianceEps\"\
          (\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/c2cb9645-dafc-11ed-aa26-6ec1e3b3f7b3/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\"\
          :228:0)): error: input types 'tensor<1x154x1xf16>' and 'tensor<1xf32>' are\
          \ not broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s)."
        updatedAt: '2023-06-10T22:24:22.968Z'
      numEdits: 0
      reactions: []
    id: 6484f8165ef97021905c9bea
    type: comment
  author: ryaker
  content: "Changed CUDA to MPS, but getting errors.\r\nYou are using a model of type\
    \ xlm-roberta to instantiate a model of type M-CLIP. This is not supported for\
    \ all configurations of models and can yield errors.\r\nloc(\"varianceEps\"(\"\
    (mpsFileLoc): /AppleInternal/Library/BuildRoots/c2cb9645-dafc-11ed-aa26-6ec1e3b3f7b3/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\"\
    :228:0)): error: input types 'tensor<1x154x1xf16>' and 'tensor<1xf32>' are not\
    \ broadcast compatible\r\nLLVM ERROR: Failed to infer result type(s)."
  created_at: 2023-06-10 21:24:22+00:00
  edited: false
  hidden: false
  id: 6484f8165ef97021905c9bea
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6462bd1a52193f2957647949/2SRp5nF_w6T2LO5JSYwZA.jpeg?w=200&h=200&f=face
      fullname: Richard Yaker
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ryaker
      type: user
    createdAt: '2023-06-10T22:24:49.000Z'
    data:
      edited: false
      editors:
      - ryaker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3786449730396271
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6462bd1a52193f2957647949/2SRp5nF_w6T2LO5JSYwZA.jpeg?w=200&h=200&f=face
          fullname: Richard Yaker
          isHf: false
          isPro: false
          name: ryaker
          type: user
        html: '<p>this is the code</p>

          <p>from diffusers import DiffusionPipeline<br>import torch</p>

          <p>pipe_prior = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-prior",
          torch_dtype=torch.float16)<br>pipe_prior.to("mps")</p>

          <p>t2i_pipe = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1",
          torch_dtype=torch.float16)<br>t2i_pipe.to("mps")</p>

          <p>prompt = "A purple panda playing soccer, claymation, cinematic, sunny"<br>negative_prompt
          = "low quality, bad quality"</p>

          <p>generator = torch.Generator(device="mps").manual_seed(12)<br>image_embeds,
          negative_image_embeds = pipe_prior(prompt, negative_prompt, guidance_scale=1.0,
          generator=generator).to_tuple()</p>

          <p>image = t2i_pipe(prompt, negative_prompt=negative_prompt, image_embeds=image_embeds,
          negative_image_embeds=negative_image_embeds).images[0]<br>image.save("purple_soccer_panda.png")</p>

          '
        raw: 'this is the code


          from diffusers import DiffusionPipeline

          import torch


          pipe_prior = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-prior",
          torch_dtype=torch.float16)

          pipe_prior.to("mps")


          t2i_pipe = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1",
          torch_dtype=torch.float16)

          t2i_pipe.to("mps")


          prompt = "A purple panda playing soccer, claymation, cinematic, sunny"

          negative_prompt = "low quality, bad quality"


          generator = torch.Generator(device="mps").manual_seed(12)

          image_embeds, negative_image_embeds = pipe_prior(prompt, negative_prompt,
          guidance_scale=1.0, generator=generator).to_tuple()


          image = t2i_pipe(prompt, negative_prompt=negative_prompt, image_embeds=image_embeds,
          negative_image_embeds=negative_image_embeds).images[0]

          image.save("purple_soccer_panda.png")'
        updatedAt: '2023-06-10T22:24:49.372Z'
      numEdits: 0
      reactions: []
    id: 6484f8313b67aec19803d575
    type: comment
  author: ryaker
  content: 'this is the code


    from diffusers import DiffusionPipeline

    import torch


    pipe_prior = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1-prior",
    torch_dtype=torch.float16)

    pipe_prior.to("mps")


    t2i_pipe = DiffusionPipeline.from_pretrained("kandinsky-community/kandinsky-2-1",
    torch_dtype=torch.float16)

    t2i_pipe.to("mps")


    prompt = "A purple panda playing soccer, claymation, cinematic, sunny"

    negative_prompt = "low quality, bad quality"


    generator = torch.Generator(device="mps").manual_seed(12)

    image_embeds, negative_image_embeds = pipe_prior(prompt, negative_prompt, guidance_scale=1.0,
    generator=generator).to_tuple()


    image = t2i_pipe(prompt, negative_prompt=negative_prompt, image_embeds=image_embeds,
    negative_image_embeds=negative_image_embeds).images[0]

    image.save("purple_soccer_panda.png")'
  created_at: 2023-06-10 21:24:49+00:00
  edited: false
  hidden: false
  id: 6484f8313b67aec19803d575
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: kandinsky-community/kandinsky-2-1-prior
repo_type: model
status: open
target_branch: null
title: Trying to run this on an M1 Mac Mini
