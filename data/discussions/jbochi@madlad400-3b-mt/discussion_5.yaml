!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ehsanjahanbakhsh
conflicting_files: null
created_at: 2023-11-16 12:57:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c4216587c260a93fd4d26dc7d9479bd5.svg
      fullname: 'Ehsan jahanbakhsh '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ehsanjahanbakhsh
      type: user
    createdAt: '2023-11-16T12:57:10.000Z'
    data:
      edited: true
      editors:
      - Ehsanjahanbakhsh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5959683060646057
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c4216587c260a93fd4d26dc7d9479bd5.svg
          fullname: 'Ehsan jahanbakhsh '
          isHf: false
          isPro: false
          name: Ehsanjahanbakhsh
          type: user
        html: '<p>The code used to create the tokenizer adds 100 extra tokens by default.
          The padding token for <code>T5Tokenizer</code> is "&lt;pad&gt;" by default,
          which doesn''t exist in the sentencepiece model, thus adding another extra
          token, making batch inference impossible.</p>

          <pre><code>tokenizer = T5Tokenizer(''256k_vocab/spm.model'', legacy=False)

          </code></pre>

          <p>using the code below makes it work fine:</p>

          <pre><code>tokenizer = T5Tokenizer(''vocabulary_256k_vocab_spm.model'',
          extra_ids = 0, pad_token = ''&lt;s&gt;'', legacy = False)

          </code></pre>

          '
        raw: 'The code used to create the tokenizer adds 100 extra tokens by default.
          The padding token for `T5Tokenizer` is "\<pad\>" by default, which doesn''t
          exist in the sentencepiece model, thus adding another extra token, making
          batch inference impossible.

          ```

          tokenizer = T5Tokenizer(''256k_vocab/spm.model'', legacy=False)

          ```

          using the code below makes it work fine:

          ```

          tokenizer = T5Tokenizer(''vocabulary_256k_vocab_spm.model'', extra_ids =
          0, pad_token = ''<s>'', legacy = False)

          ```


          '
        updatedAt: '2023-11-16T12:57:21.903Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jbochi
    id: 655611a6a154e29d8c637fcb
    type: comment
  author: Ehsanjahanbakhsh
  content: 'The code used to create the tokenizer adds 100 extra tokens by default.
    The padding token for `T5Tokenizer` is "\<pad\>" by default, which doesn''t exist
    in the sentencepiece model, thus adding another extra token, making batch inference
    impossible.

    ```

    tokenizer = T5Tokenizer(''256k_vocab/spm.model'', legacy=False)

    ```

    using the code below makes it work fine:

    ```

    tokenizer = T5Tokenizer(''vocabulary_256k_vocab_spm.model'', extra_ids = 0, pad_token
    = ''<s>'', legacy = False)

    ```


    '
  created_at: 2023-11-16 12:57:10+00:00
  edited: true
  hidden: false
  id: 655611a6a154e29d8c637fcb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1018b29e2da89f5920a58482e17a1948.svg
      fullname: J Bochi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: jbochi
      type: user
    createdAt: '2023-11-17T11:44:13.000Z'
    data:
      edited: false
      editors:
      - jbochi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9754882454872131
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1018b29e2da89f5920a58482e17a1948.svg
          fullname: J Bochi
          isHf: false
          isPro: false
          name: jbochi
          type: user
        html: '<p>Thank you for reporting this and for the fix in <a href="/jbochi/madlad400-3b-mt/discussions/6">#6</a>.</p>

          '
        raw: 'Thank you for reporting this and for the fix in #6.'
        updatedAt: '2023-11-17T11:44:13.408Z'
      numEdits: 0
      reactions: []
    id: 6557520d7eaa0731c9276b81
    type: comment
  author: jbochi
  content: 'Thank you for reporting this and for the fix in #6.'
  created_at: 2023-11-17 11:44:13+00:00
  edited: false
  hidden: false
  id: 6557520d7eaa0731c9276b81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/1018b29e2da89f5920a58482e17a1948.svg
      fullname: J Bochi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: jbochi
      type: user
    createdAt: '2023-11-17T12:17:15.000Z'
    data:
      status: closed
    id: 655759cb47c93d37a89a3e19
    type: status-change
  author: jbochi
  created_at: 2023-11-17 12:17:15+00:00
  id: 655759cb47c93d37a89a3e19
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: jbochi/madlad400-3b-mt
repo_type: model
status: closed
target_branch: null
title: Better Tokenizer
