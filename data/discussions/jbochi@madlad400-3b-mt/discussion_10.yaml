!!python/object:huggingface_hub.community.DiscussionWithDetails
author: CXDuncan
conflicting_files: null
created_at: 2024-01-05 19:28:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/65c1d87a49651ec1efcbb9ce7cfe9a74.svg
      fullname: Jordan Duncan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CXDuncan
      type: user
    createdAt: '2024-01-05T19:28:32.000Z'
    data:
      edited: false
      editors:
      - CXDuncan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6574191451072693
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/65c1d87a49651ec1efcbb9ce7cfe9a74.svg
          fullname: Jordan Duncan
          isHf: false
          isPro: false
          name: CXDuncan
          type: user
        html: "<p>Hey! Do you have any recommendations on how to get this to translate\
          \ an entire string? I was under the impression that this is limited to 128\
          \ tokens, but it seems as though even multi-sentence strings under that\
          \ limit are causing it to stop responding.<br>chat input from user: \u0986\
          \u09AA\u09A8\u09BE\u09B0 \u09B8\u09C1\u09A6\u09C7\u09B0 \u09B9\u09BE\u09B0\
          \ \u09B8\u09AE\u09CD\u09AA\u09B0\u09CD\u0995\u09C7 \u0986\u09AA\u09A8\u09BF\
          \ \u0986\u09AE\u09BE\u0995\u09C7 \u0995\u09BF \u09AC\u09B2\u09A4\u09C7 \u09AA\
          \u09BE\u09B0\u09C7\u09A8?<br>detected language: bn<br>translated chat input:\
          \ Can you tell me about your interest rate?<br>response from llm: I'm sorry,\
          \ but I cannot provide information on interest rates. My purpose is to help\
          \ with translations and language-related tasks. If you have any questions\
          \ or need assistance related to translation, please feel free to ask!<br>translated\
          \ response from llm: \u0986\u09AE\u09BF \u09A6\u09C1\u0983\u0996\u09BF\u09A4\
          , \u0995\u09BF\u09A8\u09CD\u09A4\u09C1 \u0986\u09AE\u09BF \u09B8\u09C1\u09A6\
          \u09C7\u09B0 \u09B9\u09BE\u09B0\u09C7\u09B0 \u09A4\u09A5\u09CD\u09AF \u09A6\
          \u09BF\u09A4\u09C7 \u09AA\u09BE\u09B0\u099B\u09BF \u09A8\u09BE \u0964 \u0986\
          \u09AE\u09BE\u09B0</p>\n"
        raw: "Hey! Do you have any recommendations on how to get this to translate\
          \ an entire string? I was under the impression that this is limited to 128\
          \ tokens, but it seems as though even multi-sentence strings under that\
          \ limit are causing it to stop responding. \r\nchat input from user: \u0986\
          \u09AA\u09A8\u09BE\u09B0 \u09B8\u09C1\u09A6\u09C7\u09B0 \u09B9\u09BE\u09B0\
          \ \u09B8\u09AE\u09CD\u09AA\u09B0\u09CD\u0995\u09C7 \u0986\u09AA\u09A8\u09BF\
          \ \u0986\u09AE\u09BE\u0995\u09C7 \u0995\u09BF \u09AC\u09B2\u09A4\u09C7 \u09AA\
          \u09BE\u09B0\u09C7\u09A8?\r\ndetected language: bn\r\ntranslated chat input:\
          \ Can you tell me about your interest rate?\r\nresponse from llm: I'm sorry,\
          \ but I cannot provide information on interest rates. My purpose is to help\
          \ with translations and language-related tasks. If you have any questions\
          \ or need assistance related to translation, please feel free to ask!\r\n\
          translated response from llm: \u0986\u09AE\u09BF \u09A6\u09C1\u0983\u0996\
          \u09BF\u09A4, \u0995\u09BF\u09A8\u09CD\u09A4\u09C1 \u0986\u09AE\u09BF \u09B8\
          \u09C1\u09A6\u09C7\u09B0 \u09B9\u09BE\u09B0\u09C7\u09B0 \u09A4\u09A5\u09CD\
          \u09AF \u09A6\u09BF\u09A4\u09C7 \u09AA\u09BE\u09B0\u099B\u09BF \u09A8\u09BE\
          \ \u0964 \u0986\u09AE\u09BE\u09B0\r\n"
        updatedAt: '2024-01-05T19:28:32.618Z'
      numEdits: 0
      reactions: []
    id: 65985860d3f213741572b1a5
    type: comment
  author: CXDuncan
  content: "Hey! Do you have any recommendations on how to get this to translate an\
    \ entire string? I was under the impression that this is limited to 128 tokens,\
    \ but it seems as though even multi-sentence strings under that limit are causing\
    \ it to stop responding. \r\nchat input from user: \u0986\u09AA\u09A8\u09BE\u09B0\
    \ \u09B8\u09C1\u09A6\u09C7\u09B0 \u09B9\u09BE\u09B0 \u09B8\u09AE\u09CD\u09AA\u09B0\
    \u09CD\u0995\u09C7 \u0986\u09AA\u09A8\u09BF \u0986\u09AE\u09BE\u0995\u09C7 \u0995\
    \u09BF \u09AC\u09B2\u09A4\u09C7 \u09AA\u09BE\u09B0\u09C7\u09A8?\r\ndetected language:\
    \ bn\r\ntranslated chat input: Can you tell me about your interest rate?\r\nresponse\
    \ from llm: I'm sorry, but I cannot provide information on interest rates. My\
    \ purpose is to help with translations and language-related tasks. If you have\
    \ any questions or need assistance related to translation, please feel free to\
    \ ask!\r\ntranslated response from llm: \u0986\u09AE\u09BF \u09A6\u09C1\u0983\u0996\
    \u09BF\u09A4, \u0995\u09BF\u09A8\u09CD\u09A4\u09C1 \u0986\u09AE\u09BF \u09B8\u09C1\
    \u09A6\u09C7\u09B0 \u09B9\u09BE\u09B0\u09C7\u09B0 \u09A4\u09A5\u09CD\u09AF \u09A6\
    \u09BF\u09A4\u09C7 \u09AA\u09BE\u09B0\u099B\u09BF \u09A8\u09BE \u0964 \u0986\u09AE\
    \u09BE\u09B0\r\n"
  created_at: 2024-01-05 19:28:32+00:00
  edited: false
  hidden: false
  id: 65985860d3f213741572b1a5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1018b29e2da89f5920a58482e17a1948.svg
      fullname: J Bochi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: jbochi
      type: user
    createdAt: '2024-01-05T21:26:55.000Z'
    data:
      edited: false
      editors:
      - jbochi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8867596983909607
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1018b29e2da89f5920a58482e17a1948.svg
          fullname: J Bochi
          isHf: false
          isPro: false
          name: jbochi
          type: user
        html: '<p>How are you running the model? You might need to set <a href="https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig.max_new_tokens">max_new_tokens</a>
          to make sure the translation is not cut short.</p>

          <p>That said, I''m not sure if the model was trained on inputs with multiple
          sentences. You may want to break the input and translate each sentence separately.</p>

          '
        raw: 'How are you running the model? You might need to set [max_new_tokens](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig.max_new_tokens)
          to make sure the translation is not cut short.


          That said, I''m not sure if the model was trained on inputs with multiple
          sentences. You may want to break the input and translate each sentence separately.'
        updatedAt: '2024-01-05T21:26:55.371Z'
      numEdits: 0
      reactions: []
    id: 6598741f8982abaa5c79eab5
    type: comment
  author: jbochi
  content: 'How are you running the model? You might need to set [max_new_tokens](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig.max_new_tokens)
    to make sure the translation is not cut short.


    That said, I''m not sure if the model was trained on inputs with multiple sentences.
    You may want to break the input and translate each sentence separately.'
  created_at: 2024-01-05 21:26:55+00:00
  edited: false
  hidden: false
  id: 6598741f8982abaa5c79eab5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/65c1d87a49651ec1efcbb9ce7cfe9a74.svg
      fullname: Jordan Duncan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CXDuncan
      type: user
    createdAt: '2024-01-08T13:14:32.000Z'
    data:
      edited: false
      editors:
      - CXDuncan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9793776869773865
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/65c1d87a49651ec1efcbb9ce7cfe9a74.svg
          fullname: Jordan Duncan
          isHf: false
          isPro: false
          name: CXDuncan
          type: user
        html: '<p>I''ve tried a few different ways now, including setting max_new_tokens.
          Unfortunately none of those attempts resulted in a more promising outcome.
          I may come back to this another time, but I need to try another model for
          now. Thanks!</p>

          '
        raw: I've tried a few different ways now, including setting max_new_tokens.
          Unfortunately none of those attempts resulted in a more promising outcome.
          I may come back to this another time, but I need to try another model for
          now. Thanks!
        updatedAt: '2024-01-08T13:14:32.011Z'
      numEdits: 0
      reactions: []
    id: 659bf5382dfa5014dfe6cc68
    type: comment
  author: CXDuncan
  content: I've tried a few different ways now, including setting max_new_tokens.
    Unfortunately none of those attempts resulted in a more promising outcome. I may
    come back to this another time, but I need to try another model for now. Thanks!
  created_at: 2024-01-08 13:14:32+00:00
  edited: false
  hidden: false
  id: 659bf5382dfa5014dfe6cc68
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/65c1d87a49651ec1efcbb9ce7cfe9a74.svg
      fullname: Jordan Duncan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CXDuncan
      type: user
    createdAt: '2024-01-08T14:25:57.000Z'
    data:
      edited: false
      editors:
      - CXDuncan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.39610224962234497
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/65c1d87a49651ec1efcbb9ce7cfe9a74.svg
          fullname: Jordan Duncan
          isHf: false
          isPro: false
          name: CXDuncan
          type: user
        html: "<p>I dunno exactly what I did differently this time with another max_new_tokens\
          \ attempt, but this DOES work: </p>\n<pre><code>class Translator:\n    def\
          \ __init__(self, model_name_or_path: str = 'google/madlad400-3b-mt') -&gt;\
          \ None:\n        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path,\
          \ device_map=\"auto\")\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n\
          \n    def translate(self, input_text: str, target_language: str = \"en\"\
          ) -&gt; str:\n        inputs = self.tokenizer(f\"&lt;2{target_language}&gt;\
          \ {input_text}\", return_tensors=\"pt\").to(self.model.device)\n       \
          \ output_ids = self.model.generate(**inputs, max_new_tokens=4000)\n    \
          \    output = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n\
          </code></pre>\n"
        raw: "I dunno exactly what I did differently this time with another max_new_tokens\
          \ attempt, but this DOES work: \n\n```\nclass Translator:\n    def __init__(self,\
          \ model_name_or_path: str = 'google/madlad400-3b-mt') -> None:\n       \
          \ self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path,\
          \ device_map=\"auto\")\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n\
          \n    def translate(self, input_text: str, target_language: str = \"en\"\
          ) -> str:\n        inputs = self.tokenizer(f\"<2{target_language}> {input_text}\"\
          , return_tensors=\"pt\").to(self.model.device)\n        output_ids = self.model.generate(**inputs,\
          \ max_new_tokens=4000)\n        output = self.tokenizer.batch_decode(output_ids,\
          \ skip_special_tokens=True)\n```"
        updatedAt: '2024-01-08T14:25:57.193Z'
      numEdits: 0
      reactions: []
      relatedEventId: 659c05f587036872efde35f9
    id: 659c05f587036872efde35f3
    type: comment
  author: CXDuncan
  content: "I dunno exactly what I did differently this time with another max_new_tokens\
    \ attempt, but this DOES work: \n\n```\nclass Translator:\n    def __init__(self,\
    \ model_name_or_path: str = 'google/madlad400-3b-mt') -> None:\n        self.model\
    \ = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, device_map=\"auto\"\
    )\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n\
    \n    def translate(self, input_text: str, target_language: str = \"en\") -> str:\n\
    \        inputs = self.tokenizer(f\"<2{target_language}> {input_text}\", return_tensors=\"\
    pt\").to(self.model.device)\n        output_ids = self.model.generate(**inputs,\
    \ max_new_tokens=4000)\n        output = self.tokenizer.batch_decode(output_ids,\
    \ skip_special_tokens=True)\n```"
  created_at: 2024-01-08 14:25:57+00:00
  edited: false
  hidden: false
  id: 659c05f587036872efde35f3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/65c1d87a49651ec1efcbb9ce7cfe9a74.svg
      fullname: Jordan Duncan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CXDuncan
      type: user
    createdAt: '2024-01-08T14:25:57.000Z'
    data:
      status: closed
    id: 659c05f587036872efde35f9
    type: status-change
  author: CXDuncan
  created_at: 2024-01-08 14:25:57+00:00
  id: 659c05f587036872efde35f9
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/65c1d87a49651ec1efcbb9ce7cfe9a74.svg
      fullname: Jordan Duncan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: CXDuncan
      type: user
    createdAt: '2024-01-08T14:26:51.000Z'
    data:
      edited: false
      editors:
      - CXDuncan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.39867445826530457
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/65c1d87a49651ec1efcbb9ce7cfe9a74.svg
          fullname: Jordan Duncan
          isHf: false
          isPro: false
          name: CXDuncan
          type: user
        html: '<p>ohhhhh! -1 is not a valid max_new_tokens value....</p>

          '
        raw: ohhhhh! -1 is not a valid max_new_tokens value....
        updatedAt: '2024-01-08T14:26:51.462Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jbochi
    id: 659c062bcb14854e70db2326
    type: comment
  author: CXDuncan
  content: ohhhhh! -1 is not a valid max_new_tokens value....
  created_at: 2024-01-08 14:26:51+00:00
  edited: false
  hidden: false
  id: 659c062bcb14854e70db2326
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: jbochi/madlad400-3b-mt
repo_type: model
status: closed
target_branch: null
title: Translations are getting cut short
