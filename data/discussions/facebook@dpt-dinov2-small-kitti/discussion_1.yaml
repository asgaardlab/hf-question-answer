!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sfxsfx
conflicting_files: null
created_at: 2023-11-08 11:53:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/97cd351e6110f61b2a96a65243badb1a.svg
      fullname: Ivan L
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sfxsfx
      type: user
    createdAt: '2023-11-08T11:53:59.000Z'
    data:
      edited: false
      editors:
      - sfxsfx
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.36494016647338867
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/97cd351e6110f61b2a96a65243badb1a.svg
          fullname: Ivan L
          isHf: false
          isPro: false
          name: sfxsfx
          type: user
        html: "<p>I am trying to follow the model card, however I get the following\
          \ error:</p>\n<pre><code class=\"language-python\">---------------------------------------------------------------------------\n\
          TypeError                                 Traceback (most recent call last)\n\
          Cell In[<span class=\"hljs-number\">6</span>], line <span class=\"hljs-number\"\
          >5</span>\n      <span class=\"hljs-number\">2</span> image = Image.<span\
          \ class=\"hljs-built_in\">open</span>(requests.get(url, stream=<span class=\"\
          hljs-literal\">True</span>).raw)\n      <span class=\"hljs-number\">4</span>\
          \ image_processor = AutoImageProcessor.from_pretrained(<span class=\"hljs-string\"\
          >\"facebook/dpt-dinov2-small-kitti\"</span>)\n----&gt; <span class=\"hljs-number\"\
          >5</span> model = DPTForDepthEstimation.from_pretrained(<span class=\"hljs-string\"\
          >\"facebook/dpt-dinov2-small-kitti\"</span>)\n\nFile ~/miniconda3/envs/hug/lib/python3<span\
          \ class=\"hljs-number\">.9</span>/site-packages/transformers/modeling_utils.py:<span\
          \ class=\"hljs-number\">2959</span>, <span class=\"hljs-keyword\">in</span>\
          \ PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, config,\
          \ cache_dir, ignore_mismatched_sizes, force_download, local_files_only,\
          \ token, revision, use_safetensors, *model_args, **kwargs)\n   <span class=\"\
          hljs-number\">2956</span>     init_contexts.append(init_empty_weights())\n\
          \   <span class=\"hljs-number\">2958</span> <span class=\"hljs-keyword\"\
          >with</span> ContextManagers(init_contexts):\n-&gt; <span class=\"hljs-number\"\
          >2959</span>     model = cls(config, *model_args, **model_kwargs)\n   <span\
          \ class=\"hljs-number\">2961</span> <span class=\"hljs-comment\"># Check\
          \ first if we are `from_pt`</span>\n   <span class=\"hljs-number\">2962</span>\
          \ <span class=\"hljs-keyword\">if</span> use_keep_in_fp32_modules:\n\nFile\
          \ ~/miniconda3/envs/hug/lib/python3<span class=\"hljs-number\">.9</span>/site-packages/transformers/models/dpt/modeling_dpt.py:<span\
          \ class=\"hljs-number\">1056</span>, <span class=\"hljs-keyword\">in</span>\
          \ DPTForDepthEstimation.__init__(self, config)\n   <span class=\"hljs-number\"\
          >1053</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\
          \ function_\">__init__</span>(<span class=\"hljs-params\">self, config</span>):\n\
          \   <span class=\"hljs-number\">1054</span>     <span class=\"hljs-built_in\"\
          >super</span>().__init__(config)\n-&gt; <span class=\"hljs-number\">1056</span>\
          \     self.dpt = DPTModel(config, add_pooling_layer=<span class=\"hljs-literal\"\
          >False</span>)\n   <span class=\"hljs-number\">1058</span>     <span class=\"\
          hljs-comment\"># Neck</span>\n   <span class=\"hljs-number\">1059</span>\
          \     self.neck = DPTNeck(config)\n\nFile ~/miniconda3/envs/hug/lib/python3<span\
          \ class=\"hljs-number\">.9</span>/site-packages/transformers/models/dpt/modeling_dpt.py:<span\
          \ class=\"hljs-number\">873</span>, <span class=\"hljs-keyword\">in</span>\
          \ DPTModel.__init__(self, config, add_pooling_layer)\n    <span class=\"\
          hljs-number\">871</span>     self.embeddings = DPTViTHybridEmbeddings(config)\n\
          \    <span class=\"hljs-number\">872</span> <span class=\"hljs-keyword\"\
          >else</span>:\n--&gt; <span class=\"hljs-number\">873</span>     self.embeddings\
          \ = DPTViTEmbeddings(config)\n    <span class=\"hljs-number\">874</span>\
          \ self.encoder = DPTViTEncoder(config)\n    <span class=\"hljs-number\"\
          >876</span> self.layernorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n\
          \nFile ~/miniconda3/envs/hug/lib/python3<span class=\"hljs-number\">.9</span>/site-packages/transformers/models/dpt/modeling_dpt.py:<span\
          \ class=\"hljs-number\">229</span>, <span class=\"hljs-keyword\">in</span>\
          \ DPTViTEmbeddings.__init__(self, config)\n    <span class=\"hljs-number\"\
          >226</span> <span class=\"hljs-built_in\">super</span>().__init__()\n  \
          \  <span class=\"hljs-number\">228</span> self.cls_token = nn.Parameter(torch.zeros(<span\
          \ class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>,\
          \ config.hidden_size))\n--&gt; <span class=\"hljs-number\">229</span> self.patch_embeddings\
          \ = DPTViTPatchEmbeddings(config)\n    <span class=\"hljs-number\">230</span>\
          \ num_patches = self.patch_embeddings.num_patches\n    <span class=\"hljs-number\"\
          >231</span> self.position_embeddings = nn.Parameter(torch.zeros(<span class=\"\
          hljs-number\">1</span>, num_patches + <span class=\"hljs-number\">1</span>,\
          \ config.hidden_size))\n\nFile ~/miniconda3/envs/hug/lib/python3<span class=\"\
          hljs-number\">.9</span>/site-packages/transformers/models/dpt/modeling_dpt.py:<span\
          \ class=\"hljs-number\">290</span>, <span class=\"hljs-keyword\">in</span>\
          \ DPTViTPatchEmbeddings.__init__(self, config)\n    <span class=\"hljs-number\"\
          >288</span> image_size = image_size <span class=\"hljs-keyword\">if</span>\
          \ <span class=\"hljs-built_in\">isinstance</span>(image_size, collections.abc.Iterable)\
          \ <span class=\"hljs-keyword\">else</span> (image_size, image_size)\n  \
          \  <span class=\"hljs-number\">289</span> patch_size = patch_size <span\
          \ class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(patch_size,\
          \ collections.abc.Iterable) <span class=\"hljs-keyword\">else</span> (patch_size,\
          \ patch_size)\n--&gt; <span class=\"hljs-number\">290</span> num_patches\
          \ = (image_size[<span class=\"hljs-number\">1</span>] // patch_size[<span\
          \ class=\"hljs-number\">1</span>]) * (image_size[<span class=\"hljs-number\"\
          >0</span>] // patch_size[<span class=\"hljs-number\">0</span>])\n    <span\
          \ class=\"hljs-number\">291</span> self.image_size = image_size\n    <span\
          \ class=\"hljs-number\">292</span> self.patch_size = patch_size\n\nTypeError:\
          \ unsupported operand <span class=\"hljs-built_in\">type</span>(s) <span\
          \ class=\"hljs-keyword\">for</span> //: <span class=\"hljs-string\">'NoneType'</span>\
          \ <span class=\"hljs-keyword\">and</span> <span class=\"hljs-string\">'NoneType'</span>\n\
          </code></pre>\n<p>I tried with <code>facebook/dpt-dinov2-large-kitti</code>,\
          \ same error.</p>\n"
        raw: "I am trying to follow the model card, however I get the following error:\r\
          \n\r\n```python\r\n---------------------------------------------------------------------------\r\
          \nTypeError                                 Traceback (most recent call\
          \ last)\r\nCell In[6], line 5\r\n      2 image = Image.open(requests.get(url,\
          \ stream=True).raw)\r\n      4 image_processor = AutoImageProcessor.from_pretrained(\"\
          facebook/dpt-dinov2-small-kitti\")\r\n----> 5 model = DPTForDepthEstimation.from_pretrained(\"\
          facebook/dpt-dinov2-small-kitti\")\r\n\r\nFile ~/miniconda3/envs/hug/lib/python3.9/site-packages/transformers/modeling_utils.py:2959,\
          \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path,\
          \ config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only,\
          \ token, revision, use_safetensors, *model_args, **kwargs)\r\n   2956  \
          \   init_contexts.append(init_empty_weights())\r\n   2958 with ContextManagers(init_contexts):\r\
          \n-> 2959     model = cls(config, *model_args, **model_kwargs)\r\n   2961\
          \ # Check first if we are `from_pt`\r\n   2962 if use_keep_in_fp32_modules:\r\
          \n\r\nFile ~/miniconda3/envs/hug/lib/python3.9/site-packages/transformers/models/dpt/modeling_dpt.py:1056,\
          \ in DPTForDepthEstimation.__init__(self, config)\r\n   1053 def __init__(self,\
          \ config):\r\n   1054     super().__init__(config)\r\n-> 1056     self.dpt\
          \ = DPTModel(config, add_pooling_layer=False)\r\n   1058     # Neck\r\n\
          \   1059     self.neck = DPTNeck(config)\r\n\r\nFile ~/miniconda3/envs/hug/lib/python3.9/site-packages/transformers/models/dpt/modeling_dpt.py:873,\
          \ in DPTModel.__init__(self, config, add_pooling_layer)\r\n    871     self.embeddings\
          \ = DPTViTHybridEmbeddings(config)\r\n    872 else:\r\n--> 873     self.embeddings\
          \ = DPTViTEmbeddings(config)\r\n    874 self.encoder = DPTViTEncoder(config)\r\
          \n    876 self.layernorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\r\
          \n\r\nFile ~/miniconda3/envs/hug/lib/python3.9/site-packages/transformers/models/dpt/modeling_dpt.py:229,\
          \ in DPTViTEmbeddings.__init__(self, config)\r\n    226 super().__init__()\r\
          \n    228 self.cls_token = nn.Parameter(torch.zeros(1, 1, config.hidden_size))\r\
          \n--> 229 self.patch_embeddings = DPTViTPatchEmbeddings(config)\r\n    230\
          \ num_patches = self.patch_embeddings.num_patches\r\n    231 self.position_embeddings\
          \ = nn.Parameter(torch.zeros(1, num_patches + 1, config.hidden_size))\r\n\
          \r\nFile ~/miniconda3/envs/hug/lib/python3.9/site-packages/transformers/models/dpt/modeling_dpt.py:290,\
          \ in DPTViTPatchEmbeddings.__init__(self, config)\r\n    288 image_size\
          \ = image_size if isinstance(image_size, collections.abc.Iterable) else\
          \ (image_size, image_size)\r\n    289 patch_size = patch_size if isinstance(patch_size,\
          \ collections.abc.Iterable) else (patch_size, patch_size)\r\n--> 290 num_patches\
          \ = (image_size[1] // patch_size[1]) * (image_size[0] // patch_size[0])\r\
          \n    291 self.image_size = image_size\r\n    292 self.patch_size = patch_size\r\
          \n\r\nTypeError: unsupported operand type(s) for //: 'NoneType' and 'NoneType'\r\
          \n```\r\n\r\nI tried with `facebook/dpt-dinov2-large-kitti`, same error."
        updatedAt: '2023-11-08T11:53:59.207Z'
      numEdits: 0
      reactions: []
    id: 654b76d703792887e2cd07f6
    type: comment
  author: sfxsfx
  content: "I am trying to follow the model card, however I get the following error:\r\
    \n\r\n```python\r\n---------------------------------------------------------------------------\r\
    \nTypeError                                 Traceback (most recent call last)\r\
    \nCell In[6], line 5\r\n      2 image = Image.open(requests.get(url, stream=True).raw)\r\
    \n      4 image_processor = AutoImageProcessor.from_pretrained(\"facebook/dpt-dinov2-small-kitti\"\
    )\r\n----> 5 model = DPTForDepthEstimation.from_pretrained(\"facebook/dpt-dinov2-small-kitti\"\
    )\r\n\r\nFile ~/miniconda3/envs/hug/lib/python3.9/site-packages/transformers/modeling_utils.py:2959,\
    \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, config,\
    \ cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token,\
    \ revision, use_safetensors, *model_args, **kwargs)\r\n   2956     init_contexts.append(init_empty_weights())\r\
    \n   2958 with ContextManagers(init_contexts):\r\n-> 2959     model = cls(config,\
    \ *model_args, **model_kwargs)\r\n   2961 # Check first if we are `from_pt`\r\n\
    \   2962 if use_keep_in_fp32_modules:\r\n\r\nFile ~/miniconda3/envs/hug/lib/python3.9/site-packages/transformers/models/dpt/modeling_dpt.py:1056,\
    \ in DPTForDepthEstimation.__init__(self, config)\r\n   1053 def __init__(self,\
    \ config):\r\n   1054     super().__init__(config)\r\n-> 1056     self.dpt = DPTModel(config,\
    \ add_pooling_layer=False)\r\n   1058     # Neck\r\n   1059     self.neck = DPTNeck(config)\r\
    \n\r\nFile ~/miniconda3/envs/hug/lib/python3.9/site-packages/transformers/models/dpt/modeling_dpt.py:873,\
    \ in DPTModel.__init__(self, config, add_pooling_layer)\r\n    871     self.embeddings\
    \ = DPTViTHybridEmbeddings(config)\r\n    872 else:\r\n--> 873     self.embeddings\
    \ = DPTViTEmbeddings(config)\r\n    874 self.encoder = DPTViTEncoder(config)\r\
    \n    876 self.layernorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\r\
    \n\r\nFile ~/miniconda3/envs/hug/lib/python3.9/site-packages/transformers/models/dpt/modeling_dpt.py:229,\
    \ in DPTViTEmbeddings.__init__(self, config)\r\n    226 super().__init__()\r\n\
    \    228 self.cls_token = nn.Parameter(torch.zeros(1, 1, config.hidden_size))\r\
    \n--> 229 self.patch_embeddings = DPTViTPatchEmbeddings(config)\r\n    230 num_patches\
    \ = self.patch_embeddings.num_patches\r\n    231 self.position_embeddings = nn.Parameter(torch.zeros(1,\
    \ num_patches + 1, config.hidden_size))\r\n\r\nFile ~/miniconda3/envs/hug/lib/python3.9/site-packages/transformers/models/dpt/modeling_dpt.py:290,\
    \ in DPTViTPatchEmbeddings.__init__(self, config)\r\n    288 image_size = image_size\
    \ if isinstance(image_size, collections.abc.Iterable) else (image_size, image_size)\r\
    \n    289 patch_size = patch_size if isinstance(patch_size, collections.abc.Iterable)\
    \ else (patch_size, patch_size)\r\n--> 290 num_patches = (image_size[1] // patch_size[1])\
    \ * (image_size[0] // patch_size[0])\r\n    291 self.image_size = image_size\r\
    \n    292 self.patch_size = patch_size\r\n\r\nTypeError: unsupported operand type(s)\
    \ for //: 'NoneType' and 'NoneType'\r\n```\r\n\r\nI tried with `facebook/dpt-dinov2-large-kitti`,\
    \ same error."
  created_at: 2023-11-08 11:53:59+00:00
  edited: false
  hidden: false
  id: 654b76d703792887e2cd07f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7fdb70a538cd7226c10668828ca936f9.svg
      fullname: Tobias Zimmermann
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tzimmermann
      type: user
    createdAt: '2023-11-20T08:21:49.000Z'
    data:
      edited: false
      editors:
      - tzimmermann
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9677773714065552
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7fdb70a538cd7226c10668828ca936f9.svg
          fullname: Tobias Zimmermann
          isHf: false
          isPro: false
          name: tzimmermann
          type: user
        html: "<p>Getting the same error with all dpt-dinov2s, any suggestions? <span\
          \ data-props=\"{&quot;user&quot;:&quot;nielsr&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/nielsr\">@<span class=\"underline\"\
          >nielsr</span></a></span>\n\n\t</span></span>  I saw that you were working\
          \ on dpt-Dinov2 do you have any idea? </p>\n"
        raw: 'Getting the same error with all dpt-dinov2s, any suggestions? @nielsr  I
          saw that you were working on dpt-Dinov2 do you have any idea? '
        updatedAt: '2023-11-20T08:21:49.068Z'
      numEdits: 0
      reactions: []
    id: 655b171dab0644b531bd92b6
    type: comment
  author: tzimmermann
  content: 'Getting the same error with all dpt-dinov2s, any suggestions? @nielsr  I
    saw that you were working on dpt-Dinov2 do you have any idea? '
  created_at: 2023-11-20 08:21:49+00:00
  edited: false
  hidden: false
  id: 655b171dab0644b531bd92b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2023-11-20T09:07:15.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9156845808029175
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Hi,</p>

          <p>You might need to install Transformers from main for now (DPT with AutoBackbone
          support is not yet included in a new release): pip install git+<a rel="nofollow"
          href="https://github.com/huggingface/transformers.git">https://github.com/huggingface/transformers.git</a></p>

          '
        raw: 'Hi,


          You might need to install Transformers from main for now (DPT with AutoBackbone
          support is not yet included in a new release): pip install git+https://github.com/huggingface/transformers.git'
        updatedAt: '2023-11-20T09:07:15.408Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - tzimmermann
        - FatemehBehrad
      - count: 1
        reaction: "\U0001F917"
        users:
        - FatemehBehrad
    id: 655b21c3c68499a1b99ac165
    type: comment
  author: nielsr
  content: 'Hi,


    You might need to install Transformers from main for now (DPT with AutoBackbone
    support is not yet included in a new release): pip install git+https://github.com/huggingface/transformers.git'
  created_at: 2023-11-20 09:07:15+00:00
  edited: false
  hidden: false
  id: 655b21c3c68499a1b99ac165
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7fdb70a538cd7226c10668828ca936f9.svg
      fullname: Tobias Zimmermann
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tzimmermann
      type: user
    createdAt: '2023-11-20T09:19:34.000Z'
    data:
      edited: false
      editors:
      - tzimmermann
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.969183087348938
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7fdb70a538cd7226c10668828ca936f9.svg
          fullname: Tobias Zimmermann
          isHf: false
          isPro: false
          name: tzimmermann
          type: user
        html: '<p>Ah great, that worked out! Thanks for the help and for your work
          on the DPT with AutoBackbone support! </p>

          '
        raw: 'Ah great, that worked out! Thanks for the help and for your work on
          the DPT with AutoBackbone support! '
        updatedAt: '2023-11-20T09:19:34.736Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - nielsr
    id: 655b24a6c619b485319289df
    type: comment
  author: tzimmermann
  content: 'Ah great, that worked out! Thanks for the help and for your work on the
    DPT with AutoBackbone support! '
  created_at: 2023-11-20 09:19:34+00:00
  edited: false
  hidden: false
  id: 655b24a6c619b485319289df
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2024-01-22T13:10:31.000Z'
    data:
      status: closed
    id: 65ae6947dd6bdfd73c2ef4c4
    type: status-change
  author: nielsr
  created_at: 2024-01-22 13:10:31+00:00
  id: 65ae6947dd6bdfd73c2ef4c4
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: facebook/dpt-dinov2-small-kitti
repo_type: model
status: closed
target_branch: null
title: Error following the model card
