!!python/object:huggingface_hub.community.DiscussionWithDetails
author: actuallyasriel
conflicting_files: null
created_at: 2024-01-23 06:54:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe8c7b641cb77412431bba24d95b316f.svg
      fullname: Asriel Yuill
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: actuallyasriel
      type: user
    createdAt: '2024-01-23T06:54:02.000Z'
    data:
      edited: false
      editors:
      - actuallyasriel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9386425614356995
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe8c7b641cb77412431bba24d95b316f.svg
          fullname: Asriel Yuill
          isHf: false
          isPro: false
          name: actuallyasriel
          type: user
        html: '<p>When you say that this model uses ChatML''s prompting format, but
          not the special token, what do you mean by "special token" in this case?</p>

          <p>Sorry if this is kind of a noob question, I''m just trying to see if
          I need to alter something in SillyTavern''s ChatML presets for this to work
          properly (as I''m getting ### Response: in outputs despite that not being
          in the prompt at all.)</p>

          '
        raw: "When you say that this model uses ChatML's prompting format, but not\
          \ the special token, what do you mean by \"special token\" in this case?\r\
          \n\r\nSorry if this is kind of a noob question, I'm just trying to see if\
          \ I need to alter something in SillyTavern's ChatML presets for this to\
          \ work properly (as I'm getting ### Response: in outputs despite that not\
          \ being in the prompt at all.)"
        updatedAt: '2024-01-23T06:54:02.856Z'
      numEdits: 0
      reactions: []
    id: 65af628a0c672a0004878680
    type: comment
  author: actuallyasriel
  content: "When you say that this model uses ChatML's prompting format, but not the\
    \ special token, what do you mean by \"special token\" in this case?\r\n\r\nSorry\
    \ if this is kind of a noob question, I'm just trying to see if I need to alter\
    \ something in SillyTavern's ChatML presets for this to work properly (as I'm\
    \ getting ### Response: in outputs despite that not being in the prompt at all.)"
  created_at: 2024-01-23 06:54:02+00:00
  edited: false
  hidden: false
  id: 65af628a0c672a0004878680
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b534842bd3611e666bbdc3/TLhYkNTb7xKiKkyuBJAc1.png?w=200&h=200&f=face
      fullname: Zack Stone
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: zaq-hack
      type: user
    createdAt: '2024-01-23T16:55:58.000Z'
    data:
      edited: false
      editors:
      - zaq-hack
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9685055017471313
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63b534842bd3611e666bbdc3/TLhYkNTb7xKiKkyuBJAc1.png?w=200&h=200&f=face
          fullname: Zack Stone
          isHf: false
          isPro: false
          name: zaq-hack
          type: user
        html: '<p>Yeah, in SillyTavern, I try to use the ChatML presets. You might
          have to check "Use as stop strings" to keep from getting that bleed over.</p>

          '
        raw: Yeah, in SillyTavern, I try to use the ChatML presets. You might have
          to check "Use as stop strings" to keep from getting that bleed over.
        updatedAt: '2024-01-23T16:55:58.075Z'
      numEdits: 0
      reactions: []
    id: 65afef9eaa335c2842f06d91
    type: comment
  author: zaq-hack
  content: Yeah, in SillyTavern, I try to use the ChatML presets. You might have to
    check "Use as stop strings" to keep from getting that bleed over.
  created_at: 2024-01-23 16:55:58+00:00
  edited: false
  hidden: false
  id: 65afef9eaa335c2842f06d91
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fe8c7b641cb77412431bba24d95b316f.svg
      fullname: Asriel Yuill
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: actuallyasriel
      type: user
    createdAt: '2024-01-23T19:31:14.000Z'
    data:
      edited: false
      editors:
      - actuallyasriel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.990025520324707
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fe8c7b641cb77412431bba24d95b316f.svg
          fullname: Asriel Yuill
          isHf: false
          isPro: false
          name: actuallyasriel
          type: user
        html: '<p>yeah i can never get those to work even on models that explicitly
          suggest them; maybe it''s the "use as stop strings" thing that i need</p>

          '
        raw: yeah i can never get those to work even on models that explicitly suggest
          them; maybe it's the "use as stop strings" thing that i need
        updatedAt: '2024-01-23T19:31:14.446Z'
      numEdits: 0
      reactions: []
    id: 65b014027febbcc2afb1e2a3
    type: comment
  author: actuallyasriel
  content: yeah i can never get those to work even on models that explicitly suggest
    them; maybe it's the "use as stop strings" thing that i need
  created_at: 2024-01-23 19:31:14+00:00
  edited: false
  hidden: false
  id: 65b014027febbcc2afb1e2a3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: zaq-hack/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-bpw300-h6-exl2
repo_type: model
status: open
target_branch: null
title: Quick question about prompting format
