!!python/object:huggingface_hub.community.DiscussionWithDetails
author: NePe
conflicting_files: null
created_at: 2023-03-21 19:43:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/793d0a07bc37dacc5b0a486e4bf11d7f.svg
      fullname: Peter Kis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NePe
      type: user
    createdAt: '2023-03-21T20:43:56.000Z'
    data:
      edited: false
      editors:
      - NePe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/793d0a07bc37dacc5b0a486e4bf11d7f.svg
          fullname: Peter Kis
          isHf: false
          isPro: false
          name: NePe
          type: user
        html: '<p>What should i use to do inference with this model? I tried GPTQ-for-LLaMa
          but it showed checkpoint shape mismatch errors.</p>

          '
        raw: What should i use to do inference with this model? I tried GPTQ-for-LLaMa
          but it showed checkpoint shape mismatch errors.
        updatedAt: '2023-03-21T20:43:56.708Z'
      numEdits: 0
      reactions: []
    id: 641a170cf9dd6391a24335c5
    type: comment
  author: NePe
  content: What should i use to do inference with this model? I tried GPTQ-for-LLaMa
    but it showed checkpoint shape mismatch errors.
  created_at: 2023-03-21 19:43:56+00:00
  edited: false
  hidden: false
  id: 641a170cf9dd6391a24335c5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
      fullname: elinas
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: elinas
      type: user
    createdAt: '2023-03-21T22:24:12.000Z'
    data:
      edited: false
      editors:
      - elinas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
          fullname: elinas
          isHf: false
          isPro: false
          name: elinas
          type: user
        html: '<p>Please show an error log, what specs you are running, any extensions
          like the text generation UI... etc. More info the better.</p>

          '
        raw: Please show an error log, what specs you are running, any extensions
          like the text generation UI... etc. More info the better.
        updatedAt: '2023-03-21T22:24:12.440Z'
      numEdits: 0
      reactions: []
    id: 641a2e8ce9cc9f1bf3363086
    type: comment
  author: elinas
  content: Please show an error log, what specs you are running, any extensions like
    the text generation UI... etc. More info the better.
  created_at: 2023-03-21 21:24:12+00:00
  edited: false
  hidden: false
  id: 641a2e8ce9cc9f1bf3363086
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/793d0a07bc37dacc5b0a486e4bf11d7f.svg
      fullname: Peter Kis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NePe
      type: user
    createdAt: '2023-03-21T22:40:46.000Z'
    data:
      edited: false
      editors:
      - NePe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/793d0a07bc37dacc5b0a486e4bf11d7f.svg
          fullname: Peter Kis
          isHf: false
          isPro: false
          name: NePe
          type: user
        html: '<p>I just installed/tried the GPTQ-for-LLaMa code from github with
          the llama_inference.py. I tried many lora/non lora 4bit models from HF and
          it seems like only the ozcur/alpaca-native-4bit working for me. The other
          ones give RuntimeError: Error(s) in loading state_dict for LlamaForCausalLM:
          Missing key(s) in state_dict: ... Unexpected key(s) in state_dict: ...  size
          mismatch for model.layers ... errors.</p>

          '
        raw: 'I just installed/tried the GPTQ-for-LLaMa code from github with the
          llama_inference.py. I tried many lora/non lora 4bit models from HF and it
          seems like only the ozcur/alpaca-native-4bit working for me. The other ones
          give RuntimeError: Error(s) in loading state_dict for LlamaForCausalLM:
          Missing key(s) in state_dict: ... Unexpected key(s) in state_dict: ...  size
          mismatch for model.layers ... errors.'
        updatedAt: '2023-03-21T22:40:46.804Z'
      numEdits: 0
      reactions: []
    id: 641a326ee15dc827d9abad2a
    type: comment
  author: NePe
  content: 'I just installed/tried the GPTQ-for-LLaMa code from github with the llama_inference.py.
    I tried many lora/non lora 4bit models from HF and it seems like only the ozcur/alpaca-native-4bit
    working for me. The other ones give RuntimeError: Error(s) in loading state_dict
    for LlamaForCausalLM: Missing key(s) in state_dict: ... Unexpected key(s) in state_dict:
    ...  size mismatch for model.layers ... errors.'
  created_at: 2023-03-21 21:40:46+00:00
  edited: false
  hidden: false
  id: 641a326ee15dc827d9abad2a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/793d0a07bc37dacc5b0a486e4bf11d7f.svg
      fullname: Peter Kis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NePe
      type: user
    createdAt: '2023-03-21T22:50:15.000Z'
    data:
      edited: false
      editors:
      - NePe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/793d0a07bc37dacc5b0a486e4bf11d7f.svg
          fullname: Peter Kis
          isHf: false
          isPro: false
          name: NePe
          type: user
        html: '<p>Must be a rename in one of the libs, i compared the missing/unexpected
          keys ex:<br>missing: model.layers.0.self_attn.q_proj.qzeros<br>unexpected:
          model.layers.0.self_attn.q_proj.zeros</p>

          '
        raw: 'Must be a rename in one of the libs, i compared the missing/unexpected
          keys ex:

          missing: model.layers.0.self_attn.q_proj.qzeros

          unexpected: model.layers.0.self_attn.q_proj.zeros'
        updatedAt: '2023-03-21T22:50:15.990Z'
      numEdits: 0
      reactions: []
    id: 641a34a7f1ad1c1173d8bb81
    type: comment
  author: NePe
  content: 'Must be a rename in one of the libs, i compared the missing/unexpected
    keys ex:

    missing: model.layers.0.self_attn.q_proj.qzeros

    unexpected: model.layers.0.self_attn.q_proj.zeros'
  created_at: 2023-03-21 21:50:15+00:00
  edited: false
  hidden: false
  id: 641a34a7f1ad1c1173d8bb81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/793d0a07bc37dacc5b0a486e4bf11d7f.svg
      fullname: Peter Kis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NePe
      type: user
    createdAt: '2023-03-21T22:56:46.000Z'
    data:
      edited: false
      editors:
      - NePe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/793d0a07bc37dacc5b0a486e4bf11d7f.svg
          fullname: Peter Kis
          isHf: false
          isPro: false
          name: NePe
          type: user
        html: '<p>Yep, seems like they renamed some stuff to broke the old stuff as
          usually happens:<br><a rel="nofollow" href="https://github.com/qwopqwop200/GPTQ-for-LLaMa/commit/a270974e732884126ddb36f64d0a0a25261bb94f">https://github.com/qwopqwop200/GPTQ-for-LLaMa/commit/a270974e732884126ddb36f64d0a0a25261bb94f</a></p>

          '
        raw: 'Yep, seems like they renamed some stuff to broke the old stuff as usually
          happens:

          https://github.com/qwopqwop200/GPTQ-for-LLaMa/commit/a270974e732884126ddb36f64d0a0a25261bb94f'
        updatedAt: '2023-03-21T22:56:46.151Z'
      numEdits: 0
      reactions: []
    id: 641a362ee3def7b7bf1b9f39
    type: comment
  author: NePe
  content: 'Yep, seems like they renamed some stuff to broke the old stuff as usually
    happens:

    https://github.com/qwopqwop200/GPTQ-for-LLaMa/commit/a270974e732884126ddb36f64d0a0a25261bb94f'
  created_at: 2023-03-21 21:56:46+00:00
  edited: false
  hidden: false
  id: 641a362ee3def7b7bf1b9f39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/793d0a07bc37dacc5b0a486e4bf11d7f.svg
      fullname: Peter Kis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NePe
      type: user
    createdAt: '2023-03-21T23:08:05.000Z'
    data:
      edited: false
      editors:
      - NePe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/793d0a07bc37dacc5b0a486e4bf11d7f.svg
          fullname: Peter Kis
          isHf: false
          isPro: false
          name: NePe
          type: user
        html: '<p>If anyone has the same problem just downgrade to the older version
          of the lib:<br>git checkout 468c47c01b4fe370616747b6d69a2d3f48bab5e4<br>python
          setup_cuda.py install</p>

          <p>Seems to be working fine now :)</p>

          '
        raw: 'If anyone has the same problem just downgrade to the older version of
          the lib:

          git checkout 468c47c01b4fe370616747b6d69a2d3f48bab5e4

          python setup_cuda.py install


          Seems to be working fine now :)'
        updatedAt: '2023-03-21T23:08:05.709Z'
      numEdits: 0
      reactions: []
    id: 641a38d5f1ad1c1173d8f192
    type: comment
  author: NePe
  content: 'If anyone has the same problem just downgrade to the older version of
    the lib:

    git checkout 468c47c01b4fe370616747b6d69a2d3f48bab5e4

    python setup_cuda.py install


    Seems to be working fine now :)'
  created_at: 2023-03-21 22:08:05+00:00
  edited: false
  hidden: false
  id: 641a38d5f1ad1c1173d8f192
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c9ff1e8cd41470e5bf05a4f2050eac1a.svg
      fullname: Liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Davidliudev
      type: user
    createdAt: '2023-03-28T03:08:44.000Z'
    data:
      edited: false
      editors:
      - Davidliudev
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c9ff1e8cd41470e5bf05a4f2050eac1a.svg
          fullname: Liu
          isHf: false
          isPro: false
          name: Davidliudev
          type: user
        html: '<p>Now we cannot use this fix since webui also updated. I got parameter
          mismatch if i checkout an older commit</p>

          '
        raw: Now we cannot use this fix since webui also updated. I got parameter
          mismatch if i checkout an older commit
        updatedAt: '2023-03-28T03:08:44.239Z'
      numEdits: 0
      reactions: []
    id: 64225a3c5acad90e6b7344d1
    type: comment
  author: Davidliudev
  content: Now we cannot use this fix since webui also updated. I got parameter mismatch
    if i checkout an older commit
  created_at: 2023-03-28 02:08:44+00:00
  edited: false
  hidden: false
  id: 64225a3c5acad90e6b7344d1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
      fullname: elinas
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: elinas
      type: user
    createdAt: '2023-03-28T15:43:04.000Z'
    data:
      edited: false
      editors:
      - elinas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
          fullname: elinas
          isHf: false
          isPro: false
          name: elinas
          type: user
        html: '<p>New model is uploaded, going to close this issue.</p>

          '
        raw: New model is uploaded, going to close this issue.
        updatedAt: '2023-03-28T15:43:04.417Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64230b08ae7fe472976efaac
    id: 64230b08ae7fe472976efaab
    type: comment
  author: elinas
  content: New model is uploaded, going to close this issue.
  created_at: 2023-03-28 14:43:04+00:00
  edited: false
  hidden: false
  id: 64230b08ae7fe472976efaab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
      fullname: elinas
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: elinas
      type: user
    createdAt: '2023-03-28T15:43:04.000Z'
    data:
      status: closed
    id: 64230b08ae7fe472976efaac
    type: status-change
  author: elinas
  created_at: 2023-03-28 14:43:04+00:00
  id: 64230b08ae7fe472976efaac
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d6ca84cb252615dd24f7034a52885d61.svg
      fullname: Osher Ahron
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iChrist
      type: user
    createdAt: '2023-03-28T17:30:14.000Z'
    data:
      edited: false
      editors:
      - iChrist
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d6ca84cb252615dd24f7034a52885d61.svg
          fullname: Osher Ahron
          isHf: false
          isPro: false
          name: iChrist
          type: user
        html: '<blockquote>

          <p>New model is uploaded, going to close this issue.</p>

          </blockquote>

          <p>Any idea why text-generation-webui cannot find config.json file? I have
          everything needed in the folder.<br><a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui/issues/613">https://github.com/oobabooga/text-generation-webui/issues/613</a><br>Hope
          someone can figure it out</p>

          '
        raw: '> New model is uploaded, going to close this issue.


          Any idea why text-generation-webui cannot find config.json file? I have
          everything needed in the folder.

          https://github.com/oobabooga/text-generation-webui/issues/613

          Hope someone can figure it out'
        updatedAt: '2023-03-28T17:30:14.429Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F614"
        users:
        - disarmyouwitha
    id: 642324265aed4fac789f7375
    type: comment
  author: iChrist
  content: '> New model is uploaded, going to close this issue.


    Any idea why text-generation-webui cannot find config.json file? I have everything
    needed in the folder.

    https://github.com/oobabooga/text-generation-webui/issues/613

    Hope someone can figure it out'
  created_at: 2023-03-28 16:30:14+00:00
  edited: false
  hidden: false
  id: 642324265aed4fac789f7375
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/574d055ca3ee7ecab70385e44b8944ef.svg
      fullname: neural_worm
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: neuralworm
      type: user
    createdAt: '2023-04-05T18:01:54.000Z'
    data:
      edited: false
      editors:
      - neuralworm
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/574d055ca3ee7ecab70385e44b8944ef.svg
          fullname: neural_worm
          isHf: false
          isPro: false
          name: neuralworm
          type: user
        html: '<p>what about this?<br><a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui/issues/734#issuecomment-1496864694">https://github.com/oobabooga/text-generation-webui/issues/734#issuecomment-1496864694</a></p>

          <blockquote>

          <p>This branch contains the necessary changes to run the upstream cuda branch:
          <a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui/tree/new-qwop">https://github.com/oobabooga/text-generation-webui/tree/new-qwop</a></p>

          </blockquote>

          '
        raw: 'what about this?

          https://github.com/oobabooga/text-generation-webui/issues/734#issuecomment-1496864694

          > This branch contains the necessary changes to run the upstream cuda branch:
          https://github.com/oobabooga/text-generation-webui/tree/new-qwop'
        updatedAt: '2023-04-05T18:01:54.828Z'
      numEdits: 0
      reactions: []
    id: 642db7928ce1f7427b879820
    type: comment
  author: neuralworm
  content: 'what about this?

    https://github.com/oobabooga/text-generation-webui/issues/734#issuecomment-1496864694

    > This branch contains the necessary changes to run the upstream cuda branch:
    https://github.com/oobabooga/text-generation-webui/tree/new-qwop'
  created_at: 2023-04-05 17:01:54+00:00
  edited: false
  hidden: false
  id: 642db7928ce1f7427b879820
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: elinas/alpaca-30b-lora-int4
repo_type: model
status: closed
target_branch: null
title: How to do inferance?
