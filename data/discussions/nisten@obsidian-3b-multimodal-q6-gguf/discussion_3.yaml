!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nawal2
conflicting_files: null
created_at: 2023-12-21 14:02:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/361c0c14c27e6100379bfec9520886ef.svg
      fullname: Nawal Husnoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nawal2
      type: user
    createdAt: '2023-12-21T14:02:21.000Z'
    data:
      edited: true
      editors:
      - nawal2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.560502290725708
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/361c0c14c27e6100379bfec9520886ef.svg
          fullname: Nawal Husnoo
          isHf: false
          isPro: false
          name: nawal2
          type: user
        html: "<p>Using llama.cpp:  799fc2268989482054944c902874cca76337580f  Wed\
          \ Dec 20 15:41:22 2023</p>\n<pre><code> ./server -m models/obsidian-f16.gguf\
          \ --mmproj models/mmproj-obsidian-f16.gguf --host 0.0.0.0 \n</code></pre>\n\
          <pre><code>import requests\nimport json\nimport base64\n\nimage_path = '/home/nawal/IMG_20231210_220649_640x480.png'\n\
          \nwith open(image_path, 'rb') as image_file:\n    encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n\
          \nurl = 'http://192.168.0.52:8080/completion'\nheaders = { 'Content-Type':\
          \ 'application/json' }\ndata = {\n    'prompt': '''\n&lt;|im_start|&gt;user\n\
          What does this image contain?\\n&lt;image&gt;\n###\n&lt;|im_start|&gt;assistant''',\n\
          \    'n_predict': 512,\n    'top_k': 40,\n    'temperature': 0.2,\n    'image_data':\
          \ [{'data': encoded_string, 'id': 1}]\n}\nresponse = requests.post(url,\
          \ headers=headers, data=json.dumps(data))\n\n# Check the response\nif response.status_code\
          \ == 200:\n    print('Request successful!')\n    print(response.json())\
          \  # This will print the response content\nelse:\n    print('Request failed\
          \ with status code:', response.status_code)\n</code></pre>\n<p>This causes\
          \ the server to crash:</p>\n<pre><code>{\"timestamp\":1703167163,\"level\"\
          :\"INFO\",\"function\":\"log_server_request\",\"line\":2608,\"message\"\
          :\"request\",\"remote_addr\":\"192.168.0.10\",\"remote_port\":53312,\"status\"\
          :200,\"method\":\"GET\",\"path\":\"/completion.js\",\"params\":{}}\nslot\
          \ 0 - image loaded [id: 1] resolution (640 x 480)\nslot 0 is processing\
          \ [task id: 4]\nslot 0 : kv cache rm - [0, end)\nslot 0 : we have to evaluate\
          \ at least 1 token to generate logits\nslot 0 - encoding image [id: 1]\n\
          Segmentation fault (core dumped)\n</code></pre>\n"
        raw: "Using llama.cpp:  799fc2268989482054944c902874cca76337580f  Wed Dec\
          \ 20 15:41:22 2023\n\n```\n ./server -m models/obsidian-f16.gguf --mmproj\
          \ models/mmproj-obsidian-f16.gguf --host 0.0.0.0 \n```\n\n```\nimport requests\n\
          import json\nimport base64\n\nimage_path = '/home/nawal/IMG_20231210_220649_640x480.png'\n\
          \nwith open(image_path, 'rb') as image_file:\n    encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n\
          \nurl = 'http://192.168.0.52:8080/completion'\nheaders = { 'Content-Type':\
          \ 'application/json' }\ndata = {\n    'prompt': '''\n<|im_start|>user\n\
          What does this image contain?\\n<image>\n###\n<|im_start|>assistant''',\n\
          \    'n_predict': 512,\n    'top_k': 40,\n    'temperature': 0.2,\n    'image_data':\
          \ [{'data': encoded_string, 'id': 1}]\n}\nresponse = requests.post(url,\
          \ headers=headers, data=json.dumps(data))\n\n# Check the response\nif response.status_code\
          \ == 200:\n    print('Request successful!')\n    print(response.json())\
          \  # This will print the response content\nelse:\n    print('Request failed\
          \ with status code:', response.status_code)\n```\n\nThis causes the server\
          \ to crash:\n```\n{\"timestamp\":1703167163,\"level\":\"INFO\",\"function\"\
          :\"log_server_request\",\"line\":2608,\"message\":\"request\",\"remote_addr\"\
          :\"192.168.0.10\",\"remote_port\":53312,\"status\":200,\"method\":\"GET\"\
          ,\"path\":\"/completion.js\",\"params\":{}}\nslot 0 - image loaded [id:\
          \ 1] resolution (640 x 480)\nslot 0 is processing [task id: 4]\nslot 0 :\
          \ kv cache rm - [0, end)\nslot 0 : we have to evaluate at least 1 token\
          \ to generate logits\nslot 0 - encoding image [id: 1]\nSegmentation fault\
          \ (core dumped)\n```"
        updatedAt: '2023-12-21T14:03:24.586Z'
      numEdits: 2
      reactions: []
    id: 6584456da4af83584ca4ebc3
    type: comment
  author: nawal2
  content: "Using llama.cpp:  799fc2268989482054944c902874cca76337580f  Wed Dec 20\
    \ 15:41:22 2023\n\n```\n ./server -m models/obsidian-f16.gguf --mmproj models/mmproj-obsidian-f16.gguf\
    \ --host 0.0.0.0 \n```\n\n```\nimport requests\nimport json\nimport base64\n\n\
    image_path = '/home/nawal/IMG_20231210_220649_640x480.png'\n\nwith open(image_path,\
    \ 'rb') as image_file:\n    encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n\
    \nurl = 'http://192.168.0.52:8080/completion'\nheaders = { 'Content-Type': 'application/json'\
    \ }\ndata = {\n    'prompt': '''\n<|im_start|>user\nWhat does this image contain?\\\
    n<image>\n###\n<|im_start|>assistant''',\n    'n_predict': 512,\n    'top_k':\
    \ 40,\n    'temperature': 0.2,\n    'image_data': [{'data': encoded_string, 'id':\
    \ 1}]\n}\nresponse = requests.post(url, headers=headers, data=json.dumps(data))\n\
    \n# Check the response\nif response.status_code == 200:\n    print('Request successful!')\n\
    \    print(response.json())  # This will print the response content\nelse:\n \
    \   print('Request failed with status code:', response.status_code)\n```\n\nThis\
    \ causes the server to crash:\n```\n{\"timestamp\":1703167163,\"level\":\"INFO\"\
    ,\"function\":\"log_server_request\",\"line\":2608,\"message\":\"request\",\"\
    remote_addr\":\"192.168.0.10\",\"remote_port\":53312,\"status\":200,\"method\"\
    :\"GET\",\"path\":\"/completion.js\",\"params\":{}}\nslot 0 - image loaded [id:\
    \ 1] resolution (640 x 480)\nslot 0 is processing [task id: 4]\nslot 0 : kv cache\
    \ rm - [0, end)\nslot 0 : we have to evaluate at least 1 token to generate logits\n\
    slot 0 - encoding image [id: 1]\nSegmentation fault (core dumped)\n```"
  created_at: 2023-12-21 14:02:21+00:00
  edited: true
  hidden: false
  id: 6584456da4af83584ca4ebc3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/361c0c14c27e6100379bfec9520886ef.svg
      fullname: Nawal Husnoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nawal2
      type: user
    createdAt: '2023-12-21T14:10:10.000Z'
    data:
      edited: false
      editors:
      - nawal2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.887593150138855
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/361c0c14c27e6100379bfec9520886ef.svg
          fullname: Nawal Husnoo
          isHf: false
          isPro: false
          name: nawal2
          type: user
        html: '<p>Nope, I should have used [img-1] instead of <img>. Closing.</p>

          '
        raw: Nope, I should have used [img-1] instead of <img>. Closing.
        updatedAt: '2023-12-21T14:10:10.649Z'
      numEdits: 0
      reactions: []
      relatedEventId: 658447422031da25dac8b420
    id: 658447422031da25dac8b41d
    type: comment
  author: nawal2
  content: Nope, I should have used [img-1] instead of <img>. Closing.
  created_at: 2023-12-21 14:10:10+00:00
  edited: false
  hidden: false
  id: 658447422031da25dac8b41d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/361c0c14c27e6100379bfec9520886ef.svg
      fullname: Nawal Husnoo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nawal2
      type: user
    createdAt: '2023-12-21T14:10:10.000Z'
    data:
      status: closed
    id: 658447422031da25dac8b420
    type: status-change
  author: nawal2
  created_at: 2023-12-21 14:10:10+00:00
  id: 658447422031da25dac8b420
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: nisten/obsidian-3b-multimodal-q6-gguf
repo_type: model
status: closed
target_branch: null
title: seg fault when calling from python
