!!python/object:huggingface_hub.community.DiscussionWithDetails
author: atakanince
conflicting_files: null
created_at: 2023-12-20 21:30:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f7ecb0ecf4759fd0eeb8ae7726af6301.svg
      fullname: Atakan Ince
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: atakanince
      type: user
    createdAt: '2023-12-20T21:30:13.000Z'
    data:
      edited: false
      editors:
      - atakanince
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7505705952644348
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f7ecb0ecf4759fd0eeb8ae7726af6301.svg
          fullname: Atakan Ince
          isHf: false
          isPro: false
          name: atakanince
          type: user
        html: '<p>I am trying to download the model on Google Colab with the following
          command:</p>

          <p>"</p>

          <h1 id="load-model-directly">Load model directly</h1>

          <p>from transformers import AutoTokenizer, AutoModelForCausalLM</p>

          <p>tokenizer = AutoTokenizer.from_pretrained("osunlp/TableLlama")<br>model
          = AutoModelForCausalLM.from_pretrained("osunlp/TableLlama")<br>"</p>

          <p>However, I get the following error message:</p>

          <p>"ValueError: Couldn''t instantiate the backend tokenizer from one of:<br>(1)
          a <code>tokenizers</code> library serialization file,<br>(2) a slow tokenizer
          instance to convert or<br>(3) an equivalent slow tokenizer class to instantiate
          and convert.<br>You need to have sentencepiece installed to convert a slow
          tokenizer to a fast one."</p>

          <p>transformers version: 4.35.2</p>

          '
        raw: "I am trying to download the model on Google Colab with the following\
          \ command:\r\n\r\n\"\r\n# Load model directly\r\nfrom transformers import\
          \ AutoTokenizer, AutoModelForCausalLM\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(\"\
          osunlp/TableLlama\")\r\nmodel = AutoModelForCausalLM.from_pretrained(\"\
          osunlp/TableLlama\")\r\n\"\r\n\r\nHowever, I get the following error message:\r\
          \n\r\n\"ValueError: Couldn't instantiate the backend tokenizer from one\
          \ of: \r\n(1) a `tokenizers` library serialization file, \r\n(2) a slow\
          \ tokenizer instance to convert or \r\n(3) an equivalent slow tokenizer\
          \ class to instantiate and convert. \r\nYou need to have sentencepiece installed\
          \ to convert a slow tokenizer to a fast one.\"\r\n\r\ntransformers version:\
          \ 4.35.2"
        updatedAt: '2023-12-20T21:30:13.403Z'
      numEdits: 0
      reactions: []
    id: 65835ce51804c2d0609f4068
    type: comment
  author: atakanince
  content: "I am trying to download the model on Google Colab with the following command:\r\
    \n\r\n\"\r\n# Load model directly\r\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\r\
    \n\r\ntokenizer = AutoTokenizer.from_pretrained(\"osunlp/TableLlama\")\r\nmodel\
    \ = AutoModelForCausalLM.from_pretrained(\"osunlp/TableLlama\")\r\n\"\r\n\r\n\
    However, I get the following error message:\r\n\r\n\"ValueError: Couldn't instantiate\
    \ the backend tokenizer from one of: \r\n(1) a `tokenizers` library serialization\
    \ file, \r\n(2) a slow tokenizer instance to convert or \r\n(3) an equivalent\
    \ slow tokenizer class to instantiate and convert. \r\nYou need to have sentencepiece\
    \ installed to convert a slow tokenizer to a fast one.\"\r\n\r\ntransformers version:\
    \ 4.35.2"
  created_at: 2023-12-20 21:30:13+00:00
  edited: false
  hidden: false
  id: 65835ce51804c2d0609f4068
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/651f07370bb29b2f4ec3f8a4/awin11r3GY4MtpwnCBlhn.png?w=200&h=200&f=face
      fullname: TIANSHU ZHANG
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: tianshuzhang
      type: user
    createdAt: '2023-12-20T22:16:13.000Z'
    data:
      edited: false
      editors:
      - tianshuzhang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7990598678588867
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/651f07370bb29b2f4ec3f8a4/awin11r3GY4MtpwnCBlhn.png?w=200&h=200&f=face
          fullname: TIANSHU ZHANG
          isHf: false
          isPro: false
          name: tianshuzhang
          type: user
        html: '<p>I tried "transformers version: 4.35.2" this version. You can try
          to install sentencepiece package using "!pip install sentencepiece" on Colab.</p>

          '
        raw: 'I tried "transformers version: 4.35.2" this version. You can try to
          install sentencepiece package using "!pip install sentencepiece" on Colab.'
        updatedAt: '2023-12-20T22:16:13.251Z'
      numEdits: 0
      reactions: []
    id: 658367ad92a21e76945623c6
    type: comment
  author: tianshuzhang
  content: 'I tried "transformers version: 4.35.2" this version. You can try to install
    sentencepiece package using "!pip install sentencepiece" on Colab.'
  created_at: 2023-12-20 22:16:13+00:00
  edited: false
  hidden: false
  id: 658367ad92a21e76945623c6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: osunlp/TableLlama
repo_type: model
status: open
target_branch: null
title: Error message while downloading the model
