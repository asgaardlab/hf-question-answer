!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bikalnetomi
conflicting_files: null
created_at: 2023-09-06 20:05:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/214be746a5f6c72bed1faa584496c821.svg
      fullname: Bikal Basnet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bikalnetomi
      type: user
    createdAt: '2023-09-06T21:05:54.000Z'
    data:
      edited: true
      editors:
      - bikalnetomi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5410243272781372
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/214be746a5f6c72bed1faa584496c821.svg
          fullname: Bikal Basnet
          isHf: false
          isPro: false
          name: bikalnetomi
          type: user
        html: '<p>I am trying to run the model using the Text Generation Inference.
          Getting the following error.</p>

          <p>I used the Sagemaker Jumpstart code<br>Hub Model configuration. <a href="https://huggingface.co/models">https://huggingface.co/models</a><br>hub
          = {<br>''HF_MODEL_ID'':''TheBloke/Genz-70b-GPTQ,<br>''SM_NUM_GPUS'': json.dumps(4)<br>}</p>

          <p>create Hugging Face Model Class<br>huggingface_model = HuggingFaceModel(<br>image_uri=get_huggingface_llm_image_uri("huggingface",version="0.9.3"),<br>env=hub,<br>role=role,<br>)</p>

          <p>deploy model to SageMaker Inference<br>predictor = huggingface_model.deploy(<br>initial_instance_count=1,<br>instance_type="ml.g4dn.12xlarge",<br>container_startup_health_check_timeout=300,<br>)</p>

          <p>Any help to resolve the following error.</p>

          <p>File "/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py",
          line 142, in serve_inner<br>model = get_model(<br>File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/init.py",
          line 185, in get_model<br>return FlashLlama(<br>File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_llama.py",
          line 65, in init<br>model = FlashLlamaForCausalLM(config, weights)<br>File
          "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 452, in init<br>self.model = FlashLlamaModel(config, weights)<br>File
          "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 390, in init<br>[<br>File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 391, in<br>FlashLlamaLayer(<br>File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 326, in init<br>self.self_attn = FlashLlamaAttention(<br>File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 183, in init<br>self.rotary_emb = PositionRotaryEmbedding.load(<br>File
          "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/layers.py",
          line 395, in load<br>inv_freq = weights.get_tensor(f"{prefix}.inv_freq")<br>File
          "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py",
          line 62, in get_tensor<br>filename, tensor_name = self.get_filename(tensor_name)<br>File
          "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py",
          line 49, in get_filename<br>raise RuntimeError(f"weight {tensor_name} does
          not exist")<br>RuntimeError: weight model.layers.0.self_attn.rotary_emb.inv_freq
          does not exist</p>

          '
        raw: 'I am trying to run the model using the Text Generation Inference. Getting
          the following error.


          I used the Sagemaker Jumpstart code

          Hub Model configuration. https://huggingface.co/models

          hub = {

          ''HF_MODEL_ID'':''TheBloke/Genz-70b-GPTQ,

          ''SM_NUM_GPUS'': json.dumps(4)

          }


          create Hugging Face Model Class

          huggingface_model = HuggingFaceModel(

          image_uri=get_huggingface_llm_image_uri("huggingface",version="0.9.3"),

          env=hub,

          role=role,

          )


          deploy model to SageMaker Inference

          predictor = huggingface_model.deploy(

          initial_instance_count=1,

          instance_type="ml.g4dn.12xlarge",

          container_startup_health_check_timeout=300,

          )


          Any help to resolve the following error.


          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py",
          line 142, in serve_inner

          model = get_model(

          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/init.py",
          line 185, in get_model

          return FlashLlama(

          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_llama.py",
          line 65, in init

          model = FlashLlamaForCausalLM(config, weights)

          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 452, in init

          self.model = FlashLlamaModel(config, weights)

          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 390, in init

          [

          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 391, in

          FlashLlamaLayer(

          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 326, in init

          self.self_attn = FlashLlamaAttention(

          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
          line 183, in init

          self.rotary_emb = PositionRotaryEmbedding.load(

          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/layers.py",
          line 395, in load

          inv_freq = weights.get_tensor(f"{prefix}.inv_freq")

          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py",
          line 62, in get_tensor

          filename, tensor_name = self.get_filename(tensor_name)

          File "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py",
          line 49, in get_filename

          raise RuntimeError(f"weight {tensor_name} does not exist")

          RuntimeError: weight model.layers.0.self_attn.rotary_emb.inv_freq does not
          exist'
        updatedAt: '2023-09-06T21:06:44.942Z'
      numEdits: 1
      reactions: []
    id: 64f8e9b22f7d3d945cf30402
    type: comment
  author: bikalnetomi
  content: 'I am trying to run the model using the Text Generation Inference. Getting
    the following error.


    I used the Sagemaker Jumpstart code

    Hub Model configuration. https://huggingface.co/models

    hub = {

    ''HF_MODEL_ID'':''TheBloke/Genz-70b-GPTQ,

    ''SM_NUM_GPUS'': json.dumps(4)

    }


    create Hugging Face Model Class

    huggingface_model = HuggingFaceModel(

    image_uri=get_huggingface_llm_image_uri("huggingface",version="0.9.3"),

    env=hub,

    role=role,

    )


    deploy model to SageMaker Inference

    predictor = huggingface_model.deploy(

    initial_instance_count=1,

    instance_type="ml.g4dn.12xlarge",

    container_startup_health_check_timeout=300,

    )


    Any help to resolve the following error.


    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/server.py",
    line 142, in serve_inner

    model = get_model(

    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/init.py",
    line 185, in get_model

    return FlashLlama(

    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/flash_llama.py",
    line 65, in init

    model = FlashLlamaForCausalLM(config, weights)

    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
    line 452, in init

    self.model = FlashLlamaModel(config, weights)

    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
    line 390, in init

    [

    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
    line 391, in

    FlashLlamaLayer(

    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
    line 326, in init

    self.self_attn = FlashLlamaAttention(

    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/models/custom_modeling/flash_llama_modeling.py",
    line 183, in init

    self.rotary_emb = PositionRotaryEmbedding.load(

    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/layers.py",
    line 395, in load

    inv_freq = weights.get_tensor(f"{prefix}.inv_freq")

    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py",
    line 62, in get_tensor

    filename, tensor_name = self.get_filename(tensor_name)

    File "/opt/conda/lib/python3.9/site-packages/text_generation_server/utils/weights.py",
    line 49, in get_filename

    raise RuntimeError(f"weight {tensor_name} does not exist")

    RuntimeError: weight model.layers.0.self_attn.rotary_emb.inv_freq does not exist'
  created_at: 2023-09-06 20:05:54+00:00
  edited: true
  hidden: false
  id: 64f8e9b22f7d3d945cf30402
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/Genz-70b-GPTQ
repo_type: model
status: open
target_branch: null
title: 'Error running with Sagemaker Jumpstart + Text Generation Inference : weight
  model.layers.0.self_attn.rotary_emb.inv_freq does not exist'
