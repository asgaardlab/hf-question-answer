!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Mykee
conflicting_files: null
created_at: 2023-07-25 11:27:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6b49b41b696f6bd5802594f772a83786.svg
      fullname: Miklos
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Mykee
      type: user
    createdAt: '2023-07-25T12:27:37.000Z'
    data:
      edited: false
      editors:
      - Mykee
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9646729230880737
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6b49b41b696f6bd5802594f772a83786.svg
          fullname: Miklos
          isHf: false
          isPro: false
          name: Mykee
          type: user
        html: '<p>I see that the k-quant models have been deleted. Will there be a
          new version or Llama2 release?</p>

          '
        raw: I see that the k-quant models have been deleted. Will there be a new
          version or Llama2 release?
        updatedAt: '2023-07-25T12:27:37.861Z'
      numEdits: 0
      reactions: []
    id: 64bfbfb97b4c422525ec8f6f
    type: comment
  author: Mykee
  content: I see that the k-quant models have been deleted. Will there be a new version
    or Llama2 release?
  created_at: 2023-07-25 11:27:37+00:00
  edited: false
  hidden: false
  id: 64bfbfb97b4c422525ec8f6f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6251b9851842c08ef3111c4f/JLiEuSvejrcCruYmnRV4-.jpeg?w=200&h=200&f=face
      fullname: Taco
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Crataco
      type: user
    createdAt: '2023-08-05T02:54:37.000Z'
    data:
      edited: false
      editors:
      - Crataco
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8227586150169373
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6251b9851842c08ef3111c4f/JLiEuSvejrcCruYmnRV4-.jpeg?w=200&h=200&f=face
          fullname: Taco
          isHf: false
          isPro: false
          name: Crataco
          type: user
        html: '<p>Yeah, that confused me too. You can still get them from an older
          version of the repo <a href="https://huggingface.co/TheBloke/chronos-hermes-13B-GGML/tree/d62cad8b2abcaeb9f76686978d2cda04ffe2179f">(here)</a>.</p>

          '
        raw: Yeah, that confused me too. You can still get them from an older version
          of the repo [(here)](https://huggingface.co/TheBloke/chronos-hermes-13B-GGML/tree/d62cad8b2abcaeb9f76686978d2cda04ffe2179f).
        updatedAt: '2023-08-05T02:54:37.602Z'
      numEdits: 0
      reactions: []
    id: 64cdb9ed73174cecdf7aeb98
    type: comment
  author: Crataco
  content: Yeah, that confused me too. You can still get them from an older version
    of the repo [(here)](https://huggingface.co/TheBloke/chronos-hermes-13B-GGML/tree/d62cad8b2abcaeb9f76686978d2cda04ffe2179f).
  created_at: 2023-08-05 01:54:37+00:00
  edited: false
  hidden: false
  id: 64cdb9ed73174cecdf7aeb98
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-05T08:32:44.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.982599675655365
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I deleted them a while ago because they were at risk of producing
          garbage output. This model uses a non-standard vocab size (32001) and for
          a while that broke k-quants.  The issue was resolved a few weeks ago, but
          I''ve not had a chance to go back and re-make k-quants for this or some
          other older models.</p>

          <p>Are you saying that the k-quants I deleted do in fact work?  I think
          it may be the case that they sometimes produce garbage output, as a change
          was required in llama.cpp to produce valid k-quants for models like this,
          changing how certain layers of the model were quantised. But maybe they
          work most of the time?</p>

          <p>There hasn''t been a Llama 2 Chronos Hermes yet, but there is a Llama
          2 Chronos, and a whole bunch of Chronos merges which I quantised over the
          last 48 hours.  So there''s a lot of Llama 2 choice now.</p>

          '
        raw: 'I deleted them a while ago because they were at risk of producing garbage
          output. This model uses a non-standard vocab size (32001) and for a while
          that broke k-quants.  The issue was resolved a few weeks ago, but I''ve
          not had a chance to go back and re-make k-quants for this or some other
          older models.


          Are you saying that the k-quants I deleted do in fact work?  I think it
          may be the case that they sometimes produce garbage output, as a change
          was required in llama.cpp to produce valid k-quants for models like this,
          changing how certain layers of the model were quantised. But maybe they
          work most of the time?


          There hasn''t been a Llama 2 Chronos Hermes yet, but there is a Llama 2
          Chronos, and a whole bunch of Chronos merges which I quantised over the
          last 48 hours.  So there''s a lot of Llama 2 choice now.'
        updatedAt: '2023-08-05T08:32:44.027Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Crataco
        - Mykee
    id: 64ce092ce13e7c2bc5806363
    type: comment
  author: TheBloke
  content: 'I deleted them a while ago because they were at risk of producing garbage
    output. This model uses a non-standard vocab size (32001) and for a while that
    broke k-quants.  The issue was resolved a few weeks ago, but I''ve not had a chance
    to go back and re-make k-quants for this or some other older models.


    Are you saying that the k-quants I deleted do in fact work?  I think it may be
    the case that they sometimes produce garbage output, as a change was required
    in llama.cpp to produce valid k-quants for models like this, changing how certain
    layers of the model were quantised. But maybe they work most of the time?


    There hasn''t been a Llama 2 Chronos Hermes yet, but there is a Llama 2 Chronos,
    and a whole bunch of Chronos merges which I quantised over the last 48 hours.  So
    there''s a lot of Llama 2 choice now.'
  created_at: 2023-08-05 07:32:44+00:00
  edited: false
  hidden: false
  id: 64ce092ce13e7c2bc5806363
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6251b9851842c08ef3111c4f/JLiEuSvejrcCruYmnRV4-.jpeg?w=200&h=200&f=face
      fullname: Taco
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Crataco
      type: user
    createdAt: '2023-08-07T04:31:07.000Z'
    data:
      edited: false
      editors:
      - Crataco
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.932982861995697
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6251b9851842c08ef3111c4f/JLiEuSvejrcCruYmnRV4-.jpeg?w=200&h=200&f=face
          fullname: Taco
          isHf: false
          isPro: false
          name: Crataco
          type: user
        html: '<p>In my testing with q6_K in Oobabooga, the model works as intended
          (tested with Simple-1 and Mirostat settings), but maybe I haven''t been
          testing for longer periods of time.</p>

          <p>I would think it''s worth a revisit to quantize again, just in case.
          I''ve heard <a rel="nofollow" href="https://old.reddit.com/r/LocalLLaMA/comments/155vy0k/llama_2_too_repetitive/">some
          reports</a> of Llama 2 models <a rel="nofollow" href="https://old.reddit.com/r/LocalLLaMA/comments/15gp9fq/chronos13bv2_llama_2_roleplay_storywriting_and/junbr4x/">having
          repetition issues</a>, including <a rel="nofollow" href="https://old.reddit.com/r/LocalLLaMA/comments/15k07ba/anyone_else_is_getting_problems_with_repetition/">Chronos-Hermes
          2</a>, so for some of us LLaMA 1-based models are still a viable option.</p>

          <p>If not, we still have the original quants. Either way, keep up the great
          work.</p>

          '
        raw: 'In my testing with q6_K in Oobabooga, the model works as intended (tested
          with Simple-1 and Mirostat settings), but maybe I haven''t been testing
          for longer periods of time.


          I would think it''s worth a revisit to quantize again, just in case. I''ve
          heard [some reports](https://old.reddit.com/r/LocalLLaMA/comments/155vy0k/llama_2_too_repetitive/)
          of Llama 2 models [having repetition issues](https://old.reddit.com/r/LocalLLaMA/comments/15gp9fq/chronos13bv2_llama_2_roleplay_storywriting_and/junbr4x/),
          including [Chronos-Hermes 2](https://old.reddit.com/r/LocalLLaMA/comments/15k07ba/anyone_else_is_getting_problems_with_repetition/),
          so for some of us LLaMA 1-based models are still a viable option.


          If not, we still have the original quants. Either way, keep up the great
          work.'
        updatedAt: '2023-08-07T04:31:07.157Z'
      numEdits: 0
      reactions: []
    id: 64d0738b84f2058690e54235
    type: comment
  author: Crataco
  content: 'In my testing with q6_K in Oobabooga, the model works as intended (tested
    with Simple-1 and Mirostat settings), but maybe I haven''t been testing for longer
    periods of time.


    I would think it''s worth a revisit to quantize again, just in case. I''ve heard
    [some reports](https://old.reddit.com/r/LocalLLaMA/comments/155vy0k/llama_2_too_repetitive/)
    of Llama 2 models [having repetition issues](https://old.reddit.com/r/LocalLLaMA/comments/15gp9fq/chronos13bv2_llama_2_roleplay_storywriting_and/junbr4x/),
    including [Chronos-Hermes 2](https://old.reddit.com/r/LocalLLaMA/comments/15k07ba/anyone_else_is_getting_problems_with_repetition/),
    so for some of us LLaMA 1-based models are still a viable option.


    If not, we still have the original quants. Either way, keep up the great work.'
  created_at: 2023-08-07 03:31:07+00:00
  edited: false
  hidden: false
  id: 64d0738b84f2058690e54235
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6251b9851842c08ef3111c4f/JLiEuSvejrcCruYmnRV4-.jpeg?w=200&h=200&f=face
      fullname: Taco
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Crataco
      type: user
    createdAt: '2023-09-26T06:23:14.000Z'
    data:
      edited: false
      editors:
      - Crataco
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8282229900360107
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6251b9851842c08ef3111c4f/JLiEuSvejrcCruYmnRV4-.jpeg?w=200&h=200&f=face
          fullname: Taco
          isHf: false
          isPro: false
          name: Crataco
          type: user
        html: '<p>I noticed TheBloke is requantizing some older models, so a GGUF
          version has been released with updated k-quants. Thank you!<br><a href="https://huggingface.co/TheBloke/chronos-hermes-13B-GGUF">TheBloke/chronos-hermes-13B-GGUF</a></p>

          '
        raw: 'I noticed TheBloke is requantizing some older models, so a GGUF version
          has been released with updated k-quants. Thank you!

          [TheBloke/chronos-hermes-13B-GGUF](https://huggingface.co/TheBloke/chronos-hermes-13B-GGUF)'
        updatedAt: '2023-09-26T06:23:14.211Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - Mykee
    id: 651278d2311a12ef0c29d8db
    type: comment
  author: Crataco
  content: 'I noticed TheBloke is requantizing some older models, so a GGUF version
    has been released with updated k-quants. Thank you!

    [TheBloke/chronos-hermes-13B-GGUF](https://huggingface.co/TheBloke/chronos-hermes-13B-GGUF)'
  created_at: 2023-09-26 05:23:14+00:00
  edited: false
  hidden: false
  id: 651278d2311a12ef0c29d8db
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/chronos-hermes-13B-GGML
repo_type: model
status: open
target_branch: null
title: k-quant models?
