!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Music4Dogs
conflicting_files: null
created_at: 2023-12-17 15:45:54+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0ed8abd806e0475c96e53fad35582dee.svg
      fullname: Saul Loranne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Music4Dogs
      type: user
    createdAt: '2023-12-17T15:45:54.000Z'
    data:
      edited: false
      editors:
      - Music4Dogs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8752208352088928
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0ed8abd806e0475c96e53fad35582dee.svg
          fullname: Saul Loranne
          isHf: false
          isPro: false
          name: Music4Dogs
          type: user
        html: '<p>Using Q4_0 on koboldcpp 1.52.2, the model is outputting the newline
          as &lt;0x0A&gt;, has broken speech, nonsensical repetition, and all the
          typical hallmarks of a broken model. Seems like it''s probably a model issue
          not a quant issue, but i can''t test the fp16 to confirm.</p>

          <p>A simple qa assistant prompt inside proper mistral template like "roleplay
          as a large language model trained to act as a personal assistant. User:
          Please explain how a microwave oven works." it outputs:</p>

          <p>Yes, I can, please help you learn a new language, a new roleplay and
          a new language model.&lt;0x0A&gt;[/INST]&lt;0x0A&gt;&lt;0x0A&gt;Open Assistant:
          How do you learn a new language?&lt;0x0A&gt;[INST]&lt;0x0A&gt;Open Assistant:
          A large number of users have a large language model trained to help users
          learn a new language, a new roleplay and a new language model.&lt;0x0A&gt;[/INST]&lt;0x0A&gt;&lt;0x0A&gt;Open
          Assistant: As a large language model, you are learning a new language model
          and you are a large language model.&lt;0x0A&gt;[/INST]&lt;0x0A&gt;&lt;0x0A&gt;Open
          Assistant: A large number of users have a large language model trained to
          help users learn a new language, a new roleplay and a new language model.&lt;0x0A&gt;[/INST]&lt;0x0A&gt;&lt;0x0A&gt;Open
          Assistant: The model is based on the idea that the model will help you learn
          a new language model.&lt;0x0A&gt;[/INST]&lt;0x0A&gt;&lt;0x0A&gt;Open Assistant:
          A large number of users have a large language model trained to help users
          learn a new language, a new roleplay and a new language model.&lt;0x0A&gt;[/</p>

          '
        raw: "Using Q4_0 on koboldcpp 1.52.2, the model is outputting the newline\
          \ as <0x0A>, has broken speech, nonsensical repetition, and all the typical\
          \ hallmarks of a broken model. Seems like it's probably a model issue not\
          \ a quant issue, but i can't test the fp16 to confirm.\r\n\r\nA simple qa\
          \ assistant prompt inside proper mistral template like \"roleplay as a large\
          \ language model trained to act as a personal assistant. User: Please explain\
          \ how a microwave oven works.\" it outputs:\r\n\r\nYes, I can, please help\
          \ you learn a new language, a new roleplay and a new language model.<0x0A>[/INST]<0x0A><0x0A>Open\
          \ Assistant: How do you learn a new language?<0x0A>[INST]<0x0A>Open Assistant:\
          \ A large number of users have a large language model trained to help users\
          \ learn a new language, a new roleplay and a new language model.<0x0A>[/INST]<0x0A><0x0A>Open\
          \ Assistant: As a large language model, you are learning a new language\
          \ model and you are a large language model.<0x0A>[/INST]<0x0A><0x0A>Open\
          \ Assistant: A large number of users have a large language model trained\
          \ to help users learn a new language, a new roleplay and a new language\
          \ model.<0x0A>[/INST]<0x0A><0x0A>Open Assistant: The model is based on the\
          \ idea that the model will help you learn a new language model.<0x0A>[/INST]<0x0A><0x0A>Open\
          \ Assistant: A large number of users have a large language model trained\
          \ to help users learn a new language, a new roleplay and a new language\
          \ model.<0x0A>[/"
        updatedAt: '2023-12-17T15:45:54.278Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Sensath
    id: 657f17b21815b29c9af99429
    type: comment
  author: Music4Dogs
  content: "Using Q4_0 on koboldcpp 1.52.2, the model is outputting the newline as\
    \ <0x0A>, has broken speech, nonsensical repetition, and all the typical hallmarks\
    \ of a broken model. Seems like it's probably a model issue not a quant issue,\
    \ but i can't test the fp16 to confirm.\r\n\r\nA simple qa assistant prompt inside\
    \ proper mistral template like \"roleplay as a large language model trained to\
    \ act as a personal assistant. User: Please explain how a microwave oven works.\"\
    \ it outputs:\r\n\r\nYes, I can, please help you learn a new language, a new roleplay\
    \ and a new language model.<0x0A>[/INST]<0x0A><0x0A>Open Assistant: How do you\
    \ learn a new language?<0x0A>[INST]<0x0A>Open Assistant: A large number of users\
    \ have a large language model trained to help users learn a new language, a new\
    \ roleplay and a new language model.<0x0A>[/INST]<0x0A><0x0A>Open Assistant: As\
    \ a large language model, you are learning a new language model and you are a\
    \ large language model.<0x0A>[/INST]<0x0A><0x0A>Open Assistant: A large number\
    \ of users have a large language model trained to help users learn a new language,\
    \ a new roleplay and a new language model.<0x0A>[/INST]<0x0A><0x0A>Open Assistant:\
    \ The model is based on the idea that the model will help you learn a new language\
    \ model.<0x0A>[/INST]<0x0A><0x0A>Open Assistant: A large number of users have\
    \ a large language model trained to help users learn a new language, a new roleplay\
    \ and a new language model.<0x0A>[/"
  created_at: 2023-12-17 15:45:54+00:00
  edited: false
  hidden: false
  id: 657f17b21815b29c9af99429
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5fbb6845f2a11d9abec0337a365e4a8e.svg
      fullname: Jeroen Adam Devenijn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JeroenAdam
      type: user
    createdAt: '2023-12-17T16:16:20.000Z'
    data:
      edited: false
      editors:
      - JeroenAdam
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9940299391746521
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5fbb6845f2a11d9abec0337a365e4a8e.svg
          fullname: Jeroen Adam Devenijn
          isHf: false
          isPro: false
          name: JeroenAdam
          type: user
        html: '<p>I just tried out the Q3_K_M GGUF with llama.cpp<br>The same issue
          for me. The responses are somewhat related to the prompt but still gibberish.</p>

          <p>Eg.</p>

          <p>What was John Holt''s vision on education?</p>

          <p>"I decided to become a scientist after I saw that the professors in my
          school were not very keen on education. It seemed to me like science would
          be something that could help me get out of poverty and provide a good lifestyle
          for my family and give them a way to make money. So I studied science after
          seeing that the teachers in my school were not interested in education.
          That is what was my vision on education as I saw it in other schools. "</p>

          '
        raw: 'I just tried out the Q3_K_M GGUF with llama.cpp

          The same issue for me. The responses are somewhat related to the prompt
          but still gibberish.


          Eg.


          What was John Holt''s vision on education?


          "I decided to become a scientist after I saw that the professors in my school
          were not very keen on education. It seemed to me like science would be something
          that could help me get out of poverty and provide a good lifestyle for my
          family and give them a way to make money. So I studied science after seeing
          that the teachers in my school were not interested in education. That is
          what was my vision on education as I saw it in other schools. "'
        updatedAt: '2023-12-17T16:16:20.601Z'
      numEdits: 0
      reactions: []
    id: 657f1ed4365456e36240932a
    type: comment
  author: JeroenAdam
  content: 'I just tried out the Q3_K_M GGUF with llama.cpp

    The same issue for me. The responses are somewhat related to the prompt but still
    gibberish.


    Eg.


    What was John Holt''s vision on education?


    "I decided to become a scientist after I saw that the professors in my school
    were not very keen on education. It seemed to me like science would be something
    that could help me get out of poverty and provide a good lifestyle for my family
    and give them a way to make money. So I studied science after seeing that the
    teachers in my school were not interested in education. That is what was my vision
    on education as I saw it in other schools. "'
  created_at: 2023-12-17 16:16:20+00:00
  edited: false
  hidden: false
  id: 657f1ed4365456e36240932a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8feade4bbb062d76540ea193b5b9c596.svg
      fullname: Canada Bass
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sensath
      type: user
    createdAt: '2024-01-17T01:33:58.000Z'
    data:
      edited: false
      editors:
      - Sensath
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8853648900985718
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8feade4bbb062d76540ea193b5b9c596.svg
          fullname: Canada Bass
          isHf: false
          isPro: false
          name: Sensath
          type: user
        html: '<p>It''s missing the tokenizer. Needs updated with on.</p>

          '
        raw: It's missing the tokenizer. Needs updated with on.
        updatedAt: '2024-01-17T01:33:58.046Z'
      numEdits: 0
      reactions: []
    id: 65a72e861a2b0fa27b40e5f8
    type: comment
  author: Sensath
  content: It's missing the tokenizer. Needs updated with on.
  created_at: 2024-01-17 01:33:58+00:00
  edited: false
  hidden: false
  id: 65a72e861a2b0fa27b40e5f8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Mixtral-Fusion-4x7B-Instruct-v0.1-GGUF
repo_type: model
status: open
target_branch: null
title: Incoherent Output
