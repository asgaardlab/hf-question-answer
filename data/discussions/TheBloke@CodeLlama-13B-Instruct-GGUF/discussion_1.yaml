!!python/object:huggingface_hub.community.DiscussionWithDetails
author: deetungsten
conflicting_files: null
created_at: 2023-08-25 01:29:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fbe4da0ad46033965ebe295238a0cfcb.svg
      fullname: Dee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: deetungsten
      type: user
    createdAt: '2023-08-25T02:29:04.000Z'
    data:
      edited: true
      editors:
      - deetungsten
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7476966381072998
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fbe4da0ad46033965ebe295238a0cfcb.svg
          fullname: Dee
          isHf: false
          isPro: false
          name: deetungsten
          type: user
        html: "<p>When I try loading any (7, 13,34) of your GGUF models (regardless\
          \ of instruct or text completion) in interactive mode, it starts generating\
          \ random code like below. I am running this with a vanilla command <code>-m\
          \ codellama-13b-instruct.Q8_0.gguf --color -i</code>. Has anyone else seen\
          \ this?</p>\n<pre><code>== Running in interactive mode. ==\n - Press Ctrl+C\
          \ to interject at any time.\n - Press Return to return control to LLaMa.\n\
          \ - To return control without starting a new line, end your input with '/'.\n\
          \ - If you want to submit another line, end your input with '\\'.\n\n using\
          \ System;\nusing System.Collections.Generic;\nusing System.Lin\n</code></pre>\n"
        raw: "When I try loading any (7, 13,34) of your GGUF models (regardless of\
          \ instruct or text completion) in interactive mode, it starts generating\
          \ random code like below. I am running this with a vanilla command `-m codellama-13b-instruct.Q8_0.gguf\
          \ --color -i`. Has anyone else seen this?\n\n```\n== Running in interactive\
          \ mode. ==\n - Press Ctrl+C to interject at any time.\n - Press Return to\
          \ return control to LLaMa.\n - To return control without starting a new\
          \ line, end your input with '/'.\n - If you want to submit another line,\
          \ end your input with '\\'.\n\n using System;\nusing System.Collections.Generic;\n\
          using System.Lin\n```"
        updatedAt: '2023-08-25T02:29:37.220Z'
      numEdits: 1
      reactions: []
    id: 64e811f022a21efcebb19a64
    type: comment
  author: deetungsten
  content: "When I try loading any (7, 13,34) of your GGUF models (regardless of instruct\
    \ or text completion) in interactive mode, it starts generating random code like\
    \ below. I am running this with a vanilla command `-m codellama-13b-instruct.Q8_0.gguf\
    \ --color -i`. Has anyone else seen this?\n\n```\n== Running in interactive mode.\
    \ ==\n - Press Ctrl+C to interject at any time.\n - Press Return to return control\
    \ to LLaMa.\n - To return control without starting a new line, end your input\
    \ with '/'.\n - If you want to submit another line, end your input with '\\'.\n\
    \n using System;\nusing System.Collections.Generic;\nusing System.Lin\n```"
  created_at: 2023-08-25 01:29:04+00:00
  edited: true
  hidden: false
  id: 64e811f022a21efcebb19a64
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c51694bb7cf20383d211cc6093683594.svg
      fullname: MDD
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: md2
      type: user
    createdAt: '2023-08-25T08:24:01.000Z'
    data:
      edited: false
      editors:
      - md2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9006032347679138
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c51694bb7cf20383d211cc6093683594.svg
          fullname: MDD
          isHf: false
          isPro: false
          name: md2
          type: user
        html: "<p>Yes, similar behavior here for codellama-13b-instruct.Q5_K_S.gguf\
          \ and a variety of settings. For instance, for</p>\n<p>./main -t 8 -ngl\
          \ 32 -m models/13B/codellama-13b-instruct.Q5_K_S.gguf --color -c 8192 --temp\
          \ 0.3 --rope-freq-base 10000 --rope-freq-scale 0.5 -i</p>\n<p>I get:</p>\n\
          <p>== Running in interactive mode. ==</p>\n<ul>\n<li><p>Press Ctrl+C to\
          \ interject at any time.</p>\n</li>\n<li><p>Press Return to return control\
          \ to LLaMa.</p>\n</li>\n<li><p>To return control without starting a new\
          \ line, end your input with '/'.</p>\n</li>\n<li><p>If you want to submit\
          \ another line, end your input with ''.</p>\n<pre><code>               \
          \              if ( ! isset( $settings['icon'] ) || empty( $settings['icon']\
          \ ) ) {\n                     $settings['icon'] = 'fa fa-star';\n      \
          \           }\n\n                 if ( ! isset( $settings['color'] ) ||\
          \ empty( $settings['color'] ) ) {\n                     $settings['color']\
          \ = '#f1d204';\n                 }\n\n                 if ( ! isset( $settings['size']\
          \ ) || empty( $settings['size'] ) ) {\n                     $settings['size']\
          \ = '35px';\n                 }\n\n                 if ( ! isset( $settings['margin_top']\
          \ ) || empty( $settings['margin_top'] ) ) {\n</code></pre>\n</li>\n</ul>\n\
          <p>For the prompt method, using -f codellama.prompt with</p>\n<p>codellama.prompt\
          \ content:</p>\n<p>[INST]<br>&lt;&gt;<br>You are a helpful, respectful and\
          \ honest assistant.</p>\n<p>If you are unsure about an answer, truthfully\
          \ say 'I don't know'.<br>&lt;&gt;</p>\n<p>Write a story about llamas<br>[/INST]</p>\n\
          <p>I get a reasonable output:</p>\n<p>Once upon a time, in the Andes mountains\
          \ of South America, there lived a group of llamas. These llamas were known\
          \ for their soft, woolly coats and their gentle nature. They spent their\
          \ days grazing on the lush grasses of the Andes, and at night they would\
          \ gather together to rest and sleep.</p>\n<p>One day, a young llama named\
          \ Luna decided that she wanted to explore the world beyond her home in the\
          \ Andes. She packed a small bag with some food and water, and set off on\
          \ her journey.</p>\n<p>Luna traveled for many days, through mountains and\
          \ valleys, until she finally reached a new land. This land was filled with\
          \ strange creatures and plants that Luna had never seen before. But despite\
          \ the challenges of this new world, Luna was determined to make it her home.</p>\n\
          <p>And so, Luna settled down in her new land, surrounded by the strange\
          \ and wondrous creatures that she had encountered on her journey. She lived\
          \ a long and happy life, and her story was passed down from generation to\
          \ generation as a reminder of the power of determination and perseverance.\
          \ [end of text]</p>\n"
        raw: "Yes, similar behavior here for codellama-13b-instruct.Q5_K_S.gguf and\
          \ a variety of settings. For instance, for\n\n./main -t 8 -ngl 32 -m models/13B/codellama-13b-instruct.Q5_K_S.gguf\
          \ --color -c 8192 --temp 0.3 --rope-freq-base 10000 --rope-freq-scale 0.5\
          \ -i\n\nI get:\n\n== Running in interactive mode. ==\n - Press Ctrl+C to\
          \ interject at any time.\n - Press Return to return control to LLaMa.\n\
          \ - To return control without starting a new line, end your input with '/'.\n\
          \ - If you want to submit another line, end your input with '\\'.\n\n\n\n\
          \t\t\t\t\t\t\t\t\tif ( ! isset( $settings['icon'] ) || empty( $settings['icon']\
          \ ) ) {\n\t\t\t\t\t\t\t$settings['icon'] = 'fa fa-star';\n\t\t\t\t\t\t}\n\
          \n\t\t\t\t\t\tif ( ! isset( $settings['color'] ) || empty( $settings['color']\
          \ ) ) {\n\t\t\t\t\t\t\t$settings['color'] = '#f1d204';\n\t\t\t\t\t\t}\n\n\
          \t\t\t\t\t\tif ( ! isset( $settings['size'] ) || empty( $settings['size']\
          \ ) ) {\n\t\t\t\t\t\t\t$settings['size'] = '35px';\n\t\t\t\t\t\t}\n\n\t\t\
          \t\t\t\tif ( ! isset( $settings['margin_top'] ) || empty( $settings['margin_top']\
          \ ) ) {\n\n\nFor the prompt method, using -f codellama.prompt with\n\ncodellama.prompt\
          \ content:\n\n[INST] \n<<SYS>>\nYou are a helpful, respectful and honest\
          \ assistant.\n\nIf you are unsure about an answer, truthfully say 'I don't\
          \ know'.\n<</SYS>>\n\nWrite a story about llamas\n[/INST]\n\nI get a reasonable\
          \ output:\n\nOnce upon a time, in the Andes mountains of South America,\
          \ there lived a group of llamas. These llamas were known for their soft,\
          \ woolly coats and their gentle nature. They spent their days grazing on\
          \ the lush grasses of the Andes, and at night they would gather together\
          \ to rest and sleep.\n\nOne day, a young llama named Luna decided that she\
          \ wanted to explore the world beyond her home in the Andes. She packed a\
          \ small bag with some food and water, and set off on her journey.\n\nLuna\
          \ traveled for many days, through mountains and valleys, until she finally\
          \ reached a new land. This land was filled with strange creatures and plants\
          \ that Luna had never seen before. But despite the challenges of this new\
          \ world, Luna was determined to make it her home.\n\nAnd so, Luna settled\
          \ down in her new land, surrounded by the strange and wondrous creatures\
          \ that she had encountered on her journey. She lived a long and happy life,\
          \ and her story was passed down from generation to generation as a reminder\
          \ of the power of determination and perseverance. [end of text]\n"
        updatedAt: '2023-08-25T08:24:01.914Z'
      numEdits: 0
      reactions: []
    id: 64e8652121540e1da324f46f
    type: comment
  author: md2
  content: "Yes, similar behavior here for codellama-13b-instruct.Q5_K_S.gguf and\
    \ a variety of settings. For instance, for\n\n./main -t 8 -ngl 32 -m models/13B/codellama-13b-instruct.Q5_K_S.gguf\
    \ --color -c 8192 --temp 0.3 --rope-freq-base 10000 --rope-freq-scale 0.5 -i\n\
    \nI get:\n\n== Running in interactive mode. ==\n - Press Ctrl+C to interject at\
    \ any time.\n - Press Return to return control to LLaMa.\n - To return control\
    \ without starting a new line, end your input with '/'.\n - If you want to submit\
    \ another line, end your input with '\\'.\n\n\n\n\t\t\t\t\t\t\t\t\tif ( ! isset(\
    \ $settings['icon'] ) || empty( $settings['icon'] ) ) {\n\t\t\t\t\t\t\t$settings['icon']\
    \ = 'fa fa-star';\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif ( ! isset( $settings['color']\
    \ ) || empty( $settings['color'] ) ) {\n\t\t\t\t\t\t\t$settings['color'] = '#f1d204';\n\
    \t\t\t\t\t\t}\n\n\t\t\t\t\t\tif ( ! isset( $settings['size'] ) || empty( $settings['size']\
    \ ) ) {\n\t\t\t\t\t\t\t$settings['size'] = '35px';\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\
    \tif ( ! isset( $settings['margin_top'] ) || empty( $settings['margin_top'] )\
    \ ) {\n\n\nFor the prompt method, using -f codellama.prompt with\n\ncodellama.prompt\
    \ content:\n\n[INST] \n<<SYS>>\nYou are a helpful, respectful and honest assistant.\n\
    \nIf you are unsure about an answer, truthfully say 'I don't know'.\n<</SYS>>\n\
    \nWrite a story about llamas\n[/INST]\n\nI get a reasonable output:\n\nOnce upon\
    \ a time, in the Andes mountains of South America, there lived a group of llamas.\
    \ These llamas were known for their soft, woolly coats and their gentle nature.\
    \ They spent their days grazing on the lush grasses of the Andes, and at night\
    \ they would gather together to rest and sleep.\n\nOne day, a young llama named\
    \ Luna decided that she wanted to explore the world beyond her home in the Andes.\
    \ She packed a small bag with some food and water, and set off on her journey.\n\
    \nLuna traveled for many days, through mountains and valleys, until she finally\
    \ reached a new land. This land was filled with strange creatures and plants that\
    \ Luna had never seen before. But despite the challenges of this new world, Luna\
    \ was determined to make it her home.\n\nAnd so, Luna settled down in her new\
    \ land, surrounded by the strange and wondrous creatures that she had encountered\
    \ on her journey. She lived a long and happy life, and her story was passed down\
    \ from generation to generation as a reminder of the power of determination and\
    \ perseverance. [end of text]\n"
  created_at: 2023-08-25 07:24:01+00:00
  edited: false
  hidden: false
  id: 64e8652121540e1da324f46f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-08-25T08:25:45.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9208813905715942
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Don''t use <code>--rope-freq-base</code> with this model - the correct
          value is already included in the GGUF, and it is not 10000 for CodeLlama
          models</p>

          <p>This will be affecting the quality of the output</p>

          <p>I''ll remove mention of that from CodeLlama GGUF READMEs</p>

          '
        raw: 'Don''t use `--rope-freq-base` with this model - the correct value is
          already included in the GGUF, and it is not 10000 for CodeLlama models


          This will be affecting the quality of the output


          I''ll remove mention of that from CodeLlama GGUF READMEs'
        updatedAt: '2023-08-25T08:25:45.367Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - md2
        - phi0112358
        - lurker0
        - filipealmeida
    id: 64e865891a6fd0c6f2643c14
    type: comment
  author: TheBloke
  content: 'Don''t use `--rope-freq-base` with this model - the correct value is already
    included in the GGUF, and it is not 10000 for CodeLlama models


    This will be affecting the quality of the output


    I''ll remove mention of that from CodeLlama GGUF READMEs'
  created_at: 2023-08-25 07:25:45+00:00
  edited: false
  hidden: false
  id: 64e865891a6fd0c6f2643c14
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fbe4da0ad46033965ebe295238a0cfcb.svg
      fullname: Dee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: deetungsten
      type: user
    createdAt: '2023-08-25T23:06:12.000Z'
    data:
      edited: true
      editors:
      - deetungsten
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.953971803188324
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fbe4da0ad46033965ebe295238a0cfcb.svg
          fullname: Dee
          isHf: false
          isPro: false
          name: deetungsten
          type: user
        html: '<p>This still happens without that flag though. I tried this on a MBP
          and another computer with a nvidia GPU with the same thing happening. Is
          there a specific command I am suppose to use with main?</p>

          '
        raw: This still happens without that flag though. I tried this on a MBP and
          another computer with a nvidia GPU with the same thing happening. Is there
          a specific command I am suppose to use with main?
        updatedAt: '2023-08-25T23:06:24.519Z'
      numEdits: 1
      reactions: []
    id: 64e933e496f42afd62536602
    type: comment
  author: deetungsten
  content: This still happens without that flag though. I tried this on a MBP and
    another computer with a nvidia GPU with the same thing happening. Is there a specific
    command I am suppose to use with main?
  created_at: 2023-08-25 22:06:12+00:00
  edited: true
  hidden: false
  id: 64e933e496f42afd62536602
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679299766133-63e7f060db40d9e67ff2a2ba.jpeg?w=200&h=200&f=face
      fullname: Dave Young
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dyoung
      type: user
    createdAt: '2023-10-07T02:43:41.000Z'
    data:
      edited: false
      editors:
      - dyoung
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9614167213439941
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679299766133-63e7f060db40d9e67ff2a2ba.jpeg?w=200&h=200&f=face
          fullname: Dave Young
          isHf: false
          isPro: false
          name: dyoung
          type: user
        html: "<p>Just out of curiosity, what client backend were you guys using to\
          \ load the model when the phantom talking happened? I'm not familiar with\
          \ all of them that can load GGUF models. I don't recognize it from the text\
          \ <span data-props=\"{&quot;user&quot;:&quot;deetungsten&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/deetungsten\">@<span\
          \ class=\"underline\">deetungsten</span></a></span>\n\n\t</span></span>\
          \ and <span data-props=\"{&quot;user&quot;:&quot;md2&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/md2\">@<span class=\"\
          underline\">md2</span></a></span>\n\n\t</span></span> has shared in this\
          \ thread. Does this happen across different Client loading backends?</p>\n"
        raw: Just out of curiosity, what client backend were you guys using to load
          the model when the phantom talking happened? I'm not familiar with all of
          them that can load GGUF models. I don't recognize it from the text @deetungsten
          and @md2 has shared in this thread. Does this happen across different Client
          loading backends?
        updatedAt: '2023-10-07T02:43:41.971Z'
      numEdits: 0
      reactions: []
    id: 6520c5ddb0e0d57453da7b09
    type: comment
  author: dyoung
  content: Just out of curiosity, what client backend were you guys using to load
    the model when the phantom talking happened? I'm not familiar with all of them
    that can load GGUF models. I don't recognize it from the text @deetungsten and
    @md2 has shared in this thread. Does this happen across different Client loading
    backends?
  created_at: 2023-10-07 01:43:41+00:00
  edited: false
  hidden: false
  id: 6520c5ddb0e0d57453da7b09
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/CodeLlama-13B-Instruct-GGUF
repo_type: model
status: open
target_branch: null
title: Phatom Talking
