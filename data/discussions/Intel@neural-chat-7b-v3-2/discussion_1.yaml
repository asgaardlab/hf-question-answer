!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bartowski
conflicting_files: null
created_at: 2023-12-02 07:19:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6435718aaaef013d1aec3b8b/XKf-8MA47tjVAM6SCX0MP.jpeg?w=200&h=200&f=face
      fullname: Bartowski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bartowski
      type: user
    createdAt: '2023-12-02T07:19:01.000Z'
    data:
      edited: false
      editors:
      - bartowski
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9733226299285889
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6435718aaaef013d1aec3b8b/XKf-8MA47tjVAM6SCX0MP.jpeg?w=200&h=200&f=face
          fullname: Bartowski
          isHf: false
          isPro: false
          name: bartowski
          type: user
        html: '<p>Not much in the model card, any notable differences? increased training
          or otherwise?</p>

          '
        raw: Not much in the model card, any notable differences? increased training
          or otherwise?
        updatedAt: '2023-12-02T07:19:01.845Z'
      numEdits: 0
      reactions:
      - count: 13
        reaction: "\U0001F44D"
        users:
        - eramax
        - Charlie-B
        - iData
        - ddh0
        - mrfakename
        - joujiboi
        - tarruda
        - lixbo
        - TheYuriLover
        - Ichsan2895
        - Ilianos
        - iskenderulgen
        - lvkaokao
    id: 656ada658dffbab5afff62d9
    type: comment
  author: bartowski
  content: Not much in the model card, any notable differences? increased training
    or otherwise?
  created_at: 2023-12-02 07:19:01+00:00
  edited: false
  hidden: false
  id: 656ada658dffbab5afff62d9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b0389d0bcec73364c6583e33f10f70b7.svg
      fullname: linbo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lixbo
      type: user
    createdAt: '2023-12-03T13:45:55.000Z'
    data:
      edited: false
      editors:
      - lixbo
      hidden: false
      identifiedLanguage:
        language: sr
        probability: 0.5080763697624207
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b0389d0bcec73364c6583e33f10f70b7.svg
          fullname: linbo
          isHf: false
          isPro: false
          name: lixbo
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;lvkaokao&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/lvkaokao\">@<span class=\"\
          underline\">lvkaokao</span></a></span>\n\n\t</span></span> </p>\n"
        raw: '@lvkaokao '
        updatedAt: '2023-12-03T13:45:55.802Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - lvkaokao
    id: 656c86931f8d9b618db8e567
    type: comment
  author: lixbo
  content: '@lvkaokao '
  created_at: 2023-12-03 13:45:55+00:00
  edited: false
  hidden: false
  id: 656c86931f8d9b618db8e567
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/aa47fb2fc7039660ee89593cd6777f41.svg
      fullname: Mike Kasprzak
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: PoVRAZOR
      type: user
    createdAt: '2023-12-03T21:20:58.000Z'
    data:
      edited: false
      editors:
      - PoVRAZOR
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9572777152061462
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/aa47fb2fc7039660ee89593cd6777f41.svg
          fullname: Mike Kasprzak
          isHf: false
          isPro: false
          name: PoVRAZOR
          type: user
        html: '<p>In my initial testing, v3.2 is getting facts more correct than v3.1,
          but I have been using the 5bit quantized models. I''m currently downloading
          the fp16 version for further testing.</p>

          '
        raw: In my initial testing, v3.2 is getting facts more correct than v3.1,
          but I have been using the 5bit quantized models. I'm currently downloading
          the fp16 version for further testing.
        updatedAt: '2023-12-03T21:20:58.777Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - bartowski
      - count: 1
        reaction: "\U0001F917"
        users:
        - lvkaokao
    id: 656cf13a3e60cb2621cb1d9a
    type: comment
  author: PoVRAZOR
  content: In my initial testing, v3.2 is getting facts more correct than v3.1, but
    I have been using the 5bit quantized models. I'm currently downloading the fp16
    version for further testing.
  created_at: 2023-12-03 21:20:58+00:00
  edited: false
  hidden: false
  id: 656cf13a3e60cb2621cb1d9a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/646f1952753be77a8e933f90/OnohCFBLC9aUwqKBTYax8.jpeg?w=200&h=200&f=face
      fullname: Robert Kelley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Metricon
      type: user
    createdAt: '2023-12-07T06:49:27.000Z'
    data:
      edited: true
      editors:
      - Metricon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8989554643630981
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/646f1952753be77a8e933f90/OnohCFBLC9aUwqKBTYax8.jpeg?w=200&h=200&f=face
          fullname: Robert Kelley
          isHf: false
          isPro: false
          name: Metricon
          type: user
        html: '<p>In testing, this new version appears to work very well.</p>

          '
        raw: In testing, this new version appears to work very well.
        updatedAt: '2023-12-07T06:56:06.984Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - lvkaokao
    id: 65716af73ddb53dd57d2ce7f
    type: comment
  author: Metricon
  content: In testing, this new version appears to work very well.
  created_at: 2023-12-07 06:49:27+00:00
  edited: true
  hidden: false
  id: 65716af73ddb53dd57d2ce7f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/df7c2780f4b2dcf9c5010ad7595da9c3.svg
      fullname: Iskender Ulgen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iskenderulgen
      type: user
    createdAt: '2023-12-07T18:11:52.000Z'
    data:
      edited: false
      editors:
      - iskenderulgen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8840765953063965
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/df7c2780f4b2dcf9c5010ad7595da9c3.svg
          fullname: Iskender Ulgen
          isHf: false
          isPro: false
          name: iskenderulgen
          type: user
        html: '<p>Is the model trained with Quantization Aware Training to save more
          accuracy do we have any knowledge of that ? and the model checkpoints in
          the files are full precision or half precision ? Apart from the questions
          model gives great results for language understanding thought in some cases
          gives better results when using 8bit inference over torch fp16 dtype need
          more testing probably</p>

          '
        raw: Is the model trained with Quantization Aware Training to save more accuracy
          do we have any knowledge of that ? and the model checkpoints in the files
          are full precision or half precision ? Apart from the questions model gives
          great results for language understanding thought in some cases gives better
          results when using 8bit inference over torch fp16 dtype need more testing
          probably
        updatedAt: '2023-12-07T18:11:52.989Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - lvkaokao
    id: 65720ae86e1ac5922a9040bb
    type: comment
  author: iskenderulgen
  content: Is the model trained with Quantization Aware Training to save more accuracy
    do we have any knowledge of that ? and the model checkpoints in the files are
    full precision or half precision ? Apart from the questions model gives great
    results for language understanding thought in some cases gives better results
    when using 8bit inference over torch fp16 dtype need more testing probably
  created_at: 2023-12-07 18:11:52+00:00
  edited: false
  hidden: false
  id: 65720ae86e1ac5922a9040bb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
      fullname: lvkaokao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lvkaokao
      type: user
    createdAt: '2023-12-11T02:32:30.000Z'
    data:
      edited: false
      editors:
      - lvkaokao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6799663305282593
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
          fullname: lvkaokao
          isHf: false
          isPro: false
          name: lvkaokao
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;bartowski&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/bartowski\">@<span class=\"\
          underline\">bartowski</span></a></span>\n\n\t</span></span>  hi,  we update\
          \ the model card</p>\n<p><span data-props=\"{&quot;user&quot;:&quot;PoVRAZOR&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/PoVRAZOR\"\
          >@<span class=\"underline\">PoVRAZOR</span></a></span>\n\n\t</span></span>\
          \ Thanks for your testing, we continue training the <a href=\"https://huggingface.co/Intel/neural-chat-7b-v3-1\"\
          >https://huggingface.co/Intel/neural-chat-7b-v3-1</a> with <a href=\"https://huggingface.co/datasets/meta-math/MetaMathQA\"\
          >https://huggingface.co/datasets/meta-math/MetaMathQA</a> dataset</p>\n\
          <p><span data-props=\"{&quot;user&quot;:&quot;Metricon&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Metricon\">@<span class=\"\
          underline\">Metricon</span></a></span>\n\n\t</span></span> Thanks~</p>\n\
          <p><span data-props=\"{&quot;user&quot;:&quot;iskenderulgen&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/iskenderulgen\">@<span\
          \ class=\"underline\">iskenderulgen</span></a></span>\n\n\t</span></span>\
          \ hi, we use fp16 mixed training.</p>\n"
        raw: '@bartowski  hi,  we update the model card


          @PoVRAZOR Thanks for your testing, we continue training the https://huggingface.co/Intel/neural-chat-7b-v3-1
          with https://huggingface.co/datasets/meta-math/MetaMathQA dataset


          @Metricon Thanks~


          @iskenderulgen hi, we use fp16 mixed training.'
        updatedAt: '2023-12-11T02:32:30.342Z'
      numEdits: 0
      reactions: []
    id: 657674be88805b3ba12e0caf
    type: comment
  author: lvkaokao
  content: '@bartowski  hi,  we update the model card


    @PoVRAZOR Thanks for your testing, we continue training the https://huggingface.co/Intel/neural-chat-7b-v3-1
    with https://huggingface.co/datasets/meta-math/MetaMathQA dataset


    @Metricon Thanks~


    @iskenderulgen hi, we use fp16 mixed training.'
  created_at: 2023-12-11 02:32:30+00:00
  edited: false
  hidden: false
  id: 657674be88805b3ba12e0caf
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Intel/neural-chat-7b-v3-2
repo_type: model
status: open
target_branch: null
title: v3-2 vs v3-1
