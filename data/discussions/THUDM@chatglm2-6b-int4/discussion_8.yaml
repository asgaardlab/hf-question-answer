!!python/object:huggingface_hub.community.DiscussionWithDetails
author: you-2
conflicting_files: null
created_at: 2023-07-04 08:30:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/138f038fbb4907ed9e045da098ed4c88.svg
      fullname: yo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: you-2
      type: user
    createdAt: '2023-07-04T09:30:51.000Z'
    data:
      edited: false
      editors:
      - you-2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5280830264091492
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/138f038fbb4907ed9e045da098ed4c88.svg
          fullname: yo
          isHf: false
          isPro: false
          name: you-2
          type: user
        html: "<p>\u63A8\u7406\u62A5\u9519</p>\n<p>from transformers import AutoTokenizer,\
          \ AutoModel<br>checkpoint = \"./chatglm2-6b-int4/\"<br>tokenizer = AutoTokenizer.from_pretrained(checkpoint,\
          \ trust_remote_code=True)<br>model = AutoModel.from_pretrained(checkpoint,\
          \ trust_remote_code=True, device='cpu')</p>\n<h1 id=\"model--modeleval\"\
          >model = model.eval()</h1>\n<p>model = model.cpu()<br>response, history\
          \ = model.chat(tokenizer, \"\u4F60\u597D\", history=[])<br>print(response)</p>\n"
        raw: "\u63A8\u7406\u62A5\u9519\r\n\r\nfrom transformers import AutoTokenizer,\
          \ AutoModel\r\ncheckpoint = \"./chatglm2-6b-int4/\"\r\ntokenizer = AutoTokenizer.from_pretrained(checkpoint,\
          \ trust_remote_code=True)\r\nmodel = AutoModel.from_pretrained(checkpoint,\
          \ trust_remote_code=True, device='cpu')\r\n# model = model.eval()\r\nmodel\
          \ = model.cpu()\r\nresponse, history = model.chat(tokenizer, \"\u4F60\u597D\
          \", history=[])\r\nprint(response)\r\n"
        updatedAt: '2023-07-04T09:30:51.433Z'
      numEdits: 0
      reactions: []
    id: 64a3e6cbaab6329074372e82
    type: comment
  author: you-2
  content: "\u63A8\u7406\u62A5\u9519\r\n\r\nfrom transformers import AutoTokenizer,\
    \ AutoModel\r\ncheckpoint = \"./chatglm2-6b-int4/\"\r\ntokenizer = AutoTokenizer.from_pretrained(checkpoint,\
    \ trust_remote_code=True)\r\nmodel = AutoModel.from_pretrained(checkpoint, trust_remote_code=True,\
    \ device='cpu')\r\n# model = model.eval()\r\nmodel = model.cpu()\r\nresponse,\
    \ history = model.chat(tokenizer, \"\u4F60\u597D\", history=[])\r\nprint(response)\r\
    \n"
  created_at: 2023-07-04 08:30:51+00:00
  edited: false
  hidden: false
  id: 64a3e6cbaab6329074372e82
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: THUDM/chatglm2-6b-int4
repo_type: model
status: open
target_branch: null
title: '"addmm_impl_cpu_" not implemented for ''Half'''
