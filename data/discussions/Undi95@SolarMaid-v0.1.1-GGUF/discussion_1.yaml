!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BlueNipples
conflicting_files: null
created_at: 2023-12-22 10:47:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
      fullname: Matthew Andrews
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlueNipples
      type: user
    createdAt: '2023-12-22T10:47:46.000Z'
    data:
      edited: true
      editors:
      - BlueNipples
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9704698324203491
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
          fullname: Matthew Andrews
          isHf: false
          isPro: false
          name: BlueNipples
          type: user
        html: '<p>This model is pretty promising on it''s own as a RP model. Nothing
          I''ve seen in finetunes really have great prose tho yet. But it does seem
          to grok the story context often better than a 13b. Like seems like an amazing
          base at 10.7b for RP. What''s more I can run it comfortably on my laptop
          grade GPU. I hope more people do training with this model! </p>

          <p>Also I wonder if you could hybridize it with toppy, without increasing
          the size? Like maybe 32 of the bottom layers of solar instruct, and 16 of
          the topmost layers of Toppy? It might work because it has mistral layers
          mixed in there? Or noromaid as I guess solar is llama-2 and thus incompatible.
          Lol, I''m probably just too keen to see what this can do when given real
          training :P</p>

          '
        raw: "This model is pretty promising on it's own as a RP model. Nothing I've\
          \ seen in finetunes really have great prose tho yet. But it does seem to\
          \ grok the story context often better than a 13b. Like seems like an amazing\
          \ base at 10.7b for RP. What's more I can run it comfortably on my laptop\
          \ grade GPU. I hope more people do training with this model! \n\nAlso I\
          \ wonder if you could hybridize it with toppy, without increasing the size?\
          \ Like maybe 32 of the bottom layers of solar instruct, and 16 of the topmost\
          \ layers of Toppy? It might work because it has mistral layers mixed in\
          \ there? Or noromaid as I guess solar is llama-2 and thus incompatible.\
          \ Lol, I'm probably just too keen to see what this can do when given real\
          \ training :P"
        updatedAt: '2023-12-22T10:54:53.331Z'
      numEdits: 1
      reactions: []
    id: 65856952d21213ef126233ac
    type: comment
  author: BlueNipples
  content: "This model is pretty promising on it's own as a RP model. Nothing I've\
    \ seen in finetunes really have great prose tho yet. But it does seem to grok\
    \ the story context often better than a 13b. Like seems like an amazing base at\
    \ 10.7b for RP. What's more I can run it comfortably on my laptop grade GPU. I\
    \ hope more people do training with this model! \n\nAlso I wonder if you could\
    \ hybridize it with toppy, without increasing the size? Like maybe 32 of the bottom\
    \ layers of solar instruct, and 16 of the topmost layers of Toppy? It might work\
    \ because it has mistral layers mixed in there? Or noromaid as I guess solar is\
    \ llama-2 and thus incompatible. Lol, I'm probably just too keen to see what this\
    \ can do when given real training :P"
  created_at: 2023-12-22 10:47:46+00:00
  edited: true
  hidden: false
  id: 65856952d21213ef126233ac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2023-12-22T14:21:56.000Z'
    data:
      edited: false
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9101550579071045
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<p>I''m working on a Solar Maid 0.2 with last Noromaid.<br>Also, SOLAR
          is Mistral, even if their config say otherwise. </p>

          '
        raw: 'I''m working on a Solar Maid 0.2 with last Noromaid.

          Also, SOLAR is Mistral, even if their config say otherwise. '
        updatedAt: '2023-12-22T14:21:56.984Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F91D"
        users:
        - BlueNipples
        - den0620
    id: 65859b84e6012e80629b995e
    type: comment
  author: Undi95
  content: 'I''m working on a Solar Maid 0.2 with last Noromaid.

    Also, SOLAR is Mistral, even if their config say otherwise. '
  created_at: 2023-12-22 14:21:56+00:00
  edited: false
  hidden: false
  id: 65859b84e6012e80629b995e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
      fullname: Matthew Andrews
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlueNipples
      type: user
    createdAt: '2023-12-22T14:54:57.000Z'
    data:
      edited: false
      editors:
      - BlueNipples
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8151442408561707
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
          fullname: Matthew Andrews
          isHf: false
          isPro: false
          name: BlueNipples
          type: user
        html: "<p>Just remember us GPU poors \U0001F923 Keep up the good work!</p>\n"
        raw: "Just remember us GPU poors \U0001F923 Keep up the good work!"
        updatedAt: '2023-12-22T14:54:57.320Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Herman555
    id: 6585a341fceda32a94891d4f
    type: comment
  author: BlueNipples
  content: "Just remember us GPU poors \U0001F923 Keep up the good work!"
  created_at: 2023-12-22 14:54:57+00:00
  edited: false
  hidden: false
  id: 6585a341fceda32a94891d4f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b9465e33684fed55d6166b3c90dffc9e.svg
      fullname: Justo Rivera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cesar3569
      type: user
    createdAt: '2023-12-29T04:08:40.000Z'
    data:
      edited: false
      editors:
      - cesar3569
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9832910895347595
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b9465e33684fed55d6166b3c90dffc9e.svg
          fullname: Justo Rivera
          isHf: false
          isPro: false
          name: cesar3569
          type: user
        html: '<p>I''m going to have to put this up on the cloud cause my gpu sucks.
          I love the models you make. just you and the bloke are my 1st go-to people
          for models. I''m never disappointed</p>

          '
        raw: I'm going to have to put this up on the cloud cause my gpu sucks. I love
          the models you make. just you and the bloke are my 1st go-to people for
          models. I'm never disappointed
        updatedAt: '2023-12-29T04:08:40.724Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Undi95
      - count: 1
        reaction: "\U0001F44D"
        users:
        - green-anger
    id: 658e464850d39af7f4a6b364
    type: comment
  author: cesar3569
  content: I'm going to have to put this up on the cloud cause my gpu sucks. I love
    the models you make. just you and the bloke are my 1st go-to people for models.
    I'm never disappointed
  created_at: 2023-12-29 04:08:40+00:00
  edited: false
  hidden: false
  id: 658e464850d39af7f4a6b364
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Undi95/SolarMaid-v0.1.1-GGUF
repo_type: model
status: open
target_branch: null
title: Solar 10.7
