!!python/object:huggingface_hub.community.DiscussionWithDetails
author: RiggityWrckd
conflicting_files: null
created_at: 2023-04-15 18:37:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ad8daf7101b78ae4226f3ade0d64bbe6.svg
      fullname: Riggity Wrckd
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: RiggityWrckd
      type: user
    createdAt: '2023-04-15T19:37:07.000Z'
    data:
      edited: true
      editors:
      - RiggityWrckd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ad8daf7101b78ae4226f3ade0d64bbe6.svg
          fullname: Riggity Wrckd
          isHf: false
          isPro: false
          name: RiggityWrckd
          type: user
        html: '<p>Hi, I was just wondering if anyone had tried out the 4bit safetensor
          file yet on triton? Was it quantized with triton or with cuda?  My setup
          is all triton right now.  This looks like a really cool model. Thanks for
          putting it together :)</p>

          <p>Edit: I answered my own question and downloaded the 4bit.safetensor it
          works on my triton branch textgen install with no groupsize set.  Hope this
          helps someone out there</p>

          '
        raw: 'Hi, I was just wondering if anyone had tried out the 4bit safetensor
          file yet on triton? Was it quantized with triton or with cuda?  My setup
          is all triton right now.  This looks like a really cool model. Thanks for
          putting it together :)


          Edit: I answered my own question and downloaded the 4bit.safetensor it works
          on my triton branch textgen install with no groupsize set.  Hope this helps
          someone out there'
        updatedAt: '2023-04-16T07:24:14.327Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - ultra2mh
        - PrimeD
    id: 643afce3b54b34655652d81f
    type: comment
  author: RiggityWrckd
  content: 'Hi, I was just wondering if anyone had tried out the 4bit safetensor file
    yet on triton? Was it quantized with triton or with cuda?  My setup is all triton
    right now.  This looks like a really cool model. Thanks for putting it together
    :)


    Edit: I answered my own question and downloaded the 4bit.safetensor it works on
    my triton branch textgen install with no groupsize set.  Hope this helps someone
    out there'
  created_at: 2023-04-15 18:37:07+00:00
  edited: true
  hidden: false
  id: 643afce3b54b34655652d81f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
      fullname: Erik
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: digitous
      type: user
    createdAt: '2023-05-19T06:32:23.000Z'
    data:
      edited: false
      editors:
      - digitous
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676448086084-62ae5fbe4ff605c0411397bb.jpeg?w=200&h=200&f=face
          fullname: Erik
          isHf: false
          isPro: false
          name: digitous
          type: user
        html: '<p>Apologies for the late reply; I''m glad you found the answer, thank
          you for sharing!</p>

          '
        raw: Apologies for the late reply; I'm glad you found the answer, thank you
          for sharing!
        updatedAt: '2023-05-19T06:32:23.683Z'
      numEdits: 0
      reactions: []
    id: 646717f73a7c8dda23fd5f64
    type: comment
  author: digitous
  content: Apologies for the late reply; I'm glad you found the answer, thank you
    for sharing!
  created_at: 2023-05-19 05:32:23+00:00
  edited: false
  hidden: false
  id: 646717f73a7c8dda23fd5f64
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: digitous/Alpacino13b
repo_type: model
status: open
target_branch: null
title: 4bit safetensor file triton or cuda?
