!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SVBilenko
conflicting_files: null
created_at: 2023-05-05 16:55:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b783255b6666620a51ccee7f652364e4.svg
      fullname: Sergey Bilenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SVBilenko
      type: user
    createdAt: '2023-05-05T17:55:17.000Z'
    data:
      edited: true
      editors:
      - SVBilenko
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b783255b6666620a51ccee7f652364e4.svg
          fullname: Sergey Bilenko
          isHf: false
          isPro: false
          name: SVBilenko
          type: user
        html: '<p>Can you tell me how much computer RAM is needed to deploy this model?
          My attempt to deploy the model on a computer with 64 gigabytes of RAM ended
          in failure due to lack of memory.</p>

          '
        raw: Can you tell me how much computer RAM is needed to deploy this model?
          My attempt to deploy the model on a computer with 64 gigabytes of RAM ended
          in failure due to lack of memory.
        updatedAt: '2023-05-05T17:59:23.617Z'
      numEdits: 1
      reactions: []
    id: 64554305fbe00f9e73c0e2c1
    type: comment
  author: SVBilenko
  content: Can you tell me how much computer RAM is needed to deploy this model? My
    attempt to deploy the model on a computer with 64 gigabytes of RAM ended in failure
    due to lack of memory.
  created_at: 2023-05-05 16:55:17+00:00
  edited: true
  hidden: false
  id: 64554305fbe00f9e73c0e2c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/29746867b8a5e964cb998b17a363310d.svg
      fullname: ymn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pseudon
      type: user
    createdAt: '2023-05-05T18:10:21.000Z'
    data:
      edited: false
      editors:
      - pseudon
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/29746867b8a5e964cb998b17a363310d.svg
          fullname: ymn
          isHf: false
          isPro: false
          name: pseudon
          type: user
        html: '<p>i added 40gb of swap and it took up 22gb of it, perhaps adding bf16?</p>

          '
        raw: i added 40gb of swap and it took up 22gb of it, perhaps adding bf16?
        updatedAt: '2023-05-05T18:10:21.995Z'
      numEdits: 0
      reactions: []
    id: 6455468dfe2f48cb4b6c1760
    type: comment
  author: pseudon
  content: i added 40gb of swap and it took up 22gb of it, perhaps adding bf16?
  created_at: 2023-05-05 17:10:21+00:00
  edited: false
  hidden: false
  id: 6455468dfe2f48cb4b6c1760
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-05-05T18:16:15.000Z'
    data:
      edited: false
      editors:
      - loubnabnl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: '<p>yes, try using bf16 of fp16 by specifying <code>torch_dtype</code>
          when loading the model it will take ~30GB, <code>load_in_8bit</code> might
          save even more memory (as mentioned <a href="https://huggingface.co/bigcode/starcoder/discussions/10#6454212ace1cc3ed5fe34e6a">here</a>)</p>

          '
        raw: yes, try using bf16 of fp16 by specifying `torch_dtype` when loading
          the model it will take ~30GB, `load_in_8bit` might save even more memory
          (as mentioned [here](https://huggingface.co/bigcode/starcoder/discussions/10#6454212ace1cc3ed5fe34e6a))
        updatedAt: '2023-05-05T18:16:15.385Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - apol
        - cactusthecoder8
        - OwenXXXX
        - noobmldude
    id: 645547eff61f10d69dcda2ef
    type: comment
  author: loubnabnl
  content: yes, try using bf16 of fp16 by specifying `torch_dtype` when loading the
    model it will take ~30GB, `load_in_8bit` might save even more memory (as mentioned
    [here](https://huggingface.co/bigcode/starcoder/discussions/10#6454212ace1cc3ed5fe34e6a))
  created_at: 2023-05-05 17:16:15+00:00
  edited: false
  hidden: false
  id: 645547eff61f10d69dcda2ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/29746867b8a5e964cb998b17a363310d.svg
      fullname: ymn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pseudon
      type: user
    createdAt: '2023-05-05T18:42:59.000Z'
    data:
      edited: false
      editors:
      - pseudon
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/29746867b8a5e964cb998b17a363310d.svg
          fullname: ymn
          isHf: false
          isPro: false
          name: pseudon
          type: user
        html: '<p>would a ggml model run better on cpus?</p>

          '
        raw: would a ggml model run better on cpus?
        updatedAt: '2023-05-05T18:42:59.435Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - shirman
    id: 64554e33f61f10d69dce1a60
    type: comment
  author: pseudon
  content: would a ggml model run better on cpus?
  created_at: 2023-05-05 17:42:59+00:00
  edited: false
  hidden: false
  id: 64554e33f61f10d69dce1a60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/305ffe97659628082e04ca17949cba89.svg
      fullname: Wali
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hussainwali1
      type: user
    createdAt: '2023-05-19T10:55:30.000Z'
    data:
      edited: false
      editors:
      - hussainwali1
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/305ffe97659628082e04ca17949cba89.svg
          fullname: Wali
          isHf: false
          isPro: false
          name: hussainwali1
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;pseudon&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/pseudon\">@<span class=\"\
          underline\">pseudon</span></a></span>\n\n\t</span></span> how to add the\
          \ 40gb swap? am a bit of a noob sorry</p>\n"
        raw: '@pseudon how to add the 40gb swap? am a bit of a noob sorry'
        updatedAt: '2023-05-19T10:55:30.106Z'
      numEdits: 0
      reactions: []
    id: 646755a2ab75d9cb3c445976
    type: comment
  author: hussainwali1
  content: '@pseudon how to add the 40gb swap? am a bit of a noob sorry'
  created_at: 2023-05-19 09:55:30+00:00
  edited: false
  hidden: false
  id: 646755a2ab75d9cb3c445976
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/631f2d07788f34547a98a2b1/YGC8RkiOO7P0VMArVM1k8.jpeg?w=200&h=200&f=face
      fullname: Faried Nawaz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: faried
      type: user
    createdAt: '2023-05-23T19:27:04.000Z'
    data:
      edited: false
      editors:
      - faried
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/631f2d07788f34547a98a2b1/YGC8RkiOO7P0VMArVM1k8.jpeg?w=200&h=200&f=face
          fullname: Faried Nawaz
          isHf: false
          isPro: false
          name: faried
          type: user
        html: '<blockquote>

          <p>how to add the 40gb swap? am a bit of a noob sorry</p>

          </blockquote>

          <pre><code>sudo dd if=/dev/zero of=/.swap bs=16777216 count=2560

          sudo mkswap /.swap

          sudo swapon -v /.swap

          </code></pre>

          '
        raw: '> how to add the 40gb swap? am a bit of a noob sorry


          ```

          sudo dd if=/dev/zero of=/.swap bs=16777216 count=2560

          sudo mkswap /.swap

          sudo swapon -v /.swap

          ```'
        updatedAt: '2023-05-23T19:27:04.853Z'
      numEdits: 0
      reactions: []
    id: 646d13884a2db774437a95e8
    type: comment
  author: faried
  content: '> how to add the 40gb swap? am a bit of a noob sorry


    ```

    sudo dd if=/dev/zero of=/.swap bs=16777216 count=2560

    sudo mkswap /.swap

    sudo swapon -v /.swap

    ```'
  created_at: 2023-05-23 18:27:04+00:00
  edited: false
  hidden: false
  id: 646d13884a2db774437a95e8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-06-06T22:00:55.000Z'
    data:
      edited: false
      editors:
      - loubnabnl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7412329912185669
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: '<p>Closing this issue as we added a hardware requirements section <a
          rel="nofollow" href="https://github.com/bigcode-project/starcoder#inference-hardware-requirements">here</a>
          and we have a ggml implementation at <a rel="nofollow" href="https://github.com/bigcode-project/starcoder.cpp">starcoder.cpp</a></p>

          '
        raw: Closing this issue as we added a hardware requirements section [here](https://github.com/bigcode-project/starcoder#inference-hardware-requirements)
          and we have a ggml implementation at [starcoder.cpp](https://github.com/bigcode-project/starcoder.cpp)
        updatedAt: '2023-06-06T22:00:55.926Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - noobmldude
      relatedEventId: 647fac97c20d8d1b6a5f3ec5
    id: 647fac97c20d8d1b6a5f3ec4
    type: comment
  author: loubnabnl
  content: Closing this issue as we added a hardware requirements section [here](https://github.com/bigcode-project/starcoder#inference-hardware-requirements)
    and we have a ggml implementation at [starcoder.cpp](https://github.com/bigcode-project/starcoder.cpp)
  created_at: 2023-06-06 21:00:55+00:00
  edited: false
  hidden: false
  id: 647fac97c20d8d1b6a5f3ec4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-06-06T22:00:55.000Z'
    data:
      status: closed
    id: 647fac97c20d8d1b6a5f3ec5
    type: status-change
  author: loubnabnl
  created_at: 2023-06-06 21:00:55+00:00
  id: 647fac97c20d8d1b6a5f3ec5
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: bigcode/starcoder
repo_type: model
status: closed
target_branch: null
title: Computer RAM requirements
