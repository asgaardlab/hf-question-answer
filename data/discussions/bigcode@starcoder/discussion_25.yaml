!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rookielyb
conflicting_files: null
created_at: 2023-05-10 19:41:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/89c90ca3d94d8cb99924746d2c3522c4.svg
      fullname: yibo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rookielyb
      type: user
    createdAt: '2023-05-10T20:41:40.000Z'
    data:
      edited: false
      editors:
      - rookielyb
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/89c90ca3d94d8cb99924746d2c3522c4.svg
          fullname: yibo
          isHf: false
          isPro: false
          name: rookielyb
          type: user
        html: '<p>When I was using it, I found that the effect of Code Completion
          Playground is much better than the offline prediction effect of the weight
          of the starcoder I downloaded. Why is this, and is there any difference?
          At the same time, the effect of Hosted inference API is not as good as that
          of Code Completion Playground. OK, does it do anything special?</p>

          '
        raw: When I was using it, I found that the effect of Code Completion Playground
          is much better than the offline prediction effect of the weight of the starcoder
          I downloaded. Why is this, and is there any difference? At the same time,
          the effect of Hosted inference API is not as good as that of Code Completion
          Playground. OK, does it do anything special?
        updatedAt: '2023-05-10T20:41:40.382Z'
      numEdits: 0
      reactions: []
    id: 645c01849522edfc8e51d217
    type: comment
  author: rookielyb
  content: When I was using it, I found that the effect of Code Completion Playground
    is much better than the offline prediction effect of the weight of the starcoder
    I downloaded. Why is this, and is there any difference? At the same time, the
    effect of Hosted inference API is not as good as that of Code Completion Playground.
    OK, does it do anything special?
  created_at: 2023-05-10 19:41:40+00:00
  edited: false
  hidden: false
  id: 645c01849522edfc8e51d217
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
      fullname: Qian Liu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: SivilTaram
      type: user
    createdAt: '2023-05-11T00:30:10.000Z'
    data:
      edited: false
      editors:
      - SivilTaram
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
          fullname: Qian Liu
          isHf: false
          isPro: false
          name: SivilTaram
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;rookielyb&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/rookielyb\">@<span class=\"\
          underline\">rookielyb</span></a></span>\n\n\t</span></span> I'm not sure,\
          \ but you may be careful about the hyper-parameter (e.g., temperature).</p>\n"
        raw: '@rookielyb I''m not sure, but you may be careful about the hyper-parameter
          (e.g., temperature).'
        updatedAt: '2023-05-11T00:30:10.418Z'
      numEdits: 0
      reactions: []
    id: 645c3712c79d6c83aa46400c
    type: comment
  author: SivilTaram
  content: '@rookielyb I''m not sure, but you may be careful about the hyper-parameter
    (e.g., temperature).'
  created_at: 2023-05-10 23:30:10+00:00
  edited: false
  hidden: false
  id: 645c3712c79d6c83aa46400c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/34c7f3f30759bbbbee0a77d0361e08a2.svg
      fullname: zhaositong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: miraclezst
      type: user
    createdAt: '2023-05-11T02:10:43.000Z'
    data:
      edited: true
      editors:
      - miraclezst
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/34c7f3f30759bbbbee0a77d0361e08a2.svg
          fullname: zhaositong
          isHf: false
          isPro: false
          name: miraclezst
          type: user
        html: '<p>I have the same problem,  but I am running in 8bit mode, I don''t
          know if this is the reason</p>

          '
        raw: I have the same problem,  but I am running in 8bit mode, I don't know
          if this is the reason
        updatedAt: '2023-05-11T02:12:03.845Z'
      numEdits: 1
      reactions: []
    id: 645c4ea311b04b05ad080b0e
    type: comment
  author: miraclezst
  content: I have the same problem,  but I am running in 8bit mode, I don't know if
    this is the reason
  created_at: 2023-05-11 01:10:43+00:00
  edited: true
  hidden: false
  id: 645c4ea311b04b05ad080b0e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/89c90ca3d94d8cb99924746d2c3522c4.svg
      fullname: yibo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rookielyb
      type: user
    createdAt: '2023-05-11T03:20:54.000Z'
    data:
      edited: false
      editors:
      - rookielyb
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/89c90ca3d94d8cb99924746d2c3522c4.svg
          fullname: yibo
          isHf: false
          isPro: false
          name: rookielyb
          type: user
        html: "<p>this is my code</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/ZC11uBIa5EDntuhCWRdUA.png\"\
          ><img alt=\"\u4F01\u4E1A\u5FAE\u4FE1\u622A\u56FE_d75ee79f-5d8b-47b1-8dd2-90f08aedbf16.png\"\
          \ src=\"https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/ZC11uBIa5EDntuhCWRdUA.png\"\
          ></a><br>I predicted 10 times and didn't get one correct result</p>\n<p><a\
          \ rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/42I3j_IAM-WruWFAXONr6.png\"\
          ><img alt=\"\u4F01\u4E1A\u5FAE\u4FE1\u622A\u56FE_0fdde452-8bfa-4f0e-ab56-1e434709f631.png\"\
          \ src=\"https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/42I3j_IAM-WruWFAXONr6.png\"\
          ></a><br>But I try to use your api, can get the correct result</p>\n<p><a\
          \ rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/x6-UwbY52zOiFUdpFAImq.png\"\
          ><img alt=\"\u4F01\u4E1A\u5FAE\u4FE1\u622A\u56FE_d92508a3-b65c-4886-a2a7-da07b5b8e7f4.png\"\
          \ src=\"https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/x6-UwbY52zOiFUdpFAImq.png\"\
          ></a></p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/TbHfeWAQmit4TMyo0Y8Sd.png\"\
          ><img alt=\"\u4F01\u4E1A\u5FAE\u4FE1\u622A\u56FE_5fe67b3b-5dab-48c4-9f90-124ed0015831.png\"\
          \ src=\"https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/TbHfeWAQmit4TMyo0Y8Sd.png\"\
          ></a><br>Why is this? I'm having a hard time achieving your results in human\
          \ eval.<br>Hope to get your reply!</p>\n"
        raw: "this is my code\n\n![\u4F01\u4E1A\u5FAE\u4FE1\u622A\u56FE_d75ee79f-5d8b-47b1-8dd2-90f08aedbf16.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/ZC11uBIa5EDntuhCWRdUA.png)\n\
          I predicted 10 times and didn't get one correct result\n\n![\u4F01\u4E1A\
          \u5FAE\u4FE1\u622A\u56FE_0fdde452-8bfa-4f0e-ab56-1e434709f631.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/42I3j_IAM-WruWFAXONr6.png)\n\
          But I try to use your api, can get the correct result\n\n![\u4F01\u4E1A\u5FAE\
          \u4FE1\u622A\u56FE_d92508a3-b65c-4886-a2a7-da07b5b8e7f4.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/x6-UwbY52zOiFUdpFAImq.png)\n\
          \n\n![\u4F01\u4E1A\u5FAE\u4FE1\u622A\u56FE_5fe67b3b-5dab-48c4-9f90-124ed0015831.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/TbHfeWAQmit4TMyo0Y8Sd.png)\n\
          Why is this? I'm having a hard time achieving your results in human eval.\n\
          Hope to get your reply!"
        updatedAt: '2023-05-11T03:20:54.566Z'
      numEdits: 0
      reactions: []
    id: 645c5f16b0c06125080e5083
    type: comment
  author: rookielyb
  content: "this is my code\n\n![\u4F01\u4E1A\u5FAE\u4FE1\u622A\u56FE_d75ee79f-5d8b-47b1-8dd2-90f08aedbf16.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/ZC11uBIa5EDntuhCWRdUA.png)\n\
    I predicted 10 times and didn't get one correct result\n\n![\u4F01\u4E1A\u5FAE\
    \u4FE1\u622A\u56FE_0fdde452-8bfa-4f0e-ab56-1e434709f631.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/42I3j_IAM-WruWFAXONr6.png)\n\
    But I try to use your api, can get the correct result\n\n![\u4F01\u4E1A\u5FAE\u4FE1\
    \u622A\u56FE_d92508a3-b65c-4886-a2a7-da07b5b8e7f4.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/x6-UwbY52zOiFUdpFAImq.png)\n\
    \n\n![\u4F01\u4E1A\u5FAE\u4FE1\u622A\u56FE_5fe67b3b-5dab-48c4-9f90-124ed0015831.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/TbHfeWAQmit4TMyo0Y8Sd.png)\n\
    Why is this? I'm having a hard time achieving your results in human eval.\nHope\
    \ to get your reply!"
  created_at: 2023-05-11 02:20:54+00:00
  edited: false
  hidden: false
  id: 645c5f16b0c06125080e5083
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
      fullname: Qian Liu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: SivilTaram
      type: user
    createdAt: '2023-05-11T08:21:43.000Z'
    data:
      edited: false
      editors:
      - SivilTaram
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
          fullname: Qian Liu
          isHf: false
          isPro: false
          name: SivilTaram
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;rookielyb&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/rookielyb\">@<span class=\"\
          underline\">rookielyb</span></a></span>\n\n\t</span></span> I notice that\
          \ you set the <code>topk_k=50</code>. Can you try again after removing the\
          \ constraint? I do not think we have ever set <code>top_k</code>.</p>\n"
        raw: '@rookielyb I notice that you set the `topk_k=50`. Can you try again
          after removing the constraint? I do not think we have ever set `top_k`.'
        updatedAt: '2023-05-11T08:21:43.604Z'
      numEdits: 0
      reactions: []
    id: 645ca5978ce4443cae6c93c2
    type: comment
  author: SivilTaram
  content: '@rookielyb I notice that you set the `topk_k=50`. Can you try again after
    removing the constraint? I do not think we have ever set `top_k`.'
  created_at: 2023-05-11 07:21:43+00:00
  edited: false
  hidden: false
  id: 645ca5978ce4443cae6c93c2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/89c90ca3d94d8cb99924746d2c3522c4.svg
      fullname: yibo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: rookielyb
      type: user
    createdAt: '2023-05-11T10:18:57.000Z'
    data:
      edited: false
      editors:
      - rookielyb
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/89c90ca3d94d8cb99924746d2c3522c4.svg
          fullname: yibo
          isHf: false
          isPro: false
          name: rookielyb
          type: user
        html: '<p>thank you for your reply!<br>Here are the latest parameters<br><a
          rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/J2-ObFdJfht7UlSv92y3I.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/J2-ObFdJfht7UlSv92y3I.png"></a><br>The
          effect of the same parameter starcoderbase is better than that of starcoder</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/2Du-zmcchSNmE6YXtq8o4.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/2Du-zmcchSNmE6YXtq8o4.png"></a><br>The
          left side of the figure is the weight based on starcoderbase, and the right
          side is based on starcoder<br>I found that the generated results are very
          sensitive to the parameters.<br>Is it convenient to give the parameters
          of the human eval results in the paper? pass@1</p>

          '
        raw: 'thank you for your reply!

          Here are the latest parameters

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/J2-ObFdJfht7UlSv92y3I.png)

          The effect of the same parameter starcoderbase is better than that of starcoder


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/2Du-zmcchSNmE6YXtq8o4.png)

          The left side of the figure is the weight based on starcoderbase, and the
          right side is based on starcoder

          I found that the generated results are very sensitive to the parameters.

          Is it convenient to give the parameters of the human eval results in the
          paper? pass@1'
        updatedAt: '2023-05-11T10:18:57.886Z'
      numEdits: 0
      reactions: []
    id: 645cc111f36ed281fab9dceb
    type: comment
  author: rookielyb
  content: 'thank you for your reply!

    Here are the latest parameters

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/J2-ObFdJfht7UlSv92y3I.png)

    The effect of the same parameter starcoderbase is better than that of starcoder


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/64228bd266d8fdee07b402bf/2Du-zmcchSNmE6YXtq8o4.png)

    The left side of the figure is the weight based on starcoderbase, and the right
    side is based on starcoder

    I found that the generated results are very sensitive to the parameters.

    Is it convenient to give the parameters of the human eval results in the paper?
    pass@1'
  created_at: 2023-05-11 09:18:57+00:00
  edited: false
  hidden: false
  id: 645cc111f36ed281fab9dceb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
      fullname: Qian Liu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: SivilTaram
      type: user
    createdAt: '2023-05-11T12:19:30.000Z'
    data:
      edited: false
      editors:
      - SivilTaram
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
          fullname: Qian Liu
          isHf: false
          isPro: false
          name: SivilTaram
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;rookielyb&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/rookielyb\">@<span class=\"\
          underline\">rookielyb</span></a></span>\n\n\t</span></span> sure, you can\
          \ already find them in the paper:</p>\n<blockquote>\n<p>Like Chen et al.\
          \ (2021), we use sampling temperature 0.2 for pass@1, and temperature 0.8\
          \ for k &gt; 1. We generate n = 200 samples for all experiments with open-access\
          \ models.</p>\n</blockquote>\n"
        raw: '@rookielyb sure, you can already find them in the paper:

          > Like Chen et al. (2021), we use sampling temperature 0.2 for pass@1, and
          temperature 0.8 for k > 1. We generate n = 200 samples for all experiments
          with open-access models.'
        updatedAt: '2023-05-11T12:19:30.871Z'
      numEdits: 0
      reactions: []
    id: 645cdd52afa77201e2f983d4
    type: comment
  author: SivilTaram
  content: '@rookielyb sure, you can already find them in the paper:

    > Like Chen et al. (2021), we use sampling temperature 0.2 for pass@1, and temperature
    0.8 for k > 1. We generate n = 200 samples for all experiments with open-access
    models.'
  created_at: 2023-05-11 11:19:30+00:00
  edited: false
  hidden: false
  id: 645cdd52afa77201e2f983d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-05-12T12:52:39.000Z'
    data:
      edited: true
      editors:
      - loubnabnl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: "<p>Hi, as answered in this <a rel=\"nofollow\" href=\"https://github.com/bigcode-project/starcoder/issues/23#issuecomment-1544059826\"\
          >issue</a> the playground doesn't do anything special  it calls the inference\
          \ endpoint to generate code which is equivalent to doing <code>model.generate</code>\
          \ if you use the same parameters (check the Playground's <a rel=\"nofollow\"\
          \ href=\"(https://huggingface.co/spaces/bigcode/bigcode-playground/blob/2009abb380464f89aba1603069e720f031735cce/app.py#L112)\"\
          >public code</a>. </p>\n<p>The humaneval score is 33%-40% so it's normal\
          \ that the model gets some solutions wrong, if you want to reproduce the\
          \ humaneval score you can run the <a rel=\"nofollow\" href=\"https://github.com/bigcode-project/bigcode-evaluation-harness\"\
          >evaluation-harness</a> on the full benchmark instead of comparing a few\
          \ problems, as specified in the <a rel=\"nofollow\" href=\"https://github.com/bigcode-project/starcoder/issues/23#issuecomment-1545681879\"\
          >issue</a> both the paper settings provided by <span data-props=\"{&quot;user&quot;:&quot;SivilTaram&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/SivilTaram\"\
          >@<span class=\"underline\">SivilTaram</span></a></span>\n\n\t</span></span>\
          \ and greedy decoding give a pass@1 of 33%-34%. (btw it helps to strip the\
          \ prompt before generation if you're not doing it)</p>\n"
        raw: "Hi, as answered in this [issue](https://github.com/bigcode-project/starcoder/issues/23#issuecomment-1544059826)\
          \ the playground doesn't do anything special  it calls the inference endpoint\
          \ to generate code which is equivalent to doing `model.generate` if you\
          \ use the same parameters (check the Playground's [public code]((https://huggingface.co/spaces/bigcode/bigcode-playground/blob/2009abb380464f89aba1603069e720f031735cce/app.py#L112)\
          \ ). \n\nThe humaneval score is 33%-40% so it's normal that the model gets\
          \ some solutions wrong, if you want to reproduce the humaneval score you\
          \ can run the [evaluation-harness](https://github.com/bigcode-project/bigcode-evaluation-harness)\
          \ on the full benchmark instead of comparing a few problems, as specified\
          \ in the [issue](https://github.com/bigcode-project/starcoder/issues/23#issuecomment-1545681879)\
          \ both the paper settings provided by @SivilTaram and greedy decoding give\
          \ a pass@1 of 33%-34%. (btw it helps to strip the prompt before generation\
          \ if you're not doing it)"
        updatedAt: '2023-05-13T10:24:48.849Z'
      numEdits: 1
      reactions: []
    id: 645e369743abb116540d4e98
    type: comment
  author: loubnabnl
  content: "Hi, as answered in this [issue](https://github.com/bigcode-project/starcoder/issues/23#issuecomment-1544059826)\
    \ the playground doesn't do anything special  it calls the inference endpoint\
    \ to generate code which is equivalent to doing `model.generate` if you use the\
    \ same parameters (check the Playground's [public code]((https://huggingface.co/spaces/bigcode/bigcode-playground/blob/2009abb380464f89aba1603069e720f031735cce/app.py#L112)\
    \ ). \n\nThe humaneval score is 33%-40% so it's normal that the model gets some\
    \ solutions wrong, if you want to reproduce the humaneval score you can run the\
    \ [evaluation-harness](https://github.com/bigcode-project/bigcode-evaluation-harness)\
    \ on the full benchmark instead of comparing a few problems, as specified in the\
    \ [issue](https://github.com/bigcode-project/starcoder/issues/23#issuecomment-1545681879)\
    \ both the paper settings provided by @SivilTaram and greedy decoding give a pass@1\
    \ of 33%-34%. (btw it helps to strip the prompt before generation if you're not\
    \ doing it)"
  created_at: 2023-05-12 11:52:39+00:00
  edited: true
  hidden: false
  id: 645e369743abb116540d4e98
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-06-06T22:03:11.000Z'
    data:
      status: closed
    id: 647fad1febbd5b7972a20df0
    type: status-change
  author: loubnabnl
  created_at: 2023-06-06 21:03:11+00:00
  id: 647fad1febbd5b7972a20df0
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 25
repo_id: bigcode/starcoder
repo_type: model
status: closed
target_branch: null
title: How to get the effect like Code Completion Playground above
