!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dshah3
conflicting_files: null
created_at: 2023-08-17 16:20:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ba4c40eb8635451033dce9aa9ccfb702.svg
      fullname: Devin Shah
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dshah3
      type: user
    createdAt: '2023-08-17T17:20:11.000Z'
    data:
      edited: false
      editors:
      - dshah3
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9199389219284058
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ba4c40eb8635451033dce9aa9ccfb702.svg
          fullname: Devin Shah
          isHf: false
          isPro: false
          name: dshah3
          type: user
        html: '<p>Hi, I have a set of p4 (A100) instances available through Sagemaker
          training jobs. I would like to finetune StarCoder on a function summarization
          task. Would I be able to use the HuggingFace "Train" SageMaker interface
          and the Transformers library to run a fine-tuning job? Or would I have to
          use the fine-tuning script in the GitHub library and adapt it to run on
          SageMaker?</p>

          '
        raw: Hi, I have a set of p4 (A100) instances available through Sagemaker training
          jobs. I would like to finetune StarCoder on a function summarization task.
          Would I be able to use the HuggingFace "Train" SageMaker interface and the
          Transformers library to run a fine-tuning job? Or would I have to use the
          fine-tuning script in the GitHub library and adapt it to run on SageMaker?
        updatedAt: '2023-08-17T17:20:11.992Z'
      numEdits: 0
      reactions: []
    id: 64de56cbf08b064990d57395
    type: comment
  author: dshah3
  content: Hi, I have a set of p4 (A100) instances available through Sagemaker training
    jobs. I would like to finetune StarCoder on a function summarization task. Would
    I be able to use the HuggingFace "Train" SageMaker interface and the Transformers
    library to run a fine-tuning job? Or would I have to use the fine-tuning script
    in the GitHub library and adapt it to run on SageMaker?
  created_at: 2023-08-17 16:20:11+00:00
  edited: false
  hidden: false
  id: 64de56cbf08b064990d57395
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8bfcc688e16fbbfe58d4ae7141fbad9c.svg
      fullname: Shuja ahmed
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: shujahm
      type: user
    createdAt: '2023-08-22T18:09:59.000Z'
    data:
      edited: false
      editors:
      - shujahm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7485174536705017
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8bfcc688e16fbbfe58d4ae7141fbad9c.svg
          fullname: Shuja ahmed
          isHf: false
          isPro: false
          name: shujahm
          type: user
        html: "<p>I am trying to achieve something similar? any guidelines <span data-props=\"\
          {&quot;user&quot;:&quot;loubnabnl&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/loubnabnl\">@<span class=\"underline\">loubnabnl</span></a></span>\n\
          \n\t</span></span> ?</p>\n"
        raw: I am trying to achieve something similar? any guidelines @loubnabnl ?
        updatedAt: '2023-08-22T18:09:59.681Z'
      numEdits: 0
      reactions: []
    id: 64e4f9f7e39849fe470d8140
    type: comment
  author: shujahm
  content: I am trying to achieve something similar? any guidelines @loubnabnl ?
  created_at: 2023-08-22 17:09:59+00:00
  edited: false
  hidden: false
  id: 64e4f9f7e39849fe470d8140
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 82
repo_id: bigcode/starcoder
repo_type: model
status: open
target_branch: null
title: FineTuning on SageMaker
