!!python/object:huggingface_hub.community.DiscussionWithDetails
author: avirajsingh
conflicting_files: null
created_at: 2023-09-26 18:03:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9727d1933db36496ed126a273364e108.svg
      fullname: Aviraj Singh
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: avirajsingh
      type: user
    createdAt: '2023-09-26T19:03:45.000Z'
    data:
      edited: false
      editors:
      - avirajsingh
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.610268235206604
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9727d1933db36496ed126a273364e108.svg
          fullname: Aviraj Singh
          isHf: false
          isPro: false
          name: avirajsingh
          type: user
        html: '<p>I deployed the star coder model using the huggingface text generation
          inference container (replaced the token)</p>

          <p>docker run -p 8080:80 -v $PWD/data:/data -e HUGGING_FACE_HUB_TOKEN= -d  ghcr.io/huggingface/text-generation-inference:latest
          --model-id bigcode/starcoder --max-total-tokens 8192</p>

          <p>After the docker container starts, the api end point does not work</p>

          <p>curl 127.0.0.1:8080/generate \ -X POST \ -d ''{"inputs":"What is Deep
          Learning?","parameters":{"max_new_tokens":20}}'' \ -H ''Content-Type: application/json''</p>

          <p>The response is ''curl: (52) Empty reply from server''</p>

          <p>I think the api server is not started in the container. Is there anything
          else we have to do to get the api server working in the container? how do
          i debug this issue?</p>

          <p>Reference: <a rel="nofollow" href="https://github.com/bigcode-project/starcoder#installation">https://github.com/bigcode-project/starcoder#installation</a></p>

          '
        raw: "I deployed the star coder model using the huggingface text generation\
          \ inference container (replaced the token)\r\n\r\ndocker run -p 8080:80\
          \ -v $PWD/data:/data -e HUGGING_FACE_HUB_TOKEN=<YOUR BIGCODE ENABLED TOKEN>\
          \ -d  ghcr.io/huggingface/text-generation-inference:latest --model-id bigcode/starcoder\
          \ --max-total-tokens 8192\r\n\r\nAfter the docker container starts, the\
          \ api end point does not work\r\n\r\ncurl 127.0.0.1:8080/generate \\ -X\
          \ POST \\ -d '{\"inputs\":\"What is Deep Learning?\",\"parameters\":{\"\
          max_new_tokens\":20}}' \\ -H 'Content-Type: application/json'\r\n\r\nThe\
          \ response is 'curl: (52) Empty reply from server'\r\n\r\nI think the api\
          \ server is not started in the container. Is there anything else we have\
          \ to do to get the api server working in the container? how do i debug this\
          \ issue?\r\n\r\nReference: https://github.com/bigcode-project/starcoder#installation"
        updatedAt: '2023-09-26T19:03:45.808Z'
      numEdits: 0
      reactions: []
    id: 65132b11584d106e627def38
    type: comment
  author: avirajsingh
  content: "I deployed the star coder model using the huggingface text generation\
    \ inference container (replaced the token)\r\n\r\ndocker run -p 8080:80 -v $PWD/data:/data\
    \ -e HUGGING_FACE_HUB_TOKEN=<YOUR BIGCODE ENABLED TOKEN> -d  ghcr.io/huggingface/text-generation-inference:latest\
    \ --model-id bigcode/starcoder --max-total-tokens 8192\r\n\r\nAfter the docker\
    \ container starts, the api end point does not work\r\n\r\ncurl 127.0.0.1:8080/generate\
    \ \\ -X POST \\ -d '{\"inputs\":\"What is Deep Learning?\",\"parameters\":{\"\
    max_new_tokens\":20}}' \\ -H 'Content-Type: application/json'\r\n\r\nThe response\
    \ is 'curl: (52) Empty reply from server'\r\n\r\nI think the api server is not\
    \ started in the container. Is there anything else we have to do to get the api\
    \ server working in the container? how do i debug this issue?\r\n\r\nReference:\
    \ https://github.com/bigcode-project/starcoder#installation"
  created_at: 2023-09-26 18:03:45+00:00
  edited: false
  hidden: false
  id: 65132b11584d106e627def38
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 91
repo_id: bigcode/starcoder
repo_type: model
status: open
target_branch: null
title: text generation inference not working for starcoder model
