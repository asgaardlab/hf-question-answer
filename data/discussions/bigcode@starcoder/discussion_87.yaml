!!python/object:huggingface_hub.community.DiscussionWithDetails
author: satsat
conflicting_files: null
created_at: 2023-08-24 10:27:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/46c119f8b76ee816b82f552d0e01b26a.svg
      fullname: SNair
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: satsat
      type: user
    createdAt: '2023-08-24T11:27:31.000Z'
    data:
      edited: false
      editors:
      - satsat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8572583794593811
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/46c119f8b76ee816b82f552d0e01b26a.svg
          fullname: SNair
          isHf: false
          isPro: false
          name: satsat
          type: user
        html: '<p>Hi,</p>

          <p>Scenario: I have got 5 files , which has code in it. Now I am trying
          to evaluate the files and get some recommendations via starcoder model.</p>

          <p>Challenge: I am able to iterate thru all files and get recommendations
          independently. But when running in a single flow in a loop, after the first
          file is encoded and decoded, for the second file, the input_ids of the previous
          file remains. How to remove the input_ids tokens of the previous file.</p>

          <p>for each file<br>input_ids: torch.Tensor = self.tokenizer.encode(query,
          max_length=7000, return_tensors=''pt'', truncation=True).to(self.device)<br>print(len(input_ids[0]))</p>

          <p>For example:<br>1st file: Len of input IDs is , 1111<br>2nd file[2nd
          iteration]: Len of input IDs is, 3018 [but it should 1907]</p>

          <p>Please help with a solution for this. Thanks.</p>

          '
        raw: "Hi,\r\n\r\nScenario: I have got 5 files , which has code in it. Now\
          \ I am trying to evaluate the files and get some recommendations via starcoder\
          \ model.\r\n\r\nChallenge: I am able to iterate thru all files and get recommendations\
          \ independently. But when running in a single flow in a loop, after the\
          \ first file is encoded and decoded, for the second file, the input_ids\
          \ of the previous file remains. How to remove the input_ids tokens of the\
          \ previous file.\r\n\r\nfor each file\r\ninput_ids: torch.Tensor = self.tokenizer.encode(query,\
          \ max_length=7000, return_tensors='pt', truncation=True).to(self.device)\r\
          \nprint(len(input_ids[0]))\r\n\r\nFor example:\r\n1st file: Len of input\
          \ IDs is , 1111\r\n2nd file[2nd iteration]: Len of input IDs is, 3018 [but\
          \ it should 1907]\r\n\r\nPlease help with a solution for this. Thanks."
        updatedAt: '2023-08-24T11:27:31.757Z'
      numEdits: 0
      reactions: []
    id: 64e73ea3c0cc3e95d1dd7808
    type: comment
  author: satsat
  content: "Hi,\r\n\r\nScenario: I have got 5 files , which has code in it. Now I\
    \ am trying to evaluate the files and get some recommendations via starcoder model.\r\
    \n\r\nChallenge: I am able to iterate thru all files and get recommendations independently.\
    \ But when running in a single flow in a loop, after the first file is encoded\
    \ and decoded, for the second file, the input_ids of the previous file remains.\
    \ How to remove the input_ids tokens of the previous file.\r\n\r\nfor each file\r\
    \ninput_ids: torch.Tensor = self.tokenizer.encode(query, max_length=7000, return_tensors='pt',\
    \ truncation=True).to(self.device)\r\nprint(len(input_ids[0]))\r\n\r\nFor example:\r\
    \n1st file: Len of input IDs is , 1111\r\n2nd file[2nd iteration]: Len of input\
    \ IDs is, 3018 [but it should 1907]\r\n\r\nPlease help with a solution for this.\
    \ Thanks."
  created_at: 2023-08-24 10:27:31+00:00
  edited: false
  hidden: false
  id: 64e73ea3c0cc3e95d1dd7808
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 87
repo_id: bigcode/starcoder
repo_type: model
status: open
target_branch: null
title: Remove input id tokens
