!!python/object:huggingface_hub.community.DiscussionWithDetails
author: rameshn
conflicting_files: null
created_at: 2023-05-05 05:11:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0df67dddf51d29897245d515b24ba98b.svg
      fullname: Ramesh Narayanaswamy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: rameshn
      type: user
    createdAt: '2023-05-05T06:11:27.000Z'
    data:
      edited: false
      editors:
      - rameshn
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0df67dddf51d29897245d515b24ba98b.svg
          fullname: Ramesh Narayanaswamy
          isHf: false
          isPro: true
          name: rameshn
          type: user
        html: '<p>Hi,<br>I tried running the following, and get an error. Is the model
          path correct ?<br>Thanks.</p>

          <blockquote>

          <p>--<br>from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline<br>model_ckpt
          = "bigcode/starcoder"<br>#model_ckpt = "<a href="https://huggingface.co/bigcode/starcoder&quot;">https://huggingface.co/bigcode/starcoder"</a></p>

          </blockquote>

          <p>model = AutoModelForCausalLM.from_pretrained(model_ckpt)<br>tokenizer
          = AutoTokenizer.from_pretrained(model_ckpt)</p>

          <p>pipe = pipeline("text-generation", model=model, tokenizer=tokenizer,
          device="cuda:2")<br>print( pipe("def hello():") )</p>

          <blockquote>

          <p>--<br>...<br>OSError: bigcode/starcoder is not a local folder and is
          not a valid model identifier listed on ''<a href="https://huggingface.co/models''">https://huggingface.co/models''</a></p>

          </blockquote>

          '
        raw: "Hi,\r\nI tried running the following, and get an error. Is the model\
          \ path correct ?\r\nThanks.\r\n>--\r\nfrom transformers import AutoModelForCausalLM,\
          \ AutoTokenizer, pipeline\r\nmodel_ckpt = \"bigcode/starcoder\"\r\n#model_ckpt\
          \ = \"https://huggingface.co/bigcode/starcoder\"\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(model_ckpt)\r\
          \ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\r\n\r\npipe = pipeline(\"\
          text-generation\", model=model, tokenizer=tokenizer, device=\"cuda:2\")\r\
          \nprint( pipe(\"def hello():\") )\r\n>--\r\n...\r\nOSError: bigcode/starcoder\
          \ is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\r\
          \n"
        updatedAt: '2023-05-05T06:11:27.610Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - ViPo
        - davidgang
        - usholanb
    id: 64549e0f02912fad3f1f4b8f
    type: comment
  author: rameshn
  content: "Hi,\r\nI tried running the following, and get an error. Is the model path\
    \ correct ?\r\nThanks.\r\n>--\r\nfrom transformers import AutoModelForCausalLM,\
    \ AutoTokenizer, pipeline\r\nmodel_ckpt = \"bigcode/starcoder\"\r\n#model_ckpt\
    \ = \"https://huggingface.co/bigcode/starcoder\"\r\n\r\nmodel = AutoModelForCausalLM.from_pretrained(model_ckpt)\r\
    \ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\r\n\r\npipe = pipeline(\"\
    text-generation\", model=model, tokenizer=tokenizer, device=\"cuda:2\")\r\nprint(\
    \ pipe(\"def hello():\") )\r\n>--\r\n...\r\nOSError: bigcode/starcoder is not\
    \ a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\r\
    \n"
  created_at: 2023-05-05 05:11:27+00:00
  edited: false
  hidden: false
  id: 64549e0f02912fad3f1f4b8f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ab3461b3335122516077fdb98e0a7d14.svg
      fullname: Daniil
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: br3w0r
      type: user
    createdAt: '2023-05-05T11:15:25.000Z'
    data:
      edited: false
      editors:
      - br3w0r
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ab3461b3335122516077fdb98e0a7d14.svg
          fullname: Daniil
          isHf: false
          isPro: false
          name: br3w0r
          type: user
        html: '<p>You have to login using huggingface_hub. Look at the Quickstart
          guide</p>

          '
        raw: You have to login using huggingface_hub. Look at the Quickstart guide
        updatedAt: '2023-05-05T11:15:25.339Z'
      numEdits: 0
      reactions: []
    id: 6454e54df61f10d69dc3d134
    type: comment
  author: br3w0r
  content: You have to login using huggingface_hub. Look at the Quickstart guide
  created_at: 2023-05-05 10:15:25+00:00
  edited: false
  hidden: false
  id: 6454e54df61f10d69dc3d134
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b89f4ad9fd07ccd0db02d4e3c2c555fc.svg
      fullname: Zdar
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArmelR
      type: user
    createdAt: '2023-05-05T11:17:53.000Z'
    data:
      edited: false
      editors:
      - ArmelR
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b89f4ad9fd07ccd0db02d4e3c2c555fc.svg
          fullname: Zdar
          isHf: false
          isPro: false
          name: ArmelR
          type: user
        html: '<p>Hi. You should go to hf.co/bigcode/starcoder and fill accept the
          agreement if you want to be able to use the model. You would also want to
          connect using huggingface-cli.</p>

          '
        raw: Hi. You should go to hf.co/bigcode/starcoder and fill accept the agreement
          if you want to be able to use the model. You would also want to connect
          using huggingface-cli.
        updatedAt: '2023-05-05T11:17:53.880Z'
      numEdits: 0
      reactions: []
    id: 6454e5e1d55525a4fee23b49
    type: comment
  author: ArmelR
  content: Hi. You should go to hf.co/bigcode/starcoder and fill accept the agreement
    if you want to be able to use the model. You would also want to connect using
    huggingface-cli.
  created_at: 2023-05-05 10:17:53+00:00
  edited: false
  hidden: false
  id: 6454e5e1d55525a4fee23b49
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dfe70288972eb3c6af2f1d27de9b1773.svg
      fullname: Fran Tena
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarodnet
      type: user
    createdAt: '2023-05-05T15:05:16.000Z'
    data:
      edited: false
      editors:
      - tarodnet
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dfe70288972eb3c6af2f1d27de9b1773.svg
          fullname: Fran Tena
          isHf: false
          isPro: false
          name: tarodnet
          type: user
        html: '<p>Maybe you also need some requirements:</p>

          <p><a rel="nofollow" href="https://github.com/bigcode-project/starcoder/blob/main/requirements.txt">https://github.com/bigcode-project/starcoder</a></p>

          '
        raw: 'Maybe you also need some requirements:


          [https://github.com/bigcode-project/starcoder](https://github.com/bigcode-project/starcoder/blob/main/requirements.txt)'
        updatedAt: '2023-05-05T15:05:16.342Z'
      numEdits: 0
      reactions: []
    id: 64551b2cfe2f48cb4b678923
    type: comment
  author: tarodnet
  content: 'Maybe you also need some requirements:


    [https://github.com/bigcode-project/starcoder](https://github.com/bigcode-project/starcoder/blob/main/requirements.txt)'
  created_at: 2023-05-05 14:05:16+00:00
  edited: false
  hidden: false
  id: 64551b2cfe2f48cb4b678923
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d4adc5a46c5f740a82576b12370286ef.svg
      fullname: GC
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cactusthecoder8
      type: user
    createdAt: '2023-05-06T05:52:02.000Z'
    data:
      edited: false
      editors:
      - cactusthecoder8
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d4adc5a46c5f740a82576b12370286ef.svg
          fullname: GC
          isHf: false
          isPro: false
          name: cactusthecoder8
          type: user
        html: '<p>Set your personal access token to the use_auth_token parameter when
          you call from_pretrained.</p>

          '
        raw: Set your personal access token to the use_auth_token parameter when you
          call from_pretrained.
        updatedAt: '2023-05-06T05:52:02.241Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - ViPo
        - miraclezst
        - vitali87
        - usholanb
    id: 6455eb02e39c6464656411e0
    type: comment
  author: cactusthecoder8
  content: Set your personal access token to the use_auth_token parameter when you
    call from_pretrained.
  created_at: 2023-05-06 04:52:02+00:00
  edited: false
  hidden: false
  id: 6455eb02e39c6464656411e0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/33ab4f42ba56631ef5836420a6915c84.svg
      fullname: Vitalii Pomoinytskyi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ViPo
      type: user
    createdAt: '2023-05-06T06:34:49.000Z'
    data:
      edited: false
      editors:
      - ViPo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/33ab4f42ba56631ef5836420a6915c84.svg
          fullname: Vitalii Pomoinytskyi
          isHf: false
          isPro: false
          name: ViPo
          type: user
        html: "<p>I have same issue. Tried to login using huggingface_hub, install\
          \ all requirements,  only <span data-props=\"{&quot;user&quot;:&quot;cactusthecoder8&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/cactusthecoder8\"\
          >@<span class=\"underline\">cactusthecoder8</span></a></span>\n\n\t</span></span>\
          \  recomendation helped, to use use_auth_token parameter to download tokenizer,\
          \ but then running fails on the next line<br><code>model = AutoModelForCausalLM.from_pretrained(checkpoint,\
          \ trust_remote_code=True).to(device)</code><br>With error:</p>\n<p><code>We\
          \ couldn't connect to 'https://huggingface.co' to load this model, couldn't\
          \ find it in the cached files and it looks like bigcode/starcoder is not\
          \ the path to a directory containing a {configuration_file} file. Checkout\
          \ your internet connection or see how to run the library in offline mode\
          \ at 'https://huggingface.co/docs/transformers/installation#offline-mode'.</code></p>\n"
        raw: 'I have same issue. Tried to login using huggingface_hub, install all
          requirements,  only @cactusthecoder8  recomendation helped, to use use_auth_token
          parameter to download tokenizer, but then running fails on the next line

          ``` model = AutoModelForCausalLM.from_pretrained(checkpoint, trust_remote_code=True).to(device)
          ```

          With error:

          ``` We couldn''t connect to ''https://huggingface.co'' to load this model,
          couldn''t find it in the cached files and it looks like bigcode/starcoder
          is not the path to a directory containing a {configuration_file} file.

          Checkout your internet connection or see how to run the library in offline
          mode at ''https://huggingface.co/docs/transformers/installation#offline-mode''.
          ```'
        updatedAt: '2023-05-06T06:34:49.491Z'
      numEdits: 0
      reactions: []
    id: 6455f509d10badc95553fde7
    type: comment
  author: ViPo
  content: 'I have same issue. Tried to login using huggingface_hub, install all requirements,  only
    @cactusthecoder8  recomendation helped, to use use_auth_token parameter to download
    tokenizer, but then running fails on the next line

    ``` model = AutoModelForCausalLM.from_pretrained(checkpoint, trust_remote_code=True).to(device)
    ```

    With error:

    ``` We couldn''t connect to ''https://huggingface.co'' to load this model, couldn''t
    find it in the cached files and it looks like bigcode/starcoder is not the path
    to a directory containing a {configuration_file} file.

    Checkout your internet connection or see how to run the library in offline mode
    at ''https://huggingface.co/docs/transformers/installation#offline-mode''. ```'
  created_at: 2023-05-06 05:34:49+00:00
  edited: false
  hidden: false
  id: 6455f509d10badc95553fde7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-05-06T10:10:12.000Z'
    data:
      edited: false
      editors:
      - loubnabnl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: '<p>Can you try adding <code>use_auth_token</code> to model loading  too
          (btw you don''t need <code>trust_remote_code=True</code>). Overall if you
          accept the agreement on the model page and follow these steps it should
          work (assuming you have enough memory):</p>

          <pre><code>!pip install transformers==4.28.1

          !huggingface-cli login

          </code></pre>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM,
          AutoTokenizer


          tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"bigcode/starcoder"</span>)

          model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">"bigcode/starcoder"</span>)

          </code></pre>

          '
        raw: 'Can you try adding `use_auth_token` to model loading  too (btw you don''t
          need `trust_remote_code=True`). Overall if you accept the agreement on the
          model page and follow these steps it should work (assuming you have enough
          memory):

          ```

          !pip install transformers==4.28.1

          !huggingface-cli login

          ```

          ```python

          from transformers import AutoModelForCausalLM, AutoTokenizer


          tokenizer = AutoTokenizer.from_pretrained("bigcode/starcoder")

          model = AutoModelForCausalLM.from_pretrained("bigcode/starcoder")

          ```'
        updatedAt: '2023-05-06T10:10:12.388Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - dev-ninja
        - forrany
    id: 6456278478c059b099ae6555
    type: comment
  author: loubnabnl
  content: 'Can you try adding `use_auth_token` to model loading  too (btw you don''t
    need `trust_remote_code=True`). Overall if you accept the agreement on the model
    page and follow these steps it should work (assuming you have enough memory):

    ```

    !pip install transformers==4.28.1

    !huggingface-cli login

    ```

    ```python

    from transformers import AutoModelForCausalLM, AutoTokenizer


    tokenizer = AutoTokenizer.from_pretrained("bigcode/starcoder")

    model = AutoModelForCausalLM.from_pretrained("bigcode/starcoder")

    ```'
  created_at: 2023-05-06 09:10:12+00:00
  edited: false
  hidden: false
  id: 6456278478c059b099ae6555
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dfe70288972eb3c6af2f1d27de9b1773.svg
      fullname: Fran Tena
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarodnet
      type: user
    createdAt: '2023-05-06T14:33:14.000Z'
    data:
      edited: false
      editors:
      - tarodnet
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dfe70288972eb3c6af2f1d27de9b1773.svg
          fullname: Fran Tena
          isHf: false
          isPro: false
          name: tarodnet
          type: user
        html: '<blockquote>

          <p>Can you try adding <code>use_auth_token</code> to model loading  too
          (btw you don''t need <code>trust_remote_code=True</code>). Overall if you
          accept the agreement on the model page and follow these steps it should
          work (assuming you have enough memory):</p>

          <pre><code>!pip install transformers==4.28.1

          !huggingface-cli login

          </code></pre>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM,
          AutoTokenizer


          tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"bigcode/starcoder"</span>)

          model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">"bigcode/starcoder"</span>)

          </code></pre>

          </blockquote>

          <p>What is the recommended memory?</p>

          '
        raw: "> Can you try adding `use_auth_token` to model loading  too (btw you\
          \ don't need `trust_remote_code=True`). Overall if you accept the agreement\
          \ on the model page and follow these steps it should work (assuming you\
          \ have enough memory):\n> ```\n> !pip install transformers==4.28.1\n> !huggingface-cli\
          \ login\n> ```\n> ```python\n> from transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\n> \n> tokenizer = AutoTokenizer.from_pretrained(\"bigcode/starcoder\"\
          )\n> model = AutoModelForCausalLM.from_pretrained(\"bigcode/starcoder\"\
          )\n> ```\n\nWhat is the recommended memory?"
        updatedAt: '2023-05-06T14:33:14.855Z'
      numEdits: 0
      reactions: []
    id: 6456652ad10badc9555bd2a1
    type: comment
  author: tarodnet
  content: "> Can you try adding `use_auth_token` to model loading  too (btw you don't\
    \ need `trust_remote_code=True`). Overall if you accept the agreement on the model\
    \ page and follow these steps it should work (assuming you have enough memory):\n\
    > ```\n> !pip install transformers==4.28.1\n> !huggingface-cli login\n> ```\n\
    > ```python\n> from transformers import AutoModelForCausalLM, AutoTokenizer\n\
    > \n> tokenizer = AutoTokenizer.from_pretrained(\"bigcode/starcoder\")\n> model\
    \ = AutoModelForCausalLM.from_pretrained(\"bigcode/starcoder\")\n> ```\n\nWhat\
    \ is the recommended memory?"
  created_at: 2023-05-06 13:33:14+00:00
  edited: false
  hidden: false
  id: 6456652ad10badc9555bd2a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d4adc5a46c5f740a82576b12370286ef.svg
      fullname: GC
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cactusthecoder8
      type: user
    createdAt: '2023-05-06T15:08:15.000Z'
    data:
      edited: true
      editors:
      - cactusthecoder8
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d4adc5a46c5f740a82576b12370286ef.svg
          fullname: GC
          isHf: false
          isPro: false
          name: cactusthecoder8
          type: user
        html: '<blockquote>

          <blockquote>

          <p>What is the recommended memory?</p>

          </blockquote>

          </blockquote>

          <p>RAM: There are 7 checkpoints with approximately 10G per shard.<br>GPU
          memory: definitely &gt; 16 G but 32G is enough</p>

          '
        raw: ">> What is the recommended memory?\n\nRAM: There are 7 checkpoints with\
          \ approximately 10G per shard. \nGPU memory: definitely > 16 G but 32G is\
          \ enough"
        updatedAt: '2023-05-14T04:28:05.380Z'
      numEdits: 1
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - tarodnet
        - noobmldude
    id: 64566d5f78c059b099b3333c
    type: comment
  author: cactusthecoder8
  content: ">> What is the recommended memory?\n\nRAM: There are 7 checkpoints with\
    \ approximately 10G per shard. \nGPU memory: definitely > 16 G but 32G is enough"
  created_at: 2023-05-06 14:08:15+00:00
  edited: true
  hidden: false
  id: 64566d5f78c059b099b3333c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dfe70288972eb3c6af2f1d27de9b1773.svg
      fullname: Fran Tena
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarodnet
      type: user
    createdAt: '2023-05-06T15:11:19.000Z'
    data:
      edited: true
      editors:
      - tarodnet
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dfe70288972eb3c6af2f1d27de9b1773.svg
          fullname: Fran Tena
          isHf: false
          isPro: false
          name: tarodnet
          type: user
        html: '<blockquote>

          <blockquote>

          <blockquote>

          <p>What is the recommended memory?</p>

          </blockquote>

          </blockquote>

          <p>RAM: There are 7 checkpoints with approximately 10G per shard.<br>GPU
          memory: definitely &gt; 16 G but 24G is enough</p>

          </blockquote>

          <p>Oh :( I suppose that is the reason I''m getting a killed application
          when I try to run the example... thanks mate!</p>

          '
        raw: "> >> What is the recommended memory?\n> \n> RAM: There are 7 checkpoints\
          \ with approximately 10G per shard. \n> GPU memory: definitely > 16 G but\
          \ 24G is enough\n\nOh :( I suppose that is the reason I'm getting a killed\
          \ application when I try to run the example... thanks mate!"
        updatedAt: '2023-05-07T16:25:31.352Z'
      numEdits: 1
      reactions: []
    id: 64566e1778c059b099b33fe4
    type: comment
  author: tarodnet
  content: "> >> What is the recommended memory?\n> \n> RAM: There are 7 checkpoints\
    \ with approximately 10G per shard. \n> GPU memory: definitely > 16 G but 24G\
    \ is enough\n\nOh :( I suppose that is the reason I'm getting a killed application\
    \ when I try to run the example... thanks mate!"
  created_at: 2023-05-06 14:11:19+00:00
  edited: true
  hidden: false
  id: 64566e1778c059b099b33fe4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0df67dddf51d29897245d515b24ba98b.svg
      fullname: Ramesh Narayanaswamy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: rameshn
      type: user
    createdAt: '2023-05-10T04:41:24.000Z'
    data:
      edited: false
      editors:
      - rameshn
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0df67dddf51d29897245d515b24ba98b.svg
          fullname: Ramesh Narayanaswamy
          isHf: false
          isPro: true
          name: rameshn
          type: user
        html: '<p>Summarizing the suggestions that fixed the problem for me: (these
          are in addition to pip install of requirements.txt)<br>a) accept the license
          agreement on <a href="https://huggingface.co/bigcode/starcoder">https://huggingface.co/bigcode/starcoder</a><br>b)
          get access token for starcoder from <a href="https://huggingface.co/settings/tokens">https://huggingface.co/settings/tokens</a><br>c)
          run ''huggingface-cli login'' --&gt; use token provided above</p>

          '
        raw: 'Summarizing the suggestions that fixed the problem for me: (these are
          in addition to pip install of requirements.txt)

          a) accept the license agreement on https://huggingface.co/bigcode/starcoder

          b) get access token for starcoder from https://huggingface.co/settings/tokens

          c) run ''huggingface-cli login'' --> use token provided above'
        updatedAt: '2023-05-10T04:41:24.754Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - liangdong12
        - sagivo
        - cactusthecoder8
        - sam1120
        - qftie
        - jckuri-nola-ai
    id: 645b2074bca1aab2a281d2ec
    type: comment
  author: rameshn
  content: 'Summarizing the suggestions that fixed the problem for me: (these are
    in addition to pip install of requirements.txt)

    a) accept the license agreement on https://huggingface.co/bigcode/starcoder

    b) get access token for starcoder from https://huggingface.co/settings/tokens

    c) run ''huggingface-cli login'' --> use token provided above'
  created_at: 2023-05-10 03:41:24+00:00
  edited: false
  hidden: false
  id: 645b2074bca1aab2a281d2ec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/897c4e3ed9b2cdd9eb0aefe442b98772.svg
      fullname: leo liu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: breakenknife
      type: user
    createdAt: '2023-05-30T09:48:24.000Z'
    data:
      edited: true
      editors:
      - breakenknife
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/897c4e3ed9b2cdd9eb0aefe442b98772.svg
          fullname: leo liu
          isHf: false
          isPro: false
          name: breakenknife
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;rameshn&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/rameshn\">@<span class=\"\
          underline\">rameshn</span></a></span>\n\n\t</span></span> how to accept\
          \ the license agreement ?   </p>\n<blockquote>\n<p>Summarizing the suggestions\
          \ that fixed the problem for me: (these are in addition to pip install of\
          \ requirements.txt)<br>a) accept the license agreement on <a href=\"https://huggingface.co/bigcode/starcoder\"\
          >https://huggingface.co/bigcode/starcoder</a><br>b) get access token for\
          \ starcoder from <a href=\"https://huggingface.co/settings/tokens\">https://huggingface.co/settings/tokens</a><br>c)\
          \ run 'huggingface-cli login' --&gt; use token provided above</p>\n</blockquote>\n"
        raw: "@rameshn how to accept the license agreement ?   \n> Summarizing the\
          \ suggestions that fixed the problem for me: (these are in addition to pip\
          \ install of requirements.txt)\n> a) accept the license agreement on https://huggingface.co/bigcode/starcoder\n\
          > b) get access token for starcoder from https://huggingface.co/settings/tokens\n\
          > c) run 'huggingface-cli login' --> use token provided above"
        updatedAt: '2023-05-30T09:50:16.744Z'
      numEdits: 2
      reactions: []
    id: 6475c668ab17a37d0b1a168d
    type: comment
  author: breakenknife
  content: "@rameshn how to accept the license agreement ?   \n> Summarizing the suggestions\
    \ that fixed the problem for me: (these are in addition to pip install of requirements.txt)\n\
    > a) accept the license agreement on https://huggingface.co/bigcode/starcoder\n\
    > b) get access token for starcoder from https://huggingface.co/settings/tokens\n\
    > c) run 'huggingface-cli login' --> use token provided above"
  created_at: 2023-05-30 08:48:24+00:00
  edited: true
  hidden: false
  id: 6475c668ab17a37d0b1a168d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677059240779-noauth.jpeg?w=200&h=200&f=face
      fullname: Zhao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kingzzm
      type: user
    createdAt: '2023-06-25T07:04:05.000Z'
    data:
      edited: false
      editors:
      - kingzzm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5422961115837097
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1677059240779-noauth.jpeg?w=200&h=200&f=face
          fullname: Zhao
          isHf: false
          isPro: false
          name: kingzzm
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;rameshn&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/rameshn\"\
          >@<span class=\"underline\">rameshn</span></a></span>\n\n\t</span></span>\
          \ how to accept the license agreement ?   </p>\n</blockquote>\n<p><a rel=\"\
          nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/63f5e4cb4b831cc179b97aa0/ezgKNnE37PFwSHUl7ZkgW.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/63f5e4cb4b831cc179b97aa0/ezgKNnE37PFwSHUl7ZkgW.png\"\
          ></a></p>\n"
        raw: "> @rameshn how to accept the license agreement ?   \n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63f5e4cb4b831cc179b97aa0/ezgKNnE37PFwSHUl7ZkgW.png)\n"
        updatedAt: '2023-06-25T07:04:05.928Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - hoot123
    id: 6497e6e58f9988c8337eb535
    type: comment
  author: kingzzm
  content: "> @rameshn how to accept the license agreement ?   \n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/63f5e4cb4b831cc179b97aa0/ezgKNnE37PFwSHUl7ZkgW.png)\n"
  created_at: 2023-06-25 06:04:05+00:00
  edited: false
  hidden: false
  id: 6497e6e58f9988c8337eb535
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ac94cb31b4b7128e8a98790404827c62.svg
      fullname: Arianna Taormina
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: arita89
      type: user
    createdAt: '2023-07-04T15:43:46.000Z'
    data:
      edited: false
      editors:
      - arita89
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9449582099914551
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ac94cb31b4b7128e8a98790404827c62.svg
          fullname: Arianna Taormina
          isHf: false
          isPro: false
          name: arita89
          type: user
        html: '<blockquote>

          <blockquote>

          <blockquote>

          <p>What is the recommended memory?</p>

          </blockquote>

          </blockquote>

          <p>RAM: There are 7 checkpoints with approximately 10G per shard.<br>GPU
          memory: definitely &gt; 16 G but 32G is enough</p>

          </blockquote>

          <p>wait,me stupid, do i need 10G or 70G of RAM? </p>

          '
        raw: "> >> What is the recommended memory?\n> \n> RAM: There are 7 checkpoints\
          \ with approximately 10G per shard. \n> GPU memory: definitely > 16 G but\
          \ 32G is enough\n\nwait,me stupid, do i need 10G or 70G of RAM? "
        updatedAt: '2023-07-04T15:43:46.104Z'
      numEdits: 0
      reactions: []
    id: 64a43e329c659c2379ee417f
    type: comment
  author: arita89
  content: "> >> What is the recommended memory?\n> \n> RAM: There are 7 checkpoints\
    \ with approximately 10G per shard. \n> GPU memory: definitely > 16 G but 32G\
    \ is enough\n\nwait,me stupid, do i need 10G or 70G of RAM? "
  created_at: 2023-07-04 14:43:46+00:00
  edited: false
  hidden: false
  id: 64a43e329c659c2379ee417f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/69316ed42612e76335b677d2b8b5b527.svg
      fullname: Thanh Ng
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thanhnew2001
      type: user
    createdAt: '2023-07-24T15:10:16.000Z'
    data:
      edited: false
      editors:
      - thanhnew2001
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9152033925056458
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/69316ed42612e76335b677d2b8b5b527.svg
          fullname: Thanh Ng
          isHf: false
          isPro: false
          name: thanhnew2001
          type: user
        html: '<blockquote>

          <p>70GB for storage</p>

          </blockquote>

          '
        raw: '>70GB for storage'
        updatedAt: '2023-07-24T15:10:16.702Z'
      numEdits: 0
      reactions: []
    id: 64be9458b7375f6b848b3940
    type: comment
  author: thanhnew2001
  content: '>70GB for storage'
  created_at: 2023-07-24 14:10:16+00:00
  edited: false
  hidden: false
  id: 64be9458b7375f6b848b3940
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: bigcode/starcoder
repo_type: model
status: open
target_branch: null
title: Not able to run hello world example, bigcode/starcoder is not a valid model
  identifier
