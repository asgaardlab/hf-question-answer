!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jiang719
conflicting_files: null
created_at: 2023-07-04 19:17:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/629e4ca2f2bda18349b6d330/piLhXi1uUW6IPXZ5bCLzt.jpeg?w=200&h=200&f=face
      fullname: Nan Jiang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jiang719
      type: user
    createdAt: '2023-07-04T20:17:11.000Z'
    data:
      edited: true
      editors:
      - jiang719
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9425197243690491
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/629e4ca2f2bda18349b6d330/piLhXi1uUW6IPXZ5bCLzt.jpeg?w=200&h=200&f=face
          fullname: Nan Jiang
          isHf: false
          isPro: false
          name: jiang719
          type: user
        html: '<p>Hi, </p>

          <p>StarCoder supports input up to 8192 tokens, so I assume you also train
          the model with such long input. But when I was trying to fine-tune it, I
          found I cannot even use input with 2048 tokens.</p>

          <p>Even with 4 A100 80G, and half precision enabled, deepspeed''s ZERO3
          enabled, param/optimizer offload opened, and gradient checkpointing enabled.
          I still got OOM with even batch_size_per_gpu set to 1. And I monitor the
          GPU usage, it seems the forward of 2048 tokens already take all the GPU
          memory. That means, the OOM happened even before the backward() is called</p>

          <p>I wonder how could you train it with even longer inputs? Or any suggestions
          on training/fine-tuning with long inputs? Thank you!</p>

          '
        raw: "Hi, \n\nStarCoder supports input up to 8192 tokens, so I assume you\
          \ also train the model with such long input. But when I was trying to fine-tune\
          \ it, I found I cannot even use input with 2048 tokens.\n\nEven with 4 A100\
          \ 80G, and half precision enabled, deepspeed's ZERO3 enabled, param/optimizer\
          \ offload opened, and gradient checkpointing enabled. I still got OOM with\
          \ even batch_size_per_gpu set to 1. And I monitor the GPU usage, it seems\
          \ the forward of 2048 tokens already take all the GPU memory. That means,\
          \ the OOM happened even before the backward() is called\n\nI wonder how\
          \ could you train it with even longer inputs? Or any suggestions on training/fine-tuning\
          \ with long inputs? Thank you!"
        updatedAt: '2023-07-04T20:18:11.709Z'
      numEdits: 1
      reactions: []
    id: 64a47e47f7c0b86a62ea9004
    type: comment
  author: jiang719
  content: "Hi, \n\nStarCoder supports input up to 8192 tokens, so I assume you also\
    \ train the model with such long input. But when I was trying to fine-tune it,\
    \ I found I cannot even use input with 2048 tokens.\n\nEven with 4 A100 80G, and\
    \ half precision enabled, deepspeed's ZERO3 enabled, param/optimizer offload opened,\
    \ and gradient checkpointing enabled. I still got OOM with even batch_size_per_gpu\
    \ set to 1. And I monitor the GPU usage, it seems the forward of 2048 tokens already\
    \ take all the GPU memory. That means, the OOM happened even before the backward()\
    \ is called\n\nI wonder how could you train it with even longer inputs? Or any\
    \ suggestions on training/fine-tuning with long inputs? Thank you!"
  created_at: 2023-07-04 19:17:11+00:00
  edited: true
  hidden: false
  id: 64a47e47f7c0b86a62ea9004
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-07-04T23:55:12.000Z'
    data:
      edited: true
      editors:
      - loubnabnl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8389519453048706
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: '<p>We used tensor parallelism and pipeline parallelism when training
          with <a rel="nofollow" href="https://github.com/bigcode-project/Megatron-LM/tree/multi-query-attention">Megatron-LM</a>
          to split the model on multiple GPUs (you can find details <a rel="nofollow"
          href="https://github.com/bigcode-project/Megatron-LM/blob/22238910d9c66cfb97564228f980da99ac7d5ec9/examples/pretrain_bigcode_model.slurm#L41">here</a>).
          You can also use PEFT fine-tuning which requires much less memory and will
          allow you to fit a large context (example <a rel="nofollow" href="https://github.com/bigcode-project/starcoder/tree/main">here</a>)</p>

          '
        raw: We used tensor parallelism and pipeline parallelism when training with
          [Megatron-LM](https://github.com/bigcode-project/Megatron-LM/tree/multi-query-attention)
          to split the model on multiple GPUs (you can find details [here](https://github.com/bigcode-project/Megatron-LM/blob/22238910d9c66cfb97564228f980da99ac7d5ec9/examples/pretrain_bigcode_model.slurm#L41)).
          You can also use PEFT fine-tuning which requires much less memory and will
          allow you to fit a large context (example [here](https://github.com/bigcode-project/starcoder/tree/main))
        updatedAt: '2023-07-05T00:01:16.007Z'
      numEdits: 1
      reactions: []
    id: 64a4b160143b1c7b58ffc516
    type: comment
  author: loubnabnl
  content: We used tensor parallelism and pipeline parallelism when training with
    [Megatron-LM](https://github.com/bigcode-project/Megatron-LM/tree/multi-query-attention)
    to split the model on multiple GPUs (you can find details [here](https://github.com/bigcode-project/Megatron-LM/blob/22238910d9c66cfb97564228f980da99ac7d5ec9/examples/pretrain_bigcode_model.slurm#L41)).
    You can also use PEFT fine-tuning which requires much less memory and will allow
    you to fit a large context (example [here](https://github.com/bigcode-project/starcoder/tree/main))
  created_at: 2023-07-04 22:55:12+00:00
  edited: true
  hidden: false
  id: 64a4b160143b1c7b58ffc516
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/decf2cb9ea2c3008aadafae59c392199.svg
      fullname: Satyanarayana Reddy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Satya4093
      type: user
    createdAt: '2023-07-20T06:03:20.000Z'
    data:
      edited: false
      editors:
      - Satya4093
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8670989274978638
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/decf2cb9ea2c3008aadafae59c392199.svg
          fullname: Satyanarayana Reddy
          isHf: false
          isPro: false
          name: Satya4093
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;loubnabnl&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/loubnabnl\"\
          >@<span class=\"underline\">loubnabnl</span></a></span>\n\n\t</span></span>\
          \ with Tensor parallelism=4 and pipeline parallelism=4, we need 4*4  16GPUs\
          \ right, correct me if i am wrong.<br>Even with peft-lora I am not able\
          \ to finetune on 8K with 6 A100 40GB GPUs, even with qlora also i am not\
          \ able to train starcoder model on 8K.<br>Any Suggestions? Am i missing\
          \ anything?  Please Suggest. Thank you!</p>\n"
        raw: "Hello @loubnabnl with Tensor parallelism=4 and pipeline parallelism=4,\
          \ we need 4*4  16GPUs right, correct me if i am wrong.\nEven with peft-lora\
          \ I am not able to finetune on 8K with 6 A100 40GB GPUs, even with qlora\
          \ also i am not able to train starcoder model on 8K. \nAny Suggestions?\
          \ Am i missing anything?  Please Suggest. Thank you!"
        updatedAt: '2023-07-20T06:03:20.526Z'
      numEdits: 0
      reactions: []
    id: 64b8ce28a62c52b252c48429
    type: comment
  author: Satya4093
  content: "Hello @loubnabnl with Tensor parallelism=4 and pipeline parallelism=4,\
    \ we need 4*4  16GPUs right, correct me if i am wrong.\nEven with peft-lora I\
    \ am not able to finetune on 8K with 6 A100 40GB GPUs, even with qlora also i\
    \ am not able to train starcoder model on 8K. \nAny Suggestions? Am i missing\
    \ anything?  Please Suggest. Thank you!"
  created_at: 2023-07-20 05:03:20+00:00
  edited: false
  hidden: false
  id: 64b8ce28a62c52b252c48429
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 62
repo_id: bigcode/starcoder
repo_type: model
status: open
target_branch: null
title: How to train with long inputs (Training memory requirement)
