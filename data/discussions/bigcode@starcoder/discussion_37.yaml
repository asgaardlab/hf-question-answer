!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mintglobe
conflicting_files: null
created_at: 2023-05-23 10:32:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cf23f8bbd32355a72bb73a8805de644a.svg
      fullname: lisong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mintglobe
      type: user
    createdAt: '2023-05-23T11:32:14.000Z'
    data:
      edited: false
      editors:
      - mintglobe
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cf23f8bbd32355a72bb73a8805de644a.svg
          fullname: lisong
          isHf: false
          isPro: false
          name: mintglobe
          type: user
        html: "<p>hello\uFF0C i want to retrain starcoderbase with c language\uFF0C\
          \ just like retrain starcoderbase with python and get starcoder.<br>How\
          \ many gpu do i need to run the training\uFF1F  now I got a node with 2\
          \ A100\uFF0Cand it report \u2018CUDA out of memory\u2019. If  I get a node\
          \ with 8 A100(that's my limit), can i afford the training? thank you.</p>\n"
        raw: "hello\uFF0C i want to retrain starcoderbase with c language\uFF0C just\
          \ like retrain starcoderbase with python and get starcoder.  \r\nHow many\
          \ gpu do i need to run the training\uFF1F  now I got a node with 2 A100\uFF0C\
          and it report \u2018CUDA out of memory\u2019. If  I get a node with 8 A100(that's\
          \ my limit), can i afford the training? thank you."
        updatedAt: '2023-05-23T11:32:14.866Z'
      numEdits: 0
      reactions: []
    id: 646ca43e93badbc8c2e85287
    type: comment
  author: mintglobe
  content: "hello\uFF0C i want to retrain starcoderbase with c language\uFF0C just\
    \ like retrain starcoderbase with python and get starcoder.  \r\nHow many gpu\
    \ do i need to run the training\uFF1F  now I got a node with 2 A100\uFF0Cand it\
    \ report \u2018CUDA out of memory\u2019. If  I get a node with 8 A100(that's my\
    \ limit), can i afford the training? thank you."
  created_at: 2023-05-23 10:32:14+00:00
  edited: false
  hidden: false
  id: 646ca43e93badbc8c2e85287
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/056370e376f77d75e8092f0c6338956f.svg
      fullname: Nithin I Bhandari
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nib12345
      type: user
    createdAt: '2023-05-25T15:19:56.000Z'
    data:
      edited: true
      editors:
      - nib12345
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/056370e376f77d75e8092f0c6338956f.svg
          fullname: Nithin I Bhandari
          isHf: false
          isPro: false
          name: nib12345
          type: user
        html: '<p>I may be wrong, but</p>

          <p>According to the model documentation, it states that the training process
          for this model would take 512 * A100 units and span a duration of 24 days.<br>Link:
          <a href="https://huggingface.co/bigcode/starcoder#hardware">https://huggingface.co/bigcode/starcoder#hardware</a></p>

          <p>So it means<br>One A100 40 GB per hour cost $1.10 on lambdalabs<br>It
          would cost ($1.1 per hour *24 hour * 24 days *512 A100) = $324403.2<br>or
          $1.1 * $24 * $24 *  $512 = $324403.2</p>

          <p>or</p>

          <p>One A100 80 GB per hour cost $1.50 on lambdalabs<br>It would cost ($1.5
          per hour *24 hour * 24 days *512 A100) = $442368<br>or $1.5 * $24 * $24
          *  $512 = $442368</p>

          <p>Here, they did not say which A100 GPU they have used. It is A100 40 GB
          or A100 80GB</p>

          <p>So i believe that most people cannot spend that much amount of cash to
          train the model.</p>

          '
        raw: 'I may be wrong, but


          According to the model documentation, it states that the training process
          for this model would take 512 * A100 units and span a duration of 24 days.

          Link: https://huggingface.co/bigcode/starcoder#hardware


          So it means

          One A100 40 GB per hour cost $1.10 on lambdalabs

          It would cost ($1.1 per hour *24 hour * 24 days *512 A100) = $324403.2

          or $1.1 * $24 * $24 *  $512 = $324403.2


          or


          One A100 80 GB per hour cost $1.50 on lambdalabs

          It would cost ($1.5 per hour *24 hour * 24 days *512 A100) = $442368

          or $1.5 * $24 * $24 *  $512 = $442368


          Here, they did not say which A100 GPU they have used. It is A100 40 GB or
          A100 80GB


          So i believe that most people cannot spend that much amount of cash to train
          the model.'
        updatedAt: '2023-06-05T19:16:57.495Z'
      numEdits: 4
      reactions: []
    id: 646f7c9cbc42f4b0022f4238
    type: comment
  author: nib12345
  content: 'I may be wrong, but


    According to the model documentation, it states that the training process for
    this model would take 512 * A100 units and span a duration of 24 days.

    Link: https://huggingface.co/bigcode/starcoder#hardware


    So it means

    One A100 40 GB per hour cost $1.10 on lambdalabs

    It would cost ($1.1 per hour *24 hour * 24 days *512 A100) = $324403.2

    or $1.1 * $24 * $24 *  $512 = $324403.2


    or


    One A100 80 GB per hour cost $1.50 on lambdalabs

    It would cost ($1.5 per hour *24 hour * 24 days *512 A100) = $442368

    or $1.5 * $24 * $24 *  $512 = $442368


    Here, they did not say which A100 GPU they have used. It is A100 40 GB or A100
    80GB


    So i believe that most people cannot spend that much amount of cash to train the
    model.'
  created_at: 2023-05-25 14:19:56+00:00
  edited: true
  hidden: false
  id: 646f7c9cbc42f4b0022f4238
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-05-25T15:32:48.000Z'
    data:
      edited: true
      editors:
      - loubnabnl
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
          fullname: Loubna Ben Allal
          isHf: true
          isPro: false
          name: loubnabnl
          type: user
        html: '<p>You can fine-tune StarCoderBase on C (instead of training from Scratch
          like we did with Python to get StarCoder), although you probably won''t
          be able to go through the full C dataset with 8 GPUs only in a short period
          of time, for information the python fine-tuning for 2 epochs on 35B tokens
          took ~10k GPU hours. Check this repo for some fine-tuning code: <a rel="nofollow"
          href="https://github.com/bigcode-project/starcoder">https://github.com/bigcode-project/starcoder</a></p>

          '
        raw: 'You can fine-tune StarCoderBase on C (instead of training from Scratch
          like we did with Python to get StarCoder), although you probably won''t
          be able to go through the full C dataset with 8 GPUs only in a short period
          of time, for information the python fine-tuning for 2 epochs on 35B tokens
          took ~10k GPU hours. Check this repo for some fine-tuning code: https://github.com/bigcode-project/starcoder'
        updatedAt: '2023-05-25T15:40:42.447Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mintglobe
    id: 646f7fa0bc42f4b0022f7d6d
    type: comment
  author: loubnabnl
  content: 'You can fine-tune StarCoderBase on C (instead of training from Scratch
    like we did with Python to get StarCoder), although you probably won''t be able
    to go through the full C dataset with 8 GPUs only in a short period of time, for
    information the python fine-tuning for 2 epochs on 35B tokens took ~10k GPU hours.
    Check this repo for some fine-tuning code: https://github.com/bigcode-project/starcoder'
  created_at: 2023-05-25 14:32:48+00:00
  edited: true
  hidden: false
  id: 646f7fa0bc42f4b0022f7d6d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg?w=200&h=200&f=face
      fullname: Loubna Ben Allal
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: loubnabnl
      type: user
    createdAt: '2023-06-06T08:50:32.000Z'
    data:
      status: closed
    id: 647ef3589c3102445798c48e
    type: status-change
  author: loubnabnl
  created_at: 2023-06-06 07:50:32+00:00
  id: 647ef3589c3102445798c48e
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 37
repo_id: bigcode/starcoder
repo_type: model
status: closed
target_branch: null
title: training demand of GPU
