!!python/object:huggingface_hub.community.DiscussionWithDetails
author: glad4enkonm
conflicting_files: null
created_at: 2023-10-19 19:31:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c8e340570aa3bee3147af64f0ec9b9b8.svg
      fullname: Nikolai Gladchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: glad4enkonm
      type: user
    createdAt: '2023-10-19T20:31:17.000Z'
    data:
      edited: false
      editors:
      - glad4enkonm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9699469208717346
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c8e340570aa3bee3147af64f0ec9b9b8.svg
          fullname: Nikolai Gladchenko
          isHf: false
          isPro: false
          name: glad4enkonm
          type: user
        html: '<p>Dear Community,</p>

          <p>could you please explain what are the hardware requirements to run this
          model locall?<br>I''ve tried a bunch of videocards and still getting errors
          ((</p>

          <p>Thanks in advance!</p>

          '
        raw: "Dear Community,\r\n\r\ncould you please explain what are the hardware\
          \ requirements to run this model locall?\r\nI've tried a bunch of videocards\
          \ and still getting errors ((\r\n\r\nThanks in advance!"
        updatedAt: '2023-10-19T20:31:17.485Z'
      numEdits: 0
      reactions: []
    id: 65319215829e1dc2f280b8ef
    type: comment
  author: glad4enkonm
  content: "Dear Community,\r\n\r\ncould you please explain what are the hardware\
    \ requirements to run this model locall?\r\nI've tried a bunch of videocards and\
    \ still getting errors ((\r\n\r\nThanks in advance!"
  created_at: 2023-10-19 19:31:17+00:00
  edited: false
  hidden: false
  id: 65319215829e1dc2f280b8ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
      fullname: Qian Liu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: SivilTaram
      type: user
    createdAt: '2023-10-20T02:07:25.000Z'
    data:
      edited: false
      editors:
      - SivilTaram
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7634773254394531
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
          fullname: Qian Liu
          isHf: false
          isPro: false
          name: SivilTaram
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;glad4enkonm&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/glad4enkonm\"\
          >@<span class=\"underline\">glad4enkonm</span></a></span>\n\n\t</span></span>\
          \ Thanks for your interest! I think the minimum hardware should be 1 x A100\
          \ (80G) card with the option <code>load_in_8_bit=True</code>. Otherwise,\
          \ you may try the framework of TGI and etc.</p>\n"
        raw: '@glad4enkonm Thanks for your interest! I think the minimum hardware
          should be 1 x A100 (80G) card with the option `load_in_8_bit=True`. Otherwise,
          you may try the framework of TGI and etc.'
        updatedAt: '2023-10-20T02:07:25.765Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - glad4enkonm
    id: 6531e0dd005c969984da8352
    type: comment
  author: SivilTaram
  content: '@glad4enkonm Thanks for your interest! I think the minimum hardware should
    be 1 x A100 (80G) card with the option `load_in_8_bit=True`. Otherwise, you may
    try the framework of TGI and etc.'
  created_at: 2023-10-20 01:07:25+00:00
  edited: false
  hidden: false
  id: 6531e0dd005c969984da8352
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c8e340570aa3bee3147af64f0ec9b9b8.svg
      fullname: Nikolai Gladchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: glad4enkonm
      type: user
    createdAt: '2023-10-20T08:48:44.000Z'
    data:
      edited: false
      editors:
      - glad4enkonm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9020740985870361
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c8e340570aa3bee3147af64f0ec9b9b8.svg
          fullname: Nikolai Gladchenko
          isHf: false
          isPro: false
          name: glad4enkonm
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;SivilTaram&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/SivilTaram\">@<span class=\"\
          underline\">SivilTaram</span></a></span>\n\n\t</span></span> Thanks a lot\
          \ for your quick reply!</p>\n<p>There are 2 docker deploy scripts in the\
          \ Lemur github repo.<br>One of them is using vllm with 4 GPUs (gpus='\"\
          device=0,1,2,3\"')<br>what are hardware requirements for that GPUs? Are\
          \ requirements the same to run<br>tgi and vllm scripts?</p>\n"
        raw: "@SivilTaram Thanks a lot for your quick reply!\n\nThere are 2 docker\
          \ deploy scripts in the Lemur github repo. \nOne of them is using vllm with\
          \ 4 GPUs (gpus='\"device=0,1,2,3\"') \nwhat are hardware requirements for\
          \ that GPUs? Are requirements the same to run\ntgi and vllm scripts?\n\n"
        updatedAt: '2023-10-20T08:48:44.503Z'
      numEdits: 0
      reactions: []
    id: 65323eeca1162a3f87a6bc3f
    type: comment
  author: glad4enkonm
  content: "@SivilTaram Thanks a lot for your quick reply!\n\nThere are 2 docker deploy\
    \ scripts in the Lemur github repo. \nOne of them is using vllm with 4 GPUs (gpus='\"\
    device=0,1,2,3\"') \nwhat are hardware requirements for that GPUs? Are requirements\
    \ the same to run\ntgi and vllm scripts?\n\n"
  created_at: 2023-10-20 07:48:44+00:00
  edited: false
  hidden: false
  id: 65323eeca1162a3f87a6bc3f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
      fullname: Qian Liu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: SivilTaram
      type: user
    createdAt: '2023-10-20T10:12:42.000Z'
    data:
      edited: false
      editors:
      - SivilTaram
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9368546605110168
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
          fullname: Qian Liu
          isHf: false
          isPro: false
          name: SivilTaram
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;glad4enkonm&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/glad4enkonm\"\
          >@<span class=\"underline\">glad4enkonm</span></a></span>\n\n\t</span></span>\
          \ We deploy it using 4 x 80 GB A100, but I think it should also work on\
          \ 8 x 40 GB A100 cards. Yes the requirements are the same to run tgi and\
          \ vllm scripts.</p>\n"
        raw: '@glad4enkonm We deploy it using 4 x 80 GB A100, but I think it should
          also work on 8 x 40 GB A100 cards. Yes the requirements are the same to
          run tgi and vllm scripts.'
        updatedAt: '2023-10-20T10:12:42.403Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - glad4enkonm
    id: 6532529a9824bcc3f44eeb6a
    type: comment
  author: SivilTaram
  content: '@glad4enkonm We deploy it using 4 x 80 GB A100, but I think it should
    also work on 8 x 40 GB A100 cards. Yes the requirements are the same to run tgi
    and vllm scripts.'
  created_at: 2023-10-20 09:12:42+00:00
  edited: false
  hidden: false
  id: 6532529a9824bcc3f44eeb6a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c8e340570aa3bee3147af64f0ec9b9b8.svg
      fullname: Nikolai Gladchenko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: glad4enkonm
      type: user
    createdAt: '2023-10-20T16:35:31.000Z'
    data:
      edited: false
      editors:
      - glad4enkonm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8076265454292297
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c8e340570aa3bee3147af64f0ec9b9b8.svg
          fullname: Nikolai Gladchenko
          isHf: false
          isPro: false
          name: glad4enkonm
          type: user
        html: '<p>Thanks a lot!</p>

          '
        raw: 'Thanks a lot!

          '
        updatedAt: '2023-10-20T16:35:31.612Z'
      numEdits: 0
      reactions: []
    id: 6532ac53910b8447865ad0d0
    type: comment
  author: glad4enkonm
  content: 'Thanks a lot!

    '
  created_at: 2023-10-20 15:35:31+00:00
  edited: false
  hidden: false
  id: 6532ac53910b8447865ad0d0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg?w=200&h=200&f=face
      fullname: Qian Liu
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: SivilTaram
      type: user
    createdAt: '2023-10-23T02:05:17.000Z'
    data:
      status: closed
    id: 6535d4dde983fb23fa65f448
    type: status-change
  author: SivilTaram
  created_at: 2023-10-23 01:05:17+00:00
  id: 6535d4dde983fb23fa65f448
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: OpenLemur/lemur-70b-v1
repo_type: model
status: closed
target_branch: null
title: HW requirements
