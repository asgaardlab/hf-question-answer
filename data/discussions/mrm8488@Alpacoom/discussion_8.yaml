!!python/object:huggingface_hub.community.DiscussionWithDetails
author: damesek
conflicting_files: null
created_at: 2023-04-18 09:05:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a26a527fe8b07a6a081de460476a5239.svg
      fullname: Bader Szabolcs
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: damesek
      type: user
    createdAt: '2023-04-18T10:05:15.000Z'
    data:
      edited: false
      editors:
      - damesek
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a26a527fe8b07a6a081de460476a5239.svg
          fullname: Bader Szabolcs
          isHf: false
          isPro: false
          name: damesek
          type: user
        html: "<p>Hello,</p>\n<p>I got this error in Google Colabs (see under my text).\
          \ I installed <code>!pip install bitsandbytes</code> too, so that couldn't\
          \ be a problem.. so Im not sure, how to fix. If you have any idea, Im happy\
          \ to hear :)</p>\n<pre><code class=\"language-Looking\">Requirement already\
          \ satisfied: bitsandbytes in /usr/local/lib/python3.9/dist-packages (0.38.1)\n\
          \n\u256D\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent\
          \ call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256E\n\u2502\
          \ in &lt;cell line: 2&gt;:2                                            \
          \                                  \u2502\n\u2502                      \
          \                                                                      \
          \      \u2502\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:143\
          \ in from_pretrained                 \u2502\n\u2502                    \
          \                                                                      \
          \        \u2502\n\u2502   140 \u2502   \u2502   if config.task_type not\
          \ in MODEL_TYPE_TO_PEFT_MODEL_MAPPING.keys():                \u2502\n\u2502\
          \   141 \u2502   \u2502   \u2502   model = cls(model, config)          \
          \                                           \u2502\n\u2502   142 \u2502\
          \   \u2502   else:                                                     \
          \                         \u2502\n\u2502 \u2771 143 \u2502   \u2502   \u2502\
          \   model = MODEL_TYPE_TO_PEFT_MODEL_MAPPING[config.task_type](model, config)\
          \      \u2502\n\u2502   144 \u2502   \u2502                            \
          \                                                          \u2502\n\u2502\
          \   145 \u2502   \u2502   # load weights if any                        \
          \                                      \u2502\n\u2502   146 \u2502   \u2502\
          \   if os.path.exists(os.path.join(model_id, WEIGHTS_NAME)):           \
          \                \u2502\n\u2502                                        \
          \                                                          \u2502\n\u2502\
          \ /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:514 in __init__\
          \                        \u2502\n\u2502                                \
          \                                                                  \u2502\
          \n\u2502   511 \u2502   \"\"\"                                         \
          \                                           \u2502\n\u2502   512 \u2502\
          \                                                                      \
          \                    \u2502\n\u2502   513 \u2502   def __init__(self, model,\
          \ peft_config: PeftConfig):                                    \u2502\n\u2502\
          \ \u2771 514 \u2502   \u2502   super().__init__(model, peft_config)    \
          \                                           \u2502\n\u2502   515 \u2502\
          \   \u2502   self.base_model_prepare_inputs_for_generation = self.base_model.prepare_inputs_f\
          \   \u2502\n\u2502   516 \u2502   \u2502   self.base_model.prepare_inputs_for_generation\
          \ = self.prepare_inputs_for_generati   \u2502\n\u2502   517            \
          \                                                                      \
          \          \u2502\n\u2502                                              \
          \                                                    \u2502\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:79\
          \ in __init__                         \u2502\n\u2502                   \
          \                                                                      \
          \         \u2502\n\u2502    76 \u2502   \u2502   if isinstance(self.peft_config,\
          \ PromptLearningConfig):                             \u2502\n\u2502    77\
          \ \u2502   \u2502   \u2502   self._setup_prompt_encoder()              \
          \                                     \u2502\n\u2502    78 \u2502   \u2502\
          \   else:                                                              \
          \                \u2502\n\u2502 \u2771  79 \u2502   \u2502   \u2502   self.base_model\
          \ = LoraModel(peft_config, model)                                \u2502\n\
          \u2502    80 \u2502   \u2502   if getattr(self.peft_config, \"modules_to_save\"\
          , None) is not None:                 \u2502\n\u2502    81 \u2502   \u2502\
          \   \u2502   self.modules_to_save = self.peft_config.modules_to_save   \
          \                     \u2502\n\u2502    82 \u2502   \u2502   \u2502   _set_trainable(self)\
          \                                                           \u2502\n\u2502\
          \                                                                      \
          \                            \u2502\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/tuners/lora.py:118\
          \ in __init__                       \u2502\n\u2502                     \
          \                                                                      \
          \       \u2502\n\u2502   115 \u2502   \u2502   super().__init__()      \
          \                                                           \u2502\n\u2502\
          \   116 \u2502   \u2502   self.peft_config = config                    \
          \                                      \u2502\n\u2502   117 \u2502   \u2502\
          \   self.model = model                                                 \
          \                \u2502\n\u2502 \u2771 118 \u2502   \u2502   self._find_and_replace()\
          \                                                           \u2502\n\u2502\
          \   119 \u2502   \u2502   mark_only_lora_as_trainable(self.model, self.peft_config.bias)\
          \                     \u2502\n\u2502   120 \u2502   \u2502   self.forward\
          \ = self.model.forward                                                 \
          \ \u2502\n\u2502   121                                                 \
          \                                           \u2502\n\u2502             \
          \                                                                      \
          \               \u2502\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/tuners/lora.py:148\
          \ in _find_and_replace              \u2502\n\u2502                     \
          \                                                                      \
          \       \u2502\n\u2502   145 \u2502   \u2502   \u2502   \u2502   \u2502\
          \   is_target_modules_in_base_model = True                             \
          \    \u2502\n\u2502   146 \u2502   \u2502   \u2502   \u2502   parent, target,\
          \ target_name = self._get_submodules(key)                    \u2502\n\u2502\
          \   147 \u2502   \u2502   \u2502   \u2502   bias = target.bias is not None\
          \                                             \u2502\n\u2502 \u2771 148\
          \ \u2502   \u2502   \u2502   \u2502   if loaded_in_8bit and isinstance(target,\
          \ bnb.nn.Linear8bitLt):             \u2502\n\u2502   149 \u2502   \u2502\
          \   \u2502   \u2502   \u2502   kwargs.update(                          \
          \                               \u2502\n\u2502   150 \u2502   \u2502   \u2502\
          \   \u2502   \u2502   \u2502   {                                       \
          \                           \u2502\n\u2502   151 \u2502   \u2502   \u2502\
          \   \u2502   \u2502   \u2502   \u2502   \"has_fp16_weights\": target.state.has_fp16_weights,\
          \             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u256F\nNameError: name 'bnb' is not\
          \ defined```\n</code></pre>\n"
        raw: "Hello,\r\n\r\nI got this error in Google Colabs (see under my text).\
          \ I installed `!pip install bitsandbytes` too, so that couldn't be a problem..\
          \ so Im not sure, how to fix. If you have any idea, Im happy to hear :)\r\
          \n\r\n```Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\r\
          \nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.9/dist-packages\
          \ (0.38.1)\r\n\r\n\u256D\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback\
          \ (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u256E\r\n\u2502 in <cell line: 2>:2                                   \
          \                                           \u2502\r\n\u2502           \
          \                                                                      \
          \                 \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:143\
          \ in from_pretrained                 \u2502\r\n\u2502                  \
          \                                                                      \
          \          \u2502\r\n\u2502   140 \u2502   \u2502   if config.task_type\
          \ not in MODEL_TYPE_TO_PEFT_MODEL_MAPPING.keys():                \u2502\r\
          \n\u2502   141 \u2502   \u2502   \u2502   model = cls(model, config)   \
          \                                                  \u2502\r\n\u2502   142\
          \ \u2502   \u2502   else:                                              \
          \                                \u2502\r\n\u2502 \u2771 143 \u2502   \u2502\
          \   \u2502   model = MODEL_TYPE_TO_PEFT_MODEL_MAPPING[config.task_type](model,\
          \ config)      \u2502\r\n\u2502   144 \u2502   \u2502                  \
          \                                                                    \u2502\
          \r\n\u2502   145 \u2502   \u2502   # load weights if any               \
          \                                               \u2502\r\n\u2502   146 \u2502\
          \   \u2502   if os.path.exists(os.path.join(model_id, WEIGHTS_NAME)):  \
          \                         \u2502\r\n\u2502                             \
          \                                                                     \u2502\
          \r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:514\
          \ in __init__                        \u2502\r\n\u2502                  \
          \                                                                      \
          \          \u2502\r\n\u2502   511 \u2502   \"\"\"                      \
          \                                                              \u2502\r\n\
          \u2502   512 \u2502                                                    \
          \                                      \u2502\r\n\u2502   513 \u2502   def\
          \ __init__(self, model, peft_config: PeftConfig):                      \
          \              \u2502\r\n\u2502 \u2771 514 \u2502   \u2502   super().__init__(model,\
          \ peft_config)                                               \u2502\r\n\u2502\
          \   515 \u2502   \u2502   self.base_model_prepare_inputs_for_generation\
          \ = self.base_model.prepare_inputs_f   \u2502\r\n\u2502   516 \u2502   \u2502\
          \   self.base_model.prepare_inputs_for_generation = self.prepare_inputs_for_generati\
          \   \u2502\r\n\u2502   517                                             \
          \                                               \u2502\r\n\u2502       \
          \                                                                      \
          \                     \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:79\
          \ in __init__                         \u2502\r\n\u2502                 \
          \                                                                      \
          \           \u2502\r\n\u2502    76 \u2502   \u2502   if isinstance(self.peft_config,\
          \ PromptLearningConfig):                             \u2502\r\n\u2502  \
          \  77 \u2502   \u2502   \u2502   self._setup_prompt_encoder()          \
          \                                         \u2502\r\n\u2502    78 \u2502\
          \   \u2502   else:                                                     \
          \                         \u2502\r\n\u2502 \u2771  79 \u2502   \u2502  \
          \ \u2502   self.base_model = LoraModel(peft_config, model)             \
          \                   \u2502\r\n\u2502    80 \u2502   \u2502   if getattr(self.peft_config,\
          \ \"modules_to_save\", None) is not None:                 \u2502\r\n\u2502\
          \    81 \u2502   \u2502   \u2502   self.modules_to_save = self.peft_config.modules_to_save\
          \                        \u2502\r\n\u2502    82 \u2502   \u2502   \u2502\
          \   _set_trainable(self)                                               \
          \            \u2502\r\n\u2502                                          \
          \                                                        \u2502\r\n\u2502\
          \ /usr/local/lib/python3.9/dist-packages/peft/tuners/lora.py:118 in __init__\
          \                       \u2502\r\n\u2502                               \
          \                                                                   \u2502\
          \r\n\u2502   115 \u2502   \u2502   super().__init__()                  \
          \                                               \u2502\r\n\u2502   116 \u2502\
          \   \u2502   self.peft_config = config                                 \
          \                         \u2502\r\n\u2502   117 \u2502   \u2502   self.model\
          \ = model                                                              \
          \   \u2502\r\n\u2502 \u2771 118 \u2502   \u2502   self._find_and_replace()\
          \                                                           \u2502\r\n\u2502\
          \   119 \u2502   \u2502   mark_only_lora_as_trainable(self.model, self.peft_config.bias)\
          \                     \u2502\r\n\u2502   120 \u2502   \u2502   self.forward\
          \ = self.model.forward                                                 \
          \ \u2502\r\n\u2502   121                                               \
          \                                             \u2502\r\n\u2502         \
          \                                                                      \
          \                   \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/tuners/lora.py:148\
          \ in _find_and_replace              \u2502\r\n\u2502                   \
          \                                                                      \
          \         \u2502\r\n\u2502   145 \u2502   \u2502   \u2502   \u2502   \u2502\
          \   is_target_modules_in_base_model = True                             \
          \    \u2502\r\n\u2502   146 \u2502   \u2502   \u2502   \u2502   parent,\
          \ target, target_name = self._get_submodules(key)                    \u2502\
          \r\n\u2502   147 \u2502   \u2502   \u2502   \u2502   bias = target.bias\
          \ is not None                                             \u2502\r\n\u2502\
          \ \u2771 148 \u2502   \u2502   \u2502   \u2502   if loaded_in_8bit and isinstance(target,\
          \ bnb.nn.Linear8bitLt):             \u2502\r\n\u2502   149 \u2502   \u2502\
          \   \u2502   \u2502   \u2502   kwargs.update(                          \
          \                               \u2502\r\n\u2502   150 \u2502   \u2502 \
          \  \u2502   \u2502   \u2502   \u2502   {                               \
          \                                   \u2502\r\n\u2502   151 \u2502   \u2502\
          \   \u2502   \u2502   \u2502   \u2502   \u2502   \"has_fp16_weights\": target.state.has_fp16_weights,\
          \             \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256F\r\nNameError: name 'bnb'\
          \ is not defined```\r\n\r\n"
        updatedAt: '2023-04-18T10:05:15.090Z'
      numEdits: 0
      reactions: []
    id: 643e6b5b70c6a27621ea1963
    type: comment
  author: damesek
  content: "Hello,\r\n\r\nI got this error in Google Colabs (see under my text). I\
    \ installed `!pip install bitsandbytes` too, so that couldn't be a problem.. so\
    \ Im not sure, how to fix. If you have any idea, Im happy to hear :)\r\n\r\n```Looking\
    \ in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\r\
    \nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.9/dist-packages\
    \ (0.38.1)\r\n\r\n\u256D\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent\
    \ call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256E\r\n\u2502 in <cell line:\
    \ 2>:2                                                                       \
    \       \u2502\r\n\u2502                                                     \
    \                                             \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:143\
    \ in from_pretrained                 \u2502\r\n\u2502                        \
    \                                                                          \u2502\
    \r\n\u2502   140 \u2502   \u2502   if config.task_type not in MODEL_TYPE_TO_PEFT_MODEL_MAPPING.keys():\
    \                \u2502\r\n\u2502   141 \u2502   \u2502   \u2502   model = cls(model,\
    \ config)                                                     \u2502\r\n\u2502\
    \   142 \u2502   \u2502   else:                                              \
    \                                \u2502\r\n\u2502 \u2771 143 \u2502   \u2502 \
    \  \u2502   model = MODEL_TYPE_TO_PEFT_MODEL_MAPPING[config.task_type](model,\
    \ config)      \u2502\r\n\u2502   144 \u2502   \u2502                        \
    \                                                              \u2502\r\n\u2502\
    \   145 \u2502   \u2502   # load weights if any                              \
    \                                \u2502\r\n\u2502   146 \u2502   \u2502   if os.path.exists(os.path.join(model_id,\
    \ WEIGHTS_NAME)):                           \u2502\r\n\u2502                 \
    \                                                                            \
    \     \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:514\
    \ in __init__                        \u2502\r\n\u2502                        \
    \                                                                          \u2502\
    \r\n\u2502   511 \u2502   \"\"\"                                             \
    \                                       \u2502\r\n\u2502   512 \u2502        \
    \                                                                            \
    \      \u2502\r\n\u2502   513 \u2502   def __init__(self, model, peft_config:\
    \ PeftConfig):                                    \u2502\r\n\u2502 \u2771 514\
    \ \u2502   \u2502   super().__init__(model, peft_config)                     \
    \                          \u2502\r\n\u2502   515 \u2502   \u2502   self.base_model_prepare_inputs_for_generation\
    \ = self.base_model.prepare_inputs_f   \u2502\r\n\u2502   516 \u2502   \u2502\
    \   self.base_model.prepare_inputs_for_generation = self.prepare_inputs_for_generati\
    \   \u2502\r\n\u2502   517                                                   \
    \                                         \u2502\r\n\u2502                   \
    \                                                                            \
    \   \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:79\
    \ in __init__                         \u2502\r\n\u2502                       \
    \                                                                           \u2502\
    \r\n\u2502    76 \u2502   \u2502   if isinstance(self.peft_config, PromptLearningConfig):\
    \                             \u2502\r\n\u2502    77 \u2502   \u2502   \u2502\
    \   self._setup_prompt_encoder()                                             \
    \      \u2502\r\n\u2502    78 \u2502   \u2502   else:                        \
    \                                                      \u2502\r\n\u2502 \u2771\
    \  79 \u2502   \u2502   \u2502   self.base_model = LoraModel(peft_config, model)\
    \                                \u2502\r\n\u2502    80 \u2502   \u2502   if getattr(self.peft_config,\
    \ \"modules_to_save\", None) is not None:                 \u2502\r\n\u2502   \
    \ 81 \u2502   \u2502   \u2502   self.modules_to_save = self.peft_config.modules_to_save\
    \                        \u2502\r\n\u2502    82 \u2502   \u2502   \u2502   _set_trainable(self)\
    \                                                           \u2502\r\n\u2502 \
    \                                                                            \
    \                     \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/tuners/lora.py:118\
    \ in __init__                       \u2502\r\n\u2502                         \
    \                                                                         \u2502\
    \r\n\u2502   115 \u2502   \u2502   super().__init__()                        \
    \                                         \u2502\r\n\u2502   116 \u2502   \u2502\
    \   self.peft_config = config                                                \
    \          \u2502\r\n\u2502   117 \u2502   \u2502   self.model = model       \
    \                                                          \u2502\r\n\u2502 \u2771\
    \ 118 \u2502   \u2502   self._find_and_replace()                             \
    \                              \u2502\r\n\u2502   119 \u2502   \u2502   mark_only_lora_as_trainable(self.model,\
    \ self.peft_config.bias)                     \u2502\r\n\u2502   120 \u2502   \u2502\
    \   self.forward = self.model.forward                                        \
    \          \u2502\r\n\u2502   121                                            \
    \                                                \u2502\r\n\u2502            \
    \                                                                            \
    \          \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/tuners/lora.py:148\
    \ in _find_and_replace              \u2502\r\n\u2502                         \
    \                                                                         \u2502\
    \r\n\u2502   145 \u2502   \u2502   \u2502   \u2502   \u2502   is_target_modules_in_base_model\
    \ = True                                 \u2502\r\n\u2502   146 \u2502   \u2502\
    \   \u2502   \u2502   parent, target, target_name = self._get_submodules(key)\
    \                    \u2502\r\n\u2502   147 \u2502   \u2502   \u2502   \u2502\
    \   bias = target.bias is not None                                           \
    \  \u2502\r\n\u2502 \u2771 148 \u2502   \u2502   \u2502   \u2502   if loaded_in_8bit\
    \ and isinstance(target, bnb.nn.Linear8bitLt):             \u2502\r\n\u2502  \
    \ 149 \u2502   \u2502   \u2502   \u2502   \u2502   kwargs.update(            \
    \                                             \u2502\r\n\u2502   150 \u2502  \
    \ \u2502   \u2502   \u2502   \u2502   \u2502   {                             \
    \                                     \u2502\r\n\u2502   151 \u2502   \u2502 \
    \  \u2502   \u2502   \u2502   \u2502   \u2502   \"has_fp16_weights\": target.state.has_fp16_weights,\
    \             \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\
    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256F\
    \r\nNameError: name 'bnb' is not defined```\r\n\r\n"
  created_at: 2023-04-18 09:05:15+00:00
  edited: false
  hidden: false
  id: 643e6b5b70c6a27621ea1963
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a26a527fe8b07a6a081de460476a5239.svg
      fullname: Bader Szabolcs
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: damesek
      type: user
    createdAt: '2023-04-18T10:11:53.000Z'
    data:
      edited: false
      editors:
      - damesek
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a26a527fe8b07a6a081de460476a5239.svg
          fullname: Bader Szabolcs
          isHf: false
          isPro: false
          name: damesek
          type: user
        html: '<p>I fixed it by pip install bitsandbytes==0.35.0</p>

          '
        raw: I fixed it by pip install bitsandbytes==0.35.0
        updatedAt: '2023-04-18T10:11:53.141Z'
      numEdits: 0
      reactions: []
    id: 643e6ce9ab725487d8e6c1c8
    type: comment
  author: damesek
  content: I fixed it by pip install bitsandbytes==0.35.0
  created_at: 2023-04-18 09:11:53+00:00
  edited: false
  hidden: false
  id: 643e6ce9ab725487d8e6c1c8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/a26a527fe8b07a6a081de460476a5239.svg
      fullname: Bader Szabolcs
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: damesek
      type: user
    createdAt: '2023-04-18T10:12:08.000Z'
    data:
      status: closed
    id: 643e6cf852885f3d3f5201aa
    type: status-change
  author: damesek
  created_at: 2023-04-18 09:12:08+00:00
  id: 643e6cf852885f3d3f5201aa
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: mrm8488/Alpacoom
repo_type: model
status: closed
target_branch: null
title: 'Google Colabs I got this error: NameError: name ''bnb'' is not defined'
