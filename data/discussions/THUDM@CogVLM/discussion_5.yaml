!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wkh666
conflicting_files: null
created_at: 2023-12-14 04:06:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c562010582243dada12f477234963872.svg
      fullname: kaihan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wkh666
      type: user
    createdAt: '2023-12-14T04:06:01.000Z'
    data:
      edited: false
      editors:
      - wkh666
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9969378709793091
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c562010582243dada12f477234963872.svg
          fullname: kaihan
          isHf: false
          isPro: false
          name: wkh666
          type: user
        html: "<p>\u4F5C\u8005\u60A8\u597D\uFF0C\u6211\u662F\u521A\u63A5\u89E6\u9879\
          \u76EE\u7684\u5C0F\u767D\uFF0C\u60F3\u95EE\u4E00\u4E0Bzip\u538B\u7F29\u5305\
          \u91CC\u7684\u6587\u4EF6\u4F3C\u4E4E\u548C \u4EE5-hf\u547D\u540D\u7684\u6587\
          \u4EF6\u662F\u4E0D\u4E00\u6837\u7684\uFF0C\u8FD9\u4E24\u8005\u7684\u533A\
          \u522B\u662F\u4EC0\u4E48\u5462\uFF1F\u8C22\u8C22</p>\n"
        raw: "\u4F5C\u8005\u60A8\u597D\uFF0C\u6211\u662F\u521A\u63A5\u89E6\u9879\u76EE\
          \u7684\u5C0F\u767D\uFF0C\u60F3\u95EE\u4E00\u4E0Bzip\u538B\u7F29\u5305\u91CC\
          \u7684\u6587\u4EF6\u4F3C\u4E4E\u548C \u4EE5-hf\u547D\u540D\u7684\u6587\u4EF6\
          \u662F\u4E0D\u4E00\u6837\u7684\uFF0C\u8FD9\u4E24\u8005\u7684\u533A\u522B\
          \u662F\u4EC0\u4E48\u5462\uFF1F\u8C22\u8C22"
        updatedAt: '2023-12-14T04:06:01.301Z'
      numEdits: 0
      reactions: []
    id: 657a7f29a66c1fbf66e56686
    type: comment
  author: wkh666
  content: "\u4F5C\u8005\u60A8\u597D\uFF0C\u6211\u662F\u521A\u63A5\u89E6\u9879\u76EE\
    \u7684\u5C0F\u767D\uFF0C\u60F3\u95EE\u4E00\u4E0Bzip\u538B\u7F29\u5305\u91CC\u7684\
    \u6587\u4EF6\u4F3C\u4E4E\u548C \u4EE5-hf\u547D\u540D\u7684\u6587\u4EF6\u662F\u4E0D\
    \u4E00\u6837\u7684\uFF0C\u8FD9\u4E24\u8005\u7684\u533A\u522B\u662F\u4EC0\u4E48\
    \u5462\uFF1F\u8C22\u8C22"
  created_at: 2023-12-14 04:06:01+00:00
  edited: false
  hidden: false
  id: 657a7f29a66c1fbf66e56686
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0d95d65d30f6672ec09dc92155324d7f.svg
      fullname: chenkq
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: chenkq
      type: user
    createdAt: '2023-12-14T05:44:01.000Z'
    data:
      edited: false
      editors:
      - chenkq
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.7988694906234741
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0d95d65d30f6672ec09dc92155324d7f.svg
          fullname: chenkq
          isHf: false
          isPro: false
          name: chenkq
          type: user
        html: "<p>\u8FD9\u4E2Azip\u4E2D\u7684\u6743\u91CD\u662F\u7528<a rel=\"nofollow\"\
          \ href=\"https://github.com/THUDM/SwissArmyTransformer\">sat</a>\u8BAD\u7EC3\
          \u7684\u6743\u91CD\uFF0C\u548C<a rel=\"nofollow\" href=\"https://github.com/THUDM/CogVLM/blob/main/models/cogvlm_model.py\"\
          >\u8FD9\u91CC\u7684\u6A21\u578B\u5B9E\u73B0</a>\u662F\u914D\u5BF9\u7684\u3002\
          \u4E4B\u540E\u4E3A\u4E86\u65B9\u4FBF\u5927\u5BB6\u4F7F\u7528\uFF0C\u628A\
          \u6A21\u578B\u5B9E\u73B0\u548C\u6743\u91CD\u90FD\u8F6C\u5316\u6210\u548C\
          huggingface\u517C\u5BB9\u7684\u683C\u5F0F\u4E86\uFF0C\u5C31\u662F\u4F60\u770B\
          \u5230\u7684-hf\u7684\u4ED3\u5E93\u3002</p>\n"
        raw: "\u8FD9\u4E2Azip\u4E2D\u7684\u6743\u91CD\u662F\u7528[sat](https://github.com/THUDM/SwissArmyTransformer)\u8BAD\
          \u7EC3\u7684\u6743\u91CD\uFF0C\u548C[\u8FD9\u91CC\u7684\u6A21\u578B\u5B9E\
          \u73B0](https://github.com/THUDM/CogVLM/blob/main/models/cogvlm_model.py)\u662F\
          \u914D\u5BF9\u7684\u3002\u4E4B\u540E\u4E3A\u4E86\u65B9\u4FBF\u5927\u5BB6\
          \u4F7F\u7528\uFF0C\u628A\u6A21\u578B\u5B9E\u73B0\u548C\u6743\u91CD\u90FD\
          \u8F6C\u5316\u6210\u548Chuggingface\u517C\u5BB9\u7684\u683C\u5F0F\u4E86\uFF0C\
          \u5C31\u662F\u4F60\u770B\u5230\u7684-hf\u7684\u4ED3\u5E93\u3002"
        updatedAt: '2023-12-14T05:44:01.074Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - wkh666
        - jizhongpeng
    id: 657a9621ea977ac71ccc397a
    type: comment
  author: chenkq
  content: "\u8FD9\u4E2Azip\u4E2D\u7684\u6743\u91CD\u662F\u7528[sat](https://github.com/THUDM/SwissArmyTransformer)\u8BAD\
    \u7EC3\u7684\u6743\u91CD\uFF0C\u548C[\u8FD9\u91CC\u7684\u6A21\u578B\u5B9E\u73B0\
    ](https://github.com/THUDM/CogVLM/blob/main/models/cogvlm_model.py)\u662F\u914D\
    \u5BF9\u7684\u3002\u4E4B\u540E\u4E3A\u4E86\u65B9\u4FBF\u5927\u5BB6\u4F7F\u7528\
    \uFF0C\u628A\u6A21\u578B\u5B9E\u73B0\u548C\u6743\u91CD\u90FD\u8F6C\u5316\u6210\
    \u548Chuggingface\u517C\u5BB9\u7684\u683C\u5F0F\u4E86\uFF0C\u5C31\u662F\u4F60\u770B\
    \u5230\u7684-hf\u7684\u4ED3\u5E93\u3002"
  created_at: 2023-12-14 05:44:01+00:00
  edited: false
  hidden: false
  id: 657a9621ea977ac71ccc397a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c562010582243dada12f477234963872.svg
      fullname: kaihan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wkh666
      type: user
    createdAt: '2023-12-14T06:11:30.000Z'
    data:
      edited: false
      editors:
      - wkh666
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9705580472946167
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c562010582243dada12f477234963872.svg
          fullname: kaihan
          isHf: false
          isPro: false
          name: wkh666
          type: user
        html: "<p>\u660E\u767D\uFF0C\u80FD\u5426\u63D0\u4F9B\u4E00\u4E0B\u8F6C\u5316\
          \u7684\u4EE3\u7801\u5462\uFF1F\u975E\u5E38\u611F\u8C22</p>\n"
        raw: "\u660E\u767D\uFF0C\u80FD\u5426\u63D0\u4F9B\u4E00\u4E0B\u8F6C\u5316\u7684\
          \u4EE3\u7801\u5462\uFF1F\u975E\u5E38\u611F\u8C22"
        updatedAt: '2023-12-14T06:11:30.919Z'
      numEdits: 0
      reactions: []
    id: 657a9c9210503b507c60e911
    type: comment
  author: wkh666
  content: "\u660E\u767D\uFF0C\u80FD\u5426\u63D0\u4F9B\u4E00\u4E0B\u8F6C\u5316\u7684\
    \u4EE3\u7801\u5462\uFF1F\u975E\u5E38\u611F\u8C22"
  created_at: 2023-12-14 06:11:30+00:00
  edited: false
  hidden: false
  id: 657a9c9210503b507c60e911
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0d95d65d30f6672ec09dc92155324d7f.svg
      fullname: chenkq
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: chenkq
      type: user
    createdAt: '2023-12-15T03:31:06.000Z'
    data:
      edited: true
      editors:
      - chenkq
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.23712949454784393
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0d95d65d30f6672ec09dc92155324d7f.svg
          fullname: chenkq
          isHf: false
          isPro: false
          name: chenkq
          type: user
        html: "<p>\u5C31\u662F\u628Astate_dict\u5185weights\u7684\u540D\u5B57\u66FF\
          \u6362\u4E0B</p>\n<details>\n<summary> \u6709\u70B9\u4E11\u964B\u7684\u4EE3\
          \u7801 </summary>\n\n\n<pre><code class=\"language-python\"><span class=\"\
          hljs-keyword\">def</span> <span class=\"hljs-title function_\">vlm</span>(<span\
          \ class=\"hljs-params\"></span>\n<span class=\"hljs-params\">        hf_dir:\
          \ <span class=\"hljs-built_in\">str</span>,</span>\n<span class=\"hljs-params\"\
          >        sat_dir: <span class=\"hljs-built_in\">str</span>,</span>\n<span\
          \ class=\"hljs-params\"></span>):\n    <span class=\"hljs-keyword\">import</span>\
          \ os\n    <span class=\"hljs-keyword\">import</span> json\n    <span class=\"\
          hljs-keyword\">import</span> torch\n    <span class=\"hljs-keyword\">from</span>\
          \ pathlib <span class=\"hljs-keyword\">import</span> Path\n    Path(hf_dir).mkdir(exist_ok=<span\
          \ class=\"hljs-literal\">True</span>)\n\n    <span class=\"hljs-comment\"\
          ># state dict</span>\n    state_dict = torch.load(os.path.expanduser(os.path.join(sat_dir,\
          \ <span class=\"hljs-string\">'1'</span>, <span class=\"hljs-string\">'mp_rank_00_model_states.pt'</span>)),\
          \ map_location=<span class=\"hljs-string\">'cpu'</span>)\n    state_dict\
          \ = state_dict[<span class=\"hljs-string\">'module'</span>]\n    new_state_dict\
          \ = {}\n    <span class=\"hljs-keyword\">for</span> k, v <span class=\"\
          hljs-keyword\">in</span> state_dict.items():\n        <span class=\"hljs-keyword\"\
          >if</span> k.startswith(<span class=\"hljs-string\">'mixins.eva.vit_model.mixins.patch_embedding'</span>):\n\
          \            new_state_dict[k.replace(<span class=\"hljs-string\">'mixins.eva.vit_model.mixins.'</span>,\
          \ <span class=\"hljs-string\">''</span>, <span class=\"hljs-number\">1</span>)]\
          \ = v\n        <span class=\"hljs-keyword\">elif</span> k.startswith(<span\
          \ class=\"hljs-string\">'mixins.eva.vit_model.transformer.position_embeddings'</span>):\n\
          \            new_state_dict[k.replace(<span class=\"hljs-string\">'mixins.eva.vit_model.transformer.position_embeddings'</span>,\
          \ <span class=\"hljs-string\">'patch_embedding.position_embedding'</span>,\
          \ <span class=\"hljs-number\">1</span>)] = v\n        <span class=\"hljs-keyword\"\
          >elif</span> k.startswith(<span class=\"hljs-string\">'mixins.eva.vit_model.transformer.layers'</span>):\n\
          \            k = k.replace(<span class=\"hljs-string\">'mlp.dense_4h_to_h'</span>,\
          \ <span class=\"hljs-string\">'mlp.fc2'</span>).replace(<span class=\"hljs-string\"\
          >'mlp.dense_h_to_4h'</span>, <span class=\"hljs-string\">'mlp.fc1'</span>)\n\
          \            new_state_dict[k.replace(<span class=\"hljs-string\">'mixins.eva.vit_model.transformer.layers'</span>,\
          \ <span class=\"hljs-string\">'transformer.layers'</span>, <span class=\"\
          hljs-number\">1</span>)] = v\n        <span class=\"hljs-keyword\">elif</span>\
          \ k.startswith(<span class=\"hljs-string\">'mixins.eva.linear_proj'</span>):\n\
          \            new_state_dict[k.replace(<span class=\"hljs-string\">'mixins.eva.linear_proj'</span>,\
          \ <span class=\"hljs-string\">'linear_proj'</span>, <span class=\"hljs-number\"\
          >1</span>)] = v\n        <span class=\"hljs-keyword\">elif</span> k <span\
          \ class=\"hljs-keyword\">in</span> [<span class=\"hljs-string\">'mixins.eva.vit_model.transformer.word_embeddings.weight'</span>]:\n\
          \            new_state_dict[<span class=\"hljs-string\">'patch_embedding.cls_embedding'</span>]\
          \ = v\n        <span class=\"hljs-keyword\">elif</span> k <span class=\"\
          hljs-keyword\">in</span> [<span class=\"hljs-string\">'mixins.eva.boi'</span>,\
          \ <span class=\"hljs-string\">'mixins.eva.eoi'</span>]:\n            new_state_dict[k.replace(<span\
          \ class=\"hljs-string\">'mixins.eva.'</span>, <span class=\"hljs-string\"\
          >''</span>, <span class=\"hljs-number\">1</span>)] = v\n        <span class=\"\
          hljs-keyword\">else</span>:\n            <span class=\"hljs-keyword\">assert</span>\
          \ <span class=\"hljs-keyword\">not</span> <span class=\"hljs-built_in\"\
          >str</span>(k).startswith(<span class=\"hljs-string\">'mixins.eva'</span>),\
          \ <span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{k}</span>\"\
          </span>\n\n    vision_state_dict = {<span class=\"hljs-string\">f\"model.vision.<span\
          \ class=\"hljs-subst\">{k}</span>\"</span>: v <span class=\"hljs-keyword\"\
          >for</span> k, v <span class=\"hljs-keyword\">in</span> new_state_dict.items()}\n\
          \    new_state_dict = {}\n    <span class=\"hljs-keyword\">for</span> k,\
          \ v <span class=\"hljs-keyword\">in</span> state_dict.items():\n       \
          \ <span class=\"hljs-keyword\">if</span> k == <span class=\"hljs-string\"\
          >'mixins.lm.lm_head.weight'</span>:\n            new_state_dict[<span class=\"\
          hljs-string\">'lm_head.weight'</span>] = v\n        <span class=\"hljs-keyword\"\
          >elif</span> k.startswith(<span class=\"hljs-string\">\"mixins.eva\"</span>):\n\
          \            <span class=\"hljs-keyword\">continue</span>\n        <span\
          \ class=\"hljs-comment\"># mlp</span>\n        <span class=\"hljs-keyword\"\
          >elif</span> k.startswith(<span class=\"hljs-string\">'mixins.mlp.vision_dense_h_to_4h_list.'</span>)\
          \ <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\"\
          >str</span>(k).endswith(<span class=\"hljs-string\">'.weight'</span>):\n\
          \            idx = <span class=\"hljs-built_in\">str</span>(k).replace(<span\
          \ class=\"hljs-string\">'mixins.mlp.vision_dense_h_to_4h_list.'</span>,\
          \ <span class=\"hljs-string\">''</span>).replace(<span class=\"hljs-string\"\
          >'.weight'</span>, <span class=\"hljs-string\">''</span>)\n            new_state_dict[<span\
          \ class=\"hljs-string\">f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.mlp.vision_mlp.up_proj.weight\"\
          </span>] = v\n        <span class=\"hljs-keyword\">elif</span> k.startswith(<span\
          \ class=\"hljs-string\">'mixins.mlp.vision_dense_4h_to_h_list.'</span>)\
          \ <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\"\
          >str</span>(k).endswith(<span class=\"hljs-string\">'.weight'</span>):\n\
          \            idx = <span class=\"hljs-built_in\">str</span>(k).replace(<span\
          \ class=\"hljs-string\">'mixins.mlp.vision_dense_4h_to_h_list.'</span>,\
          \ <span class=\"hljs-string\">''</span>).replace(<span class=\"hljs-string\"\
          >'.weight'</span>, <span class=\"hljs-string\">''</span>)\n            new_state_dict[<span\
          \ class=\"hljs-string\">f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.mlp.vision_mlp.down_proj.weight\"\
          </span>] = v\n        <span class=\"hljs-keyword\">elif</span> k.startswith(<span\
          \ class=\"hljs-string\">'mixins.mlp.vision_gate_proj.'</span>) <span class=\"\
          hljs-keyword\">and</span> <span class=\"hljs-built_in\">str</span>(k).endswith(<span\
          \ class=\"hljs-string\">'.weight'</span>):\n            idx = <span class=\"\
          hljs-built_in\">str</span>(k).replace(<span class=\"hljs-string\">'mixins.mlp.vision_gate_proj.'</span>,\
          \ <span class=\"hljs-string\">''</span>).replace(<span class=\"hljs-string\"\
          >'.weight'</span>, <span class=\"hljs-string\">''</span>)\n            new_state_dict[<span\
          \ class=\"hljs-string\">f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.mlp.vision_mlp.gate_proj.weight\"\
          </span>] = v\n\n        <span class=\"hljs-keyword\">elif</span> k.startswith(<span\
          \ class=\"hljs-string\">'mixins.mlp.gate_proj.'</span>) <span class=\"hljs-keyword\"\
          >and</span> <span class=\"hljs-built_in\">str</span>(k).endswith(<span class=\"\
          hljs-string\">'.weight'</span>):\n            idx = <span class=\"hljs-built_in\"\
          >str</span>(k).replace(<span class=\"hljs-string\">'mixins.mlp.gate_proj.'</span>,\
          \ <span class=\"hljs-string\">''</span>).replace(<span class=\"hljs-string\"\
          >'.weight'</span>, <span class=\"hljs-string\">''</span>)\n            new_state_dict[<span\
          \ class=\"hljs-string\">f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.mlp.language_mlp.gate_proj.weight\"\
          </span>] = v\n        <span class=\"hljs-keyword\">elif</span> k.startswith(<span\
          \ class=\"hljs-string\">'transformer.layers.'</span>) <span class=\"hljs-keyword\"\
          >and</span> <span class=\"hljs-built_in\">str</span>(k).endswith(<span class=\"\
          hljs-string\">'.mlp.dense_h_to_4h.weight'</span>):\n            idx = <span\
          \ class=\"hljs-built_in\">str</span>(k).replace(<span class=\"hljs-string\"\
          >'transformer.layers.'</span>, <span class=\"hljs-string\">''</span>).replace(<span\
          \ class=\"hljs-string\">'.mlp.dense_h_to_4h.weight'</span>, <span class=\"\
          hljs-string\">''</span>)\n            new_state_dict[<span class=\"hljs-string\"\
          >f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.mlp.language_mlp.up_proj.weight\"\
          </span>] = v\n        <span class=\"hljs-keyword\">elif</span> k.startswith(<span\
          \ class=\"hljs-string\">'transformer.layers.'</span>) <span class=\"hljs-keyword\"\
          >and</span> <span class=\"hljs-built_in\">str</span>(k).endswith(<span class=\"\
          hljs-string\">'.mlp.dense_4h_to_h.weight'</span>):\n            idx = <span\
          \ class=\"hljs-built_in\">str</span>(k).replace(<span class=\"hljs-string\"\
          >'transformer.layers.'</span>, <span class=\"hljs-string\">''</span>).replace(<span\
          \ class=\"hljs-string\">'.mlp.dense_4h_to_h.weight'</span>, <span class=\"\
          hljs-string\">''</span>)\n            new_state_dict[<span class=\"hljs-string\"\
          >f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.mlp.language_mlp.down_proj.weight\"\
          </span>] = v\n        <span class=\"hljs-comment\"># attn</span>\n     \
          \   <span class=\"hljs-keyword\">elif</span> k.startswith(<span class=\"\
          hljs-string\">'transformer.layers.'</span>) <span class=\"hljs-keyword\"\
          >and</span> <span class=\"hljs-built_in\">str</span>(k).endswith(<span class=\"\
          hljs-string\">'.attention.query_key_value.weight'</span>):\n           \
          \ idx = <span class=\"hljs-built_in\">str</span>(k).replace(<span class=\"\
          hljs-string\">'transformer.layers.'</span>, <span class=\"hljs-string\"\
          >''</span>).replace(<span class=\"hljs-string\">'.attention.query_key_value.weight'</span>,\
          \ <span class=\"hljs-string\">''</span>)\n            new_state_dict[<span\
          \ class=\"hljs-string\">f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.self_attn.language_expert_query_key_value.weight\"\
          </span>] = v\n        <span class=\"hljs-keyword\">elif</span> k.startswith(<span\
          \ class=\"hljs-string\">'transformer.layers.'</span>) <span class=\"hljs-keyword\"\
          >and</span> <span class=\"hljs-built_in\">str</span>(k).endswith(<span class=\"\
          hljs-string\">'.attention.dense.weight'</span>):\n            idx = <span\
          \ class=\"hljs-built_in\">str</span>(k).replace(<span class=\"hljs-string\"\
          >'transformer.layers.'</span>, <span class=\"hljs-string\">''</span>).replace(<span\
          \ class=\"hljs-string\">'.attention.dense.weight'</span>, <span class=\"\
          hljs-string\">''</span>)\n            new_state_dict[<span class=\"hljs-string\"\
          >f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.self_attn.language_expert_dense.weight\"\
          </span>] = v\n\n        <span class=\"hljs-keyword\">elif</span> k.startswith(<span\
          \ class=\"hljs-string\">'mixins.rotary.vision_query_key_value_list.'</span>)\
          \ <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\"\
          >str</span>(k).endswith(<span class=\"hljs-string\">'.weight'</span>):\n\
          \            idx = <span class=\"hljs-built_in\">str</span>(k).replace(<span\
          \ class=\"hljs-string\">'mixins.rotary.vision_query_key_value_list.'</span>,\
          \ <span class=\"hljs-string\">''</span>).replace(<span class=\"hljs-string\"\
          >'.weight'</span>, <span class=\"hljs-string\">''</span>)\n            new_state_dict[<span\
          \ class=\"hljs-string\">f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.self_attn.vision_expert_query_key_value.weight\"\
          </span>] = v\n        <span class=\"hljs-keyword\">elif</span> k.startswith(<span\
          \ class=\"hljs-string\">'mixins.rotary.vision_dense_list.'</span>) <span\
          \ class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\">str</span>(k).endswith(<span\
          \ class=\"hljs-string\">'.weight'</span>):\n            idx = <span class=\"\
          hljs-built_in\">str</span>(k).replace(<span class=\"hljs-string\">'mixins.rotary.vision_dense_list.'</span>,\
          \ <span class=\"hljs-string\">''</span>).replace(<span class=\"hljs-string\"\
          >'.weight'</span>, <span class=\"hljs-string\">''</span>)\n            new_state_dict[<span\
          \ class=\"hljs-string\">f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.self_attn.vision_expert_dense.weight\"\
          </span>] = v\n        <span class=\"hljs-comment\"># norm</span>\n     \
          \   <span class=\"hljs-keyword\">elif</span> k.startswith(<span class=\"\
          hljs-string\">'transformer.layers.'</span>) <span class=\"hljs-keyword\"\
          >and</span> <span class=\"hljs-built_in\">str</span>(k).endswith(<span class=\"\
          hljs-string\">'.input_layernorm.weight'</span>):\n            idx = <span\
          \ class=\"hljs-built_in\">str</span>(k).replace(<span class=\"hljs-string\"\
          >'transformer.layers.'</span>, <span class=\"hljs-string\">''</span>).replace(<span\
          \ class=\"hljs-string\">'.input_layernorm.weight'</span>, <span class=\"\
          hljs-string\">''</span>)\n            new_state_dict[<span class=\"hljs-string\"\
          >f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.input_layernorm.weight\"\
          </span>] = v\n        <span class=\"hljs-keyword\">elif</span> k.startswith(<span\
          \ class=\"hljs-string\">'transformer.layers.'</span>) <span class=\"hljs-keyword\"\
          >and</span> <span class=\"hljs-built_in\">str</span>(k).endswith(<span class=\"\
          hljs-string\">'.post_attention_layernorm.weight'</span>):\n            idx\
          \ = <span class=\"hljs-built_in\">str</span>(k).replace(<span class=\"hljs-string\"\
          >'transformer.layers.'</span>, <span class=\"hljs-string\">''</span>).replace(<span\
          \ class=\"hljs-string\">'.post_attention_layernorm.weight'</span>, <span\
          \ class=\"hljs-string\">''</span>)\n            new_state_dict[<span class=\"\
          hljs-string\">f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.post_attention_layernorm.weight\"\
          </span>] = v\n        <span class=\"hljs-comment\">#</span>\n        <span\
          \ class=\"hljs-keyword\">elif</span> k == <span class=\"hljs-string\">'transformer.word_embeddings.weight'</span>:\n\
          \            new_state_dict[<span class=\"hljs-string\">f\"model.embed_tokens.weight\"\
          </span>] = v\n        <span class=\"hljs-keyword\">elif</span> k == <span\
          \ class=\"hljs-string\">'transformer.final_layernorm.weight'</span>:\n \
          \           new_state_dict[<span class=\"hljs-string\">f\"model.norm.weight\"\
          </span>] = v\n        <span class=\"hljs-keyword\">elif</span> k == <span\
          \ class=\"hljs-string\">'mixins.rotary.rotary_emb.inv_freq'</span>:\n  \
          \          <span class=\"hljs-keyword\">for</span> idx <span class=\"hljs-keyword\"\
          >in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\"\
          >32</span>):\n                new_state_dict[<span class=\"hljs-string\"\
          >f\"model.layers.<span class=\"hljs-subst\">{idx}</span>.self_attn.rotary_emb.inv_freq\"\
          </span>] = v.clone()\n        <span class=\"hljs-keyword\">else</span>:\n\
          \            <span class=\"hljs-keyword\">assert</span> <span class=\"hljs-literal\"\
          >False</span>, <span class=\"hljs-string\">f\"<span class=\"hljs-subst\"\
          >{k}</span>\"</span>\n    new_state_dict.update(vision_state_dict)\n   \
          \ torch.save(new_state_dict, os.path.join(hf_dir, <span class=\"hljs-string\"\
          >'pytorch_model.bin'</span>))\n\n    <span class=\"hljs-comment\"># configs</span>\n\
          \    config = json.load(<span class=\"hljs-built_in\">open</span>(os.path.expanduser(os.path.join(sat_dir,\
          \ <span class=\"hljs-string\">'model_config.json'</span>))))\n    vision_config\
          \ = {\n        <span class=\"hljs-string\">'dropout_prob'</span>: <span\
          \ class=\"hljs-number\">0.0</span>,\n        <span class=\"hljs-string\"\
          >'hidden_act'</span>: <span class=\"hljs-string\">'gelu'</span>,\n     \
          \   <span class=\"hljs-string\">'in_channels'</span>: config[<span class=\"\
          hljs-string\">'eva_args'</span>][<span class=\"hljs-string\">'in_channels'</span>],\n\
          \        <span class=\"hljs-string\">'num_hidden_layers'</span>: config[<span\
          \ class=\"hljs-string\">'eva_args'</span>][<span class=\"hljs-string\">'num_layers'</span>],\n\
          \        <span class=\"hljs-string\">'hidden_size'</span>: config[<span\
          \ class=\"hljs-string\">'eva_args'</span>][<span class=\"hljs-string\">'hidden_size'</span>],\n\
          \        <span class=\"hljs-string\">'patch_size'</span>: config[<span class=\"\
          hljs-string\">'eva_args'</span>][<span class=\"hljs-string\">'patch_size'</span>],\n\
          \        <span class=\"hljs-string\">'num_heads'</span>: config[<span class=\"\
          hljs-string\">'eva_args'</span>][<span class=\"hljs-string\">'num_attention_heads'</span>],\n\
          \        <span class=\"hljs-string\">'intermediate_size'</span>: config[<span\
          \ class=\"hljs-string\">'eva_args'</span>][<span class=\"hljs-string\">'inner_hidden_size'</span>],\n\
          \        <span class=\"hljs-string\">'layer_norm_eps'</span>: config[<span\
          \ class=\"hljs-string\">'eva_args'</span>][<span class=\"hljs-string\">'layernorm_epsilon'</span>],\n\
          \        <span class=\"hljs-string\">'num_positions'</span>: <span class=\"\
          hljs-built_in\">int</span>(<span class=\"hljs-number\">1</span> + (config[<span\
          \ class=\"hljs-string\">'eva_args'</span>][<span class=\"hljs-string\">'image_size'</span>][<span\
          \ class=\"hljs-number\">0</span>] / config[<span class=\"hljs-string\">'eva_args'</span>][<span\
          \ class=\"hljs-string\">'patch_size'</span>]) * (\n                    config[<span\
          \ class=\"hljs-string\">'eva_args'</span>][<span class=\"hljs-string\">'image_size'</span>][<span\
          \ class=\"hljs-number\">0</span>] / config[<span class=\"hljs-string\">'eva_args'</span>][<span\
          \ class=\"hljs-string\">'patch_size'</span>])),\n        <span class=\"\
          hljs-comment\">#</span>\n        <span class=\"hljs-string\">'image_size'</span>:\
          \ config[<span class=\"hljs-string\">'eva_args'</span>][<span class=\"hljs-string\"\
          >'image_size'</span>][<span class=\"hljs-number\">0</span>],\n    }\n\n\
          \    final_config = {\n        <span class=\"hljs-string\">'vision_config'</span>:\
          \ vision_config,\n        <span class=\"hljs-string\">'hidden_size'</span>:\
          \ config[<span class=\"hljs-string\">'hidden_size'</span>],\n        <span\
          \ class=\"hljs-comment\">#</span>\n        <span class=\"hljs-string\">'intermediate_size'</span>:\
          \ config[<span class=\"hljs-string\">'inner_hidden_size'</span>],\n    \
          \    <span class=\"hljs-string\">'num_attention_heads'</span>: config[<span\
          \ class=\"hljs-string\">'num_attention_heads'</span>],\n        <span class=\"\
          hljs-string\">'max_position_embeddings'</span>: <span class=\"hljs-number\"\
          >2048</span>,\n        <span class=\"hljs-string\">'rms_norm_eps'</span>:\
          \ <span class=\"hljs-number\">1e-5</span>,\n        <span class=\"hljs-string\"\
          >'template_version'</span>: <span class=\"hljs-string\">'chat'</span> <span\
          \ class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">'chat'</span>\
          \ <span class=\"hljs-keyword\">in</span> sat_dir <span class=\"hljs-keyword\"\
          >else</span> <span class=\"hljs-string\">'base'</span>,\n        <span class=\"\
          hljs-string\">'initializer_range'</span>: <span class=\"hljs-number\">0.02</span>,\n\
          \        <span class=\"hljs-string\">'pad_token_id'</span>: <span class=\"\
          hljs-number\">0</span>,\n        <span class=\"hljs-string\">\"bos_token_id\"\
          </span>: <span class=\"hljs-number\">1</span>,\n        <span class=\"hljs-string\"\
          >\"eos_token_id\"</span>: <span class=\"hljs-number\">2</span>,\n      \
          \  <span class=\"hljs-comment\">#</span>\n        <span class=\"hljs-string\"\
          >'vocab_size'</span>: config[<span class=\"hljs-string\">'vocab_size'</span>],\n\
          \        <span class=\"hljs-string\">'num_hidden_layers'</span>: config[<span\
          \ class=\"hljs-string\">'num_layers'</span>],\n        <span class=\"hljs-string\"\
          >'hidden_act'</span>: <span class=\"hljs-string\">'silu'</span>,\n     \
          \   <span class=\"hljs-string\">'use_cache'</span>: <span class=\"hljs-literal\"\
          >True</span>,\n    }\n    <span class=\"hljs-keyword\">with</span> <span\
          \ class=\"hljs-built_in\">open</span>(os.path.join(hf_dir, <span class=\"\
          hljs-string\">'config.json'</span>), <span class=\"hljs-string\">'w'</span>)\
          \ <span class=\"hljs-keyword\">as</span> f:\n</code></pre>\n</details>"
        raw: "\u5C31\u662F\u628Astate_dict\u5185weights\u7684\u540D\u5B57\u66FF\u6362\
          \u4E0B\n<details>\n<summary> \u6709\u70B9\u4E11\u964B\u7684\u4EE3\u7801\
          \ </summary>\n\n\n```python\ndef vlm(\n        hf_dir: str,\n        sat_dir:\
          \ str,\n):\n    import os\n    import json\n    import torch\n    from pathlib\
          \ import Path\n    Path(hf_dir).mkdir(exist_ok=True)\n\n    # state dict\n\
          \    state_dict = torch.load(os.path.expanduser(os.path.join(sat_dir, '1',\
          \ 'mp_rank_00_model_states.pt')), map_location='cpu')\n    state_dict =\
          \ state_dict['module']\n    new_state_dict = {}\n    for k, v in state_dict.items():\n\
          \        if k.startswith('mixins.eva.vit_model.mixins.patch_embedding'):\n\
          \            new_state_dict[k.replace('mixins.eva.vit_model.mixins.', '',\
          \ 1)] = v\n        elif k.startswith('mixins.eva.vit_model.transformer.position_embeddings'):\n\
          \            new_state_dict[k.replace('mixins.eva.vit_model.transformer.position_embeddings',\
          \ 'patch_embedding.position_embedding', 1)] = v\n        elif k.startswith('mixins.eva.vit_model.transformer.layers'):\n\
          \            k = k.replace('mlp.dense_4h_to_h', 'mlp.fc2').replace('mlp.dense_h_to_4h',\
          \ 'mlp.fc1')\n            new_state_dict[k.replace('mixins.eva.vit_model.transformer.layers',\
          \ 'transformer.layers', 1)] = v\n        elif k.startswith('mixins.eva.linear_proj'):\n\
          \            new_state_dict[k.replace('mixins.eva.linear_proj', 'linear_proj',\
          \ 1)] = v\n        elif k in ['mixins.eva.vit_model.transformer.word_embeddings.weight']:\n\
          \            new_state_dict['patch_embedding.cls_embedding'] = v\n     \
          \   elif k in ['mixins.eva.boi', 'mixins.eva.eoi']:\n            new_state_dict[k.replace('mixins.eva.',\
          \ '', 1)] = v\n        else:\n            assert not str(k).startswith('mixins.eva'),\
          \ f\"{k}\"\n\n    vision_state_dict = {f\"model.vision.{k}\": v for k, v\
          \ in new_state_dict.items()}\n    new_state_dict = {}\n    for k, v in state_dict.items():\n\
          \        if k == 'mixins.lm.lm_head.weight':\n            new_state_dict['lm_head.weight']\
          \ = v\n        elif k.startswith(\"mixins.eva\"):\n            continue\n\
          \        # mlp\n        elif k.startswith('mixins.mlp.vision_dense_h_to_4h_list.')\
          \ and str(k).endswith('.weight'):\n            idx = str(k).replace('mixins.mlp.vision_dense_h_to_4h_list.',\
          \ '').replace('.weight', '')\n            new_state_dict[f\"model.layers.{idx}.mlp.vision_mlp.up_proj.weight\"\
          ] = v\n        elif k.startswith('mixins.mlp.vision_dense_4h_to_h_list.')\
          \ and str(k).endswith('.weight'):\n            idx = str(k).replace('mixins.mlp.vision_dense_4h_to_h_list.',\
          \ '').replace('.weight', '')\n            new_state_dict[f\"model.layers.{idx}.mlp.vision_mlp.down_proj.weight\"\
          ] = v\n        elif k.startswith('mixins.mlp.vision_gate_proj.') and str(k).endswith('.weight'):\n\
          \            idx = str(k).replace('mixins.mlp.vision_gate_proj.', '').replace('.weight',\
          \ '')\n            new_state_dict[f\"model.layers.{idx}.mlp.vision_mlp.gate_proj.weight\"\
          ] = v\n\n        elif k.startswith('mixins.mlp.gate_proj.') and str(k).endswith('.weight'):\n\
          \            idx = str(k).replace('mixins.mlp.gate_proj.', '').replace('.weight',\
          \ '')\n            new_state_dict[f\"model.layers.{idx}.mlp.language_mlp.gate_proj.weight\"\
          ] = v\n        elif k.startswith('transformer.layers.') and str(k).endswith('.mlp.dense_h_to_4h.weight'):\n\
          \            idx = str(k).replace('transformer.layers.', '').replace('.mlp.dense_h_to_4h.weight',\
          \ '')\n            new_state_dict[f\"model.layers.{idx}.mlp.language_mlp.up_proj.weight\"\
          ] = v\n        elif k.startswith('transformer.layers.') and str(k).endswith('.mlp.dense_4h_to_h.weight'):\n\
          \            idx = str(k).replace('transformer.layers.', '').replace('.mlp.dense_4h_to_h.weight',\
          \ '')\n            new_state_dict[f\"model.layers.{idx}.mlp.language_mlp.down_proj.weight\"\
          ] = v\n        # attn\n        elif k.startswith('transformer.layers.')\
          \ and str(k).endswith('.attention.query_key_value.weight'):\n          \
          \  idx = str(k).replace('transformer.layers.', '').replace('.attention.query_key_value.weight',\
          \ '')\n            new_state_dict[f\"model.layers.{idx}.self_attn.language_expert_query_key_value.weight\"\
          ] = v\n        elif k.startswith('transformer.layers.') and str(k).endswith('.attention.dense.weight'):\n\
          \            idx = str(k).replace('transformer.layers.', '').replace('.attention.dense.weight',\
          \ '')\n            new_state_dict[f\"model.layers.{idx}.self_attn.language_expert_dense.weight\"\
          ] = v\n\n        elif k.startswith('mixins.rotary.vision_query_key_value_list.')\
          \ and str(k).endswith('.weight'):\n            idx = str(k).replace('mixins.rotary.vision_query_key_value_list.',\
          \ '').replace('.weight', '')\n            new_state_dict[f\"model.layers.{idx}.self_attn.vision_expert_query_key_value.weight\"\
          ] = v\n        elif k.startswith('mixins.rotary.vision_dense_list.') and\
          \ str(k).endswith('.weight'):\n            idx = str(k).replace('mixins.rotary.vision_dense_list.',\
          \ '').replace('.weight', '')\n            new_state_dict[f\"model.layers.{idx}.self_attn.vision_expert_dense.weight\"\
          ] = v\n        # norm\n        elif k.startswith('transformer.layers.')\
          \ and str(k).endswith('.input_layernorm.weight'):\n            idx = str(k).replace('transformer.layers.',\
          \ '').replace('.input_layernorm.weight', '')\n            new_state_dict[f\"\
          model.layers.{idx}.input_layernorm.weight\"] = v\n        elif k.startswith('transformer.layers.')\
          \ and str(k).endswith('.post_attention_layernorm.weight'):\n           \
          \ idx = str(k).replace('transformer.layers.', '').replace('.post_attention_layernorm.weight',\
          \ '')\n            new_state_dict[f\"model.layers.{idx}.post_attention_layernorm.weight\"\
          ] = v\n        #\n        elif k == 'transformer.word_embeddings.weight':\n\
          \            new_state_dict[f\"model.embed_tokens.weight\"] = v\n      \
          \  elif k == 'transformer.final_layernorm.weight':\n            new_state_dict[f\"\
          model.norm.weight\"] = v\n        elif k == 'mixins.rotary.rotary_emb.inv_freq':\n\
          \            for idx in range(32):\n                new_state_dict[f\"model.layers.{idx}.self_attn.rotary_emb.inv_freq\"\
          ] = v.clone()\n        else:\n            assert False, f\"{k}\"\n    new_state_dict.update(vision_state_dict)\n\
          \    torch.save(new_state_dict, os.path.join(hf_dir, 'pytorch_model.bin'))\n\
          \n    # configs\n    config = json.load(open(os.path.expanduser(os.path.join(sat_dir,\
          \ 'model_config.json'))))\n    vision_config = {\n        'dropout_prob':\
          \ 0.0,\n        'hidden_act': 'gelu',\n        'in_channels': config['eva_args']['in_channels'],\n\
          \        'num_hidden_layers': config['eva_args']['num_layers'],\n      \
          \  'hidden_size': config['eva_args']['hidden_size'],\n        'patch_size':\
          \ config['eva_args']['patch_size'],\n        'num_heads': config['eva_args']['num_attention_heads'],\n\
          \        'intermediate_size': config['eva_args']['inner_hidden_size'],\n\
          \        'layer_norm_eps': config['eva_args']['layernorm_epsilon'],\n  \
          \      'num_positions': int(1 + (config['eva_args']['image_size'][0] / config['eva_args']['patch_size'])\
          \ * (\n                    config['eva_args']['image_size'][0] / config['eva_args']['patch_size'])),\n\
          \        #\n        'image_size': config['eva_args']['image_size'][0],\n\
          \    }\n\n    final_config = {\n        'vision_config': vision_config,\n\
          \        'hidden_size': config['hidden_size'],\n        #\n        'intermediate_size':\
          \ config['inner_hidden_size'],\n        'num_attention_heads': config['num_attention_heads'],\n\
          \        'max_position_embeddings': 2048,\n        'rms_norm_eps': 1e-5,\n\
          \        'template_version': 'chat' if 'chat' in sat_dir else 'base',\n\
          \        'initializer_range': 0.02,\n        'pad_token_id': 0,\n      \
          \  \"bos_token_id\": 1,\n        \"eos_token_id\": 2,\n        #\n     \
          \   'vocab_size': config['vocab_size'],\n        'num_hidden_layers': config['num_layers'],\n\
          \        'hidden_act': 'silu',\n        'use_cache': True,\n    }\n    with\
          \ open(os.path.join(hf_dir, 'config.json'), 'w') as f:\n```\n\n</details>"
        updatedAt: '2023-12-15T03:33:16.655Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jizhongpeng
    id: 657bc87a3bc822bb71a87b43
    type: comment
  author: chenkq
  content: "\u5C31\u662F\u628Astate_dict\u5185weights\u7684\u540D\u5B57\u66FF\u6362\
    \u4E0B\n<details>\n<summary> \u6709\u70B9\u4E11\u964B\u7684\u4EE3\u7801 </summary>\n\
    \n\n```python\ndef vlm(\n        hf_dir: str,\n        sat_dir: str,\n):\n   \
    \ import os\n    import json\n    import torch\n    from pathlib import Path\n\
    \    Path(hf_dir).mkdir(exist_ok=True)\n\n    # state dict\n    state_dict = torch.load(os.path.expanduser(os.path.join(sat_dir,\
    \ '1', 'mp_rank_00_model_states.pt')), map_location='cpu')\n    state_dict = state_dict['module']\n\
    \    new_state_dict = {}\n    for k, v in state_dict.items():\n        if k.startswith('mixins.eva.vit_model.mixins.patch_embedding'):\n\
    \            new_state_dict[k.replace('mixins.eva.vit_model.mixins.', '', 1)]\
    \ = v\n        elif k.startswith('mixins.eva.vit_model.transformer.position_embeddings'):\n\
    \            new_state_dict[k.replace('mixins.eva.vit_model.transformer.position_embeddings',\
    \ 'patch_embedding.position_embedding', 1)] = v\n        elif k.startswith('mixins.eva.vit_model.transformer.layers'):\n\
    \            k = k.replace('mlp.dense_4h_to_h', 'mlp.fc2').replace('mlp.dense_h_to_4h',\
    \ 'mlp.fc1')\n            new_state_dict[k.replace('mixins.eva.vit_model.transformer.layers',\
    \ 'transformer.layers', 1)] = v\n        elif k.startswith('mixins.eva.linear_proj'):\n\
    \            new_state_dict[k.replace('mixins.eva.linear_proj', 'linear_proj',\
    \ 1)] = v\n        elif k in ['mixins.eva.vit_model.transformer.word_embeddings.weight']:\n\
    \            new_state_dict['patch_embedding.cls_embedding'] = v\n        elif\
    \ k in ['mixins.eva.boi', 'mixins.eva.eoi']:\n            new_state_dict[k.replace('mixins.eva.',\
    \ '', 1)] = v\n        else:\n            assert not str(k).startswith('mixins.eva'),\
    \ f\"{k}\"\n\n    vision_state_dict = {f\"model.vision.{k}\": v for k, v in new_state_dict.items()}\n\
    \    new_state_dict = {}\n    for k, v in state_dict.items():\n        if k ==\
    \ 'mixins.lm.lm_head.weight':\n            new_state_dict['lm_head.weight'] =\
    \ v\n        elif k.startswith(\"mixins.eva\"):\n            continue\n      \
    \  # mlp\n        elif k.startswith('mixins.mlp.vision_dense_h_to_4h_list.') and\
    \ str(k).endswith('.weight'):\n            idx = str(k).replace('mixins.mlp.vision_dense_h_to_4h_list.',\
    \ '').replace('.weight', '')\n            new_state_dict[f\"model.layers.{idx}.mlp.vision_mlp.up_proj.weight\"\
    ] = v\n        elif k.startswith('mixins.mlp.vision_dense_4h_to_h_list.') and\
    \ str(k).endswith('.weight'):\n            idx = str(k).replace('mixins.mlp.vision_dense_4h_to_h_list.',\
    \ '').replace('.weight', '')\n            new_state_dict[f\"model.layers.{idx}.mlp.vision_mlp.down_proj.weight\"\
    ] = v\n        elif k.startswith('mixins.mlp.vision_gate_proj.') and str(k).endswith('.weight'):\n\
    \            idx = str(k).replace('mixins.mlp.vision_gate_proj.', '').replace('.weight',\
    \ '')\n            new_state_dict[f\"model.layers.{idx}.mlp.vision_mlp.gate_proj.weight\"\
    ] = v\n\n        elif k.startswith('mixins.mlp.gate_proj.') and str(k).endswith('.weight'):\n\
    \            idx = str(k).replace('mixins.mlp.gate_proj.', '').replace('.weight',\
    \ '')\n            new_state_dict[f\"model.layers.{idx}.mlp.language_mlp.gate_proj.weight\"\
    ] = v\n        elif k.startswith('transformer.layers.') and str(k).endswith('.mlp.dense_h_to_4h.weight'):\n\
    \            idx = str(k).replace('transformer.layers.', '').replace('.mlp.dense_h_to_4h.weight',\
    \ '')\n            new_state_dict[f\"model.layers.{idx}.mlp.language_mlp.up_proj.weight\"\
    ] = v\n        elif k.startswith('transformer.layers.') and str(k).endswith('.mlp.dense_4h_to_h.weight'):\n\
    \            idx = str(k).replace('transformer.layers.', '').replace('.mlp.dense_4h_to_h.weight',\
    \ '')\n            new_state_dict[f\"model.layers.{idx}.mlp.language_mlp.down_proj.weight\"\
    ] = v\n        # attn\n        elif k.startswith('transformer.layers.') and str(k).endswith('.attention.query_key_value.weight'):\n\
    \            idx = str(k).replace('transformer.layers.', '').replace('.attention.query_key_value.weight',\
    \ '')\n            new_state_dict[f\"model.layers.{idx}.self_attn.language_expert_query_key_value.weight\"\
    ] = v\n        elif k.startswith('transformer.layers.') and str(k).endswith('.attention.dense.weight'):\n\
    \            idx = str(k).replace('transformer.layers.', '').replace('.attention.dense.weight',\
    \ '')\n            new_state_dict[f\"model.layers.{idx}.self_attn.language_expert_dense.weight\"\
    ] = v\n\n        elif k.startswith('mixins.rotary.vision_query_key_value_list.')\
    \ and str(k).endswith('.weight'):\n            idx = str(k).replace('mixins.rotary.vision_query_key_value_list.',\
    \ '').replace('.weight', '')\n            new_state_dict[f\"model.layers.{idx}.self_attn.vision_expert_query_key_value.weight\"\
    ] = v\n        elif k.startswith('mixins.rotary.vision_dense_list.') and str(k).endswith('.weight'):\n\
    \            idx = str(k).replace('mixins.rotary.vision_dense_list.', '').replace('.weight',\
    \ '')\n            new_state_dict[f\"model.layers.{idx}.self_attn.vision_expert_dense.weight\"\
    ] = v\n        # norm\n        elif k.startswith('transformer.layers.') and str(k).endswith('.input_layernorm.weight'):\n\
    \            idx = str(k).replace('transformer.layers.', '').replace('.input_layernorm.weight',\
    \ '')\n            new_state_dict[f\"model.layers.{idx}.input_layernorm.weight\"\
    ] = v\n        elif k.startswith('transformer.layers.') and str(k).endswith('.post_attention_layernorm.weight'):\n\
    \            idx = str(k).replace('transformer.layers.', '').replace('.post_attention_layernorm.weight',\
    \ '')\n            new_state_dict[f\"model.layers.{idx}.post_attention_layernorm.weight\"\
    ] = v\n        #\n        elif k == 'transformer.word_embeddings.weight':\n  \
    \          new_state_dict[f\"model.embed_tokens.weight\"] = v\n        elif k\
    \ == 'transformer.final_layernorm.weight':\n            new_state_dict[f\"model.norm.weight\"\
    ] = v\n        elif k == 'mixins.rotary.rotary_emb.inv_freq':\n            for\
    \ idx in range(32):\n                new_state_dict[f\"model.layers.{idx}.self_attn.rotary_emb.inv_freq\"\
    ] = v.clone()\n        else:\n            assert False, f\"{k}\"\n    new_state_dict.update(vision_state_dict)\n\
    \    torch.save(new_state_dict, os.path.join(hf_dir, 'pytorch_model.bin'))\n\n\
    \    # configs\n    config = json.load(open(os.path.expanduser(os.path.join(sat_dir,\
    \ 'model_config.json'))))\n    vision_config = {\n        'dropout_prob': 0.0,\n\
    \        'hidden_act': 'gelu',\n        'in_channels': config['eva_args']['in_channels'],\n\
    \        'num_hidden_layers': config['eva_args']['num_layers'],\n        'hidden_size':\
    \ config['eva_args']['hidden_size'],\n        'patch_size': config['eva_args']['patch_size'],\n\
    \        'num_heads': config['eva_args']['num_attention_heads'],\n        'intermediate_size':\
    \ config['eva_args']['inner_hidden_size'],\n        'layer_norm_eps': config['eva_args']['layernorm_epsilon'],\n\
    \        'num_positions': int(1 + (config['eva_args']['image_size'][0] / config['eva_args']['patch_size'])\
    \ * (\n                    config['eva_args']['image_size'][0] / config['eva_args']['patch_size'])),\n\
    \        #\n        'image_size': config['eva_args']['image_size'][0],\n    }\n\
    \n    final_config = {\n        'vision_config': vision_config,\n        'hidden_size':\
    \ config['hidden_size'],\n        #\n        'intermediate_size': config['inner_hidden_size'],\n\
    \        'num_attention_heads': config['num_attention_heads'],\n        'max_position_embeddings':\
    \ 2048,\n        'rms_norm_eps': 1e-5,\n        'template_version': 'chat' if\
    \ 'chat' in sat_dir else 'base',\n        'initializer_range': 0.02,\n       \
    \ 'pad_token_id': 0,\n        \"bos_token_id\": 1,\n        \"eos_token_id\":\
    \ 2,\n        #\n        'vocab_size': config['vocab_size'],\n        'num_hidden_layers':\
    \ config['num_layers'],\n        'hidden_act': 'silu',\n        'use_cache': True,\n\
    \    }\n    with open(os.path.join(hf_dir, 'config.json'), 'w') as f:\n```\n\n\
    </details>"
  created_at: 2023-12-15 03:31:06+00:00
  edited: true
  hidden: false
  id: 657bc87a3bc822bb71a87b43
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c562010582243dada12f477234963872.svg
      fullname: kaihan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wkh666
      type: user
    createdAt: '2023-12-15T03:47:07.000Z'
    data:
      edited: false
      editors:
      - wkh666
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9095081686973572
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c562010582243dada12f477234963872.svg
          fullname: kaihan
          isHf: false
          isPro: false
          name: wkh666
          type: user
        html: '<p>Thank you very much!</p>

          '
        raw: Thank you very much!
        updatedAt: '2023-12-15T03:47:07.630Z'
      numEdits: 0
      reactions: []
    id: 657bcc3be34a7de14b0c896a
    type: comment
  author: wkh666
  content: Thank you very much!
  created_at: 2023-12-15 03:47:07+00:00
  edited: false
  hidden: false
  id: 657bcc3be34a7de14b0c896a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/0d95d65d30f6672ec09dc92155324d7f.svg
      fullname: chenkq
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: chenkq
      type: user
    createdAt: '2023-12-15T03:58:42.000Z'
    data:
      status: closed
    id: 657bcef26b314373ed633e12
    type: status-change
  author: chenkq
  created_at: 2023-12-15 03:58:42+00:00
  id: 657bcef26b314373ed633e12
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: THUDM/CogVLM
repo_type: model
status: closed
target_branch: null
title: The files in the zip compression package seem to be different from the files
  named -hf, I would like to ask what is the difference between the two?
