!!python/object:huggingface_hub.community.DiscussionWithDetails
author: thefaheem
conflicting_files: null
created_at: 2023-05-19 17:05:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
      fullname: Mohammed Faheem
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thefaheem
      type: user
    createdAt: '2023-05-19T18:05:20.000Z'
    data:
      edited: false
      editors:
      - thefaheem
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
          fullname: Mohammed Faheem
          isHf: false
          isPro: false
          name: thefaheem
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ First of all Thanks for your work for the community man! </p>\n<p>I'm\
          \ Asking You, Why Don't You Create Quantized Model For RWKV. it would be\
          \ very very helpful to me and the community?</p>\n"
        raw: "Hey @TheBloke First of all Thanks for your work for the community man!\
          \ \r\n\r\nI'm Asking You, Why Don't You Create Quantized Model For RWKV.\
          \ it would be very very helpful to me and the community?"
        updatedAt: '2023-05-19T18:05:20.126Z'
      numEdits: 0
      reactions: []
    id: 6467ba60a9b4610868a3812d
    type: comment
  author: thefaheem
  content: "Hey @TheBloke First of all Thanks for your work for the community man!\
    \ \r\n\r\nI'm Asking You, Why Don't You Create Quantized Model For RWKV. it would\
    \ be very very helpful to me and the community?"
  created_at: 2023-05-19 17:05:20+00:00
  edited: false
  hidden: false
  id: 6467ba60a9b4610868a3812d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
      fullname: Daniel Duval
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dduval
      type: user
    createdAt: '2023-05-19T19:13:20.000Z'
    data:
      edited: false
      editors:
      - dduval
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
          fullname: Daniel Duval
          isHf: false
          isPro: false
          name: dduval
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;thefaheem&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/thefaheem\">@<span class=\"\
          underline\">thefaheem</span></a></span>\n\n\t</span></span>, xzuyn have\
          \ released some: <a href=\"https://huggingface.co/models?sort=modified&amp;search=xzuyn+rwkv+raven+ggml\"\
          >https://huggingface.co/models?sort=modified&amp;search=xzuyn+rwkv+raven+ggml</a></p>\n"
        raw: '@thefaheem, xzuyn have released some: https://huggingface.co/models?sort=modified&search=xzuyn+rwkv+raven+ggml'
        updatedAt: '2023-05-19T19:13:20.577Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - PrimeD
        - thefaheem
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - thefaheem
    id: 6467ca50e92e2372d5d3eaac
    type: comment
  author: dduval
  content: '@thefaheem, xzuyn have released some: https://huggingface.co/models?sort=modified&search=xzuyn+rwkv+raven+ggml'
  created_at: 2023-05-19 18:13:20+00:00
  edited: false
  hidden: false
  id: 6467ca50e92e2372d5d3eaac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
      fullname: Mohammed Faheem
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thefaheem
      type: user
    createdAt: '2023-05-20T02:41:16.000Z'
    data:
      edited: false
      editors:
      - thefaheem
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
          fullname: Mohammed Faheem
          isHf: false
          isPro: false
          name: thefaheem
          type: user
        html: "<p>yo! I Searched But Never Got This Result...</p>\n<p>Thanks <span\
          \ data-props=\"{&quot;user&quot;:&quot;dduval&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/dduval\">@<span class=\"underline\"\
          >dduval</span></a></span>\n\n\t</span></span></p>\n"
        raw: 'yo! I Searched But Never Got This Result...


          Thanks @dduval'
        updatedAt: '2023-05-20T02:41:16.689Z'
      numEdits: 0
      reactions: []
    id: 6468334ca48c2b6f0d6b6b79
    type: comment
  author: thefaheem
  content: 'yo! I Searched But Never Got This Result...


    Thanks @dduval'
  created_at: 2023-05-20 01:41:16+00:00
  edited: false
  hidden: false
  id: 6468334ca48c2b6f0d6b6b79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
      fullname: Mohammed Faheem
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thefaheem
      type: user
    createdAt: '2023-05-20T02:41:30.000Z'
    data:
      status: closed
    id: 6468335a3a7c8dda230f8ad7
    type: status-change
  author: thefaheem
  created_at: 2023-05-20 01:41:30+00:00
  id: 6468335a3a7c8dda230f8ad7
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
      fullname: Mohammed Faheem
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thefaheem
      type: user
    createdAt: '2023-05-20T03:10:54.000Z'
    data:
      edited: false
      editors:
      - thefaheem
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
          fullname: Mohammed Faheem
          isHf: false
          isPro: false
          name: thefaheem
          type: user
        html: '<p>I Can''t use it with LLama cpp python, it gives a value error. I
          Think its because RWKV is not Decoder Architecture and its not unidirectional.</p>

          <p>So, What Should I Use To Run These?</p>

          <p>Can Anyone Help?</p>

          '
        raw: 'I Can''t use it with LLama cpp python, it gives a value error. I Think
          its because RWKV is not Decoder Architecture and its not unidirectional.


          So, What Should I Use To Run These?


          Can Anyone Help?'
        updatedAt: '2023-05-20T03:10:54.866Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64683a3e3a7c8dda230fda5a
    id: 64683a3e3a7c8dda230fda59
    type: comment
  author: thefaheem
  content: 'I Can''t use it with LLama cpp python, it gives a value error. I Think
    its because RWKV is not Decoder Architecture and its not unidirectional.


    So, What Should I Use To Run These?


    Can Anyone Help?'
  created_at: 2023-05-20 02:10:54+00:00
  edited: false
  hidden: false
  id: 64683a3e3a7c8dda230fda59
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
      fullname: Mohammed Faheem
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thefaheem
      type: user
    createdAt: '2023-05-20T03:10:54.000Z'
    data:
      status: open
    id: 64683a3e3a7c8dda230fda5a
    type: status-change
  author: thefaheem
  created_at: 2023-05-20 02:10:54+00:00
  id: 64683a3e3a7c8dda230fda5a
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
      fullname: Daniel Duval
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dduval
      type: user
    createdAt: '2023-05-20T03:23:02.000Z'
    data:
      edited: true
      editors:
      - dduval
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
          fullname: Daniel Duval
          isHf: false
          isPro: false
          name: dduval
          type: user
        html: '<p>It worked for me with koboldcpp: <a rel="nofollow" href="https://github.com/LostRuins/koboldcpp">https://github.com/LostRuins/koboldcpp</a><br>I
          only had time to try the 14B q5_1.</p>

          '
        raw: 'It worked for me with koboldcpp: https://github.com/LostRuins/koboldcpp

          I only had time to try the 14B q5_1.'
        updatedAt: '2023-05-20T03:25:02.569Z'
      numEdits: 1
      reactions: []
    id: 64683d16a48c2b6f0d6bddbe
    type: comment
  author: dduval
  content: 'It worked for me with koboldcpp: https://github.com/LostRuins/koboldcpp

    I only had time to try the 14B q5_1.'
  created_at: 2023-05-20 02:23:02+00:00
  edited: true
  hidden: false
  id: 64683d16a48c2b6f0d6bddbe
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
      fullname: Mohammed Faheem
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thefaheem
      type: user
    createdAt: '2023-05-20T03:33:00.000Z'
    data:
      edited: true
      editors:
      - thefaheem
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
          fullname: Mohammed Faheem
          isHf: false
          isPro: false
          name: thefaheem
          type: user
        html: '<p>I''m a Dumb. Can You Please Tell me How to Run in linux or colab</p>

          '
        raw: I'm a Dumb. Can You Please Tell me How to Run in linux or colab
        updatedAt: '2023-05-20T03:34:14.111Z'
      numEdits: 1
      reactions: []
    id: 64683f6c3a7c8dda231017ee
    type: comment
  author: thefaheem
  content: I'm a Dumb. Can You Please Tell me How to Run in linux or colab
  created_at: 2023-05-20 02:33:00+00:00
  edited: true
  hidden: false
  id: 64683f6c3a7c8dda231017ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
      fullname: Daniel Duval
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dduval
      type: user
    createdAt: '2023-05-20T03:52:10.000Z'
    data:
      edited: false
      editors:
      - dduval
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
          fullname: Daniel Duval
          isHf: false
          isPro: false
          name: dduval
          type: user
        html: '<p>Instructions for Windows:</p>

          <ol>

          <li>Download the latest release: <a rel="nofollow" href="https://github.com/LostRuins/koboldcpp/releases/latest/download/koboldcpp.exe">https://github.com/LostRuins/koboldcpp/releases/latest/download/koboldcpp.exe</a></li>

          <li>double-click koboldcpp.exe</li>

          <li>click Launch and open your model .bin file</li>

          </ol>

          <p>That''s it! You may be able to improve performance if you launch it from
          command prompt and set a number of threads and give high priority to the
          process. Run koboldcpp.exe --help to see all the options. I launch it using
          the following command: koboldcpp.exe ggml-model-q5_1.bin --launch --threads
          16 --highpriority --smartcontext</p>

          '
        raw: 'Instructions for Windows:

          1. Download the latest release: https://github.com/LostRuins/koboldcpp/releases/latest/download/koboldcpp.exe

          2. double-click koboldcpp.exe

          3. click Launch and open your model .bin file


          That''s it! You may be able to improve performance if you launch it from
          command prompt and set a number of threads and give high priority to the
          process. Run koboldcpp.exe --help to see all the options. I launch it using
          the following command: koboldcpp.exe ggml-model-q5_1.bin --launch --threads
          16 --highpriority --smartcontext'
        updatedAt: '2023-05-20T03:52:10.299Z'
      numEdits: 0
      reactions: []
    id: 646843eaab75d9cb3c52798e
    type: comment
  author: dduval
  content: 'Instructions for Windows:

    1. Download the latest release: https://github.com/LostRuins/koboldcpp/releases/latest/download/koboldcpp.exe

    2. double-click koboldcpp.exe

    3. click Launch and open your model .bin file


    That''s it! You may be able to improve performance if you launch it from command
    prompt and set a number of threads and give high priority to the process. Run
    koboldcpp.exe --help to see all the options. I launch it using the following command:
    koboldcpp.exe ggml-model-q5_1.bin --launch --threads 16 --highpriority --smartcontext'
  created_at: 2023-05-20 02:52:10+00:00
  edited: false
  hidden: false
  id: 646843eaab75d9cb3c52798e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
      fullname: Mohammed Faheem
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thefaheem
      type: user
    createdAt: '2023-05-20T03:53:41.000Z'
    data:
      edited: false
      editors:
      - thefaheem
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
          fullname: Mohammed Faheem
          isHf: false
          isPro: false
          name: thefaheem
          type: user
        html: '<p>For Linux?..</p>

          '
        raw: For Linux?..
        updatedAt: '2023-05-20T03:53:41.724Z'
      numEdits: 0
      reactions: []
    id: 64684445a48c2b6f0d6c3467
    type: comment
  author: thefaheem
  content: For Linux?..
  created_at: 2023-05-20 02:53:41+00:00
  edited: false
  hidden: false
  id: 64684445a48c2b6f0d6c3467
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
      fullname: Daniel Duval
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dduval
      type: user
    createdAt: '2023-05-20T03:59:57.000Z'
    data:
      edited: true
      editors:
      - dduval
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4dce85c104456948d6668b2c8109b4f4.svg
          fullname: Daniel Duval
          isHf: false
          isPro: false
          name: dduval
          type: user
        html: '<p>I have yet to try koboldcpp on Linux. Check the README.md on the
          GitHub page for Linux instructions. I see that oobabooga''s text-generation-webui
          should support RWKV as well: <a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui/blob/main/docs/RWKV-model.md">https://github.com/oobabooga/text-generation-webui/blob/main/docs/RWKV-model.md</a></p>

          <p>Edit: I just realized that you specifically asked for linux or colab,
          and I gave you Windows instructions. Sorry for that. As for oobabooga, I
          may be wrong, but I don''t think it supports quantized versions.</p>

          '
        raw: 'I have yet to try koboldcpp on Linux. Check the README.md on the GitHub
          page for Linux instructions. I see that oobabooga''s text-generation-webui
          should support RWKV as well: https://github.com/oobabooga/text-generation-webui/blob/main/docs/RWKV-model.md


          Edit: I just realized that you specifically asked for linux or colab, and
          I gave you Windows instructions. Sorry for that. As for oobabooga, I may
          be wrong, but I don''t think it supports quantized versions.'
        updatedAt: '2023-05-20T04:09:59.041Z'
      numEdits: 1
      reactions: []
    id: 646845bde92e2372d5da319d
    type: comment
  author: dduval
  content: 'I have yet to try koboldcpp on Linux. Check the README.md on the GitHub
    page for Linux instructions. I see that oobabooga''s text-generation-webui should
    support RWKV as well: https://github.com/oobabooga/text-generation-webui/blob/main/docs/RWKV-model.md


    Edit: I just realized that you specifically asked for linux or colab, and I gave
    you Windows instructions. Sorry for that. As for oobabooga, I may be wrong, but
    I don''t think it supports quantized versions.'
  created_at: 2023-05-20 02:59:57+00:00
  edited: true
  hidden: false
  id: 646845bde92e2372d5da319d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
      fullname: Mohammed Faheem
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thefaheem
      type: user
    createdAt: '2023-05-20T08:45:52.000Z'
    data:
      edited: false
      editors:
      - thefaheem
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
          fullname: Mohammed Faheem
          isHf: false
          isPro: false
          name: thefaheem
          type: user
        html: '<p>No Problem Mate, I Found it to be works well with rwkv.cpp.</p>

          <p>Anyways Thanks For Your Help...</p>

          '
        raw: 'No Problem Mate, I Found it to be works well with rwkv.cpp.


          Anyways Thanks For Your Help...'
        updatedAt: '2023-05-20T08:45:52.144Z'
      numEdits: 0
      reactions: []
      relatedEventId: 646888c099182de178440327
    id: 646888c099182de178440326
    type: comment
  author: thefaheem
  content: 'No Problem Mate, I Found it to be works well with rwkv.cpp.


    Anyways Thanks For Your Help...'
  created_at: 2023-05-20 07:45:52+00:00
  edited: false
  hidden: false
  id: 646888c099182de178440326
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1679399646223-noauth.png?w=200&h=200&f=face
      fullname: Mohammed Faheem
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thefaheem
      type: user
    createdAt: '2023-05-20T08:45:52.000Z'
    data:
      status: closed
    id: 646888c099182de178440327
    type: status-change
  author: thefaheem
  created_at: 2023-05-20 07:45:52+00:00
  id: 646888c099182de178440327
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Manticore-13B-GGML
repo_type: model
status: closed
target_branch: null
title: RWKV Quantisation
