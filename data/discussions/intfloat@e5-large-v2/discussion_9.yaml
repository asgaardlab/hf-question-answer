!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Suijhin
conflicting_files: null
created_at: 2023-07-05 00:23:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a17e7e1154acf7617d6eaf1699e18f9a.svg
      fullname: Varun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Suijhin
      type: user
    createdAt: '2023-07-05T01:23:29.000Z'
    data:
      edited: false
      editors:
      - Suijhin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.964213490486145
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a17e7e1154acf7617d6eaf1699e18f9a.svg
          fullname: Varun
          isHf: false
          isPro: false
          name: Suijhin
          type: user
        html: '<p>Hi,<br>I just wanted to know if its possible to get the dimension
          of the embedding as 512, without training again</p>

          '
        raw: "Hi,\r\nI just wanted to know if its possible to get the dimension of\
          \ the embedding as 512, without training again"
        updatedAt: '2023-07-05T01:23:29.047Z'
      numEdits: 0
      reactions: []
    id: 64a4c6114a1f142c2b22d272
    type: comment
  author: Suijhin
  content: "Hi,\r\nI just wanted to know if its possible to get the dimension of the\
    \ embedding as 512, without training again"
  created_at: 2023-07-05 00:23:29+00:00
  edited: false
  hidden: false
  id: 64a4c6114a1f142c2b22d272
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
      fullname: Liang Wang
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: intfloat
      type: user
    createdAt: '2023-07-05T09:00:13.000Z'
    data:
      edited: false
      editors:
      - intfloat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9404521584510803
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5a1ee74c2dbe349a6ec9843a1599d281.svg
          fullname: Liang Wang
          isHf: false
          isPro: false
          name: intfloat
          type: user
        html: '<p>As far as I know, there is no obvious way to do this without training.</p>

          <p>But you can reduce the storage cost by using compression techniques like
          product quantization, which has a nice implementation in <a rel="nofollow"
          href="https://github.com/facebookresearch/faiss">FAISS</a>.</p>

          '
        raw: 'As far as I know, there is no obvious way to do this without training.


          But you can reduce the storage cost by using compression techniques like
          product quantization, which has a nice implementation in [FAISS](https://github.com/facebookresearch/faiss).'
        updatedAt: '2023-07-05T09:00:13.420Z'
      numEdits: 0
      reactions: []
    id: 64a5311d4260367c11a01194
    type: comment
  author: intfloat
  content: 'As far as I know, there is no obvious way to do this without training.


    But you can reduce the storage cost by using compression techniques like product
    quantization, which has a nice implementation in [FAISS](https://github.com/facebookresearch/faiss).'
  created_at: 2023-07-05 08:00:13+00:00
  edited: false
  hidden: false
  id: 64a5311d4260367c11a01194
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: intfloat/e5-large-v2
repo_type: model
status: open
target_branch: null
title: Changing the dimensions of the embeddings
