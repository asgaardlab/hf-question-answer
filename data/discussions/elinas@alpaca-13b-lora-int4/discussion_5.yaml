!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Fenfel
conflicting_files: null
created_at: 2023-04-02 05:43:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63e3ce7099a032b1c952ea09/GBKxnHY-OkGXhzxEJK-AD.png?w=200&h=200&f=face
      fullname: Anton Meller
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Fenfel
      type: user
    createdAt: '2023-04-02T06:43:37.000Z'
    data:
      edited: false
      editors:
      - Fenfel
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63e3ce7099a032b1c952ea09/GBKxnHY-OkGXhzxEJK-AD.png?w=200&h=200&f=face
          fullname: Anton Meller
          isHf: false
          isPro: false
          name: Fenfel
          type: user
        html: '<p>What is the output tokens limit for generating coherent text? At
          2000 the bot writes something like random comments from the Internet</p>

          '
        raw: What is the output tokens limit for generating coherent text? At 2000
          the bot writes something like random comments from the Internet
        updatedAt: '2023-04-02T06:43:37.271Z'
      numEdits: 0
      reactions: []
    id: 6429241975bcc24c5e527d4c
    type: comment
  author: Fenfel
  content: What is the output tokens limit for generating coherent text? At 2000 the
    bot writes something like random comments from the Internet
  created_at: 2023-04-02 05:43:37+00:00
  edited: false
  hidden: false
  id: 6429241975bcc24c5e527d4c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
      fullname: elinas
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: elinas
      type: user
    createdAt: '2023-04-02T16:54:46.000Z'
    data:
      edited: false
      editors:
      - elinas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
          fullname: elinas
          isHf: false
          isPro: false
          name: elinas
          type: user
        html: '<p>The max context size is 2048. If you generate past that it will
          start losing the initial context.</p>

          '
        raw: The max context size is 2048. If you generate past that it will start
          losing the initial context.
        updatedAt: '2023-04-02T16:54:46.833Z'
      numEdits: 0
      reactions: []
    id: 6429b3566801699f7c3f9023
    type: comment
  author: elinas
  content: The max context size is 2048. If you generate past that it will start losing
    the initial context.
  created_at: 2023-04-02 15:54:46+00:00
  edited: false
  hidden: false
  id: 6429b3566801699f7c3f9023
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63e3ce7099a032b1c952ea09/GBKxnHY-OkGXhzxEJK-AD.png?w=200&h=200&f=face
      fullname: Anton Meller
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Fenfel
      type: user
    createdAt: '2023-04-02T17:06:53.000Z'
    data:
      edited: false
      editors:
      - Fenfel
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63e3ce7099a032b1c952ea09/GBKxnHY-OkGXhzxEJK-AD.png?w=200&h=200&f=face
          fullname: Anton Meller
          isHf: false
          isPro: false
          name: Fenfel
          type: user
        html: '<blockquote>

          <p>The max context size is 2048. If you generate past that it will start
          losing the initial context.</p>

          </blockquote>

          <p>I mean "max new tokens". 200 is normal and sometimes is good (like ChatGPT
          answer) but 2000 is worse and incoherently at all</p>

          '
        raw: '> The max context size is 2048. If you generate past that it will start
          losing the initial context.


          I mean "max new tokens". 200 is normal and sometimes is good (like ChatGPT
          answer) but 2000 is worse and incoherently at all'
        updatedAt: '2023-04-02T17:06:53.819Z'
      numEdits: 0
      reactions: []
    id: 6429b62d6801699f7c3f9f5c
    type: comment
  author: Fenfel
  content: '> The max context size is 2048. If you generate past that it will start
    losing the initial context.


    I mean "max new tokens". 200 is normal and sometimes is good (like ChatGPT answer)
    but 2000 is worse and incoherently at all'
  created_at: 2023-04-02 16:06:53+00:00
  edited: false
  hidden: false
  id: 6429b62d6801699f7c3f9f5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
      fullname: elinas
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: elinas
      type: user
    createdAt: '2023-04-02T17:10:22.000Z'
    data:
      edited: false
      editors:
      - elinas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
          fullname: elinas
          isHf: false
          isPro: false
          name: elinas
          type: user
        html: "<p>Then don\u2019t use 2000 tokens. The dataset doesn\u2019t include\
          \ such long answers as far as I know. When does chatgpt give you that long\
          \ of a response anyway?</p>\n"
        raw: "Then don\u2019t use 2000 tokens. The dataset doesn\u2019t include such\
          \ long answers as far as I know. When does chatgpt give you that long of\
          \ a response anyway?"
        updatedAt: '2023-04-02T17:10:22.886Z'
      numEdits: 0
      reactions: []
    id: 6429b6fec9f3ac3c754a513a
    type: comment
  author: elinas
  content: "Then don\u2019t use 2000 tokens. The dataset doesn\u2019t include such\
    \ long answers as far as I know. When does chatgpt give you that long of a response\
    \ anyway?"
  created_at: 2023-04-02 16:10:22+00:00
  edited: false
  hidden: false
  id: 6429b6fec9f3ac3c754a513a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63e3ce7099a032b1c952ea09/GBKxnHY-OkGXhzxEJK-AD.png?w=200&h=200&f=face
      fullname: Anton Meller
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Fenfel
      type: user
    createdAt: '2023-04-02T17:22:58.000Z'
    data:
      edited: false
      editors:
      - Fenfel
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63e3ce7099a032b1c952ea09/GBKxnHY-OkGXhzxEJK-AD.png?w=200&h=200&f=face
          fullname: Anton Meller
          isHf: false
          isPro: false
          name: Fenfel
          type: user
        html: "<blockquote>\n<p>Then don\u2019t use 2000 tokens. The dataset doesn\u2019\
          t include such long answers as far as I know. When does chatgpt give you\
          \ that long of a response anyway?</p>\n</blockquote>\n<p>\"Write a fanfic\
          \ about...\" XD (but this is just one example that I use most often, there\
          \ are topics that require quite a detailed answer)</p>\n"
        raw: "> Then don\u2019t use 2000 tokens. The dataset doesn\u2019t include\
          \ such long answers as far as I know. When does chatgpt give you that long\
          \ of a response anyway?\n\n\"Write a fanfic about...\" XD (but this is just\
          \ one example that I use most often, there are topics that require quite\
          \ a detailed answer)"
        updatedAt: '2023-04-02T17:22:58.164Z'
      numEdits: 0
      reactions: []
    id: 6429b9f2316c9207b7c10066
    type: comment
  author: Fenfel
  content: "> Then don\u2019t use 2000 tokens. The dataset doesn\u2019t include such\
    \ long answers as far as I know. When does chatgpt give you that long of a response\
    \ anyway?\n\n\"Write a fanfic about...\" XD (but this is just one example that\
    \ I use most often, there are topics that require quite a detailed answer)"
  created_at: 2023-04-02 16:22:58+00:00
  edited: false
  hidden: false
  id: 6429b9f2316c9207b7c10066
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
      fullname: elinas
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: elinas
      type: user
    createdAt: '2023-04-02T17:24:41.000Z'
    data:
      edited: false
      editors:
      - elinas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
          fullname: elinas
          isHf: false
          isPro: false
          name: elinas
          type: user
        html: "<p>That\u2019s not going to work. You\u2019re better off using it as\
          \ an ai assisted writing tool in notebook mode rather than instructing such\
          \ long responses.</p>\n"
        raw: "That\u2019s not going to work. You\u2019re better off using it as an\
          \ ai assisted writing tool in notebook mode rather than instructing such\
          \ long responses."
        updatedAt: '2023-04-02T17:24:41.943Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6429ba594059ac9e68389796
    id: 6429ba594059ac9e68389795
    type: comment
  author: elinas
  content: "That\u2019s not going to work. You\u2019re better off using it as an ai\
    \ assisted writing tool in notebook mode rather than instructing such long responses."
  created_at: 2023-04-02 16:24:41+00:00
  edited: false
  hidden: false
  id: 6429ba594059ac9e68389795
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630417380907b9a115c6aa9f/hsmz_dU2AyXe1DWHW7Pvd.png?w=200&h=200&f=face
      fullname: elinas
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: elinas
      type: user
    createdAt: '2023-04-02T17:24:41.000Z'
    data:
      status: closed
    id: 6429ba594059ac9e68389796
    type: status-change
  author: elinas
  created_at: 2023-04-02 16:24:41+00:00
  id: 6429ba594059ac9e68389796
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: elinas/alpaca-13b-lora-int4
repo_type: model
status: closed
target_branch: null
title: Maximum new tokens size
