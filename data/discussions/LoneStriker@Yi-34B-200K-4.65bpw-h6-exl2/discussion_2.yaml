!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ishotoli
conflicting_files: null
created_at: 2023-11-09 08:35:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e86b752896195ce66bcc0737eba18cbf.svg
      fullname: Kaiz Zhao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ishotoli
      type: user
    createdAt: '2023-11-09T08:35:41.000Z'
    data:
      edited: false
      editors:
      - ishotoli
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.485090047121048
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e86b752896195ce66bcc0737eba18cbf.svg
          fullname: Kaiz Zhao
          isHf: false
          isPro: false
          name: ishotoli
          type: user
        html: '<p>When I use Exllamav2 to load the model, I encounter the following
          error:<br>File ~/anaconda3/envs/chainlit/lib/python3.10/site-packages/exllamav2/config.py:134,
          in ExLlamaV2Config.prepare(self)<br>    132 for prefix in expect_keys:<br>    133     if
          not any(key.startswith(prefix) for key in self.tensor_file_map):<br>--&gt;
          134         raise ValueError(f" ## Could not find {prefix}.* in model")<br>    136
          # Model dimensions<br>    138 self.head_dim = self.hidden_size // self.num_attention_heads</p>

          <p>ValueError:  ## Could not find model.layers.0.input_layernorm.* in model</p>

          <p>Exllamav2 version: 0.0.7</p>

          <p>Do you have any suggestions on how to load the model?</p>

          '
        raw: "When I use Exllamav2 to load the model, I encounter the following error:\r\
          \nFile ~/anaconda3/envs/chainlit/lib/python3.10/site-packages/exllamav2/config.py:134,\
          \ in ExLlamaV2Config.prepare(self)\r\n    132 for prefix in expect_keys:\r\
          \n    133     if not any(key.startswith(prefix) for key in self.tensor_file_map):\r\
          \n--> 134         raise ValueError(f\" ## Could not find {prefix}.* in model\"\
          )\r\n    136 # Model dimensions\r\n    138 self.head_dim = self.hidden_size\
          \ // self.num_attention_heads\r\n\r\nValueError:  ## Could not find model.layers.0.input_layernorm.*\
          \ in model\r\n\r\nExllamav2 version: 0.0.7\r\n\r\nDo you have any suggestions\
          \ on how to load the model?"
        updatedAt: '2023-11-09T08:35:41.477Z'
      numEdits: 0
      reactions: []
    id: 654c99dd08031bb3dec363c6
    type: comment
  author: ishotoli
  content: "When I use Exllamav2 to load the model, I encounter the following error:\r\
    \nFile ~/anaconda3/envs/chainlit/lib/python3.10/site-packages/exllamav2/config.py:134,\
    \ in ExLlamaV2Config.prepare(self)\r\n    132 for prefix in expect_keys:\r\n \
    \   133     if not any(key.startswith(prefix) for key in self.tensor_file_map):\r\
    \n--> 134         raise ValueError(f\" ## Could not find {prefix}.* in model\"\
    )\r\n    136 # Model dimensions\r\n    138 self.head_dim = self.hidden_size //\
    \ self.num_attention_heads\r\n\r\nValueError:  ## Could not find model.layers.0.input_layernorm.*\
    \ in model\r\n\r\nExllamav2 version: 0.0.7\r\n\r\nDo you have any suggestions\
    \ on how to load the model?"
  created_at: 2023-11-09 08:35:41+00:00
  edited: false
  hidden: false
  id: 654c99dd08031bb3dec363c6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
      fullname: Lone Striker
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: LoneStriker
      type: user
    createdAt: '2023-11-09T11:24:37.000Z'
    data:
      edited: false
      editors:
      - LoneStriker
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.977118730545044
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f18351bc5ce9c106ba74523d9a55567c.svg
          fullname: Lone Striker
          isHf: false
          isPro: false
          name: LoneStriker
          type: user
        html: '<p>You need to make sure ooba is up to date. You may need to install
          exllamav2 manually as well if the latest version has not been pre-built
          as a binary wheel and updated in ooba.</p>

          '
        raw: You need to make sure ooba is up to date. You may need to install exllamav2
          manually as well if the latest version has not been pre-built as a binary
          wheel and updated in ooba.
        updatedAt: '2023-11-09T11:24:37.203Z'
      numEdits: 0
      reactions: []
    id: 654cc175e1b4cd6d40d4698f
    type: comment
  author: LoneStriker
  content: You need to make sure ooba is up to date. You may need to install exllamav2
    manually as well if the latest version has not been pre-built as a binary wheel
    and updated in ooba.
  created_at: 2023-11-09 11:24:37+00:00
  edited: false
  hidden: false
  id: 654cc175e1b4cd6d40d4698f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: LoneStriker/Yi-34B-200K-4.65bpw-h6-exl2
repo_type: model
status: open
target_branch: null
title: An error occurred when using Exllamav2 to load the model.
