!!python/object:huggingface_hub.community.DiscussionWithDetails
author: bri25yu
conflicting_files: null
created_at: 2023-12-06 18:58:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5d3dbc92100850a087d3ab1badaf5b59.svg
      fullname: Brian Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: bri25yu
      type: user
    createdAt: '2023-12-06T18:58:51.000Z'
    data:
      edited: false
      editors:
      - bri25yu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8545878529548645
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5d3dbc92100850a087d3ab1badaf5b59.svg
          fullname: Brian Yu
          isHf: false
          isPro: true
          name: bri25yu
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/64e152b30f0157f458f4b3e9/1X6hSOeWge9q-RGWAWjEQ.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/64e152b30f0157f458f4b3e9/1X6hSOeWge9q-RGWAWjEQ.png"></a></p>

          <p>Not 100% if this is a fair comparison. Also it seems strange that they
          only report BLEURT scores as opposed to BLEU or chrF++ scores. Thoughts?</p>

          <p>Also can somebody with more experience using BLEURT say something about
          how meaningful the difference in performance of 74.4 (Gemini Ultra, all
          languages) vs 73.8 (GPT-4, all languages) is?</p>

          '
        raw: "![image.png](https://cdn-uploads.huggingface.co/production/uploads/64e152b30f0157f458f4b3e9/1X6hSOeWge9q-RGWAWjEQ.png)\r\
          \n\r\nNot 100% if this is a fair comparison. Also it seems strange that\
          \ they only report BLEURT scores as opposed to BLEU or chrF++ scores. Thoughts?\r\
          \n\r\nAlso can somebody with more experience using BLEURT say something\
          \ about how meaningful the difference in performance of 74.4 (Gemini Ultra,\
          \ all languages) vs 73.8 (GPT-4, all languages) is?"
        updatedAt: '2023-12-06T18:58:51.127Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - clem
    id: 6570c46b458930ab2881967e
    type: comment
  author: bri25yu
  content: "![image.png](https://cdn-uploads.huggingface.co/production/uploads/64e152b30f0157f458f4b3e9/1X6hSOeWge9q-RGWAWjEQ.png)\r\
    \n\r\nNot 100% if this is a fair comparison. Also it seems strange that they only\
    \ report BLEURT scores as opposed to BLEU or chrF++ scores. Thoughts?\r\n\r\n\
    Also can somebody with more experience using BLEURT say something about how meaningful\
    \ the difference in performance of 74.4 (Gemini Ultra, all languages) vs 73.8\
    \ (GPT-4, all languages) is?"
  created_at: 2023-12-06 18:58:51+00:00
  edited: false
  hidden: false
  id: 6570c46b458930ab2881967e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1637711517996-6039478ab3ecf716b1a5fd4d.jpeg?w=200&h=200&f=face
      fullname: taesiri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: taesiri
      type: user
    createdAt: '2023-12-06T19:35:25.000Z'
    data:
      edited: false
      editors:
      - taesiri
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.934638261795044
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1637711517996-6039478ab3ecf716b1a5fd4d.jpeg?w=200&h=200&f=face
          fullname: taesiri
          isHf: false
          isPro: true
          name: taesiri
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;bri25yu&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/bri25yu\">@<span class=\"\
          underline\">bri25yu</span></a></span>\n\n\t</span></span> </p>\n<p>I tried\
          \ to ask perplexity.ai interpret the results; take this with a grain of\
          \ salt :D </p>\n<blockquote>\n<p>In your case, the model with a BLEURT score\
          \ of 74.4 is slightly better at generating translations that are fluent\
          \ and convey the same meaning as the reference sentences than the model\
          \ with a score of 73.8. However, the difference is relatively small, and\
          \ it might not be significant depending on the specific use case and the\
          \ variability of the scores. It's also worth noting that while BLEURT is\
          \ a useful tool for comparing different systems' performance on the same\
          \ task, it's not perfect and a high BLEURT score does not necessarily mean\
          \ high quality translations in all cases</p>\n</blockquote>\n"
        raw: "@bri25yu \n\nI tried to ask perplexity.ai interpret the results; take\
          \ this with a grain of salt :D \n\n>In your case, the model with a BLEURT\
          \ score of 74.4 is slightly better at generating translations that are fluent\
          \ and convey the same meaning as the reference sentences than the model\
          \ with a score of 73.8. However, the difference is relatively small, and\
          \ it might not be significant depending on the specific use case and the\
          \ variability of the scores. It's also worth noting that while BLEURT is\
          \ a useful tool for comparing different systems' performance on the same\
          \ task, it's not perfect and a high BLEURT score does not necessarily mean\
          \ high quality translations in all cases\n"
        updatedAt: '2023-12-06T19:35:25.839Z'
      numEdits: 0
      reactions: []
    id: 6570ccfd9c503c4a6afcf59d
    type: comment
  author: taesiri
  content: "@bri25yu \n\nI tried to ask perplexity.ai interpret the results; take\
    \ this with a grain of salt :D \n\n>In your case, the model with a BLEURT score\
    \ of 74.4 is slightly better at generating translations that are fluent and convey\
    \ the same meaning as the reference sentences than the model with a score of 73.8.\
    \ However, the difference is relatively small, and it might not be significant\
    \ depending on the specific use case and the variability of the scores. It's also\
    \ worth noting that while BLEURT is a useful tool for comparing different systems'\
    \ performance on the same task, it's not perfect and a high BLEURT score does\
    \ not necessarily mean high quality translations in all cases\n"
  created_at: 2023-12-06 19:35:25+00:00
  edited: false
  hidden: false
  id: 6570ccfd9c503c4a6afcf59d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594192845975-5e1e17b6fcf41d740b6996a8.jpeg?w=200&h=200&f=face
      fullname: Bram Vanroy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BramVanroy
      type: user
    createdAt: '2023-12-06T19:37:09.000Z'
    data:
      edited: true
      editors:
      - BramVanroy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9768573641777039
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594192845975-5e1e17b6fcf41d740b6996a8.jpeg?w=200&h=200&f=face
          fullname: Bram Vanroy
          isHf: false
          isPro: false
          name: BramVanroy
          type: user
        html: '<p>BLEURT is a very good metric, so not odd that it is included. It''s
          also developed by Google. I agree that it''d be better if they''d also include
          another metric, preferably CHRF for it''s language/tokenizer-agnosticism,
          but only in addition to BLEURT - not as a replacement.</p>

          <p>BLEU should be avoided. It''s not a good metric (correlates poorly with
          human judgments). Just look at the title of the latest findings of <a rel="nofollow"
          href="https://aclanthology.org/2022.wmt-1.2/">the WMT shared task</a> ;-)
          People are stubborn and keep using it, but there''s seldom a good reason
          for it.</p>

          <p>Unfortunately they did not do any significance testing so it is hard
          to know how meaningful the relative differences are between the systems.
          </p>

          '
        raw: 'BLEURT is a very good metric, so not odd that it is included. It''s
          also developed by Google. I agree that it''d be better if they''d also include
          another metric, preferably CHRF for it''s language/tokenizer-agnosticism,
          but only in addition to BLEURT - not as a replacement.


          BLEU should be avoided. It''s not a good metric (correlates poorly with
          human judgments). Just look at the title of the latest findings of [the
          WMT shared task](https://aclanthology.org/2022.wmt-1.2/) ;-) People are
          stubborn and keep using it, but there''s seldom a good reason for it.


          Unfortunately they did not do any significance testing so it is hard to
          know how meaningful the relative differences are between the systems. '
        updatedAt: '2023-12-07T07:35:30.209Z'
      numEdits: 1
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - taesiri
        - bri25yu
        - iceicenice2ice
        - clem
    id: 6570cd65c8018fe64079e7f0
    type: comment
  author: BramVanroy
  content: 'BLEURT is a very good metric, so not odd that it is included. It''s also
    developed by Google. I agree that it''d be better if they''d also include another
    metric, preferably CHRF for it''s language/tokenizer-agnosticism, but only in
    addition to BLEURT - not as a replacement.


    BLEU should be avoided. It''s not a good metric (correlates poorly with human
    judgments). Just look at the title of the latest findings of [the WMT shared task](https://aclanthology.org/2022.wmt-1.2/)
    ;-) People are stubborn and keep using it, but there''s seldom a good reason for
    it.


    Unfortunately they did not do any significance testing so it is hard to know how
    meaningful the relative differences are between the systems. '
  created_at: 2023-12-06 19:37:09+00:00
  edited: true
  hidden: false
  id: 6570cd65c8018fe64079e7f0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5d3dbc92100850a087d3ab1badaf5b59.svg
      fullname: Brian Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: bri25yu
      type: user
    createdAt: '2023-12-06T19:41:01.000Z'
    data:
      edited: false
      editors:
      - bri25yu
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7909792065620422
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5d3dbc92100850a087d3ab1badaf5b59.svg
          fullname: Brian Yu
          isHf: false
          isPro: true
          name: bri25yu
          type: user
        html: '<p>Gotcha, thanks for the explanation Bram!</p>

          '
        raw: Gotcha, thanks for the explanation Bram!
        updatedAt: '2023-12-06T19:41:01.585Z'
      numEdits: 0
      reactions: []
    id: 6570ce4d10d0841de2db95bc
    type: comment
  author: bri25yu
  content: Gotcha, thanks for the explanation Bram!
  created_at: 2023-12-06 19:41:01+00:00
  edited: false
  hidden: false
  id: 6570ce4d10d0841de2db95bc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: clem/gemini
repo_type: model
status: open
target_branch: null
title: 'Re: Machine Translation performance'
