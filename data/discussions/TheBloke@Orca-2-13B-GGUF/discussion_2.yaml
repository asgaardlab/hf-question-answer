!!python/object:huggingface_hub.community.DiscussionWithDetails
author: d3m0t3p
conflicting_files: null
created_at: 2023-11-22 00:11:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/acd37e156acdc71f2d822d3b6795c886.svg
      fullname: jsch
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: d3m0t3p
      type: user
    createdAt: '2023-11-22T00:11:23.000Z'
    data:
      edited: false
      editors:
      - d3m0t3p
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9641274213790894
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/acd37e156acdc71f2d822d3b6795c886.svg
          fullname: jsch
          isHf: false
          isPro: false
          name: d3m0t3p
          type: user
        html: '<p>Hi,<br>thx for your work it''s greatly appreciated.<br>I''m wondering
          how to use the model:</p>

          <ul>

          <li>directly from python, i tried the top "use in transformers" but it didn''t
          work.</li>

          <li>using llama.cpp but it crashed, my computer (i had to reboot)<br>Any
          help would be appreciated,<br>Thx !</li>

          </ul>

          '
        raw: "Hi, \r\nthx for your work it's greatly appreciated.\r\nI'm wondering\
          \ how to use the model:\r\n-  directly from python, i tried the top \"use\
          \ in transformers\" but it didn't work.\r\n- using llama.cpp but it crashed,\
          \ my computer (i had to reboot)\r\nAny help would be appreciated, \r\nThx\
          \ ! "
        updatedAt: '2023-11-22T00:11:23.662Z'
      numEdits: 0
      reactions: []
    id: 655d472b89546ea4b3954d25
    type: comment
  author: d3m0t3p
  content: "Hi, \r\nthx for your work it's greatly appreciated.\r\nI'm wondering how\
    \ to use the model:\r\n-  directly from python, i tried the top \"use in transformers\"\
    \ but it didn't work.\r\n- using llama.cpp but it crashed, my computer (i had\
    \ to reboot)\r\nAny help would be appreciated, \r\nThx ! "
  created_at: 2023-11-22 00:11:23+00:00
  edited: false
  hidden: false
  id: 655d472b89546ea4b3954d25
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/688d526cefc4db09c7944af997c15227.svg
      fullname: '-'
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: asterix51
      type: user
    createdAt: '2023-12-05T01:55:54.000Z'
    data:
      edited: false
      editors:
      - asterix51
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8461282253265381
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/688d526cefc4db09c7944af997c15227.svg
          fullname: '-'
          isHf: false
          isPro: false
          name: asterix51
          type: user
        html: '<p>Use Koboldcpp, this app for allow you to split the workload effectively.</p>

          '
        raw: Use Koboldcpp, this app for allow you to split the workload effectively.
        updatedAt: '2023-12-05T01:55:54.356Z'
      numEdits: 0
      reactions: []
    id: 656e832a8bb9f4f8d947faff
    type: comment
  author: asterix51
  content: Use Koboldcpp, this app for allow you to split the workload effectively.
  created_at: 2023-12-05 01:55:54+00:00
  edited: false
  hidden: false
  id: 656e832a8bb9f4f8d947faff
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/Orca-2-13B-GGUF
repo_type: model
status: open
target_branch: null
title: How to run the model ?
