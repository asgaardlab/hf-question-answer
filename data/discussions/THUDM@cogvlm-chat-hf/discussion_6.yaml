!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mnbucher
conflicting_files: null
created_at: 2023-11-29 06:03:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5e18b9584d1d72d683d95189432e9913.svg
      fullname: "Martin Juan Jos\xE9 Bucher"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mnbucher
      type: user
    createdAt: '2023-11-29T06:03:41.000Z'
    data:
      edited: false
      editors:
      - mnbucher
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9202287197113037
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5e18b9584d1d72d683d95189432e9913.svg
          fullname: "Martin Juan Jos\xE9 Bucher"
          isHf: false
          isPro: false
          name: mnbucher
          type: user
        html: '<p>Hi there.</p>

          <p>I''m currently trying to set up the code to fine-tune the model on my
          own vision/language dataset, and I started by looking at the original code
          repository on Github, but then switched over to Huggingface here as it might
          be easier to set up the full training pipeline using the HF API. </p>

          <p>I can''t find any information on how to properly encode the input for
          training... </p>

          <p><code>build_conversation_input_ids`` is just for inference, but for training
          we need to encode both the query and the intended text output + a bunch
          of other stuff. I''m now digging into the codebase of </code><a href="https://huggingface.co/THUDM/cogvlm-chat-hf/blob/main/modeling_cogvlm.py%60%60%60">https://huggingface.co/THUDM/cogvlm-chat-hf/blob/main/modeling_cogvlm.py```</a>
          to better understand the details, but just wanted to check if the authors
          of CogVLM could maybe provide some guidance here, at least in the README?
          </p>

          <p>Thanks a lot!</p>

          <p>Best,<br>Martin</p>

          '
        raw: "Hi there.\r\n\r\nI'm currently trying to set up the code to fine-tune\
          \ the model on my own vision/language dataset, and I started by looking\
          \ at the original code repository on Github, but then switched over to Huggingface\
          \ here as it might be easier to set up the full training pipeline using\
          \ the HF API. \r\n\r\nI can't find any information on how to properly encode\
          \ the input for training... \r\n\r\n```build_conversation_input_ids`` is\
          \ just for inference, but for training we need to encode both the query\
          \ and the intended text output + a bunch of other stuff. I'm now digging\
          \ into the codebase of ```https://huggingface.co/THUDM/cogvlm-chat-hf/blob/main/modeling_cogvlm.py```\
          \ to better understand the details, but just wanted to check if the authors\
          \ of CogVLM could maybe provide some guidance here, at least in the README?\
          \ \r\n\r\nThanks a lot!\r\n\r\nBest,\r\nMartin"
        updatedAt: '2023-11-29T06:03:41.885Z'
      numEdits: 0
      reactions: []
    id: 6566d43d751591e4fae42aee
    type: comment
  author: mnbucher
  content: "Hi there.\r\n\r\nI'm currently trying to set up the code to fine-tune\
    \ the model on my own vision/language dataset, and I started by looking at the\
    \ original code repository on Github, but then switched over to Huggingface here\
    \ as it might be easier to set up the full training pipeline using the HF API.\
    \ \r\n\r\nI can't find any information on how to properly encode the input for\
    \ training... \r\n\r\n```build_conversation_input_ids`` is just for inference,\
    \ but for training we need to encode both the query and the intended text output\
    \ + a bunch of other stuff. I'm now digging into the codebase of ```https://huggingface.co/THUDM/cogvlm-chat-hf/blob/main/modeling_cogvlm.py```\
    \ to better understand the details, but just wanted to check if the authors of\
    \ CogVLM could maybe provide some guidance here, at least in the README? \r\n\r\
    \nThanks a lot!\r\n\r\nBest,\r\nMartin"
  created_at: 2023-11-29 06:03:41+00:00
  edited: false
  hidden: false
  id: 6566d43d751591e4fae42aee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3f68cbabcdfc96de3ef84d094ba1d60c.svg
      fullname: Sidharth Baskaran
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sidnb13
      type: user
    createdAt: '2023-12-03T19:00:30.000Z'
    data:
      edited: false
      editors:
      - sidnb13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9240442514419556
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3f68cbabcdfc96de3ef84d094ba1d60c.svg
          fullname: Sidharth Baskaran
          isHf: false
          isPro: false
          name: sidnb13
          type: user
        html: '<p>Curious if you were able to set up a finetuning pipeline using HF?
          I''m trying to finetune CogVLM using LoRA on my custom image-text datasets
          and couldn''t find any info on what linear layers to target, etc. from the
          original repository. The implementation using SAT is a bit obscure so ideally
          I''d like to use PEFT.</p>

          '
        raw: Curious if you were able to set up a finetuning pipeline using HF? I'm
          trying to finetune CogVLM using LoRA on my custom image-text datasets and
          couldn't find any info on what linear layers to target, etc. from the original
          repository. The implementation using SAT is a bit obscure so ideally I'd
          like to use PEFT.
        updatedAt: '2023-12-03T19:00:30.762Z'
      numEdits: 0
      reactions: []
    id: 656cd04e3dbac3a83d25deb1
    type: comment
  author: sidnb13
  content: Curious if you were able to set up a finetuning pipeline using HF? I'm
    trying to finetune CogVLM using LoRA on my custom image-text datasets and couldn't
    find any info on what linear layers to target, etc. from the original repository.
    The implementation using SAT is a bit obscure so ideally I'd like to use PEFT.
  created_at: 2023-12-03 19:00:30+00:00
  edited: false
  hidden: false
  id: 656cd04e3dbac3a83d25deb1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/804a7b7a7c0b9dd57ccf95abcf2a263a.svg
      fullname: 'Alhassan Mohammed Nuruddin '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mohammednuruddin
      type: user
    createdAt: '2023-12-18T22:31:42.000Z'
    data:
      edited: true
      editors:
      - mohammednuruddin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9217216968536377
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/804a7b7a7c0b9dd57ccf95abcf2a263a.svg
          fullname: 'Alhassan Mohammed Nuruddin '
          isHf: false
          isPro: false
          name: mohammednuruddin
          type: user
        html: '<blockquote>

          <p>Curious if you were able to set up a finetuning pipeline using HF? I''m
          trying to finetune CogVLM using LoRA on my custom image-text datasets and
          couldn''t find any info on what linear layers to target, etc. from the original
          repository. The implementation using SAT is a bit obscure so ideally I''d
          like to use PEFT.</p>

          </blockquote>

          <p>Were you able to do it?</p>

          '
        raw: '> Curious if you were able to set up a finetuning pipeline using HF?
          I''m trying to finetune CogVLM using LoRA on my custom image-text datasets
          and couldn''t find any info on what linear layers to target, etc. from the
          original repository. The implementation using SAT is a bit obscure so ideally
          I''d like to use PEFT.


          Were you able to do it?

          '
        updatedAt: '2023-12-18T22:32:25.172Z'
      numEdits: 1
      reactions: []
    id: 6580c84ec1b5aed69338a371
    type: comment
  author: mohammednuruddin
  content: '> Curious if you were able to set up a finetuning pipeline using HF? I''m
    trying to finetune CogVLM using LoRA on my custom image-text datasets and couldn''t
    find any info on what linear layers to target, etc. from the original repository.
    The implementation using SAT is a bit obscure so ideally I''d like to use PEFT.


    Were you able to do it?

    '
  created_at: 2023-12-18 22:31:42+00:00
  edited: true
  hidden: false
  id: 6580c84ec1b5aed69338a371
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5e18b9584d1d72d683d95189432e9913.svg
      fullname: "Martin Juan Jos\xE9 Bucher"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mnbucher
      type: user
    createdAt: '2023-12-18T23:20:21.000Z'
    data:
      edited: false
      editors:
      - mnbucher
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9275906085968018
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5e18b9584d1d72d683d95189432e9913.svg
          fullname: "Martin Juan Jos\xE9 Bucher"
          isHf: false
          isPro: false
          name: mnbucher
          type: user
        html: "<p>hi both <span data-props=\"{&quot;user&quot;:&quot;sidnb13&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sidnb13\"\
          >@<span class=\"underline\">sidnb13</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;mohammednuruddin&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mohammednuruddin\">@<span\
          \ class=\"underline\">mohammednuruddin</span></a></span>\n\n\t</span></span>\
          \ ,<br>i haven't continued working on this since then, so if you have any\
          \ running code snippet that might be very valuable.<br>\u2014 cheers, martin</p>\n"
        raw: "hi both @sidnb13 @mohammednuruddin ,\ni haven't continued working on\
          \ this since then, so if you have any running code snippet that might be\
          \ very valuable.\n\u2014 cheers, martin"
        updatedAt: '2023-12-18T23:20:21.663Z'
      numEdits: 0
      reactions: []
    id: 6580d3b598aa9fcdd25ecb3f
    type: comment
  author: mnbucher
  content: "hi both @sidnb13 @mohammednuruddin ,\ni haven't continued working on this\
    \ since then, so if you have any running code snippet that might be very valuable.\n\
    \u2014 cheers, martin"
  created_at: 2023-12-18 23:20:21+00:00
  edited: false
  hidden: false
  id: 6580d3b598aa9fcdd25ecb3f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/171bfa9094ea98ef340e229d7e99ca38.svg
      fullname: 'Fred '
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: z3ugma
      type: user
    createdAt: '2023-12-22T23:55:12.000Z'
    data:
      edited: false
      editors:
      - z3ugma
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9893620014190674
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/171bfa9094ea98ef340e229d7e99ca38.svg
          fullname: 'Fred '
          isHf: false
          isPro: false
          name: z3ugma
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sidnb13&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sidnb13\">@<span class=\"\
          underline\">sidnb13</span></a></span>\n\n\t</span></span> I would like to\
          \ do the same as you are doing, did you succeed at finetuning using PEFT?\
          \ </p>\n"
        raw: "@sidnb13 I would like to do the same as you are doing, did you succeed\
          \ at finetuning using PEFT? \n"
        updatedAt: '2023-12-22T23:55:12.987Z'
      numEdits: 0
      reactions: []
    id: 658621e0a66bd1cdb2257f8e
    type: comment
  author: z3ugma
  content: "@sidnb13 I would like to do the same as you are doing, did you succeed\
    \ at finetuning using PEFT? \n"
  created_at: 2023-12-22 23:55:12+00:00
  edited: false
  hidden: false
  id: 658621e0a66bd1cdb2257f8e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/78a5114ed30ae1fdb78965659dc9eeb9.svg
      fullname: Jeremiah Ayensu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ayensujeremiah
      type: user
    createdAt: '2024-01-22T17:07:18.000Z'
    data:
      edited: false
      editors:
      - ayensujeremiah
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.805885374546051
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/78a5114ed30ae1fdb78965659dc9eeb9.svg
          fullname: Jeremiah Ayensu
          isHf: false
          isPro: false
          name: ayensujeremiah
          type: user
        html: '<p>Hello Everyone. I am also trying to finetune the chat version of
          CogVLM too for image-text dataset. My text set are QA pairs regarding the
          image in a json format. any idea how I might preprocess the data for the
          finetuning?</p>

          '
        raw: 'Hello Everyone. I am also trying to finetune the chat version of CogVLM
          too for image-text dataset. My text set are QA pairs regarding the image
          in a json format. any idea how I might preprocess the data for the finetuning?

          '
        updatedAt: '2024-01-22T17:07:18.750Z'
      numEdits: 0
      reactions: []
    id: 65aea0c6fcbe71d6d59ea572
    type: comment
  author: ayensujeremiah
  content: 'Hello Everyone. I am also trying to finetune the chat version of CogVLM
    too for image-text dataset. My text set are QA pairs regarding the image in a
    json format. any idea how I might preprocess the data for the finetuning?

    '
  created_at: 2024-01-22 17:07:18+00:00
  edited: false
  hidden: false
  id: 65aea0c6fcbe71d6d59ea572
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: THUDM/cogvlm-chat-hf
repo_type: model
status: open
target_branch: null
title: Guidance on How to Train / Finetune Model
