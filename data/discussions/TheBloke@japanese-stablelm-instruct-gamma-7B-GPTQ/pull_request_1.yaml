!!python/object:huggingface_hub.community.DiscussionWithDetails
author: alfredplpl
conflicting_files: []
created_at: 2023-10-30 09:14:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670594087059-630412d57373aacccd88af95.jpeg?w=200&h=200&f=face
      fullname: Yasunori Ozaki
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alfredplpl
      type: user
    createdAt: '2023-10-30T10:14:17.000Z'
    data:
      edited: false
      editors:
      - alfredplpl
      hidden: false
      identifiedLanguage:
        language: ja
        probability: 0.6045931577682495
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670594087059-630412d57373aacccd88af95.jpeg?w=200&h=200&f=face
          fullname: Yasunori Ozaki
          isHf: false
          isPro: false
          name: alfredplpl
          type: user
        html: "<p>I'm Japanese.<br>I feel that the prompt template is weird.<br>\u6307\
          \u793A is the instruction.<br>So, \u6307\u793A is \u4EE5\u4E0B\u306F\u3001\
          \u30BF\u30B9\u30AF\u3092\u8AAC\u660E\u3059\u308B\u6307\u793A\u3068\u3001\
          \u6587\u8108\u306E\u3042\u308B\u5165\u529B\u306E\u7D44\u307F\u5408\u308F\
          \u305B\u3067\u3059\u3002\u8981\u6C42\u3092\u9069\u5207\u306B\u6E80\u305F\
          \u3059\u5FDC\u7B54\u3092\u66F8\u304D\u306A\u3055\u3044\u3002<br>\u5165\u529B\
          \ is the user prompt. Of course, \u5165\u529B also means \"input\".<br>So,\
          \ \u5165\u529B is {prompt}.</p>\n<p>Thanks in advance.</p>\n"
        raw: "I'm Japanese.\nI feel that the prompt template is weird.\n\u6307\u793A\
          \ is the instruction.\nSo, \u6307\u793A is \u4EE5\u4E0B\u306F\u3001\u30BF\
          \u30B9\u30AF\u3092\u8AAC\u660E\u3059\u308B\u6307\u793A\u3068\u3001\u6587\
          \u8108\u306E\u3042\u308B\u5165\u529B\u306E\u7D44\u307F\u5408\u308F\u305B\
          \u3067\u3059\u3002\u8981\u6C42\u3092\u9069\u5207\u306B\u6E80\u305F\u3059\
          \u5FDC\u7B54\u3092\u66F8\u304D\u306A\u3055\u3044\u3002\n\u5165\u529B is\
          \ the user prompt. Of course, \u5165\u529B also means \"input\".\nSo, \u5165\
          \u529B is {prompt}.\n\nThanks in advance."
        updatedAt: '2023-10-30T10:14:17.634Z'
      numEdits: 0
      reactions: []
    id: 653f81f9284fa7923cf3f6e4
    type: comment
  author: alfredplpl
  content: "I'm Japanese.\nI feel that the prompt template is weird.\n\u6307\u793A\
    \ is the instruction.\nSo, \u6307\u793A is \u4EE5\u4E0B\u306F\u3001\u30BF\u30B9\
    \u30AF\u3092\u8AAC\u660E\u3059\u308B\u6307\u793A\u3068\u3001\u6587\u8108\u306E\
    \u3042\u308B\u5165\u529B\u306E\u7D44\u307F\u5408\u308F\u305B\u3067\u3059\u3002\
    \u8981\u6C42\u3092\u9069\u5207\u306B\u6E80\u305F\u3059\u5FDC\u7B54\u3092\u66F8\
    \u304D\u306A\u3055\u3044\u3002\n\u5165\u529B is the user prompt. Of course, \u5165\
    \u529B also means \"input\".\nSo, \u5165\u529B is {prompt}.\n\nThanks in advance."
  created_at: 2023-10-30 09:14:17+00:00
  edited: false
  hidden: false
  id: 653f81f9284fa7923cf3f6e4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670594087059-630412d57373aacccd88af95.jpeg?w=200&h=200&f=face
      fullname: Yasunori Ozaki
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alfredplpl
      type: user
    createdAt: '2023-10-30T10:14:18.000Z'
    data:
      oid: f2cb8bb9247915bdbfbf63fcda95c759c37248b7
      parents:
      - 03f05cdb9506d3f7b13b4a218b9aeb4e7cc94d0f
      subject: Update README.md
    id: 653f81fa0000000000000000
    type: commit
  author: alfredplpl
  created_at: 2023-10-30 09:14:18+00:00
  id: 653f81fa0000000000000000
  oid: f2cb8bb9247915bdbfbf63fcda95c759c37248b7
  summary: Update README.md
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-10-30T10:42:32.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5270232558250427
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>Oh OK - well you're probably right!</p>\n<p>But let me show you\
          \ how I came to this prompt, because it was based on code provided by the\
          \ model creators.  Maybe I misunderstood it?</p>\n<p>This code is provided\
          \ in the original model README:</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >build_prompt</span>(<span class=\"hljs-params\">user_query, inputs=<span\
          \ class=\"hljs-string\">\"\"</span>, sep=<span class=\"hljs-string\">\"\\\
          n\\n### \"</span></span>):\n    sys_msg = <span class=\"hljs-string\">\"\
          \u4EE5\u4E0B\u306F\u3001\u30BF\u30B9\u30AF\u3092\u8AAC\u660E\u3059\u308B\
          \u6307\u793A\u3068\u3001\u6587\u8108\u306E\u3042\u308B\u5165\u529B\u306E\
          \u7D44\u307F\u5408\u308F\u305B\u3067\u3059\u3002\u8981\u6C42\u3092\u9069\
          \u5207\u306B\u6E80\u305F\u3059\u5FDC\u7B54\u3092\u66F8\u304D\u306A\u3055\
          \u3044\u3002\"</span>\n    p = sys_msg\n    roles = [<span class=\"hljs-string\"\
          >\"\u6307\u793A\"</span>, <span class=\"hljs-string\">\"\u5FDC\u7B54\"</span>]\n\
          \    msgs = [<span class=\"hljs-string\">\": \\n\"</span> + user_query,\
          \ <span class=\"hljs-string\">\": \\n\"</span>]\n    <span class=\"hljs-keyword\"\
          >if</span> inputs:\n        roles.insert(<span class=\"hljs-number\">1</span>,\
          \ <span class=\"hljs-string\">\"\u5165\u529B\"</span>)\n        msgs.insert(<span\
          \ class=\"hljs-number\">1</span>, <span class=\"hljs-string\">\": \\n\"\
          </span> + inputs)\n    <span class=\"hljs-keyword\">for</span> role, msg\
          \ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(roles,\
          \ msgs):\n        p += sep + role + msg\n    <span class=\"hljs-keyword\"\
          >return</span> p\n\n<span class=\"hljs-comment\"># Infer with prompt without\
          \ any additional input</span>\nuser_inputs = {\n    <span class=\"hljs-string\"\
          >\"user_query\"</span>: <span class=\"hljs-string\">\"\u4E0E\u3048\u3089\
          \u308C\u305F\u3053\u3068\u308F\u3056\u306E\u610F\u5473\u3092\u5C0F\u5B66\
          \u751F\u3067\u3082\u5206\u304B\u308B\u3088\u3046\u306B\u6559\u3048\u3066\
          \u304F\u3060\u3055\u3044\u3002\"</span>,\n    <span class=\"hljs-string\"\
          >\"inputs\"</span>: <span class=\"hljs-string\">\"\u60C5\u3051\u306F\u4EBA\
          \u306E\u305F\u3081\u306A\u3089\u305A\"</span>\n}\nprompt = build_prompt(**user_inputs)\n\
          </code></pre>\n<p>So what I did was run this code:</p>\n<pre><code class=\"\
          language-python\"><span class=\"hljs-keyword\">def</span> <span class=\"\
          hljs-title function_\">build_prompt</span>(<span class=\"hljs-params\">user_query,\
          \ inputs=<span class=\"hljs-string\">\"\"</span>, sep=<span class=\"hljs-string\"\
          >\"\\n\\n### \"</span></span>):\n    sys_msg = <span class=\"hljs-string\"\
          >\"\u4EE5\u4E0B\u306F\u3001\u30BF\u30B9\u30AF\u3092\u8AAC\u660E\u3059\u308B\
          \u6307\u793A\u3068\u3001\u6587\u8108\u306E\u3042\u308B\u5165\u529B\u306E\
          \u7D44\u307F\u5408\u308F\u305B\u3067\u3059\u3002\u8981\u6C42\u3092\u9069\
          \u5207\u306B\u6E80\u305F\u3059\u5FDC\u7B54\u3092\u66F8\u304D\u306A\u3055\
          \u3044\u3002\"</span>\n    p = sys_msg\n    roles = [<span class=\"hljs-string\"\
          >\"\u6307\u793A\"</span>, <span class=\"hljs-string\">\"\u5FDC\u7B54\"</span>]\n\
          \    msgs = [<span class=\"hljs-string\">\": \\n\"</span> + user_query,\
          \ <span class=\"hljs-string\">\": \\n\"</span>]\n    <span class=\"hljs-keyword\"\
          >if</span> inputs:\n        roles.insert(<span class=\"hljs-number\">1</span>,\
          \ <span class=\"hljs-string\">\"\u5165\u529B\"</span>)\n        msgs.insert(<span\
          \ class=\"hljs-number\">1</span>, <span class=\"hljs-string\">\": \\n\"\
          </span> + inputs)\n    <span class=\"hljs-keyword\">for</span> role, msg\
          \ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(roles,\
          \ msgs):\n        p += sep + role + msg\n    <span class=\"hljs-keyword\"\
          >return</span> p\n\n<span class=\"hljs-comment\"># Infer with prompt without\
          \ any additional input</span>\nuser_inputs = {\n    <span class=\"hljs-string\"\
          >\"user_query\"</span>: <span class=\"hljs-string\">\"write a story about\
          \ llamas\"</span>,\n    <span class=\"hljs-string\">\"inputs\"</span>: <span\
          \ class=\"hljs-string\">\"the llamas are nice\"</span>\n}\n<span class=\"\
          hljs-built_in\">print</span>(build_prompt(**user_inputs))\n</code></pre>\n\
          <p>And it gave me this output:</p>\n<pre><code>\u4EE5\u4E0B\u306F\u3001\u30BF\
          \u30B9\u30AF\u3092\u8AAC\u660E\u3059\u308B\u6307\u793A\u3068\u3001\u6587\
          \u8108\u306E\u3042\u308B\u5165\u529B\u306E\u7D44\u307F\u5408\u308F\u305B\
          \u3067\u3059\u3002\u8981\u6C42\u3092\u9069\u5207\u306B\u6E80\u305F\u3059\
          \u5FDC\u7B54\u3092\u66F8\u304D\u306A\u3055\u3044\u3002\n\n### \u6307\u793A\
          :\nwrite a story about llamas\n\n### \u5165\u529B:\nthe llamas are nice\n\
          \n### \u5FDC\u7B54:\n</code></pre>\n<p>And then I set my prompt_template\
          \ according to my understanding that \"write a story about llamas\" was\
          \ the prompt and \"the llamas are nice\" was the input.</p>\n<p>Did I misunderstand?\
          \  Please let me know.</p>\n"
        raw: "Oh OK - well you're probably right!\n\nBut let me show you how I came\
          \ to this prompt, because it was based on code provided by the model creators.\
          \  Maybe I misunderstood it?\n\nThis code is provided in the original model\
          \ README:\n```python\ndef build_prompt(user_query, inputs=\"\", sep=\"\\\
          n\\n### \"):\n    sys_msg = \"\u4EE5\u4E0B\u306F\u3001\u30BF\u30B9\u30AF\
          \u3092\u8AAC\u660E\u3059\u308B\u6307\u793A\u3068\u3001\u6587\u8108\u306E\
          \u3042\u308B\u5165\u529B\u306E\u7D44\u307F\u5408\u308F\u305B\u3067\u3059\
          \u3002\u8981\u6C42\u3092\u9069\u5207\u306B\u6E80\u305F\u3059\u5FDC\u7B54\
          \u3092\u66F8\u304D\u306A\u3055\u3044\u3002\"\n    p = sys_msg\n    roles\
          \ = [\"\u6307\u793A\", \"\u5FDC\u7B54\"]\n    msgs = [\": \\n\" + user_query,\
          \ \": \\n\"]\n    if inputs:\n        roles.insert(1, \"\u5165\u529B\")\n\
          \        msgs.insert(1, \": \\n\" + inputs)\n    for role, msg in zip(roles,\
          \ msgs):\n        p += sep + role + msg\n    return p\n\n# Infer with prompt\
          \ without any additional input\nuser_inputs = {\n    \"user_query\": \"\u4E0E\
          \u3048\u3089\u308C\u305F\u3053\u3068\u308F\u3056\u306E\u610F\u5473\u3092\
          \u5C0F\u5B66\u751F\u3067\u3082\u5206\u304B\u308B\u3088\u3046\u306B\u6559\
          \u3048\u3066\u304F\u3060\u3055\u3044\u3002\",\n    \"inputs\": \"\u60C5\u3051\
          \u306F\u4EBA\u306E\u305F\u3081\u306A\u3089\u305A\"\n}\nprompt = build_prompt(**user_inputs)\n\
          ```\n\nSo what I did was run this code:\n```python\ndef build_prompt(user_query,\
          \ inputs=\"\", sep=\"\\n\\n### \"):\n    sys_msg = \"\u4EE5\u4E0B\u306F\u3001\
          \u30BF\u30B9\u30AF\u3092\u8AAC\u660E\u3059\u308B\u6307\u793A\u3068\u3001\
          \u6587\u8108\u306E\u3042\u308B\u5165\u529B\u306E\u7D44\u307F\u5408\u308F\
          \u305B\u3067\u3059\u3002\u8981\u6C42\u3092\u9069\u5207\u306B\u6E80\u305F\
          \u3059\u5FDC\u7B54\u3092\u66F8\u304D\u306A\u3055\u3044\u3002\"\n    p =\
          \ sys_msg\n    roles = [\"\u6307\u793A\", \"\u5FDC\u7B54\"]\n    msgs =\
          \ [\": \\n\" + user_query, \": \\n\"]\n    if inputs:\n        roles.insert(1,\
          \ \"\u5165\u529B\")\n        msgs.insert(1, \": \\n\" + inputs)\n    for\
          \ role, msg in zip(roles, msgs):\n        p += sep + role + msg\n    return\
          \ p\n\n# Infer with prompt without any additional input\nuser_inputs = {\n\
          \    \"user_query\": \"write a story about llamas\",\n    \"inputs\": \"\
          the llamas are nice\"\n}\nprint(build_prompt(**user_inputs))\n```\n\nAnd\
          \ it gave me this output:\n```\n\u4EE5\u4E0B\u306F\u3001\u30BF\u30B9\u30AF\
          \u3092\u8AAC\u660E\u3059\u308B\u6307\u793A\u3068\u3001\u6587\u8108\u306E\
          \u3042\u308B\u5165\u529B\u306E\u7D44\u307F\u5408\u308F\u305B\u3067\u3059\
          \u3002\u8981\u6C42\u3092\u9069\u5207\u306B\u6E80\u305F\u3059\u5FDC\u7B54\
          \u3092\u66F8\u304D\u306A\u3055\u3044\u3002\n\n### \u6307\u793A:\nwrite a\
          \ story about llamas\n\n### \u5165\u529B:\nthe llamas are nice\n\n### \u5FDC\
          \u7B54:\n```\n\nAnd then I set my prompt_template according to my understanding\
          \ that \"write a story about llamas\" was the prompt and \"the llamas are\
          \ nice\" was the input.\n\nDid I misunderstand?  Please let me know."
        updatedAt: '2023-10-30T10:42:32.383Z'
      numEdits: 0
      reactions: []
    id: 653f88984a52f10eaf8eca57
    type: comment
  author: TheBloke
  content: "Oh OK - well you're probably right!\n\nBut let me show you how I came\
    \ to this prompt, because it was based on code provided by the model creators.\
    \  Maybe I misunderstood it?\n\nThis code is provided in the original model README:\n\
    ```python\ndef build_prompt(user_query, inputs=\"\", sep=\"\\n\\n### \"):\n  \
    \  sys_msg = \"\u4EE5\u4E0B\u306F\u3001\u30BF\u30B9\u30AF\u3092\u8AAC\u660E\u3059\
    \u308B\u6307\u793A\u3068\u3001\u6587\u8108\u306E\u3042\u308B\u5165\u529B\u306E\
    \u7D44\u307F\u5408\u308F\u305B\u3067\u3059\u3002\u8981\u6C42\u3092\u9069\u5207\
    \u306B\u6E80\u305F\u3059\u5FDC\u7B54\u3092\u66F8\u304D\u306A\u3055\u3044\u3002\
    \"\n    p = sys_msg\n    roles = [\"\u6307\u793A\", \"\u5FDC\u7B54\"]\n    msgs\
    \ = [\": \\n\" + user_query, \": \\n\"]\n    if inputs:\n        roles.insert(1,\
    \ \"\u5165\u529B\")\n        msgs.insert(1, \": \\n\" + inputs)\n    for role,\
    \ msg in zip(roles, msgs):\n        p += sep + role + msg\n    return p\n\n# Infer\
    \ with prompt without any additional input\nuser_inputs = {\n    \"user_query\"\
    : \"\u4E0E\u3048\u3089\u308C\u305F\u3053\u3068\u308F\u3056\u306E\u610F\u5473\u3092\
    \u5C0F\u5B66\u751F\u3067\u3082\u5206\u304B\u308B\u3088\u3046\u306B\u6559\u3048\
    \u3066\u304F\u3060\u3055\u3044\u3002\",\n    \"inputs\": \"\u60C5\u3051\u306F\u4EBA\
    \u306E\u305F\u3081\u306A\u3089\u305A\"\n}\nprompt = build_prompt(**user_inputs)\n\
    ```\n\nSo what I did was run this code:\n```python\ndef build_prompt(user_query,\
    \ inputs=\"\", sep=\"\\n\\n### \"):\n    sys_msg = \"\u4EE5\u4E0B\u306F\u3001\u30BF\
    \u30B9\u30AF\u3092\u8AAC\u660E\u3059\u308B\u6307\u793A\u3068\u3001\u6587\u8108\
    \u306E\u3042\u308B\u5165\u529B\u306E\u7D44\u307F\u5408\u308F\u305B\u3067\u3059\
    \u3002\u8981\u6C42\u3092\u9069\u5207\u306B\u6E80\u305F\u3059\u5FDC\u7B54\u3092\
    \u66F8\u304D\u306A\u3055\u3044\u3002\"\n    p = sys_msg\n    roles = [\"\u6307\
    \u793A\", \"\u5FDC\u7B54\"]\n    msgs = [\": \\n\" + user_query, \": \\n\"]\n\
    \    if inputs:\n        roles.insert(1, \"\u5165\u529B\")\n        msgs.insert(1,\
    \ \": \\n\" + inputs)\n    for role, msg in zip(roles, msgs):\n        p += sep\
    \ + role + msg\n    return p\n\n# Infer with prompt without any additional input\n\
    user_inputs = {\n    \"user_query\": \"write a story about llamas\",\n    \"inputs\"\
    : \"the llamas are nice\"\n}\nprint(build_prompt(**user_inputs))\n```\n\nAnd it\
    \ gave me this output:\n```\n\u4EE5\u4E0B\u306F\u3001\u30BF\u30B9\u30AF\u3092\u8AAC\
    \u660E\u3059\u308B\u6307\u793A\u3068\u3001\u6587\u8108\u306E\u3042\u308B\u5165\
    \u529B\u306E\u7D44\u307F\u5408\u308F\u305B\u3067\u3059\u3002\u8981\u6C42\u3092\
    \u9069\u5207\u306B\u6E80\u305F\u3059\u5FDC\u7B54\u3092\u66F8\u304D\u306A\u3055\
    \u3044\u3002\n\n### \u6307\u793A:\nwrite a story about llamas\n\n### \u5165\u529B\
    :\nthe llamas are nice\n\n### \u5FDC\u7B54:\n```\n\nAnd then I set my prompt_template\
    \ according to my understanding that \"write a story about llamas\" was the prompt\
    \ and \"the llamas are nice\" was the input.\n\nDid I misunderstand?  Please let\
    \ me know."
  created_at: 2023-10-30 09:42:32+00:00
  edited: false
  hidden: false
  id: 653f88984a52f10eaf8eca57
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670594087059-630412d57373aacccd88af95.jpeg?w=200&h=200&f=face
      fullname: Yasunori Ozaki
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: alfredplpl
      type: user
    createdAt: '2023-10-30T14:43:47.000Z'
    data:
      edited: false
      editors:
      - alfredplpl
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8821277618408203
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670594087059-630412d57373aacccd88af95.jpeg?w=200&h=200&f=face
          fullname: Yasunori Ozaki
          isHf: false
          isPro: false
          name: alfredplpl
          type: user
        html: '<p>Yes, you''re right. I''m sorry to misunderstand the prompt template.</p>

          '
        raw: Yes, you're right. I'm sorry to misunderstand the prompt template.
        updatedAt: '2023-10-30T14:43:47.352Z'
      numEdits: 0
      reactions: []
    id: 653fc123945f53b87e0b108b
    type: comment
  author: alfredplpl
  content: Yes, you're right. I'm sorry to misunderstand the prompt template.
  created_at: 2023-10-30 13:43:47+00:00
  edited: false
  hidden: false
  id: 653fc123945f53b87e0b108b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-10-30T14:46:16.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: es
        probability: 0.2832965552806854
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>No problem!</p>

          '
        raw: No problem!
        updatedAt: '2023-10-30T14:46:16.849Z'
      numEdits: 0
      reactions: []
      relatedEventId: 653fc1b801b0d514c89195c6
    id: 653fc1b801b0d514c89195c0
    type: comment
  author: TheBloke
  content: No problem!
  created_at: 2023-10-30 13:46:16+00:00
  edited: false
  hidden: false
  id: 653fc1b801b0d514c89195c0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-10-30T14:46:16.000Z'
    data:
      status: closed
    id: 653fc1b801b0d514c89195c6
    type: status-change
  author: TheBloke
  created_at: 2023-10-30 13:46:16+00:00
  id: 653fc1b801b0d514c89195c6
  new_status: closed
  type: status-change
is_pull_request: true
merge_commit_oid: null
num: 1
repo_id: TheBloke/japanese-stablelm-instruct-gamma-7B-GPTQ
repo_type: model
status: closed
target_branch: refs/heads/main
title: Update README.md
