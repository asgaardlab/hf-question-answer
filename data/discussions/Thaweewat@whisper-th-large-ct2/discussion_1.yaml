!!python/object:huggingface_hub.community.DiscussionWithDetails
author: kobkrit
conflicting_files: null
created_at: 2024-01-06 05:24:25+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5fcd9c426d942eaf4d1ebd30/jEvknD1l_avxP4kDEel_C.jpeg?w=200&h=200&f=face
      fullname: Kobkrit Viriyayudhakorn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kobkrit
      type: user
    createdAt: '2024-01-06T05:24:25.000Z'
    data:
      edited: false
      editors:
      - kobkrit
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7956507802009583
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5fcd9c426d942eaf4d1ebd30/jEvknD1l_avxP4kDEel_C.jpeg?w=200&h=200&f=face
          fullname: Kobkrit Viriyayudhakorn
          isHf: false
          isPro: false
          name: kobkrit
          type: user
        html: '<p>Can you share evaluation result on this model?</p>

          '
        raw: Can you share evaluation result on this model?
        updatedAt: '2024-01-06T05:24:25.174Z'
      numEdits: 0
      reactions: []
    id: 6598e409eff07dcf1f2d04f8
    type: comment
  author: kobkrit
  content: Can you share evaluation result on this model?
  created_at: 2024-01-06 05:24:25+00:00
  edited: false
  hidden: false
  id: 6598e409eff07dcf1f2d04f8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63906a5ccd3cf0bc0044a76c/qSS4FofAfbMQRkUcc0-0F.jpeg?w=200&h=200&f=face
      fullname: Thaweewat R
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Thaweewat
      type: user
    createdAt: '2024-01-06T12:10:09.000Z'
    data:
      edited: true
      editors:
      - Thaweewat
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7668349742889404
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63906a5ccd3cf0bc0044a76c/qSS4FofAfbMQRkUcc0-0F.jpeg?w=200&h=200&f=face
          fullname: Thaweewat R
          isHf: false
          isPro: false
          name: Thaweewat
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;kobkrit&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/kobkrit\">@<span class=\"\
          underline\">kobkrit</span></a></span>\n\n\t</span></span> , the CTranslate\
          \ format shouldn't degrade the WER from the base model in most cases, so\
          \ the evaluation is theoretically close to the base model.<br>However, WhisperX\
          \ uses VAD preprocessing, so the results might be better. Thus, I conducted\
          \ my own evaluation on commonvoice 11.<br>The WER is around <strong>0.66</strong>\
          \ (no space) and around <strong>1.05</strong> ( raw output), whisper-th-large\
          \ is around 15 Which is better than I expected \U0001F44D<br>(I will run\
          \ the evaluation again in the future without using combined_text and will\
          \ let you know once it's done.)</p>\n<p>Here's how you can replicate the\
          \ evaluation , You can modify the code to support batching,<br>but due to\
          \ the speed of this model, it took me just around 30 minutes for a 10K test\
          \ set by  simple loop process.</p>\n<pre><code class=\"language-python\"\
          ><span class=\"hljs-keyword\">import</span> time\n<span class=\"hljs-keyword\"\
          >from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\
          \ \n<span class=\"hljs-keyword\">from</span> evaluate <span class=\"hljs-keyword\"\
          >import</span> load \n<span class=\"hljs-keyword\">from</span> tqdm <span\
          \ class=\"hljs-keyword\">import</span> tqdm  \n<span class=\"hljs-keyword\"\
          >import</span> whisperx \n\n<span class=\"hljs-comment\"># Load the Whisper\
          \ model</span>\ndevice = <span class=\"hljs-string\">\"cuda\"</span>  \n\
          batch_size = <span class=\"hljs-number\">16</span>  \ncompute_type = <span\
          \ class=\"hljs-string\">\"float16\"</span>  \nmodel = whisperx.load_model(<span\
          \ class=\"hljs-string\">\"Thaweewat/whisper-th-large-ct2\"</span>, device,\
          \ compute_type=compute_type)\n\n<span class=\"hljs-comment\"># Load the\
          \ WER metric and the dataset</span>\nwer = load(<span class=\"hljs-string\"\
          >\"wer\"</span>)\ntest_dataset = load_dataset(<span class=\"hljs-string\"\
          >\"mozilla-foundation/common_voice_11_0\"</span>, <span class=\"hljs-string\"\
          >\"th\"</span>, split=<span class=\"hljs-string\">\"test\"</span>)\n\n<span\
          \ class=\"hljs-comment\"># Initialize lists for predictions and references</span>\n\
          predictions = []\nreferences = []\n\n<span class=\"hljs-comment\"># Process\
          \ each audio file</span>\n<span class=\"hljs-keyword\">for</span> sample\
          \ <span class=\"hljs-keyword\">in</span> tqdm(test_dataset, desc=<span class=\"\
          hljs-string\">\"Processing Audio Files\"</span>): \n    audio_file = sample[<span\
          \ class=\"hljs-string\">'path'</span>]\n    ground_truth = sample[<span\
          \ class=\"hljs-string\">'sentence'</span>]\n\n    <span class=\"hljs-comment\"\
          ># Load and transcribe audio</span>\n    audio = whisperx.load_audio(audio_file)\n\
          \    result = model.transcribe(audio, batch_size=batch_size, language=<span\
          \ class=\"hljs-string\">'th'</span>)\n\n    <span class=\"hljs-comment\"\
          ># Combine text for evaluation</span>\n    combined_text = <span class=\"\
          hljs-string\">' '</span>.join(segment[<span class=\"hljs-string\">'text'</span>]\
          \ <span class=\"hljs-keyword\">for</span> segment <span class=\"hljs-keyword\"\
          >in</span> result[<span class=\"hljs-string\">'segments'</span>])\n    predictions.append(combined_text)\n\
          \    references.append(ground_truth)\n\n<span class=\"hljs-comment\"># Remove\
          \ spaces from each prediction &amp; Output the WER score </span>\npredictions_no_space\
          \ = [text.replace(<span class=\"hljs-string\">\" \"</span>, <span class=\"\
          hljs-string\">\"\"</span>) <span class=\"hljs-keyword\">for</span> text\
          \ <span class=\"hljs-keyword\">in</span> predictions]\nwer_score_no_space\
          \ = wer.compute(predictions=predictions_no_space, references=references)\n\
          wer_score = wer.compute(predictions=predictions, references=references)\n\
          <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"\
          Word Error Rate: <span class=\"hljs-subst\">{wer_score}</span>\"</span>)\n\
          <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"\
          Word Error Rate: <span class=\"hljs-subst\">{wer_score_no_space}</span>\"\
          </span>)\n</code></pre>\n"
        raw: "Hi @kobkrit , the CTranslate format shouldn't degrade the WER from the\
          \ base model in most cases, so the evaluation is theoretically close to\
          \ the base model. \nHowever, WhisperX uses VAD preprocessing, so the results\
          \ might be better. Thus, I conducted my own evaluation on commonvoice 11.\
          \  \nThe WER is around **0.66** (no space) and around **1.05** ( raw output),\
          \ whisper-th-large is around 15 Which is better than I expected \U0001F44D\
          \n(I will run the evaluation again in the future without using combined_text\
          \ and will let you know once it's done.)\n\nHere's how you can replicate\
          \ the evaluation , You can modify the code to support batching, \nbut due\
          \ to the speed of this model, it took me just around 30 minutes for a 10K\
          \ test set by  simple loop process.\n\n```python\nimport time\nfrom datasets\
          \ import load_dataset \nfrom evaluate import load \nfrom tqdm import tqdm\
          \  \nimport whisperx \n\n# Load the Whisper model\ndevice = \"cuda\"  \n\
          batch_size = 16  \ncompute_type = \"float16\"  \nmodel = whisperx.load_model(\"\
          Thaweewat/whisper-th-large-ct2\", device, compute_type=compute_type)\n\n\
          # Load the WER metric and the dataset\nwer = load(\"wer\")\ntest_dataset\
          \ = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"th\", split=\"\
          test\")\n\n# Initialize lists for predictions and references\npredictions\
          \ = []\nreferences = []\n\n# Process each audio file\nfor sample in tqdm(test_dataset,\
          \ desc=\"Processing Audio Files\"): \n    audio_file = sample['path']\n\
          \    ground_truth = sample['sentence']\n\n    # Load and transcribe audio\n\
          \    audio = whisperx.load_audio(audio_file)\n    result = model.transcribe(audio,\
          \ batch_size=batch_size, language='th')\n\n    # Combine text for evaluation\n\
          \    combined_text = ' '.join(segment['text'] for segment in result['segments'])\n\
          \    predictions.append(combined_text)\n    references.append(ground_truth)\n\
          \n# Remove spaces from each prediction & Output the WER score \npredictions_no_space\
          \ = [text.replace(\" \", \"\") for text in predictions]\nwer_score_no_space\
          \ = wer.compute(predictions=predictions_no_space, references=references)\n\
          wer_score = wer.compute(predictions=predictions, references=references)\n\
          print(f\"Word Error Rate: {wer_score}\")\nprint(f\"Word Error Rate: {wer_score_no_space}\"\
          )\n```"
        updatedAt: '2024-01-06T12:17:45.565Z'
      numEdits: 1
      reactions: []
    id: 65994321351b289063dfce83
    type: comment
  author: Thaweewat
  content: "Hi @kobkrit , the CTranslate format shouldn't degrade the WER from the\
    \ base model in most cases, so the evaluation is theoretically close to the base\
    \ model. \nHowever, WhisperX uses VAD preprocessing, so the results might be better.\
    \ Thus, I conducted my own evaluation on commonvoice 11.  \nThe WER is around\
    \ **0.66** (no space) and around **1.05** ( raw output), whisper-th-large is around\
    \ 15 Which is better than I expected \U0001F44D\n(I will run the evaluation again\
    \ in the future without using combined_text and will let you know once it's done.)\n\
    \nHere's how you can replicate the evaluation , You can modify the code to support\
    \ batching, \nbut due to the speed of this model, it took me just around 30 minutes\
    \ for a 10K test set by  simple loop process.\n\n```python\nimport time\nfrom\
    \ datasets import load_dataset \nfrom evaluate import load \nfrom tqdm import\
    \ tqdm  \nimport whisperx \n\n# Load the Whisper model\ndevice = \"cuda\"  \n\
    batch_size = 16  \ncompute_type = \"float16\"  \nmodel = whisperx.load_model(\"\
    Thaweewat/whisper-th-large-ct2\", device, compute_type=compute_type)\n\n# Load\
    \ the WER metric and the dataset\nwer = load(\"wer\")\ntest_dataset = load_dataset(\"\
    mozilla-foundation/common_voice_11_0\", \"th\", split=\"test\")\n\n# Initialize\
    \ lists for predictions and references\npredictions = []\nreferences = []\n\n\
    # Process each audio file\nfor sample in tqdm(test_dataset, desc=\"Processing\
    \ Audio Files\"): \n    audio_file = sample['path']\n    ground_truth = sample['sentence']\n\
    \n    # Load and transcribe audio\n    audio = whisperx.load_audio(audio_file)\n\
    \    result = model.transcribe(audio, batch_size=batch_size, language='th')\n\n\
    \    # Combine text for evaluation\n    combined_text = ' '.join(segment['text']\
    \ for segment in result['segments'])\n    predictions.append(combined_text)\n\
    \    references.append(ground_truth)\n\n# Remove spaces from each prediction &\
    \ Output the WER score \npredictions_no_space = [text.replace(\" \", \"\") for\
    \ text in predictions]\nwer_score_no_space = wer.compute(predictions=predictions_no_space,\
    \ references=references)\nwer_score = wer.compute(predictions=predictions, references=references)\n\
    print(f\"Word Error Rate: {wer_score}\")\nprint(f\"Word Error Rate: {wer_score_no_space}\"\
    )\n```"
  created_at: 2024-01-06 12:10:09+00:00
  edited: true
  hidden: false
  id: 65994321351b289063dfce83
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63906a5ccd3cf0bc0044a76c/qSS4FofAfbMQRkUcc0-0F.jpeg?w=200&h=200&f=face
      fullname: Thaweewat R
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Thaweewat
      type: user
    createdAt: '2024-01-06T12:18:16.000Z'
    data:
      status: closed
    id: 659945086da3461e28a7535a
    type: status-change
  author: Thaweewat
  created_at: 2024-01-06 12:18:16+00:00
  id: 659945086da3461e28a7535a
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5fcd9c426d942eaf4d1ebd30/jEvknD1l_avxP4kDEel_C.jpeg?w=200&h=200&f=face
      fullname: Kobkrit Viriyayudhakorn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: kobkrit
      type: user
    createdAt: '2024-01-06T12:23:43.000Z'
    data:
      edited: false
      editors:
      - kobkrit
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5393414497375488
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/5fcd9c426d942eaf4d1ebd30/jEvknD1l_avxP4kDEel_C.jpeg?w=200&h=200&f=face
          fullname: Kobkrit Viriyayudhakorn
          isHf: false
          isPro: false
          name: kobkrit
          type: user
        html: '<p>Superb!!!!!!!!</p>

          '
        raw: Superb!!!!!!!!
        updatedAt: '2024-01-06T12:23:43.097Z'
      numEdits: 0
      reactions: []
    id: 6599464f0e574e59dceb1387
    type: comment
  author: kobkrit
  content: Superb!!!!!!!!
  created_at: 2024-01-06 12:23:43+00:00
  edited: false
  hidden: false
  id: 6599464f0e574e59dceb1387
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Thaweewat/whisper-th-large-ct2
repo_type: model
status: closed
target_branch: null
title: Evaluation Result ?
