!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mayank31398
conflicting_files: []
created_at: 2023-04-22 12:21:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
      fullname: Mayank Mishra
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mayank31398
      type: user
    createdAt: '2023-04-22T13:21:11.000Z'
    data:
      edited: false
      editors:
      - mayank31398
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
          fullname: Mayank Mishra
          isHf: false
          isPro: false
          name: mayank31398
          type: user
        html: ''
        raw: ''
        updatedAt: '2023-04-22T13:21:11.938Z'
      numEdits: 0
      reactions: []
    id: 6443df47c63001ae634f6e60
    type: comment
  author: mayank31398
  content: ''
  created_at: 2023-04-22 12:21:11+00:00
  edited: false
  hidden: false
  id: 6443df47c63001ae634f6e60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
      fullname: Mayank Mishra
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mayank31398
      type: user
    createdAt: '2023-04-22T13:26:20.000Z'
    data:
      oid: 8c5534bb6a33b7bea90d9bd6f3b2194cfcc12f16
      parents:
      - 1233b5dccab64dedd8725aba9144557ebbc2d3f7
      subject: fix eos and bos token to match the tokenizer
    id: 6443e07c0000000000000000
    type: commit
  author: mayank31398
  created_at: 2023-04-22 12:26:20+00:00
  id: 6443e07c0000000000000000
  oid: 8c5534bb6a33b7bea90d9bd6f3b2194cfcc12f16
  summary: fix eos and bos token to match the tokenizer
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
      fullname: Mayank Mishra
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mayank31398
      type: user
    createdAt: '2023-04-22T13:28:46.000Z'
    data:
      edited: false
      editors:
      - mayank31398
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
          fullname: Mayank Mishra
          isHf: false
          isPro: false
          name: mayank31398
          type: user
        html: "<p>fixes the eos and bos token id in the config to match the tokenizer<br>The\
          \ generation config picks eos_token from the config and not the tokenizer.<br>So,\
          \ when specifying, min_new_tokens, the code crashes with the following error:</p>\n\
          <pre><code class=\"language-shell\">Traceback (most recent call last):\n\
          \  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/runpy.py\"\
          , line 194, in _run_module_as_main\n    return _run_code(code, main_globals,\
          \ None,\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/runpy.py\"\
          , line 87, in _run_code\n    exec(code, run_globals)\n  File \"/dccstor/mayankgpfs/scratch/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 90, in &lt;module&gt;\n    main()\n  File \"/dccstor/mayankgpfs/scratch/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 86, in main\n    simple_generation_test(tokenizer, model, args.prompt)\n\
          \  File \"/dccstor/mayankgpfs/scratch/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 55, in simple_generation_test\n    generated = model.generate(batch[\"\
          input_ids\"], do_sample=False, min_new_tokens=100, max_new_tokens=100)\n\
          \  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/utils.py\"\
          , line 1438, in generate\n    return self.greedy_search(\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/utils.py\"\
          , line 2263, in greedy_search\n    next_tokens_scores = logits_processor(input_ids,\
          \ next_token_logits)\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/logits_process.py\"\
          , line 92, in __call__\n    scores = processor(input_ids, scores)\n  File\
          \ \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/logits_process.py\"\
          , line 162, in __call__\n    scores[:, i] = -float(\"inf\")\nIndexError:\
          \ index 50256 is out of bounds for dimension 1 with size 49280\n</code></pre>\n"
        raw: "fixes the eos and bos token id in the config to match the tokenizer\n\
          The generation config picks eos_token from the config and not the tokenizer.\n\
          So, when specifying, min_new_tokens, the code crashes with the following\
          \ error:\n```shell\nTraceback (most recent call last):\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/runpy.py\"\
          , line 194, in _run_module_as_main\n    return _run_code(code, main_globals,\
          \ None,\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/runpy.py\"\
          , line 87, in _run_code\n    exec(code, run_globals)\n  File \"/dccstor/mayankgpfs/scratch/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 90, in <module>\n    main()\n  File \"/dccstor/mayankgpfs/scratch/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 86, in main\n    simple_generation_test(tokenizer, model, args.prompt)\n\
          \  File \"/dccstor/mayankgpfs/scratch/GPTQ-for-SantaCoder/santacoder_inference.py\"\
          , line 55, in simple_generation_test\n    generated = model.generate(batch[\"\
          input_ids\"], do_sample=False, min_new_tokens=100, max_new_tokens=100)\n\
          \  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/utils.py\"\
          , line 1438, in generate\n    return self.greedy_search(\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/utils.py\"\
          , line 2263, in greedy_search\n    next_tokens_scores = logits_processor(input_ids,\
          \ next_token_logits)\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/logits_process.py\"\
          , line 92, in __call__\n    scores = processor(input_ids, scores)\n  File\
          \ \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/logits_process.py\"\
          , line 162, in __call__\n    scores[:, i] = -float(\"inf\")\nIndexError:\
          \ index 50256 is out of bounds for dimension 1 with size 49280\n```"
        updatedAt: '2023-04-22T13:28:46.661Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6443e10e8f795c936dfee435
    id: 6443e10e8f795c936dfee434
    type: comment
  author: mayank31398
  content: "fixes the eos and bos token id in the config to match the tokenizer\n\
    The generation config picks eos_token from the config and not the tokenizer.\n\
    So, when specifying, min_new_tokens, the code crashes with the following error:\n\
    ```shell\nTraceback (most recent call last):\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/runpy.py\"\
    , line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n\
    \  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/runpy.py\", line\
    \ 87, in _run_code\n    exec(code, run_globals)\n  File \"/dccstor/mayankgpfs/scratch/GPTQ-for-SantaCoder/santacoder_inference.py\"\
    , line 90, in <module>\n    main()\n  File \"/dccstor/mayankgpfs/scratch/GPTQ-for-SantaCoder/santacoder_inference.py\"\
    , line 86, in main\n    simple_generation_test(tokenizer, model, args.prompt)\n\
    \  File \"/dccstor/mayankgpfs/scratch/GPTQ-for-SantaCoder/santacoder_inference.py\"\
    , line 55, in simple_generation_test\n    generated = model.generate(batch[\"\
    input_ids\"], do_sample=False, min_new_tokens=100, max_new_tokens=100)\n  File\
    \ \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/torch/autograd/grad_mode.py\"\
    , line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/utils.py\"\
    , line 1438, in generate\n    return self.greedy_search(\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/utils.py\"\
    , line 2263, in greedy_search\n    next_tokens_scores = logits_processor(input_ids,\
    \ next_token_logits)\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/logits_process.py\"\
    , line 92, in __call__\n    scores = processor(input_ids, scores)\n  File \"/dccstor/mayankgpfs/conda/envs/bloom/lib/python3.8/site-packages/transformers/generation/logits_process.py\"\
    , line 162, in __call__\n    scores[:, i] = -float(\"inf\")\nIndexError: index\
    \ 50256 is out of bounds for dimension 1 with size 49280\n```"
  created_at: 2023-04-22 12:28:46+00:00
  edited: false
  hidden: false
  id: 6443e10e8f795c936dfee434
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
      fullname: Mayank Mishra
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mayank31398
      type: user
    createdAt: '2023-04-22T13:28:46.000Z'
    data:
      status: open
    id: 6443e10e8f795c936dfee435
    type: status-change
  author: mayank31398
  created_at: 2023-04-22 12:28:46+00:00
  id: 6443e10e8f795c936dfee435
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62cd5057674cdb524450093d/Kc2vqHdAc96lAJjkLf1gB.jpeg?w=200&h=200&f=face
      fullname: Mayank Mishra
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: mayank31398
      type: user
    createdAt: '2023-04-22T18:31:17.000Z'
    data:
      status: merged
    id: 644427f55298d19c9c01e57b
    type: status-change
  author: mayank31398
  created_at: 2023-04-22 17:31:17+00:00
  id: 644427f55298d19c9c01e57b
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 7b85b24cf4472ca5e98b73c421ff4408ae814189
num: 1
repo_id: bigcode/gpt_bigcode-santacoder
repo_type: model
status: merged
target_branch: refs/heads/main
title: fix eos_token and bos_token in config
