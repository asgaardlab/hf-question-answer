!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nolannarine
conflicting_files: null
created_at: 2024-01-06 22:33:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f38a2877619d78e117e456f32f398ca1.svg
      fullname: Nolan Mangal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nolannarine
      type: user
    createdAt: '2024-01-06T22:33:51.000Z'
    data:
      edited: false
      editors:
      - nolannarine
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9846999645233154
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f38a2877619d78e117e456f32f398ca1.svg
          fullname: Nolan Mangal
          isHf: false
          isPro: false
          name: nolannarine
          type: user
        html: '<p>Just wondering if this is significantly better than orochi, or if
          it is about the same. I wouldn''t be that surprised if orochi more or less
          maxes out what we are capable of doing with Mixtral as a base, but I''d
          like to hear from the community.</p>

          '
        raw: Just wondering if this is significantly better than orochi, or if it
          is about the same. I wouldn't be that surprised if orochi more or less maxes
          out what we are capable of doing with Mixtral as a base, but I'd like to
          hear from the community.
        updatedAt: '2024-01-06T22:33:51.494Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - rombodawg
    id: 6599d54f2ca1fbfe1c877429
    type: comment
  author: nolannarine
  content: Just wondering if this is significantly better than orochi, or if it is
    about the same. I wouldn't be that surprised if orochi more or less maxes out
    what we are capable of doing with Mixtral as a base, but I'd like to hear from
    the community.
  created_at: 2024-01-06 22:33:51+00:00
  edited: false
  hidden: false
  id: 6599d54f2ca1fbfe1c877429
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
      fullname: rombo dawg
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: rombodawg
      type: user
    createdAt: '2024-01-06T22:39:12.000Z'
    data:
      edited: true
      editors:
      - rombodawg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9908769130706787
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/642cc1c253e76b4c2286c58e/n8h5JKRgaAoYrE36BtHRO.jpeg?w=200&h=200&f=face
          fullname: rombo dawg
          isHf: false
          isPro: false
          name: rombodawg
          type: user
        html: '<p>From my personal hand testing, and some help ive had from another
          member of the community, My impression was that It was overall better than
          orochi, with some of its own weird quirks. Your mileage may vary depending
          on your use case. But it seems to still lack behind mixtral-instruct in
          some ways which seems to be the struggle the community is dealing with right
          now (Not being able to get an overall better model than mixtral-instruct).
          Every fine tune, or mixture seems to keep taking something away from mixtral-instruct
          that it already was nearly perfect at</p>

          '
        raw: From my personal hand testing, and some help ive had from another member
          of the community, My impression was that It was overall better than orochi,
          with some of its own weird quirks. Your mileage may vary depending on your
          use case. But it seems to still lack behind mixtral-instruct in some ways
          which seems to be the struggle the community is dealing with right now (Not
          being able to get an overall better model than mixtral-instruct). Every
          fine tune, or mixture seems to keep taking something away from mixtral-instruct
          that it already was nearly perfect at
        updatedAt: '2024-01-06T22:39:24.021Z'
      numEdits: 1
      reactions: []
    id: 6599d6902fe7ca485fd30b57
    type: comment
  author: rombodawg
  content: From my personal hand testing, and some help ive had from another member
    of the community, My impression was that It was overall better than orochi, with
    some of its own weird quirks. Your mileage may vary depending on your use case.
    But it seems to still lack behind mixtral-instruct in some ways which seems to
    be the struggle the community is dealing with right now (Not being able to get
    an overall better model than mixtral-instruct). Every fine tune, or mixture seems
    to keep taking something away from mixtral-instruct that it already was nearly
    perfect at
  created_at: 2024-01-06 22:39:12+00:00
  edited: true
  hidden: false
  id: 6599d6902fe7ca485fd30b57
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: rombodawg/Open_Gpt4_8x7B_v0.1
repo_type: model
status: open
target_branch: null
title: How is the performance of this relative to Orochi?
