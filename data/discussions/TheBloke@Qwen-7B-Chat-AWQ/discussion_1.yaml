!!python/object:huggingface_hub.community.DiscussionWithDetails
author: joseph16388
conflicting_files: null
created_at: 2023-12-23 04:00:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b11a964297e716bf45dc5525e82f1d23.svg
      fullname: joseph16388
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joseph16388
      type: user
    createdAt: '2023-12-23T04:00:29.000Z'
    data:
      edited: true
      editors:
      - joseph16388
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.46841341257095337
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b11a964297e716bf45dc5525e82f1d23.svg
          fullname: joseph16388
          isHf: false
          isPro: false
          name: joseph16388
          type: user
        html: '<p>Hello!<br>When I run the following code I get the following error:<br>from
          transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer</p>

          <p>model_name_or_path = "model"</p>

          <p>tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)<br>model
          = AutoModelForCausalLM.from_pretrained(<br>model_name_or_path,<br>low_cpu_mem_usage=True,<br>device_map="cuda:0"<br>)</p>

          <p>tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)<br>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br>....\Lib\site-packages\transformers\models\auto\tokenization_auto.py",
          line 733, in from_pretrained<br>    raise ValueError(<br>ValueError: Tokenizer
          class QWenTokenizer does not exist or is not currently imported.</p>

          '
        raw: "Hello!\nWhen I run the following code I get the following error: \n\
          from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n\
          \nmodel_name_or_path = \"model\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n\
          model = AutoModelForCausalLM.from_pretrained(\nmodel_name_or_path,\nlow_cpu_mem_usage=True,\n\
          device_map=\"cuda:0\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n\
          \                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n....\\\
          Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py\",\
          \ line 733, in from_pretrained\n    raise ValueError(\nValueError: Tokenizer\
          \ class QWenTokenizer does not exist or is not currently imported.\n"
        updatedAt: '2023-12-23T04:00:58.926Z'
      numEdits: 1
      reactions: []
    id: 65865b5dce38d143c4f74d65
    type: comment
  author: joseph16388
  content: "Hello!\nWhen I run the following code I get the following error: \nfrom\
    \ transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n\nmodel_name_or_path\
    \ = \"model\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n\
    model = AutoModelForCausalLM.from_pretrained(\nmodel_name_or_path,\nlow_cpu_mem_usage=True,\n\
    device_map=\"cuda:0\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n\
    \                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n....\\Lib\\\
    site-packages\\transformers\\models\\auto\\tokenization_auto.py\", line 733, in\
    \ from_pretrained\n    raise ValueError(\nValueError: Tokenizer class QWenTokenizer\
    \ does not exist or is not currently imported.\n"
  created_at: 2023-12-23 04:00:29+00:00
  edited: true
  hidden: false
  id: 65865b5dce38d143c4f74d65
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Qwen-7B-Chat-AWQ
repo_type: model
status: open
target_branch: null
title: 'ValueError: Tokenizer class QWenTokenizer does not exist or is not currently
  imported.'
