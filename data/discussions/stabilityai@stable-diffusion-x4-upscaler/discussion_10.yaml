!!python/object:huggingface_hub.community.DiscussionWithDetails
author: LetsThink
conflicting_files: null
created_at: 2023-02-26 14:50:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9bbea28cefd71a119dfd7eaf4bf40715.svg
      fullname: Ruibin Li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LetsThink
      type: user
    createdAt: '2023-02-26T14:50:48.000Z'
    data:
      edited: true
      editors:
      - LetsThink
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9bbea28cefd71a119dfd7eaf4bf40715.svg
          fullname: Ruibin Li
          isHf: false
          isPro: false
          name: LetsThink
          type: user
        html: '<p>I try to fine-tuning the upscaler model with my own data, however,
          I find when I encode the 512x512 image to latent space 128x128 with the
          pretrain VAE parameter, I get nan with size [b,4,128,128].</p>

          <p>I have tracked the VAE forward function. I find that following the calculation
          map, the data will soon become huge and data overflow will happen. </p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1677422438991-63831508830bbad7b912151f.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1677422438991-63831508830bbad7b912151f.png"></a></p>

          <p>I use the stable diffusion fine-tuning script in the following link and
          modify the script with my own dataset since there is no finetuning script
          for this x4-upscaler model.<br><a rel="nofollow" href="https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py">https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py</a></p>

          <p>Is there any solution for this error?</p>

          '
        raw: "I try to fine-tuning the upscaler model with my own data, however, I\
          \ find when I encode the 512x512 image to latent space 128x128 with the\
          \ pretrain VAE parameter, I get nan with size [b,4,128,128].\n\nI have tracked\
          \ the VAE forward function. I find that following the calculation map, the\
          \ data will soon become huge and data overflow will happen. \n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1677422438991-63831508830bbad7b912151f.png)\n\
          \nI use the stable diffusion fine-tuning script in the following link and\
          \ modify the script with my own dataset since there is no finetuning script\
          \ for this x4-upscaler model.\nhttps://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py\n\
          \nIs there any solution for this error?"
        updatedAt: '2023-02-26T14:52:18.431Z'
      numEdits: 1
      reactions: []
    id: 63fb71c80aab060792f89cbc
    type: comment
  author: LetsThink
  content: "I try to fine-tuning the upscaler model with my own data, however, I find\
    \ when I encode the 512x512 image to latent space 128x128 with the pretrain VAE\
    \ parameter, I get nan with size [b,4,128,128].\n\nI have tracked the VAE forward\
    \ function. I find that following the calculation map, the data will soon become\
    \ huge and data overflow will happen. \n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/1677422438991-63831508830bbad7b912151f.png)\n\
    \nI use the stable diffusion fine-tuning script in the following link and modify\
    \ the script with my own dataset since there is no finetuning script for this\
    \ x4-upscaler model.\nhttps://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py\n\
    \nIs there any solution for this error?"
  created_at: 2023-02-26 14:50:48+00:00
  edited: true
  hidden: false
  id: 63fb71c80aab060792f89cbc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/56de69669d437842798cfd6d00fc4ee0.svg
      fullname: double8fun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: double8fun
      type: user
    createdAt: '2023-04-13T14:30:04.000Z'
    data:
      edited: true
      editors:
      - double8fun
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/56de69669d437842798cfd6d00fc4ee0.svg
          fullname: double8fun
          isHf: false
          isPro: false
          name: double8fun
          type: user
        html: '<p>use fp32 instead of fp16 and have a try.<br><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/634e9ae4de30ee205828138c/fivCmseIeUIzcBbkldv0C.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/634e9ae4de30ee205828138c/fivCmseIeUIzcBbkldv0C.png"></a></p>

          '
        raw: 'use fp32 instead of fp16 and have a try.

          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/634e9ae4de30ee205828138c/fivCmseIeUIzcBbkldv0C.png)'
        updatedAt: '2023-04-13T14:31:01.257Z'
      numEdits: 1
      reactions: []
    id: 643811ecf8a71f96bcdeefbd
    type: comment
  author: double8fun
  content: 'use fp32 instead of fp16 and have a try.

    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/634e9ae4de30ee205828138c/fivCmseIeUIzcBbkldv0C.png)'
  created_at: 2023-04-13 13:30:04+00:00
  edited: true
  hidden: false
  id: 643811ecf8a71f96bcdeefbd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9bbea28cefd71a119dfd7eaf4bf40715.svg
      fullname: Ruibin Li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LetsThink
      type: user
    createdAt: '2023-04-15T02:56:26.000Z'
    data:
      edited: false
      editors:
      - LetsThink
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9bbea28cefd71a119dfd7eaf4bf40715.svg
          fullname: Ruibin Li
          isHf: false
          isPro: false
          name: LetsThink
          type: user
        html: '<p>Thanks for your help,  this works. It seems when training text_to_img
          model, VAE model with --mixed_precision="fp16" can work fine. But for x4-upscaler
          model, just set VAE to torch.float16 will overflow.</p>

          '
        raw: Thanks for your help,  this works. It seems when training text_to_img
          model, VAE model with --mixed_precision="fp16" can work fine. But for x4-upscaler
          model, just set VAE to torch.float16 will overflow.
        updatedAt: '2023-04-15T02:56:26.181Z'
      numEdits: 0
      reactions: []
      relatedEventId: 643a125a1a9029fe65f1c6aa
    id: 643a125a1a9029fe65f1c6a9
    type: comment
  author: LetsThink
  content: Thanks for your help,  this works. It seems when training text_to_img model,
    VAE model with --mixed_precision="fp16" can work fine. But for x4-upscaler model,
    just set VAE to torch.float16 will overflow.
  created_at: 2023-04-15 01:56:26+00:00
  edited: false
  hidden: false
  id: 643a125a1a9029fe65f1c6a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9bbea28cefd71a119dfd7eaf4bf40715.svg
      fullname: Ruibin Li
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LetsThink
      type: user
    createdAt: '2023-04-15T02:56:26.000Z'
    data:
      status: closed
    id: 643a125a1a9029fe65f1c6aa
    type: status-change
  author: LetsThink
  created_at: 2023-04-15 01:56:26+00:00
  id: 643a125a1a9029fe65f1c6aa
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/857b0b4d115aa5ab2f143e60b0e4edc6.svg
      fullname: Yuntao Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YuntaoChen
      type: user
    createdAt: '2023-07-27T01:27:12.000Z'
    data:
      edited: false
      editors:
      - YuntaoChen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8237764239311218
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/857b0b4d115aa5ab2f143e60b0e4edc6.svg
          fullname: Yuntao Chen
          isHf: false
          isPro: false
          name: YuntaoChen
          type: user
        html: '<p>It seems that the 4x scaler vae will generate intermediate activation
          tensor with extreme values of 1e7-1e8</p>

          '
        raw: It seems that the 4x scaler vae will generate intermediate activation
          tensor with extreme values of 1e7-1e8
        updatedAt: '2023-07-27T01:27:12.265Z'
      numEdits: 0
      reactions: []
    id: 64c1c7f0e82e55936c046573
    type: comment
  author: YuntaoChen
  content: It seems that the 4x scaler vae will generate intermediate activation tensor
    with extreme values of 1e7-1e8
  created_at: 2023-07-27 00:27:12+00:00
  edited: false
  hidden: false
  id: 64c1c7f0e82e55936c046573
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: stabilityai/stable-diffusion-x4-upscaler
repo_type: model
status: closed
target_branch: null
title: Use pretrain VAE to encode a 512x512 image to latent space get nan, the image
  has been normalized to [-1,1]
