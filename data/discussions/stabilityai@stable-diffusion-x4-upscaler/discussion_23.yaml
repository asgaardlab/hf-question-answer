!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xings19
conflicting_files: null
created_at: 2023-07-17 14:26:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a77bb56726bae561fecb3719c66d1b7a.svg
      fullname: XingSen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xings19
      type: user
    createdAt: '2023-07-17T15:26:43.000Z'
    data:
      edited: false
      editors:
      - xings19
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6179259419441223
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a77bb56726bae561fecb3719c66d1b7a.svg
          fullname: XingSen
          isHf: false
          isPro: false
          name: xings19
          type: user
        html: '<p>my code:</p>

          <pre><code class="language-python">pipeline = StableDiffusionUpscalePipeline.from_pretrained(model_id,revision=<span
          class="hljs-string">"fp16"</span>,torch_dtype=torch.float16)

          pipeline = pipeline.to(<span class="hljs-string">"cuda"</span>)

          upscaled_image = pipeline(prompt=prompt, image=in_img).images[<span class="hljs-number">0</span>]

          </code></pre>

          <p>Error:</p>

          <pre><code class="language-text">torch.cuda.OutOfMemoryError: CUDA out of
          memory. Tried to allocate 112.50 GiB (GPU 0; 23.69 GiB total capacity; 3.62
          GiB already allocated; 18.78 GiB free; 3.92 GiB reserved in total by PyTorch)
          If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb
          to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

          </code></pre>

          <p>in_img size is (320,768)</p>

          '
        raw: "my code:\r\n```python\r\npipeline = StableDiffusionUpscalePipeline.from_pretrained(model_id,revision=\"\
          fp16\",torch_dtype=torch.float16)\r\npipeline = pipeline.to(\"cuda\")\r\n\
          upscaled_image = pipeline(prompt=prompt, image=in_img).images[0]\r\n```\r\
          \nError:\r\n```text\r\ntorch.cuda.OutOfMemoryError: CUDA out of memory.\
          \ Tried to allocate 112.50 GiB (GPU 0; 23.69 GiB total capacity; 3.62 GiB\
          \ already allocated; 18.78 GiB free; 3.92 GiB reserved in total by PyTorch)\
          \ If reserved memory is >> allocated memory try setting max_split_size_mb\
          \ to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\
          \n```\r\nin_img size is (320,768)"
        updatedAt: '2023-07-17T15:26:43.606Z'
      numEdits: 0
      reactions: []
    id: 64b55db368d745f5cb1c0e04
    type: comment
  author: xings19
  content: "my code:\r\n```python\r\npipeline = StableDiffusionUpscalePipeline.from_pretrained(model_id,revision=\"\
    fp16\",torch_dtype=torch.float16)\r\npipeline = pipeline.to(\"cuda\")\r\nupscaled_image\
    \ = pipeline(prompt=prompt, image=in_img).images[0]\r\n```\r\nError:\r\n```text\r\
    \ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.50 GiB\
    \ (GPU 0; 23.69 GiB total capacity; 3.62 GiB already allocated; 18.78 GiB free;\
    \ 3.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory\
    \ try setting max_split_size_mb to avoid fragmentation.  See documentation for\
    \ Memory Management and PYTORCH_CUDA_ALLOC_CONF\r\n```\r\nin_img size is (320,768)"
  created_at: 2023-07-17 14:26:43+00:00
  edited: false
  hidden: false
  id: 64b55db368d745f5cb1c0e04
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 23
repo_id: stabilityai/stable-diffusion-x4-upscaler
repo_type: model
status: open
target_branch: null
title: Cuda Out of Memory
