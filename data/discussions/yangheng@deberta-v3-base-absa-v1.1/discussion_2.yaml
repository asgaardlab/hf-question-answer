!!python/object:huggingface_hub.community.DiscussionWithDetails
author: naif576
conflicting_files: null
created_at: 2023-04-05 11:19:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa685f82ff9789c6fb68ac5642f955b7.svg
      fullname: Naif Saad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: naif576
      type: user
    createdAt: '2023-04-05T12:19:03.000Z'
    data:
      edited: false
      editors:
      - naif576
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa685f82ff9789c6fb68ac5642f955b7.svg
          fullname: Naif Saad
          isHf: false
          isPro: false
          name: naif576
          type: user
        html: '<p>hello there,<br>how can I fine tune this model using the trainer
          class by huggingface transformers?<br>What will be the input shape to the
          tokenizer.?</p>

          '
        raw: "hello there, \r\nhow can I fine tune this model using the trainer class\
          \ by huggingface transformers?\r\nWhat will be the input shape to the tokenizer.?"
        updatedAt: '2023-04-05T12:19:03.868Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Abesadi
      - count: 1
        reaction: "\U0001F44D"
        users:
        - turkenm
    id: 642d6737179328845319ea79
    type: comment
  author: naif576
  content: "hello there, \r\nhow can I fine tune this model using the trainer class\
    \ by huggingface transformers?\r\nWhat will be the input shape to the tokenizer.?"
  created_at: 2023-04-05 11:19:03+00:00
  edited: false
  hidden: false
  id: 642d6737179328845319ea79
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
      fullname: HENG YANG
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: yangheng
      type: user
    createdAt: '2023-04-10T17:37:45.000Z'
    data:
      edited: false
      editors:
      - yangheng
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
          fullname: HENG YANG
          isHf: false
          isPro: false
          name: yangheng
          type: user
        html: '<p>If you mean fine-tune a model based on this model, then you can
          refer to <a rel="nofollow" href="https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/Aspect_Sentiment_Classification.ipynb">https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/Aspect_Sentiment_Classification.ipynb</a>.
          Or if you want to fine-tune this model only, you may need to check the tutorials
          porvided by huggingface.</p>

          '
        raw: If you mean fine-tune a model based on this model, then you can refer
          to https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/Aspect_Sentiment_Classification.ipynb.
          Or if you want to fine-tune this model only, you may need to check the tutorials
          porvided by huggingface.
        updatedAt: '2023-04-10T17:37:45.081Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Abesadi
    id: 64344969d12a239d72e51c45
    type: comment
  author: yangheng
  content: If you mean fine-tune a model based on this model, then you can refer to
    https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/Aspect_Sentiment_Classification.ipynb.
    Or if you want to fine-tune this model only, you may need to check the tutorials
    porvided by huggingface.
  created_at: 2023-04-10 16:37:45+00:00
  edited: false
  hidden: false
  id: 64344969d12a239d72e51c45
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa685f82ff9789c6fb68ac5642f955b7.svg
      fullname: Naif Saad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: naif576
      type: user
    createdAt: '2023-04-10T18:06:53.000Z'
    data:
      edited: false
      editors:
      - naif576
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa685f82ff9789c6fb68ac5642f955b7.svg
          fullname: Naif Saad
          isHf: false
          isPro: false
          name: naif576
          type: user
        html: '<p>Yes I meant fine-tuning this model<br>But I am struggling with input.<br>How
          would combine the sentence with the aspect?<br>If you can provide a sample
          example of training this model using huggingface trainer, that would be
          helpful</p>

          '
        raw: "Yes I meant fine-tuning this model \nBut I am struggling with input.\n\
          How would combine the sentence with the aspect? \nIf you can provide a sample\
          \ example of training this model using huggingface trainer, that would be\
          \ helpful"
        updatedAt: '2023-04-10T18:06:53.405Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Abesadi
    id: 6434503def6d5abefe420324
    type: comment
  author: naif576
  content: "Yes I meant fine-tuning this model \nBut I am struggling with input.\n\
    How would combine the sentence with the aspect? \nIf you can provide a sample\
    \ example of training this model using huggingface trainer, that would be helpful"
  created_at: 2023-04-10 17:06:53+00:00
  edited: false
  hidden: false
  id: 6434503def6d5abefe420324
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1093db813d54f2ec8fbf05254925ac27.svg
      fullname: Sadi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Abesadi
      type: user
    createdAt: '2023-04-10T18:10:32.000Z'
    data:
      edited: false
      editors:
      - Abesadi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1093db813d54f2ec8fbf05254925ac27.svg
          fullname: Sadi
          isHf: false
          isPro: false
          name: Abesadi
          type: user
        html: "<p>I agree with <span data-props=\"{&quot;user&quot;:&quot;naif576&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/naif576\"\
          >@<span class=\"underline\">naif576</span></a></span>\n\n\t</span></span>\
          \ , Is there any example direction how we can use hugging face framework\
          \ to fine-tune the model, and how input data look like, also, is there any\
          \ concise documentation regarding quadruple extraction,, how to train the\
          \ model and how training input data will look like as well. Great work indeed\
          \ <span data-props=\"{&quot;user&quot;:&quot;yangheng&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/yangheng\">@<span class=\"\
          underline\">yangheng</span></a></span>\n\n\t</span></span></p>\n"
        raw: I agree with @naif576 , Is there any example direction how we can use
          hugging face framework to fine-tune the model, and how input data look like,
          also, is there any concise documentation regarding quadruple extraction,,
          how to train the model and how training input data will look like as well.
          Great work indeed @yangheng
        updatedAt: '2023-04-10T18:10:32.448Z'
      numEdits: 0
      reactions: []
    id: 64345118d72427b82480856b
    type: comment
  author: Abesadi
  content: I agree with @naif576 , Is there any example direction how we can use hugging
    face framework to fine-tune the model, and how input data look like, also, is
    there any concise documentation regarding quadruple extraction,, how to train
    the model and how training input data will look like as well. Great work indeed
    @yangheng
  created_at: 2023-04-10 17:10:32+00:00
  edited: false
  hidden: false
  id: 64345118d72427b82480856b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
      fullname: HENG YANG
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: yangheng
      type: user
    createdAt: '2023-04-12T17:35:52.000Z'
    data:
      edited: false
      editors:
      - yangheng
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
          fullname: HENG YANG
          isHf: false
          isPro: false
          name: yangheng
          type: user
        html: "<blockquote>\n<p>I agree with <span data-props=\"{&quot;user&quot;:&quot;naif576&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/naif576\"\
          >@<span class=\"underline\">naif576</span></a></span>\n\n\t</span></span>\
          \ , Is there any example direction how we can use hugging face framework\
          \ to fine-tune the model, and how input data look like, also, is there any\
          \ concise documentation regarding quadruple extraction,, how to train the\
          \ model and how training input data will look like as well. Great work indeed\
          \ <span data-props=\"{&quot;user&quot;:&quot;yangheng&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/yangheng\">@<span class=\"\
          underline\">yangheng</span></a></span>\n\n\t</span></span></p>\n</blockquote>\n\
          <p>Acutally, this model is only used for aspect sentiment classification.\
          \ Any task else you need to refer to the turorials in PyABSA.</p>\n"
        raw: '> I agree with @naif576 , Is there any example direction how we can
          use hugging face framework to fine-tune the model, and how input data look
          like, also, is there any concise documentation regarding quadruple extraction,,
          how to train the model and how training input data will look like as well.
          Great work indeed @yangheng


          Acutally, this model is only used for aspect sentiment classification. Any
          task else you need to refer to the turorials in PyABSA.'
        updatedAt: '2023-04-12T17:35:52.377Z'
      numEdits: 0
      reactions: []
    id: 6436ebf8197d3e05c1cb8eb0
    type: comment
  author: yangheng
  content: '> I agree with @naif576 , Is there any example direction how we can use
    hugging face framework to fine-tune the model, and how input data look like, also,
    is there any concise documentation regarding quadruple extraction,, how to train
    the model and how training input data will look like as well. Great work indeed
    @yangheng


    Acutally, this model is only used for aspect sentiment classification. Any task
    else you need to refer to the turorials in PyABSA.'
  created_at: 2023-04-12 16:35:52+00:00
  edited: false
  hidden: false
  id: 6436ebf8197d3e05c1cb8eb0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa685f82ff9789c6fb68ac5642f955b7.svg
      fullname: Naif Saad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: naif576
      type: user
    createdAt: '2023-04-12T17:47:47.000Z'
    data:
      edited: false
      editors:
      - naif576
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa685f82ff9789c6fb68ac5642f955b7.svg
          fullname: Naif Saad
          isHf: false
          isPro: false
          name: naif576
          type: user
        html: '<p>Ok, how can we train this model for aspect sentiment classification
          using the hugging face framework<br>And thanks for responding.</p>

          '
        raw: "Ok, how can we train this model for aspect sentiment classification\
          \ using the hugging face framework \nAnd thanks for responding."
        updatedAt: '2023-04-12T17:47:47.245Z'
      numEdits: 0
      reactions: []
    id: 6436eec3f8962b4332ba19d7
    type: comment
  author: naif576
  content: "Ok, how can we train this model for aspect sentiment classification using\
    \ the hugging face framework \nAnd thanks for responding."
  created_at: 2023-04-12 16:47:47+00:00
  edited: false
  hidden: false
  id: 6436eec3f8962b4332ba19d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
      fullname: HENG YANG
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: yangheng
      type: user
    createdAt: '2023-04-12T18:13:43.000Z'
    data:
      edited: true
      editors:
      - yangheng
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
          fullname: HENG YANG
          isHf: false
          isPro: false
          name: yangheng
          type: user
        html: "<p>import torch<br>from sklearn.metrics import accuracy_score, precision_recall_fscore_support<br>from\
          \ transformers import AutoTokenizer, AutoModelForSequenceClassification,\
          \ AdamW<br>from torch.utils.data import TensorDataset, DataLoader, RandomSampler,\
          \ SequentialSampler</p>\n<h1 id=\"set-the-batch-size\">Set the batch size</h1>\n\
          <p>batch_size = 16</p>\n<p>from datasets import load_dataset</p>\n<h1 id=\"\
          load-the-sst-2-dataset-from-the-glue-benchmark\">Load the SST-2 dataset\
          \ from the GLUE benchmark</h1>\n<p>dataset = load_dataset('glue', 'sst2')</p>\n\
          <h1 id=\"extract-the-texts-and-labels\">Extract the texts and labels</h1>\n\
          <p>train_texts = dataset['train']['sentence']<br>train_labels = dataset['train']['label']<br>test_texts\
          \ = dataset['validation']['sentence']<br>test_labels = dataset['validation']['label']</p>\n\
          <h1 id=\"load-the-tokenizer\">Load the tokenizer</h1>\n<p>tokenizer = AutoTokenizer.from_pretrained('yangheng/deberta-v3-base-absa-v1.1')</p>\n\
          <h1 id=\"tokenize-the-data\">Tokenize the data</h1>\n<p>train_encodings\
          \ = tokenizer(train_texts, truncation=True, padding=True, max_length=80)<br>test_encodings\
          \ = tokenizer(test_texts, truncation=True, padding=True, max_length=80)</p>\n\
          <p>train_dataset = TensorDataset(<br>    torch.tensor(train_encodings['input_ids']),<br>\
          \    torch.tensor(train_encodings['attention_mask']),<br>    torch.tensor(train_labels)<br>)</p>\n\
          <p>test_dataset = TensorDataset(<br>    torch.tensor(test_encodings['input_ids']),<br>\
          \    torch.tensor(test_encodings['attention_mask']),<br>    torch.tensor(test_labels)<br>)</p>\n\
          <h1 id=\"create-the-data-loaders\">Create the data loaders</h1>\n<p>train_sampler\
          \ = RandomSampler(train_dataset)<br>train_dataloader = DataLoader(train_dataset,\
          \ sampler=train_sampler, batch_size=batch_size)</p>\n<p>test_sampler = SequentialSampler(test_dataset)<br>test_dataloader\
          \ = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)</p>\n\
          <h1 id=\"load-the-model\">Load the model</h1>\n<p>model = AutoModelForSequenceClassification.from_pretrained('yangheng/deberta-v3-base-absa-v1.1')</p>\n\
          <p>model.to('cuda')</p>\n<h1 id=\"set-the-optimizer-and-learning-rate\"\
          >Set the optimizer and learning rate</h1>\n<p>optimizer = AdamW(model.parameters(),\
          \ lr=5e-5)</p>\n<h1 id=\"train-the-model\">Train the model</h1>\n<p>model.train()</p>\n\
          <p>for epoch in range(3):<br>    for batch in train_dataloader:<br>    \
          \    inputs = {<br>            'input_ids': batch[0].to('cuda'),<br>   \
          \         'attention_mask': batch[1].to('cuda'),<br>            'labels':\
          \ batch[2].to('cuda')<br>        }</p>\n<pre><code>    optimizer.zero_grad()\n\
          \n    outputs = model(**inputs)\n\n    loss = outputs.loss\n    loss.backward()\n\
          \n    optimizer.step()\n</code></pre>\n<h1 id=\"evaluate-the-model\">Evaluate\
          \ the model</h1>\n<p>model.eval()</p>\n<p>with torch.no_grad():<br>    for\
          \ batch in test_dataloader:<br>        inputs = {<br>            'input_ids':\
          \ batch[0],<br>            'attention_mask': batch[1],<br>            'labels':\
          \ batch[2]<br>        }</p>\n<pre><code>    outputs = model(**inputs)\n\n\
          \    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n\
          \n    with torch.no_grad():\n        all_predictions = []\n        all_labels\
          \ = []\n\n        for batch in test_dataloader:\n            inputs = {\n\
          \                'input_ids': batch[0],\n                'attention_mask':\
          \ batch[1],\n                'labels': batch[2]\n            }\n\n     \
          \       outputs = model(**inputs)\n\n            logits = outputs.logits\n\
          \            predictions = torch.argmax(logits, dim=-1)\n\n            all_predictions.extend(predictions.tolist())\n\
          \            all_labels.extend(inputs['labels'].tolist())\n\n    accuracy\
          \ = accuracy_score(all_labels, all_predictions)\n    precision, recall,\
          \ f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='binary')\n\
          \    print(f'Accuracy: {accuracy}')\n    print(f'Precision: {precision}')\n\
          \    print(f'Recall: {recall}')\n    print(f'F1: {f1}')\n</code></pre>\n"
        raw: "import torch\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\
          from transformers import AutoTokenizer, AutoModelForSequenceClassification,\
          \ AdamW\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler,\
          \ SequentialSampler\n\n# Set the batch size\nbatch_size = 16\n\nfrom datasets\
          \ import load_dataset\n\n# Load the SST-2 dataset from the GLUE benchmark\n\
          dataset = load_dataset('glue', 'sst2')\n\n# Extract the texts and labels\n\
          train_texts = dataset['train']['sentence']\ntrain_labels = dataset['train']['label']\n\
          test_texts = dataset['validation']['sentence']\ntest_labels = dataset['validation']['label']\n\
          \n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained('yangheng/deberta-v3-base-absa-v1.1')\n\
          \n# Tokenize the data\ntrain_encodings = tokenizer(train_texts, truncation=True,\
          \ padding=True, max_length=80)\ntest_encodings = tokenizer(test_texts, truncation=True,\
          \ padding=True, max_length=80)\n\ntrain_dataset = TensorDataset(\n    torch.tensor(train_encodings['input_ids']),\n\
          \    torch.tensor(train_encodings['attention_mask']),\n    torch.tensor(train_labels)\n\
          )\n\ntest_dataset = TensorDataset(\n    torch.tensor(test_encodings['input_ids']),\n\
          \    torch.tensor(test_encodings['attention_mask']),\n    torch.tensor(test_labels)\n\
          )\n\n# Create the data loaders\ntrain_sampler = RandomSampler(train_dataset)\n\
          train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n\
          \ntest_sampler = SequentialSampler(test_dataset)\ntest_dataloader = DataLoader(test_dataset,\
          \ sampler=test_sampler, batch_size=batch_size)\n\n# Load the model\nmodel\
          \ = AutoModelForSequenceClassification.from_pretrained('yangheng/deberta-v3-base-absa-v1.1')\n\
          \nmodel.to('cuda')\n\n# Set the optimizer and learning rate\noptimizer =\
          \ AdamW(model.parameters(), lr=5e-5)\n\n# Train the model\nmodel.train()\n\
          \nfor epoch in range(3):\n    for batch in train_dataloader:\n        inputs\
          \ = {\n            'input_ids': batch[0].to('cuda'),\n            'attention_mask':\
          \ batch[1].to('cuda'),\n            'labels': batch[2].to('cuda')\n    \
          \    }\n\n        optimizer.zero_grad()\n\n        outputs = model(**inputs)\n\
          \n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n\
          \n# Evaluate the model\nmodel.eval()\n\nwith torch.no_grad():\n    for batch\
          \ in test_dataloader:\n        inputs = {\n            'input_ids': batch[0],\n\
          \            'attention_mask': batch[1],\n            'labels': batch[2]\n\
          \        }\n\n        outputs = model(**inputs)\n\n        logits = outputs.logits\n\
          \        predictions = torch.argmax(logits, dim=-1)\n\n        with torch.no_grad():\n\
          \            all_predictions = []\n            all_labels = []\n\n     \
          \       for batch in test_dataloader:\n                inputs = {\n    \
          \                'input_ids': batch[0],\n                    'attention_mask':\
          \ batch[1],\n                    'labels': batch[2]\n                }\n\
          \n                outputs = model(**inputs)\n\n                logits =\
          \ outputs.logits\n                predictions = torch.argmax(logits, dim=-1)\n\
          \n                all_predictions.extend(predictions.tolist())\n       \
          \         all_labels.extend(inputs['labels'].tolist())\n\n        accuracy\
          \ = accuracy_score(all_labels, all_predictions)\n        precision, recall,\
          \ f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='binary')\n\
          \        print(f'Accuracy: {accuracy}')\n        print(f'Precision: {precision}')\n\
          \        print(f'Recall: {recall}')\n        print(f'F1: {f1}')"
        updatedAt: '2023-04-12T18:24:55.020Z'
      numEdits: 1
      reactions: []
    id: 6436f4d7a5b5d3fa4bef8496
    type: comment
  author: yangheng
  content: "import torch\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\
    from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n\
    from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\
    \n# Set the batch size\nbatch_size = 16\n\nfrom datasets import load_dataset\n\
    \n# Load the SST-2 dataset from the GLUE benchmark\ndataset = load_dataset('glue',\
    \ 'sst2')\n\n# Extract the texts and labels\ntrain_texts = dataset['train']['sentence']\n\
    train_labels = dataset['train']['label']\ntest_texts = dataset['validation']['sentence']\n\
    test_labels = dataset['validation']['label']\n\n\n# Load the tokenizer\ntokenizer\
    \ = AutoTokenizer.from_pretrained('yangheng/deberta-v3-base-absa-v1.1')\n\n# Tokenize\
    \ the data\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True,\
    \ max_length=80)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True,\
    \ max_length=80)\n\ntrain_dataset = TensorDataset(\n    torch.tensor(train_encodings['input_ids']),\n\
    \    torch.tensor(train_encodings['attention_mask']),\n    torch.tensor(train_labels)\n\
    )\n\ntest_dataset = TensorDataset(\n    torch.tensor(test_encodings['input_ids']),\n\
    \    torch.tensor(test_encodings['attention_mask']),\n    torch.tensor(test_labels)\n\
    )\n\n# Create the data loaders\ntrain_sampler = RandomSampler(train_dataset)\n\
    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n\
    \ntest_sampler = SequentialSampler(test_dataset)\ntest_dataloader = DataLoader(test_dataset,\
    \ sampler=test_sampler, batch_size=batch_size)\n\n# Load the model\nmodel = AutoModelForSequenceClassification.from_pretrained('yangheng/deberta-v3-base-absa-v1.1')\n\
    \nmodel.to('cuda')\n\n# Set the optimizer and learning rate\noptimizer = AdamW(model.parameters(),\
    \ lr=5e-5)\n\n# Train the model\nmodel.train()\n\nfor epoch in range(3):\n   \
    \ for batch in train_dataloader:\n        inputs = {\n            'input_ids':\
    \ batch[0].to('cuda'),\n            'attention_mask': batch[1].to('cuda'),\n \
    \           'labels': batch[2].to('cuda')\n        }\n\n        optimizer.zero_grad()\n\
    \n        outputs = model(**inputs)\n\n        loss = outputs.loss\n        loss.backward()\n\
    \n        optimizer.step()\n\n# Evaluate the model\nmodel.eval()\n\nwith torch.no_grad():\n\
    \    for batch in test_dataloader:\n        inputs = {\n            'input_ids':\
    \ batch[0],\n            'attention_mask': batch[1],\n            'labels': batch[2]\n\
    \        }\n\n        outputs = model(**inputs)\n\n        logits = outputs.logits\n\
    \        predictions = torch.argmax(logits, dim=-1)\n\n        with torch.no_grad():\n\
    \            all_predictions = []\n            all_labels = []\n\n           \
    \ for batch in test_dataloader:\n                inputs = {\n                \
    \    'input_ids': batch[0],\n                    'attention_mask': batch[1],\n\
    \                    'labels': batch[2]\n                }\n\n               \
    \ outputs = model(**inputs)\n\n                logits = outputs.logits\n     \
    \           predictions = torch.argmax(logits, dim=-1)\n\n                all_predictions.extend(predictions.tolist())\n\
    \                all_labels.extend(inputs['labels'].tolist())\n\n        accuracy\
    \ = accuracy_score(all_labels, all_predictions)\n        precision, recall, f1,\
    \ _ = precision_recall_fscore_support(all_labels, all_predictions, average='binary')\n\
    \        print(f'Accuracy: {accuracy}')\n        print(f'Precision: {precision}')\n\
    \        print(f'Recall: {recall}')\n        print(f'F1: {f1}')"
  created_at: 2023-04-12 17:13:43+00:00
  edited: true
  hidden: false
  id: 6436f4d7a5b5d3fa4bef8496
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
      fullname: HENG YANG
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: yangheng
      type: user
    createdAt: '2023-04-12T18:14:37.000Z'
    data:
      edited: false
      editors:
      - yangheng
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
          fullname: HENG YANG
          isHf: false
          isPro: false
          name: yangheng
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;naif576&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/naif576\">@<span class=\"\
          underline\">naif576</span></a></span>\n\n\t</span></span> <span data-props=\"\
          {&quot;user&quot;:&quot;Abesadi&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/Abesadi\">@<span class=\"underline\">Abesadi</span></a></span>\n\
          \n\t</span></span> Please see the example. However, I think it will be difficult\
          \ for you to prepare the dataset.</p>\n"
        raw: '@naif576 @Abesadi Please see the example. However, I think it will be
          difficult for you to prepare the dataset.'
        updatedAt: '2023-04-12T18:14:37.365Z'
      numEdits: 0
      reactions: []
    id: 6436f50d1ed4fe4c0e949954
    type: comment
  author: yangheng
  content: '@naif576 @Abesadi Please see the example. However, I think it will be
    difficult for you to prepare the dataset.'
  created_at: 2023-04-12 17:14:37+00:00
  edited: false
  hidden: false
  id: 6436f50d1ed4fe4c0e949954
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa685f82ff9789c6fb68ac5642f955b7.svg
      fullname: Naif Saad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: naif576
      type: user
    createdAt: '2023-04-12T18:54:11.000Z'
    data:
      edited: false
      editors:
      - naif576
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa685f82ff9789c6fb68ac5642f955b7.svg
          fullname: Naif Saad
          isHf: false
          isPro: false
          name: naif576
          type: user
        html: '<p>thank you so much<br>that helped me a lot<br>about the dataset,
          preparing the input is the main issue I am facing<br>I could not figure
          out how to combine the sentence with an aspect to feed it to the model for
          training.</p>

          <p>If you can edit the example and use it for aspect-based dataset</p>

          '
        raw: "thank you so much \nthat helped me a lot \nabout the dataset, preparing\
          \ the input is the main issue I am facing \nI could not figure out how to\
          \ combine the sentence with an aspect to feed it to the model for training.\n\
          \nIf you can edit the example and use it for aspect-based dataset"
        updatedAt: '2023-04-12T18:54:11.760Z'
      numEdits: 0
      reactions: []
    id: 6436fe53a9ac163631ad6b95
    type: comment
  author: naif576
  content: "thank you so much \nthat helped me a lot \nabout the dataset, preparing\
    \ the input is the main issue I am facing \nI could not figure out how to combine\
    \ the sentence with an aspect to feed it to the model for training.\n\nIf you\
    \ can edit the example and use it for aspect-based dataset"
  created_at: 2023-04-12 17:54:11+00:00
  edited: false
  hidden: false
  id: 6436fe53a9ac163631ad6b95
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1093db813d54f2ec8fbf05254925ac27.svg
      fullname: Sadi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Abesadi
      type: user
    createdAt: '2023-04-18T19:24:38.000Z'
    data:
      edited: false
      editors:
      - Abesadi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1093db813d54f2ec8fbf05254925ac27.svg
          fullname: Sadi
          isHf: false
          isPro: false
          name: Abesadi
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;yangheng&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/yangheng\">@<span class=\"\
          underline\">yangheng</span></a></span>\n\n\t</span></span>  can you please\
          \ confirm if input should be like below for above code script you shared:</p>\n\
          <p>I am an engineer and I use matlab and stata for data analysis and currently\
          \ taking Machine Learning course $T$ by Stanford which is fabulous .<br>course<br>Positive</p>\n"
        raw: '@yangheng  can you please confirm if input should be like below for
          above code script you shared:


          I am an engineer and I use matlab and stata for data analysis and currently
          taking Machine Learning course $T$ by Stanford which is fabulous .

          course

          Positive'
        updatedAt: '2023-04-18T19:24:38.839Z'
      numEdits: 0
      reactions: []
    id: 643eee76f2ed3bc5c063db1f
    type: comment
  author: Abesadi
  content: '@yangheng  can you please confirm if input should be like below for above
    code script you shared:


    I am an engineer and I use matlab and stata for data analysis and currently taking
    Machine Learning course $T$ by Stanford which is fabulous .

    course

    Positive'
  created_at: 2023-04-18 18:24:38+00:00
  edited: false
  hidden: false
  id: 643eee76f2ed3bc5c063db1f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
      fullname: HENG YANG
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: yangheng
      type: user
    createdAt: '2023-04-19T12:11:29.000Z'
    data:
      edited: true
      editors:
      - yangheng
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
          fullname: HENG YANG
          isHf: false
          isPro: false
          name: yangheng
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Abesadi&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Abesadi\">@<span class=\"\
          underline\">Abesadi</span></a></span>\n\n\t</span></span>  NO, it sould\
          \ be:</p>\n<p>I am an engineer and I use matlab and stata for data analysis\
          \ and currently taking Machine Learning $T$ by Stanford which is fabulous\
          \ .<br>course<br>Positive</p>\n<p>ref: <a rel=\"nofollow\" href=\"https://github.com/yangheng95/ABSADatasets/issues/47\"\
          >https://github.com/yangheng95/ABSADatasets/issues/47</a></p>\n"
        raw: '@Abesadi  NO, it sould be:


          I am an engineer and I use matlab and stata for data analysis and currently
          taking Machine Learning $T$ by Stanford which is fabulous .

          course

          Positive


          ref: https://github.com/yangheng95/ABSADatasets/issues/47'
        updatedAt: '2023-04-19T12:11:43.206Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F92F"
        users:
        - Ryukijano
    id: 643fda714164a65ca1232797
    type: comment
  author: yangheng
  content: '@Abesadi  NO, it sould be:


    I am an engineer and I use matlab and stata for data analysis and currently taking
    Machine Learning $T$ by Stanford which is fabulous .

    course

    Positive


    ref: https://github.com/yangheng95/ABSADatasets/issues/47'
  created_at: 2023-04-19 11:11:29+00:00
  edited: true
  hidden: false
  id: 643fda714164a65ca1232797
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0bbb33f2304256f9a0d784b812fdd44c.svg
      fullname: chenjy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sunybright
      type: user
    createdAt: '2023-06-18T12:12:16.000Z'
    data:
      edited: false
      editors:
      - sunybright
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.716973602771759
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0bbb33f2304256f9a0d784b812fdd44c.svg
          fullname: chenjy
          isHf: false
          isPro: false
          name: sunybright
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;yangheng&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/yangheng\">@<span class=\"\
          underline\">yangheng</span></a></span>\n\n\t</span></span> hello,good evening.I\
          \ try to run the code you have written above,but meet this error:</p>\n\
          <p>ModuleNotFoundError                       Traceback (most recent call\
          \ last)<br>Cell In[3], line 9<br>      4 from torch.utils.data import TensorDataset,\
          \ DataLoader, RandomSampler, SequentialSampler<br>      7 batch_size = 16<br>----&gt;\
          \ 9 from dataset import load_dataset</p>\n<p>ModuleNotFoundError: No module\
          \ named 'dataset'</p>\n<p>Could you tell me how to deal with it,please?\
          \ Thank you for reading and replying. </p>\n"
        raw: "@yangheng hello,good evening.I try to run the code you have written\
          \ above,but meet this error:\n\nModuleNotFoundError                    \
          \   Traceback (most recent call last)\nCell In[3], line 9\n      4 from\
          \ torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\
          \      7 batch_size = 16\n----> 9 from dataset import load_dataset\n\nModuleNotFoundError:\
          \ No module named 'dataset'\n\nCould you tell me how to deal with it,please?\
          \ Thank you for reading and replying. "
        updatedAt: '2023-06-18T12:12:16.152Z'
      numEdits: 0
      reactions: []
    id: 648ef4a091951fb245d7fe27
    type: comment
  author: sunybright
  content: "@yangheng hello,good evening.I try to run the code you have written above,but\
    \ meet this error:\n\nModuleNotFoundError                       Traceback (most\
    \ recent call last)\nCell In[3], line 9\n      4 from torch.utils.data import\
    \ TensorDataset, DataLoader, RandomSampler, SequentialSampler\n      7 batch_size\
    \ = 16\n----> 9 from dataset import load_dataset\n\nModuleNotFoundError: No module\
    \ named 'dataset'\n\nCould you tell me how to deal with it,please? Thank you for\
    \ reading and replying. "
  created_at: 2023-06-18 11:12:16+00:00
  edited: false
  hidden: false
  id: 648ef4a091951fb245d7fe27
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fa685f82ff9789c6fb68ac5642f955b7.svg
      fullname: Naif Saad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: naif576
      type: user
    createdAt: '2023-06-18T12:52:04.000Z'
    data:
      edited: false
      editors:
      - naif576
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5677917003631592
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fa685f82ff9789c6fb68ac5642f955b7.svg
          fullname: Naif Saad
          isHf: false
          isPro: false
          name: naif576
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sunybright&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sunybright\">@<span class=\"\
          underline\">sunybright</span></a></span>\n\n\t</span></span>  </p>\n<p>run<br>pip\
          \ install datasets</p>\n"
        raw: "@sunybright  \n\nrun \npip install datasets"
        updatedAt: '2023-06-18T12:52:04.107Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - sunybright
    id: 648efdf4434eed3599bda511
    type: comment
  author: naif576
  content: "@sunybright  \n\nrun \npip install datasets"
  created_at: 2023-06-18 11:52:04+00:00
  edited: false
  hidden: false
  id: 648efdf4434eed3599bda511
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0bbb33f2304256f9a0d784b812fdd44c.svg
      fullname: chenjy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sunybright
      type: user
    createdAt: '2023-06-20T08:42:19.000Z'
    data:
      edited: false
      editors:
      - sunybright
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8477050065994263
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0bbb33f2304256f9a0d784b812fdd44c.svg
          fullname: chenjy
          isHf: false
          isPro: false
          name: sunybright
          type: user
        html: '<p>Hello,could you help me to ensure whether I feed the data to the
          model  in the right way?<br> I have seen the train data given online,which
          looks like:<br>==========================================================================<br>Mmmm&amp;
          I forgot how much I love having a $T$ . Even if it is slightly pointless
          !<br>ipad<br>Positive<br>==========================================================================<br>But
          I don''t konw how to feed data of this form to the model .Thus I only input
          the sentence and the label into the model,<br>the sentence(before encoding)
          is like(just replace the aspect with $T$):<br>my day off after a wedding
          consist of $T$ zelda and chinese food.<br>and the labels are 0 or 1  or
          2(not one_hot vector)</p>

          <p>Thanks for your reading and replying.</p>

          '
        raw: "Hello,could you help me to ensure whether I feed the data to the model\
          \  in the right way?\n I have seen the train data given online,which looks\
          \ like:\n==========================================================================\n\
          Mmmm& I forgot how much I love having a $T$ . Even if it is slightly pointless\
          \ !\nipad\nPositive\n==========================================================================\n\
          But I don't konw how to feed data of this form to the model .Thus I only\
          \ input the sentence and the label into the model,\nthe sentence(before\
          \ encoding) is like(just replace the aspect with $T$):\nmy day off after\
          \ a wedding consist of $T$ zelda and chinese food.\nand the labels are 0\
          \ or 1  or 2(not one_hot vector)\n\n\nThanks for your reading and replying."
        updatedAt: '2023-06-20T08:42:19.335Z'
      numEdits: 0
      reactions: []
    id: 6491666b8d62a5e264bf7154
    type: comment
  author: sunybright
  content: "Hello,could you help me to ensure whether I feed the data to the model\
    \  in the right way?\n I have seen the train data given online,which looks like:\n\
    ==========================================================================\nMmmm&\
    \ I forgot how much I love having a $T$ . Even if it is slightly pointless !\n\
    ipad\nPositive\n==========================================================================\n\
    But I don't konw how to feed data of this form to the model .Thus I only input\
    \ the sentence and the label into the model,\nthe sentence(before encoding) is\
    \ like(just replace the aspect with $T$):\nmy day off after a wedding consist\
    \ of $T$ zelda and chinese food.\nand the labels are 0 or 1  or 2(not one_hot\
    \ vector)\n\n\nThanks for your reading and replying."
  created_at: 2023-06-20 07:42:19+00:00
  edited: false
  hidden: false
  id: 6491666b8d62a5e264bf7154
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
      fullname: HENG YANG
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: yangheng
      type: user
    createdAt: '2023-06-20T09:02:35.000Z'
    data:
      edited: false
      editors:
      - yangheng
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5239642262458801
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1648662840473-61a7780d989fb8e2c252be60.jpeg?w=200&h=200&f=face
          fullname: HENG YANG
          isHf: false
          isPro: false
          name: yangheng
          type: user
        html: '<p><a rel="nofollow" href="https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/inference.py">https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/inference.py</a></p>

          '
        raw: https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/inference.py
        updatedAt: '2023-06-20T09:02:35.082Z'
      numEdits: 0
      reactions: []
    id: 64916b2b6d765d8e6b330134
    type: comment
  author: yangheng
  content: https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/inference.py
  created_at: 2023-06-20 08:02:35+00:00
  edited: false
  hidden: false
  id: 64916b2b6d765d8e6b330134
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0bbb33f2304256f9a0d784b812fdd44c.svg
      fullname: chenjy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sunybright
      type: user
    createdAt: '2023-06-20T09:58:00.000Z'
    data:
      edited: false
      editors:
      - sunybright
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9018542766571045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0bbb33f2304256f9a0d784b812fdd44c.svg
          fullname: chenjy
          isHf: false
          isPro: false
          name: sunybright
          type: user
        html: '<p>oh,sorry,maybe I have not made myself clear. I want to fine-tune
          the model to fit on my own dataset,it seems that the method given in <a
          rel="nofollow" href="https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/inference.py">https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/inference.py</a>
          doesn''t give an example of fine-tuning a model.I follow the code you have
          written in your previous notations(<a href="https://huggingface.co/yangheng/deberta-v3-base-absa-v1.1/discussions/2#6491666b8d62a5e264bf7154">https://huggingface.co/yangheng/deberta-v3-base-absa-v1.1/discussions/2#6491666b8d62a5e264bf7154</a>)
          but don''t know what train_texts and test_texts should be looked like?<br>Thank
          you for helping.</p>

          '
        raw: "oh,sorry,maybe I have not made myself clear. I want to fine-tune the\
          \ model to fit on my own dataset,it seems that the method given in https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/inference.py\
          \ doesn't give an example of fine-tuning a model.I follow the code you have\
          \ written in your previous notations(https://huggingface.co/yangheng/deberta-v3-base-absa-v1.1/discussions/2#6491666b8d62a5e264bf7154)\
          \ but don't know what train_texts and test_texts should be looked like?\
          \ \nThank you for helping."
        updatedAt: '2023-06-20T09:58:00.733Z'
      numEdits: 0
      reactions: []
    id: 649178283b5cf91ae5d88148
    type: comment
  author: sunybright
  content: "oh,sorry,maybe I have not made myself clear. I want to fine-tune the model\
    \ to fit on my own dataset,it seems that the method given in https://github.com/yangheng95/PyABSA/blob/v2/examples-v2/aspect_polarity_classification/inference.py\
    \ doesn't give an example of fine-tuning a model.I follow the code you have written\
    \ in your previous notations(https://huggingface.co/yangheng/deberta-v3-base-absa-v1.1/discussions/2#6491666b8d62a5e264bf7154)\
    \ but don't know what train_texts and test_texts should be looked like? \nThank\
    \ you for helping."
  created_at: 2023-06-20 08:58:00+00:00
  edited: false
  hidden: false
  id: 649178283b5cf91ae5d88148
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: yangheng/deberta-v3-base-absa-v1.1
repo_type: model
status: open
target_branch: null
title: 'Fine-tuning using transformers trainer '
