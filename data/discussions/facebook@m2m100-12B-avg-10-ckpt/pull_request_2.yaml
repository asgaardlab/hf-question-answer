!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tomsherborne
conflicting_files: []
created_at: 2023-06-06 19:59:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1c0575701529ae0f15a6fed6834a473c.svg
      fullname: Tom Sherborne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomsherborne
      type: user
    createdAt: '2023-06-06T20:59:55.000Z'
    data:
      edited: false
      editors:
      - tomsherborne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8351491093635559
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1c0575701529ae0f15a6fed6834a473c.svg
          fullname: Tom Sherborne
          isHf: false
          isPro: false
          name: tomsherborne
          type: user
        html: '<p>The 12B model does not match the performance of the 1.2B model as
          the generation defaults to the max_length of "20". This results in shorter
          sequences than the model should be generating. For example on WMT14-DE-EN:
          the 12B model scores 15.52 and the 1.2B model scores 31.786 (SacreBLEU).
          The default max_length is properly set in the smaller models (see <a href="https://huggingface.co/facebook/m2m100_1.2B/blob/main/generation_config.json">https://huggingface.co/facebook/m2m100_1.2B/blob/main/generation_config.json</a>)
          and the 12B models should match this. I am submitting similar PRs for the
          other 12B models.</p>

          '
        raw: 'The 12B model does not match the performance of the 1.2B model as the
          generation defaults to the max_length of "20". This results in shorter sequences
          than the model should be generating. For example on WMT14-DE-EN: the 12B
          model scores 15.52 and the 1.2B model scores 31.786 (SacreBLEU). The default
          max_length is properly set in the smaller models (see https://huggingface.co/facebook/m2m100_1.2B/blob/main/generation_config.json)
          and the 12B models should match this. I am submitting similar PRs for the
          other 12B models.'
        updatedAt: '2023-06-06T20:59:55.348Z'
      numEdits: 0
      reactions: []
    id: 647f9e4bcbb8294ed80873d3
    type: comment
  author: tomsherborne
  content: 'The 12B model does not match the performance of the 1.2B model as the
    generation defaults to the max_length of "20". This results in shorter sequences
    than the model should be generating. For example on WMT14-DE-EN: the 12B model
    scores 15.52 and the 1.2B model scores 31.786 (SacreBLEU). The default max_length
    is properly set in the smaller models (see https://huggingface.co/facebook/m2m100_1.2B/blob/main/generation_config.json)
    and the 12B models should match this. I am submitting similar PRs for the other
    12B models.'
  created_at: 2023-06-06 19:59:55+00:00
  edited: false
  hidden: false
  id: 647f9e4bcbb8294ed80873d3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/1c0575701529ae0f15a6fed6834a473c.svg
      fullname: Tom Sherborne
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tomsherborne
      type: user
    createdAt: '2023-06-06T20:59:56.000Z'
    data:
      oid: 4c85d39b86f72068143bf4e0c2e8b14d808fece3
      parents:
      - 31869cd623bdb0fac1f4980ca0b49a1fb5ea3097
      subject: Add the "max_length" parameter to the Generation configuration.
    id: 647f9e4c0000000000000000
    type: commit
  author: tomsherborne
  created_at: 2023-06-06 19:59:56+00:00
  id: 647f9e4c0000000000000000
  oid: 4c85d39b86f72068143bf4e0c2e8b14d808fece3
  summary: Add the "max_length" parameter to the Generation configuration.
  type: commit
is_pull_request: true
merge_commit_oid: null
num: 2
repo_id: facebook/m2m100-12B-avg-10-ckpt
repo_type: model
status: open
target_branch: refs/heads/main
title: Add the "max_length" parameter to the Generation configuration.
