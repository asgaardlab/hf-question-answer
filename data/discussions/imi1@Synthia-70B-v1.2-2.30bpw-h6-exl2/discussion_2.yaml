!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Ixel1
conflicting_files: null
created_at: 2023-09-27 07:40:32+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3e55c2053d58df3fcef8b18fc8958c31.svg
      fullname: Paul
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ixel1
      type: user
    createdAt: '2023-09-27T08:40:32.000Z'
    data:
      edited: false
      editors:
      - Ixel1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9069914817810059
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3e55c2053d58df3fcef8b18fc8958c31.svg
          fullname: Paul
          isHf: false
          isPro: false
          name: Ixel1
          type: user
        html: '<p>Just wanting to say thanks for quantising this so that I can fit
          it on an RTX 3090 GPU. So far, of all the models I''ve tried this is performing
          the best for my use case (analysing whether a user message contains certain
          words or variations of the word to evade detection). It works nice.</p>

          '
        raw: Just wanting to say thanks for quantising this so that I can fit it on
          an RTX 3090 GPU. So far, of all the models I've tried this is performing
          the best for my use case (analysing whether a user message contains certain
          words or variations of the word to evade detection). It works nice.
        updatedAt: '2023-09-27T08:40:32.415Z'
      numEdits: 0
      reactions: []
    id: 6513ea80739b1a50b2a50cac
    type: comment
  author: Ixel1
  content: Just wanting to say thanks for quantising this so that I can fit it on
    an RTX 3090 GPU. So far, of all the models I've tried this is performing the best
    for my use case (analysing whether a user message contains certain words or variations
    of the word to evade detection). It works nice.
  created_at: 2023-09-27 07:40:32+00:00
  edited: false
  hidden: false
  id: 6513ea80739b1a50b2a50cac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3e55c2053d58df3fcef8b18fc8958c31.svg
      fullname: Paul
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ixel1
      type: user
    createdAt: '2023-09-27T18:19:29.000Z'
    data:
      status: closed
    id: 651472317f797735a04cf4ad
    type: status-change
  author: Ixel1
  created_at: 2023-09-27 17:19:29+00:00
  id: 651472317f797735a04cf4ad
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b9d89b26c53dbee663bf8e599e294d1b.svg
      fullname: imi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: imi1
      type: user
    createdAt: '2023-09-29T12:19:40.000Z'
    data:
      edited: false
      editors:
      - imi1
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9518279433250427
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b9d89b26c53dbee663bf8e599e294d1b.svg
          fullname: imi
          isHf: false
          isPro: false
          name: imi1
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Ixel1&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Ixel1\">@<span class=\"\
          underline\">Ixel1</span></a></span>\n\n\t</span></span>, happy to hear,\
          \ though I should mention that this model is not the very latest. It was\
          \ quantized with the wikitest parquet file many people use for calibration.\
          \ I might do 70B 1.2b (2.55bpw and 2.3bpw) later, recent changes broke the\
          \ quantization/calibration on windows so I might need to switch OS if I\
          \ want to do more :)</p>\n"
        raw: '@Ixel1, happy to hear, though I should mention that this model is not
          the very latest. It was quantized with the wikitest parquet file many people
          use for calibration. I might do 70B 1.2b (2.55bpw and 2.3bpw) later, recent
          changes broke the quantization/calibration on windows so I might need to
          switch OS if I want to do more :)'
        updatedAt: '2023-09-29T12:19:40.155Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Ixel1
    id: 6516c0dc7f18cec973c9ed56
    type: comment
  author: imi1
  content: '@Ixel1, happy to hear, though I should mention that this model is not
    the very latest. It was quantized with the wikitest parquet file many people use
    for calibration. I might do 70B 1.2b (2.55bpw and 2.3bpw) later, recent changes
    broke the quantization/calibration on windows so I might need to switch OS if
    I want to do more :)'
  created_at: 2023-09-29 11:19:40+00:00
  edited: false
  hidden: false
  id: 6516c0dc7f18cec973c9ed56
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: imi1/Synthia-70B-v1.2-2.30bpw-h6-exl2
repo_type: model
status: closed
target_branch: null
title: Thanks
