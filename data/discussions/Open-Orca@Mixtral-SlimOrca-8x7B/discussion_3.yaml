!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Phil337
conflicting_files: null
created_at: 2023-12-14 03:16:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-14T03:16:26.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9600066542625427
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>Mistral is bragging that it beats GPT3.5 across the board, including
          with an Arc score of 85.8, yet all models are only achieving 66.</p>

          <p>Can someone PLEASE explain why this discrepancy exists? Did they run
          the test using all 8 experts at once during inference rather than 2 in order
          to hit 85.8 on the Arc test?</p>

          '
        raw: "Mistral is bragging that it beats GPT3.5 across the board, including\
          \ with an Arc score of 85.8, yet all models are only achieving 66.\r\n\r\
          \nCan someone PLEASE explain why this discrepancy exists? Did they run the\
          \ test using all 8 experts at once during inference rather than 2 in order\
          \ to hit 85.8 on the Arc test?"
        updatedAt: '2023-12-14T03:16:26.782Z'
      numEdits: 0
      reactions: []
    id: 657a738ac28ce07c52b266b8
    type: comment
  author: Phil337
  content: "Mistral is bragging that it beats GPT3.5 across the board, including with\
    \ an Arc score of 85.8, yet all models are only achieving 66.\r\n\r\nCan someone\
    \ PLEASE explain why this discrepancy exists? Did they run the test using all\
    \ 8 experts at once during inference rather than 2 in order to hit 85.8 on the\
    \ Arc test?"
  created_at: 2023-12-14 03:16:26+00:00
  edited: false
  hidden: false
  id: 657a738ac28ce07c52b266b8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-12-14T17:51:36.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9170659780502319
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>First on the leaderboard I see 70.22 not 66.<br>Second that ARC
          85.8 is getting medium version not small like we got so far.</p>

          '
        raw: 'First on the leaderboard I see 70.22 not 66.

          Second that ARC 85.8 is getting medium version not small like we got so
          far.'
        updatedAt: '2023-12-14T17:51:36.684Z'
      numEdits: 0
      reactions: []
    id: 657b40a8688f1a0f7ea7d534
    type: comment
  author: mirek190
  content: 'First on the leaderboard I see 70.22 not 66.

    Second that ARC 85.8 is getting medium version not small like we got so far.'
  created_at: 2023-12-14 17:51:36+00:00
  edited: false
  hidden: false
  id: 657b40a8688f1a0f7ea7d534
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-14T18:06:45.000Z'
    data:
      edited: true
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9264975786209106
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/mirek190\">@<span class=\"\
          underline\">mirek190</span></a></span>\n\n\t</span></span> Thanks for responding.\
          \ But I just double checked and confirmed that the Arc score of 85.8 is\
          \ for the foundational 7x8 model (e.g. see the link to their website below).\
          \ 70.22 is for the instruct, 66 for the foundational.</p>\n<p>Plus all the\
          \ other scores for 8x7b match perfectly (e.g. MMLU, HellaSwag and Winogrande)\
          \ and the as yet unreleased \"medium\" model reports scores that are about\
          \ 3-5 points higher than these across the board. </p>\n<p>The 85.8 Arc score\
          \ needs to be independently verified ASAP.  A claim of matching GPT3.5's\
          \ performance was ALWAYS about Arc. Mistral 7b already came within 3-5 points\
          \ of matching GPT3.5 on the other benchmarks like (65 MMLU, 83 HellaSwag,\
          \ 78 WinoGrande). Simply boosting Mistral 7b to Mistral 14b dense would\
          \ have easily matched GPT3.5's performance on all but Arc. Arc requires\
          \ \"brains\" (60 for Mistral 7b and 85 for GPT3.5). Mixtral 7x8 isn't performing\
          \ better on most tests, including Arc, than Mistral 14b dense would have\
          \ sans the multi-linguage upgrade (French, Spanish... x3).</p>\n<p><a rel=\"\
          nofollow\" href=\"https://mistral.ai/news/mixtral-of-experts/\">https://mistral.ai/news/mixtral-of-experts/</a></p>\n"
        raw: "@mirek190 Thanks for responding. But I just double checked and confirmed\
          \ that the Arc score of 85.8 is for the foundational 7x8 model (e.g. see\
          \ the link to their website below). 70.22 is for the instruct, 66 for the\
          \ foundational.\n\nPlus all the other scores for 8x7b match perfectly (e.g.\
          \ MMLU, HellaSwag and Winogrande) and the as yet unreleased \"medium\" model\
          \ reports scores that are about 3-5 points higher than these across the\
          \ board. \n\nThe 85.8 Arc score needs to be independently verified ASAP.\
          \  A claim of matching GPT3.5's performance was ALWAYS about Arc. Mistral\
          \ 7b already came within 3-5 points of matching GPT3.5 on the other benchmarks\
          \ like (65 MMLU, 83 HellaSwag, 78 WinoGrande). Simply boosting Mistral 7b\
          \ to Mistral 14b dense would have easily matched GPT3.5's performance on\
          \ all but Arc. Arc requires \"brains\" (60 for Mistral 7b and 85 for GPT3.5).\
          \ Mixtral 7x8 isn't performing better on most tests, including Arc, than\
          \ Mistral 14b dense would have sans the multi-linguage upgrade (French,\
          \ Spanish... x3).\n\nhttps://mistral.ai/news/mixtral-of-experts/\n\n"
        updatedAt: '2023-12-14T18:10:04.986Z'
      numEdits: 1
      reactions: []
    id: 657b4435688f1a0f7ea8b8b8
    type: comment
  author: Phil337
  content: "@mirek190 Thanks for responding. But I just double checked and confirmed\
    \ that the Arc score of 85.8 is for the foundational 7x8 model (e.g. see the link\
    \ to their website below). 70.22 is for the instruct, 66 for the foundational.\n\
    \nPlus all the other scores for 8x7b match perfectly (e.g. MMLU, HellaSwag and\
    \ Winogrande) and the as yet unreleased \"medium\" model reports scores that are\
    \ about 3-5 points higher than these across the board. \n\nThe 85.8 Arc score\
    \ needs to be independently verified ASAP.  A claim of matching GPT3.5's performance\
    \ was ALWAYS about Arc. Mistral 7b already came within 3-5 points of matching\
    \ GPT3.5 on the other benchmarks like (65 MMLU, 83 HellaSwag, 78 WinoGrande).\
    \ Simply boosting Mistral 7b to Mistral 14b dense would have easily matched GPT3.5's\
    \ performance on all but Arc. Arc requires \"brains\" (60 for Mistral 7b and 85\
    \ for GPT3.5). Mixtral 7x8 isn't performing better on most tests, including Arc,\
    \ than Mistral 14b dense would have sans the multi-linguage upgrade (French, Spanish...\
    \ x3).\n\nhttps://mistral.ai/news/mixtral-of-experts/\n\n"
  created_at: 2023-12-14 18:06:45+00:00
  edited: true
  hidden: false
  id: 657b4435688f1a0f7ea8b8b8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-12-14T18:51:23.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.927338182926178
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/mirek190\"\
          >@<span class=\"underline\">mirek190</span></a></span>\n\n\t</span></span>\
          \ Thanks for responding. But I just double checked and confirmed that the\
          \ Arc score of 85.8 is for the foundational 7x8 model (e.g. see the link\
          \ to their website below). 70.22 is for the instruct, 66 for the foundational.</p>\n\
          <p>Plus all the other scores for 8x7b match perfectly (e.g. MMLU, HellaSwag\
          \ and Winogrande) and the as yet unreleased \"medium\" model reports scores\
          \ that are about 3-5 points higher than these across the board. </p>\n<p>The\
          \ 85.8 Arc score needs to be independently verified ASAP.  A claim of matching\
          \ GPT3.5's performance was ALWAYS about Arc. Mistral 7b already came within\
          \ 3-5 points of matching GPT3.5 on the other benchmarks like (65 MMLU, 83\
          \ HellaSwag, 78 WinoGrande). Simply boosting Mistral 7b to Mistral 14b dense\
          \ would have easily matched GPT3.5's performance on all but Arc. Arc requires\
          \ \"brains\" (60 for Mistral 7b and 85 for GPT3.5). Mixtral 7x8 isn't performing\
          \ better on most tests, including Arc, than Mistral 14b dense would have\
          \ sans the multi-linguage upgrade (French, Spanish... x3).</p>\n<p><a rel=\"\
          nofollow\" href=\"https://mistral.ai/news/mixtral-of-experts/\">https://mistral.ai/news/mixtral-of-experts/</a></p>\n\
          </blockquote>\n<p>Also from their webpage llama 2 70b also has ARC 85 so\
          \ i suspec they are using different ARC questions because llama2-70b huggingface\
          \ leaderboard has 67.32. </p>\n"
        raw: "> @mirek190 Thanks for responding. But I just double checked and confirmed\
          \ that the Arc score of 85.8 is for the foundational 7x8 model (e.g. see\
          \ the link to their website below). 70.22 is for the instruct, 66 for the\
          \ foundational.\n> \n> Plus all the other scores for 8x7b match perfectly\
          \ (e.g. MMLU, HellaSwag and Winogrande) and the as yet unreleased \"medium\"\
          \ model reports scores that are about 3-5 points higher than these across\
          \ the board. \n> \n> The 85.8 Arc score needs to be independently verified\
          \ ASAP.  A claim of matching GPT3.5's performance was ALWAYS about Arc.\
          \ Mistral 7b already came within 3-5 points of matching GPT3.5 on the other\
          \ benchmarks like (65 MMLU, 83 HellaSwag, 78 WinoGrande). Simply boosting\
          \ Mistral 7b to Mistral 14b dense would have easily matched GPT3.5's performance\
          \ on all but Arc. Arc requires \"brains\" (60 for Mistral 7b and 85 for\
          \ GPT3.5). Mixtral 7x8 isn't performing better on most tests, including\
          \ Arc, than Mistral 14b dense would have sans the multi-linguage upgrade\
          \ (French, Spanish... x3).\n> \n> https://mistral.ai/news/mixtral-of-experts/\n\
          \nAlso from their webpage llama 2 70b also has ARC 85 so i suspec they are\
          \ using different ARC questions because llama2-70b huggingface leaderboard\
          \ has 67.32. "
        updatedAt: '2023-12-14T18:51:23.367Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Phil337
    id: 657b4eabc8c6e8dceeb3e9aa
    type: comment
  author: mirek190
  content: "> @mirek190 Thanks for responding. But I just double checked and confirmed\
    \ that the Arc score of 85.8 is for the foundational 7x8 model (e.g. see the link\
    \ to their website below). 70.22 is for the instruct, 66 for the foundational.\n\
    > \n> Plus all the other scores for 8x7b match perfectly (e.g. MMLU, HellaSwag\
    \ and Winogrande) and the as yet unreleased \"medium\" model reports scores that\
    \ are about 3-5 points higher than these across the board. \n> \n> The 85.8 Arc\
    \ score needs to be independently verified ASAP.  A claim of matching GPT3.5's\
    \ performance was ALWAYS about Arc. Mistral 7b already came within 3-5 points\
    \ of matching GPT3.5 on the other benchmarks like (65 MMLU, 83 HellaSwag, 78 WinoGrande).\
    \ Simply boosting Mistral 7b to Mistral 14b dense would have easily matched GPT3.5's\
    \ performance on all but Arc. Arc requires \"brains\" (60 for Mistral 7b and 85\
    \ for GPT3.5). Mixtral 7x8 isn't performing better on most tests, including Arc,\
    \ than Mistral 14b dense would have sans the multi-linguage upgrade (French, Spanish...\
    \ x3).\n> \n> https://mistral.ai/news/mixtral-of-experts/\n\nAlso from their webpage\
    \ llama 2 70b also has ARC 85 so i suspec they are using different ARC questions\
    \ because llama2-70b huggingface leaderboard has 67.32. "
  created_at: 2023-12-14 18:51:23+00:00
  edited: false
  hidden: false
  id: 657b4eabc8c6e8dceeb3e9aa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-14T19:01:20.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9473504424095154
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;mirek190&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/mirek190\"\
          >@<span class=\"underline\">mirek190</span></a></span>\n\n\t</span></span>\
          \ The fact that Llama 2 70b has an Arc of 85 is very relevant. I just assumed\
          \ that's what Llama2 70b got on HF because it's the same 25-shot test and\
          \ the same 7.5k questions.</p>\n"
        raw: Thanks @mirek190 The fact that Llama 2 70b has an Arc of 85 is very relevant.
          I just assumed that's what Llama2 70b got on HF because it's the same 25-shot
          test and the same 7.5k questions.
        updatedAt: '2023-12-14T19:01:20.521Z'
      numEdits: 0
      reactions: []
    id: 657b5100c8c6e8dceeb468e7
    type: comment
  author: Phil337
  content: Thanks @mirek190 The fact that Llama 2 70b has an Arc of 85 is very relevant.
    I just assumed that's what Llama2 70b got on HF because it's the same 25-shot
    test and the same 7.5k questions.
  created_at: 2023-12-14 19:01:20+00:00
  edited: false
  hidden: false
  id: 657b5100c8c6e8dceeb468e7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-12-14T19:25:37.000Z'
    data:
      status: closed
    id: 657b56b1e37d702c1d553185
    type: status-change
  author: Phil337
  created_at: 2023-12-14 19:25:37+00:00
  id: 657b56b1e37d702c1d553185
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Open-Orca/Mixtral-SlimOrca-8x7B
repo_type: model
status: closed
target_branch: null
title: How do you get the reported Arc score of 85.8?
