!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sandrobovelli
conflicting_files: null
created_at: 2023-08-25 21:28:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647b2e6c9c71e428601f9427/L55kTnuwim1lzSaeg5vTO.png?w=200&h=200&f=face
      fullname: sandro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sandrobovelli
      type: user
    createdAt: '2023-08-25T22:28:49.000Z'
    data:
      edited: true
      editors:
      - sandrobovelli
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.960053563117981
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/647b2e6c9c71e428601f9427/L55kTnuwim1lzSaeg5vTO.png?w=200&h=200&f=face
          fullname: sandro
          isHf: false
          isPro: false
          name: sandrobovelli
          type: user
        html: '<p>Hi. I would like to know when the 4bit quantized 70B weights will
          be released.<br>I''m trying to quantize the original hf checkpoint, but
          the script constantly run out of memory (my system RAM is around 96GB).<br>What
          is the approximate memory requirement to quantize the 70B model?</p>

          '
        raw: 'Hi. I would like to know when the 4bit quantized 70B weights will be
          released.

          I''m trying to quantize the original hf checkpoint, but the script constantly
          run out of memory (my system RAM is around 96GB).

          What is the approximate memory requirement to quantize the 70B model?

          '
        updatedAt: '2023-08-25T22:29:17.895Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Sherstnev
    id: 64e92b214a2e17421151155d
    type: comment
  author: sandrobovelli
  content: 'Hi. I would like to know when the 4bit quantized 70B weights will be released.

    I''m trying to quantize the original hf checkpoint, but the script constantly
    run out of memory (my system RAM is around 96GB).

    What is the approximate memory requirement to quantize the 70B model?

    '
  created_at: 2023-08-25 21:28:49+00:00
  edited: true
  hidden: false
  id: 64e92b214a2e17421151155d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/xV4Xlk01BsqfRqxAWsO8Z.png?w=200&h=200&f=face
      fullname: Viktor Ferenczi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: viktor-ferenczi
      type: user
    createdAt: '2023-09-08T21:01:43.000Z'
    data:
      edited: false
      editors:
      - viktor-ferenczi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9788917899131775
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/xV4Xlk01BsqfRqxAWsO8Z.png?w=200&h=200&f=face
          fullname: Viktor Ferenczi
          isHf: false
          isPro: false
          name: viktor-ferenczi
          type: user
        html: '<p>Add more swap and run again. But still, having the weights here
          would be nice.</p>

          '
        raw: Add more swap and run again. But still, having the weights here would
          be nice.
        updatedAt: '2023-09-08T21:01:43.440Z'
      numEdits: 0
      reactions: []
    id: 64fb8bb7da4429f25df0b49d
    type: comment
  author: viktor-ferenczi
  content: Add more swap and run again. But still, having the weights here would be
    nice.
  created_at: 2023-09-08 20:01:43+00:00
  edited: false
  hidden: false
  id: 64fb8bb7da4429f25df0b49d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3f6279ee9e9f6a5b2f6794c5a394ef09.svg
      fullname: lmdeploy
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: unsubscribe
      type: user
    createdAt: '2023-11-14T08:20:39.000Z'
    data:
      edited: false
      editors:
      - unsubscribe
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11766260117292404
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3f6279ee9e9f6a5b2f6794c5a394ef09.svg
          fullname: lmdeploy
          isHf: false
          isPro: false
          name: unsubscribe
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;sandrobovelli&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/sandrobovelli\"\
          >@<span class=\"underline\">sandrobovelli</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;viktor-ferenczi&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/viktor-ferenczi\">@<span\
          \ class=\"underline\">viktor-ferenczi</span></a></span>\n\n\t</span></span>\
          \ updated</p>\n"
        raw: '@sandrobovelli @viktor-ferenczi updated'
        updatedAt: '2023-11-14T08:20:39.927Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65532dd7efd7d3fe23489114
    id: 65532dd7efd7d3fe23489113
    type: comment
  author: unsubscribe
  content: '@sandrobovelli @viktor-ferenczi updated'
  created_at: 2023-11-14 08:20:39+00:00
  edited: false
  hidden: false
  id: 65532dd7efd7d3fe23489113
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3f6279ee9e9f6a5b2f6794c5a394ef09.svg
      fullname: lmdeploy
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: unsubscribe
      type: user
    createdAt: '2023-11-14T08:20:39.000Z'
    data:
      status: closed
    id: 65532dd7efd7d3fe23489114
    type: status-change
  author: unsubscribe
  created_at: 2023-11-14 08:20:39+00:00
  id: 65532dd7efd7d3fe23489114
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: lmdeploy/llama2-chat-70b-4bit
repo_type: model
status: closed
target_branch: null
title: ' llama2-chat-70b-w4 weights'
