!!python/object:huggingface_hub.community.DiscussionWithDetails
author: weezywitasneezy
conflicting_files: null
created_at: 2023-06-05 14:46:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/27554f42b2fc598c15bfbbda752f8ccb.svg
      fullname: Dj Wepsro
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: weezywitasneezy
      type: user
    createdAt: '2023-06-05T15:46:02.000Z'
    data:
      edited: false
      editors:
      - weezywitasneezy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.968617856502533
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/27554f42b2fc598c15bfbbda752f8ccb.svg
          fullname: Dj Wepsro
          isHf: false
          isPro: false
          name: weezywitasneezy
          type: user
        html: '<p>I absolutely love the work you''re doing! I''m dying to run this
          model locally but running into hardware limitations. Is there any hope of
          a 13B or 7B version in the near future? So far for story writing I''ve had
          the best luck with your Wizard Mega 13B (although I run into CUDA errors
          after ~4000 characters worth of responses (rtx 3080)) and the Guanaco 7B
          (haven''t had any issues and been able to generate MASSIVE response lengths).
          Thanks and keep up the awesome work!</p>

          '
        raw: I absolutely love the work you're doing! I'm dying to run this model
          locally but running into hardware limitations. Is there any hope of a 13B
          or 7B version in the near future? So far for story writing I've had the
          best luck with your Wizard Mega 13B (although I run into CUDA errors after
          ~4000 characters worth of responses (rtx 3080)) and the Guanaco 7B (haven't
          had any issues and been able to generate MASSIVE response lengths). Thanks
          and keep up the awesome work!
        updatedAt: '2023-06-05T15:46:02.212Z'
      numEdits: 0
      reactions: []
    id: 647e033a11084fb5831ad7a3
    type: comment
  author: weezywitasneezy
  content: I absolutely love the work you're doing! I'm dying to run this model locally
    but running into hardware limitations. Is there any hope of a 13B or 7B version
    in the near future? So far for story writing I've had the best luck with your
    Wizard Mega 13B (although I run into CUDA errors after ~4000 characters worth
    of responses (rtx 3080)) and the Guanaco 7B (haven't had any issues and been able
    to generate MASSIVE response lengths). Thanks and keep up the awesome work!
  created_at: 2023-06-05 14:46:02+00:00
  edited: false
  hidden: false
  id: 647e033a11084fb5831ad7a3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ
repo_type: model
status: open
target_branch: null
title: Any plans to make a 13B or 7B version of this?
