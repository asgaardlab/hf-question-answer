!!python/object:huggingface_hub.community.DiscussionWithDetails
author: vdruts
conflicting_files: null
created_at: 2023-06-05 15:36:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-05T16:36:52.000Z'
    data:
      edited: false
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7406133413314819
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: '<p>Seem to be able to load most any other 30B models, but this one
          always results in a "BUS" error. In WSl/Ubuntu</p>

          <p>/WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order.safetensors<br>Bus
          error</p>

          '
        raw: "Seem to be able to load most any other 30B models, but this one always\
          \ results in a \"BUS\" error. In WSl/Ubuntu\r\n\r\n/WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order.safetensors\r\
          \nBus error"
        updatedAt: '2023-06-05T16:36:52.636Z'
      numEdits: 0
      reactions: []
    id: 647e0f2418274bce03051be7
    type: comment
  author: vdruts
  content: "Seem to be able to load most any other 30B models, but this one always\
    \ results in a \"BUS\" error. In WSl/Ubuntu\r\n\r\n/WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order.safetensors\r\
    \nBus error"
  created_at: 2023-06-05 15:36:52+00:00
  edited: false
  hidden: false
  id: 647e0f2418274bce03051be7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-06T20:41:57.000Z'
    data:
      edited: false
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8559744954109192
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: '<p>So I''m trying to load this model in AutoGPT (Windows) after successfully
          loading several of your other 30B models... and still getting a BUS error.
          Any ideas? For some reason the GPU memory barely moves on this one, as in
          I don''t really see it being loaded into memory unlike other models.</p>

          <p>In windows it just crashes.</p>

          <blockquote>

          <blockquote>

          <p>WARNING:The safetensors archive passed at models\TheBloke_WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ\WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order.safetensors
          does not contain metadata. Make sure to save your model with the <code>save_pretrained</code>
          method. Defaulting to ''pt'' metadata.<br>Press any key to continue . .
          .</p>

          </blockquote>

          </blockquote>

          '
        raw: 'So I''m trying to load this model in AutoGPT (Windows) after successfully
          loading several of your other 30B models... and still getting a BUS error.
          Any ideas? For some reason the GPU memory barely moves on this one, as in
          I don''t really see it being loaded into memory unlike other models.


          In windows it just crashes.


          >> WARNING:The safetensors archive passed at models\TheBloke_WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ\WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order.safetensors
          does not contain metadata. Make sure to save your model with the `save_pretrained`
          method. Defaulting to ''pt'' metadata.

          Press any key to continue . . .'
        updatedAt: '2023-06-06T20:41:57.638Z'
      numEdits: 0
      reactions: []
    id: 647f9a15db6dca2bd24ad1bd
    type: comment
  author: vdruts
  content: 'So I''m trying to load this model in AutoGPT (Windows) after successfully
    loading several of your other 30B models... and still getting a BUS error. Any
    ideas? For some reason the GPU memory barely moves on this one, as in I don''t
    really see it being loaded into memory unlike other models.


    In windows it just crashes.


    >> WARNING:The safetensors archive passed at models\TheBloke_WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ\WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order.safetensors
    does not contain metadata. Make sure to save your model with the `save_pretrained`
    method. Defaulting to ''pt'' metadata.

    Press any key to continue . . .'
  created_at: 2023-06-06 19:41:57+00:00
  edited: false
  hidden: false
  id: 647f9a15db6dca2bd24ad1bd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-06T20:54:32.000Z'
    data:
      edited: false
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9277510643005371
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: '<p>I''ve tried changing page-file size. Windows 11 just crashes...
          For reason reason the CPU barely spins up, no system memory is really used
          and only 5GB of VRAM, then it hangs and crashes.</p>

          '
        raw: I've tried changing page-file size. Windows 11 just crashes... For reason
          reason the CPU barely spins up, no system memory is really used and only
          5GB of VRAM, then it hangs and crashes.
        updatedAt: '2023-06-06T20:54:32.989Z'
      numEdits: 0
      reactions: []
    id: 647f9d08cbb8294ed8085226
    type: comment
  author: vdruts
  content: I've tried changing page-file size. Windows 11 just crashes... For reason
    reason the CPU barely spins up, no system memory is really used and only 5GB of
    VRAM, then it hangs and crashes.
  created_at: 2023-06-06 19:54:32+00:00
  edited: false
  hidden: false
  id: 647f9d08cbb8294ed8085226
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-06T21:35:16.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9750616550445557
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>The WARNING is fine, it can be ignored - it''s not an error at all.  Hopefully
          it will go away in a future release.</p>

          <p>The "press a key to continue" is, as you thought, related to Pagefile.  I
          don''t know what to suggest other than making sure Pagefile is at least
          90GB.  That seems to work for everyone else who has this problem.</p>

          <p>It''s a known problem on Windows that it seems to need use about 3x the
          size of the model in RAM, and it maps it all to pagefile even if you have
          plenty of free RAM.  Like even on a 128GB system, it still fails unless
          there''s plenty of pagefile.</p>

          '
        raw: 'The WARNING is fine, it can be ignored - it''s not an error at all.  Hopefully
          it will go away in a future release.


          The "press a key to continue" is, as you thought, related to Pagefile.  I
          don''t know what to suggest other than making sure Pagefile is at least
          90GB.  That seems to work for everyone else who has this problem.


          It''s a known problem on Windows that it seems to need use about 3x the
          size of the model in RAM, and it maps it all to pagefile even if you have
          plenty of free RAM.  Like even on a 128GB system, it still fails unless
          there''s plenty of pagefile.'
        updatedAt: '2023-06-06T21:35:16.537Z'
      numEdits: 0
      reactions: []
    id: 647fa694db6dca2bd24c14d6
    type: comment
  author: TheBloke
  content: 'The WARNING is fine, it can be ignored - it''s not an error at all.  Hopefully
    it will go away in a future release.


    The "press a key to continue" is, as you thought, related to Pagefile.  I don''t
    know what to suggest other than making sure Pagefile is at least 90GB.  That seems
    to work for everyone else who has this problem.


    It''s a known problem on Windows that it seems to need use about 3x the size of
    the model in RAM, and it maps it all to pagefile even if you have plenty of free
    RAM.  Like even on a 128GB system, it still fails unless there''s plenty of pagefile.'
  created_at: 2023-06-06 20:35:16+00:00
  edited: false
  hidden: false
  id: 647fa694db6dca2bd24c14d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-06T21:37:53.000Z'
    data:
      edited: true
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9620217084884644
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: '<p>It''s odd because I made the page-file 128GB and it still threw
          the error :/ I guess I can try 200GB but that insane lol</p>

          <p>Any clues as to why this is one of the only models with this particular
          issue? I feel like its one of the json config files... your other 30B models
          load fine.</p>

          '
        raw: 'It''s odd because I made the page-file 128GB and it still threw the
          error :/ I guess I can try 200GB but that insane lol


          Any clues as to why this is one of the only models with this particular
          issue? I feel like its one of the json config files... your other 30B models
          load fine.'
        updatedAt: '2023-06-06T21:38:41.312Z'
      numEdits: 2
      reactions: []
    id: 647fa73186888bbffbde1ec7
    type: comment
  author: vdruts
  content: 'It''s odd because I made the page-file 128GB and it still threw the error
    :/ I guess I can try 200GB but that insane lol


    Any clues as to why this is one of the only models with this particular issue?
    I feel like its one of the json config files... your other 30B models load fine.'
  created_at: 2023-06-06 20:37:53+00:00
  edited: true
  hidden: false
  id: 647fa73186888bbffbde1ec7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-06T21:47:15.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.908292293548584
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p>Yeah that would be insane. I really have no idea I'm afraid. I don't\
          \ own an NV GPU and I can't easily get a Windows cloud system, so it's hard\
          \ for me to ever test Windows.</p>\n<p>What about WSL2? That's what I recommend\
          \ to most Windows users.  I know you said you had problems with it, but\
          \ that might just be an install issue. Perhaps make a new conda environment\
          \ with Miniconda and start again in WSL2, installing CUDA toolkit 11.8 and\
          \ then torch with: </p>\n<pre><code>pip install torch  --index-url https://download.pytorch.org/whl/cu118\n\
          </code></pre>\n<p>and then text-generation-webui with </p>\n<pre><code>git\
          \ clone https://github.com/oobabooga/text-generation-webui \ncd text-generation-webui\n\
          pip install -r requirements.txt\n</code></pre>\n<p>That will install AutoGPTQ\
          \ automatically, and then it should work immediately. In theory!</p>\n"
        raw: "Yeah that would be insane. I really have no idea I'm afraid. I don't\
          \ own an NV GPU and I can't easily get a Windows cloud system, so it's hard\
          \ for me to ever test Windows.\n\nWhat about WSL2? That's what I recommend\
          \ to most Windows users.  I know you said you had problems with it, but\
          \ that might just be an install issue. Perhaps make a new conda environment\
          \ with Miniconda and start again in WSL2, installing CUDA toolkit 11.8 and\
          \ then torch with: \n\n```\npip install torch  --index-url https://download.pytorch.org/whl/cu118\n\
          ``` \nand then text-generation-webui with \n```\ngit clone https://github.com/oobabooga/text-generation-webui\
          \ \ncd text-generation-webui\npip install -r requirements.txt\n```\n\nThat\
          \ will install AutoGPTQ automatically, and then it should work immediately.\
          \ In theory!"
        updatedAt: '2023-06-06T21:47:26.884Z'
      numEdits: 1
      reactions: []
    id: 647fa96386888bbffbde581f
    type: comment
  author: TheBloke
  content: "Yeah that would be insane. I really have no idea I'm afraid. I don't own\
    \ an NV GPU and I can't easily get a Windows cloud system, so it's hard for me\
    \ to ever test Windows.\n\nWhat about WSL2? That's what I recommend to most Windows\
    \ users.  I know you said you had problems with it, but that might just be an\
    \ install issue. Perhaps make a new conda environment with Miniconda and start\
    \ again in WSL2, installing CUDA toolkit 11.8 and then torch with: \n\n```\npip\
    \ install torch  --index-url https://download.pytorch.org/whl/cu118\n``` \nand\
    \ then text-generation-webui with \n```\ngit clone https://github.com/oobabooga/text-generation-webui\
    \ \ncd text-generation-webui\npip install -r requirements.txt\n```\n\nThat will\
    \ install AutoGPTQ automatically, and then it should work immediately. In theory!"
  created_at: 2023-06-06 20:47:15+00:00
  edited: true
  hidden: false
  id: 647fa96386888bbffbde581f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-06T21:50:05.000Z'
    data:
      edited: false
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9912136197090149
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: '<p>Yea, did that about 10x over recently and still had the issue :/
          no clue. I''d be down for you to Teamview into my system and run some test
          if you like later this week. Win11/WSL2/4090 here.</p>

          '
        raw: Yea, did that about 10x over recently and still had the issue :/ no clue.
          I'd be down for you to Teamview into my system and run some test if you
          like later this week. Win11/WSL2/4090 here.
        updatedAt: '2023-06-06T21:50:05.895Z'
      numEdits: 0
      reactions: []
    id: 647faa0ddb6dca2bd24c718c
    type: comment
  author: vdruts
  content: Yea, did that about 10x over recently and still had the issue :/ no clue.
    I'd be down for you to Teamview into my system and run some test if you like later
    this week. Win11/WSL2/4090 here.
  created_at: 2023-06-06 20:50:05+00:00
  edited: false
  hidden: false
  id: 647faa0ddb6dca2bd24c718c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
      fullname: Man Cub
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mancub
      type: user
    createdAt: '2023-06-07T00:13:02.000Z'
    data:
      edited: false
      editors:
      - mancub
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9335769414901733
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f6da5ac096770743875fe1ee7eb1897f.svg
          fullname: Man Cub
          isHf: false
          isPro: false
          name: mancub
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;vdruts&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/vdruts\">@<span class=\"\
          underline\">vdruts</span></a></span>\n\n\t</span></span> are you sure you\
          \ have installed and setup WSL2 correctly?</p>\n<p>I'm using WSL2 with Ubuntu\
          \ in Win10 on my 3090 and it can load most 30B models.</p>\n"
        raw: '@vdruts are you sure you have installed and setup WSL2 correctly?


          I''m using WSL2 with Ubuntu in Win10 on my 3090 and it can load most 30B
          models.'
        updatedAt: '2023-06-07T00:13:02.766Z'
      numEdits: 0
      reactions: []
    id: 647fcb8e1637c1c0e6f1851f
    type: comment
  author: mancub
  content: '@vdruts are you sure you have installed and setup WSL2 correctly?


    I''m using WSL2 with Ubuntu in Win10 on my 3090 and it can load most 30B models.'
  created_at: 2023-06-06 23:13:02+00:00
  edited: false
  hidden: false
  id: 647fcb8e1637c1c0e6f1851f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-07T00:58:09.000Z'
    data:
      edited: false
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9648646712303162
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;vdruts&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/vdruts\"\
          >@<span class=\"underline\">vdruts</span></a></span>\n\n\t</span></span>\
          \ are you sure you have installed and setup WSL2 correctly?</p>\n<p>I'm\
          \ using WSL2 with Ubuntu in Win10 on my 3090 and it can load most 30B models.</p>\n\
          </blockquote>\n<p>Yes. I never had any issues weeks ago but then started\
          \ running into issues. Anyway most 30B models load with no problem but this\
          \ 30B model wont load in WSL or Windows.. in WSL I get a \"BUS\" error.\
          \ I've tried increasing and creating a WSL swap file as well and no luck.\
          \ Same error.</p>\n"
        raw: "> @vdruts are you sure you have installed and setup WSL2 correctly?\n\
          > \n> I'm using WSL2 with Ubuntu in Win10 on my 3090 and it can load most\
          \ 30B models.\n\nYes. I never had any issues weeks ago but then started\
          \ running into issues. Anyway most 30B models load with no problem but this\
          \ 30B model wont load in WSL or Windows.. in WSL I get a \"BUS\" error.\
          \ I've tried increasing and creating a WSL swap file as well and no luck.\
          \ Same error."
        updatedAt: '2023-06-07T00:58:09.657Z'
      numEdits: 0
      reactions: []
    id: 647fd6211637c1c0e6f28b89
    type: comment
  author: vdruts
  content: "> @vdruts are you sure you have installed and setup WSL2 correctly?\n\
    > \n> I'm using WSL2 with Ubuntu in Win10 on my 3090 and it can load most 30B\
    \ models.\n\nYes. I never had any issues weeks ago but then started running into\
    \ issues. Anyway most 30B models load with no problem but this 30B model wont\
    \ load in WSL or Windows.. in WSL I get a \"BUS\" error. I've tried increasing\
    \ and creating a WSL swap file as well and no luck. Same error."
  created_at: 2023-06-06 23:58:09+00:00
  edited: false
  hidden: false
  id: 647fd6211637c1c0e6f28b89
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-07T01:04:09.000Z'
    data:
      edited: false
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8749170899391174
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: '<p>Just tried again in Windows. </p>

          <blockquote>

          <p>Loading Wizard 30B (new one) loads in 48s AutoGPT<br>Loading The Cot
          Mix 30B (gets stuck at 5.7GB loaded into GPU memory) then throws the ''press
          any key''</p>

          </blockquote>

          <p>I''ve got 64-128GB Swap file set. That did not fix it.</p>

          '
        raw: "Just tried again in Windows. \n\n> Loading Wizard 30B (new one) loads\
          \ in 48s AutoGPT\n> Loading The Cot Mix 30B (gets stuck at 5.7GB loaded\
          \ into GPU memory) then throws the 'press any key'\n\nI've got 64-128GB\
          \ Swap file set. That did not fix it."
        updatedAt: '2023-06-07T01:04:09.970Z'
      numEdits: 0
      reactions: []
    id: 647fd789db6dca2bd250def7
    type: comment
  author: vdruts
  content: "Just tried again in Windows. \n\n> Loading Wizard 30B (new one) loads\
    \ in 48s AutoGPT\n> Loading The Cot Mix 30B (gets stuck at 5.7GB loaded into GPU\
    \ memory) then throws the 'press any key'\n\nI've got 64-128GB Swap file set.\
    \ That did not fix it."
  created_at: 2023-06-07 00:04:09+00:00
  edited: false
  hidden: false
  id: 647fd789db6dca2bd250def7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-07T01:04:54.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9812401533126831
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>That is really weird. I can''t understand what could be different
          about one 30B model vs another.  They''re all made the same way, and no-one
          else is reporting issues specific to this file.</p>

          <p>Have you confirmed the file is definitely downloaded OK?  Checked the
          sha256sum? Or just delete it and re-download it?</p>

          <p>Also, if you have saved settings for this model in text-gen-ui, check
          those and maybe delete them.  You can see those in <code>models/config-user.yaml</code>.
          Maybe a different/bad setting got added somewhere that''s breaking things.</p>

          '
        raw: 'That is really weird. I can''t understand what could be different about
          one 30B model vs another.  They''re all made the same way, and no-one else
          is reporting issues specific to this file.


          Have you confirmed the file is definitely downloaded OK?  Checked the sha256sum?
          Or just delete it and re-download it?


          Also, if you have saved settings for this model in text-gen-ui, check those
          and maybe delete them.  You can see those in `models/config-user.yaml`.
          Maybe a different/bad setting got added somewhere that''s breaking things.'
        updatedAt: '2023-06-07T01:05:11.288Z'
      numEdits: 1
      reactions: []
    id: 647fd7b6db6dca2bd250e3de
    type: comment
  author: TheBloke
  content: 'That is really weird. I can''t understand what could be different about
    one 30B model vs another.  They''re all made the same way, and no-one else is
    reporting issues specific to this file.


    Have you confirmed the file is definitely downloaded OK?  Checked the sha256sum?
    Or just delete it and re-download it?


    Also, if you have saved settings for this model in text-gen-ui, check those and
    maybe delete them.  You can see those in `models/config-user.yaml`. Maybe a different/bad
    setting got added somewhere that''s breaking things.'
  created_at: 2023-06-07 00:04:54+00:00
  edited: true
  hidden: false
  id: 647fd7b6db6dca2bd250e3de
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-07T01:12:57.000Z'
    data:
      edited: true
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9963213801383972
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: '<p>It is weird... I''ve tried downloading it. I''ll try again.... and
          it''s working... So weird. Because I had downloaded several times before.
          Now its working. No explanation. Something must have gotten corrupted.</p>

          '
        raw: It is weird... I've tried downloading it. I'll try again.... and it's
          working... So weird. Because I had downloaded several times before. Now
          its working. No explanation. Something must have gotten corrupted.
        updatedAt: '2023-06-07T01:26:43.965Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - mancub
    id: 647fd999cbb8294ed80e30e8
    type: comment
  author: vdruts
  content: It is weird... I've tried downloading it. I'll try again.... and it's working...
    So weird. Because I had downloaded several times before. Now its working. No explanation.
    Something must have gotten corrupted.
  created_at: 2023-06-07 00:12:57+00:00
  edited: true
  hidden: false
  id: 647fd999cbb8294ed80e30e8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ
repo_type: model
status: open
target_branch: null
title: Unable to load/use this model.
