!!python/object:huggingface_hub.community.DiscussionWithDetails
author: remowylliams
conflicting_files: null
created_at: 2023-06-02 01:14:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662503689554-noauth.jpeg?w=200&h=200&f=face
      fullname: Brett Henley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: remowylliams
      type: user
    createdAt: '2023-06-02T02:14:56.000Z'
    data:
      edited: false
      editors:
      - remowylliams
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1662503689554-noauth.jpeg?w=200&h=200&f=face
          fullname: Brett Henley
          isHf: false
          isPro: false
          name: remowylliams
          type: user
        html: '<p>Hi There,<br>  Thanks for putting this model out. I gave it a plot
          for a story that I''ve only had middling success for with 9 other models.
          This one.. wow It really brought some nice details, kept track of the characters
          and gave the environment and comment on the protagonists experience in vivid
          detail. This rocked.<br>So many thanks.</p>

          <p>It just barely fits in 24GB of vram, it kept up a decent rate too between
          16 - 20 tokens/s on a RTX 3090. your instructions on the Model card were
          perfect.<br>Just nothing but accolades. </p>

          <p>Bravo.</p>

          <p>Remo</p>

          '
        raw: "Hi There,\r\n  Thanks for putting this model out. I gave it a plot for\
          \ a story that I've only had middling success for with 9 other models. This\
          \ one.. wow It really brought some nice details, kept track of the characters\
          \ and gave the environment and comment on the protagonists experience in\
          \ vivid detail. This rocked. \r\nSo many thanks.\r\n\r\nIt just barely fits\
          \ in 24GB of vram, it kept up a decent rate too between 16 - 20 tokens/s\
          \ on a RTX 3090. your instructions on the Model card were perfect.\r\nJust\
          \ nothing but accolades. \r\n\r\nBravo.\r\n\r\nRemo\r\n"
        updatedAt: '2023-06-02T02:14:56.114Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - texturalnewbie
        - Sciumo
        - Mykee
        - max-fry
        - kleberbaum
        - zachwill
    id: 647950a0e504380e5c88c849
    type: comment
  author: remowylliams
  content: "Hi There,\r\n  Thanks for putting this model out. I gave it a plot for\
    \ a story that I've only had middling success for with 9 other models. This one..\
    \ wow It really brought some nice details, kept track of the characters and gave\
    \ the environment and comment on the protagonists experience in vivid detail.\
    \ This rocked. \r\nSo many thanks.\r\n\r\nIt just barely fits in 24GB of vram,\
    \ it kept up a decent rate too between 16 - 20 tokens/s on a RTX 3090. your instructions\
    \ on the Model card were perfect.\r\nJust nothing but accolades. \r\n\r\nBravo.\r\
    \n\r\nRemo\r\n"
  created_at: 2023-06-02 01:14:56+00:00
  edited: false
  hidden: false
  id: 647950a0e504380e5c88c849
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a0d146e4b922a325b69d3d509965ed60.svg
      fullname: Frankie G
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: spanielrassler
      type: user
    createdAt: '2023-06-02T21:54:51.000Z'
    data:
      edited: false
      editors:
      - spanielrassler
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9792113304138184
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a0d146e4b922a325b69d3d509965ed60.svg
          fullname: Frankie G
          isHf: false
          isPro: false
          name: spanielrassler
          type: user
        html: '<p>Yes, thanks so much for doing this conversion! I was originally
          going to try my hand at conversion but experienced some random issue so
          you saved the day once again!</p>

          '
        raw: Yes, thanks so much for doing this conversion! I was originally going
          to try my hand at conversion but experienced some random issue so you saved
          the day once again!
        updatedAt: '2023-06-02T21:54:51.906Z'
      numEdits: 0
      reactions: []
    id: 647a652b822b7e8ccbd8be90
    type: comment
  author: spanielrassler
  content: Yes, thanks so much for doing this conversion! I was originally going to
    try my hand at conversion but experienced some random issue so you saved the day
    once again!
  created_at: 2023-06-02 20:54:51+00:00
  edited: false
  hidden: false
  id: 647a652b822b7e8ccbd8be90
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-03T10:31:14.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9700484275817871
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Great, glad it''s useful for you guys!</p>

          '
        raw: Great, glad it's useful for you guys!
        updatedAt: '2023-06-03T10:31:14.549Z'
      numEdits: 0
      reactions: []
    id: 647b1672e8b73330589e0812
    type: comment
  author: TheBloke
  content: Great, glad it's useful for you guys!
  created_at: 2023-06-03 09:31:14+00:00
  edited: false
  hidden: false
  id: 647b1672e8b73330589e0812
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28b401d5789d6a0f736be80ada2151fe.svg
      fullname: Simon Howe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ex01
      type: user
    createdAt: '2023-06-03T19:04:33.000Z'
    data:
      edited: false
      editors:
      - Ex01
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8605955243110657
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28b401d5789d6a0f736be80ada2151fe.svg
          fullname: Simon Howe
          isHf: false
          isPro: false
          name: Ex01
          type: user
        html: '<blockquote>

          <p>Hi There,<br>  Thanks for putting this model out. I gave it a plot for
          a story that I''ve only had middling success for with 9 other models. This
          one.. wow It really brought some nice details, kept track of the characters
          and gave the environment and comment on the protagonists experience in vivid
          detail. This rocked.<br>So many thanks.</p>

          <p>It just barely fits in 24GB of vram, it kept up a decent rate too between
          16 - 20 tokens/s on a RTX 3090. your instructions on the Model card were
          perfect.<br>Just nothing but accolades. </p>

          <p>Bravo.</p>

          <p>Remo</p>

          </blockquote>

          <p>Hey im quite new to this and enjoying the exploring more than the chat
          to be honest. </p>

          <p>got a RTX3090 too and this model crashes on loading.<br>Running the latest
          text-generation-webui with GPTQ to use the GPU.<br>not sure if that''s enough
          to get a hand or not?<br>Errors basically "Press any key to continue".?</p>

          <p>"INFO:The AutoGPTQ params are: {''model_basename'': ''WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order'',
          ''device'': ''cuda:0'', ''use_triton'': False, ''use_safetensors'': True,
          ''trust_remote_code'': True, ''max_memory'': {0: ''23GiB'', ''cpu'': ''99GiB''},
          ''quantize_config'': None}<br>WARNING:The safetensors archive passed at
          models\TheBloke_WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ\WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order.safetensors
          does not contain metadata. Make sure to save your model with the <code>save_pretrained</code>
          method. Defaulting to ''pt'' metadata.<br>Press any key to continue . .
          ."</p>

          <p>Window closes.</p>

          <p>Also if ''TheBloke'' happens to read this I know its my incompetence
          in learning but I very much appreciate the work you do, been great learning
          with it.</p>

          '
        raw: "> Hi There,\n>   Thanks for putting this model out. I gave it a plot\
          \ for a story that I've only had middling success for with 9 other models.\
          \ This one.. wow It really brought some nice details, kept track of the\
          \ characters and gave the environment and comment on the protagonists experience\
          \ in vivid detail. This rocked. \n> So many thanks.\n> \n> It just barely\
          \ fits in 24GB of vram, it kept up a decent rate too between 16 - 20 tokens/s\
          \ on a RTX 3090. your instructions on the Model card were perfect.\n> Just\
          \ nothing but accolades. \n> \n> Bravo.\n> \n> Remo\n\nHey im quite new\
          \ to this and enjoying the exploring more than the chat to be honest. \n\
          \ngot a RTX3090 too and this model crashes on loading.\nRunning the latest\
          \ text-generation-webui with GPTQ to use the GPU.\nnot sure if that's enough\
          \ to get a hand or not? \nErrors basically \"Press any key to continue\"\
          .?\n\n\"INFO:The AutoGPTQ params are: {'model_basename': 'WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order',\
          \ 'device': 'cuda:0', 'use_triton': False, 'use_safetensors': True, 'trust_remote_code':\
          \ True, 'max_memory': {0: '23GiB', 'cpu': '99GiB'}, 'quantize_config': None}\n\
          WARNING:The safetensors archive passed at models\\TheBloke_WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ\\\
          WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order.safetensors\
          \ does not contain metadata. Make sure to save your model with the `save_pretrained`\
          \ method. Defaulting to 'pt' metadata.\nPress any key to continue . . .\"\
          \n\nWindow closes.\n\nAlso if 'TheBloke' happens to read this I know its\
          \ my incompetence in learning but I very much appreciate the work you do,\
          \ been great learning with it."
        updatedAt: '2023-06-03T19:04:33.874Z'
      numEdits: 0
      reactions: []
    id: 647b8ec1b31514a4a6e15cd4
    type: comment
  author: Ex01
  content: "> Hi There,\n>   Thanks for putting this model out. I gave it a plot for\
    \ a story that I've only had middling success for with 9 other models. This one..\
    \ wow It really brought some nice details, kept track of the characters and gave\
    \ the environment and comment on the protagonists experience in vivid detail.\
    \ This rocked. \n> So many thanks.\n> \n> It just barely fits in 24GB of vram,\
    \ it kept up a decent rate too between 16 - 20 tokens/s on a RTX 3090. your instructions\
    \ on the Model card were perfect.\n> Just nothing but accolades. \n> \n> Bravo.\n\
    > \n> Remo\n\nHey im quite new to this and enjoying the exploring more than the\
    \ chat to be honest. \n\ngot a RTX3090 too and this model crashes on loading.\n\
    Running the latest text-generation-webui with GPTQ to use the GPU.\nnot sure if\
    \ that's enough to get a hand or not? \nErrors basically \"Press any key to continue\"\
    .?\n\n\"INFO:The AutoGPTQ params are: {'model_basename': 'WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order',\
    \ 'device': 'cuda:0', 'use_triton': False, 'use_safetensors': True, 'trust_remote_code':\
    \ True, 'max_memory': {0: '23GiB', 'cpu': '99GiB'}, 'quantize_config': None}\n\
    WARNING:The safetensors archive passed at models\\TheBloke_WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ\\\
    WizardLM-Uncensored-SuperCOT-Storytelling-GPTQ-4bit.act.order.safetensors does\
    \ not contain metadata. Make sure to save your model with the `save_pretrained`\
    \ method. Defaulting to 'pt' metadata.\nPress any key to continue . . .\"\n\n\
    Window closes.\n\nAlso if 'TheBloke' happens to read this I know its my incompetence\
    \ in learning but I very much appreciate the work you do, been great learning\
    \ with it."
  created_at: 2023-06-03 18:04:33+00:00
  edited: false
  hidden: false
  id: 647b8ec1b31514a4a6e15cd4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-04T10:30:36.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9178264737129211
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>OK this is a common problem on Windows.  You need to increase your
          pagefile size.  As this is a 30B model, increase it to about 90GB.</p>

          <p>Or just set it to Auto, and make sure you have enough free disk space
          on C: (or whatever drive holds the pagefile) for it to grow that large.</p>

          <p>For some reason, on Windows it needs a massive pagefile size to load
          the model into RAM before it can move it to VRAM.</p>

          <p>Here''s a guide on adjusting the pagefile if you''re not familiar with
          doing that: <a rel="nofollow" href="https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows">https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows</a></p>

          '
        raw: 'OK this is a common problem on Windows.  You need to increase your pagefile
          size.  As this is a 30B model, increase it to about 90GB.


          Or just set it to Auto, and make sure you have enough free disk space on
          C: (or whatever drive holds the pagefile) for it to grow that large.


          For some reason, on Windows it needs a massive pagefile size to load the
          model into RAM before it can move it to VRAM.


          Here''s a guide on adjusting the pagefile if you''re not familiar with doing
          that: https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows'
        updatedAt: '2023-06-04T10:30:36.956Z'
      numEdits: 0
      reactions: []
    id: 647c67cc83c62f3249155f09
    type: comment
  author: TheBloke
  content: 'OK this is a common problem on Windows.  You need to increase your pagefile
    size.  As this is a 30B model, increase it to about 90GB.


    Or just set it to Auto, and make sure you have enough free disk space on C: (or
    whatever drive holds the pagefile) for it to grow that large.


    For some reason, on Windows it needs a massive pagefile size to load the model
    into RAM before it can move it to VRAM.


    Here''s a guide on adjusting the pagefile if you''re not familiar with doing that:
    https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows'
  created_at: 2023-06-04 09:30:36+00:00
  edited: false
  hidden: false
  id: 647c67cc83c62f3249155f09
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-04T10:30:45.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9459200501441956
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>And you''re welcome!</p>

          '
        raw: And you're welcome!
        updatedAt: '2023-06-04T10:30:45.662Z'
      numEdits: 0
      reactions: []
    id: 647c67d560dfe0f35d4d8da3
    type: comment
  author: TheBloke
  content: And you're welcome!
  created_at: 2023-06-04 09:30:45+00:00
  edited: false
  hidden: false
  id: 647c67d560dfe0f35d4d8da3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28b401d5789d6a0f736be80ada2151fe.svg
      fullname: Simon Howe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ex01
      type: user
    createdAt: '2023-06-04T11:26:07.000Z'
    data:
      edited: false
      editors:
      - Ex01
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9186531901359558
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28b401d5789d6a0f736be80ada2151fe.svg
          fullname: Simon Howe
          isHf: false
          isPro: false
          name: Ex01
          type: user
        html: '<blockquote>

          <p>OK this is a common problem on Windows.  You need to increase your pagefile
          size.  As this is a 30B model, increase it to about 90GB.</p>

          <p>Or just set it to Auto, and make sure you have enough free disk space
          on C: (or whatever drive holds the pagefile) for it to grow that large.</p>

          <p>For some reason, on Windows it needs a massive pagefile size to load
          the model into RAM before it can move it to VRAM.</p>

          <p>Here''s a guide on adjusting the pagefile if you''re not familiar with
          doing that: <a rel="nofollow" href="https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows">https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows</a></p>

          </blockquote>

          <p>Legend appreciate the help!<br>Honestly I thought a 50gb Pagefile was
          enough with 32gb Ram... WoW!!</p>

          '
        raw: "> OK this is a common problem on Windows.  You need to increase your\
          \ pagefile size.  As this is a 30B model, increase it to about 90GB.\n>\
          \ \n> Or just set it to Auto, and make sure you have enough free disk space\
          \ on C: (or whatever drive holds the pagefile) for it to grow that large.\n\
          > \n> For some reason, on Windows it needs a massive pagefile size to load\
          \ the model into RAM before it can move it to VRAM.\n> \n> Here's a guide\
          \ on adjusting the pagefile if you're not familiar with doing that: https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows\n\
          \nLegend appreciate the help!\nHonestly I thought a 50gb Pagefile was enough\
          \ with 32gb Ram... WoW!!"
        updatedAt: '2023-06-04T11:26:07.771Z'
      numEdits: 0
      reactions: []
    id: 647c74cf83c62f324916b110
    type: comment
  author: Ex01
  content: "> OK this is a common problem on Windows.  You need to increase your pagefile\
    \ size.  As this is a 30B model, increase it to about 90GB.\n> \n> Or just set\
    \ it to Auto, and make sure you have enough free disk space on C: (or whatever\
    \ drive holds the pagefile) for it to grow that large.\n> \n> For some reason,\
    \ on Windows it needs a massive pagefile size to load the model into RAM before\
    \ it can move it to VRAM.\n> \n> Here's a guide on adjusting the pagefile if you're\
    \ not familiar with doing that: https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows\n\
    \nLegend appreciate the help!\nHonestly I thought a 50gb Pagefile was enough with\
    \ 32gb Ram... WoW!!"
  created_at: 2023-06-04 10:26:07+00:00
  edited: false
  hidden: false
  id: 647c74cf83c62f324916b110
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-04T11:30:25.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9799038767814636
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah it really should be. Windows does something weird here. Even
          people with 128GB RAM still need that pagefile.  It seems that it always
          maps it into pagefile, regardless of how much RAM is free.</p>

          '
        raw: Yeah it really should be. Windows does something weird here. Even people
          with 128GB RAM still need that pagefile.  It seems that it always maps it
          into pagefile, regardless of how much RAM is free.
        updatedAt: '2023-06-04T11:30:25.301Z'
      numEdits: 0
      reactions: []
    id: 647c75d1c788767ab5cac85d
    type: comment
  author: TheBloke
  content: Yeah it really should be. Windows does something weird here. Even people
    with 128GB RAM still need that pagefile.  It seems that it always maps it into
    pagefile, regardless of how much RAM is free.
  created_at: 2023-06-04 10:30:25+00:00
  edited: false
  hidden: false
  id: 647c75d1c788767ab5cac85d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/7iwA4iN4xmvsp_UVKymHR.png?w=200&h=200&f=face
      fullname: Jim Kidwell
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AcidSpark
      type: user
    createdAt: '2023-06-04T23:11:27.000Z'
    data:
      edited: false
      editors:
      - AcidSpark
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9783594012260437
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/7iwA4iN4xmvsp_UVKymHR.png?w=200&h=200&f=face
          fullname: Jim Kidwell
          isHf: false
          isPro: false
          name: AcidSpark
          type: user
        html: '<p>So far, this is the most capable model I''ve run locally for role
          play. It''s better (still not perfect) at staying in character and doesn''t
          lose the plot nearly as quickly as other models, or devolve into repeating
          variations on the same message over and over.</p>

          '
        raw: So far, this is the most capable model I've run locally for role play.
          It's better (still not perfect) at staying in character and doesn't lose
          the plot nearly as quickly as other models, or devolve into repeating variations
          on the same message over and over.
        updatedAt: '2023-06-04T23:11:27.830Z'
      numEdits: 0
      reactions: []
    id: 647d1a1f83c62f324929b596
    type: comment
  author: AcidSpark
  content: So far, this is the most capable model I've run locally for role play.
    It's better (still not perfect) at staying in character and doesn't lose the plot
    nearly as quickly as other models, or devolve into repeating variations on the
    same message over and over.
  created_at: 2023-06-04 22:11:27+00:00
  edited: false
  hidden: false
  id: 647d1a1f83c62f324929b596
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-05T00:18:38.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9408519864082336
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Great to hear!</p>

          '
        raw: Great to hear!
        updatedAt: '2023-06-05T00:18:38.168Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - AcidSpark
        - Yhyu13
    id: 647d29dec788767ab5e00e11
    type: comment
  author: TheBloke
  content: Great to hear!
  created_at: 2023-06-04 23:18:38+00:00
  edited: false
  hidden: false
  id: 647d29dec788767ab5e00e11
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28b401d5789d6a0f736be80ada2151fe.svg
      fullname: Simon Howe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ex01
      type: user
    createdAt: '2023-06-05T10:24:21.000Z'
    data:
      edited: false
      editors:
      - Ex01
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9789304733276367
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28b401d5789d6a0f736be80ada2151fe.svg
          fullname: Simon Howe
          isHf: false
          isPro: false
          name: Ex01
          type: user
        html: '<blockquote>

          <p>So far, this is the most capable model I''ve run locally for role play.
          It''s better (still not perfect) at staying in character and doesn''t lose
          the plot nearly as quickly as other models, or devolve into repeating variations
          on the same message over and over.</p>

          </blockquote>

          <p>This is the biggest problem I have found too, I haven''t had time to
          put this 30b through the ringer yet, though this week will hit it hard.
          I have had interesting success with digitous/13B-HyperMantis over the last
          few days. For some reason it finds a unique creativity while remaining on
          topic... until it inevitably does fall off the wagon so to speak.<br>Keep
          up the models I have tried a few of yours now and enjoying the learning
          process. Once I understand how they work Im looking forward to creating
          my own works or tweaks.</p>

          <p>Thanks for your work!</p>

          '
        raw: '> So far, this is the most capable model I''ve run locally for role
          play. It''s better (still not perfect) at staying in character and doesn''t
          lose the plot nearly as quickly as other models, or devolve into repeating
          variations on the same message over and over.


          This is the biggest problem I have found too, I haven''t had time to put
          this 30b through the ringer yet, though this week will hit it hard. I have
          had interesting success with digitous/13B-HyperMantis over the last few
          days. For some reason it finds a unique creativity while remaining on topic...
          until it inevitably does fall off the wagon so to speak.

          Keep up the models I have tried a few of yours now and enjoying the learning
          process. Once I understand how they work Im looking forward to creating
          my own works or tweaks.


          Thanks for your work!'
        updatedAt: '2023-06-05T10:24:21.614Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - TheBloke
    id: 647db7d55214d172cbb29ded
    type: comment
  author: Ex01
  content: '> So far, this is the most capable model I''ve run locally for role play.
    It''s better (still not perfect) at staying in character and doesn''t lose the
    plot nearly as quickly as other models, or devolve into repeating variations on
    the same message over and over.


    This is the biggest problem I have found too, I haven''t had time to put this
    30b through the ringer yet, though this week will hit it hard. I have had interesting
    success with digitous/13B-HyperMantis over the last few days. For some reason
    it finds a unique creativity while remaining on topic... until it inevitably does
    fall off the wagon so to speak.

    Keep up the models I have tried a few of yours now and enjoying the learning process.
    Once I understand how they work Im looking forward to creating my own works or
    tweaks.


    Thanks for your work!'
  created_at: 2023-06-05 09:24:21+00:00
  edited: false
  hidden: false
  id: 647db7d55214d172cbb29ded
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
      fullname: Vladimir
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vdruts
      type: user
    createdAt: '2023-06-06T20:43:41.000Z'
    data:
      edited: true
      editors:
      - vdruts
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9072270393371582
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661628312160-noauth.png?w=200&h=200&f=face
          fullname: Vladimir
          isHf: false
          isPro: false
          name: vdruts
          type: user
        html: '<blockquote>

          <p>OK this is a common problem on Windows.  You need to increase your pagefile
          size.  As this is a 30B model, increase it to about 90GB.</p>

          <p>Or just set it to Auto, and make sure you have enough free disk space
          on C: (or whatever drive holds the pagefile) for it to grow that large.</p>

          <p>For some reason, on Windows it needs a massive pagefile size to load
          the model into RAM before it can move it to VRAM.</p>

          <p>Here''s a guide on adjusting the pagefile if you''re not familiar with
          doing that: <a rel="nofollow" href="https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows">https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows</a></p>

          </blockquote>

          <p>Hmm. I have a 120GIG Pagefilesize and still get this error :/ Win 10.</p>

          <p>I have never been able to load this model successfully in Windows or
          WSL. 4090 23VRAM  + 64GB Ram.</p>

          '
        raw: "> OK this is a common problem on Windows.  You need to increase your\
          \ pagefile size.  As this is a 30B model, increase it to about 90GB.\n>\
          \ \n> Or just set it to Auto, and make sure you have enough free disk space\
          \ on C: (or whatever drive holds the pagefile) for it to grow that large.\n\
          > \n> For some reason, on Windows it needs a massive pagefile size to load\
          \ the model into RAM before it can move it to VRAM.\n> \n> Here's a guide\
          \ on adjusting the pagefile if you're not familiar with doing that: https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows\n\
          \nHmm. I have a 120GIG Pagefilesize and still get this error :/ Win 10.\n\
          \nI have never been able to load this model successfully in Windows or WSL.\
          \ 4090 23VRAM  + 64GB Ram."
        updatedAt: '2023-06-06T20:44:14.627Z'
      numEdits: 1
      reactions: []
    id: 647f9a7d1637c1c0e6eca1b5
    type: comment
  author: vdruts
  content: "> OK this is a common problem on Windows.  You need to increase your pagefile\
    \ size.  As this is a 30B model, increase it to about 90GB.\n> \n> Or just set\
    \ it to Auto, and make sure you have enough free disk space on C: (or whatever\
    \ drive holds the pagefile) for it to grow that large.\n> \n> For some reason,\
    \ on Windows it needs a massive pagefile size to load the model into RAM before\
    \ it can move it to VRAM.\n> \n> Here's a guide on adjusting the pagefile if you're\
    \ not familiar with doing that: https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows\n\
    \nHmm. I have a 120GIG Pagefilesize and still get this error :/ Win 10.\n\nI have\
    \ never been able to load this model successfully in Windows or WSL. 4090 23VRAM\
    \  + 64GB Ram."
  created_at: 2023-06-06 19:43:41+00:00
  edited: true
  hidden: false
  id: 647f9a7d1637c1c0e6eca1b5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/28b401d5789d6a0f736be80ada2151fe.svg
      fullname: Simon Howe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ex01
      type: user
    createdAt: '2023-06-07T07:03:13.000Z'
    data:
      edited: false
      editors:
      - Ex01
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9197764992713928
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/28b401d5789d6a0f736be80ada2151fe.svg
          fullname: Simon Howe
          isHf: false
          isPro: false
          name: Ex01
          type: user
        html: '<blockquote>

          <blockquote>

          <p>OK this is a common problem on Windows.  You need to increase your pagefile
          size.  As this is a 30B model, increase it to about 90GB.</p>

          <p>Or just set it to Auto, and make sure you have enough free disk space
          on C: (or whatever drive holds the pagefile) for it to grow that large.</p>

          <p>For some reason, on Windows it needs a massive pagefile size to load
          the model into RAM before it can move it to VRAM.</p>

          <p>Here''s a guide on adjusting the pagefile if you''re not familiar with
          doing that: <a rel="nofollow" href="https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows">https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows</a></p>

          </blockquote>

          <p>Hmm. I have a 120GIG Pagefilesize and still get this error :/ Win 10.</p>

          <p>I have never been able to load this model successfully in Windows or
          WSL. 4090 23VRAM  + 64GB Ram.</p>

          </blockquote>

          <p>|I''m not expert yet, however reading the above I set my SSD page file
          to 100BG and it works brilliantly. I am on windows 11 and ''The Bloke''
          talks about anomalies in windows page file usage, so its quite possible
          windows 10 hands pagefile different to Win 11 and perhaps try more room?</p>

          '
        raw: "> > OK this is a common problem on Windows.  You need to increase your\
          \ pagefile size.  As this is a 30B model, increase it to about 90GB.\n>\
          \ > \n> > Or just set it to Auto, and make sure you have enough free disk\
          \ space on C: (or whatever drive holds the pagefile) for it to grow that\
          \ large.\n> > \n> > For some reason, on Windows it needs a massive pagefile\
          \ size to load the model into RAM before it can move it to VRAM.\n> > \n\
          > > Here's a guide on adjusting the pagefile if you're not familiar with\
          \ doing that: https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows\n\
          > \n> Hmm. I have a 120GIG Pagefilesize and still get this error :/ Win\
          \ 10.\n> \n> I have never been able to load this model successfully in Windows\
          \ or WSL. 4090 23VRAM  + 64GB Ram.\n\n|I'm not expert yet, however reading\
          \ the above I set my SSD page file to 100BG and it works brilliantly. I\
          \ am on windows 11 and 'The Bloke' talks about anomalies in windows page\
          \ file usage, so its quite possible windows 10 hands pagefile different\
          \ to Win 11 and perhaps try more room?"
        updatedAt: '2023-06-07T07:03:13.920Z'
      numEdits: 0
      reactions: []
    id: 64802bb1a96905a480739961
    type: comment
  author: Ex01
  content: "> > OK this is a common problem on Windows.  You need to increase your\
    \ pagefile size.  As this is a 30B model, increase it to about 90GB.\n> > \n>\
    \ > Or just set it to Auto, and make sure you have enough free disk space on C:\
    \ (or whatever drive holds the pagefile) for it to grow that large.\n> > \n> >\
    \ For some reason, on Windows it needs a massive pagefile size to load the model\
    \ into RAM before it can move it to VRAM.\n> > \n> > Here's a guide on adjusting\
    \ the pagefile if you're not familiar with doing that: https://www.thewindowsclub.com/increase-page-file-size-virtual-memory-windows\n\
    > \n> Hmm. I have a 120GIG Pagefilesize and still get this error :/ Win 10.\n\
    > \n> I have never been able to load this model successfully in Windows or WSL.\
    \ 4090 23VRAM  + 64GB Ram.\n\n|I'm not expert yet, however reading the above I\
    \ set my SSD page file to 100BG and it works brilliantly. I am on windows 11 and\
    \ 'The Bloke' talks about anomalies in windows page file usage, so its quite possible\
    \ windows 10 hands pagefile different to Win 11 and perhaps try more room?"
  created_at: 2023-06-07 06:03:13+00:00
  edited: false
  hidden: false
  id: 64802bb1a96905a480739961
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ
repo_type: model
status: open
target_branch: null
title: Oh my gosh StoryTelling indeed
