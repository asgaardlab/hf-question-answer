!!python/object:huggingface_hub.community.DiscussionWithDetails
author: DesmondChoy
conflicting_files: null
created_at: 2023-08-01 06:51:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6f37c2b90685ad866fb116497f1563d5.svg
      fullname: Desmond Choy
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DesmondChoy
      type: user
    createdAt: '2023-08-01T07:51:02.000Z'
    data:
      edited: false
      editors:
      - DesmondChoy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8981436491012573
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6f37c2b90685ad866fb116497f1563d5.svg
          fullname: Desmond Choy
          isHf: false
          isPro: false
          name: DesmondChoy
          type: user
        html: '<p>I''ve checked <a rel="nofollow" href="https://python.langchain.com/docs/integrations/llms/">https://python.langchain.com/docs/integrations/llms/</a>
          but I can''t find options on integrating this with Langchain.<br>I''ve installed
          the 4-bit model and was hoping to use it for a <a rel="nofollow" href="https://python.langchain.com/docs/use_cases/question_answering">Q&amp;A
          use case</a>.<br>Would appreciate any help, thank you!</p>

          '
        raw: "I've checked https://python.langchain.com/docs/integrations/llms/ but\
          \ I can't find options on integrating this with Langchain. \r\nI've installed\
          \ the 4-bit model and was hoping to use it for a [Q&A use case](https://python.langchain.com/docs/use_cases/question_answering).\r\
          \nWould appreciate any help, thank you!"
        updatedAt: '2023-08-01T07:51:02.030Z'
      numEdits: 0
      reactions: []
    id: 64c8b966e761f470612171a8
    type: comment
  author: DesmondChoy
  content: "I've checked https://python.langchain.com/docs/integrations/llms/ but\
    \ I can't find options on integrating this with Langchain. \r\nI've installed\
    \ the 4-bit model and was hoping to use it for a [Q&A use case](https://python.langchain.com/docs/use_cases/question_answering).\r\
    \nWould appreciate any help, thank you!"
  created_at: 2023-08-01 06:51:02+00:00
  edited: false
  hidden: false
  id: 64c8b966e761f470612171a8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/6WE3ys5P8uuZwWRSChWJV.jpeg?w=200&h=200&f=face
      fullname: Alex McAnulty
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GentlePickle
      type: user
    createdAt: '2023-08-01T23:44:30.000Z'
    data:
      edited: false
      editors:
      - GentlePickle
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.91795814037323
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/6WE3ys5P8uuZwWRSChWJV.jpeg?w=200&h=200&f=face
          fullname: Alex McAnulty
          isHf: false
          isPro: false
          name: GentlePickle
          type: user
        html: '<p>This isn''t a question about or regarding the model. If you have
          the knowhow then you could integrate anything that generates text from input
          with langchain. </p>

          <p>You can run any llama-architecture type model from a variety of frameworks,
          many of which have langchain integration. The simplest is probably transformers
          or CTransformers. Also pretty simple is running it with Oobabooga''s textgen
          web UI, or any application like that that you can run and perform inference
          with. That tool comes with a variety of options for langchain integration,
          including blocking and streaming APIs, or just a local URL that you can
          plug right in to a langchain function. There''s a whole massive section
          in the langchain documentation on which inference frameworks have supported
          packages. </p>

          '
        raw: "This isn't a question about or regarding the model. If you have the\
          \ knowhow then you could integrate anything that generates text from input\
          \ with langchain. \n\nYou can run any llama-architecture type model from\
          \ a variety of frameworks, many of which have langchain integration. The\
          \ simplest is probably transformers or CTransformers. Also pretty simple\
          \ is running it with Oobabooga's textgen web UI, or any application like\
          \ that that you can run and perform inference with. That tool comes with\
          \ a variety of options for langchain integration, including blocking and\
          \ streaming APIs, or just a local URL that you can plug right in to a langchain\
          \ function. There's a whole massive section in the langchain documentation\
          \ on which inference frameworks have supported packages. "
        updatedAt: '2023-08-01T23:44:30.265Z'
      numEdits: 0
      reactions: []
    id: 64c998de36c11430f339421c
    type: comment
  author: GentlePickle
  content: "This isn't a question about or regarding the model. If you have the knowhow\
    \ then you could integrate anything that generates text from input with langchain.\
    \ \n\nYou can run any llama-architecture type model from a variety of frameworks,\
    \ many of which have langchain integration. The simplest is probably transformers\
    \ or CTransformers. Also pretty simple is running it with Oobabooga's textgen\
    \ web UI, or any application like that that you can run and perform inference\
    \ with. That tool comes with a variety of options for langchain integration, including\
    \ blocking and streaming APIs, or just a local URL that you can plug right in\
    \ to a langchain function. There's a whole massive section in the langchain documentation\
    \ on which inference frameworks have supported packages. "
  created_at: 2023-08-01 22:44:30+00:00
  edited: false
  hidden: false
  id: 64c998de36c11430f339421c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 24
repo_id: stabilityai/StableBeluga2
repo_type: model
status: open
target_branch: null
title: Is there integration with Langchain?
