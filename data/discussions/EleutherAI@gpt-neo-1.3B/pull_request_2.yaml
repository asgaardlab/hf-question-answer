!!python/object:huggingface_hub.community.DiscussionWithDetails
author: orena
conflicting_files: []
created_at: 2022-11-18 21:44:34+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/dcd7951e3c3373c9ec918b173cbcf2f6.svg
      fullname: oren
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: orena
      type: user
    createdAt: '2022-11-18T21:44:34.000Z'
    data:
      edited: false
      editors:
      - orena
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/dcd7951e3c3373c9ec918b173cbcf2f6.svg
          fullname: oren
          isHf: false
          isPro: false
          name: orena
          type: user
        html: "<p>When running without <code>max_length</code> we are getting this\
          \ error:</p>\n<pre><code>Setting `pad_token_id` to `eos_token_id`:50256\
          \ for open-end generation.\n/home/oamsalem/.local/lib/python3.9/site-packages/transformers/generation_utils.py:1359:\
          \ UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length`\
          \ will default to 50 (`self.config.max_length`). Controlling `max_length`\
          \ via the config is deprecated and `max_length` will be removed from the\
          \ config in v5 of Transformers -- we recommend using `max_new_tokens` to\
          \ control the maximum length of the generation.\n  warnings.warn(\n</code></pre>\n\
          <p>Better to set it to avoid this message</p>\n"
        raw: "When running without `max_length` we are getting this error:\n```\n\
          Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\
          /home/oamsalem/.local/lib/python3.9/site-packages/transformers/generation_utils.py:1359:\
          \ UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length`\
          \ will default to 50 (`self.config.max_length`). Controlling `max_length`\
          \ via the config is deprecated and `max_length` will be removed from the\
          \ config in v5 of Transformers -- we recommend using `max_new_tokens` to\
          \ control the maximum length of the generation.\n  warnings.warn(\n```\n\
          Better to set it to avoid this message"
        updatedAt: '2022-11-18T21:44:34.148Z'
      numEdits: 0
      reactions: []
    id: 6377fcc2500186f250b6ad8d
    type: comment
  author: orena
  content: "When running without `max_length` we are getting this error:\n```\nSetting\
    \ `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n/home/oamsalem/.local/lib/python3.9/site-packages/transformers/generation_utils.py:1359:\
    \ UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length`\
    \ will default to 50 (`self.config.max_length`). Controlling `max_length` via\
    \ the config is deprecated and `max_length` will be removed from the config in\
    \ v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum\
    \ length of the generation.\n  warnings.warn(\n```\nBetter to set it to avoid\
    \ this message"
  created_at: 2022-11-18 21:44:34+00:00
  edited: false
  hidden: false
  id: 6377fcc2500186f250b6ad8d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/dcd7951e3c3373c9ec918b173cbcf2f6.svg
      fullname: oren
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: orena
      type: user
    createdAt: '2022-11-18T21:44:34.000Z'
    data:
      oid: cc5bffa77e235fb99e17abf290e8beca645be074
      parents:
      - 797174552ae47f449ab70b684cabcb6603e5e85e
      subject: Set max_length to 50 to avoid deprecation message
    id: 6377fcc20000000000000000
    type: commit
  author: orena
  created_at: 2022-11-18 21:44:34+00:00
  id: 6377fcc20000000000000000
  oid: cc5bffa77e235fb99e17abf290e8beca645be074
  summary: Set max_length to 50 to avoid deprecation message
  type: commit
is_pull_request: true
merge_commit_oid: null
num: 2
repo_id: EleutherAI/gpt-neo-1.3B
repo_type: model
status: open
target_branch: refs/heads/main
title: Set max_length to 50 to avoid deprecation message
