!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Nexesenex
conflicting_files: null
created_at: 2023-09-04 17:10:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/31b10b87d67ff7d0691f786a857d319a.svg
      fullname: Nexesenex
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nexesenex
      type: user
    createdAt: '2023-09-04T18:10:01.000Z'
    data:
      edited: true
      editors:
      - Nexesenex
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8589772582054138
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/31b10b87d67ff7d0691f786a857d319a.svg
          fullname: Nexesenex
          isHf: false
          isPro: false
          name: Nexesenex
          type: user
        html: '<p>On this model, it reads :</p>

          <p>  "max_position_embeddings": 2048,<br>  "torch_dtype": "float16",</p>

          <p>Shouldn''t it be like on the original CodeLlama model and Airoboros c34b
          2.1?</p>

          <p>  "max_position_embeddings": 16384,<br>  "torch_dtype": "bfloat16",</p>

          <p>Also,  wouldn''t  "rope_theta": 1000000, be useful, as per the original
          CodeLlama model?</p>

          <p>Thanks for publishing this, as well as for Samantha C34 1.11 (who is
          a real challenge for context obedient prompt and model schizophrenia between
          the Assistant and the Character Samantha), Eric!</p>

          '
        raw: "On this model, it reads :\n\n  \"max_position_embeddings\": 2048,\n\
          \  \"torch_dtype\": \"float16\",\n\nShouldn't it be like on the original\
          \ CodeLlama model and Airoboros c34b 2.1?\n\n  \"max_position_embeddings\"\
          : 16384,\n  \"torch_dtype\": \"bfloat16\",\n\nAlso,  wouldn't  \"rope_theta\"\
          : 1000000, be useful, as per the original CodeLlama model?\n\nThanks for\
          \ publishing this, as well as for Samantha C34 1.11 (who is a real challenge\
          \ for context obedient prompt and model schizophrenia between the Assistant\
          \ and the Character Samantha), Eric!"
        updatedAt: '2023-09-04T18:31:02.251Z'
      numEdits: 2
      reactions: []
    id: 64f61d7913e91ef83b8df2ab
    type: comment
  author: Nexesenex
  content: "On this model, it reads :\n\n  \"max_position_embeddings\": 2048,\n  \"\
    torch_dtype\": \"float16\",\n\nShouldn't it be like on the original CodeLlama\
    \ model and Airoboros c34b 2.1?\n\n  \"max_position_embeddings\": 16384,\n  \"\
    torch_dtype\": \"bfloat16\",\n\nAlso,  wouldn't  \"rope_theta\": 1000000, be useful,\
    \ as per the original CodeLlama model?\n\nThanks for publishing this, as well\
    \ as for Samantha C34 1.11 (who is a real challenge for context obedient prompt\
    \ and model schizophrenia between the Assistant and the Character Samantha), Eric!"
  created_at: 2023-09-04 17:10:01+00:00
  edited: true
  hidden: false
  id: 64f61d7913e91ef83b8df2ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-09-05T06:44:57.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9754308462142944
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>I didn''t set any of those values.  I used CodeLlama as the base
          model</p>

          '
        raw: I didn't set any of those values.  I used CodeLlama as the base model
        updatedAt: '2023-09-05T06:44:57.345Z'
      numEdits: 0
      reactions: []
    id: 64f6ce69c03c6f1042883821
    type: comment
  author: ehartford
  content: I didn't set any of those values.  I used CodeLlama as the base model
  created_at: 2023-09-05 05:44:57+00:00
  edited: false
  hidden: false
  id: 64f6ce69c03c6f1042883821
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-09-05T19:36:32.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.45573052763938904
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>From where?  Did you use a non-official source perhaps?  The correct
          values are here: <a href="https://huggingface.co/codellama/CodeLlama-34b-hf/blob/main/config.json">https://huggingface.co/codellama/CodeLlama-34b-hf/blob/main/config.json</a>
          </p>

          <p>It should have 16K and rope_theta 1M yeah.  I''ll change it for my quants
          and I put in a PR</p>

          '
        raw: "From where?  Did you use a non-official source perhaps?  The correct\
          \ values are here: https://huggingface.co/codellama/CodeLlama-34b-hf/blob/main/config.json\
          \ \n\nIt should have 16K and rope_theta 1M yeah.  I'll change it for my\
          \ quants and I put in a PR"
        updatedAt: '2023-09-05T19:37:20.781Z'
      numEdits: 1
      reactions: []
    id: 64f783406a71cea1c7c5d243
    type: comment
  author: TheBloke
  content: "From where?  Did you use a non-official source perhaps?  The correct values\
    \ are here: https://huggingface.co/codellama/CodeLlama-34b-hf/blob/main/config.json\
    \ \n\nIt should have 16K and rope_theta 1M yeah.  I'll change it for my quants\
    \ and I put in a PR"
  created_at: 2023-09-05 18:36:32+00:00
  edited: true
  hidden: false
  id: 64f783406a71cea1c7c5d243
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-09-05T20:04:45.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6747040748596191
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>Thank you Tom </p>

          '
        raw: 'Thank you Tom '
        updatedAt: '2023-09-05T20:04:45.718Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - TheBloke
    id: 64f789dd7fa750529705ab2e
    type: comment
  author: ehartford
  content: 'Thank you Tom '
  created_at: 2023-09-05 19:04:45+00:00
  edited: false
  hidden: false
  id: 64f789dd7fa750529705ab2e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: cognitivecomputations/WizardLM-1.0-Uncensored-CodeLlama-34b
repo_type: model
status: open
target_branch: null
title: config.json paramaters
