!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jvamvas
conflicting_files: []
created_at: 2023-10-06 09:02:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/f4945fb277e60cc065ad33c9fcc5be03.svg
      fullname: Jannis Vamvas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jvamvas
      type: user
    createdAt: '2023-10-06T10:00:38.000Z'
    data:
      oid: 007e82656cdb52dda51a3f6b674aa57df98ba058
      parents:
      - e36a5078c684f164d4cf5df3e1d5a4ffe73e4642
      subject: Copy XLM-R tokenizer to this repo
    id: 651fdac60000000000000000
    type: commit
  author: jvamvas
  created_at: 2023-10-06 09:00:38+00:00
  id: 651fdac60000000000000000
  oid: 007e82656cdb52dda51a3f6b674aa57df98ba058
  summary: Copy XLM-R tokenizer to this repo
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f4945fb277e60cc065ad33c9fcc5be03.svg
      fullname: Jannis Vamvas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jvamvas
      type: user
    createdAt: '2023-10-06T10:02:01.000Z'
    data:
      edited: false
      editors:
      - jvamvas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f4945fb277e60cc065ad33c9fcc5be03.svg
          fullname: Jannis Vamvas
          isHf: false
          isPro: false
          name: jvamvas
          type: user
        html: ''
        raw: ''
        updatedAt: '2023-10-06T10:02:01.660Z'
      numEdits: 0
      reactions: []
    id: 651fdb19607b4e7eea5bd971
    type: comment
  author: jvamvas
  content: ''
  created_at: 2023-10-06 09:02:01+00:00
  edited: false
  hidden: false
  id: 651fdb19607b4e7eea5bd971
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f4945fb277e60cc065ad33c9fcc5be03.svg
      fullname: Jannis Vamvas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jvamvas
      type: user
    createdAt: '2023-10-06T10:12:47.000Z'
    data:
      edited: false
      editors:
      - jvamvas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9826967120170593
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f4945fb277e60cc065ad33c9fcc5be03.svg
          fullname: Jannis Vamvas
          isHf: false
          isPro: false
          name: jvamvas
          type: user
        html: '<p>Resolves <a href="/facebook/xmod-base/discussions/1">#1</a></p>

          '
        raw: 'Resolves #1'
        updatedAt: '2023-10-06T10:12:47.709Z'
      numEdits: 0
      reactions: []
      relatedEventId: 651fdd9fada176d71133edab
    id: 651fdd9fada176d71133eda4
    type: comment
  author: jvamvas
  content: 'Resolves #1'
  created_at: 2023-10-06 09:12:47+00:00
  edited: false
  hidden: false
  id: 651fdd9fada176d71133eda4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f4945fb277e60cc065ad33c9fcc5be03.svg
      fullname: Jannis Vamvas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jvamvas
      type: user
    createdAt: '2023-10-06T10:12:47.000Z'
    data:
      status: open
    id: 651fdd9fada176d71133edab
    type: status-change
  author: jvamvas
  created_at: 2023-10-06 09:12:47+00:00
  id: 651fdd9fada176d71133edab
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2023-10-06T11:27:38.000Z'
    data:
      edited: false
      editors:
      - lysandre
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.12180587649345398
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
          fullname: Lysandre
          isHf: true
          isPro: false
          name: lysandre
          type: user
        html: "<p>Perfect! Verified this works:</p>\n<pre><code class=\"language-py\"\
          >In [<span class=\"hljs-number\">1</span>]: <span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer\n\
          In [<span class=\"hljs-number\">2</span>]: tokenizer = AutoTokenizer.from_pretrained(<span\
          \ class=\"hljs-string\">\"facebook/xmod-base\"</span>, revision=<span class=\"\
          hljs-string\">\"refs/pr/2\"</span>)\nDownloading (\u2026)okenizer_config.json:\
          \ <span class=\"hljs-number\">100</span>%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          | <span class=\"hljs-number\">48.0</span>/<span class=\"hljs-number\">48.0</span>\
          \ [<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>&lt;<span\
          \ class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>,\
          \ <span class=\"hljs-number\">10.9</span>kB/s]\nDownloading (\u2026)r%2F2/tokenizer.json:\
          \ <span class=\"hljs-number\">100</span>%|\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| <span class=\"\
          hljs-number\">9.10</span>M/<span class=\"hljs-number\">9.10</span>M [<span\
          \ class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>&lt;<span\
          \ class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>,\
          \ <span class=\"hljs-number\">14.1</span>MB/s]\n\nIn [<span class=\"hljs-number\"\
          >3</span>]: tokenizer\nOut[<span class=\"hljs-number\">3</span>]:\nXLMRobertaTokenizerFast(name_or_path=<span\
          \ class=\"hljs-string\">'facebook/xmod-base'</span>, vocab_size=<span class=\"\
          hljs-number\">250002</span>, model_max_length=<span class=\"hljs-number\"\
          >1000000000000000019884624838656</span>, is_fast=<span class=\"hljs-literal\"\
          >True</span>, padding_side=<span class=\"hljs-string\">'right'</span>, truncation_side=<span\
          \ class=\"hljs-string\">'right'</span>, special_tokens={<span class=\"hljs-string\"\
          >'bos_token'</span>: <span class=\"hljs-string\">'&lt;s&gt;'</span>, <span\
          \ class=\"hljs-string\">'eos_token'</span>: <span class=\"hljs-string\"\
          >'&lt;/s&gt;'</span>, <span class=\"hljs-string\">'unk_token'</span>: <span\
          \ class=\"hljs-string\">'&lt;unk&gt;'</span>, <span class=\"hljs-string\"\
          >'sep_token'</span>: <span class=\"hljs-string\">'&lt;/s&gt;'</span>, <span\
          \ class=\"hljs-string\">'pad_token'</span>: <span class=\"hljs-string\"\
          >'&lt;pad&gt;'</span>, <span class=\"hljs-string\">'cls_token'</span>: <span\
          \ class=\"hljs-string\">'&lt;s&gt;'</span>, <span class=\"hljs-string\"\
          >'mask_token'</span>: <span class=\"hljs-string\">'&lt;mask&gt;'</span>},\
          \ clean_up_tokenization_spaces=<span class=\"hljs-literal\">True</span>),\
          \  added_tokens_decoder={\n    <span class=\"hljs-number\">0</span>: AddedToken(<span\
          \ class=\"hljs-string\">\"&lt;s&gt;\"</span>, rstrip=<span class=\"hljs-literal\"\
          >False</span>, lstrip=<span class=\"hljs-literal\">False</span>, single_word=<span\
          \ class=\"hljs-literal\">False</span>, normalized=<span class=\"hljs-literal\"\
          >False</span>, special=<span class=\"hljs-literal\">True</span>),\n    <span\
          \ class=\"hljs-number\">1</span>: AddedToken(<span class=\"hljs-string\"\
          >\"&lt;pad&gt;\"</span>, rstrip=<span class=\"hljs-literal\">False</span>,\
          \ lstrip=<span class=\"hljs-literal\">False</span>, single_word=<span class=\"\
          hljs-literal\">False</span>, normalized=<span class=\"hljs-literal\">False</span>,\
          \ special=<span class=\"hljs-literal\">True</span>),\n    <span class=\"\
          hljs-number\">2</span>: AddedToken(<span class=\"hljs-string\">\"&lt;/s&gt;\"\
          </span>, rstrip=<span class=\"hljs-literal\">False</span>, lstrip=<span\
          \ class=\"hljs-literal\">False</span>, single_word=<span class=\"hljs-literal\"\
          >False</span>, normalized=<span class=\"hljs-literal\">False</span>, special=<span\
          \ class=\"hljs-literal\">True</span>),\n    <span class=\"hljs-number\"\
          >3</span>: AddedToken(<span class=\"hljs-string\">\"&lt;unk&gt;\"</span>,\
          \ rstrip=<span class=\"hljs-literal\">False</span>, lstrip=<span class=\"\
          hljs-literal\">False</span>, single_word=<span class=\"hljs-literal\">False</span>,\
          \ normalized=<span class=\"hljs-literal\">False</span>, special=<span class=\"\
          hljs-literal\">True</span>),\n    <span class=\"hljs-number\">250001</span>:\
          \ AddedToken(<span class=\"hljs-string\">\"&lt;mask&gt;\"</span>, rstrip=<span\
          \ class=\"hljs-literal\">False</span>, lstrip=<span class=\"hljs-literal\"\
          >True</span>, single_word=<span class=\"hljs-literal\">False</span>, normalized=<span\
          \ class=\"hljs-literal\">False</span>, special=<span class=\"hljs-literal\"\
          >True</span>),\n}\n</code></pre>\n"
        raw: "Perfect! Verified this works:\n\n```py\nIn [1]: from transformers import\
          \ AutoTokenizer\nIn [2]: tokenizer = AutoTokenizer.from_pretrained(\"facebook/xmod-base\"\
          , revision=\"refs/pr/2\")\nDownloading (\u2026)okenizer_config.json: 100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588| 48.0/48.0 [00:00<00:00, 10.9kB/s]\nDownloading\
          \ (\u2026)r%2F2/tokenizer.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9.10M/9.10M [00:00<00:00,\
          \ 14.1MB/s]\n\nIn [3]: tokenizer\nOut[3]:\nXLMRobertaTokenizerFast(name_or_path='facebook/xmod-base',\
          \ vocab_size=250002, model_max_length=1000000000000000019884624838656, is_fast=True,\
          \ padding_side='right', truncation_side='right', special_tokens={'bos_token':\
          \ '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>',\
          \ 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),\
          \  added_tokens_decoder={\n\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False,\
          \ single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"\
          <pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False,\
          \ special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False,\
          \ single_word=False, normalized=False, special=True),\n\t3: AddedToken(\"\
          <unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False,\
          \ special=True),\n\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True,\
          \ single_word=False, normalized=False, special=True),\n}\n```"
        updatedAt: '2023-10-06T11:27:38.188Z'
      numEdits: 0
      reactions: []
      relatedEventId: 651fef2ab32435c1feec73ce
    id: 651fef2ab32435c1feec73cc
    type: comment
  author: lysandre
  content: "Perfect! Verified this works:\n\n```py\nIn [1]: from transformers import\
    \ AutoTokenizer\nIn [2]: tokenizer = AutoTokenizer.from_pretrained(\"facebook/xmod-base\"\
    , revision=\"refs/pr/2\")\nDownloading (\u2026)okenizer_config.json: 100%|\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 48.0/48.0 [00:00<00:00, 10.9kB/s]\n\
    Downloading (\u2026)r%2F2/tokenizer.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588| 9.10M/9.10M [00:00<00:00, 14.1MB/s]\n\nIn [3]: tokenizer\nOut[3]:\nXLMRobertaTokenizerFast(name_or_path='facebook/xmod-base',\
    \ vocab_size=250002, model_max_length=1000000000000000019884624838656, is_fast=True,\
    \ padding_side='right', truncation_side='right', special_tokens={'bos_token':\
    \ '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token':\
    \ '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),\
    \  added_tokens_decoder={\n\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False,\
    \ single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<pad>\"\
    , rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\
    \t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False,\
    \ special=True),\n\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False,\
    \ normalized=False, special=True),\n\t250001: AddedToken(\"<mask>\", rstrip=False,\
    \ lstrip=True, single_word=False, normalized=False, special=True),\n}\n```"
  created_at: 2023-10-06 10:27:38+00:00
  edited: false
  hidden: false
  id: 651fef2ab32435c1feec73cc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1618450692745-5e3aec01f55e2b62848a5217.jpeg?w=200&h=200&f=face
      fullname: Lysandre
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lysandre
      type: user
    createdAt: '2023-10-06T11:27:38.000Z'
    data:
      status: merged
    id: 651fef2ab32435c1feec73ce
    type: status-change
  author: lysandre
  created_at: 2023-10-06 10:27:38+00:00
  id: 651fef2ab32435c1feec73ce
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 1ff23836a9ee8b9656553630c33506a9a8a59c4f
num: 2
repo_id: facebook/xmod-base
repo_type: model
status: merged
target_branch: refs/heads/main
title: Add XLM-R tokenizer files
