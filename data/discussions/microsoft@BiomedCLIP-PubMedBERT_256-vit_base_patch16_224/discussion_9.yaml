!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jyx-su
conflicting_files: null
created_at: 2023-07-22 11:35:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d5be06d419a1a6f3e53706c8e44cd7bc.svg
      fullname: Kyle Jiang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jyx-su
      type: user
    createdAt: '2023-07-22T12:35:18.000Z'
    data:
      edited: false
      editors:
      - jyx-su
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.4708938002586365
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d5be06d419a1a6f3e53706c8e44cd7bc.svg
          fullname: Kyle Jiang
          isHf: false
          isPro: false
          name: jyx-su
          type: user
        html: '<p>When I was executing "model, preprocess_train, preprocess_val =
          open_clip.create_model_and_transforms(''hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'')",
          the following error was encountered. </p>

          <p>File ".../open_clip/factory.py", line 104, in load_checkpoint<br>       incompatible_keys
          = model.load_state_dict(state_dict, strict=strict)<br>RuntimeError: Error(s)
          in loading state_dict for CustomTextCLIP:<br>        Unexpected key(s) in
          state_dict: "text.transformer.embeddings.position_ids". </p>

          <p>Package versions:</p>

          <p>open-clip-torch           2.20.0                   pypi_0    pypi<br>pytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch<br>pytorch-cuda              11.8                 h7e8668a_5    pytorch<br>pytorch-mutex             1.0                        cuda    pytorch<br>torchaudio                2.0.2               py311_cu118    pytorch<br>torchtriton               2.0.0                     py311    pytorch<br>torchvision               0.15.2              py311_cu118    pytorch<br>transformers              4.31.0                   pypi_0    pypi</p>

          '
        raw: "When I was executing \"model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\"\
          , the following error was encountered. \r\n\r\nFile \".../open_clip/factory.py\"\
          , line 104, in load_checkpoint\r\n       incompatible_keys = model.load_state_dict(state_dict,\
          \ strict=strict)\r\nRuntimeError: Error(s) in loading state_dict for CustomTextCLIP:\r\
          \n        Unexpected key(s) in state_dict: \"text.transformer.embeddings.position_ids\"\
          . \r\n\r\nPackage versions:\r\n\r\nopen-clip-torch           2.20.0    \
          \               pypi_0    pypi\r\npytorch                   2.0.1      \
          \     py3.11_cuda11.8_cudnn8.7.0_0    pytorch\r\npytorch-cuda          \
          \    11.8                 h7e8668a_5    pytorch\r\npytorch-mutex       \
          \      1.0                        cuda    pytorch\r\ntorchaudio        \
          \        2.0.2               py311_cu118    pytorch\r\ntorchtriton     \
          \          2.0.0                     py311    pytorch\r\ntorchvision   \
          \            0.15.2              py311_cu118    pytorch\r\ntransformers\
          \              4.31.0                   pypi_0    pypi"
        updatedAt: '2023-07-22T12:35:18.269Z'
      numEdits: 0
      reactions: []
    id: 64bbcd068496ee0fb6d02c4d
    type: comment
  author: jyx-su
  content: "When I was executing \"model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\"\
    , the following error was encountered. \r\n\r\nFile \".../open_clip/factory.py\"\
    , line 104, in load_checkpoint\r\n       incompatible_keys = model.load_state_dict(state_dict,\
    \ strict=strict)\r\nRuntimeError: Error(s) in loading state_dict for CustomTextCLIP:\r\
    \n        Unexpected key(s) in state_dict: \"text.transformer.embeddings.position_ids\"\
    . \r\n\r\nPackage versions:\r\n\r\nopen-clip-torch           2.20.0          \
    \         pypi_0    pypi\r\npytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0\
    \    pytorch\r\npytorch-cuda              11.8                 h7e8668a_5    pytorch\r\
    \npytorch-mutex             1.0                        cuda    pytorch\r\ntorchaudio\
    \                2.0.2               py311_cu118    pytorch\r\ntorchtriton   \
    \            2.0.0                     py311    pytorch\r\ntorchvision       \
    \        0.15.2              py311_cu118    pytorch\r\ntransformers          \
    \    4.31.0                   pypi_0    pypi"
  created_at: 2023-07-22 11:35:18+00:00
  edited: false
  hidden: false
  id: 64bbcd068496ee0fb6d02c4d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6481e089ab49674d438403a5098fa35a.svg
      fullname: Giovanni Palla
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: giovp
      type: user
    createdAt: '2023-08-01T21:15:10.000Z'
    data:
      edited: false
      editors:
      - giovp
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.885412335395813
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6481e089ab49674d438403a5098fa35a.svg
          fullname: Giovanni Palla
          isHf: false
          isPro: false
          name: giovp
          type: user
        html: "<p>same! I have same versions as <span data-props=\"{&quot;user&quot;:&quot;jyx-su&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/jyx-su\"\
          >@<span class=\"underline\">jyx-su</span></a></span>\n\n\t</span></span>\
          \ reported, downgrading to transformers-4.30.2 fixed the issue. Think it\
          \ might be the \"tied weights load\" bit in the changelog <a rel=\"nofollow\"\
          \ href=\"https://github.com/huggingface/transformers/releases\">https://github.com/huggingface/transformers/releases</a></p>\n"
        raw: same! I have same versions as @jyx-su reported, downgrading to transformers-4.30.2
          fixed the issue. Think it might be the "tied weights load" bit in the changelog
          https://github.com/huggingface/transformers/releases
        updatedAt: '2023-08-01T21:15:10.139Z'
      numEdits: 0
      reactions: []
    id: 64c975dec547ed5243008b8e
    type: comment
  author: giovp
  content: same! I have same versions as @jyx-su reported, downgrading to transformers-4.30.2
    fixed the issue. Think it might be the "tied weights load" bit in the changelog
    https://github.com/huggingface/transformers/releases
  created_at: 2023-08-01 20:15:10+00:00
  edited: false
  hidden: false
  id: 64c975dec547ed5243008b8e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c05dc66de815717374ba582cd103f165.svg
      fullname: Linus Kreitner
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KreitnerL
      type: user
    createdAt: '2023-08-16T08:01:31.000Z'
    data:
      edited: false
      editors:
      - KreitnerL
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6085966229438782
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c05dc66de815717374ba582cd103f165.svg
          fullname: Linus Kreitner
          isHf: false
          isPro: false
          name: KreitnerL
          type: user
        html: "<p>If you cannot downgrade to a lower transformer version and need\
          \ a quick fix, try this:<br>in <code>site-packages/open_clip/factory.py</code>fix\
          \ the load_checkpoint function by deleting the unexpected key from the checkpoint:</p>\n\
          <pre><code class=\"language-py\"><span class=\"hljs-keyword\">def</span>\
          \ <span class=\"hljs-title function_\">load_checkpoint</span>(<span class=\"\
          hljs-params\">model, checkpoint_path, strict=<span class=\"hljs-literal\"\
          >True</span></span>):\n    state_dict = load_state_dict(checkpoint_path)\n\
          \    <span class=\"hljs-comment\"># detect old format and make compatible\
          \ with new format</span>\n    <span class=\"hljs-keyword\">if</span> <span\
          \ class=\"hljs-string\">'positional_embedding'</span> <span class=\"hljs-keyword\"\
          >in</span> state_dict <span class=\"hljs-keyword\">and</span> <span class=\"\
          hljs-keyword\">not</span> <span class=\"hljs-built_in\">hasattr</span>(model,\
          \ <span class=\"hljs-string\">'positional_embedding'</span>):\n        state_dict\
          \ = convert_to_custom_text_state_dict(state_dict)\n    resize_pos_embed(state_dict,\
          \ model)\n    <span class=\"hljs-keyword\">del</span> state_dict[<span class=\"\
          hljs-string\">\"text.transformer.embeddings.position_ids\"</span>] <span\
          \ class=\"hljs-comment\"># &lt;----- This line is new</span>\n    incompatible_keys\
          \ = model.load_state_dict(state_dict, strict=strict)\n    <span class=\"\
          hljs-keyword\">return</span> incompatible_keys\n</code></pre>\n"
        raw: "If you cannot downgrade to a lower transformer version and need a quick\
          \ fix, try this:\nin `site-packages/open_clip/factory.py`fix the load_checkpoint\
          \ function by deleting the unexpected key from the checkpoint:\n```py\n\
          def load_checkpoint(model, checkpoint_path, strict=True):\n    state_dict\
          \ = load_state_dict(checkpoint_path)\n    # detect old format and make compatible\
          \ with new format\n    if 'positional_embedding' in state_dict and not hasattr(model,\
          \ 'positional_embedding'):\n        state_dict = convert_to_custom_text_state_dict(state_dict)\n\
          \    resize_pos_embed(state_dict, model)\n    del state_dict[\"text.transformer.embeddings.position_ids\"\
          ] # <----- This line is new\n    incompatible_keys = model.load_state_dict(state_dict,\
          \ strict=strict)\n    return incompatible_keys\n```"
        updatedAt: '2023-08-16T08:01:31.537Z'
      numEdits: 0
      reactions: []
    id: 64dc825be1e953158d69d398
    type: comment
  author: KreitnerL
  content: "If you cannot downgrade to a lower transformer version and need a quick\
    \ fix, try this:\nin `site-packages/open_clip/factory.py`fix the load_checkpoint\
    \ function by deleting the unexpected key from the checkpoint:\n```py\ndef load_checkpoint(model,\
    \ checkpoint_path, strict=True):\n    state_dict = load_state_dict(checkpoint_path)\n\
    \    # detect old format and make compatible with new format\n    if 'positional_embedding'\
    \ in state_dict and not hasattr(model, 'positional_embedding'):\n        state_dict\
    \ = convert_to_custom_text_state_dict(state_dict)\n    resize_pos_embed(state_dict,\
    \ model)\n    del state_dict[\"text.transformer.embeddings.position_ids\"] # <-----\
    \ This line is new\n    incompatible_keys = model.load_state_dict(state_dict,\
    \ strict=strict)\n    return incompatible_keys\n```"
  created_at: 2023-08-16 07:01:31+00:00
  edited: false
  hidden: false
  id: 64dc825be1e953158d69d398
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1596208460315-noauth.jpeg?w=200&h=200&f=face
      fullname: Naoto Usuyama
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: naotous
      type: user
    createdAt: '2023-08-28T19:32:23.000Z'
    data:
      edited: false
      editors:
      - naotous
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6906167268753052
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1596208460315-noauth.jpeg?w=200&h=200&f=face
          fullname: Naoto Usuyama
          isHf: false
          isPro: false
          name: naotous
          type: user
        html: '<p>Hope this PR fixes this issue!</p>

          <p><a rel="nofollow" href="https://github.com/mlfoundations/open_clip/pull/595">https://github.com/mlfoundations/open_clip/pull/595</a></p>

          '
        raw: 'Hope this PR fixes this issue!


          https://github.com/mlfoundations/open_clip/pull/595'
        updatedAt: '2023-08-28T19:32:23.421Z'
      numEdits: 0
      reactions: []
    id: 64ecf6478a351f5b73934fcc
    type: comment
  author: naotous
  content: 'Hope this PR fixes this issue!


    https://github.com/mlfoundations/open_clip/pull/595'
  created_at: 2023-08-28 18:32:23+00:00
  edited: false
  hidden: false
  id: 64ecf6478a351f5b73934fcc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7ec3ecb0a51d84f9fea1a146b5dacdaf.svg
      fullname: Meilu Zhu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lobsterzml
      type: user
    createdAt: '2023-09-20T13:09:44.000Z'
    data:
      edited: false
      editors:
      - lobsterzml
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6377145648002625
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7ec3ecb0a51d84f9fea1a146b5dacdaf.svg
          fullname: Meilu Zhu
          isHf: false
          isPro: false
          name: lobsterzml
          type: user
        html: "<blockquote>\n<p>If you cannot downgrade to a lower transformer version\
          \ and need a quick fix, try this:<br>in <code>site-packages/open_clip/factory.py</code>fix\
          \ the load_checkpoint function by deleting the unexpected key from the checkpoint:</p>\n\
          <pre><code class=\"language-py\"><span class=\"hljs-keyword\">def</span>\
          \ <span class=\"hljs-title function_\">load_checkpoint</span>(<span class=\"\
          hljs-params\">model, checkpoint_path, strict=<span class=\"hljs-literal\"\
          >True</span></span>):\n    state_dict = load_state_dict(checkpoint_path)\n\
          \    <span class=\"hljs-comment\"># detect old format and make compatible\
          \ with new format</span>\n    <span class=\"hljs-keyword\">if</span> <span\
          \ class=\"hljs-string\">'positional_embedding'</span> <span class=\"hljs-keyword\"\
          >in</span> state_dict <span class=\"hljs-keyword\">and</span> <span class=\"\
          hljs-keyword\">not</span> <span class=\"hljs-built_in\">hasattr</span>(model,\
          \ <span class=\"hljs-string\">'positional_embedding'</span>):\n        state_dict\
          \ = convert_to_custom_text_state_dict(state_dict)\n    resize_pos_embed(state_dict,\
          \ model)\n    <span class=\"hljs-keyword\">del</span> state_dict[<span class=\"\
          hljs-string\">\"text.transformer.embeddings.position_ids\"</span>] <span\
          \ class=\"hljs-comment\"># &lt;----- This line is new</span>\n    incompatible_keys\
          \ = model.load_state_dict(state_dict, strict=strict)\n    <span class=\"\
          hljs-keyword\">return</span> incompatible_keys\n</code></pre>\n</blockquote>\n\
          <p>After modifying the part, I still met the same error. How to solve it?</p>\n"
        raw: '> If you cannot downgrade to a lower transformer version and need a
          quick fix, try this:

          > in `site-packages/open_clip/factory.py`fix the load_checkpoint function
          by deleting the unexpected key from the checkpoint:

          > ```py

          > def load_checkpoint(model, checkpoint_path, strict=True):

          >     state_dict = load_state_dict(checkpoint_path)

          >     # detect old format and make compatible with new format

          >     if ''positional_embedding'' in state_dict and not hasattr(model, ''positional_embedding''):

          >         state_dict = convert_to_custom_text_state_dict(state_dict)

          >     resize_pos_embed(state_dict, model)

          >     del state_dict["text.transformer.embeddings.position_ids"] # <-----
          This line is new

          >     incompatible_keys = model.load_state_dict(state_dict, strict=strict)

          >     return incompatible_keys

          > ```


          After modifying the part, I still met the same error. How to solve it?'
        updatedAt: '2023-09-20T13:09:44.669Z'
      numEdits: 0
      reactions: []
    id: 650aef1824cda11346af2419
    type: comment
  author: lobsterzml
  content: '> If you cannot downgrade to a lower transformer version and need a quick
    fix, try this:

    > in `site-packages/open_clip/factory.py`fix the load_checkpoint function by deleting
    the unexpected key from the checkpoint:

    > ```py

    > def load_checkpoint(model, checkpoint_path, strict=True):

    >     state_dict = load_state_dict(checkpoint_path)

    >     # detect old format and make compatible with new format

    >     if ''positional_embedding'' in state_dict and not hasattr(model, ''positional_embedding''):

    >         state_dict = convert_to_custom_text_state_dict(state_dict)

    >     resize_pos_embed(state_dict, model)

    >     del state_dict["text.transformer.embeddings.position_ids"] # <----- This
    line is new

    >     incompatible_keys = model.load_state_dict(state_dict, strict=strict)

    >     return incompatible_keys

    > ```


    After modifying the part, I still met the same error. How to solve it?'
  created_at: 2023-09-20 12:09:44+00:00
  edited: false
  hidden: false
  id: 650aef1824cda11346af2419
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3ca569596f9c7134e8d4b560a06ee1e7.svg
      fullname: Sheng Zhang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: shengz
      type: user
    createdAt: '2023-11-24T18:16:42.000Z'
    data:
      edited: false
      editors:
      - shengz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5678611993789673
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3ca569596f9c7134e8d4b560a06ee1e7.svg
          fullname: Sheng Zhang
          isHf: false
          isPro: false
          name: shengz
          type: user
        html: '<p>This was fixed. Please check out the latest ipynb: <a href="https://huggingface.co/microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blob/main/biomed_clip_example.ipynb">https://huggingface.co/microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blob/main/biomed_clip_example.ipynb</a></p>

          '
        raw: 'This was fixed. Please check out the latest ipynb: https://huggingface.co/microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blob/main/biomed_clip_example.ipynb'
        updatedAt: '2023-11-24T18:16:42.153Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6560e88aa72f05d2ea6a344a
    id: 6560e88aa72f05d2ea6a3445
    type: comment
  author: shengz
  content: 'This was fixed. Please check out the latest ipynb: https://huggingface.co/microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blob/main/biomed_clip_example.ipynb'
  created_at: 2023-11-24 18:16:42+00:00
  edited: false
  hidden: false
  id: 6560e88aa72f05d2ea6a3445
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3ca569596f9c7134e8d4b560a06ee1e7.svg
      fullname: Sheng Zhang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: shengz
      type: user
    createdAt: '2023-11-24T18:16:42.000Z'
    data:
      status: closed
    id: 6560e88aa72f05d2ea6a344a
    type: status-change
  author: shengz
  created_at: 2023-11-24 18:16:42+00:00
  id: 6560e88aa72f05d2ea6a344a
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224
repo_type: model
status: closed
target_branch: null
title: 'RuntimeError: Error(s) in loading state_dict for CustomTextCLIP:         Unexpected
  key(s) in state_dict: "text.transformer.embeddings.position_ids". '
