!!python/object:huggingface_hub.community.DiscussionWithDetails
author: liyxmse
conflicting_files: null
created_at: 2023-04-27 13:48:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/48e7db4a4bba1bab021fc8572dc80d60.svg
      fullname: liyx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: liyxmse
      type: user
    createdAt: '2023-04-27T14:48:19.000Z'
    data:
      edited: false
      editors:
      - liyxmse
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/48e7db4a4bba1bab021fc8572dc80d60.svg
          fullname: liyx
          isHf: false
          isPro: false
          name: liyxmse
          type: user
        html: "<p>Hi, I have deployed the model to sagemaker with the following code,\
          \ b</p>\n<pre><code class=\"language-Python\"><span class=\"hljs-keyword\"\
          >from</span> sagemaker.huggingface <span class=\"hljs-keyword\">import</span>\
          \ HuggingFaceModel\n<span class=\"hljs-keyword\">import</span> sagemaker\n\
          \nrole = sagemaker.get_execution_role()\n<span class=\"hljs-comment\">#\
          \ Hub Model configuration. https://huggingface.co/models</span>\nhub = {\n\
          \    <span class=\"hljs-string\">'HF_MODEL_ID'</span>:<span class=\"hljs-string\"\
          >'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli'</span>,\n    <span class=\"hljs-string\"\
          >'HF_TASK'</span>:<span class=\"hljs-string\">'zero-shot-classification'</span>\n\
          }\n\n<span class=\"hljs-comment\"># create Hugging Face Model Class</span>\n\
          huggingface_model = HuggingFaceModel(\n    transformers_version=<span class=\"\
          hljs-string\">'4.17.0'</span>,\n    pytorch_version=<span class=\"hljs-string\"\
          >'1.10.2'</span>,\n    py_version=<span class=\"hljs-string\">'py38'</span>,\n\
          \    env=hub,\n    role=role, \n)\n\n<span class=\"hljs-comment\"># deploy\
          \ model to SageMaker Inference</span>\npredictor = huggingface_model.deploy(\n\
          \    initial_instance_count=<span class=\"hljs-number\">1</span>, <span\
          \ class=\"hljs-comment\"># number of instances</span>\n    instance_type=<span\
          \ class=\"hljs-string\">'ml.m5.xlarge'</span> <span class=\"hljs-comment\"\
          ># ec2 instance type</span>\n)\n\npredictor.predict({\n    <span class=\"\
          hljs-string\">'inputs'</span>: <span class=\"hljs-string\">\"Hi, I recently\
          \ bought a device from your company but it is not working as advertised\
          \ and I would like to get reimbursed!\"</span>\n})\n</code></pre>\n<p>But\
          \ the sample code to invoke the predictor seems to be broken since the candidate_labels\
          \ are not included. I have tried several methods but without sucess.<br>Is\
          \ it possible to give some sample code in the following way?</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">from</span> sagemaker.huggingface.model\
          \ <span class=\"hljs-keyword\">import</span> HuggingFacePredictor\n\npredictor\
          \ = HuggingFacePredictor(endpoint_name=<span class=\"hljs-string\">\"huggingface-pytorch-inference-2023-04-26-09-23-40-125\"\
          </span>)\nresult = predictor.predict({\n    <span class=\"hljs-string\"\
          >'inputs'</span>: <span class=\"hljs-string\">\"\"</span>\n})\n\n<span class=\"\
          hljs-built_in\">print</span>(result)\n</code></pre>\n"
        raw: "Hi, I have deployed the model to sagemaker with the following code,\
          \ b\r\n\r\n```Python\r\nfrom sagemaker.huggingface import HuggingFaceModel\r\
          \nimport sagemaker\r\n\r\nrole = sagemaker.get_execution_role()\r\n# Hub\
          \ Model configuration. https://huggingface.co/models\r\nhub = {\r\n\t'HF_MODEL_ID':'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli',\r\
          \n\t'HF_TASK':'zero-shot-classification'\r\n}\r\n\r\n# create Hugging Face\
          \ Model Class\r\nhuggingface_model = HuggingFaceModel(\r\n\ttransformers_version='4.17.0',\r\
          \n\tpytorch_version='1.10.2',\r\n\tpy_version='py38',\r\n\tenv=hub,\r\n\t\
          role=role, \r\n)\r\n\r\n# deploy model to SageMaker Inference\r\npredictor\
          \ = huggingface_model.deploy(\r\n\tinitial_instance_count=1, # number of\
          \ instances\r\n\tinstance_type='ml.m5.xlarge' # ec2 instance type\r\n)\r\
          \n\r\npredictor.predict({\r\n\t'inputs': \"Hi, I recently bought a device\
          \ from your company but it is not working as advertised and I would like\
          \ to get reimbursed!\"\r\n})\r\n```\r\n\r\nBut the sample code to invoke\
          \ the predictor seems to be broken since the candidate_labels are not included.\
          \ I have tried several methods but without sucess.\r\nIs it possible to\
          \ give some sample code in the following way?\r\n\r\n```python\r\nfrom sagemaker.huggingface.model\
          \ import HuggingFacePredictor\r\n\r\npredictor = HuggingFacePredictor(endpoint_name=\"\
          huggingface-pytorch-inference-2023-04-26-09-23-40-125\")\r\nresult = predictor.predict({\r\
          \n    'inputs': \"\"\r\n})\r\n\r\nprint(result)\r\n``` "
        updatedAt: '2023-04-27T14:48:19.739Z'
      numEdits: 0
      reactions: []
    id: 644a8b33ccc39135fb30c71b
    type: comment
  author: liyxmse
  content: "Hi, I have deployed the model to sagemaker with the following code, b\r\
    \n\r\n```Python\r\nfrom sagemaker.huggingface import HuggingFaceModel\r\nimport\
    \ sagemaker\r\n\r\nrole = sagemaker.get_execution_role()\r\n# Hub Model configuration.\
    \ https://huggingface.co/models\r\nhub = {\r\n\t'HF_MODEL_ID':'MoritzLaurer/mDeBERTa-v3-base-mnli-xnli',\r\
    \n\t'HF_TASK':'zero-shot-classification'\r\n}\r\n\r\n# create Hugging Face Model\
    \ Class\r\nhuggingface_model = HuggingFaceModel(\r\n\ttransformers_version='4.17.0',\r\
    \n\tpytorch_version='1.10.2',\r\n\tpy_version='py38',\r\n\tenv=hub,\r\n\trole=role,\
    \ \r\n)\r\n\r\n# deploy model to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\
    \n\tinitial_instance_count=1, # number of instances\r\n\tinstance_type='ml.m5.xlarge'\
    \ # ec2 instance type\r\n)\r\n\r\npredictor.predict({\r\n\t'inputs': \"Hi, I recently\
    \ bought a device from your company but it is not working as advertised and I\
    \ would like to get reimbursed!\"\r\n})\r\n```\r\n\r\nBut the sample code to invoke\
    \ the predictor seems to be broken since the candidate_labels are not included.\
    \ I have tried several methods but without sucess.\r\nIs it possible to give some\
    \ sample code in the following way?\r\n\r\n```python\r\nfrom sagemaker.huggingface.model\
    \ import HuggingFacePredictor\r\n\r\npredictor = HuggingFacePredictor(endpoint_name=\"\
    huggingface-pytorch-inference-2023-04-26-09-23-40-125\")\r\nresult = predictor.predict({\r\
    \n    'inputs': \"\"\r\n})\r\n\r\nprint(result)\r\n``` "
  created_at: 2023-04-27 13:48:19+00:00
  edited: false
  hidden: false
  id: 644a8b33ccc39135fb30c71b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/48e7db4a4bba1bab021fc8572dc80d60.svg
      fullname: liyx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: liyxmse
      type: user
    createdAt: '2023-05-06T03:26:33.000Z'
    data:
      edited: false
      editors:
      - liyxmse
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/48e7db4a4bba1bab021fc8572dc80d60.svg
          fullname: liyx
          isHf: false
          isPro: false
          name: liyxmse
          type: user
        html: "<p>I figured it out, it can be invoked in two ways</p>\n<h2 id=\"hf\"\
          >HF</h2>\n<pre><code class=\"language-Python\"><span class=\"hljs-keyword\"\
          >import</span> json\n<span class=\"hljs-keyword\">from</span> sagemaker.huggingface.model\
          \ <span class=\"hljs-keyword\">import</span> HuggingFacePredictor\n\npredictor\
          \ = HuggingFacePredictor(endpoint_name=<span class=\"hljs-string\">\"mDeBERTa-v3-base-mnli-xnli-arbric-zeor-shot\"\
          </span>)\n\npayload = <span class=\"hljs-string\">\"\"\"</span>\n<span class=\"\
          hljs-string\">{</span>\n<span class=\"hljs-string\">  \"inputs\": \"Applying\
          \ artificial intelligence to the world of finance is all the rage, and a\
          \ new investing platform just took it to another level.Magnifi is one of\
          \ the first investing platforms that uses ChatGPT and computer programs\
          \ to provide personalized, data-driven investment advice. Not only does\
          \ It answer investor questions in human-like conversations, it also monitors\
          \ individual portfolios, guiding users through market-moving events like\
          \ rate hikes and earnings reports. And there\u2019s a bonus \u2014 it performs\
          \ like a brokerage where you can directly trade stocks and ETFs.\",</span>\n\
          <span class=\"hljs-string\">  \"parameters\": {</span>\n<span class=\"hljs-string\"\
          >    \"candidate_labels\": \"IT, AI, finance\",</span>\n<span class=\"hljs-string\"\
          >    \"multi_class\": false</span>\n<span class=\"hljs-string\">  }</span>\n\
          <span class=\"hljs-string\">}</span>\n<span class=\"hljs-string\">\"\"\"\
          </span>\n\nresult = predictor.predict(json.loads(payload))\n\n<span class=\"\
          hljs-built_in\">print</span>(result)\n</code></pre>\n<h2 id=\"boto3\">Boto3</h2>\n\
          <pre><code class=\"language-Python\"><span class=\"hljs-keyword\">import</span>\
          \ boto3\n<span class=\"hljs-keyword\">import</span> json\n\nclient = boto3.client(<span\
          \ class=\"hljs-string\">'sagemaker-runtime'</span>)\n\nendpoint_name = <span\
          \ class=\"hljs-string\">\"mDeBERTa-v3-base-mnli-xnli-arbric-zeor-shot\"\
          </span>                                       <span class=\"hljs-comment\"\
          ># Your endpoint name.</span>\ncontent_type = <span class=\"hljs-string\"\
          >\"application/json\"</span>                                        <span\
          \ class=\"hljs-comment\"># The MIME type of the input data in the request\
          \ body.</span>\naccept = <span class=\"hljs-string\">\"application/json\"\
          </span>                                              <span class=\"hljs-comment\"\
          ># The desired MIME type of the inference in the response.</span>\npayload\
          \ = <span class=\"hljs-string\">\"\"\"</span>\n<span class=\"hljs-string\"\
          >{</span>\n<span class=\"hljs-string\">  \"inputs\": \"The long text to\
          \ test\",</span>\n<span class=\"hljs-string\">  \"parameters\": {</span>\n\
          <span class=\"hljs-string\">    \"candidate_labels\": \"label1, label2,\
          \ label3\",</span>\n<span class=\"hljs-string\">    \"multi_class\":  false</span>\n\
          <span class=\"hljs-string\">  }</span>\n<span class=\"hljs-string\">}</span>\n\
          <span class=\"hljs-string\">\"\"\"</span>                              \
          \            <span class=\"hljs-comment\"># Payload for inference.</span>\n\
          response = client.invoke_endpoint(\n    EndpointName=endpoint_name, \n \
          \   CustomAttributes=custom_attributes, \n    ContentType=content_type,\n\
          \    Accept=accept,\n    Body=<span class=\"hljs-built_in\">bytes</span>(payload,\
          \ <span class=\"hljs-string\">'UTF-8'</span>)\n    )\n\nresult = json.loads(response[<span\
          \ class=\"hljs-string\">'Body'</span>].read().decode(<span class=\"hljs-string\"\
          >'UTF-8'</span>))\n\n<span class=\"hljs-built_in\">print</span>(result)\n\
          </code></pre>\n"
        raw: "I figured it out, it can be invoked in two ways\n\n## HF\n```Python\n\
          import json\nfrom sagemaker.huggingface.model import HuggingFacePredictor\n\
          \npredictor = HuggingFacePredictor(endpoint_name=\"mDeBERTa-v3-base-mnli-xnli-arbric-zeor-shot\"\
          )\n\npayload = \"\"\"\n{\n  \"inputs\": \"Applying artificial intelligence\
          \ to the world of finance is all the rage, and a new investing platform\
          \ just took it to another level.Magnifi is one of the first investing platforms\
          \ that uses ChatGPT and computer programs to provide personalized, data-driven\
          \ investment advice. Not only does It answer investor questions in human-like\
          \ conversations, it also monitors individual portfolios, guiding users through\
          \ market-moving events like rate hikes and earnings reports. And there\u2019\
          s a bonus \u2014 it performs like a brokerage where you can directly trade\
          \ stocks and ETFs.\",\n  \"parameters\": {\n    \"candidate_labels\": \"\
          IT, AI, finance\",\n    \"multi_class\": false\n  }\n}\n\"\"\"\n\nresult\
          \ = predictor.predict(json.loads(payload))\n\nprint(result)\n```\n\n## Boto3\n\
          ```Python\nimport boto3\nimport json\n\nclient = boto3.client('sagemaker-runtime')\n\
          \nendpoint_name = \"mDeBERTa-v3-base-mnli-xnli-arbric-zeor-shot\"      \
          \                                 # Your endpoint name.\ncontent_type =\
          \ \"application/json\"                                        # The MIME\
          \ type of the input data in the request body.\naccept = \"application/json\"\
          \                                              # The desired MIME type of\
          \ the inference in the response.\npayload = \"\"\"\n{\n  \"inputs\": \"\
          The long text to test\",\n  \"parameters\": {\n    \"candidate_labels\"\
          : \"label1, label2, label3\",\n    \"multi_class\":  false\n  }\n}\n\"\"\
          \"                                          # Payload for inference.\nresponse\
          \ = client.invoke_endpoint(\n    EndpointName=endpoint_name, \n    CustomAttributes=custom_attributes,\
          \ \n    ContentType=content_type,\n    Accept=accept,\n    Body=bytes(payload,\
          \ 'UTF-8')\n    )\n\nresult = json.loads(response['Body'].read().decode('UTF-8'))\n\
          \nprint(result)\n```\n"
        updatedAt: '2023-05-06T03:26:33.232Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MoritzLaurer
      relatedEventId: 6455c8e9bcfbcbd469beebb1
    id: 6455c8e9bcfbcbd469beebb0
    type: comment
  author: liyxmse
  content: "I figured it out, it can be invoked in two ways\n\n## HF\n```Python\n\
    import json\nfrom sagemaker.huggingface.model import HuggingFacePredictor\n\n\
    predictor = HuggingFacePredictor(endpoint_name=\"mDeBERTa-v3-base-mnli-xnli-arbric-zeor-shot\"\
    )\n\npayload = \"\"\"\n{\n  \"inputs\": \"Applying artificial intelligence to\
    \ the world of finance is all the rage, and a new investing platform just took\
    \ it to another level.Magnifi is one of the first investing platforms that uses\
    \ ChatGPT and computer programs to provide personalized, data-driven investment\
    \ advice. Not only does It answer investor questions in human-like conversations,\
    \ it also monitors individual portfolios, guiding users through market-moving\
    \ events like rate hikes and earnings reports. And there\u2019s a bonus \u2014\
    \ it performs like a brokerage where you can directly trade stocks and ETFs.\"\
    ,\n  \"parameters\": {\n    \"candidate_labels\": \"IT, AI, finance\",\n    \"\
    multi_class\": false\n  }\n}\n\"\"\"\n\nresult = predictor.predict(json.loads(payload))\n\
    \nprint(result)\n```\n\n## Boto3\n```Python\nimport boto3\nimport json\n\nclient\
    \ = boto3.client('sagemaker-runtime')\n\nendpoint_name = \"mDeBERTa-v3-base-mnli-xnli-arbric-zeor-shot\"\
    \                                       # Your endpoint name.\ncontent_type =\
    \ \"application/json\"                                        # The MIME type\
    \ of the input data in the request body.\naccept = \"application/json\"      \
    \                                        # The desired MIME type of the inference\
    \ in the response.\npayload = \"\"\"\n{\n  \"inputs\": \"The long text to test\"\
    ,\n  \"parameters\": {\n    \"candidate_labels\": \"label1, label2, label3\",\n\
    \    \"multi_class\":  false\n  }\n}\n\"\"\"                                 \
    \         # Payload for inference.\nresponse = client.invoke_endpoint(\n    EndpointName=endpoint_name,\
    \ \n    CustomAttributes=custom_attributes, \n    ContentType=content_type,\n\
    \    Accept=accept,\n    Body=bytes(payload, 'UTF-8')\n    )\n\nresult = json.loads(response['Body'].read().decode('UTF-8'))\n\
    \nprint(result)\n```\n"
  created_at: 2023-05-06 02:26:33+00:00
  edited: false
  hidden: false
  id: 6455c8e9bcfbcbd469beebb0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/48e7db4a4bba1bab021fc8572dc80d60.svg
      fullname: liyx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: liyxmse
      type: user
    createdAt: '2023-05-06T03:26:33.000Z'
    data:
      status: closed
    id: 6455c8e9bcfbcbd469beebb1
    type: status-change
  author: liyxmse
  created_at: 2023-05-06 02:26:33+00:00
  id: 6455c8e9bcfbcbd469beebb1
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: MoritzLaurer/mDeBERTa-v3-base-mnli-xnli
repo_type: model
status: closed
target_branch: null
title: How to invoke the endpoint after deployed to Sagemaker
