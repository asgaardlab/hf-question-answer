!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dafen
conflicting_files: null
created_at: 2023-11-10 14:13:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5d3e8c861245d0e48324a4bcb7921158.svg
      fullname: fenjun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dafen
      type: user
    createdAt: '2023-11-10T14:13:56.000Z'
    data:
      edited: false
      editors:
      - dafen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.374104768037796
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5d3e8c861245d0e48324a4bcb7921158.svg
          fullname: fenjun
          isHf: false
          isPro: false
          name: dafen
          type: user
        html: "<p>import torch<br>from modelscope import AutoModelForCausalLM, AutoTokenizer,\
          \ snapshot_download<br>model_dir = snapshot_download(\"vivo-ai/BlueLM-7B-Chat-32K\"\
          , revision=\"v1.0.1\")<br>tokenizer = AutoTokenizer.from_pretrained(model_dir,\
          \ trust_remote_code=True, use_fast=False)<br>model = AutoModelForCausalLM.from_pretrained(model_dir,\
          \ device_map=\"cuda:3\", torch_dtype=torch.bfloat16, trust_remote_code=True)<br>model\
          \ = model.eval()<br>inputs = tokenizer(\"[|Human|]:\u4E09\u56FD\u6F14\u4E49\
          \u7684\u4F5C\u8005\u662F\u8C01\uFF1F[|AI|]:\", return_tensors=\"pt\")<br>inputs\
          \ = inputs.to(\"cuda:3\")<br>pred = model.generate(**inputs, max_new_tokens=64,\
          \ repetition_penalty=1.1)<br>print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))</p>\n\
          <p>\u62A5\u9519\uFF1A<br>File /opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py:114,\
          \ in Linear.forward(self, input)<br>    113 def forward(self, input: Tensor)\
          \ -&gt; Tensor:<br>--&gt; 114     return F.linear(input, self.weight, self.bias)</p>\n\
          <p>RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling\
          \ <code>cublasGemmEx( handle, opa, opb, m, n, k, &amp;falpha, a, CUDA_R_16BF,\
          \ lda, b, CUDA_R_16BF, ldb, &amp;fbeta, c, CUDA_R_16BF, ldc, CUDA_R_32F,\
          \ CUBLAS_GEMM_DFALT_TENSOR_OP)</code></p>\n<p>During handling of the above\
          \ exception, another exception occurred:</p>\n<p>GPU\u578B\u53F7 A100\uFF0C\
          \u6307\u5B9A\u7B2C4\u5F20\u5361\u52A0\u8F7D\u6A21\u578B\u8FD0\u884C\u4F1A\
          \u62A5\u9519\uFF01</p>\n"
        raw: "import torch\r\nfrom modelscope import AutoModelForCausalLM, AutoTokenizer,\
          \ snapshot_download\r\nmodel_dir = snapshot_download(\"vivo-ai/BlueLM-7B-Chat-32K\"\
          , revision=\"v1.0.1\")\r\ntokenizer = AutoTokenizer.from_pretrained(model_dir,\
          \ trust_remote_code=True, use_fast=False)\r\nmodel = AutoModelForCausalLM.from_pretrained(model_dir,\
          \ device_map=\"cuda:3\", torch_dtype=torch.bfloat16, trust_remote_code=True)\r\
          \nmodel = model.eval()\r\ninputs = tokenizer(\"[|Human|]:\u4E09\u56FD\u6F14\
          \u4E49\u7684\u4F5C\u8005\u662F\u8C01\uFF1F[|AI|]:\", return_tensors=\"pt\"\
          )\r\ninputs = inputs.to(\"cuda:3\")\r\npred = model.generate(**inputs, max_new_tokens=64,\
          \ repetition_penalty=1.1)\r\nprint(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))\r\
          \n\r\n\u62A5\u9519\uFF1A\r\nFile /opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py:114,\
          \ in Linear.forward(self, input)\r\n    113 def forward(self, input: Tensor)\
          \ -> Tensor:\r\n--> 114     return F.linear(input, self.weight, self.bias)\r\
          \n\r\nRuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling\
          \ `cublasGemmEx( handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16BF, lda,\
          \ b, CUDA_R_16BF, ldb, &fbeta, c, CUDA_R_16BF, ldc, CUDA_R_32F, CUBLAS_GEMM_DFALT_TENSOR_OP)`\r\
          \n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nGPU\u578B\u53F7 A100\uFF0C\u6307\u5B9A\u7B2C4\u5F20\u5361\u52A0\u8F7D\
          \u6A21\u578B\u8FD0\u884C\u4F1A\u62A5\u9519\uFF01"
        updatedAt: '2023-11-10T14:13:56.196Z'
      numEdits: 0
      reactions: []
    id: 654e3aa46d7667e51ab79a45
    type: comment
  author: dafen
  content: "import torch\r\nfrom modelscope import AutoModelForCausalLM, AutoTokenizer,\
    \ snapshot_download\r\nmodel_dir = snapshot_download(\"vivo-ai/BlueLM-7B-Chat-32K\"\
    , revision=\"v1.0.1\")\r\ntokenizer = AutoTokenizer.from_pretrained(model_dir,\
    \ trust_remote_code=True, use_fast=False)\r\nmodel = AutoModelForCausalLM.from_pretrained(model_dir,\
    \ device_map=\"cuda:3\", torch_dtype=torch.bfloat16, trust_remote_code=True)\r\
    \nmodel = model.eval()\r\ninputs = tokenizer(\"[|Human|]:\u4E09\u56FD\u6F14\u4E49\
    \u7684\u4F5C\u8005\u662F\u8C01\uFF1F[|AI|]:\", return_tensors=\"pt\")\r\ninputs\
    \ = inputs.to(\"cuda:3\")\r\npred = model.generate(**inputs, max_new_tokens=64,\
    \ repetition_penalty=1.1)\r\nprint(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))\r\
    \n\r\n\u62A5\u9519\uFF1A\r\nFile /opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py:114,\
    \ in Linear.forward(self, input)\r\n    113 def forward(self, input: Tensor) ->\
    \ Tensor:\r\n--> 114     return F.linear(input, self.weight, self.bias)\r\n\r\n\
    RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasGemmEx(\
    \ handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16BF, lda, b, CUDA_R_16BF, ldb,\
    \ &fbeta, c, CUDA_R_16BF, ldc, CUDA_R_32F, CUBLAS_GEMM_DFALT_TENSOR_OP)`\r\n\r\
    \nDuring handling of the above exception, another exception occurred:\r\n\r\n\
    GPU\u578B\u53F7 A100\uFF0C\u6307\u5B9A\u7B2C4\u5F20\u5361\u52A0\u8F7D\u6A21\u578B\
    \u8FD0\u884C\u4F1A\u62A5\u9519\uFF01"
  created_at: 2023-11-10 14:13:56+00:00
  edited: false
  hidden: false
  id: 654e3aa46d7667e51ab79a45
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5d3e8c861245d0e48324a4bcb7921158.svg
      fullname: fenjun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dafen
      type: user
    createdAt: '2023-11-10T14:33:08.000Z'
    data:
      edited: false
      editors:
      - dafen
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9972556233406067
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5d3e8c861245d0e48324a4bcb7921158.svg
          fullname: fenjun
          isHf: false
          isPro: false
          name: dafen
          type: user
        html: "<p>\u8865\u5145\u4E00\u4E0B\uFF0C\u8FD0\u884C\u65F6\u53D1\u73B0\u6A21\
          \u578B\u4E3B\u8981\u53C2\u6570\u52A0\u8F7D\u5230gpu3\u4E0A\u4E86\uFF0C\u4F46\
          \u662F\u4E0D\u77E5\u9053\u4E3A\u4EC0\u4E48\u8FD8\u6709\u5C0F\u90E8\u5206\
          \u5728gpu0\u4E0A\u4E5F\u5B58\u5728\u3002\u6CA1\u6709\u5B8C\u5168\u52A0\u8F7D\
          \u5230gpu3</p>\n"
        raw: "\u8865\u5145\u4E00\u4E0B\uFF0C\u8FD0\u884C\u65F6\u53D1\u73B0\u6A21\u578B\
          \u4E3B\u8981\u53C2\u6570\u52A0\u8F7D\u5230gpu3\u4E0A\u4E86\uFF0C\u4F46\u662F\
          \u4E0D\u77E5\u9053\u4E3A\u4EC0\u4E48\u8FD8\u6709\u5C0F\u90E8\u5206\u5728\
          gpu0\u4E0A\u4E5F\u5B58\u5728\u3002\u6CA1\u6709\u5B8C\u5168\u52A0\u8F7D\u5230\
          gpu3"
        updatedAt: '2023-11-10T14:33:08.952Z'
      numEdits: 0
      reactions: []
    id: 654e3f2412c9597b209e03ff
    type: comment
  author: dafen
  content: "\u8865\u5145\u4E00\u4E0B\uFF0C\u8FD0\u884C\u65F6\u53D1\u73B0\u6A21\u578B\
    \u4E3B\u8981\u53C2\u6570\u52A0\u8F7D\u5230gpu3\u4E0A\u4E86\uFF0C\u4F46\u662F\u4E0D\
    \u77E5\u9053\u4E3A\u4EC0\u4E48\u8FD8\u6709\u5C0F\u90E8\u5206\u5728gpu0\u4E0A\u4E5F\
    \u5B58\u5728\u3002\u6CA1\u6709\u5B8C\u5168\u52A0\u8F7D\u5230gpu3"
  created_at: 2023-11-10 14:33:08+00:00
  edited: false
  hidden: false
  id: 654e3f2412c9597b209e03ff
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4b4312d553a59ad5246b2b88c43847d9.svg
      fullname: LiHongbin
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: JoeyHeisenberg
      type: user
    createdAt: '2023-11-13T02:17:24.000Z'
    data:
      edited: false
      editors:
      - JoeyHeisenberg
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.8531373143196106
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4b4312d553a59ad5246b2b88c43847d9.svg
          fullname: LiHongbin
          isHf: false
          isPro: false
          name: JoeyHeisenberg
          type: user
        html: "<p>\u53EF\u4EE5\u7528CUDA_VISIBLE_DEVICES \u6307\u5B9A\u4E0B\u663E\u5361\
          \u8BD5\u8BD5</p>\n"
        raw: "\u53EF\u4EE5\u7528CUDA_VISIBLE_DEVICES \u6307\u5B9A\u4E0B\u663E\u5361\
          \u8BD5\u8BD5"
        updatedAt: '2023-11-13T02:17:24.623Z'
      numEdits: 0
      reactions: []
    id: 65518734b5ec9f9a076fb709
    type: comment
  author: JoeyHeisenberg
  content: "\u53EF\u4EE5\u7528CUDA_VISIBLE_DEVICES \u6307\u5B9A\u4E0B\u663E\u5361\u8BD5\
    \u8BD5"
  created_at: 2023-11-13 02:17:24+00:00
  edited: false
  hidden: false
  id: 65518734b5ec9f9a076fb709
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/5d3e8c861245d0e48324a4bcb7921158.svg
      fullname: fenjun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dafen
      type: user
    createdAt: '2023-11-13T06:39:26.000Z'
    data:
      edited: false
      editors:
      - dafen
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9998387098312378
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/5d3e8c861245d0e48324a4bcb7921158.svg
          fullname: fenjun
          isHf: false
          isPro: false
          name: dafen
          type: user
        html: "<p>\u8FD9\u79CD\u8BBE\u7F6E\u786E\u5B9E\u53EF\u4EE5\u4E86</p>\n"
        raw: "\u8FD9\u79CD\u8BBE\u7F6E\u786E\u5B9E\u53EF\u4EE5\u4E86"
        updatedAt: '2023-11-13T06:39:26.062Z'
      numEdits: 0
      reactions: []
    id: 6551c49e1ac896152b6e998d
    type: comment
  author: dafen
  content: "\u8FD9\u79CD\u8BBE\u7F6E\u786E\u5B9E\u53EF\u4EE5\u4E86"
  created_at: 2023-11-13 06:39:26+00:00
  edited: false
  hidden: false
  id: 6551c49e1ac896152b6e998d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/870724e20dc1c221fbe9c6656720ab9b.svg
      fullname: Pororo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jeffreygao
      type: user
    createdAt: '2023-11-23T11:29:01.000Z'
    data:
      status: closed
    id: 655f377d02567cbe4bc61569
    type: status-change
  author: jeffreygao
  created_at: 2023-11-23 11:29:01+00:00
  id: 655f377d02567cbe4bc61569
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: vivo-ai/BlueLM-7B-Base-32K
repo_type: model
status: closed
target_branch: null
title: "\u6307\u5B9AGPU\u540E\u4F1A\u62A5\u9519CUBLAS_STATUS_EXECUTION_FAILED"
