!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Tirthankar
conflicting_files: null
created_at: 2023-07-07 10:54:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7431631083795923af61c8765e19c190.svg
      fullname: Tirthankar Banerjee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tirthankar
      type: user
    createdAt: '2023-07-07T11:54:02.000Z'
    data:
      edited: false
      editors:
      - Tirthankar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.798362672328949
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7431631083795923af61c8765e19c190.svg
          fullname: Tirthankar Banerjee
          isHf: false
          isPro: false
          name: Tirthankar
          type: user
        html: "<p>I can successfully pre-train patrickvonplaten/wav2vec2-base-v2 with\
          \ a new language unlabeled wav corpus by following the steps  outlined in\
          \ <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-pretraining\"\
          >https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-pretraining</a>\
          \ on a single GPU A100.</p>\n<p>However, when I want to use it with patrickvonplaten/mms-300\
          \ or facebook/wav2vec2-xls-r-300m, it gives error at accelerator.backward(loss).\
          \ </p>\n<p>RuntimeError: handle_0 INTERNAL ASSERT FAILED at \"../c10/cuda/driver_api.cpp\"\
          :15, please report a bug to PyTorch.</p>\n<p>Any pointer to the resolution\
          \ of this would be great.\n </p>\n"
        raw: "I can successfully pre-train patrickvonplaten/wav2vec2-base-v2 with\
          \ a new language unlabeled wav corpus by following the steps  outlined in\
          \ https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-pretraining\
          \ on a single GPU A100.\r\n\r\nHowever, when I want to use it with patrickvonplaten/mms-300\
          \ or facebook/wav2vec2-xls-r-300m, it gives error at accelerator.backward(loss).\
          \ \r\n\r\nRuntimeError: handle_0 INTERNAL ASSERT FAILED at \"../c10/cuda/driver_api.cpp\"\
          :15, please report a bug to PyTorch.\r\n\r\nAny pointer to the resolution\
          \ of this would be great.\r\n "
        updatedAt: '2023-07-07T11:54:02.567Z'
      numEdits: 0
      reactions: []
    id: 64a7fcda0c56078383f6c6a0
    type: comment
  author: Tirthankar
  content: "I can successfully pre-train patrickvonplaten/wav2vec2-base-v2 with a\
    \ new language unlabeled wav corpus by following the steps  outlined in https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-pretraining\
    \ on a single GPU A100.\r\n\r\nHowever, when I want to use it with patrickvonplaten/mms-300\
    \ or facebook/wav2vec2-xls-r-300m, it gives error at accelerator.backward(loss).\
    \ \r\n\r\nRuntimeError: handle_0 INTERNAL ASSERT FAILED at \"../c10/cuda/driver_api.cpp\"\
    :15, please report a bug to PyTorch.\r\n\r\nAny pointer to the resolution of this\
    \ would be great.\r\n "
  created_at: 2023-07-07 10:54:02+00:00
  edited: false
  hidden: false
  id: 64a7fcda0c56078383f6c6a0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-07-10T14:48:12.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9410631656646729
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;Tirthankar&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Tirthankar\"\
          >@<span class=\"underline\">Tirthankar</span></a></span>\n\n\t</span></span>\
          \ - could you please provide a full stack trace and reproducible code snippet?\
          \ And also your current environment details, which can be obtained by copying\
          \ the output of the command:</p>\n<pre><code>transformers-cli env\n</code></pre>\n\
          <p>Although judging by the runtime error, it looks like it's a bug with\
          \ either the <code>accelerate</code> library and/or PyTorch, so IMO definitely\
          \ worth opening issues there already to get some direct help!</p>\n"
        raw: 'Hey @Tirthankar - could you please provide a full stack trace and reproducible
          code snippet? And also your current environment details, which can be obtained
          by copying the output of the command:

          ```

          transformers-cli env

          ```

          Although judging by the runtime error, it looks like it''s a bug with either
          the `accelerate` library and/or PyTorch, so IMO definitely worth opening
          issues there already to get some direct help!'
        updatedAt: '2023-07-10T14:48:12.672Z'
      numEdits: 0
      reactions: []
    id: 64ac1a2c497a4167a5b3939b
    type: comment
  author: sanchit-gandhi
  content: 'Hey @Tirthankar - could you please provide a full stack trace and reproducible
    code snippet? And also your current environment details, which can be obtained
    by copying the output of the command:

    ```

    transformers-cli env

    ```

    Although judging by the runtime error, it looks like it''s a bug with either the
    `accelerate` library and/or PyTorch, so IMO definitely worth opening issues there
    already to get some direct help!'
  created_at: 2023-07-10 13:48:12+00:00
  edited: false
  hidden: false
  id: 64ac1a2c497a4167a5b3939b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7431631083795923af61c8765e19c190.svg
      fullname: Tirthankar Banerjee
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Tirthankar
      type: user
    createdAt: '2023-07-11T06:05:17.000Z'
    data:
      edited: false
      editors:
      - Tirthankar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7828192114830017
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7431631083795923af61c8765e19c190.svg
          fullname: Tirthankar Banerjee
          isHf: false
          isPro: false
          name: Tirthankar
          type: user
        html: '<p>Hi Sanchit - Thanks for your reply. Here is the Jupyter Notebook
          cell-by-cell execution of the original wav2vec2_no_trainer.py modified as
          per the current requirements. Also the last part of the command: transformers-cli
          env is pasted below. This is on a A100 single GPU with 40GB memory. There
          was no problem for pre-training wav2vec2 but not so for mms-300m.</p>

          <ul>

          <li><code>transformers</code> version: 4.30.2</li>

          <li>Platform: Linux-4.15.0-189-generic-x86_64-with-glibc2.27</li>

          <li>Python version: 3.8.16</li>

          <li>Huggingface_hub version: 0.16.4</li>

          <li>Safetensors version: 0.3.1</li>

          <li>PyTorch version (GPU?): 2.1.0.dev20230523+cu117 (True)</li>

          <li>Tensorflow version (GPU?): 2.12.0 (True)</li>

          <li>Flax version (CPU?/GPU?/TPU?): not installed (NA)</li>

          <li>Jax version: not installed</li>

          <li>JaxLib version: not installed</li>

          <li>Using GPU in script?: </li>

          <li>Using distributed or parallel set-up in script?: </li>

          </ul>

          <p>The notebook:<br>The error was at accelerator.backward(loss) [see cell
          21]<br>There is an assertion error to interrupt the execution just before
          the above command in cell 20 just after the loss calculation.</p>

          <p><a rel="nofollow" href="https://github.com/Tirthankar-iiitb/mms_pretrain/blob/main/wav2vec2_no_trainer_kas.ipynb">https://github.com/Tirthankar-iiitb/mms_pretrain/blob/main/wav2vec2_no_trainer_kas.ipynb</a></p>

          <p>Hope these info helps to advise further.</p>

          <p>Thanks/Tirthankar.</p>

          '
        raw: 'Hi Sanchit - Thanks for your reply. Here is the Jupyter Notebook cell-by-cell
          execution of the original wav2vec2_no_trainer.py modified as per the current
          requirements. Also the last part of the command: transformers-cli env is
          pasted below. This is on a A100 single GPU with 40GB memory. There was no
          problem for pre-training wav2vec2 but not so for mms-300m.


          - `transformers` version: 4.30.2

          - Platform: Linux-4.15.0-189-generic-x86_64-with-glibc2.27

          - Python version: 3.8.16

          - Huggingface_hub version: 0.16.4

          - Safetensors version: 0.3.1

          - PyTorch version (GPU?): 2.1.0.dev20230523+cu117 (True)

          - Tensorflow version (GPU?): 2.12.0 (True)

          - Flax version (CPU?/GPU?/TPU?): not installed (NA)

          - Jax version: not installed

          - JaxLib version: not installed

          - Using GPU in script?: <fill in>

          - Using distributed or parallel set-up in script?: <fill in>


          The notebook:

          The error was at accelerator.backward(loss) [see cell 21]

          There is an assertion error to interrupt the execution just before the above
          command in cell 20 just after the loss calculation.


          https://github.com/Tirthankar-iiitb/mms_pretrain/blob/main/wav2vec2_no_trainer_kas.ipynb


          Hope these info helps to advise further.


          Thanks/Tirthankar.

          '
        updatedAt: '2023-07-11T06:05:17.068Z'
      numEdits: 0
      reactions: []
    id: 64acf11dd15440de82804fa3
    type: comment
  author: Tirthankar
  content: 'Hi Sanchit - Thanks for your reply. Here is the Jupyter Notebook cell-by-cell
    execution of the original wav2vec2_no_trainer.py modified as per the current requirements.
    Also the last part of the command: transformers-cli env is pasted below. This
    is on a A100 single GPU with 40GB memory. There was no problem for pre-training
    wav2vec2 but not so for mms-300m.


    - `transformers` version: 4.30.2

    - Platform: Linux-4.15.0-189-generic-x86_64-with-glibc2.27

    - Python version: 3.8.16

    - Huggingface_hub version: 0.16.4

    - Safetensors version: 0.3.1

    - PyTorch version (GPU?): 2.1.0.dev20230523+cu117 (True)

    - Tensorflow version (GPU?): 2.12.0 (True)

    - Flax version (CPU?/GPU?/TPU?): not installed (NA)

    - Jax version: not installed

    - JaxLib version: not installed

    - Using GPU in script?: <fill in>

    - Using distributed or parallel set-up in script?: <fill in>


    The notebook:

    The error was at accelerator.backward(loss) [see cell 21]

    There is an assertion error to interrupt the execution just before the above command
    in cell 20 just after the loss calculation.


    https://github.com/Tirthankar-iiitb/mms_pretrain/blob/main/wav2vec2_no_trainer_kas.ipynb


    Hope these info helps to advise further.


    Thanks/Tirthankar.

    '
  created_at: 2023-07-11 05:05:17+00:00
  edited: false
  hidden: false
  id: 64acf11dd15440de82804fa3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: facebook/mms-300m
repo_type: model
status: open
target_branch: null
title: Pre-training MMS-300M with a new language
