!!python/object:huggingface_hub.community.DiscussionWithDetails
author: EMaitre
conflicting_files: null
created_at: 2022-12-14 15:08:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7aff7630c21260fdf938566379e548c4.svg
      fullname: "Elliot Ma\xEEtre"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: EMaitre
      type: user
    createdAt: '2022-12-14T15:08:26.000Z'
    data:
      edited: false
      editors:
      - EMaitre
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7aff7630c21260fdf938566379e548c4.svg
          fullname: "Elliot Ma\xEEtre"
          isHf: false
          isPro: false
          name: EMaitre
          type: user
        html: "<p>Hi folks, </p>\n<p>I am currently working on a benchmark of mitosis\
          \ detection on medical images, so I am performing object detection. Currently,\
          \ I can train YOLOS and DETR on my data but I can't find a way to train\
          \ DeformableDETR. In particular, I am using the exact same code as the one\
          \ provided in the balloon example for DETR, with the few following modifications\
          \ : </p>\n<p>My feature extractor is initialized the following way : </p>\n\
          <p><code>feature_extractor = DeformableDetrImageProcessor.from_pretrained(\"\
          SenseTime/deformable-detr\")</code></p>\n<p>and my model : </p>\n<p><code>self.model\
          \ = DeformableDetrForObjectDetection.from_pretrained(\"SenseTime/deformable-detr\"\
          , num_labels=1, ignore_mismatched_sizes=True)</code></p>\n<p>I only have\
          \ 1 label so I guess it is not a problem, since it is working for the init\
          \ of DETR.</p>\n<p>Using this code, during the <code>Validation sanity check</code>,\
          \ I have the following error :</p>\n<pre><code>Traceback (most recent call\
          \ last):\n  File \"/home/elliot/apriorics/scripts/train/train_deformabledetr.py\"\
          , line 57, in &lt;module&gt;\n    trainer.fit(\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 740, in fit\n    self._call_and_handle_interrupt(\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 685, in _call_and_handle_interrupt\n    return trainer_fn(*args,\
          \ **kwargs)\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 777, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File\
          \ \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 1199, in _run\n    self._dispatch()\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 1279, in _dispatch\n    self.training_type_plugin.start_training(self)\n\
          \  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\"\
          , line 202, in start_training\n    self._results = trainer.run_stage()\n\
          \  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 1289, in run_stage\n    return self._run_train()\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 1311, in _run_train\n    self._run_sanity_check(self.lightning_module)\n\
          \  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 1375, in _run_sanity_check\n    self._evaluation_loop.run()\n  File\
          \ \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\"\
          , line 145, in run\n    self.advance(*args, **kwargs)\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\"\
          , line 110, in advance\n    dl_outputs = self.epoch_loop.run(dataloader,\
          \ dataloader_idx, dl_max_batches, self.num_dataloaders)\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\"\
          , line 145, in run\n    self.advance(*args, **kwargs)\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\"\
          , line 122, in advance\n    output = self._evaluation_step(batch, batch_idx,\
          \ dataloader_idx)\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\"\
          , line 217, in _evaluation_step\n    output = self.trainer.accelerator.validation_step(step_kwargs)\n\
          \  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\"\
          , line 239, in validation_step\n    return self.training_type_plugin.validation_step(*step_kwargs.values())\n\
          \  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\"\
          , line 219, in validation_step\n    return self.model.validation_step(*args,\
          \ **kwargs)\n  File \"/home/elliot/apriorics/apriorics/models.py\", line\
          \ 899, in validation_step\n    loss, loss_dict = self.common_step(batch,\
          \ batch_idx)\n  File \"/home/elliot/apriorics/apriorics/models.py\", line\
          \ 865, in common_step\n    outputs = self.model(pixel_values=pixel_values,\
          \ pixel_mask=pixel_mask, labels=labels)\n  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n\
          \  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py\"\
          , line 1980, in forward\n    loss_dict = criterion(outputs_loss, labels)\n\
          \  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n\
          \  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py\"\
          , line 2213, in forward\n    indices = self.matcher(outputs_without_aux,\
          \ targets)\n  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n\
          \  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\n    return func(*args, **kwargs)\n  File\
          \ \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py\"\
          , line 2341, in forward\n    class_cost = pos_cost_class[:, target_ids]\
          \ - neg_cost_class[:, target_ids]\nIndexError: index 1 is out of bounds\
          \ for dimension 0 with size 1\n</code></pre>\n<p>I guess I am using the\
          \ feature extractor wrongly, but I can't figure out why. I tried two different\
          \ ways to preprocess the data, but none is working : </p>\n<p><code>encoding\
          \ = self.feature_extractor.preprocess(images=img, annotations=target, return_tensors=\"\
          pt\")</code> </p>\n<p>and</p>\n<p><code>encoding = self.feature_extractor(images=img,\
          \ annotations=target, return_tensors=\"pt\")</code></p>\n<p>Any help would\
          \ be appreciated, I can also provide more information if needed.</p>\n<p>Elliot</p>\n"
        raw: "Hi folks, \r\n\r\nI am currently working on a benchmark of mitosis detection\
          \ on medical images, so I am performing object detection. Currently, I can\
          \ train YOLOS and DETR on my data but I can't find a way to train DeformableDETR.\
          \ In particular, I am using the exact same code as the one provided in the\
          \ balloon example for DETR, with the few following modifications : \r\n\r\
          \nMy feature extractor is initialized the following way : \r\n\r\n`feature_extractor\
          \ = DeformableDetrImageProcessor.from_pretrained(\"SenseTime/deformable-detr\"\
          )`\r\n\r\nand my model : \r\n\r\n`self.model = DeformableDetrForObjectDetection.from_pretrained(\"\
          SenseTime/deformable-detr\", num_labels=1, ignore_mismatched_sizes=True)`\r\
          \n\r\nI only have 1 label so I guess it is not a problem, since it is working\
          \ for the init of DETR.\r\n\r\nUsing this code, during the `Validation sanity\
          \ check`, I have the following error :\r\n\r\n```\r\nTraceback (most recent\
          \ call last):\r\n  File \"/home/elliot/apriorics/scripts/train/train_deformabledetr.py\"\
          , line 57, in <module>\r\n    trainer.fit(\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 740, in fit\r\n    self._call_and_handle_interrupt(\r\n  File \"\
          /data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 685, in _call_and_handle_interrupt\r\n    return trainer_fn(*args,\
          \ **kwargs)\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 777, in _fit_impl\r\n    self._run(model, ckpt_path=ckpt_path)\r\n\
          \  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 1199, in _run\r\n    self._dispatch()\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 1279, in _dispatch\r\n    self.training_type_plugin.start_training(self)\r\
          \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\"\
          , line 202, in start_training\r\n    self._results = trainer.run_stage()\r\
          \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 1289, in run_stage\r\n    return self._run_train()\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 1311, in _run_train\r\n    self._run_sanity_check(self.lightning_module)\r\
          \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
          , line 1375, in _run_sanity_check\r\n    self._evaluation_loop.run()\r\n\
          \  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\"\
          , line 145, in run\r\n    self.advance(*args, **kwargs)\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\"\
          , line 110, in advance\r\n    dl_outputs = self.epoch_loop.run(dataloader,\
          \ dataloader_idx, dl_max_batches, self.num_dataloaders)\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\"\
          , line 145, in run\r\n    self.advance(*args, **kwargs)\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\"\
          , line 122, in advance\r\n    output = self._evaluation_step(batch, batch_idx,\
          \ dataloader_idx)\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\"\
          , line 217, in _evaluation_step\r\n    output = self.trainer.accelerator.validation_step(step_kwargs)\r\
          \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\"\
          , line 239, in validation_step\r\n    return self.training_type_plugin.validation_step(*step_kwargs.values())\r\
          \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\"\
          , line 219, in validation_step\r\n    return self.model.validation_step(*args,\
          \ **kwargs)\r\n  File \"/home/elliot/apriorics/apriorics/models.py\", line\
          \ 899, in validation_step\r\n    loss, loss_dict = self.common_step(batch,\
          \ batch_idx)\r\n  File \"/home/elliot/apriorics/apriorics/models.py\", line\
          \ 865, in common_step\r\n    outputs = self.model(pixel_values=pixel_values,\
          \ pixel_mask=pixel_mask, labels=labels)\r\n  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py\"\
          , line 1980, in forward\r\n    loss_dict = criterion(outputs_loss, labels)\r\
          \n  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py\"\
          , line 2213, in forward\r\n    indices = self.matcher(outputs_without_aux,\
          \ targets)\r\n  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\
          \n  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/autograd/grad_mode.py\"\
          , line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n \
          \ File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py\"\
          , line 2341, in forward\r\n    class_cost = pos_cost_class[:, target_ids]\
          \ - neg_cost_class[:, target_ids]\r\nIndexError: index 1 is out of bounds\
          \ for dimension 0 with size 1\r\n```\r\n\r\n\r\nI guess I am using the feature\
          \ extractor wrongly, but I can't figure out why. I tried two different ways\
          \ to preprocess the data, but none is working : \r\n\r\n`encoding = self.feature_extractor.preprocess(images=img,\
          \ annotations=target, return_tensors=\"pt\")` \r\n\r\nand\r\n\r\n`encoding\
          \ = self.feature_extractor(images=img, annotations=target, return_tensors=\"\
          pt\")`\r\n\r\n\r\nAny help would be appreciated, I can also provide more\
          \ information if needed.\r\n\r\nElliot\r\n\r\n\r\n\r\n"
        updatedAt: '2022-12-14T15:08:26.089Z'
      numEdits: 0
      reactions: []
    id: 6399e6ead84dd5ddaacf2122
    type: comment
  author: EMaitre
  content: "Hi folks, \r\n\r\nI am currently working on a benchmark of mitosis detection\
    \ on medical images, so I am performing object detection. Currently, I can train\
    \ YOLOS and DETR on my data but I can't find a way to train DeformableDETR. In\
    \ particular, I am using the exact same code as the one provided in the balloon\
    \ example for DETR, with the few following modifications : \r\n\r\nMy feature\
    \ extractor is initialized the following way : \r\n\r\n`feature_extractor = DeformableDetrImageProcessor.from_pretrained(\"\
    SenseTime/deformable-detr\")`\r\n\r\nand my model : \r\n\r\n`self.model = DeformableDetrForObjectDetection.from_pretrained(\"\
    SenseTime/deformable-detr\", num_labels=1, ignore_mismatched_sizes=True)`\r\n\r\
    \nI only have 1 label so I guess it is not a problem, since it is working for\
    \ the init of DETR.\r\n\r\nUsing this code, during the `Validation sanity check`,\
    \ I have the following error :\r\n\r\n```\r\nTraceback (most recent call last):\r\
    \n  File \"/home/elliot/apriorics/scripts/train/train_deformabledetr.py\", line\
    \ 57, in <module>\r\n    trainer.fit(\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
    , line 740, in fit\r\n    self._call_and_handle_interrupt(\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
    , line 685, in _call_and_handle_interrupt\r\n    return trainer_fn(*args, **kwargs)\r\
    \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
    , line 777, in _fit_impl\r\n    self._run(model, ckpt_path=ckpt_path)\r\n  File\
    \ \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
    , line 1199, in _run\r\n    self._dispatch()\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
    , line 1279, in _dispatch\r\n    self.training_type_plugin.start_training(self)\r\
    \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\"\
    , line 202, in start_training\r\n    self._results = trainer.run_stage()\r\n \
    \ File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
    , line 1289, in run_stage\r\n    return self._run_train()\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
    , line 1311, in _run_train\r\n    self._run_sanity_check(self.lightning_module)\r\
    \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\"\
    , line 1375, in _run_sanity_check\r\n    self._evaluation_loop.run()\r\n  File\
    \ \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\"\
    , line 145, in run\r\n    self.advance(*args, **kwargs)\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\"\
    , line 110, in advance\r\n    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx,\
    \ dl_max_batches, self.num_dataloaders)\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\"\
    , line 145, in run\r\n    self.advance(*args, **kwargs)\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\"\
    , line 122, in advance\r\n    output = self._evaluation_step(batch, batch_idx,\
    \ dataloader_idx)\r\n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\"\
    , line 217, in _evaluation_step\r\n    output = self.trainer.accelerator.validation_step(step_kwargs)\r\
    \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\"\
    , line 239, in validation_step\r\n    return self.training_type_plugin.validation_step(*step_kwargs.values())\r\
    \n  File \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\"\
    , line 219, in validation_step\r\n    return self.model.validation_step(*args,\
    \ **kwargs)\r\n  File \"/home/elliot/apriorics/apriorics/models.py\", line 899,\
    \ in validation_step\r\n    loss, loss_dict = self.common_step(batch, batch_idx)\r\
    \n  File \"/home/elliot/apriorics/apriorics/models.py\", line 865, in common_step\r\
    \n    outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\r\
    \n  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py\"\
    , line 1980, in forward\r\n    loss_dict = criterion(outputs_loss, labels)\r\n\
    \  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py\"\
    , line 2213, in forward\r\n    indices = self.matcher(outputs_without_aux, targets)\r\
    \n  File \"/home/elliot/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File\
    \ \"/home/elliot/.local/lib/python3.9/site-packages/torch/autograd/grad_mode.py\"\
    , line 27, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"\
    /data/apps/conda/elliot/envs/transformers/lib/python3.9/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py\"\
    , line 2341, in forward\r\n    class_cost = pos_cost_class[:, target_ids] - neg_cost_class[:,\
    \ target_ids]\r\nIndexError: index 1 is out of bounds for dimension 0 with size\
    \ 1\r\n```\r\n\r\n\r\nI guess I am using the feature extractor wrongly, but I\
    \ can't figure out why. I tried two different ways to preprocess the data, but\
    \ none is working : \r\n\r\n`encoding = self.feature_extractor.preprocess(images=img,\
    \ annotations=target, return_tensors=\"pt\")` \r\n\r\nand\r\n\r\n`encoding = self.feature_extractor(images=img,\
    \ annotations=target, return_tensors=\"pt\")`\r\n\r\n\r\nAny help would be appreciated,\
    \ I can also provide more information if needed.\r\n\r\nElliot\r\n\r\n\r\n\r\n"
  created_at: 2022-12-14 15:08:26+00:00
  edited: false
  hidden: false
  id: 6399e6ead84dd5ddaacf2122
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2022-12-15T15:17:11.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Hi,</p>

          <p>Thanks for your interest in Deformable DETR! Could you print out the
          content of <code>encoding</code>? It might there''s something wrong with
          the class label IDs.</p>

          '
        raw: 'Hi,


          Thanks for your interest in Deformable DETR! Could you print out the content
          of `encoding`? It might there''s something wrong with the class label IDs.'
        updatedAt: '2022-12-15T15:17:11.405Z'
      numEdits: 0
      reactions: []
    id: 639b3a77e8c7ac902b7481d7
    type: comment
  author: nielsr
  content: 'Hi,


    Thanks for your interest in Deformable DETR! Could you print out the content of
    `encoding`? It might there''s something wrong with the class label IDs.'
  created_at: 2022-12-15 15:17:11+00:00
  edited: false
  hidden: false
  id: 639b3a77e8c7ac902b7481d7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7aff7630c21260fdf938566379e548c4.svg
      fullname: "Elliot Ma\xEEtre"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: EMaitre
      type: user
    createdAt: '2022-12-16T10:29:14.000Z'
    data:
      edited: true
      editors:
      - EMaitre
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7aff7630c21260fdf938566379e548c4.svg
          fullname: "Elliot Ma\xEEtre"
          isHf: false
          isPro: false
          name: EMaitre
          type: user
        html: "<p>It looks like that : </p>\n<pre><code>{'pixel_values': tensor([[[[1.1700,\
          \ 1.1700, 1.1700,  ..., 1.7523, 1.7694, 1.7694],\n          [1.1700, 1.1700,\
          \ 1.1700,  ..., 1.7523, 1.7694, 1.7694],\n          [1.2043, 1.2043, 1.2043,\
          \  ..., 1.7523, 1.7523, 1.7523],\n          ...,\n          [1.4440, 1.4440,\
          \ 1.4269,  ..., 1.5468, 1.5468, 1.5468],\n          [1.3755, 1.3755, 1.3584,\
          \  ..., 1.5639, 1.5810, 1.5810],\n          [1.3755, 1.3755, 1.3584,  ...,\
          \ 1.5639, 1.5810, 1.5810]],\n\n         [[0.7654, 0.7654, 0.7654,  ...,\
          \ 1.6232, 1.6408, 1.6408],\n          [0.7654, 0.7654, 0.7654,  ..., 1.6232,\
          \ 1.6408, 1.6408],\n          [0.8004, 0.8004, 0.8004,  ..., 1.6232, 1.6408,\
          \ 1.6408],\n          ...,\n          [1.1681, 1.1681, 1.1506,  ..., 1.0280,\
          \ 1.0280, 1.0280],\n          [1.0980, 1.0980, 1.0805,  ..., 1.0455, 1.0630,\
          \ 1.0630],\n          [1.0980, 1.0980, 1.0805,  ..., 1.0455, 1.0630, 1.0630]],\n\
          \n         [[1.1759, 1.1759, 1.1759,  ..., 2.0125, 2.0300, 2.0300],\n  \
          \        [1.1759, 1.1759, 1.1759,  ..., 2.0125, 2.0300, 2.0300],\n     \
          \     [1.2108, 1.2108, 1.2108,  ..., 2.0125, 2.0300, 2.0300],\n        \
          \  ...,\n          [1.7511, 1.7511, 1.7337,  ..., 1.2631, 1.2631, 1.2631],\n\
          \          [1.6814, 1.6814, 1.6640,  ..., 1.2805, 1.2980, 1.2980],\n   \
          \       [1.6814, 1.6814, 1.6640,  ..., 1.2805, 1.2980, 1.2980]]]]), 'pixel_mask':\
          \ tensor([[[1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n\
          \         [1, 1, 1,  ..., 1, 1, 1],\n         ...,\n         [1, 1, 1, \
          \ ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,\
          \  ..., 1, 1, 1]]]), 'labels': [{'size': tensor([800, 800]), 'image_id':\
          \ tensor([63]), 'class_labels': tensor([1]), 'boxes': tensor([[0.7051, 0.2578,\
          \ 0.0586, 0.0625]]), 'area': tensor([722.6562]), 'iscrowd': tensor([0]),\
          \ 'orig_size': tensor([256, 256])}]}\n</code></pre>\n<p>I think it looks\
          \ like it should ? I could see it for different images and it looked the\
          \ same.</p>\n<p>Thanks for your help</p>\n"
        raw: "It looks like that : \n\n```\n{'pixel_values': tensor([[[[1.1700, 1.1700,\
          \ 1.1700,  ..., 1.7523, 1.7694, 1.7694],\n          [1.1700, 1.1700, 1.1700,\
          \  ..., 1.7523, 1.7694, 1.7694],\n          [1.2043, 1.2043, 1.2043,  ...,\
          \ 1.7523, 1.7523, 1.7523],\n          ...,\n          [1.4440, 1.4440, 1.4269,\
          \  ..., 1.5468, 1.5468, 1.5468],\n          [1.3755, 1.3755, 1.3584,  ...,\
          \ 1.5639, 1.5810, 1.5810],\n          [1.3755, 1.3755, 1.3584,  ..., 1.5639,\
          \ 1.5810, 1.5810]],\n\n         [[0.7654, 0.7654, 0.7654,  ..., 1.6232,\
          \ 1.6408, 1.6408],\n          [0.7654, 0.7654, 0.7654,  ..., 1.6232, 1.6408,\
          \ 1.6408],\n          [0.8004, 0.8004, 0.8004,  ..., 1.6232, 1.6408, 1.6408],\n\
          \          ...,\n          [1.1681, 1.1681, 1.1506,  ..., 1.0280, 1.0280,\
          \ 1.0280],\n          [1.0980, 1.0980, 1.0805,  ..., 1.0455, 1.0630, 1.0630],\n\
          \          [1.0980, 1.0980, 1.0805,  ..., 1.0455, 1.0630, 1.0630]],\n\n\
          \         [[1.1759, 1.1759, 1.1759,  ..., 2.0125, 2.0300, 2.0300],\n   \
          \       [1.1759, 1.1759, 1.1759,  ..., 2.0125, 2.0300, 2.0300],\n      \
          \    [1.2108, 1.2108, 1.2108,  ..., 2.0125, 2.0300, 2.0300],\n         \
          \ ...,\n          [1.7511, 1.7511, 1.7337,  ..., 1.2631, 1.2631, 1.2631],\n\
          \          [1.6814, 1.6814, 1.6640,  ..., 1.2805, 1.2980, 1.2980],\n   \
          \       [1.6814, 1.6814, 1.6640,  ..., 1.2805, 1.2980, 1.2980]]]]), 'pixel_mask':\
          \ tensor([[[1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n\
          \         [1, 1, 1,  ..., 1, 1, 1],\n         ...,\n         [1, 1, 1, \
          \ ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,\
          \  ..., 1, 1, 1]]]), 'labels': [{'size': tensor([800, 800]), 'image_id':\
          \ tensor([63]), 'class_labels': tensor([1]), 'boxes': tensor([[0.7051, 0.2578,\
          \ 0.0586, 0.0625]]), 'area': tensor([722.6562]), 'iscrowd': tensor([0]),\
          \ 'orig_size': tensor([256, 256])}]}\n```\n\nI think it looks like it should\
          \ ? I could see it for different images and it looked the same.\n\nThanks\
          \ for your help"
        updatedAt: '2022-12-16T10:30:20.055Z'
      numEdits: 1
      reactions: []
    id: 639c487a1c597f893b68717b
    type: comment
  author: EMaitre
  content: "It looks like that : \n\n```\n{'pixel_values': tensor([[[[1.1700, 1.1700,\
    \ 1.1700,  ..., 1.7523, 1.7694, 1.7694],\n          [1.1700, 1.1700, 1.1700, \
    \ ..., 1.7523, 1.7694, 1.7694],\n          [1.2043, 1.2043, 1.2043,  ..., 1.7523,\
    \ 1.7523, 1.7523],\n          ...,\n          [1.4440, 1.4440, 1.4269,  ..., 1.5468,\
    \ 1.5468, 1.5468],\n          [1.3755, 1.3755, 1.3584,  ..., 1.5639, 1.5810, 1.5810],\n\
    \          [1.3755, 1.3755, 1.3584,  ..., 1.5639, 1.5810, 1.5810]],\n\n      \
    \   [[0.7654, 0.7654, 0.7654,  ..., 1.6232, 1.6408, 1.6408],\n          [0.7654,\
    \ 0.7654, 0.7654,  ..., 1.6232, 1.6408, 1.6408],\n          [0.8004, 0.8004, 0.8004,\
    \  ..., 1.6232, 1.6408, 1.6408],\n          ...,\n          [1.1681, 1.1681, 1.1506,\
    \  ..., 1.0280, 1.0280, 1.0280],\n          [1.0980, 1.0980, 1.0805,  ..., 1.0455,\
    \ 1.0630, 1.0630],\n          [1.0980, 1.0980, 1.0805,  ..., 1.0455, 1.0630, 1.0630]],\n\
    \n         [[1.1759, 1.1759, 1.1759,  ..., 2.0125, 2.0300, 2.0300],\n        \
    \  [1.1759, 1.1759, 1.1759,  ..., 2.0125, 2.0300, 2.0300],\n          [1.2108,\
    \ 1.2108, 1.2108,  ..., 2.0125, 2.0300, 2.0300],\n          ...,\n          [1.7511,\
    \ 1.7511, 1.7337,  ..., 1.2631, 1.2631, 1.2631],\n          [1.6814, 1.6814, 1.6640,\
    \  ..., 1.2805, 1.2980, 1.2980],\n          [1.6814, 1.6814, 1.6640,  ..., 1.2805,\
    \ 1.2980, 1.2980]]]]), 'pixel_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1],\n    \
    \     [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n        \
    \ ...,\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n\
    \         [1, 1, 1,  ..., 1, 1, 1]]]), 'labels': [{'size': tensor([800, 800]),\
    \ 'image_id': tensor([63]), 'class_labels': tensor([1]), 'boxes': tensor([[0.7051,\
    \ 0.2578, 0.0586, 0.0625]]), 'area': tensor([722.6562]), 'iscrowd': tensor([0]),\
    \ 'orig_size': tensor([256, 256])}]}\n```\n\nI think it looks like it should ?\
    \ I could see it for different images and it looked the same.\n\nThanks for your\
    \ help"
  created_at: 2022-12-16 10:29:14+00:00
  edited: true
  hidden: false
  id: 639c487a1c597f893b68717b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
      fullname: Niels Rogge
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nielsr
      type: user
    createdAt: '2022-12-16T10:49:16.000Z'
    data:
      edited: false
      editors:
      - nielsr
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg?w=200&h=200&f=face
          fullname: Niels Rogge
          isHf: true
          isPro: false
          name: nielsr
          type: user
        html: '<p>Hmm ok but the Deformable DETR tutorial is on the "balloon" dataset
          which also consists of only one class, right?</p>

          '
        raw: Hmm ok but the Deformable DETR tutorial is on the "balloon" dataset which
          also consists of only one class, right?
        updatedAt: '2022-12-16T10:49:16.933Z'
      numEdits: 0
      reactions: []
    id: 639c4d2c1c597f893b68e532
    type: comment
  author: nielsr
  content: Hmm ok but the Deformable DETR tutorial is on the "balloon" dataset which
    also consists of only one class, right?
  created_at: 2022-12-16 10:49:16+00:00
  edited: false
  hidden: false
  id: 639c4d2c1c597f893b68e532
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7aff7630c21260fdf938566379e548c4.svg
      fullname: "Elliot Ma\xEEtre"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: EMaitre
      type: user
    createdAt: '2022-12-16T15:59:54.000Z'
    data:
      edited: true
      editors:
      - EMaitre
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7aff7630c21260fdf938566379e548c4.svg
          fullname: "Elliot Ma\xEEtre"
          isHf: false
          isPro: false
          name: EMaitre
          type: user
        html: '<p>Hi,</p>

          <p>I tried with the balloon dataset (I thought I had done it but actually
          I didn''t). It worked, and I realized that the <code>class_label</code>
          is actually 0 and not 1 in the balloon dataset. I changed this value in
          my custom dataset, and now it is training. What I find weird is that I used
          the exact same dataset for DETR and YOLOS (<code>class label</code> starting
          at 1), and it worked.</p>

          <p>Thanks for your help and your work,<br>Elliot</p>

          '
        raw: 'Hi,


          I tried with the balloon dataset (I thought I had done it but actually I
          didn''t). It worked, and I realized that the `class_label` is actually 0
          and not 1 in the balloon dataset. I changed this value in my custom dataset,
          and now it is training. What I find weird is that I used the exact same
          dataset for DETR and YOLOS (`class label` starting at 1), and it worked.


          Thanks for your help and your work,

          Elliot'
        updatedAt: '2022-12-16T16:00:16.335Z'
      numEdits: 1
      reactions: []
    id: 639c95faa41c0ad6bafa76dd
    type: comment
  author: EMaitre
  content: 'Hi,


    I tried with the balloon dataset (I thought I had done it but actually I didn''t).
    It worked, and I realized that the `class_label` is actually 0 and not 1 in the
    balloon dataset. I changed this value in my custom dataset, and now it is training.
    What I find weird is that I used the exact same dataset for DETR and YOLOS (`class
    label` starting at 1), and it worked.


    Thanks for your help and your work,

    Elliot'
  created_at: 2022-12-16 15:59:54+00:00
  edited: true
  hidden: false
  id: 639c95faa41c0ad6bafa76dd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: SenseTime/deformable-detr
repo_type: model
status: open
target_branch: null
title: Unable to train this model
