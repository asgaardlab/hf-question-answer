!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hbhb
conflicting_files: null
created_at: 2022-09-26 03:43:47+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ea15766aeb5a3233c50d9ac9a7493bb9.svg
      fullname: hbkim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hbhb
      type: user
    createdAt: '2022-09-26T04:43:47.000Z'
    data:
      edited: false
      editors:
      - hbhb
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ea15766aeb5a3233c50d9ac9a7493bb9.svg
          fullname: hbkim
          isHf: false
          isPro: false
          name: hbhb
          type: user
        html: "<p>Hi, jhgan :)</p>\n<p>I'm doing a project about Korean Job name.<br>While\
          \ I test your model, I found a weird case.<br>This is here.<br>'''<br>Source\
          \ Sentence: \uB0B4 \uC9C1\uC5C5\uC740 \uD310\uC0AC\uC608\uC694.</p>\n<p>Sentences\
          \ to compare to:<br>\uD310\uC0AC 0.075<br>\uBC95\uBB34\uC0AC 0.498<br>\uAD50\
          \uB3C4\uAD00 0.380<br>\uBCC0\uD638\uC0AC 0.381<br>\uB85C\uD38C\uB300\uD45C\
          \ 0.400<br>'''<br>\uD310\uC0AC showed way lower score than I expected.</p>\n\
          <p>So I relearned the model, just like you did here(<a rel=\"nofollow\"\
          \ href=\"https://github.com/jhgan00/ko-sentence-transformers\">https://github.com/jhgan00/ko-sentence-transformers</a>)</p>\n\
          <p>And the case was fixed perfectly.<br>So I guess there was a small mistake\
          \ uploading this model.</p>\n<p>If you are ok, please check this issue.</p>\n\
          <p>Thx!</p>\n"
        raw: "Hi, jhgan :)\r\n\r\nI'm doing a project about Korean Job name.\r\nWhile\
          \ I test your model, I found a weird case.\r\nThis is here.\r\n'''\r\nSource\
          \ Sentence: \uB0B4 \uC9C1\uC5C5\uC740 \uD310\uC0AC\uC608\uC694.\r\n\r\n\
          Sentences to compare to: \r\n\uD310\uC0AC 0.075\r\n\uBC95\uBB34\uC0AC 0.498\r\
          \n\uAD50\uB3C4\uAD00 0.380\r\n\uBCC0\uD638\uC0AC 0.381\r\n\uB85C\uD38C\uB300\
          \uD45C 0.400\r\n'''\r\n\uD310\uC0AC showed way lower score than I expected.\r\
          \n\r\nSo I relearned the model, just like you did here(https://github.com/jhgan00/ko-sentence-transformers)\r\
          \n\r\nAnd the case was fixed perfectly.\r\nSo I guess there was a small\
          \ mistake uploading this model.\r\n\r\nIf you are ok, please check this\
          \ issue.\r\n\r\nThx!"
        updatedAt: '2022-09-26T04:43:47.134Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jhgan
    id: 63312e03c375586dc3b5a494
    type: comment
  author: hbhb
  content: "Hi, jhgan :)\r\n\r\nI'm doing a project about Korean Job name.\r\nWhile\
    \ I test your model, I found a weird case.\r\nThis is here.\r\n'''\r\nSource Sentence:\
    \ \uB0B4 \uC9C1\uC5C5\uC740 \uD310\uC0AC\uC608\uC694.\r\n\r\nSentences to compare\
    \ to: \r\n\uD310\uC0AC 0.075\r\n\uBC95\uBB34\uC0AC 0.498\r\n\uAD50\uB3C4\uAD00\
    \ 0.380\r\n\uBCC0\uD638\uC0AC 0.381\r\n\uB85C\uD38C\uB300\uD45C 0.400\r\n'''\r\
    \n\uD310\uC0AC showed way lower score than I expected.\r\n\r\nSo I relearned the\
    \ model, just like you did here(https://github.com/jhgan00/ko-sentence-transformers)\r\
    \n\r\nAnd the case was fixed perfectly.\r\nSo I guess there was a small mistake\
    \ uploading this model.\r\n\r\nIf you are ok, please check this issue.\r\n\r\n\
    Thx!"
  created_at: 2022-09-26 03:43:47+00:00
  edited: false
  hidden: false
  id: 63312e03c375586dc3b5a494
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1cf08cb4f3db389863c46f3813be6659.svg
      fullname: Junghyun Gan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: jhgan
      type: user
    createdAt: '2022-09-26T07:00:37.000Z'
    data:
      edited: false
      editors:
      - jhgan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1cf08cb4f3db389863c46f3813be6659.svg
          fullname: Junghyun Gan
          isHf: false
          isPro: false
          name: jhgan
          type: user
        html: '<p>Hello, I''ve checked out your issue and could have reproduced the
          case you reported.<br>However, the benchmark result shows that there is
          no significant problem in the model (the model achieves about <code>0.8477</code>
          pearson correlation in the STS testset. See <code>benchmark.py</code> for
          the benchmark script).<br>I guess because the model is trained to extract
          sentence level semantics(not word level semantics or lexical features),
          and it may sometimes fail if no sufficient context is given.<br>I could
          get reasonable result using the sentences, not words.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/1664174917390-60ebe6ae368c3c96bb302823.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/1664174917390-60ebe6ae368c3c96bb302823.png"></a></p>

          <p>Maybe you got different result because randomness is not perfectly controlled
          in my training script (but yours look better to me!).</p>

          <p>Thanks.</p>

          '
        raw: 'Hello, I''ve checked out your issue and could have reproduced the case
          you reported.

          However, the benchmark result shows that there is no significant problem
          in the model (the model achieves about `0.8477` pearson correlation in the
          STS testset. See `benchmark.py` for the benchmark script).

          I guess because the model is trained to extract sentence level semantics(not
          word level semantics or lexical features), and it may sometimes fail if
          no sufficient context is given.

          I could get reasonable result using the sentences, not words.


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1664174917390-60ebe6ae368c3c96bb302823.png)


          Maybe you got different result because randomness is not perfectly controlled
          in my training script (but yours look better to me!).


          Thanks.'
        updatedAt: '2022-09-26T07:00:37.724Z'
      numEdits: 0
      reactions: []
    id: 63314e15e092098b57b991d5
    type: comment
  author: jhgan
  content: 'Hello, I''ve checked out your issue and could have reproduced the case
    you reported.

    However, the benchmark result shows that there is no significant problem in the
    model (the model achieves about `0.8477` pearson correlation in the STS testset.
    See `benchmark.py` for the benchmark script).

    I guess because the model is trained to extract sentence level semantics(not word
    level semantics or lexical features), and it may sometimes fail if no sufficient
    context is given.

    I could get reasonable result using the sentences, not words.


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/1664174917390-60ebe6ae368c3c96bb302823.png)


    Maybe you got different result because randomness is not perfectly controlled
    in my training script (but yours look better to me!).


    Thanks.'
  created_at: 2022-09-26 06:00:37+00:00
  edited: false
  hidden: false
  id: 63314e15e092098b57b991d5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: jhgan/ko-sroberta-multitask
repo_type: model
status: open
target_branch: null
title: There is a weird case.
