!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ehartford
conflicting_files: null
created_at: 2023-10-26 13:47:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-10-26T14:47:57.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.933489978313446
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>may I see the dataset please?</p>

          '
        raw: may I see the dataset please?
        updatedAt: '2023-10-26T14:47:57.204Z'
      numEdits: 0
      reactions: []
    id: 653a7c1d5f1703225b17e35b
    type: comment
  author: ehartford
  content: may I see the dataset please?
  created_at: 2023-10-26 13:47:57+00:00
  edited: false
  hidden: false
  id: 653a7c1d5f1703225b17e35b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
      fullname: Undi
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Undi95
      type: user
    createdAt: '2023-10-26T15:51:21.000Z'
    data:
      edited: true
      editors:
      - Undi95
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5609552264213562
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ab1241ad514ca8d1430003/shjRx3yOP2eQvIyOWsQYV.png?w=200&h=200&f=face
          fullname: Undi
          isHf: false
          isPro: false
          name: Undi95
          type: user
        html: '<p>Hello!<br>There is no dataset, it''s a merge of multiple LoRA/Model</p>

          <ul>

          <li><a href="https://huggingface.co/Undi95/MLewd-L2-13B-Part3">Undi95/MLewd-L2-13B-Part3</a>
          (checkpoint of MLewd without LORA)</li>

          <li><a href="https://huggingface.co/posicube/Llama2-chat-AYT-13B">posicube/Llama2-chat-AYT-13B</a></li>

          <li><a href="https://huggingface.co/zattio770/120-Days-of-LORA-v2-13B">zattio770/120-Days-of-LORA-v2-13B</a></li>

          <li><a href="https://huggingface.co/royallab/Pygmalion-2-13b-SuperCOT">royallab/Pygmalion-2-13b-SuperCOT</a></li>

          <li><a href="https://huggingface.co/Undi95/MMSoul-13b-lora">Undi95/MMSoul-13b-lora</a></li>

          </ul>

          <p>For a starting point you could check :</p>

          <ul>

          <li>Pygmalion datasets</li>

          <li>120-Days-of-LORA-v2-13B</li>

          <li>SuperCOT</li>

          <li>All the model/dataset used in <a href="https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-FP16">https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-FP16</a></li>

          </ul>

          <p>Sorry!</p>

          <p>Edit: I gave you access to the private model <a href="https://huggingface.co/Undi95/ReMM-S-Light">Undi95/ReMM-S-Light</a>
          and <a href="https://huggingface.co/Undi95/MLewd-L2-13B-Part3">Undi95/MLewd-L2-13B-Part3</a>,
          the second one was done with an old version of mergekit, all model used
          to do it are public (outside ReMM-S-Light), here is the recipe:</p>

          <p>python main.py ./MLewd-L2-13B-Part1 --cuda --method slerp --base-model
          Undi95/ReMM-S-Light --merge Undi95/CreativityEngine --weight 0.25<br>=&gt;
          MLewd-L2-13B-Part1 (0.75 ReMM / 0.25 CreativeEngine)</p>

          <p>python main.py ./MLewd-L2-13B-Part2 --cuda --method slerp --base-model
          Undi95/MLewd-L2-13B-Part1 --merge Sao10K/Stheno-Inverted-L2-13B --weight
          0.20<br>=&gt; MLewd-L2-13B-Part2 (0.64 ReMM / 0.16 CreateEngine / 0.25 Stheno-Inverted)</p>

          <p>python main.py ./MLewd-L2-13B-Part3 --cuda --method slerp --base-model
          Undi95/MLewd-L2-13B-Part2 --merge The-Face-Of-Goonery/Huginn-v3-13b --weight
          0.15<br>=&gt; MLewd-L2-13B-Part3 (0.544 ReMM / 0.136 CreateEngine / 0.2125
          Stheno-Inverted / 0.15 Huginn-v3)</p>

          '
        raw: 'Hello!

          There is no dataset, it''s a merge of multiple LoRA/Model


          - [Undi95/MLewd-L2-13B-Part3](https://huggingface.co/Undi95/MLewd-L2-13B-Part3)
          (checkpoint of MLewd without LORA)

          - [posicube/Llama2-chat-AYT-13B](https://huggingface.co/posicube/Llama2-chat-AYT-13B)

          - [zattio770/120-Days-of-LORA-v2-13B](https://huggingface.co/zattio770/120-Days-of-LORA-v2-13B)

          - [royallab/Pygmalion-2-13b-SuperCOT](https://huggingface.co/royallab/Pygmalion-2-13b-SuperCOT)

          - [Undi95/MMSoul-13b-lora](https://huggingface.co/Undi95/MMSoul-13b-lora)


          For a starting point you could check :

          - Pygmalion datasets

          - 120-Days-of-LORA-v2-13B

          - SuperCOT

          - All the model/dataset used in https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-FP16


          Sorry!


          Edit: I gave you access to the private model [Undi95/ReMM-S-Light](https://huggingface.co/Undi95/ReMM-S-Light)
          and [Undi95/MLewd-L2-13B-Part3](https://huggingface.co/Undi95/MLewd-L2-13B-Part3),
          the second one was done with an old version of mergekit, all model used
          to do it are public (outside ReMM-S-Light), here is the recipe:


          python main.py ./MLewd-L2-13B-Part1 --cuda --method slerp --base-model Undi95/ReMM-S-Light
          --merge Undi95/CreativityEngine --weight 0.25

          => MLewd-L2-13B-Part1 (0.75 ReMM / 0.25 CreativeEngine)


          python main.py ./MLewd-L2-13B-Part2 --cuda --method slerp --base-model Undi95/MLewd-L2-13B-Part1
          --merge Sao10K/Stheno-Inverted-L2-13B --weight 0.20

          => MLewd-L2-13B-Part2 (0.64 ReMM / 0.16 CreateEngine / 0.25 Stheno-Inverted)


          python main.py ./MLewd-L2-13B-Part3 --cuda --method slerp --base-model Undi95/MLewd-L2-13B-Part2
          --merge The-Face-Of-Goonery/Huginn-v3-13b --weight 0.15

          => MLewd-L2-13B-Part3 (0.544 ReMM / 0.136 CreateEngine / 0.2125 Stheno-Inverted
          / 0.15 Huginn-v3)'
        updatedAt: '2023-10-26T15:59:17.107Z'
      numEdits: 4
      reactions: []
    id: 653a8af90157cf1d9cfb01f7
    type: comment
  author: Undi95
  content: 'Hello!

    There is no dataset, it''s a merge of multiple LoRA/Model


    - [Undi95/MLewd-L2-13B-Part3](https://huggingface.co/Undi95/MLewd-L2-13B-Part3)
    (checkpoint of MLewd without LORA)

    - [posicube/Llama2-chat-AYT-13B](https://huggingface.co/posicube/Llama2-chat-AYT-13B)

    - [zattio770/120-Days-of-LORA-v2-13B](https://huggingface.co/zattio770/120-Days-of-LORA-v2-13B)

    - [royallab/Pygmalion-2-13b-SuperCOT](https://huggingface.co/royallab/Pygmalion-2-13b-SuperCOT)

    - [Undi95/MMSoul-13b-lora](https://huggingface.co/Undi95/MMSoul-13b-lora)


    For a starting point you could check :

    - Pygmalion datasets

    - 120-Days-of-LORA-v2-13B

    - SuperCOT

    - All the model/dataset used in https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-FP16


    Sorry!


    Edit: I gave you access to the private model [Undi95/ReMM-S-Light](https://huggingface.co/Undi95/ReMM-S-Light)
    and [Undi95/MLewd-L2-13B-Part3](https://huggingface.co/Undi95/MLewd-L2-13B-Part3),
    the second one was done with an old version of mergekit, all model used to do
    it are public (outside ReMM-S-Light), here is the recipe:


    python main.py ./MLewd-L2-13B-Part1 --cuda --method slerp --base-model Undi95/ReMM-S-Light
    --merge Undi95/CreativityEngine --weight 0.25

    => MLewd-L2-13B-Part1 (0.75 ReMM / 0.25 CreativeEngine)


    python main.py ./MLewd-L2-13B-Part2 --cuda --method slerp --base-model Undi95/MLewd-L2-13B-Part1
    --merge Sao10K/Stheno-Inverted-L2-13B --weight 0.20

    => MLewd-L2-13B-Part2 (0.64 ReMM / 0.16 CreateEngine / 0.25 Stheno-Inverted)


    python main.py ./MLewd-L2-13B-Part3 --cuda --method slerp --base-model Undi95/MLewd-L2-13B-Part2
    --merge The-Face-Of-Goonery/Huginn-v3-13b --weight 0.15

    => MLewd-L2-13B-Part3 (0.544 ReMM / 0.136 CreateEngine / 0.2125 Stheno-Inverted
    / 0.15 Huginn-v3)'
  created_at: 2023-10-26 14:51:21+00:00
  edited: true
  hidden: false
  id: 653a8af90157cf1d9cfb01f7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Undi95/MLewd-L2-Chat-13B
repo_type: model
status: open
target_branch: null
title: dataset
