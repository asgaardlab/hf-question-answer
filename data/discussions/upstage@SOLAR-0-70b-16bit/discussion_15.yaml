!!python/object:huggingface_hub.community.DiscussionWithDetails
author: markding
conflicting_files: null
created_at: 2023-10-12 18:16:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62d1218684bfbee86b6ee521/BpXX_XUP80IfdGAvbs_VI.png?w=200&h=200&f=face
      fullname: MD
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: markding
      type: user
    createdAt: '2023-10-12T19:16:16.000Z'
    data:
      edited: true
      editors:
      - markding
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8989872932434082
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62d1218684bfbee86b6ee521/BpXX_XUP80IfdGAvbs_VI.png?w=200&h=200&f=face
          fullname: MD
          isHf: false
          isPro: false
          name: markding
          type: user
        html: '<p>Intriguing to see Solar as "a great example of the progress enabled
          by open source". However, for a model claiming this, Solar is remarkably
          silent about its own sources. The dataset details are <a href="https://huggingface.co/upstage/SOLAR-0-70b-16bit#used-datasets">given
          as</a>:</p>

          <blockquote>

          <p>Orca-style dataset<br>Alpaca-style dataset</p>

          </blockquote>

          <p>It would be helpful to document exactly which datasets and which versions
          have been used, and to specify the instruction tuning process and overall
          architecture in more detail.</p>

          <p>Currently, this model trails the very bottom of the <a rel="nofollow"
          href="https://opening-up-chatgpt.github.io/">openness leaderboard</a>: it
          is more closed and less documented than even Llama2 itself. Hoping to see
          this improve!</p>

          '
        raw: 'Intriguing to see Solar as "a great example of the progress enabled
          by open source". However, for a model claiming this, Solar is remarkably
          silent about its own sources. The dataset details are [given as](https://huggingface.co/upstage/SOLAR-0-70b-16bit#used-datasets):


          >Orca-style dataset

          >Alpaca-style dataset


          It would be helpful to document exactly which datasets and which versions
          have been used, and to specify the instruction tuning process and overall
          architecture in more detail.


          Currently, this model trails the very bottom of the [openness leaderboard](https://opening-up-chatgpt.github.io/):
          it is more closed and less documented than even Llama2 itself. Hoping to
          see this improve!'
        updatedAt: '2023-10-19T17:09:56.567Z'
      numEdits: 1
      reactions: []
    id: 65284600591c20f2dec96127
    type: comment
  author: markding
  content: 'Intriguing to see Solar as "a great example of the progress enabled by
    open source". However, for a model claiming this, Solar is remarkably silent about
    its own sources. The dataset details are [given as](https://huggingface.co/upstage/SOLAR-0-70b-16bit#used-datasets):


    >Orca-style dataset

    >Alpaca-style dataset


    It would be helpful to document exactly which datasets and which versions have
    been used, and to specify the instruction tuning process and overall architecture
    in more detail.


    Currently, this model trails the very bottom of the [openness leaderboard](https://opening-up-chatgpt.github.io/):
    it is more closed and less documented than even Llama2 itself. Hoping to see this
    improve!'
  created_at: 2023-10-12 18:16:16+00:00
  edited: true
  hidden: false
  id: 65284600591c20f2dec96127
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a81f2ea42e958c3dea3c729eb210e34e.svg
      fullname: Matthew Wallace
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: m9e
      type: user
    createdAt: '2023-10-19T14:10:28.000Z'
    data:
      edited: false
      editors:
      - m9e
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9734298586845398
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a81f2ea42e958c3dea3c729eb210e34e.svg
          fullname: Matthew Wallace
          isHf: false
          isPro: false
          name: m9e
          type: user
        html: '<p>Well, they were enabled by open source, but they are clearly NOT
          open source. No dataset, no code, and no commercial use. "Weights available
          for evaluation/personal use" is not open. One might assume that since they
          said "alpaca-style dataset" that they are using an actual Alpaca variant
          - and as Alpaca is CC-by-NC, they may feel they must then restrict to CC-by-NC;
          but cc-by-nc also requires attribution and "alpaca-style" is NOT an attribution
          and it would mean, imo, that they were breaching the Alpaca terms. Strange
          days.</p>

          '
        raw: Well, they were enabled by open source, but they are clearly NOT open
          source. No dataset, no code, and no commercial use. "Weights available for
          evaluation/personal use" is not open. One might assume that since they said
          "alpaca-style dataset" that they are using an actual Alpaca variant - and
          as Alpaca is CC-by-NC, they may feel they must then restrict to CC-by-NC;
          but cc-by-nc also requires attribution and "alpaca-style" is NOT an attribution
          and it would mean, imo, that they were breaching the Alpaca terms. Strange
          days.
        updatedAt: '2023-10-19T14:10:28.115Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - markding
    id: 653138d468a8764a565f74ce
    type: comment
  author: m9e
  content: Well, they were enabled by open source, but they are clearly NOT open source.
    No dataset, no code, and no commercial use. "Weights available for evaluation/personal
    use" is not open. One might assume that since they said "alpaca-style dataset"
    that they are using an actual Alpaca variant - and as Alpaca is CC-by-NC, they
    may feel they must then restrict to CC-by-NC; but cc-by-nc also requires attribution
    and "alpaca-style" is NOT an attribution and it would mean, imo, that they were
    breaching the Alpaca terms. Strange days.
  created_at: 2023-10-19 13:10:28+00:00
  edited: false
  hidden: false
  id: 653138d468a8764a565f74ce
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: upstage/SOLAR-0-70b-16bit
repo_type: model
status: open
target_branch: null
title: Lacking documentation of datasets used, architecture, fine-tuning procedures,
  source code
