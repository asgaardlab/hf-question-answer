!!python/object:huggingface_hub.community.DiscussionWithDetails
author: uncletang
conflicting_files: null
created_at: 2023-07-27 01:05:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f0c6a890bb9f048bed96cd9516b9580f.svg
      fullname: uc tang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: uncletang
      type: user
    createdAt: '2023-07-27T02:05:50.000Z'
    data:
      edited: false
      editors:
      - uncletang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.773703932762146
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f0c6a890bb9f048bed96cd9516b9580f.svg
          fullname: uc tang
          isHf: false
          isPro: false
          name: uncletang
          type: user
        html: '<p>CUDA out of memory. Tried to allocate 108.00 MiB (GPU 0; 5.79 GiB
          total capacity; 4.96 GiB already allocated; 145.19 MiB free; 4.96 GiB reserved
          in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try
          setting max_split_size_mb to avoid fragmentation.  See documentation for
          Memory Management and PYTORCH_CUDA_ALLOC_CONF</p>

          '
        raw: CUDA out of memory. Tried to allocate 108.00 MiB (GPU 0; 5.79 GiB total
          capacity; 4.96 GiB already allocated; 145.19 MiB free; 4.96 GiB reserved
          in total by PyTorch) If reserved memory is >> allocated memory try setting
          max_split_size_mb to avoid fragmentation.  See documentation for Memory
          Management and PYTORCH_CUDA_ALLOC_CONF
        updatedAt: '2023-07-27T02:05:50.613Z'
      numEdits: 0
      reactions: []
    id: 64c1d0fe8eaab3b628622294
    type: comment
  author: uncletang
  content: CUDA out of memory. Tried to allocate 108.00 MiB (GPU 0; 5.79 GiB total
    capacity; 4.96 GiB already allocated; 145.19 MiB free; 4.96 GiB reserved in total
    by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb
    to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  created_at: 2023-07-27 01:05:50+00:00
  edited: false
  hidden: false
  id: 64c1d0fe8eaab3b628622294
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ed5fe6bcae801c0c0ab87c8412cd5cc.svg
      fullname: Hu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Siy
      type: user
    createdAt: '2023-08-11T14:53:25.000Z'
    data:
      edited: false
      editors:
      - Siy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5069186687469482
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ed5fe6bcae801c0c0ab87c8412cd5cc.svg
          fullname: Hu
          isHf: false
          isPro: false
          name: Siy
          type: user
        html: "<p>\u6211\u7684\u5927\u5C0F\u4E5F\u8D85\u4E86\uFF0C\u4F46\u662F\u4E0D\
          \u662F\u8BF45.3gb\uFF0C\u6211\u76848gb\u4E5F\u7206\u4E86<br>    return torch.empty_strided(<br>torch.cuda.OutOfMemoryError:\
          \ CUDA out of memory. Tried to allocate 108.00 MiB (GPU 0; 8.00 GiB total\
          \ capacity; 7.25 GiB already allocated; 0 bytes free; 7.25 GiB reserved\
          \ in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try\
          \ setting max_split_size_mb to avoid fragmentation.  See documentation for\
          \ Memory Management and PYTORCH_CUDA_ALLOC_CONF</p>\n"
        raw: "\u6211\u7684\u5927\u5C0F\u4E5F\u8D85\u4E86\uFF0C\u4F46\u662F\u4E0D\u662F\
          \u8BF45.3gb\uFF0C\u6211\u76848gb\u4E5F\u7206\u4E86\n    return torch.empty_strided(\n\
          torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00\
          \ MiB (GPU 0; 8.00 GiB total capacity; 7.25 GiB already allocated; 0 bytes\
          \ free; 7.25 GiB reserved in total by PyTorch) If reserved memory is >>\
          \ allocated memory try setting max_split_size_mb to avoid fragmentation.\
          \  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
        updatedAt: '2023-08-11T14:53:25.836Z'
      numEdits: 0
      reactions: []
    id: 64d64b65c13c27a70161c1dd
    type: comment
  author: Siy
  content: "\u6211\u7684\u5927\u5C0F\u4E5F\u8D85\u4E86\uFF0C\u4F46\u662F\u4E0D\u662F\
    \u8BF45.3gb\uFF0C\u6211\u76848gb\u4E5F\u7206\u4E86\n    return torch.empty_strided(\n\
    torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 108.00 MiB\
    \ (GPU 0; 8.00 GiB total capacity; 7.25 GiB already allocated; 0 bytes free; 7.25\
    \ GiB reserved in total by PyTorch) If reserved memory is >> allocated memory\
    \ try setting max_split_size_mb to avoid fragmentation.  See documentation for\
    \ Memory Management and PYTORCH_CUDA_ALLOC_CONF"
  created_at: 2023-08-11 13:53:25+00:00
  edited: false
  hidden: false
  id: 64d64b65c13c27a70161c1dd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9ed5fe6bcae801c0c0ab87c8412cd5cc.svg
      fullname: Hu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Siy
      type: user
    createdAt: '2023-08-11T16:19:37.000Z'
    data:
      edited: false
      editors:
      - Siy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5292566418647766
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9ed5fe6bcae801c0c0ab87c8412cd5cc.svg
          fullname: Hu
          isHf: false
          isPro: false
          name: Siy
          type: user
        html: '<p>change to <code>trust_remote_code=True).half().to("cuda")</code>
          instead of <code>trust_remote_code=True, device=''cuda'')</code> fixed my
          problem.</p>

          '
        raw: change to `trust_remote_code=True).half().to("cuda")` instead of `trust_remote_code=True,
          device='cuda')` fixed my problem.
        updatedAt: '2023-08-11T16:19:37.559Z'
      numEdits: 0
      reactions: []
    id: 64d65f997705391d39402ab7
    type: comment
  author: Siy
  content: change to `trust_remote_code=True).half().to("cuda")` instead of `trust_remote_code=True,
    device='cuda')` fixed my problem.
  created_at: 2023-08-11 15:19:37+00:00
  edited: false
  hidden: false
  id: 64d65f997705391d39402ab7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f0c6a890bb9f048bed96cd9516b9580f.svg
      fullname: uc tang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: uncletang
      type: user
    createdAt: '2023-08-28T07:55:50.000Z'
    data:
      edited: false
      editors:
      - uncletang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3030371069908142
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f0c6a890bb9f048bed96cd9516b9580f.svg
          fullname: uc tang
          isHf: false
          isPro: false
          name: uncletang
          type: user
        html: "<blockquote>\n<p>change to <code>trust_remote_code=True).half().to(\"\
          cuda\")</code> instead of <code>trust_remote_code=True, device='cuda')</code>\
          \ fixed my problem.</p>\n</blockquote>\n<p>\u8C22\u8C22\uFF0C\u6211\u5DF2\
          \u7ECF\u89E3\u51B3\u4E86\u3002</p>\n"
        raw: "> change to `trust_remote_code=True).half().to(\"cuda\")` instead of\
          \ `trust_remote_code=True, device='cuda')` fixed my problem.\n\n\u8C22\u8C22\
          \uFF0C\u6211\u5DF2\u7ECF\u89E3\u51B3\u4E86\u3002"
        updatedAt: '2023-08-28T07:55:50.539Z'
      numEdits: 0
      reactions: []
    id: 64ec53067e69909b1ad2155d
    type: comment
  author: uncletang
  content: "> change to `trust_remote_code=True).half().to(\"cuda\")` instead of `trust_remote_code=True,\
    \ device='cuda')` fixed my problem.\n\n\u8C22\u8C22\uFF0C\u6211\u5DF2\u7ECF\u89E3\
    \u51B3\u4E86\u3002"
  created_at: 2023-08-28 06:55:50+00:00
  edited: false
  hidden: false
  id: 64ec53067e69909b1ad2155d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f0c6a890bb9f048bed96cd9516b9580f.svg
      fullname: uc tang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: uncletang
      type: user
    createdAt: '2023-08-28T07:55:55.000Z'
    data:
      status: closed
    id: 64ec530ba4b29851940bfebf
    type: status-change
  author: uncletang
  created_at: 2023-08-28 06:55:55+00:00
  id: 64ec530ba4b29851940bfebf
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: THUDM/codegeex2-6b-int4
repo_type: model
status: closed
target_branch: null
title: "\u6211\u672C\u5730\u62A5\u8FD9\u4E2A\u9519\uFF0C\u8BBE\u7F6E\u4E86\u597D\u50CF\
  \u4E5F\u4E0D\u884C\uFF0C\u662F\u4E0D\u662F\u6EE1\u4E86\uFF1F"
