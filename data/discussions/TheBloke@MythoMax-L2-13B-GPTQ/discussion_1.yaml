!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TETO101
conflicting_files: null
created_at: 2023-09-04 08:53:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673805121646-noauth.jpeg?w=200&h=200&f=face
      fullname: Teto Dola
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TETO101
      type: user
    createdAt: '2023-09-04T09:53:19.000Z'
    data:
      edited: true
      editors:
      - TETO101
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7925422787666321
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1673805121646-noauth.jpeg?w=200&h=200&f=face
          fullname: Teto Dola
          isHf: false
          isPro: false
          name: TETO101
          type: user
        html: '<p>Hello, I was experimenting with mythomax on ooba with exlamma with
          different prompt templates with the alpaca-input template. And i got this
          wierd bug where for certain rp inputs like <em>hugs you</em> or <em>touches
          you</em> doesn''t work. Sometimes it works when l load the model again but
          even then it stops working after a few tries. It outputs 0 tokens. When
          i try to do normal conversations, it just works again.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/63c43d6c8d95a5c77063f54f/AZ3TPZmhSV_LGQBKO7fKU.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/63c43d6c8d95a5c77063f54f/AZ3TPZmhSV_LGQBKO7fKU.png"></a></p>

          '
        raw: 'Hello, I was experimenting with mythomax on ooba with exlamma with different
          prompt templates with the alpaca-input template. And i got this wierd bug
          where for certain rp inputs like *hugs you* or *touches you* doesn''t work.
          Sometimes it works when l load the model again but even then it stops working
          after a few tries. It outputs 0 tokens. When i try to do normal conversations,
          it just works again.


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/63c43d6c8d95a5c77063f54f/AZ3TPZmhSV_LGQBKO7fKU.png)

          '
        updatedAt: '2023-09-04T09:56:49.321Z'
      numEdits: 5
      reactions: []
    id: 64f5a90f3cd4ab07d6541252
    type: comment
  author: TETO101
  content: 'Hello, I was experimenting with mythomax on ooba with exlamma with different
    prompt templates with the alpaca-input template. And i got this wierd bug where
    for certain rp inputs like *hugs you* or *touches you* doesn''t work. Sometimes
    it works when l load the model again but even then it stops working after a few
    tries. It outputs 0 tokens. When i try to do normal conversations, it just works
    again.


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/63c43d6c8d95a5c77063f54f/AZ3TPZmhSV_LGQBKO7fKU.png)

    '
  created_at: 2023-09-04 08:53:19+00:00
  edited: true
  hidden: false
  id: 64f5a90f3cd4ab07d6541252
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d27781b1e1d4c94801dab4adcab5d73.svg
      fullname: kool aid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: koolaidfiction
      type: user
    createdAt: '2023-09-08T08:01:05.000Z'
    data:
      edited: false
      editors:
      - koolaidfiction
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6909911632537842
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d27781b1e1d4c94801dab4adcab5d73.svg
          fullname: kool aid
          isHf: false
          isPro: false
          name: koolaidfiction
          type: user
        html: '<p>this aint no issue from the GPTQ files itself, go ahead and file
          an issue on <a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui">here</a>
          instead</p>

          '
        raw: this aint no issue from the GPTQ files itself, go ahead and file an issue
          on [here](https://github.com/oobabooga/text-generation-webui) instead
        updatedAt: '2023-09-08T08:01:05.955Z'
      numEdits: 0
      reactions: []
    id: 64fad4c12d20ced4e9f8cc0f
    type: comment
  author: koolaidfiction
  content: this aint no issue from the GPTQ files itself, go ahead and file an issue
    on [here](https://github.com/oobabooga/text-generation-webui) instead
  created_at: 2023-09-08 07:01:05+00:00
  edited: false
  hidden: false
  id: 64fad4c12d20ced4e9f8cc0f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/HP9e3Xfn5XlMdV3GINYJe.jpeg?w=200&h=200&f=face
      fullname: Paul Gostelow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Doomed1986
      type: user
    createdAt: '2023-10-26T17:29:52.000Z'
    data:
      edited: false
      editors:
      - Doomed1986
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.965601921081543
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/HP9e3Xfn5XlMdV3GINYJe.jpeg?w=200&h=200&f=face
          fullname: Paul Gostelow
          isHf: false
          isPro: false
          name: Doomed1986
          type: user
        html: "<p>I have a question related to this...<br>i was going to ask if anyone\
          \ knows if this model recognises and uses emojis and  the same for actions\
          \ denoted by <em>action</em> or \U0001D622\U0001D624\U0001D635\U0001D62A\
          \U0001D630\U0001D62F, and internal dialogue/thoughts with something like\
          \ (\"OMG HE TOUCHED ME!\")<br>I've seen various formatting for actions and\
          \ thoughts on those chatbot apps and websites.  Seems typing something encased\
          \ with asterisks basically always denotes action across several different\
          \ bots and i was hoping this LLM would have the same capabilities.  I'm\
          \ not that bothered about thoughts as for me thats too unrealistic, hearing\
          \ a third party's thoughts.  But if Mytho can do emojis and/or actions that\
          \ would be great!</p>\n"
        raw: "I have a question related to this...\ni was going to ask if anyone knows\
          \ if this model recognises and uses emojis and  the same for actions denoted\
          \ by *action* or \U0001D622\U0001D624\U0001D635\U0001D62A\U0001D630\U0001D62F\
          , and internal dialogue/thoughts with something like (\"OMG HE TOUCHED ME!\"\
          )\nI've seen various formatting for actions and thoughts on those chatbot\
          \ apps and websites.  Seems typing something encased with asterisks basically\
          \ always denotes action across several different bots and i was hoping this\
          \ LLM would have the same capabilities.  I'm not that bothered about thoughts\
          \ as for me thats too unrealistic, hearing a third party's thoughts.  But\
          \ if Mytho can do emojis and/or actions that would be great!"
        updatedAt: '2023-10-26T17:29:52.973Z'
      numEdits: 0
      reactions: []
    id: 653aa210025e5d017241c2ed
    type: comment
  author: Doomed1986
  content: "I have a question related to this...\ni was going to ask if anyone knows\
    \ if this model recognises and uses emojis and  the same for actions denoted by\
    \ *action* or \U0001D622\U0001D624\U0001D635\U0001D62A\U0001D630\U0001D62F, and\
    \ internal dialogue/thoughts with something like (\"OMG HE TOUCHED ME!\")\nI've\
    \ seen various formatting for actions and thoughts on those chatbot apps and websites.\
    \  Seems typing something encased with asterisks basically always denotes action\
    \ across several different bots and i was hoping this LLM would have the same\
    \ capabilities.  I'm not that bothered about thoughts as for me thats too unrealistic,\
    \ hearing a third party's thoughts.  But if Mytho can do emojis and/or actions\
    \ that would be great!"
  created_at: 2023-10-26 16:29:52+00:00
  edited: false
  hidden: false
  id: 653aa210025e5d017241c2ed
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d27781b1e1d4c94801dab4adcab5d73.svg
      fullname: kool aid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: koolaidfiction
      type: user
    createdAt: '2023-10-28T00:58:58.000Z'
    data:
      edited: false
      editors:
      - koolaidfiction
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9803630113601685
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d27781b1e1d4c94801dab4adcab5d73.svg
          fullname: kool aid
          isHf: false
          isPro: false
          name: koolaidfiction
          type: user
        html: '<p>this is a quantized version of mythomax... don''t expect anything
          great from it</p>

          '
        raw: this is a quantized version of mythomax... don't expect anything great
          from it
        updatedAt: '2023-10-28T00:58:58.350Z'
      numEdits: 0
      reactions: []
    id: 653c5cd2b16f657d28ac4c53
    type: comment
  author: koolaidfiction
  content: this is a quantized version of mythomax... don't expect anything great
    from it
  created_at: 2023-10-27 23:58:58+00:00
  edited: false
  hidden: false
  id: 653c5cd2b16f657d28ac4c53
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/HP9e3Xfn5XlMdV3GINYJe.jpeg?w=200&h=200&f=face
      fullname: Paul Gostelow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Doomed1986
      type: user
    createdAt: '2023-10-31T15:01:30.000Z'
    data:
      edited: false
      editors:
      - Doomed1986
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9816643595695496
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/HP9e3Xfn5XlMdV3GINYJe.jpeg?w=200&h=200&f=face
          fullname: Paul Gostelow
          isHf: false
          isPro: false
          name: Doomed1986
          type: user
        html: '<p>Yeh of course, there is that limitation.  But im pleased to report
          I did get the model to use <em>action</em> before.<br>do you know the size
          of the recognised context window?  i want to pack it with as much as possible</p>

          '
        raw: 'Yeh of course, there is that limitation.  But im pleased to report I
          did get the model to use *action* before.

          do you know the size of the recognised context window?  i want to pack it
          with as much as possible'
        updatedAt: '2023-10-31T15:01:30.175Z'
      numEdits: 0
      reactions: []
    id: 654116cadf8f1e9385f4a1ab
    type: comment
  author: Doomed1986
  content: 'Yeh of course, there is that limitation.  But im pleased to report I did
    get the model to use *action* before.

    do you know the size of the recognised context window?  i want to pack it with
    as much as possible'
  created_at: 2023-10-31 14:01:30+00:00
  edited: false
  hidden: false
  id: 654116cadf8f1e9385f4a1ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6d27781b1e1d4c94801dab4adcab5d73.svg
      fullname: kool aid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: koolaidfiction
      type: user
    createdAt: '2023-11-06T09:33:29.000Z'
    data:
      edited: false
      editors:
      - koolaidfiction
      hidden: false
      identifiedLanguage:
        language: fr
        probability: 0.1649104356765747
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6d27781b1e1d4c94801dab4adcab5d73.svg
          fullname: kool aid
          isHf: false
          isPro: false
          name: koolaidfiction
          type: user
        html: '<p>4096</p>

          '
        raw: '4096

          '
        updatedAt: '2023-11-06T09:33:29.745Z'
      numEdits: 0
      reactions: []
    id: 6548b2e9e3486f8a5ee14192
    type: comment
  author: koolaidfiction
  content: '4096

    '
  created_at: 2023-11-06 09:33:29+00:00
  edited: false
  hidden: false
  id: 6548b2e9e3486f8a5ee14192
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/HP9e3Xfn5XlMdV3GINYJe.jpeg?w=200&h=200&f=face
      fullname: Paul Gostelow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Doomed1986
      type: user
    createdAt: '2023-11-06T21:29:58.000Z'
    data:
      edited: false
      editors:
      - Doomed1986
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9123069643974304
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/HP9e3Xfn5XlMdV3GINYJe.jpeg?w=200&h=200&f=face
          fullname: Paul Gostelow
          isHf: false
          isPro: false
          name: Doomed1986
          type: user
        html: '<p>isnt that the max seq length of the chat?  or does a huge context
          window reduce the chat ''memory'' as it were?  Sorry, im a noob.</p>

          '
        raw: 'isnt that the max seq length of the chat?  or does a huge context window
          reduce the chat ''memory'' as it were?  Sorry, im a noob.

          '
        updatedAt: '2023-11-06T21:29:58.086Z'
      numEdits: 0
      reactions: []
    id: 65495ad6c26b9e805dd160e3
    type: comment
  author: Doomed1986
  content: 'isnt that the max seq length of the chat?  or does a huge context window
    reduce the chat ''memory'' as it were?  Sorry, im a noob.

    '
  created_at: 2023-11-06 21:29:58+00:00
  edited: false
  hidden: false
  id: 65495ad6c26b9e805dd160e3
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/MythoMax-L2-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: 0 tokens output on slight or NSFW stuff
