!!python/object:huggingface_hub.community.DiscussionWithDetails
author: UMCU
conflicting_files: null
created_at: 2023-11-21 09:44:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/618b9a79ba796dc2bf3f4412/66ustwEp1EDU_rxcXJBIO.jpeg?w=200&h=200&f=face
      fullname: Bram van Es
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: UMCU
      type: user
    createdAt: '2023-11-21T09:44:15.000Z'
    data:
      edited: false
      editors:
      - UMCU
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9142430424690247
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/618b9a79ba796dc2bf3f4412/66ustwEp1EDU_rxcXJBIO.jpeg?w=200&h=200&f=face
          fullname: Bram van Es
          isHf: false
          isPro: false
          name: UMCU
          type: user
        html: "<p>Hi Bram, </p>\n<p>thanks for this great work (and <span data-props=\"\
          {&quot;user&quot;:&quot;yhavinga&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/yhavinga\">@<span class=\"underline\">yhavinga</span></a></span>\n\
          \n\t</span></span> of course)! I have a question. I am in the process of\
          \ arranging compute to<br>finetune a Dutch language model of about the same\
          \ size with about the same sized dataset.  You used 4x3090's, do you still\
          \ remember the wall clock time and the average GPU-loading? </p>\n<p>As\
          \ for the finetuning, I assume you trained all layers?</p>\n<p>Groeten,</p>\n\
          <p>Bram</p>\n"
        raw: "Hi Bram, \r\n\r\nthanks for this great work (and @yhavinga of course)!\
          \ I have a question. I am in the process of arranging compute to \r\nfinetune\
          \ a Dutch language model of about the same size with about the same sized\
          \ dataset.  You used 4x3090's, do you still remember the wall clock time\
          \ and the average GPU-loading? \r\n\r\nAs for the finetuning, I assume you\
          \ trained all layers?\r\n\r\nGroeten,\r\n\r\nBram"
        updatedAt: '2023-11-21T09:44:15.422Z'
      numEdits: 0
      reactions: []
    id: 655c7bef2d1922b228a30b87
    type: comment
  author: UMCU
  content: "Hi Bram, \r\n\r\nthanks for this great work (and @yhavinga of course)!\
    \ I have a question. I am in the process of arranging compute to \r\nfinetune\
    \ a Dutch language model of about the same size with about the same sized dataset.\
    \  You used 4x3090's, do you still remember the wall clock time and the average\
    \ GPU-loading? \r\n\r\nAs for the finetuning, I assume you trained all layers?\r\
    \n\r\nGroeten,\r\n\r\nBram"
  created_at: 2023-11-21 09:44:15+00:00
  edited: false
  hidden: false
  id: 655c7bef2d1922b228a30b87
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594192845975-5e1e17b6fcf41d740b6996a8.jpeg?w=200&h=200&f=face
      fullname: Bram Vanroy
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: BramVanroy
      type: user
    createdAt: '2023-12-04T07:30:37.000Z'
    data:
      edited: false
      editors:
      - BramVanroy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8987289667129517
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594192845975-5e1e17b6fcf41d740b6996a8.jpeg?w=200&h=200&f=face
          fullname: Bram Vanroy
          isHf: false
          isPro: false
          name: BramVanroy
          type: user
        html: "<p>HI <span data-props=\"{&quot;user&quot;:&quot;UMCU&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/UMCU\">@<span class=\"\
          underline\">UMCU</span></a></span>\n\n\t</span></span>. This flew below\
          \ the radar, sorry for not catching it!</p>\n<p>To be honest I do not remember\
          \ all the details, but if you look at the train_results.json file you can\
          \ see some metrics there, like the runtime in seconds and how many samples\
          \ were processed per second at a context length of 4096 (<a href=\"https://huggingface.co/BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny/blob/main/train_results.json#L6\"\
          >https://huggingface.co/BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny/blob/main/train_results.json#L6</a>).\
          \ </p>\n<p>For finetuning I did not finetune all layers due to limited compute.\
          \ I used QLoRA. If you have the compute, I would recommend doing a full\
          \ finetune indeed, or at least LoRA with <em>all</em> linear layers.</p>\n\
          <p>Hope that helps!</p>\n<p>Bram</p>\n"
        raw: "HI @UMCU. This flew below the radar, sorry for not catching it!\n\n\
          To be honest I do not remember all the details, but if you look at the train_results.json\
          \ file you can see some metrics there, like the runtime in seconds and how\
          \ many samples were processed per second at a context length of 4096 (https://huggingface.co/BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny/blob/main/train_results.json#L6).\
          \ \n\nFor finetuning I did not finetune all layers due to limited compute.\
          \ I used QLoRA. If you have the compute, I would recommend doing a full\
          \ finetune indeed, or at least LoRA with _all_ linear layers.\n\nHope that\
          \ helps!\n\nBram"
        updatedAt: '2023-12-04T07:30:37.555Z'
      numEdits: 0
      reactions: []
    id: 656d801dae32721645c67042
    type: comment
  author: BramVanroy
  content: "HI @UMCU. This flew below the radar, sorry for not catching it!\n\nTo\
    \ be honest I do not remember all the details, but if you look at the train_results.json\
    \ file you can see some metrics there, like the runtime in seconds and how many\
    \ samples were processed per second at a context length of 4096 (https://huggingface.co/BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny/blob/main/train_results.json#L6).\
    \ \n\nFor finetuning I did not finetune all layers due to limited compute. I used\
    \ QLoRA. If you have the compute, I would recommend doing a full finetune indeed,\
    \ or at least LoRA with _all_ linear layers.\n\nHope that helps!\n\nBram"
  created_at: 2023-12-04 07:30:37+00:00
  edited: false
  hidden: false
  id: 656d801dae32721645c67042
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594192845975-5e1e17b6fcf41d740b6996a8.jpeg?w=200&h=200&f=face
      fullname: Bram Vanroy
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: BramVanroy
      type: user
    createdAt: '2023-12-13T19:16:25.000Z'
    data:
      status: closed
    id: 657a0309e7a39f0aad343aa4
    type: status-change
  author: BramVanroy
  created_at: 2023-12-13 19:16:25+00:00
  id: 657a0309e7a39f0aad343aa4
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/618b9a79ba796dc2bf3f4412/66ustwEp1EDU_rxcXJBIO.jpeg?w=200&h=200&f=face
      fullname: Bram van Es
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: UMCU
      type: user
    createdAt: '2023-12-13T20:26:09.000Z'
    data:
      edited: true
      editors:
      - UMCU
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9064721465110779
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/618b9a79ba796dc2bf3f4412/66ustwEp1EDU_rxcXJBIO.jpeg?w=200&h=200&f=face
          fullname: Bram van Es
          isHf: false
          isPro: false
          name: UMCU
          type: user
        html: '<p>Thanks for the reply Bram!</p>

          '
        raw: Thanks for the reply Bram!
        updatedAt: '2023-12-13T20:26:31.681Z'
      numEdits: 1
      reactions: []
    id: 657a1361b7cd0d1a525bfdfe
    type: comment
  author: UMCU
  content: Thanks for the reply Bram!
  created_at: 2023-12-13 20:26:09+00:00
  edited: true
  hidden: false
  id: 657a1361b7cd0d1a525bfdfe
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny
repo_type: model
status: closed
target_branch: null
title: How much 3090-hours did you need for the training epoch?
