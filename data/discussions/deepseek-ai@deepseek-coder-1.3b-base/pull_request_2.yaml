!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jonatanklosko
conflicting_files: []
created_at: 2023-11-16 16:21:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661254068904-noauth.jpeg?w=200&h=200&f=face
      fullname: "Jonatan K\u0142osko"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jonatanklosko
      type: user
    createdAt: '2023-11-16T16:21:45.000Z'
    data:
      oid: e94f2b11bc28abbd67ecadfaad058c30b24a589f
      parents:
      - c919139c3a9b4070729c8b2cca4847ab29ca8d94
      subject: Upload tokenizer.json
    id: '655641990000000000000000'
    type: commit
  author: jonatanklosko
  created_at: 2023-11-16 16:21:45+00:00
  id: '655641990000000000000000'
  oid: e94f2b11bc28abbd67ecadfaad058c30b24a589f
  summary: Upload tokenizer.json
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661254068904-noauth.jpeg?w=200&h=200&f=face
      fullname: "Jonatan K\u0142osko"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jonatanklosko
      type: user
    createdAt: '2023-11-16T16:21:50.000Z'
    data:
      edited: false
      editors:
      - jonatanklosko
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7854213118553162
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1661254068904-noauth.jpeg?w=200&h=200&f=face
          fullname: "Jonatan K\u0142osko"
          isHf: false
          isPro: false
          name: jonatanklosko
          type: user
        html: '<p>The persisted <code>tokenizer.json</code> does not have the template
          processor for adding special tokens. <code>transformers</code> overrides
          the processor on load, but when loading <code>tokenizer.json</code> directly
          with the Rust tokenizers it''s nice to have the processor there already
          (which worked so far in case of other models). This basically re-saves the
          tokenizer to match exactly what is loaded by <code>transformers</code>.</p>

          <hr>

          <p>Generated with:</p>

          <pre><code class="language-python"><span class="hljs-keyword">from</span>
          transformers <span class="hljs-keyword">import</span> AutoTokenizer


          tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"deepseek-ai/deepseek-coder-1.3b-base"</span>)

          <span class="hljs-keyword">assert</span> tokenizer.is_fast

          tokenizer.save_pretrained(<span class="hljs-string">"..."</span>)

          </code></pre>

          '
        raw: 'The persisted `tokenizer.json` does not have the template processor
          for adding special tokens. `transformers` overrides the processor on load,
          but when loading `tokenizer.json` directly with the Rust tokenizers it''s
          nice to have the processor there already (which worked so far in case of
          other models). This basically re-saves the tokenizer to match exactly what
          is loaded by `transformers`.


          ---


          Generated with:


          ```python

          from transformers import AutoTokenizer


          tokenizer = AutoTokenizer.from_pretrained("deepseek-ai/deepseek-coder-1.3b-base")

          assert tokenizer.is_fast

          tokenizer.save_pretrained("...")

          ```'
        updatedAt: '2023-11-16T16:21:50.756Z'
      numEdits: 0
      reactions: []
    id: 6556419eef6e96329fe2e557
    type: comment
  author: jonatanklosko
  content: 'The persisted `tokenizer.json` does not have the template processor for
    adding special tokens. `transformers` overrides the processor on load, but when
    loading `tokenizer.json` directly with the Rust tokenizers it''s nice to have
    the processor there already (which worked so far in case of other models). This
    basically re-saves the tokenizer to match exactly what is loaded by `transformers`.


    ---


    Generated with:


    ```python

    from transformers import AutoTokenizer


    tokenizer = AutoTokenizer.from_pretrained("deepseek-ai/deepseek-coder-1.3b-base")

    assert tokenizer.is_fast

    tokenizer.save_pretrained("...")

    ```'
  created_at: 2023-11-16 16:21:50+00:00
  edited: false
  hidden: false
  id: 6556419eef6e96329fe2e557
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 2
repo_id: deepseek-ai/deepseek-coder-1.3b-base
repo_type: model
status: open
target_branch: refs/heads/main
title: Upload tokenizer.json
