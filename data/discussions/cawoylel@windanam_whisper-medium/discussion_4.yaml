!!python/object:huggingface_hub.community.DiscussionWithDetails
author: flutter-painter
conflicting_files: null
created_at: 2024-01-14 00:22:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fa125c48411fc7894a8111/i5raUP6a3hZuIHQ3E7Mqi.jpeg?w=200&h=200&f=face
      fullname: Jimmy Jo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: flutter-painter
      type: user
    createdAt: '2024-01-14T00:22:43.000Z'
    data:
      edited: false
      editors:
      - flutter-painter
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9491899013519287
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fa125c48411fc7894a8111/i5raUP6a3hZuIHQ3E7Mqi.jpeg?w=200&h=200&f=face
          fullname: Jimmy Jo
          isHf: false
          isPro: false
          name: flutter-painter
          type: user
        html: '<p>This model is great but is 3 Go,<br>Do you intend to make a lighter
          version ?</p>

          '
        raw: "This model is great but is 3 Go,\r\nDo you intend to make a lighter\
          \ version ?"
        updatedAt: '2024-01-14T00:22:43.445Z'
      numEdits: 0
      reactions: []
    id: 65a32953680cb2eb941b2a7b
    type: comment
  author: flutter-painter
  content: "This model is great but is 3 Go,\r\nDo you intend to make a lighter version\
    \ ?"
  created_at: 2024-01-14 00:22:43+00:00
  edited: false
  hidden: false
  id: 65a32953680cb2eb941b2a7b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/234c196e4a06405aaa32a395ce21c91a.svg
      fullname: Yaya
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: yaya-sy
      type: user
    createdAt: '2024-01-14T13:14:10.000Z'
    data:
      edited: false
      editors:
      - yaya-sy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9211344122886658
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/234c196e4a06405aaa32a395ce21c91a.svg
          fullname: Yaya
          isHf: false
          isPro: false
          name: yaya-sy
          type: user
        html: '<p>I tried to quantized it to ggml format using whisper.cpp (<a rel="nofollow"
          href="https://github.com/ggerganov/whisper.cpp">https://github.com/ggerganov/whisper.cpp</a>).
          Indeed, the model was lighter and faster. But we plan to retrain Whisper
          with more data and longer, by reducing the vocabulary matrix. This model
          will be smaller, and combined with the quantization we hope it will fit
          on small devices.</p>

          '
        raw: I tried to quantized it to ggml format using whisper.cpp (https://github.com/ggerganov/whisper.cpp).
          Indeed, the model was lighter and faster. But we plan to retrain Whisper
          with more data and longer, by reducing the vocabulary matrix. This model
          will be smaller, and combined with the quantization we hope it will fit
          on small devices.
        updatedAt: '2024-01-14T13:14:10.627Z'
      numEdits: 0
      reactions: []
    id: 65a3de2280e2523eea0fd659
    type: comment
  author: yaya-sy
  content: I tried to quantized it to ggml format using whisper.cpp (https://github.com/ggerganov/whisper.cpp).
    Indeed, the model was lighter and faster. But we plan to retrain Whisper with
    more data and longer, by reducing the vocabulary matrix. This model will be smaller,
    and combined with the quantization we hope it will fit on small devices.
  created_at: 2024-01-14 13:14:10+00:00
  edited: false
  hidden: false
  id: 65a3de2280e2523eea0fd659
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fa125c48411fc7894a8111/i5raUP6a3hZuIHQ3E7Mqi.jpeg?w=200&h=200&f=face
      fullname: Jimmy Jo
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: flutter-painter
      type: user
    createdAt: '2024-01-14T14:54:30.000Z'
    data:
      edited: false
      editors:
      - flutter-painter
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9402621388435364
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64fa125c48411fc7894a8111/i5raUP6a3hZuIHQ3E7Mqi.jpeg?w=200&h=200&f=face
          fullname: Jimmy Jo
          isHf: false
          isPro: false
          name: flutter-painter
          type: user
        html: '<p>Ok, good news. Can''t wait to see this new model<br>Still I am not
          sure it will fit on small device. I was thinking about serving it at a lower
          cost or running it locally on desktop.<br>To fit on mobile devices it would
          need to be at least below 500Mo, actually below 200Mo should be the target
          considering the kind of android phones used by most fula speaker and also
          leaving room for offline translation model.<br>For this use case, and since
          you aggregated a vast dataset, icefall and sherpa seems to me a safer choice
          : <a rel="nofollow" href="https://k2-fsa.github.io/sherpa/onnx/index.html">https://k2-fsa.github.io/sherpa/onnx/index.html</a></p>

          '
        raw: 'Ok, good news. Can''t wait to see this new model

          Still I am not sure it will fit on small device. I was thinking about serving
          it at a lower cost or running it locally on desktop.

          To fit on mobile devices it would need to be at least below 500Mo, actually
          below 200Mo should be the target considering the kind of android phones
          used by most fula speaker and also leaving room for offline translation
          model.

          For this use case, and since you aggregated a vast dataset, icefall and
          sherpa seems to me a safer choice : https://k2-fsa.github.io/sherpa/onnx/index.html


          '
        updatedAt: '2024-01-14T14:54:30.549Z'
      numEdits: 0
      reactions: []
    id: 65a3f5a63581a68c41c7b00d
    type: comment
  author: flutter-painter
  content: 'Ok, good news. Can''t wait to see this new model

    Still I am not sure it will fit on small device. I was thinking about serving
    it at a lower cost or running it locally on desktop.

    To fit on mobile devices it would need to be at least below 500Mo, actually below
    200Mo should be the target considering the kind of android phones used by most
    fula speaker and also leaving room for offline translation model.

    For this use case, and since you aggregated a vast dataset, icefall and sherpa
    seems to me a safer choice : https://k2-fsa.github.io/sherpa/onnx/index.html


    '
  created_at: 2024-01-14 14:54:30+00:00
  edited: false
  hidden: false
  id: 65a3f5a63581a68c41c7b00d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: cawoylel/windanam_whisper-medium
repo_type: model
status: open
target_branch: null
title: Any plans of a quantized or distilled version ?
