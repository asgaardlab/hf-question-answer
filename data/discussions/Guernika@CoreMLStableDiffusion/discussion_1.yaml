!!python/object:huggingface_hub.community.DiscussionWithDetails
author: maavangent
conflicting_files: null
created_at: 2023-01-02 14:56:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665169855131-noauth.jpeg?w=200&h=200&f=face
      fullname: Maarten van Gent
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: maavangent
      type: user
    createdAt: '2023-01-02T14:56:24.000Z'
    data:
      edited: false
      editors:
      - maavangent
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665169855131-noauth.jpeg?w=200&h=200&f=face
          fullname: Maarten van Gent
          isHf: false
          isPro: false
          name: maavangent
          type: user
        html: '<p>Do you always have to convert an existing model locally? Or are
          there files (like the .CKPT files normally) that you can download and load?</p>

          <p>I''ve been trying to figure it out for the past days but I guess I need
          some help haha.</p>

          '
        raw: "Do you always have to convert an existing model locally? Or are there\
          \ files (like the .CKPT files normally) that you can download and load?\r\
          \n\r\nI've been trying to figure it out for the past days but I guess I\
          \ need some help haha."
        updatedAt: '2023-01-02T14:56:24.051Z'
      numEdits: 0
      reactions: []
    id: 63b2f098677046a142866a73
    type: comment
  author: maavangent
  content: "Do you always have to convert an existing model locally? Or are there\
    \ files (like the .CKPT files normally) that you can download and load?\r\n\r\n\
    I've been trying to figure it out for the past days but I guess I need some help\
    \ haha."
  created_at: 2023-01-02 14:56:24+00:00
  edited: false
  hidden: false
  id: 63b2f098677046a142866a73
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-02T15:00:18.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;maavangent&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/maavangent\">@<span class=\"\
          underline\">maavangent</span></a></span>\n\n\t</span></span> there are some\
          \ converted models on this repository zipped, you can go to the \"Models\"\
          \ tab and tap on the download model button (Box with and arrow down) and\
          \ enter the zip URL there.<br>You can get URLs from the <a href=\"https://huggingface.co/Guernika/CoreMLStableDiffusion/blob/main/models.json\"\
          >models.json</a> file, you should be using the \"model\" URL from the model\
          \ you want to download.<br>In any case, I'm working on a Model Converter\
          \ app that will simplify the converting process and on an update to allow\
          \ downloading these preconverted models from the app.</p>\n<p>Thank you\
          \ for the comment :)</p>\n"
        raw: '@maavangent there are some converted models on this repository zipped,
          you can go to the "Models" tab and tap on the download model button (Box
          with and arrow down) and enter the zip URL there.

          You can get URLs from the [models.json](https://huggingface.co/Guernika/CoreMLStableDiffusion/blob/main/models.json)
          file, you should be using the "model" URL from the model you want to download.

          In any case, I''m working on a Model Converter app that will simplify the
          converting process and on an update to allow downloading these preconverted
          models from the app.


          Thank you for the comment :)'
        updatedAt: '2023-01-02T15:00:18.907Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - maavangent
    id: 63b2f1826c3e6df5c38837a1
    type: comment
  author: GuiyeC
  content: '@maavangent there are some converted models on this repository zipped,
    you can go to the "Models" tab and tap on the download model button (Box with
    and arrow down) and enter the zip URL there.

    You can get URLs from the [models.json](https://huggingface.co/Guernika/CoreMLStableDiffusion/blob/main/models.json)
    file, you should be using the "model" URL from the model you want to download.

    In any case, I''m working on a Model Converter app that will simplify the converting
    process and on an update to allow downloading these preconverted models from the
    app.


    Thank you for the comment :)'
  created_at: 2023-01-02 15:00:18+00:00
  edited: false
  hidden: false
  id: 63b2f1826c3e6df5c38837a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-03T18:12:30.000Z'
    data:
      edited: true
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: "<p>I'm running a 2 TB 16\" 2021 MacBook Pro with 64GB RAM and 32 GPU\
          \ cores \u2026 but it's no 4090. \U0001F60A Much of the time I'm simultaneously\
          \ rendering with several implementations open at once.</p>\n<p>I've installed\
          \ Diffusion Bee, Auto1111, InvokeAI, as well as CoreML variant Mocha Diffusion,\
          \ and I'm running <em>Flight Test</em> with the beta version of CoreML PromptToImage.\
          \ I'm happy to support the Mac community and any CoreML efforts coming about,\
          \ so I'm about to purchase Guernika from the App Store. </p>\n<p>Surprisingly,\
          \ I hadn't heard of it before randomly coming across it here just now when\
          \ searching for CoreML models. If you haven't already, you should post to\
          \ Reddit r/stablediffusion to get some eyes on it. </p>\n<p>What are your\
          \ plans for the future? Do you have a Discord to discuss ideas for tentative\
          \ features and implementations?</p>\n<p>\u2014 <em>Thanks!</em></p>\n"
        raw: "I'm running a 2 TB 16\" 2021 MacBook Pro with 64GB RAM and 32 GPU cores\
          \ \u2026 but it's no 4090. \U0001F60A Much of the time I'm simultaneously\
          \ rendering with several implementations open at once.\n\nI've installed\
          \ Diffusion Bee, Auto1111, InvokeAI, as well as CoreML variant Mocha Diffusion,\
          \ and I'm running *Flight Test* with the beta version of CoreML PromptToImage.\
          \ I'm happy to support the Mac community and any CoreML efforts coming about,\
          \ so I'm about to purchase Guernika from the App Store. \n\nSurprisingly,\
          \ I hadn't heard of it before randomly coming across it here just now when\
          \ searching for CoreML models. If you haven't already, you should post to\
          \ Reddit r/stablediffusion to get some eyes on it. \n\nWhat are your plans\
          \ for the future? Do you have a Discord to discuss ideas for tentative features\
          \ and implementations?\n\n\u2014 *Thanks!*"
        updatedAt: '2023-01-03T18:13:29.702Z'
      numEdits: 1
      reactions: []
    id: 63b4700ea25dd8a860b25e60
    type: comment
  author: Michaelangelo
  content: "I'm running a 2 TB 16\" 2021 MacBook Pro with 64GB RAM and 32 GPU cores\
    \ \u2026 but it's no 4090. \U0001F60A Much of the time I'm simultaneously rendering\
    \ with several implementations open at once.\n\nI've installed Diffusion Bee,\
    \ Auto1111, InvokeAI, as well as CoreML variant Mocha Diffusion, and I'm running\
    \ *Flight Test* with the beta version of CoreML PromptToImage. I'm happy to support\
    \ the Mac community and any CoreML efforts coming about, so I'm about to purchase\
    \ Guernika from the App Store. \n\nSurprisingly, I hadn't heard of it before randomly\
    \ coming across it here just now when searching for CoreML models. If you haven't\
    \ already, you should post to Reddit r/stablediffusion to get some eyes on it.\
    \ \n\nWhat are your plans for the future? Do you have a Discord to discuss ideas\
    \ for tentative features and implementations?\n\n\u2014 *Thanks!*"
  created_at: 2023-01-03 18:12:30+00:00
  edited: true
  hidden: false
  id: 63b4700ea25dd8a860b25e60
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-03T20:58:37.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: '<p>That''s a good idea, I will post something on that Reddit!</p>

          <p>As for plans for the future, so far I''m using the app and when I think
          something would be useful I implement it, I have plans to improve collection
          viewing, prompt history...</p>

          <p>You could share ideas here if you want or if you think a Discord would
          be useful I could try to set one up, or maybe a Reddit?</p>

          <p>Thank you for the support!</p>

          '
        raw: 'That''s a good idea, I will post something on that Reddit!


          As for plans for the future, so far I''m using the app and when I think
          something would be useful I implement it, I have plans to improve collection
          viewing, prompt history...


          You could share ideas here if you want or if you think a Discord would be
          useful I could try to set one up, or maybe a Reddit?


          Thank you for the support!'
        updatedAt: '2023-01-03T20:58:37.743Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - maavangent
    id: 63b496fda74bd39bf1f33b15
    type: comment
  author: GuiyeC
  content: 'That''s a good idea, I will post something on that Reddit!


    As for plans for the future, so far I''m using the app and when I think something
    would be useful I implement it, I have plans to improve collection viewing, prompt
    history...


    You could share ideas here if you want or if you think a Discord would be useful
    I could try to set one up, or maybe a Reddit?


    Thank you for the support!'
  created_at: 2023-01-03 20:58:37+00:00
  edited: false
  hidden: false
  id: 63b496fda74bd39bf1f33b15
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-04T00:51:18.000Z'
    data:
      edited: false
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: "<p>Reddit would be great, you could also link to Gihub or Huggingface\
          \ pages with your profile or this page as an option for the <em>Help</em>\
          \ tab in the app. </p>\n<p>What rendering algorithm is being employed by\
          \ Guernika? Is it PNDM, DPM-Solver, or (\u2026)? Thanks again!</p>\n"
        raw: "Reddit would be great, you could also link to Gihub or Huggingface pages\
          \ with your profile or this page as an option for the *Help* tab in the\
          \ app. \n\nWhat rendering algorithm is being employed by Guernika? Is it\
          \ PNDM, DPM-Solver, or (\u2026)? Thanks again!"
        updatedAt: '2023-01-04T00:51:18.611Z'
      numEdits: 0
      reactions: []
    id: 63b4cd86a74bd39bf1f5d888
    type: comment
  author: Michaelangelo
  content: "Reddit would be great, you could also link to Gihub or Huggingface pages\
    \ with your profile or this page as an option for the *Help* tab in the app. \n\
    \nWhat rendering algorithm is being employed by Guernika? Is it PNDM, DPM-Solver,\
    \ or (\u2026)? Thanks again!"
  created_at: 2023-01-04 00:51:18+00:00
  edited: false
  hidden: false
  id: 63b4cd86a74bd39bf1f5d888
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-04T12:19:05.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: '<p>At the moment Guernika uses the PNDM which is the default one but
          it has support for DPMSolver too, I have to add an option to change that
          but I was not able to find a lot of information on what the difference really
          is and didn''t want to confuse people. If you are asking for it, it definitely
          seems people would find that useful.</p>

          '
        raw: At the moment Guernika uses the PNDM which is the default one but it
          has support for DPMSolver too, I have to add an option to change that but
          I was not able to find a lot of information on what the difference really
          is and didn't want to confuse people. If you are asking for it, it definitely
          seems people would find that useful.
        updatedAt: '2023-01-04T12:19:05.772Z'
      numEdits: 0
      reactions: []
    id: 63b56eb99d50c1463c54a382
    type: comment
  author: GuiyeC
  content: At the moment Guernika uses the PNDM which is the default one but it has
    support for DPMSolver too, I have to add an option to change that but I was not
    able to find a lot of information on what the difference really is and didn't
    want to confuse people. If you are asking for it, it definitely seems people would
    find that useful.
  created_at: 2023-01-04 12:19:05+00:00
  edited: false
  hidden: false
  id: 63b56eb99d50c1463c54a382
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-04T16:37:59.000Z'
    data:
      edited: false
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: '<p>Thanks, I know from reading on the Mochi Diffusion Github page that
          DPM++ gives great results after only 10-25 steps. I''m not familiar with
          either but was wondering if PNDM does as well; the option would be good
          to have.</p>

          '
        raw: Thanks, I know from reading on the Mochi Diffusion Github page that DPM++
          gives great results after only 10-25 steps. I'm not familiar with either
          but was wondering if PNDM does as well; the option would be good to have.
        updatedAt: '2023-01-04T16:37:59.504Z'
      numEdits: 0
      reactions: []
    id: 63b5ab6758b5e43bdded4c80
    type: comment
  author: Michaelangelo
  content: Thanks, I know from reading on the Mochi Diffusion Github page that DPM++
    gives great results after only 10-25 steps. I'm not familiar with either but was
    wondering if PNDM does as well; the option would be good to have.
  created_at: 2023-01-04 16:37:59+00:00
  edited: false
  hidden: false
  id: 63b5ab6758b5e43bdded4c80
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-04T17:08:51.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Michaelangelo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Michaelangelo\"\
          >@<span class=\"underline\">Michaelangelo</span></a></span>\n\n\t</span></span>\
          \ I will add that option on the next update then \U0001F44C. Do you have\
          \ any other requests?</p>\n"
        raw: "@Michaelangelo I will add that option on the next update then \U0001F44C\
          . Do you have any other requests?"
        updatedAt: '2023-01-04T17:08:51.567Z'
      numEdits: 0
      reactions: []
    id: 63b5b2a358b5e43bddeddcd5
    type: comment
  author: GuiyeC
  content: "@Michaelangelo I will add that option on the next update then \U0001F44C\
    . Do you have any other requests?"
  created_at: 2023-01-04 17:08:51+00:00
  edited: false
  hidden: false
  id: 63b5b2a358b5e43bddeddcd5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-04T22:39:16.000Z'
    data:
      edited: true
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: "<p><em>Short-term</em> \u2014 A lot depends on what we <em>can</em>\
          \ do given Apple's implementation. </p>\n<p>I noticed there's the option\
          \ for single image or continuous inference. It would be nice to have set\
          \ values possible between 1 and 100, e.g. 10, 20, 40, 50, 100, if not in\
          \ increments of n=1. </p>\n<p>Also, a way to bulk delete images, rather\
          \ than having to select each image manually with a right click to delete\
          \ them one-by-one.</p>\n<p>How are tokens handled by the app, what's the\
          \ maximum? After crossing the threshold for max tokens, are any further\
          \ tokens silently dropped?\u2014or are they merged to together, as the novel\
          \ solution employed by the Automatic1111 repo, which consequently doesn't\
          \ have a length limitation? If that can be worked in, as with the approach\
          \ Auto1111 took would be the ideal solution. </p>\n<p>What's the syntax\
          \ for tokens, how is prompt weighting handled per token\u2014are different\
          \ weights allowed as in the Auto1111 instance with parenthesis and brackets\
          \ or values 1.1, 1.2, etc.? </p>\n<p><em>Long-term</em> \u2014 Inpainting,\
          \ outpainting, Dreambooth and LORA training, different output sizes.</p>\n"
        raw: "_Short-term_ \u2014 A lot depends on what we _can_ do given Apple's\
          \ implementation. \n\nI noticed there's the option for single image or continuous\
          \ inference. It would be nice to have set values possible between 1 and\
          \ 100, e.g. 10, 20, 40, 50, 100, if not in increments of n=1. \n\nAlso,\
          \ a way to bulk delete images, rather than having to select each image manually\
          \ with a right click to delete them one-by-one.\n\nHow are tokens handled\
          \ by the app, what's the maximum? After crossing the threshold for max tokens,\
          \ are any further tokens silently dropped?\u2014or are they merged to together,\
          \ as the novel solution employed by the Automatic1111 repo, which consequently\
          \ doesn't have a length limitation? If that can be worked in, as with the\
          \ approach Auto1111 took would be the ideal solution. \n\nWhat's the syntax\
          \ for tokens, how is prompt weighting handled per token\u2014are different\
          \ weights allowed as in the Auto1111 instance with parenthesis and brackets\
          \ or values 1.1, 1.2, etc.? \n\n_Long-term_ \u2014 Inpainting, outpainting,\
          \ Dreambooth and LORA training, different output sizes."
        updatedAt: '2023-01-04T23:31:42.579Z'
      numEdits: 9
      reactions: []
    id: 63b6001458b5e43bddf3a381
    type: comment
  author: Michaelangelo
  content: "_Short-term_ \u2014 A lot depends on what we _can_ do given Apple's implementation.\
    \ \n\nI noticed there's the option for single image or continuous inference. It\
    \ would be nice to have set values possible between 1 and 100, e.g. 10, 20, 40,\
    \ 50, 100, if not in increments of n=1. \n\nAlso, a way to bulk delete images,\
    \ rather than having to select each image manually with a right click to delete\
    \ them one-by-one.\n\nHow are tokens handled by the app, what's the maximum? After\
    \ crossing the threshold for max tokens, are any further tokens silently dropped?\u2014\
    or are they merged to together, as the novel solution employed by the Automatic1111\
    \ repo, which consequently doesn't have a length limitation? If that can be worked\
    \ in, as with the approach Auto1111 took would be the ideal solution. \n\nWhat's\
    \ the syntax for tokens, how is prompt weighting handled per token\u2014are different\
    \ weights allowed as in the Auto1111 instance with parenthesis and brackets or\
    \ values 1.1, 1.2, etc.? \n\n_Long-term_ \u2014 Inpainting, outpainting, Dreambooth\
    \ and LORA training, different output sizes."
  created_at: 2023-01-04 22:39:16+00:00
  edited: true
  hidden: false
  id: 63b6001458b5e43bddf3a381
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-05T00:02:02.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Michaelangelo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Michaelangelo\"\
          >@<span class=\"underline\">Michaelangelo</span></a></span>\n\n\t</span></span>\
          \ I will think of a nice way of adding the image limit \U0001F44C</p>\n\
          <p>Yes, I also do want a nicer way of dealing with lots of images but it\
          \ does come with a lot of things to take into account, maybe I could add\
          \ a \"Show in Finder\" for now which would allow selecting multiple images.<br>At\
          \ the moment images are stored here <code>/Users/{YOUR_USER}/Library/Containers/com.guiyec.Guernika/Data/Documents/Images</code></p>\n\
          <p>At the moment they are truncated at the TextEconder's input length, I\
          \ will take a look at merging but that seems tricky to test, I'm not promising\
          \ anything here \U0001F605</p>\n<p>Same for prompt weightning , I have to\
          \ take a deeper look at how this is handled, at the moment it's just been\
          \ fed into the TextEncoder and I'm not sure if it's actually taking that\
          \ into account.</p>\n<p>Inpainting should already be working, not an ideal\
          \ solution but you should be able to load an inpainting model and draw a\
          \ mask to generate new images.</p>\n<p>Outpaining will be cool, I have to\
          \ improve inpainting implementation and this will hopefully facilitate outpainting.</p>\n\
          <p>Any kind of training will probably be out of scope or very far into the\
          \ future.</p>\n<p>Finally, different output sizes, Apple mentions how this\
          \ could work recommending what to do when converting models, I have tried\
          \ <strong>a lot</strong> and I have not been able to convert any models\
          \ with variable output sizes or even different output sizes that actually\
          \ work. I really want this to work but we may have to wait for Apple to\
          \ fix something on CoreML tools before we get it \U0001F615</p>\n"
        raw: "@Michaelangelo I will think of a nice way of adding the image limit\
          \ \U0001F44C\n\nYes, I also do want a nicer way of dealing with lots of\
          \ images but it does come with a lot of things to take into account, maybe\
          \ I could add a \"Show in Finder\" for now which would allow selecting multiple\
          \ images.\nAt the moment images are stored here `/Users/{YOUR_USER}/Library/Containers/com.guiyec.Guernika/Data/Documents/Images`\n\
          \nAt the moment they are truncated at the TextEconder's input length, I\
          \ will take a look at merging but that seems tricky to test, I'm not promising\
          \ anything here \U0001F605\n\nSame for prompt weightning , I have to take\
          \ a deeper look at how this is handled, at the moment it's just been fed\
          \ into the TextEncoder and I'm not sure if it's actually taking that into\
          \ account.\n\nInpainting should already be working, not an ideal solution\
          \ but you should be able to load an inpainting model and draw a mask to\
          \ generate new images.\n\nOutpaining will be cool, I have to improve inpainting\
          \ implementation and this will hopefully facilitate outpainting.\n\nAny\
          \ kind of training will probably be out of scope or very far into the future.\n\
          \nFinally, different output sizes, Apple mentions how this could work recommending\
          \ what to do when converting models, I have tried **a lot** and I have not\
          \ been able to convert any models with variable output sizes or even different\
          \ output sizes that actually work. I really want this to work but we may\
          \ have to wait for Apple to fix something on CoreML tools before we get\
          \ it \U0001F615"
        updatedAt: '2023-01-05T00:02:02.800Z'
      numEdits: 0
      reactions: []
    id: 63b6137a58b5e43bddf4bddd
    type: comment
  author: GuiyeC
  content: "@Michaelangelo I will think of a nice way of adding the image limit \U0001F44C\
    \n\nYes, I also do want a nicer way of dealing with lots of images but it does\
    \ come with a lot of things to take into account, maybe I could add a \"Show in\
    \ Finder\" for now which would allow selecting multiple images.\nAt the moment\
    \ images are stored here `/Users/{YOUR_USER}/Library/Containers/com.guiyec.Guernika/Data/Documents/Images`\n\
    \nAt the moment they are truncated at the TextEconder's input length, I will take\
    \ a look at merging but that seems tricky to test, I'm not promising anything\
    \ here \U0001F605\n\nSame for prompt weightning , I have to take a deeper look\
    \ at how this is handled, at the moment it's just been fed into the TextEncoder\
    \ and I'm not sure if it's actually taking that into account.\n\nInpainting should\
    \ already be working, not an ideal solution but you should be able to load an\
    \ inpainting model and draw a mask to generate new images.\n\nOutpaining will\
    \ be cool, I have to improve inpainting implementation and this will hopefully\
    \ facilitate outpainting.\n\nAny kind of training will probably be out of scope\
    \ or very far into the future.\n\nFinally, different output sizes, Apple mentions\
    \ how this could work recommending what to do when converting models, I have tried\
    \ **a lot** and I have not been able to convert any models with variable output\
    \ sizes or even different output sizes that actually work. I really want this\
    \ to work but we may have to wait for Apple to fix something on CoreML tools before\
    \ we get it \U0001F615"
  created_at: 2023-01-05 00:02:02+00:00
  edited: false
  hidden: false
  id: 63b6137a58b5e43bddf4bddd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-05T14:50:51.000Z'
    data:
      edited: true
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: "<p>I noted that the solution employed by the developers of CoreML SD\
          \ GUI PromptToText is to have <a href=\"https://huggingface.co/TheMurusTeam\"\
          >a different model for each image output size</a>; this is obviously not\
          \ as convenient as a drop-down box as with Python model implementations\
          \ but it's a temporary stopgap measure.</p>\n<p><span data-props=\"{&quot;user&quot;:&quot;GuiyeC&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/GuiyeC\"\
          >@<span class=\"underline\">GuiyeC</span></a></span>\n\n\t</span></span>\
          \ \u2013 Also, for selecting multiple images, see the solution employed\
          \ by PromptToImage for navigating the gallery, both to view images using\
          \ the arrow key and selecting multiple images for deletion. I believe their\
          \ project is open-source and on Github so you should be able to copy and\
          \ paste the code handling over with proper attribution, of course.</p>\n"
        raw: "I noted that the solution employed by the developers of CoreML SD GUI\
          \ PromptToText is to have [a different model for each image output size](https://huggingface.co/TheMurusTeam);\
          \ this is obviously not as convenient as a drop-down box as with Python\
          \ model implementations but it's a temporary stopgap measure.\n\n@GuiyeC\
          \ \u2013 Also, for selecting multiple images, see the solution employed\
          \ by PromptToImage for navigating the gallery, both to view images using\
          \ the arrow key and selecting multiple images for deletion. I believe their\
          \ project is open-source and on Github so you should be able to copy and\
          \ paste the code handling over with proper attribution, of course."
        updatedAt: '2023-01-05T15:13:16.242Z'
      numEdits: 2
      reactions: []
    id: 63b6e3cbf168593c6fb95ef5
    type: comment
  author: Michaelangelo
  content: "I noted that the solution employed by the developers of CoreML SD GUI\
    \ PromptToText is to have [a different model for each image output size](https://huggingface.co/TheMurusTeam);\
    \ this is obviously not as convenient as a drop-down box as with Python model\
    \ implementations but it's a temporary stopgap measure.\n\n@GuiyeC \u2013 Also,\
    \ for selecting multiple images, see the solution employed by PromptToImage for\
    \ navigating the gallery, both to view images using the arrow key and selecting\
    \ multiple images for deletion. I believe their project is open-source and on\
    \ Github so you should be able to copy and paste the code handling over with proper\
    \ attribution, of course."
  created_at: 2023-01-05 14:50:51+00:00
  edited: true
  hidden: false
  id: 63b6e3cbf168593c6fb95ef5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-06T12:34:05.000Z'
    data:
      edited: true
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: '<p>Where did you see the different models for different output size?</p>

          <p><del>Can you link to this PromptToImage project?</del> Found it</p>

          '
        raw: 'Where did you see the different models for different output size?


          ~~Can you link to this PromptToImage project?~~ Found it'
        updatedAt: '2023-01-06T12:38:12.282Z'
      numEdits: 1
      reactions: []
    id: 63b8153d0d814c2001a2e5be
    type: comment
  author: GuiyeC
  content: 'Where did you see the different models for different output size?


    ~~Can you link to this PromptToImage project?~~ Found it'
  created_at: 2023-01-06 12:34:05+00:00
  edited: true
  hidden: false
  id: 63b8153d0d814c2001a2e5be
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-06T14:19:04.000Z'
    data:
      edited: true
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: "<p>It would be nice to have a default model loaded at startup; I noticed\
          \ every time I start I've got to select and load one \u2026</p>\n<p>I also\
          \ noticed there's no upper limit to the numbers for steps or guidance, when\
          \ most implementations cap steps at 75-100 and most guidance scales cap\
          \ at 24. What, realistically, is the result of setting a guidance scale\
          \ to some crazy high number like 523? Is it clipped behind the scenes to\
          \ the SD limit of 24?</p>\n"
        raw: "It would be nice to have a default model loaded at startup; I noticed\
          \ every time I start I've got to select and load one \u2026\n\nI also noticed\
          \ there's no upper limit to the numbers for steps or guidance, when most\
          \ implementations cap steps at 75-100 and most guidance scales cap at 24.\
          \ What, realistically, is the result of setting a guidance scale to some\
          \ crazy high number like 523? Is it clipped behind the scenes to the SD\
          \ limit of 24?"
        updatedAt: '2023-01-06T14:26:56.938Z'
      numEdits: 3
      reactions: []
    id: 63b82dd80d814c2001a48db5
    type: comment
  author: Michaelangelo
  content: "It would be nice to have a default model loaded at startup; I noticed\
    \ every time I start I've got to select and load one \u2026\n\nI also noticed\
    \ there's no upper limit to the numbers for steps or guidance, when most implementations\
    \ cap steps at 75-100 and most guidance scales cap at 24. What, realistically,\
    \ is the result of setting a guidance scale to some crazy high number like 523?\
    \ Is it clipped behind the scenes to the SD limit of 24?"
  created_at: 2023-01-06 14:19:04+00:00
  edited: true
  hidden: false
  id: 63b82dd80d814c2001a48db5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-07T23:36:45.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Michaelangelo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Michaelangelo\"\
          >@<span class=\"underline\">Michaelangelo</span></a></span>\n\n\t</span></span>\
          \ I did not see the limits you mention on the python implementation, where\
          \ did you see them? I have not tinkered a lot with guidance but I have tried\
          \ using more than 100 steps with no problems, I have not tested if the gains\
          \ are visible after a certain amount of steps though.</p>\n<p>Maybe I can\
          \ add an option to autoload the last model, or auto load it and an option\
          \ to cancel loading? I agree that having it loaded on start up would be\
          \ nicer, I didn't do it at first as it can take a while to actually load\
          \ and people might want to switch models.</p>\n<p>Thank you again for all\
          \ of these comments, I really appreciate them \U0001F64F</p>\n<p>Also, I\
          \ followed your advice and created a <a rel=\"nofollow\" href=\"https://www.reddit.com/r/Guernika/\"\
          >reddit community</a> and posted on <a rel=\"nofollow\" href=\"https://www.reddit.com/r/StableDiffusion/comments/1060923/\"\
          >r/StableDiffusion</a></p>\n"
        raw: "@Michaelangelo I did not see the limits you mention on the python implementation,\
          \ where did you see them? I have not tinkered a lot with guidance but I\
          \ have tried using more than 100 steps with no problems, I have not tested\
          \ if the gains are visible after a certain amount of steps though.\n\nMaybe\
          \ I can add an option to autoload the last model, or auto load it and an\
          \ option to cancel loading? I agree that having it loaded on start up would\
          \ be nicer, I didn't do it at first as it can take a while to actually load\
          \ and people might want to switch models.\n\nThank you again for all of\
          \ these comments, I really appreciate them \U0001F64F\n\nAlso, I followed\
          \ your advice and created a [reddit community](https://www.reddit.com/r/Guernika/)\
          \ and posted on [r/StableDiffusion](https://www.reddit.com/r/StableDiffusion/comments/1060923/)"
        updatedAt: '2023-01-07T23:36:45.575Z'
      numEdits: 0
      reactions: []
    id: 63ba020d593e237fc37a9d76
    type: comment
  author: GuiyeC
  content: "@Michaelangelo I did not see the limits you mention on the python implementation,\
    \ where did you see them? I have not tinkered a lot with guidance but I have tried\
    \ using more than 100 steps with no problems, I have not tested if the gains are\
    \ visible after a certain amount of steps though.\n\nMaybe I can add an option\
    \ to autoload the last model, or auto load it and an option to cancel loading?\
    \ I agree that having it loaded on start up would be nicer, I didn't do it at\
    \ first as it can take a while to actually load and people might want to switch\
    \ models.\n\nThank you again for all of these comments, I really appreciate them\
    \ \U0001F64F\n\nAlso, I followed your advice and created a [reddit community](https://www.reddit.com/r/Guernika/)\
    \ and posted on [r/StableDiffusion](https://www.reddit.com/r/StableDiffusion/comments/1060923/)"
  created_at: 2023-01-07 23:36:45+00:00
  edited: false
  hidden: false
  id: 63ba020d593e237fc37a9d76
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-08T18:31:03.000Z'
    data:
      edited: true
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: "<p>Excellent! </p>\n<p>There are many different implementations, but\
          \ by far the most popular is the <a rel=\"nofollow\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki\"\
          >Automatic1111 repo</a> (<a rel=\"nofollow\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/\"\
          ><em>Wiki</em></a>, <a rel=\"nofollow\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features\"\
          ><em>Features</em></a>, <a rel=\"nofollow\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts\"\
          ><em>Scripts</em></a>, <a rel=\"nofollow\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Extensions\"\
          ><em>Extensions</em></a>). </p>\n<p><strong>UI Values</strong><br>Sampling\
          \ steps: (max) 150 (default) 20<br>Size: (max) 2048\xD72048 (default) 512\xD7\
          512<br>Batch count: (max) 100 (default)1<br>Batch size (max): 8 (default)\
          \ 1<br>Guidance Scale: (max) 30 (default) 6-8. <em>Depending on the model,\
          \ anything over 12-15 can result in noise from overbaked, overtrained results</em>.</p>\n\
          <p>Whether or not there are gains to be had in higher step counts depends\
          \ in part on the decoder selected. See attached grid plot showing the effect\
          \ of different CFG levels and link to Reddit with a run-down comparison\
          \ of different samplers at different step counts. </p>\n<ul>\n<li><a rel=\"\
          nofollow\" href=\"https://www.reddit.com/r/StableDiffusion/comments/x1587s/sampler_step_count_comparison_with_timing_info/\"\
          ><strong>Reddit: Sampler and Step Count Comparison</strong></a><br><a rel=\"\
          nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1673201953834-631f07005172252802e316e3.png\"\
          ><img alt=\"208332322-24339554-0274-4add-88a7-d33bba1e3823.png\" src=\"\
          https://cdn-uploads.huggingface.co/production/uploads/1673201953834-631f07005172252802e316e3.png\"\
          ></a><br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1673201953767-631f07005172252802e316e3.png\"\
          ><img alt=\"197560013-51e535d6-7cef-4946-ab6b-747e1c76b007.png\" src=\"\
          https://cdn-uploads.huggingface.co/production/uploads/1673201953767-631f07005172252802e316e3.png\"\
          ></a></li>\n</ul>\n<p><strong>CFG Strength Comparison</strong><br><a rel=\"\
          nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/1673202147126-631f07005172252802e316e3.jpeg\"\
          ><img alt=\"sampling.jpg\" src=\"https://cdn-uploads.huggingface.co/production/uploads/1673202147126-631f07005172252802e316e3.jpeg\"\
          ></a></p>\n"
        raw: "Excellent! \n\nThere are many different implementations, but by far\
          \ the most popular is the [Automatic1111 repo](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki)\
          \ ([*Wiki*](https://github.com/AUTOMATIC1111/stable-diffusion-webui/), [*Features*](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features),\
          \ [*Scripts*](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts),\
          \ [*Extensions*](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Extensions)).\
          \ \n\n**UI Values**\nSampling steps: (max) 150 (default) 20\nSize: (max)\
          \ 2048\xD72048 (default) 512\xD7512\nBatch count: (max) 100 (default)1\n\
          Batch size (max): 8 (default) 1\nGuidance Scale: (max) 30 (default) 6-8.\
          \ *Depending on the model, anything over 12-15 can result in noise from\
          \ overbaked, overtrained results*.\n\nWhether or not there are gains to\
          \ be had in higher step counts depends in part on the decoder selected.\
          \ See attached grid plot showing the effect of different CFG levels and\
          \ link to Reddit with a run-down comparison of different samplers at different\
          \ step counts. \n\n* [**Reddit: Sampler and Step Count Comparison**](https://www.reddit.com/r/StableDiffusion/comments/x1587s/sampler_step_count_comparison_with_timing_info/)\n\
          ![208332322-24339554-0274-4add-88a7-d33bba1e3823.png](https://cdn-uploads.huggingface.co/production/uploads/1673201953834-631f07005172252802e316e3.png)\n\
          ![197560013-51e535d6-7cef-4946-ab6b-747e1c76b007.png](https://cdn-uploads.huggingface.co/production/uploads/1673201953767-631f07005172252802e316e3.png)\n\
          \n**CFG Strength Comparison**\n![sampling.jpg](https://cdn-uploads.huggingface.co/production/uploads/1673202147126-631f07005172252802e316e3.jpeg)"
        updatedAt: '2023-01-08T18:33:42.453Z'
      numEdits: 2
      reactions: []
    id: 63bb0be7f948864bc8e8f1b2
    type: comment
  author: Michaelangelo
  content: "Excellent! \n\nThere are many different implementations, but by far the\
    \ most popular is the [Automatic1111 repo](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki)\
    \ ([*Wiki*](https://github.com/AUTOMATIC1111/stable-diffusion-webui/), [*Features*](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features),\
    \ [*Scripts*](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts),\
    \ [*Extensions*](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Extensions)).\
    \ \n\n**UI Values**\nSampling steps: (max) 150 (default) 20\nSize: (max) 2048\xD7\
    2048 (default) 512\xD7512\nBatch count: (max) 100 (default)1\nBatch size (max):\
    \ 8 (default) 1\nGuidance Scale: (max) 30 (default) 6-8. *Depending on the model,\
    \ anything over 12-15 can result in noise from overbaked, overtrained results*.\n\
    \nWhether or not there are gains to be had in higher step counts depends in part\
    \ on the decoder selected. See attached grid plot showing the effect of different\
    \ CFG levels and link to Reddit with a run-down comparison of different samplers\
    \ at different step counts. \n\n* [**Reddit: Sampler and Step Count Comparison**](https://www.reddit.com/r/StableDiffusion/comments/x1587s/sampler_step_count_comparison_with_timing_info/)\n\
    ![208332322-24339554-0274-4add-88a7-d33bba1e3823.png](https://cdn-uploads.huggingface.co/production/uploads/1673201953834-631f07005172252802e316e3.png)\n\
    ![197560013-51e535d6-7cef-4946-ab6b-747e1c76b007.png](https://cdn-uploads.huggingface.co/production/uploads/1673201953767-631f07005172252802e316e3.png)\n\
    \n**CFG Strength Comparison**\n![sampling.jpg](https://cdn-uploads.huggingface.co/production/uploads/1673202147126-631f07005172252802e316e3.jpeg)"
  created_at: 2023-01-08 18:31:03+00:00
  edited: true
  hidden: false
  id: 63bb0be7f948864bc8e8f1b2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Guernika/CoreMLStableDiffusion
repo_type: model
status: open
target_branch: null
title: How to load models?
