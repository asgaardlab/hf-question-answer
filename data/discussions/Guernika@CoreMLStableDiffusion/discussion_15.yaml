!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jettan
conflicting_files: null
created_at: 2023-04-04 05:28:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e89ce2aaf4a7c493e7e3bc0dcd65ffe2.svg
      fullname: Jethro Tan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jettan
      type: user
    createdAt: '2023-04-04T06:28:59.000Z'
    data:
      edited: false
      editors:
      - jettan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e89ce2aaf4a7c493e7e3bc0dcd65ffe2.svg
          fullname: Jethro Tan
          isHf: false
          isPro: false
          name: jettan
          type: user
        html: '<p>First of all, I''d like to give huge compliments for the great job
          done!<br>The UI is very snappy and feature-wise it is ahead of mainstream
          due to support of ControlNet extensions and textual inversions (on MacOS
          at least... any chances they will also arrive for iOS?)</p>

          <p>I would like to ask whether there is some difference between the models
          converted by Guernika Model Converter/script provided in this repository
          and the procedure described in Mochi Diffusion repository: <a rel="nofollow"
          href="https://github.com/godly-devotion/MochiDiffusion/wiki/How-to-convert-Stable-Diffusion-models-to-Core-ML">https://github.com/godly-devotion/MochiDiffusion/wiki/How-to-convert-Stable-Diffusion-models-to-Core-ML</a></p>

          <p>I tried to use the models that were converted from the one on the other
          and vice versa, but was not able to get it working.<br>Additionally, it
          seems that the Guernika Model Converter adds some metadata (guernika.json).
          I thought that by making this and putting the coreml converted models would
          be enough, but it seems to crash Guernika, so clearly something else is
          done additionally. It would be nice if they were cross compatible through
          apps.</p>

          <p>Also, I''d like to ask whether there are plans to support HD upscaling
          (with e.g., Real ESRGAN) just like Mochi Diffusion has (they even have it
          included in their repository. </p>

          <p>Lastly, do you have any data on how much memory is needed for an iOS
          device to run stable diffusion with Unet chunked VS non chunked?</p>

          <p>Thanks in advance.</p>

          '
        raw: "First of all, I'd like to give huge compliments for the great job done!\r\
          \nThe UI is very snappy and feature-wise it is ahead of mainstream due to\
          \ support of ControlNet extensions and textual inversions (on MacOS at least...\
          \ any chances they will also arrive for iOS?)\r\n\r\nI would like to ask\
          \ whether there is some difference between the models converted by Guernika\
          \ Model Converter/script provided in this repository and the procedure described\
          \ in Mochi Diffusion repository: https://github.com/godly-devotion/MochiDiffusion/wiki/How-to-convert-Stable-Diffusion-models-to-Core-ML\r\
          \n\r\nI tried to use the models that were converted from the one on the\
          \ other and vice versa, but was not able to get it working.\r\nAdditionally,\
          \ it seems that the Guernika Model Converter adds some metadata (guernika.json).\
          \ I thought that by making this and putting the coreml converted models\
          \ would be enough, but it seems to crash Guernika, so clearly something\
          \ else is done additionally. It would be nice if they were cross compatible\
          \ through apps.\r\n\r\nAlso, I'd like to ask whether there are plans to\
          \ support HD upscaling (with e.g., Real ESRGAN) just like Mochi Diffusion\
          \ has (they even have it included in their repository. \r\n\r\nLastly, do\
          \ you have any data on how much memory is needed for an iOS device to run\
          \ stable diffusion with Unet chunked VS non chunked?\r\n\r\nThanks in advance."
        updatedAt: '2023-04-04T06:28:59.561Z'
      numEdits: 0
      reactions: []
    id: 642bc3ab77967049cf4a0233
    type: comment
  author: jettan
  content: "First of all, I'd like to give huge compliments for the great job done!\r\
    \nThe UI is very snappy and feature-wise it is ahead of mainstream due to support\
    \ of ControlNet extensions and textual inversions (on MacOS at least... any chances\
    \ they will also arrive for iOS?)\r\n\r\nI would like to ask whether there is\
    \ some difference between the models converted by Guernika Model Converter/script\
    \ provided in this repository and the procedure described in Mochi Diffusion repository:\
    \ https://github.com/godly-devotion/MochiDiffusion/wiki/How-to-convert-Stable-Diffusion-models-to-Core-ML\r\
    \n\r\nI tried to use the models that were converted from the one on the other\
    \ and vice versa, but was not able to get it working.\r\nAdditionally, it seems\
    \ that the Guernika Model Converter adds some metadata (guernika.json). I thought\
    \ that by making this and putting the coreml converted models would be enough,\
    \ but it seems to crash Guernika, so clearly something else is done additionally.\
    \ It would be nice if they were cross compatible through apps.\r\n\r\nAlso, I'd\
    \ like to ask whether there are plans to support HD upscaling (with e.g., Real\
    \ ESRGAN) just like Mochi Diffusion has (they even have it included in their repository.\
    \ \r\n\r\nLastly, do you have any data on how much memory is needed for an iOS\
    \ device to run stable diffusion with Unet chunked VS non chunked?\r\n\r\nThanks\
    \ in advance."
  created_at: 2023-04-04 05:28:59+00:00
  edited: false
  hidden: false
  id: 642bc3ab77967049cf4a0233
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/29d17cafebc2de883588964706360101.svg
      fullname: ZProphete
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ZProphete
      type: user
    createdAt: '2023-04-04T07:02:23.000Z'
    data:
      edited: true
      editors:
      - ZProphete
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/29d17cafebc2de883588964706360101.svg
          fullname: ZProphete
          isHf: false
          isPro: false
          name: ZProphete
          type: user
        html: '<p>Let me answer !<br>Guernika models are a little different, because
          the author implemented features before apple''s official ones (yea, big
          brain), so it diverged a bit.<br>While Mochi refers to Apple official implementation
          (stuck at t2i/i2i as today), it lacks the new features like inpainting,
          Textual Inversion, ControlNet, Prompt weighting etc...<br>Transfering model
          into Guernika may work with text2image, not the other way around, Apple/Mochi
          has to catch up xD</p>

          <p>You also have graphical user interface for converting models simply,
          you can see amazing updates pop often.</p>

          <ul>

          <li><p>In my honest personal opinion, HD upscale is possible (and wanted),
          I looked up for myself but I found little sample codes online and I wouldn''t
          leech a concurrent app code...<br>If that''s all you needed from cross compatibility,
          I bet it Upscale will come any time soon.</p>

          </li>

          <li><p>For iOS devices, you MUST have it chunked, no matter what, I usually
          chunk every time for my iPad/Mac usage, I guess the chunking is supposed
          to swap chunks one after another thus not fill the whole ram.</p>

          </li>

          </ul>

          <p>Welcome to the gang.</p>

          '
        raw: 'Let me answer !

          Guernika models are a little different, because the author implemented features
          before apple''s official ones (yea, big brain), so it diverged a bit.

          While Mochi refers to Apple official implementation (stuck at t2i/i2i as
          today), it lacks the new features like inpainting, Textual Inversion, ControlNet,
          Prompt weighting etc...

          Transfering model into Guernika may work with text2image, not the other
          way around, Apple/Mochi has to catch up xD


          You also have graphical user interface for converting models simply, you
          can see amazing updates pop often.


          - In my honest personal opinion, HD upscale is possible (and wanted), I
          looked up for myself but I found little sample codes online and I wouldn''t
          leech a concurrent app code...

          If that''s all you needed from cross compatibility, I bet it Upscale will
          come any time soon.


          - For iOS devices, you MUST have it chunked, no matter what, I usually chunk
          every time for my iPad/Mac usage, I guess the chunking is supposed to swap
          chunks one after another thus not fill the whole ram.


          Welcome to the gang.'
        updatedAt: '2023-04-04T07:24:04.090Z'
      numEdits: 3
      reactions: []
    id: 642bcb7f8b820fae7323b0d6
    type: comment
  author: ZProphete
  content: 'Let me answer !

    Guernika models are a little different, because the author implemented features
    before apple''s official ones (yea, big brain), so it diverged a bit.

    While Mochi refers to Apple official implementation (stuck at t2i/i2i as today),
    it lacks the new features like inpainting, Textual Inversion, ControlNet, Prompt
    weighting etc...

    Transfering model into Guernika may work with text2image, not the other way around,
    Apple/Mochi has to catch up xD


    You also have graphical user interface for converting models simply, you can see
    amazing updates pop often.


    - In my honest personal opinion, HD upscale is possible (and wanted), I looked
    up for myself but I found little sample codes online and I wouldn''t leech a concurrent
    app code...

    If that''s all you needed from cross compatibility, I bet it Upscale will come
    any time soon.


    - For iOS devices, you MUST have it chunked, no matter what, I usually chunk every
    time for my iPad/Mac usage, I guess the chunking is supposed to swap chunks one
    after another thus not fill the whole ram.


    Welcome to the gang.'
  created_at: 2023-04-04 06:02:23+00:00
  edited: true
  hidden: false
  id: 642bcb7f8b820fae7323b0d6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e89ce2aaf4a7c493e7e3bc0dcd65ffe2.svg
      fullname: Jethro Tan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jettan
      type: user
    createdAt: '2023-04-04T07:31:25.000Z'
    data:
      edited: false
      editors:
      - jettan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e89ce2aaf4a7c493e7e3bc0dcd65ffe2.svg
          fullname: Jethro Tan
          isHf: false
          isPro: false
          name: jettan
          type: user
        html: '<p>Thanks for the prompt and clear response!</p>

          <p>Interesting! Looking forward to updates here then.<br>I''ll try chunked
          on iPad then (on macbook air M2 I have had no problems without chunks),
          but did not have luck on iPad.</p>

          <p>And thanks for the warm welcome. Glad to be here and experience the next
          wave of AI first hand.</p>

          '
        raw: 'Thanks for the prompt and clear response!


          Interesting! Looking forward to updates here then.

          I''ll try chunked on iPad then (on macbook air M2 I have had no problems
          without chunks), but did not have luck on iPad.


          And thanks for the warm welcome. Glad to be here and experience the next
          wave of AI first hand.'
        updatedAt: '2023-04-04T07:31:25.389Z'
      numEdits: 0
      reactions: []
    id: 642bd24d8b820fae7323eb4f
    type: comment
  author: jettan
  content: 'Thanks for the prompt and clear response!


    Interesting! Looking forward to updates here then.

    I''ll try chunked on iPad then (on macbook air M2 I have had no problems without
    chunks), but did not have luck on iPad.


    And thanks for the warm welcome. Glad to be here and experience the next wave
    of AI first hand.'
  created_at: 2023-04-04 06:31:25+00:00
  edited: false
  hidden: false
  id: 642bd24d8b820fae7323eb4f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/29d17cafebc2de883588964706360101.svg
      fullname: ZProphete
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ZProphete
      type: user
    createdAt: '2023-04-04T07:54:08.000Z'
    data:
      edited: true
      editors:
      - ZProphete
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/29d17cafebc2de883588964706360101.svg
          fullname: ZProphete
          isHf: false
          isPro: false
          name: ZProphete
          type: user
        html: "<p>Here's how it works when the model is chunked :</p>\n<ul>\n<li>on\
          \ iOS devices it does the swap-thing</li>\n<li>on Mac, both chunks are loaded\
          \ into memory<br>So you can have the chunked model for both iPad/Mac, so\
          \ everytime I need a 512x512 I always chunk/AllComputeMode and have a sync\
          \ to play with.<br>Edit : uncheck \"Chunk U-net\" if you want to make it\
          \ Mac-only, checked is for both</li>\n</ul>\n<p><span data-props=\"{&quot;user&quot;:&quot;GuiyeC&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/GuiyeC\"\
          >@<span class=\"underline\">GuiyeC</span></a></span>\n\n\t</span></span>\
          \ must confirm everything tho, I'm just part of the fanbase :D</p>\n<p>Have\
          \ fun :)</p>\n"
        raw: 'Here''s how it works when the model is chunked :

          - on iOS devices it does the swap-thing

          - on Mac, both chunks are loaded into memory

          So you can have the chunked model for both iPad/Mac, so everytime I need
          a 512x512 I always chunk/AllComputeMode and have a sync to play with.

          Edit : uncheck "Chunk U-net" if you want to make it Mac-only, checked is
          for both


          @GuiyeC must confirm everything tho, I''m just part of the fanbase :D


          Have fun :)'
        updatedAt: '2023-04-04T08:24:20.792Z'
      numEdits: 1
      reactions: []
    id: 642bd7a04bfd1c42df9c30ba
    type: comment
  author: ZProphete
  content: 'Here''s how it works when the model is chunked :

    - on iOS devices it does the swap-thing

    - on Mac, both chunks are loaded into memory

    So you can have the chunked model for both iPad/Mac, so everytime I need a 512x512
    I always chunk/AllComputeMode and have a sync to play with.

    Edit : uncheck "Chunk U-net" if you want to make it Mac-only, checked is for both


    @GuiyeC must confirm everything tho, I''m just part of the fanbase :D


    Have fun :)'
  created_at: 2023-04-04 06:54:08+00:00
  edited: true
  hidden: false
  id: 642bd7a04bfd1c42df9c30ba
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e89ce2aaf4a7c493e7e3bc0dcd65ffe2.svg
      fullname: Jethro Tan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jettan
      type: user
    createdAt: '2023-04-04T09:02:37.000Z'
    data:
      edited: false
      editors:
      - jettan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e89ce2aaf4a7c493e7e3bc0dcd65ffe2.svg
          fullname: Jethro Tan
          isHf: false
          isPro: false
          name: jettan
          type: user
        html: '<p>I got it working as you described. Thanks!<br>Sadly I was a bit
          ambitious for memory constraints trying to get it working on an iPad mini
          6 (4GB RAM) and even chunked could not help this case...<br>It''s really
          just for testing/fun purposes though, as I do have other compute resources
          available. Appreciate the help.</p>

          '
        raw: 'I got it working as you described. Thanks!

          Sadly I was a bit ambitious for memory constraints trying to get it working
          on an iPad mini 6 (4GB RAM) and even chunked could not help this case...

          It''s really just for testing/fun purposes though, as I do have other compute
          resources available. Appreciate the help.'
        updatedAt: '2023-04-04T09:02:37.061Z'
      numEdits: 0
      reactions: []
    id: 642be7ad763db0f10aca2048
    type: comment
  author: jettan
  content: 'I got it working as you described. Thanks!

    Sadly I was a bit ambitious for memory constraints trying to get it working on
    an iPad mini 6 (4GB RAM) and even chunked could not help this case...

    It''s really just for testing/fun purposes though, as I do have other compute
    resources available. Appreciate the help.'
  created_at: 2023-04-04 08:02:37+00:00
  edited: false
  hidden: false
  id: 642be7ad763db0f10aca2048
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e89ce2aaf4a7c493e7e3bc0dcd65ffe2.svg
      fullname: Jethro Tan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jettan
      type: user
    createdAt: '2023-04-04T12:23:59.000Z'
    data:
      edited: false
      editors:
      - jettan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e89ce2aaf4a7c493e7e3bc0dcd65ffe2.svg
          fullname: Jethro Tan
          isHf: false
          isPro: false
          name: jettan
          type: user
        html: '<p>It looks like in CoreML models they have all kinds of upscaler models
          converted already: <a rel="nofollow" href="https://github.com/john-rocky/CoreML-Models">https://github.com/john-rocky/CoreML-Models</a><br>I
          might try something myself to see how it works. Coming from Python, Swift
          is very new to me.</p>

          '
        raw: 'It looks like in CoreML models they have all kinds of upscaler models
          converted already: https://github.com/john-rocky/CoreML-Models

          I might try something myself to see how it works. Coming from Python, Swift
          is very new to me.'
        updatedAt: '2023-04-04T12:23:59.856Z'
      numEdits: 0
      reactions: []
    id: 642c16dfdb95af333d1a6d14
    type: comment
  author: jettan
  content: 'It looks like in CoreML models they have all kinds of upscaler models
    converted already: https://github.com/john-rocky/CoreML-Models

    I might try something myself to see how it works. Coming from Python, Swift is
    very new to me.'
  created_at: 2023-04-04 11:23:59+00:00
  edited: false
  hidden: false
  id: 642c16dfdb95af333d1a6d14
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-04-04T17:43:36.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;jettan&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/jettan\">@<span class=\"\
          underline\">jettan</span></a></span>\n\n\t</span></span> hey! thank you\
          \ for your comments and thank you too <span data-props=\"{&quot;user&quot;:&quot;ZProphete&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ZProphete\"\
          >@<span class=\"underline\">ZProphete</span></a></span>\n\n\t</span></span>\
          \ for helping here.</p>\n<p>I got good news on the model compatibility,\
          \ I created a Pull Request in Apple\u2019s <a rel=\"nofollow\" href=\"https://github.com/apple/ml-stable-diffusion/pull/145\"\
          >main repository</a> and this should bring compatibility to newer models\
          \ converted using Apple\u2019s official repository, which is the one used\
          \ in the instructions you shared. But yes, the reason was pretty much what\
          \ ZProphete explained, img2img implementation was a bit different and so\
          \ the enconder module would be different.</p>\n<p>I have the upscaling in\
          \ my TODO list, should be easy to implement but there are a few apps that\
          \ do this already like <a rel=\"nofollow\" href=\"https://upscalo.com\"\
          >Upscalo</a> and that\u2019s why I didn\u2019t hurry.</p>\n<p>About the\
          \ chunks, I understand that unchunked models should be faster in macOS,\
          \ the step is calculated at once in the whole Unet instead of having it\
          \ calculated in two and then joined, I\u2019m not sure how noticeable the\
          \ difference is. In iOS, there is some loading/unloading of resources as\
          \ ZProphete explained, and I don\u2019t think the unchunked model would\
          \ work, I have not tested this thoroughly as I simply don\u2019t have one\
          \ of the higher end iPad Pros, I would recommend testing what works best\
          \ on your device.</p>\n"
        raw: "@jettan hey! thank you for your comments and thank you too @ZProphete\
          \ for helping here.\n\nI got good news on the model compatibility, I created\
          \ a Pull Request in Apple\u2019s [main repository](https://github.com/apple/ml-stable-diffusion/pull/145)\
          \ and this should bring compatibility to newer models converted using Apple\u2019\
          s official repository, which is the one used in the instructions you shared.\
          \ But yes, the reason was pretty much what ZProphete explained, img2img\
          \ implementation was a bit different and so the enconder module would be\
          \ different.\n\nI have the upscaling in my TODO list, should be easy to\
          \ implement but there are a few apps that do this already like [Upscalo](https://upscalo.com)\
          \ and that\u2019s why I didn\u2019t hurry.\n\nAbout the chunks, I understand\
          \ that unchunked models should be faster in macOS, the step is calculated\
          \ at once in the whole Unet instead of having it calculated in two and then\
          \ joined, I\u2019m not sure how noticeable the difference is. In iOS, there\
          \ is some loading/unloading of resources as ZProphete explained, and I don\u2019\
          t think the unchunked model would work, I have not tested this thoroughly\
          \ as I simply don\u2019t have one of the higher end iPad Pros, I would recommend\
          \ testing what works best on your device."
        updatedAt: '2023-04-04T17:43:36.219Z'
      numEdits: 0
      reactions: []
    id: 642c61c8c811cd1de5ba5a5a
    type: comment
  author: GuiyeC
  content: "@jettan hey! thank you for your comments and thank you too @ZProphete\
    \ for helping here.\n\nI got good news on the model compatibility, I created a\
    \ Pull Request in Apple\u2019s [main repository](https://github.com/apple/ml-stable-diffusion/pull/145)\
    \ and this should bring compatibility to newer models converted using Apple\u2019\
    s official repository, which is the one used in the instructions you shared. But\
    \ yes, the reason was pretty much what ZProphete explained, img2img implementation\
    \ was a bit different and so the enconder module would be different.\n\nI have\
    \ the upscaling in my TODO list, should be easy to implement but there are a few\
    \ apps that do this already like [Upscalo](https://upscalo.com) and that\u2019\
    s why I didn\u2019t hurry.\n\nAbout the chunks, I understand that unchunked models\
    \ should be faster in macOS, the step is calculated at once in the whole Unet\
    \ instead of having it calculated in two and then joined, I\u2019m not sure how\
    \ noticeable the difference is. In iOS, there is some loading/unloading of resources\
    \ as ZProphete explained, and I don\u2019t think the unchunked model would work,\
    \ I have not tested this thoroughly as I simply don\u2019t have one of the higher\
    \ end iPad Pros, I would recommend testing what works best on your device."
  created_at: 2023-04-04 16:43:36+00:00
  edited: false
  hidden: false
  id: 642c61c8c811cd1de5ba5a5a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e89ce2aaf4a7c493e7e3bc0dcd65ffe2.svg
      fullname: Jethro Tan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jettan
      type: user
    createdAt: '2023-04-05T08:34:21.000Z'
    data:
      edited: false
      editors:
      - jettan
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e89ce2aaf4a7c493e7e3bc0dcd65ffe2.svg
          fullname: Jethro Tan
          isHf: false
          isPro: false
          name: jettan
          type: user
        html: '<p>Thanks for the response! </p>

          <p>Wow, what a timely PR. Looking forward to test it out between different
          apps and all the updates you may add.<br>For now I have given up on running
          models on my iOS devices as they are a bit outdated. Will revisit this some
          day when I decide to upgrade my iPhone or so, but for now will stick to
          macOS variants. Thanks for the information.</p>

          <p>If there is anything that needs testing after a release, please let me
          know and I''d be more than happy to test out as user.</p>

          '
        raw: "Thanks for the response! \n\nWow, what a timely PR. Looking forward\
          \ to test it out between different apps and all the updates you may add.\n\
          For now I have given up on running models on my iOS devices as they are\
          \ a bit outdated. Will revisit this some day when I decide to upgrade my\
          \ iPhone or so, but for now will stick to macOS variants. Thanks for the\
          \ information.\n\nIf there is anything that needs testing after a release,\
          \ please let me know and I'd be more than happy to test out as user."
        updatedAt: '2023-04-05T08:34:21.791Z'
      numEdits: 0
      reactions: []
    id: 642d328d9c58e9c723d5ea82
    type: comment
  author: jettan
  content: "Thanks for the response! \n\nWow, what a timely PR. Looking forward to\
    \ test it out between different apps and all the updates you may add.\nFor now\
    \ I have given up on running models on my iOS devices as they are a bit outdated.\
    \ Will revisit this some day when I decide to upgrade my iPhone or so, but for\
    \ now will stick to macOS variants. Thanks for the information.\n\nIf there is\
    \ anything that needs testing after a release, please let me know and I'd be more\
    \ than happy to test out as user."
  created_at: 2023-04-05 07:34:21+00:00
  edited: false
  hidden: false
  id: 642d328d9c58e9c723d5ea82
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: Guernika/CoreMLStableDiffusion
repo_type: model
status: open
target_branch: null
title: Model conversion differences VS Mochi Diffusion and future improvements?
