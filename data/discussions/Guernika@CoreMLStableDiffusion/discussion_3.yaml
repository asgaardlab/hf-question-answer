!!python/object:huggingface_hub.community.DiscussionWithDetails
author: blocksgh
conflicting_files: null
created_at: 2023-01-03 18:41:17+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/675658dc9332d4b082146afa1d62483d.svg
      fullname: Bloc Gha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: blocksgh
      type: user
    createdAt: '2023-01-03T18:41:17.000Z'
    data:
      edited: false
      editors:
      - blocksgh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/675658dc9332d4b082146afa1d62483d.svg
          fullname: Bloc Gha
          isHf: false
          isPro: false
          name: blocksgh
          type: user
        html: "<p>M1 Mac Air, 8gb, os 13.1, xcode 14.2<br>CPU and NE</p>\n<p>Two different\
          \ errors from two different models</p>\n<ul>\n<li>1 (dreamLikeSamKuvshino_ckpt.ckpt)<br>An\
          \ error occurred during conversion<br>Traceback (most recent call last):<br>File\
          \ \"python_coreml_stable_diffusion/torch2coreml_ui.py\", line 254, in convert_model<br>File\
          \ \"python_coreml_stable_diffusion/torch2coreml.py\", line 897, in main<br>File\
          \ \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 650, in load_from_ckpt<br>KeyError: 'state_dict'</li>\n</ul>\n<p>-2\
          \  (v1-5-pruned-emaonly.ckpt)<br>An error occurred during conversion<br>Traceback\
          \ (most recent call last):<br>File \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
          , line 254, in convert_model<br>File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 897, in main<br>File \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 649, in load_from_ckpt<br>File \"torch/serialization.py\", line 789,\
          \ in load<br>return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)<br>File\
          \ \"torch/serialization.py\", line 1131, in _load<br>result = unpickler.load()<br>File\
          \ \"torch/serialization.py\", line 1124, in find_class<br>return super().find_class(mod_name,\
          \ name)<br>ModuleNotFoundError: No module named 'pytorch_lightning'\n </p>\n"
        raw: "M1 Mac Air, 8gb, os 13.1, xcode 14.2\r\nCPU and NE\r\n\r\nTwo different\
          \ errors from two different models\r\n\r\n- 1 (dreamLikeSamKuvshino_ckpt.ckpt)\r\
          \nAn error occurred during conversion\r\nTraceback (most recent call last):\r\
          \nFile \"python_coreml_stable_diffusion/torch2coreml_ui.py\", line 254,\
          \ in convert_model\r\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 897, in main\r\nFile \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 650, in load_from_ckpt\r\nKeyError: 'state_dict'\r\n\r\n\r\n-2  (v1-5-pruned-emaonly.ckpt)\r\
          \nAn error occurred during conversion\r\nTraceback (most recent call last):\r\
          \nFile \"python_coreml_stable_diffusion/torch2coreml_ui.py\", line 254,\
          \ in convert_model\r\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 897, in main\r\nFile \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 649, in load_from_ckpt\r\nFile \"torch/serialization.py\", line 789,\
          \ in load\r\nreturn _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\r\
          \nFile \"torch/serialization.py\", line 1131, in _load\r\nresult = unpickler.load()\r\
          \nFile \"torch/serialization.py\", line 1124, in find_class\r\nreturn super().find_class(mod_name,\
          \ name)\r\nModuleNotFoundError: No module named 'pytorch_lightning'\r\n "
        updatedAt: '2023-01-03T18:41:17.874Z'
      numEdits: 0
      reactions: []
    id: 63b476cd58f367a212c0b9fc
    type: comment
  author: blocksgh
  content: "M1 Mac Air, 8gb, os 13.1, xcode 14.2\r\nCPU and NE\r\n\r\nTwo different\
    \ errors from two different models\r\n\r\n- 1 (dreamLikeSamKuvshino_ckpt.ckpt)\r\
    \nAn error occurred during conversion\r\nTraceback (most recent call last):\r\n\
    File \"python_coreml_stable_diffusion/torch2coreml_ui.py\", line 254, in convert_model\r\
    \nFile \"python_coreml_stable_diffusion/torch2coreml.py\", line 897, in main\r\
    \nFile \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
    , line 650, in load_from_ckpt\r\nKeyError: 'state_dict'\r\n\r\n\r\n-2  (v1-5-pruned-emaonly.ckpt)\r\
    \nAn error occurred during conversion\r\nTraceback (most recent call last):\r\n\
    File \"python_coreml_stable_diffusion/torch2coreml_ui.py\", line 254, in convert_model\r\
    \nFile \"python_coreml_stable_diffusion/torch2coreml.py\", line 897, in main\r\
    \nFile \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
    , line 649, in load_from_ckpt\r\nFile \"torch/serialization.py\", line 789, in\
    \ load\r\nreturn _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\r\
    \nFile \"torch/serialization.py\", line 1131, in _load\r\nresult = unpickler.load()\r\
    \nFile \"torch/serialization.py\", line 1124, in find_class\r\nreturn super().find_class(mod_name,\
    \ name)\r\nModuleNotFoundError: No module named 'pytorch_lightning'\r\n "
  created_at: 2023-01-03 18:41:17+00:00
  edited: false
  hidden: false
  id: 63b476cd58f367a212c0b9fc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-03T21:00:46.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: '<p>Hey! Thanks for the detailed feedback I just uploaded a new version
          of the converter that hopefully fixes both those problems. Could you check
          it?</p>

          '
        raw: Hey! Thanks for the detailed feedback I just uploaded a new version of
          the converter that hopefully fixes both those problems. Could you check
          it?
        updatedAt: '2023-01-03T21:00:46.427Z'
      numEdits: 0
      reactions: []
    id: 63b4977ea74bd39bf1f3428b
    type: comment
  author: GuiyeC
  content: Hey! Thanks for the detailed feedback I just uploaded a new version of
    the converter that hopefully fixes both those problems. Could you check it?
  created_at: 2023-01-03 21:00:46+00:00
  edited: false
  hidden: false
  id: 63b4977ea74bd39bf1f3428b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/675658dc9332d4b082146afa1d62483d.svg
      fullname: Bloc Gha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: blocksgh
      type: user
    createdAt: '2023-01-03T23:36:44.000Z'
    data:
      edited: false
      editors:
      - blocksgh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/675658dc9332d4b082146afa1d62483d.svg
          fullname: Bloc Gha
          isHf: false
          isPro: false
          name: blocksgh
          type: user
        html: '<p>Ok i will redownload and try again.</p>

          <p>Another issue though...<br>with 8gb macs, Sometimes conversion fails</p>

          <p>With python scrips can convert each component one at a time, not together</p>

          <p>eg<br><code>python -m ....... --convert-vae-decoder  --model-version
          .... --convert-unet ..... --model-version  ....</code></p>

          <p>Is this something you can do from your end ?</p>

          <p>see this link<br><a rel="nofollow" href="https://github.com/godly-devotion/mochi-diffusion/discussions/43">https://github.com/godly-devotion/mochi-diffusion/discussions/43</a></p>

          '
        raw: "Ok i will redownload and try again.\n\nAnother issue though... \nwith\
          \ 8gb macs, Sometimes conversion fails\n\nWith python scrips can convert\
          \ each component one at a time, not together\n\neg\n`python -m ....... --convert-vae-decoder\
          \  --model-version .... --convert-unet ..... --model-version  ....`\n\n\
          Is this something you can do from your end ?\n\nsee this link\nhttps://github.com/godly-devotion/mochi-diffusion/discussions/43"
        updatedAt: '2023-01-03T23:36:44.422Z'
      numEdits: 0
      reactions: []
    id: 63b4bc0ca25dd8a860b6a1bd
    type: comment
  author: blocksgh
  content: "Ok i will redownload and try again.\n\nAnother issue though... \nwith\
    \ 8gb macs, Sometimes conversion fails\n\nWith python scrips can convert each\
    \ component one at a time, not together\n\neg\n`python -m ....... --convert-vae-decoder\
    \  --model-version .... --convert-unet ..... --model-version  ....`\n\nIs this\
    \ something you can do from your end ?\n\nsee this link\nhttps://github.com/godly-devotion/mochi-diffusion/discussions/43"
  created_at: 2023-01-03 23:36:44+00:00
  edited: false
  hidden: false
  id: 63b4bc0ca25dd8a860b6a1bd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-03T23:41:18.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: '<p>Yes, when using the Guernika Model Converter you can select a single
          module at a time and it will be the same as with the python scrtipt.</p>

          '
        raw: Yes, when using the Guernika Model Converter you can select a single
          module at a time and it will be the same as with the python scrtipt.
        updatedAt: '2023-01-03T23:41:18.043Z'
      numEdits: 0
      reactions: []
    id: 63b4bd1ea25dd8a860b6ad2a
    type: comment
  author: GuiyeC
  content: Yes, when using the Guernika Model Converter you can select a single module
    at a time and it will be the same as with the python scrtipt.
  created_at: 2023-01-03 23:41:18+00:00
  edited: false
  hidden: false
  id: 63b4bd1ea25dd8a860b6ad2a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-04T01:30:54.000Z'
    data:
      edited: true
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: "<p>I'm getting the following error when trying to convert a 1.5 model\
          \ checkpoint with Guernika Model Converter: </p>\n<blockquote>\n<p>An error\
          \ occurred during conversion<br>Traceback (most recent call last):<br>File\
          \ \"shutil.py\", line 791, in move<br>FileNotFoundError: [Errno 2] No such\
          \ file or directory: '/Users/michaelangelo/Desktop/Astria SKS man (v1.5)/Stable_Diffusion_version_Astria\
          \ SKS man (v1.5)_text_encoder.mlmodelc' -&gt; '/Users/michaelangelo/Desktop/Astria\
          \ SKS man (v1.5)/TextEncoder.mlmodelc'</p>\n<p>During handling of the above\
          \ exception, another exception occurred:</p>\n<p>Traceback (most recent\
          \ call last):<br>File \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
          , line 254, in convert_model<br>File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 932, in main<br>File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 205, in bundle_resources_for_guernika<br>File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 180, in _compile_coreml_model<br>File \"shutil.py\", line 811, in\
          \ move<br>File \"shutil.py\", line 435, in copy2<br>File \"shutil.py\",\
          \ line 264, in copyfile<br>FileNotFoundError: [Errno 2] No such file or\
          \ directory: '/Users/michaelangelo/Desktop/Astria SKS man (v1.5)/Stable_Diffusion_version_Astria\
          \ SKS man (v1.5)_text_encoder.mlmodelc'</p>\n</blockquote>\n<p>where <em>Desktop</em>\
          \ was designated as the Save To: directory for <em>Astria SKS man.ckpt</em>\
          \ \u2026</p>\n"
        raw: "I'm getting the following error when trying to convert a 1.5 model checkpoint\
          \ with Guernika Model Converter: \n\n> An error occurred during conversion\n\
          Traceback (most recent call last):\nFile \"shutil.py\", line 791, in move\n\
          FileNotFoundError: [Errno 2] No such file or directory: '/Users/michaelangelo/Desktop/Astria\
          \ SKS man (v1.5)/Stable_Diffusion_version_Astria SKS man (v1.5)_text_encoder.mlmodelc'\
          \ -> '/Users/michaelangelo/Desktop/Astria SKS man (v1.5)/TextEncoder.mlmodelc'\n\
          >\n> During handling of the above exception, another exception occurred:\n\
          >\n> Traceback (most recent call last):\nFile \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
          , line 254, in convert_model\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 932, in main\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 205, in bundle_resources_for_guernika\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 180, in _compile_coreml_model\nFile \"shutil.py\", line 811, in move\n\
          File \"shutil.py\", line 435, in copy2\nFile \"shutil.py\", line 264, in\
          \ copyfile\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/michaelangelo/Desktop/Astria\
          \ SKS man (v1.5)/Stable_Diffusion_version_Astria SKS man (v1.5)_text_encoder.mlmodelc'\n\
          \nwhere _Desktop_ was designated as the Save To: directory for _Astria SKS\
          \ man.ckpt_ \u2026"
        updatedAt: '2023-01-04T16:42:42.950Z'
      numEdits: 4
      reactions: []
    id: 63b4d6cea25dd8a860b7c687
    type: comment
  author: Michaelangelo
  content: "I'm getting the following error when trying to convert a 1.5 model checkpoint\
    \ with Guernika Model Converter: \n\n> An error occurred during conversion\nTraceback\
    \ (most recent call last):\nFile \"shutil.py\", line 791, in move\nFileNotFoundError:\
    \ [Errno 2] No such file or directory: '/Users/michaelangelo/Desktop/Astria SKS\
    \ man (v1.5)/Stable_Diffusion_version_Astria SKS man (v1.5)_text_encoder.mlmodelc'\
    \ -> '/Users/michaelangelo/Desktop/Astria SKS man (v1.5)/TextEncoder.mlmodelc'\n\
    >\n> During handling of the above exception, another exception occurred:\n>\n\
    > Traceback (most recent call last):\nFile \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
    , line 254, in convert_model\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
    , line 932, in main\nFile \"python_coreml_stable_diffusion/torch2coreml.py\",\
    \ line 205, in bundle_resources_for_guernika\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
    , line 180, in _compile_coreml_model\nFile \"shutil.py\", line 811, in move\n\
    File \"shutil.py\", line 435, in copy2\nFile \"shutil.py\", line 264, in copyfile\n\
    FileNotFoundError: [Errno 2] No such file or directory: '/Users/michaelangelo/Desktop/Astria\
    \ SKS man (v1.5)/Stable_Diffusion_version_Astria SKS man (v1.5)_text_encoder.mlmodelc'\n\
    \nwhere _Desktop_ was designated as the Save To: directory for _Astria SKS man.ckpt_\
    \ \u2026"
  created_at: 2023-01-04 01:30:54+00:00
  edited: true
  hidden: false
  id: 63b4d6cea25dd8a860b7c687
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/675658dc9332d4b082146afa1d62483d.svg
      fullname: Bloc Gha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: blocksgh
      type: user
    createdAt: '2023-01-04T16:45:38.000Z'
    data:
      edited: false
      editors:
      - blocksgh
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/675658dc9332d4b082146afa1d62483d.svg
          fullname: Bloc Gha
          isHf: false
          isPro: false
          name: blocksgh
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;GuiyeC&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/GuiyeC\">@<span class=\"\
          underline\">GuiyeC</span></a></span>\n\n\t</span></span> , updated version\
          \ succesfully converted the  first model above. Thanks</p>\n<p>Will try\
          \ with more models and update you.</p>\n"
        raw: '@GuiyeC , updated version succesfully converted the  first model above.
          Thanks


          Will try with more models and update you.'
        updatedAt: '2023-01-04T16:45:38.730Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - GuiyeC
    id: 63b5ad329d50c1463c591213
    type: comment
  author: blocksgh
  content: '@GuiyeC , updated version succesfully converted the  first model above.
    Thanks


    Will try with more models and update you.'
  created_at: 2023-01-04 16:45:38+00:00
  edited: false
  hidden: false
  id: 63b5ad329d50c1463c591213
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-04T17:07:42.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Michaelangelo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Michaelangelo\"\
          >@<span class=\"underline\">Michaelangelo</span></a></span>\n\n\t</span></span>\
          \ I'm not sure why you got that error, were you able to convert it or are\
          \ you getting the same error every time? were you able to convert any other\
          \ models?</p>\n"
        raw: '@Michaelangelo I''m not sure why you got that error, were you able to
          convert it or are you getting the same error every time? were you able to
          convert any other models?'
        updatedAt: '2023-01-04T17:07:42.832Z'
      numEdits: 0
      reactions: []
    id: 63b5b25e9d50c1463c5979ef
    type: comment
  author: GuiyeC
  content: '@Michaelangelo I''m not sure why you got that error, were you able to
    convert it or are you getting the same error every time? were you able to convert
    any other models?'
  created_at: 2023-01-04 17:07:42+00:00
  edited: false
  hidden: false
  id: 63b5b25e9d50c1463c5979ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-04T17:34:52.000Z'
    data:
      edited: true
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: "<p>Same every time. No other models, latest error with another model:\
          \ </p>\n<blockquote>\n<p>An error occurred during conversion<br>Traceback\
          \ (most recent call last):<br>File \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
          , line 254, in convert_model<br>File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 897, in main<br>File \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 650, in load_from_ckpt<br>KeyError: 'state_dict'</p>\n</blockquote>\n\
          <p>when trying to convert local 1.5 checkpoint and save to <em>Desktop</em>\
          \ ...</p>\n<p>and here's the error from trying to convert 1.4 official checkpoint:</p>\n\
          <blockquote>\n<p>An error occurred during conversion<br>Traceback (most\
          \ recent call last):<br>File \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
          , line 254, in convert_model<br>File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 897, in main<br>File \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 649, in load_from_ckpt<br>File \"torch/serialization.py\", line 789,\
          \ in load<br>return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)<br>File\
          \ \"torch/serialization.py\", line 1131, in _load<br>result = unpickler.load()<br>File\
          \ \"torch/serialization.py\", line 1124, in find_class<br>return super().find_class(mod_name,\
          \ name)<br>ModuleNotFoundError: No module named 'pytorch_lightning'</p>\n\
          </blockquote>\n<p>\u2014 Pytorch 1.13.1 is already installed and up-to-date.</p>\n"
        raw: "Same every time. No other models, latest error with another model: \n\
          \n> An error occurred during conversion\nTraceback (most recent call last):\n\
          File \"python_coreml_stable_diffusion/torch2coreml_ui.py\", line 254, in\
          \ convert_model\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 897, in main\nFile \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 650, in load_from_ckpt\nKeyError: 'state_dict'\n\nwhen trying to\
          \ convert local 1.5 checkpoint and save to _Desktop_ ...\n\nand here's the\
          \ error from trying to convert 1.4 official checkpoint:\n\n>An error occurred\
          \ during conversion\nTraceback (most recent call last):\nFile \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
          , line 254, in convert_model\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 897, in main\nFile \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 649, in load_from_ckpt\nFile \"torch/serialization.py\", line 789,\
          \ in load\nreturn _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n\
          File \"torch/serialization.py\", line 1131, in _load\nresult = unpickler.load()\n\
          File \"torch/serialization.py\", line 1124, in find_class\nreturn super().find_class(mod_name,\
          \ name)\nModuleNotFoundError: No module named 'pytorch_lightning'\n\n\u2014\
          \ Pytorch 1.13.1 is already installed and up-to-date."
        updatedAt: '2023-01-04T17:38:17.470Z'
      numEdits: 4
      reactions: []
    id: 63b5b8bc58b5e43bddee63ad
    type: comment
  author: Michaelangelo
  content: "Same every time. No other models, latest error with another model: \n\n\
    > An error occurred during conversion\nTraceback (most recent call last):\nFile\
    \ \"python_coreml_stable_diffusion/torch2coreml_ui.py\", line 254, in convert_model\n\
    File \"python_coreml_stable_diffusion/torch2coreml.py\", line 897, in main\nFile\
    \ \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
    , line 650, in load_from_ckpt\nKeyError: 'state_dict'\n\nwhen trying to convert\
    \ local 1.5 checkpoint and save to _Desktop_ ...\n\nand here's the error from\
    \ trying to convert 1.4 official checkpoint:\n\n>An error occurred during conversion\n\
    Traceback (most recent call last):\nFile \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
    , line 254, in convert_model\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
    , line 897, in main\nFile \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
    , line 649, in load_from_ckpt\nFile \"torch/serialization.py\", line 789, in load\n\
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n\
    File \"torch/serialization.py\", line 1131, in _load\nresult = unpickler.load()\n\
    File \"torch/serialization.py\", line 1124, in find_class\nreturn super().find_class(mod_name,\
    \ name)\nModuleNotFoundError: No module named 'pytorch_lightning'\n\n\u2014 Pytorch\
    \ 1.13.1 is already installed and up-to-date."
  created_at: 2023-01-04 17:34:52+00:00
  edited: true
  hidden: false
  id: 63b5b8bc58b5e43bddee63ad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-04T23:21:50.000Z'
    data:
      edited: false
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: "<p>Latest instance Guernika model converter triggered an <em>out of\
          \ memory</em> error and was taking up 160 GB of data before restarting \u2026\
          </p>\n"
        raw: "Latest instance Guernika model converter triggered an _out of memory_\
          \ error and was taking up 160 GB of data before restarting \u2026"
        updatedAt: '2023-01-04T23:21:50.436Z'
      numEdits: 0
      reactions: []
    id: 63b60a0e58b5e43bddf43461
    type: comment
  author: Michaelangelo
  content: "Latest instance Guernika model converter triggered an _out of memory_\
    \ error and was taking up 160 GB of data before restarting \u2026"
  created_at: 2023-01-04 23:21:50+00:00
  edited: false
  hidden: false
  id: 63b60a0e58b5e43bddf43461
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-04T23:47:48.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Michaelangelo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Michaelangelo\"\
          >@<span class=\"underline\">Michaelangelo</span></a></span>\n\n\t</span></span>\
          \ 160GB of disk space? I've seen it take tens of GBs but that is way too\
          \ much, were you trying to convert one of the official models?<br>The model\
          \ converter is actually just a wrapper of the python scripts, if you want\
          \ to test with better output you can right click the app \"Show Package\
          \ Contents\" then go to Contents -&gt; MacOS and double click the \"Guernika\
          \ Model Converter\" there, it should launch with a terminal window showing\
          \ all the output of the python scripts, could be helpful.</p>\n"
        raw: "@Michaelangelo 160GB of disk space? I've seen it take tens of GBs but\
          \ that is way too much, were you trying to convert one of the official models?\
          \ \nThe model converter is actually just a wrapper of the python scripts,\
          \ if you want to test with better output you can right click the app \"\
          Show Package Contents\" then go to Contents -> MacOS and double click the\
          \ \"Guernika Model Converter\" there, it should launch with a terminal window\
          \ showing all the output of the python scripts, could be helpful."
        updatedAt: '2023-01-04T23:47:48.279Z'
      numEdits: 0
      reactions: []
    id: 63b61024c5a5432fd8603b6a
    type: comment
  author: GuiyeC
  content: "@Michaelangelo 160GB of disk space? I've seen it take tens of GBs but\
    \ that is way too much, were you trying to convert one of the official models?\
    \ \nThe model converter is actually just a wrapper of the python scripts, if you\
    \ want to test with better output you can right click the app \"Show Package Contents\"\
    \ then go to Contents -> MacOS and double click the \"Guernika Model Converter\"\
    \ there, it should launch with a terminal window showing all the output of the\
    \ python scripts, could be helpful."
  created_at: 2023-01-04 23:47:48+00:00
  edited: false
  hidden: false
  id: 63b61024c5a5432fd8603b6a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/675658dc9332d4b082146afa1d62483d.svg
      fullname: Bloc Gha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: blocksgh
      type: user
    createdAt: '2023-01-09T11:24:31.000Z'
    data:
      status: closed
    id: 63bbf96f3c229a497ba6de3f
    type: status-change
  author: blocksgh
  created_at: 2023-01-09 11:24:31+00:00
  id: 63bbf96f3c229a497ba6de3f
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-01-09T15:00:17.000Z'
    data:
      edited: false
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;GuiyeC&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/GuiyeC\">@<span class=\"\
          underline\">GuiyeC</span></a></span>\n\n\t</span></span>  \u2014  <em>Thanks\
          \ for the tips. I've tried converting several official models as well as\
          \ custom models, such as Analog Diffusion.</em> </p>\n<p><em>Attached are\
          \ the errors resulting from attempted conversion of official release versions\
          \ for base <a href=\"https://huggingface.co/Guernika/CoreMLStableDiffusion/discussions/3#63b5b8bc58b5e43bddee63ad\"\
          >Model 1.4</a> and the official release for base <a href=\"https://huggingface.co/Guernika/CoreMLStableDiffusion/discussions/3#63b4d6cea25dd8a860b7c687\"\
          >Model 1.5</a>.</em></p>\n<p><em>With Protogen-v5.3, the conversion script\
          \ returns an empty output folder where the models should have been saved,\
          \ accompanied by the following error report on exit following ten to fifteen\
          \ minutes of active processing:</em></p>\n<pre><code>An error occurred during\
          \ conversion\nTraceback (most recent call last):\nFile \"shutil.py\", line\
          \ 791, in move\nFileNotFoundError: [Errno 2] No such file or directory:\
          \ '/Users/michaelangelo/Downloads/Converted ORIGINAL/Protogen-v5.3-Photorealism/Stable_Diffusion_version_Protogen-v5.3-Photorealism_text_encoder.mlmodelc'\
          \ -&gt; '/Users/michaelangelo/Downloads/Converted ORIGINAL/Protogen-v5.3-Photorealism/TextEncoder.mlmodelc'\n\
          \nDuring handling of the above exception, another exception occurred:\n\n\
          Traceback (most recent call last):\nFile \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
          , line 254, in convert_model\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 932, in main\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 205, in bundle_resources_for_guernika\nFile \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 180, in _compile_coreml_model\nFile \"shutil.py\", line 811, in move\n\
          File \"shutil.py\", line 435, in copy2\nFile \"shutil.py\", line 264, in\
          \ copyfile\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/michaelangelo/Downloads/Converted\
          \ ORIGINAL/Protogen-v5.3-Photorealism/Stable_Diffusion_version_Protogen-v5.3-Photorealism_text_encoder.mlmodelc'\n\
          </code></pre>\n<p><em>When trying to convert the official release for the\
          \ base 2.0 model (512px), I receive the following error straight away:</em></p>\n\
          <pre><code>Traceback (most recent call last):\n  File \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
          , line 254, in convert_model\n  File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 897, in main\n  File \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 692, in load_from_ckpt\n  File \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 245, in create_unet_diffusers_config\n  File \"omegaconf/dictconfig.py\"\
          , line 355, in __getattr__\nself._format_and_raise(\n  File \"omegaconf/base.py\"\
          , line 231, in _format_and_raise\nformat_and_raise(\n  File \"omegaconf/_utils.py\"\
          , line 899, in format_and_raise\n_raise(ex, cause)\n  File \"omegaconf/_utils.py\"\
          , line 797, in _raise\nraise ex.with_traceback(sys.exc_info()[2])  # set\
          \ env var OC_CAUSE=1 for full trace\n  File \"omegaconf/dictconfig.py\"\
          , line 351, in __getattr__\nreturn self._get_impl(\n  File \"omegaconf/dictconfig.py\"\
          , line 442, in _get_impl\nnode = self._get_child(\n  File \"omegaconf/basecontainer.py\"\
          , line 73, in _get_child\nchild = self._get_node(\n  File \"omegaconf/dictconfig.py\"\
          , line 480, in _get_node\nraise ConfigKeyError(f\"Missing key {key!s}\"\
          )\nomegaconf.errors.ConfigAttributeError: Missing key num_heads\n    full_key:\
          \ model.params.unet_config.params.num_heads\n    object_type=dict\n</code></pre>\n\
          <p><em>Right-clicking to Show Package Contents then Contents -&gt; MacOS\
          \ and Guernika Model Converter launches a terminal window which outputs\
          \ a continual stream of progress info, the last page of which returns the\
          \ following error(s) on scrollback:</em></p>\n<pre><code>Traceback (most\
          \ recent call last):\nFile \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/routes.py\"\
          , line 284, in run_predict\noutput = await app.blocks.process_api(\n File\
          \ \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 982, in process_api\n    result = await self.call_function(fn_index,\
          \ inputs, iterator)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 824, in call_function\n    prediction = await anyio.to_thread.run_sync(\n\
          \  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/to_thread.py\"\
          , line 31, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n\
          \  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 937, in run_sync_in_worker_thread\nreturn await future\n  File \"\
          /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 867, in run\nresult = context.run(func, *args)\nTypeError: DetectionDetailerScript.ui.&lt;locals&gt;.&lt;lambda&gt;()\
          \ takes 1 positional argument but 2 were given\nTraceback (most recent call\
          \ last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/routes.py\"\
          , line 284, in run_predict\noutput = await app.blocks.process_api(\n  File\
          \ \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 982, in process_api\nresult = await self.call_function(fn_index,\
          \ inputs, iterator)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 824, in call_function\nprediction = await anyio.to_thread.run_sync(\n\
          \  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/to_thread.py\"\
          , line 31, in run_sync\nreturn await get_asynclib().run_sync_in_worker_thread(\n\
          \  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 937, in run_sync_in_worker_thread\nreturn await future\n  File \"\
          /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 867, in run\nresult = context.run(func, *args)\nTypeError: DetectionDetailerScript.ui.&lt;locals&gt;.&lt;lambda&gt;()\
          \ takes 1 positional argument but 2 were given`\n</code></pre>\n<p><em>I'd\
          \ certainly appreciate any potential insight through your perspective and\
          \ experience. Many thanks!</em></p>\n"
        raw: "@GuiyeC  \u2014  _Thanks for the tips. I've tried converting several\
          \ official models as well as custom models, such as Analog Diffusion._ \n\
          \n_Attached are the errors resulting from attempted conversion of official\
          \ release versions for base [Model 1.4](https://huggingface.co/Guernika/CoreMLStableDiffusion/discussions/3#63b5b8bc58b5e43bddee63ad)\
          \ and the official release for base [Model 1.5](https://huggingface.co/Guernika/CoreMLStableDiffusion/discussions/3#63b4d6cea25dd8a860b7c687)._\n\
          \n_With Protogen-v5.3, the conversion script returns an empty output folder\
          \ where the models should have been saved, accompanied by the following\
          \ error report on exit following ten to fifteen minutes of active processing:_\n\
          \n    An error occurred during conversion\n    Traceback (most recent call\
          \ last):\n    File \"shutil.py\", line 791, in move\n    FileNotFoundError:\
          \ [Errno 2] No such file or directory: '/Users/michaelangelo/Downloads/Converted\
          \ ORIGINAL/Protogen-v5.3-Photorealism/Stable_Diffusion_version_Protogen-v5.3-Photorealism_text_encoder.mlmodelc'\
          \ -> '/Users/michaelangelo/Downloads/Converted ORIGINAL/Protogen-v5.3-Photorealism/TextEncoder.mlmodelc'\n\
          \n    During handling of the above exception, another exception occurred:\n\
          \n    Traceback (most recent call last):\n    File \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
          , line 254, in convert_model\n    File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 932, in main\n    File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 205, in bundle_resources_for_guernika\n    File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 180, in _compile_coreml_model\n    File \"shutil.py\", line 811,\
          \ in move\n    File \"shutil.py\", line 435, in copy2\n    File \"shutil.py\"\
          , line 264, in copyfile\n    FileNotFoundError: [Errno 2] No such file or\
          \ directory: '/Users/michaelangelo/Downloads/Converted ORIGINAL/Protogen-v5.3-Photorealism/Stable_Diffusion_version_Protogen-v5.3-Photorealism_text_encoder.mlmodelc'\n\
          \n\n\n_When trying to convert the official release for the base 2.0 model\
          \ (512px), I receive the following error straight away:_\n\n    Traceback\
          \ (most recent call last):\n      File \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
          , line 254, in convert_model\n      File \"python_coreml_stable_diffusion/torch2coreml.py\"\
          , line 897, in main\n      File \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 692, in load_from_ckpt\n      File \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
          , line 245, in create_unet_diffusers_config\n      File \"omegaconf/dictconfig.py\"\
          , line 355, in __getattr__\n    self._format_and_raise(\n      File \"omegaconf/base.py\"\
          , line 231, in _format_and_raise\n    format_and_raise(\n      File \"omegaconf/_utils.py\"\
          , line 899, in format_and_raise\n    _raise(ex, cause)\n      File \"omegaconf/_utils.py\"\
          , line 797, in _raise\n    raise ex.with_traceback(sys.exc_info()[2])  #\
          \ set env var OC_CAUSE=1 for full trace\n      File \"omegaconf/dictconfig.py\"\
          , line 351, in __getattr__\n    return self._get_impl(\n      File \"omegaconf/dictconfig.py\"\
          , line 442, in _get_impl\n    node = self._get_child(\n      File \"omegaconf/basecontainer.py\"\
          , line 73, in _get_child\n    child = self._get_node(\n      File \"omegaconf/dictconfig.py\"\
          , line 480, in _get_node\n    raise ConfigKeyError(f\"Missing key {key!s}\"\
          )\n    omegaconf.errors.ConfigAttributeError: Missing key num_heads\n  \
          \      full_key: model.params.unet_config.params.num_heads\n        object_type=dict\n\
          \n_Right-clicking to Show Package Contents then Contents -> MacOS and Guernika\
          \ Model Converter launches a terminal window which outputs a continual stream\
          \ of progress info, the last page of which returns the following error(s)\
          \ on scrollback:_\n\n    Traceback (most recent call last):\n    File \"\
          /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/routes.py\"\
          , line 284, in run_predict\n    output = await app.blocks.process_api(\n\
          \     File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 982, in process_api\n        result = await self.call_function(fn_index,\
          \ inputs, iterator)\n      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 824, in call_function\n        prediction = await anyio.to_thread.run_sync(\n\
          \      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/to_thread.py\"\
          , line 31, in run_sync\n        return await get_asynclib().run_sync_in_worker_thread(\n\
          \      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 937, in run_sync_in_worker_thread\n    return await future\n    \
          \  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 867, in run\n    result = context.run(func, *args)\n    TypeError:\
          \ DetectionDetailerScript.ui.<locals>.<lambda>() takes 1 positional argument\
          \ but 2 were given\n    Traceback (most recent call last):\n      File \"\
          /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/routes.py\"\
          , line 284, in run_predict\n    output = await app.blocks.process_api(\n\
          \      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 982, in process_api\n    result = await self.call_function(fn_index,\
          \ inputs, iterator)\n      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
          , line 824, in call_function\n    prediction = await anyio.to_thread.run_sync(\n\
          \      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/to_thread.py\"\
          , line 31, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n\
          \      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 937, in run_sync_in_worker_thread\n    return await future\n    \
          \  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
          , line 867, in run\n    result = context.run(func, *args)\n    TypeError:\
          \ DetectionDetailerScript.ui.<locals>.<lambda>() takes 1 positional argument\
          \ but 2 were given`\n\n_I'd certainly appreciate any potential insight through\
          \ your perspective and experience. Many thanks!_"
        updatedAt: '2023-01-09T15:00:17.066Z'
      numEdits: 0
      reactions: []
    id: 63bc2c010718d5f0c1ea2137
    type: comment
  author: Michaelangelo
  content: "@GuiyeC  \u2014  _Thanks for the tips. I've tried converting several official\
    \ models as well as custom models, such as Analog Diffusion._ \n\n_Attached are\
    \ the errors resulting from attempted conversion of official release versions\
    \ for base [Model 1.4](https://huggingface.co/Guernika/CoreMLStableDiffusion/discussions/3#63b5b8bc58b5e43bddee63ad)\
    \ and the official release for base [Model 1.5](https://huggingface.co/Guernika/CoreMLStableDiffusion/discussions/3#63b4d6cea25dd8a860b7c687)._\n\
    \n_With Protogen-v5.3, the conversion script returns an empty output folder where\
    \ the models should have been saved, accompanied by the following error report\
    \ on exit following ten to fifteen minutes of active processing:_\n\n    An error\
    \ occurred during conversion\n    Traceback (most recent call last):\n    File\
    \ \"shutil.py\", line 791, in move\n    FileNotFoundError: [Errno 2] No such file\
    \ or directory: '/Users/michaelangelo/Downloads/Converted ORIGINAL/Protogen-v5.3-Photorealism/Stable_Diffusion_version_Protogen-v5.3-Photorealism_text_encoder.mlmodelc'\
    \ -> '/Users/michaelangelo/Downloads/Converted ORIGINAL/Protogen-v5.3-Photorealism/TextEncoder.mlmodelc'\n\
    \n    During handling of the above exception, another exception occurred:\n\n\
    \    Traceback (most recent call last):\n    File \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
    , line 254, in convert_model\n    File \"python_coreml_stable_diffusion/torch2coreml.py\"\
    , line 932, in main\n    File \"python_coreml_stable_diffusion/torch2coreml.py\"\
    , line 205, in bundle_resources_for_guernika\n    File \"python_coreml_stable_diffusion/torch2coreml.py\"\
    , line 180, in _compile_coreml_model\n    File \"shutil.py\", line 811, in move\n\
    \    File \"shutil.py\", line 435, in copy2\n    File \"shutil.py\", line 264,\
    \ in copyfile\n    FileNotFoundError: [Errno 2] No such file or directory: '/Users/michaelangelo/Downloads/Converted\
    \ ORIGINAL/Protogen-v5.3-Photorealism/Stable_Diffusion_version_Protogen-v5.3-Photorealism_text_encoder.mlmodelc'\n\
    \n\n\n_When trying to convert the official release for the base 2.0 model (512px),\
    \ I receive the following error straight away:_\n\n    Traceback (most recent\
    \ call last):\n      File \"python_coreml_stable_diffusion/torch2coreml_ui.py\"\
    , line 254, in convert_model\n      File \"python_coreml_stable_diffusion/torch2coreml.py\"\
    , line 897, in main\n      File \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
    , line 692, in load_from_ckpt\n      File \"python_coreml_stable_diffusion/convert_original_stable_diffusion_to_diffusers.py\"\
    , line 245, in create_unet_diffusers_config\n      File \"omegaconf/dictconfig.py\"\
    , line 355, in __getattr__\n    self._format_and_raise(\n      File \"omegaconf/base.py\"\
    , line 231, in _format_and_raise\n    format_and_raise(\n      File \"omegaconf/_utils.py\"\
    , line 899, in format_and_raise\n    _raise(ex, cause)\n      File \"omegaconf/_utils.py\"\
    , line 797, in _raise\n    raise ex.with_traceback(sys.exc_info()[2])  # set env\
    \ var OC_CAUSE=1 for full trace\n      File \"omegaconf/dictconfig.py\", line\
    \ 351, in __getattr__\n    return self._get_impl(\n      File \"omegaconf/dictconfig.py\"\
    , line 442, in _get_impl\n    node = self._get_child(\n      File \"omegaconf/basecontainer.py\"\
    , line 73, in _get_child\n    child = self._get_node(\n      File \"omegaconf/dictconfig.py\"\
    , line 480, in _get_node\n    raise ConfigKeyError(f\"Missing key {key!s}\")\n\
    \    omegaconf.errors.ConfigAttributeError: Missing key num_heads\n        full_key:\
    \ model.params.unet_config.params.num_heads\n        object_type=dict\n\n_Right-clicking\
    \ to Show Package Contents then Contents -> MacOS and Guernika Model Converter\
    \ launches a terminal window which outputs a continual stream of progress info,\
    \ the last page of which returns the following error(s) on scrollback:_\n\n  \
    \  Traceback (most recent call last):\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/routes.py\"\
    , line 284, in run_predict\n    output = await app.blocks.process_api(\n     File\
    \ \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
    , line 982, in process_api\n        result = await self.call_function(fn_index,\
    \ inputs, iterator)\n      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
    , line 824, in call_function\n        prediction = await anyio.to_thread.run_sync(\n\
    \      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/to_thread.py\"\
    , line 31, in run_sync\n        return await get_asynclib().run_sync_in_worker_thread(\n\
    \      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
    , line 937, in run_sync_in_worker_thread\n    return await future\n      File\
    \ \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
    , line 867, in run\n    result = context.run(func, *args)\n    TypeError: DetectionDetailerScript.ui.<locals>.<lambda>()\
    \ takes 1 positional argument but 2 were given\n    Traceback (most recent call\
    \ last):\n      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/routes.py\"\
    , line 284, in run_predict\n    output = await app.blocks.process_api(\n     \
    \ File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
    , line 982, in process_api\n    result = await self.call_function(fn_index, inputs,\
    \ iterator)\n      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gradio/blocks.py\"\
    , line 824, in call_function\n    prediction = await anyio.to_thread.run_sync(\n\
    \      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/to_thread.py\"\
    , line 31, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n\
    \      File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
    , line 937, in run_sync_in_worker_thread\n    return await future\n      File\
    \ \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\"\
    , line 867, in run\n    result = context.run(func, *args)\n    TypeError: DetectionDetailerScript.ui.<locals>.<lambda>()\
    \ takes 1 positional argument but 2 were given`\n\n_I'd certainly appreciate any\
    \ potential insight through your perspective and experience. Many thanks!_"
  created_at: 2023-01-09 15:00:17+00:00
  edited: false
  hidden: false
  id: 63bc2c010718d5f0c1ea2137
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
      fullname: Guillermo Cique
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: GuiyeC
      type: user
    createdAt: '2023-01-10T18:30:40.000Z'
    data:
      edited: false
      editors:
      - GuiyeC
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672782907557-6313af200b24eab4746e7d34.jpeg?w=200&h=200&f=face
          fullname: Guillermo Cique
          isHf: false
          isPro: false
          name: GuiyeC
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Michaelangelo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Michaelangelo\"\
          >@<span class=\"underline\">Michaelangelo</span></a></span>\n\n\t</span></span>\
          \ hey! could you share the exact links to get the models so I can give it\
          \ a try converting them?</p>\n"
        raw: '@Michaelangelo hey! could you share the exact links to get the models
          so I can give it a try converting them?'
        updatedAt: '2023-01-10T18:30:40.377Z'
      numEdits: 0
      reactions: []
    id: 63bdaed00a7cc50a4f2a3881
    type: comment
  author: GuiyeC
  content: '@Michaelangelo hey! could you share the exact links to get the models
    so I can give it a try converting them?'
  created_at: 2023-01-10 18:30:40+00:00
  edited: false
  hidden: false
  id: 63bdaed00a7cc50a4f2a3881
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
      fullname: Duhamel
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Michaelangelo
      type: user
    createdAt: '2023-03-25T05:20:57.000Z'
    data:
      edited: true
      editors:
      - Michaelangelo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d21675fc1554ebd5dd7b0576d487dc2.svg
          fullname: Duhamel
          isHf: false
          isPro: false
          name: Michaelangelo
          type: user
        html: '<p>The latest version of the model converter works fine for me on my
          M1 Max. However, it says it should take 15-20 minutes, and it took over
          4 hours for me to convert a 2 GB Realistic Vision 1.3 model ...</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/631f07005172252802e316e3/npjUphbFAp0fTx3Ru7TIy.jpeg"><img
          alt="Screenshot 2023-03-25 at 13.20.12.jpg" src="https://cdn-uploads.huggingface.co/production/uploads/631f07005172252802e316e3/npjUphbFAp0fTx3Ru7TIy.jpeg"></a></p>

          '
        raw: 'The latest version of the model converter works fine for me on my M1
          Max. However, it says it should take 15-20 minutes, and it took over 4 hours
          for me to convert a 2 GB Realistic Vision 1.3 model ...


          ![Screenshot 2023-03-25 at 13.20.12.jpg](https://cdn-uploads.huggingface.co/production/uploads/631f07005172252802e316e3/npjUphbFAp0fTx3Ru7TIy.jpeg)'
        updatedAt: '2023-03-25T05:21:27.410Z'
      numEdits: 1
      reactions: []
    id: 641e84b95d820e1adc6cacba
    type: comment
  author: Michaelangelo
  content: 'The latest version of the model converter works fine for me on my M1 Max.
    However, it says it should take 15-20 minutes, and it took over 4 hours for me
    to convert a 2 GB Realistic Vision 1.3 model ...


    ![Screenshot 2023-03-25 at 13.20.12.jpg](https://cdn-uploads.huggingface.co/production/uploads/631f07005172252802e316e3/npjUphbFAp0fTx3Ru7TIy.jpeg)'
  created_at: 2023-03-25 04:20:57+00:00
  edited: true
  hidden: false
  id: 641e84b95d820e1adc6cacba
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Guernika/CoreMLStableDiffusion
repo_type: model
status: closed
target_branch: null
title: errors converting local .ckpt
