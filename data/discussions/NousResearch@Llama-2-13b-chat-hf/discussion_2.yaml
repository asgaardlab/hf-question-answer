!!python/object:huggingface_hub.community.DiscussionWithDetails
author: amgadhasan
conflicting_files: null
created_at: 2023-08-01 17:47:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e67aba15dab9399c06be912719e1ec0b.svg
      fullname: Amgad Hasan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: amgadhasan
      type: user
    createdAt: '2023-08-01T18:47:27.000Z'
    data:
      edited: false
      editors:
      - amgadhasan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.680578351020813
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e67aba15dab9399c06be912719e1ec0b.svg
          fullname: Amgad Hasan
          isHf: false
          isPro: false
          name: amgadhasan
          type: user
        html: "<p>Code:</p>\n<pre><code>model = \"NousResearch/Llama-2-13b-chat-hf\"\
          \n\ntokenizer = AutoTokenizer.from_pretrained(model)\nchatbot = transformers.pipeline(\n\
          \    \"text-generation\",\n    model=model,\n    torch_dtype=torch.float16,\n\
          \    device_map=\"auto\",\n)\n</code></pre>\n<p>Error:</p>\n<pre><code>ValueError:\
          \ Couldn't instantiate the backend tokenizer from one of: \n(1) a `tokenizers`\
          \ library serialization file, \n(2) a slow tokenizer instance to convert\
          \ or \n(3) an equivalent slow tokenizer class to instantiate and convert.\
          \ \nYou need to have sentencepiece installed to convert a slow tokenizer\
          \ to a fast one.\n</code></pre>\n"
        raw: "\r\n\r\nCode:\r\n```\r\nmodel = \"NousResearch/Llama-2-13b-chat-hf\"\
          \r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model)\r\nchatbot = transformers.pipeline(\r\
          \n    \"text-generation\",\r\n    model=model,\r\n    torch_dtype=torch.float16,\r\
          \n    device_map=\"auto\",\r\n)\r\n```\r\n\r\nError:\r\n```\r\nValueError:\
          \ Couldn't instantiate the backend tokenizer from one of: \r\n(1) a `tokenizers`\
          \ library serialization file, \r\n(2) a slow tokenizer instance to convert\
          \ or \r\n(3) an equivalent slow tokenizer class to instantiate and convert.\
          \ \r\nYou need to have sentencepiece installed to convert a slow tokenizer\
          \ to a fast one.\r\n```"
        updatedAt: '2023-08-01T18:47:27.137Z'
      numEdits: 0
      reactions: []
    id: 64c9533f8d2d187c24c3e856
    type: comment
  author: amgadhasan
  content: "\r\n\r\nCode:\r\n```\r\nmodel = \"NousResearch/Llama-2-13b-chat-hf\"\r\
    \n\r\ntokenizer = AutoTokenizer.from_pretrained(model)\r\nchatbot = transformers.pipeline(\r\
    \n    \"text-generation\",\r\n    model=model,\r\n    torch_dtype=torch.float16,\r\
    \n    device_map=\"auto\",\r\n)\r\n```\r\n\r\nError:\r\n```\r\nValueError: Couldn't\
    \ instantiate the backend tokenizer from one of: \r\n(1) a `tokenizers` library\
    \ serialization file, \r\n(2) a slow tokenizer instance to convert or \r\n(3)\
    \ an equivalent slow tokenizer class to instantiate and convert. \r\nYou need\
    \ to have sentencepiece installed to convert a slow tokenizer to a fast one.\r\
    \n```"
  created_at: 2023-08-01 17:47:27+00:00
  edited: false
  hidden: false
  id: 64c9533f8d2d187c24c3e856
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0878bc930e27371f55e24196c199ff62.svg
      fullname: Dx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NPap
      type: user
    createdAt: '2023-10-10T10:01:58.000Z'
    data:
      edited: false
      editors:
      - NPap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8392346501350403
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0878bc930e27371f55e24196c199ff62.svg
          fullname: Dx
          isHf: false
          isPro: false
          name: NPap
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;amgadhasan&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/amgadhasan\">@<span class=\"\
          underline\">amgadhasan</span></a></span>\n\n\t</span></span> Have you installed\
          \ SentencePiece?</p>\n"
        raw: '@amgadhasan Have you installed SentencePiece?'
        updatedAt: '2023-10-10T10:01:58.198Z'
      numEdits: 0
      reactions: []
    id: 65252116c4edc1682029d0a2
    type: comment
  author: NPap
  content: '@amgadhasan Have you installed SentencePiece?'
  created_at: 2023-10-10 09:01:58+00:00
  edited: false
  hidden: false
  id: 65252116c4edc1682029d0a2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e67aba15dab9399c06be912719e1ec0b.svg
      fullname: Amgad Hasan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: amgadhasan
      type: user
    createdAt: '2023-10-10T10:38:45.000Z'
    data:
      edited: false
      editors:
      - amgadhasan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7920976877212524
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e67aba15dab9399c06be912719e1ec0b.svg
          fullname: Amgad Hasan
          isHf: false
          isPro: false
          name: amgadhasan
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;amgadhasan&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/amgadhasan\"\
          >@<span class=\"underline\">amgadhasan</span></a></span>\n\n\t</span></span>\
          \ Have you installed SentencePiece?</p>\n</blockquote>\n<p>Yes, it fixed\
          \ the error.</p>\n<p>Thank you!</p>\n"
        raw: '> @amgadhasan Have you installed SentencePiece?


          Yes, it fixed the error.


          Thank you!'
        updatedAt: '2023-10-10T10:38:45.681Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - NPap
      relatedEventId: 652529b5d8b9ef864ddf64b7
    id: 652529b5d8b9ef864ddf64b5
    type: comment
  author: amgadhasan
  content: '> @amgadhasan Have you installed SentencePiece?


    Yes, it fixed the error.


    Thank you!'
  created_at: 2023-10-10 09:38:45+00:00
  edited: false
  hidden: false
  id: 652529b5d8b9ef864ddf64b5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/e67aba15dab9399c06be912719e1ec0b.svg
      fullname: Amgad Hasan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: amgadhasan
      type: user
    createdAt: '2023-10-10T10:38:45.000Z'
    data:
      status: closed
    id: 652529b5d8b9ef864ddf64b7
    type: status-change
  author: amgadhasan
  created_at: 2023-10-10 09:38:45+00:00
  id: 652529b5d8b9ef864ddf64b7
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: NousResearch/Llama-2-13b-chat-hf
repo_type: model
status: closed
target_branch: null
title: tokenizer error
