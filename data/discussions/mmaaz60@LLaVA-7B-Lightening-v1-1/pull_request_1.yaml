!!python/object:huggingface_hub.community.DiscussionWithDetails
author: smile123
conflicting_files: []
created_at: 2023-07-17 06:21:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/60141be38f4a7b1fdfe681c5b8aedffb.svg
      fullname: ZhuBin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: smile123
      type: user
    createdAt: '2023-07-17T07:21:40.000Z'
    data:
      edited: false
      editors:
      - smile123
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.11044929921627045
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/60141be38f4a7b1fdfe681c5b8aedffb.svg
          fullname: ZhuBin
          isHf: false
          isPro: false
          name: smile123
          type: user
        html: ''
        raw: ''
        updatedAt: '2023-07-17T07:21:40.612Z'
      numEdits: 0
      reactions: []
    id: 64b4ec0499ba6b13023af107
    type: comment
  author: smile123
  content: ''
  created_at: 2023-07-17 06:21:40+00:00
  edited: false
  hidden: false
  id: 64b4ec0499ba6b13023af107
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/60141be38f4a7b1fdfe681c5b8aedffb.svg
      fullname: ZhuBin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: smile123
      type: user
    createdAt: '2023-07-17T07:21:50.000Z'
    data:
      edited: true
      editors:
      - smile123
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.137142151594162
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/60141be38f4a7b1fdfe681c5b8aedffb.svg
          fullname: ZhuBin
          isHf: false
          isPro: false
          name: smile123
          type: user
        html: "<p> python3.8 hf_tmp.py<br>Downloading (\u2026)lve/main/config.json:\
          \ 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588| 839/839 [00:00&lt;00:00, 124kB/s]<br>Traceback\
          \ (most recent call last):<br>  File \"hf_tmp.py\", line 6, in <br>    model\
          \ = AutoModel.from_pretrained('mmaaz60/LLaVA-7B-Lightening-v1-1', cache_dir='./cache_dir')<br>\
          \  File \"/usr/local/python/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 456, in from_pretrained<br>    config, kwargs = AutoConfig.from_pretrained(<br>\
          \  File \"/usr/local/python/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 957, in from_pretrained<br>    config_class = CONFIG_MAPPING[config_dict[\"\
          model_type\"]]<br>  File \"/usr/local/python/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 671, in <strong>getitem</strong><br>    raise KeyError(key)<br>KeyError:\
          \ 'llava'</p>\n"
        raw: " python3.8 hf_tmp.py \nDownloading (\u2026)lve/main/config.json: 100%|\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
          \u2588\u2588\u2588| 839/839 [00:00<00:00, 124kB/s]\nTraceback (most recent\
          \ call last):\n  File \"hf_tmp.py\", line 6, in <module>\n    model = AutoModel.from_pretrained('mmaaz60/LLaVA-7B-Lightening-v1-1',\
          \ cache_dir='./cache_dir')\n  File \"/usr/local/python/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 456, in from_pretrained\n    config, kwargs = AutoConfig.from_pretrained(\n\
          \  File \"/usr/local/python/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 957, in from_pretrained\n    config_class = CONFIG_MAPPING[config_dict[\"\
          model_type\"]]\n  File \"/usr/local/python/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 671, in __getitem__\n    raise KeyError(key)\nKeyError: 'llava'"
        updatedAt: '2023-07-17T07:22:07.189Z'
      numEdits: 1
      reactions: []
    id: 64b4ec0e6d953e7c7511e888
    type: comment
  author: smile123
  content: " python3.8 hf_tmp.py \nDownloading (\u2026)lve/main/config.json: 100%|\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\
    \u2588\u2588\u2588\u2588\u2588| 839/839 [00:00<00:00, 124kB/s]\nTraceback (most\
    \ recent call last):\n  File \"hf_tmp.py\", line 6, in <module>\n    model = AutoModel.from_pretrained('mmaaz60/LLaVA-7B-Lightening-v1-1',\
    \ cache_dir='./cache_dir')\n  File \"/usr/local/python/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\"\
    , line 456, in from_pretrained\n    config, kwargs = AutoConfig.from_pretrained(\n\
    \  File \"/usr/local/python/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 957, in from_pretrained\n    config_class = CONFIG_MAPPING[config_dict[\"\
    model_type\"]]\n  File \"/usr/local/python/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 671, in __getitem__\n    raise KeyError(key)\nKeyError: 'llava'"
  created_at: 2023-07-17 06:21:50+00:00
  edited: true
  hidden: false
  id: 64b4ec0e6d953e7c7511e888
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/kmCo6brXhQ7SyxVx3lpsx.jpeg?w=200&h=200&f=face
      fullname: Muhammad Maaz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mmaaz60
      type: user
    createdAt: '2023-07-17T19:06:25.000Z'
    data:
      edited: false
      editors:
      - mmaaz60
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7710822224617004
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/kmCo6brXhQ7SyxVx3lpsx.jpeg?w=200&h=200&f=face
          fullname: Muhammad Maaz
          isHf: false
          isPro: false
          name: mmaaz60
          type: user
        html: '<p>Hi, please note that you have to set <code>model_type=''llava''</code>.
          Please have a look at <a rel="nofollow" href="https://github.com/haotian-liu/LLaVA/blob/7ace501183c4bdec6052ec1a30039cdc3242a67c/llava/model/llava.py#L36">here</a>
          and <a rel="nofollow" href="https://github.com/mbzuai-oryx/Video-ChatGPT/blob/c7eaa2ad36bd0eeebc455a4b9740a32600789b6f/video_chatgpt/model/video_chatgpt.py#L25">here</a>
          for reference.</p>

          <p>Also, please try using LLaVA or Video-ChatGPT official repo to load this
          model and it should work. Thank you and would be happy to discuss it further
          in case if you have any comments/questions. Thank You.</p>

          '
        raw: 'Hi, please note that you have to set `model_type=''llava''`. Please
          have a look at [here](https://github.com/haotian-liu/LLaVA/blob/7ace501183c4bdec6052ec1a30039cdc3242a67c/llava/model/llava.py#L36)
          and [here](https://github.com/mbzuai-oryx/Video-ChatGPT/blob/c7eaa2ad36bd0eeebc455a4b9740a32600789b6f/video_chatgpt/model/video_chatgpt.py#L25)
          for reference.


          Also, please try using LLaVA or Video-ChatGPT official repo to load this
          model and it should work. Thank you and would be happy to discuss it further
          in case if you have any comments/questions. Thank You.'
        updatedAt: '2023-07-17T19:06:25.456Z'
      numEdits: 0
      reactions: []
    id: 64b591311977b0f24610fe10
    type: comment
  author: mmaaz60
  content: 'Hi, please note that you have to set `model_type=''llava''`. Please have
    a look at [here](https://github.com/haotian-liu/LLaVA/blob/7ace501183c4bdec6052ec1a30039cdc3242a67c/llava/model/llava.py#L36)
    and [here](https://github.com/mbzuai-oryx/Video-ChatGPT/blob/c7eaa2ad36bd0eeebc455a4b9740a32600789b6f/video_chatgpt/model/video_chatgpt.py#L25)
    for reference.


    Also, please try using LLaVA or Video-ChatGPT official repo to load this model
    and it should work. Thank you and would be happy to discuss it further in case
    if you have any comments/questions. Thank You.'
  created_at: 2023-07-17 18:06:25+00:00
  edited: false
  hidden: false
  id: 64b591311977b0f24610fe10
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 1
repo_id: mmaaz60/LLaVA-7B-Lightening-v1-1
repo_type: model
status: draft
target_branch: refs/heads/main
title: 'Keyerror:  llava'
