!!python/object:huggingface_hub.community.DiscussionWithDetails
author: HeavyarmsD77
conflicting_files: null
created_at: 2023-09-30 16:49:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0fca1a893593ecc930d26e1a12305912.svg
      fullname: Brian Dina
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HeavyarmsD77
      type: user
    createdAt: '2023-09-30T17:49:00.000Z'
    data:
      edited: true
      editors:
      - HeavyarmsD77
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9136659502983093
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0fca1a893593ecc930d26e1a12305912.svg
          fullname: Brian Dina
          isHf: false
          isPro: false
          name: HeavyarmsD77
          type: user
        html: '<p>Can anyone show me how to download this? I tried using the cache_dir="./mydir/"
          but it seems so slow when downloading. </p>

          <p>example of the code I use:</p>

          <h1 id="load-model-directly">Load model directly</h1>

          <p>from transformers import AutoModelForCausalLM<br>model_path = "/home/bdina/Desktop/GEO-ChatGPT/lava_weights"<br>model
          = AutoModelForCausalLM.from_pretrained(model_path)</p>

          <p>Why do I get this error:</p>

          <p>Exception has occurred: KeyError       (note: full exception trace is
          shown but execution is paused at: _run_module_as_main)<br>''llava''<br>  File
          "/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py",
          line 748, in <strong>getitem</strong><br>    raise KeyError(key)<br>  File
          "/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py",
          line 1050, in from_pretrained<br>    config_class = CONFIG_MAPPING[config_dict["model_type"]]<br>  File
          "/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py",
          line 525, in from_pretrained<br>    config, kwargs = AutoConfig.from_pretrained(<br>  File
          "/home/bdina/Desktop/GEO-ChatGPT/data/llava_test.py", line 5, in <br>    model
          = AutoModelForCausalLM.from_pretrained(model_path)<br>  File "/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/runpy.py",
          line 86, in _run_code<br>    exec(code, run_globals)<br>  File "/home/USER/anaconda3/envs/video_chatgpt/lib/python3.10/runpy.py",
          line 196, in _run_module_as_main (Current frame)<br>    return _run_code(code,
          main_globals, None,<br>KeyError: ''llava''</p>

          '
        raw: "Can anyone show me how to download this? I tried using the cache_dir=\"\
          ./mydir/\" but it seems so slow when downloading. \n\nexample of the code\
          \ I use:\n# Load model directly\nfrom transformers import AutoModelForCausalLM\n\
          model_path = \"/home/bdina/Desktop/GEO-ChatGPT/lava_weights\"\nmodel = AutoModelForCausalLM.from_pretrained(model_path)\n\
          \nWhy do I get this error:\n\nException has occurred: KeyError       (note:\
          \ full exception trace is shown but execution is paused at: _run_module_as_main)\n\
          'llava'\n  File \"/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 748, in __getitem__\n    raise KeyError(key)\n  File \"/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
          , line 1050, in from_pretrained\n    config_class = CONFIG_MAPPING[config_dict[\"\
          model_type\"]]\n  File \"/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\"\
          , line 525, in from_pretrained\n    config, kwargs = AutoConfig.from_pretrained(\n\
          \  File \"/home/bdina/Desktop/GEO-ChatGPT/data/llava_test.py\", line 5,\
          \ in <module>\n    model = AutoModelForCausalLM.from_pretrained(model_path)\n\
          \  File \"/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/runpy.py\"\
          , line 86, in _run_code\n    exec(code, run_globals)\n  File \"/home/USER/anaconda3/envs/video_chatgpt/lib/python3.10/runpy.py\"\
          , line 196, in _run_module_as_main (Current frame)\n    return _run_code(code,\
          \ main_globals, None,\nKeyError: 'llava'"
        updatedAt: '2023-10-05T17:06:23.266Z'
      numEdits: 1
      reactions: []
    id: 65185f8cff197684a51d15a0
    type: comment
  author: HeavyarmsD77
  content: "Can anyone show me how to download this? I tried using the cache_dir=\"\
    ./mydir/\" but it seems so slow when downloading. \n\nexample of the code I use:\n\
    # Load model directly\nfrom transformers import AutoModelForCausalLM\nmodel_path\
    \ = \"/home/bdina/Desktop/GEO-ChatGPT/lava_weights\"\nmodel = AutoModelForCausalLM.from_pretrained(model_path)\n\
    \nWhy do I get this error:\n\nException has occurred: KeyError       (note: full\
    \ exception trace is shown but execution is paused at: _run_module_as_main)\n\
    'llava'\n  File \"/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 748, in __getitem__\n    raise KeyError(key)\n  File \"/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\"\
    , line 1050, in from_pretrained\n    config_class = CONFIG_MAPPING[config_dict[\"\
    model_type\"]]\n  File \"/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\"\
    , line 525, in from_pretrained\n    config, kwargs = AutoConfig.from_pretrained(\n\
    \  File \"/home/bdina/Desktop/GEO-ChatGPT/data/llava_test.py\", line 5, in <module>\n\
    \    model = AutoModelForCausalLM.from_pretrained(model_path)\n  File \"/home/bdina/anaconda3/envs/video_chatgpt/lib/python3.10/runpy.py\"\
    , line 86, in _run_code\n    exec(code, run_globals)\n  File \"/home/USER/anaconda3/envs/video_chatgpt/lib/python3.10/runpy.py\"\
    , line 196, in _run_module_as_main (Current frame)\n    return _run_code(code,\
    \ main_globals, None,\nKeyError: 'llava'"
  created_at: 2023-09-30 16:49:00+00:00
  edited: true
  hidden: false
  id: 65185f8cff197684a51d15a0
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: mmaaz60/LLaVA-7B-Lightening-v1-1
repo_type: model
status: open
target_branch: null
title: New to this
