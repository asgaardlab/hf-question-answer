!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Phil337
conflicting_files: null
created_at: 2023-11-21 23:16:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-11-21T23:16:55.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8948136568069458
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>I''m not interested in using a GGUF Qwen. Just wondering if there''s
          a technical, legal or other reason why Qwens can be found in GPTQ and AWQ,
          but not GGUF.</p>

          '
        raw: I'm not interested in using a GGUF Qwen. Just wondering if there's a
          technical, legal or other reason why Qwens can be found in GPTQ and AWQ,
          but not GGUF.
        updatedAt: '2023-11-21T23:16:55.011Z'
      numEdits: 0
      reactions: []
    id: 655d3a67ca52f87505d32e6a
    type: comment
  author: Phil337
  content: I'm not interested in using a GGUF Qwen. Just wondering if there's a technical,
    legal or other reason why Qwens can be found in GPTQ and AWQ, but not GGUF.
  created_at: 2023-11-21 23:16:55+00:00
  edited: false
  hidden: false
  id: 655d3a67ca52f87505d32e6a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8e25320e77517a16f61522457510a69e.svg
      fullname: "Murillo Brand\xE3o"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: murillobrand
      type: user
    createdAt: '2023-11-22T02:12:07.000Z'
    data:
      edited: false
      editors:
      - murillobrand
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9900057911872864
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8e25320e77517a16f61522457510a69e.svg
          fullname: "Murillo Brand\xE3o"
          isHf: false
          isPro: false
          name: murillobrand
          type: user
        html: '<p>It would be really nice to have a GGUF version of it to use with
          Ollama.</p>

          '
        raw: It would be really nice to have a GGUF version of it to use with Ollama.
        updatedAt: '2023-11-22T02:12:07.893Z'
      numEdits: 0
      reactions: []
    id: 655d637716ede91c78083665
    type: comment
  author: murillobrand
  content: It would be really nice to have a GGUF version of it to use with Ollama.
  created_at: 2023-11-22 02:12:07+00:00
  edited: false
  hidden: false
  id: 655d637716ede91c78083665
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-11-28T19:42:19.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9582085609436035
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>Did a little research and apparently the token library of Qwen 14b
          is gigantic because of the vast number of Chinese symbols used, which someone
          said is incompatible with GGUF.</p>

          <p>I don''t think this is a big loss. I tested out the online chat version
          of Qwen 14b and it performed notably worse across the board compared to
          most Llama 2 13b and Mistral 7b fine-tunes, often outputting random nonsense.
          Which is odd because Qwen 14b scores notably higher on multi-shot LLM tests
          compared to Llama 13b and Mistral 7b. Perhaps this isn''t an issue with
          the base model, but rather the inability of the official chat version to
          respond appropriately to 0-shot user prompts.</p>

          '
        raw: 'Did a little research and apparently the token library of Qwen 14b is
          gigantic because of the vast number of Chinese symbols used, which someone
          said is incompatible with GGUF.


          I don''t think this is a big loss. I tested out the online chat version
          of Qwen 14b and it performed notably worse across the board compared to
          most Llama 2 13b and Mistral 7b fine-tunes, often outputting random nonsense.
          Which is odd because Qwen 14b scores notably higher on multi-shot LLM tests
          compared to Llama 13b and Mistral 7b. Perhaps this isn''t an issue with
          the base model, but rather the inability of the official chat version to
          respond appropriately to 0-shot user prompts.'
        updatedAt: '2023-11-28T19:42:19.076Z'
      numEdits: 0
      reactions: []
    id: 6566429b93e30c8a60e2155f
    type: comment
  author: Phil337
  content: 'Did a little research and apparently the token library of Qwen 14b is
    gigantic because of the vast number of Chinese symbols used, which someone said
    is incompatible with GGUF.


    I don''t think this is a big loss. I tested out the online chat version of Qwen
    14b and it performed notably worse across the board compared to most Llama 2 13b
    and Mistral 7b fine-tunes, often outputting random nonsense. Which is odd because
    Qwen 14b scores notably higher on multi-shot LLM tests compared to Llama 13b and
    Mistral 7b. Perhaps this isn''t an issue with the base model, but rather the inability
    of the official chat version to respond appropriately to 0-shot user prompts.'
  created_at: 2023-11-28 19:42:19+00:00
  edited: false
  hidden: false
  id: 6566429b93e30c8a60e2155f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Qwen-14B-Chat-AWQ
repo_type: model
status: open
target_branch: null
title: Couldn't Find A GGUF Qwen
