!!python/object:huggingface_hub.community.DiscussionWithDetails
author: opyate
conflicting_files: null
created_at: 2023-04-28 11:12:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-04-28T12:12:35.000Z'
    data:
      edited: false
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: "<p>Hello,</p>\n<p>I'm fine-tuning Dolly with my own data.</p>\n<p>However,\
          \ there's a <code>test-size</code> hyperparameter, which I'm not sure about.\
          \  I can't find mention of it in <a rel=\"nofollow\" href=\"https://github.com/microsoft/DeepSpeed\"\
          >their repo</a> or <a rel=\"nofollow\" href=\"https://deepspeed.readthedocs.io\"\
          >pypi</a>.</p>\n<pre><code># https://github.com/databrickslabs/dolly#a10-gpus-1\n\
          !deepspeed {num_gpus_flag} \\\n    --module training.trainer \\\n    --input-model\
          \ {input_model} \\\n    --deepspeed {deepspeed_config} \\\n    --epochs\
          \ 2 \\\n    --local-output-dir {local_output_dir} \\\n    --dbfs-output-dir\
          \ {dbfs_output_dir} \\\n    --per-device-train-batch-size 3 \\\n    --per-device-eval-batch-size\
          \ 3 \\\n    --logging-steps 10 \\\n    --save-steps 200 \\\n    --save-total-limit\
          \ 20 \\\n    --eval-steps 50 \\\n    --warmup-steps 50 \\\n    --test-size\
          \ 200 \\\n    --lr 5e-6\n</code></pre>\n<p>My training set is 1,000 datapoints.\
          \ What should the hyperparams, especially <code>test-size</code> be to suit\
          \ the training size?</p>\n"
        raw: "Hello,\r\n\r\nI'm fine-tuning Dolly with my own data.\r\n\r\nHowever,\
          \ there's a `test-size` hyperparameter, which I'm not sure about.  I can't\
          \ find mention of it in [their repo](https://github.com/microsoft/DeepSpeed)\
          \ or [pypi](https://deepspeed.readthedocs.io).\r\n\r\n```\r\n# https://github.com/databrickslabs/dolly#a10-gpus-1\r\
          \n!deepspeed {num_gpus_flag} \\\r\n    --module training.trainer \\\r\n\
          \    --input-model {input_model} \\\r\n    --deepspeed {deepspeed_config}\
          \ \\\r\n    --epochs 2 \\\r\n    --local-output-dir {local_output_dir} \\\
          \r\n    --dbfs-output-dir {dbfs_output_dir} \\\r\n    --per-device-train-batch-size\
          \ 3 \\\r\n    --per-device-eval-batch-size 3 \\\r\n    --logging-steps 10\
          \ \\\r\n    --save-steps 200 \\\r\n    --save-total-limit 20 \\\r\n    --eval-steps\
          \ 50 \\\r\n    --warmup-steps 50 \\\r\n    --test-size 200 \\\r\n    --lr\
          \ 5e-6\r\n```\r\n\r\nMy training set is 1,000 datapoints. What should the\
          \ hyperparams, especially `test-size` be to suit the training size?"
        updatedAt: '2023-04-28T12:12:35.233Z'
      numEdits: 0
      reactions: []
    id: 644bb83370dd5a31301097dc
    type: comment
  author: opyate
  content: "Hello,\r\n\r\nI'm fine-tuning Dolly with my own data.\r\n\r\nHowever,\
    \ there's a `test-size` hyperparameter, which I'm not sure about.  I can't find\
    \ mention of it in [their repo](https://github.com/microsoft/DeepSpeed) or [pypi](https://deepspeed.readthedocs.io).\r\
    \n\r\n```\r\n# https://github.com/databrickslabs/dolly#a10-gpus-1\r\n!deepspeed\
    \ {num_gpus_flag} \\\r\n    --module training.trainer \\\r\n    --input-model\
    \ {input_model} \\\r\n    --deepspeed {deepspeed_config} \\\r\n    --epochs 2\
    \ \\\r\n    --local-output-dir {local_output_dir} \\\r\n    --dbfs-output-dir\
    \ {dbfs_output_dir} \\\r\n    --per-device-train-batch-size 3 \\\r\n    --per-device-eval-batch-size\
    \ 3 \\\r\n    --logging-steps 10 \\\r\n    --save-steps 200 \\\r\n    --save-total-limit\
    \ 20 \\\r\n    --eval-steps 50 \\\r\n    --warmup-steps 50 \\\r\n    --test-size\
    \ 200 \\\r\n    --lr 5e-6\r\n```\r\n\r\nMy training set is 1,000 datapoints. What\
    \ should the hyperparams, especially `test-size` be to suit the training size?"
  created_at: 2023-04-28 11:12:35+00:00
  edited: false
  hidden: false
  id: 644bb83370dd5a31301097dc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-28T12:36:05.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Most of the actual training configuration is in the HF Trainer:
          <a rel="nofollow" href="https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L236">https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L236</a><br>These
          arguments to deepspeed tell deepspeed about the training also, so sometimes
          it''s a little repetitive. Here I guess deepspeed also wants to know how
          big the test set size is. It''s possible it''s actually redundant, I haven''t
          looked closely.</p>

          '
        raw: 'Most of the actual training configuration is in the HF Trainer: https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L236

          These arguments to deepspeed tell deepspeed about the training also, so
          sometimes it''s a little repetitive. Here I guess deepspeed also wants to
          know how big the test set size is. It''s possible it''s actually redundant,
          I haven''t looked closely.'
        updatedAt: '2023-04-28T12:36:05.176Z'
      numEdits: 0
      reactions: []
    id: 644bbdb5cb0886c51c22998c
    type: comment
  author: srowen
  content: 'Most of the actual training configuration is in the HF Trainer: https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L236

    These arguments to deepspeed tell deepspeed about the training also, so sometimes
    it''s a little repetitive. Here I guess deepspeed also wants to know how big the
    test set size is. It''s possible it''s actually redundant, I haven''t looked closely.'
  created_at: 2023-04-28 11:36:05+00:00
  edited: false
  hidden: false
  id: 644bbdb5cb0886c51c22998c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-04-28T13:09:09.000Z'
    data:
      edited: false
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: '<p>Thanks for the pointers, Sean. It might very well be redundant.</p>

          '
        raw: Thanks for the pointers, Sean. It might very well be redundant.
        updatedAt: '2023-04-28T13:09:09.314Z'
      numEdits: 0
      reactions: []
      relatedEventId: 644bc57596b76e7c3105c3bf
    id: 644bc57596b76e7c3105c3be
    type: comment
  author: opyate
  content: Thanks for the pointers, Sean. It might very well be redundant.
  created_at: 2023-04-28 12:09:09+00:00
  edited: false
  hidden: false
  id: 644bc57596b76e7c3105c3be
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-04-28T13:09:09.000Z'
    data:
      status: closed
    id: 644bc57596b76e7c3105c3bf
    type: status-change
  author: opyate
  created_at: 2023-04-28 12:09:09+00:00
  id: 644bc57596b76e7c3105c3bf
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-28T22:26:02.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Oh, wait I''m misreading this. <code>--test-size</code> is how you
          pass the argument through deepspeed down to Trainer. It''s not redundant.
          It''s just saying how much of the dataset to hold out for eval.</p>

          '
        raw: Oh, wait I'm misreading this. `--test-size` is how you pass the argument
          through deepspeed down to Trainer. It's not redundant. It's just saying
          how much of the dataset to hold out for eval.
        updatedAt: '2023-04-28T22:26:02.786Z'
      numEdits: 0
      reactions: []
    id: 644c47fa194e124dacc165d4
    type: comment
  author: srowen
  content: Oh, wait I'm misreading this. `--test-size` is how you pass the argument
    through deepspeed down to Trainer. It's not redundant. It's just saying how much
    of the dataset to hold out for eval.
  created_at: 2023-04-28 21:26:02+00:00
  edited: false
  hidden: false
  id: 644c47fa194e124dacc165d4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
      fullname: Matthew Hayes
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: matthayes
      type: user
    createdAt: '2023-04-28T23:29:27.000Z'
    data:
      edited: false
      editors:
      - matthayes
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6424a91ff1d18f46decba5b3/5RrvrmYbW9nh6G1uxZjE6.jpeg?w=200&h=200&f=face
          fullname: Matthew Hayes
          isHf: false
          isPro: false
          name: matthayes
          type: user
        html: '<p>With only 1000 data points the test size may not be very useful
          here.  I would consider just setting it very low (like 1 or 10) and perhaps
          ignoring the eval loss.  You could try running generation at different checkpoints
          to see how the quality actually looks.</p>

          '
        raw: With only 1000 data points the test size may not be very useful here.  I
          would consider just setting it very low (like 1 or 10) and perhaps ignoring
          the eval loss.  You could try running generation at different checkpoints
          to see how the quality actually looks.
        updatedAt: '2023-04-28T23:29:27.355Z'
      numEdits: 0
      reactions: []
    id: 644c56d745e79023c7e6e064
    type: comment
  author: matthayes
  content: With only 1000 data points the test size may not be very useful here.  I
    would consider just setting it very low (like 1 or 10) and perhaps ignoring the
    eval loss.  You could try running generation at different checkpoints to see how
    the quality actually looks.
  created_at: 2023-04-28 22:29:27+00:00
  edited: false
  hidden: false
  id: 644c56d745e79023c7e6e064
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-04-29T08:14:38.000Z'
    data:
      edited: false
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: '<p>Thanks. I see the dolly-15k dataset only has "train". Mine has "train"
          and "test". I suppose I have to put it all in "train", for a few more data
          points.</p>

          '
        raw: Thanks. I see the dolly-15k dataset only has "train". Mine has "train"
          and "test". I suppose I have to put it all in "train", for a few more data
          points.
        updatedAt: '2023-04-29T08:14:38.526Z'
      numEdits: 0
      reactions: []
    id: 644cd1eefa94e93b0ebb0452
    type: comment
  author: opyate
  content: Thanks. I see the dolly-15k dataset only has "train". Mine has "train"
    and "test". I suppose I have to put it all in "train", for a few more data points.
  created_at: 2023-04-29 07:14:38+00:00
  edited: false
  hidden: false
  id: 644cd1eefa94e93b0ebb0452
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-29T11:22:23.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>You can also just modify the code to load your train and test set,
          instead of randomly splitting test out of train</p>

          '
        raw: You can also just modify the code to load your train and test set, instead
          of randomly splitting test out of train
        updatedAt: '2023-04-29T11:22:23.500Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - opyate
    id: 644cfdef97a3b0904a4d2add
    type: comment
  author: srowen
  content: You can also just modify the code to load your train and test set, instead
    of randomly splitting test out of train
  created_at: 2023-04-29 10:22:23+00:00
  edited: false
  hidden: false
  id: 644cfdef97a3b0904a4d2add
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-05-01T09:21:16.000Z'
    data:
      edited: false
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: '<p>Deepspeed exited with -9 on a fine-tuning run against the 7b model.
          I guess it means OOM. (Using 4x A10 GPUs)</p>

          <p>I''ll look into trying Parameter-Efficient Tuning.<br>Or perhaps try
          with 8x A100 (p4d instance).</p>

          '
        raw: "Deepspeed exited with -9 on a fine-tuning run against the 7b model.\
          \ I guess it means OOM. (Using 4x A10 GPUs)\n\nI'll look into trying Parameter-Efficient\
          \ Tuning. \nOr perhaps try with 8x A100 (p4d instance)."
        updatedAt: '2023-05-01T09:21:16.024Z'
      numEdits: 0
      reactions: []
    id: 644f848c28774bd665d11878
    type: comment
  author: opyate
  content: "Deepspeed exited with -9 on a fine-tuning run against the 7b model. I\
    \ guess it means OOM. (Using 4x A10 GPUs)\n\nI'll look into trying Parameter-Efficient\
    \ Tuning. \nOr perhaps try with 8x A100 (p4d instance)."
  created_at: 2023-05-01 08:21:16+00:00
  edited: false
  hidden: false
  id: 644f848c28774bd665d11878
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-01T12:09:44.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>What model size are you using and what instance? that should not
          be needed. <a rel="nofollow" href="https://github.com/databrickslabs/dolly#a10-gpus">https://github.com/databrickslabs/dolly#a10-gpus</a></p>

          '
        raw: What model size are you using and what instance? that should not be needed.
          https://github.com/databrickslabs/dolly#a10-gpus
        updatedAt: '2023-05-01T12:09:44.405Z'
      numEdits: 0
      reactions: []
    id: 644fac08577838187ef74045
    type: comment
  author: srowen
  content: What model size are you using and what instance? that should not be needed.
    https://github.com/databrickslabs/dolly#a10-gpus
  created_at: 2023-05-01 11:09:44+00:00
  edited: false
  hidden: false
  id: 644fac08577838187ef74045
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-05-02T08:03:18.000Z'
    data:
      edited: true
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: "<p>I'm trying to fine-tune the 7b model with learning rate <code>5e-8</code>\
          \ (to not clobber the weights too much) and number of epochs 2.</p>\n<p>Here's\
          \ the <a rel=\"nofollow\" href=\"https://pastebin.com/ZN49frXq\">log</a>.</p>\n\
          <p>I use 4 x A10G GPUs:</p>\n<pre><code>Python 3.9.5\ntorch:  1.13 ; cuda:\
          \  cu117\nMon May  1 12:23:15 2023       \n+-----------------------------------------------------------------------------+\n\
          | NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4\
          \     |\n|-------------------------------+----------------------+----------------------+\n\
          | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr.\
          \ ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util\
          \  Compute M. |\n|                               |                     \
          \ |               MIG M. |\n|===============================+======================+======================|\n\
          |   0  NVIDIA A10G         Off  | 00000000:00:1B.0 Off |               \
          \     0 |\n|  0%   19C    P8     9W / 300W |      0MiB / 22731MiB |    \
          \  0%      Default |\n|                               |                \
          \      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\
          |   1  NVIDIA A10G         Off  | 00000000:00:1C.0 Off |               \
          \     0 |\n|  0%   18C    P8     9W / 300W |      0MiB / 22731MiB |    \
          \  0%      Default |\n|                               |                \
          \      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\
          |   2  NVIDIA A10G         Off  | 00000000:00:1D.0 Off |               \
          \     0 |\n|  0%   19C    P8     9W / 300W |      0MiB / 22731MiB |    \
          \  0%      Default |\n|                               |                \
          \      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\
          |   3  NVIDIA A10G         Off  | 00000000:00:1E.0 Off |               \
          \     0 |\n|  0%   19C    P8     8W / 300W |      0MiB / 22731MiB |    \
          \  0%      Default |\n|                               |                \
          \      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\
          </code></pre>\n<p>The instance:</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/bKSa6puDVTAEBPFyzP8Nb.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/bKSa6puDVTAEBPFyzP8Nb.png\"\
          ></a></p>\n"
        raw: "I'm trying to fine-tune the 7b model with learning rate `5e-8` (to not\
          \ clobber the weights too much) and number of epochs 2.\n\nHere's the [log](https://pastebin.com/ZN49frXq).\n\
          \nI use 4 x A10G GPUs:\n\n```\nPython 3.9.5\ntorch:  1.13 ; cuda:  cu117\n\
          Mon May  1 12:23:15 2023       \n+-----------------------------------------------------------------------------+\n\
          | NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4\
          \     |\n|-------------------------------+----------------------+----------------------+\n\
          | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr.\
          \ ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util\
          \  Compute M. |\n|                               |                     \
          \ |               MIG M. |\n|===============================+======================+======================|\n\
          |   0  NVIDIA A10G         Off  | 00000000:00:1B.0 Off |               \
          \     0 |\n|  0%   19C    P8     9W / 300W |      0MiB / 22731MiB |    \
          \  0%      Default |\n|                               |                \
          \      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\
          |   1  NVIDIA A10G         Off  | 00000000:00:1C.0 Off |               \
          \     0 |\n|  0%   18C    P8     9W / 300W |      0MiB / 22731MiB |    \
          \  0%      Default |\n|                               |                \
          \      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\
          |   2  NVIDIA A10G         Off  | 00000000:00:1D.0 Off |               \
          \     0 |\n|  0%   19C    P8     9W / 300W |      0MiB / 22731MiB |    \
          \  0%      Default |\n|                               |                \
          \      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\
          |   3  NVIDIA A10G         Off  | 00000000:00:1E.0 Off |               \
          \     0 |\n|  0%   19C    P8     8W / 300W |      0MiB / 22731MiB |    \
          \  0%      Default |\n|                               |                \
          \      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\
          \n```\n\nThe instance:\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/bKSa6puDVTAEBPFyzP8Nb.png)"
        updatedAt: '2023-05-02T08:58:37.080Z'
      numEdits: 2
      reactions: []
    id: 6450c3c6e4827192b35285b8
    type: comment
  author: opyate
  content: "I'm trying to fine-tune the 7b model with learning rate `5e-8` (to not\
    \ clobber the weights too much) and number of epochs 2.\n\nHere's the [log](https://pastebin.com/ZN49frXq).\n\
    \nI use 4 x A10G GPUs:\n\n```\nPython 3.9.5\ntorch:  1.13 ; cuda:  cu117\nMon\
    \ May  1 12:23:15 2023       \n+-----------------------------------------------------------------------------+\n\
    | NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4    \
    \ |\n|-------------------------------+----------------------+----------------------+\n\
    | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC\
    \ |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute\
    \ M. |\n|                               |                      |             \
    \  MIG M. |\n|===============================+======================+======================|\n\
    |   0  NVIDIA A10G         Off  | 00000000:00:1B.0 Off |                    0\
    \ |\n|  0%   19C    P8     9W / 300W |      0MiB / 22731MiB |      0%      Default\
    \ |\n|                               |                      |                \
    \  N/A |\n+-------------------------------+----------------------+----------------------+\n\
    |   1  NVIDIA A10G         Off  | 00000000:00:1C.0 Off |                    0\
    \ |\n|  0%   18C    P8     9W / 300W |      0MiB / 22731MiB |      0%      Default\
    \ |\n|                               |                      |                \
    \  N/A |\n+-------------------------------+----------------------+----------------------+\n\
    |   2  NVIDIA A10G         Off  | 00000000:00:1D.0 Off |                    0\
    \ |\n|  0%   19C    P8     9W / 300W |      0MiB / 22731MiB |      0%      Default\
    \ |\n|                               |                      |                \
    \  N/A |\n+-------------------------------+----------------------+----------------------+\n\
    |   3  NVIDIA A10G         Off  | 00000000:00:1E.0 Off |                    0\
    \ |\n|  0%   19C    P8     8W / 300W |      0MiB / 22731MiB |      0%      Default\
    \ |\n|                               |                      |                \
    \  N/A |\n+-------------------------------+----------------------+----------------------+\n\
    \n```\n\nThe instance:\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/bKSa6puDVTAEBPFyzP8Nb.png)"
  created_at: 2023-05-02 07:03:18+00:00
  edited: true
  hidden: false
  id: 6450c3c6e4827192b35285b8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-05-02T10:20:32.000Z'
    data:
      edited: true
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: '<p>Deepspeed exit code <code>-9</code> again with learning rate at
          <code>5e-7</code> and <code>5e-6</code> (the original rate).</p>

          <p><a rel="nofollow" href="https://pastebin.com/6NkMNm85">Log</a> for 5e-7<br><a
          rel="nofollow" href="https://pastebin.com/vmpUs5wn">Log</a> for 5e-6</p>

          '
        raw: 'Deepspeed exit code `-9` again with learning rate at `5e-7` and `5e-6`
          (the original rate).


          [Log](https://pastebin.com/6NkMNm85) for 5e-7

          [Log](https://pastebin.com/vmpUs5wn) for 5e-6'
        updatedAt: '2023-05-02T10:54:56.641Z'
      numEdits: 2
      reactions: []
    id: 6450e3f08c5830e111da3b7c
    type: comment
  author: opyate
  content: 'Deepspeed exit code `-9` again with learning rate at `5e-7` and `5e-6`
    (the original rate).


    [Log](https://pastebin.com/6NkMNm85) for 5e-7

    [Log](https://pastebin.com/vmpUs5wn) for 5e-6'
  created_at: 2023-05-02 09:20:32+00:00
  edited: true
  hidden: false
  id: 6450e3f08c5830e111da3b7c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-02T12:30:33.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Learning rate is not related to mem usage. Are you following the
          instructions in the repo for changing the code when using A10s? it will
          not work out of the box unless you modify some settings as described there.</p>

          '
        raw: Learning rate is not related to mem usage. Are you following the instructions
          in the repo for changing the code when using A10s? it will not work out
          of the box unless you modify some settings as described there.
        updatedAt: '2023-05-02T12:30:33.442Z'
      numEdits: 0
      reactions: []
    id: 645102699d916c596e25c8b3
    type: comment
  author: srowen
  content: Learning rate is not related to mem usage. Are you following the instructions
    in the repo for changing the code when using A10s? it will not work out of the
    box unless you modify some settings as described there.
  created_at: 2023-05-02 11:30:33+00:00
  edited: false
  hidden: false
  id: 645102699d916c596e25c8b3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-05-03T09:02:49.000Z'
    data:
      edited: false
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: '<p>Yes, I''m following this exactly: <a rel="nofollow" href="https://github.com/databrickslabs/dolly#a10-gpus-1">https://github.com/databrickslabs/dolly#a10-gpus-1</a></p>

          '
        raw: 'Yes, I''m following this exactly: https://github.com/databrickslabs/dolly#a10-gpus-1'
        updatedAt: '2023-05-03T09:02:49.121Z'
      numEdits: 0
      reactions: []
    id: 64522339ae012a3da9a183db
    type: comment
  author: opyate
  content: 'Yes, I''m following this exactly: https://github.com/databrickslabs/dolly#a10-gpus-1'
  created_at: 2023-05-03 08:02:49+00:00
  edited: false
  hidden: false
  id: 64522339ae012a3da9a183db
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-03T12:16:29.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Oh, you have a g5.12xlarge. Try g5.24xlarge. I think that''s not
          enough RAM to load the model 4x into memory</p>

          '
        raw: Oh, you have a g5.12xlarge. Try g5.24xlarge. I think that's not enough
          RAM to load the model 4x into memory
        updatedAt: '2023-05-03T12:16:29.584Z'
      numEdits: 0
      reactions: []
    id: 6452509ddcfda85e982b3c96
    type: comment
  author: srowen
  content: Oh, you have a g5.12xlarge. Try g5.24xlarge. I think that's not enough
    RAM to load the model 4x into memory
  created_at: 2023-05-03 11:16:29+00:00
  edited: false
  hidden: false
  id: 6452509ddcfda85e982b3c96
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-05-05T07:58:13.000Z'
    data:
      edited: false
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: '<p>Ah, sorry - yes, that worked, and it took 5 hours to fine-tune my
          model. Thanks for your help!</p>

          '
        raw: Ah, sorry - yes, that worked, and it took 5 hours to fine-tune my model.
          Thanks for your help!
        updatedAt: '2023-05-05T07:58:13.560Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - srowen
    id: 6454b715a473375be567acec
    type: comment
  author: opyate
  content: Ah, sorry - yes, that worked, and it took 5 hours to fine-tune my model.
    Thanks for your help!
  created_at: 2023-05-05 06:58:13+00:00
  edited: false
  hidden: false
  id: 6454b715a473375be567acec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-05-23T05:13:02.000Z'
    data:
      edited: true
      editors:
      - abhi24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
          fullname: Abhilash Sanap
          isHf: false
          isPro: false
          name: abhi24
          type: user
        html: '<p>Hello opyate!<br>I''m also looking to fine tune dolly on ec2 g5.24xlarge
          instance. </p>

          <blockquote>

          <p>!deepspeed {num_gpus_flag} <br>    --module training.trainer <br>    --input-model
          {input_model} <br>    --deepspeed {deepspeed_config} <br>    --epochs 2
          <br>    --local-output-dir {local_output_dir} <br>    --dbfs-output-dir
          {dbfs_output_dir} <br>    --per-device-train-batch-size 3 <br>    --per-device-eval-batch-size
          3 <br>    --logging-steps 10 <br>    --save-steps 200 <br>    --save-total-limit
          20 <br>    --eval-steps 50 <br>    --warmup-steps 50 <br>    --test-size
          200 <br>    --lr 5e-6</p>

          <pre><code>

          </code></pre>

          </blockquote>

          <p>Did you run this command directly on terminal or was it part of another
          file? how are the values to variables in {} are passed?</p>

          <p>I''m looking into tutorials for using deepspeed but not been able to
          crack it. It would be great if you share how you used deepspeed to fine
          tune Dolly!<br>One tutorial mentioned to run ''accelerate config'' first
          and answer a bunch of questions. Is that the way to proceed?</p>

          <p>Thanks,<br>Abhilash</p>

          '
        raw: "Hello opyate!\nI'm also looking to fine tune dolly on ec2 g5.24xlarge\
          \ instance. \n\n> !deepspeed {num_gpus_flag} \\\n>     --module training.trainer\
          \ \\\n>     --input-model {input_model} \\\n>     --deepspeed {deepspeed_config}\
          \ \\\n>     --epochs 2 \\\n>     --local-output-dir {local_output_dir} \\\
          \n>     --dbfs-output-dir {dbfs_output_dir} \\\n>     --per-device-train-batch-size\
          \ 3 \\\n>     --per-device-eval-batch-size 3 \\\n>     --logging-steps 10\
          \ \\\n>     --save-steps 200 \\\n>     --save-total-limit 20 \\\n>     --eval-steps\
          \ 50 \\\n>     --warmup-steps 50 \\\n>     --test-size 200 \\\n>     --lr\
          \ 5e-6\n> ```\n\nDid you run this command directly on terminal or was it\
          \ part of another file? how are the values to variables in {} are passed?\n\
          \nI'm looking into tutorials for using deepspeed but not been able to crack\
          \ it. It would be great if you share how you used deepspeed to fine tune\
          \ Dolly!\nOne tutorial mentioned to run 'accelerate config' first and answer\
          \ a bunch of questions. Is that the way to proceed?\n\nThanks,\nAbhilash"
        updatedAt: '2023-05-23T05:29:32.222Z'
      numEdits: 1
      reactions: []
    id: 646c4b5eed228272134c8789
    type: comment
  author: abhi24
  content: "Hello opyate!\nI'm also looking to fine tune dolly on ec2 g5.24xlarge\
    \ instance. \n\n> !deepspeed {num_gpus_flag} \\\n>     --module training.trainer\
    \ \\\n>     --input-model {input_model} \\\n>     --deepspeed {deepspeed_config}\
    \ \\\n>     --epochs 2 \\\n>     --local-output-dir {local_output_dir} \\\n> \
    \    --dbfs-output-dir {dbfs_output_dir} \\\n>     --per-device-train-batch-size\
    \ 3 \\\n>     --per-device-eval-batch-size 3 \\\n>     --logging-steps 10 \\\n\
    >     --save-steps 200 \\\n>     --save-total-limit 20 \\\n>     --eval-steps\
    \ 50 \\\n>     --warmup-steps 50 \\\n>     --test-size 200 \\\n>     --lr 5e-6\n\
    > ```\n\nDid you run this command directly on terminal or was it part of another\
    \ file? how are the values to variables in {} are passed?\n\nI'm looking into\
    \ tutorials for using deepspeed but not been able to crack it. It would be great\
    \ if you share how you used deepspeed to fine tune Dolly!\nOne tutorial mentioned\
    \ to run 'accelerate config' first and answer a bunch of questions. Is that the\
    \ way to proceed?\n\nThanks,\nAbhilash"
  created_at: 2023-05-23 04:13:02+00:00
  edited: true
  hidden: false
  id: 646c4b5eed228272134c8789
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-05-23T08:16:57.000Z'
    data:
      edited: false
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: '<blockquote>

          <p>Did you run this command directly on terminal or was it part of another
          file? how are the values to variables in {} are passed?</p>

          </blockquote>

          <p>Hi, you can clone the dolly repo into Databricks, then open <a rel="nofollow"
          href="https://github.com/databrickslabs/dolly/blob/master/train_dolly.py">this
          notebook</a>, and it''s all there. Then just follow the extra guidance for
          <a rel="nofollow" href="https://github.com/databrickslabs/dolly#a10-gpus-1">A10
          GPUs</a>.</p>

          '
        raw: '> Did you run this command directly on terminal or was it part of another
          file? how are the values to variables in {} are passed?


          Hi, you can clone the dolly repo into Databricks, then open [this notebook](https://github.com/databrickslabs/dolly/blob/master/train_dolly.py),
          and it''s all there. Then just follow the extra guidance for [A10 GPUs](https://github.com/databrickslabs/dolly#a10-gpus-1).'
        updatedAt: '2023-05-23T08:16:57.406Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - abhi24
    id: 646c767910f66cc3c758eafb
    type: comment
  author: opyate
  content: '> Did you run this command directly on terminal or was it part of another
    file? how are the values to variables in {} are passed?


    Hi, you can clone the dolly repo into Databricks, then open [this notebook](https://github.com/databrickslabs/dolly/blob/master/train_dolly.py),
    and it''s all there. Then just follow the extra guidance for [A10 GPUs](https://github.com/databrickslabs/dolly#a10-gpus-1).'
  created_at: 2023-05-23 07:16:57+00:00
  edited: false
  hidden: false
  id: 646c767910f66cc3c758eafb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-23T11:55:01.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>deepspeed docs: <a rel="nofollow" href="https://deepspeed.readthedocs.io/en/latest/">https://deepspeed.readthedocs.io/en/latest/</a><br>accelerate
          is a different library.<br>You already have a working example linked from
          this model card: <a rel="nofollow" href="https://github.com/databrickslabs/dolly">https://github.com/databrickslabs/dolly</a></p>

          '
        raw: 'deepspeed docs: https://deepspeed.readthedocs.io/en/latest/

          accelerate is a different library.

          You already have a working example linked from this model card: https://github.com/databrickslabs/dolly'
        updatedAt: '2023-05-23T11:55:01.578Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - abhi24
    id: 646ca99510f66cc3c76441cf
    type: comment
  author: srowen
  content: 'deepspeed docs: https://deepspeed.readthedocs.io/en/latest/

    accelerate is a different library.

    You already have a working example linked from this model card: https://github.com/databrickslabs/dolly'
  created_at: 2023-05-23 10:55:01+00:00
  edited: false
  hidden: false
  id: 646ca99510f66cc3c76441cf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-05-23T21:23:02.000Z'
    data:
      edited: true
      editors:
      - abhi24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
          fullname: Abhilash Sanap
          isHf: false
          isPro: false
          name: abhi24
          type: user
        html: "<p>Many thanks both of you! I have been able to train the dolly-v2-3B\
          \ model on the 15k dataset. It has reached epoch = 0.41 and I hope it doesn't\
          \ get into any errors. </p>\n<p>My original aim, though, was to fine tune\
          \ the dolly-v2-3b on my custom data (Summarisation/Extraction). I have the\
          \ data ready in csv format. I just have to adapt it to the jsonl format.\
          \ </p>\n<ol>\n<li>The dolly 15k data has 4 fields - {\"instruction\": \u201C\
          \", \"context\": \"\", \"response\": , \"category\": \"\"}. Is it okay to\
          \ leave some of them blank? </li>\n<li>My data has many \"\\n\" in it. Should\
          \ I get rid of them?</li>\n</ol>\n<p>Any other thing to look out for?</p>\n\
          <p>Thanks</p>\n"
        raw: "Many thanks both of you! I have been able to train the dolly-v2-3B model\
          \ on the 15k dataset. It has reached epoch = 0.41 and I hope it doesn't\
          \ get into any errors. \n\nMy original aim, though, was to fine tune the\
          \ dolly-v2-3b on my custom data (Summarisation/Extraction). I have the data\
          \ ready in csv format. I just have to adapt it to the jsonl format. \n\n\
          1. The dolly 15k data has 4 fields - {\"instruction\": \u201C\", \"context\"\
          : \"\", \"response\": , \"category\": \"\"}. Is it okay to leave some of\
          \ them blank? \n2. My data has many \"\\n\" in it. Should I get rid of them?\n\
          \nAny other thing to look out for?\n\nThanks"
        updatedAt: '2023-05-23T21:27:35.603Z'
      numEdits: 1
      reactions: []
    id: 646d2eb64a2db774437ec5e2
    type: comment
  author: abhi24
  content: "Many thanks both of you! I have been able to train the dolly-v2-3B model\
    \ on the 15k dataset. It has reached epoch = 0.41 and I hope it doesn't get into\
    \ any errors. \n\nMy original aim, though, was to fine tune the dolly-v2-3b on\
    \ my custom data (Summarisation/Extraction). I have the data ready in csv format.\
    \ I just have to adapt it to the jsonl format. \n\n1. The dolly 15k data has 4\
    \ fields - {\"instruction\": \u201C\", \"context\": \"\", \"response\": , \"category\"\
    : \"\"}. Is it okay to leave some of them blank? \n2. My data has many \"\\n\"\
    \ in it. Should I get rid of them?\n\nAny other thing to look out for?\n\nThanks"
  created_at: 2023-05-23 20:23:02+00:00
  edited: true
  hidden: false
  id: 646d2eb64a2db774437ec5e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-05-23T21:27:00.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Category is actually unused. Context can be blank, yes, you can
          see that in some entries. You can see how it turns the fields into a string
          with prompt here: <a rel="nofollow" href="https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L109">https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L109</a>
          (You could even change the code to do whatever you want; in the end all
          you are feeding the model are strings)</p>

          '
        raw: 'Category is actually unused. Context can be blank, yes, you can see
          that in some entries. You can see how it turns the fields into a string
          with prompt here: https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L109
          (You could even change the code to do whatever you want; in the end all
          you are feeding the model are strings)'
        updatedAt: '2023-05-23T21:27:00.285Z'
      numEdits: 0
      reactions: []
    id: 646d2fa42abe5323fe1c96b1
    type: comment
  author: srowen
  content: 'Category is actually unused. Context can be blank, yes, you can see that
    in some entries. You can see how it turns the fields into a string with prompt
    here: https://github.com/databrickslabs/dolly/blob/master/training/trainer.py#L109
    (You could even change the code to do whatever you want; in the end all you are
    feeding the model are strings)'
  created_at: 2023-05-23 20:27:00+00:00
  edited: false
  hidden: false
  id: 646d2fa42abe5323fe1c96b1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-05-23T22:52:27.000Z'
    data:
      edited: false
      editors:
      - abhi24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
          fullname: Abhilash Sanap
          isHf: false
          isPro: false
          name: abhi24
          type: user
        html: '<p>Thanks!</p>

          '
        raw: Thanks!
        updatedAt: '2023-05-23T22:52:27.830Z'
      numEdits: 0
      reactions: []
    id: 646d43ab2abe5323fe1f9313
    type: comment
  author: abhi24
  content: Thanks!
  created_at: 2023-05-23 21:52:27+00:00
  edited: false
  hidden: false
  id: 646d43ab2abe5323fe1f9313
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: databricks/dolly-v2-3b
repo_type: model
status: closed
target_branch: null
title: Not sure about hyperparam `test-size` during fine-tuning
