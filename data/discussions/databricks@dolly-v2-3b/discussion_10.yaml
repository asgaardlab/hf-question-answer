!!python/object:huggingface_hub.community.DiscussionWithDetails
author: opyate
conflicting_files: null
created_at: 2023-04-25 16:08:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-04-25T17:08:44.000Z'
    data:
      edited: true
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: '<blockquote>

          <p>OSError: /local_disk0/dolly_training/dolly__2023-04-25T17:01:09 does
          not appear to have a file named config.json.</p>

          </blockquote>

          <p>I''ll investigate this tomorrow, but for now, here''s the error I''m
          getting:</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/joS6-qzQ3I0Rfluj8ioKz.png"><img
          alt="Screenshot from 2023-04-25 18-06-40.png" src="https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/joS6-qzQ3I0Rfluj8ioKz.png"></a></p>

          <p>It happens at the following step:</p>

          <pre><code>from training.generate import generate_response, load_model_tokenizer_for_generate


          model, tokenizer = load_model_tokenizer_for_generate(local_output_dir)

          </code></pre>

          '
        raw: '> OSError: /local_disk0/dolly_training/dolly__2023-04-25T17:01:09 does
          not appear to have a file named config.json.


          I''ll investigate this tomorrow, but for now, here''s the error I''m getting:



          ![Screenshot from 2023-04-25 18-06-40.png](https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/joS6-qzQ3I0Rfluj8ioKz.png)


          It happens at the following step:


          ```

          from training.generate import generate_response, load_model_tokenizer_for_generate


          model, tokenizer = load_model_tokenizer_for_generate(local_output_dir)

          ```'
        updatedAt: '2023-04-25T17:09:36.637Z'
      numEdits: 1
      reactions: []
    id: 6448091cab5c7251886ed72e
    type: comment
  author: opyate
  content: '> OSError: /local_disk0/dolly_training/dolly__2023-04-25T17:01:09 does
    not appear to have a file named config.json.


    I''ll investigate this tomorrow, but for now, here''s the error I''m getting:



    ![Screenshot from 2023-04-25 18-06-40.png](https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/joS6-qzQ3I0Rfluj8ioKz.png)


    It happens at the following step:


    ```

    from training.generate import generate_response, load_model_tokenizer_for_generate


    model, tokenizer = load_model_tokenizer_for_generate(local_output_dir)

    ```'
  created_at: 2023-04-25 16:08:44+00:00
  edited: true
  hidden: false
  id: 6448091cab5c7251886ed72e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-25T17:33:13.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>Can you show the contents of that directory? did training complete
          successfully?</p>

          '
        raw: Can you show the contents of that directory? did training complete successfully?
        updatedAt: '2023-04-25T17:33:13.068Z'
      numEdits: 0
      reactions: []
    id: 64480ed93411a0902bbddfd7
    type: comment
  author: srowen
  content: Can you show the contents of that directory? did training complete successfully?
  created_at: 2023-04-25 16:33:13+00:00
  edited: false
  hidden: false
  id: 64480ed93411a0902bbddfd7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-04-25T21:04:46.000Z'
    data:
      edited: false
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: '<p>Ah, ok - the training error was below the fold in the previous block,
          so I didn''t spot it.</p>

          <p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/r01X6jZZ3ezNHmKINpwg6.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/r01X6jZZ3ezNHmKINpwg6.png"></a></p>

          <p>Here''s the entire log from the frame below the above error:<br><a rel="nofollow"
          href="https://pastebin.com/uPwwqJbE">https://pastebin.com/uPwwqJbE</a></p>

          <p>I''m using this instance: <a rel="nofollow" href="https://aws.amazon.com/ec2/instance-types/g5/">g5.12xlarge</a>,
          so 4x A10G GPUs at 24GB each.</p>

          <pre><code>+-----------------------------------------------------------------------------+

          | NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |

          |-------------------------------+----------------------+----------------------+

          | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr.
          ECC |

          | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute
          M. |

          |                               |                      |               MIG
          M. |

          |===============================+======================+======================|

          |   0  NVIDIA A10G         Off  | 00000000:00:1B.0 Off |                    0
          |

          |  0%   28C    P0    57W / 300W |   7808MiB / 22731MiB |      0%      Default
          |

          |                               |                      |                  N/A
          |

          +-------------------------------+----------------------+----------------------+

          |   1  NVIDIA A10G         Off  | 00000000:00:1C.0 Off |                    0
          |

          |  0%   29C    P0    61W / 300W |   7926MiB / 22731MiB |      0%      Default
          |

          |                               |                      |                  N/A
          |

          +-------------------------------+----------------------+----------------------+

          |   2  NVIDIA A10G         Off  | 00000000:00:1D.0 Off |                    0
          |

          |  0%   29C    P0    59W / 300W |   5812MiB / 22731MiB |      0%      Default
          |

          |                               |                      |                  N/A
          |

          +-------------------------------+----------------------+----------------------+

          |   3  NVIDIA A10G         Off  | 00000000:00:1E.0 Off |                    0
          |

          |  0%   28C    P0    59W / 300W |   5546MiB / 22731MiB |      0%      Default
          |

          |                               |                      |                  N/A
          |

          +-------------------------------+----------------------+----------------------+

          </code></pre>

          <p>I''m trying pythia 3b (or 2.8b more specifically). Should I rather use
          a large GPU with more contiguous memory, like A100?</p>

          '
        raw: 'Ah, ok - the training error was below the fold in the previous block,
          so I didn''t spot it.


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/r01X6jZZ3ezNHmKINpwg6.png)


          Here''s the entire log from the frame below the above error:

          https://pastebin.com/uPwwqJbE


          I''m using this instance: [g5.12xlarge](https://aws.amazon.com/ec2/instance-types/g5/),
          so 4x A10G GPUs at 24GB each.


          ```

          +-----------------------------------------------------------------------------+

          | NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |

          |-------------------------------+----------------------+----------------------+

          | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr.
          ECC |

          | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute
          M. |

          |                               |                      |               MIG
          M. |

          |===============================+======================+======================|

          |   0  NVIDIA A10G         Off  | 00000000:00:1B.0 Off |                    0
          |

          |  0%   28C    P0    57W / 300W |   7808MiB / 22731MiB |      0%      Default
          |

          |                               |                      |                  N/A
          |

          +-------------------------------+----------------------+----------------------+

          |   1  NVIDIA A10G         Off  | 00000000:00:1C.0 Off |                    0
          |

          |  0%   29C    P0    61W / 300W |   7926MiB / 22731MiB |      0%      Default
          |

          |                               |                      |                  N/A
          |

          +-------------------------------+----------------------+----------------------+

          |   2  NVIDIA A10G         Off  | 00000000:00:1D.0 Off |                    0
          |

          |  0%   29C    P0    59W / 300W |   5812MiB / 22731MiB |      0%      Default
          |

          |                               |                      |                  N/A
          |

          +-------------------------------+----------------------+----------------------+

          |   3  NVIDIA A10G         Off  | 00000000:00:1E.0 Off |                    0
          |

          |  0%   28C    P0    59W / 300W |   5546MiB / 22731MiB |      0%      Default
          |

          |                               |                      |                  N/A
          |

          +-------------------------------+----------------------+----------------------+

          ```


          I''m trying pythia 3b (or 2.8b more specifically). Should I rather use a
          large GPU with more contiguous memory, like A100?'
        updatedAt: '2023-04-25T21:04:46.463Z'
      numEdits: 0
      reactions: []
    id: 6448406e3411a0902bc266ca
    type: comment
  author: opyate
  content: 'Ah, ok - the training error was below the fold in the previous block,
    so I didn''t spot it.


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/r01X6jZZ3ezNHmKINpwg6.png)


    Here''s the entire log from the frame below the above error:

    https://pastebin.com/uPwwqJbE


    I''m using this instance: [g5.12xlarge](https://aws.amazon.com/ec2/instance-types/g5/),
    so 4x A10G GPUs at 24GB each.


    ```

    +-----------------------------------------------------------------------------+

    | NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |

    |-------------------------------+----------------------+----------------------+

    | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC
    |

    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M.
    |

    |                               |                      |               MIG M.
    |

    |===============================+======================+======================|

    |   0  NVIDIA A10G         Off  | 00000000:00:1B.0 Off |                    0
    |

    |  0%   28C    P0    57W / 300W |   7808MiB / 22731MiB |      0%      Default
    |

    |                               |                      |                  N/A
    |

    +-------------------------------+----------------------+----------------------+

    |   1  NVIDIA A10G         Off  | 00000000:00:1C.0 Off |                    0
    |

    |  0%   29C    P0    61W / 300W |   7926MiB / 22731MiB |      0%      Default
    |

    |                               |                      |                  N/A
    |

    +-------------------------------+----------------------+----------------------+

    |   2  NVIDIA A10G         Off  | 00000000:00:1D.0 Off |                    0
    |

    |  0%   29C    P0    59W / 300W |   5812MiB / 22731MiB |      0%      Default
    |

    |                               |                      |                  N/A
    |

    +-------------------------------+----------------------+----------------------+

    |   3  NVIDIA A10G         Off  | 00000000:00:1E.0 Off |                    0
    |

    |  0%   28C    P0    59W / 300W |   5546MiB / 22731MiB |      0%      Default
    |

    |                               |                      |                  N/A
    |

    +-------------------------------+----------------------+----------------------+

    ```


    I''m trying pythia 3b (or 2.8b more specifically). Should I rather use a large
    GPU with more contiguous memory, like A100?'
  created_at: 2023-04-25 20:04:46+00:00
  edited: false
  hidden: false
  id: 6448406e3411a0902bc266ca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-25T21:17:43.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>The error you show isn''t actually an error, it''s a weird ignorable
          error from the notebook (Databricks needs to fix that). Is there more below?
          did the training show a problem in the actual cell output? my guess is it
          didn''t finish, but we don''t see that output. </p>

          <p>4 x A10 is fine for the smallest model, but, did you see these instructions?
          <a rel="nofollow" href="https://github.com/databrickslabs/dolly#a10-gpus-1">https://github.com/databrickslabs/dolly#a10-gpus-1</a>
          You need to set batch size to 3 or less.</p>

          '
        raw: "The error you show isn't actually an error, it's a weird ignorable error\
          \ from the notebook (Databricks needs to fix that). Is there more below?\
          \ did the training show a problem in the actual cell output? my guess is\
          \ it didn't finish, but we don't see that output. \n\n4 x A10 is fine for\
          \ the smallest model, but, did you see these instructions? https://github.com/databrickslabs/dolly#a10-gpus-1\
          \ You need to set batch size to 3 or less."
        updatedAt: '2023-04-25T21:17:43.452Z'
      numEdits: 0
      reactions: []
    id: 64484377e54b488070b73004
    type: comment
  author: srowen
  content: "The error you show isn't actually an error, it's a weird ignorable error\
    \ from the notebook (Databricks needs to fix that). Is there more below? did the\
    \ training show a problem in the actual cell output? my guess is it didn't finish,\
    \ but we don't see that output. \n\n4 x A10 is fine for the smallest model, but,\
    \ did you see these instructions? https://github.com/databrickslabs/dolly#a10-gpus-1\
    \ You need to set batch size to 3 or less."
  created_at: 2023-04-25 20:17:43+00:00
  edited: false
  hidden: false
  id: 64484377e54b488070b73004
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-04-26T14:10:52.000Z'
    data:
      edited: true
      editors:
      - opyate
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
          fullname: Juan Uys
          isHf: false
          isPro: false
          name: opyate
          type: user
        html: '<p>Thanks for the guidance. I made the change in this PR, and it worked:
          <a rel="nofollow" href="https://github.com/databrickslabs/dolly/pull/135">https://github.com/databrickslabs/dolly/pull/135</a></p>

          <p>My thinking is that the missing <code>datetime</code> import resulted
          in the timestamped output directory not being created, hence my error.</p>

          <p>I successfully trained a 3b model on Databricks with the above GPU configuration
          in 5.6 hours.</p>

          <p>EDIT: the PR is moot. One of my cells didn''t run, so <code>datetime</code>
          wasn''t imported in an earlier cell.</p>

          '
        raw: 'Thanks for the guidance. I made the change in this PR, and it worked:
          https://github.com/databrickslabs/dolly/pull/135


          My thinking is that the missing `datetime` import resulted in the timestamped
          output directory not being created, hence my error.


          I successfully trained a 3b model on Databricks with the above GPU configuration
          in 5.6 hours.


          EDIT: the PR is moot. One of my cells didn''t run, so `datetime` wasn''t
          imported in an earlier cell.'
        updatedAt: '2023-04-26T14:24:52.608Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - srowen
    id: 644930ecab5abd9278645d68
    type: comment
  author: opyate
  content: 'Thanks for the guidance. I made the change in this PR, and it worked:
    https://github.com/databrickslabs/dolly/pull/135


    My thinking is that the missing `datetime` import resulted in the timestamped
    output directory not being created, hence my error.


    I successfully trained a 3b model on Databricks with the above GPU configuration
    in 5.6 hours.


    EDIT: the PR is moot. One of my cells didn''t run, so `datetime` wasn''t imported
    in an earlier cell.'
  created_at: 2023-04-26 13:10:52+00:00
  edited: true
  hidden: false
  id: 644930ecab5abd9278645d68
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/630f1f7502ce39336c3faf40/GNFO3mU9Sn3OTAxVHWrsh.jpeg?w=200&h=200&f=face
      fullname: Juan Uys
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: opyate
      type: user
    createdAt: '2023-04-27T14:39:00.000Z'
    data:
      status: closed
    id: 644a8904e3a902dbe0049c73
    type: status-change
  author: opyate
  created_at: 2023-04-27 13:39:00+00:00
  id: 644a8904e3a902dbe0049c73
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: databricks/dolly-v2-3b
repo_type: model
status: closed
target_branch: null
title: Error whilst running the dolly repo on Databricks
