!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Judklp
conflicting_files: null
created_at: 2023-04-24 00:43:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/01e88d51631e9857964563e1092863ce.svg
      fullname: Judicael
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Judklp
      type: user
    createdAt: '2023-04-24T01:43:12.000Z'
    data:
      edited: false
      editors:
      - Judklp
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/01e88d51631e9857964563e1092863ce.svg
          fullname: Judicael
          isHf: false
          isPro: false
          name: Judklp
          type: user
        html: '<p>I am trying to run the model in a few seconds for getting an answer.
          My difficulty is to provision a GPU fast enough. I have tried on OVH, Google
          cloud, Amazon and Azure, spend countless hours on it, trying to provision
          A10s, A100 sor V100s. Either I cannot get approved for enough GPUs (Amazon
          , Google) or their are not available to be provisioned (A100 and A10 in
          particular) . The fastest instance I could get with enough memory was a
          a T4 but it take 10 minutes per answer even with 3b model..too slow<br>Any
          advice on which cloud service a can provision a GPU fast enough ? really
          wondering how other are doing.</p>

          '
        raw: "I am trying to run the model in a few seconds for getting an answer.\
          \ My difficulty is to provision a GPU fast enough. I have tried on OVH,\
          \ Google cloud, Amazon and Azure, spend countless hours on it, trying to\
          \ provision A10s, A100 sor V100s. Either I cannot get approved for enough\
          \ GPUs (Amazon , Google) or their are not available to be provisioned (A100\
          \ and A10 in particular) . The fastest instance I could get with enough\
          \ memory was a a T4 but it take 10 minutes per answer even with 3b model..too\
          \ slow\r\nAny advice on which cloud service a can provision a GPU fast enough\
          \ ? really wondering how other are doing.\r\n"
        updatedAt: '2023-04-24T01:43:12.336Z'
      numEdits: 0
      reactions: []
    id: 6445deb01cfc9ae6bb405b6f
    type: comment
  author: Judklp
  content: "I am trying to run the model in a few seconds for getting an answer. My\
    \ difficulty is to provision a GPU fast enough. I have tried on OVH, Google cloud,\
    \ Amazon and Azure, spend countless hours on it, trying to provision A10s, A100\
    \ sor V100s. Either I cannot get approved for enough GPUs (Amazon , Google) or\
    \ their are not available to be provisioned (A100 and A10 in particular) . The\
    \ fastest instance I could get with enough memory was a a T4 but it take 10 minutes\
    \ per answer even with 3b model..too slow\r\nAny advice on which cloud service\
    \ a can provision a GPU fast enough ? really wondering how other are doing.\r\n"
  created_at: 2023-04-24 00:43:12+00:00
  edited: false
  hidden: false
  id: 6445deb01cfc9ae6bb405b6f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-24T01:54:43.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>A100s are pretty hard to provision, overall. I haven''t had any
          trouble with A10 or V100 on AWS and Azure, for what it''s worth. Do not
          use spot instances. Try switching to a region with better availability,
          maybe.</p>

          '
        raw: A100s are pretty hard to provision, overall. I haven't had any trouble
          with A10 or V100 on AWS and Azure, for what it's worth. Do not use spot
          instances. Try switching to a region with better availability, maybe.
        updatedAt: '2023-04-24T01:54:43.656Z'
      numEdits: 0
      reactions: []
    id: 6445e16353ecc52f50fa6202
    type: comment
  author: srowen
  content: A100s are pretty hard to provision, overall. I haven't had any trouble
    with A10 or V100 on AWS and Azure, for what it's worth. Do not use spot instances.
    Try switching to a region with better availability, maybe.
  created_at: 2023-04-24 00:54:43+00:00
  edited: false
  hidden: false
  id: 6445e16353ecc52f50fa6202
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-25T17:33:25.000Z'
    data:
      status: closed
    id: 64480ee53411a0902bbde112
    type: status-change
  author: srowen
  created_at: 2023-04-25 16:33:25+00:00
  id: 64480ee53411a0902bbde112
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: databricks/dolly-v2-3b
repo_type: model
status: closed
target_branch: null
title: How to find the right cloud ? Help
