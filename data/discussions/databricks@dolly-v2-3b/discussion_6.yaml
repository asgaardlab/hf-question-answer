!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abhi24
conflicting_files: null
created_at: 2023-04-20 19:59:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-04-20T20:59:31.000Z'
    data:
      edited: true
      editors:
      - abhi24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
          fullname: Abhilash Sanap
          isHf: false
          isPro: false
          name: abhi24
          type: user
        html: '<p>Hello!<br>I have only tried the Dolly v2 12b so far. I''m curious
          if anyone has tried all three. </p>

          <ol>

          <li>Is there a considerable difference in the response time?</li>

          <li>If I were to finetune the model, do I need lesser training samples if
          I use smaller models?</li>

          </ol>

          <p>Thanks,<br>Abhilash</p>

          '
        raw: "Hello!\nI have only tried the Dolly v2 12b so far. I'm curious if anyone\
          \ has tried all three. \n\n1. Is there a considerable difference in the\
          \ response time?\n2. If I were to finetune the model, do I need lesser training\
          \ samples if I use smaller models?\n\nThanks,\nAbhilash"
        updatedAt: '2023-04-20T21:05:35.155Z'
      numEdits: 1
      reactions: []
    id: 6441a7b3ad24e9b2cfbf73b7
    type: comment
  author: abhi24
  content: "Hello!\nI have only tried the Dolly v2 12b so far. I'm curious if anyone\
    \ has tried all three. \n\n1. Is there a considerable difference in the response\
    \ time?\n2. If I were to finetune the model, do I need lesser training samples\
    \ if I use smaller models?\n\nThanks,\nAbhilash"
  created_at: 2023-04-20 19:59:31+00:00
  edited: true
  hidden: false
  id: 6441a7b3ad24e9b2cfbf73b7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-04-20T20:59:48.000Z'
    data:
      from: Response time comparison among 3b, 7b and 12b
      to: Response time comparison among Dolly v2 3b, 7b and 12b
    id: 6441a7c47f13a7b5a26d5ed7
    type: title-change
  author: abhi24
  created_at: 2023-04-20 19:59:48+00:00
  id: 6441a7c47f13a7b5a26d5ed7
  new_title: Response time comparison among Dolly v2 3b, 7b and 12b
  old_title: Response time comparison among 3b, 7b and 12b
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-04-20T21:04:10.000Z'
    data:
      from: Response time comparison among Dolly v2 3b, 7b and 12b
      to: Comparison among Dolly v2 3b, 7b and 12b
    id: 6441a8ca4c2acf3398ae6094
    type: title-change
  author: abhi24
  created_at: 2023-04-20 20:04:10+00:00
  id: 6441a8ca4c2acf3398ae6094
  new_title: Comparison among Dolly v2 3b, 7b and 12b
  old_title: Response time comparison among Dolly v2 3b, 7b and 12b
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-21T00:28:54.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>I can tell you that on an A10, generation takes maybe 2-5 seconds
          for the 3B model, 5-15 sec for the 7B model, and in 8bit the 12B model takes
          about 15-40 seconds. It really varies depending on the generation settings
          and how long the response ends up being. (I''d try an A100 but I can''t
          get one at the moment!)</p>

          <p>For real-time use, you''d be doing some more work than just loading an
          HF pipeline. Multiple GPUs, FastTokenizer, etc.</p>

          '
        raw: 'I can tell you that on an A10, generation takes maybe 2-5 seconds for
          the 3B model, 5-15 sec for the 7B model, and in 8bit the 12B model takes
          about 15-40 seconds. It really varies depending on the generation settings
          and how long the response ends up being. (I''d try an A100 but I can''t
          get one at the moment!)


          For real-time use, you''d be doing some more work than just loading an HF
          pipeline. Multiple GPUs, FastTokenizer, etc.'
        updatedAt: '2023-04-21T00:28:54.483Z'
      numEdits: 0
      reactions: []
    id: 6441d8c694de4da2585b2c44
    type: comment
  author: srowen
  content: 'I can tell you that on an A10, generation takes maybe 2-5 seconds for
    the 3B model, 5-15 sec for the 7B model, and in 8bit the 12B model takes about
    15-40 seconds. It really varies depending on the generation settings and how long
    the response ends up being. (I''d try an A100 but I can''t get one at the moment!)


    For real-time use, you''d be doing some more work than just loading an HF pipeline.
    Multiple GPUs, FastTokenizer, etc.'
  created_at: 2023-04-20 23:28:54+00:00
  edited: false
  hidden: false
  id: 6441d8c694de4da2585b2c44
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-04-21T02:13:43.000Z'
    data:
      edited: false
      editors:
      - abhi24
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
          fullname: Abhilash Sanap
          isHf: false
          isPro: false
          name: abhi24
          type: user
        html: "<p>Thank you <span data-props=\"{&quot;user&quot;:&quot;srowen&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/srowen\"\
          >@<span class=\"underline\">srowen</span></a></span>\n\n\t</span></span>!\
          \ </p>\n<p>Can you please tell me if I'll need lesser number of training\
          \ instances if I'm fine tuning a 3b model vs 12b one?</p>\n<p>Thanks!</p>\n"
        raw: "Thank you @srowen! \n\nCan you please tell me if I'll need lesser number\
          \ of training instances if I'm fine tuning a 3b model vs 12b one?\n\nThanks!"
        updatedAt: '2023-04-21T02:13:43.937Z'
      numEdits: 0
      reactions: []
    id: 6441f15755a16ae60fa68746
    type: comment
  author: abhi24
  content: "Thank you @srowen! \n\nCan you please tell me if I'll need lesser number\
    \ of training instances if I'm fine tuning a 3b model vs 12b one?\n\nThanks!"
  created_at: 2023-04-21 01:13:43+00:00
  edited: false
  hidden: false
  id: 6441f15755a16ae60fa68746
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
      fullname: Sean Owen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: srowen
      type: user
    createdAt: '2023-04-21T02:20:58.000Z'
    data:
      edited: false
      editors:
      - srowen
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63050fbfce6b12280b1e2976/2lJphRSgdt9B_5YAQ1SIs.jpeg?w=200&h=200&f=face
          fullname: Sean Owen
          isHf: false
          isPro: false
          name: srowen
          type: user
        html: '<p>I don''t think there is necessarily a strong relationship there,
          but I''m not an expert. I would use as much as you''ve got!</p>

          '
        raw: I don't think there is necessarily a strong relationship there, but I'm
          not an expert. I would use as much as you've got!
        updatedAt: '2023-04-21T02:20:58.914Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - abhi24
    id: 6441f30a55a16ae60fa6be88
    type: comment
  author: srowen
  content: I don't think there is necessarily a strong relationship there, but I'm
    not an expert. I would use as much as you've got!
  created_at: 2023-04-21 01:20:58+00:00
  edited: false
  hidden: false
  id: 6441f30a55a16ae60fa6be88
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/c03bc3c7b2c20b91387d0f2d44107336.svg
      fullname: Abhilash Sanap
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhi24
      type: user
    createdAt: '2023-04-21T02:54:59.000Z'
    data:
      status: closed
    id: 6441fb030771bec9d26da2b3
    type: status-change
  author: abhi24
  created_at: 2023-04-21 01:54:59+00:00
  id: 6441fb030771bec9d26da2b3
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: databricks/dolly-v2-3b
repo_type: model
status: closed
target_branch: null
title: Comparison among Dolly v2 3b, 7b and 12b
