!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hyzhak
conflicting_files: null
created_at: 2023-09-30 07:01:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f23bae5a9063d79256aae707689308cb.svg
      fullname: Ievgenii Krevenets
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hyzhak
      type: user
    createdAt: '2023-09-30T08:01:26.000Z'
    data:
      edited: true
      editors:
      - hyzhak
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8696954250335693
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f23bae5a9063d79256aae707689308cb.svg
          fullname: Ievgenii Krevenets
          isHf: false
          isPro: false
          name: hyzhak
          type: user
        html: '<p>Hi team,</p>

          <p>I''m passing request to the LLM model and it repeats my request (with
          slight variation) and add response to it. Is it expected?</p>

          <ul>

          <li>revision: <code>gptq-4bit-32g-actorder_True</code></li>

          <li>do_sample: True</li>

          <li>temperature: 0.25</li>

          <li>repetition_penalty: 1.2</li>

          <li>max_new_tokens: 512</li>

          </ul>

          <h2 id="example-i-tried-use-instruction-like-inst-but-it-didnt-help">Example
          (I tried use instruction like [INST] but it didn''t help).</h2>

          <p>Input:</p>

          <pre><code>Please write a haiku about llama

          </code></pre>

          <p>output from TheBloke/Llama-2-7b-Chat-GPTQ:</p>

          <pre><code>Please write a haiku about llama-ing.


          Here is my attempt:

          Llama''s gentle glow,

          Softly grazes the landscape,

          Serenity found.

          </code></pre>

          <p>output from TheBloke/Llama-2-7b-GPTQ:</p>

          <pre><code>Please write a haiku about llama.

          I''ll start:

          Llama is my friend,

          He lives in the zoo.

          His name is Llamalot!

          Reactions: Squirrel_and_Bird and TigerTankFan

          </code></pre>

          <p>Is there any way to prevent Llama2 to repeat request, since like in a
          case with <em>"llama-ing"</em> it isn''t no only removing few similar characters
          at the beginning, sometimes it could be more.</p>

          '
        raw: 'Hi team,


          I''m passing request to the LLM model and it repeats my request (with slight
          variation) and add response to it. Is it expected?

          - revision: `gptq-4bit-32g-actorder_True`

          - do_sample: True

          - temperature: 0.25

          - repetition_penalty: 1.2

          - max_new_tokens: 512


          ## Example (I tried use instruction like [INST] but it didn''t help).

          Input:

          ```

          Please write a haiku about llama

          ```

          output from TheBloke/Llama-2-7b-Chat-GPTQ:

          ```

          Please write a haiku about llama-ing.


          Here is my attempt:

          Llama''s gentle glow,

          Softly grazes the landscape,

          Serenity found.

          ```

          output from TheBloke/Llama-2-7b-GPTQ:

          ```

          Please write a haiku about llama.

          I''ll start:

          Llama is my friend,

          He lives in the zoo.

          His name is Llamalot!

          Reactions: Squirrel_and_Bird and TigerTankFan

          ```


          Is there any way to prevent Llama2 to repeat request, since like in a case
          with _"llama-ing"_ it isn''t no only removing few similar characters at
          the beginning, sometimes it could be more.'
        updatedAt: '2023-09-30T08:11:19.752Z'
      numEdits: 1
      reactions: []
    id: 6517d5d6fff98a48b2bfdecb
    type: comment
  author: hyzhak
  content: 'Hi team,


    I''m passing request to the LLM model and it repeats my request (with slight variation)
    and add response to it. Is it expected?

    - revision: `gptq-4bit-32g-actorder_True`

    - do_sample: True

    - temperature: 0.25

    - repetition_penalty: 1.2

    - max_new_tokens: 512


    ## Example (I tried use instruction like [INST] but it didn''t help).

    Input:

    ```

    Please write a haiku about llama

    ```

    output from TheBloke/Llama-2-7b-Chat-GPTQ:

    ```

    Please write a haiku about llama-ing.


    Here is my attempt:

    Llama''s gentle glow,

    Softly grazes the landscape,

    Serenity found.

    ```

    output from TheBloke/Llama-2-7b-GPTQ:

    ```

    Please write a haiku about llama.

    I''ll start:

    Llama is my friend,

    He lives in the zoo.

    His name is Llamalot!

    Reactions: Squirrel_and_Bird and TigerTankFan

    ```


    Is there any way to prevent Llama2 to repeat request, since like in a case with
    _"llama-ing"_ it isn''t no only removing few similar characters at the beginning,
    sometimes it could be more.'
  created_at: 2023-09-30 07:01:26+00:00
  edited: true
  hidden: false
  id: 6517d5d6fff98a48b2bfdecb
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 22
repo_id: TheBloke/Llama-2-7B-Chat-GPTQ
repo_type: model
status: open
target_branch: null
title: TheBloke/Llama-2-7b-(Chat-)GPTQ repeats request
