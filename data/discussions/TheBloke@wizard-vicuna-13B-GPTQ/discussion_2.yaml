!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ptamas
conflicting_files: null
created_at: 2023-05-06 07:23:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/616742740e47eb33b79818f959a1fd40.svg
      fullname: peter tamas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ptamas
      type: user
    createdAt: '2023-05-06T08:23:31.000Z'
    data:
      edited: false
      editors:
      - ptamas
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/616742740e47eb33b79818f959a1fd40.svg
          fullname: peter tamas
          isHf: false
          isPro: false
          name: ptamas
          type: user
        html: '<p>Hi<br>install is throwing this error<br>OSError: Error no file named
          pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack found
          in directory models/TheBloke_wizard-vicuna-13B-GPTQ.</p>

          '
        raw: "Hi\r\ninstall is throwing this error\r\nOSError: Error no file named\
          \ pytorch_model.bin, tf_model.h5, model.ckpt.index or flax_model.msgpack\
          \ found in directory models/TheBloke_wizard-vicuna-13B-GPTQ."
        updatedAt: '2023-05-06T08:23:31.765Z'
      numEdits: 0
      reactions: []
    id: 64560e83aaaf85a98fa9c151
    type: comment
  author: ptamas
  content: "Hi\r\ninstall is throwing this error\r\nOSError: Error no file named pytorch_model.bin,\
    \ tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory models/TheBloke_wizard-vicuna-13B-GPTQ."
  created_at: 2023-05-06 07:23:31+00:00
  edited: false
  hidden: false
  id: 64560e83aaaf85a98fa9c151
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-06T13:24:52.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Please check the README and follow the instructions for text-generation-webui.
          You need to set the GPTQ parameters and "save this model" and "reload this
          model".</p>

          '
        raw: Please check the README and follow the instructions for text-generation-webui.
          You need to set the GPTQ parameters and "save this model" and "reload this
          model".
        updatedAt: '2023-05-06T13:24:52.373Z'
      numEdits: 0
      reactions: []
    id: 6456552478c059b099b17e9e
    type: comment
  author: TheBloke
  content: Please check the README and follow the instructions for text-generation-webui.
    You need to set the GPTQ parameters and "save this model" and "reload this model".
  created_at: 2023-05-06 12:24:52+00:00
  edited: false
  hidden: false
  id: 6456552478c059b099b17e9e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ee0177dc2851892f90c6e107616e14db.svg
      fullname: Aman Goyal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: amangoyal
      type: user
    createdAt: '2023-05-06T13:26:08.000Z'
    data:
      edited: false
      editors:
      - amangoyal
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ee0177dc2851892f90c6e107616e14db.svg
          fullname: Aman Goyal
          isHf: false
          isPro: false
          name: amangoyal
          type: user
        html: '<blockquote>

          <p>Please check the README and follow the instructions for text-generation-webui.
          You need to set the GPTQ parameters and "save this model" and "reload this
          model".</p>

          </blockquote>

          <p>This!<br>Or you can also load the model with these params<br><code>--wbits
          4 --groupsize 128 --model_type "Llama"</code></p>

          '
        raw: '> Please check the README and follow the instructions for text-generation-webui.
          You need to set the GPTQ parameters and "save this model" and "reload this
          model".


          This!

          Or you can also load the model with these params

          `--wbits 4 --groupsize 128 --model_type "Llama"`'
        updatedAt: '2023-05-06T13:26:08.973Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TheBloke
    id: 64565570d10badc9555ab813
    type: comment
  author: amangoyal
  content: '> Please check the README and follow the instructions for text-generation-webui.
    You need to set the GPTQ parameters and "save this model" and "reload this model".


    This!

    Or you can also load the model with these params

    `--wbits 4 --groupsize 128 --model_type "Llama"`'
  created_at: 2023-05-06 12:26:08+00:00
  edited: false
  hidden: false
  id: 64565570d10badc9555ab813
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f85c5b4c90e014b191f64e5e670258eb.svg
      fullname: Wai Shing Fung
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wsfung2008
      type: user
    createdAt: '2023-05-06T14:06:37.000Z'
    data:
      edited: false
      editors:
      - wsfung2008
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f85c5b4c90e014b191f64e5e670258eb.svg
          fullname: Wai Shing Fung
          isHf: false
          isPro: false
          name: wsfung2008
          type: user
        html: '<p>Can this be used directly with AutoModelForCausalLM.from_pretrained
          if I dont need the text-generation-webui?<br>I am getting the same error.</p>

          '
        raw: 'Can this be used directly with AutoModelForCausalLM.from_pretrained
          if I dont need the text-generation-webui?

          I am getting the same error.'
        updatedAt: '2023-05-06T14:06:37.402Z'
      numEdits: 0
      reactions: []
    id: 64565eedcd6567f52fb5055f
    type: comment
  author: wsfung2008
  content: 'Can this be used directly with AutoModelForCausalLM.from_pretrained if
    I dont need the text-generation-webui?

    I am getting the same error.'
  created_at: 2023-05-06 13:06:37+00:00
  edited: false
  hidden: false
  id: 64565eedcd6567f52fb5055f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-06T14:12:54.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<blockquote>

          <p>Can this be used directly with AutoModelForCausalLM.from_pretrained if
          I dont need the text-generation-webui?</p>

          </blockquote>

          <p>No.  With AutoGPTQ it can be used in a manner quite similar to that.  AutoGPTQ
          will be the future of GPTQ and supports nice easy inference from Python
          code.  It''s currently still in development and has a number of issues,
          so I can''t blanket recommend it to you right now.  But in a few days to
          a week I will be able to.</p>

          <p>If you really want to do Python inference from a GPTQ model right now,
          check out this discussion thread <a href="https://huggingface.co/TheBloke/stable-vicuna-13B-GPTQ/discussions/1#644cc8af97a3b0904a481e3e">https://huggingface.co/TheBloke/stable-vicuna-13B-GPTQ/discussions/1#644cc8af97a3b0904a481e3e</a>
          . It has working code in it, that uses GPTQ-for-LLaMa.</p>

          <blockquote>

          <p>I am getting the same error.</p>

          </blockquote>

          <p>If you''re still getting the error after saving the model settings, then
          it sounds like the model isn''t installed properly. I''d suggest deleting
          it and following the "easy install instructions for text-generation-webui"
          from the beginning, and making sure you''re following every step.</p>

          '
        raw: '> Can this be used directly with AutoModelForCausalLM.from_pretrained
          if I dont need the text-generation-webui?


          No.  With AutoGPTQ it can be used in a manner quite similar to that.  AutoGPTQ
          will be the future of GPTQ and supports nice easy inference from Python
          code.  It''s currently still in development and has a number of issues,
          so I can''t blanket recommend it to you right now.  But in a few days to
          a week I will be able to.


          If you really want to do Python inference from a GPTQ model right now, check
          out this discussion thread https://huggingface.co/TheBloke/stable-vicuna-13B-GPTQ/discussions/1#644cc8af97a3b0904a481e3e
          . It has working code in it, that uses GPTQ-for-LLaMa.


          > I am getting the same error.


          If you''re still getting the error after saving the model settings, then
          it sounds like the model isn''t installed properly. I''d suggest deleting
          it and following the "easy install instructions for text-generation-webui"
          from the beginning, and making sure you''re following every step.'
        updatedAt: '2023-05-06T14:13:46.868Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - wsfung2008
    id: 64566066cd6567f52fb52035
    type: comment
  author: TheBloke
  content: '> Can this be used directly with AutoModelForCausalLM.from_pretrained
    if I dont need the text-generation-webui?


    No.  With AutoGPTQ it can be used in a manner quite similar to that.  AutoGPTQ
    will be the future of GPTQ and supports nice easy inference from Python code.  It''s
    currently still in development and has a number of issues, so I can''t blanket
    recommend it to you right now.  But in a few days to a week I will be able to.


    If you really want to do Python inference from a GPTQ model right now, check out
    this discussion thread https://huggingface.co/TheBloke/stable-vicuna-13B-GPTQ/discussions/1#644cc8af97a3b0904a481e3e
    . It has working code in it, that uses GPTQ-for-LLaMa.


    > I am getting the same error.


    If you''re still getting the error after saving the model settings, then it sounds
    like the model isn''t installed properly. I''d suggest deleting it and following
    the "easy install instructions for text-generation-webui" from the beginning,
    and making sure you''re following every step.'
  created_at: 2023-05-06 13:12:54+00:00
  edited: true
  hidden: false
  id: 64566066cd6567f52fb52035
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/16c1106c83c1191be46fde23f54243c9.svg
      fullname: Luke
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Holonet
      type: user
    createdAt: '2023-05-06T17:11:39.000Z'
    data:
      edited: false
      editors:
      - Holonet
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/16c1106c83c1191be46fde23f54243c9.svg
          fullname: Luke
          isHf: false
          isPro: false
          name: Holonet
          type: user
        html: '<p>One irritation about oobabooga is that it makes you choose a model
          to load when you start it up.  If the only model you have in your models
          directory is a model that throws an error, then you can''t go in and save
          the parameters via the webui, because it never starts up.  I think a workaround
          to this would be, in the models folder, create/edit the config-user.yaml
          file manually (which is all the UI is really doing, I believe), and add
          this:</p>

          <p>wizard-vicuna-13B-GPTQ:<br>  auto_devices: false<br>  bf16: false<br>  cpu:
          false<br>  cpu_memory: 0<br>  disk: false<br>  gpu_memory_0: 0<br>  groupsize:
          ''128''<br>  load_in_8bit: false<br>  model_type: llama<br>  pre_layer:
          0<br>  wbits: ''4''</p>

          '
        raw: "One irritation about oobabooga is that it makes you choose a model to\
          \ load when you start it up.  If the only model you have in your models\
          \ directory is a model that throws an error, then you can't go in and save\
          \ the parameters via the webui, because it never starts up.  I think a workaround\
          \ to this would be, in the models folder, create/edit the config-user.yaml\
          \ file manually (which is all the UI is really doing, I believe), and add\
          \ this:\n\nwizard-vicuna-13B-GPTQ:\n  auto_devices: false\n  bf16: false\n\
          \  cpu: false\n  cpu_memory: 0\n  disk: false\n  gpu_memory_0: 0\n  groupsize:\
          \ '128'\n  load_in_8bit: false\n  model_type: llama\n  pre_layer: 0\n  wbits:\
          \ '4'"
        updatedAt: '2023-05-06T17:11:39.735Z'
      numEdits: 0
      reactions: []
    id: 64568a4bd10badc9555e3e85
    type: comment
  author: Holonet
  content: "One irritation about oobabooga is that it makes you choose a model to\
    \ load when you start it up.  If the only model you have in your models directory\
    \ is a model that throws an error, then you can't go in and save the parameters\
    \ via the webui, because it never starts up.  I think a workaround to this would\
    \ be, in the models folder, create/edit the config-user.yaml file manually (which\
    \ is all the UI is really doing, I believe), and add this:\n\nwizard-vicuna-13B-GPTQ:\n\
    \  auto_devices: false\n  bf16: false\n  cpu: false\n  cpu_memory: 0\n  disk:\
    \ false\n  gpu_memory_0: 0\n  groupsize: '128'\n  load_in_8bit: false\n  model_type:\
    \ llama\n  pre_layer: 0\n  wbits: '4'"
  created_at: 2023-05-06 16:11:39+00:00
  edited: false
  hidden: false
  id: 64568a4bd10badc9555e3e85
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/76f92b41f85d3a901911f962660830ed.svg
      fullname: a749734
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: a749734
      type: user
    createdAt: '2023-05-31T14:15:36.000Z'
    data:
      edited: false
      editors:
      - a749734
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/76f92b41f85d3a901911f962660830ed.svg
          fullname: a749734
          isHf: false
          isPro: false
          name: a749734
          type: user
        html: '<p>OSError: TheBloke/wizard-vicuna-13B-GPTQ does not appear to have
          a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack<br>error
          after downloading , what to do here</p>

          '
        raw: 'OSError: TheBloke/wizard-vicuna-13B-GPTQ does not appear to have a file
          named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack

          error after downloading , what to do here'
        updatedAt: '2023-05-31T14:15:36.590Z'
      numEdits: 0
      reactions: []
    id: 6477568804aa03da2abb532f
    type: comment
  author: a749734
  content: 'OSError: TheBloke/wizard-vicuna-13B-GPTQ does not appear to have a file
    named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack

    error after downloading , what to do here'
  created_at: 2023-05-31 13:15:36+00:00
  edited: false
  hidden: false
  id: 6477568804aa03da2abb532f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-31T17:01:08.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;a749734&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/a749734\">@<span class=\"\
          underline\">a749734</span></a></span>\n\n\t</span></span> Please check the\
          \ README again. You need to set GPTQ parameters and then \"Save settings\
          \ for this model\" and \"reload this model\"</p>\n"
        raw: '@a749734 Please check the README again. You need to set GPTQ parameters
          and then "Save settings for this model" and "reload this model"'
        updatedAt: '2023-05-31T17:01:08.970Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Nurb432
    id: 64777d5404aa03da2abf06a7
    type: comment
  author: TheBloke
  content: '@a749734 Please check the README again. You need to set GPTQ parameters
    and then "Save settings for this model" and "reload this model"'
  created_at: 2023-05-31 16:01:08+00:00
  edited: false
  hidden: false
  id: 64777d5404aa03da2abf06a7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/wizard-vicuna-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: oobabooga error (missing a file it seems)
