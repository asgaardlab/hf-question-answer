!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Gautam18k12
conflicting_files: null
created_at: 2023-07-25 07:15:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e320ee8af9816e1b7aa13f80816e2944.svg
      fullname: Gautam Kumar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Gautam18k12
      type: user
    createdAt: '2023-07-25T08:15:41.000Z'
    data:
      edited: false
      editors:
      - Gautam18k12
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3533366024494171
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e320ee8af9816e1b7aa13f80816e2944.svg
          fullname: Gautam Kumar
          isHf: false
          isPro: false
          name: Gautam18k12
          type: user
        html: '<p>i am getting below error while loading the model. any help on this.<br>ValidationError                           Traceback
          (most recent call last)<br>Cell In[4], line 2<br>      1 # initialize the
          LLM &amp; Embeddings<br>----&gt; 2 llm = LlamaCpp(model_path="C:/Users/Gautam/OneDrive/Desktop/ChatBot/LocalLLMQnA/model/llama-7b.ggmlv3.q4_0.bin")<br>      3
          #embeddings = LlamaCppEmbeddings(model_path="./model/llama-7b.ggmlv3.q4_0.bin")<br>      4
          #llm_chain = LLMChain(llm=llm, prompt=prompt)</p>

          <p>File ~\anaconda3\envs\llm_llama\lib\site-packages\langchain\load\serializable.py:64,
          in Serializable.<strong>init</strong>(self, **kwargs)<br>     63 def <strong>init</strong>(self,
          **kwargs: Any) -&gt; None:<br>---&gt; 64     super().<strong>init</strong>(**kwargs)<br>     65     self._lc_kwargs
          = kwargs</p>

          <p>File ~\anaconda3\envs\llm_llama\lib\site-packages\pydantic\main.py:341,
          in pydantic.main.BaseModel.<strong>init</strong>()</p>

          <p>ValidationError: 1 validation error for LlamaCpp<br><strong>root</strong><br>  Could
          not load Llama model from path: C:/Users/Gautam/OneDrive/Desktop/ChatBot/LocalLLMQnA/model/llama-7b.ggmlv3.q4_0.bin.
          Received error [WinError -1073741795] Windows Error 0xc000001d (type=value_error)</p>

          '
        raw: "i am getting below error while loading the model. any help on this.\r\
          \nValidationError                           Traceback (most recent call\
          \ last)\r\nCell In[4], line 2\r\n      1 # initialize the LLM & Embeddings\r\
          \n----> 2 llm = LlamaCpp(model_path=\"C:/Users/Gautam/OneDrive/Desktop/ChatBot/LocalLLMQnA/model/llama-7b.ggmlv3.q4_0.bin\"\
          )\r\n      3 #embeddings = LlamaCppEmbeddings(model_path=\"./model/llama-7b.ggmlv3.q4_0.bin\"\
          )\r\n      4 #llm_chain = LLMChain(llm=llm, prompt=prompt)\r\n\r\nFile ~\\\
          anaconda3\\envs\\llm_llama\\lib\\site-packages\\langchain\\load\\serializable.py:64,\
          \ in Serializable.__init__(self, **kwargs)\r\n     63 def __init__(self,\
          \ **kwargs: Any) -> None:\r\n---> 64     super().__init__(**kwargs)\r\n\
          \     65     self._lc_kwargs = kwargs\r\n\r\nFile ~\\anaconda3\\envs\\llm_llama\\\
          lib\\site-packages\\pydantic\\main.py:341, in pydantic.main.BaseModel.__init__()\r\
          \n\r\nValidationError: 1 validation error for LlamaCpp\r\n__root__\r\n \
          \ Could not load Llama model from path: C:/Users/Gautam/OneDrive/Desktop/ChatBot/LocalLLMQnA/model/llama-7b.ggmlv3.q4_0.bin.\
          \ Received error [WinError -1073741795] Windows Error 0xc000001d (type=value_error)\r\
          \n"
        updatedAt: '2023-07-25T08:15:41.332Z'
      numEdits: 0
      reactions: []
    id: 64bf84adb1a6188809ce2d49
    type: comment
  author: Gautam18k12
  content: "i am getting below error while loading the model. any help on this.\r\n\
    ValidationError                           Traceback (most recent call last)\r\n\
    Cell In[4], line 2\r\n      1 # initialize the LLM & Embeddings\r\n----> 2 llm\
    \ = LlamaCpp(model_path=\"C:/Users/Gautam/OneDrive/Desktop/ChatBot/LocalLLMQnA/model/llama-7b.ggmlv3.q4_0.bin\"\
    )\r\n      3 #embeddings = LlamaCppEmbeddings(model_path=\"./model/llama-7b.ggmlv3.q4_0.bin\"\
    )\r\n      4 #llm_chain = LLMChain(llm=llm, prompt=prompt)\r\n\r\nFile ~\\anaconda3\\\
    envs\\llm_llama\\lib\\site-packages\\langchain\\load\\serializable.py:64, in Serializable.__init__(self,\
    \ **kwargs)\r\n     63 def __init__(self, **kwargs: Any) -> None:\r\n---> 64 \
    \    super().__init__(**kwargs)\r\n     65     self._lc_kwargs = kwargs\r\n\r\n\
    File ~\\anaconda3\\envs\\llm_llama\\lib\\site-packages\\pydantic\\main.py:341,\
    \ in pydantic.main.BaseModel.__init__()\r\n\r\nValidationError: 1 validation error\
    \ for LlamaCpp\r\n__root__\r\n  Could not load Llama model from path: C:/Users/Gautam/OneDrive/Desktop/ChatBot/LocalLLMQnA/model/llama-7b.ggmlv3.q4_0.bin.\
    \ Received error [WinError -1073741795] Windows Error 0xc000001d (type=value_error)\r\
    \n"
  created_at: 2023-07-25 07:15:41+00:00
  edited: false
  hidden: false
  id: 64bf84adb1a6188809ce2d49
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/LLaMa-7B-GGML
repo_type: model
status: open
target_branch: null
title: ' 1 validation error for LlamaCpp __root__.  Could not load Llama model from
  path: ./model/llama-7b.ggmlv3.q4_0.bin. Received error [WinError -1073741795] Windows
  Error 0xc000001d (type=value_error)'
