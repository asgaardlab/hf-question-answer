!!python/object:huggingface_hub.community.DiscussionWithDetails
author: dillfrescott
conflicting_files: null
created_at: 2023-10-25 13:57:33+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
      fullname: Cross Nastasi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dillfrescott
      type: user
    createdAt: '2023-10-25T14:57:33.000Z'
    data:
      edited: false
      editors:
      - dillfrescott
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.19852906465530396
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
          fullname: Cross Nastasi
          isHf: false
          isPro: false
          name: dillfrescott
          type: user
        html: '<pre><code>llama_new_context_with_model: n_ctx      = 4096

          llama_new_context_with_model: freq_base  = 10000.0

          llama_new_context_with_model: freq_scale = 1

          llama_kv_cache_init: offloading v cache to GPU

          llama_kv_cache_init: offloading k cache to GPU

          llama_kv_cache_init: VRAM kv self = 3200.00 MB

          llama_new_context_with_model: kv self size  = 3200.00 MB

          llama_new_context_with_model: compute buffer total size = 364.13 MB

          llama_new_context_with_model: VRAM scratch buffer: 358.00 MB

          llama_new_context_with_model: total VRAM used: 17125.05 MB (model: 13567.05
          MB, context: 3558.00 MB)

          &lt;|endoftext|&gt;


          CUDA error 9 at ggml-cuda.cu:6863: invalid configuration argument

          current device: 0

          </code></pre>

          '
        raw: "```\r\nllama_new_context_with_model: n_ctx      = 4096\r\nllama_new_context_with_model:\
          \ freq_base  = 10000.0\r\nllama_new_context_with_model: freq_scale = 1\r\
          \nllama_kv_cache_init: offloading v cache to GPU\r\nllama_kv_cache_init:\
          \ offloading k cache to GPU\r\nllama_kv_cache_init: VRAM kv self = 3200.00\
          \ MB\r\nllama_new_context_with_model: kv self size  = 3200.00 MB\r\nllama_new_context_with_model:\
          \ compute buffer total size = 364.13 MB\r\nllama_new_context_with_model:\
          \ VRAM scratch buffer: 358.00 MB\r\nllama_new_context_with_model: total\
          \ VRAM used: 17125.05 MB (model: 13567.05 MB, context: 3558.00 MB)\r\n<|endoftext|>\r\
          \n\r\nCUDA error 9 at ggml-cuda.cu:6863: invalid configuration argument\r\
          \ncurrent device: 0\r\n```"
        updatedAt: '2023-10-25T14:57:33.113Z'
      numEdits: 0
      reactions: []
    id: 65392cdd1ad9b3ba7c3b76a4
    type: comment
  author: dillfrescott
  content: "```\r\nllama_new_context_with_model: n_ctx      = 4096\r\nllama_new_context_with_model:\
    \ freq_base  = 10000.0\r\nllama_new_context_with_model: freq_scale = 1\r\nllama_kv_cache_init:\
    \ offloading v cache to GPU\r\nllama_kv_cache_init: offloading k cache to GPU\r\
    \nllama_kv_cache_init: VRAM kv self = 3200.00 MB\r\nllama_new_context_with_model:\
    \ kv self size  = 3200.00 MB\r\nllama_new_context_with_model: compute buffer total\
    \ size = 364.13 MB\r\nllama_new_context_with_model: VRAM scratch buffer: 358.00\
    \ MB\r\nllama_new_context_with_model: total VRAM used: 17125.05 MB (model: 13567.05\
    \ MB, context: 3558.00 MB)\r\n<|endoftext|>\r\n\r\nCUDA error 9 at ggml-cuda.cu:6863:\
    \ invalid configuration argument\r\ncurrent device: 0\r\n```"
  created_at: 2023-10-25 13:57:33+00:00
  edited: false
  hidden: false
  id: 65392cdd1ad9b3ba7c3b76a4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
      fullname: Cross Nastasi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dillfrescott
      type: user
    createdAt: '2023-10-25T14:59:53.000Z'
    data:
      edited: false
      editors:
      - dillfrescott
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.975088894367218
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
          fullname: Cross Nastasi
          isHf: false
          isPro: false
          name: dillfrescott
          type: user
        html: '<p>Every other model I''ve tried works fine except this one. :/</p>

          '
        raw: Every other model I've tried works fine except this one. :/
        updatedAt: '2023-10-25T14:59:53.640Z'
      numEdits: 0
      reactions: []
    id: 65392d698e687a416256ed56
    type: comment
  author: dillfrescott
  content: Every other model I've tried works fine except this one. :/
  created_at: 2023-10-25 13:59:53+00:00
  edited: false
  hidden: false
  id: 65392d698e687a416256ed56
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-10-25T15:19:25.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9633100032806396
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Yeah, this model should be considered experimental. It required
          a special fix to llama.cpp to work in teh first place, because of its unusual
          vocab.</p>

          <p>I''ve had several reports of this CUDA error. It''s possible that the
          fix mentioned above only works on CPU, and there''s a bug with GPU processing.</p>

          <p>Please could you report it on the llama.cpp Github - it''s not something
          I can do anything about, unless/until there''s a fix in llama.cpp requiring
          me to re-make the GGUFs.  But it may well be that on the client needs to
          change, and the GGUFs are already fine.</p>

          <p>Feel free to ping me in the Github Issue you raise so I can keep track
          of it, or link it here.</p>

          '
        raw: 'Yeah, this model should be considered experimental. It required a special
          fix to llama.cpp to work in teh first place, because of its unusual vocab.


          I''ve had several reports of this CUDA error. It''s possible that the fix
          mentioned above only works on CPU, and there''s a bug with GPU processing.


          Please could you report it on the llama.cpp Github - it''s not something
          I can do anything about, unless/until there''s a fix in llama.cpp requiring
          me to re-make the GGUFs.  But it may well be that on the client needs to
          change, and the GGUFs are already fine.


          Feel free to ping me in the Github Issue you raise so I can keep track of
          it, or link it here.'
        updatedAt: '2023-10-25T15:19:25.235Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - tastypear
    id: 653931fd6882a4dcf7ba2b2b
    type: comment
  author: TheBloke
  content: 'Yeah, this model should be considered experimental. It required a special
    fix to llama.cpp to work in teh first place, because of its unusual vocab.


    I''ve had several reports of this CUDA error. It''s possible that the fix mentioned
    above only works on CPU, and there''s a bug with GPU processing.


    Please could you report it on the llama.cpp Github - it''s not something I can
    do anything about, unless/until there''s a fix in llama.cpp requiring me to re-make
    the GGUFs.  But it may well be that on the client needs to change, and the GGUFs
    are already fine.


    Feel free to ping me in the Github Issue you raise so I can keep track of it,
    or link it here.'
  created_at: 2023-10-25 14:19:25+00:00
  edited: false
  hidden: false
  id: 653931fd6882a4dcf7ba2b2b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/88f10b8c46c8de3828f478b020519880.svg
      fullname: Bobby D
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BobbyThrillz
      type: user
    createdAt: '2023-10-25T15:27:01.000Z'
    data:
      edited: false
      editors:
      - BobbyThrillz
      hidden: false
      identifiedLanguage:
        language: fa
        probability: 0.22799432277679443
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/88f10b8c46c8de3828f478b020519880.svg
          fullname: Bobby D
          isHf: false
          isPro: false
          name: BobbyThrillz
          type: user
        html: '<p>Swag</p>

          '
        raw: 'Swag

          '
        updatedAt: '2023-10-25T15:27:01.784Z'
      numEdits: 0
      reactions: []
    id: 653933c5690022ca51d675bf
    type: comment
  author: BobbyThrillz
  content: 'Swag

    '
  created_at: 2023-10-25 14:27:01+00:00
  edited: false
  hidden: false
  id: 653933c5690022ca51d675bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
      fullname: Cross Nastasi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dillfrescott
      type: user
    createdAt: '2023-10-26T15:30:37.000Z'
    data:
      edited: false
      editors:
      - dillfrescott
      hidden: false
      identifiedLanguage:
        language: pt
        probability: 0.23232592642307281
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
          fullname: Cross Nastasi
          isHf: false
          isPro: false
          name: dillfrescott
          type: user
        html: '<p>Gotcha. Thanks! Will do!</p>

          '
        raw: Gotcha. Thanks! Will do!
        updatedAt: '2023-10-26T15:30:37.179Z'
      numEdits: 0
      reactions: []
    id: 653a861d8f8d60f2046bc050
    type: comment
  author: dillfrescott
  content: Gotcha. Thanks! Will do!
  created_at: 2023-10-26 14:30:37+00:00
  edited: false
  hidden: false
  id: 653a861d8f8d60f2046bc050
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
      fullname: Cross Nastasi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dillfrescott
      type: user
    createdAt: '2023-10-28T18:36:17.000Z'
    data:
      edited: false
      editors:
      - dillfrescott
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7071133852005005
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6215ce9abfcb3893344dd0a2/8nZkcC2lhaFHFSGcgf01T.png?w=200&h=200&f=face
          fullname: Cross Nastasi
          isHf: false
          isPro: false
          name: dillfrescott
          type: user
        html: "<p><a rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp/issues/1732\"\
          >https://github.com/ggerganov/llama.cpp/issues/1732</a> <span data-props=\"\
          {&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/TheBloke\">@<span class=\"underline\">TheBloke</span></a></span>\n\
          \n\t</span></span> </p>\n"
        raw: 'https://github.com/ggerganov/llama.cpp/issues/1732 @TheBloke '
        updatedAt: '2023-10-28T18:36:17.252Z'
      numEdits: 0
      reactions: []
    id: 653d54a16d28265c85b3a130
    type: comment
  author: dillfrescott
  content: 'https://github.com/ggerganov/llama.cpp/issues/1732 @TheBloke '
  created_at: 2023-10-28 17:36:17+00:00
  edited: false
  hidden: false
  id: 653d54a16d28265c85b3a130
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/CausalLM-14B-GGUF
repo_type: model
status: open
target_branch: null
title: Llama.cpp error
