!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tarruda
conflicting_files: null
created_at: 2023-12-04 12:48:10+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
      fullname: Thiago de Arruda Padilha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarruda
      type: user
    createdAt: '2023-12-04T12:48:10.000Z'
    data:
      edited: false
      editors:
      - tarruda
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9257668852806091
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
          fullname: Thiago de Arruda Padilha
          isHf: false
          isPro: false
          name: tarruda
          type: user
        html: '<p>Does it require extra training?</p>

          '
        raw: Does it require extra training?
        updatedAt: '2023-12-04T12:48:10.848Z'
      numEdits: 0
      reactions: []
    id: 656dca8a3e60cb2621f1c2ab
    type: comment
  author: tarruda
  content: Does it require extra training?
  created_at: 2023-12-04 12:48:10+00:00
  edited: false
  hidden: false
  id: 656dca8a3e60cb2621f1c2ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
      fullname: Maxime Labonne
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mlabonne
      type: user
    createdAt: '2023-12-04T13:09:38.000Z'
    data:
      edited: false
      editors:
      - mlabonne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9736239910125732
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
          fullname: Maxime Labonne
          isHf: false
          isPro: false
          name: mlabonne
          type: user
        html: '<p>Thanks! It would indeed require extra training and, more specifically,
          extra supervised fine-tuning. I think that Teknium, the creator of the base
          SFT model, is working on it.</p>

          '
        raw: Thanks! It would indeed require extra training and, more specifically,
          extra supervised fine-tuning. I think that Teknium, the creator of the base
          SFT model, is working on it.
        updatedAt: '2023-12-04T13:09:38.249Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - tarruda
        - lan2720
    id: 656dcf92adba74cd5ea8f617
    type: comment
  author: mlabonne
  content: Thanks! It would indeed require extra training and, more specifically,
    extra supervised fine-tuning. I think that Teknium, the creator of the base SFT
    model, is working on it.
  created_at: 2023-12-04 13:09:38+00:00
  edited: false
  hidden: false
  id: 656dcf92adba74cd5ea8f617
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
      fullname: Thiago de Arruda Padilha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarruda
      type: user
    createdAt: '2023-12-04T18:16:31.000Z'
    data:
      edited: true
      editors:
      - tarruda
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8340149521827698
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
          fullname: Thiago de Arruda Padilha
          isHf: false
          isPro: false
          name: tarruda
          type: user
        html: "<p>I don't know if I'm approaching this the right way, but this model\
          \ is so good that by explaining how to call functions in the system prompt\
          \ I got it to respond in a format that for my purposes is good enough. Here's\
          \ my system prompt:</p>\n<pre><code>You are an AI assistant that does your\
          \ best to answer questions of perform task for the user. The following is\
          \ a list of external functions that may be called to complete certain tasks:\n\
          \n\n[\n  {\"function_name\": \"eval_math\", \"description\": \"Evaluate\
          \ mathematical expressions\"},\n  {\"function_name\": \"datetime\", \"description\"\
          : \"Get the current date/time\"},\n  {\"function_name\": \"describe_image\"\
          , \"description\": \"Generate a text description of an image identified\
          \ by the uuid parameter\"}\n]\n\n\nWhenever the user asks you something,\
          \ you can either respond directly or invoke a function. The decision to\
          \ invoke a function is yours, only invoke functions when it makes sense\
          \ to do so.\n\nHere are some example of interactions:\n\n\n&lt;|im_start|&gt;user\n\
          Hello, who are you?&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nHi there!\
          \ My name is Hermes 2\n\n\n\n&lt;|im_start|&gt;user\nWhat is 4 + 3 / 2 ?&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;assistant\n[call:eval_math,`4+3/2`]&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;user\n[result:eval_math:3.5]&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n\
          4 + 3 / 2 is 3.5\n\n\n\n&lt;|im_start|&gt;user\nWhat is the current time?&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;assistant\n[call:datetime()]&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\n\
          [result:datetime:Mon Dec  4 02:48:57 PM -03 2023]&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n\
          Current time is 02:48:57 PM GMT-03\n\n\n\n&lt;|im_start|&gt;user\nWho was\
          \ Abraham Lincoln?&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nAbraham\
          \ Lincoln was the 16th President of the United States\n</code></pre>\n<p>I\
          \ have embeded the user/assistant start/end tokens in the examples and it\
          \ seemed to have just worked:</p>\n<p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/6453f2e9096d57ae122d79e6/WFuHMCsespiJJgFq2lvXz.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/6453f2e9096d57ae122d79e6/WFuHMCsespiJJgFq2lvXz.png\"\
          ></a></p>\n<p>Note that I haven't really called any functions, and simply\
          \ added simulated function call responses in the chatbot-ui response field\
          \ (to test if the model extracted the function call response).</p>\n"
        raw: "I don't know if I'm approaching this the right way, but this model is\
          \ so good that by explaining how to call functions in the system prompt\
          \ I got it to respond in a format that for my purposes is good enough. Here's\
          \ my system prompt:\n\n```\nYou are an AI assistant that does your best\
          \ to answer questions of perform task for the user. The following is a list\
          \ of external functions that may be called to complete certain tasks:\n\n\
          \n[\n  {\"function_name\": \"eval_math\", \"description\": \"Evaluate mathematical\
          \ expressions\"},\n  {\"function_name\": \"datetime\", \"description\":\
          \ \"Get the current date/time\"},\n  {\"function_name\": \"describe_image\"\
          , \"description\": \"Generate a text description of an image identified\
          \ by the uuid parameter\"}\n]\n\n\nWhenever the user asks you something,\
          \ you can either respond directly or invoke a function. The decision to\
          \ invoke a function is yours, only invoke functions when it makes sense\
          \ to do so.\n\nHere are some example of interactions:\n\n\n<|im_start|>user\n\
          Hello, who are you?<|im_end|>\n<|im_start|>assistant\nHi there! My name\
          \ is Hermes 2\n\n\n\n<|im_start|>user\nWhat is 4 + 3 / 2 ?<|im_end|>\n<|im_start|>assistant\n\
          [call:eval_math,`4+3/2`]<|im_end|>\n<|im_start|>user\n[result:eval_math:3.5]<|im_end|>\n\
          <|im_start|>assistant\n4 + 3 / 2 is 3.5\n\n\n\n<|im_start|>user\nWhat is\
          \ the current time?<|im_end|>\n<|im_start|>assistant\n[call:datetime()]<|im_end|>\n\
          <|im_start|>user\n[result:datetime:Mon Dec  4 02:48:57 PM -03 2023]<|im_end|>\n\
          <|im_start|>assistant\nCurrent time is 02:48:57 PM GMT-03\n\n\n\n<|im_start|>user\n\
          Who was Abraham Lincoln?<|im_end|>\n<|im_start|>assistant\nAbraham Lincoln\
          \ was the 16th President of the United States\n```\n\n\nI have embeded the\
          \ user/assistant start/end tokens in the examples and it seemed to have\
          \ just worked:\n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6453f2e9096d57ae122d79e6/WFuHMCsespiJJgFq2lvXz.png)\n\
          \nNote that I haven't really called any functions, and simply added simulated\
          \ function call responses in the chatbot-ui response field (to test if the\
          \ model extracted the function call response)."
        updatedAt: '2023-12-04T18:17:35.953Z'
      numEdits: 1
      reactions: []
    id: 656e177f85562996982218ef
    type: comment
  author: tarruda
  content: "I don't know if I'm approaching this the right way, but this model is\
    \ so good that by explaining how to call functions in the system prompt I got\
    \ it to respond in a format that for my purposes is good enough. Here's my system\
    \ prompt:\n\n```\nYou are an AI assistant that does your best to answer questions\
    \ of perform task for the user. The following is a list of external functions\
    \ that may be called to complete certain tasks:\n\n\n[\n  {\"function_name\":\
    \ \"eval_math\", \"description\": \"Evaluate mathematical expressions\"},\n  {\"\
    function_name\": \"datetime\", \"description\": \"Get the current date/time\"\
    },\n  {\"function_name\": \"describe_image\", \"description\": \"Generate a text\
    \ description of an image identified by the uuid parameter\"}\n]\n\n\nWhenever\
    \ the user asks you something, you can either respond directly or invoke a function.\
    \ The decision to invoke a function is yours, only invoke functions when it makes\
    \ sense to do so.\n\nHere are some example of interactions:\n\n\n<|im_start|>user\n\
    Hello, who are you?<|im_end|>\n<|im_start|>assistant\nHi there! My name is Hermes\
    \ 2\n\n\n\n<|im_start|>user\nWhat is 4 + 3 / 2 ?<|im_end|>\n<|im_start|>assistant\n\
    [call:eval_math,`4+3/2`]<|im_end|>\n<|im_start|>user\n[result:eval_math:3.5]<|im_end|>\n\
    <|im_start|>assistant\n4 + 3 / 2 is 3.5\n\n\n\n<|im_start|>user\nWhat is the current\
    \ time?<|im_end|>\n<|im_start|>assistant\n[call:datetime()]<|im_end|>\n<|im_start|>user\n\
    [result:datetime:Mon Dec  4 02:48:57 PM -03 2023]<|im_end|>\n<|im_start|>assistant\n\
    Current time is 02:48:57 PM GMT-03\n\n\n\n<|im_start|>user\nWho was Abraham Lincoln?<|im_end|>\n\
    <|im_start|>assistant\nAbraham Lincoln was the 16th President of the United States\n\
    ```\n\n\nI have embeded the user/assistant start/end tokens in the examples and\
    \ it seemed to have just worked:\n\n\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/6453f2e9096d57ae122d79e6/WFuHMCsespiJJgFq2lvXz.png)\n\
    \nNote that I haven't really called any functions, and simply added simulated\
    \ function call responses in the chatbot-ui response field (to test if the model\
    \ extracted the function call response)."
  created_at: 2023-12-04 18:16:31+00:00
  edited: true
  hidden: false
  id: 656e177f85562996982218ef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
      fullname: Maxime Labonne
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: mlabonne
      type: user
    createdAt: '2023-12-05T11:30:39.000Z'
    data:
      edited: false
      editors:
      - mlabonne
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9640963673591614
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/4XZP5aVsMWwzGx_313cqd.jpeg?w=200&h=200&f=face
          fullname: Maxime Labonne
          isHf: false
          isPro: false
          name: mlabonne
          type: user
        html: '<p>hahaha I didn''t expect zero-shot function calling to work that
          well with a 7b model, thanks for sharing this!</p>

          '
        raw: hahaha I didn't expect zero-shot function calling to work that well with
          a 7b model, thanks for sharing this!
        updatedAt: '2023-12-05T11:30:39.916Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\u2764\uFE0F"
        users:
        - kgourgou
        - tarruda
    id: 656f09dfa1f8b1d0d4936440
    type: comment
  author: mlabonne
  content: hahaha I didn't expect zero-shot function calling to work that well with
    a 7b model, thanks for sharing this!
  created_at: 2023-12-05 11:30:39+00:00
  edited: false
  hidden: false
  id: 656f09dfa1f8b1d0d4936440
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
      fullname: Thiago de Arruda Padilha
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tarruda
      type: user
    createdAt: '2023-12-06T00:41:08.000Z'
    data:
      edited: false
      editors:
      - tarruda
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9795089364051819
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/70a745746569b264a2ea4815dd04d3a7.svg
          fullname: Thiago de Arruda Padilha
          isHf: false
          isPro: false
          name: tarruda
          type: user
        html: '<blockquote>

          <p>hahaha I didn''t expect zero-shot function calling to work that well
          with a 7b model, thanks for sharing this!</p>

          </blockquote>

          <p>So far this is the best model that I can run on my computer. I''ve tried
          a few 13b models, but they don''t compare with this one. I even tried some
          reasoning/logic examples of the Orca 2 paper and IMO this model does better
          than Orca 2!</p>

          '
        raw: '> hahaha I didn''t expect zero-shot function calling to work that well
          with a 7b model, thanks for sharing this!


          So far this is the best model that I can run on my computer. I''ve tried
          a few 13b models, but they don''t compare with this one. I even tried some
          reasoning/logic examples of the Orca 2 paper and IMO this model does better
          than Orca 2!'
        updatedAt: '2023-12-06T00:41:08.408Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - TioPeperino
        - mlabonne
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - davidlu
    id: 656fc3242cf29b89e9109b48
    type: comment
  author: tarruda
  content: '> hahaha I didn''t expect zero-shot function calling to work that well
    with a 7b model, thanks for sharing this!


    So far this is the best model that I can run on my computer. I''ve tried a few
    13b models, but they don''t compare with this one. I even tried some reasoning/logic
    examples of the Orca 2 paper and IMO this model does better than Orca 2!'
  created_at: 2023-12-06 00:41:08+00:00
  edited: false
  hidden: false
  id: 656fc3242cf29b89e9109b48
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: mlabonne/NeuralHermes-2.5-Mistral-7B
repo_type: model
status: open
target_branch: null
title: Model is amazing, how can we implement function calling?
