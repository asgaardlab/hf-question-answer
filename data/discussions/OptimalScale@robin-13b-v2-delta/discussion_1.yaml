!!python/object:huggingface_hub.community.DiscussionWithDetails
author: haydenhong
conflicting_files: null
created_at: 2023-06-30 10:10:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a05379ab140073de0281000e1b21f119.svg
      fullname: hhong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: haydenhong
      type: user
    createdAt: '2023-06-30T11:10:56.000Z'
    data:
      edited: false
      editors:
      - haydenhong
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9719082117080688
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a05379ab140073de0281000e1b21f119.svg
          fullname: hhong
          isHf: false
          isPro: false
          name: haydenhong
          type: user
        html: '<p>Downloaded this 13b weights, loaded and run successfully, just that
          the outputs are gibberish. Not sure if it is my weights corrupted or what.
          Anyone sees this, or anyone is successful? thanks.</p>

          '
        raw: Downloaded this 13b weights, loaded and run successfully, just that the
          outputs are gibberish. Not sure if it is my weights corrupted or what. Anyone
          sees this, or anyone is successful? thanks.
        updatedAt: '2023-06-30T11:10:56.581Z'
      numEdits: 0
      reactions: []
    id: 649eb84023beadd91641ebfb
    type: comment
  author: haydenhong
  content: Downloaded this 13b weights, loaded and run successfully, just that the
    outputs are gibberish. Not sure if it is my weights corrupted or what. Anyone
    sees this, or anyone is successful? thanks.
  created_at: 2023-06-30 10:10:56+00:00
  edited: false
  hidden: false
  id: 649eb84023beadd91641ebfb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/150aa5b8d9bcca24366402932bf2d049.svg
      fullname: victordiao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: victordiao
      type: user
    createdAt: '2023-06-30T15:34:32.000Z'
    data:
      edited: false
      editors:
      - victordiao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7479692101478577
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/150aa5b8d9bcca24366402932bf2d049.svg
          fullname: victordiao
          isHf: false
          isPro: false
          name: victordiao
          type: user
        html: "<p>Hi,<br>robin-delta-v2 is a delta model, which means you need to\
          \ merge it with the base model (i.e., LLaMA-13B).<br>The merge script could\
          \ be found at <a rel=\"nofollow\" href=\"https://github.com/OptimalScale/LMFlow#53-reproduce-the-result\"\
          >https://github.com/OptimalScale/LMFlow#53-reproduce-the-result</a></p>\n\
          <pre><code>python utils/apply_delta.py \\\n    --base-model-path {huggingface-model-name-or-path-to-base-model}\
          \ \\\n    --delta-path {path-to-delta-model} \\\n    --target-model-path\
          \ {path-to-merged-model}\n</code></pre>\n"
        raw: "Hi,\nrobin-delta-v2 is a delta model, which means you need to merge\
          \ it with the base model (i.e., LLaMA-13B).\nThe merge script could be found\
          \ at https://github.com/OptimalScale/LMFlow#53-reproduce-the-result\n\n\
          ```\npython utils/apply_delta.py \\\n    --base-model-path {huggingface-model-name-or-path-to-base-model}\
          \ \\\n    --delta-path {path-to-delta-model} \\\n    --target-model-path\
          \ {path-to-merged-model}\n```"
        updatedAt: '2023-06-30T15:34:32.406Z'
      numEdits: 0
      reactions: []
    id: 649ef608643a3f8b3e26849b
    type: comment
  author: victordiao
  content: "Hi,\nrobin-delta-v2 is a delta model, which means you need to merge it\
    \ with the base model (i.e., LLaMA-13B).\nThe merge script could be found at https://github.com/OptimalScale/LMFlow#53-reproduce-the-result\n\
    \n```\npython utils/apply_delta.py \\\n    --base-model-path {huggingface-model-name-or-path-to-base-model}\
    \ \\\n    --delta-path {path-to-delta-model} \\\n    --target-model-path {path-to-merged-model}\n\
    ```"
  created_at: 2023-06-30 14:34:32+00:00
  edited: false
  hidden: false
  id: 649ef608643a3f8b3e26849b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a05379ab140073de0281000e1b21f119.svg
      fullname: hhong
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: haydenhong
      type: user
    createdAt: '2023-07-01T15:17:33.000Z'
    data:
      edited: false
      editors:
      - haydenhong
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9425750374794006
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a05379ab140073de0281000e1b21f119.svg
          fullname: hhong
          isHf: false
          isPro: false
          name: haydenhong
          type: user
        html: '<p>thanks! it works.<br>btw, does the generation require "#" as eos_token
          to terminate? just ant to bring this up: I think vicuna v2 fixed a similar
          issue by re-training using "" to replace "###", wonder if it is similar
          cause.</p>

          '
        raw: 'thanks! it works.

          btw, does the generation require "#" as eos_token to terminate? just ant
          to bring this up: I think vicuna v2 fixed a similar issue by re-training
          using "</s>" to replace "###", wonder if it is similar cause.'
        updatedAt: '2023-07-01T15:17:33.497Z'
      numEdits: 0
      reactions: []
    id: 64a0438d1a5a824ce10a0d7b
    type: comment
  author: haydenhong
  content: 'thanks! it works.

    btw, does the generation require "#" as eos_token to terminate? just ant to bring
    this up: I think vicuna v2 fixed a similar issue by re-training using "</s>" to
    replace "###", wonder if it is similar cause.'
  created_at: 2023-07-01 14:17:33+00:00
  edited: false
  hidden: false
  id: 64a0438d1a5a824ce10a0d7b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/150aa5b8d9bcca24366402932bf2d049.svg
      fullname: victordiao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: victordiao
      type: user
    createdAt: '2023-07-01T15:20:18.000Z'
    data:
      edited: false
      editors:
      - victordiao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.940575361251831
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/150aa5b8d9bcca24366402932bf2d049.svg
          fullname: victordiao
          isHf: false
          isPro: false
          name: victordiao
          type: user
        html: '<p>yes, robin models use "###" as eos_token to terminate.<br>I do not
          fully understand what is the issue/consequence of using "#" you mentioned.
          Could you elaborate more?<br>Thanks!</p>

          '
        raw: 'yes, robin models use "###" as eos_token to terminate.

          I do not fully understand what is the issue/consequence of using "#" you
          mentioned. Could you elaborate more?

          Thanks!'
        updatedAt: '2023-07-01T15:20:18.758Z'
      numEdits: 0
      reactions: []
    id: 64a044324812ea6b2d40436d
    type: comment
  author: victordiao
  content: 'yes, robin models use "###" as eos_token to terminate.

    I do not fully understand what is the issue/consequence of using "#" you mentioned.
    Could you elaborate more?

    Thanks!'
  created_at: 2023-07-01 14:20:18+00:00
  edited: false
  hidden: false
  id: 64a044324812ea6b2d40436d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/95c5a23614724e22047e369b108c6d6d.svg
      fullname: Ada Huang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: acaiadaca
      type: user
    createdAt: '2023-07-13T02:59:51.000Z'
    data:
      edited: false
      editors:
      - acaiadaca
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8909127712249756
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/95c5a23614724e22047e369b108c6d6d.svg
          fullname: Ada Huang
          isHf: false
          isPro: false
          name: acaiadaca
          type: user
        html: '<blockquote>

          <p>yes, robin models use "###" as eos_token to terminate.<br>I do not fully
          understand what is the issue/consequence of using "#" you mentioned. Could
          you elaborate more?<br>Thanks!</p>

          </blockquote>

          <p>Is Robin-7B-v2 a base model or a model that has learned eos_token through
          SFT? I tired to set eos_token = ''###'' in tokenizer, also I used<br>model.generate(inputs,
          eos_token_id= tokenizer.eos_token_id, max_length=512)<br>BUT it does not
          stop at eos_token, instead continues until the maximum length.</p>

          '
        raw: '> yes, robin models use "###" as eos_token to terminate.

          > I do not fully understand what is the issue/consequence of using "#" you
          mentioned. Could you elaborate more?

          > Thanks!


          Is Robin-7B-v2 a base model or a model that has learned eos_token through
          SFT? I tired to set eos_token = ''###'' in tokenizer, also I used

          model.generate(inputs, eos_token_id= tokenizer.eos_token_id, max_length=512)

          BUT it does not stop at eos_token, instead continues until the maximum length.'
        updatedAt: '2023-07-13T02:59:51.263Z'
      numEdits: 0
      reactions: []
    id: 64af68a703246ffd04ca1a3a
    type: comment
  author: acaiadaca
  content: '> yes, robin models use "###" as eos_token to terminate.

    > I do not fully understand what is the issue/consequence of using "#" you mentioned.
    Could you elaborate more?

    > Thanks!


    Is Robin-7B-v2 a base model or a model that has learned eos_token through SFT?
    I tired to set eos_token = ''###'' in tokenizer, also I used

    model.generate(inputs, eos_token_id= tokenizer.eos_token_id, max_length=512)

    BUT it does not stop at eos_token, instead continues until the maximum length.'
  created_at: 2023-07-13 01:59:51+00:00
  edited: false
  hidden: false
  id: 64af68a703246ffd04ca1a3a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/150aa5b8d9bcca24366402932bf2d049.svg
      fullname: victordiao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: victordiao
      type: user
    createdAt: '2023-07-13T03:05:29.000Z'
    data:
      edited: false
      editors:
      - victordiao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9061644077301025
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/150aa5b8d9bcca24366402932bf2d049.svg
          fullname: victordiao
          isHf: false
          isPro: false
          name: victordiao
          type: user
        html: '<p>Hi, it is a model after SFT. the stop token is ''###''<br>As for
          inference, you can take a look at our doc <a rel="nofollow" href="https://github.com/OptimalScale/LMFlow">https://github.com/OptimalScale/LMFlow</a><br>Thanks</p>

          '
        raw: 'Hi, it is a model after SFT. the stop token is ''###''

          As for inference, you can take a look at our doc https://github.com/OptimalScale/LMFlow

          Thanks'
        updatedAt: '2023-07-13T03:05:29.186Z'
      numEdits: 0
      reactions: []
    id: 64af69f96eb97a9d93bbfce2
    type: comment
  author: victordiao
  content: 'Hi, it is a model after SFT. the stop token is ''###''

    As for inference, you can take a look at our doc https://github.com/OptimalScale/LMFlow

    Thanks'
  created_at: 2023-07-13 02:05:29+00:00
  edited: false
  hidden: false
  id: 64af69f96eb97a9d93bbfce2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: OptimalScale/robin-13b-v2-delta
repo_type: model
status: open
target_branch: null
title: 'output gibberish '
