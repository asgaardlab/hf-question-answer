!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Maoi
conflicting_files: null
created_at: 2023-05-11 10:28:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e8ccb9e8aab07f20049d040695998abd.svg
      fullname: Cristofer Alarcon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Maoi
      type: user
    createdAt: '2023-05-11T11:28:20.000Z'
    data:
      edited: false
      editors:
      - Maoi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e8ccb9e8aab07f20049d040695998abd.svg
          fullname: Cristofer Alarcon
          isHf: false
          isPro: false
          name: Maoi
          type: user
        html: '<p>Hello, i really like your scripts, but seems that when using it,
          takes mostly all of the VRAM to upscale x2 an image of 512x512. </p>

          '
        raw: 'Hello, i really like your scripts, but seems that when using it, takes
          mostly all of the VRAM to upscale x2 an image of 512x512. '
        updatedAt: '2023-05-11T11:28:20.956Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F917"
        users:
        - poipii
    id: 645cd154680734460f9b9069
    type: comment
  author: Maoi
  content: 'Hello, i really like your scripts, but seems that when using it, takes
    mostly all of the VRAM to upscale x2 an image of 512x512. '
  created_at: 2023-05-11 10:28:20+00:00
  edited: false
  hidden: false
  id: 645cd154680734460f9b9069
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/e8ccb9e8aab07f20049d040695998abd.svg
      fullname: Cristofer Alarcon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Maoi
      type: user
    createdAt: '2023-05-11T11:30:14.000Z'
    data:
      from: Txt2img takes all memory of GPU
      to: Txt2img Highres takes all memory of GPU
    id: 645cd1c68a63155046d8cc01
    type: title-change
  author: Maoi
  created_at: 2023-05-11 10:30:14+00:00
  id: 645cd1c68a63155046d8cc01
  new_title: Txt2img Highres takes all memory of GPU
  old_title: Txt2img takes all memory of GPU
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672637245812-5ff0111581db4de1746a7514.png?w=200&h=200&f=face
      fullname: Loy Jun Cheng
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: poipii
      type: user
    createdAt: '2023-05-11T11:35:48.000Z'
    data:
      edited: false
      editors:
      - poipii
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672637245812-5ff0111581db4de1746a7514.png?w=200&h=200&f=face
          fullname: Loy Jun Cheng
          isHf: false
          isPro: false
          name: poipii
          type: user
        html: '<blockquote>

          <p>Hello, i really like your scripts, but seems that when using it, takes
          mostly all of the VRAM to upscale x2 an image of 512x512.</p>

          </blockquote>

          <p>hi this repo is WIP I''m trying to replicate the latent high res fix
          option found in automatic1111 sd web UI , so for now the reason why its
          using a lot of vram its because you need to do 2 passes in the model to
          generate a higher res image and it seems i need to do some clean up after
          the first step to free up more vram, in my testing i was able to get it
          to use about 6gb of vram using google colab and kaggle for testing </p>

          <pre><code class="language-python">pipe.enable_attention_slicing()

          pipe.enable_xformers_memory_efficient_attention()

          </code></pre>

          '
        raw: "> Hello, i really like your scripts, but seems that when using it, takes\
          \ mostly all of the VRAM to upscale x2 an image of 512x512.\n\nhi this repo\
          \ is WIP I'm trying to replicate the latent high res fix option found in\
          \ automatic1111 sd web UI , so for now the reason why its using a lot of\
          \ vram its because you need to do 2 passes in the model to generate a higher\
          \ res image and it seems i need to do some clean up after the first step\
          \ to free up more vram, in my testing i was able to get it to use about\
          \ 6gb of vram using google colab and kaggle for testing \n\n```python\n\
          pipe.enable_attention_slicing()\npipe.enable_xformers_memory_efficient_attention()\n\
          ```"
        updatedAt: '2023-05-11T11:35:48.835Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Maoi
    id: 645cd314afa77201e2f91ac1
    type: comment
  author: poipii
  content: "> Hello, i really like your scripts, but seems that when using it, takes\
    \ mostly all of the VRAM to upscale x2 an image of 512x512.\n\nhi this repo is\
    \ WIP I'm trying to replicate the latent high res fix option found in automatic1111\
    \ sd web UI , so for now the reason why its using a lot of vram its because you\
    \ need to do 2 passes in the model to generate a higher res image and it seems\
    \ i need to do some clean up after the first step to free up more vram, in my\
    \ testing i was able to get it to use about 6gb of vram using google colab and\
    \ kaggle for testing \n\n```python\npipe.enable_attention_slicing()\npipe.enable_xformers_memory_efficient_attention()\n\
    ```"
  created_at: 2023-05-11 10:35:48+00:00
  edited: false
  hidden: false
  id: 645cd314afa77201e2f91ac1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e8ccb9e8aab07f20049d040695998abd.svg
      fullname: Cristofer Alarcon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Maoi
      type: user
    createdAt: '2023-05-11T12:50:42.000Z'
    data:
      edited: false
      editors:
      - Maoi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e8ccb9e8aab07f20049d040695998abd.svg
          fullname: Cristofer Alarcon
          isHf: false
          isPro: false
          name: Maoi
          type: user
        html: '<p>Yes, the problem isn''t during generation, is after executing txt2img
          when the VRAM is still storing previous data.</p>

          <p>I used some tricks to optimize vram usage, but it will always fill up.
          For example i used this:</p>

          <p>!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024<br>highrespipe.enable_attention_slicing()</p>

          <p> As i said, generating a 512x512px image for itself doesn''t takes a
          lot (like 4gb vram) when upscaling, but after 5 o 6 gens vram will fill
          up</p>

          '
        raw: "Yes, the problem isn't during generation, is after executing txt2img\
          \ when the VRAM is still storing previous data.\n\nI used some tricks to\
          \ optimize vram usage, but it will always fill up. For example i used this:\n\
          \n!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024\nhighrespipe.enable_attention_slicing()\n\
          \n As i said, generating a 512x512px image for itself doesn't takes a lot\
          \ (like 4gb vram) when upscaling, but after 5 o 6 gens vram will fill up"
        updatedAt: '2023-05-11T12:50:42.523Z'
      numEdits: 0
      reactions: []
    id: 645ce4a24e2cf468917928e5
    type: comment
  author: Maoi
  content: "Yes, the problem isn't during generation, is after executing txt2img when\
    \ the VRAM is still storing previous data.\n\nI used some tricks to optimize vram\
    \ usage, but it will always fill up. For example i used this:\n\n!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024\n\
    highrespipe.enable_attention_slicing()\n\n As i said, generating a 512x512px image\
    \ for itself doesn't takes a lot (like 4gb vram) when upscaling, but after 5 o\
    \ 6 gens vram will fill up"
  created_at: 2023-05-11 11:50:42+00:00
  edited: false
  hidden: false
  id: 645ce4a24e2cf468917928e5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: poipii/lpw_high_res_fix_pipeline
repo_type: model
status: open
target_branch: null
title: Txt2img Highres takes all memory of GPU
