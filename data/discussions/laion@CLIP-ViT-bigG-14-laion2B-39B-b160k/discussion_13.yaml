!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MonsterMMORPG
conflicting_files: null
created_at: 2023-10-10 19:39:57+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
      fullname: "Furkan G\xF6z\xFCkara"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MonsterMMORPG
      type: user
    createdAt: '2023-10-10T20:39:57.000Z'
    data:
      edited: false
      editors:
      - MonsterMMORPG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8333601355552673
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
          fullname: "Furkan G\xF6z\xFCkara"
          isHf: false
          isPro: false
          name: MonsterMMORPG
          type: user
        html: '<p>I want to use ViT-bigG-14, laion2b_s39b_b160k to generate captions
          for a given folder of images</p>

          <p>And save them with same file name</p>

          <p>Any example code please?</p>

          <p>Thank you so much</p>

          '
        raw: "I want to use ViT-bigG-14, laion2b_s39b_b160k to generate captions for\
          \ a given folder of images\r\n\r\nAnd save them with same file name\r\n\r\
          \nAny example code please?\r\n\r\nThank you so much"
        updatedAt: '2023-10-10T20:39:57.039Z'
      numEdits: 0
      reactions: []
    id: 6525b69db017be1fc19a8550
    type: comment
  author: MonsterMMORPG
  content: "I want to use ViT-bigG-14, laion2b_s39b_b160k to generate captions for\
    \ a given folder of images\r\n\r\nAnd save them with same file name\r\n\r\nAny\
    \ example code please?\r\n\r\nThank you so much"
  created_at: 2023-10-10 19:39:57+00:00
  edited: false
  hidden: false
  id: 6525b69db017be1fc19a8550
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595261977978-noauth.jpeg?w=200&h=200&f=face
      fullname: Alex Rozgo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: rozgo
      type: user
    createdAt: '2023-12-28T18:55:43.000Z'
    data:
      edited: false
      editors:
      - rozgo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5716565847396851
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595261977978-noauth.jpeg?w=200&h=200&f=face
          fullname: Alex Rozgo
          isHf: false
          isPro: true
          name: rozgo
          type: user
        html: "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">import</span>\
          \ torch\n<span class=\"hljs-keyword\">from</span> PIL <span class=\"hljs-keyword\"\
          >import</span> Image\n<span class=\"hljs-keyword\">import</span> open_clip\n\
          \nmodel, _, preprocess = open_clip.create_model_and_transforms(<span class=\"\
          hljs-string\">'ViT-bigG-14'</span>, pretrained=<span class=\"hljs-string\"\
          >'.checkpoints/CLIP-ViT-bigG-14-laion2B-39B-b160k.bin'</span>)\ntokenizer\
          \ = open_clip.get_tokenizer(<span class=\"hljs-string\">'ViT-bigG-14'</span>)\n\
          \nimage = preprocess(Image.<span class=\"hljs-built_in\">open</span>(<span\
          \ class=\"hljs-string\">\"animals.jpg\"</span>)).unsqueeze(<span class=\"\
          hljs-number\">0</span>)\ntext = tokenizer([<span class=\"hljs-string\">\"\
          a dog\"</span>,<span class=\"hljs-string\">\"a cat\"</span>])\n\n<span class=\"\
          hljs-keyword\">with</span> torch.no_grad(), torch.cuda.amp.autocast():\n\
          \    image_features = model.encode_image(image)\n    text_features = model.encode_text(text)\n\
          \    image_features /= image_features.norm(dim=-<span class=\"hljs-number\"\
          >1</span>, keepdim=<span class=\"hljs-literal\">True</span>)\n    text_features\
          \ /= text_features.norm(dim=-<span class=\"hljs-number\">1</span>, keepdim=<span\
          \ class=\"hljs-literal\">True</span>)\n\n    text_probs = (<span class=\"\
          hljs-number\">100.0</span> * image_features @ text_features.T).softmax(dim=-<span\
          \ class=\"hljs-number\">1</span>)\n\n<span class=\"hljs-built_in\">print</span>(<span\
          \ class=\"hljs-string\">\"Label probs:\"</span>, text_probs)\n</code></pre>\n"
        raw: "```python\nimport torch\nfrom PIL import Image\nimport open_clip\n\n\
          model, _, preprocess = open_clip.create_model_and_transforms('ViT-bigG-14',\
          \ pretrained='.checkpoints/CLIP-ViT-bigG-14-laion2B-39B-b160k.bin')\ntokenizer\
          \ = open_clip.get_tokenizer('ViT-bigG-14')\n\nimage = preprocess(Image.open(\"\
          animals.jpg\")).unsqueeze(0)\ntext = tokenizer([\"a dog\",\"a cat\"])\n\n\
          with torch.no_grad(), torch.cuda.amp.autocast():\n    image_features = model.encode_image(image)\n\
          \    text_features = model.encode_text(text)\n    image_features /= image_features.norm(dim=-1,\
          \ keepdim=True)\n    text_features /= text_features.norm(dim=-1, keepdim=True)\n\
          \n    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n\
          \nprint(\"Label probs:\", text_probs)\n```"
        updatedAt: '2023-12-28T18:55:43.908Z'
      numEdits: 0
      reactions: []
    id: 658dc4af7fe0235473be25a7
    type: comment
  author: rozgo
  content: "```python\nimport torch\nfrom PIL import Image\nimport open_clip\n\nmodel,\
    \ _, preprocess = open_clip.create_model_and_transforms('ViT-bigG-14', pretrained='.checkpoints/CLIP-ViT-bigG-14-laion2B-39B-b160k.bin')\n\
    tokenizer = open_clip.get_tokenizer('ViT-bigG-14')\n\nimage = preprocess(Image.open(\"\
    animals.jpg\")).unsqueeze(0)\ntext = tokenizer([\"a dog\",\"a cat\"])\n\nwith\
    \ torch.no_grad(), torch.cuda.amp.autocast():\n    image_features = model.encode_image(image)\n\
    \    text_features = model.encode_text(text)\n    image_features /= image_features.norm(dim=-1,\
    \ keepdim=True)\n    text_features /= text_features.norm(dim=-1, keepdim=True)\n\
    \n    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n\
    \nprint(\"Label probs:\", text_probs)\n```"
  created_at: 2023-12-28 18:55:43+00:00
  edited: false
  hidden: false
  id: 658dc4af7fe0235473be25a7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
      fullname: "Furkan G\xF6z\xFCkara"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MonsterMMORPG
      type: user
    createdAt: '2023-12-28T19:18:38.000Z'
    data:
      edited: false
      editors:
      - MonsterMMORPG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6870974898338318
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672531901326-6345bd89fe134dfd7a0dba40.png?w=200&h=200&f=face
          fullname: "Furkan G\xF6z\xFCkara"
          isHf: false
          isPro: false
          name: MonsterMMORPG
          type: user
        html: "<blockquote>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >import</span> torch\n<span class=\"hljs-keyword\">from</span> PIL <span\
          \ class=\"hljs-keyword\">import</span> Image\n<span class=\"hljs-keyword\"\
          >import</span> open_clip\n\nmodel, _, preprocess = open_clip.create_model_and_transforms(<span\
          \ class=\"hljs-string\">'ViT-bigG-14'</span>, pretrained=<span class=\"\
          hljs-string\">'.checkpoints/CLIP-ViT-bigG-14-laion2B-39B-b160k.bin'</span>)\n\
          tokenizer = open_clip.get_tokenizer(<span class=\"hljs-string\">'ViT-bigG-14'</span>)\n\
          \nimage = preprocess(Image.<span class=\"hljs-built_in\">open</span>(<span\
          \ class=\"hljs-string\">\"animals.jpg\"</span>)).unsqueeze(<span class=\"\
          hljs-number\">0</span>)\ntext = tokenizer([<span class=\"hljs-string\">\"\
          a dog\"</span>,<span class=\"hljs-string\">\"a cat\"</span>])\n\n<span class=\"\
          hljs-keyword\">with</span> torch.no_grad(), torch.cuda.amp.autocast():\n\
          \    image_features = model.encode_image(image)\n    text_features = model.encode_text(text)\n\
          \    image_features /= image_features.norm(dim=-<span class=\"hljs-number\"\
          >1</span>, keepdim=<span class=\"hljs-literal\">True</span>)\n    text_features\
          \ /= text_features.norm(dim=-<span class=\"hljs-number\">1</span>, keepdim=<span\
          \ class=\"hljs-literal\">True</span>)\n\n    text_probs = (<span class=\"\
          hljs-number\">100.0</span> * image_features @ text_features.T).softmax(dim=-<span\
          \ class=\"hljs-number\">1</span>)\n\n<span class=\"hljs-built_in\">print</span>(<span\
          \ class=\"hljs-string\">\"Label probs:\"</span>, text_probs)\n</code></pre>\n\
          </blockquote>\n<p>thanks but this is not what i was looking</p>\n<p>this\
          \ is token based chances</p>\n<p>actually i found how to use and even have\
          \ a auto installer right now</p>\n<p><a rel=\"nofollow\" href=\"https://youtu.be/PNA9p94JmtY\"\
          >https://youtu.be/PNA9p94JmtY</a></p>\n"
        raw: "> ```python\n> import torch\n> from PIL import Image\n> import open_clip\n\
          > \n> model, _, preprocess = open_clip.create_model_and_transforms('ViT-bigG-14',\
          \ pretrained='.checkpoints/CLIP-ViT-bigG-14-laion2B-39B-b160k.bin')\n> tokenizer\
          \ = open_clip.get_tokenizer('ViT-bigG-14')\n> \n> image = preprocess(Image.open(\"\
          animals.jpg\")).unsqueeze(0)\n> text = tokenizer([\"a dog\",\"a cat\"])\n\
          > \n> with torch.no_grad(), torch.cuda.amp.autocast():\n>     image_features\
          \ = model.encode_image(image)\n>     text_features = model.encode_text(text)\n\
          >     image_features /= image_features.norm(dim=-1, keepdim=True)\n>   \
          \  text_features /= text_features.norm(dim=-1, keepdim=True)\n> \n>    \
          \ text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n\
          > \n> print(\"Label probs:\", text_probs)\n> ```\n\nthanks but this is not\
          \ what i was looking\n\nthis is token based chances\n\nactually i found\
          \ how to use and even have a auto installer right now\n\nhttps://youtu.be/PNA9p94JmtY"
        updatedAt: '2023-12-28T19:18:38.936Z'
      numEdits: 0
      reactions: []
    id: 658dca0ebea632dc941d40ab
    type: comment
  author: MonsterMMORPG
  content: "> ```python\n> import torch\n> from PIL import Image\n> import open_clip\n\
    > \n> model, _, preprocess = open_clip.create_model_and_transforms('ViT-bigG-14',\
    \ pretrained='.checkpoints/CLIP-ViT-bigG-14-laion2B-39B-b160k.bin')\n> tokenizer\
    \ = open_clip.get_tokenizer('ViT-bigG-14')\n> \n> image = preprocess(Image.open(\"\
    animals.jpg\")).unsqueeze(0)\n> text = tokenizer([\"a dog\",\"a cat\"])\n> \n\
    > with torch.no_grad(), torch.cuda.amp.autocast():\n>     image_features = model.encode_image(image)\n\
    >     text_features = model.encode_text(text)\n>     image_features /= image_features.norm(dim=-1,\
    \ keepdim=True)\n>     text_features /= text_features.norm(dim=-1, keepdim=True)\n\
    > \n>     text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n\
    > \n> print(\"Label probs:\", text_probs)\n> ```\n\nthanks but this is not what\
    \ i was looking\n\nthis is token based chances\n\nactually i found how to use\
    \ and even have a auto installer right now\n\nhttps://youtu.be/PNA9p94JmtY"
  created_at: 2023-12-28 19:18:38+00:00
  edited: false
  hidden: false
  id: 658dca0ebea632dc941d40ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595261977978-noauth.jpeg?w=200&h=200&f=face
      fullname: Alex Rozgo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: rozgo
      type: user
    createdAt: '2023-12-28T19:21:44.000Z'
    data:
      edited: false
      editors:
      - rozgo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8488150238990784
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1595261977978-noauth.jpeg?w=200&h=200&f=face
          fullname: Alex Rozgo
          isHf: false
          isPro: true
          name: rozgo
          type: user
        html: '<p>Ah! I missed the captions part. Happy inferencing.</p>

          '
        raw: Ah! I missed the captions part. Happy inferencing.
        updatedAt: '2023-12-28T19:21:44.192Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MonsterMMORPG
    id: 658dcac8ac02633c0d19c147
    type: comment
  author: rozgo
  content: Ah! I missed the captions part. Happy inferencing.
  created_at: 2023-12-28 19:21:44+00:00
  edited: false
  hidden: false
  id: 658dcac8ac02633c0d19c147
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 13
repo_id: laion/CLIP-ViT-bigG-14-laion2B-39B-b160k
repo_type: model
status: open
target_branch: null
title: Model card has 0 info how to use amazing! I want to use ViT-bigG-14, laion2b_s39b_b160k
  to generate captions for a given folder of images
