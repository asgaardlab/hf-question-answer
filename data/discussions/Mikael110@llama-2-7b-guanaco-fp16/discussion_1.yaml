!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SinanAkkoyun
conflicting_files: null
created_at: 2023-07-19 22:19:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63dcff68a8877129a1574f33/O-8C_Wy8nr_zo8TudBF1k.jpeg?w=200&h=200&f=face
      fullname: Sinan Akkoyun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SinanAkkoyun
      type: user
    createdAt: '2023-07-19T23:19:18.000Z'
    data:
      edited: false
      editors:
      - SinanAkkoyun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9767789244651794
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63dcff68a8877129a1574f33/O-8C_Wy8nr_zo8TudBF1k.jpeg?w=200&h=200&f=face
          fullname: Sinan Akkoyun
          isHf: false
          isPro: false
          name: SinanAkkoyun
          type: user
        html: '<p>Hi, I am wondering why you didn''t use the new prompt format, given
          that the model already was heavily finetuned on that?</p>

          '
        raw: Hi, I am wondering why you didn't use the new prompt format, given that
          the model already was heavily finetuned on that?
        updatedAt: '2023-07-19T23:19:18.290Z'
      numEdits: 0
      reactions: []
    id: 64b86f760d8834cb3230a00d
    type: comment
  author: SinanAkkoyun
  content: Hi, I am wondering why you didn't use the new prompt format, given that
    the model already was heavily finetuned on that?
  created_at: 2023-07-19 22:19:18+00:00
  edited: false
  hidden: false
  id: 64b86f760d8834cb3230a00d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/229e60726cd92951c31d7303e40be2cd.svg
      fullname: Mikael
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Mikael110
      type: user
    createdAt: '2023-07-20T00:20:58.000Z'
    data:
      edited: true
      editors:
      - Mikael110
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9526243209838867
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/229e60726cd92951c31d7303e40be2cd.svg
          fullname: Mikael
          isHf: false
          isPro: false
          name: Mikael110
          type: user
        html: '<p>This finetune is based on the Llama-2 <a href="https://huggingface.co/meta-llama/Llama-2-7b-hf">base</a>
          model, not the <a href="https://huggingface.co/meta-llama/Llama-2-7b-chat-hf">chat</a>
          model. The base model does not have a prompt format as it is not an instruct
          tuned model. If it was based on the chat model then it would indeed make
          more sense to stick to that format. But generally speaking it is always
          best to finetune base models, especially in this case where the chat model
          has already been very heavily tuned.</p>

          <p>Also since I''m interested in doing like-for-like comparisons I wanted
          the model training to be as close to the original as possible. Which is
          why I used the exact script that was used to train the original Guanaco
          model with basically 0 modifications.  I''m also relatively new when it
          comes to finetuning so I wanted to stick with something proven, to try to
          decrease the chances that I screw something up.</p>

          '
        raw: 'This finetune is based on the Llama-2 [base](https://huggingface.co/meta-llama/Llama-2-7b-hf)
          model, not the [chat](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)
          model. The base model does not have a prompt format as it is not an instruct
          tuned model. If it was based on the chat model then it would indeed make
          more sense to stick to that format. But generally speaking it is always
          best to finetune base models, especially in this case where the chat model
          has already been very heavily tuned.


          Also since I''m interested in doing like-for-like comparisons I wanted the
          model training to be as close to the original as possible. Which is why
          I used the exact script that was used to train the original Guanaco model
          with basically 0 modifications.  I''m also relatively new when it comes
          to finetuning so I wanted to stick with something proven, to try to decrease
          the chances that I screw something up.'
        updatedAt: '2023-07-20T00:32:45.257Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Psychopatz
    id: 64b87deaf1f8e6ea58501546
    type: comment
  author: Mikael110
  content: 'This finetune is based on the Llama-2 [base](https://huggingface.co/meta-llama/Llama-2-7b-hf)
    model, not the [chat](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf) model.
    The base model does not have a prompt format as it is not an instruct tuned model.
    If it was based on the chat model then it would indeed make more sense to stick
    to that format. But generally speaking it is always best to finetune base models,
    especially in this case where the chat model has already been very heavily tuned.


    Also since I''m interested in doing like-for-like comparisons I wanted the model
    training to be as close to the original as possible. Which is why I used the exact
    script that was used to train the original Guanaco model with basically 0 modifications.  I''m
    also relatively new when it comes to finetuning so I wanted to stick with something
    proven, to try to decrease the chances that I screw something up.'
  created_at: 2023-07-19 23:20:58+00:00
  edited: true
  hidden: false
  id: 64b87deaf1f8e6ea58501546
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63dcff68a8877129a1574f33/O-8C_Wy8nr_zo8TudBF1k.jpeg?w=200&h=200&f=face
      fullname: Sinan Akkoyun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SinanAkkoyun
      type: user
    createdAt: '2023-07-20T06:41:40.000Z'
    data:
      edited: false
      editors:
      - SinanAkkoyun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9831016659736633
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63dcff68a8877129a1574f33/O-8C_Wy8nr_zo8TudBF1k.jpeg?w=200&h=200&f=face
          fullname: Sinan Akkoyun
          isHf: false
          isPro: false
          name: SinanAkkoyun
          type: user
        html: '<p>Oh, I totally missed that this was trained on the base model! I
          completely get it, thank you for the comment!</p>

          <p>Did you come across evaluating performance? :)</p>

          '
        raw: 'Oh, I totally missed that this was trained on the base model! I completely
          get it, thank you for the comment!


          Did you come across evaluating performance? :)'
        updatedAt: '2023-07-20T06:41:40.087Z'
      numEdits: 0
      reactions: []
    id: 64b8d72435c815492d3003c5
    type: comment
  author: SinanAkkoyun
  content: 'Oh, I totally missed that this was trained on the base model! I completely
    get it, thank you for the comment!


    Did you come across evaluating performance? :)'
  created_at: 2023-07-20 05:41:40+00:00
  edited: false
  hidden: false
  id: 64b8d72435c815492d3003c5
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Mikael110/llama-2-7b-guanaco-fp16
repo_type: model
status: open
target_branch: null
title: Why not the new prompt format?
