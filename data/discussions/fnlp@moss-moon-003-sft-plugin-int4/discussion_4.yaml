!!python/object:huggingface_hub.community.DiscussionWithDetails
author: karfly
conflicting_files: null
created_at: 2023-04-26 22:41:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2a0a85072b0fdb6b4e16fe592e38d07b.svg
      fullname: Karim Iskakov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: karfly
      type: user
    createdAt: '2023-04-26T23:41:28.000Z'
    data:
      edited: false
      editors:
      - karfly
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2a0a85072b0fdb6b4e16fe592e38d07b.svg
          fullname: Karim Iskakov
          isHf: false
          isPro: false
          name: karfly
          type: user
        html: "<p>Get this error whiles executing <code>model = AutoModelForCausalLM.from_pretrained(MODEL_PATH,\
          \ trust_remote_code=True).half().cuda()</code></p>\n<p>Full traceback:</p>\n\
          <pre><code class=\"language-python\">Traceback (most recent call last):\n\
          \  File <span class=\"hljs-string\">\"/usr/lib/python3.8/runpy.py\"</span>,\
          \ line <span class=\"hljs-number\">194</span>, <span class=\"hljs-keyword\"\
          >in</span> _run_module_as_main\n    <span class=\"hljs-keyword\">return</span>\
          \ _run_code(code, main_globals, <span class=\"hljs-literal\">None</span>,\n\
          \  File <span class=\"hljs-string\">\"/usr/lib/python3.8/runpy.py\"</span>,\
          \ line <span class=\"hljs-number\">87</span>, <span class=\"hljs-keyword\"\
          >in</span> _run_code\n    <span class=\"hljs-built_in\">exec</span>(code,\
          \ run_globals)\n  File <span class=\"hljs-string\">\"/app/basaran/__main__.py\"\
          </span>, line <span class=\"hljs-number\">40</span>, <span class=\"hljs-keyword\"\
          >in</span> &lt;module&gt;\n    stream_model = load_model(\n  File <span\
          \ class=\"hljs-string\">\"/app/basaran/model.py\"</span>, line <span class=\"\
          hljs-number\">342</span>, <span class=\"hljs-keyword\">in</span> load_model\n\
          \    model = AutoModelForCausalLM.from_pretrained(name_or_path, trust_remote_code=<span\
          \ class=\"hljs-literal\">True</span>).half().cuda()\n  File <span class=\"\
          hljs-string\">\"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py\"\
          </span>, line <span class=\"hljs-number\">466</span>, <span class=\"hljs-keyword\"\
          >in</span> from_pretrained\n    <span class=\"hljs-keyword\">return</span>\
          \ model_class.from_pretrained(\n  File <span class=\"hljs-string\">\"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
          </span>, line <span class=\"hljs-number\">2629</span>, <span class=\"hljs-keyword\"\
          >in</span> from_pretrained\n    model = cls(config, *model_args, **model_kwargs)\n\
          \  File <span class=\"hljs-string\">\"/root/.cache/huggingface/modules/transformers_modules/moss-moon-003-sft-int4/modeling_moss.py\"\
          </span>, line <span class=\"hljs-number\">608</span>, <span class=\"hljs-keyword\"\
          >in</span> __init__\n    self.quantize(config.wbits, config.groupsize)\n\
          \  File <span class=\"hljs-string\">\"/root/.cache/huggingface/modules/transformers_modules/moss-moon-003-sft-int4/modeling_moss.py\"\
          </span>, line <span class=\"hljs-number\">732</span>, <span class=\"hljs-keyword\"\
          >in</span> quantize\n    <span class=\"hljs-keyword\">from</span> .quantization\
          \ <span class=\"hljs-keyword\">import</span> quantize_with_gptq\n  File\
          \ <span class=\"hljs-string\">\"/root/.cache/huggingface/modules/transformers_modules/moss-moon-003-sft-int4/quantization.py\"\
          </span>, line <span class=\"hljs-number\">8</span>, <span class=\"hljs-keyword\"\
          >in</span> &lt;module&gt;\n    <span class=\"hljs-keyword\">from</span>\
          \ .custom_autotune <span class=\"hljs-keyword\">import</span> *\nModuleNotFoundError:\
          \ No module named <span class=\"hljs-string\">'transformers_modules.moss-moon-003-sft-int4.custom_autotune'</span>\n\
          </code></pre>\n<p>How to solve it?</p>\n"
        raw: "Get this error whiles executing `model = AutoModelForCausalLM.from_pretrained(MODEL_PATH,\
          \ trust_remote_code=True).half().cuda()`\r\n\r\nFull traceback:\r\n```python\r\
          \nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.8/runpy.py\"\
          , line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals,\
          \ None,\r\n  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\r\
          \n    exec(code, run_globals)\r\n  File \"/app/basaran/__main__.py\", line\
          \ 40, in <module>\r\n    stream_model = load_model(\r\n  File \"/app/basaran/model.py\"\
          , line 342, in load_model\r\n    model = AutoModelForCausalLM.from_pretrained(name_or_path,\
          \ trust_remote_code=True).half().cuda()\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py\"\
          , line 466, in from_pretrained\r\n    return model_class.from_pretrained(\r\
          \n  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
          , line 2629, in from_pretrained\r\n    model = cls(config, *model_args,\
          \ **model_kwargs)\r\n  File \"/root/.cache/huggingface/modules/transformers_modules/moss-moon-003-sft-int4/modeling_moss.py\"\
          , line 608, in __init__\r\n    self.quantize(config.wbits, config.groupsize)\r\
          \n  File \"/root/.cache/huggingface/modules/transformers_modules/moss-moon-003-sft-int4/modeling_moss.py\"\
          , line 732, in quantize\r\n    from .quantization import quantize_with_gptq\r\
          \n  File \"/root/.cache/huggingface/modules/transformers_modules/moss-moon-003-sft-int4/quantization.py\"\
          , line 8, in <module>\r\n    from .custom_autotune import *\r\nModuleNotFoundError:\
          \ No module named 'transformers_modules.moss-moon-003-sft-int4.custom_autotune'\r\
          \n```\r\n\r\nHow to solve it?"
        updatedAt: '2023-04-26T23:41:28.574Z'
      numEdits: 0
      reactions: []
    id: 6449b6a85dec46f9adc25b3f
    type: comment
  author: karfly
  content: "Get this error whiles executing `model = AutoModelForCausalLM.from_pretrained(MODEL_PATH,\
    \ trust_remote_code=True).half().cuda()`\r\n\r\nFull traceback:\r\n```python\r\
    \nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.8/runpy.py\"\
    , line 194, in _run_module_as_main\r\n    return _run_code(code, main_globals,\
    \ None,\r\n  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\r\n \
    \   exec(code, run_globals)\r\n  File \"/app/basaran/__main__.py\", line 40, in\
    \ <module>\r\n    stream_model = load_model(\r\n  File \"/app/basaran/model.py\"\
    , line 342, in load_model\r\n    model = AutoModelForCausalLM.from_pretrained(name_or_path,\
    \ trust_remote_code=True).half().cuda()\r\n  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py\"\
    , line 466, in from_pretrained\r\n    return model_class.from_pretrained(\r\n\
    \  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\"\
    , line 2629, in from_pretrained\r\n    model = cls(config, *model_args, **model_kwargs)\r\
    \n  File \"/root/.cache/huggingface/modules/transformers_modules/moss-moon-003-sft-int4/modeling_moss.py\"\
    , line 608, in __init__\r\n    self.quantize(config.wbits, config.groupsize)\r\
    \n  File \"/root/.cache/huggingface/modules/transformers_modules/moss-moon-003-sft-int4/modeling_moss.py\"\
    , line 732, in quantize\r\n    from .quantization import quantize_with_gptq\r\n\
    \  File \"/root/.cache/huggingface/modules/transformers_modules/moss-moon-003-sft-int4/quantization.py\"\
    , line 8, in <module>\r\n    from .custom_autotune import *\r\nModuleNotFoundError:\
    \ No module named 'transformers_modules.moss-moon-003-sft-int4.custom_autotune'\r\
    \n```\r\n\r\nHow to solve it?"
  created_at: 2023-04-26 22:41:28+00:00
  edited: false
  hidden: false
  id: 6449b6a85dec46f9adc25b3f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3004a4a66caa7746b81cb7ad33bb27d6.svg
      fullname: Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Lenery
      type: user
    createdAt: '2023-05-05T06:12:49.000Z'
    data:
      edited: true
      editors:
      - Lenery
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3004a4a66caa7746b81cb7ad33bb27d6.svg
          fullname: Chen
          isHf: false
          isPro: false
          name: Lenery
          type: user
        html: '<p>You could try this</p>

          <pre><code class="language-python"><span class="hljs-keyword">import</span>
          sys

          sys.path.append(<span class="hljs-string">''/root/.cache/huggingface/modules''</span>)

          </code></pre>

          '
        raw: 'You could try this

          ```python

          import sys

          sys.path.append(''/root/.cache/huggingface/modules'')

          ```'
        updatedAt: '2023-05-05T06:13:14.131Z'
      numEdits: 2
      reactions: []
    id: 64549e61d55525a4fedb691d
    type: comment
  author: Lenery
  content: 'You could try this

    ```python

    import sys

    sys.path.append(''/root/.cache/huggingface/modules'')

    ```'
  created_at: 2023-05-05 05:12:49+00:00
  edited: true
  hidden: false
  id: 64549e61d55525a4fedb691d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: fnlp/moss-moon-003-sft-plugin-int4
repo_type: model
status: open
target_branch: null
title: 'Getting ModuleNotFoundError: No module named ''transformers_modules.moss-moon-003-sft-int4.custom_autotune'''
