!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JinchaoLove
conflicting_files: null
created_at: 2022-12-29 08:23:19+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c806f66b1b3719242a73bcf55efcd054.svg
      fullname: JinchaoLove
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JinchaoLove
      type: user
    createdAt: '2022-12-29T08:23:19.000Z'
    data:
      edited: false
      editors:
      - JinchaoLove
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c806f66b1b3719242a73bcf55efcd054.svg
          fullname: JinchaoLove
          isHf: false
          isPro: false
          name: JinchaoLove
          type: user
        html: '<p>Hi, there! I found the outputs of encoders from <code>transformers</code>
          and <code>whisper</code> are not matched, may I ask why? Here''re my codes:</p>

          <pre><code class="language-python"><span class="hljs-keyword">import</span>
          torch

          <span class="hljs-keyword">import</span> whisper

          <span class="hljs-keyword">import</span> transformers <span class="hljs-keyword">as</span>
          ppb

          x = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">80</span>,
          <span class="hljs-number">3000</span>)  <span class="hljs-comment"># random
          input feature</span>

          enc1 = ppb.models.whisper.modeling_whisper.WhisperEncoder.from_pretrained(<span
          class="hljs-string">''openai/whisper-small''</span>)

          enc2 = whisper.load_model(<span class="hljs-string">''small''</span>).encoder

          y1 = enc1(x)

          y2 = enc2(x)

          <span class="hljs-built_in">print</span>(torch.<span class="hljs-built_in">sum</span>(<span
          class="hljs-built_in">abs</span>(y1.last_hidden_state - y2)))  <span class="hljs-comment">#
          expected 0, but got &gt; 1e6</span>

          </code></pre>

          '
        raw: "Hi, there! I found the outputs of encoders from `transformers` and `whisper`\
          \ are not matched, may I ask why? Here're my codes:\r\n```python\r\nimport\
          \ torch\r\nimport whisper\r\nimport transformers as ppb\r\nx = torch.randn(1,\
          \ 80, 3000)  # random input feature\r\nenc1 = ppb.models.whisper.modeling_whisper.WhisperEncoder.from_pretrained('openai/whisper-small')\r\
          \nenc2 = whisper.load_model('small').encoder\r\ny1 = enc1(x)\r\ny2 = enc2(x)\r\
          \nprint(torch.sum(abs(y1.last_hidden_state - y2)))  # expected 0, but got\
          \ > 1e6\r\n```"
        updatedAt: '2022-12-29T08:23:19.590Z'
      numEdits: 0
      reactions: []
    id: 63ad4e779835dd4b124f48e2
    type: comment
  author: JinchaoLove
  content: "Hi, there! I found the outputs of encoders from `transformers` and `whisper`\
    \ are not matched, may I ask why? Here're my codes:\r\n```python\r\nimport torch\r\
    \nimport whisper\r\nimport transformers as ppb\r\nx = torch.randn(1, 80, 3000)\
    \  # random input feature\r\nenc1 = ppb.models.whisper.modeling_whisper.WhisperEncoder.from_pretrained('openai/whisper-small')\r\
    \nenc2 = whisper.load_model('small').encoder\r\ny1 = enc1(x)\r\ny2 = enc2(x)\r\
    \nprint(torch.sum(abs(y1.last_hidden_state - y2)))  # expected 0, but got > 1e6\r\
    \n```"
  created_at: 2022-12-29 08:23:19+00:00
  edited: false
  hidden: false
  id: 63ad4e779835dd4b124f48e2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-01-05T15:31:16.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>The proposed method of loading the WhisperEncoder <code>from_pretrained</code>\
          \ is resulting in none of the pre-trained weights being loaded:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">import</span> transformers\
          \ <span class=\"hljs-keyword\">as</span> ppb\n\nenc1 = ppb.models.whisper.modeling_whisper.WhisperEncoder.from_pretrained(<span\
          \ class=\"hljs-string\">'openai/whisper-small'</span>)\n</code></pre>\n\
          <details>\n\n<summary> Warning message: </summary>\n\n<pre><code>Some weights\
          \ of WhisperEncoder were not initialized from the model checkpoint at openai/whisper-small\
          \ and are newly initialized: ['model.layers.3.self_attn.v_proj.weight',\
          \ 'model.layers.6.self_attn_layer_norm.weight', 'model.layers.0.self_attn_layer_norm.bias',\
          \ 'model.layers.3.final_layer_norm.bias', 'model.layers.2.fc2.weight', 'model.layers.9.fc2.bias',\
          \ 'model.layers.6.self_attn_layer_norm.bias', 'model.layers.6.self_attn.v_proj.bias',\
          \ 'model.layers.10.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.weight',\
          \ 'model.layers.5.self_attn.q_proj.weight', 'model.layers.9.fc1.weight',\
          \ 'model.layers.1.final_layer_norm.weight', 'model.layers.1.self_attn.q_proj.bias',\
          \ 'model.layers.9.fc1.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.conv2.weight',\
          \ 'model.layers.3.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.bias',\
          \ 'model.layers.3.final_layer_norm.weight', 'model.layers.2.self_attn.q_proj.weight',\
          \ 'model.layers.3.self_attn.k_proj.weight', 'model.layers.4.self_attn.out_proj.weight',\
          \ 'model.layers.11.final_layer_norm.bias', 'model.layers.8.self_attn.k_proj.weight',\
          \ 'model.layers.8.final_layer_norm.bias', 'model.layers.4.self_attn.k_proj.weight',\
          \ 'model.layers.1.fc1.weight', 'model.layers.5.fc2.bias', 'model.layers.5.self_attn.v_proj.weight',\
          \ 'model.layers.8.self_attn.out_proj.bias', 'model.layers.8.self_attn.q_proj.weight',\
          \ 'model.layers.6.final_layer_norm.bias', 'model.layers.10.fc1.weight',\
          \ 'model.layers.11.self_attn_layer_norm.bias', 'model.layers.6.fc1.weight',\
          \ 'model.layers.11.self_attn.v_proj.weight', 'model.layers.10.final_layer_norm.weight',\
          \ 'model.layers.7.self_attn.v_proj.bias', 'model.layers.1.self_attn_layer_norm.weight',\
          \ 'model.layers.3.fc2.weight', 'model.layers.2.self_attn.k_proj.weight',\
          \ 'model.conv2.bias', 'model.layers.11.self_attn.out_proj.bias', 'model.layers.11.fc2.weight',\
          \ 'model.layers.0.fc1.bias', 'model.layer_norm.bias', 'model.layers.10.self_attn_layer_norm.weight',\
          \ 'model.layers.5.fc1.weight', 'model.layers.10.self_attn.k_proj.weight',\
          \ 'model.layers.1.self_attn.v_proj.weight', 'model.layers.5.self_attn.out_proj.weight',\
          \ 'model.layers.3.self_attn_layer_norm.bias', 'model.layers.3.fc1.weight',\
          \ 'model.layers.1.self_attn.out_proj.weight', 'model.layers.4.final_layer_norm.bias',\
          \ 'model.conv1.bias', 'model.layers.5.self_attn.out_proj.bias', 'model.layers.4.self_attn.out_proj.bias',\
          \ 'model.layers.5.fc2.weight', 'model.layers.6.self_attn.out_proj.bias',\
          \ 'model.layers.4.final_layer_norm.weight', 'model.layers.10.fc2.weight',\
          \ 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.fc2.weight',\
          \ 'model.layers.2.self_attn.q_proj.bias', 'model.layers.4.fc1.weight', 'model.layers.6.self_attn.q_proj.weight',\
          \ 'model.layers.6.final_layer_norm.weight', 'model.layers.9.self_attn.q_proj.bias',\
          \ 'model.layers.8.self_attn.v_proj.weight', 'model.layers.0.fc1.weight',\
          \ 'model.layers.2.self_attn.v_proj.weight', 'model.layers.7.self_attn.k_proj.weight',\
          \ 'model.layers.9.self_attn.q_proj.weight', 'model.layers.4.fc1.bias', 'model.layers.7.self_attn.out_proj.weight',\
          \ 'model.layers.11.fc2.bias', 'model.layers.2.self_attn_layer_norm.bias',\
          \ 'model.layers.5.fc1.bias', 'model.layers.9.self_attn_layer_norm.bias',\
          \ 'model.layers.6.fc1.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.6.fc2.weight',\
          \ 'model.layers.11.final_layer_norm.weight', 'model.layers.0.self_attn.k_proj.weight',\
          \ 'model.layers.0.fc2.weight', 'model.layers.7.final_layer_norm.weight',\
          \ 'model.layers.10.self_attn.out_proj.weight', 'model.layers.5.self_attn.q_proj.bias',\
          \ 'model.layers.10.self_attn.out_proj.bias', 'model.layers.11.fc1.bias',\
          \ 'model.layers.2.fc1.weight', 'model.layers.2.final_layer_norm.weight',\
          \ 'model.layers.7.final_layer_norm.bias', 'model.layers.3.self_attn.v_proj.bias',\
          \ 'model.layers.4.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight',\
          \ 'model.layers.8.fc2.weight', 'model.layers.11.self_attn.k_proj.weight',\
          \ 'model.layers.1.final_layer_norm.bias', 'model.layers.2.self_attn_layer_norm.weight',\
          \ 'model.layers.5.final_layer_norm.weight', 'model.layers.8.self_attn_layer_norm.bias',\
          \ 'model.layers.7.self_attn.q_proj.bias', 'model.layers.10.self_attn_layer_norm.bias',\
          \ 'model.layers.5.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.weight',\
          \ 'model.layers.3.self_attn.out_proj.bias', 'model.layers.9.final_layer_norm.bias',\
          \ 'model.conv1.weight', 'model.layers.10.fc1.bias', 'model.layers.9.self_attn.k_proj.weight',\
          \ 'model.layers.1.fc2.weight', 'model.layers.6.self_attn.k_proj.weight',\
          \ 'model.layers.3.self_attn.out_proj.weight', 'model.layers.8.self_attn.out_proj.weight',\
          \ 'model.layers.3.fc2.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.7.self_attn.out_proj.bias',\
          \ 'model.layers.3.fc1.bias', 'model.layers.10.final_layer_norm.bias', 'model.layers.9.final_layer_norm.weight',\
          \ 'model.layers.1.fc2.bias', 'model.layers.1.fc1.bias', 'model.layers.9.fc2.weight',\
          \ 'model.layers.7.fc2.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layer_norm.weight',\
          \ 'model.layers.8.fc1.bias', 'model.layers.8.self_attn_layer_norm.weight',\
          \ 'model.layers.7.fc1.weight', 'model.layers.2.self_attn.out_proj.bias',\
          \ 'model.layers.8.self_attn.v_proj.bias', 'model.layers.6.fc2.bias', 'model.layers.0.fc2.bias',\
          \ 'model.layers.9.self_attn.v_proj.weight', 'model.layers.8.final_layer_norm.weight',\
          \ 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.q_proj.weight',\
          \ 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.final_layer_norm.weight',\
          \ 'model.layers.0.self_attn.v_proj.weight', 'model.layers.8.fc2.bias', 'model.layers.0.self_attn_layer_norm.weight',\
          \ 'model.layers.10.self_attn.q_proj.weight', 'model.layers.7.fc2.weight',\
          \ 'model.layers.4.self_attn_layer_norm.weight', 'model.layers.6.self_attn.out_proj.weight',\
          \ 'model.layers.11.self_attn_layer_norm.weight', 'model.layers.5.self_attn_layer_norm.weight',\
          \ 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.final_layer_norm.bias',\
          \ 'model.layers.4.fc2.bias', 'model.layers.9.self_attn.out_proj.weight',\
          \ 'model.layers.0.self_attn.q_proj.weight', 'model.layers.4.self_attn_layer_norm.bias',\
          \ 'model.layers.10.fc2.bias', 'model.layers.7.self_attn.q_proj.weight',\
          \ 'model.layers.0.self_attn.out_proj.bias', 'model.layers.2.self_attn.out_proj.weight',\
          \ 'model.layers.1.self_attn.out_proj.bias', 'model.layers.7.fc1.bias', 'model.layers.2.fc1.bias',\
          \ 'model.layers.8.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias',\
          \ 'model.layers.2.fc2.bias', 'model.layers.7.self_attn_layer_norm.bias',\
          \ 'model.layers.11.self_attn.out_proj.weight', 'model.layers.4.self_attn.v_proj.weight',\
          \ 'model.layers.2.final_layer_norm.bias', 'model.layers.11.fc1.weight',\
          \ 'model.layers.3.self_attn_layer_norm.weight', 'model.layers.0.self_attn.out_proj.weight',\
          \ 'model.layers.7.self_attn.v_proj.weight', 'model.layers.9.self_attn.out_proj.bias',\
          \ 'model.layers.2.self_attn.v_proj.bias', 'model.layers.9.self_attn_layer_norm.weight',\
          \ 'model.layers.3.self_attn.q_proj.bias', 'model.layers.1.self_attn_layer_norm.bias',\
          \ 'model.layers.0.final_layer_norm.bias', 'model.layers.1.self_attn.v_proj.bias',\
          \ 'model.layers.0.self_attn.v_proj.bias', 'model.layers.7.self_attn_layer_norm.weight',\
          \ 'model.embed_positions.weight', 'model.layers.5.self_attn_layer_norm.bias',\
          \ 'model.layers.8.fc1.weight']\n</code></pre>\n</details>\n\n<p>Instead,\
          \ we should load all of the encoder-decoder weights using <code>WhisperForConditionalGeneration</code>\
          \ and then extract the encoder module. This is the same logic we are using\
          \ for the OpenAI implementation. When we do so, the maximum element-wise\
          \ difference between the HF implementation and the OpenAI implementation\
          \ is <code>8.5e-5</code> (to within numerical precision):</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">import</span> torch\n\
          <span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\"\
          >import</span> WhisperForConditionalGeneration\n<span class=\"hljs-keyword\"\
          >import</span> whisper\n\nx = torch.randn(<span class=\"hljs-number\">1</span>,\
          \ <span class=\"hljs-number\">80</span>, <span class=\"hljs-number\">3000</span>)\
          \  <span class=\"hljs-comment\"># random input feature</span>\n\nenc1 =\
          \ WhisperForConditionalGeneration.from_pretrained(<span class=\"hljs-string\"\
          >'openai/whisper-small'</span>).model.encoder\nenc2 = whisper.load_model(<span\
          \ class=\"hljs-string\">'small'</span>).encoder\n\n<span class=\"hljs-keyword\"\
          >with</span> torch.no_grad():\n    y1 = enc1(x)\n    y2 = enc2(x)\n\n<span\
          \ class=\"hljs-built_in\">print</span>(torch.<span class=\"hljs-built_in\"\
          >max</span>(<span class=\"hljs-built_in\">abs</span>(y1.last_hidden_state\
          \ - y2)))\n</code></pre>\n<p><strong>Print Output:</strong></p>\n<pre><code>tensor(8.5831e-05)\n\
          </code></pre>\n"
        raw: "The proposed method of loading the WhisperEncoder `from_pretrained`\
          \ is resulting in none of the pre-trained weights being loaded:\n```python\n\
          import transformers as ppb\n\nenc1 = ppb.models.whisper.modeling_whisper.WhisperEncoder.from_pretrained('openai/whisper-small')\n\
          ```\n<details>\n\n<summary> Warning message: </summary>\n\n```\nSome weights\
          \ of WhisperEncoder were not initialized from the model checkpoint at openai/whisper-small\
          \ and are newly initialized: ['model.layers.3.self_attn.v_proj.weight',\
          \ 'model.layers.6.self_attn_layer_norm.weight', 'model.layers.0.self_attn_layer_norm.bias',\
          \ 'model.layers.3.final_layer_norm.bias', 'model.layers.2.fc2.weight', 'model.layers.9.fc2.bias',\
          \ 'model.layers.6.self_attn_layer_norm.bias', 'model.layers.6.self_attn.v_proj.bias',\
          \ 'model.layers.10.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.weight',\
          \ 'model.layers.5.self_attn.q_proj.weight', 'model.layers.9.fc1.weight',\
          \ 'model.layers.1.final_layer_norm.weight', 'model.layers.1.self_attn.q_proj.bias',\
          \ 'model.layers.9.fc1.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.conv2.weight',\
          \ 'model.layers.3.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.bias',\
          \ 'model.layers.3.final_layer_norm.weight', 'model.layers.2.self_attn.q_proj.weight',\
          \ 'model.layers.3.self_attn.k_proj.weight', 'model.layers.4.self_attn.out_proj.weight',\
          \ 'model.layers.11.final_layer_norm.bias', 'model.layers.8.self_attn.k_proj.weight',\
          \ 'model.layers.8.final_layer_norm.bias', 'model.layers.4.self_attn.k_proj.weight',\
          \ 'model.layers.1.fc1.weight', 'model.layers.5.fc2.bias', 'model.layers.5.self_attn.v_proj.weight',\
          \ 'model.layers.8.self_attn.out_proj.bias', 'model.layers.8.self_attn.q_proj.weight',\
          \ 'model.layers.6.final_layer_norm.bias', 'model.layers.10.fc1.weight',\
          \ 'model.layers.11.self_attn_layer_norm.bias', 'model.layers.6.fc1.weight',\
          \ 'model.layers.11.self_attn.v_proj.weight', 'model.layers.10.final_layer_norm.weight',\
          \ 'model.layers.7.self_attn.v_proj.bias', 'model.layers.1.self_attn_layer_norm.weight',\
          \ 'model.layers.3.fc2.weight', 'model.layers.2.self_attn.k_proj.weight',\
          \ 'model.conv2.bias', 'model.layers.11.self_attn.out_proj.bias', 'model.layers.11.fc2.weight',\
          \ 'model.layers.0.fc1.bias', 'model.layer_norm.bias', 'model.layers.10.self_attn_layer_norm.weight',\
          \ 'model.layers.5.fc1.weight', 'model.layers.10.self_attn.k_proj.weight',\
          \ 'model.layers.1.self_attn.v_proj.weight', 'model.layers.5.self_attn.out_proj.weight',\
          \ 'model.layers.3.self_attn_layer_norm.bias', 'model.layers.3.fc1.weight',\
          \ 'model.layers.1.self_attn.out_proj.weight', 'model.layers.4.final_layer_norm.bias',\
          \ 'model.conv1.bias', 'model.layers.5.self_attn.out_proj.bias', 'model.layers.4.self_attn.out_proj.bias',\
          \ 'model.layers.5.fc2.weight', 'model.layers.6.self_attn.out_proj.bias',\
          \ 'model.layers.4.final_layer_norm.weight', 'model.layers.10.fc2.weight',\
          \ 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.fc2.weight',\
          \ 'model.layers.2.self_attn.q_proj.bias', 'model.layers.4.fc1.weight', 'model.layers.6.self_attn.q_proj.weight',\
          \ 'model.layers.6.final_layer_norm.weight', 'model.layers.9.self_attn.q_proj.bias',\
          \ 'model.layers.8.self_attn.v_proj.weight', 'model.layers.0.fc1.weight',\
          \ 'model.layers.2.self_attn.v_proj.weight', 'model.layers.7.self_attn.k_proj.weight',\
          \ 'model.layers.9.self_attn.q_proj.weight', 'model.layers.4.fc1.bias', 'model.layers.7.self_attn.out_proj.weight',\
          \ 'model.layers.11.fc2.bias', 'model.layers.2.self_attn_layer_norm.bias',\
          \ 'model.layers.5.fc1.bias', 'model.layers.9.self_attn_layer_norm.bias',\
          \ 'model.layers.6.fc1.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.6.fc2.weight',\
          \ 'model.layers.11.final_layer_norm.weight', 'model.layers.0.self_attn.k_proj.weight',\
          \ 'model.layers.0.fc2.weight', 'model.layers.7.final_layer_norm.weight',\
          \ 'model.layers.10.self_attn.out_proj.weight', 'model.layers.5.self_attn.q_proj.bias',\
          \ 'model.layers.10.self_attn.out_proj.bias', 'model.layers.11.fc1.bias',\
          \ 'model.layers.2.fc1.weight', 'model.layers.2.final_layer_norm.weight',\
          \ 'model.layers.7.final_layer_norm.bias', 'model.layers.3.self_attn.v_proj.bias',\
          \ 'model.layers.4.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight',\
          \ 'model.layers.8.fc2.weight', 'model.layers.11.self_attn.k_proj.weight',\
          \ 'model.layers.1.final_layer_norm.bias', 'model.layers.2.self_attn_layer_norm.weight',\
          \ 'model.layers.5.final_layer_norm.weight', 'model.layers.8.self_attn_layer_norm.bias',\
          \ 'model.layers.7.self_attn.q_proj.bias', 'model.layers.10.self_attn_layer_norm.bias',\
          \ 'model.layers.5.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.weight',\
          \ 'model.layers.3.self_attn.out_proj.bias', 'model.layers.9.final_layer_norm.bias',\
          \ 'model.conv1.weight', 'model.layers.10.fc1.bias', 'model.layers.9.self_attn.k_proj.weight',\
          \ 'model.layers.1.fc2.weight', 'model.layers.6.self_attn.k_proj.weight',\
          \ 'model.layers.3.self_attn.out_proj.weight', 'model.layers.8.self_attn.out_proj.weight',\
          \ 'model.layers.3.fc2.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.7.self_attn.out_proj.bias',\
          \ 'model.layers.3.fc1.bias', 'model.layers.10.final_layer_norm.bias', 'model.layers.9.final_layer_norm.weight',\
          \ 'model.layers.1.fc2.bias', 'model.layers.1.fc1.bias', 'model.layers.9.fc2.weight',\
          \ 'model.layers.7.fc2.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layer_norm.weight',\
          \ 'model.layers.8.fc1.bias', 'model.layers.8.self_attn_layer_norm.weight',\
          \ 'model.layers.7.fc1.weight', 'model.layers.2.self_attn.out_proj.bias',\
          \ 'model.layers.8.self_attn.v_proj.bias', 'model.layers.6.fc2.bias', 'model.layers.0.fc2.bias',\
          \ 'model.layers.9.self_attn.v_proj.weight', 'model.layers.8.final_layer_norm.weight',\
          \ 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.q_proj.weight',\
          \ 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.final_layer_norm.weight',\
          \ 'model.layers.0.self_attn.v_proj.weight', 'model.layers.8.fc2.bias', 'model.layers.0.self_attn_layer_norm.weight',\
          \ 'model.layers.10.self_attn.q_proj.weight', 'model.layers.7.fc2.weight',\
          \ 'model.layers.4.self_attn_layer_norm.weight', 'model.layers.6.self_attn.out_proj.weight',\
          \ 'model.layers.11.self_attn_layer_norm.weight', 'model.layers.5.self_attn_layer_norm.weight',\
          \ 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.final_layer_norm.bias',\
          \ 'model.layers.4.fc2.bias', 'model.layers.9.self_attn.out_proj.weight',\
          \ 'model.layers.0.self_attn.q_proj.weight', 'model.layers.4.self_attn_layer_norm.bias',\
          \ 'model.layers.10.fc2.bias', 'model.layers.7.self_attn.q_proj.weight',\
          \ 'model.layers.0.self_attn.out_proj.bias', 'model.layers.2.self_attn.out_proj.weight',\
          \ 'model.layers.1.self_attn.out_proj.bias', 'model.layers.7.fc1.bias', 'model.layers.2.fc1.bias',\
          \ 'model.layers.8.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias',\
          \ 'model.layers.2.fc2.bias', 'model.layers.7.self_attn_layer_norm.bias',\
          \ 'model.layers.11.self_attn.out_proj.weight', 'model.layers.4.self_attn.v_proj.weight',\
          \ 'model.layers.2.final_layer_norm.bias', 'model.layers.11.fc1.weight',\
          \ 'model.layers.3.self_attn_layer_norm.weight', 'model.layers.0.self_attn.out_proj.weight',\
          \ 'model.layers.7.self_attn.v_proj.weight', 'model.layers.9.self_attn.out_proj.bias',\
          \ 'model.layers.2.self_attn.v_proj.bias', 'model.layers.9.self_attn_layer_norm.weight',\
          \ 'model.layers.3.self_attn.q_proj.bias', 'model.layers.1.self_attn_layer_norm.bias',\
          \ 'model.layers.0.final_layer_norm.bias', 'model.layers.1.self_attn.v_proj.bias',\
          \ 'model.layers.0.self_attn.v_proj.bias', 'model.layers.7.self_attn_layer_norm.weight',\
          \ 'model.embed_positions.weight', 'model.layers.5.self_attn_layer_norm.bias',\
          \ 'model.layers.8.fc1.weight']\n```\n</details>\n\nInstead, we should load\
          \ all of the encoder-decoder weights using `WhisperForConditionalGeneration`\
          \ and then extract the encoder module. This is the same logic we are using\
          \ for the OpenAI implementation. When we do so, the maximum element-wise\
          \ difference between the HF implementation and the OpenAI implementation\
          \ is `8.5e-5` (to within numerical precision):\n\n```python\nimport torch\n\
          from transformers import WhisperForConditionalGeneration\nimport whisper\n\
          \nx = torch.randn(1, 80, 3000)  # random input feature\n\nenc1 = WhisperForConditionalGeneration.from_pretrained('openai/whisper-small').model.encoder\n\
          enc2 = whisper.load_model('small').encoder\n\nwith torch.no_grad():\n  \
          \  y1 = enc1(x)\n    y2 = enc2(x)\n\nprint(torch.max(abs(y1.last_hidden_state\
          \ - y2)))\n```\n**Print Output:**\n```\ntensor(8.5831e-05)\n```"
        updatedAt: '2023-01-05T15:36:49.779Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - JinchaoLove
    id: 63b6ed4438471ff4c0818f19
    type: comment
  author: sanchit-gandhi
  content: "The proposed method of loading the WhisperEncoder `from_pretrained` is\
    \ resulting in none of the pre-trained weights being loaded:\n```python\nimport\
    \ transformers as ppb\n\nenc1 = ppb.models.whisper.modeling_whisper.WhisperEncoder.from_pretrained('openai/whisper-small')\n\
    ```\n<details>\n\n<summary> Warning message: </summary>\n\n```\nSome weights of\
    \ WhisperEncoder were not initialized from the model checkpoint at openai/whisper-small\
    \ and are newly initialized: ['model.layers.3.self_attn.v_proj.weight', 'model.layers.6.self_attn_layer_norm.weight',\
    \ 'model.layers.0.self_attn_layer_norm.bias', 'model.layers.3.final_layer_norm.bias',\
    \ 'model.layers.2.fc2.weight', 'model.layers.9.fc2.bias', 'model.layers.6.self_attn_layer_norm.bias',\
    \ 'model.layers.6.self_attn.v_proj.bias', 'model.layers.10.self_attn.q_proj.bias',\
    \ 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.q_proj.weight',\
    \ 'model.layers.9.fc1.weight', 'model.layers.1.final_layer_norm.weight', 'model.layers.1.self_attn.q_proj.bias',\
    \ 'model.layers.9.fc1.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.conv2.weight',\
    \ 'model.layers.3.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.bias',\
    \ 'model.layers.3.final_layer_norm.weight', 'model.layers.2.self_attn.q_proj.weight',\
    \ 'model.layers.3.self_attn.k_proj.weight', 'model.layers.4.self_attn.out_proj.weight',\
    \ 'model.layers.11.final_layer_norm.bias', 'model.layers.8.self_attn.k_proj.weight',\
    \ 'model.layers.8.final_layer_norm.bias', 'model.layers.4.self_attn.k_proj.weight',\
    \ 'model.layers.1.fc1.weight', 'model.layers.5.fc2.bias', 'model.layers.5.self_attn.v_proj.weight',\
    \ 'model.layers.8.self_attn.out_proj.bias', 'model.layers.8.self_attn.q_proj.weight',\
    \ 'model.layers.6.final_layer_norm.bias', 'model.layers.10.fc1.weight', 'model.layers.11.self_attn_layer_norm.bias',\
    \ 'model.layers.6.fc1.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.10.final_layer_norm.weight',\
    \ 'model.layers.7.self_attn.v_proj.bias', 'model.layers.1.self_attn_layer_norm.weight',\
    \ 'model.layers.3.fc2.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.conv2.bias',\
    \ 'model.layers.11.self_attn.out_proj.bias', 'model.layers.11.fc2.weight', 'model.layers.0.fc1.bias',\
    \ 'model.layer_norm.bias', 'model.layers.10.self_attn_layer_norm.weight', 'model.layers.5.fc1.weight',\
    \ 'model.layers.10.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight',\
    \ 'model.layers.5.self_attn.out_proj.weight', 'model.layers.3.self_attn_layer_norm.bias',\
    \ 'model.layers.3.fc1.weight', 'model.layers.1.self_attn.out_proj.weight', 'model.layers.4.final_layer_norm.bias',\
    \ 'model.conv1.bias', 'model.layers.5.self_attn.out_proj.bias', 'model.layers.4.self_attn.out_proj.bias',\
    \ 'model.layers.5.fc2.weight', 'model.layers.6.self_attn.out_proj.bias', 'model.layers.4.final_layer_norm.weight',\
    \ 'model.layers.10.fc2.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.fc2.weight',\
    \ 'model.layers.2.self_attn.q_proj.bias', 'model.layers.4.fc1.weight', 'model.layers.6.self_attn.q_proj.weight',\
    \ 'model.layers.6.final_layer_norm.weight', 'model.layers.9.self_attn.q_proj.bias',\
    \ 'model.layers.8.self_attn.v_proj.weight', 'model.layers.0.fc1.weight', 'model.layers.2.self_attn.v_proj.weight',\
    \ 'model.layers.7.self_attn.k_proj.weight', 'model.layers.9.self_attn.q_proj.weight',\
    \ 'model.layers.4.fc1.bias', 'model.layers.7.self_attn.out_proj.weight', 'model.layers.11.fc2.bias',\
    \ 'model.layers.2.self_attn_layer_norm.bias', 'model.layers.5.fc1.bias', 'model.layers.9.self_attn_layer_norm.bias',\
    \ 'model.layers.6.fc1.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.6.fc2.weight',\
    \ 'model.layers.11.final_layer_norm.weight', 'model.layers.0.self_attn.k_proj.weight',\
    \ 'model.layers.0.fc2.weight', 'model.layers.7.final_layer_norm.weight', 'model.layers.10.self_attn.out_proj.weight',\
    \ 'model.layers.5.self_attn.q_proj.bias', 'model.layers.10.self_attn.out_proj.bias',\
    \ 'model.layers.11.fc1.bias', 'model.layers.2.fc1.weight', 'model.layers.2.final_layer_norm.weight',\
    \ 'model.layers.7.final_layer_norm.bias', 'model.layers.3.self_attn.v_proj.bias',\
    \ 'model.layers.4.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight',\
    \ 'model.layers.8.fc2.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.1.final_layer_norm.bias',\
    \ 'model.layers.2.self_attn_layer_norm.weight', 'model.layers.5.final_layer_norm.weight',\
    \ 'model.layers.8.self_attn_layer_norm.bias', 'model.layers.7.self_attn.q_proj.bias',\
    \ 'model.layers.10.self_attn_layer_norm.bias', 'model.layers.5.self_attn.v_proj.bias',\
    \ 'model.layers.10.self_attn.v_proj.weight', 'model.layers.3.self_attn.out_proj.bias',\
    \ 'model.layers.9.final_layer_norm.bias', 'model.conv1.weight', 'model.layers.10.fc1.bias',\
    \ 'model.layers.9.self_attn.k_proj.weight', 'model.layers.1.fc2.weight', 'model.layers.6.self_attn.k_proj.weight',\
    \ 'model.layers.3.self_attn.out_proj.weight', 'model.layers.8.self_attn.out_proj.weight',\
    \ 'model.layers.3.fc2.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.7.self_attn.out_proj.bias',\
    \ 'model.layers.3.fc1.bias', 'model.layers.10.final_layer_norm.bias', 'model.layers.9.final_layer_norm.weight',\
    \ 'model.layers.1.fc2.bias', 'model.layers.1.fc1.bias', 'model.layers.9.fc2.weight',\
    \ 'model.layers.7.fc2.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layer_norm.weight',\
    \ 'model.layers.8.fc1.bias', 'model.layers.8.self_attn_layer_norm.weight', 'model.layers.7.fc1.weight',\
    \ 'model.layers.2.self_attn.out_proj.bias', 'model.layers.8.self_attn.v_proj.bias',\
    \ 'model.layers.6.fc2.bias', 'model.layers.0.fc2.bias', 'model.layers.9.self_attn.v_proj.weight',\
    \ 'model.layers.8.final_layer_norm.weight', 'model.layers.11.self_attn.q_proj.bias',\
    \ 'model.layers.11.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.bias',\
    \ 'model.layers.0.final_layer_norm.weight', 'model.layers.0.self_attn.v_proj.weight',\
    \ 'model.layers.8.fc2.bias', 'model.layers.0.self_attn_layer_norm.weight', 'model.layers.10.self_attn.q_proj.weight',\
    \ 'model.layers.7.fc2.weight', 'model.layers.4.self_attn_layer_norm.weight', 'model.layers.6.self_attn.out_proj.weight',\
    \ 'model.layers.11.self_attn_layer_norm.weight', 'model.layers.5.self_attn_layer_norm.weight',\
    \ 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.final_layer_norm.bias',\
    \ 'model.layers.4.fc2.bias', 'model.layers.9.self_attn.out_proj.weight', 'model.layers.0.self_attn.q_proj.weight',\
    \ 'model.layers.4.self_attn_layer_norm.bias', 'model.layers.10.fc2.bias', 'model.layers.7.self_attn.q_proj.weight',\
    \ 'model.layers.0.self_attn.out_proj.bias', 'model.layers.2.self_attn.out_proj.weight',\
    \ 'model.layers.1.self_attn.out_proj.bias', 'model.layers.7.fc1.bias', 'model.layers.2.fc1.bias',\
    \ 'model.layers.8.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias',\
    \ 'model.layers.2.fc2.bias', 'model.layers.7.self_attn_layer_norm.bias', 'model.layers.11.self_attn.out_proj.weight',\
    \ 'model.layers.4.self_attn.v_proj.weight', 'model.layers.2.final_layer_norm.bias',\
    \ 'model.layers.11.fc1.weight', 'model.layers.3.self_attn_layer_norm.weight',\
    \ 'model.layers.0.self_attn.out_proj.weight', 'model.layers.7.self_attn.v_proj.weight',\
    \ 'model.layers.9.self_attn.out_proj.bias', 'model.layers.2.self_attn.v_proj.bias',\
    \ 'model.layers.9.self_attn_layer_norm.weight', 'model.layers.3.self_attn.q_proj.bias',\
    \ 'model.layers.1.self_attn_layer_norm.bias', 'model.layers.0.final_layer_norm.bias',\
    \ 'model.layers.1.self_attn.v_proj.bias', 'model.layers.0.self_attn.v_proj.bias',\
    \ 'model.layers.7.self_attn_layer_norm.weight', 'model.embed_positions.weight',\
    \ 'model.layers.5.self_attn_layer_norm.bias', 'model.layers.8.fc1.weight']\n```\n\
    </details>\n\nInstead, we should load all of the encoder-decoder weights using\
    \ `WhisperForConditionalGeneration` and then extract the encoder module. This\
    \ is the same logic we are using for the OpenAI implementation. When we do so,\
    \ the maximum element-wise difference between the HF implementation and the OpenAI\
    \ implementation is `8.5e-5` (to within numerical precision):\n\n```python\nimport\
    \ torch\nfrom transformers import WhisperForConditionalGeneration\nimport whisper\n\
    \nx = torch.randn(1, 80, 3000)  # random input feature\n\nenc1 = WhisperForConditionalGeneration.from_pretrained('openai/whisper-small').model.encoder\n\
    enc2 = whisper.load_model('small').encoder\n\nwith torch.no_grad():\n    y1 =\
    \ enc1(x)\n    y2 = enc2(x)\n\nprint(torch.max(abs(y1.last_hidden_state - y2)))\n\
    ```\n**Print Output:**\n```\ntensor(8.5831e-05)\n```"
  created_at: 2023-01-05 15:31:16+00:00
  edited: true
  hidden: false
  id: 63b6ed4438471ff4c0818f19
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-01-13T15:45:00.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: "<p>(we could probably fix this by adding <code>base_model_prefix =\
          \ \"model\"</code>  to the <code>WhisperEncoder</code> class WDYT <span\
          \ data-props=\"{&quot;user&quot;:&quot;sanchit-gandhi&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/sanchit-gandhi\">@<span\
          \ class=\"underline\">sanchit-gandhi</span></a></span>\n\n\t</span></span>\
          \ )</p>\n"
        raw: (we could probably fix this by adding `base_model_prefix = "model"`  to
          the `WhisperEncoder` class WDYT @sanchit-gandhi )
        updatedAt: '2023-01-13T15:45:00.825Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - JinchaoLove
        - sanchit-gandhi
    id: 63c17c7c2b643e4015360314
    type: comment
  author: ArthurZ
  content: (we could probably fix this by adding `base_model_prefix = "model"`  to
    the `WhisperEncoder` class WDYT @sanchit-gandhi )
  created_at: 2023-01-13 15:45:00+00:00
  edited: false
  hidden: false
  id: 63c17c7c2b643e4015360314
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-01-16T15:26:32.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: '<p>SGTM!</p>

          '
        raw: SGTM!
        updatedAt: '2023-01-16T15:26:32.378Z'
      numEdits: 0
      reactions: []
    id: 63c56ca89fa5d07c2c357636
    type: comment
  author: sanchit-gandhi
  content: SGTM!
  created_at: 2023-01-16 15:26:32+00:00
  edited: false
  hidden: false
  id: 63c56ca89fa5d07c2c357636
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: openai/whisper-small
repo_type: model
status: open
target_branch: null
title: Mismatched outputs from encoders of `transformers` and `whisper`
