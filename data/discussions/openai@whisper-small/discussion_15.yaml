!!python/object:huggingface_hub.community.DiscussionWithDetails
author: lucas-aixplain
conflicting_files: null
created_at: 2023-02-10 14:16:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676053778405-6282703d6b99692e7d9ed4ff.jpeg?w=200&h=200&f=face
      fullname: Lucas Pavanelli
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lucas-aixplain
      type: user
    createdAt: '2023-02-10T14:16:49.000Z'
    data:
      edited: false
      editors:
      - lucas-aixplain
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676053778405-6282703d6b99692e7d9ed4ff.jpeg?w=200&h=200&f=face
          fullname: Lucas Pavanelli
          isHf: false
          isPro: false
          name: lucas-aixplain
          type: user
        html: "<p>Hi there!<br>I am following the sample code in README to transcribe\
          \ a couple of English audios, but the forced decoder is not working, I am\
          \ getting transcriptions in other languages. Here is my code:</p>\n<pre><code\
          \ class=\"language-python\"><span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> WhisperProcessor, WhisperForConditionalGeneration\n\
          <span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\"\
          >import</span> Dataset, Audio\n\n<span class=\"hljs-comment\"># load model\
          \ and processor</span>\nprocessor = WhisperProcessor.from_pretrained(<span\
          \ class=\"hljs-string\">\"openai/whisper-small\"</span>)\nmodel = WhisperForConditionalGeneration.from_pretrained(<span\
          \ class=\"hljs-string\">\"openai/whisper-small\"</span>)\nmodel.config.forced_decoder_ids\
          \ = processor.get_decoder_prompt_ids(language=<span class=\"hljs-string\"\
          >\"english\"</span>, task=<span class=\"hljs-string\">\"transcribe\"</span>)\n\
          \nds = Dataset.from_dict({<span class=\"hljs-string\">\"audio\"</span>:\
          \ [<span class=\"hljs-string\">'&lt;audio_path&gt;'</span>]}).cast_column(<span\
          \ class=\"hljs-string\">\"audio\"</span>, Audio())\nsample = ds[<span class=\"\
          hljs-number\">0</span>][<span class=\"hljs-string\">\"audio\"</span>]\n\
          input_features = processor(sample[<span class=\"hljs-string\">\"array\"\
          </span>], sampling_rate=sample[<span class=\"hljs-string\">\"sampling_rate\"\
          </span>], return_tensors=<span class=\"hljs-string\">\"pt\"</span>).input_features\
          \ \n<span class=\"hljs-comment\"># generate token ids</span>\npredicted_ids\
          \ = model.generate(input_features)\n<span class=\"hljs-comment\"># decode\
          \ token ids to text</span>\ntranscription = processor.batch_decode(predicted_ids,\
          \ skip_special_tokens=<span class=\"hljs-literal\">False</span>)\ntranscription\n\
          </code></pre>\n<p>And the result:</p>\n<pre><code>['&lt;|startoftranscript|&gt;&lt;|bo|&gt;&lt;|transcribe|&gt;&lt;|notimestamps|&gt;\
          \ [...] &lt;|endoftext|&gt;']\n</code></pre>\n<p>Unfortunately, I cannot\
          \ share the audio file because it is private.<br>Some recent changes are\
          \ causing this problem because I tested 3 weeks ago and was getting ~30\
          \ WER and now it is ~70 WER which is caused by transcribing to other languages.</p>\n"
        raw: "Hi there!\r\nI am following the sample code in README to transcribe\
          \ a couple of English audios, but the forced decoder is not working, I am\
          \ getting transcriptions in other languages. Here is my code:\r\n```python\r\
          \nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\r\
          \nfrom datasets import Dataset, Audio\r\n\r\n# load model and processor\r\
          \nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-small\"\
          )\r\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\"\
          )\r\nmodel.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"\
          english\", task=\"transcribe\")\r\n\r\nds = Dataset.from_dict({\"audio\"\
          : ['<audio_path>']}).cast_column(\"audio\", Audio())\r\nsample = ds[0][\"\
          audio\"]\r\ninput_features = processor(sample[\"array\"], sampling_rate=sample[\"\
          sampling_rate\"], return_tensors=\"pt\").input_features \r\n# generate token\
          \ ids\r\npredicted_ids = model.generate(input_features)\r\n# decode token\
          \ ids to text\r\ntranscription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\r\
          \ntranscription\r\n```\r\nAnd the result:\r\n```\r\n['<|startoftranscript|><|bo|><|transcribe|><|notimestamps|>\
          \ [...] <|endoftext|>']\r\n```\r\nUnfortunately, I cannot share the audio\
          \ file because it is private. \r\nSome recent changes are causing this problem\
          \ because I tested 3 weeks ago and was getting ~30 WER and now it is ~70\
          \ WER which is caused by transcribing to other languages.\r\n"
        updatedAt: '2023-02-10T14:16:49.060Z'
      numEdits: 0
      reactions: []
    id: 63e651d12d704152abaf8912
    type: comment
  author: lucas-aixplain
  content: "Hi there!\r\nI am following the sample code in README to transcribe a\
    \ couple of English audios, but the forced decoder is not working, I am getting\
    \ transcriptions in other languages. Here is my code:\r\n```python\r\nfrom transformers\
    \ import WhisperProcessor, WhisperForConditionalGeneration\r\nfrom datasets import\
    \ Dataset, Audio\r\n\r\n# load model and processor\r\nprocessor = WhisperProcessor.from_pretrained(\"\
    openai/whisper-small\")\r\nmodel = WhisperForConditionalGeneration.from_pretrained(\"\
    openai/whisper-small\")\r\nmodel.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"\
    english\", task=\"transcribe\")\r\n\r\nds = Dataset.from_dict({\"audio\": ['<audio_path>']}).cast_column(\"\
    audio\", Audio())\r\nsample = ds[0][\"audio\"]\r\ninput_features = processor(sample[\"\
    array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features\
    \ \r\n# generate token ids\r\npredicted_ids = model.generate(input_features)\r\
    \n# decode token ids to text\r\ntranscription = processor.batch_decode(predicted_ids,\
    \ skip_special_tokens=False)\r\ntranscription\r\n```\r\nAnd the result:\r\n```\r\
    \n['<|startoftranscript|><|bo|><|transcribe|><|notimestamps|> [...] <|endoftext|>']\r\
    \n```\r\nUnfortunately, I cannot share the audio file because it is private. \r\
    \nSome recent changes are causing this problem because I tested 3 weeks ago and\
    \ was getting ~30 WER and now it is ~70 WER which is caused by transcribing to\
    \ other languages.\r\n"
  created_at: 2023-02-10 14:16:49+00:00
  edited: false
  hidden: false
  id: 63e651d12d704152abaf8912
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-02-10T15:04:08.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ArthurZ&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ArthurZ\">@<span class=\"\
          underline\">ArthurZ</span></a></span>\n\n\t</span></span> the change to\
          \ <code>.generate()</code> was backwards compatible with the <code>forced_decoder_ids</code>\
          \ no? Maybe you could take a look here!</p>\n"
        raw: '@ArthurZ the change to `.generate()` was backwards compatible with the
          `forced_decoder_ids` no? Maybe you could take a look here!'
        updatedAt: '2023-02-10T15:04:24.016Z'
      numEdits: 1
      reactions: []
    id: 63e65ce826fa42e117f3ccbd
    type: comment
  author: sanchit-gandhi
  content: '@ArthurZ the change to `.generate()` was backwards compatible with the
    `forced_decoder_ids` no? Maybe you could take a look here!'
  created_at: 2023-02-10 15:04:08+00:00
  edited: true
  hidden: false
  id: 63e65ce826fa42e117f3ccbd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676053778405-6282703d6b99692e7d9ed4ff.jpeg?w=200&h=200&f=face
      fullname: Lucas Pavanelli
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: lucas-aixplain
      type: user
    createdAt: '2023-02-28T00:30:38.000Z'
    data:
      edited: false
      editors:
      - lucas-aixplain
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1676053778405-6282703d6b99692e7d9ed4ff.jpeg?w=200&h=200&f=face
          fullname: Lucas Pavanelli
          isHf: false
          isPro: false
          name: lucas-aixplain
          type: user
        html: '<p>Any updates on this bug?</p>

          '
        raw: Any updates on this bug?
        updatedAt: '2023-02-28T00:30:38.090Z'
      numEdits: 0
      reactions: []
    id: 63fd4b2e1cca11052a4da976
    type: comment
  author: lucas-aixplain
  content: Any updates on this bug?
  created_at: 2023-02-28 00:30:38+00:00
  edited: false
  hidden: false
  id: 63fd4b2e1cca11052a4da976
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-03-03T16:55:15.000Z'
    data:
      edited: true
      editors:
      - sanchit-gandhi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Hey <span data-props=\"{&quot;user&quot;:&quot;lucas-aixplain&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/lucas-aixplain\"\
          >@<span class=\"underline\">lucas-aixplain</span></a></span>\n\n\t</span></span>,\
          \ thanks for flagging this, I was able to reproduce:</p>\n<pre><code class=\"\
          language-python\"><span class=\"hljs-keyword\">from</span> transformers\
          \ <span class=\"hljs-keyword\">import</span> WhisperProcessor, WhisperForConditionalGeneration\n\
          <span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\"\
          >import</span> load_dataset\n\n<span class=\"hljs-comment\"># load model\
          \ and processor</span>\nprocessor = WhisperProcessor.from_pretrained(<span\
          \ class=\"hljs-string\">\"openai/whisper-tiny\"</span>)\nmodel = WhisperForConditionalGeneration.from_pretrained(<span\
          \ class=\"hljs-string\">\"openai/whisper-tiny\"</span>)\n\nds = load_dataset(<span\
          \ class=\"hljs-string\">\"hf-internal-testing/librispeech_asr_dummy\"</span>,\
          \ <span class=\"hljs-string\">\"clean\"</span>, split=<span class=\"hljs-string\"\
          >\"validation\"</span>)\nsample = ds[<span class=\"hljs-number\">0</span>][<span\
          \ class=\"hljs-string\">\"audio\"</span>]\ninput_features = processor(sample[<span\
          \ class=\"hljs-string\">\"array\"</span>], sampling_rate=sample[<span class=\"\
          hljs-string\">\"sampling_rate\"</span>], return_tensors=<span class=\"hljs-string\"\
          >\"pt\"</span>).input_features \n\n<span class=\"hljs-comment\"># set the\
          \ forced ids</span>\nmodel.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=<span\
          \ class=\"hljs-string\">\"french\"</span>, task=<span class=\"hljs-string\"\
          >\"transcribe\"</span>)\n\n<span class=\"hljs-comment\"># generate token\
          \ ids</span>\npredicted_ids = model.generate(input_features)\n<span class=\"\
          hljs-comment\"># decode token ids to text</span>\ntranscription = processor.batch_decode(predicted_ids,\
          \ skip_special_tokens=<span class=\"hljs-literal\">False</span>)\n<span\
          \ class=\"hljs-built_in\">print</span>(transcription)\n</code></pre>\n<p><strong>Print\
          \ Output</strong>:</p>\n<pre><code>['&lt;|startoftranscript|&gt;&lt;|en|&gt;&lt;|transcribe|&gt;&lt;|notimestamps|&gt;\
          \ Mr. Quilter is the apostle of the middle classes and we are glad to welcome\
          \ his gospel.&lt;|endoftext|&gt;']\n</code></pre>\n<p>Opened an issue on\
          \ Transformers to track: <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/issues/21937\"\
          >https://github.com/huggingface/transformers/issues/21937</a></p>\n"
        raw: "Hey @lucas-aixplain, thanks for flagging this, I was able to reproduce:\n\
          ```python\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\n\
          from datasets import load_dataset\n\n# load model and processor\nprocessor\
          \ = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\nmodel = WhisperForConditionalGeneration.from_pretrained(\"\
          openai/whisper-tiny\")\n\nds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\"\
          , \"clean\", split=\"validation\")\nsample = ds[0][\"audio\"]\ninput_features\
          \ = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"\
          ], return_tensors=\"pt\").input_features \n\n# set the forced ids\nmodel.config.forced_decoder_ids\
          \ = processor.get_decoder_prompt_ids(language=\"french\", task=\"transcribe\"\
          )\n\n# generate token ids\npredicted_ids = model.generate(input_features)\n\
          # decode token ids to text\ntranscription = processor.batch_decode(predicted_ids,\
          \ skip_special_tokens=False)\nprint(transcription)\n```\n**Print Output**:\n\
          ```\n['<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Mr. Quilter\
          \ is the apostle of the middle classes and we are glad to welcome his gospel.<|endoftext|>']\n\
          ```\nOpened an issue on Transformers to track: https://github.com/huggingface/transformers/issues/21937"
        updatedAt: '2023-03-03T17:01:48.838Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - lucas-aixplain
    id: 640226739fe2fcff94e2ec9b
    type: comment
  author: sanchit-gandhi
  content: "Hey @lucas-aixplain, thanks for flagging this, I was able to reproduce:\n\
    ```python\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\n\
    from datasets import load_dataset\n\n# load model and processor\nprocessor = WhisperProcessor.from_pretrained(\"\
    openai/whisper-tiny\")\nmodel = WhisperForConditionalGeneration.from_pretrained(\"\
    openai/whisper-tiny\")\n\nds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\"\
    , \"clean\", split=\"validation\")\nsample = ds[0][\"audio\"]\ninput_features\
    \ = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"\
    pt\").input_features \n\n# set the forced ids\nmodel.config.forced_decoder_ids\
    \ = processor.get_decoder_prompt_ids(language=\"french\", task=\"transcribe\"\
    )\n\n# generate token ids\npredicted_ids = model.generate(input_features)\n# decode\
    \ token ids to text\ntranscription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n\
    print(transcription)\n```\n**Print Output**:\n```\n['<|startoftranscript|><|en|><|transcribe|><|notimestamps|>\
    \ Mr. Quilter is the apostle of the middle classes and we are glad to welcome\
    \ his gospel.<|endoftext|>']\n```\nOpened an issue on Transformers to track: https://github.com/huggingface/transformers/issues/21937"
  created_at: 2023-03-03 16:55:15+00:00
  edited: true
  hidden: false
  id: 640226739fe2fcff94e2ec9b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: openai/whisper-small
repo_type: model
status: open
target_branch: null
title: Forcing decoder to transcribe English is not working
