!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Noahloghman
conflicting_files: null
created_at: 2023-12-05 17:06:49+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
      fullname: Brahim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Noahloghman
      type: user
    createdAt: '2023-12-05T17:06:49.000Z'
    data:
      edited: false
      editors:
      - Noahloghman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.903857946395874
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
          fullname: Brahim
          isHf: false
          isPro: false
          name: Noahloghman
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;Xenova&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Xenova\">@<span class=\"\
          underline\">Xenova</span></a></span>\n\n\t</span></span><br>I have this\
          \ error when I run this code : Error: Exception during initialization: D:\\\
          a_work\\1\\s\\onnxruntime\\core\\optimizer\\initializer.cc:31 onnxruntime::Initializer::Initializer\
          \ !model_path.IsEmpty() was false. model_path must not be empty. Ensure\
          \ that a path is provided when the model is created or loaded.<br>did you\
          \ added or modified some line inside the .onnx file in order to make it\
          \ work? </p>\n<p>am I, missing something?</p>\n"
        raw: "Hi @Xenova \r\nI have this error when I run this code : Error: Exception\
          \ during initialization: D:\\a\\_work\\1\\s\\onnxruntime\\core\\optimizer\\\
          initializer.cc:31 onnxruntime::Initializer::Initializer !model_path.IsEmpty()\
          \ was false. model_path must not be empty. Ensure that a path is provided\
          \ when the model is created or loaded.\r\ndid you added or modified some\
          \ line inside the .onnx file in order to make it work? \r\n\r\nam I, missing\
          \ something?"
        updatedAt: '2023-12-05T17:06:49.222Z'
      numEdits: 0
      reactions: []
    id: 656f58a983450322ca36d188
    type: comment
  author: Noahloghman
  content: "Hi @Xenova \r\nI have this error when I run this code : Error: Exception\
    \ during initialization: D:\\a\\_work\\1\\s\\onnxruntime\\core\\optimizer\\initializer.cc:31\
    \ onnxruntime::Initializer::Initializer !model_path.IsEmpty() was false. model_path\
    \ must not be empty. Ensure that a path is provided when the model is created\
    \ or loaded.\r\ndid you added or modified some line inside the .onnx file in order\
    \ to make it work? \r\n\r\nam I, missing something?"
  created_at: 2023-12-05 17:06:49+00:00
  edited: false
  hidden: false
  id: 656f58a983450322ca36d188
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png?w=200&h=200&f=face
      fullname: Joshua
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Xenova
      type: user
    createdAt: '2023-12-05T17:08:59.000Z'
    data:
      edited: false
      editors:
      - Xenova
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9459512829780579
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png?w=200&h=200&f=face
          fullname: Joshua
          isHf: true
          isPro: false
          name: Xenova
          type: user
        html: '<p>Hi there! Are you using this from transformers.js? Could you provide
          the piece of code which resulted in this issue?</p>

          '
        raw: Hi there! Are you using this from transformers.js? Could you provide
          the piece of code which resulted in this issue?
        updatedAt: '2023-12-05T17:08:59.306Z'
      numEdits: 0
      reactions: []
    id: 656f592b7734a829bbbc1c6c
    type: comment
  author: Xenova
  content: Hi there! Are you using this from transformers.js? Could you provide the
    piece of code which resulted in this issue?
  created_at: 2023-12-05 17:08:59+00:00
  edited: false
  hidden: false
  id: 656f592b7734a829bbbc1c6c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
      fullname: Brahim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Noahloghman
      type: user
    createdAt: '2023-12-05T17:24:11.000Z'
    data:
      edited: true
      editors:
      - Noahloghman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8311820030212402
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
          fullname: Brahim
          isHf: false
          isPro: false
          name: Noahloghman
          type: user
        html: '<p>Yes, I''m using transformers.js library</p>

          <p>when I call your repo_id all works good<br>import { pipeline } from ''@xenova/transformers'';<br>const
          pipe = await pipeline(''text-generation'', ''Xenova/gpt2-large-conversational'');</p>

          <p>but when I call same files (all .onnx and .onnx_data inside onnx folder
          and the rest outside) (from your repo id) I have the error above<br>import
          { pipeline } from ''@xenova/transformers'';<br>const pipe = await pipeline(''text-generation'',
          my repo id);</p>

          <p>I added the library transformers.js and granted access into it.<br> I
          did this tests because I''am training my own model but I have same error,
          this is why I tried with yours in order to understand what I''m missing<br>Maybe
          I''m missing this: Is there a way to call ORTModelForCausalLM from optimum.onnxruntime
          inside pipeline of transformers.js (this is in python, )does it exit in
          transformers.js?</p>

          '
        raw: "Yes, I'm using transformers.js library\n\nwhen I call your repo_id all\
          \ works good\nimport { pipeline } from '@xenova/transformers';\nconst pipe\
          \ = await pipeline('text-generation', 'Xenova/gpt2-large-conversational');\n\
          \nbut when I call same files (all .onnx and .onnx_data inside onnx folder\
          \ and the rest outside) (from your repo id) I have the error above\nimport\
          \ { pipeline } from '@xenova/transformers';\nconst pipe = await pipeline('text-generation',\
          \ my repo id);\n\nI added the library transformers.js and granted access\
          \ into it.\n I did this tests because I'am training my own model but I have\
          \ same error, this is why I tried with yours in order to understand what\
          \ I'm missing\nMaybe I'm missing this: Is there a way to call ORTModelForCausalLM\
          \ from optimum.onnxruntime inside pipeline of transformers.js (this is in\
          \ python, )does it exit in transformers.js?\n\n"
        updatedAt: '2023-12-05T23:01:44.529Z'
      numEdits: 1
      reactions: []
    id: 656f5cbbb4ebaeb855bc553a
    type: comment
  author: Noahloghman
  content: "Yes, I'm using transformers.js library\n\nwhen I call your repo_id all\
    \ works good\nimport { pipeline } from '@xenova/transformers';\nconst pipe = await\
    \ pipeline('text-generation', 'Xenova/gpt2-large-conversational');\n\nbut when\
    \ I call same files (all .onnx and .onnx_data inside onnx folder and the rest\
    \ outside) (from your repo id) I have the error above\nimport { pipeline } from\
    \ '@xenova/transformers';\nconst pipe = await pipeline('text-generation', my repo\
    \ id);\n\nI added the library transformers.js and granted access into it.\n I\
    \ did this tests because I'am training my own model but I have same error, this\
    \ is why I tried with yours in order to understand what I'm missing\nMaybe I'm\
    \ missing this: Is there a way to call ORTModelForCausalLM from optimum.onnxruntime\
    \ inside pipeline of transformers.js (this is in python, )does it exit in transformers.js?\n\
    \n"
  created_at: 2023-12-05 17:24:11+00:00
  edited: true
  hidden: false
  id: 656f5cbbb4ebaeb855bc553a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
      fullname: Brahim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Noahloghman
      type: user
    createdAt: '2023-12-05T17:34:11.000Z'
    data:
      edited: false
      editors:
      - Noahloghman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9822219014167786
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
          fullname: Brahim
          isHf: false
          isPro: false
          name: Noahloghman
          type: user
        html: '<p>Is your repo id has more privileges than mine? because I uploaded
          same files inside my new repo_id for testing and I had same error</p>

          '
        raw: Is your repo id has more privileges than mine? because I uploaded same
          files inside my new repo_id for testing and I had same error
        updatedAt: '2023-12-05T17:34:11.019Z'
      numEdits: 0
      reactions: []
    id: 656f5f13dd58e86f240e015d
    type: comment
  author: Noahloghman
  content: Is your repo id has more privileges than mine? because I uploaded same
    files inside my new repo_id for testing and I had same error
  created_at: 2023-12-05 17:34:11+00:00
  edited: false
  hidden: false
  id: 656f5f13dd58e86f240e015d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png?w=200&h=200&f=face
      fullname: Joshua
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Xenova
      type: user
    createdAt: '2023-12-05T17:38:18.000Z'
    data:
      edited: false
      editors:
      - Xenova
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8300030827522278
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png?w=200&h=200&f=face
          fullname: Joshua
          isHf: true
          isPro: false
          name: Xenova
          type: user
        html: '<p>Since your repo is private, are you correctly passing environment
          variables to allow access to the model? See this guide for more info: <a
          href="https://huggingface.co/docs/transformers.js/guides/private">https://huggingface.co/docs/transformers.js/guides/private</a></p>

          '
        raw: 'Since your repo is private, are you correctly passing environment variables
          to allow access to the model? See this guide for more info: https://huggingface.co/docs/transformers.js/guides/private'
        updatedAt: '2023-12-05T17:38:18.085Z'
      numEdits: 0
      reactions: []
    id: 656f600a83450322ca3829b2
    type: comment
  author: Xenova
  content: 'Since your repo is private, are you correctly passing environment variables
    to allow access to the model? See this guide for more info: https://huggingface.co/docs/transformers.js/guides/private'
  created_at: 2023-12-05 17:38:18+00:00
  edited: false
  hidden: false
  id: 656f600a83450322ca3829b2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
      fullname: Brahim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Noahloghman
      type: user
    createdAt: '2023-12-05T18:05:17.000Z'
    data:
      edited: true
      editors:
      - Noahloghman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7944799661636353
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
          fullname: Brahim
          isHf: false
          isPro: false
          name: Noahloghman
          type: user
        html: '<p>Yes I tried this passed correctly environment variables process.env.HF_ACCESS_TOKEN
          = ''hf_...'', even I made it public, but still have the same message error.</p>

          <p>Thank you</p>

          '
        raw: 'Yes I tried this passed correctly environment variables process.env.HF_ACCESS_TOKEN
          = ''hf_...'', even I made it public, but still have the same message error.


          Thank you'
        updatedAt: '2023-12-05T18:16:08.072Z'
      numEdits: 1
      reactions: []
    id: 656f665d8c2bfffc8914de39
    type: comment
  author: Noahloghman
  content: 'Yes I tried this passed correctly environment variables process.env.HF_ACCESS_TOKEN
    = ''hf_...'', even I made it public, but still have the same message error.


    Thank you'
  created_at: 2023-12-05 18:05:17+00:00
  edited: true
  hidden: false
  id: 656f665d8c2bfffc8914de39
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
      fullname: Brahim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Noahloghman
      type: user
    createdAt: '2023-12-05T18:36:35.000Z'
    data:
      edited: false
      editors:
      - Noahloghman
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7928240299224854
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
          fullname: Brahim
          isHf: false
          isPro: false
          name: Noahloghman
          type: user
        html: '<p>Otherwise , with transformers.js , can we call our model from local
          machine, or only from huggingface?</p>

          '
        raw: Otherwise , with transformers.js , can we call our model from local machine,
          or only from huggingface?
        updatedAt: '2023-12-05T18:36:35.047Z'
      numEdits: 0
      reactions: []
    id: 656f6db32f058b368c12c475
    type: comment
  author: Noahloghman
  content: Otherwise , with transformers.js , can we call our model from local machine,
    or only from huggingface?
  created_at: 2023-12-05 18:36:35+00:00
  edited: false
  hidden: false
  id: 656f6db32f058b368c12c475
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/05e659e1164c3dd916550d4caea09804.svg
      fullname: Brahim
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Noahloghman
      type: user
    createdAt: '2023-12-05T22:55:19.000Z'
    data:
      status: closed
    id: 656faa57d81a20af9c1539af
    type: status-change
  author: Noahloghman
  created_at: 2023-12-05 22:55:19+00:00
  id: 656faa57d81a20af9c1539af
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Xenova/gpt2-large-conversational
repo_type: model
status: closed
target_branch: null
title: 'Error: Exception during initialization'
