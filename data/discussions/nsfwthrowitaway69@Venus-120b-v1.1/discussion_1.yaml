!!python/object:huggingface_hub.community.DiscussionWithDetails
author: AS1200
conflicting_files: null
created_at: 2023-12-29 16:19:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/062c16dfafe7f1d7371454934bf91527.svg
      fullname: SA2100
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AS1200
      type: user
    createdAt: '2023-12-29T16:19:51.000Z'
    data:
      edited: false
      editors:
      - AS1200
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9247069358825684
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/062c16dfafe7f1d7371454934bf91527.svg
          fullname: SA2100
          isHf: false
          isPro: false
          name: AS1200
          type: user
        html: "<p>I would like to suggest using 70B storywriter - <a href=\"https://huggingface.co/GOAT-AI/GOAT-70B-Storytelling\"\
          >https://huggingface.co/GOAT-AI/GOAT-70B-Storytelling</a><br>This is my\
          \ personal wish. I\u2019m not forcing anyone to do this and I definitely\
          \ won\u2019t find where you live. Thank you for your attention</p>\n"
        raw: "I would like to suggest using 70B storywriter - https://huggingface.co/GOAT-AI/GOAT-70B-Storytelling\r\
          \nThis is my personal wish. I\u2019m not forcing anyone to do this and I\
          \ definitely won\u2019t find where you live. Thank you for your attention"
        updatedAt: '2023-12-29T16:19:51.362Z'
      numEdits: 0
      reactions: []
    id: 658ef1a75b7553ca5c3c92db
    type: comment
  author: AS1200
  content: "I would like to suggest using 70B storywriter - https://huggingface.co/GOAT-AI/GOAT-70B-Storytelling\r\
    \nThis is my personal wish. I\u2019m not forcing anyone to do this and I definitely\
    \ won\u2019t find where you live. Thank you for your attention"
  created_at: 2023-12-29 16:19:51+00:00
  edited: false
  hidden: false
  id: 658ef1a75b7553ca5c3c92db
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/311b7f466c5f282fe9f5e25e4431d813.svg
      fullname: John Smith
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nsfwthrowitaway69
      type: user
    createdAt: '2023-12-30T04:59:04.000Z'
    data:
      edited: false
      editors:
      - nsfwthrowitaway69
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.954783022403717
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/311b7f466c5f282fe9f5e25e4431d813.svg
          fullname: John Smith
          isHf: false
          isPro: false
          name: nsfwthrowitaway69
          type: user
        html: '<p>I used GOAT in one of my 103b merges and it turned out alright.
          I''ll definitely consider making a 120b 1.2 with GOAT, but I am a bit hesitant
          to make more merges considering that llama 3 is (probably) just around the
          corner :)</p>

          '
        raw: I used GOAT in one of my 103b merges and it turned out alright. I'll
          definitely consider making a 120b 1.2 with GOAT, but I am a bit hesitant
          to make more merges considering that llama 3 is (probably) just around the
          corner :)
        updatedAt: '2023-12-30T04:59:04.891Z'
      numEdits: 0
      reactions: []
    id: 658fa39850d39af7f4e7f2c7
    type: comment
  author: nsfwthrowitaway69
  content: I used GOAT in one of my 103b merges and it turned out alright. I'll definitely
    consider making a 120b 1.2 with GOAT, but I am a bit hesitant to make more merges
    considering that llama 3 is (probably) just around the corner :)
  created_at: 2023-12-30 04:59:04+00:00
  edited: false
  hidden: false
  id: 658fa39850d39af7f4e7f2c7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/062c16dfafe7f1d7371454934bf91527.svg
      fullname: SA2100
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AS1200
      type: user
    createdAt: '2023-12-30T07:57:42.000Z'
    data:
      edited: false
      editors:
      - AS1200
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9631209373474121
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/062c16dfafe7f1d7371454934bf91527.svg
          fullname: SA2100
          isHf: false
          isPro: false
          name: AS1200
          type: user
        html: "<p>I have a very important question, at least for me. Should we expect\
          \ that Llama 3 will be similar in resource consumption to the previous iterations\
          \ of llama 1 b and 2? I would like to use the llama 3 70B with the same\
          \ comfort, but as for the proposed llama 3 120B, I\u2019m not sure that\
          \ its consumption will be similar to the 120B community models that we currently\
          \ have. I somehow run q3 k m at a speed of 0.5 token/second</p>\n"
        raw: "I have a very important question, at least for me. Should we expect\
          \ that Llama 3 will be similar in resource consumption to the previous iterations\
          \ of llama 1 b and 2? I would like to use the llama 3 70B with the same\
          \ comfort, but as for the proposed llama 3 120B, I\u2019m not sure that\
          \ its consumption will be similar to the 120B community models that we currently\
          \ have. I somehow run q3 k m at a speed of 0.5 token/second"
        updatedAt: '2023-12-30T07:57:42.669Z'
      numEdits: 0
      reactions: []
    id: 658fcd7643971eed45f0a74b
    type: comment
  author: AS1200
  content: "I have a very important question, at least for me. Should we expect that\
    \ Llama 3 will be similar in resource consumption to the previous iterations of\
    \ llama 1 b and 2? I would like to use the llama 3 70B with the same comfort,\
    \ but as for the proposed llama 3 120B, I\u2019m not sure that its consumption\
    \ will be similar to the 120B community models that we currently have. I somehow\
    \ run q3 k m at a speed of 0.5 token/second"
  created_at: 2023-12-30 07:57:42+00:00
  edited: false
  hidden: false
  id: 658fcd7643971eed45f0a74b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/311b7f466c5f282fe9f5e25e4431d813.svg
      fullname: John Smith
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nsfwthrowitaway69
      type: user
    createdAt: '2024-01-02T18:01:48.000Z'
    data:
      edited: false
      editors:
      - nsfwthrowitaway69
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9359101057052612
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/311b7f466c5f282fe9f5e25e4431d813.svg
          fullname: John Smith
          isHf: false
          isPro: false
          name: nsfwthrowitaway69
          type: user
        html: '<p>I don''t have any knowledge about what llama 3 will be capable of
          other than whatever rumors have been circulating online. I imagine that
          if there is a 120b version it will be able to run  at similar speeds to
          current 120b frakenmerges.</p>

          '
        raw: I don't have any knowledge about what llama 3 will be capable of other
          than whatever rumors have been circulating online. I imagine that if there
          is a 120b version it will be able to run  at similar speeds to current 120b
          frakenmerges.
        updatedAt: '2024-01-02T18:01:48.962Z'
      numEdits: 0
      reactions: []
    id: 65944f8ce7c71d6d9eae6612
    type: comment
  author: nsfwthrowitaway69
  content: I don't have any knowledge about what llama 3 will be capable of other
    than whatever rumors have been circulating online. I imagine that if there is
    a 120b version it will be able to run  at similar speeds to current 120b frakenmerges.
  created_at: 2024-01-02 18:01:48+00:00
  edited: false
  hidden: false
  id: 65944f8ce7c71d6d9eae6612
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: nsfwthrowitaway69/Venus-120b-v1.1
repo_type: model
status: open
target_branch: null
title: What models will be used for version 1.2?
