!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Sirisha
conflicting_files: null
created_at: 2023-01-09 17:52:41+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9f0ef93507539fb54d9f643727d6c1c7.svg
      fullname: Sita Sirisha Madugula
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sirisha
      type: user
    createdAt: '2023-01-09T17:52:41.000Z'
    data:
      edited: false
      editors:
      - Sirisha
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9f0ef93507539fb54d9f643727d6c1c7.svg
          fullname: Sita Sirisha Madugula
          isHf: false
          isPro: false
          name: Sirisha
          type: user
        html: '<p>Hello, </p>

          <p>Thanks for the amazing work like ProtGPT2. I am relatively new to transformers
          and I am trying to get this package work to generate new cas protein sequences.
          I followed the instructions on the huggingface page and got the model working
          until the step to generate "de novo proteins in a zero-shot fashion".  But
          after this step, I am unable to follow the remaining instructions. My aim
          is to generate new cas protein sequences using ProtGPT2 on my  own dataset
          containing 886 sequences.  </p>

          <p>As per the instructions I substituted the beginning of the FASTA with
          "&lt;|endoftext|&gt;", generated the train, test and validation sets. But
          I am unable to get the command working:<br>"python run_clm.py --model_name_or_path
          nferruz/ProtGPT2 --train_file training.txt --validation_file validation.txt
          --tokenizer_name nferruz/ProtGPT2<br> --do_train --do_eval --output_dir
          output --learning_rate 1e-06" </p>

          <p>What would be the tokenizer name here?<br>What do I put in place of do_train
          and do_eval? Sorry for these nieve questions.   </p>

          <p>Sirisha </p>

          '
        raw: "Hello, \r\n\r\nThanks for the amazing work like ProtGPT2. I am relatively\
          \ new to transformers and I am trying to get this package work to generate\
          \ new cas protein sequences. I followed the instructions on the huggingface\
          \ page and got the model working until the step to generate \"de novo proteins\
          \ in a zero-shot fashion\".  But after this step, I am unable to follow\
          \ the remaining instructions. My aim is to generate new cas protein sequences\
          \ using ProtGPT2 on my  own dataset containing 886 sequences.  \r\n\r\n\
          As per the instructions I substituted the beginning of the FASTA with \"\
          <|endoftext|>\", generated the train, test and validation sets. But I am\
          \ unable to get the command working:\r\n\"python run_clm.py --model_name_or_path\
          \ nferruz/ProtGPT2 --train_file training.txt --validation_file validation.txt\
          \ --tokenizer_name nferruz/ProtGPT2\r\n --do_train --do_eval --output_dir\
          \ output --learning_rate 1e-06\" \r\n\r\n\r\nWhat would be the tokenizer\
          \ name here? \r\nWhat do I put in place of do_train and do_eval? Sorry for\
          \ these nieve questions.   \r\n\r\nSirisha \r\n\r\n \r\n"
        updatedAt: '2023-01-09T17:52:41.750Z'
      numEdits: 0
      reactions: []
    id: 63bc5469d8d676a229a1c6b4
    type: comment
  author: Sirisha
  content: "Hello, \r\n\r\nThanks for the amazing work like ProtGPT2. I am relatively\
    \ new to transformers and I am trying to get this package work to generate new\
    \ cas protein sequences. I followed the instructions on the huggingface page and\
    \ got the model working until the step to generate \"de novo proteins in a zero-shot\
    \ fashion\".  But after this step, I am unable to follow the remaining instructions.\
    \ My aim is to generate new cas protein sequences using ProtGPT2 on my  own dataset\
    \ containing 886 sequences.  \r\n\r\nAs per the instructions I substituted the\
    \ beginning of the FASTA with \"<|endoftext|>\", generated the train, test and\
    \ validation sets. But I am unable to get the command working:\r\n\"python run_clm.py\
    \ --model_name_or_path nferruz/ProtGPT2 --train_file training.txt --validation_file\
    \ validation.txt --tokenizer_name nferruz/ProtGPT2\r\n --do_train --do_eval --output_dir\
    \ output --learning_rate 1e-06\" \r\n\r\n\r\nWhat would be the tokenizer name\
    \ here? \r\nWhat do I put in place of do_train and do_eval? Sorry for these nieve\
    \ questions.   \r\n\r\nSirisha \r\n\r\n \r\n"
  created_at: 2023-01-09 17:52:41+00:00
  edited: false
  hidden: false
  id: 63bc5469d8d676a229a1c6b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2023-01-10T21:35:15.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: '<p>Hi Sirisha,</p>

          <p>Thanks a lot for writing!<br>What is the error you are getting when you
          use that command? The flags --do_train and --do_eval do not require any
          parameters after them, they only specify to the script that there should
          be training and evaluation. If you could paste your error here, I''ll be
          able to help you - the command as you wrote it should work fine.</p>

          <p>best &amp; thanks<br>Noelia</p>

          '
        raw: 'Hi Sirisha,


          Thanks a lot for writing!

          What is the error you are getting when you use that command? The flags --do_train
          and --do_eval do not require any parameters after them, they only specify
          to the script that there should be training and evaluation. If you could
          paste your error here, I''ll be able to help you - the command as you wrote
          it should work fine.


          best & thanks

          Noelia'
        updatedAt: '2023-01-10T21:35:15.230Z'
      numEdits: 0
      reactions: []
    id: 63bdda13084098273354665e
    type: comment
  author: nferruz
  content: 'Hi Sirisha,


    Thanks a lot for writing!

    What is the error you are getting when you use that command? The flags --do_train
    and --do_eval do not require any parameters after them, they only specify to the
    script that there should be training and evaluation. If you could paste your error
    here, I''ll be able to help you - the command as you wrote it should work fine.


    best & thanks

    Noelia'
  created_at: 2023-01-10 21:35:15+00:00
  edited: false
  hidden: false
  id: 63bdda13084098273354665e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9f0ef93507539fb54d9f643727d6c1c7.svg
      fullname: Sita Sirisha Madugula
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sirisha
      type: user
    createdAt: '2023-01-10T22:42:46.000Z'
    data:
      edited: false
      editors:
      - Sirisha
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9f0ef93507539fb54d9f643727d6c1c7.svg
          fullname: Sita Sirisha Madugula
          isHf: false
          isPro: false
          name: Sirisha
          type: user
        html: '<p>Hi Noelia, </p>

          <p>Thanks for your reply. The following are the things i did:</p>

          <p>In my G-drive I created a directory  into which I cloned protgpt2 github
          as given in huggingface versions. My own dataset is also in the same directory.
          I also put  "run_clm.py" in the same directory. Then using Colab, I ran
          the following commands:</p>

          <ol>

          <li>pip install git+<a rel="nofollow" href="https://github.com/huggingface/transformers.git">https://github.com/huggingface/transformers.git</a></li>

          <li>from transformers import AutoTokenizer, AutoModelForSeq2SeqLM</li>

          <li>from transformers import pipeline<br> protgpt2 = pipeline(''text-generation'',
          model="nferruz/ProtGPT2")<br> sequences = protgpt2("&lt;|endoftext|&gt;",
          max_length=100, do_sample=True, top_k=950, repetition_penalty=1.2, num_return_sequences=10,
          eos_token_id=0)<br> for seq in sequences:<br> print(seq)<br>The 3rd command
          gave me the new sequences following "M". So this is good<br>Then  I substituted
          the beginning of the FASTA (of my dataset; a csv file with three columns
          and  FASTA being the second column) with "&lt;|endoftext|&gt;".<br>Then
          I ran the command:</li>

          <li>from transformers import AutoTokenizer, AutoModelForCausalLM<br> tokenizer
          = AutoTokenizer.from_pretrained("nferruz/ProtGPT2")<br> model = AutoModelForCausalLM.from_pretrained("nferruz/ProtGPT2")</li>

          </ol>

          <p>Then I loaded my dataset and and  generated the train, test and validation
          sets and ran the command:<br>5. python run_clm.py --model_name_or_path nferruz/ProtGPT2
          --train_file training.txt --validation_file validation.txt --tokenizer_name
          nferruz/ProtGPT2<br> --do_train --do_eval --output_dir output --learning_rate
          1e-06.<br>I got:<br>File "", line 1<br>    python run_clm.py --model_name_or_path
          nferruz/ProtGPT2 --train_file training.txt --validation_file validation.txt
          --tokenizer_name nferruz/ProtGPT2<br>           ^<br>SyntaxError: invalid
          syntax</p>

          <ol start="6">

          <li>Then I changed the command as following:<br>python /content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/run_clm.py
          --nferruz/ProtGPT2 --X_train --X_val-- /content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/tokenizer.json
          nferruz/ProtGPT2 --do_train --do_eval --/content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/output
          --learning_rate 1e-06</li>

          </ol>

          <p>But the error persists</p>

          '
        raw: "\nHi Noelia, \n\nThanks for your reply. The following are the things\
          \ i did:\n\nIn my G-drive I created a directory  into which I cloned protgpt2\
          \ github as given in huggingface versions. My own dataset is also in the\
          \ same directory. I also put  \"run_clm.py\" in the same directory. Then\
          \ using Colab, I ran the following commands:\n\n1. pip install git+https://github.com/huggingface/transformers.git\n\
          2. from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n3. from\
          \ transformers import pipeline\n    protgpt2 = pipeline('text-generation',\
          \ model=\"nferruz/ProtGPT2\")\n    sequences = protgpt2(\"<|endoftext|>\"\
          , max_length=100, do_sample=True, top_k=950, repetition_penalty=1.2, num_return_sequences=10,\
          \ eos_token_id=0)\n    for seq in sequences:\n    print(seq)\nThe 3rd command\
          \ gave me the new sequences following \"M\". So this is good \nThen  I substituted\
          \ the beginning of the FASTA (of my dataset; a csv file with three columns\
          \ and  FASTA being the second column) with \"<|endoftext|>\". \nThen I ran\
          \ the command:\n4. from transformers import AutoTokenizer, AutoModelForCausalLM\n\
          \    tokenizer = AutoTokenizer.from_pretrained(\"nferruz/ProtGPT2\")\n \
          \   model = AutoModelForCausalLM.from_pretrained(\"nferruz/ProtGPT2\")\n\
          \nThen I loaded my dataset and and  generated the train, test and validation\
          \ sets and ran the command:\n5. python run_clm.py --model_name_or_path nferruz/ProtGPT2\
          \ --train_file training.txt --validation_file validation.txt --tokenizer_name\
          \ nferruz/ProtGPT2\n --do_train --do_eval --output_dir output --learning_rate\
          \ 1e-06. \nI got:\nFile \"<ipython-input-16-bcc7459dcd27>\", line 1\n  \
          \  python run_clm.py --model_name_or_path nferruz/ProtGPT2 --train_file\
          \ training.txt --validation_file validation.txt --tokenizer_name nferruz/ProtGPT2\n\
          \           ^\nSyntaxError: invalid syntax\n \n6. Then I changed the command\
          \ as following:\npython /content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/run_clm.py\
          \ --nferruz/ProtGPT2 --X_train --X_val-- /content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/tokenizer.json\
          \ nferruz/ProtGPT2 --do_train --do_eval --/content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/output\
          \ --learning_rate 1e-06 \n\nBut the error persists\n\n\n\n\n\n"
        updatedAt: '2023-01-10T22:42:46.931Z'
      numEdits: 0
      reactions: []
      relatedEventId: 63bde9e60840982733556d53
    id: 63bde9e60840982733556d52
    type: comment
  author: Sirisha
  content: "\nHi Noelia, \n\nThanks for your reply. The following are the things i\
    \ did:\n\nIn my G-drive I created a directory  into which I cloned protgpt2 github\
    \ as given in huggingface versions. My own dataset is also in the same directory.\
    \ I also put  \"run_clm.py\" in the same directory. Then using Colab, I ran the\
    \ following commands:\n\n1. pip install git+https://github.com/huggingface/transformers.git\n\
    2. from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n3. from transformers\
    \ import pipeline\n    protgpt2 = pipeline('text-generation', model=\"nferruz/ProtGPT2\"\
    )\n    sequences = protgpt2(\"<|endoftext|>\", max_length=100, do_sample=True,\
    \ top_k=950, repetition_penalty=1.2, num_return_sequences=10, eos_token_id=0)\n\
    \    for seq in sequences:\n    print(seq)\nThe 3rd command gave me the new sequences\
    \ following \"M\". So this is good \nThen  I substituted the beginning of the\
    \ FASTA (of my dataset; a csv file with three columns and  FASTA being the second\
    \ column) with \"<|endoftext|>\". \nThen I ran the command:\n4. from transformers\
    \ import AutoTokenizer, AutoModelForCausalLM\n    tokenizer = AutoTokenizer.from_pretrained(\"\
    nferruz/ProtGPT2\")\n    model = AutoModelForCausalLM.from_pretrained(\"nferruz/ProtGPT2\"\
    )\n\nThen I loaded my dataset and and  generated the train, test and validation\
    \ sets and ran the command:\n5. python run_clm.py --model_name_or_path nferruz/ProtGPT2\
    \ --train_file training.txt --validation_file validation.txt --tokenizer_name\
    \ nferruz/ProtGPT2\n --do_train --do_eval --output_dir output --learning_rate\
    \ 1e-06. \nI got:\nFile \"<ipython-input-16-bcc7459dcd27>\", line 1\n    python\
    \ run_clm.py --model_name_or_path nferruz/ProtGPT2 --train_file training.txt --validation_file\
    \ validation.txt --tokenizer_name nferruz/ProtGPT2\n           ^\nSyntaxError:\
    \ invalid syntax\n \n6. Then I changed the command as following:\npython /content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/run_clm.py\
    \ --nferruz/ProtGPT2 --X_train --X_val-- /content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/tokenizer.json\
    \ nferruz/ProtGPT2 --do_train --do_eval --/content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/output\
    \ --learning_rate 1e-06 \n\nBut the error persists\n\n\n\n\n\n"
  created_at: 2023-01-10 22:42:46+00:00
  edited: false
  hidden: false
  id: 63bde9e60840982733556d52
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9f0ef93507539fb54d9f643727d6c1c7.svg
      fullname: Sita Sirisha Madugula
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sirisha
      type: user
    createdAt: '2023-01-10T22:42:46.000Z'
    data:
      status: closed
    id: 63bde9e60840982733556d53
    type: status-change
  author: Sirisha
  created_at: 2023-01-10 22:42:46+00:00
  id: 63bde9e60840982733556d53
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9f0ef93507539fb54d9f643727d6c1c7.svg
      fullname: Sita Sirisha Madugula
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Sirisha
      type: user
    createdAt: '2023-01-10T22:43:12.000Z'
    data:
      status: open
    id: 63bdea000a7cc50a4f2eb6ec
    type: status-change
  author: Sirisha
  created_at: 2023-01-10 22:43:12+00:00
  id: 63bdea000a7cc50a4f2eb6ec
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2023-01-14T10:15:32.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: '<p>Hi Sirisha,</p>

          <p>In the second function that you post, try giving tokenizer_name the path
          of a folder, not a file.  so '' /content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/''
          instead.</p>

          <p>Hope this helps.</p>

          '
        raw: "Hi Sirisha,\n\nIn the second function that you post, try giving tokenizer_name\
          \ the path of a folder, not a file.  so ' /content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/'\
          \ instead.\n \nHope this helps."
        updatedAt: '2023-01-14T10:15:32.126Z'
      numEdits: 0
      reactions: []
    id: 63c280c4e25fc176426ebcf1
    type: comment
  author: nferruz
  content: "Hi Sirisha,\n\nIn the second function that you post, try giving tokenizer_name\
    \ the path of a folder, not a file.  so ' /content/drive/MyDrive/Prot-GPT2_master/ProtGPT2/'\
    \ instead.\n \nHope this helps."
  created_at: 2023-01-14 10:15:32+00:00
  edited: false
  hidden: false
  id: 63c280c4e25fc176426ebcf1
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: nferruz/ProtGPT2
repo_type: model
status: open
target_branch: null
title: 'Unable to finetune ProtGPT2 model '
