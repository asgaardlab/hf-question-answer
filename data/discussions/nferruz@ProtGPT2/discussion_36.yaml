!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ChetnaA
conflicting_files: null
created_at: 2023-11-20 17:37:51+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2571f2f1804e725409a762aef7483898.svg
      fullname: Chetna Agarwal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ChetnaA
      type: user
    createdAt: '2023-11-20T17:37:51.000Z'
    data:
      edited: false
      editors:
      - ChetnaA
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9469120502471924
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2571f2f1804e725409a762aef7483898.svg
          fullname: Chetna Agarwal
          isHf: false
          isPro: false
          name: ChetnaA
          type: user
        html: '<p>I''m in the process of fine-tuning the protGPT-2 model using a set
          of training examples I''ve collected.  I have about 500k sequences and am
          thinking of starting with a small subset of these, say 2k sequences. I have
          access to two instances of NVIDIA A100 GPUs, each with 40 GB of memory.
          Will this be enough for training? Will I need any kind of memory saving
          tricks? Also, can someone give me an idea of how long it''ll take to run
          the fine tuning for different number of sequences (between 2k and 500k)?<br>Thanks!</p>

          '
        raw: "I'm in the process of fine-tuning the protGPT-2 model using a set of\
          \ training examples I've collected.  I have about 500k sequences and am\
          \ thinking of starting with a small subset of these, say 2k sequences. I\
          \ have access to two instances of NVIDIA A100 GPUs, each with 40 GB of memory.\
          \ Will this be enough for training? Will I need any kind of memory saving\
          \ tricks? Also, can someone give me an idea of how long it'll take to run\
          \ the fine tuning for different number of sequences (between 2k and 500k)?\r\
          \nThanks!"
        updatedAt: '2023-11-20T17:37:51.052Z'
      numEdits: 0
      reactions: []
    id: 655b996fbd749814aedcc50a
    type: comment
  author: ChetnaA
  content: "I'm in the process of fine-tuning the protGPT-2 model using a set of training\
    \ examples I've collected.  I have about 500k sequences and am thinking of starting\
    \ with a small subset of these, say 2k sequences. I have access to two instances\
    \ of NVIDIA A100 GPUs, each with 40 GB of memory. Will this be enough for training?\
    \ Will I need any kind of memory saving tricks? Also, can someone give me an idea\
    \ of how long it'll take to run the fine tuning for different number of sequences\
    \ (between 2k and 500k)?\r\nThanks!"
  created_at: 2023-11-20 17:37:51+00:00
  edited: false
  hidden: false
  id: 655b996fbd749814aedcc50a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2023-11-21T05:49:05.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9046297073364258
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: "<p>Hi,</p>\n<p>Your resources sound like more than plenty. With 2k\
          \ you wouldn\u2019t need more than one hour. With 5000k it will take longer,\
          \ but using 2 A100s I don\u2019t imagine it takes you longer than a day\
          \ to run several epochs (but I\u2019m doing very simple maths here). If\
          \ you want to save some vRAM you could use deep speed. In fact I recommend\
          \ it it\u2019s super easy to use!</p>\n"
        raw: "Hi,\n\nYour resources sound like more than plenty. With 2k you wouldn\u2019\
          t need more than one hour. With 5000k it will take longer, but using 2 A100s\
          \ I don\u2019t imagine it takes you longer than a day to run several epochs\
          \ (but I\u2019m doing very simple maths here). If you want to save some\
          \ vRAM you could use deep speed. In fact I recommend it it\u2019s super\
          \ easy to use!"
        updatedAt: '2023-11-21T05:49:05.004Z'
      numEdits: 0
      reactions: []
    id: 655c44d121a128df0acf1fcd
    type: comment
  author: nferruz
  content: "Hi,\n\nYour resources sound like more than plenty. With 2k you wouldn\u2019\
    t need more than one hour. With 5000k it will take longer, but using 2 A100s I\
    \ don\u2019t imagine it takes you longer than a day to run several epochs (but\
    \ I\u2019m doing very simple maths here). If you want to save some vRAM you could\
    \ use deep speed. In fact I recommend it it\u2019s super easy to use!"
  created_at: 2023-11-21 05:49:05+00:00
  edited: false
  hidden: false
  id: 655c44d121a128df0acf1fcd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2571f2f1804e725409a762aef7483898.svg
      fullname: Chetna Agarwal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ChetnaA
      type: user
    createdAt: '2023-11-21T18:44:24.000Z'
    data:
      edited: false
      editors:
      - ChetnaA
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9507948756217957
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2571f2f1804e725409a762aef7483898.svg
          fullname: Chetna Agarwal
          isHf: false
          isPro: false
          name: ChetnaA
          type: user
        html: '<p>Hi,<br>Thanks for the quick response. I''ll definitely look into
          deep speed library! One more question, will V100 GPUs also work for this
          fine tuning task?</p>

          '
        raw: 'Hi,

          Thanks for the quick response. I''ll definitely look into deep speed library!
          One more question, will V100 GPUs also work for this fine tuning task?'
        updatedAt: '2023-11-21T18:44:24.202Z'
      numEdits: 0
      reactions: []
    id: 655cfa888e56f09d55ec81da
    type: comment
  author: ChetnaA
  content: 'Hi,

    Thanks for the quick response. I''ll definitely look into deep speed library!
    One more question, will V100 GPUs also work for this fine tuning task?'
  created_at: 2023-11-21 18:44:24+00:00
  edited: false
  hidden: false
  id: 655cfa888e56f09d55ec81da
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2023-11-21T22:37:25.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.996412992477417
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: '<p>I haven''t tried them myself but they should, absolutely.</p>

          '
        raw: I haven't tried them myself but they should, absolutely.
        updatedAt: '2023-11-21T22:37:25.331Z'
      numEdits: 0
      reactions: []
    id: 655d312521be567f0cc6fbd8
    type: comment
  author: nferruz
  content: I haven't tried them myself but they should, absolutely.
  created_at: 2023-11-21 22:37:25+00:00
  edited: false
  hidden: false
  id: 655d312521be567f0cc6fbd8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2571f2f1804e725409a762aef7483898.svg
      fullname: Chetna Agarwal
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ChetnaA
      type: user
    createdAt: '2023-11-22T16:29:13.000Z'
    data:
      edited: false
      editors:
      - ChetnaA
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9859728813171387
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2571f2f1804e725409a762aef7483898.svg
          fullname: Chetna Agarwal
          isHf: false
          isPro: false
          name: ChetnaA
          type: user
        html: '<p>Great, thanks! I''ll try them out!</p>

          '
        raw: Great, thanks! I'll try them out!
        updatedAt: '2023-11-22T16:29:13.180Z'
      numEdits: 0
      reactions: []
    id: 655e2c5916ede91c782e1562
    type: comment
  author: ChetnaA
  content: Great, thanks! I'll try them out!
  created_at: 2023-11-22 16:29:13+00:00
  edited: false
  hidden: false
  id: 655e2c5916ede91c782e1562
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 36
repo_id: nferruz/ProtGPT2
repo_type: model
status: open
target_branch: null
title: Resources required for fine tuning Protgpt2
