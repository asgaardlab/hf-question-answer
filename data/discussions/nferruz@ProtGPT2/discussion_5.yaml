!!python/object:huggingface_hub.community.DiscussionWithDetails
author: hunarbatra
conflicting_files: null
created_at: 2022-08-16 20:43:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660273191881-noauth.jpeg?w=200&h=200&f=face
      fullname: Hunar Batra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hunarbatra
      type: user
    createdAt: '2022-08-16T21:43:06.000Z'
    data:
      edited: false
      editors:
      - hunarbatra
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660273191881-noauth.jpeg?w=200&h=200&f=face
          fullname: Hunar Batra
          isHf: false
          isPro: false
          name: hunarbatra
          type: user
        html: '<p>Hi,</p>

          <p>Is it possible to condition ProtGPT2 sequence generation with pre-computed
          embeddings from another model (eg: MSA Transformer) - so that we could generate
          a sequence of logits conditioned on the given embeddings (by another model)?
          If yes, then could you please guide with how to implement this? </p>

          <p>Thank you so much :)</p>

          '
        raw: "Hi,\r\n\r\nIs it possible to condition ProtGPT2 sequence generation\
          \ with pre-computed embeddings from another model (eg: MSA Transformer)\
          \ - so that we could generate a sequence of logits conditioned on the given\
          \ embeddings (by another model)? If yes, then could you please guide with\
          \ how to implement this? \r\n\r\nThank you so much :)"
        updatedAt: '2022-08-16T21:43:06.663Z'
      numEdits: 0
      reactions: []
    id: 62fc0f6a21c444a56f7d0f0e
    type: comment
  author: hunarbatra
  content: "Hi,\r\n\r\nIs it possible to condition ProtGPT2 sequence generation with\
    \ pre-computed embeddings from another model (eg: MSA Transformer) - so that we\
    \ could generate a sequence of logits conditioned on the given embeddings (by\
    \ another model)? If yes, then could you please guide with how to implement this?\
    \ \r\n\r\nThank you so much :)"
  created_at: 2022-08-16 20:43:06+00:00
  edited: false
  hidden: false
  id: 62fc0f6a21c444a56f7d0f0e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2022-08-16T21:48:42.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: '<p>Hi!<br>I know someone who tried to do something similar to this.
          Let me see if I can get to talk to this person and see if, in the end, they
          managed to do it :)</p>

          '
        raw: 'Hi!

          I know someone who tried to do something similar to this. Let me see if
          I can get to talk to this person and see if, in the end, they managed to
          do it :)'
        updatedAt: '2022-08-16T21:48:42.154Z'
      numEdits: 0
      reactions: []
    id: 62fc10baa80632fbd47d1abf
    type: comment
  author: nferruz
  content: 'Hi!

    I know someone who tried to do something similar to this. Let me see if I can
    get to talk to this person and see if, in the end, they managed to do it :)'
  created_at: 2022-08-16 20:48:42+00:00
  edited: false
  hidden: false
  id: 62fc10baa80632fbd47d1abf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660273191881-noauth.jpeg?w=200&h=200&f=face
      fullname: Hunar Batra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hunarbatra
      type: user
    createdAt: '2022-08-16T21:49:47.000Z'
    data:
      edited: false
      editors:
      - hunarbatra
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660273191881-noauth.jpeg?w=200&h=200&f=face
          fullname: Hunar Batra
          isHf: false
          isPro: false
          name: hunarbatra
          type: user
        html: '<p>Sure, that''ll be great if you could check about that and get back
          to me at the earliest :)<br>Thank you so much! :)</p>

          '
        raw: 'Sure, that''ll be great if you could check about that and get back to
          me at the earliest :)

          Thank you so much! :)'
        updatedAt: '2022-08-16T21:49:47.724Z'
      numEdits: 0
      reactions: []
    id: 62fc10fbe44837de5448c718
    type: comment
  author: hunarbatra
  content: 'Sure, that''ll be great if you could check about that and get back to
    me at the earliest :)

    Thank you so much! :)'
  created_at: 2022-08-16 20:49:47+00:00
  edited: false
  hidden: false
  id: 62fc10fbe44837de5448c718
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2022-08-16T22:00:48.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: '<p>Not sure when they''ll reply, but I found this issue on GitHub that
          might be of your interest: <a rel="nofollow" href="https://github.com/huggingface/transformers/issues?q=is%3Aissue+protgpt2+is%3Aclosed">https://github.com/huggingface/transformers/issues?q=is%3Aissue+protgpt2+is%3Aclosed</a><br>I
          think you can pass input_embeds to the model as well. And from there, get
          the logits. I don''t know if it would be possible to generate new sequences,
          but I hope this for now maybe helps a bit.</p>

          '
        raw: 'Not sure when they''ll reply, but I found this issue on GitHub that
          might be of your interest: https://github.com/huggingface/transformers/issues?q=is%3Aissue+protgpt2+is%3Aclosed

          I think you can pass input_embeds to the model as well. And from there,
          get the logits. I don''t know if it would be possible to generate new sequences,
          but I hope this for now maybe helps a bit.'
        updatedAt: '2022-08-16T22:00:48.764Z'
      numEdits: 0
      reactions: []
    id: 62fc1390ce54be18b09afa54
    type: comment
  author: nferruz
  content: 'Not sure when they''ll reply, but I found this issue on GitHub that might
    be of your interest: https://github.com/huggingface/transformers/issues?q=is%3Aissue+protgpt2+is%3Aclosed

    I think you can pass input_embeds to the model as well. And from there, get the
    logits. I don''t know if it would be possible to generate new sequences, but I
    hope this for now maybe helps a bit.'
  created_at: 2022-08-16 21:00:48+00:00
  edited: false
  hidden: false
  id: 62fc1390ce54be18b09afa54
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660273191881-noauth.jpeg?w=200&h=200&f=face
      fullname: Hunar Batra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hunarbatra
      type: user
    createdAt: '2022-08-16T23:10:58.000Z'
    data:
      edited: true
      editors:
      - hunarbatra
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660273191881-noauth.jpeg?w=200&h=200&f=face
          fullname: Hunar Batra
          isHf: false
          isPro: false
          name: hunarbatra
          type: user
        html: '<p>Thank you so much for sharing this :).<br>Can the returned logits
          be passed to ProtGPT2 for generating sequences somehow?</p>

          <p>(update from what I found out: inputs_embeds cannot be passed to decoder
          only (autoregressive) models like GPT2)</p>

          '
        raw: 'Thank you so much for sharing this :).

          Can the returned logits be passed to ProtGPT2 for generating sequences somehow?


          (update from what I found out: inputs_embeds cannot be passed to decoder
          only (autoregressive) models like GPT2)'
        updatedAt: '2022-08-17T01:25:51.107Z'
      numEdits: 1
      reactions: []
    id: 62fc2402ce54be18b09b7319
    type: comment
  author: hunarbatra
  content: 'Thank you so much for sharing this :).

    Can the returned logits be passed to ProtGPT2 for generating sequences somehow?


    (update from what I found out: inputs_embeds cannot be passed to decoder only
    (autoregressive) models like GPT2)'
  created_at: 2022-08-16 22:10:58+00:00
  edited: true
  hidden: false
  id: 62fc2402ce54be18b09b7319
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2022-08-17T07:39:28.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: "<p>Good question, I've been reading for a while and all points out\
          \ that using LogitsProcessors should be what you need.<br>From what I've\
          \ read, a LogitsProcessor arg can be passed to the sample(), beam_search(),\
          \ etc. functions, but not directly to generate(). Thus I'd recommend using\
          \ sample(): <a href=\"https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.sample.example\"\
          >https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.sample.example</a>.</p>\n\
          <p>I've had a quick look, but I haven't managed to pass the logits with\
          \ any of the logits processors they specify in the documentation. Something\
          \ like this will error:</p>\n<pre><code>&gt;&gt;&gt; logits_processor =\
          \ LogitsProcessorList([LogitsProcessor()])\n&gt;&gt;&gt; model.sample(input_ids,pad_token_id=0,logits_processor=out['logits'])\n\
          Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in\
          \ &lt;module&gt;\n  File \"/path/hface/lib/python3.6/site-packages/transformers/generation_utils.py\"\
          , line 1906, in sample\n    next_token_scores = logits_processor(input_ids,\
          \ next_token_logits)\nTypeError: 'Tensor' object is not callable\n</code></pre>\n\
          <p>I do not have the time right now, but I hope I can have a look again\
          \ later tonight. Maybe in the meanwhile, this can point you in the right\
          \ direction, i hope! Let me know if you find a better way :)</p>\n<p>Best,<br>Noelia</p>\n"
        raw: "Good question, I've been reading for a while and all points out that\
          \ using LogitsProcessors should be what you need.\nFrom what I've read,\
          \ a LogitsProcessor arg can be passed to the sample(), beam_search(), etc.\
          \ functions, but not directly to generate(). Thus I'd recommend using sample():\
          \ https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.sample.example.\n\
          \nI've had a quick look, but I haven't managed to pass the logits with any\
          \ of the logits processors they specify in the documentation. Something\
          \ like this will error:\n\n```\n>>> logits_processor = LogitsProcessorList([LogitsProcessor()])\n\
          >>> model.sample(input_ids,pad_token_id=0,logits_processor=out['logits'])\n\
          Traceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n\
          \  File \"/path/hface/lib/python3.6/site-packages/transformers/generation_utils.py\"\
          , line 1906, in sample\n    next_token_scores = logits_processor(input_ids,\
          \ next_token_logits)\nTypeError: 'Tensor' object is not callable\n```\n\
          I do not have the time right now, but I hope I can have a look again later\
          \ tonight. Maybe in the meanwhile, this can point you in the right direction,\
          \ i hope! Let me know if you find a better way :)\n\nBest,\nNoelia"
        updatedAt: '2022-08-17T07:39:28.147Z'
      numEdits: 0
      reactions: []
    id: 62fc9b30ee999004b5a916ac
    type: comment
  author: nferruz
  content: "Good question, I've been reading for a while and all points out that using\
    \ LogitsProcessors should be what you need.\nFrom what I've read, a LogitsProcessor\
    \ arg can be passed to the sample(), beam_search(), etc. functions, but not directly\
    \ to generate(). Thus I'd recommend using sample(): https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.sample.example.\n\
    \nI've had a quick look, but I haven't managed to pass the logits with any of\
    \ the logits processors they specify in the documentation. Something like this\
    \ will error:\n\n```\n>>> logits_processor = LogitsProcessorList([LogitsProcessor()])\n\
    >>> model.sample(input_ids,pad_token_id=0,logits_processor=out['logits'])\nTraceback\
    \ (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"\
    /path/hface/lib/python3.6/site-packages/transformers/generation_utils.py\", line\
    \ 1906, in sample\n    next_token_scores = logits_processor(input_ids, next_token_logits)\n\
    TypeError: 'Tensor' object is not callable\n```\nI do not have the time right\
    \ now, but I hope I can have a look again later tonight. Maybe in the meanwhile,\
    \ this can point you in the right direction, i hope! Let me know if you find a\
    \ better way :)\n\nBest,\nNoelia"
  created_at: 2022-08-17 06:39:28+00:00
  edited: false
  hidden: false
  id: 62fc9b30ee999004b5a916ac
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660273191881-noauth.jpeg?w=200&h=200&f=face
      fullname: Hunar Batra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: hunarbatra
      type: user
    createdAt: '2022-08-18T17:35:00.000Z'
    data:
      edited: false
      editors:
      - hunarbatra
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1660273191881-noauth.jpeg?w=200&h=200&f=face
          fullname: Hunar Batra
          isHf: false
          isPro: false
          name: hunarbatra
          type: user
        html: '<p>Thank you so much Noelia for sharing this! I try it out later today
          and update you if I''m able to make it work :)</p>

          '
        raw: Thank you so much Noelia for sharing this! I try it out later today and
          update you if I'm able to make it work :)
        updatedAt: '2022-08-18T17:35:00.568Z'
      numEdits: 0
      reactions: []
    id: 62fe784468ad54f88a4dbf7b
    type: comment
  author: hunarbatra
  content: Thank you so much Noelia for sharing this! I try it out later today and
    update you if I'm able to make it work :)
  created_at: 2022-08-18 16:35:00+00:00
  edited: false
  hidden: false
  id: 62fe784468ad54f88a4dbf7b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: nferruz/ProtGPT2
repo_type: model
status: open
target_branch: null
title: Generating Sequences Pre-conditioned on Embeddings from MSA Transformer
