!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pipparichter
conflicting_files: null
created_at: 2023-08-01 21:04:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8fdf615015d6cc3f0f2be6af3ffa8dc9.svg
      fullname: Philippa Richter
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pipparichter
      type: user
    createdAt: '2023-08-01T22:04:14.000Z'
    data:
      edited: false
      editors:
      - pipparichter
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9572961330413818
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8fdf615015d6cc3f0f2be6af3ffa8dc9.svg
          fullname: Philippa Richter
          isHf: false
          isPro: false
          name: pipparichter
          type: user
        html: '<p>Hello! I am trying to use the model to predict whether or not a
          protein sequence is complete (as opposed to erroneously truncated). It seems
          as though ProtGPT2 model tends to extend already-complete protein sequences
          (i.e. it would rarely predict 0 as the next token). I wanted to double-check
          these results using the API on the browser, which led to the following observation:
          I noticed that it never predicts and &lt;|end of text|&gt; token -- it simply
          spits out a warning saying "no text generated." Does this mean that the
          model has concluded the input sequence is complete?</p>

          <p>Thank you!</p>

          '
        raw: "Hello! I am trying to use the model to predict whether or not a protein\
          \ sequence is complete (as opposed to erroneously truncated). It seems as\
          \ though ProtGPT2 model tends to extend already-complete protein sequences\
          \ (i.e. it would rarely predict 0 as the next token). I wanted to double-check\
          \ these results using the API on the browser, which led to the following\
          \ observation: I noticed that it never predicts and <|end of text|> token\
          \ -- it simply spits out a warning saying \"no text generated.\" Does this\
          \ mean that the model has concluded the input sequence is complete?\r\n\r\
          \nThank you!"
        updatedAt: '2023-08-01T22:04:14.306Z'
      numEdits: 0
      reactions: []
    id: 64c9815e29d2f65419ee3c90
    type: comment
  author: pipparichter
  content: "Hello! I am trying to use the model to predict whether or not a protein\
    \ sequence is complete (as opposed to erroneously truncated). It seems as though\
    \ ProtGPT2 model tends to extend already-complete protein sequences (i.e. it would\
    \ rarely predict 0 as the next token). I wanted to double-check these results\
    \ using the API on the browser, which led to the following observation: I noticed\
    \ that it never predicts and <|end of text|> token -- it simply spits out a warning\
    \ saying \"no text generated.\" Does this mean that the model has concluded the\
    \ input sequence is complete?\r\n\r\nThank you!"
  created_at: 2023-08-01 21:04:14+00:00
  edited: false
  hidden: false
  id: 64c9815e29d2f65419ee3c90
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2023-08-04T07:48:42.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9400262236595154
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: '<p>Hi!<br>The model will terminate sequences producing an &lt;|endoftext|&gt;
          token, but it won''t appear during generation because special tokens are
          not displayed unless you choose to. Bear in mind that this model tends to
          generate sequences a bit longer than natural on average (it likes to speak
          a lot), so it may continue sequences that are already complete. Other models
          we''ve trained later do not show this behavior.</p>

          <p>On a different note, what do you mean by the API in the browser? Do you
          mean here in HF? If so, I would not rely on the generation because it''s
          automatically produced by HF without using the most optimal generation parameters.
          Also, it does not filter by perplexity. In any case, the HF API would not
          show the special character &lt;|endoftext|&gt;, so I guess the behaviour
          would be ''no text generated'' as you said (but with no experience generating
          from this browser, I''d do it locally instead :)).</p>

          <p>Hope this helps,<br>Noelia</p>

          '
        raw: 'Hi!

          The model will terminate sequences producing an <|endoftext|> token, but
          it won''t appear during generation because special tokens are not displayed
          unless you choose to. Bear in mind that this model tends to generate sequences
          a bit longer than natural on average (it likes to speak a lot), so it may
          continue sequences that are already complete. Other models we''ve trained
          later do not show this behavior.


          On a different note, what do you mean by the API in the browser? Do you
          mean here in HF? If so, I would not rely on the generation because it''s
          automatically produced by HF without using the most optimal generation parameters.
          Also, it does not filter by perplexity. In any case, the HF API would not
          show the special character <|endoftext|>, so I guess the behaviour would
          be ''no text generated'' as you said (but with no experience generating
          from this browser, I''d do it locally instead :)).


          Hope this helps,

          Noelia'
        updatedAt: '2023-08-04T07:48:42.048Z'
      numEdits: 0
      reactions: []
    id: 64ccad5adc4e83885709c1b6
    type: comment
  author: nferruz
  content: 'Hi!

    The model will terminate sequences producing an <|endoftext|> token, but it won''t
    appear during generation because special tokens are not displayed unless you choose
    to. Bear in mind that this model tends to generate sequences a bit longer than
    natural on average (it likes to speak a lot), so it may continue sequences that
    are already complete. Other models we''ve trained later do not show this behavior.


    On a different note, what do you mean by the API in the browser? Do you mean here
    in HF? If so, I would not rely on the generation because it''s automatically produced
    by HF without using the most optimal generation parameters. Also, it does not
    filter by perplexity. In any case, the HF API would not show the special character
    <|endoftext|>, so I guess the behaviour would be ''no text generated'' as you
    said (but with no experience generating from this browser, I''d do it locally
    instead :)).


    Hope this helps,

    Noelia'
  created_at: 2023-08-04 06:48:42+00:00
  edited: false
  hidden: false
  id: 64ccad5adc4e83885709c1b6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 31
repo_id: nferruz/ProtGPT2
repo_type: model
status: open
target_branch: null
title: Predicting end of sequence
