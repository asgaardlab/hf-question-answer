!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Jonathanlin
conflicting_files: null
created_at: 2023-06-19 13:26:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/018c682141184f64caf514384213dff8.svg
      fullname: Jonathanlin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jonathanlin
      type: user
    createdAt: '2023-06-19T14:26:48.000Z'
    data:
      edited: false
      editors:
      - Jonathanlin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9616250395774841
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/018c682141184f64caf514384213dff8.svg
          fullname: Jonathanlin
          isHf: false
          isPro: false
          name: Jonathanlin
          type: user
        html: '<p>Hello,<br>Thank u so much for this wonderful work, it works perfectly!!!!
          And I was thinking if I could work on GPU will be much more efficient.<br>But
          there are some problems with training and generating on a GPU environment
          that I can''t figure out.<br>Sorry, I do not know well about working it
          on GPU, never tried that before. :(<br>Want to ask if you can help me with
          this problem. Thank u so much!!!  :)<br>(GPU---RTX3050-8G)</p>

          '
        raw: "Hello,\r\nThank u so much for this wonderful work, it works perfectly!!!!\
          \ And I was thinking if I could work on GPU will be much more efficient.\r\
          \nBut there are some problems with training and generating on a GPU environment\
          \ that I can't figure out. \r\nSorry, I do not know well about working it\
          \ on GPU, never tried that before. :(\r\nWant to ask if you can help me\
          \ with this problem. Thank u so much!!!  :)\r\n(GPU---RTX3050-8G)"
        updatedAt: '2023-06-19T14:26:48.073Z'
      numEdits: 0
      reactions: []
    id: 649065a8f21c9d7609555e93
    type: comment
  author: Jonathanlin
  content: "Hello,\r\nThank u so much for this wonderful work, it works perfectly!!!!\
    \ And I was thinking if I could work on GPU will be much more efficient.\r\nBut\
    \ there are some problems with training and generating on a GPU environment that\
    \ I can't figure out. \r\nSorry, I do not know well about working it on GPU, never\
    \ tried that before. :(\r\nWant to ask if you can help me with this problem. Thank\
    \ u so much!!!  :)\r\n(GPU---RTX3050-8G)"
  created_at: 2023-06-19 13:26:48+00:00
  edited: false
  hidden: false
  id: 649065a8f21c9d7609555e93
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
      fullname: Noelia Ferruz
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: nferruz
      type: user
    createdAt: '2023-06-20T13:07:03.000Z'
    data:
      edited: false
      editors:
      - nferruz
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8472434282302856
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d53ce612a2ca69b758fd3fe0e962d3cc.svg
          fullname: Noelia Ferruz
          isHf: false
          isPro: false
          name: nferruz
          type: user
        html: '<p>Hi Jonathanlin,</p>

          <p>Not sure how can I help you, if you follow the installation guidelines
          from huggingface, the transformer library works by default on GPUs. Then,
          the code in the documentation uses also the GPUs by default. </p>

          '
        raw: 'Hi Jonathanlin,


          Not sure how can I help you, if you follow the installation guidelines from
          huggingface, the transformer library works by default on GPUs. Then, the
          code in the documentation uses also the GPUs by default. '
        updatedAt: '2023-06-20T13:07:03.177Z'
      numEdits: 0
      reactions: []
    id: 6491a4772c826e334eb3ce43
    type: comment
  author: nferruz
  content: 'Hi Jonathanlin,


    Not sure how can I help you, if you follow the installation guidelines from huggingface,
    the transformer library works by default on GPUs. Then, the code in the documentation
    uses also the GPUs by default. '
  created_at: 2023-06-20 12:07:03+00:00
  edited: false
  hidden: false
  id: 6491a4772c826e334eb3ce43
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/018c682141184f64caf514384213dff8.svg
      fullname: Jonathanlin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jonathanlin
      type: user
    createdAt: '2023-06-20T17:34:00.000Z'
    data:
      edited: false
      editors:
      - Jonathanlin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9552980065345764
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/018c682141184f64caf514384213dff8.svg
          fullname: Jonathanlin
          isHf: false
          isPro: false
          name: Jonathanlin
          type: user
        html: '<p>But I am distressed about which part of the code in the documentation
          alters to the GPUs by default. :(<br>I am trying to add .to(''cuda'') on
          it, but I can''t found here should I check? Want to ask if you have any
          tips or suggestions.</p>

          '
        raw: 'But I am distressed about which part of the code in the documentation
          alters to the GPUs by default. :(

          I am trying to add .to(''cuda'') on it, but I can''t found here should I
          check? Want to ask if you have any tips or suggestions.'
        updatedAt: '2023-06-20T17:34:00.790Z'
      numEdits: 0
      reactions: []
    id: 6491e3082bd45bd755ab7b1e
    type: comment
  author: Jonathanlin
  content: 'But I am distressed about which part of the code in the documentation
    alters to the GPUs by default. :(

    I am trying to add .to(''cuda'') on it, but I can''t found here should I check?
    Want to ask if you have any tips or suggestions.'
  created_at: 2023-06-20 16:34:00+00:00
  edited: false
  hidden: false
  id: 6491e3082bd45bd755ab7b1e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 29
repo_id: nferruz/ProtGPT2
repo_type: model
status: open
target_branch: null
title: 'How to work training and generating on GPU environment '
