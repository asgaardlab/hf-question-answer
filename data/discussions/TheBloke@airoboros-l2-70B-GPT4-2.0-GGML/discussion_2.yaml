!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nacs
conflicting_files: null
created_at: 2023-08-12 19:56:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8ca3771abd51458d8d3055d2b4668cf.svg
      fullname: nacs
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nacs
      type: user
    createdAt: '2023-08-12T20:56:18.000Z'
    data:
      edited: false
      editors:
      - nacs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7970507144927979
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8ca3771abd51458d8d3055d2b4668cf.svg
          fullname: nacs
          isHf: false
          isPro: false
          name: nacs
          type: user
        html: '<p>I''ve tried the latest llama.cpp (as of August 11th) as well as
          the commit mentioned in the <code>README</code> ( commit <code>e76d630</code>)
          but am getting an error when trying to load this model.</p>

          <p>I''ve tried the <code>q2_k.bin</code> as well as <code>q3_K_S.bin</code>
          and both give the following error:</p>

          <pre><code>llama_model_load_internal: using CUDA for GPU acceleration

          ggml_cuda_set_main_device: using device 0 (NVIDIA GeForce RTX 3060) as main
          device

          error loading model: llama.cpp: tensor ''layers.0.attention.wk.weight''
          has wrong shape; expected  8192 x  8192, got  8192 x  1024

          llama_load_model_from_file: failed to load model

          llama_init_from_gpt_params: error: failed to load model ''./models/airoboros-l2-70b-gpt4-2.0.ggmlv3.q2_K.bin''

          main: error: unable to load model

          </code></pre>

          <p>Am I doing something wrong?</p>

          '
        raw: "I've tried the latest llama.cpp (as of August 11th) as well as the commit\
          \ mentioned in the `README` ( commit `e76d630`) but am getting an error\
          \ when trying to load this model.\r\n\r\nI've tried the `q2_k.bin` as well\
          \ as `q3_K_S.bin` and both give the following error:\r\n\r\n```\r\nllama_model_load_internal:\
          \ using CUDA for GPU acceleration\r\nggml_cuda_set_main_device: using device\
          \ 0 (NVIDIA GeForce RTX 3060) as main device\r\nerror loading model: llama.cpp:\
          \ tensor 'layers.0.attention.wk.weight' has wrong shape; expected  8192\
          \ x  8192, got  8192 x  1024\r\nllama_load_model_from_file: failed to load\
          \ model\r\nllama_init_from_gpt_params: error: failed to load model './models/airoboros-l2-70b-gpt4-2.0.ggmlv3.q2_K.bin'\r\
          \nmain: error: unable to load model\r\n```\r\n\r\nAm I doing something wrong?"
        updatedAt: '2023-08-12T20:56:18.330Z'
      numEdits: 0
      reactions: []
    id: 64d7f1f28711e883ca84a3c1
    type: comment
  author: nacs
  content: "I've tried the latest llama.cpp (as of August 11th) as well as the commit\
    \ mentioned in the `README` ( commit `e76d630`) but am getting an error when trying\
    \ to load this model.\r\n\r\nI've tried the `q2_k.bin` as well as `q3_K_S.bin`\
    \ and both give the following error:\r\n\r\n```\r\nllama_model_load_internal:\
    \ using CUDA for GPU acceleration\r\nggml_cuda_set_main_device: using device 0\
    \ (NVIDIA GeForce RTX 3060) as main device\r\nerror loading model: llama.cpp:\
    \ tensor 'layers.0.attention.wk.weight' has wrong shape; expected  8192 x  8192,\
    \ got  8192 x  1024\r\nllama_load_model_from_file: failed to load model\r\nllama_init_from_gpt_params:\
    \ error: failed to load model './models/airoboros-l2-70b-gpt4-2.0.ggmlv3.q2_K.bin'\r\
    \nmain: error: unable to load model\r\n```\r\n\r\nAm I doing something wrong?"
  created_at: 2023-08-12 19:56:18+00:00
  edited: false
  hidden: false
  id: 64d7f1f28711e883ca84a3c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b8ca3771abd51458d8d3055d2b4668cf.svg
      fullname: nacs
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nacs
      type: user
    createdAt: '2023-08-12T20:58:29.000Z'
    data:
      edited: false
      editors:
      - nacs
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9468618035316467
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b8ca3771abd51458d8d3055d2b4668cf.svg
          fullname: nacs
          isHf: false
          isPro: false
          name: nacs
          type: user
        html: '<p>Sorry, this was my fault. I missed the part of the README that says
          to use "<code> -gqa 8</code>" when using this model. It works now thanks.</p>

          '
        raw: Sorry, this was my fault. I missed the part of the README that says to
          use "` -gqa 8`" when using this model. It works now thanks.
        updatedAt: '2023-08-12T20:58:29.924Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64d7f275c8d03cca8fc69a11
    id: 64d7f275c8d03cca8fc69a0f
    type: comment
  author: nacs
  content: Sorry, this was my fault. I missed the part of the README that says to
    use "` -gqa 8`" when using this model. It works now thanks.
  created_at: 2023-08-12 19:58:29+00:00
  edited: false
  hidden: false
  id: 64d7f275c8d03cca8fc69a0f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/b8ca3771abd51458d8d3055d2b4668cf.svg
      fullname: nacs
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nacs
      type: user
    createdAt: '2023-08-12T20:58:29.000Z'
    data:
      status: closed
    id: 64d7f275c8d03cca8fc69a11
    type: status-change
  author: nacs
  created_at: 2023-08-12 19:58:29+00:00
  id: 64d7f275c8d03cca8fc69a11
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/airoboros-l2-70B-GPT4-2.0-GGML
repo_type: model
status: closed
target_branch: null
title: Can't load model?
