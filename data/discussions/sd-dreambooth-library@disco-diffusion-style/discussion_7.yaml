!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tiktok-legacy
conflicting_files: null
created_at: 2022-12-11 22:25:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/41a62060fc35df3dd1c0ef93c5fe8cdc.svg
      fullname: Yunfeng Xi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tiktok-legacy
      type: user
    createdAt: '2022-12-11T22:25:02.000Z'
    data:
      edited: false
      editors:
      - tiktok-legacy
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/41a62060fc35df3dd1c0ef93c5fe8cdc.svg
          fullname: Yunfeng Xi
          isHf: false
          isPro: false
          name: tiktok-legacy
          type: user
        html: '<p>Hi folks,<br>Got this error when I was running the training colab.
          Do you have any clue? Below is more error logs. Thanks!</p>

          <p>RuntimeError                              Traceback (most recent call
          last)<br> in <br>      1 #@title Run training<br>      2 import accelerate<br>----&gt;
          3 accelerate.notebook_launcher(training_function, args=(text_encoder, vae,
          unet))<br>      4 for param in itertools.chain(unet.parameters(), text_encoder.parameters()):<br>      5   if
          param.grad is not None:</p>

          <p>6 frames<br>/usr/local/lib/python3.8/dist-packages/accelerate/launchers.py
          in notebook_launcher(function, args, num_processes, use_fp16, mixed_precision,
          use_port)<br>     80         else:<br>     81             print("Launching
          training on one CPU.")<br>---&gt; 82         function(*args)<br>     83     else:<br>     84         if
          num_processes is None:</p>

          <p> in training_function(text_encoder, vae, unet)<br>    156<br>    157                 #
          Predict the noise residual<br>--&gt; 158                 noise_pred = unet(noisy_latents,
          timesteps, encoder_hidden_states).sample<br>    159<br>    160                 #
          Get the target for loss depending on the prediction type</p>

          <p>/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py in
          _call_impl(self, *input, **kwargs)<br>   1188         if not (self._backward_hooks
          or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks<br>   1189                 or
          _global_forward_hooks or _global_forward_pre_hooks):<br>-&gt; 1190             return
          forward_call(*input, **kwargs)<br>   1191         # Do not call functions
          when jit is used<br>   1192         full_backward_hooks, non_full_backward_hooks
          = [], []</p>

          <p>/usr/local/lib/python3.8/dist-packages/diffusers/models/unet_2d_condition.py
          in forward(self, sample, timestep, encoder_hidden_states, class_labels,
          return_dict)<br>    373<br>    374         # 2. pre-process<br>--&gt; 375         sample
          = self.conv_in(sample)<br>    376<br>    377         # 3. down</p>

          <p>/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py in
          _call_impl(self, *input, **kwargs)<br>   1188         if not (self._backward_hooks
          or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks<br>   1189                 or
          _global_forward_hooks or _global_forward_pre_hooks):<br>-&gt; 1190             return
          forward_call(*input, **kwargs)<br>   1191         # Do not call functions
          when jit is used<br>   1192         full_backward_hooks, non_full_backward_hooks
          = [], []</p>

          <p>/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py in forward(self,
          input)<br>    461<br>    462     def forward(self, input: Tensor) -&gt;
          Tensor:<br>--&gt; 463         return self._conv_forward(input, self.weight,
          self.bias)<br>    464<br>    465 class Conv3d(_ConvNd):</p>

          <p>/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py in _conv_forward(self,
          input, weight, bias)<br>    457                             weight, bias,
          self.stride,<br>    458                             _pair(0), self.dilation,
          self.groups)<br>--&gt; 459         return F.conv2d(input, weight, bias,
          self.stride,<br>    460                         self.padding, self.dilation,
          self.groups)<br>    461 </p>

          '
        raw: "Hi folks,\r\nGot this error when I was running the training colab. Do\
          \ you have any clue? Below is more error logs. Thanks!\r\n\r\nRuntimeError\
          \                              Traceback (most recent call last)\r\n<ipython-input-14-fff6785cb183>\
          \ in <module>\r\n      1 #@title Run training\r\n      2 import accelerate\r\
          \n----> 3 accelerate.notebook_launcher(training_function, args=(text_encoder,\
          \ vae, unet))\r\n      4 for param in itertools.chain(unet.parameters(),\
          \ text_encoder.parameters()):\r\n      5   if param.grad is not None:\r\n\
          \r\n6 frames\r\n/usr/local/lib/python3.8/dist-packages/accelerate/launchers.py\
          \ in notebook_launcher(function, args, num_processes, use_fp16, mixed_precision,\
          \ use_port)\r\n     80         else:\r\n     81             print(\"Launching\
          \ training on one CPU.\")\r\n---> 82         function(*args)\r\n     83\
          \     else:\r\n     84         if num_processes is None:\r\n\r\n<ipython-input-13-1e1a65c23a9e>\
          \ in training_function(text_encoder, vae, unet)\r\n    156 \r\n    157 \
          \                # Predict the noise residual\r\n--> 158               \
          \  noise_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\r\
          \n    159 \r\n    160                 # Get the target for loss depending\
          \ on the prediction type\r\n\r\n/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\
          \ in _call_impl(self, *input, **kwargs)\r\n   1188         if not (self._backward_hooks\
          \ or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\
          \n   1189                 or _global_forward_hooks or _global_forward_pre_hooks):\r\
          \n-> 1190             return forward_call(*input, **kwargs)\r\n   1191 \
          \        # Do not call functions when jit is used\r\n   1192         full_backward_hooks,\
          \ non_full_backward_hooks = [], []\r\n\r\n/usr/local/lib/python3.8/dist-packages/diffusers/models/unet_2d_condition.py\
          \ in forward(self, sample, timestep, encoder_hidden_states, class_labels,\
          \ return_dict)\r\n    373 \r\n    374         # 2. pre-process\r\n--> 375\
          \         sample = self.conv_in(sample)\r\n    376 \r\n    377         #\
          \ 3. down\r\n\r\n/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\
          \ in _call_impl(self, *input, **kwargs)\r\n   1188         if not (self._backward_hooks\
          \ or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\
          \n   1189                 or _global_forward_hooks or _global_forward_pre_hooks):\r\
          \n-> 1190             return forward_call(*input, **kwargs)\r\n   1191 \
          \        # Do not call functions when jit is used\r\n   1192         full_backward_hooks,\
          \ non_full_backward_hooks = [], []\r\n\r\n/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\
          \ in forward(self, input)\r\n    461 \r\n    462     def forward(self, input:\
          \ Tensor) -> Tensor:\r\n--> 463         return self._conv_forward(input,\
          \ self.weight, self.bias)\r\n    464 \r\n    465 class Conv3d(_ConvNd):\r\
          \n\r\n/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py in\
          \ _conv_forward(self, input, weight, bias)\r\n    457                  \
          \           weight, bias, self.stride,\r\n    458                      \
          \       _pair(0), self.dilation, self.groups)\r\n--> 459         return\
          \ F.conv2d(input, weight, bias, self.stride,\r\n    460                \
          \         self.padding, self.dilation, self.groups)\r\n    461 \r\n"
        updatedAt: '2022-12-11T22:25:02.553Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F614"
        users:
        - AnticPan
        - dmztheone
        - PyrateGFX
        - frzpichl
    id: 639658be008acac200ffcd99
    type: comment
  author: tiktok-legacy
  content: "Hi folks,\r\nGot this error when I was running the training colab. Do\
    \ you have any clue? Below is more error logs. Thanks!\r\n\r\nRuntimeError   \
    \                           Traceback (most recent call last)\r\n<ipython-input-14-fff6785cb183>\
    \ in <module>\r\n      1 #@title Run training\r\n      2 import accelerate\r\n\
    ----> 3 accelerate.notebook_launcher(training_function, args=(text_encoder, vae,\
    \ unet))\r\n      4 for param in itertools.chain(unet.parameters(), text_encoder.parameters()):\r\
    \n      5   if param.grad is not None:\r\n\r\n6 frames\r\n/usr/local/lib/python3.8/dist-packages/accelerate/launchers.py\
    \ in notebook_launcher(function, args, num_processes, use_fp16, mixed_precision,\
    \ use_port)\r\n     80         else:\r\n     81             print(\"Launching\
    \ training on one CPU.\")\r\n---> 82         function(*args)\r\n     83     else:\r\
    \n     84         if num_processes is None:\r\n\r\n<ipython-input-13-1e1a65c23a9e>\
    \ in training_function(text_encoder, vae, unet)\r\n    156 \r\n    157       \
    \          # Predict the noise residual\r\n--> 158                 noise_pred\
    \ = unet(noisy_latents, timesteps, encoder_hidden_states).sample\r\n    159 \r\
    \n    160                 # Get the target for loss depending on the prediction\
    \ type\r\n\r\n/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\
    \ in _call_impl(self, *input, **kwargs)\r\n   1188         if not (self._backward_hooks\
    \ or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\
    \n   1189                 or _global_forward_hooks or _global_forward_pre_hooks):\r\
    \n-> 1190             return forward_call(*input, **kwargs)\r\n   1191       \
    \  # Do not call functions when jit is used\r\n   1192         full_backward_hooks,\
    \ non_full_backward_hooks = [], []\r\n\r\n/usr/local/lib/python3.8/dist-packages/diffusers/models/unet_2d_condition.py\
    \ in forward(self, sample, timestep, encoder_hidden_states, class_labels, return_dict)\r\
    \n    373 \r\n    374         # 2. pre-process\r\n--> 375         sample = self.conv_in(sample)\r\
    \n    376 \r\n    377         # 3. down\r\n\r\n/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\
    \ in _call_impl(self, *input, **kwargs)\r\n   1188         if not (self._backward_hooks\
    \ or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\r\
    \n   1189                 or _global_forward_hooks or _global_forward_pre_hooks):\r\
    \n-> 1190             return forward_call(*input, **kwargs)\r\n   1191       \
    \  # Do not call functions when jit is used\r\n   1192         full_backward_hooks,\
    \ non_full_backward_hooks = [], []\r\n\r\n/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\
    \ in forward(self, input)\r\n    461 \r\n    462     def forward(self, input:\
    \ Tensor) -> Tensor:\r\n--> 463         return self._conv_forward(input, self.weight,\
    \ self.bias)\r\n    464 \r\n    465 class Conv3d(_ConvNd):\r\n\r\n/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\
    \ in _conv_forward(self, input, weight, bias)\r\n    457                     \
    \        weight, bias, self.stride,\r\n    458                             _pair(0),\
    \ self.dilation, self.groups)\r\n--> 459         return F.conv2d(input, weight,\
    \ bias, self.stride,\r\n    460                         self.padding, self.dilation,\
    \ self.groups)\r\n    461 \r\n"
  created_at: 2022-12-11 22:25:02+00:00
  edited: false
  hidden: false
  id: 639658be008acac200ffcd99
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: sd-dreambooth-library/disco-diffusion-style
repo_type: model
status: open
target_branch: null
title: 'RuntimeError: Input type (c10::Half) and bias type (float) should be the same'
