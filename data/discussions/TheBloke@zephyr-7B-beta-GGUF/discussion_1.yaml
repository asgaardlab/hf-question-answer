!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Phil337
conflicting_files: null
created_at: 2023-10-27 14:39:27+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-10-27T15:39:27.000Z'
    data:
      edited: true
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9753047823905945
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>It may just be on my end, but this model doesn''t load for me in
          GPT4All. I''ve tried about a dozen other recent GGUF models and they all
          work. It says it''s an "invalid format".</p>

          <p>Note: I tried both the Q4 0 and Q4 K M versions.</p>

          '
        raw: 'It may just be on my end, but this model doesn''t load for me in GPT4All.
          I''ve tried about a dozen other recent GGUF models and they all work. It
          says it''s an "invalid format".


          Note: I tried both the Q4 0 and Q4 K M versions.'
        updatedAt: '2023-10-27T15:47:07.682Z'
      numEdits: 1
      reactions: []
    id: 653bd9af221c8e1346fece8e
    type: comment
  author: Phil337
  content: 'It may just be on my end, but this model doesn''t load for me in GPT4All.
    I''ve tried about a dozen other recent GGUF models and they all work. It says
    it''s an "invalid format".


    Note: I tried both the Q4 0 and Q4 K M versions.'
  created_at: 2023-10-27 14:39:27+00:00
  edited: true
  hidden: false
  id: 653bd9af221c8e1346fece8e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0b03ed572c45abf79295055c137cbdc2.svg
      fullname: Robert Sedlacek
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: phaylon
      type: user
    createdAt: '2023-10-27T16:08:05.000Z'
    data:
      edited: false
      editors:
      - phaylon
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9715583920478821
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0b03ed572c45abf79295055c137cbdc2.svg
          fullname: Robert Sedlacek
          isHf: false
          isPro: false
          name: phaylon
          type: user
        html: '<p>Same problem here. candle tells me it''s in GGUF version 3, but
          I assume version 2 is expected.</p>

          '
        raw: Same problem here. candle tells me it's in GGUF version 3, but I assume
          version 2 is expected.
        updatedAt: '2023-10-27T16:08:05.630Z'
      numEdits: 0
      reactions: []
    id: 653be065aa10295ef1c6a153
    type: comment
  author: phaylon
  content: Same problem here. candle tells me it's in GGUF version 3, but I assume
    version 2 is expected.
  created_at: 2023-10-27 15:08:05+00:00
  edited: false
  hidden: false
  id: 653be065aa10295ef1c6a153
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643807cd819f3ab20d17266d/rE_uTjsAXXy26pQewm8c_.png?w=200&h=200&f=face
      fullname: qm9 (Casalioy Research)
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: qm9
      type: user
    createdAt: '2023-10-27T18:20:16.000Z'
    data:
      edited: false
      editors:
      - qm9
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9237933158874512
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643807cd819f3ab20d17266d/rE_uTjsAXXy26pQewm8c_.png?w=200&h=200&f=face
          fullname: qm9 (Casalioy Research)
          isHf: false
          isPro: false
          name: qm9
          type: user
        html: "<p>bit off topic: what's the performance difference compared to llamacpp?\
          \ <span data-props=\"{&quot;user&quot;:&quot;Phil337&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Phil337\">@<span class=\"\
          underline\">Phil337</span></a></span>\n\n\t</span></span> </p>\n"
        raw: 'bit off topic: what''s the performance difference compared to llamacpp?
          @Phil337 '
        updatedAt: '2023-10-27T18:20:16.524Z'
      numEdits: 0
      reactions: []
    id: 653bff60327edb8179eb82b6
    type: comment
  author: qm9
  content: 'bit off topic: what''s the performance difference compared to llamacpp?
    @Phil337 '
  created_at: 2023-10-27 17:20:16+00:00
  edited: false
  hidden: false
  id: 653bff60327edb8179eb82b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-10-27T18:32:30.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9315382242202759
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p>I don't know much about how all this works. From what I read GPT4All\
          \ uses a fork of llamacpp. Whenever I come across a bad response I test\
          \ it on the full unquantized version online and it gives comparable outputs\
          \ and makes the same mistakes, so there's little difference in terms of\
          \ hallucinations and other errors. And in terms of speed it's about 3 tokens/second\
          \ using 3 cores at 2.7 ghz with AVX2 CPU instructions. <span data-props=\"\
          {&quot;user&quot;:&quot;qm9&quot;}\" data-target=\"UserMention\" class=\"\
          SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"><span\
          \ class=\"contents\"><a href=\"/qm9\">@<span class=\"underline\">qm9</span></a></span>\n\
          \n\t</span></span> </p>\n"
        raw: 'I don''t know much about how all this works. From what I read GPT4All
          uses a fork of llamacpp. Whenever I come across a bad response I test it
          on the full unquantized version online and it gives comparable outputs and
          makes the same mistakes, so there''s little difference in terms of hallucinations
          and other errors. And in terms of speed it''s about 3 tokens/second using
          3 cores at 2.7 ghz with AVX2 CPU instructions. @qm9 '
        updatedAt: '2023-10-27T18:32:30.818Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - qm9
    id: 653c023ee819da8e0b496119
    type: comment
  author: Phil337
  content: 'I don''t know much about how all this works. From what I read GPT4All
    uses a fork of llamacpp. Whenever I come across a bad response I test it on the
    full unquantized version online and it gives comparable outputs and makes the
    same mistakes, so there''s little difference in terms of hallucinations and other
    errors. And in terms of speed it''s about 3 tokens/second using 3 cores at 2.7
    ghz with AVX2 CPU instructions. @qm9 '
  created_at: 2023-10-27 17:32:30+00:00
  edited: false
  hidden: false
  id: 653c023ee819da8e0b496119
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-10-27T22:07:51.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9649883508682251
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>Update: It seems all the new Bloke GGUF models are now incompatible
          with GPT4ALL. Earlier releases all worked (such as Dolphin 2.1 and Open
          Hermes 2), but all subsequent releases don''t (just tested AshhLimaRP).
          Perhaps there was a recent change to the standard and the newer models will
          work with a future version of GPT4All.</p>

          '
        raw: 'Update: It seems all the new Bloke GGUF models are now incompatible
          with GPT4ALL. Earlier releases all worked (such as Dolphin 2.1 and Open
          Hermes 2), but all subsequent releases don''t (just tested AshhLimaRP).
          Perhaps there was a recent change to the standard and the newer models will
          work with a future version of GPT4All.'
        updatedAt: '2023-10-27T22:07:51.539Z'
      numEdits: 0
      reactions: []
    id: 653c34b781f52ceb4df5b0ba
    type: comment
  author: Phil337
  content: 'Update: It seems all the new Bloke GGUF models are now incompatible with
    GPT4ALL. Earlier releases all worked (such as Dolphin 2.1 and Open Hermes 2),
    but all subsequent releases don''t (just tested AshhLimaRP). Perhaps there was
    a recent change to the standard and the newer models will work with a future version
    of GPT4All.'
  created_at: 2023-10-27 21:07:51+00:00
  edited: false
  hidden: false
  id: 653c34b781f52ceb4df5b0ba
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4j4M_alYew0CbD7wn2zo5.jpeg?w=200&h=200&f=face
      fullname: Kerfuffle V. II, Esq, Ltd, all rights reserved
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KerfuffleV2
      type: user
    createdAt: '2023-10-28T00:48:01.000Z'
    data:
      edited: false
      editors:
      - KerfuffleV2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9377679824829102
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4j4M_alYew0CbD7wn2zo5.jpeg?w=200&h=200&f=face
          fullname: Kerfuffle V. II, Esq, Ltd, all rights reserved
          isHf: false
          isPro: false
          name: KerfuffleV2
          type: user
        html: '<p>There''s actually no real difference in the file format except the
          version bump as far as I know (except if you happen to be on a big-endian
          platform which is unlikely), so you can just change the 5th byte (index
          4) of the file from <code>0x03</code> to <code>0x02</code> to transform
          the GGMLv3 file to a GGMLv2 one. Some examples of how to edit a byte like
          that: <a rel="nofollow" href="https://stackoverflow.com/a/34524796">https://stackoverflow.com/a/34524796</a></p>

          '
        raw: 'There''s actually no real difference in the file format except the version
          bump as far as I know (except if you happen to be on a big-endian platform
          which is unlikely), so you can just change the 5th byte (index 4) of the
          file from `0x03` to `0x02` to transform the GGMLv3 file to a GGMLv2 one.
          Some examples of how to edit a byte like that: https://stackoverflow.com/a/34524796'
        updatedAt: '2023-10-28T00:48:01.197Z'
      numEdits: 0
      reactions: []
    id: 653c5a41ceb0a0f6cef741be
    type: comment
  author: KerfuffleV2
  content: 'There''s actually no real difference in the file format except the version
    bump as far as I know (except if you happen to be on a big-endian platform which
    is unlikely), so you can just change the 5th byte (index 4) of the file from `0x03`
    to `0x02` to transform the GGMLv3 file to a GGMLv2 one. Some examples of how to
    edit a byte like that: https://stackoverflow.com/a/34524796'
  created_at: 2023-10-27 23:48:01+00:00
  edited: false
  hidden: false
  id: 653c5a41ceb0a0f6cef741be
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-10-28T01:29:15.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9496907591819763
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;KerfuffleV2&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/KerfuffleV2\"\
          >@<span class=\"underline\">KerfuffleV2</span></a></span>\n\n\t</span></span>\
          \ , I bet you're right since this LLM works with other apps, earlier Mistrals\
          \ all worked in GPT4ALL, and it fails immediately before even trying to\
          \ load a LLM into RAM. So detecting an unsupported format (GGUFv3), then\
          \ refusing to load it, adds up.</p>\n"
        raw: Thanks @KerfuffleV2 , I bet you're right since this LLM works with other
          apps, earlier Mistrals all worked in GPT4ALL, and it fails immediately before
          even trying to load a LLM into RAM. So detecting an unsupported format (GGUFv3),
          then refusing to load it, adds up.
        updatedAt: '2023-10-28T01:29:15.969Z'
      numEdits: 0
      reactions: []
    id: 653c63eb3479e9ebbe0b9292
    type: comment
  author: Phil337
  content: Thanks @KerfuffleV2 , I bet you're right since this LLM works with other
    apps, earlier Mistrals all worked in GPT4ALL, and it fails immediately before
    even trying to load a LLM into RAM. So detecting an unsupported format (GGUFv3),
    then refusing to load it, adds up.
  created_at: 2023-10-28 00:29:15+00:00
  edited: false
  hidden: false
  id: 653c63eb3479e9ebbe0b9292
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4j4M_alYew0CbD7wn2zo5.jpeg?w=200&h=200&f=face
      fullname: Kerfuffle V. II, Esq, Ltd, all rights reserved
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: KerfuffleV2
      type: user
    createdAt: '2023-10-28T01:42:12.000Z'
    data:
      edited: false
      editors:
      - KerfuffleV2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9752122759819031
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/4j4M_alYew0CbD7wn2zo5.jpeg?w=200&h=200&f=face
          fullname: Kerfuffle V. II, Esq, Ltd, all rights reserved
          isHf: false
          isPro: false
          name: KerfuffleV2
          type: user
        html: '<blockquote>

          <p> I bet you''re right since this LLM works with other apps</p>

          </blockquote>

          <p>I actually checked the patch where the GGUF version changed to 3 to make
          sure as well, so I was pretty confident about it.</p>

          <p>I just looked at the GPT4ALL project and it seems like they already pulled
          in the changes for supporting GGUFv3 files, so if you use the main branch
          the GGUFv3 models should work. Otherwise, I guess wait for them to make
          a release (or use the model revert workaround I suggested). The good news
          is it shouldn''t be a pain point for much longer.</p>

          '
        raw: '>  I bet you''re right since this LLM works with other apps


          I actually checked the patch where the GGUF version changed to 3 to make
          sure as well, so I was pretty confident about it.


          I just looked at the GPT4ALL project and it seems like they already pulled
          in the changes for supporting GGUFv3 files, so if you use the main branch
          the GGUFv3 models should work. Otherwise, I guess wait for them to make
          a release (or use the model revert workaround I suggested). The good news
          is it shouldn''t be a pain point for much longer.'
        updatedAt: '2023-10-28T01:42:12.976Z'
      numEdits: 0
      reactions: []
    id: 653c66f46217d355c660611c
    type: comment
  author: KerfuffleV2
  content: '>  I bet you''re right since this LLM works with other apps


    I actually checked the patch where the GGUF version changed to 3 to make sure
    as well, so I was pretty confident about it.


    I just looked at the GPT4ALL project and it seems like they already pulled in
    the changes for supporting GGUFv3 files, so if you use the main branch the GGUFv3
    models should work. Otherwise, I guess wait for them to make a release (or use
    the model revert workaround I suggested). The good news is it shouldn''t be a
    pain point for much longer.'
  created_at: 2023-10-28 00:42:12+00:00
  edited: false
  hidden: false
  id: 653c66f46217d355c660611c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-10-28T01:45:51.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9969320893287659
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>Cool. I''ll wait. It''s nice to know it''s already been addressed.</p>

          '
        raw: Cool. I'll wait. It's nice to know it's already been addressed.
        updatedAt: '2023-10-28T01:45:51.995Z'
      numEdits: 0
      reactions: []
    id: 653c67cf2dedebcbb75c7a62
    type: comment
  author: Phil337
  content: Cool. I'll wait. It's nice to know it's already been addressed.
  created_at: 2023-10-28 00:45:51+00:00
  edited: false
  hidden: false
  id: 653c67cf2dedebcbb75c7a62
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/64ac7b4159bd86340458e53d3e30aee2.svg
      fullname: Bumba
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pumba2
      type: user
    createdAt: '2023-10-28T04:01:03.000Z'
    data:
      edited: false
      editors:
      - Pumba2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8696557879447937
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/64ac7b4159bd86340458e53d3e30aee2.svg
          fullname: Bumba
          isHf: false
          isPro: false
          name: Pumba2
          type: user
        html: '<p>What ver of GPT4All are you using ?</p>

          '
        raw: 'What ver of GPT4All are you using ?

          '
        updatedAt: '2023-10-28T04:01:03.032Z'
      numEdits: 0
      reactions: []
    id: 653c877f3fc9c706fa53eb07
    type: comment
  author: Pumba2
  content: 'What ver of GPT4All are you using ?

    '
  created_at: 2023-10-28 03:01:03+00:00
  edited: false
  hidden: false
  id: 653c877f3fc9c706fa53eb07
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-10-28T04:20:11.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3437952697277069
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>I''m using GPT4All v2.5.1. </p>

          '
        raw: 'I''m using GPT4All v2.5.1. '
        updatedAt: '2023-10-28T04:20:11.659Z'
      numEdits: 0
      reactions: []
    id: 653c8bfb8a67c542eecf9f10
    type: comment
  author: Phil337
  content: 'I''m using GPT4All v2.5.1. '
  created_at: 2023-10-28 03:20:11+00:00
  edited: false
  hidden: false
  id: 653c8bfb8a67c542eecf9f10
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/64ac7b4159bd86340458e53d3e30aee2.svg
      fullname: Bumba
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Pumba2
      type: user
    createdAt: '2023-10-28T04:26:07.000Z'
    data:
      edited: false
      editors:
      - Pumba2
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9577851891517639
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/64ac7b4159bd86340458e53d3e30aee2.svg
          fullname: Bumba
          isHf: false
          isPro: false
          name: Pumba2
          type: user
        html: '<p>Ok thx. Good to know coz i was just about to download the model
          and got the same ver of gpt4all. : )</p>

          '
        raw: 'Ok thx. Good to know coz i was just about to download the model and
          got the same ver of gpt4all. : )'
        updatedAt: '2023-10-28T04:26:07.175Z'
      numEdits: 0
      reactions: []
    id: 653c8d5fb16f657d28b33db4
    type: comment
  author: Pumba2
  content: 'Ok thx. Good to know coz i was just about to download the model and got
    the same ver of gpt4all. : )'
  created_at: 2023-10-28 03:26:07+00:00
  edited: false
  hidden: false
  id: 653c8d5fb16f657d28b33db4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/zephyr-7B-beta-GGUF
repo_type: model
status: open
target_branch: null
title: Possible Loading Error with GPT4All
