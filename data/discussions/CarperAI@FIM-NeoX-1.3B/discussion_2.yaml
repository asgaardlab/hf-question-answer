!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BigSalmon
conflicting_files: null
created_at: 2022-10-08 19:19:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b14483dce02604e3683e53bc29ea309c.svg
      fullname: Simon Salmon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BigSalmon
      type: user
    createdAt: '2022-10-08T20:19:04.000Z'
    data:
      edited: false
      editors:
      - BigSalmon
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b14483dce02604e3683e53bc29ea309c.svg
          fullname: Simon Salmon
          isHf: false
          isPro: false
          name: BigSalmon
          type: user
        html: '<pre><code>pip install transformers

          </code></pre>

          <pre><code>prefix = "this is some text preceding the cursor,"

          suffix = "and this is some text after it."

          model_tokenized_input = [50253, *tokenizer(suffix), 50254, *tokenizer(prefix),
          50255]

          infilled = model.generate(model_tokenized_input)

          </code></pre>

          <pre><code>AttributeError: ''list'' object has no attribute ''shape''

          </code></pre>

          '
        raw: "```\r\npip install transformers\r\n```\r\n\r\n```\r\nprefix = \"this\
          \ is some text preceding the cursor,\"\r\nsuffix = \"and this is some text\
          \ after it.\"\r\nmodel_tokenized_input = [50253, *tokenizer(suffix), 50254,\
          \ *tokenizer(prefix), 50255]\r\ninfilled = model.generate(model_tokenized_input)\r\
          \n```\r\n\r\n```\r\nAttributeError: 'list' object has no attribute 'shape'\r\
          \n```"
        updatedAt: '2022-10-08T20:19:04.997Z'
      numEdits: 0
      reactions: []
    id: 6341db38e5071b0c5cd08646
    type: comment
  author: BigSalmon
  content: "```\r\npip install transformers\r\n```\r\n\r\n```\r\nprefix = \"this is\
    \ some text preceding the cursor,\"\r\nsuffix = \"and this is some text after\
    \ it.\"\r\nmodel_tokenized_input = [50253, *tokenizer(suffix), 50254, *tokenizer(prefix),\
    \ 50255]\r\ninfilled = model.generate(model_tokenized_input)\r\n```\r\n\r\n```\r\
    \nAttributeError: 'list' object has no attribute 'shape'\r\n```"
  created_at: 2022-10-08 19:19:04+00:00
  edited: false
  hidden: false
  id: 6341db38e5071b0c5cd08646
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e97159e69482979e2da637f7f01f3f87.svg
      fullname: Sid
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sradc
      type: user
    createdAt: '2022-10-09T09:47:42.000Z'
    data:
      edited: true
      editors:
      - sradc
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e97159e69482979e2da637f7f01f3f87.svg
          fullname: Sid
          isHf: false
          isPro: false
          name: sradc
          type: user
        html: "<p>I went with:</p>\n<pre><code class=\"language-python\">device =\
          \ <span class=\"hljs-string\">\"cuda\"</span> <span class=\"hljs-keyword\"\
          >if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span>\
          \ <span class=\"hljs-string\">\"cpu\"</span>\n\n<span class=\"hljs-keyword\"\
          >def</span> <span class=\"hljs-title function_\">infill</span>(<span class=\"\
          hljs-params\">prefix, suffix</span>):\n    input_ids = (\n        torch.tensor(\n\
          \            [\n                <span class=\"hljs-number\">50253</span>,\n\
          \                *tokenizer(suffix)[<span class=\"hljs-string\">\"input_ids\"\
          </span>],\n                <span class=\"hljs-number\">50254</span>,\n \
          \               *tokenizer(prefix)[<span class=\"hljs-string\">\"input_ids\"\
          </span>],\n                <span class=\"hljs-number\">50255</span>,\n \
          \           ]\n        )\n        .reshape(<span class=\"hljs-number\">1</span>,\
          \ -<span class=\"hljs-number\">1</span>)\n        .to(device)\n    )\n \
          \   attention_mask = torch.ones_like(input_ids)\n    infilled = model.generate(input_ids=input_ids,\
          \ attention_mask=attention_mask)\n    filled_text = tokenizer.decode(\n\
          \        infilled[<span class=\"hljs-number\">0</span>, ...][input_ids[<span\
          \ class=\"hljs-number\">0</span>].tolist().index(<span class=\"hljs-number\"\
          >50255</span>) + <span class=\"hljs-number\">1</span> :], special_tokens=<span\
          \ class=\"hljs-literal\">False</span>\n    )\n    <span class=\"hljs-keyword\"\
          >return</span> filled_text\n\ninfill(<span class=\"hljs-string\">\"A rabbit\
          \ is an\"</span>, <span class=\"hljs-string\">\"found in the wild.\"</span>)\n\
          </code></pre>\n<p>(Though infilling doesn't currently work properly due\
          \ to the tokenizer, see <a href=\"https://huggingface.co/CarperAI/FIM-NeoX-1.3B/discussions/1\"\
          >https://huggingface.co/CarperAI/FIM-NeoX-1.3B/discussions/1</a>)</p>\n"
        raw: "I went with:\n```python\ndevice = \"cuda\" if torch.cuda.is_available()\
          \ else \"cpu\"\n\ndef infill(prefix, suffix):\n    input_ids = (\n     \
          \   torch.tensor(\n            [\n                50253,\n             \
          \   *tokenizer(suffix)[\"input_ids\"],\n                50254,\n       \
          \         *tokenizer(prefix)[\"input_ids\"],\n                50255,\n \
          \           ]\n        )\n        .reshape(1, -1)\n        .to(device)\n\
          \    )\n    attention_mask = torch.ones_like(input_ids)\n    infilled =\
          \ model.generate(input_ids=input_ids, attention_mask=attention_mask)\n \
          \   filled_text = tokenizer.decode(\n        infilled[0, ...][input_ids[0].tolist().index(50255)\
          \ + 1 :], special_tokens=False\n    )\n    return filled_text\n\ninfill(\"\
          A rabbit is an\", \"found in the wild.\")\n```\n(Though infilling doesn't\
          \ currently work properly due to the tokenizer, see https://huggingface.co/CarperAI/FIM-NeoX-1.3B/discussions/1)"
        updatedAt: '2022-10-09T10:48:23.151Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - BigSalmon
    id: 634298be6f59b79da0762b6a
    type: comment
  author: sradc
  content: "I went with:\n```python\ndevice = \"cuda\" if torch.cuda.is_available()\
    \ else \"cpu\"\n\ndef infill(prefix, suffix):\n    input_ids = (\n        torch.tensor(\n\
    \            [\n                50253,\n                *tokenizer(suffix)[\"\
    input_ids\"],\n                50254,\n                *tokenizer(prefix)[\"input_ids\"\
    ],\n                50255,\n            ]\n        )\n        .reshape(1, -1)\n\
    \        .to(device)\n    )\n    attention_mask = torch.ones_like(input_ids)\n\
    \    infilled = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n\
    \    filled_text = tokenizer.decode(\n        infilled[0, ...][input_ids[0].tolist().index(50255)\
    \ + 1 :], special_tokens=False\n    )\n    return filled_text\n\ninfill(\"A rabbit\
    \ is an\", \"found in the wild.\")\n```\n(Though infilling doesn't currently work\
    \ properly due to the tokenizer, see https://huggingface.co/CarperAI/FIM-NeoX-1.3B/discussions/1)"
  created_at: 2022-10-09 08:47:42+00:00
  edited: true
  hidden: false
  id: 634298be6f59b79da0762b6a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b14483dce02604e3683e53bc29ea309c.svg
      fullname: Simon Salmon
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BigSalmon
      type: user
    createdAt: '2022-10-09T14:50:08.000Z'
    data:
      edited: false
      editors:
      - BigSalmon
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b14483dce02604e3683e53bc29ea309c.svg
          fullname: Simon Salmon
          isHf: false
          isPro: false
          name: BigSalmon
          type: user
        html: "<p>Thank you! I\u2019ll use this on Tuesday or Wednesday, when they\u2019\
          ve updated the tokenizer.</p>\n"
        raw: "Thank you! I\u2019ll use this on Tuesday or Wednesday, when they\u2019\
          ve updated the tokenizer."
        updatedAt: '2022-10-09T14:50:08.551Z'
      numEdits: 0
      reactions: []
    id: 6342dfa007fa6ff0c2216a89
    type: comment
  author: BigSalmon
  content: "Thank you! I\u2019ll use this on Tuesday or Wednesday, when they\u2019\
    ve updated the tokenizer."
  created_at: 2022-10-09 13:50:08+00:00
  edited: false
  hidden: false
  id: 6342dfa007fa6ff0c2216a89
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665155571839-60d35a0307da9c17c7270909.jpeg?w=200&h=200&f=face
      fullname: Louis Castricato
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: LouisCastricato
      type: user
    createdAt: '2022-10-11T14:15:11.000Z'
    data:
      edited: true
      editors:
      - LouisCastricato
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665155571839-60d35a0307da9c17c7270909.jpeg?w=200&h=200&f=face
          fullname: Louis Castricato
          isHf: false
          isPro: false
          name: LouisCastricato
          type: user
        html: '<p>Tokenizer has been patched. Thank you for your patience.</p>

          '
        raw: Tokenizer has been patched. Thank you for your patience.
        updatedAt: '2022-10-11T14:15:25.517Z'
      numEdits: 1
      reactions: []
    id: 63457a6ffe134dfd7a0b08fe
    type: comment
  author: LouisCastricato
  content: Tokenizer has been patched. Thank you for your patience.
  created_at: 2022-10-11 13:15:11+00:00
  edited: true
  hidden: false
  id: 63457a6ffe134dfd7a0b08fe
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: CarperAI/FIM-NeoX-1.3B
repo_type: model
status: open
target_branch: null
title: 'AttributeError: ''list'' object has no attribute ''shape'''
