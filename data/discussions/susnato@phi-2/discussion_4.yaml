!!python/object:huggingface_hub.community.DiscussionWithDetails
author: g-ronimo
conflicting_files: null
created_at: 2024-01-12 22:03:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da2a58c307ee5369b92d36/7xEgll8v5SxxcG_XF86tU.jpeg?w=200&h=200&f=face
      fullname: geronimo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g-ronimo
      type: user
    createdAt: '2024-01-12T22:03:43.000Z'
    data:
      edited: false
      editors:
      - g-ronimo
      hidden: false
      identifiedLanguage:
        language: ja
        probability: 0.08007144182920456
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da2a58c307ee5369b92d36/7xEgll8v5SxxcG_XF86tU.jpeg?w=200&h=200&f=face
          fullname: geronimo
          isHf: false
          isPro: false
          name: g-ronimo
          type: user
        html: "<pre><code class=\"language-python\">model_path=<span class=\"hljs-string\"\
          >\"susnato/phi-2\"</span>\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    model_path, \n    torch_dtype=torch.bfloat16, \n    device_map=<span\
          \ class=\"hljs-string\">\"auto\"</span>,\n)\n</code></pre>\n<p>Model outputs\
          \ only garbage.  What's wrong here?<br>Using latest <code>transformers</code>\
          \ git pulled an hour ago</p>\n<p>full error message:</p>\n<pre><code>Some\
          \ weights of the model checkpoint at susnato/phi-2 were not used when initializing\
          \ PhiForCausalLM: ['model.layers.0.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.weight',\
          \ 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.1.self_attn.query_key_value.weight',\
          \ 'model.layers.10.self_attn.query_key_value.bias', 'model.layers.10.self_attn.query_key_value.weight',\
          \ 'model.layers.11.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.weight',\
          \ 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.weight',\
          \ 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.13.self_attn.query_key_value.weight',\
          \ 'model.layers.14.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.weight',\
          \ 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.15.self_attn.query_key_value.weight',\
          \ 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.weight',\
          \ 'model.layers.17.self_attn.query_key_value.bias', 'model.layers.17.self_attn.query_key_value.weight',\
          \ 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.weight',\
          \ 'model.layers.19.self_attn.query_key_value.bias', 'model.layers.19.self_attn.query_key_value.weight',\
          \ 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.weight',\
          \ 'model.layers.20.self_attn.query_key_value.bias', 'model.layers.20.self_attn.query_key_value.weight',\
          \ 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.21.self_attn.query_key_value.weight',\
          \ 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.22.self_attn.query_key_value.weight',\
          \ 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.weight',\
          \ 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.weight',\
          \ 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.weight',\
          \ 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.26.self_attn.query_key_value.weight',\
          \ 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.27.self_attn.query_key_value.weight',\
          \ 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.weight',\
          \ 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.29.self_attn.query_key_value.weight',\
          \ 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.weight',\
          \ 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.weight',\
          \ 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.31.self_attn.query_key_value.weight',\
          \ 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.weight',\
          \ 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.5.self_attn.query_key_value.weight',\
          \ 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.weight',\
          \ 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.weight',\
          \ 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.weight',\
          \ 'model.layers.9.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.weight']\n\
          - This IS expected if you are initializing PhiForCausalLM from the checkpoint\
          \ of a model trained on another task or with another architecture (e.g.\
          \ initializing a BertForSequenceClassification model from a BertForPreTraining\
          \ model).\n- This IS NOT expected if you are initializing PhiForCausalLM\
          \ from the checkpoint of a model that you expect to be exactly identical\
          \ (initializing a BertForSequenceClassification model from a BertForSequenceClassification\
          \ model).\nSome weights of PhiForCausalLM were not initialized from the\
          \ model checkpoint at susnato/phi-2 and are newly initialized: ['model.layers.0.self_attn.k_proj.bias',\
          \ 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.q_proj.bias',\
          \ 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.bias',\
          \ 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.self_attn.k_proj.bias',\
          \ 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.q_proj.bias',\
          \ 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.bias',\
          \ 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.self_attn.k_proj.bias',\
          \ 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.q_proj.bias',\
          \ 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.bias',\
          \ 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.self_attn.k_proj.bias',\
          \ 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.q_proj.bias',\
          \ 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.bias',\
          \ 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.self_attn.k_proj.bias',\
          \ 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.q_proj.bias',\
          \ 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.bias',\
          \ 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.self_attn.k_proj.bias',\
          \ 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.q_proj.bias',\
          \ 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.bias',\
          \ 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.self_attn.k_proj.bias',\
          \ 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.q_proj.bias',\
          \ 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.bias',\
          \ 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.self_attn.k_proj.bias',\
          \ 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.q_proj.bias',\
          \ 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.bias',\
          \ 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.self_attn.k_proj.bias',\
          \ 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.q_proj.bias',\
          \ 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.bias',\
          \ 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.self_attn.k_proj.bias',\
          \ 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.q_proj.bias',\
          \ 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.bias',\
          \ 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.self_attn.k_proj.bias',\
          \ 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.q_proj.bias',\
          \ 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.bias',\
          \ 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.self_attn.k_proj.bias',\
          \ 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.q_proj.bias',\
          \ 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.bias',\
          \ 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.self_attn.k_proj.bias',\
          \ 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.q_proj.bias',\
          \ 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.bias',\
          \ 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.self_attn.k_proj.bias',\
          \ 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.q_proj.bias',\
          \ 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.bias',\
          \ 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.self_attn.k_proj.bias',\
          \ 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.q_proj.bias',\
          \ 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.bias',\
          \ 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.self_attn.k_proj.bias',\
          \ 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.q_proj.bias',\
          \ 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.bias',\
          \ 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.self_attn.k_proj.bias',\
          \ 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.q_proj.bias',\
          \ 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.bias',\
          \ 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.self_attn.k_proj.bias',\
          \ 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.q_proj.bias',\
          \ 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.bias',\
          \ 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.self_attn.k_proj.bias',\
          \ 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.q_proj.bias',\
          \ 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.bias',\
          \ 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.self_attn.k_proj.bias',\
          \ 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.q_proj.bias',\
          \ 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.bias',\
          \ 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.self_attn.k_proj.bias',\
          \ 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.q_proj.bias',\
          \ 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.bias',\
          \ 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.self_attn.k_proj.bias',\
          \ 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.q_proj.bias',\
          \ 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.bias',\
          \ 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.self_attn.k_proj.bias',\
          \ 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.q_proj.bias',\
          \ 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.bias',\
          \ 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.self_attn.k_proj.bias',\
          \ 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.q_proj.bias',\
          \ 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.bias',\
          \ 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.self_attn.k_proj.bias',\
          \ 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.q_proj.bias',\
          \ 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.bias',\
          \ 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.self_attn.k_proj.bias',\
          \ 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.q_proj.bias',\
          \ 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.bias',\
          \ 'model.layers.31.self_attn.v_proj.weight', 'model.layers.4.self_attn.k_proj.bias',\
          \ 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.q_proj.bias',\
          \ 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.bias',\
          \ 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.self_attn.k_proj.bias',\
          \ 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.q_proj.bias',\
          \ 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.bias',\
          \ 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.self_attn.k_proj.bias',\
          \ 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.q_proj.bias',\
          \ 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.bias',\
          \ 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.self_attn.k_proj.bias',\
          \ 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.q_proj.bias',\
          \ 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.bias',\
          \ 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.self_attn.k_proj.bias',\
          \ 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.q_proj.bias',\
          \ 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.bias',\
          \ 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.self_attn.k_proj.bias',\
          \ 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.q_proj.bias',\
          \ 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.bias',\
          \ 'model.layers.9.self_attn.v_proj.weight']\nYou should probably TRAIN this\
          \ model on a down-stream task to be able to use it for predictions and inference.\n\
          </code></pre>\n"
        raw: "```python\r\nmodel_path=\"susnato/phi-2\"\r\nmodel = AutoModelForCausalLM.from_pretrained(\r\
          \n    model_path, \r\n    torch_dtype=torch.bfloat16, \r\n    device_map=\"\
          auto\",\r\n)\r\n```\r\n\r\nModel outputs only garbage.  What's wrong here?\r\
          \nUsing latest ```transformers``` git pulled an hour ago\r\n\r\nfull error\
          \ message:\r\n```\r\nSome weights of the model checkpoint at susnato/phi-2\
          \ were not used when initializing PhiForCausalLM: ['model.layers.0.self_attn.query_key_value.bias',\
          \ 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.bias',\
          \ 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.bias',\
          \ 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.bias',\
          \ 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.12.self_attn.query_key_value.bias',\
          \ 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.bias',\
          \ 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.bias',\
          \ 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.bias',\
          \ 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.16.self_attn.query_key_value.bias',\
          \ 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.bias',\
          \ 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.18.self_attn.query_key_value.bias',\
          \ 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.bias',\
          \ 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.bias',\
          \ 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.bias',\
          \ 'model.layers.20.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.bias',\
          \ 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.bias',\
          \ 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.bias',\
          \ 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.24.self_attn.query_key_value.bias',\
          \ 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.25.self_attn.query_key_value.bias',\
          \ 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.bias',\
          \ 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.bias',\
          \ 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.28.self_attn.query_key_value.bias',\
          \ 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.bias',\
          \ 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.bias',\
          \ 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.bias',\
          \ 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.bias',\
          \ 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.4.self_attn.query_key_value.bias',\
          \ 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.bias',\
          \ 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.6.self_attn.query_key_value.bias',\
          \ 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.bias',\
          \ 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.bias',\
          \ 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.9.self_attn.query_key_value.bias',\
          \ 'model.layers.9.self_attn.query_key_value.weight']\r\n- This IS expected\
          \ if you are initializing PhiForCausalLM from the checkpoint of a model\
          \ trained on another task or with another architecture (e.g. initializing\
          \ a BertForSequenceClassification model from a BertForPreTraining model).\r\
          \n- This IS NOT expected if you are initializing PhiForCausalLM from the\
          \ checkpoint of a model that you expect to be exactly identical (initializing\
          \ a BertForSequenceClassification model from a BertForSequenceClassification\
          \ model).\r\nSome weights of PhiForCausalLM were not initialized from the\
          \ model checkpoint at susnato/phi-2 and are newly initialized: ['model.layers.0.self_attn.k_proj.bias',\
          \ 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.q_proj.bias',\
          \ 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.bias',\
          \ 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.self_attn.k_proj.bias',\
          \ 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.q_proj.bias',\
          \ 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.bias',\
          \ 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.self_attn.k_proj.bias',\
          \ 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.q_proj.bias',\
          \ 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.bias',\
          \ 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.self_attn.k_proj.bias',\
          \ 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.q_proj.bias',\
          \ 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.bias',\
          \ 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.self_attn.k_proj.bias',\
          \ 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.q_proj.bias',\
          \ 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.bias',\
          \ 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.self_attn.k_proj.bias',\
          \ 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.q_proj.bias',\
          \ 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.bias',\
          \ 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.self_attn.k_proj.bias',\
          \ 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.q_proj.bias',\
          \ 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.bias',\
          \ 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.self_attn.k_proj.bias',\
          \ 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.q_proj.bias',\
          \ 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.bias',\
          \ 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.self_attn.k_proj.bias',\
          \ 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.q_proj.bias',\
          \ 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.bias',\
          \ 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.self_attn.k_proj.bias',\
          \ 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.q_proj.bias',\
          \ 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.bias',\
          \ 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.self_attn.k_proj.bias',\
          \ 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.q_proj.bias',\
          \ 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.bias',\
          \ 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.self_attn.k_proj.bias',\
          \ 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.q_proj.bias',\
          \ 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.bias',\
          \ 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.self_attn.k_proj.bias',\
          \ 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.q_proj.bias',\
          \ 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.bias',\
          \ 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.self_attn.k_proj.bias',\
          \ 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.q_proj.bias',\
          \ 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.bias',\
          \ 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.self_attn.k_proj.bias',\
          \ 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.q_proj.bias',\
          \ 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.bias',\
          \ 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.self_attn.k_proj.bias',\
          \ 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.q_proj.bias',\
          \ 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.bias',\
          \ 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.self_attn.k_proj.bias',\
          \ 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.q_proj.bias',\
          \ 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.bias',\
          \ 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.self_attn.k_proj.bias',\
          \ 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.q_proj.bias',\
          \ 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.bias',\
          \ 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.self_attn.k_proj.bias',\
          \ 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.q_proj.bias',\
          \ 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.bias',\
          \ 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.self_attn.k_proj.bias',\
          \ 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.q_proj.bias',\
          \ 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.bias',\
          \ 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.self_attn.k_proj.bias',\
          \ 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.q_proj.bias',\
          \ 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.bias',\
          \ 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.self_attn.k_proj.bias',\
          \ 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.q_proj.bias',\
          \ 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.bias',\
          \ 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.self_attn.k_proj.bias',\
          \ 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.q_proj.bias',\
          \ 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.bias',\
          \ 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.self_attn.k_proj.bias',\
          \ 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.q_proj.bias',\
          \ 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.bias',\
          \ 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.self_attn.k_proj.bias',\
          \ 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.q_proj.bias',\
          \ 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.bias',\
          \ 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.self_attn.k_proj.bias',\
          \ 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.q_proj.bias',\
          \ 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.bias',\
          \ 'model.layers.31.self_attn.v_proj.weight', 'model.layers.4.self_attn.k_proj.bias',\
          \ 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.q_proj.bias',\
          \ 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.bias',\
          \ 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.self_attn.k_proj.bias',\
          \ 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.q_proj.bias',\
          \ 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.bias',\
          \ 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.self_attn.k_proj.bias',\
          \ 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.q_proj.bias',\
          \ 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.bias',\
          \ 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.self_attn.k_proj.bias',\
          \ 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.q_proj.bias',\
          \ 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.bias',\
          \ 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.self_attn.k_proj.bias',\
          \ 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.q_proj.bias',\
          \ 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.bias',\
          \ 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.self_attn.k_proj.bias',\
          \ 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.q_proj.bias',\
          \ 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.bias',\
          \ 'model.layers.9.self_attn.v_proj.weight']\r\nYou should probably TRAIN\
          \ this model on a down-stream task to be able to use it for predictions\
          \ and inference.\r\n```"
        updatedAt: '2024-01-12T22:03:43.556Z'
      numEdits: 0
      reactions: []
    id: 65a1b73f41b6ef119c012b18
    type: comment
  author: g-ronimo
  content: "```python\r\nmodel_path=\"susnato/phi-2\"\r\nmodel = AutoModelForCausalLM.from_pretrained(\r\
    \n    model_path, \r\n    torch_dtype=torch.bfloat16, \r\n    device_map=\"auto\"\
    ,\r\n)\r\n```\r\n\r\nModel outputs only garbage.  What's wrong here?\r\nUsing\
    \ latest ```transformers``` git pulled an hour ago\r\n\r\nfull error message:\r\
    \n```\r\nSome weights of the model checkpoint at susnato/phi-2 were not used when\
    \ initializing PhiForCausalLM: ['model.layers.0.self_attn.query_key_value.bias',\
    \ 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.bias',\
    \ 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.bias',\
    \ 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.bias',\
    \ 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.12.self_attn.query_key_value.bias',\
    \ 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.bias',\
    \ 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.bias',\
    \ 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.bias',\
    \ 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.16.self_attn.query_key_value.bias',\
    \ 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.bias',\
    \ 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.18.self_attn.query_key_value.bias',\
    \ 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.bias',\
    \ 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.bias',\
    \ 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.bias',\
    \ 'model.layers.20.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.bias',\
    \ 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.bias',\
    \ 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.bias',\
    \ 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.24.self_attn.query_key_value.bias',\
    \ 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.25.self_attn.query_key_value.bias',\
    \ 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.bias',\
    \ 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.bias',\
    \ 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.28.self_attn.query_key_value.bias',\
    \ 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.bias',\
    \ 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.bias',\
    \ 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.bias',\
    \ 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.bias',\
    \ 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.4.self_attn.query_key_value.bias',\
    \ 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.bias',\
    \ 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.6.self_attn.query_key_value.bias',\
    \ 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.bias',\
    \ 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.bias',\
    \ 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.9.self_attn.query_key_value.bias',\
    \ 'model.layers.9.self_attn.query_key_value.weight']\r\n- This IS expected if\
    \ you are initializing PhiForCausalLM from the checkpoint of a model trained on\
    \ another task or with another architecture (e.g. initializing a BertForSequenceClassification\
    \ model from a BertForPreTraining model).\r\n- This IS NOT expected if you are\
    \ initializing PhiForCausalLM from the checkpoint of a model that you expect to\
    \ be exactly identical (initializing a BertForSequenceClassification model from\
    \ a BertForSequenceClassification model).\r\nSome weights of PhiForCausalLM were\
    \ not initialized from the model checkpoint at susnato/phi-2 and are newly initialized:\
    \ ['model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.k_proj.weight',\
    \ 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.q_proj.weight',\
    \ 'model.layers.0.self_attn.v_proj.bias', 'model.layers.0.self_attn.v_proj.weight',\
    \ 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.k_proj.weight',\
    \ 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.q_proj.weight',\
    \ 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.weight',\
    \ 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.k_proj.weight',\
    \ 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.q_proj.weight',\
    \ 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.weight',\
    \ 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.k_proj.weight',\
    \ 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.q_proj.weight',\
    \ 'model.layers.11.self_attn.v_proj.bias', 'model.layers.11.self_attn.v_proj.weight',\
    \ 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.k_proj.weight',\
    \ 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.q_proj.weight',\
    \ 'model.layers.12.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.weight',\
    \ 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.k_proj.weight',\
    \ 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.q_proj.weight',\
    \ 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.v_proj.weight',\
    \ 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.k_proj.weight',\
    \ 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.q_proj.weight',\
    \ 'model.layers.14.self_attn.v_proj.bias', 'model.layers.14.self_attn.v_proj.weight',\
    \ 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.k_proj.weight',\
    \ 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.q_proj.weight',\
    \ 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.v_proj.weight',\
    \ 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.k_proj.weight',\
    \ 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.weight',\
    \ 'model.layers.16.self_attn.v_proj.bias', 'model.layers.16.self_attn.v_proj.weight',\
    \ 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.k_proj.weight',\
    \ 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.q_proj.weight',\
    \ 'model.layers.17.self_attn.v_proj.bias', 'model.layers.17.self_attn.v_proj.weight',\
    \ 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.k_proj.weight',\
    \ 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.q_proj.weight',\
    \ 'model.layers.18.self_attn.v_proj.bias', 'model.layers.18.self_attn.v_proj.weight',\
    \ 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.k_proj.weight',\
    \ 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.q_proj.weight',\
    \ 'model.layers.19.self_attn.v_proj.bias', 'model.layers.19.self_attn.v_proj.weight',\
    \ 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.k_proj.weight',\
    \ 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.q_proj.weight',\
    \ 'model.layers.2.self_attn.v_proj.bias', 'model.layers.2.self_attn.v_proj.weight',\
    \ 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.k_proj.weight',\
    \ 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.q_proj.weight',\
    \ 'model.layers.20.self_attn.v_proj.bias', 'model.layers.20.self_attn.v_proj.weight',\
    \ 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.k_proj.weight',\
    \ 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.weight',\
    \ 'model.layers.21.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.weight',\
    \ 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.k_proj.weight',\
    \ 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.q_proj.weight',\
    \ 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.v_proj.weight',\
    \ 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.k_proj.weight',\
    \ 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.q_proj.weight',\
    \ 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.v_proj.weight',\
    \ 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.k_proj.weight',\
    \ 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.q_proj.weight',\
    \ 'model.layers.24.self_attn.v_proj.bias', 'model.layers.24.self_attn.v_proj.weight',\
    \ 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.k_proj.weight',\
    \ 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.q_proj.weight',\
    \ 'model.layers.25.self_attn.v_proj.bias', 'model.layers.25.self_attn.v_proj.weight',\
    \ 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.k_proj.weight',\
    \ 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.weight',\
    \ 'model.layers.26.self_attn.v_proj.bias', 'model.layers.26.self_attn.v_proj.weight',\
    \ 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.k_proj.weight',\
    \ 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.weight',\
    \ 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.v_proj.weight',\
    \ 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.k_proj.weight',\
    \ 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.q_proj.weight',\
    \ 'model.layers.28.self_attn.v_proj.bias', 'model.layers.28.self_attn.v_proj.weight',\
    \ 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.weight',\
    \ 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.q_proj.weight',\
    \ 'model.layers.29.self_attn.v_proj.bias', 'model.layers.29.self_attn.v_proj.weight',\
    \ 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.k_proj.weight',\
    \ 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.q_proj.weight',\
    \ 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.v_proj.weight',\
    \ 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.k_proj.weight',\
    \ 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.q_proj.weight',\
    \ 'model.layers.30.self_attn.v_proj.bias', 'model.layers.30.self_attn.v_proj.weight',\
    \ 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.k_proj.weight',\
    \ 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.q_proj.weight',\
    \ 'model.layers.31.self_attn.v_proj.bias', 'model.layers.31.self_attn.v_proj.weight',\
    \ 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.k_proj.weight',\
    \ 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.weight',\
    \ 'model.layers.4.self_attn.v_proj.bias', 'model.layers.4.self_attn.v_proj.weight',\
    \ 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.k_proj.weight',\
    \ 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.q_proj.weight',\
    \ 'model.layers.5.self_attn.v_proj.bias', 'model.layers.5.self_attn.v_proj.weight',\
    \ 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.k_proj.weight',\
    \ 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.weight',\
    \ 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.v_proj.weight',\
    \ 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.k_proj.weight',\
    \ 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.q_proj.weight',\
    \ 'model.layers.7.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.weight',\
    \ 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.k_proj.weight',\
    \ 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.q_proj.weight',\
    \ 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.v_proj.weight',\
    \ 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.k_proj.weight',\
    \ 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.q_proj.weight',\
    \ 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.v_proj.weight']\r\
    \nYou should probably TRAIN this model on a down-stream task to be able to use\
    \ it for predictions and inference.\r\n```"
  created_at: 2024-01-12 22:03:43+00:00
  edited: false
  hidden: false
  id: 65a1b73f41b6ef119c012b18
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
      fullname: Susnato Dhar
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: susnato
      type: user
    createdAt: '2024-01-13T07:05:53.000Z'
    data:
      edited: true
      editors:
      - susnato
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8676283955574036
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
          fullname: Susnato Dhar
          isHf: false
          isPro: false
          name: susnato
          type: user
        html: "<p>Hi, <span data-props=\"{&quot;user&quot;:&quot;g-ronimo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/g-ronimo\"\
          >@<span class=\"underline\">g-ronimo</span></a></span>\n\n\t</span></span>,\
          \ yes because of the latest commit, the weights order is now changed to\
          \ seperate q,k,v layers instead of a concatenated qkv  layer. I will fix\
          \ this ASAP. :) </p>\n"
        raw: 'Hi, @g-ronimo, yes because of the latest commit, the weights order is
          now changed to seperate q,k,v layers instead of a concatenated qkv  layer.
          I will fix this ASAP. :) '
        updatedAt: '2024-01-15T16:52:42.030Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - g-ronimo
    id: 65a23651e8fe70d60ce5cc87
    type: comment
  author: susnato
  content: 'Hi, @g-ronimo, yes because of the latest commit, the weights order is
    now changed to seperate q,k,v layers instead of a concatenated qkv  layer. I will
    fix this ASAP. :) '
  created_at: 2024-01-13 07:05:53+00:00
  edited: true
  hidden: false
  id: 65a23651e8fe70d60ce5cc87
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
      fullname: Susnato Dhar
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: susnato
      type: user
    createdAt: '2024-01-15T16:56:37.000Z'
    data:
      edited: false
      editors:
      - susnato
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9720338582992554
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
          fullname: Susnato Dhar
          isHf: false
          isPro: false
          name: susnato
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;g-ronimo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/g-ronimo\"\
          >@<span class=\"underline\">g-ronimo</span></a></span>\n\n\t</span></span>,\
          \ I wasn't able to look into updating the weights but will try to do that\
          \ tomorrow, sorry for the delay.</p>\n"
        raw: Hi @g-ronimo, I wasn't able to look into updating the weights but will
          try to do that tomorrow, sorry for the delay.
        updatedAt: '2024-01-15T16:56:37.346Z'
      numEdits: 0
      reactions: []
    id: 65a563c54d251e93563f2cbd
    type: comment
  author: susnato
  content: Hi @g-ronimo, I wasn't able to look into updating the weights but will
    try to do that tomorrow, sorry for the delay.
  created_at: 2024-01-15 16:56:37+00:00
  edited: false
  hidden: false
  id: 65a563c54d251e93563f2cbd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da2a58c307ee5369b92d36/7xEgll8v5SxxcG_XF86tU.jpeg?w=200&h=200&f=face
      fullname: geronimo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g-ronimo
      type: user
    createdAt: '2024-01-15T20:23:33.000Z'
    data:
      edited: false
      editors:
      - g-ronimo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9270998239517212
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da2a58c307ee5369b92d36/7xEgll8v5SxxcG_XF86tU.jpeg?w=200&h=200&f=face
          fullname: geronimo
          isHf: false
          isPro: false
          name: g-ronimo
          type: user
        html: "<p>i'm just glad you're on it \U0001F44D thank you</p>\n"
        raw: "i'm just glad you're on it \U0001F44D thank you"
        updatedAt: '2024-01-15T20:23:33.090Z'
      numEdits: 0
      reactions: []
    id: 65a59445ee7aa779f591c8f8
    type: comment
  author: g-ronimo
  content: "i'm just glad you're on it \U0001F44D thank you"
  created_at: 2024-01-15 20:23:33+00:00
  edited: false
  hidden: false
  id: 65a59445ee7aa779f591c8f8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1ef00b312d2b009c8c7aab21b4b3f258.svg
      fullname: guiminghardychen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g-h-chen
      type: user
    createdAt: '2024-01-21T02:07:18.000Z'
    data:
      edited: false
      editors:
      - g-h-chen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9585863351821899
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1ef00b312d2b009c8c7aab21b4b3f258.svg
          fullname: guiminghardychen
          isHf: false
          isPro: false
          name: g-h-chen
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;susnato&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/susnato\">@<span class=\"\
          underline\">susnato</span></a></span>\n\n\t</span></span> hii dude, has\
          \ the bug been fixed?</p>\n"
        raw: '@susnato hii dude, has the bug been fixed?

          '
        updatedAt: '2024-01-21T02:07:18.785Z'
      numEdits: 0
      reactions: []
    id: 65ac7c56dd55025184c821b8
    type: comment
  author: g-h-chen
  content: '@susnato hii dude, has the bug been fixed?

    '
  created_at: 2024-01-21 02:07:18+00:00
  edited: false
  hidden: false
  id: 65ac7c56dd55025184c821b8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
      fullname: Susnato Dhar
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: susnato
      type: user
    createdAt: '2024-01-21T10:33:32.000Z'
    data:
      edited: false
      editors:
      - susnato
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8981151580810547
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
          fullname: Susnato Dhar
          isHf: false
          isPro: false
          name: susnato
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;g-ronimo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/g-ronimo\"\
          >@<span class=\"underline\">g-ronimo</span></a></span>\n\n\t</span></span>,\
          \ <span data-props=\"{&quot;user&quot;:&quot;g-h-chen&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/g-h-chen\">@<span class=\"\
          underline\">g-h-chen</span></a></span>\n\n\t</span></span>, I apologise\
          \ for the huge delay.<br>I have updated the checkpoint and it should work\
          \ now. Please install the latest <code>transformers</code> version <code>4.38.0.dev0</code>\
          \ by running this command - </p>\n<pre><code class=\"language-bash\">pip\
          \ uninstall -y transformers &amp;&amp; pip install git+https://github.com/huggingface/transformers\n\
          </code></pre>\n<p>After updating the library, it should work as expected.</p>\n\
          <p>Please let me know if you are facing any issues with it.</p>\n"
        raw: "Hi @g-ronimo, @g-h-chen, I apologise for the huge delay.\nI have updated\
          \ the checkpoint and it should work now. Please install the latest `transformers`\
          \ version `4.38.0.dev0` by running this command - \n\n```bash\npip uninstall\
          \ -y transformers && pip install git+https://github.com/huggingface/transformers\n\
          ```\n\nAfter updating the library, it should work as expected.\n\nPlease\
          \ let me know if you are facing any issues with it."
        updatedAt: '2024-01-21T10:33:32.126Z'
      numEdits: 0
      reactions: []
    id: 65acf2fca92a64ef5b21382a
    type: comment
  author: susnato
  content: "Hi @g-ronimo, @g-h-chen, I apologise for the huge delay.\nI have updated\
    \ the checkpoint and it should work now. Please install the latest `transformers`\
    \ version `4.38.0.dev0` by running this command - \n\n```bash\npip uninstall -y\
    \ transformers && pip install git+https://github.com/huggingface/transformers\n\
    ```\n\nAfter updating the library, it should work as expected.\n\nPlease let me\
    \ know if you are facing any issues with it."
  created_at: 2024-01-21 10:33:32+00:00
  edited: false
  hidden: false
  id: 65acf2fca92a64ef5b21382a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da2a58c307ee5369b92d36/7xEgll8v5SxxcG_XF86tU.jpeg?w=200&h=200&f=face
      fullname: geronimo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g-ronimo
      type: user
    createdAt: '2024-01-21T20:01:57.000Z'
    data:
      edited: false
      editors:
      - g-ronimo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8571894764900208
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da2a58c307ee5369b92d36/7xEgll8v5SxxcG_XF86tU.jpeg?w=200&h=200&f=face
          fullname: geronimo
          isHf: false
          isPro: false
          name: g-ronimo
          type: user
        html: "<p>works! \U0001F44C thank you</p>\n"
        raw: "works! \U0001F44C thank you"
        updatedAt: '2024-01-21T20:01:57.653Z'
      numEdits: 0
      reactions: []
    id: 65ad78352ed95c799fffb259
    type: comment
  author: g-ronimo
  content: "works! \U0001F44C thank you"
  created_at: 2024-01-21 20:01:57+00:00
  edited: false
  hidden: false
  id: 65ad78352ed95c799fffb259
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
      fullname: Susnato Dhar
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: susnato
      type: user
    createdAt: '2024-01-22T13:17:28.000Z'
    data:
      edited: false
      editors:
      - susnato
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9480281472206116
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
          fullname: Susnato Dhar
          isHf: false
          isPro: false
          name: susnato
          type: user
        html: "<p>Thanks a lot <span data-props=\"{&quot;user&quot;:&quot;g-ronimo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/g-ronimo\"\
          >@<span class=\"underline\">g-ronimo</span></a></span>\n\n\t</span></span>\
          \ for the feedback! closing the issue since it is fixed. </p>\n"
        raw: 'Thanks a lot @g-ronimo for the feedback! closing the issue since it
          is fixed. '
        updatedAt: '2024-01-22T13:17:28.236Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65ae6ae8bff3ae9f331de8a3
    id: 65ae6ae8bff3ae9f331de89e
    type: comment
  author: susnato
  content: 'Thanks a lot @g-ronimo for the feedback! closing the issue since it is
    fixed. '
  created_at: 2024-01-22 13:17:28+00:00
  edited: false
  hidden: false
  id: 65ae6ae8bff3ae9f331de89e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
      fullname: Susnato Dhar
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: susnato
      type: user
    createdAt: '2024-01-22T13:17:28.000Z'
    data:
      status: closed
    id: 65ae6ae8bff3ae9f331de8a3
    type: status-change
  author: susnato
  created_at: 2024-01-22 13:17:28+00:00
  id: 65ae6ae8bff3ae9f331de8a3
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da2a58c307ee5369b92d36/7xEgll8v5SxxcG_XF86tU.jpeg?w=200&h=200&f=face
      fullname: geronimo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: g-ronimo
      type: user
    createdAt: '2024-01-22T14:23:43.000Z'
    data:
      edited: false
      editors:
      - g-ronimo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8850511908531189
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64da2a58c307ee5369b92d36/7xEgll8v5SxxcG_XF86tU.jpeg?w=200&h=200&f=face
          fullname: geronimo
          isHf: false
          isPro: false
          name: g-ronimo
          type: user
        html: '<p>thank you! one last stupid question, what''s the difference now
          between your model and <code>microsoft/phi-2</code> ?<br>Is it that we can
          load <code>microsoft/phi-2</code> only with <code>trust_remote_code=True</code>
          while yours works with the HF modeling files?</p>

          '
        raw: "thank you! one last stupid question, what's the difference now between\
          \ your model and ```microsoft/phi-2``` ? \nIs it that we can load ```microsoft/phi-2```\
          \ only with ```trust_remote_code=True``` while yours works with the HF modeling\
          \ files?"
        updatedAt: '2024-01-22T14:23:43.277Z'
      numEdits: 0
      reactions: []
    id: 65ae7a6fa134c07dde4c1afc
    type: comment
  author: g-ronimo
  content: "thank you! one last stupid question, what's the difference now between\
    \ your model and ```microsoft/phi-2``` ? \nIs it that we can load ```microsoft/phi-2```\
    \ only with ```trust_remote_code=True``` while yours works with the HF modeling\
    \ files?"
  created_at: 2024-01-22 14:23:43+00:00
  edited: false
  hidden: false
  id: 65ae7a6fa134c07dde4c1afc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
      fullname: Susnato Dhar
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: susnato
      type: user
    createdAt: '2024-01-22T14:34:06.000Z'
    data:
      edited: false
      editors:
      - susnato
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9591591358184814
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
          fullname: Susnato Dhar
          isHf: false
          isPro: false
          name: susnato
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;g-ronimo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/g-ronimo\"\
          >@<span class=\"underline\">g-ronimo</span></a></span>\n\n\t</span></span>\
          \ , If you load the latest commit from <code>microsoft/phi-2</code> now,\
          \ then it's the same. So, you can use any of these.</p>\n<p>Actually some\
          \ months ago I contributed <code>phi</code> (1 and 1.5) to HF transformers\
          \ library so Arthur told me to also add <code>phi-2</code> (mainly to reorder\
          \ the weights, update configs and add tests) and upload the updated weights\
          \ here so that anyone who wants to use <code>phi-2</code> with the library\
          \ model can use it along with all the features that come with the library.<br>So,\
          \ I did that and now we have successfully transferred the weights to microsoft/phi-2\
          \ and these repos are same now. It was a temporary fix.</p>\n"
        raw: 'Hi @g-ronimo , If you load the latest commit from `microsoft/phi-2`
          now, then it''s the same. So, you can use any of these.


          Actually some months ago I contributed `phi` (1 and 1.5) to HF transformers
          library so Arthur told me to also add `phi-2` (mainly to reorder the weights,
          update configs and add tests) and upload the updated weights here so that
          anyone who wants to use `phi-2` with the library model can use it along
          with all the features that come with the library.

          So, I did that and now we have successfully transferred the weights to microsoft/phi-2
          and these repos are same now. It was a temporary fix.'
        updatedAt: '2024-01-22T14:34:06.906Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - g-ronimo
    id: 65ae7cde01b6f61e241708f8
    type: comment
  author: susnato
  content: 'Hi @g-ronimo , If you load the latest commit from `microsoft/phi-2` now,
    then it''s the same. So, you can use any of these.


    Actually some months ago I contributed `phi` (1 and 1.5) to HF transformers library
    so Arthur told me to also add `phi-2` (mainly to reorder the weights, update configs
    and add tests) and upload the updated weights here so that anyone who wants to
    use `phi-2` with the library model can use it along with all the features that
    come with the library.

    So, I did that and now we have successfully transferred the weights to microsoft/phi-2
    and these repos are same now. It was a temporary fix.'
  created_at: 2024-01-22 14:34:06+00:00
  edited: false
  hidden: false
  id: 65ae7cde01b6f61e241708f8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
      fullname: Susnato Dhar
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: susnato
      type: user
    createdAt: '2024-01-22T14:34:51.000Z'
    data:
      edited: false
      editors:
      - susnato
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9722749590873718
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1e6f6d78aa1e72c5eb39cbfe5da896cb.svg
          fullname: Susnato Dhar
          isHf: false
          isPro: false
          name: susnato
          type: user
        html: "<p>Feel free to ask any question \U0001F917, I will try to answer them\
          \ according to my knowledge.</p>\n"
        raw: "Feel free to ask any question \U0001F917, I will try to answer them\
          \ according to my knowledge."
        updatedAt: '2024-01-22T14:34:51.802Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - g-ronimo
    id: 65ae7d0b77ce425d18dd61cd
    type: comment
  author: susnato
  content: "Feel free to ask any question \U0001F917, I will try to answer them according\
    \ to my knowledge."
  created_at: 2024-01-22 14:34:51+00:00
  edited: false
  hidden: false
  id: 65ae7d0b77ce425d18dd61cd
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: susnato/phi-2
repo_type: model
status: closed
target_branch: null
title: Some weights of the model checkpoint at susnato/phi-2 were not used when initializing
  PhiForCausalLM
