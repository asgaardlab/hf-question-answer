!!python/object:huggingface_hub.community.DiscussionWithDetails
author: intervitens
conflicting_files: null
created_at: 2024-01-17 00:41:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/73152716fc35874255eadb5ef237aae2.svg
      fullname: intervitens
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: intervitens
      type: user
    createdAt: '2024-01-17T00:41:02.000Z'
    data:
      edited: false
      editors:
      - intervitens
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7055554389953613
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/73152716fc35874255eadb5ef237aae2.svg
          fullname: intervitens
          isHf: false
          isPro: false
          name: intervitens
          type: user
        html: '<p>This model causes a crash when the input includes "&lt;|im_end|&gt;"
          or "&lt;|im_start|&gt;" tokens.</p>

          <ol>

          <li>Nous-mixtral model added two new tokens for the ChatML format, expanding
          the model''s vocab_size and the input embeddings tensor dimension by two,
          from 32000 to 32002.</li>

          <li>This model copied the tokenizer files from the Nous model, but the actual
          input embeddings are still vanilla size, so when you use those tokens in
          the prompt, you get a "index out of range" error<br>To fix, replace the
          tokenizer.json and tokenizer_config.json files with the ones from the base
          Mixtral and delete added_tokens.json file.</li>

          </ol>

          '
        raw: "This model causes a crash when the input includes \"<|im_end|>\" or\
          \ \"<|im_start|>\" tokens.\r\n1. Nous-mixtral model added two new tokens\
          \ for the ChatML format, expanding the model's vocab_size and the input\
          \ embeddings tensor dimension by two, from 32000 to 32002.\r\n2. This model\
          \ copied the tokenizer files from the Nous model, but the actual input embeddings\
          \ are still vanilla size, so when you use those tokens in the prompt, you\
          \ get a \"index out of range\" error\r\nTo fix, replace the tokenizer.json\
          \ and tokenizer_config.json files with the ones from the base Mixtral and\
          \ delete added_tokens.json file."
        updatedAt: '2024-01-17T00:41:02.200Z'
      numEdits: 0
      reactions: []
    id: 65a7221e293f73160de21b59
    type: comment
  author: intervitens
  content: "This model causes a crash when the input includes \"<|im_end|>\" or \"\
    <|im_start|>\" tokens.\r\n1. Nous-mixtral model added two new tokens for the ChatML\
    \ format, expanding the model's vocab_size and the input embeddings tensor dimension\
    \ by two, from 32000 to 32002.\r\n2. This model copied the tokenizer files from\
    \ the Nous model, but the actual input embeddings are still vanilla size, so when\
    \ you use those tokens in the prompt, you get a \"index out of range\" error\r\
    \nTo fix, replace the tokenizer.json and tokenizer_config.json files with the\
    \ ones from the base Mixtral and delete added_tokens.json file."
  created_at: 2024-01-17 00:41:02+00:00
  edited: false
  hidden: false
  id: 65a7221e293f73160de21b59
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1ff790eb151c7eb65abf7034ad1f7b76.svg
      fullname: Del Leet
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Envoid
      type: user
    createdAt: '2024-01-17T05:20:24.000Z'
    data:
      edited: false
      editors:
      - Envoid
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9583501219749451
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1ff790eb151c7eb65abf7034ad1f7b76.svg
          fullname: Del Leet
          isHf: false
          isPro: false
          name: Envoid
          type: user
        html: '<p>Thanks for the heads up! I have made the change you suggested and
          hopefully this fixes the crash.  (Due to hardware constraints I have to
          convert everything to .gguf to use it and can''t actually test the HF/FP16
          version properly).</p>

          '
        raw: Thanks for the heads up! I have made the change you suggested and hopefully
          this fixes the crash.  (Due to hardware constraints I have to convert everything
          to .gguf to use it and can't actually test the HF/FP16 version properly).
        updatedAt: '2024-01-17T05:20:24.577Z'
      numEdits: 0
      reactions: []
    id: 65a763983d3c839408210c15
    type: comment
  author: Envoid
  content: Thanks for the heads up! I have made the change you suggested and hopefully
    this fixes the crash.  (Due to hardware constraints I have to convert everything
    to .gguf to use it and can't actually test the HF/FP16 version properly).
  created_at: 2024-01-17 05:20:24+00:00
  edited: false
  hidden: false
  id: 65a763983d3c839408210c15
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2024-01-25T09:57:21.000Z'
    data:
      edited: true
      editors:
      - TheYuriLover
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6796635389328003
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: '<p>Something is still wrong with this model config, I can''t use the
          grammar feature because of it:<br><a rel="nofollow" href="https://github.com/oobabooga/text-generation-webui/issues/5369">https://github.com/oobabooga/text-generation-webui/issues/5369</a></p>

          <p>I used this quant, maybe the problem is there?<br><a href="https://huggingface.co/Artefact2/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-GGUF/blob/main/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-Q5_K_S.gguf">https://huggingface.co/Artefact2/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-GGUF/blob/main/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-Q5_K_S.gguf</a></p>

          <p>Edit: I also tried with this quant (that doesn''t use iMatrix) and the
          problem persists<br><a href="https://huggingface.co/Envoid/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-GGUF/blob/main/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-q6_K.gguf">https://huggingface.co/Envoid/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-GGUF/blob/main/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-q6_K.gguf</a></p>

          '
        raw: 'Something is still wrong with this model config, I can''t use the grammar
          feature because of it:

          [https://github.com/oobabooga/text-generation-webui/issues/5369](https://github.com/oobabooga/text-generation-webui/issues/5369)


          I used this quant, maybe the problem is there?

          https://huggingface.co/Artefact2/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-GGUF/blob/main/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-Q5_K_S.gguf


          Edit: I also tried with this quant (that doesn''t use iMatrix) and the problem
          persists

          https://huggingface.co/Envoid/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-GGUF/blob/main/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-q6_K.gguf'
        updatedAt: '2024-01-25T11:18:27.231Z'
      numEdits: 2
      reactions: []
    id: 65b23081f32c79fea744561c
    type: comment
  author: TheYuriLover
  content: 'Something is still wrong with this model config, I can''t use the grammar
    feature because of it:

    [https://github.com/oobabooga/text-generation-webui/issues/5369](https://github.com/oobabooga/text-generation-webui/issues/5369)


    I used this quant, maybe the problem is there?

    https://huggingface.co/Artefact2/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-GGUF/blob/main/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-Q5_K_S.gguf


    Edit: I also tried with this quant (that doesn''t use iMatrix) and the problem
    persists

    https://huggingface.co/Envoid/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-GGUF/blob/main/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B-q6_K.gguf'
  created_at: 2024-01-25 09:57:21+00:00
  edited: true
  hidden: false
  id: 65b23081f32c79fea744561c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Envoid/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B
repo_type: model
status: open
target_branch: null
title: Issue with the tokenizer
