!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pabloce
conflicting_files: null
created_at: 2024-01-08 01:22:30+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641d161921964f8f6d4a20f9/91wraye7NHAFJTVwotEDN.png?w=200&h=200&f=face
      fullname: Pablo Carrera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pabloce
      type: user
    createdAt: '2024-01-08T01:22:30.000Z'
    data:
      edited: false
      editors:
      - pabloce
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9153928160667419
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641d161921964f8f6d4a20f9/91wraye7NHAFJTVwotEDN.png?w=200&h=200&f=face
          fullname: Pablo Carrera
          isHf: false
          isPro: false
          name: pabloce
          type: user
        html: '<p>sorry the noob question but <code>ggml-model-f16.gguf</code> is
          better than quants can you explain me the advantage?</p>

          '
        raw: sorry the noob question but `ggml-model-f16.gguf` is better than quants
          can you explain me the advantage?
        updatedAt: '2024-01-08T01:22:30.649Z'
      numEdits: 0
      reactions: []
    id: 659b4e562e1d57d594e808b7
    type: comment
  author: pabloce
  content: sorry the noob question but `ggml-model-f16.gguf` is better than quants
    can you explain me the advantage?
  created_at: 2024-01-08 01:22:30+00:00
  edited: false
  hidden: false
  id: 659b4e562e1d57d594e808b7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a6a5bde4a2ea6ffd1a7552e6821615af.svg
      fullname: Rob
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: kroonen
      type: user
    createdAt: '2024-01-09T01:49:09.000Z'
    data:
      edited: false
      editors:
      - kroonen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9306249022483826
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a6a5bde4a2ea6ffd1a7552e6821615af.svg
          fullname: Rob
          isHf: false
          isPro: false
          name: kroonen
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;pabloce&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/pabloce\">@<span class=\"\
          underline\">pabloce</span></a></span>\n\n\t</span></span> yes, the '16 Floating\
          \ Point' means the model uses 16 bits for each number. It's more precise\
          \ than models with fewer bits, like 8-bit or 4-bit. As the bit count goes\
          \ down, the precision decreases, but the models become faster and use less\
          \ memory.</p>\n"
        raw: '@pabloce yes, the ''16 Floating Point'' means the model uses 16 bits
          for each number. It''s more precise than models with fewer bits, like 8-bit
          or 4-bit. As the bit count goes down, the precision decreases, but the models
          become faster and use less memory.'
        updatedAt: '2024-01-09T01:49:09.213Z'
      numEdits: 0
      reactions: []
    id: 659ca615bc65f1e59df83e06
    type: comment
  author: kroonen
  content: '@pabloce yes, the ''16 Floating Point'' means the model uses 16 bits for
    each number. It''s more precise than models with fewer bits, like 8-bit or 4-bit.
    As the bit count goes down, the precision decreases, but the models become faster
    and use less memory.'
  created_at: 2024-01-09 01:49:09+00:00
  edited: false
  hidden: false
  id: 659ca615bc65f1e59df83e06
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641d161921964f8f6d4a20f9/91wraye7NHAFJTVwotEDN.png?w=200&h=200&f=face
      fullname: Pablo Carrera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pabloce
      type: user
    createdAt: '2024-01-10T16:10:34.000Z'
    data:
      edited: false
      editors:
      - pabloce
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8148284554481506
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641d161921964f8f6d4a20f9/91wraye7NHAFJTVwotEDN.png?w=200&h=200&f=face
          fullname: Pablo Carrera
          isHf: false
          isPro: false
          name: pabloce
          type: user
        html: '<p>Love it already test it :)<br>Thanks</p>

          '
        raw: 'Love it already test it :)

          Thanks'
        updatedAt: '2024-01-10T16:10:34.369Z'
      numEdits: 0
      reactions: []
      relatedEventId: 659ec17abdcf4de474fdcfef
    id: 659ec17abdcf4de474fdcfe8
    type: comment
  author: pabloce
  content: 'Love it already test it :)

    Thanks'
  created_at: 2024-01-10 16:10:34+00:00
  edited: false
  hidden: false
  id: 659ec17abdcf4de474fdcfe8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/641d161921964f8f6d4a20f9/91wraye7NHAFJTVwotEDN.png?w=200&h=200&f=face
      fullname: Pablo Carrera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pabloce
      type: user
    createdAt: '2024-01-10T16:10:34.000Z'
    data:
      status: closed
    id: 659ec17abdcf4de474fdcfef
    type: status-change
  author: pabloce
  created_at: 2024-01-10 16:10:34+00:00
  id: 659ec17abdcf4de474fdcfef
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: kroonen/dolphin-2.6-mistral-7b-dpo-laser-GGUF
repo_type: model
status: closed
target_branch: null
title: ggml-model-f16.gguf
