!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Kerlion
conflicting_files: null
created_at: 2023-10-10 00:07:42+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/65b559ed5228ca6c9e4c6feb7ca0c84d.svg
      fullname: Kerlion He
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kerlion
      type: user
    createdAt: '2023-10-10T01:07:42.000Z'
    data:
      edited: false
      editors:
      - Kerlion
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.37681230902671814
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/65b559ed5228ca6c9e4c6feb7ca0c84d.svg
          fullname: Kerlion He
          isHf: false
          isPro: false
          name: Kerlion
          type: user
        html: '<p> conda list cuda-toolkit<br>cuda-toolkit              11.8.0                        0    nvidia/label/cuda-11.8.0</p>

          <p>llama_cpp_python  0.2.11 with LLAMA_CUBLAS=1</p>

          <p>Python</p>

          <blockquote>

          <blockquote>

          <blockquote>

          <p>from llama_cpp import Llama<br>llm = Llama(model_path="/opt/AI/LLM/Llama-2-7B-GGUF",
          n_ctx=2048)<br>ggml_init_cublas: found 1 CUDA devices:<br>  Device 0: NVIDIA
          RTXA6000-48Q, compute capability 8.6<br>gguf_init_from_file: invalid magic
          number 00000000<br>error loading model: llama_model_loader: failed to load
          model from /opt/AI/LLM/Llama-2-7B-GGUF</p>

          </blockquote>

          </blockquote>

          </blockquote>

          <p>llama_load_model_from_file: failed to load model<br>Traceback (most recent
          call last):<br>  File "", line 1, in <br>  File "/opt/AI/anaconda3/envs/test/lib/python3.11/site-packages/llama_cpp/llama.py",
          line 365, in <strong>init</strong><br>    assert self.model is not None<br>           ^^^^^^^^^^^^^^^^^^^^^^<br>AssertionError</p>

          <blockquote>

          <blockquote>

          <blockquote>

          <p>llm = Llama(model_path="/opt/AI/LLM/Llama-2-7B-GGUF")<br>gguf_init_from_file:
          invalid magic number 00000000<br>error loading model: llama_model_loader:
          failed to load model from /opt/AI/LLM/Llama-2-7B-GGUF</p>

          </blockquote>

          </blockquote>

          </blockquote>

          <p>llama_load_model_from_file: failed to load model<br>Traceback (most recent
          call last):<br>  File "", line 1, in <br>  File "/opt/AI/anaconda3/envs/test/lib/python3.11/site-packages/llama_cpp/llama.py",
          line 365, in <strong>init</strong><br>    assert self.model is not None<br>           ^^^^^^^^^^^^^^^^^^^^^^<br>AssertionError</p>

          '
        raw: " conda list cuda-toolkit\r\ncuda-toolkit              11.8.0       \
          \                 0    nvidia/label/cuda-11.8.0\r\n\r\nllama_cpp_python\
          \  0.2.11 with LLAMA_CUBLAS=1\r\n\r\nPython\r\n>>> from llama_cpp import\
          \ Llama\r\n>>> llm = Llama(model_path=\"/opt/AI/LLM/Llama-2-7B-GGUF\", n_ctx=2048)\r\
          \nggml_init_cublas: found 1 CUDA devices:\r\n  Device 0: NVIDIA RTXA6000-48Q,\
          \ compute capability 8.6\r\ngguf_init_from_file: invalid magic number 00000000\r\
          \nerror loading model: llama_model_loader: failed to load model from /opt/AI/LLM/Llama-2-7B-GGUF\r\
          \n\r\nllama_load_model_from_file: failed to load model\r\nTraceback (most\
          \ recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File\
          \ \"/opt/AI/anaconda3/envs/test/lib/python3.11/site-packages/llama_cpp/llama.py\"\
          , line 365, in __init__\r\n    assert self.model is not None\r\n       \
          \    ^^^^^^^^^^^^^^^^^^^^^^\r\nAssertionError\r\n>>> llm = Llama(model_path=\"\
          /opt/AI/LLM/Llama-2-7B-GGUF\")\r\ngguf_init_from_file: invalid magic number\
          \ 00000000\r\nerror loading model: llama_model_loader: failed to load model\
          \ from /opt/AI/LLM/Llama-2-7B-GGUF\r\n\r\nllama_load_model_from_file: failed\
          \ to load model\r\nTraceback (most recent call last):\r\n  File \"<stdin>\"\
          , line 1, in <module>\r\n  File \"/opt/AI/anaconda3/envs/test/lib/python3.11/site-packages/llama_cpp/llama.py\"\
          , line 365, in __init__\r\n    assert self.model is not None\r\n       \
          \    ^^^^^^^^^^^^^^^^^^^^^^\r\nAssertionError\r\n\r\n"
        updatedAt: '2023-10-10T01:07:42.043Z'
      numEdits: 0
      reactions: []
    id: 6524a3dec2d93460839d642c
    type: comment
  author: Kerlion
  content: " conda list cuda-toolkit\r\ncuda-toolkit              11.8.0         \
    \               0    nvidia/label/cuda-11.8.0\r\n\r\nllama_cpp_python  0.2.11\
    \ with LLAMA_CUBLAS=1\r\n\r\nPython\r\n>>> from llama_cpp import Llama\r\n>>>\
    \ llm = Llama(model_path=\"/opt/AI/LLM/Llama-2-7B-GGUF\", n_ctx=2048)\r\nggml_init_cublas:\
    \ found 1 CUDA devices:\r\n  Device 0: NVIDIA RTXA6000-48Q, compute capability\
    \ 8.6\r\ngguf_init_from_file: invalid magic number 00000000\r\nerror loading model:\
    \ llama_model_loader: failed to load model from /opt/AI/LLM/Llama-2-7B-GGUF\r\n\
    \r\nllama_load_model_from_file: failed to load model\r\nTraceback (most recent\
    \ call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/opt/AI/anaconda3/envs/test/lib/python3.11/site-packages/llama_cpp/llama.py\"\
    , line 365, in __init__\r\n    assert self.model is not None\r\n           ^^^^^^^^^^^^^^^^^^^^^^\r\
    \nAssertionError\r\n>>> llm = Llama(model_path=\"/opt/AI/LLM/Llama-2-7B-GGUF\"\
    )\r\ngguf_init_from_file: invalid magic number 00000000\r\nerror loading model:\
    \ llama_model_loader: failed to load model from /opt/AI/LLM/Llama-2-7B-GGUF\r\n\
    \r\nllama_load_model_from_file: failed to load model\r\nTraceback (most recent\
    \ call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/opt/AI/anaconda3/envs/test/lib/python3.11/site-packages/llama_cpp/llama.py\"\
    , line 365, in __init__\r\n    assert self.model is not None\r\n           ^^^^^^^^^^^^^^^^^^^^^^\r\
    \nAssertionError\r\n\r\n"
  created_at: 2023-10-10 00:07:42+00:00
  edited: false
  hidden: false
  id: 6524a3dec2d93460839d642c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4d7c61024308b4dc2fddeb454e70145a.svg
      fullname: vigneshwaran
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vignesh150
      type: user
    createdAt: '2023-11-14T09:15:12.000Z'
    data:
      edited: false
      editors:
      - vignesh150
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9872976541519165
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4d7c61024308b4dc2fddeb454e70145a.svg
          fullname: vigneshwaran
          isHf: false
          isPro: false
          name: vignesh150
          type: user
        html: '<p>I am also facing same issue does any one found resolution for this?</p>

          '
        raw: I am also facing same issue does any one found resolution for this?
        updatedAt: '2023-11-14T09:15:12.813Z'
      numEdits: 0
      reactions: []
    id: 65533aa04cb336b5fe678733
    type: comment
  author: vignesh150
  content: I am also facing same issue does any one found resolution for this?
  created_at: 2023-11-14 09:15:12+00:00
  edited: false
  hidden: false
  id: 65533aa04cb336b5fe678733
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: TheBloke/Llama-2-7B-Chat-GGUF
repo_type: model
status: open
target_branch: null
title: 'error loading model: GGUF with latest llama_cpp_python  0.2.11'
