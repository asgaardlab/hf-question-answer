!!python/object:huggingface_hub.community.DiscussionWithDetails
author: pootow
conflicting_files: null
created_at: 2023-12-01 16:32:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
      fullname: Richard Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pootow
      type: user
    createdAt: '2023-12-01T16:32:58.000Z'
    data:
      edited: false
      editors:
      - pootow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9006038904190063
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
          fullname: Richard Zhang
          isHf: false
          isPro: false
          name: pootow
          type: user
        html: '<p>I am using <code>text-generation-webui</code> to test this model.
          whatever the <code>temperature</code>, <code>top_p</code>, etc. etc. is
          tuned, the model just gives repeated gibberish output after few "normal"
          words.</p>

          <p>why would it be? any suggestions?</p>

          '
        raw: "I am using `text-generation-webui` to test this model. whatever the\
          \ `temperature`, `top_p`, etc. etc. is tuned, the model just gives repeated\
          \ gibberish output after few \"normal\" words.\r\n\r\nwhy would it be? any\
          \ suggestions?"
        updatedAt: '2023-12-01T16:32:58.440Z'
      numEdits: 0
      reactions: []
    id: 656a0abac56388a98585255b
    type: comment
  author: pootow
  content: "I am using `text-generation-webui` to test this model. whatever the `temperature`,\
    \ `top_p`, etc. etc. is tuned, the model just gives repeated gibberish output\
    \ after few \"normal\" words.\r\n\r\nwhy would it be? any suggestions?"
  created_at: 2023-12-01 16:32:58+00:00
  edited: false
  hidden: false
  id: 656a0abac56388a98585255b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-12-01T17:07:38.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9157739281654358
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>Try a different prompt? I have found a lot of models dont work right
          with the ''suggested'' prompts.  I have the best luck with VIcuna1.1 even
          when it says use something like llama .  </p>

          '
        raw: 'Try a different prompt? I have found a lot of models dont work right
          with the ''suggested'' prompts.  I have the best luck with VIcuna1.1 even
          when it says use something like llama .  '
        updatedAt: '2023-12-01T17:07:38.825Z'
      numEdits: 0
      reactions: []
    id: 656a12daaf6d3c4129dafa7f
    type: comment
  author: Nurb432
  content: 'Try a different prompt? I have found a lot of models dont work right with
    the ''suggested'' prompts.  I have the best luck with VIcuna1.1 even when it says
    use something like llama .  '
  created_at: 2023-12-01 17:07:38+00:00
  edited: false
  hidden: false
  id: 656a12daaf6d3c4129dafa7f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
      fullname: Richard Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pootow
      type: user
    createdAt: '2023-12-02T15:02:31.000Z'
    data:
      edited: false
      editors:
      - pootow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9633580446243286
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
          fullname: Richard Zhang
          isHf: false
          isPro: false
          name: pootow
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Nurb432&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Nurb432\">@<span class=\"\
          underline\">Nurb432</span></a></span>\n\n\t</span></span> thanks for your\
          \ suggestion. It is not the problem of the prompt, I downloaded the GPTQ\
          \ version, and all things are back to normal and even the inference speed\
          \ is getting up.</p>\n"
        raw: '@Nurb432 thanks for your suggestion. It is not the problem of the prompt,
          I downloaded the GPTQ version, and all things are back to normal and even
          the inference speed is getting up.'
        updatedAt: '2023-12-02T15:02:31.537Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Nurb432
    id: 656b47073dbac3a83ddf1986
    type: comment
  author: pootow
  content: '@Nurb432 thanks for your suggestion. It is not the problem of the prompt,
    I downloaded the GPTQ version, and all things are back to normal and even the
    inference speed is getting up.'
  created_at: 2023-12-02 15:02:31+00:00
  edited: false
  hidden: false
  id: 656b47073dbac3a83ddf1986
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
      fullname: Richard Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pootow
      type: user
    createdAt: '2023-12-02T16:12:10.000Z'
    data:
      edited: false
      editors:
      - pootow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8416637778282166
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
          fullname: Richard Zhang
          isHf: false
          isPro: false
          name: pootow
          type: user
        html: '<p>I find the problem, I should not load the model using AutoAWQ loader,
          but use huggingface transformer loader, evething is just fine.</p>

          '
        raw: I find the problem, I should not load the model using AutoAWQ loader,
          but use huggingface transformer loader, evething is just fine.
        updatedAt: '2023-12-02T16:12:10.633Z'
      numEdits: 0
      reactions: []
      relatedEventId: 656b575a1812378141554386
    id: 656b575a1812378141554384
    type: comment
  author: pootow
  content: I find the problem, I should not load the model using AutoAWQ loader, but
    use huggingface transformer loader, evething is just fine.
  created_at: 2023-12-02 16:12:10+00:00
  edited: false
  hidden: false
  id: 656b575a1812378141554384
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/6454d56be2c15909e5c42c5ecfbfb0d9.svg
      fullname: Richard Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: pootow
      type: user
    createdAt: '2023-12-02T16:12:10.000Z'
    data:
      status: closed
    id: 656b575a1812378141554386
    type: status-change
  author: pootow
  created_at: 2023-12-02 16:12:10+00:00
  id: 656b575a1812378141554386
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/Phind-CodeLlama-34B-v2-AWQ
repo_type: model
status: closed
target_branch: null
title: I get repeated gibberish output all the time.
