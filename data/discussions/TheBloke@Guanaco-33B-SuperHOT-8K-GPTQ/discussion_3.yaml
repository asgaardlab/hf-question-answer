!!python/object:huggingface_hub.community.DiscussionWithDetails
author: andrews-llms
conflicting_files: null
created_at: 2023-09-21 08:38:43+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/22994ba4a50794c6e835fa63a24b4ae3.svg
      fullname: Fabio espinosa
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andrews-llms
      type: user
    createdAt: '2023-09-21T09:38:43.000Z'
    data:
      edited: false
      editors:
      - andrews-llms
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6740788221359253
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/22994ba4a50794c6e835fa63a24b4ae3.svg
          fullname: Fabio espinosa
          isHf: false
          isPro: false
          name: andrews-llms
          type: user
        html: '<p>Hi all, this model is producing the following error when using <code>AutoTokenizer.from_pretrained</code>:</p>

          <p>RecursionError: maximum recursion depth exceeded while calling a Python
          object</p>

          <p>I think this might be related to transformers or tokenizers<br>I am using
          tranformers==4.33.1<br>and tokenizers==0.13.3</p>

          '
        raw: "Hi all, this model is producing the following error when using `AutoTokenizer.from_pretrained`:\r\
          \n\r\nRecursionError: maximum recursion depth exceeded while calling a Python\
          \ object\r\n\r\nI think this might be related to transformers or tokenizers\r\
          \nI am using tranformers==4.33.1\r\nand tokenizers==0.13.3"
        updatedAt: '2023-09-21T09:38:43.858Z'
      numEdits: 0
      reactions: []
    id: 650c0f23bffe40057366bc41
    type: comment
  author: andrews-llms
  content: "Hi all, this model is producing the following error when using `AutoTokenizer.from_pretrained`:\r\
    \n\r\nRecursionError: maximum recursion depth exceeded while calling a Python\
    \ object\r\n\r\nI think this might be related to transformers or tokenizers\r\n\
    I am using tranformers==4.33.1\r\nand tokenizers==0.13.3"
  created_at: 2023-09-21 08:38:43+00:00
  edited: false
  hidden: false
  id: 650c0f23bffe40057366bc41
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-09-21T09:41:16.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9530729651451111
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>This should now be fixed.  Some old models didn''t include the BOS/EOS/UNK
          tokens in <code>tokenizer_config.json</code>, and with later versions of
          Transformers this causes that error.</p>

          <p>I''ve fixed the file. Please try a download again and then it should
          work.</p>

          '
        raw: 'This should now be fixed.  Some old models didn''t include the BOS/EOS/UNK
          tokens in `tokenizer_config.json`, and with later versions of Transformers
          this causes that error.


          I''ve fixed the file. Please try a download again and then it should work.'
        updatedAt: '2023-09-21T09:41:16.716Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - andrews-llms
    id: 650c0fbcd4a0852d3c8b4a84
    type: comment
  author: TheBloke
  content: 'This should now be fixed.  Some old models didn''t include the BOS/EOS/UNK
    tokens in `tokenizer_config.json`, and with later versions of Transformers this
    causes that error.


    I''ve fixed the file. Please try a download again and then it should work.'
  created_at: 2023-09-21 08:41:16+00:00
  edited: false
  hidden: false
  id: 650c0fbcd4a0852d3c8b4a84
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TheBloke/Guanaco-33B-SuperHOT-8K-GPTQ
repo_type: model
status: open
target_branch: null
title: 'RecursionError: maximum recursion depth exceeded'
