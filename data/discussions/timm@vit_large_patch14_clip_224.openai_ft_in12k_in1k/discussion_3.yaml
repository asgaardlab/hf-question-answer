!!python/object:huggingface_hub.community.DiscussionWithDetails
author: himanshudixitcapitalone
conflicting_files: null
created_at: 2023-04-20 13:25:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6dbddb995793d509af40e1caa89cf384.svg
      fullname: Himanshu Dixit
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: himanshudixitcapitalone
      type: user
    createdAt: '2023-04-20T14:25:26.000Z'
    data:
      edited: false
      editors:
      - himanshudixitcapitalone
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6dbddb995793d509af40e1caa89cf384.svg
          fullname: Himanshu Dixit
          isHf: false
          isPro: false
          name: himanshudixitcapitalone
          type: user
        html: '<p>Preprocessor.json file not found</p>

          '
        raw: Preprocessor.json file not found
        updatedAt: '2023-04-20T14:25:26.165Z'
      numEdits: 0
      reactions: []
    id: 64414b56b3e14d9ba7b76a81
    type: comment
  author: himanshudixitcapitalone
  content: Preprocessor.json file not found
  created_at: 2023-04-20 13:25:26+00:00
  edited: false
  hidden: false
  id: 64414b56b3e14d9ba7b76a81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/241259b839f054b078b22c31f1bc861e.svg
      fullname: Chris M.
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: chriskyndrid
      type: user
    createdAt: '2023-04-20T16:37:39.000Z'
    data:
      edited: false
      editors:
      - chriskyndrid
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/241259b839f054b078b22c31f1bc861e.svg
          fullname: Chris M.
          isHf: false
          isPro: false
          name: chriskyndrid
          type: user
        html: "<p>You can create your own like this:</p>\n<pre><code class=\"language-python\"\
          >            feature_extractor = CustomImageProcessor(<span class=\"hljs-number\"\
          >224</span>)\n            model = ViTForImageClassification.from_pretrained(<span\
          \ class=\"hljs-string\">\"timm/vit_large_patch14_clip_224.openai_ft_in12k_in1k\"\
          </span>,\n                                                             \
          \ num_labels=num_classes)\n</code></pre>\n<p>where:</p>\n<pre><code class=\"\
          language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"\
          hljs-title class_\">CustomImageProcessor</span>(<span class=\"hljs-title\
          \ class_ inherited__\">ViTImageProcessor</span>):\n    <span class=\"hljs-keyword\"\
          >def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"\
          hljs-params\">self, size</span>):\n        <span class=\"hljs-built_in\"\
          >super</span>().__init__(size=size)\n\n    <span class=\"hljs-keyword\"\
          >def</span> <span class=\"hljs-title function_\">__call__</span>(<span class=\"\
          hljs-params\">self, images, return_tensors=<span class=\"hljs-string\">\"\
          pt\"</span></span>):\n        <span class=\"hljs-keyword\">return</span>\
          \ <span class=\"hljs-built_in\">super</span>().__call__(images=images, return_tensors=return_tensors)\n\
          \n<span class=\"hljs-keyword\">and</span>\n\n<span class=\"hljs-keyword\"\
          >class</span> <span class=\"hljs-title class_\">ImageDataCollator</span>:\n\
          \    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >__init__</span>(<span class=\"hljs-params\">self, feature_extractor</span>):\n\
          \        self.feature_extractor = feature_extractor\n\n    <span class=\"\
          hljs-keyword\">def</span> <span class=\"hljs-title function_\">__call__</span>(<span\
          \ class=\"hljs-params\">self, batch</span>):\n        images, labels = <span\
          \ class=\"hljs-built_in\">zip</span>(*batch)\n        inputs = self.feature_extractor(images=images,\
          \ return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\n        inputs[<span\
          \ class=\"hljs-string\">\"labels\"</span>] = torch.tensor(labels, dtype=torch.long)\n\
          \        <span class=\"hljs-keyword\">return</span> inputs\n</code></pre>\n\
          <p>then</p>\n<pre><code class=\"language-python\">            data_collator\
          \ = ImageDataCollator(feature_extractor)\n\n            trainer = Trainer(\n\
          \                model=model,\n                args=training_args,\n   \
          \             train_dataset=train_dataset,\n                eval_dataset=val_dataset,\n\
          \                data_collator=data_collator,\n            )\n</code></pre>\n"
        raw: "You can create your own like this:\n\n```python\n            feature_extractor\
          \ = CustomImageProcessor(224)\n            model = ViTForImageClassification.from_pretrained(\"\
          timm/vit_large_patch14_clip_224.openai_ft_in12k_in1k\",\n              \
          \                                                num_labels=num_classes)\n\
          ```\n\nwhere:\n\n```python\nclass CustomImageProcessor(ViTImageProcessor):\n\
          \    def __init__(self, size):\n        super().__init__(size=size)\n\n\
          \    def __call__(self, images, return_tensors=\"pt\"):\n        return\
          \ super().__call__(images=images, return_tensors=return_tensors)\n\nand\n\
          \nclass ImageDataCollator:\n    def __init__(self, feature_extractor):\n\
          \        self.feature_extractor = feature_extractor\n\n    def __call__(self,\
          \ batch):\n        images, labels = zip(*batch)\n        inputs = self.feature_extractor(images=images,\
          \ return_tensors=\"pt\")\n        inputs[\"labels\"] = torch.tensor(labels,\
          \ dtype=torch.long)\n        return inputs\n```\n\nthen\n\n```python\n \
          \           data_collator = ImageDataCollator(feature_extractor)\n\n   \
          \         trainer = Trainer(\n                model=model,\n           \
          \     args=training_args,\n                train_dataset=train_dataset,\n\
          \                eval_dataset=val_dataset,\n                data_collator=data_collator,\n\
          \            )\n```"
        updatedAt: '2023-04-20T16:37:39.549Z'
      numEdits: 0
      reactions: []
    id: 64416a534c2acf3398a7da8d
    type: comment
  author: chriskyndrid
  content: "You can create your own like this:\n\n```python\n            feature_extractor\
    \ = CustomImageProcessor(224)\n            model = ViTForImageClassification.from_pretrained(\"\
    timm/vit_large_patch14_clip_224.openai_ft_in12k_in1k\",\n                    \
    \                                          num_labels=num_classes)\n```\n\nwhere:\n\
    \n```python\nclass CustomImageProcessor(ViTImageProcessor):\n    def __init__(self,\
    \ size):\n        super().__init__(size=size)\n\n    def __call__(self, images,\
    \ return_tensors=\"pt\"):\n        return super().__call__(images=images, return_tensors=return_tensors)\n\
    \nand\n\nclass ImageDataCollator:\n    def __init__(self, feature_extractor):\n\
    \        self.feature_extractor = feature_extractor\n\n    def __call__(self,\
    \ batch):\n        images, labels = zip(*batch)\n        inputs = self.feature_extractor(images=images,\
    \ return_tensors=\"pt\")\n        inputs[\"labels\"] = torch.tensor(labels, dtype=torch.long)\n\
    \        return inputs\n```\n\nthen\n\n```python\n            data_collator =\
    \ ImageDataCollator(feature_extractor)\n\n            trainer = Trainer(\n   \
    \             model=model,\n                args=training_args,\n            \
    \    train_dataset=train_dataset,\n                eval_dataset=val_dataset,\n\
    \                data_collator=data_collator,\n            )\n```"
  created_at: 2023-04-20 15:37:39+00:00
  edited: false
  hidden: false
  id: 64416a534c2acf3398a7da8d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-04-20T22:02:06.000Z'
    data:
      edited: false
      editors:
      - rwightman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: '<p>FYI this is not a transformers ViT model, it''s a timm model</p>

          '
        raw: FYI this is not a transformers ViT model, it's a timm model
        updatedAt: '2023-04-20T22:02:06.619Z'
      numEdits: 0
      reactions: []
    id: 6441b65e0771bec9d26744bc
    type: comment
  author: rwightman
  content: FYI this is not a transformers ViT model, it's a timm model
  created_at: 2023-04-20 21:02:06+00:00
  edited: false
  hidden: false
  id: 6441b65e0771bec9d26744bc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: timm/vit_large_patch14_clip_224.openai_ft_in12k_in1k
repo_type: model
status: open
target_branch: null
title: Preprocessor.json file not found
