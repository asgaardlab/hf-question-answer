!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Madd0g
conflicting_files: null
created_at: 2023-11-29 19:27:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/fd4e93b9b50cc2850afdceb96696f147.svg
      fullname: Maddog
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Madd0g
      type: user
    createdAt: '2023-11-29T19:27:59.000Z'
    data:
      edited: false
      editors:
      - Madd0g
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9652326703071594
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/fd4e93b9b50cc2850afdceb96696f147.svg
          fullname: Maddog
          isHf: false
          isPro: false
          name: Madd0g
          type: user
        html: '<p>2.2 is a magical model, absolutely hands down the best 7b I tried
          (I''m using GGUF Q4 version through ollama).</p>

          <p>It''s amazingly steerable, I''m giving it GPT4 level requests, just dumping
          thought-train in prompts instead of actual proper instructions, but in the
          end it just understands and does very well in my very demanding and technical
          tasks.</p>

          <p>Especially, it''s MUCH better than 2.1 and 2.2.1 at just stopping (I''m
          doing a lot of zero-shot prompts, so there aren''t too many examples). In
          my tests 2.2.1 gives me good answers too but then keeps on completing what
          it shouldn''t like from the examples or instructions. Sometimes 2.2 prints
          an errant codeblock at the end or adds an extra sentence, but the problems
          are so minimal compared to the disasters the same exact conditions evoke
          from 2.2.1.</p>

          <p>I spent all day yesterday working on just 1-2 prompts and I could tell,
          as I was adding more guidance and instructions that it started understanding
          what I was trying to get it to do. When the same challenges were given to
          the other versions, 2.2.1 achieved (almost) comparable results, but then
          consistently created crap at the end or repeated the instructions back to
          me. Like they just couldn''t stop at the right time. It sounds like a little
          thing but the difference is so noticeable.</p>

          <p>Also multi-turn chat in 2.2 is absolutely from another world, it simply
          works for very longer contexts and shifting technical challenges (not something
          I was specifically testing, but I was still very impressed).</p>

          <p>I want to see 2.2 on the leaderboard, such a shame it''s the only one
          missing, I really believe in it.<br>I don''t know what''s different with
          this version, but maybe a little overfitting is good?</p>

          <p>Whatever you did, please do more of it :)</p>

          '
        raw: "2.2 is a magical model, absolutely hands down the best 7b I tried (I'm\
          \ using GGUF Q4 version through ollama).\r\n\r\nIt's amazingly steerable,\
          \ I'm giving it GPT4 level requests, just dumping thought-train in prompts\
          \ instead of actual proper instructions, but in the end it just understands\
          \ and does very well in my very demanding and technical tasks.\r\n\r\nEspecially,\
          \ it's MUCH better than 2.1 and 2.2.1 at just stopping (I'm doing a lot\
          \ of zero-shot prompts, so there aren't too many examples). In my tests\
          \ 2.2.1 gives me good answers too but then keeps on completing what it shouldn't\
          \ like from the examples or instructions. Sometimes 2.2 prints an errant\
          \ codeblock at the end or adds an extra sentence, but the problems are so\
          \ minimal compared to the disasters the same exact conditions evoke from\
          \ 2.2.1.\r\n\r\nI spent all day yesterday working on just 1-2 prompts and\
          \ I could tell, as I was adding more guidance and instructions that it started\
          \ understanding what I was trying to get it to do. When the same challenges\
          \ were given to the other versions, 2.2.1 achieved (almost) comparable results,\
          \ but then consistently created crap at the end or repeated the instructions\
          \ back to me. Like they just couldn't stop at the right time. It sounds\
          \ like a little thing but the difference is so noticeable.\r\n\r\nAlso multi-turn\
          \ chat in 2.2 is absolutely from another world, it simply works for very\
          \ longer contexts and shifting technical challenges (not something I was\
          \ specifically testing, but I was still very impressed).\r\n\r\nI want to\
          \ see 2.2 on the leaderboard, such a shame it's the only one missing, I\
          \ really believe in it.\r\nI don't know what's different with this version,\
          \ but maybe a little overfitting is good?\r\n\r\nWhatever you did, please\
          \ do more of it :)"
        updatedAt: '2023-11-29T19:27:59.916Z'
      numEdits: 0
      reactions: []
    id: 656790bf2d738342787af937
    type: comment
  author: Madd0g
  content: "2.2 is a magical model, absolutely hands down the best 7b I tried (I'm\
    \ using GGUF Q4 version through ollama).\r\n\r\nIt's amazingly steerable, I'm\
    \ giving it GPT4 level requests, just dumping thought-train in prompts instead\
    \ of actual proper instructions, but in the end it just understands and does very\
    \ well in my very demanding and technical tasks.\r\n\r\nEspecially, it's MUCH\
    \ better than 2.1 and 2.2.1 at just stopping (I'm doing a lot of zero-shot prompts,\
    \ so there aren't too many examples). In my tests 2.2.1 gives me good answers\
    \ too but then keeps on completing what it shouldn't like from the examples or\
    \ instructions. Sometimes 2.2 prints an errant codeblock at the end or adds an\
    \ extra sentence, but the problems are so minimal compared to the disasters the\
    \ same exact conditions evoke from 2.2.1.\r\n\r\nI spent all day yesterday working\
    \ on just 1-2 prompts and I could tell, as I was adding more guidance and instructions\
    \ that it started understanding what I was trying to get it to do. When the same\
    \ challenges were given to the other versions, 2.2.1 achieved (almost) comparable\
    \ results, but then consistently created crap at the end or repeated the instructions\
    \ back to me. Like they just couldn't stop at the right time. It sounds like a\
    \ little thing but the difference is so noticeable.\r\n\r\nAlso multi-turn chat\
    \ in 2.2 is absolutely from another world, it simply works for very longer contexts\
    \ and shifting technical challenges (not something I was specifically testing,\
    \ but I was still very impressed).\r\n\r\nI want to see 2.2 on the leaderboard,\
    \ such a shame it's the only one missing, I really believe in it.\r\nI don't know\
    \ what's different with this version, but maybe a little overfitting is good?\r\
    \n\r\nWhatever you did, please do more of it :)"
  created_at: 2023-11-29 19:27:59+00:00
  edited: false
  hidden: false
  id: 656790bf2d738342787af937
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
      fullname: Eric Hartford
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: ehartford
      type: user
    createdAt: '2023-11-29T19:36:13.000Z'
    data:
      edited: false
      editors:
      - ehartford
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9886709451675415
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63111b2d88942700629f5771/u2a9y-yx6TG0N31OhMSHI.png?w=200&h=200&f=face
          fullname: Eric Hartford
          isHf: false
          isPro: true
          name: ehartford
          type: user
        html: '<p>Thanks for the update.<br>This one was 3 epochs I think that''s
          the only difference</p>

          '
        raw: 'Thanks for the update.

          This one was 3 epochs I think that''s the only difference'
        updatedAt: '2023-11-29T19:36:13.559Z'
      numEdits: 0
      reactions: []
    id: 656792ad9e3a02a3b1b73619
    type: comment
  author: ehartford
  content: 'Thanks for the update.

    This one was 3 epochs I think that''s the only difference'
  created_at: 2023-11-29 19:36:13+00:00
  edited: false
  hidden: false
  id: 656792ad9e3a02a3b1b73619
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: cognitivecomputations/dolphin-2.2-mistral-7b
repo_type: model
status: open
target_branch: null
title: 2.2.1 is not better, this is the best version
