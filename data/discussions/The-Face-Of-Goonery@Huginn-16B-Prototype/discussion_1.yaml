!!python/object:huggingface_hub.community.DiscussionWithDetails
author: BlueNipples
conflicting_files: null
created_at: 2023-09-13 09:13:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
      fullname: Matthew Andrews
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlueNipples
      type: user
    createdAt: '2023-09-13T10:13:50.000Z'
    data:
      edited: false
      editors:
      - BlueNipples
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9158846735954285
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
          fullname: Matthew Andrews
          isHf: false
          isPro: false
          name: BlueNipples
          type: user
        html: '<p>Any chance you could make a 9b or 10b model for us gpu poor freaks?
          Would be rad if you could pour some coherency into some of the smaller rp
          models. Not that I know what TF I''m talking about. </p>

          '
        raw: 'Any chance you could make a 9b or 10b model for us gpu poor freaks?
          Would be rad if you could pour some coherency into some of the smaller rp
          models. Not that I know what TF I''m talking about. '
        updatedAt: '2023-09-13T10:13:50.183Z'
      numEdits: 0
      reactions: []
    id: 65018b5ebfe33e66e37bcc43
    type: comment
  author: BlueNipples
  content: 'Any chance you could make a 9b or 10b model for us gpu poor freaks? Would
    be rad if you could pour some coherency into some of the smaller rp models. Not
    that I know what TF I''m talking about. '
  created_at: 2023-09-13 09:13:50+00:00
  edited: false
  hidden: false
  id: 65018b5ebfe33e66e37bcc43
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303c6da4ec2dfa82a558005/QaV0BlzL3vV-JVUpp74OL.png?w=200&h=200&f=face
      fullname: Caleb morgan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: The-Face-Of-Goonery
      type: user
    createdAt: '2023-09-13T13:06:13.000Z'
    data:
      edited: true
      editors:
      - The-Face-Of-Goonery
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9998175501823425
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303c6da4ec2dfa82a558005/QaV0BlzL3vV-JVUpp74OL.png?w=200&h=200&f=face
          fullname: Caleb morgan
          isHf: false
          isPro: false
          name: The-Face-Of-Goonery
          type: user
        html: '<p>Actually, I put in a request to this HF org(minervaAI) to start
          training on Phi-1.5 using our new custom dataset I will be using for huginn
          v5 when the public release is out, Idk when either model will be able to
          be released though</p>

          '
        raw: Actually, I put in a request to this HF org(minervaAI) to start training
          on Phi-1.5 using our new custom dataset I will be using for huginn v5 when
          the public release is out, Idk when either model will be able to be released
          though
        updatedAt: '2023-09-13T14:40:31.082Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - BlueNipples
    id: 6501b3c59edb80e16d4a58d5
    type: comment
  author: The-Face-Of-Goonery
  content: Actually, I put in a request to this HF org(minervaAI) to start training
    on Phi-1.5 using our new custom dataset I will be using for huginn v5 when the
    public release is out, Idk when either model will be able to be released though
  created_at: 2023-09-13 12:06:13+00:00
  edited: true
  hidden: false
  id: 6501b3c59edb80e16d4a58d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
      fullname: Matthew Andrews
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlueNipples
      type: user
    createdAt: '2023-09-13T16:20:54.000Z'
    data:
      edited: false
      editors:
      - BlueNipples
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9435817003250122
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
          fullname: Matthew Andrews
          isHf: false
          isPro: false
          name: BlueNipples
          type: user
        html: '<p>That''s awesome :) Only just been hearing about that model recently
          and sounds pretty exciting! That it''s more logical and coherent in some
          ways than llama-2 7b speaks to a lot of possibility there. </p>

          <p>I wonder could you Nesting doll that shizz, somehow. Like gradient merge
          ph-1.5 into Guanaco-3B-Uncensored-v2 to give that model some extra logical
          meat and phi more depth, and then gradient merge the cold logical core of
          that output into something creative/role-playing like pygmalion-2.7b or
          OPT-2.7B-Nerybus-Mix, or just run a custom the Lora on it then. Random musings
          from someone who ain''t doing nothing and knows nothing lol. Probs would
          be a Frankenstein monster or isn''t possible. </p>

          <p>I''m going to have to play with phi in any case. See what the hype is
          about. 3-7b runs easy AF on my current hardware so 1.3B must be like lightning.
          Thanks for the  stuff you guys do!</p>

          '
        raw: "That's awesome :) Only just been hearing about that model recently and\
          \ sounds pretty exciting! That it's more logical and coherent in some ways\
          \ than llama-2 7b speaks to a lot of possibility there. \n\nI wonder could\
          \ you Nesting doll that shizz, somehow. Like gradient merge ph-1.5 into\
          \ Guanaco-3B-Uncensored-v2 to give that model some extra logical meat and\
          \ phi more depth, and then gradient merge the cold logical core of that\
          \ output into something creative/role-playing like pygmalion-2.7b or OPT-2.7B-Nerybus-Mix,\
          \ or just run a custom the Lora on it then. Random musings from someone\
          \ who ain't doing nothing and knows nothing lol. Probs would be a Frankenstein\
          \ monster or isn't possible. \n\nI'm going to have to play with phi in any\
          \ case. See what the hype is about. 3-7b runs easy AF on my current hardware\
          \ so 1.3B must be like lightning. Thanks for the  stuff you guys do!"
        updatedAt: '2023-09-13T16:20:54.768Z'
      numEdits: 0
      reactions: []
    id: 6501e16610e7fc91cbe16922
    type: comment
  author: BlueNipples
  content: "That's awesome :) Only just been hearing about that model recently and\
    \ sounds pretty exciting! That it's more logical and coherent in some ways than\
    \ llama-2 7b speaks to a lot of possibility there. \n\nI wonder could you Nesting\
    \ doll that shizz, somehow. Like gradient merge ph-1.5 into Guanaco-3B-Uncensored-v2\
    \ to give that model some extra logical meat and phi more depth, and then gradient\
    \ merge the cold logical core of that output into something creative/role-playing\
    \ like pygmalion-2.7b or OPT-2.7B-Nerybus-Mix, or just run a custom the Lora on\
    \ it then. Random musings from someone who ain't doing nothing and knows nothing\
    \ lol. Probs would be a Frankenstein monster or isn't possible. \n\nI'm going\
    \ to have to play with phi in any case. See what the hype is about. 3-7b runs\
    \ easy AF on my current hardware so 1.3B must be like lightning. Thanks for the\
    \  stuff you guys do!"
  created_at: 2023-09-13 15:20:54+00:00
  edited: false
  hidden: false
  id: 6501e16610e7fc91cbe16922
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303c6da4ec2dfa82a558005/QaV0BlzL3vV-JVUpp74OL.png?w=200&h=200&f=face
      fullname: Caleb morgan
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: The-Face-Of-Goonery
      type: user
    createdAt: '2023-09-13T19:53:18.000Z'
    data:
      edited: false
      editors:
      - The-Face-Of-Goonery
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9084354043006897
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303c6da4ec2dfa82a558005/QaV0BlzL3vV-JVUpp74OL.png?w=200&h=200&f=face
          fullname: Caleb morgan
          isHf: false
          isPro: false
          name: The-Face-Of-Goonery
          type: user
        html: '<p>no, merging doesnt work if the models are different architectures</p>

          '
        raw: no, merging doesnt work if the models are different architectures
        updatedAt: '2023-09-13T19:53:18.391Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - BlueNipples
    id: 6502132e8e46888d671311ab
    type: comment
  author: The-Face-Of-Goonery
  content: no, merging doesnt work if the models are different architectures
  created_at: 2023-09-13 18:53:18+00:00
  edited: false
  hidden: false
  id: 6502132e8e46888d671311ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
      fullname: Matthew Andrews
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: BlueNipples
      type: user
    createdAt: '2023-09-14T00:16:39.000Z'
    data:
      edited: false
      editors:
      - BlueNipples
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9932748079299927
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/64bb1109aaccfd28b023bcec/fumfSHv9pnW1rMvgQeibP.png?w=200&h=200&f=face
          fullname: Matthew Andrews
          isHf: false
          isPro: false
          name: BlueNipples
          type: user
        html: '<p>Ah, well I had a look at the paper for this model today. Defo going
          to install it. Looks <em>soo</em> impressive for it''s size. </p>

          '
        raw: 'Ah, well I had a look at the paper for this model today. Defo going
          to install it. Looks _soo_ impressive for it''s size. '
        updatedAt: '2023-09-14T00:16:39.341Z'
      numEdits: 0
      reactions: []
    id: 650250e720246c6f9f4808c9
    type: comment
  author: BlueNipples
  content: 'Ah, well I had a look at the paper for this model today. Defo going to
    install it. Looks _soo_ impressive for it''s size. '
  created_at: 2023-09-13 23:16:39+00:00
  edited: false
  hidden: false
  id: 650250e720246c6f9f4808c9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: The-Face-Of-Goonery/Huginn-16B-Prototype
repo_type: model
status: open
target_branch: null
title: Request from a moron
