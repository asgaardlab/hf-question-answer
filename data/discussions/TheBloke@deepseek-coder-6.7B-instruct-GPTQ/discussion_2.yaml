!!python/object:huggingface_hub.community.DiscussionWithDetails
author: anon7463435254
conflicting_files: null
created_at: 2023-11-22 13:14:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/311d0fed32d6ed4b44e3757556ef07bd.svg
      fullname: anon7463435254
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: anon7463435254
      type: user
    createdAt: '2023-11-22T13:14:15.000Z'
    data:
      edited: false
      editors:
      - anon7463435254
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7825028300285339
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/311d0fed32d6ed4b44e3757556ef07bd.svg
          fullname: anon7463435254
          isHf: false
          isPro: false
          name: anon7463435254
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheBloke\"\
          >@<span class=\"underline\">TheBloke</span></a></span>\n\n\t</span></span>\
          \ ,</p>\n<p>I am getting the following error when trying to load the model\
          \ using either ExLLaMA or AutoGPTQ. Actually there is no tokenizer.model\
          \ file, but how can this be solved?</p>\n<p>OSError: Not found: \"models/TheBloke_deepseek-coder-6.7B-instruct-GPTQ/tokenizer.model\"\
          : No such file or directory Error <a href=\"/TheBloke/deepseek-coder-6.7B-instruct-GPTQ/discussions/2\"\
          >#2</a>.</p>\n<p>Thank you.</p>\n"
        raw: "Hi @TheBloke ,\r\n\r\nI am getting the following error when trying to\
          \ load the model using either ExLLaMA or AutoGPTQ. Actually there is no\
          \ tokenizer.model file, but how can this be solved?\r\n\r\nOSError: Not\
          \ found: \"models/TheBloke_deepseek-coder-6.7B-instruct-GPTQ/tokenizer.model\"\
          : No such file or directory Error #2.\r\n\r\nThank you."
        updatedAt: '2023-11-22T13:14:15.447Z'
      numEdits: 0
      reactions: []
    id: 655dfea7dcb845354c225f27
    type: comment
  author: anon7463435254
  content: "Hi @TheBloke ,\r\n\r\nI am getting the following error when trying to\
    \ load the model using either ExLLaMA or AutoGPTQ. Actually there is no tokenizer.model\
    \ file, but how can this be solved?\r\n\r\nOSError: Not found: \"models/TheBloke_deepseek-coder-6.7B-instruct-GPTQ/tokenizer.model\"\
    : No such file or directory Error #2.\r\n\r\nThank you."
  created_at: 2023-11-22 13:14:15+00:00
  edited: false
  hidden: false
  id: 655dfea7dcb845354c225f27
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bfa555eec57de3885a607aa045d927e0.svg
      fullname: guenter hager
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: eb8
      type: user
    createdAt: '2023-11-29T17:25:16.000Z'
    data:
      edited: false
      editors:
      - eb8
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8063808679580688
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bfa555eec57de3885a607aa045d927e0.svg
          fullname: guenter hager
          isHf: false
          isPro: false
          name: eb8
          type: user
        html: '<p>the same here, with fastchat &amp; exllama2</p>

          '
        raw: the same here, with fastchat & exllama2
        updatedAt: '2023-11-29T17:25:16.836Z'
      numEdits: 0
      reactions: []
    id: 656773fc456d7733de3f8afa
    type: comment
  author: eb8
  content: the same here, with fastchat & exllama2
  created_at: 2023-11-29 17:25:16+00:00
  edited: false
  hidden: false
  id: 656773fc456d7733de3f8afa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-29T21:50:19.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9627172946929932
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>ExLlama doesn''t support models without tokenizer.model, but ExLlamav2
          added a patch with support last night.  AutoGPTQ will work.</p>

          '
        raw: ExLlama doesn't support models without tokenizer.model, but ExLlamav2
          added a patch with support last night.  AutoGPTQ will work.
        updatedAt: '2023-11-29T21:50:19.436Z'
      numEdits: 0
      reactions: []
    id: 6567b21b9e3a02a3b1bdab6e
    type: comment
  author: TheBloke
  content: ExLlama doesn't support models without tokenizer.model, but ExLlamav2 added
    a patch with support last night.  AutoGPTQ will work.
  created_at: 2023-11-29 21:50:19+00:00
  edited: false
  hidden: false
  id: 6567b21b9e3a02a3b1bdab6e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/deepseek-coder-6.7B-instruct-GPTQ
repo_type: model
status: open
target_branch: null
title: error while loading with exllama and AutoGPTQ
