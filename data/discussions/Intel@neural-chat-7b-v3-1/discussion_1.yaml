!!python/object:huggingface_hub.community.DiscussionWithDetails
author: fakezeta
conflicting_files: null
created_at: 2023-11-14 16:29:11+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8d363b7d14672efa7b44046b611702e9.svg
      fullname: Flavio Catalani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fakezeta
      type: user
    createdAt: '2023-11-14T16:29:11.000Z'
    data:
      edited: false
      editors:
      - fakezeta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6912095546722412
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8d363b7d14672efa7b44046b611702e9.svg
          fullname: Flavio Catalani
          isHf: false
          isPro: false
          name: fakezeta
          type: user
        html: '<p>Based on <a rel="nofollow" href="https://github.com/intel/intel-extension-for-transformers/blob/main/intel_extension_for_transformers/neural_chat/prompts/prompt.py">https://github.com/intel/intel-extension-for-transformers/blob/main/intel_extension_for_transformers/neural_chat/prompts/prompt.py</a>
          I see that v1 uses ChatML while v2 an Alpaca style prompt.</p>

          <p>What is the correct Prompt Template for v3?</p>

          '
        raw: "Based on https://github.com/intel/intel-extension-for-transformers/blob/main/intel_extension_for_transformers/neural_chat/prompts/prompt.py\
          \ I see that v1 uses ChatML while v2 an Alpaca style prompt.\r\n\r\nWhat\
          \ is the correct Prompt Template for v3?\r\n"
        updatedAt: '2023-11-14T16:29:11.924Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - YearZero
        - andysalerno
        - sleepyjoecheated
    id: 6553a05751328cedf9b843e7
    type: comment
  author: fakezeta
  content: "Based on https://github.com/intel/intel-extension-for-transformers/blob/main/intel_extension_for_transformers/neural_chat/prompts/prompt.py\
    \ I see that v1 uses ChatML while v2 an Alpaca style prompt.\r\n\r\nWhat is the\
    \ correct Prompt Template for v3?\r\n"
  created_at: 2023-11-14 16:29:11+00:00
  edited: false
  hidden: false
  id: 6553a05751328cedf9b843e7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-11-15T18:15:06.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9999691843986511
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>I''d also like to know</p>

          '
        raw: I'd also like to know
        updatedAt: '2023-11-15T18:15:06.509Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - eramax
    id: 65550aaa7f0cf58a2bd5b7ab
    type: comment
  author: TheBloke
  content: I'd also like to know
  created_at: 2023-11-15 18:15:06+00:00
  edited: false
  hidden: false
  id: 65550aaa7f0cf58a2bd5b7ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8d363b7d14672efa7b44046b611702e9.svg
      fullname: Flavio Catalani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fakezeta
      type: user
    createdAt: '2023-11-15T18:28:56.000Z'
    data:
      edited: false
      editors:
      - fakezeta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8905121684074402
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8d363b7d14672efa7b44046b611702e9.svg
          fullname: Flavio Catalani
          isHf: false
          isPro: false
          name: fakezeta
          type: user
        html: '<p>If even the mighty TheBloke cannot sort it out I''m relieved :-)</p>

          '
        raw: If even the mighty TheBloke cannot sort it out I'm relieved :-)
        updatedAt: '2023-11-15T18:28:56.991Z'
      numEdits: 0
      reactions: []
    id: 65550de889fd41f8afdb33ee
    type: comment
  author: fakezeta
  content: If even the mighty TheBloke cannot sort it out I'm relieved :-)
  created_at: 2023-11-15 18:28:56+00:00
  edited: false
  hidden: false
  id: 65550de889fd41f8afdb33ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4cd276aaa319b12d0beaf23c65630769.svg
      fullname: "DAN\u2122"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: dranger003
      type: user
    createdAt: '2023-11-15T21:09:56.000Z'
    data:
      edited: true
      editors:
      - dranger003
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8669223785400391
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4cd276aaa319b12d0beaf23c65630769.svg
          fullname: "DAN\u2122"
          isHf: false
          isPro: false
          name: dranger003
          type: user
        html: "<blockquote>\n<p>I'd also like to know</p>\n</blockquote>\n<p><span\
          \ data-props=\"{&quot;user&quot;:&quot;TheBloke&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheBloke\">@<span class=\"\
          underline\">TheBloke</span></a></span>\n\n\t</span></span> FYI - I've tested\
          \ most of the templates from the link provided above (i.e. github) and the\
          \ v2 template appears to work quite well. The other templates generate bad\
          \ responses.</p>\n<pre><code>### System:\n{system_prompt}\n\n### User:\n\
          {user_prompt}\n\n### Assistant:\n \n</code></pre>\n"
        raw: "> I'd also like to know\n\n@TheBloke FYI - I've tested most of the templates\
          \ from the link provided above (i.e. github) and the v2 template appears\
          \ to work quite well. The other templates generate bad responses.\n\n```\n\
          ### System:\n{system_prompt}\n\n### User:\n{user_prompt}\n\n### Assistant:\n\
          \ \n```\n"
        updatedAt: '2023-11-15T21:10:57.556Z'
      numEdits: 3
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - fakezeta
    id: 655533a4bc6ff300d447f85d
    type: comment
  author: dranger003
  content: "> I'd also like to know\n\n@TheBloke FYI - I've tested most of the templates\
    \ from the link provided above (i.e. github) and the v2 template appears to work\
    \ quite well. The other templates generate bad responses.\n\n```\n### System:\n\
    {system_prompt}\n\n### User:\n{user_prompt}\n\n### Assistant:\n \n```\n"
  created_at: 2023-11-15 21:09:56+00:00
  edited: true
  hidden: false
  id: 655533a4bc6ff300d447f85d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
      fullname: lvkaokao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lvkaokao
      type: user
    createdAt: '2023-11-16T02:01:32.000Z'
    data:
      edited: false
      editors:
      - lvkaokao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7371317744255066
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
          fullname: lvkaokao
          isHf: false
          isPro: false
          name: lvkaokao
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;dranger003&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/dranger003\">@<span class=\"\
          underline\">dranger003</span></a></span>\n\n\t</span></span>  the template\
          \ is correct, Thank you!</p>\n"
        raw: '@dranger003  the template is correct, Thank you!

          '
        updatedAt: '2023-11-16T02:01:32.652Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - fakezeta
    id: 655577fc41c144eefec8e616
    type: comment
  author: lvkaokao
  content: '@dranger003  the template is correct, Thank you!

    '
  created_at: 2023-11-16 02:01:32+00:00
  edited: false
  hidden: false
  id: 655577fc41c144eefec8e616
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8d363b7d14672efa7b44046b611702e9.svg
      fullname: Flavio Catalani
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: fakezeta
      type: user
    createdAt: '2023-11-17T13:43:25.000Z'
    data:
      edited: false
      editors:
      - fakezeta
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6461685299873352
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8d363b7d14672efa7b44046b611702e9.svg
          fullname: Flavio Catalani
          isHf: false
          isPro: false
          name: fakezeta
          type: user
        html: '<p>Thank you</p>

          '
        raw: Thank you
        updatedAt: '2023-11-17T13:43:25.561Z'
      numEdits: 0
      reactions: []
    id: 65576dfd97423a8b9d02fa10
    type: comment
  author: fakezeta
  content: Thank you
  created_at: 2023-11-17 13:43:25+00:00
  edited: false
  hidden: false
  id: 65576dfd97423a8b9d02fa10
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4e3b34f0605e6e2c9b5c5beb1a9c192f.svg
      fullname: Xiao Jin
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mljxy
      type: user
    createdAt: '2023-11-17T15:35:29.000Z'
    data:
      edited: true
      editors:
      - mljxy
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8617092370986938
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4e3b34f0605e6e2c9b5c5beb1a9c192f.svg
          fullname: Xiao Jin
          isHf: false
          isPro: false
          name: mljxy
          type: user
        html: '<p>I did some tests. It feels to me that the model prefers the following
          format (without the new lines):</p>

          <pre><code>### System:

          $SYSTEM&lt;/s&gt;

          ### User: $PROMPT0

          ### Assistant: $REPLY0&lt;/s&gt;

          ### User: $PROMPT1

          ### Assistant:

          </code></pre>

          '
        raw: 'I did some tests. It feels to me that the model prefers the following
          format (without the new lines):


          ```

          ### System:

          $SYSTEM</s>

          ### User: $PROMPT0

          ### Assistant: $REPLY0</s>

          ### User: $PROMPT1

          ### Assistant:

          ```'
        updatedAt: '2023-11-17T15:36:55.675Z'
      numEdits: 2
      reactions:
      - count: 6
        reaction: "\U0001F44D"
        users:
        - Lyte
        - eramax
        - lvkaokao
        - akumaburn
        - RedAndr
        - TunyTrinh
    id: 65578841f551801d4091f86c
    type: comment
  author: mljxy
  content: 'I did some tests. It feels to me that the model prefers the following
    format (without the new lines):


    ```

    ### System:

    $SYSTEM</s>

    ### User: $PROMPT0

    ### Assistant: $REPLY0</s>

    ### User: $PROMPT1

    ### Assistant:

    ```'
  created_at: 2023-11-17 15:35:29+00:00
  edited: true
  hidden: false
  id: 65578841f551801d4091f86c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e201b25be0df77c861bd53d3c40ed685.svg
      fullname: akumaburn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: akumaburn
      type: user
    createdAt: '2023-11-21T15:04:02.000Z'
    data:
      edited: false
      editors:
      - akumaburn
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9373375773429871
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e201b25be0df77c861bd53d3c40ed685.svg
          fullname: akumaburn
          isHf: false
          isPro: false
          name: akumaburn
          type: user
        html: '<p>Sigh.. I''d wish people would stick to a consistent prompt format,
          at least when sharing on hugging face. It makes it so much more tedious
          to test out and compare different LLMs when they don''t normalize the prompting
          template.</p>

          '
        raw: Sigh.. I'd wish people would stick to a consistent prompt format, at
          least when sharing on hugging face. It makes it so much more tedious to
          test out and compare different LLMs when they don't normalize the prompting
          template.
        updatedAt: '2023-11-21T15:04:02.067Z'
      numEdits: 0
      reactions: []
    id: 655cc6e2c6ee15a0bde056b4
    type: comment
  author: akumaburn
  content: Sigh.. I'd wish people would stick to a consistent prompt format, at least
    when sharing on hugging face. It makes it so much more tedious to test out and
    compare different LLMs when they don't normalize the prompting template.
  created_at: 2023-11-21 15:04:02+00:00
  edited: false
  hidden: false
  id: 655cc6e2c6ee15a0bde056b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/486c1b4c3f4d21f2691fca7f9bc15bb7.svg
      fullname: Haihao Shen
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Haihao
      type: user
    createdAt: '2023-11-21T15:07:15.000Z'
    data:
      edited: false
      editors:
      - Haihao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9899486303329468
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/486c1b4c3f4d21f2691fca7f9bc15bb7.svg
          fullname: Haihao Shen
          isHf: false
          isPro: false
          name: Haihao
          type: user
        html: '<p>Sorry for being late. It has been updated in model card.</p>

          '
        raw: Sorry for being late. It has been updated in model card.
        updatedAt: '2023-11-21T15:07:15.496Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - akumaburn
    id: 655cc7a32735108d4975f499
    type: comment
  author: Haihao
  content: Sorry for being late. It has been updated in model card.
  created_at: 2023-11-21 15:07:15+00:00
  edited: false
  hidden: false
  id: 655cc7a32735108d4975f499
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0878bc930e27371f55e24196c199ff62.svg
      fullname: Dx
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: NPap
      type: user
    createdAt: '2023-11-24T10:33:02.000Z'
    data:
      edited: true
      editors:
      - NPap
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9262943267822266
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0878bc930e27371f55e24196c199ff62.svg
          fullname: Dx
          isHf: false
          isPro: false
          name: NPap
          type: user
        html: '<blockquote>

          <p>Sigh.. I''d wish people would stick to a consistent prompt format, at
          least when sharing on hugging face. It makes it so much more tedious to
          test out and compare different LLMs when they don''t normalize the prompting
          template.</p>

          </blockquote>

          <p>Huggingface has been trying to alleviate this issue with the chat_template.<br><a
          href="https://huggingface.co/docs/transformers/chat_templating">https://huggingface.co/docs/transformers/chat_templating</a><br>The
          creator can submit the format there and the rest of us can just call that
          and have the input ready to go by just providing it with our raw input strings.</p>

          '
        raw: '> Sigh.. I''d wish people would stick to a consistent prompt format,
          at least when sharing on hugging face. It makes it so much more tedious
          to test out and compare different LLMs when they don''t normalize the prompting
          template.


          Huggingface has been trying to alleviate this issue with the chat_template.

          https://huggingface.co/docs/transformers/chat_templating

          The creator can submit the format there and the rest of us can just call
          that and have the input ready to go by just providing it with our raw input
          strings.'
        updatedAt: '2023-11-24T10:33:47.067Z'
      numEdits: 1
      reactions: []
    id: 65607bded37b9999f09d809f
    type: comment
  author: NPap
  content: '> Sigh.. I''d wish people would stick to a consistent prompt format, at
    least when sharing on hugging face. It makes it so much more tedious to test out
    and compare different LLMs when they don''t normalize the prompting template.


    Huggingface has been trying to alleviate this issue with the chat_template.

    https://huggingface.co/docs/transformers/chat_templating

    The creator can submit the format there and the rest of us can just call that
    and have the input ready to go by just providing it with our raw input strings.'
  created_at: 2023-11-24 10:33:02+00:00
  edited: true
  hidden: false
  id: 65607bded37b9999f09d809f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62c69e036af791614d03b80c/crgI4C5GRj7zZLA-cZRNF.jpeg?w=200&h=200&f=face
      fullname: Phani Srikanth
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: binga
      type: user
    createdAt: '2023-11-26T17:56:43.000Z'
    data:
      edited: false
      editors:
      - binga
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7539676427841187
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62c69e036af791614d03b80c/crgI4C5GRj7zZLA-cZRNF.jpeg?w=200&h=200&f=face
          fullname: Phani Srikanth
          isHf: false
          isPro: false
          name: binga
          type: user
        html: '<p>I tried running this model with transformers and I see this warning.</p>

          <blockquote>

          <p>No chat template is defined for this tokenizer - using the default template
          for the LlamaTokenizerFast class. If the default is not appropriate for
          your model, please set <code>tokenizer.chat_template</code> to an appropriate
          template. See <a href="https://huggingface.co/docs/transformers/main/chat_templating">https://huggingface.co/docs/transformers/main/chat_templating</a>
          for more information.</p>

          </blockquote>

          <p>It''d be great if Intel can leverage the new chat_templating functionality
          by HF  that makes it easy and accurate for all downstream users.</p>

          <p>Thank you for your work!</p>

          '
        raw: 'I tried running this model with transformers and I see this warning.


          > No chat template is defined for this tokenizer - using the default template
          for the LlamaTokenizerFast class. If the default is not appropriate for
          your model, please set `tokenizer.chat_template` to an appropriate template.
          See https://huggingface.co/docs/transformers/main/chat_templating for more
          information.


          It''d be great if Intel can leverage the new chat_templating functionality
          by HF  that makes it easy and accurate for all downstream users.


          Thank you for your work!'
        updatedAt: '2023-11-26T17:56:43.769Z'
      numEdits: 0
      reactions: []
    id: 656386dbb29be3f5b6ee56a6
    type: comment
  author: binga
  content: 'I tried running this model with transformers and I see this warning.


    > No chat template is defined for this tokenizer - using the default template
    for the LlamaTokenizerFast class. If the default is not appropriate for your model,
    please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating
    for more information.


    It''d be great if Intel can leverage the new chat_templating functionality by
    HF  that makes it easy and accurate for all downstream users.


    Thank you for your work!'
  created_at: 2023-11-26 17:56:43+00:00
  edited: false
  hidden: false
  id: 656386dbb29be3f5b6ee56a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bf22d0ded3407be69886f53de96d3f46.svg
      fullname: andy s
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: andysalerno
      type: user
    createdAt: '2023-11-27T20:32:23.000Z'
    data:
      edited: false
      editors:
      - andysalerno
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8794560432434082
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bf22d0ded3407be69886f53de96d3f46.svg
          fullname: andy s
          isHf: false
          isPro: false
          name: andysalerno
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Haihao&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Haihao\">@<span class=\"\
          underline\">Haihao</span></a></span>\n\n\t</span></span> I'm curious, is\
          \ there a particular reason for selecting the chat template format?</p>\n\
          <p>More and more LLMs are using the following standard ChatML template,\
          \ like so:</p>\n<pre><code>&lt;|im_start|&gt;user\nHi there!&lt;|im_end|&gt;\n\
          &lt;|im_start|&gt;assistant\nNice to meet you!&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\n\
          Can I ask a question?&lt;|im_end|&gt;\n</code></pre>\n<p>With dedicated\
          \ special tokens for &lt;|im_start|&gt; and &lt;|im_end|&gt;.</p>\n<p>Unfortunately\
          \ I can't provide real data... but I can say that from subjective experience,\
          \ models with the ChatML template seem to behave better as chat agents,\
          \ probably because every turn has a clear token to designate the beginning/end.\
          \ I'd be great if future neural-chat models use the same ChatML template!</p>\n"
        raw: '@Haihao I''m curious, is there a particular reason for selecting the
          chat template format?


          More and more LLMs are using the following standard ChatML template, like
          so:

          ```

          <|im_start|>user

          Hi there!<|im_end|>

          <|im_start|>assistant

          Nice to meet you!<|im_end|>

          <|im_start|>user

          Can I ask a question?<|im_end|>

          ```


          With dedicated special tokens for <|im_start|> and <|im_end|>.


          Unfortunately I can''t provide real data... but I can say that from subjective
          experience, models with the ChatML template seem to behave better as chat
          agents, probably because every turn has a clear token to designate the beginning/end.
          I''d be great if future neural-chat models use the same ChatML template!'
        updatedAt: '2023-11-27T20:32:23.787Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - jlzhou
        - binga
    id: 6564fcd739002bd4271cc754
    type: comment
  author: andysalerno
  content: '@Haihao I''m curious, is there a particular reason for selecting the chat
    template format?


    More and more LLMs are using the following standard ChatML template, like so:

    ```

    <|im_start|>user

    Hi there!<|im_end|>

    <|im_start|>assistant

    Nice to meet you!<|im_end|>

    <|im_start|>user

    Can I ask a question?<|im_end|>

    ```


    With dedicated special tokens for <|im_start|> and <|im_end|>.


    Unfortunately I can''t provide real data... but I can say that from subjective
    experience, models with the ChatML template seem to behave better as chat agents,
    probably because every turn has a clear token to designate the beginning/end.
    I''d be great if future neural-chat models use the same ChatML template!'
  created_at: 2023-11-27 20:32:23+00:00
  edited: false
  hidden: false
  id: 6564fcd739002bd4271cc754
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
      fullname: lvkaokao
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lvkaokao
      type: user
    createdAt: '2023-11-30T05:58:40.000Z'
    data:
      edited: true
      editors:
      - lvkaokao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7157667279243469
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8cdf266604b24bc9ae599aa2def8debd.svg
          fullname: lvkaokao
          isHf: false
          isPro: false
          name: lvkaokao
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;andysalerno&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/andysalerno\"\
          >@<span class=\"underline\">andysalerno</span></a></span>\n\n\t</span></span>\
          \ hi, good points and I agree your idea. Actually, we used the special tokens\
          \ &lt;|im_start|&gt; and &lt;|im_end|&gt; to train mpt and llama2 model.\
          \ So In this model version iterations, we will consider using the special\
          \ tokens &lt;|im_start|&gt; and &lt;|im_end|&gt;</p>\n"
        raw: '@andysalerno hi, good points and I agree your idea. Actually, we used
          the special tokens <|im_start|> and <|im_end|> to train mpt and llama2 model.
          So In this model version iterations, we will consider using the special
          tokens <|im_start|> and <|im_end|>'
        updatedAt: '2023-11-30T05:59:01.558Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - andysalerno
    id: 6568249083a448555e3034b8
    type: comment
  author: lvkaokao
  content: '@andysalerno hi, good points and I agree your idea. Actually, we used
    the special tokens <|im_start|> and <|im_end|> to train mpt and llama2 model.
    So In this model version iterations, we will consider using the special tokens
    <|im_start|> and <|im_end|>'
  created_at: 2023-11-30 05:58:40+00:00
  edited: true
  hidden: false
  id: 6568249083a448555e3034b8
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Intel/neural-chat-7b-v3-1
repo_type: model
status: open
target_branch: null
title: Prompt Template?
