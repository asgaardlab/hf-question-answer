!!python/object:huggingface_hub.community.DiscussionWithDetails
author: HR1777
conflicting_files: null
created_at: 2023-06-25 17:34:16+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
      fullname: H R
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HR1777
      type: user
    createdAt: '2023-06-25T18:34:16.000Z'
    data:
      edited: false
      editors:
      - HR1777
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9715973734855652
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
          fullname: H R
          isHf: false
          isPro: false
          name: HR1777
          type: user
        html: '<p>I have a question not only about this specific mode but about all
          quantized models ( GGMl models). I would like to know can we expect the
          same quality and the same output from the quantized models exactly as unquantized
          models?</p>

          '
        raw: I have a question not only about this specific mode but about all quantized
          models ( GGMl models). I would like to know can we expect the same quality
          and the same output from the quantized models exactly as unquantized models?
        updatedAt: '2023-06-25T18:34:16.140Z'
      numEdits: 0
      reactions: []
    id: 649888a88242893df51447e9
    type: comment
  author: HR1777
  content: I have a question not only about this specific mode but about all quantized
    models ( GGMl models). I would like to know can we expect the same quality and
    the same output from the quantized models exactly as unquantized models?
  created_at: 2023-06-25 17:34:16+00:00
  edited: false
  hidden: false
  id: 649888a88242893df51447e9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
      fullname: Ziggy Stardust
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Nurb432
      type: user
    createdAt: '2023-06-25T19:28:24.000Z'
    data:
      edited: false
      editors:
      - Nurb432
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9921194911003113
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c7e4979f04fda14b73a43c398ce7da27.svg
          fullname: Ziggy Stardust
          isHf: false
          isPro: false
          name: Nurb432
          type: user
        html: '<p>why would you expect it to be the same? its all about trade offs.
          </p>

          '
        raw: "why would you expect it to be the same? its all about trade offs. \n"
        updatedAt: '2023-06-25T19:28:24.473Z'
      numEdits: 0
      reactions: []
    id: 649895585b5d43c1c7889eb2
    type: comment
  author: Nurb432
  content: "why would you expect it to be the same? its all about trade offs. \n"
  created_at: 2023-06-25 18:28:24+00:00
  edited: false
  hidden: false
  id: 649895585b5d43c1c7889eb2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d380e709fe0e95f8bb1684e961549013.svg
      fullname: Hut hiu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Hoioi
      type: user
    createdAt: '2023-06-25T20:06:42.000Z'
    data:
      edited: false
      editors:
      - Hoioi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.988030731678009
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d380e709fe0e95f8bb1684e961549013.svg
          fullname: Hut hiu
          isHf: false
          isPro: false
          name: Hoioi
          type: user
        html: '<blockquote>

          <p>why would you expect it to be the same? its all about trade offs.</p>

          </blockquote>

          <p>That''s right, but when you choose a model after trying tens of models,
          it''s obvious that you''ve made that choice because of some criterias you
          had and you are selective, so you expect that it fulfills your requirements.
          If a model gives different results, in some cases its acceptable, but in
          other cases, you just think that you are using that selected model, while
          you are not getting the expected output and its more like another model
          that you didn''t want to choose. </p>

          '
        raw: '> why would you expect it to be the same? its all about trade offs.


          That''s right, but when you choose a model after trying tens of models,
          it''s obvious that you''ve made that choice because of some criterias you
          had and you are selective, so you expect that it fulfills your requirements.
          If a model gives different results, in some cases its acceptable, but in
          other cases, you just think that you are using that selected model, while
          you are not getting the expected output and its more like another model
          that you didn''t want to choose. '
        updatedAt: '2023-06-25T20:06:42.217Z'
      numEdits: 0
      reactions: []
    id: 64989e5298a76dbc608117ad
    type: comment
  author: Hoioi
  content: '> why would you expect it to be the same? its all about trade offs.


    That''s right, but when you choose a model after trying tens of models, it''s
    obvious that you''ve made that choice because of some criterias you had and you
    are selective, so you expect that it fulfills your requirements. If a model gives
    different results, in some cases its acceptable, but in other cases, you just
    think that you are using that selected model, while you are not getting the expected
    output and its more like another model that you didn''t want to choose. '
  created_at: 2023-06-25 19:06:42+00:00
  edited: false
  hidden: false
  id: 64989e5298a76dbc608117ad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
      fullname: H R
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HR1777
      type: user
    createdAt: '2023-06-26T09:31:42.000Z'
    data:
      edited: false
      editors:
      - HR1777
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9872642755508423
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
          fullname: H R
          isHf: false
          isPro: false
          name: HR1777
          type: user
        html: '<blockquote>

          <blockquote>

          <p>why would you expect it to be the same? its all about trade offs.</p>

          </blockquote>

          <p>That''s right, but when you choose a model after trying tens of models,
          it''s obvious that you''ve made that choice because of some criterias you
          had and you are selective, so you expect that it fulfills your requirements.
          If a model gives different results, in some cases its acceptable, but in
          other cases, you just think that you are using that selected model, while
          you are not getting the expected output and its more like another model
          that you didn''t want to choose.</p>

          </blockquote>

          <p>Yes, that''s right. I exactly feel the same and looking for a response
          from developers.</p>

          '
        raw: "> > why would you expect it to be the same? its all about trade offs.\n\
          > \n> That's right, but when you choose a model after trying tens of models,\
          \ it's obvious that you've made that choice because of some criterias you\
          \ had and you are selective, so you expect that it fulfills your requirements.\
          \ If a model gives different results, in some cases its acceptable, but\
          \ in other cases, you just think that you are using that selected model,\
          \ while you are not getting the expected output and its more like another\
          \ model that you didn't want to choose.\n\nYes, that's right. I exactly\
          \ feel the same and looking for a response from developers."
        updatedAt: '2023-06-26T09:31:42.036Z'
      numEdits: 0
      reactions: []
    id: 64995afecd4afd93710a7170
    type: comment
  author: HR1777
  content: "> > why would you expect it to be the same? its all about trade offs.\n\
    > \n> That's right, but when you choose a model after trying tens of models, it's\
    \ obvious that you've made that choice because of some criterias you had and you\
    \ are selective, so you expect that it fulfills your requirements. If a model\
    \ gives different results, in some cases its acceptable, but in other cases, you\
    \ just think that you are using that selected model, while you are not getting\
    \ the expected output and its more like another model that you didn't want to\
    \ choose.\n\nYes, that's right. I exactly feel the same and looking for a response\
    \ from developers."
  created_at: 2023-06-26 08:31:42+00:00
  edited: false
  hidden: false
  id: 64995afecd4afd93710a7170
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
      fullname: H R
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HR1777
      type: user
    createdAt: '2023-07-06T07:33:00.000Z'
    data:
      status: closed
    id: 64a66e2c02e46deb19aeb55d
    type: status-change
  author: HR1777
  created_at: 2023-07-06 06:33:00+00:00
  id: 64a66e2c02e46deb19aeb55d
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-07-06T08:31:46.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9165927171707153
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>There is always some accuracy loss from quantisation.  But the great
          thing with GGML is it gives you a huge range of options so you can pick
          how much you want to compromise between size + speed vs quality.</p>

          <p>If you pick the q8_0 model you will not be able to notice any difference
          from the original fp16 model; they are so close it should be impossible
          to tell the difference in normal usage.</p>

          <p>At the other end of the scale, the q2_K model will be degraded quite
          a lot.</p>

          <p>Most people select a 4bit or 5bit option.  Whether you can notice a difference
          there will depend on your use case and exact criteria. But most people consider
          5bit to be pretty indistinguishable from the original model, and 4bit is
          more than good enough for most use cases.</p>

          '
        raw: 'There is always some accuracy loss from quantisation.  But the great
          thing with GGML is it gives you a huge range of options so you can pick
          how much you want to compromise between size + speed vs quality.


          If you pick the q8_0 model you will not be able to notice any difference
          from the original fp16 model; they are so close it should be impossible
          to tell the difference in normal usage.


          At the other end of the scale, the q2_K model will be degraded quite a lot.


          Most people select a 4bit or 5bit option.  Whether you can notice a difference
          there will depend on your use case and exact criteria. But most people consider
          5bit to be pretty indistinguishable from the original model, and 4bit is
          more than good enough for most use cases.'
        updatedAt: '2023-07-06T08:31:46.877Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - HR1777
        - phi0112358
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Hoioi
    id: 64a67bf22c59891d57096674
    type: comment
  author: TheBloke
  content: 'There is always some accuracy loss from quantisation.  But the great thing
    with GGML is it gives you a huge range of options so you can pick how much you
    want to compromise between size + speed vs quality.


    If you pick the q8_0 model you will not be able to notice any difference from
    the original fp16 model; they are so close it should be impossible to tell the
    difference in normal usage.


    At the other end of the scale, the q2_K model will be degraded quite a lot.


    Most people select a 4bit or 5bit option.  Whether you can notice a difference
    there will depend on your use case and exact criteria. But most people consider
    5bit to be pretty indistinguishable from the original model, and 4bit is more
    than good enough for most use cases.'
  created_at: 2023-07-06 07:31:46+00:00
  edited: false
  hidden: false
  id: 64a67bf22c59891d57096674
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
      fullname: H R
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HR1777
      type: user
    createdAt: '2023-07-06T09:13:07.000Z'
    data:
      edited: false
      editors:
      - HR1777
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9900670051574707
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
          fullname: H R
          isHf: false
          isPro: false
          name: HR1777
          type: user
        html: '<p>Thank you very much for your detailed explanations. I really appreciate
          it.</p>

          '
        raw: Thank you very much for your detailed explanations. I really appreciate
          it.
        updatedAt: '2023-07-06T09:13:07.385Z'
      numEdits: 0
      reactions: []
    id: 64a685a3de8f7e2e407928f2
    type: comment
  author: HR1777
  content: Thank you very much for your detailed explanations. I really appreciate
    it.
  created_at: 2023-07-06 08:13:07+00:00
  edited: false
  hidden: false
  id: 64a685a3de8f7e2e407928f2
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/vicuna-13b-v1.3.0-GGML
repo_type: model
status: closed
target_branch: null
title: Quality of the model
