!!python/object:huggingface_hub.community.DiscussionWithDetails
author: sordidloam
conflicting_files: null
created_at: 2023-09-09 23:21:40+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7f7aa0db25af37c73d5a23f532765856.svg
      fullname: Matthew Elliott
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sordidloam
      type: user
    createdAt: '2023-09-10T00:21:40.000Z'
    data:
      edited: false
      editors:
      - sordidloam
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6412284970283508
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7f7aa0db25af37c73d5a23f532765856.svg
          fullname: Matthew Elliott
          isHf: false
          isPro: false
          name: sordidloam
          type: user
        html: "<p>When downloading the model inside a fresh install (09/09/2023) of\
          \ 'Text Generation web ui' upon loading with ExLlamma_HF with default settings,\
          \ 'max_seq_len' I get this error.</p>\n<p>'File \u201CE:\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\exllama\\model.py\u201D, line\
          \ 732, in init</p>\n<p>with safe_open(self.config.model_path, framework\
          \ = \"pt\", device = \"cpu\") as f:<br>safetensors_rust.SafetensorError:\
          \ Error while deserializing header: HeaderTooLarge'</p>\n"
        raw: "When downloading the model inside a fresh install (09/09/2023) of 'Text\
          \ Generation web ui' upon loading with ExLlamma_HF with default settings,\
          \ 'max_seq_len' I get this error.\r\n\r\n'File \u201CE:\\oobabooga_windows\\\
          installer_files\\env\\lib\\site-packages\\exllama\\model.py\u201D, line\
          \ 732, in init\r\n\r\nwith safe_open(self.config.model_path, framework =\
          \ \"pt\", device = \"cpu\") as f:\r\nsafetensors_rust.SafetensorError: Error\
          \ while deserializing header: HeaderTooLarge'"
        updatedAt: '2023-09-10T00:21:40.336Z'
      numEdits: 0
      reactions: []
    id: 64fd0c1452e82dd432a19e79
    type: comment
  author: sordidloam
  content: "When downloading the model inside a fresh install (09/09/2023) of 'Text\
    \ Generation web ui' upon loading with ExLlamma_HF with default settings, 'max_seq_len'\
    \ I get this error.\r\n\r\n'File \u201CE:\\oobabooga_windows\\installer_files\\\
    env\\lib\\site-packages\\exllama\\model.py\u201D, line 732, in init\r\n\r\nwith\
    \ safe_open(self.config.model_path, framework = \"pt\", device = \"cpu\") as f:\r\
    \nsafetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge'"
  created_at: 2023-09-09 23:21:40+00:00
  edited: false
  hidden: false
  id: 64fd0c1452e82dd432a19e79
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: WizardLM/WizardCoder-Python-13B-V1.0
repo_type: model
status: open
target_branch: null
title: Text Generation Web UI - 'HeaderTooLarge'
