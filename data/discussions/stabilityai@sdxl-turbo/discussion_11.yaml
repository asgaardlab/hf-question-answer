!!python/object:huggingface_hub.community.DiscussionWithDetails
author: macadeliccc
conflicting_files: null
created_at: 2023-11-29 18:23:00+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6455cc8d679315e4ef16fbec/NcB1yDz0ZBtXXFiApnFyl.png?w=200&h=200&f=face
      fullname: Tim Dolan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: macadeliccc
      type: user
    createdAt: '2023-11-29T18:23:00.000Z'
    data:
      edited: true
      editors:
      - macadeliccc
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5877856016159058
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6455cc8d679315e4ef16fbec/NcB1yDz0ZBtXXFiApnFyl.png?w=200&h=200&f=face
          fullname: Tim Dolan
          isHf: false
          isPro: false
          name: macadeliccc
          type: user
        html: "<p>This demo is pretty self explanatory but I figured I would just\
          \ submit this here rather than a pull request seeing as they have a demo\
          \ provided.</p>\n<p>However, if you do not want to use the provided interface\
          \ or just want to test it very quickly here is this streamlit script:</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">import</span>\
          \ streamlit <span class=\"hljs-keyword\">as</span> st\n<span class=\"hljs-keyword\"\
          >from</span> diffusers <span class=\"hljs-keyword\">import</span> AutoPipelineForText2Image\n\
          <span class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\"\
          >import</span> os\n<span class=\"hljs-keyword\">import</span> time\n<span\
          \ class=\"hljs-keyword\">import</span> random\n\nst.title(<span class=\"\
          hljs-string\">\"SDXL Turbo\"</span>)\n\n<span class=\"hljs-keyword\">if</span>\
          \ <span class=\"hljs-keyword\">not</span> os.path.exists(<span class=\"\
          hljs-string\">'outputs'</span>):\n    os.makedirs(<span class=\"hljs-string\"\
          >'outputs'</span>)\n\n<span class=\"hljs-meta\"><span data-props=\"{&quot;user&quot;:&quot;st&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/st\"\
          >@<span class=\"underline\">st</span></a></span>\n\n\t</span></span>.cache_resource</span>\n\
          <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\"\
          >load_model</span>():\n    device = <span class=\"hljs-string\">\"cuda\"\
          </span> <span class=\"hljs-keyword\">if</span> torch.cuda.is_available()\
          \ <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"\
          cpu\"</span>\n    pipe = AutoPipelineForText2Image.from_pretrained(<span\
          \ class=\"hljs-string\">\"stabilityai/sdxl-turbo\"</span>, torch_dtype=torch.float16,\
          \ variant=<span class=\"hljs-string\">\"fp16\"</span>).to(device)\n    <span\
          \ class=\"hljs-keyword\">return</span> pipe\n\npipe = load_model()\n\nprompt\
          \ = st.sidebar.text_area(<span class=\"hljs-string\">\"Enter a prompt:\"\
          </span>, <span class=\"hljs-string\">\"A cinematic shot of a baby raccoon\
          \ wearing an intricate Italian priest robe.\"</span>, height=<span class=\"\
          hljs-number\">1</span>)\nnum_inference_steps = st.sidebar.slider(<span class=\"\
          hljs-string\">\"Number of inference steps\"</span>, <span class=\"hljs-number\"\
          >1</span>, <span class=\"hljs-number\">10</span>, <span class=\"hljs-number\"\
          >1</span>)\nguidance_scale = st.sidebar.slider(<span class=\"hljs-string\"\
          >\"Guidance scale\"</span>, <span class=\"hljs-number\">0.0</span>, <span\
          \ class=\"hljs-number\">2.0</span>, <span class=\"hljs-number\">0.0</span>)\n\
          \n<span class=\"hljs-keyword\">if</span> st.sidebar.button(<span class=\"\
          hljs-string\">'Generate Image'</span>):\n    <span class=\"hljs-keyword\"\
          >with</span> st.spinner(<span class=\"hljs-string\">'Generating image...'</span>):\n\
          \        <span class=\"hljs-comment\"># Generate the image</span>\n    \
          \    image = pipe(prompt=prompt, num_inference_steps=num_inference_steps,\
          \ guidance_scale=guidance_scale).images[<span class=\"hljs-number\">0</span>]\n\
          \n        <span class=\"hljs-comment\"># Generate a unique filename</span>\n\
          \        timestamp = <span class=\"hljs-built_in\">int</span>(time.time())\n\
          \        random_number = random.randint(<span class=\"hljs-number\">0</span>,\
          \ <span class=\"hljs-number\">99999</span>)\n        filename = <span class=\"\
          hljs-string\">f\"outputs/image_<span class=\"hljs-subst\">{timestamp}</span>_<span\
          \ class=\"hljs-subst\">{random_number}</span>.png\"</span>\n\n        <span\
          \ class=\"hljs-comment\"># Save the image</span>\n        image.save(filename)\n\
          \n        <span class=\"hljs-comment\"># Display the image</span>\n    \
          \    st.image(filename, caption=<span class=\"hljs-string\">'Generated Image'</span>)\n\
          </code></pre>\n"
        raw: "This demo is pretty self explanatory but I figured I would just submit\
          \ this here rather than a pull request seeing as they have a demo provided.\n\
          \nHowever, if you do not want to use the provided interface or just want\
          \ to test it very quickly here is this streamlit script:\n\n```python\n\
          import streamlit as st\nfrom diffusers import AutoPipelineForText2Image\n\
          import torch\nimport os\nimport time\nimport random\n\nst.title(\"SDXL Turbo\"\
          )\n\nif not os.path.exists('outputs'):\n    os.makedirs('outputs')\n\n@st.cache_resource\n\
          def load_model():\n    device = \"cuda\" if torch.cuda.is_available() else\
          \ \"cpu\"\n    pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\"\
          , torch_dtype=torch.float16, variant=\"fp16\").to(device)\n    return pipe\n\
          \npipe = load_model()\n\nprompt = st.sidebar.text_area(\"Enter a prompt:\"\
          , \"A cinematic shot of a baby raccoon wearing an intricate Italian priest\
          \ robe.\", height=1)\nnum_inference_steps = st.sidebar.slider(\"Number of\
          \ inference steps\", 1, 10, 1)\nguidance_scale = st.sidebar.slider(\"Guidance\
          \ scale\", 0.0, 2.0, 0.0)\n\nif st.sidebar.button('Generate Image'):\n \
          \   with st.spinner('Generating image...'):\n        # Generate the image\n\
          \        image = pipe(prompt=prompt, num_inference_steps=num_inference_steps,\
          \ guidance_scale=guidance_scale).images[0]\n\n        # Generate a unique\
          \ filename\n        timestamp = int(time.time())\n        random_number\
          \ = random.randint(0, 99999)\n        filename = f\"outputs/image_{timestamp}_{random_number}.png\"\
          \n\n        # Save the image\n        image.save(filename)\n\n        #\
          \ Display the image\n        st.image(filename, caption='Generated Image')\n\
          ```\n"
        updatedAt: '2023-11-29T18:23:47.277Z'
      numEdits: 2
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - yht4work
        - abhi011999
        - jwooldridge
        - patrickvonplaten
    id: 6567818449653cac90f5f541
    type: comment
  author: macadeliccc
  content: "This demo is pretty self explanatory but I figured I would just submit\
    \ this here rather than a pull request seeing as they have a demo provided.\n\n\
    However, if you do not want to use the provided interface or just want to test\
    \ it very quickly here is this streamlit script:\n\n```python\nimport streamlit\
    \ as st\nfrom diffusers import AutoPipelineForText2Image\nimport torch\nimport\
    \ os\nimport time\nimport random\n\nst.title(\"SDXL Turbo\")\n\nif not os.path.exists('outputs'):\n\
    \    os.makedirs('outputs')\n\n@st.cache_resource\ndef load_model():\n    device\
    \ = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    pipe = AutoPipelineForText2Image.from_pretrained(\"\
    stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\").to(device)\n\
    \    return pipe\n\npipe = load_model()\n\nprompt = st.sidebar.text_area(\"Enter\
    \ a prompt:\", \"A cinematic shot of a baby raccoon wearing an intricate Italian\
    \ priest robe.\", height=1)\nnum_inference_steps = st.sidebar.slider(\"Number\
    \ of inference steps\", 1, 10, 1)\nguidance_scale = st.sidebar.slider(\"Guidance\
    \ scale\", 0.0, 2.0, 0.0)\n\nif st.sidebar.button('Generate Image'):\n    with\
    \ st.spinner('Generating image...'):\n        # Generate the image\n        image\
    \ = pipe(prompt=prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n\
    \n        # Generate a unique filename\n        timestamp = int(time.time())\n\
    \        random_number = random.randint(0, 99999)\n        filename = f\"outputs/image_{timestamp}_{random_number}.png\"\
    \n\n        # Save the image\n        image.save(filename)\n\n        # Display\
    \ the image\n        st.image(filename, caption='Generated Image')\n```\n"
  created_at: 2023-11-29 18:23:00+00:00
  edited: true
  hidden: false
  id: 6567818449653cac90f5f541
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 11
repo_id: stabilityai/sdxl-turbo
repo_type: model
status: open
target_branch: null
title: Very fast streamlit demo
