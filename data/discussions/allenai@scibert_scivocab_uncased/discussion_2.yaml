!!python/object:huggingface_hub.community.DiscussionWithDetails
author: owood
conflicting_files: null
created_at: 2022-09-30 13:41:31+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0626433b2abaaebaa2d4f11349bdfa8e.svg
      fullname: Oskar Hansen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: owood
      type: user
    createdAt: '2022-09-30T14:41:31.000Z'
    data:
      edited: false
      editors:
      - owood
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0626433b2abaaebaa2d4f11349bdfa8e.svg
          fullname: Oskar Hansen
          isHf: false
          isPro: false
          name: owood
          type: user
        html: '<p>Dear allen ai</p>

          <p>I am trying to use scivocab as a pre-trained model for some topic modelling
          on scientific papers.<br>Unfortunately, I cannot download scivocab using
          SentenceTransformers, and the transformers.pipelines won''t work either,
          since there is no specified pipeline type. </p>

          <p>How do you suggest usage in python?</p>

          '
        raw: "Dear allen ai\r\n\r\nI am trying to use scivocab as a pre-trained model\
          \ for some topic modelling on scientific papers. \r\nUnfortunately, I cannot\
          \ download scivocab using SentenceTransformers, and the transformers.pipelines\
          \ won't work either, since there is no specified pipeline type. \r\n\r\n\
          How do you suggest usage in python?"
        updatedAt: '2022-09-30T14:41:31.138Z'
      numEdits: 0
      reactions: []
    id: 6337001b164fd6b346e4130b
    type: comment
  author: owood
  content: "Dear allen ai\r\n\r\nI am trying to use scivocab as a pre-trained model\
    \ for some topic modelling on scientific papers. \r\nUnfortunately, I cannot download\
    \ scivocab using SentenceTransformers, and the transformers.pipelines won't work\
    \ either, since there is no specified pipeline type. \r\n\r\nHow do you suggest\
    \ usage in python?"
  created_at: 2022-09-30 13:41:31+00:00
  edited: false
  hidden: false
  id: 6337001b164fd6b346e4130b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/6c74f72a600f14b0374208dbf8434381.svg
      fullname: corn pop
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: cornpopper
      type: user
    createdAt: '2022-10-18T18:59:52.000Z'
    data:
      edited: false
      editors:
      - cornpopper
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/6c74f72a600f14b0374208dbf8434381.svg
          fullname: corn pop
          isHf: false
          isPro: false
          name: cornpopper
          type: user
        html: '<p>From here <a rel="nofollow" href="https://github.com/allenai/scibert">https://github.com/allenai/scibert</a>
          and there''s a .sh to get you started. Something like...</p>

          <p>from transformers import *<br>from transformers import pipeline</p>

          <p>classifier = pipeline("sentiment-analysis")<br>tokenizer = AutoTokenizer.from_pretrained(''allenai/scibert_scivocab_uncased'')<br>model
          = AutoModel.from_pretrained(''allenai/scibert_scivocab_uncased'')</p>

          '
        raw: 'From here https://github.com/allenai/scibert and there''s a .sh to get
          you started. Something like...


          from transformers import *

          from transformers import pipeline


          classifier = pipeline("sentiment-analysis")

          tokenizer = AutoTokenizer.from_pretrained(''allenai/scibert_scivocab_uncased'')

          model = AutoModel.from_pretrained(''allenai/scibert_scivocab_uncased'')'
        updatedAt: '2022-10-18T18:59:52.550Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - owood
    id: 634ef7a88d0f051a450650a1
    type: comment
  author: cornpopper
  content: 'From here https://github.com/allenai/scibert and there''s a .sh to get
    you started. Something like...


    from transformers import *

    from transformers import pipeline


    classifier = pipeline("sentiment-analysis")

    tokenizer = AutoTokenizer.from_pretrained(''allenai/scibert_scivocab_uncased'')

    model = AutoModel.from_pretrained(''allenai/scibert_scivocab_uncased'')'
  created_at: 2022-10-18 17:59:52+00:00
  edited: false
  hidden: false
  id: 634ef7a88d0f051a450650a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0626433b2abaaebaa2d4f11349bdfa8e.svg
      fullname: Oskar Hansen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: owood
      type: user
    createdAt: '2022-11-01T15:27:43.000Z'
    data:
      edited: false
      editors:
      - owood
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0626433b2abaaebaa2d4f11349bdfa8e.svg
          fullname: Oskar Hansen
          isHf: false
          isPro: false
          name: owood
          type: user
        html: "<p>Thanks. It also works if I skip the pipeline i.e.</p>\n<pre><code>from\
          \ transformers import *\ntokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\
          \ \nembed_model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n\
          </code></pre>\n<p>However, I am unsure if BERTopic is actually using it,\
          \ or just defaulting to . When I run<br><code>topic_model = BERTopic(embedding_model=embed_model,\
          \ language=\"english\", nr_topics=\"auto\", verbose=True )</code><br><code>topics,\
          \ probs = topic_model.fit_transform(docs)</code></p>\n<p>the verbose output\
          \ is:</p>\n<pre><code>loading configuration file `.cache\\torch\\sentence_transformers\\\
          sentence-transformers_all-MiniLM-L6-v2\\config.json\nModel config BertConfig\
          \ {\n  \"_name_or_path\": \".cache\\\\torch\\\\sentence_transformers\\\\\
          sentence-transformers_all-MiniLM-L6-v2\\\\\",  \"architectures\": [\n  \
          \  \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\"\
          : null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\"\
          ,\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 384,\n  \"initializer_range\"\
          : 0.02,\n  \"intermediate_size\": 1536,\n  \"layer_norm_eps\": 1e-12,\n\
          \  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"\
          num_attention_heads\": 12,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\"\
          : 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\"\
          : \"4.22.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\"\
          : 30522\n}\n\nloading weights file .cache\\torch\\sentence_transformers\\\
          sentence-transformers_all-MiniLM-L6-v2\\pytorch_model.bin\nAll model checkpoint\
          \ weights were used when initializing BertModel.\n\nAll the weights of BertModel\
          \ were initialized from the model checkpoint at C:\\Users\\oskar/.cache\\\
          torch\\sentence_transformers\\sentence-transformers_all-MiniLM-L6-v2\\.\n\
          </code></pre>\n<p>THis might of course be an issue in the Bertopic package.</p>\n"
        raw: "Thanks. It also works if I skip the pipeline i.e.\n```\nfrom transformers\
          \ import *\ntokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\
          \ \nembed_model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n\
          ```\nHowever, I am unsure if BERTopic is actually using it, or just defaulting\
          \ to . When I run \n`topic_model = BERTopic(embedding_model=embed_model,\
          \ language=\"english\", nr_topics=\"auto\", verbose=True )`\n`topics, probs\
          \ = topic_model.fit_transform(docs)`\n\nthe verbose output is:\n```\nloading\
          \ configuration file `.cache\\torch\\sentence_transformers\\sentence-transformers_all-MiniLM-L6-v2\\\
          config.json\nModel config BertConfig {\n  \"_name_or_path\": \".cache\\\\\
          torch\\\\sentence_transformers\\\\sentence-transformers_all-MiniLM-L6-v2\\\
          \\\",  \"architectures\": [\n    \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\"\
          : 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n\
          \  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\"\
          : 384,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 1536,\n\
          \  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"\
          model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\"\
          : 6,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\"\
          ,\n  \"transformers_version\": \"4.22.2\",\n  \"type_vocab_size\": 2,\n\
          \  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file\
          \ .cache\\torch\\sentence_transformers\\sentence-transformers_all-MiniLM-L6-v2\\\
          pytorch_model.bin\nAll model checkpoint weights were used when initializing\
          \ BertModel.\n\nAll the weights of BertModel were initialized from the model\
          \ checkpoint at C:\\Users\\oskar/.cache\\torch\\sentence_transformers\\\
          sentence-transformers_all-MiniLM-L6-v2\\.\n```\n\nTHis might of course be\
          \ an issue in the Bertopic package."
        updatedAt: '2022-11-01T15:27:43.069Z'
      numEdits: 0
      reactions: []
    id: 63613aefda0599dc08c39ad9
    type: comment
  author: owood
  content: "Thanks. It also works if I skip the pipeline i.e.\n```\nfrom transformers\
    \ import *\ntokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\
    \ \nembed_model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n\
    ```\nHowever, I am unsure if BERTopic is actually using it, or just defaulting\
    \ to . When I run \n`topic_model = BERTopic(embedding_model=embed_model, language=\"\
    english\", nr_topics=\"auto\", verbose=True )`\n`topics, probs = topic_model.fit_transform(docs)`\n\
    \nthe verbose output is:\n```\nloading configuration file `.cache\\torch\\sentence_transformers\\\
    sentence-transformers_all-MiniLM-L6-v2\\config.json\nModel config BertConfig {\n\
    \  \"_name_or_path\": \".cache\\\\torch\\\\sentence_transformers\\\\sentence-transformers_all-MiniLM-L6-v2\\\
    \\\",  \"architectures\": [\n    \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\"\
    : 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n\
    \  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\"\
    : 384,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 1536,\n  \"layer_norm_eps\"\
    : 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n \
    \ \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\"\
    : 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\"\
    : \"4.22.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\"\
    : 30522\n}\n\nloading weights file .cache\\torch\\sentence_transformers\\sentence-transformers_all-MiniLM-L6-v2\\\
    pytorch_model.bin\nAll model checkpoint weights were used when initializing BertModel.\n\
    \nAll the weights of BertModel were initialized from the model checkpoint at C:\\\
    Users\\oskar/.cache\\torch\\sentence_transformers\\sentence-transformers_all-MiniLM-L6-v2\\\
    .\n```\n\nTHis might of course be an issue in the Bertopic package."
  created_at: 2022-11-01 14:27:43+00:00
  edited: false
  hidden: false
  id: 63613aefda0599dc08c39ad9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/43835e16f8bedfde105a71e2589e0ea6.svg
      fullname: Moulik Gupta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SteadySurfdom
      type: user
    createdAt: '2023-11-01T15:19:40.000Z'
    data:
      edited: false
      editors:
      - SteadySurfdom
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9682515859603882
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/43835e16f8bedfde105a71e2589e0ea6.svg
          fullname: Moulik Gupta
          isHf: false
          isPro: false
          name: SteadySurfdom
          type: user
        html: '<p>I have downloaded the recommended Tensorflow model from the GitHub
          ReadMe file. But I am not sure how to use that model in Python now. I am
          new to using BERT and its derivatives, so any help would be appreciated.</p>

          '
        raw: I have downloaded the recommended Tensorflow model from the GitHub ReadMe
          file. But I am not sure how to use that model in Python now. I am new to
          using BERT and its derivatives, so any help would be appreciated.
        updatedAt: '2023-11-01T15:19:40.489Z'
      numEdits: 0
      reactions: []
    id: 65426c8c41676ceaa2e56cc4
    type: comment
  author: SteadySurfdom
  content: I have downloaded the recommended Tensorflow model from the GitHub ReadMe
    file. But I am not sure how to use that model in Python now. I am new to using
    BERT and its derivatives, so any help would be appreciated.
  created_at: 2023-11-01 14:19:40+00:00
  edited: false
  hidden: false
  id: 65426c8c41676ceaa2e56cc4
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: allenai/scibert_scivocab_uncased
repo_type: model
status: open
target_branch: null
title: Usage in python
