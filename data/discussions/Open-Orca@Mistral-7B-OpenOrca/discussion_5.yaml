!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mzhadigerov
conflicting_files: null
created_at: 2023-10-03 21:15:23+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/18abefb4c2cb745cf3742cd8883635f2.svg
      fullname: Ali Zhadigerov
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mzhadigerov
      type: user
    createdAt: '2023-10-03T22:15:23.000Z'
    data:
      edited: false
      editors:
      - mzhadigerov
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9352500438690186
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/18abefb4c2cb745cf3742cd8883635f2.svg
          fullname: Ali Zhadigerov
          isHf: false
          isPro: false
          name: mzhadigerov
          type: user
        html: '<p>What is the size of VRAM required to run it for inference?</p>

          '
        raw: What is the size of VRAM required to run it for inference?
        updatedAt: '2023-10-03T22:15:23.322Z'
      numEdits: 0
      reactions: []
    id: 651c927b0cd82f89cc2f099a
    type: comment
  author: mzhadigerov
  content: What is the size of VRAM required to run it for inference?
  created_at: 2023-10-03 21:15:23+00:00
  edited: false
  hidden: false
  id: 651c927b0cd82f89cc2f099a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2023-10-05T23:09:24.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8544860482215881
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: '<p>Roughly 14gb vram</p>

          '
        raw: Roughly 14gb vram
        updatedAt: '2023-10-05T23:09:24.846Z'
      numEdits: 0
      reactions: []
    id: 651f422482dbe82d3f5fadf3
    type: comment
  author: YaTharThShaRma999
  content: Roughly 14gb vram
  created_at: 2023-10-05 22:09:24+00:00
  edited: false
  hidden: false
  id: 651f422482dbe82d3f5fadf3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/pYlWSv2_7XPIvB0nB4wYi.jpeg?w=200&h=200&f=face
      fullname: Adirtha Borgohain
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aborgohain
      type: user
    createdAt: '2023-10-06T11:51:34.000Z'
    data:
      edited: false
      editors:
      - aborgohain
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8287485241889954
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/pYlWSv2_7XPIvB0nB4wYi.jpeg?w=200&h=200&f=face
          fullname: Adirtha Borgohain
          isHf: false
          isPro: false
          name: aborgohain
          type: user
        html: '<p>Use quantized GGUF/GGML/AWQ models if you want to run on machines
          with lower computational resources.</p>

          '
        raw: Use quantized GGUF/GGML/AWQ models if you want to run on machines with
          lower computational resources.
        updatedAt: '2023-10-06T11:51:34.326Z'
      numEdits: 0
      reactions: []
    id: 651ff4c6cff71ddb1dcf43c7
    type: comment
  author: aborgohain
  content: Use quantized GGUF/GGML/AWQ models if you want to run on machines with
    lower computational resources.
  created_at: 2023-10-06 10:51:34+00:00
  edited: false
  hidden: false
  id: 651ff4c6cff71ddb1dcf43c7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2023-10-06T12:58:08.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6184309720993042
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: '<p>Yeah then it will be roughly 6gb vram. </p>

          '
        raw: 'Yeah then it will be roughly 6gb vram. '
        updatedAt: '2023-10-06T12:58:08.936Z'
      numEdits: 0
      reactions: []
    id: 65200460bd82b0a6c8960c97
    type: comment
  author: YaTharThShaRma999
  content: 'Yeah then it will be roughly 6gb vram. '
  created_at: 2023-10-06 11:58:08+00:00
  edited: false
  hidden: false
  id: 65200460bd82b0a6c8960c97
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/457bc8db4a0d94789773d29e186cf748.svg
      fullname: Raza Abbas
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: smrazaabbas
      type: user
    createdAt: '2023-11-29T09:47:24.000Z'
    data:
      edited: false
      editors:
      - smrazaabbas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.927189826965332
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/457bc8db4a0d94789773d29e186cf748.svg
          fullname: Raza Abbas
          isHf: false
          isPro: false
          name: smrazaabbas
          type: user
        html: '<p>Can you suggest the smallest SageMaker instance I can use to deploy?
          For some reason loading the model via sample notebook given fails on the
          ml.g5.12xlarge instance even though the VRAM should be enough based on your
          suggestion?</p>

          '
        raw: Can you suggest the smallest SageMaker instance I can use to deploy?
          For some reason loading the model via sample notebook given fails on the
          ml.g5.12xlarge instance even though the VRAM should be enough based on your
          suggestion?
        updatedAt: '2023-11-29T09:47:24.508Z'
      numEdits: 0
      reactions: []
    id: 656708ac0767cf87063faa08
    type: comment
  author: smrazaabbas
  content: Can you suggest the smallest SageMaker instance I can use to deploy? For
    some reason loading the model via sample notebook given fails on the ml.g5.12xlarge
    instance even though the VRAM should be enough based on your suggestion?
  created_at: 2023-11-29 09:47:24+00:00
  edited: false
  hidden: false
  id: 656708ac0767cf87063faa08
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
      fullname: Yatharth  Sharma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: YaTharThShaRma999
      type: user
    createdAt: '2023-12-06T22:33:21.000Z'
    data:
      edited: false
      editors:
      - YaTharThShaRma999
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9353349804878235
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c82779fdf94f80cdb5020504f83c818b.svg
          fullname: Yatharth  Sharma
          isHf: false
          isPro: false
          name: YaTharThShaRma999
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;smrazaabbas&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/smrazaabbas\"\
          >@<span class=\"underline\">smrazaabbas</span></a></span>\n\n\t</span></span>\
          \ you have to use the quantized version with 4 bit. It should work then</p>\n"
        raw: '@smrazaabbas you have to use the quantized version with 4 bit. It should
          work then'
        updatedAt: '2023-12-06T22:33:21.673Z'
      numEdits: 0
      reactions: []
    id: 6570f6b123363fa194ba6dae
    type: comment
  author: YaTharThShaRma999
  content: '@smrazaabbas you have to use the quantized version with 4 bit. It should
    work then'
  created_at: 2023-12-06 22:33:21+00:00
  edited: false
  hidden: false
  id: 6570f6b123363fa194ba6dae
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: Open-Orca/Mistral-7B-OpenOrca
repo_type: model
status: open
target_branch: null
title: Specs for inference
