!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mattma1970
conflicting_files: null
created_at: 2023-11-10 05:15:26+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8addf8cb4b243ac1e2ac14ef1e707f81.svg
      fullname: Matt Ma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: mattma1970
      type: user
    createdAt: '2023-11-10T05:15:26.000Z'
    data:
      edited: false
      editors:
      - mattma1970
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9617547392845154
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8addf8cb4b243ac1e2ac14ef1e707f81.svg
          fullname: Matt Ma
          isHf: false
          isPro: true
          name: mattma1970
          type: user
        html: '<p>I''m serving OpenOrca using HF TGI with stream=True.  The problem
          is that the stopping sequence &lt;|im_end|&gt; consists of 10 tokens . It
          that string is split across two response chunks then it doesn''t get automatically
          removed from the text. </p>

          <p>I know this is a very specific instance but wondering if anyone else
          has encountered this and managed to solve it?</p>

          '
        raw: "I'm serving OpenOrca using HF TGI with stream=True.  The problem is\
          \ that the stopping sequence <|im_end|> consists of 10 tokens . It that\
          \ string is split across two response chunks then it doesn't get automatically\
          \ removed from the text. \r\n\r\nI know this is a very specific instance\
          \ but wondering if anyone else has encountered this and managed to solve\
          \ it?\r\n"
        updatedAt: '2023-11-10T05:15:26.649Z'
      numEdits: 0
      reactions: []
    id: 654dbc6e67555cb9e6cf88fd
    type: comment
  author: mattma1970
  content: "I'm serving OpenOrca using HF TGI with stream=True.  The problem is that\
    \ the stopping sequence <|im_end|> consists of 10 tokens . It that string is split\
    \ across two response chunks then it doesn't get automatically removed from the\
    \ text. \r\n\r\nI know this is a very specific instance but wondering if anyone\
    \ else has encountered this and managed to solve it?\r\n"
  created_at: 2023-11-10 05:15:26+00:00
  edited: false
  hidden: false
  id: 654dbc6e67555cb9e6cf88fd
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae43c3f5ab87b82f4bad25c65ac55d01.svg
      fullname: Junlin Zhou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jlzhou
      type: user
    createdAt: '2023-11-10T12:22:07.000Z'
    data:
      edited: false
      editors:
      - jlzhou
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7959114909172058
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae43c3f5ab87b82f4bad25c65ac55d01.svg
          fullname: Junlin Zhou
          isHf: false
          isPro: false
          name: jlzhou
          type: user
        html: '<p>You need to upgrade the transformers version, mistral support was
          introduced in 4.34.0, TGI 1.1.0 depends on transformers 4.33.3. After upgrading
          transformers my TGI can stop without generating ''&lt;|im_end|&gt;''.</p>

          <p>We build a docker image if you want to use, <code>zjuici/mirror.huggingface.text-generation-inference:1.1.0-transformers-4.34.1</code></p>

          '
        raw: 'You need to upgrade the transformers version, mistral support was introduced
          in 4.34.0, TGI 1.1.0 depends on transformers 4.33.3. After upgrading transformers
          my TGI can stop without generating ''<|im_end|>''.


          We build a docker image if you want to use, `zjuici/mirror.huggingface.text-generation-inference:1.1.0-transformers-4.34.1`'
        updatedAt: '2023-11-10T12:22:07.097Z'
      numEdits: 0
      reactions: []
    id: 654e206f552b35816aa947d5
    type: comment
  author: jlzhou
  content: 'You need to upgrade the transformers version, mistral support was introduced
    in 4.34.0, TGI 1.1.0 depends on transformers 4.33.3. After upgrading transformers
    my TGI can stop without generating ''<|im_end|>''.


    We build a docker image if you want to use, `zjuici/mirror.huggingface.text-generation-inference:1.1.0-transformers-4.34.1`'
  created_at: 2023-11-10 12:22:07+00:00
  edited: false
  hidden: false
  id: 654e206f552b35816aa947d5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8addf8cb4b243ac1e2ac14ef1e707f81.svg
      fullname: Matt Ma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: mattma1970
      type: user
    createdAt: '2023-11-13T01:30:51.000Z'
    data:
      edited: false
      editors:
      - mattma1970
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9395331740379333
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8addf8cb4b243ac1e2ac14ef1e707f81.svg
          fullname: Matt Ma
          isHf: false
          isPro: true
          name: mattma1970
          type: user
        html: '<p>Thanks for helping. I haven''t tried yet. I am running TGI for the
          official docker image so I''m try yours instead. Cheers<br>Matt</p>

          '
        raw: 'Thanks for helping. I haven''t tried yet. I am running TGI for the official
          docker image so I''m try yours instead. Cheers

          Matt

          '
        updatedAt: '2023-11-13T01:30:51.529Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65517c4b380ee26b49f31d83
    id: 65517c4b380ee26b49f31d81
    type: comment
  author: mattma1970
  content: 'Thanks for helping. I haven''t tried yet. I am running TGI for the official
    docker image so I''m try yours instead. Cheers

    Matt

    '
  created_at: 2023-11-13 01:30:51+00:00
  edited: false
  hidden: false
  id: 65517c4b380ee26b49f31d81
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/8addf8cb4b243ac1e2ac14ef1e707f81.svg
      fullname: Matt Ma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: mattma1970
      type: user
    createdAt: '2023-11-13T01:30:51.000Z'
    data:
      status: closed
    id: 65517c4b380ee26b49f31d83
    type: status-change
  author: mattma1970
  created_at: 2023-11-13 01:30:51+00:00
  id: 65517c4b380ee26b49f31d83
  new_status: closed
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/8addf8cb4b243ac1e2ac14ef1e707f81.svg
      fullname: Matt Ma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: mattma1970
      type: user
    createdAt: '2023-11-13T01:37:33.000Z'
    data:
      status: open
    id: 65517ddd8cc59d5b495a1fa9
    type: status-change
  author: mattma1970
  created_at: 2023-11-13 01:37:33+00:00
  id: 65517ddd8cc59d5b495a1fa9
  new_status: open
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8addf8cb4b243ac1e2ac14ef1e707f81.svg
      fullname: Matt Ma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: mattma1970
      type: user
    createdAt: '2023-11-13T01:38:43.000Z'
    data:
      edited: false
      editors:
      - mattma1970
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9040166735649109
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8addf8cb4b243ac1e2ac14ef1e707f81.svg
          fullname: Matt Ma
          isHf: false
          isPro: true
          name: mattma1970
          type: user
        html: '<p>I''m curious about where the change in the transformer version is
          set in the image? (docker novice). </p>

          '
        raw: "I'm curious about where the change in the transformer version is set\
          \ in the image? (docker novice). \n"
        updatedAt: '2023-11-13T01:38:43.708Z'
      numEdits: 0
      reactions: []
    id: 65517e237490049d62530e99
    type: comment
  author: mattma1970
  content: "I'm curious about where the change in the transformer version is set in\
    \ the image? (docker novice). \n"
  created_at: 2023-11-13 01:38:43+00:00
  edited: false
  hidden: false
  id: 65517e237490049d62530e99
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae43c3f5ab87b82f4bad25c65ac55d01.svg
      fullname: Junlin Zhou
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jlzhou
      type: user
    createdAt: '2023-11-13T02:31:16.000Z'
    data:
      edited: false
      editors:
      - jlzhou
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8076239824295044
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae43c3f5ab87b82f4bad25c65ac55d01.svg
          fullname: Junlin Zhou
          isHf: false
          isPro: false
          name: jlzhou
          type: user
        html: '<p>I could not find the Dockerfile right now but it should be as simple
          as (IIRC):</p>

          <pre><code class="language-dockerfile"><span class="hljs-keyword">FROM</span>
          ghcr.io/huggingface/text-generation-inference:<span class="hljs-number">1.1</span>.<span
          class="hljs-number">0</span>


          <span class="hljs-keyword">RUN</span><span class="language-bash"> python
          -m pip install transformers==4.34.1</span>

          </code></pre>

          '
        raw: 'I could not find the Dockerfile right now but it should be as simple
          as (IIRC):


          ```dockerfile

          FROM ghcr.io/huggingface/text-generation-inference:1.1.0


          RUN python -m pip install transformers==4.34.1

          ```'
        updatedAt: '2023-11-13T02:31:16.130Z'
      numEdits: 0
      reactions: []
    id: 65518a741ac896152b653ac6
    type: comment
  author: jlzhou
  content: 'I could not find the Dockerfile right now but it should be as simple as
    (IIRC):


    ```dockerfile

    FROM ghcr.io/huggingface/text-generation-inference:1.1.0


    RUN python -m pip install transformers==4.34.1

    ```'
  created_at: 2023-11-13 02:31:16+00:00
  edited: false
  hidden: false
  id: 65518a741ac896152b653ac6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8addf8cb4b243ac1e2ac14ef1e707f81.svg
      fullname: Matt Ma
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: mattma1970
      type: user
    createdAt: '2023-11-13T03:18:40.000Z'
    data:
      edited: false
      editors:
      - mattma1970
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7788880467414856
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8addf8cb4b243ac1e2ac14ef1e707f81.svg
          fullname: Matt Ma
          isHf: false
          isPro: true
          name: mattma1970
          type: user
        html: '<p>Thanks!</p>

          '
        raw: Thanks!
        updatedAt: '2023-11-13T03:18:40.160Z'
      numEdits: 0
      reactions: []
    id: 655195900c11ee1eb9ffdb31
    type: comment
  author: mattma1970
  content: Thanks!
  created_at: 2023-11-13 03:18:40+00:00
  edited: false
  hidden: false
  id: 655195900c11ee1eb9ffdb31
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 17
repo_id: Open-Orca/Mistral-7B-OpenOrca
repo_type: model
status: open
target_branch: null
title: Problem with streaming support
