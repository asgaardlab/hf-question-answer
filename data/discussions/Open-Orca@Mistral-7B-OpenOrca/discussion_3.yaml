!!python/object:huggingface_hub.community.DiscussionWithDetails
author: joeofportland
conflicting_files: null
created_at: 2023-10-03 06:51:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/25f65f580e5af972c3f64518c41c1bd2.svg
      fullname: Joe
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: joeofportland
      type: user
    createdAt: '2023-10-03T07:51:18.000Z'
    data:
      edited: false
      editors:
      - joeofportland
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5882993340492249
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/25f65f580e5af972c3f64518c41c1bd2.svg
          fullname: Joe
          isHf: false
          isPro: false
          name: joeofportland
          type: user
        html: '<p>Is there a trick to get this work?</p>

          <p>File "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py",
          line 1854, in from_pretrained\n return cls._from_pretrained(\n\n File "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py",
          line 1886, in _from_pretrained\n slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(\n\n
          File "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py",
          line 2073, in _from_pretrained\n raise ValueError(\n\nValueError: Non-consecutive
          added token '''' found. Should have index 32000 but has index 0 in saved
          vocabulary.\n"},"target":"text_generation_launcher","span":{"rank":0,"name":"shard-manager"},"spans":[{"rank":0,"name":"shard-manager"}]}
          2023/10/03 00:35:24 ~ Error: ShardCannotStart</p>

          '
        raw: "Is there a trick to get this work?\r\n\r\nFile \\\"/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\\\
          \", line 1854, in from_pretrained\\n return cls._from_pretrained(\\n\\n\
          \ File \\\"/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\\\
          \", line 1886, in _from_pretrained\\n slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(\\\
          n\\n File \\\"/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\\\
          \", line 2073, in _from_pretrained\\n raise ValueError(\\n\\nValueError:\
          \ Non-consecutive added token '<unk>' found. Should have index 32000 but\
          \ has index 0 in saved vocabulary.\\n\"},\"target\":\"text_generation_launcher\"\
          ,\"span\":{\"rank\":0,\"name\":\"shard-manager\"},\"spans\":[{\"rank\":0,\"\
          name\":\"shard-manager\"}]} 2023/10/03 00:35:24 ~ Error: ShardCannotStart"
        updatedAt: '2023-10-03T07:51:18.382Z'
      numEdits: 0
      reactions: []
    id: 651bc7f61088bf68c3720a48
    type: comment
  author: joeofportland
  content: "Is there a trick to get this work?\r\n\r\nFile \\\"/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\\\
    \", line 1854, in from_pretrained\\n return cls._from_pretrained(\\n\\n File \\\
    \"/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\\\
    \", line 1886, in _from_pretrained\\n slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(\\\
    n\\n File \\\"/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\\\
    \", line 2073, in _from_pretrained\\n raise ValueError(\\n\\nValueError: Non-consecutive\
    \ added token '<unk>' found. Should have index 32000 but has index 0 in saved\
    \ vocabulary.\\n\"},\"target\":\"text_generation_launcher\",\"span\":{\"rank\"\
    :0,\"name\":\"shard-manager\"},\"spans\":[{\"rank\":0,\"name\":\"shard-manager\"\
    }]} 2023/10/03 00:35:24 ~ Error: ShardCannotStart"
  created_at: 2023-10-03 06:51:18+00:00
  edited: false
  hidden: false
  id: 651bc7f61088bf68c3720a48
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
      fullname: ko
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mirek190
      type: user
    createdAt: '2023-10-03T20:22:57.000Z'
    data:
      edited: false
      editors:
      - mirek190
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2394886463880539
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8796019821146893ce5150cec2573a12.svg
          fullname: ko
          isHf: false
          isPro: false
          name: mirek190
          type: user
        html: '<p>use llamaccp and guff format ?</p>

          '
        raw: use llamaccp and guff format ?
        updatedAt: '2023-10-03T20:22:57.429Z'
      numEdits: 0
      reactions: []
    id: 651c7821e648c876f14637f6
    type: comment
  author: mirek190
  content: use llamaccp and guff format ?
  created_at: 2023-10-03 19:22:57+00:00
  edited: false
  hidden: false
  id: 651c7821e648c876f14637f6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9441d895e3308a15a50c5dab942454ff.svg
      fullname: Bleys
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: bleysg
      type: user
    createdAt: '2023-10-03T20:25:08.000Z'
    data:
      edited: false
      editors:
      - bleysg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9420481324195862
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9441d895e3308a15a50c5dab942454ff.svg
          fullname: Bleys
          isHf: false
          isPro: true
          name: bleysg
          type: user
        html: '<p>You''ll need to get into whatever environment you have setup there
          (e.g. conda) and do:</p>

          <pre><code>pip install git+https://github.com/huggingface/transformers

          </code></pre>

          <p>This is because support for Mistral in Transformers is not merged to
          PyPI yet, so you need to install from the development snapshot.</p>

          '
        raw: 'You''ll need to get into whatever environment you have setup there (e.g.
          conda) and do:

          ```

          pip install git+https://github.com/huggingface/transformers

          ```


          This is because support for Mistral in Transformers is not merged to PyPI
          yet, so you need to install from the development snapshot.'
        updatedAt: '2023-10-03T20:25:08.572Z'
      numEdits: 0
      reactions: []
    id: 651c78a40c858cea465983b7
    type: comment
  author: bleysg
  content: 'You''ll need to get into whatever environment you have setup there (e.g.
    conda) and do:

    ```

    pip install git+https://github.com/huggingface/transformers

    ```


    This is because support for Mistral in Transformers is not merged to PyPI yet,
    so you need to install from the development snapshot.'
  created_at: 2023-10-03 19:25:08+00:00
  edited: false
  hidden: false
  id: 651c78a40c858cea465983b7
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: Open-Orca/Mistral-7B-OpenOrca
repo_type: model
status: open
target_branch: null
title: "Can\u2019t get to work in inference endpoints"
