!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MoritzLaurer
conflicting_files: null
created_at: 2022-12-23 10:44:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2022-12-23T10:44:08.000Z'
    data:
      edited: false
      editors:
      - MoritzLaurer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
          fullname: Moritz Laurer
          isHf: true
          isPro: false
          name: MoritzLaurer
          type: user
        html: "<p>When I run the following code with the device_map=\"auto\" argument\
          \ from accelerate, I get the following error. Do you have advice on how\
          \ to make the model run with accelerate? The code provided directly in the\
          \ model card does not throw the error, but it would be great to be able\
          \ to use the model with HF accelerate.</p>\n<pre><code>model_name = \"allenai/tk-instruct-3b-def\"\
          \ \nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\ntokenizer\
          \ = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name,\
          \ torch_dtype=torch.bfloat16, device_map=\"auto\")\n</code></pre>\n<pre><code>NameError\
          \                                 Traceback (most recent call last)\n\n\
          &lt;ipython-input-10-a4310e097fa9&gt; in &lt;module&gt;\n      2 from transformers\
          \ import AutoTokenizer, AutoModelForSeq2SeqLM\n      3 tokenizer = AutoTokenizer.from_pretrained(model_name)\n\
          ----&gt; 4 model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16,\
          \ device_map=\"auto\")\n\n1 frames\n\n/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)\n\
          \   2271             init_contexts = [deepspeed.zero.Init(config_dict_or_path=deepspeed_config())]\
          \ + init_contexts\n   2272         elif load_in_8bit or low_cpu_mem_usage:\n\
          -&gt; 2273             init_contexts.append(init_empty_weights())\n   2274\
          \ \n   2275         with ContextManagers(init_contexts):\n\nNameError: name\
          \ 'init_empty_weights' is not defined\n</code></pre>\n"
        raw: "When I run the following code with the device_map=\"auto\" argument\
          \ from accelerate, I get the following error. Do you have advice on how\
          \ to make the model run with accelerate? The code provided directly in the\
          \ model card does not throw the error, but it would be great to be able\
          \ to use the model with HF accelerate.\r\n\r\n```\r\nmodel_name = \"allenai/tk-instruct-3b-def\"\
          \ \r\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\r\n\
          tokenizer = AutoTokenizer.from_pretrained(model_name)\r\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name,\
          \ torch_dtype=torch.bfloat16, device_map=\"auto\")\r\n```\r\n\r\n```\r\n\
          NameError                                 Traceback (most recent call last)\r\
          \n\r\n<ipython-input-10-a4310e097fa9> in <module>\r\n      2 from transformers\
          \ import AutoTokenizer, AutoModelForSeq2SeqLM\r\n      3 tokenizer = AutoTokenizer.from_pretrained(model_name)\r\
          \n----> 4 model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16,\
          \ device_map=\"auto\")\r\n\r\n1 frames\r\n\r\n/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)\r\
          \n   2271             init_contexts = [deepspeed.zero.Init(config_dict_or_path=deepspeed_config())]\
          \ + init_contexts\r\n   2272         elif load_in_8bit or low_cpu_mem_usage:\r\
          \n-> 2273             init_contexts.append(init_empty_weights())\r\n   2274\
          \ \r\n   2275         with ContextManagers(init_contexts):\r\n\r\nNameError:\
          \ name 'init_empty_weights' is not defined\r\n```\r\n\r\n\r\n"
        updatedAt: '2022-12-23T10:44:08.106Z'
      numEdits: 0
      reactions: []
    id: 63a5867864f470027813cb4e
    type: comment
  author: MoritzLaurer
  content: "When I run the following code with the device_map=\"auto\" argument from\
    \ accelerate, I get the following error. Do you have advice on how to make the\
    \ model run with accelerate? The code provided directly in the model card does\
    \ not throw the error, but it would be great to be able to use the model with\
    \ HF accelerate.\r\n\r\n```\r\nmodel_name = \"allenai/tk-instruct-3b-def\" \r\n\
    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\r\ntokenizer = AutoTokenizer.from_pretrained(model_name)\r\
    \nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16,\
    \ device_map=\"auto\")\r\n```\r\n\r\n```\r\nNameError                        \
    \         Traceback (most recent call last)\r\n\r\n<ipython-input-10-a4310e097fa9>\
    \ in <module>\r\n      2 from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\r\
    \n      3 tokenizer = AutoTokenizer.from_pretrained(model_name)\r\n----> 4 model\
    \ = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16,\
    \ device_map=\"auto\")\r\n\r\n1 frames\r\n\r\n/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\
    \ in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)\r\
    \n   2271             init_contexts = [deepspeed.zero.Init(config_dict_or_path=deepspeed_config())]\
    \ + init_contexts\r\n   2272         elif load_in_8bit or low_cpu_mem_usage:\r\
    \n-> 2273             init_contexts.append(init_empty_weights())\r\n   2274 \r\
    \n   2275         with ContextManagers(init_contexts):\r\n\r\nNameError: name\
    \ 'init_empty_weights' is not defined\r\n```\r\n\r\n\r\n"
  created_at: 2022-12-23 10:44:08+00:00
  edited: false
  hidden: false
  id: 63a5867864f470027813cb4e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2022-12-23T11:26:17.000Z'
    data:
      edited: false
      editors:
      - MoritzLaurer
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
          fullname: Moritz Laurer
          isHf: true
          isPro: false
          name: MoritzLaurer
          type: user
        html: '<p>weird, after further tests (loading different sizes and changing
          arguments around) I do not get this error anymore, even with the exact same
          code as above. You can ignore this issue (just leaving it here in case others
          encounter it again)</p>

          '
        raw: weird, after further tests (loading different sizes and changing arguments
          around) I do not get this error anymore, even with the exact same code as
          above. You can ignore this issue (just leaving it here in case others encounter
          it again)
        updatedAt: '2022-12-23T11:26:17.532Z'
      numEdits: 0
      reactions: []
      relatedEventId: 63a59059832a40058005e5c2
    id: 63a59059832a40058005e5c1
    type: comment
  author: MoritzLaurer
  content: weird, after further tests (loading different sizes and changing arguments
    around) I do not get this error anymore, even with the exact same code as above.
    You can ignore this issue (just leaving it here in case others encounter it again)
  created_at: 2022-12-23 11:26:17+00:00
  edited: false
  hidden: false
  id: 63a59059832a40058005e5c1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2022-12-23T11:26:17.000Z'
    data:
      status: closed
    id: 63a59059832a40058005e5c2
    type: status-change
  author: MoritzLaurer
  created_at: 2022-12-23 11:26:17+00:00
  id: 63a59059832a40058005e5c2
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: allenai/tk-instruct-3b-def
repo_type: model
status: closed
target_branch: null
title: 'NameError: name ''init_empty_weights'' is not defined'
