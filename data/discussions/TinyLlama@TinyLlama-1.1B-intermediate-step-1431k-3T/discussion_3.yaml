!!python/object:huggingface_hub.community.DiscussionWithDetails
author: danielhanchen
conflicting_files: null
created_at: 2024-01-01 15:43:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ecdc18b72a69615d6bd857/ixLCk0TwaCVyL_nAfrgEs.png?w=200&h=200&f=face
      fullname: Daniel Han-Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: danielhanchen
      type: user
    createdAt: '2024-01-01T15:43:08.000Z'
    data:
      edited: false
      editors:
      - danielhanchen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6133217811584473
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ecdc18b72a69615d6bd857/ixLCk0TwaCVyL_nAfrgEs.png?w=200&h=200&f=face
          fullname: Daniel Han-Chen
          isHf: false
          isPro: false
          name: danielhanchen
          type: user
        html: "<p>Great work again on TInyLlama!</p>\n<p>I tried loading this on <code>transformers==4.37.0.dev0</code>\
          \ and sadly it doesn't work :( The Chat one successfully loads though!</p>\n\
          <pre><code>config.json: 100%\n560/560 [00:00&lt;00:00, 36.3kB/s]\npytorch_model.bin:\
          \ 100%\n4.40G/4.40G [00:18&lt;00:00, 239MB/s]\n\n---------------------------------------------------------------------------\n\
          \nUnpicklingError                           Traceback (most recent call\
          \ last)\n\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\
          \ in load_state_dict(checkpoint_file)\n    518 \n--&gt; 519         return\
          \ torch.load(checkpoint_file, map_location=map_location, weights_only=True)\n\
          \    520     except Exception as e:\n\n6 frames\n\nUnpicklingError: Weights\
          \ only load failed. Re-running `torch.load` with `weights_only` set to `False`\
          \ will likely succeed, but it can result in arbitrary code execution.Do\
          \ it only if you get the file from a trusted source. WeightsUnpickler error:\
          \ Unsupported operand 149\n\n\nDuring handling of the above exception, another\
          \ exception occurred:\n\nUnicodeDecodeError                        Traceback\
          \ (most recent call last)\n\nUnicodeDecodeError: 'utf-8' codec can't decode\
          \ byte 0xc1 in position 70: invalid start byte\n\n\nDuring handling of the\
          \ above exception, another exception occurred:\n\nOSError              \
          \                     Traceback (most recent call last)\n\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\
          \ in load_state_dict(checkpoint_file)\n    533                     ) from\
          \ e\n    534         except (UnicodeDecodeError, ValueError):\n--&gt; 535\
          \             raise OSError(\n    536                 f\"Unable to load\
          \ weights from pytorch checkpoint file for '{checkpoint_file}' \"\n    537\
          \                 f\"at '{checkpoint_file}'. \"\n\nOSError: Unable to load\
          \ weights from pytorch checkpoint file for '/root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/4b8dd7e43ec08c24ccaf89cbf67898cff53c95ae/pytorch_model.bin'\
          \ at '/root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/4b8dd7e43ec08c24ccaf89cbf67898cff53c95ae/pytorch_model.bin'.\
          \ If you tried to load a PyTorch model from a TF 2.0 checkpoint, please\
          \ set from_tf=True.\n</code></pre>\n<p>I also tried <code>from_tf  = True</code>:</p>\n\
          <pre><code>---------------------------------------------------------------------------\n\
          \nOSError                                   Traceback (most recent call\
          \ last)\n\n&lt;ipython-input-20-be4f4485136b&gt; in &lt;cell line: 25&gt;()\n\
          \     23     bnb_4bit_compute_dtype    = dtype,\n     24 )\n---&gt; 25 model\
          \ = AutoModelForCausalLM.from_pretrained(\n     26     model_name,\n   \
          \  27     device_map = \"sequential\",\n\n1 frames\n\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, config, cache_dir,\
          \ ignore_mismatched_sizes, force_download, local_files_only, token, revision,\
          \ use_safetensors, *model_args, **kwargs)\n   3351                     \
          \        )\n   3352                         else:\n-&gt; 3353          \
          \                   raise EnvironmentError(\n   3354                   \
          \              f\"{pretrained_model_name_or_path} does not appear to have\
          \ a file named\"\n   3355                                 f\" {_add_variant(WEIGHTS_NAME,\
          \ variant)}, {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or\"\n\nOSError: TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\
          \ does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt\
          \ or flax_model.msgpack.\n</code></pre>\n<p>Again great work!</p>\n"
        raw: "Great work again on TInyLlama!\r\n\r\nI tried loading this on `transformers==4.37.0.dev0`\
          \ and sadly it doesn't work :( The Chat one successfully loads though!\r\
          \n\r\n```\r\nconfig.json: 100%\r\n560/560 [00:00<00:00, 36.3kB/s]\r\npytorch_model.bin:\
          \ 100%\r\n4.40G/4.40G [00:18<00:00, 239MB/s]\r\n\r\n---------------------------------------------------------------------------\r\
          \n\r\nUnpicklingError                           Traceback (most recent call\
          \ last)\r\n\r\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\
          \ in load_state_dict(checkpoint_file)\r\n    518 \r\n--> 519         return\
          \ torch.load(checkpoint_file, map_location=map_location, weights_only=True)\r\
          \n    520     except Exception as e:\r\n\r\n6 frames\r\n\r\nUnpicklingError:\
          \ Weights only load failed. Re-running `torch.load` with `weights_only`\
          \ set to `False` will likely succeed, but it can result in arbitrary code\
          \ execution.Do it only if you get the file from a trusted source. WeightsUnpickler\
          \ error: Unsupported operand 149\r\n\r\n\r\nDuring handling of the above\
          \ exception, another exception occurred:\r\n\r\nUnicodeDecodeError     \
          \                   Traceback (most recent call last)\r\n\r\nUnicodeDecodeError:\
          \ 'utf-8' codec can't decode byte 0xc1 in position 70: invalid start byte\r\
          \n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nOSError                                   Traceback (most recent call\
          \ last)\r\n\r\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\
          \ in load_state_dict(checkpoint_file)\r\n    533                     ) from\
          \ e\r\n    534         except (UnicodeDecodeError, ValueError):\r\n--> 535\
          \             raise OSError(\r\n    536                 f\"Unable to load\
          \ weights from pytorch checkpoint file for '{checkpoint_file}' \"\r\n  \
          \  537                 f\"at '{checkpoint_file}'. \"\r\n\r\nOSError: Unable\
          \ to load weights from pytorch checkpoint file for '/root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/4b8dd7e43ec08c24ccaf89cbf67898cff53c95ae/pytorch_model.bin'\
          \ at '/root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/4b8dd7e43ec08c24ccaf89cbf67898cff53c95ae/pytorch_model.bin'.\
          \ If you tried to load a PyTorch model from a TF 2.0 checkpoint, please\
          \ set from_tf=True.\r\n```\r\n\r\nI also tried `from_tf  = True`:\r\n```\r\
          \n---------------------------------------------------------------------------\r\
          \n\r\nOSError                                   Traceback (most recent call\
          \ last)\r\n\r\n<ipython-input-20-be4f4485136b> in <cell line: 25>()\r\n\
          \     23     bnb_4bit_compute_dtype    = dtype,\r\n     24 )\r\n---> 25\
          \ model = AutoModelForCausalLM.from_pretrained(\r\n     26     model_name,\r\
          \n     27     device_map = \"sequential\",\r\n\r\n1 frames\r\n\r\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\
          \ in from_pretrained(cls, pretrained_model_name_or_path, config, cache_dir,\
          \ ignore_mismatched_sizes, force_download, local_files_only, token, revision,\
          \ use_safetensors, *model_args, **kwargs)\r\n   3351                   \
          \          )\r\n   3352                         else:\r\n-> 3353       \
          \                      raise EnvironmentError(\r\n   3354              \
          \                   f\"{pretrained_model_name_or_path} does not appear to\
          \ have a file named\"\r\n   3355                                 f\" {_add_variant(WEIGHTS_NAME,\
          \ variant)}, {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or\"\r\n\r\nOSError:\
          \ TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T does not appear to\
          \ have a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.\r\
          \n```\r\n\r\nAgain great work!"
        updatedAt: '2024-01-01T15:43:08.461Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - zhuocheng
    id: 6592dd8c075245eadd0f8a3d
    type: comment
  author: danielhanchen
  content: "Great work again on TInyLlama!\r\n\r\nI tried loading this on `transformers==4.37.0.dev0`\
    \ and sadly it doesn't work :( The Chat one successfully loads though!\r\n\r\n\
    ```\r\nconfig.json: 100%\r\n560/560 [00:00<00:00, 36.3kB/s]\r\npytorch_model.bin:\
    \ 100%\r\n4.40G/4.40G [00:18<00:00, 239MB/s]\r\n\r\n---------------------------------------------------------------------------\r\
    \n\r\nUnpicklingError                           Traceback (most recent call last)\r\
    \n\r\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py in\
    \ load_state_dict(checkpoint_file)\r\n    518 \r\n--> 519         return torch.load(checkpoint_file,\
    \ map_location=map_location, weights_only=True)\r\n    520     except Exception\
    \ as e:\r\n\r\n6 frames\r\n\r\nUnpicklingError: Weights only load failed. Re-running\
    \ `torch.load` with `weights_only` set to `False` will likely succeed, but it\
    \ can result in arbitrary code execution.Do it only if you get the file from a\
    \ trusted source. WeightsUnpickler error: Unsupported operand 149\r\n\r\n\r\n\
    During handling of the above exception, another exception occurred:\r\n\r\nUnicodeDecodeError\
    \                        Traceback (most recent call last)\r\n\r\nUnicodeDecodeError:\
    \ 'utf-8' codec can't decode byte 0xc1 in position 70: invalid start byte\r\n\r\
    \n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\
    \nOSError                                   Traceback (most recent call last)\r\
    \n\r\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py in\
    \ load_state_dict(checkpoint_file)\r\n    533                     ) from e\r\n\
    \    534         except (UnicodeDecodeError, ValueError):\r\n--> 535         \
    \    raise OSError(\r\n    536                 f\"Unable to load weights from\
    \ pytorch checkpoint file for '{checkpoint_file}' \"\r\n    537              \
    \   f\"at '{checkpoint_file}'. \"\r\n\r\nOSError: Unable to load weights from\
    \ pytorch checkpoint file for '/root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/4b8dd7e43ec08c24ccaf89cbf67898cff53c95ae/pytorch_model.bin'\
    \ at '/root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/4b8dd7e43ec08c24ccaf89cbf67898cff53c95ae/pytorch_model.bin'.\
    \ If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.\r\
    \n```\r\n\r\nI also tried `from_tf  = True`:\r\n```\r\n---------------------------------------------------------------------------\r\
    \n\r\nOSError                                   Traceback (most recent call last)\r\
    \n\r\n<ipython-input-20-be4f4485136b> in <cell line: 25>()\r\n     23     bnb_4bit_compute_dtype\
    \    = dtype,\r\n     24 )\r\n---> 25 model = AutoModelForCausalLM.from_pretrained(\r\
    \n     26     model_name,\r\n     27     device_map = \"sequential\",\r\n\r\n\
    1 frames\r\n\r\n/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\
    \ in from_pretrained(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes,\
    \ force_download, local_files_only, token, revision, use_safetensors, *model_args,\
    \ **kwargs)\r\n   3351                             )\r\n   3352              \
    \           else:\r\n-> 3353                             raise EnvironmentError(\r\
    \n   3354                                 f\"{pretrained_model_name_or_path} does\
    \ not appear to have a file named\"\r\n   3355                               \
    \  f\" {_add_variant(WEIGHTS_NAME, variant)}, {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME}\
    \ or\"\r\n\r\nOSError: TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T does\
    \ not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or\
    \ flax_model.msgpack.\r\n```\r\n\r\nAgain great work!"
  created_at: 2024-01-01 15:43:08+00:00
  edited: false
  hidden: false
  id: 6592dd8c075245eadd0f8a3d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a1a1f0f30c4642277600e2/pWDppszNjTw_qHkT9S0vd.jpeg?w=200&h=200&f=face
      fullname: Devasheesh Mishra
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: devasheeshG
      type: user
    createdAt: '2024-01-01T19:13:14.000Z'
    data:
      edited: false
      editors:
      - devasheeshG
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8789965510368347
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a1a1f0f30c4642277600e2/pWDppszNjTw_qHkT9S0vd.jpeg?w=200&h=200&f=face
          fullname: Devasheesh Mishra
          isHf: false
          isPro: false
          name: devasheeshG
          type: user
        html: '<p>can you share the code you used for loading the model :)</p>

          '
        raw: can you share the code you used for loading the model :)
        updatedAt: '2024-01-01T19:13:14.639Z'
      numEdits: 0
      reactions: []
    id: 65930eca35331883759e3b5e
    type: comment
  author: devasheeshG
  content: can you share the code you used for loading the model :)
  created_at: 2024-01-01 19:13:14+00:00
  edited: false
  hidden: false
  id: 65930eca35331883759e3b5e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ecdc18b72a69615d6bd857/ixLCk0TwaCVyL_nAfrgEs.png?w=200&h=200&f=face
      fullname: Daniel Han-Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: danielhanchen
      type: user
    createdAt: '2024-01-02T02:33:37.000Z'
    data:
      edited: false
      editors:
      - danielhanchen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.775033712387085
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ecdc18b72a69615d6bd857/ixLCk0TwaCVyL_nAfrgEs.png?w=200&h=200&f=face
          fullname: Daniel Han-Chen
          isHf: false
          isPro: false
          name: danielhanchen
          type: user
        html: "<p>Interestingly I just noticed the stable release of transformers==4.36.2\
          \ works fine! It might be an issue only with 4.37.</p>\n<p>Oh my code is\
          \ literally the normal code for loading:</p>\n<pre><code>model = AutoModelForCausalLM.from_pretrained(\n\
          \    \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\",\n    torch_dtype\
          \ = torch.bfloat16,\n)\n</code></pre>\n"
        raw: "Interestingly I just noticed the stable release of transformers==4.36.2\
          \ works fine! It might be an issue only with 4.37.\n\nOh my code is literally\
          \ the normal code for loading:\n```\nmodel = AutoModelForCausalLM.from_pretrained(\n\
          \    \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\",\n    torch_dtype\
          \ = torch.bfloat16,\n)\n```"
        updatedAt: '2024-01-02T02:33:37.084Z'
      numEdits: 0
      reactions: []
    id: 6593760152dc1046ca713dd2
    type: comment
  author: danielhanchen
  content: "Interestingly I just noticed the stable release of transformers==4.36.2\
    \ works fine! It might be an issue only with 4.37.\n\nOh my code is literally\
    \ the normal code for loading:\n```\nmodel = AutoModelForCausalLM.from_pretrained(\n\
    \    \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\",\n    torch_dtype\
    \ = torch.bfloat16,\n)\n```"
  created_at: 2024-01-02 02:33:37+00:00
  edited: false
  hidden: false
  id: 6593760152dc1046ca713dd2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/770e9e63ec55f1a9c5915f1e37d8e66d.svg
      fullname: Manish Prakash
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: manishiitg
      type: user
    createdAt: '2024-01-04T12:58:13.000Z'
    data:
      edited: false
      editors:
      - manishiitg
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9075469970703125
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/770e9e63ec55f1a9c5915f1e37d8e66d.svg
          fullname: Manish Prakash
          isHf: false
          isPro: false
          name: manishiitg
          type: user
        html: '<p>getting the same issue </p>

          '
        raw: 'getting the same issue '
        updatedAt: '2024-01-04T12:58:13.817Z'
      numEdits: 0
      reactions: []
    id: 6596ab65225b6af72f582433
    type: comment
  author: manishiitg
  content: 'getting the same issue '
  created_at: 2024-01-04 12:58:13+00:00
  edited: false
  hidden: false
  id: 6596ab65225b6af72f582433
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ecdc18b72a69615d6bd857/ixLCk0TwaCVyL_nAfrgEs.png?w=200&h=200&f=face
      fullname: Daniel Han-Chen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: danielhanchen
      type: user
    createdAt: '2024-01-05T02:56:21.000Z'
    data:
      edited: false
      editors:
      - danielhanchen
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6782448887825012
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ecdc18b72a69615d6bd857/ixLCk0TwaCVyL_nAfrgEs.png?w=200&h=200&f=face
          fullname: Daniel Han-Chen
          isHf: false
          isPro: false
          name: danielhanchen
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;manishiitg&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/manishiitg\">@<span class=\"\
          underline\">manishiitg</span></a></span>\n\n\t</span></span> I reuploaded\
          \ it at <a href=\"https://huggingface.co/unsloth/tinyllama\">https://huggingface.co/unsloth/tinyllama</a>\
          \ to work for the transformers dev branch!</p>\n"
        raw: '@manishiitg I reuploaded it at https://huggingface.co/unsloth/tinyllama
          to work for the transformers dev branch!'
        updatedAt: '2024-01-05T02:56:21.697Z'
      numEdits: 0
      reactions: []
    id: 65976fd504f13fb853d1a64d
    type: comment
  author: danielhanchen
  content: '@manishiitg I reuploaded it at https://huggingface.co/unsloth/tinyllama
    to work for the transformers dev branch!'
  created_at: 2024-01-05 02:56:21+00:00
  edited: false
  hidden: false
  id: 65976fd504f13fb853d1a64d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9f3f0c5cef13fcc08daa3bb114ffb50a.svg
      fullname: Zhuocheng Zhang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zhuocheng
      type: user
    createdAt: '2024-01-23T08:01:45.000Z'
    data:
      edited: false
      editors:
      - zhuocheng
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7411078810691833
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9f3f0c5cef13fcc08daa3bb114ffb50a.svg
          fullname: Zhuocheng Zhang
          isHf: false
          isPro: false
          name: zhuocheng
          type: user
        html: '<p>This is caused by <a rel="nofollow" href="https://github.com/huggingface/transformers/pull/28506">safe
          loading</a> feature introduced by transformers==4.37, which add weights_only=True
          argument to the torch.load function. To fix this issue, you can simply load
          and re-save the model using the latest pytorch.</p>

          <pre><code class="language-python"><span class="hljs-keyword">import</span>
          torch


          model = torch.load(<span class="hljs-string">''pytorch_model.bin''</span>)

          torch.save(model, <span class="hljs-string">''pytorch_model.bin''</span>)

          </code></pre>

          '
        raw: 'This is caused by [safe loading](https://github.com/huggingface/transformers/pull/28506)
          feature introduced by transformers==4.37, which add weights_only=True argument
          to the torch.load function. To fix this issue, you can simply load and re-save
          the model using the latest pytorch.

          ```python

          import torch


          model = torch.load(''pytorch_model.bin'')

          torch.save(model, ''pytorch_model.bin'')

          ```'
        updatedAt: '2024-01-23T08:01:45.918Z'
      numEdits: 0
      reactions: []
    id: 65af72693e82498d4c629fbc
    type: comment
  author: zhuocheng
  content: 'This is caused by [safe loading](https://github.com/huggingface/transformers/pull/28506)
    feature introduced by transformers==4.37, which add weights_only=True argument
    to the torch.load function. To fix this issue, you can simply load and re-save
    the model using the latest pytorch.

    ```python

    import torch


    model = torch.load(''pytorch_model.bin'')

    torch.save(model, ''pytorch_model.bin'')

    ```'
  created_at: 2024-01-23 08:01:45+00:00
  edited: false
  hidden: false
  id: 65af72693e82498d4c629fbc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 3
repo_id: TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T
repo_type: model
status: open
target_branch: null
title: Pickling error - cannot load on transformers==4.37.0.dev0
