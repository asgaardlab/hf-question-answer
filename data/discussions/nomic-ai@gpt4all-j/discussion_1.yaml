!!python/object:huggingface_hub.community.DiscussionWithDetails
author: saurabh48782
conflicting_files: null
created_at: 2023-04-28 10:43:28+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/875a10e6ad1d860bf665275513a0fbed.svg
      fullname: Saurabh Gupta
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: saurabh48782
      type: user
    createdAt: '2023-04-28T11:43:28.000Z'
    data:
      edited: false
      editors:
      - saurabh48782
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/875a10e6ad1d860bf665275513a0fbed.svg
          fullname: Saurabh Gupta
          isHf: false
          isPro: false
          name: saurabh48782
          type: user
        html: '<p>I was wondering, Is there a way we can use this model with LangChain
          for creating a model that can answer to questions based on corpus of text
          present inside a custom pdf documents.</p>

          '
        raw: I was wondering, Is there a way we can use this model with LangChain
          for creating a model that can answer to questions based on corpus of text
          present inside a custom pdf documents.
        updatedAt: '2023-04-28T11:43:28.837Z'
      numEdits: 0
      reactions: []
    id: 644bb160c2c8f1229870642c
    type: comment
  author: saurabh48782
  content: I was wondering, Is there a way we can use this model with LangChain for
    creating a model that can answer to questions based on corpus of text present
    inside a custom pdf documents.
  created_at: 2023-04-28 10:43:28+00:00
  edited: false
  hidden: false
  id: 644bb160c2c8f1229870642c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ae6d424eb50b94c7e082ebd1b52bdce4.svg
      fullname: Kevin Helvig
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: khelvig97
      type: user
    createdAt: '2023-05-02T12:31:47.000Z'
    data:
      edited: false
      editors:
      - khelvig97
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ae6d424eb50b94c7e082ebd1b52bdce4.svg
          fullname: Kevin Helvig
          isHf: false
          isPro: false
          name: khelvig97
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2023-05-02T12:31:47.279Z'
      numEdits: 0
      reactions: []
    id: 645102b35fb40b9f50a63fed
    type: comment
  author: khelvig97
  content: '+1'
  created_at: 2023-05-02 11:31:47+00:00
  edited: false
  hidden: false
  id: 645102b35fb40b9f50a63fed
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7fb7b0ba1ca8be5adf410573e79ecd31.svg
      fullname: guillaume
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: odysseus340
      type: user
    createdAt: '2023-05-07T13:51:09.000Z'
    data:
      edited: false
      editors:
      - odysseus340
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7fb7b0ba1ca8be5adf410573e79ecd31.svg
          fullname: guillaume
          isHf: false
          isPro: false
          name: odysseus340
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2023-05-07T13:51:09.478Z'
      numEdits: 0
      reactions: []
    id: 6457accdcf099a9dd14e9763
    type: comment
  author: odysseus340
  content: '+1'
  created_at: 2023-05-07 12:51:09+00:00
  edited: false
  hidden: false
  id: 6457accdcf099a9dd14e9763
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e012b92026493a702bfc527c3acfee25.svg
      fullname: Zeyad Al Mothafar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zeyadAlMothafar
      type: user
    createdAt: '2023-05-08T04:43:26.000Z'
    data:
      edited: false
      editors:
      - zeyadAlMothafar
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e012b92026493a702bfc527c3acfee25.svg
          fullname: Zeyad Al Mothafar
          isHf: false
          isPro: false
          name: zeyadAlMothafar
          type: user
        html: '<p>+1</p>

          '
        raw: '+1'
        updatedAt: '2023-05-08T04:43:26.727Z'
      numEdits: 0
      reactions: []
    id: 64587dee0332c1fb59fcb268
    type: comment
  author: zeyadAlMothafar
  content: '+1'
  created_at: 2023-05-08 03:43:26+00:00
  edited: false
  hidden: false
  id: 64587dee0332c1fb59fcb268
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7fb7b0ba1ca8be5adf410573e79ecd31.svg
      fullname: guillaume
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: odysseus340
      type: user
    createdAt: '2023-05-08T05:34:36.000Z'
    data:
      edited: false
      editors:
      - odysseus340
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7fb7b0ba1ca8be5adf410573e79ecd31.svg
          fullname: guillaume
          isHf: false
          isPro: false
          name: odysseus340
          type: user
        html: '<p>there is a tuto to integrate dolly (open source) as LLM under langchain<br><a
          rel="nofollow" href="https://www.dbdemos.ai/demo-notebooks.html?demoName=llm-dolly-chatbot">https://www.dbdemos.ai/demo-notebooks.html?demoName=llm-dolly-chatbot</a></p>

          <p>but I did not manage to do it. Maybe there could be a simplified version.<br>if
          someone has the talent to to do it...</p>

          '
        raw: "there is a tuto to integrate dolly (open source) as LLM under langchain\n\
          https://www.dbdemos.ai/demo-notebooks.html?demoName=llm-dolly-chatbot\n\n\
          but I did not manage to do it. Maybe there could be a simplified version.\
          \ \nif someone has the talent to to do it..."
        updatedAt: '2023-05-08T05:34:36.624Z'
      numEdits: 0
      reactions: []
    id: 645889ecc9af80de217d4bfa
    type: comment
  author: odysseus340
  content: "there is a tuto to integrate dolly (open source) as LLM under langchain\n\
    https://www.dbdemos.ai/demo-notebooks.html?demoName=llm-dolly-chatbot\n\nbut I\
    \ did not manage to do it. Maybe there could be a simplified version. \nif someone\
    \ has the talent to to do it..."
  created_at: 2023-05-08 04:34:36+00:00
  edited: false
  hidden: false
  id: 645889ecc9af80de217d4bfa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e012b92026493a702bfc527c3acfee25.svg
      fullname: Zeyad Al Mothafar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: zeyadAlMothafar
      type: user
    createdAt: '2023-05-08T06:52:03.000Z'
    data:
      edited: false
      editors:
      - zeyadAlMothafar
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e012b92026493a702bfc527c3acfee25.svg
          fullname: Zeyad Al Mothafar
          isHf: false
          isPro: false
          name: zeyadAlMothafar
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;odysseus340&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/odysseus340\"\
          >@<span class=\"underline\">odysseus340</span></a></span>\n\n\t</span></span>\
          \ this guide looks promising but it needs a cluster with GPU on the cloud,\
          \ i will try it on Google Colab PRO then i will try it on my personal PC\
          \ with 32gb RAM but will use the 3B parameters dolly on my PC instead.<br>ill\
          \ let you know if this works, thanks for sharing!</p>\n"
        raw: '@odysseus340 this guide looks promising but it needs a cluster with
          GPU on the cloud, i will try it on Google Colab PRO then i will try it on
          my personal PC with 32gb RAM but will use the 3B parameters dolly on my
          PC instead.

          ill let you know if this works, thanks for sharing!'
        updatedAt: '2023-05-08T06:52:03.377Z'
      numEdits: 0
      reactions: []
    id: 64589c13f92601affa27cc17
    type: comment
  author: zeyadAlMothafar
  content: '@odysseus340 this guide looks promising but it needs a cluster with GPU
    on the cloud, i will try it on Google Colab PRO then i will try it on my personal
    PC with 32gb RAM but will use the 3B parameters dolly on my PC instead.

    ill let you know if this works, thanks for sharing!'
  created_at: 2023-05-08 05:52:03+00:00
  edited: false
  hidden: false
  id: 64589c13f92601affa27cc17
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643807cd819f3ab20d17266d/rE_uTjsAXXy26pQewm8c_.png?w=200&h=200&f=face
      fullname: qm9 (Casalioy Research)
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: qm9
      type: user
    createdAt: '2023-05-10T19:56:59.000Z'
    data:
      edited: true
      editors:
      - qm9
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643807cd819f3ab20d17266d/rE_uTjsAXXy26pQewm8c_.png?w=200&h=200&f=face
          fullname: qm9 (Casalioy Research)
          isHf: false
          isPro: false
          name: qm9
          type: user
        html: '<p><a rel="nofollow" href="https://github.com/su77ungr/CASALIOY">https://github.com/su77ungr/CASALIOY</a></p>

          <p>ingesting .txt locally. just convert pdf to text before</p>

          '
        raw: 'https://github.com/su77ungr/CASALIOY


          ingesting .txt locally. just convert pdf to text before'
        updatedAt: '2023-05-10T19:57:39.557Z'
      numEdits: 2
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - qm9
    id: 645bf70b337b2ccf07fdc371
    type: comment
  author: qm9
  content: 'https://github.com/su77ungr/CASALIOY


    ingesting .txt locally. just convert pdf to text before'
  created_at: 2023-05-10 18:56:59+00:00
  edited: true
  hidden: false
  id: 645bf70b337b2ccf07fdc371
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643807cd819f3ab20d17266d/rE_uTjsAXXy26pQewm8c_.png?w=200&h=200&f=face
      fullname: qm9 (Casalioy Research)
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: qm9
      type: user
    createdAt: '2023-05-12T07:43:03.000Z'
    data:
      edited: false
      editors:
      - qm9
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643807cd819f3ab20d17266d/rE_uTjsAXXy26pQewm8c_.png?w=200&h=200&f=face
          fullname: qm9 (Casalioy Research)
          isHf: false
          isPro: false
          name: qm9
          type: user
        html: '<p>I''m running 30ms per Token on a i5-9600k and 16GB. Using 7B Vicuna
          and Qdrant. You soon won''t be using OpenAI anymore</p>

          '
        raw: I'm running 30ms per Token on a i5-9600k and 16GB. Using 7B Vicuna and
          Qdrant. You soon won't be using OpenAI anymore
        updatedAt: '2023-05-12T07:43:03.541Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - odysseus340
        - marcusdusd
    id: 645dee07fa43f072e93d5c9c
    type: comment
  author: qm9
  content: I'm running 30ms per Token on a i5-9600k and 16GB. Using 7B Vicuna and
    Qdrant. You soon won't be using OpenAI anymore
  created_at: 2023-05-12 06:43:03+00:00
  edited: false
  hidden: false
  id: 645dee07fa43f072e93d5c9c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7fb7b0ba1ca8be5adf410573e79ecd31.svg
      fullname: guillaume
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: odysseus340
      type: user
    createdAt: '2023-05-12T08:08:57.000Z'
    data:
      edited: false
      editors:
      - odysseus340
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7fb7b0ba1ca8be5adf410573e79ecd31.svg
          fullname: guillaume
          isHf: false
          isPro: false
          name: odysseus340
          type: user
        html: '<p>That sounds incredible!!!<br>maybe you know this one already. I
          have discovered sagemaker yesterday: <a rel="nofollow" href="https://studiolab.sagemaker.aws/">https://studiolab.sagemaker.aws/</a><br>it
          is a kind of free google collab on steroids.</p>

          '
        raw: 'That sounds incredible!!!

          maybe you know this one already. I have discovered sagemaker yesterday:
          https://studiolab.sagemaker.aws/

          it is a kind of free google collab on steroids.'
        updatedAt: '2023-05-12T08:08:57.514Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - qm9
    id: 645df419faa533beced05e52
    type: comment
  author: odysseus340
  content: 'That sounds incredible!!!

    maybe you know this one already. I have discovered sagemaker yesterday: https://studiolab.sagemaker.aws/

    it is a kind of free google collab on steroids.'
  created_at: 2023-05-12 07:08:57+00:00
  edited: false
  hidden: false
  id: 645df419faa533beced05e52
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643807cd819f3ab20d17266d/rE_uTjsAXXy26pQewm8c_.png?w=200&h=200&f=face
      fullname: qm9 (Casalioy Research)
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: qm9
      type: user
    createdAt: '2023-05-12T15:29:42.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/643807cd819f3ab20d17266d/rE_uTjsAXXy26pQewm8c_.png?w=200&h=200&f=face
          fullname: qm9 (Casalioy Research)
          isHf: false
          isPro: false
          name: qm9
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-05-18T22:38:50.633Z'
      numEdits: 1
      reactions: []
    id: 645e5b66340d0b66d1418b60
    type: comment
  author: qm9
  content: This comment has been hidden
  created_at: 2023-05-12 14:29:42+00:00
  edited: true
  hidden: true
  id: 645e5b66340d0b66d1418b60
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: nomic-ai/gpt4all-j
repo_type: model
status: open
target_branch: null
title: Integrating gpt4all-j  as a LLM under LangChain
