!!python/object:huggingface_hub.community.DiscussionWithDetails
author: TheYuriLover
conflicting_files: null
created_at: 2023-04-04 21:07:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-04T22:07:15.000Z'
    data:
      edited: false
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: '<p>When you said "filtered", you mean that your model is trained by
          a dataset without the moralizing nonsence in it?<br>If that''s the case,
          can you provide us the safetensor quantized model? I want to try it on the
          oobabooga webui :D</p>

          '
        raw: "When you said \"filtered\", you mean that your model is trained by a\
          \ dataset without the moralizing nonsence in it?\r\nIf that's the case,\
          \ can you provide us the safetensor quantized model? I want to try it on\
          \ the oobabooga webui :D"
        updatedAt: '2023-04-04T22:07:15.327Z'
      numEdits: 0
      reactions: []
    id: 642c9f93fc341371b02eefbc
    type: comment
  author: TheYuriLover
  content: "When you said \"filtered\", you mean that your model is trained by a dataset\
    \ without the moralizing nonsence in it?\r\nIf that's the case, can you provide\
    \ us the safetensor quantized model? I want to try it on the oobabooga webui :D"
  created_at: 2023-04-04 21:07:15+00:00
  edited: false
  hidden: false
  id: 642c9f93fc341371b02eefbc
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T04:04:02.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: '<p>Well yeah, and this model is quantized so u can use it right away</p>

          '
        raw: Well yeah, and this model is quantized so u can use it right away
        updatedAt: '2023-04-05T04:04:02.544Z'
      numEdits: 0
      reactions: []
    id: 642cf3320d7975d942767ece
    type: comment
  author: ShreyasBrill
  content: Well yeah, and this model is quantized so u can use it right away
  created_at: 2023-04-05 03:04:02+00:00
  edited: false
  hidden: false
  id: 642cf3320d7975d942767ece
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T04:04:23.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: '<p>its quantized to 4bit</p>

          '
        raw: its quantized to 4bit
        updatedAt: '2023-04-05T04:04:23.995Z'
      numEdits: 0
      reactions: []
    id: 642cf347c811cd1de5be116a
    type: comment
  author: ShreyasBrill
  content: its quantized to 4bit
  created_at: 2023-04-05 03:04:23+00:00
  edited: false
  hidden: false
  id: 642cf347c811cd1de5be116a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/024dfb2bf286aef7005eb28a27010342.svg
      fullname: Nicholas "Nick" Jaunich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: panayao
      type: user
    createdAt: '2023-04-05T04:07:20.000Z'
    data:
      edited: false
      editors:
      - panayao
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/024dfb2bf286aef7005eb28a27010342.svg
          fullname: Nicholas "Nick" Jaunich
          isHf: false
          isPro: false
          name: panayao
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ is there a way to convert this to pth format? I am relatively new to this,\
          \ but am trying to do this on my M1 Max MacBook using LLaMA_MPS as it runs\
          \ on Apple Silicon faster than oobabooga webui. Will try with that as well\
          \ thought :)</p>\n"
        raw: '@ShreyasBrill is there a way to convert this to pth format? I am relatively
          new to this, but am trying to do this on my M1 Max MacBook using LLaMA_MPS
          as it runs on Apple Silicon faster than oobabooga webui. Will try with that
          as well thought :)'
        updatedAt: '2023-04-05T04:07:20.169Z'
      numEdits: 0
      reactions: []
    id: 642cf3f87bbd304049369670
    type: comment
  author: panayao
  content: '@ShreyasBrill is there a way to convert this to pth format? I am relatively
    new to this, but am trying to do this on my M1 Max MacBook using LLaMA_MPS as
    it runs on Apple Silicon faster than oobabooga webui. Will try with that as well
    thought :)'
  created_at: 2023-04-05 03:07:20+00:00
  edited: false
  hidden: false
  id: 642cf3f87bbd304049369670
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T04:53:52.000Z'
    data:
      edited: false
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ no, I mean I'd want the format to be quantized in the safetensor format\
          \ so that I can use it here: <a rel=\"nofollow\" href=\"https://github.com/oobabooga/text-generation-webui\"\
          >https://github.com/oobabooga/text-generation-webui</a></p>\n"
        raw: '@ShreyasBrill no, I mean I''d want the format to be quantized in the
          safetensor format so that I can use it here: https://github.com/oobabooga/text-generation-webui'
        updatedAt: '2023-04-05T04:53:52.881Z'
      numEdits: 0
      reactions: []
    id: 642cfee07e1c06a3527d1c7c
    type: comment
  author: TheYuriLover
  content: '@ShreyasBrill no, I mean I''d want the format to be quantized in the safetensor
    format so that I can use it here: https://github.com/oobabooga/text-generation-webui'
  created_at: 2023-04-05 03:53:52+00:00
  edited: false
  hidden: false
  id: 642cfee07e1c06a3527d1c7c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T05:31:18.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;panayao&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/panayao\">@<span class=\"\
          underline\">panayao</span></a></span>\n\n\t</span></span> yes you can convert\
          \ it back to pth format! you can download the vicuna model and download/clone\
          \ this repository and use this convert-ggml-to-pth.py file <a rel=\"nofollow\"\
          \ href=\"https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py\"\
          >https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py</a>\
          \ easy and simple! and also it does work with M1 macs i guess. This version\
          \ is currently not very stable enough because the official vicuna released\
          \ like 2 days ago and you know its just starting up. I might update the\
          \ model when an update is released so that i make the models more stable\
          \ with their responses.</p>\n"
        raw: '@panayao yes you can convert it back to pth format! you can download
          the vicuna model and download/clone this repository and use this convert-ggml-to-pth.py
          file https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py
          easy and simple! and also it does work with M1 macs i guess. This version
          is currently not very stable enough because the official vicuna released
          like 2 days ago and you know its just starting up. I might update the model
          when an update is released so that i make the models more stable with their
          responses.'
        updatedAt: '2023-04-05T05:31:18.682Z'
      numEdits: 0
      reactions: []
    id: 642d07a6c811cd1de5be8694
    type: comment
  author: ShreyasBrill
  content: '@panayao yes you can convert it back to pth format! you can download the
    vicuna model and download/clone this repository and use this convert-ggml-to-pth.py
    file https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py
    easy and simple! and also it does work with M1 macs i guess. This version is currently
    not very stable enough because the official vicuna released like 2 days ago and
    you know its just starting up. I might update the model when an update is released
    so that i make the models more stable with their responses.'
  created_at: 2023-04-05 04:31:18+00:00
  edited: false
  hidden: false
  id: 642d07a6c811cd1de5be8694
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T05:33:02.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ Hmmm i don't know how to do that. You can download the model convert it\
          \ to .pth format and then use some other library to quantize it to safetensor\
          \ format!<br>again you can also use <a rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py\"\
          >https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py</a>\
          \ to convert the model to a different format!</p>\n"
        raw: '@TheYuriLover Hmmm i don''t know how to do that. You can download the
          model convert it to .pth format and then use some other library to quantize
          it to safetensor format!

          again you can also use https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py
          to convert the model to a different format!'
        updatedAt: '2023-04-05T05:33:02.139Z'
      numEdits: 0
      reactions: []
    id: 642d080eac7e48a03a0d9908
    type: comment
  author: ShreyasBrill
  content: '@TheYuriLover Hmmm i don''t know how to do that. You can download the
    model convert it to .pth format and then use some other library to quantize it
    to safetensor format!

    again you can also use https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py
    to convert the model to a different format!'
  created_at: 2023-04-05 04:33:02+00:00
  edited: false
  hidden: false
  id: 642d080eac7e48a03a0d9908
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T05:51:44.000Z'
    data:
      edited: false
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ nah you have to use this <a rel=\"nofollow\" href=\"https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton\"\
          >https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton</a> to convert\
          \ the HF models into safetensors, but it requires a lot of vram and unfortunately\
          \ I don't have a big enough graphic card to do it :'(</p>\n"
        raw: '@ShreyasBrill nah you have to use this https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton
          to convert the HF models into safetensors, but it requires a lot of vram
          and unfortunately I don''t have a big enough graphic card to do it :''('
        updatedAt: '2023-04-05T05:51:44.676Z'
      numEdits: 0
      reactions: []
    id: 642d0c703bf67e40142352ca
    type: comment
  author: TheYuriLover
  content: '@ShreyasBrill nah you have to use this https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton
    to convert the HF models into safetensors, but it requires a lot of vram and unfortunately
    I don''t have a big enough graphic card to do it :''('
  created_at: 2023-04-05 04:51:44+00:00
  edited: false
  hidden: false
  id: 642d0c703bf67e40142352ca
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T05:53:10.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: '<p>I created vicuna using only my CPU. I don''t have a GPU either :(</p>

          '
        raw: I created vicuna using only my CPU. I don't have a GPU either :(
        updatedAt: '2023-04-05T05:53:10.690Z'
      numEdits: 0
      reactions: []
    id: 642d0cc6d3340aee04463499
    type: comment
  author: ShreyasBrill
  content: I created vicuna using only my CPU. I don't have a GPU either :(
  created_at: 2023-04-05 04:53:10+00:00
  edited: false
  hidden: false
  id: 642d0cc6d3340aee04463499
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T06:03:58.000Z'
    data:
      edited: false
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ Do you have the original 16-bit HF model though? You should also upload\
          \ it so people can quantize it on the safetensor format.</p>\n"
        raw: '@ShreyasBrill Do you have the original 16-bit HF model though? You should
          also upload it so people can quantize it on the safetensor format.'
        updatedAt: '2023-04-05T06:03:58.774Z'
      numEdits: 0
      reactions: []
    id: 642d0f4ebcef6743c953a85a
    type: comment
  author: TheYuriLover
  content: '@ShreyasBrill Do you have the original 16-bit HF model though? You should
    also upload it so people can quantize it on the safetensor format.'
  created_at: 2023-04-05 05:03:58+00:00
  edited: false
  hidden: false
  id: 642d0f4ebcef6743c953a85a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T06:20:32.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ ill check it, if i have it ill upload it. let me see</p>\n"
        raw: '@TheYuriLover ill check it, if i have it ill upload it. let me see'
        updatedAt: '2023-04-05T06:20:32.186Z'
      numEdits: 0
      reactions: []
    id: 642d1330ba46f82e91a91993
    type: comment
  author: ShreyasBrill
  content: '@TheYuriLover ill check it, if i have it ill upload it. let me see'
  created_at: 2023-04-05 05:20:32+00:00
  edited: false
  hidden: false
  id: 642d1330ba46f82e91a91993
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T06:22:43.000Z'
    data:
      edited: false
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ thanks man, I appreciate ! :D</p>\n"
        raw: '@ShreyasBrill thanks man, I appreciate ! :D'
        updatedAt: '2023-04-05T06:22:43.529Z'
      numEdits: 0
      reactions: []
    id: 642d13b32ad4ad6f9aaf53ed
    type: comment
  author: TheYuriLover
  content: '@ShreyasBrill thanks man, I appreciate ! :D'
  created_at: 2023-04-05 05:22:43+00:00
  edited: false
  hidden: false
  id: 642d13b32ad4ad6f9aaf53ed
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T06:40:36.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ Wait!!!! i guess i am quantizing the model into safetensor.. Ill upload\
          \ it and message you here once its done. You can use it in the oogabooga\
          \ webui</p>\n"
        raw: '@TheYuriLover Wait!!!! i guess i am quantizing the model into safetensor..
          Ill upload it and message you here once its done. You can use it in the
          oogabooga webui'
        updatedAt: '2023-04-05T06:40:36.019Z'
      numEdits: 0
      reactions: []
    id: 642d17e4b2dfc2cd7c4efd7c
    type: comment
  author: ShreyasBrill
  content: '@TheYuriLover Wait!!!! i guess i am quantizing the model into safetensor..
    Ill upload it and message you here once its done. You can use it in the oogabooga
    webui'
  created_at: 2023-04-05 05:40:36+00:00
  edited: false
  hidden: false
  id: 642d17e4b2dfc2cd7c4efd7c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T06:43:32.000Z'
    data:
      edited: false
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ if you quantize it into safetensor do it with both versions, cuda and\
          \ triton, and use all the implementations aswell (true sequential + act_order\
          \ + groupsize 128)<br><a rel=\"nofollow\" href=\"https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton\"\
          >https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton</a><br><a rel=\"\
          nofollow\" href=\"https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/cuda\"\
          >https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/cuda</a></p>\n<p>If\
          \ you can just convert one of them, use triton then, it gives the fastest\
          \ output speed!</p>\n"
        raw: '@ShreyasBrill if you quantize it into safetensor do it with both versions,
          cuda and triton, and use all the implementations aswell (true sequential
          + act_order + groupsize 128)

          https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton

          https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/cuda


          If you can just convert one of them, use triton then, it gives the fastest
          output speed!'
        updatedAt: '2023-04-05T06:43:32.112Z'
      numEdits: 0
      reactions: []
    id: 642d18949c58e9c723d5235b
    type: comment
  author: TheYuriLover
  content: '@ShreyasBrill if you quantize it into safetensor do it with both versions,
    cuda and triton, and use all the implementations aswell (true sequential + act_order
    + groupsize 128)

    https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton

    https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/cuda


    If you can just convert one of them, use triton then, it gives the fastest output
    speed!'
  created_at: 2023-04-05 05:43:32+00:00
  edited: false
  hidden: false
  id: 642d18949c58e9c723d5235b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T06:46:03.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ its currently getting quantized to vicuna-13b-GPTQ-4bit-128g now</p>\n"
        raw: '@TheYuriLover its currently getting quantized to vicuna-13b-GPTQ-4bit-128g
          now'
        updatedAt: '2023-04-05T06:46:03.384Z'
      numEdits: 0
      reactions: []
    id: 642d192bb2dfc2cd7c4f0524
    type: comment
  author: ShreyasBrill
  content: '@TheYuriLover its currently getting quantized to vicuna-13b-GPTQ-4bit-128g
    now'
  created_at: 2023-04-05 05:46:03+00:00
  edited: false
  hidden: false
  id: 642d192bb2dfc2cd7c4f0524
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T06:48:51.000Z'
    data:
      edited: false
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ You used cuda or triton convertion? I hope it's triton because for the\
          \ moment we don't know how to make the cuda model run on the webui<br>Did\
          \ you add the other implementations? you wrote  vicuna-13b-GPTQ-4bit-128g\
          \ , but does it have true_sequential and act_order?</p>\n<p>CUDA_VISIBLE_DEVICES=0\
          \ python llama.py ./llama-hf/llama-7b c4 --wbits 4 --true-sequential --act-order\
          \ --groupsize 128 --save_safetensors llama7b-4bit-128g.safetensors</p>\n"
        raw: "@ShreyasBrill You used cuda or triton convertion? I hope it's triton\
          \ because for the moment we don't know how to make the cuda model run on\
          \ the webui \nDid you add the other implementations? you wrote  vicuna-13b-GPTQ-4bit-128g\
          \ , but does it have true_sequential and act_order?\n\nCUDA_VISIBLE_DEVICES=0\
          \ python llama.py ./llama-hf/llama-7b c4 --wbits 4 --true-sequential --act-order\
          \ --groupsize 128 --save_safetensors llama7b-4bit-128g.safetensors"
        updatedAt: '2023-04-05T06:48:51.212Z'
      numEdits: 0
      reactions: []
    id: 642d19d3891a88e09e6f99a1
    type: comment
  author: TheYuriLover
  content: "@ShreyasBrill You used cuda or triton convertion? I hope it's triton because\
    \ for the moment we don't know how to make the cuda model run on the webui \n\
    Did you add the other implementations? you wrote  vicuna-13b-GPTQ-4bit-128g ,\
    \ but does it have true_sequential and act_order?\n\nCUDA_VISIBLE_DEVICES=0 python\
    \ llama.py ./llama-hf/llama-7b c4 --wbits 4 --true-sequential --act-order --groupsize\
    \ 128 --save_safetensors llama7b-4bit-128g.safetensors"
  created_at: 2023-04-05 05:48:51+00:00
  edited: false
  hidden: false
  id: 642d19d3891a88e09e6f99a1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T10:23:25.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ Ah this took forever dude check the safetensors folder and download the\
          \ vicuna model from the folder then while starting up the webui use these\
          \ flags and it will start up \"--wbits 4 --groupsize 128 --model_type llama\"\
          </p>\n"
        raw: '@TheYuriLover Ah this took forever dude check the safetensors folder
          and download the vicuna model from the folder then while starting up the
          webui use these flags and it will start up "--wbits 4 --groupsize 128 --model_type
          llama"'
        updatedAt: '2023-04-05T10:23:25.266Z'
      numEdits: 0
      reactions: []
    id: 642d4c1df75f04997cfff663
    type: comment
  author: ShreyasBrill
  content: '@TheYuriLover Ah this took forever dude check the safetensors folder and
    download the vicuna model from the folder then while starting up the webui use
    these flags and it will start up "--wbits 4 --groupsize 128 --model_type llama"'
  created_at: 2023-04-05 09:23:25+00:00
  edited: false
  hidden: false
  id: 642d4c1df75f04997cfff663
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T14:11:56.000Z'
    data:
      edited: false
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ Thanks dude!! We really appreciate :D</p>\n<p>But you didn't answer my\
          \ questions from before, can you please respond to these?</p>\n<p>\"You\
          \ used cuda or triton convertion? I hope it's triton because for the moment\
          \ we don't know how to make the cuda model run on the webui<br>Did you add\
          \ the other implementations? you wrote vicuna-13b-GPTQ-4bit-128g , but does\
          \ it have true_sequential and act_order?</p>\n<p>CUDA_VISIBLE_DEVICES=0\
          \ python llama.py ./llama-hf/llama-7b c4 --wbits 4 --true-sequential --act-order\
          \ --groupsize 128 --save_safetensors llama7b-4bit-128g.safetensors\"</p>\n"
        raw: '@ShreyasBrill Thanks dude!! We really appreciate :D


          But you didn''t answer my questions from before, can you please respond
          to these?


          "You used cuda or triton convertion? I hope it''s triton because for the
          moment we don''t know how to make the cuda model run on the webui

          Did you add the other implementations? you wrote vicuna-13b-GPTQ-4bit-128g
          , but does it have true_sequential and act_order?


          CUDA_VISIBLE_DEVICES=0 python llama.py ./llama-hf/llama-7b c4 --wbits 4
          --true-sequential --act-order --groupsize 128 --save_safetensors llama7b-4bit-128g.safetensors"'
        updatedAt: '2023-04-05T14:11:56.720Z'
      numEdits: 0
      reactions: []
    id: 642d81ac32bdf5af73e7fb14
    type: comment
  author: TheYuriLover
  content: '@ShreyasBrill Thanks dude!! We really appreciate :D


    But you didn''t answer my questions from before, can you please respond to these?


    "You used cuda or triton convertion? I hope it''s triton because for the moment
    we don''t know how to make the cuda model run on the webui

    Did you add the other implementations? you wrote vicuna-13b-GPTQ-4bit-128g , but
    does it have true_sequential and act_order?


    CUDA_VISIBLE_DEVICES=0 python llama.py ./llama-hf/llama-7b c4 --wbits 4 --true-sequential
    --act-order --groupsize 128 --save_safetensors llama7b-4bit-128g.safetensors"'
  created_at: 2023-04-05 13:11:56+00:00
  edited: false
  hidden: false
  id: 642d81ac32bdf5af73e7fb14
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T14:47:59.000Z'
    data:
      edited: true
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ Are you trolling us or something? Your safetensors file is exactly the\
          \ same as anon8231489123's one (which is trained with the filtered dataset)<br><a\
          \ href=\"https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g\"\
          >https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g</a></p>\n\
          <p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/VNx9-e4vwA-rCmL8jTWoz.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/VNx9-e4vwA-rCmL8jTWoz.png\"\
          ></a></p>\n"
        raw: '@ShreyasBrill Are you trolling us or something? Your safetensors file
          is exactly the same as anon8231489123''s one (which is trained with the
          filtered dataset)

          https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g



          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/VNx9-e4vwA-rCmL8jTWoz.png)'
        updatedAt: '2023-04-05T14:48:59.148Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - DontTouchMySpaghetti
    id: 642d8a1f42b094c91387be68
    type: comment
  author: TheYuriLover
  content: '@ShreyasBrill Are you trolling us or something? Your safetensors file
    is exactly the same as anon8231489123''s one (which is trained with the filtered
    dataset)

    https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g



    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/VNx9-e4vwA-rCmL8jTWoz.png)'
  created_at: 2023-04-05 13:47:59+00:00
  edited: true
  hidden: false
  id: 642d8a1f42b094c91387be68
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T15:32:17.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ I am not trolling, as i said i had no gpu to make a safetensor and i asked\
          \ my friend to make it. He gave me a file after so long and i uploaded it\
          \ here. He also told to use those flags that i gave you. I didn't really\
          \ know that someone had made it.</p>\n"
        raw: '@TheYuriLover I am not trolling, as i said i had no gpu to make a safetensor
          and i asked my friend to make it. He gave me a file after so long and i
          uploaded it here. He also told to use those flags that i gave you. I didn''t
          really know that someone had made it.'
        updatedAt: '2023-04-05T15:32:17.212Z'
      numEdits: 0
      reactions: []
    id: 642d948124bf366459b0bea0
    type: comment
  author: ShreyasBrill
  content: '@TheYuriLover I am not trolling, as i said i had no gpu to make a safetensor
    and i asked my friend to make it. He gave me a file after so long and i uploaded
    it here. He also told to use those flags that i gave you. I didn''t really know
    that someone had made it.'
  created_at: 2023-04-05 14:32:17+00:00
  edited: false
  hidden: false
  id: 642d948124bf366459b0bea0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T15:34:36.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: '<p>and as i also said that vicuna isnt really stable enough. For confirmation
          watch this guy''s video and see how it performs<br><a rel="nofollow" href="https://youtu.be/jb4r1CL2tcc">https://youtu.be/jb4r1CL2tcc</a></p>

          '
        raw: "and as i also said that vicuna isnt really stable enough. For confirmation\
          \ watch this guy's video and see how it performs \nhttps://youtu.be/jb4r1CL2tcc"
        updatedAt: '2023-04-05T15:34:36.328Z'
      numEdits: 0
      reactions: []
    id: 642d950c8ce1f7427b859269
    type: comment
  author: ShreyasBrill
  content: "and as i also said that vicuna isnt really stable enough. For confirmation\
    \ watch this guy's video and see how it performs \nhttps://youtu.be/jb4r1CL2tcc"
  created_at: 2023-04-05 14:34:36+00:00
  edited: false
  hidden: false
  id: 642d950c8ce1f7427b859269
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T15:36:07.000Z'
    data:
      edited: false
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ In your description it says that it used the unfiltered dataset<br><a\
          \ href=\"https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered\"\
          >https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered</a></p>\n\
          <p><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/SH3ZXACCKS2e_7wmlG1pU.png\"\
          ><img alt=\"image.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/SH3ZXACCKS2e_7wmlG1pU.png\"\
          ></a></p>\n<p>The safetensor file from anon8231489123 used the filtered\
          \ dataset</p>\n<p>It shouldn't be the same safetensor file at the end, why\
          \ did you say you used the unfiltered dataset? Why lying like that?</p>\n"
        raw: '@ShreyasBrill In your description it says that it used the unfiltered
          dataset

          https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered


          ![image.png](https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/SH3ZXACCKS2e_7wmlG1pU.png)


          The safetensor file from anon8231489123 used the filtered dataset


          It shouldn''t be the same safetensor file at the end, why did you say you
          used the unfiltered dataset? Why lying like that?'
        updatedAt: '2023-04-05T15:36:07.258Z'
      numEdits: 0
      reactions: []
    id: 642d956742b094c91388d505
    type: comment
  author: TheYuriLover
  content: '@ShreyasBrill In your description it says that it used the unfiltered
    dataset

    https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered


    ![image.png](https://cdn-uploads.huggingface.co/production/uploads/639d9061f87da5e2eb0b2724/SH3ZXACCKS2e_7wmlG1pU.png)


    The safetensor file from anon8231489123 used the filtered dataset


    It shouldn''t be the same safetensor file at the end, why did you say you used
    the unfiltered dataset? Why lying like that?'
  created_at: 2023-04-05 14:36:07+00:00
  edited: false
  hidden: false
  id: 642d956742b094c91388d505
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T15:42:07.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: '<p>lol forgot to remove it hold on actually first i was another model
          and uploaded it. Then i deleted it and reuploaded a filtered model and forgot
          to change the tags. Sorry for that</p>

          '
        raw: lol forgot to remove it hold on actually first i was another model and
          uploaded it. Then i deleted it and reuploaded a filtered model and forgot
          to change the tags. Sorry for that
        updatedAt: '2023-04-05T15:42:07.598Z'
      numEdits: 0
      reactions: []
    id: 642d96cfc79218307290b917
    type: comment
  author: ShreyasBrill
  content: lol forgot to remove it hold on actually first i was another model and
    uploaded it. Then i deleted it and reuploaded a filtered model and forgot to change
    the tags. Sorry for that
  created_at: 2023-04-05 14:42:07+00:00
  edited: false
  hidden: false
  id: 642d96cfc79218307290b917
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T15:43:19.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: '<p>fixed it :)</p>

          '
        raw: fixed it :)
        updatedAt: '2023-04-05T15:43:19.081Z'
      numEdits: 0
      reactions: []
    id: 642d971732bdf5af73ea494a
    type: comment
  author: ShreyasBrill
  content: fixed it :)
  created_at: 2023-04-05 14:43:19+00:00
  edited: false
  hidden: false
  id: 642d971732bdf5af73ea494a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T15:43:38.000Z'
    data:
      edited: true
      editors: []
      hidden: true
      hiddenBy: ''
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: This comment has been hidden
        raw: This comment has been hidden
        updatedAt: '2023-04-05T15:44:14.411Z'
      numEdits: 0
      reactions: []
    id: 642d972a2098ed57472663c8
    type: comment
  author: TheYuriLover
  content: This comment has been hidden
  created_at: 2023-04-05 14:43:38+00:00
  edited: true
  hidden: true
  id: 642d972a2098ed57472663c8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T15:46:47.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ Please tell me what do you exactly need? unfiltered model with 4bit quantization\
          \ and should work with oogabooga?</p>\n"
        raw: '@TheYuriLover Please tell me what do you exactly need? unfiltered model
          with 4bit quantization and should work with oogabooga?'
        updatedAt: '2023-04-05T15:46:47.556Z'
      numEdits: 0
      reactions: []
    id: 642d97e7d6d6892408dd1ff5
    type: comment
  author: ShreyasBrill
  content: '@TheYuriLover Please tell me what do you exactly need? unfiltered model
    with 4bit quantization and should work with oogabooga?'
  created_at: 2023-04-05 14:46:47+00:00
  edited: false
  hidden: false
  id: 642d97e7d6d6892408dd1ff5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T15:49:59.000Z'
    data:
      edited: false
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\"\
          >@<span class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ yes, I want a model that is trained on the unfiltered dataset<br><a href=\"\
          https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered\"\
          >https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered</a></p>\n\
          <p>And that model should be quantized with Triton and with all the GPTQ\
          \ implementations (true sequential, act order and groupsize 128)<br><a rel=\"\
          nofollow\" href=\"https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton\"\
          >https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton</a></p>\n"
        raw: '@ShreyasBrill yes, I want a model that is trained on the unfiltered
          dataset

          https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered


          And that model should be quantized with Triton and with all the GPTQ implementations
          (true sequential, act order and groupsize 128)

          https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton'
        updatedAt: '2023-04-05T15:49:59.039Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - 57ar7up
        - satindergrewal
    id: 642d98a732bdf5af73ea6631
    type: comment
  author: TheYuriLover
  content: '@ShreyasBrill yes, I want a model that is trained on the unfiltered dataset

    https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered


    And that model should be quantized with Triton and with all the GPTQ implementations
    (true sequential, act order and groupsize 128)

    https://github.com/qwopqwop200/GPTQ-for-LLaMa/tree/triton'
  created_at: 2023-04-05 14:49:59+00:00
  edited: false
  hidden: false
  id: 642d98a732bdf5af73ea6631
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-05T15:52:51.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: '<p>Okay ill try to make it and upload it.</p>

          '
        raw: Okay ill try to make it and upload it.
        updatedAt: '2023-04-05T15:52:51.497Z'
      numEdits: 0
      reactions:
      - count: 5
        reaction: "\u2764\uFE0F"
        users:
        - panayao
        - underlines
        - MarriedCRJ
        - Chille9
        - satindergrewal
    id: 642d995325c08a2cb4baf635
    type: comment
  author: ShreyasBrill
  content: Okay ill try to make it and upload it.
  created_at: 2023-04-05 14:52:51+00:00
  edited: false
  hidden: false
  id: 642d995325c08a2cb4baf635
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/024dfb2bf286aef7005eb28a27010342.svg
      fullname: Nicholas "Nick" Jaunich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: panayao
      type: user
    createdAt: '2023-04-05T16:46:09.000Z'
    data:
      edited: false
      editors:
      - panayao
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/024dfb2bf286aef7005eb28a27010342.svg
          fullname: Nicholas "Nick" Jaunich
          isHf: false
          isPro: false
          name: panayao
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ do you know how to convert the 4-bit quantized LLaMA.cpp GGML format (ggml-model-q4_0.bin)\
          \ to the file format like \"consolidated.00.pth\"? Like the original format\
          \ LLaMA comes in? Or links to anything I need to learn/understand to figure\
          \ out? I am trying to use <a rel=\"nofollow\" href=\"https://github.com/jankais3r/LLaMA_MPS\"\
          >https://github.com/jankais3r/LLaMA_MPS</a> on my M1 Mac and it converts\
          \ from consolidated.00.pth format to pyarrow. I tried to use a script called\
          \ \"convert-ggml-to-pth.py\" but it does not work as expected. If I knew\
          \ the differences in .pth, .bin, safetensors, and how these all inter-relate\
          \ to one another it would be much easier to figure all this out lol. Any\
          \ references/pointers are much appreciated :)</p>\n"
        raw: '@TheYuriLover do you know how to convert the 4-bit quantized LLaMA.cpp
          GGML format (ggml-model-q4_0.bin) to the file format like "consolidated.00.pth"?
          Like the original format LLaMA comes in? Or links to anything I need to
          learn/understand to figure out? I am trying to use https://github.com/jankais3r/LLaMA_MPS
          on my M1 Mac and it converts from consolidated.00.pth format to pyarrow.
          I tried to use a script called "convert-ggml-to-pth.py" but it does not
          work as expected. If I knew the differences in .pth, .bin, safetensors,
          and how these all inter-relate to one another it would be much easier to
          figure all this out lol. Any references/pointers are much appreciated :)'
        updatedAt: '2023-04-05T16:46:09.238Z'
      numEdits: 0
      reactions: []
    id: 642da5d18ce1f7427b869a58
    type: comment
  author: panayao
  content: '@TheYuriLover do you know how to convert the 4-bit quantized LLaMA.cpp
    GGML format (ggml-model-q4_0.bin) to the file format like "consolidated.00.pth"?
    Like the original format LLaMA comes in? Or links to anything I need to learn/understand
    to figure out? I am trying to use https://github.com/jankais3r/LLaMA_MPS on my
    M1 Mac and it converts from consolidated.00.pth format to pyarrow. I tried to
    use a script called "convert-ggml-to-pth.py" but it does not work as expected.
    If I knew the differences in .pth, .bin, safetensors, and how these all inter-relate
    to one another it would be much easier to figure all this out lol. Any references/pointers
    are much appreciated :)'
  created_at: 2023-04-05 15:46:09+00:00
  edited: false
  hidden: false
  id: 642da5d18ce1f7427b869a58
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/024dfb2bf286aef7005eb28a27010342.svg
      fullname: Nicholas "Nick" Jaunich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: panayao
      type: user
    createdAt: '2023-04-05T16:48:14.000Z'
    data:
      edited: true
      editors:
      - panayao
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/024dfb2bf286aef7005eb28a27010342.svg
          fullname: Nicholas "Nick" Jaunich
          isHf: false
          isPro: false
          name: panayao
          type: user
        html: "<blockquote>\n<p><span data-props=\"{&quot;user&quot;:&quot;panayao&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/panayao\"\
          >@<span class=\"underline\">panayao</span></a></span>\n\n\t</span></span>\
          \ yes you can convert it back to pth format! you can download the vicuna\
          \ model and download/clone this repository and use this convert-ggml-to-pth.py\
          \ file <a rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py\"\
          >https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py</a>\
          \ easy and simple! and also it does work with M1 macs i guess. This version\
          \ is currently not very stable enough because the official vicuna released\
          \ like 2 days ago and you know its just starting up. I might update the\
          \ model when an update is released so that i make the models more stable\
          \ with their responses.</p>\n</blockquote>\n<p>This is the script I was\
          \ trying lol. It doesn't seem to work. I get this when I try to convert\
          \ to pyarrow format (which is used by LLaMA_MPS and is automatically done\
          \ upon running with *.pth files)</p>\n<pre><code>Converting checkpoint to\
          \ pyarrow format\nmodels/13B_Vicuna/consolidated.00.pth\nTraceback (most\
          \ recent call last):\n  File \"/Users/panayao/Documents/LLaMA_MPS/chat.py\"\
          , line 146, in &lt;module&gt;\n    fire.Fire(main)\n  File \"/Users/panayao/Documents/LLaMA_MPS/env/lib/python3.10/site-packages/fire/core.py\"\
          , line 141, in Fire\n    component_trace = _Fire(component, args, parsed_flag_args,\
          \ context, name)\n  File \"/Users/panayao/Documents/LLaMA_MPS/env/lib/python3.10/site-packages/fire/core.py\"\
          , line 475, in _Fire\n    component, remaining_args = _CallAndUpdateTrace(\n\
          \  File \"/Users/panayao/Documents/LLaMA_MPS/env/lib/python3.10/site-packages/fire/core.py\"\
          , line 691, in _CallAndUpdateTrace\n    component = fn(*varargs, **kwargs)\n\
          \  File \"/Users/panayao/Documents/LLaMA_MPS/chat.py\", line 106, in main\n\
          \    generator = load(ckpt_dir, tokenizer_path, max_seq_len, max_batch_size)\n\
          \  File \"/Users/panayao/Documents/LLaMA_MPS/chat.py\", line 49, in load\n\
          \    tens = pa.Tensor.from_numpy(v.numpy())\nAttributeError: 'dict' object\
          \ has no attribute 'numpy'\n</code></pre>\n"
        raw: "> @panayao yes you can convert it back to pth format! you can download\
          \ the vicuna model and download/clone this repository and use this convert-ggml-to-pth.py\
          \ file https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py\
          \ easy and simple! and also it does work with M1 macs i guess. This version\
          \ is currently not very stable enough because the official vicuna released\
          \ like 2 days ago and you know its just starting up. I might update the\
          \ model when an update is released so that i make the models more stable\
          \ with their responses.\n\nThis is the script I was trying lol. It doesn't\
          \ seem to work. I get this when I try to convert to pyarrow format (which\
          \ is used by LLaMA_MPS and is automatically done upon running with *.pth\
          \ files)\n```\nConverting checkpoint to pyarrow format\nmodels/13B_Vicuna/consolidated.00.pth\n\
          Traceback (most recent call last):\n  File \"/Users/panayao/Documents/LLaMA_MPS/chat.py\"\
          , line 146, in <module>\n    fire.Fire(main)\n  File \"/Users/panayao/Documents/LLaMA_MPS/env/lib/python3.10/site-packages/fire/core.py\"\
          , line 141, in Fire\n    component_trace = _Fire(component, args, parsed_flag_args,\
          \ context, name)\n  File \"/Users/panayao/Documents/LLaMA_MPS/env/lib/python3.10/site-packages/fire/core.py\"\
          , line 475, in _Fire\n    component, remaining_args = _CallAndUpdateTrace(\n\
          \  File \"/Users/panayao/Documents/LLaMA_MPS/env/lib/python3.10/site-packages/fire/core.py\"\
          , line 691, in _CallAndUpdateTrace\n    component = fn(*varargs, **kwargs)\n\
          \  File \"/Users/panayao/Documents/LLaMA_MPS/chat.py\", line 106, in main\n\
          \    generator = load(ckpt_dir, tokenizer_path, max_seq_len, max_batch_size)\n\
          \  File \"/Users/panayao/Documents/LLaMA_MPS/chat.py\", line 49, in load\n\
          \    tens = pa.Tensor.from_numpy(v.numpy())\nAttributeError: 'dict' object\
          \ has no attribute 'numpy'\n```"
        updatedAt: '2023-04-05T16:48:58.715Z'
      numEdits: 1
      reactions: []
    id: 642da64e24bf366459b1d804
    type: comment
  author: panayao
  content: "> @panayao yes you can convert it back to pth format! you can download\
    \ the vicuna model and download/clone this repository and use this convert-ggml-to-pth.py\
    \ file https://github.com/ggerganov/llama.cpp/blob/master/convert-ggml-to-pth.py\
    \ easy and simple! and also it does work with M1 macs i guess. This version is\
    \ currently not very stable enough because the official vicuna released like 2\
    \ days ago and you know its just starting up. I might update the model when an\
    \ update is released so that i make the models more stable with their responses.\n\
    \nThis is the script I was trying lol. It doesn't seem to work. I get this when\
    \ I try to convert to pyarrow format (which is used by LLaMA_MPS and is automatically\
    \ done upon running with *.pth files)\n```\nConverting checkpoint to pyarrow format\n\
    models/13B_Vicuna/consolidated.00.pth\nTraceback (most recent call last):\n  File\
    \ \"/Users/panayao/Documents/LLaMA_MPS/chat.py\", line 146, in <module>\n    fire.Fire(main)\n\
    \  File \"/Users/panayao/Documents/LLaMA_MPS/env/lib/python3.10/site-packages/fire/core.py\"\
    , line 141, in Fire\n    component_trace = _Fire(component, args, parsed_flag_args,\
    \ context, name)\n  File \"/Users/panayao/Documents/LLaMA_MPS/env/lib/python3.10/site-packages/fire/core.py\"\
    , line 475, in _Fire\n    component, remaining_args = _CallAndUpdateTrace(\n \
    \ File \"/Users/panayao/Documents/LLaMA_MPS/env/lib/python3.10/site-packages/fire/core.py\"\
    , line 691, in _CallAndUpdateTrace\n    component = fn(*varargs, **kwargs)\n \
    \ File \"/Users/panayao/Documents/LLaMA_MPS/chat.py\", line 106, in main\n   \
    \ generator = load(ckpt_dir, tokenizer_path, max_seq_len, max_batch_size)\n  File\
    \ \"/Users/panayao/Documents/LLaMA_MPS/chat.py\", line 49, in load\n    tens =\
    \ pa.Tensor.from_numpy(v.numpy())\nAttributeError: 'dict' object has no attribute\
    \ 'numpy'\n```"
  created_at: 2023-04-05 15:48:14+00:00
  edited: true
  hidden: false
  id: 642da64e24bf366459b1d804
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T17:08:17.000Z'
    data:
      edited: true
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;panayao&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/panayao\">@<span class=\"\
          underline\">panayao</span></a></span>\n\n\t</span></span> I guess you have\
          \ to ask them directly to fix your error: <a rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp/issues\"\
          >https://github.com/ggerganov/llama.cpp/issues</a></p>\n"
        raw: '@panayao I guess you have to ask them directly to fix your error: https://github.com/ggerganov/llama.cpp/issues'
        updatedAt: '2023-04-05T17:24:22.534Z'
      numEdits: 1
      reactions: []
    id: 642dab018ce1f7427b86de54
    type: comment
  author: TheYuriLover
  content: '@panayao I guess you have to ask them directly to fix your error: https://github.com/ggerganov/llama.cpp/issues'
  created_at: 2023-04-05 16:08:17+00:00
  edited: true
  hidden: false
  id: 642dab018ce1f7427b86de54
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/024dfb2bf286aef7005eb28a27010342.svg
      fullname: Nicholas "Nick" Jaunich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: panayao
      type: user
    createdAt: '2023-04-05T20:56:48.000Z'
    data:
      edited: false
      editors:
      - panayao
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/024dfb2bf286aef7005eb28a27010342.svg
          fullname: Nicholas "Nick" Jaunich
          isHf: false
          isPro: false
          name: panayao
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ lol I probably should have thought to open a Git issue. <span data-props=\"\
          {&quot;user&quot;:&quot;ShreyasBrill&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/ShreyasBrill\">@<span class=\"underline\"\
          >ShreyasBrill</span></a></span>\n\n\t</span></span> if you oblige <span\
          \ data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\">@<span\
          \ class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>'s\
          \ request can you also upload the unfiltered model in the same \"ggml-model-q4_0.bin\"\
          \ format in addition to the format <span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ requested?</p>\n"
        raw: Thanks @TheYuriLover lol I probably should have thought to open a Git
          issue. @ShreyasBrill if you oblige @TheYuriLover's request can you also
          upload the unfiltered model in the same "ggml-model-q4_0.bin" format in
          addition to the format @TheYuriLover requested?
        updatedAt: '2023-04-05T20:56:48.780Z'
      numEdits: 0
      reactions: []
    id: 642de090bd4d3f3296d5de50
    type: comment
  author: panayao
  content: Thanks @TheYuriLover lol I probably should have thought to open a Git issue.
    @ShreyasBrill if you oblige @TheYuriLover's request can you also upload the unfiltered
    model in the same "ggml-model-q4_0.bin" format in addition to the format @TheYuriLover
    requested?
  created_at: 2023-04-05 19:56:48+00:00
  edited: false
  hidden: false
  id: 642de090bd4d3f3296d5de50
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/024dfb2bf286aef7005eb28a27010342.svg
      fullname: Nicholas "Nick" Jaunich
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: panayao
      type: user
    createdAt: '2023-04-05T20:59:51.000Z'
    data:
      edited: false
      editors:
      - panayao
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/024dfb2bf286aef7005eb28a27010342.svg
          fullname: Nicholas "Nick" Jaunich
          isHf: false
          isPro: false
          name: panayao
          type: user
        html: "<p>Also <span data-props=\"{&quot;user&quot;:&quot;TheYuriLover&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/TheYuriLover\"\
          >@<span class=\"underline\">TheYuriLover</span></a></span>\n\n\t</span></span>\
          \ <span data-props=\"{&quot;user&quot;:&quot;ShreyasBrill&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ShreyasBrill\">@<span\
          \ class=\"underline\">ShreyasBrill</span></a></span>\n\n\t</span></span>\
          \ I have crypto mining machines running Windows and with proper CUDA drivers\
          \ that I haven't used in years but they each have 8 AMD RX470 (4Gb). So\
          \ if you need stuff converted and are willing to point me in the right direction\
          \ I can help :).</p>\n"
        raw: Also @TheYuriLover @ShreyasBrill I have crypto mining machines running
          Windows and with proper CUDA drivers that I haven't used in years but they
          each have 8 AMD RX470 (4Gb). So if you need stuff converted and are willing
          to point me in the right direction I can help :).
        updatedAt: '2023-04-05T20:59:51.930Z'
      numEdits: 0
      reactions: []
    id: 642de14725c08a2cb4beb08f
    type: comment
  author: panayao
  content: Also @TheYuriLover @ShreyasBrill I have crypto mining machines running
    Windows and with proper CUDA drivers that I haven't used in years but they each
    have 8 AMD RX470 (4Gb). So if you need stuff converted and are willing to point
    me in the right direction I can help :).
  created_at: 2023-04-05 19:59:51+00:00
  edited: false
  hidden: false
  id: 642de14725c08a2cb4beb08f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
      fullname: Yuri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: TheYuriLover
      type: user
    createdAt: '2023-04-05T21:04:22.000Z'
    data:
      edited: true
      editors:
      - TheYuriLover
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/475262a2b834ae50ec39d453fd54a41d.svg
          fullname: Yuri
          isHf: false
          isPro: false
          name: TheYuriLover
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;panayao&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/panayao\">@<span class=\"\
          underline\">panayao</span></a></span>\n\n\t</span></span> well for the moment\
          \ the 16 bit unrestricted Vicuna doesn't exist yet, so there's nothing to\
          \ quantize but if it does you can help yeah :p</p>\n"
        raw: '@panayao well for the moment the 16 bit unrestricted Vicuna doesn''t
          exist yet, so there''s nothing to quantize but if it does you can help yeah
          :p'
        updatedAt: '2023-04-05T21:04:57.687Z'
      numEdits: 1
      reactions: []
    id: 642de256d6d6892408e0fa11
    type: comment
  author: TheYuriLover
  content: '@panayao well for the moment the 16 bit unrestricted Vicuna doesn''t exist
    yet, so there''s nothing to quantize but if it does you can help yeah :p'
  created_at: 2023-04-05 20:04:22+00:00
  edited: true
  hidden: false
  id: 642de256d6d6892408e0fa11
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-06T05:30:26.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;panayao&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/panayao\">@<span class=\"\
          underline\">panayao</span></a></span>\n\n\t</span></span> yes i do need\
          \ your gpus for help to create the models but first hear out for the next\
          \ release of vicuna because its not fully stable currently. And as yuri\
          \ said 16 bit unrestricted vicuna doesnt exist</p>\n"
        raw: '@panayao yes i do need your gpus for help to create the models but first
          hear out for the next release of vicuna because its not fully stable currently.
          And as yuri said 16 bit unrestricted vicuna doesnt exist'
        updatedAt: '2023-04-06T05:30:26.064Z'
      numEdits: 0
      reactions: []
    id: 642e58f225c08a2cb4c1f756
    type: comment
  author: ShreyasBrill
  content: '@panayao yes i do need your gpus for help to create the models but first
    hear out for the next release of vicuna because its not fully stable currently.
    And as yuri said 16 bit unrestricted vicuna doesnt exist'
  created_at: 2023-04-06 04:30:26+00:00
  edited: false
  hidden: false
  id: 642e58f225c08a2cb4c1f756
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-06T05:31:02.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: '<p>and sorry i didnt reply because of different timezones. I was sleeping
          when you guys messaged me</p>

          '
        raw: and sorry i didnt reply because of different timezones. I was sleeping
          when you guys messaged me
        updatedAt: '2023-04-06T05:31:02.955Z'
      numEdits: 0
      reactions: []
    id: 642e5916c82739bc87e57532
    type: comment
  author: ShreyasBrill
  content: and sorry i didnt reply because of different timezones. I was sleeping
    when you guys messaged me
  created_at: 2023-04-06 04:31:02+00:00
  edited: false
  hidden: false
  id: 642e5916c82739bc87e57532
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f4a5bb97af8078b8544444d9ee18a2fe.svg
      fullname: Dat Boi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nucleardiffusion
      type: user
    createdAt: '2023-04-10T12:02:34.000Z'
    data:
      edited: true
      editors:
      - nucleardiffusion
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f4a5bb97af8078b8544444d9ee18a2fe.svg
          fullname: Dat Boi
          isHf: false
          isPro: false
          name: nucleardiffusion
          type: user
        html: '<p>I would also love an unfiltered version that is also quantised in
          4bit just like this version, it''s a great model,<br>Saying that, the outputs
          seem to be identicle  - as in - token for token --- to the vicuna-13b-q4,
          I am not sure this is your work?</p>

          '
        raw: "I would also love an unfiltered version that is also quantised in 4bit\
          \ just like this version, it's a great model, \nSaying that, the outputs\
          \ seem to be identicle  - as in - token for token --- to the vicuna-13b-q4,\
          \ I am not sure this is your work?"
        updatedAt: '2023-04-10T12:59:26.561Z'
      numEdits: 2
      reactions: []
    id: 6433fadad12a239d72e2a9f2
    type: comment
  author: nucleardiffusion
  content: "I would also love an unfiltered version that is also quantised in 4bit\
    \ just like this version, it's a great model, \nSaying that, the outputs seem\
    \ to be identicle  - as in - token for token --- to the vicuna-13b-q4, I am not\
    \ sure this is your work?"
  created_at: 2023-04-10 11:02:34+00:00
  edited: true
  hidden: false
  id: 6433fadad12a239d72e2a9f2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-10T12:05:23.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;nucleardiffusion&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nucleardiffusion\"\
          >@<span class=\"underline\">nucleardiffusion</span></a></span>\n\n\t</span></span>\
          \ Thanks :)</p>\n"
        raw: '@nucleardiffusion Thanks :)'
        updatedAt: '2023-04-10T12:05:23.310Z'
      numEdits: 0
      reactions: []
    id: 6433fb831d83dc03c8e68448
    type: comment
  author: ShreyasBrill
  content: '@nucleardiffusion Thanks :)'
  created_at: 2023-04-10 11:05:23+00:00
  edited: false
  hidden: false
  id: 6433fb831d83dc03c8e68448
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f4a5bb97af8078b8544444d9ee18a2fe.svg
      fullname: Dat Boi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nucleardiffusion
      type: user
    createdAt: '2023-04-10T22:16:04.000Z'
    data:
      edited: false
      editors:
      - nucleardiffusion
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f4a5bb97af8078b8544444d9ee18a2fe.svg
          fullname: Dat Boi
          isHf: false
          isPro: false
          name: nucleardiffusion
          type: user
        html: '<p>I edited my first comment after some tests could you please clarify?</p>

          '
        raw: I edited my first comment after some tests could you please clarify?
        updatedAt: '2023-04-10T22:16:04.309Z'
      numEdits: 0
      reactions: []
    id: 64348aa48d68561d70519a56
    type: comment
  author: nucleardiffusion
  content: I edited my first comment after some tests could you please clarify?
  created_at: 2023-04-10 21:16:04+00:00
  edited: false
  hidden: false
  id: 64348aa48d68561d70519a56
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
      fullname: Shreyas-ITB
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: ShreyasBrill
      type: user
    createdAt: '2023-04-11T03:50:14.000Z'
    data:
      edited: false
      editors:
      - ShreyasBrill
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62e93e1a41f76da081e2f0bb/oBe6cfZH6-K48hemK_kn6.png?w=200&h=200&f=face
          fullname: Shreyas-ITB
          isHf: false
          isPro: false
          name: ShreyasBrill
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;nucleardiffusion&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/nucleardiffusion\"\
          >@<span class=\"underline\">nucleardiffusion</span></a></span>\n\n\t</span></span>\
          \ yes its the same model. I downloaded from one of my friends who trained\
          \ the model, later on he deleted it thats why i thought of uploading it\
          \ here. This is not my work.</p>\n"
        raw: '@nucleardiffusion yes its the same model. I downloaded from one of my
          friends who trained the model, later on he deleted it thats why i thought
          of uploading it here. This is not my work.'
        updatedAt: '2023-04-11T03:50:14.677Z'
      numEdits: 0
      reactions: []
    id: 6434d8f6ef6d5abefe459d96
    type: comment
  author: ShreyasBrill
  content: '@nucleardiffusion yes its the same model. I downloaded from one of my
    friends who trained the model, later on he deleted it thats why i thought of uploading
    it here. This is not my work.'
  created_at: 2023-04-11 02:50:14+00:00
  edited: false
  hidden: false
  id: 6434d8f6ef6d5abefe459d96
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: ShreyasBrill/Vicuna-13B
repo_type: model
status: open
target_branch: null
title: Unfiltered model?
