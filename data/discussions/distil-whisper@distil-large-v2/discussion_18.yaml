!!python/object:huggingface_hub.community.DiscussionWithDetails
author: teamm
conflicting_files: null
created_at: 2023-11-30 19:13:07+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ced67f2399f8b7a3baf96836471078f2.svg
      fullname: TA
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: teamm
      type: user
    createdAt: '2023-11-30T19:13:07.000Z'
    data:
      edited: false
      editors:
      - teamm
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8860529065132141
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ced67f2399f8b7a3baf96836471078f2.svg
          fullname: TA
          isHf: false
          isPro: false
          name: teamm
          type: user
        html: '<p>Maybe I am overlooking something, but I am not seeing a way to get
          sentence level timestamps. With the openai whisper library, when you use
          "transcribe" you will get a timestamp for each text chunk (not word level,
          text chunk). I am not seeing an equivalent here. Can you please guide me?</p>

          '
        raw: Maybe I am overlooking something, but I am not seeing a way to get sentence
          level timestamps. With the openai whisper library, when you use "transcribe"
          you will get a timestamp for each text chunk (not word level, text chunk).
          I am not seeing an equivalent here. Can you please guide me?
        updatedAt: '2023-11-30T19:13:07.459Z'
      numEdits: 0
      reactions: []
    id: 6568dec35958c68e315c0e7b
    type: comment
  author: teamm
  content: Maybe I am overlooking something, but I am not seeing a way to get sentence
    level timestamps. With the openai whisper library, when you use "transcribe" you
    will get a timestamp for each text chunk (not word level, text chunk). I am not
    seeing an equivalent here. Can you please guide me?
  created_at: 2023-11-30 19:13:07+00:00
  edited: false
  hidden: false
  id: 6568dec35958c68e315c0e7b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/337cdc9b6ec99272e5afdbaa25ec3925.svg
      fullname: Thomas Legrand
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DnzzL
      type: user
    createdAt: '2023-12-07T11:48:49.000Z'
    data:
      edited: false
      editors:
      - DnzzL
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.552581787109375
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/337cdc9b6ec99272e5afdbaa25ec3925.svg
          fullname: Thomas Legrand
          isHf: false
          isPro: false
          name: DnzzL
          type: user
        html: "<p>Hello <span data-props=\"{&quot;user&quot;:&quot;teamm&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/teamm\"\
          >@<span class=\"underline\">teamm</span></a></span>\n\n\t</span></span>\
          \ , try something like this<br><code>pipeline(\"automatic-speech-recognition\"\
          , model=\"distil-whisper/distil-large-v2\", return_timestamps=True)</code></p>\n"
        raw: 'Hello @teamm , try something like this

          `pipeline("automatic-speech-recognition", model="distil-whisper/distil-large-v2",
          return_timestamps=True)`

          '
        updatedAt: '2023-12-07T11:48:49.032Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - sanchit-gandhi
        - Mohith7548
    id: 6571b1213dfb9cc7b295c636
    type: comment
  author: DnzzL
  content: 'Hello @teamm , try something like this

    `pipeline("automatic-speech-recognition", model="distil-whisper/distil-large-v2",
    return_timestamps=True)`

    '
  created_at: 2023-12-07 11:48:49+00:00
  edited: false
  hidden: false
  id: 6571b1213dfb9cc7b295c636
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
      fullname: Sanchit Gandhi
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: sanchit-gandhi
      type: user
    createdAt: '2023-12-07T12:05:22.000Z'
    data:
      edited: false
      editors:
      - sanchit-gandhi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5019892454147339
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1653243468328-61f91cf54a8e5a275b2b3e7c.jpeg?w=200&h=200&f=face
          fullname: Sanchit Gandhi
          isHf: true
          isPro: false
          name: sanchit-gandhi
          type: user
        html: "<p>Thanks <span data-props=\"{&quot;user&quot;:&quot;DnzzL&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/DnzzL\"\
          >@<span class=\"underline\">DnzzL</span></a></span>\n\n\t</span></span>!\
          \ Here's a full code snippet for this. You can see how we change the call\
          \ to the <code>pipe</code> to add the argument <code>return_timestamps=True</code>:</p>\n\
          <pre><code class=\"language-python\"><span class=\"hljs-keyword\">import</span>\
          \ torch\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"\
          hljs-keyword\">import</span> AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n\
          <span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\"\
          >import</span> load_dataset\n\n\ndevice = <span class=\"hljs-string\">\"\
          cuda:0\"</span> <span class=\"hljs-keyword\">if</span> torch.cuda.is_available()\
          \ <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"\
          cpu\"</span>\ntorch_dtype = torch.float16 <span class=\"hljs-keyword\">if</span>\
          \ torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> torch.float32\n\
          \nmodel_id = <span class=\"hljs-string\">\"distil-whisper/distil-large-v2\"\
          </span>\n\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\n    model_id,\
          \ torch_dtype=torch_dtype, low_cpu_mem_usage=<span class=\"hljs-literal\"\
          >True</span>, use_safetensors=<span class=\"hljs-literal\">True</span>\n\
          )\nmodel.to(device)\n\nprocessor = AutoProcessor.from_pretrained(model_id)\n\
          \npipe = pipeline(\n    <span class=\"hljs-string\">\"automatic-speech-recognition\"\
          </span>,\n    model=model,\n    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n\
          \    max_new_tokens=<span class=\"hljs-number\">128</span>,\n    chunk_length_s=<span\
          \ class=\"hljs-number\">15</span>,\n    batch_size=<span class=\"hljs-number\"\
          >16</span>,\n    torch_dtype=torch_dtype,\n    device=device,\n)\n\ndataset\
          \ = load_dataset(<span class=\"hljs-string\">\"distil-whisper/librispeech_long\"\
          </span>, <span class=\"hljs-string\">\"clean\"</span>, split=<span class=\"\
          hljs-string\">\"validation\"</span>)\nsample = dataset[<span class=\"hljs-number\"\
          >0</span>][<span class=\"hljs-string\">\"audio\"</span>]\n\nresult = pipe(sample,\
          \ return_timestamps=<span class=\"hljs-literal\">True</span>)\n<span class=\"\
          hljs-built_in\">print</span>(result[<span class=\"hljs-string\">\"chunks\"\
          </span>])\n</code></pre>\n"
        raw: "Thanks @DnzzL! Here's a full code snippet for this. You can see how\
          \ we change the call to the `pipe` to add the argument `return_timestamps=True`:\n\
          \n```python\nimport torch\nfrom transformers import AutoModelForSpeechSeq2Seq,\
          \ AutoProcessor, pipeline\nfrom datasets import load_dataset\n\n\ndevice\
          \ = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntorch_dtype =\
          \ torch.float16 if torch.cuda.is_available() else torch.float32\n\nmodel_id\
          \ = \"distil-whisper/distil-large-v2\"\n\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\n\
          \    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n\
          )\nmodel.to(device)\n\nprocessor = AutoProcessor.from_pretrained(model_id)\n\
          \npipe = pipeline(\n    \"automatic-speech-recognition\",\n    model=model,\n\
          \    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n\
          \    max_new_tokens=128,\n    chunk_length_s=15,\n    batch_size=16,\n \
          \   torch_dtype=torch_dtype,\n    device=device,\n)\n\ndataset = load_dataset(\"\
          distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\nsample\
          \ = dataset[0][\"audio\"]\n\nresult = pipe(sample, return_timestamps=True)\n\
          print(result[\"chunks\"])\n```"
        updatedAt: '2023-12-07T12:05:22.905Z'
      numEdits: 0
      reactions: []
    id: 6571b50206cc064e0e8d6a9f
    type: comment
  author: sanchit-gandhi
  content: "Thanks @DnzzL! Here's a full code snippet for this. You can see how we\
    \ change the call to the `pipe` to add the argument `return_timestamps=True`:\n\
    \n```python\nimport torch\nfrom transformers import AutoModelForSpeechSeq2Seq,\
    \ AutoProcessor, pipeline\nfrom datasets import load_dataset\n\n\ndevice = \"\
    cuda:0\" if torch.cuda.is_available() else \"cpu\"\ntorch_dtype = torch.float16\
    \ if torch.cuda.is_available() else torch.float32\n\nmodel_id = \"distil-whisper/distil-large-v2\"\
    \n\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\n    model_id, torch_dtype=torch_dtype,\
    \ low_cpu_mem_usage=True, use_safetensors=True\n)\nmodel.to(device)\n\nprocessor\
    \ = AutoProcessor.from_pretrained(model_id)\n\npipe = pipeline(\n    \"automatic-speech-recognition\"\
    ,\n    model=model,\n    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n\
    \    max_new_tokens=128,\n    chunk_length_s=15,\n    batch_size=16,\n    torch_dtype=torch_dtype,\n\
    \    device=device,\n)\n\ndataset = load_dataset(\"distil-whisper/librispeech_long\"\
    , \"clean\", split=\"validation\")\nsample = dataset[0][\"audio\"]\n\nresult =\
    \ pipe(sample, return_timestamps=True)\nprint(result[\"chunks\"])\n```"
  created_at: 2023-12-07 12:05:22+00:00
  edited: false
  hidden: false
  id: 6571b50206cc064e0e8d6a9f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 18
repo_id: distil-whisper/distil-large-v2
repo_type: model
status: open
target_branch: null
title: How do I get sentence level timestamps?
