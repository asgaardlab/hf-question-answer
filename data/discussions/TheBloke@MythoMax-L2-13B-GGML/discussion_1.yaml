!!python/object:huggingface_hub.community.DiscussionWithDetails
author: iDarkness
conflicting_files: null
created_at: 2023-08-22 18:05:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/qRLlyPcU_WtTarXICMgsr.jpeg?w=200&h=200&f=face
      fullname: iDarkness Kun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iDarkness
      type: user
    createdAt: '2023-08-22T19:05:18.000Z'
    data:
      edited: false
      editors:
      - iDarkness
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9536222219467163
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/qRLlyPcU_WtTarXICMgsr.jpeg?w=200&h=200&f=face
          fullname: iDarkness Kun
          isHf: false
          isPro: false
          name: iDarkness
          type: user
        html: '<p>Hello, I would like to ask if it posssible to make a MythoMax model
          with a support for 8k or 4k for context..because  I love this model but
          I think with more context this model gets even great than ever, so I would
          like to ask if you can make one having this type of stuff, thank you! (and
          if possible, having support for GGML model too, not only for the normal
          one)</p>

          '
        raw: Hello, I would like to ask if it posssible to make a MythoMax model with
          a support for 8k or 4k for context..because  I love this model but I think
          with more context this model gets even great than ever, so I would like
          to ask if you can make one having this type of stuff, thank you! (and if
          possible, having support for GGML model too, not only for the normal one)
        updatedAt: '2023-08-22T19:05:18.069Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jirka642
    id: 64e506eefba2c8c08e793278
    type: comment
  author: iDarkness
  content: Hello, I would like to ask if it posssible to make a MythoMax model with
    a support for 8k or 4k for context..because  I love this model but I think with
    more context this model gets even great than ever, so I would like to ask if you
    can make one having this type of stuff, thank you! (and if possible, having support
    for GGML model too, not only for the normal one)
  created_at: 2023-08-22 18:05:18+00:00
  edited: false
  hidden: false
  id: 64e506eefba2c8c08e793278
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/tz5GwJAcU9lt696CA4cFU.png?w=200&h=200&f=face
      fullname: noname
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yumeshiro
      type: user
    createdAt: '2023-08-22T19:25:08.000Z'
    data:
      edited: false
      editors:
      - yumeshiro
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9674145579338074
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/tz5GwJAcU9lt696CA4cFU.png?w=200&h=200&f=face
          fullname: noname
          isHf: false
          isPro: false
          name: yumeshiro
          type: user
        html: '<p>MythoMax is a LLama 2-based model and has a context of 4k by default.
          Depending on what you''re using to run the model, you can already get 8k
          context with some settings tweaking as well.</p>

          '
        raw: MythoMax is a LLama 2-based model and has a context of 4k by default.
          Depending on what you're using to run the model, you can already get 8k
          context with some settings tweaking as well.
        updatedAt: '2023-08-22T19:25:08.562Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - TravelingMan
        - jirka642
    id: 64e50b9471071da798d1588c
    type: comment
  author: yumeshiro
  content: MythoMax is a LLama 2-based model and has a context of 4k by default. Depending
    on what you're using to run the model, you can already get 8k context with some
    settings tweaking as well.
  created_at: 2023-08-22 18:25:08+00:00
  edited: false
  hidden: false
  id: 64e50b9471071da798d1588c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/qRLlyPcU_WtTarXICMgsr.jpeg?w=200&h=200&f=face
      fullname: iDarkness Kun
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iDarkness
      type: user
    createdAt: '2023-08-22T19:57:24.000Z'
    data:
      edited: false
      editors:
      - iDarkness
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9457801580429077
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/qRLlyPcU_WtTarXICMgsr.jpeg?w=200&h=200&f=face
          fullname: iDarkness Kun
          isHf: false
          isPro: false
          name: iDarkness
          type: user
        html: '<blockquote>

          <p>MythoMax is a LLama 2-based model and has a context of 4k by default.
          Depending on what you''re using to run the model, you can already get 8k
          context with some settings tweaking as well.</p>

          </blockquote>

          <p>all right...in this case, how I can make the model to run using 8k context
          on Koboldcpp for example? I''m still new at these AI stuff, I saw a 8k model
          of the MythoMax at the Horde on Agnaistic and I get impressed how much good
          it is.</p>

          '
        raw: '> MythoMax is a LLama 2-based model and has a context of 4k by default.
          Depending on what you''re using to run the model, you can already get 8k
          context with some settings tweaking as well.


          all right...in this case, how I can make the model to run using 8k context
          on Koboldcpp for example? I''m still new at these AI stuff, I saw a 8k model
          of the MythoMax at the Horde on Agnaistic and I get impressed how much good
          it is.'
        updatedAt: '2023-08-22T19:57:24.878Z'
      numEdits: 0
      reactions: []
    id: 64e51324ab9864e8ffd90fe5
    type: comment
  author: iDarkness
  content: '> MythoMax is a LLama 2-based model and has a context of 4k by default.
    Depending on what you''re using to run the model, you can already get 8k context
    with some settings tweaking as well.


    all right...in this case, how I can make the model to run using 8k context on
    Koboldcpp for example? I''m still new at these AI stuff, I saw a 8k model of the
    MythoMax at the Horde on Agnaistic and I get impressed how much good it is.'
  created_at: 2023-08-22 18:57:24+00:00
  edited: false
  hidden: false
  id: 64e51324ab9864e8ffd90fe5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/633095ed982b1a4550f6f06738153c1e.svg
      fullname: anas hajbi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Anoxiom
      type: user
    createdAt: '2023-08-27T21:06:51.000Z'
    data:
      edited: false
      editors:
      - Anoxiom
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6385408639907837
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/633095ed982b1a4550f6f06738153c1e.svg
          fullname: anas hajbi
          isHf: false
          isPro: false
          name: Anoxiom
          type: user
        html: '<p>in koboldcpp, if using the excutable, there is under tokens a custom
          ropeconfig , you can either use the linear scaler or  ntk aware scaling
          as follows:<br>-linear Scaling,for 2x linear scale, set rope scale:0.5 and
          rope base to :10000, for 4x, use  0.25 10000.<br>-NTK-Aware Scaling, set
          rope scale:1.0 32000 for approx 2x scale, or 1.0 82000 for approx 4x .<br>exemple:
          i have 4k context limit i (here im using linear scaling) set rope scale:0.5
          and rope base to :10000 and now the context limit is 8k</p>

          '
        raw: 'in koboldcpp, if using the excutable, there is under tokens a custom
          ropeconfig , you can either use the linear scaler or  ntk aware scaling
          as follows:

          -linear Scaling,for 2x linear scale, set rope scale:0.5 and rope base to
          :10000, for 4x, use  0.25 10000.

          -NTK-Aware Scaling, set rope scale:1.0 32000 for approx 2x scale, or 1.0
          82000 for approx 4x .

          exemple: i have 4k context limit i (here im using linear scaling) set rope
          scale:0.5 and rope base to :10000 and now the context limit is 8k'
        updatedAt: '2023-08-27T21:06:51.616Z'
      numEdits: 0
      reactions: []
    id: 64ebbaeba91f5a573e3048da
    type: comment
  author: Anoxiom
  content: 'in koboldcpp, if using the excutable, there is under tokens a custom ropeconfig
    , you can either use the linear scaler or  ntk aware scaling as follows:

    -linear Scaling,for 2x linear scale, set rope scale:0.5 and rope base to :10000,
    for 4x, use  0.25 10000.

    -NTK-Aware Scaling, set rope scale:1.0 32000 for approx 2x scale, or 1.0 82000
    for approx 4x .

    exemple: i have 4k context limit i (here im using linear scaling) set rope scale:0.5
    and rope base to :10000 and now the context limit is 8k'
  created_at: 2023-08-27 20:06:51+00:00
  edited: false
  hidden: false
  id: 64ebbaeba91f5a573e3048da
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/633095ed982b1a4550f6f06738153c1e.svg
      fullname: anas hajbi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Anoxiom
      type: user
    createdAt: '2023-08-27T21:08:48.000Z'
    data:
      edited: false
      editors:
      - Anoxiom
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8022231459617615
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/633095ed982b1a4550f6f06738153c1e.svg
          fullname: anas hajbi
          isHf: false
          isPro: false
          name: Anoxiom
          type: user
        html: '<p>you can find more info here:<a rel="nofollow" href="https://github.com/LostRuins/koboldcpp/wiki">https://github.com/LostRuins/koboldcpp/wiki</a>
          </p>

          '
        raw: 'you can find more info here:https://github.com/LostRuins/koboldcpp/wiki '
        updatedAt: '2023-08-27T21:08:48.365Z'
      numEdits: 0
      reactions: []
    id: 64ebbb60171e6c9862d2e11e
    type: comment
  author: Anoxiom
  content: 'you can find more info here:https://github.com/LostRuins/koboldcpp/wiki '
  created_at: 2023-08-27 20:08:48+00:00
  edited: false
  hidden: false
  id: 64ebbb60171e6c9862d2e11e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/MythoMax-L2-13B-GGML
repo_type: model
status: open
target_branch: null
title: MythoMax-L2-13B with a support for 8k or 4k context.
