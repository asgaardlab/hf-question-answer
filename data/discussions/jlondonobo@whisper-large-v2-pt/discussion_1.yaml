!!python/object:huggingface_hub.community.DiscussionWithDetails
author: skoll520
conflicting_files: null
created_at: 2022-12-26 17:15:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/315c6e6f2e3c0aeea36fd9a8853a97f4.svg
      fullname: "R\xF3ger Nascimento Santos"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: skoll520
      type: user
    createdAt: '2022-12-26T17:15:15.000Z'
    data:
      edited: false
      editors:
      - skoll520
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/315c6e6f2e3c0aeea36fd9a8853a97f4.svg
          fullname: "R\xF3ger Nascimento Santos"
          isHf: false
          isPro: false
          name: skoll520
          type: user
        html: '<p>normally I use the whisper large from openai, but, using transformers
          library, can you give me an example of python code? I can''t make it run
          anyway</p>

          '
        raw: normally I use the whisper large from openai, but, using transformers
          library, can you give me an example of python code? I can't make it run
          anyway
        updatedAt: '2022-12-26T17:15:15.203Z'
      numEdits: 0
      reactions: []
    id: 63a9d6a33453852ef53e6420
    type: comment
  author: skoll520
  content: normally I use the whisper large from openai, but, using transformers library,
    can you give me an example of python code? I can't make it run anyway
  created_at: 2022-12-26 17:15:15+00:00
  edited: false
  hidden: false
  id: 63a9d6a33453852ef53e6420
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670272965540-635e4a1d398ff343c4f3c874.jpeg?w=200&h=200&f=face
      fullname: Jose Londono Botero
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: jlondonobo
      type: user
    createdAt: '2022-12-27T04:21:53.000Z'
    data:
      edited: false
      editors:
      - jlondonobo
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1670272965540-635e4a1d398ff343c4f3c874.jpeg?w=200&h=200&f=face
          fullname: Jose Londono Botero
          isHf: false
          isPro: false
          name: jlondonobo
          type: user
        html: "<p>Ol\xE1, <span data-props=\"{&quot;user&quot;:&quot;skoll520&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/skoll520\"\
          >@<span class=\"underline\">skoll520</span></a></span>\n\n\t</span></span>\
          \ \U0001F44B\U0001F3FB thanks for your interest in this model. </p>\n<p>Here's\
          \ a snippet you can copy to run Whisper models with <code>transformers</code>\
          \ :</p>\n<pre><code class=\"language-python\"><span class=\"hljs-keyword\"\
          >from</span> transformers <span class=\"hljs-keyword\">import</span> pipeline\n\
          <span class=\"hljs-keyword\">import</span> torch\n\ndevice = <span class=\"\
          hljs-number\">0</span> <span class=\"hljs-keyword\">if</span> torch.cuda.is_available()\
          \ <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"\
          cpu\"</span>\n\ntranscribe = pipeline(\n    task=<span class=\"hljs-string\"\
          >\"automatic-speech-recognition\"</span>,\n    model=<span class=\"hljs-string\"\
          >\"jlondonobo/whisper-large-v2-pt\"</span>,\n    chunk_length_s=<span class=\"\
          hljs-number\">30</span>,\n    device=device,\n)\n\ntranscribe.model.config.forced_decoder_ids\
          \ = transcribe.tokenizer.get_decoder_prompt_ids(language=<span class=\"\
          hljs-string\">\"pt\"</span>, task=<span class=\"hljs-string\">\"transcribe\"\
          </span>)\n\n<span class=\"hljs-comment\"># audio files can be of any type\
          \ (.mp3, .m4a, .wav)</span>\ntranscribe(<span class=\"hljs-string\">\"audio.m4a\"\
          </span>)[<span class=\"hljs-string\">\"text\"</span>]\n</code></pre>\n<p>I\
          \ would encourage you to use the <a href=\"https://huggingface.co/jlondonobo/whisper-large-v2-pt-v3\"\
          >updated version of this model</a>. It is significantly more precise with\
          \ the same inference time.</p>\n"
        raw: "Ol\xE1, @skoll520 \U0001F44B\U0001F3FB thanks for your interest in this\
          \ model. \n\nHere's a snippet you can copy to run Whisper models with `transformers`\
          \ :\n\n```python\nfrom transformers import pipeline\nimport torch\n\ndevice\
          \ = 0 if torch.cuda.is_available() else \"cpu\"\n\ntranscribe = pipeline(\n\
          \    task=\"automatic-speech-recognition\",\n    model=\"jlondonobo/whisper-large-v2-pt\"\
          ,\n    chunk_length_s=30,\n    device=device,\n)\n\ntranscribe.model.config.forced_decoder_ids\
          \ = transcribe.tokenizer.get_decoder_prompt_ids(language=\"pt\", task=\"\
          transcribe\")\n\n# audio files can be of any type (.mp3, .m4a, .wav)\ntranscribe(\"\
          audio.m4a\")[\"text\"]\n```\n\nI would encourage you to use the [updated\
          \ version of this model](https://huggingface.co/jlondonobo/whisper-large-v2-pt-v3).\
          \ It is significantly more precise with the same inference time."
        updatedAt: '2022-12-27T04:21:53.857Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - skoll520
    id: 63aa72e18949ceef24a15e1f
    type: comment
  author: jlondonobo
  content: "Ol\xE1, @skoll520 \U0001F44B\U0001F3FB thanks for your interest in this\
    \ model. \n\nHere's a snippet you can copy to run Whisper models with `transformers`\
    \ :\n\n```python\nfrom transformers import pipeline\nimport torch\n\ndevice =\
    \ 0 if torch.cuda.is_available() else \"cpu\"\n\ntranscribe = pipeline(\n    task=\"\
    automatic-speech-recognition\",\n    model=\"jlondonobo/whisper-large-v2-pt\"\
    ,\n    chunk_length_s=30,\n    device=device,\n)\n\ntranscribe.model.config.forced_decoder_ids\
    \ = transcribe.tokenizer.get_decoder_prompt_ids(language=\"pt\", task=\"transcribe\"\
    )\n\n# audio files can be of any type (.mp3, .m4a, .wav)\ntranscribe(\"audio.m4a\"\
    )[\"text\"]\n```\n\nI would encourage you to use the [updated version of this\
    \ model](https://huggingface.co/jlondonobo/whisper-large-v2-pt-v3). It is significantly\
    \ more precise with the same inference time."
  created_at: 2022-12-27 04:21:53+00:00
  edited: false
  hidden: false
  id: 63aa72e18949ceef24a15e1f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: jlondonobo/whisper-large-v2-pt
repo_type: model
status: open
target_branch: null
title: python example please
