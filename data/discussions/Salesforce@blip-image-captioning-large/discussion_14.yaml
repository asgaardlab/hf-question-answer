!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Callam
conflicting_files: null
created_at: 2023-06-08 17:19:56+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e78b304d06c4e19602c3611089c478a4.svg
      fullname: Callam Ingram
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Callam
      type: user
    createdAt: '2023-06-08T18:19:56.000Z'
    data:
      edited: false
      editors:
      - Callam
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5595092177391052
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e78b304d06c4e19602c3611089c478a4.svg
          fullname: Callam Ingram
          isHf: false
          isPro: false
          name: Callam
          type: user
        html: '<p>I am trying to call </p>

          <p>hub = {<br>  ''HF_MODEL_ID'':"Salesforce/blip-image-captioning-base",
          # model_id from hf.co/models<br>  ''HF_TASK'':"image-to-text"                           #
          NLP task you want to use for predictions<br>}</p>

          <h1 id="create-hugging-face-model-class">create Hugging Face Model Class</h1>

          <p>huggingface_model = HuggingFaceModel(<br>   env=hub,                                                #
          configuration for loading model from Hub<br>   role=role,                                              #
          IAM role with permissions to create an endpoint<br>   transformers_version="4.26",                             #
          Transformers version used<br>   pytorch_version="1.13",                                  #
          PyTorch version used<br>   py_version=''py39'',                                      #
          Python version used<br>)</p>

          <h1 id="deploy-model-to-sagemaker-inference">deploy model to SageMaker Inference</h1>

          <p>predictor = huggingface_model.deploy(<br>   initial_instance_count=1,<br>   instance_type="ml.m5.xlarge"<br>)</p>

          <p>data = {<br>"inputs": {<br>    "img_url" : ''<a rel="nofollow" href="https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg''">https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg''</a><br>    }<br>}</p>

          <h1 id="request">request</h1>

          <p>predictor.predict(data)</p>

          <p>----------------------------------------------------------------------------ERROR
          Message---------------------------------------------------------------------------<br>ModelError:
          An error occurred (ModelError) when calling the InvokeEndpoint operation:
          Received client error (400) from the primary with the message "{<br>  "code":
          400,<br>  "type": "InternalServerException",<br>  "message": "Incorrect
          format used for image. Should be an url linking to an image, a local path,
          or a PIL image."<br>}</p>

          <p>Does anyone know why or how to structure the .predict() request? And
          how can I figure this out for other models in the future? </p>

          '
        raw: "I am trying to call \r\n\r\nhub = {\r\n  'HF_MODEL_ID':\"Salesforce/blip-image-captioning-base\"\
          , # model_id from hf.co/models\r\n  'HF_TASK':\"image-to-text\"        \
          \                   # NLP task you want to use for predictions\r\n}\r\n\r\
          \n# create Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\
          \n   env=hub,                                                # configuration\
          \ for loading model from Hub\r\n   role=role,                          \
          \                    # IAM role with permissions to create an endpoint\r\
          \n   transformers_version=\"4.26\",                             # Transformers\
          \ version used\r\n   pytorch_version=\"1.13\",                         \
          \         # PyTorch version used\r\n   py_version='py39',              \
          \                        # Python version used\r\n)\r\n\r\n# deploy model\
          \ to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\n  \
          \ initial_instance_count=1,\r\n   instance_type=\"ml.m5.xlarge\"\r\n)\r\n\
          \r\ndata = {\r\n\"inputs\": {\r\n\t\"img_url\" : 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg'\r\
          \n\t}\r\n}\r\n\r\n# request\r\npredictor.predict(data)\r\n\r\n----------------------------------------------------------------------------ERROR\
          \ Message---------------------------------------------------------------------------\r\
          \nModelError: An error occurred (ModelError) when calling the InvokeEndpoint\
          \ operation: Received client error (400) from the primary with the message\
          \ \"{\r\n  \"code\": 400,\r\n  \"type\": \"InternalServerException\",\r\n\
          \  \"message\": \"Incorrect format used for image. Should be an url linking\
          \ to an image, a local path, or a PIL image.\"\r\n}\r\n\r\nDoes anyone know\
          \ why or how to structure the .predict() request? And how can I figure this\
          \ out for other models in the future? "
        updatedAt: '2023-06-08T18:19:56.291Z'
      numEdits: 0
      reactions: []
    id: 64821bcc564f4a58662afc8a
    type: comment
  author: Callam
  content: "I am trying to call \r\n\r\nhub = {\r\n  'HF_MODEL_ID':\"Salesforce/blip-image-captioning-base\"\
    , # model_id from hf.co/models\r\n  'HF_TASK':\"image-to-text\"              \
    \             # NLP task you want to use for predictions\r\n}\r\n\r\n# create\
    \ Hugging Face Model Class\r\nhuggingface_model = HuggingFaceModel(\r\n   env=hub,\
    \                                                # configuration for loading model\
    \ from Hub\r\n   role=role,                                              # IAM\
    \ role with permissions to create an endpoint\r\n   transformers_version=\"4.26\"\
    ,                             # Transformers version used\r\n   pytorch_version=\"\
    1.13\",                                  # PyTorch version used\r\n   py_version='py39',\
    \                                      # Python version used\r\n)\r\n\r\n# deploy\
    \ model to SageMaker Inference\r\npredictor = huggingface_model.deploy(\r\n  \
    \ initial_instance_count=1,\r\n   instance_type=\"ml.m5.xlarge\"\r\n)\r\n\r\n\
    data = {\r\n\"inputs\": {\r\n\t\"img_url\" : 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg'\r\
    \n\t}\r\n}\r\n\r\n# request\r\npredictor.predict(data)\r\n\r\n----------------------------------------------------------------------------ERROR\
    \ Message---------------------------------------------------------------------------\r\
    \nModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation:\
    \ Received client error (400) from the primary with the message \"{\r\n  \"code\"\
    : 400,\r\n  \"type\": \"InternalServerException\",\r\n  \"message\": \"Incorrect\
    \ format used for image. Should be an url linking to an image, a local path, or\
    \ a PIL image.\"\r\n}\r\n\r\nDoes anyone know why or how to structure the .predict()\
    \ request? And how can I figure this out for other models in the future? "
  created_at: 2023-06-08 17:19:56+00:00
  edited: false
  hidden: false
  id: 64821bcc564f4a58662afc8a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/367a4e1355972d87194c08d3cbc044b4.svg
      fullname: Jakub Mioduszewski
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gitMiodek
      type: user
    createdAt: '2023-09-08T13:20:48.000Z'
    data:
      edited: false
      editors:
      - gitMiodek
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9497858881950378
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/367a4e1355972d87194c08d3cbc044b4.svg
          fullname: Jakub Mioduszewski
          isHf: false
          isPro: false
          name: gitMiodek
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Callam&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Callam\">@<span class=\"\
          underline\">Callam</span></a></span>\n\n\t</span></span> Did u fix it?</p>\n"
        raw: '@Callam Did u fix it?'
        updatedAt: '2023-09-08T13:20:48.497Z'
      numEdits: 0
      reactions: []
    id: 64fb1fb039d541478ee3ffba
    type: comment
  author: gitMiodek
  content: '@Callam Did u fix it?'
  created_at: 2023-09-08 12:20:48+00:00
  edited: false
  hidden: false
  id: 64fb1fb039d541478ee3ffba
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/7f5a91e153d989229aeb2041ab863d86.svg
      fullname: Justin Kwok
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bluetinkwok
      type: user
    createdAt: '2023-10-05T04:27:44.000Z'
    data:
      edited: false
      editors:
      - bluetinkwok
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9531469345092773
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/7f5a91e153d989229aeb2041ab863d86.svg
          fullname: Justin Kwok
          isHf: false
          isPro: false
          name: bluetinkwok
          type: user
        html: '<p>I deployed in AWS sagemaker, alos have the same problem. Did u fx
          it?</p>

          '
        raw: I deployed in AWS sagemaker, alos have the same problem. Did u fx it?
        updatedAt: '2023-10-05T04:27:44.986Z'
      numEdits: 0
      reactions: []
    id: 651e3b40a1d1733df8e9aaef
    type: comment
  author: bluetinkwok
  content: I deployed in AWS sagemaker, alos have the same problem. Did u fx it?
  created_at: 2023-10-05 03:27:44+00:00
  edited: false
  hidden: false
  id: 651e3b40a1d1733df8e9aaef
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e78b304d06c4e19602c3611089c478a4.svg
      fullname: Callam Ingram
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Callam
      type: user
    createdAt: '2023-10-05T16:22:23.000Z'
    data:
      edited: false
      editors:
      - Callam
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7445532083511353
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e78b304d06c4e19602c3611089c478a4.svg
          fullname: Callam Ingram
          isHf: false
          isPro: false
          name: Callam
          type: user
        html: '<p>Yes I did: </p>

          <p><a rel="nofollow" href="https://github.com/DSCO-Co/SageMaker-image-to-text">https://github.com/DSCO-Co/SageMaker-image-to-text</a></p>

          '
        raw: "Yes I did: \n\nhttps://github.com/DSCO-Co/SageMaker-image-to-text"
        updatedAt: '2023-10-05T16:22:23.232Z'
      numEdits: 0
      reactions: []
    id: 651ee2bf559843c34d2843ad
    type: comment
  author: Callam
  content: "Yes I did: \n\nhttps://github.com/DSCO-Co/SageMaker-image-to-text"
  created_at: 2023-10-05 15:22:23+00:00
  edited: false
  hidden: false
  id: 651ee2bf559843c34d2843ad
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e78b304d06c4e19602c3611089c478a4.svg
      fullname: Callam Ingram
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Callam
      type: user
    createdAt: '2023-10-05T16:26:34.000Z'
    data:
      edited: false
      editors:
      - Callam
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9076700806617737
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e78b304d06c4e19602c3611089c478a4.svg
          fullname: Callam Ingram
          isHf: false
          isPro: false
          name: Callam
          type: user
        html: '<blockquote>

          <p>I deployed in AWS sagemaker, alos have the same problem. Did u fx it?</p>

          </blockquote>

          <p>Yes I did:</p>

          <p><a rel="nofollow" href="https://github.com/DSCO-Co/SageMaker-image-to-text">https://github.com/DSCO-Co/SageMaker-image-to-text</a></p>

          '
        raw: '> I deployed in AWS sagemaker, alos have the same problem. Did u fx
          it?


          Yes I did:


          https://github.com/DSCO-Co/SageMaker-image-to-text'
        updatedAt: '2023-10-05T16:26:34.812Z'
      numEdits: 0
      reactions: []
    id: 651ee3bada9dcb165cad78ff
    type: comment
  author: Callam
  content: '> I deployed in AWS sagemaker, alos have the same problem. Did u fx it?


    Yes I did:


    https://github.com/DSCO-Co/SageMaker-image-to-text'
  created_at: 2023-10-05 15:26:34+00:00
  edited: false
  hidden: false
  id: 651ee3bada9dcb165cad78ff
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 14
repo_id: Salesforce/blip-image-captioning-large
repo_type: model
status: open
target_branch: null
title: Calling predictor.predict() on deployed model via SageMaker
