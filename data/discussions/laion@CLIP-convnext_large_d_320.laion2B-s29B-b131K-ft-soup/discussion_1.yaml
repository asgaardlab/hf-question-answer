!!python/object:huggingface_hub.community.DiscussionWithDetails
author: thesofakillers
conflicting_files: null
created_at: 2023-04-14 14:00:03+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665158475637-627b8bc83974b0ed6b28db67.jpeg?w=200&h=200&f=face
      fullname: Giulio Starace
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thesofakillers
      type: user
    createdAt: '2023-04-14T15:00:03.000Z'
    data:
      edited: false
      editors:
      - thesofakillers
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665158475637-627b8bc83974b0ed6b28db67.jpeg?w=200&h=200&f=face
          fullname: Giulio Starace
          isHf: false
          isPro: false
          name: thesofakillers
          type: user
        html: "<p>Hi. I am trying to load the model as usual</p>\n<pre><code class=\"\
          language-python\">MODEL_VARIANT = <span class=\"hljs-string\">\"laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\"\
          </span>\n\nmodel = transformers.CLIPModel.from_pretrained(MODEL_VARIANT)\n\
          processor = transformers.CLIPProcessor.from_pretrained(MODEL_VARIANT)\n\
          </code></pre>\n<p>But i get the following error:</p>\n<pre><code>HTTPError\
          \                                 Traceback (most recent call last)\nFile\
          \ ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:259,\
          \ in hf_raise_for_status(response, endpoint_name)\n    258 try:\n--&gt;\
          \ 259     response.raise_for_status()\n    260 except HTTPError as e:\n\n\
          File ~/miniconda3/envs/thesis/lib/python3.8/site-packages/requests/models.py:1021,\
          \ in Response.raise_for_status(self)\n   1020 if http_error_msg:\n-&gt;\
          \ 1021     raise HTTPError(http_error_msg, response=self)\n\nHTTPError:\
          \ 404 Client Error: Not Found for url: https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/resolve/main/config.json\n\
          \nThe above exception was the direct cause of the following exception:\n\
          \nEntryNotFoundError                        Traceback (most recent call\
          \ last)\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/utils/hub.py:409,\
          \ in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download,\
          \ proxies, use_auth_token, revision, local_files_only, subfolder, user_agent,\
          \ _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors,\
          \ _commit_hash)\n    407 try:\n    408     # Load from URL or cache if already\
          \ cached\n--&gt; 409     resolved_file = hf_hub_download(\n    410     \
          \    path_or_repo_id,\n    411         filename,\n    412         subfolder=None\
          \ if len(subfolder) == 0 else subfolder,\n    413         revision=revision,\n\
          \    414         cache_dir=cache_dir,\n    415         user_agent=user_agent,\n\
          \    416         force_download=force_download,\n    417         proxies=proxies,\n\
          \    418         resume_download=resume_download,\n    419         use_auth_token=use_auth_token,\n\
          \    420         local_files_only=local_files_only,\n    421     )\n   \
          \ 423 except RepositoryNotFoundError:\n\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:120,\
          \ in validate_hf_hub_args.&lt;locals&gt;._inner_fn(*args, **kwargs)\n  \
          \  118     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__name__,\
          \ has_token=has_token, kwargs=kwargs)\n--&gt; 120 return fn(*args, **kwargs)\n\
          \nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/file_download.py:1166,\
          \ in hf_hub_download(repo_id, filename, subfolder, repo_type, revision,\
          \ library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks,\
          \ user_agent, force_download, force_filename, proxies, etag_timeout, resume_download,\
          \ token, local_files_only, legacy_cache_layout)\n   1165 try:\n-&gt; 1166\
          \     metadata = get_hf_file_metadata(\n   1167         url=url,\n   1168\
          \         token=token,\n   1169         proxies=proxies,\n   1170      \
          \   timeout=etag_timeout,\n   1171     )\n   1172 except EntryNotFoundError\
          \ as http_error:\n   1173     # Cache the non-existence of the file and\
          \ raise\n\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:120,\
          \ in validate_hf_hub_args.&lt;locals&gt;._inner_fn(*args, **kwargs)\n  \
          \  118     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__name__,\
          \ has_token=has_token, kwargs=kwargs)\n--&gt; 120 return fn(*args, **kwargs)\n\
          \nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/file_download.py:1507,\
          \ in get_hf_file_metadata(url, token, proxies, timeout)\n   1498 r = _request_wrapper(\n\
          \   1499     method=\"HEAD\",\n   1500     url=url,\n   (...)\n   1505 \
          \    timeout=timeout,\n   1506 )\n-&gt; 1507 hf_raise_for_status(r)\n  \
          \ 1509 # Return\n\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:269,\
          \ in hf_raise_for_status(response, endpoint_name)\n    268     message =\
          \ f\"{response.status_code} Client Error.\" + \"\\n\\n\" + f\"Entry Not\
          \ Found for url: {response.url}.\"\n--&gt; 269     raise EntryNotFoundError(message,\
          \ response) from e\n    271 elif error_code == \"GatedRepo\":\n\nEntryNotFoundError:\
          \ 404 Client Error. (Request ID: Root=1-64396785-5de042e44737906e415c76d1)\n\
          \nEntry Not Found for url: https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/resolve/main/config.json.\n\
          \nDuring handling of the above exception, another exception occurred:\n\n\
          OSError                                   Traceback (most recent call last)\n\
          Cell In[33], line 5\n      1 # First setup the model\n      3 MODEL_VARIANT\
          \ = \"laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\"\n----&gt;\
          \ 5 model = transformers.CLIPModel.from_pretrained(MODEL_VARIANT)\n    \
          \  6 processor = transformers.CLIPProcessor.from_pretrained(MODEL_VARIANT)\n\
          \nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/modeling_utils.py:2269,\
          \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *model_args, **kwargs)\n   2267 if not isinstance(config, PretrainedConfig):\n\
          \   2268     config_path = config if config is not None else pretrained_model_name_or_path\n\
          -&gt; 2269     config, model_kwargs = cls.config_class.from_pretrained(\n\
          \   2270         config_path,\n   2271         cache_dir=cache_dir,\n  \
          \ 2272         return_unused_kwargs=True,\n   2273         force_download=force_download,\n\
          \   2274         resume_download=resume_download,\n   2275         proxies=proxies,\n\
          \   2276         local_files_only=local_files_only,\n   2277         use_auth_token=use_auth_token,\n\
          \   2278         revision=revision,\n   2279         subfolder=subfolder,\n\
          \   2280         _from_auto=from_auto_class,\n   2281         _from_pipeline=from_pipeline,\n\
          \   2282         **kwargs,\n   2283     )\n   2284 else:\n   2285     model_kwargs\
          \ = kwargs\n\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/configuration_utils.py:546,\
          \ in PretrainedConfig.from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\n    468 @classmethod\n    469 def from_pretrained(cls, pretrained_model_name_or_path:\
          \ Union[str, os.PathLike], **kwargs) -&gt; \"PretrainedConfig\":\n    470\
          \     r\"\"\"\n    471     Instantiate a [`PretrainedConfig`] (or a derived\
          \ class) from a pretrained model configuration.\n    472 \n   (...)\n  \
          \  544     assert unused_kwargs == {\"foo\": False}\n    545     ```\"\"\
          \"\n--&gt; 546     config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path,\
          \ **kwargs)\n    547     if \"model_type\" in config_dict and hasattr(cls,\
          \ \"model_type\") and config_dict[\"model_type\"] != cls.model_type:\n \
          \   548         logger.warning(\n    549             f\"You are using a\
          \ model of type {config_dict['model_type']} to instantiate a model of type\
          \ \"\n    550             f\"{cls.model_type}. This is not supported for\
          \ all configurations of models and can yield errors.\"\n    551        \
          \ )\n\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/configuration_utils.py:573,\
          \ in PretrainedConfig.get_config_dict(cls, pretrained_model_name_or_path,\
          \ **kwargs)\n    571 original_kwargs = copy.deepcopy(kwargs)\n    572 #\
          \ Get config dict associated with the base config file\n--&gt; 573 config_dict,\
          \ kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n\
          \    574 if \"_commit_hash\" in config_dict:\n    575     original_kwargs[\"\
          _commit_hash\"] = config_dict[\"_commit_hash\"]\n\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/configuration_utils.py:628,\
          \ in PretrainedConfig._get_config_dict(cls, pretrained_model_name_or_path,\
          \ **kwargs)\n    624 configuration_file = kwargs.pop(\"_configuration_file\"\
          , CONFIG_NAME)\n    626 try:\n    627     # Load from local folder or from\
          \ cache or download from model Hub and cache\n--&gt; 628     resolved_config_file\
          \ = cached_file(\n    629         pretrained_model_name_or_path,\n    630\
          \         configuration_file,\n    631         cache_dir=cache_dir,\n  \
          \  632         force_download=force_download,\n    633         proxies=proxies,\n\
          \    634         resume_download=resume_download,\n    635         local_files_only=local_files_only,\n\
          \    636         use_auth_token=use_auth_token,\n    637         user_agent=user_agent,\n\
          \    638         revision=revision,\n    639         subfolder=subfolder,\n\
          \    640         _commit_hash=commit_hash,\n    641     )\n    642     commit_hash\
          \ = extract_commit_hash(resolved_config_file, commit_hash)\n    643 except\
          \ EnvironmentError:\n    644     # Raise any environment error raise by\
          \ `cached_file`. It will have a helpful error message adapted to\n    645\
          \     # the original exception.\n\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/utils/hub.py:454,\
          \ in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download,\
          \ proxies, use_auth_token, revision, local_files_only, subfolder, user_agent,\
          \ _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors,\
          \ _commit_hash)\n    452     if revision is None:\n    453         revision\
          \ = \"main\"\n--&gt; 454     raise EnvironmentError(\n    455         f\"\
          {path_or_repo_id} does not appear to have a file named {full_filename}.\
          \ Checkout \"\n    456         f\"'https://huggingface.co/{path_or_repo_id}/{revision}'\
          \ for available files.\"\n    457     )\n    458 except HTTPError as err:\n\
          \    459     # First we try to see if we have a cached version (not up to\
          \ date):\n    460     resolved_file = try_to_load_from_cache(path_or_repo_id,\
          \ full_filename, cache_dir=cache_dir, revision=revision)\n\nOSError: laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\
          \ does not appear to have a file named config.json. Checkout 'https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/main'\
          \ for available files.\n</code></pre>\n"
        raw: "Hi. I am trying to load the model as usual\r\n\r\n```python\r\nMODEL_VARIANT\
          \ = \"laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\"\r\n\r\
          \nmodel = transformers.CLIPModel.from_pretrained(MODEL_VARIANT)\r\nprocessor\
          \ = transformers.CLIPProcessor.from_pretrained(MODEL_VARIANT)\r\n```\r\n\
          \r\nBut i get the following error:\r\n\r\n```\r\nHTTPError             \
          \                    Traceback (most recent call last)\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:259,\
          \ in hf_raise_for_status(response, endpoint_name)\r\n    258 try:\r\n-->\
          \ 259     response.raise_for_status()\r\n    260 except HTTPError as e:\r\
          \n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/requests/models.py:1021,\
          \ in Response.raise_for_status(self)\r\n   1020 if http_error_msg:\r\n->\
          \ 1021     raise HTTPError(http_error_msg, response=self)\r\n\r\nHTTPError:\
          \ 404 Client Error: Not Found for url: https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/resolve/main/config.json\r\
          \n\r\nThe above exception was the direct cause of the following exception:\r\
          \n\r\nEntryNotFoundError                        Traceback (most recent call\
          \ last)\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/utils/hub.py:409,\
          \ in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download,\
          \ proxies, use_auth_token, revision, local_files_only, subfolder, user_agent,\
          \ _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors,\
          \ _commit_hash)\r\n    407 try:\r\n    408     # Load from URL or cache\
          \ if already cached\r\n--> 409     resolved_file = hf_hub_download(\r\n\
          \    410         path_or_repo_id,\r\n    411         filename,\r\n    412\
          \         subfolder=None if len(subfolder) == 0 else subfolder,\r\n    413\
          \         revision=revision,\r\n    414         cache_dir=cache_dir,\r\n\
          \    415         user_agent=user_agent,\r\n    416         force_download=force_download,\r\
          \n    417         proxies=proxies,\r\n    418         resume_download=resume_download,\r\
          \n    419         use_auth_token=use_auth_token,\r\n    420         local_files_only=local_files_only,\r\
          \n    421     )\r\n    423 except RepositoryNotFoundError:\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:120,\
          \ in validate_hf_hub_args.<locals>._inner_fn(*args, **kwargs)\r\n    118\
          \     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__name__, has_token=has_token,\
          \ kwargs=kwargs)\r\n--> 120 return fn(*args, **kwargs)\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/file_download.py:1166,\
          \ in hf_hub_download(repo_id, filename, subfolder, repo_type, revision,\
          \ library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks,\
          \ user_agent, force_download, force_filename, proxies, etag_timeout, resume_download,\
          \ token, local_files_only, legacy_cache_layout)\r\n   1165 try:\r\n-> 1166\
          \     metadata = get_hf_file_metadata(\r\n   1167         url=url,\r\n \
          \  1168         token=token,\r\n   1169         proxies=proxies,\r\n   1170\
          \         timeout=etag_timeout,\r\n   1171     )\r\n   1172 except EntryNotFoundError\
          \ as http_error:\r\n   1173     # Cache the non-existence of the file and\
          \ raise\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:120,\
          \ in validate_hf_hub_args.<locals>._inner_fn(*args, **kwargs)\r\n    118\
          \     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__name__, has_token=has_token,\
          \ kwargs=kwargs)\r\n--> 120 return fn(*args, **kwargs)\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/file_download.py:1507,\
          \ in get_hf_file_metadata(url, token, proxies, timeout)\r\n   1498 r = _request_wrapper(\r\
          \n   1499     method=\"HEAD\",\r\n   1500     url=url,\r\n   (...)\r\n \
          \  1505     timeout=timeout,\r\n   1506 )\r\n-> 1507 hf_raise_for_status(r)\r\
          \n   1509 # Return\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:269,\
          \ in hf_raise_for_status(response, endpoint_name)\r\n    268     message\
          \ = f\"{response.status_code} Client Error.\" + \"\\n\\n\" + f\"Entry Not\
          \ Found for url: {response.url}.\"\r\n--> 269     raise EntryNotFoundError(message,\
          \ response) from e\r\n    271 elif error_code == \"GatedRepo\":\r\n\r\n\
          EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64396785-5de042e44737906e415c76d1)\r\
          \n\r\nEntry Not Found for url: https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/resolve/main/config.json.\r\
          \n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nOSError                                   Traceback (most recent call\
          \ last)\r\nCell In[33], line 5\r\n      1 # First setup the model\r\n  \
          \    3 MODEL_VARIANT = \"laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\"\
          \r\n----> 5 model = transformers.CLIPModel.from_pretrained(MODEL_VARIANT)\r\
          \n      6 processor = transformers.CLIPProcessor.from_pretrained(MODEL_VARIANT)\r\
          \n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/modeling_utils.py:2269,\
          \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *model_args, **kwargs)\r\n   2267 if not isinstance(config, PretrainedConfig):\r\
          \n   2268     config_path = config if config is not None else pretrained_model_name_or_path\r\
          \n-> 2269     config, model_kwargs = cls.config_class.from_pretrained(\r\
          \n   2270         config_path,\r\n   2271         cache_dir=cache_dir,\r\
          \n   2272         return_unused_kwargs=True,\r\n   2273         force_download=force_download,\r\
          \n   2274         resume_download=resume_download,\r\n   2275         proxies=proxies,\r\
          \n   2276         local_files_only=local_files_only,\r\n   2277        \
          \ use_auth_token=use_auth_token,\r\n   2278         revision=revision,\r\
          \n   2279         subfolder=subfolder,\r\n   2280         _from_auto=from_auto_class,\r\
          \n   2281         _from_pipeline=from_pipeline,\r\n   2282         **kwargs,\r\
          \n   2283     )\r\n   2284 else:\r\n   2285     model_kwargs = kwargs\r\n\
          \r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/configuration_utils.py:546,\
          \ in PretrainedConfig.from_pretrained(cls, pretrained_model_name_or_path,\
          \ **kwargs)\r\n    468 @classmethod\r\n    469 def from_pretrained(cls,\
          \ pretrained_model_name_or_path: Union[str, os.PathLike], **kwargs) -> \"\
          PretrainedConfig\":\r\n    470     r\"\"\"\r\n    471     Instantiate a\
          \ [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\r\
          \n    472 \r\n   (...)\r\n    544     assert unused_kwargs == {\"foo\":\
          \ False}\r\n    545     ```\"\"\"\r\n--> 546     config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path,\
          \ **kwargs)\r\n    547     if \"model_type\" in config_dict and hasattr(cls,\
          \ \"model_type\") and config_dict[\"model_type\"] != cls.model_type:\r\n\
          \    548         logger.warning(\r\n    549             f\"You are using\
          \ a model of type {config_dict['model_type']} to instantiate a model of\
          \ type \"\r\n    550             f\"{cls.model_type}. This is not supported\
          \ for all configurations of models and can yield errors.\"\r\n    551  \
          \       )\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/configuration_utils.py:573,\
          \ in PretrainedConfig.get_config_dict(cls, pretrained_model_name_or_path,\
          \ **kwargs)\r\n    571 original_kwargs = copy.deepcopy(kwargs)\r\n    572\
          \ # Get config dict associated with the base config file\r\n--> 573 config_dict,\
          \ kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\r\
          \n    574 if \"_commit_hash\" in config_dict:\r\n    575     original_kwargs[\"\
          _commit_hash\"] = config_dict[\"_commit_hash\"]\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/configuration_utils.py:628,\
          \ in PretrainedConfig._get_config_dict(cls, pretrained_model_name_or_path,\
          \ **kwargs)\r\n    624 configuration_file = kwargs.pop(\"_configuration_file\"\
          , CONFIG_NAME)\r\n    626 try:\r\n    627     # Load from local folder or\
          \ from cache or download from model Hub and cache\r\n--> 628     resolved_config_file\
          \ = cached_file(\r\n    629         pretrained_model_name_or_path,\r\n \
          \   630         configuration_file,\r\n    631         cache_dir=cache_dir,\r\
          \n    632         force_download=force_download,\r\n    633         proxies=proxies,\r\
          \n    634         resume_download=resume_download,\r\n    635         local_files_only=local_files_only,\r\
          \n    636         use_auth_token=use_auth_token,\r\n    637         user_agent=user_agent,\r\
          \n    638         revision=revision,\r\n    639         subfolder=subfolder,\r\
          \n    640         _commit_hash=commit_hash,\r\n    641     )\r\n    642\
          \     commit_hash = extract_commit_hash(resolved_config_file, commit_hash)\r\
          \n    643 except EnvironmentError:\r\n    644     # Raise any environment\
          \ error raise by `cached_file`. It will have a helpful error message adapted\
          \ to\r\n    645     # the original exception.\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/utils/hub.py:454,\
          \ in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download,\
          \ proxies, use_auth_token, revision, local_files_only, subfolder, user_agent,\
          \ _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors,\
          \ _commit_hash)\r\n    452     if revision is None:\r\n    453         revision\
          \ = \"main\"\r\n--> 454     raise EnvironmentError(\r\n    455         f\"\
          {path_or_repo_id} does not appear to have a file named {full_filename}.\
          \ Checkout \"\r\n    456         f\"'https://huggingface.co/{path_or_repo_id}/{revision}'\
          \ for available files.\"\r\n    457     )\r\n    458 except HTTPError as\
          \ err:\r\n    459     # First we try to see if we have a cached version\
          \ (not up to date):\r\n    460     resolved_file = try_to_load_from_cache(path_or_repo_id,\
          \ full_filename, cache_dir=cache_dir, revision=revision)\r\n\r\nOSError:\
          \ laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup does not appear\
          \ to have a file named config.json. Checkout 'https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/main'\
          \ for available files.\r\n```\r\n"
        updatedAt: '2023-04-14T15:00:03.720Z'
      numEdits: 0
      reactions: []
    id: 64396a73eb7c5616ef3e6c34
    type: comment
  author: thesofakillers
  content: "Hi. I am trying to load the model as usual\r\n\r\n```python\r\nMODEL_VARIANT\
    \ = \"laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\"\r\n\r\nmodel\
    \ = transformers.CLIPModel.from_pretrained(MODEL_VARIANT)\r\nprocessor = transformers.CLIPProcessor.from_pretrained(MODEL_VARIANT)\r\
    \n```\r\n\r\nBut i get the following error:\r\n\r\n```\r\nHTTPError          \
    \                       Traceback (most recent call last)\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:259,\
    \ in hf_raise_for_status(response, endpoint_name)\r\n    258 try:\r\n--> 259 \
    \    response.raise_for_status()\r\n    260 except HTTPError as e:\r\n\r\nFile\
    \ ~/miniconda3/envs/thesis/lib/python3.8/site-packages/requests/models.py:1021,\
    \ in Response.raise_for_status(self)\r\n   1020 if http_error_msg:\r\n-> 1021\
    \     raise HTTPError(http_error_msg, response=self)\r\n\r\nHTTPError: 404 Client\
    \ Error: Not Found for url: https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/resolve/main/config.json\r\
    \n\r\nThe above exception was the direct cause of the following exception:\r\n\
    \r\nEntryNotFoundError                        Traceback (most recent call last)\r\
    \nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/utils/hub.py:409,\
    \ in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download,\
    \ proxies, use_auth_token, revision, local_files_only, subfolder, user_agent,\
    \ _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors,\
    \ _commit_hash)\r\n    407 try:\r\n    408     # Load from URL or cache if already\
    \ cached\r\n--> 409     resolved_file = hf_hub_download(\r\n    410         path_or_repo_id,\r\
    \n    411         filename,\r\n    412         subfolder=None if len(subfolder)\
    \ == 0 else subfolder,\r\n    413         revision=revision,\r\n    414      \
    \   cache_dir=cache_dir,\r\n    415         user_agent=user_agent,\r\n    416\
    \         force_download=force_download,\r\n    417         proxies=proxies,\r\
    \n    418         resume_download=resume_download,\r\n    419         use_auth_token=use_auth_token,\r\
    \n    420         local_files_only=local_files_only,\r\n    421     )\r\n    423\
    \ except RepositoryNotFoundError:\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:120,\
    \ in validate_hf_hub_args.<locals>._inner_fn(*args, **kwargs)\r\n    118     kwargs\
    \ = smoothly_deprecate_use_auth_token(fn_name=fn.__name__, has_token=has_token,\
    \ kwargs=kwargs)\r\n--> 120 return fn(*args, **kwargs)\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/file_download.py:1166,\
    \ in hf_hub_download(repo_id, filename, subfolder, repo_type, revision, library_name,\
    \ library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download,\
    \ force_filename, proxies, etag_timeout, resume_download, token, local_files_only,\
    \ legacy_cache_layout)\r\n   1165 try:\r\n-> 1166     metadata = get_hf_file_metadata(\r\
    \n   1167         url=url,\r\n   1168         token=token,\r\n   1169        \
    \ proxies=proxies,\r\n   1170         timeout=etag_timeout,\r\n   1171     )\r\
    \n   1172 except EntryNotFoundError as http_error:\r\n   1173     # Cache the\
    \ non-existence of the file and raise\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:120,\
    \ in validate_hf_hub_args.<locals>._inner_fn(*args, **kwargs)\r\n    118     kwargs\
    \ = smoothly_deprecate_use_auth_token(fn_name=fn.__name__, has_token=has_token,\
    \ kwargs=kwargs)\r\n--> 120 return fn(*args, **kwargs)\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/file_download.py:1507,\
    \ in get_hf_file_metadata(url, token, proxies, timeout)\r\n   1498 r = _request_wrapper(\r\
    \n   1499     method=\"HEAD\",\r\n   1500     url=url,\r\n   (...)\r\n   1505\
    \     timeout=timeout,\r\n   1506 )\r\n-> 1507 hf_raise_for_status(r)\r\n   1509\
    \ # Return\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:269,\
    \ in hf_raise_for_status(response, endpoint_name)\r\n    268     message = f\"\
    {response.status_code} Client Error.\" + \"\\n\\n\" + f\"Entry Not Found for url:\
    \ {response.url}.\"\r\n--> 269     raise EntryNotFoundError(message, response)\
    \ from e\r\n    271 elif error_code == \"GatedRepo\":\r\n\r\nEntryNotFoundError:\
    \ 404 Client Error. (Request ID: Root=1-64396785-5de042e44737906e415c76d1)\r\n\
    \r\nEntry Not Found for url: https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/resolve/main/config.json.\r\
    \n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\
    \nOSError                                   Traceback (most recent call last)\r\
    \nCell In[33], line 5\r\n      1 # First setup the model\r\n      3 MODEL_VARIANT\
    \ = \"laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\"\r\n----> 5\
    \ model = transformers.CLIPModel.from_pretrained(MODEL_VARIANT)\r\n      6 processor\
    \ = transformers.CLIPProcessor.from_pretrained(MODEL_VARIANT)\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/modeling_utils.py:2269,\
    \ in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, *model_args,\
    \ **kwargs)\r\n   2267 if not isinstance(config, PretrainedConfig):\r\n   2268\
    \     config_path = config if config is not None else pretrained_model_name_or_path\r\
    \n-> 2269     config, model_kwargs = cls.config_class.from_pretrained(\r\n   2270\
    \         config_path,\r\n   2271         cache_dir=cache_dir,\r\n   2272    \
    \     return_unused_kwargs=True,\r\n   2273         force_download=force_download,\r\
    \n   2274         resume_download=resume_download,\r\n   2275         proxies=proxies,\r\
    \n   2276         local_files_only=local_files_only,\r\n   2277         use_auth_token=use_auth_token,\r\
    \n   2278         revision=revision,\r\n   2279         subfolder=subfolder,\r\
    \n   2280         _from_auto=from_auto_class,\r\n   2281         _from_pipeline=from_pipeline,\r\
    \n   2282         **kwargs,\r\n   2283     )\r\n   2284 else:\r\n   2285     model_kwargs\
    \ = kwargs\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/configuration_utils.py:546,\
    \ in PretrainedConfig.from_pretrained(cls, pretrained_model_name_or_path, **kwargs)\r\
    \n    468 @classmethod\r\n    469 def from_pretrained(cls, pretrained_model_name_or_path:\
    \ Union[str, os.PathLike], **kwargs) -> \"PretrainedConfig\":\r\n    470     r\"\
    \"\"\r\n    471     Instantiate a [`PretrainedConfig`] (or a derived class) from\
    \ a pretrained model configuration.\r\n    472 \r\n   (...)\r\n    544     assert\
    \ unused_kwargs == {\"foo\": False}\r\n    545     ```\"\"\"\r\n--> 546     config_dict,\
    \ kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)\r\n  \
    \  547     if \"model_type\" in config_dict and hasattr(cls, \"model_type\") and\
    \ config_dict[\"model_type\"] != cls.model_type:\r\n    548         logger.warning(\r\
    \n    549             f\"You are using a model of type {config_dict['model_type']}\
    \ to instantiate a model of type \"\r\n    550             f\"{cls.model_type}.\
    \ This is not supported for all configurations of models and can yield errors.\"\
    \r\n    551         )\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/configuration_utils.py:573,\
    \ in PretrainedConfig.get_config_dict(cls, pretrained_model_name_or_path, **kwargs)\r\
    \n    571 original_kwargs = copy.deepcopy(kwargs)\r\n    572 # Get config dict\
    \ associated with the base config file\r\n--> 573 config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path,\
    \ **kwargs)\r\n    574 if \"_commit_hash\" in config_dict:\r\n    575     original_kwargs[\"\
    _commit_hash\"] = config_dict[\"_commit_hash\"]\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/configuration_utils.py:628,\
    \ in PretrainedConfig._get_config_dict(cls, pretrained_model_name_or_path, **kwargs)\r\
    \n    624 configuration_file = kwargs.pop(\"_configuration_file\", CONFIG_NAME)\r\
    \n    626 try:\r\n    627     # Load from local folder or from cache or download\
    \ from model Hub and cache\r\n--> 628     resolved_config_file = cached_file(\r\
    \n    629         pretrained_model_name_or_path,\r\n    630         configuration_file,\r\
    \n    631         cache_dir=cache_dir,\r\n    632         force_download=force_download,\r\
    \n    633         proxies=proxies,\r\n    634         resume_download=resume_download,\r\
    \n    635         local_files_only=local_files_only,\r\n    636         use_auth_token=use_auth_token,\r\
    \n    637         user_agent=user_agent,\r\n    638         revision=revision,\r\
    \n    639         subfolder=subfolder,\r\n    640         _commit_hash=commit_hash,\r\
    \n    641     )\r\n    642     commit_hash = extract_commit_hash(resolved_config_file,\
    \ commit_hash)\r\n    643 except EnvironmentError:\r\n    644     # Raise any\
    \ environment error raise by `cached_file`. It will have a helpful error message\
    \ adapted to\r\n    645     # the original exception.\r\n\r\nFile ~/miniconda3/envs/thesis/lib/python3.8/site-packages/transformers/utils/hub.py:454,\
    \ in cached_file(path_or_repo_id, filename, cache_dir, force_download, resume_download,\
    \ proxies, use_auth_token, revision, local_files_only, subfolder, user_agent,\
    \ _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors,\
    \ _commit_hash)\r\n    452     if revision is None:\r\n    453         revision\
    \ = \"main\"\r\n--> 454     raise EnvironmentError(\r\n    455         f\"{path_or_repo_id}\
    \ does not appear to have a file named {full_filename}. Checkout \"\r\n    456\
    \         f\"'https://huggingface.co/{path_or_repo_id}/{revision}' for available\
    \ files.\"\r\n    457     )\r\n    458 except HTTPError as err:\r\n    459   \
    \  # First we try to see if we have a cached version (not up to date):\r\n   \
    \ 460     resolved_file = try_to_load_from_cache(path_or_repo_id, full_filename,\
    \ cache_dir=cache_dir, revision=revision)\r\n\r\nOSError: laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\
    \ does not appear to have a file named config.json. Checkout 'https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/main'\
    \ for available files.\r\n```\r\n"
  created_at: 2023-04-14 14:00:03+00:00
  edited: false
  hidden: false
  id: 64396a73eb7c5616ef3e6c34
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-04-14T16:57:25.000Z'
    data:
      edited: false
      editors:
      - rwightman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;thesofakillers&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/thesofakillers\"\
          >@<span class=\"underline\">thesofakillers</span></a></span>\n\n\t</span></span>\
          \  this model is an OpenCLIP only model right now (open_clip_config.json\
          \ and no config.json), there is no supporting transformers CLIP model w/\
          \ convnext. Someone would have to add support to transformers. <a rel=\"\
          nofollow\" href=\"https://github.com/mlfoundations/open_clip\">https://github.com/mlfoundations/open_clip</a>\
          \   .... have a TODO to add a usage example for this to model cards</p>\n"
        raw: '@thesofakillers  this model is an OpenCLIP only model right now (open_clip_config.json
          and no config.json), there is no supporting transformers CLIP model w/ convnext.
          Someone would have to add support to transformers. https://github.com/mlfoundations/open_clip   ....
          have a TODO to add a usage example for this to model cards'
        updatedAt: '2023-04-14T16:57:25.697Z'
      numEdits: 0
      reactions: []
    id: 643985f511e9481b75e347e8
    type: comment
  author: rwightman
  content: '@thesofakillers  this model is an OpenCLIP only model right now (open_clip_config.json
    and no config.json), there is no supporting transformers CLIP model w/ convnext.
    Someone would have to add support to transformers. https://github.com/mlfoundations/open_clip   ....
    have a TODO to add a usage example for this to model cards'
  created_at: 2023-04-14 15:57:25+00:00
  edited: false
  hidden: false
  id: 643985f511e9481b75e347e8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
      fullname: Ross Wightman
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: rwightman
      type: user
    createdAt: '2023-04-14T17:03:37.000Z'
    data:
      edited: false
      editors:
      - rwightman
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667002643224-604a5184dca2c7ac7508b849.jpeg?w=200&h=200&f=face
          fullname: Ross Wightman
          isHf: true
          isPro: false
          name: rwightman
          type: user
        html: '<p>If you have open_clip installed (pip install open_clip_torch) you
          can do following to create model/tokenizer for OpenCLIP models from the
          hub, use is very similar to the OpenAI CLIP code for getting emeddings,
          zero-shot classification, etc</p>

          <pre><code>model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(''hf-hub:laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup'')

          tokenizer = open_clip.get_tokenizer(''hf-hub:laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup'')

          </code></pre>

          '
        raw: 'If you have open_clip installed (pip install open_clip_torch) you can
          do following to create model/tokenizer for OpenCLIP models from the hub,
          use is very similar to the OpenAI CLIP code for getting emeddings, zero-shot
          classification, etc


          ```

          model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(''hf-hub:laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup'')

          tokenizer = open_clip.get_tokenizer(''hf-hub:laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup'')

          ```'
        updatedAt: '2023-04-14T17:03:37.737Z'
      numEdits: 0
      reactions: []
    id: 643987699f49f6e6ee246452
    type: comment
  author: rwightman
  content: 'If you have open_clip installed (pip install open_clip_torch) you can
    do following to create model/tokenizer for OpenCLIP models from the hub, use is
    very similar to the OpenAI CLIP code for getting emeddings, zero-shot classification,
    etc


    ```

    model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(''hf-hub:laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup'')

    tokenizer = open_clip.get_tokenizer(''hf-hub:laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup'')

    ```'
  created_at: 2023-04-14 16:03:37+00:00
  edited: false
  hidden: false
  id: 643987699f49f6e6ee246452
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665158475637-627b8bc83974b0ed6b28db67.jpeg?w=200&h=200&f=face
      fullname: Giulio Starace
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thesofakillers
      type: user
    createdAt: '2023-04-16T18:46:35.000Z'
    data:
      edited: false
      editors:
      - thesofakillers
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665158475637-627b8bc83974b0ed6b28db67.jpeg?w=200&h=200&f=face
          fullname: Giulio Starace
          isHf: false
          isPro: false
          name: thesofakillers
          type: user
        html: '<p>Ah, understood. Thanks!</p>

          '
        raw: Ah, understood. Thanks!
        updatedAt: '2023-04-16T18:46:35.942Z'
      numEdits: 0
      reactions: []
      relatedEventId: 643c428be3a7bbe2cf3d439f
    id: 643c428be3a7bbe2cf3d439e
    type: comment
  author: thesofakillers
  content: Ah, understood. Thanks!
  created_at: 2023-04-16 17:46:35+00:00
  edited: false
  hidden: false
  id: 643c428be3a7bbe2cf3d439e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665158475637-627b8bc83974b0ed6b28db67.jpeg?w=200&h=200&f=face
      fullname: Giulio Starace
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: thesofakillers
      type: user
    createdAt: '2023-04-16T18:46:35.000Z'
    data:
      status: closed
    id: 643c428be3a7bbe2cf3d439f
    type: status-change
  author: thesofakillers
  created_at: 2023-04-16 17:46:35+00:00
  id: 643c428be3a7bbe2cf3d439f
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup
repo_type: model
status: closed
target_branch: null
title: Config file not found
