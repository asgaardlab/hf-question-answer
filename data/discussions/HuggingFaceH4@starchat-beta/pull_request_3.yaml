!!python/object:huggingface_hub.community.DiscussionWithDetails
author: grafail
conflicting_files: []
created_at: 2023-06-11 10:13:13+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/409fe0d0477258cc5c16a503e2d26f1a.svg
      fullname: Rafail Giavrimis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: grafail
      type: user
    createdAt: '2023-06-11T11:13:13.000Z'
    data:
      edited: false
      editors:
      - grafail
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8722018003463745
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/409fe0d0477258cc5c16a503e2d26f1a.svg
          fullname: Rafail Giavrimis
          isHf: false
          isPro: false
          name: grafail
          type: user
        html: '<p>Wrong token causes issues with <a rel="nofollow" href="https://github.com/huggingface/text-generation-inference">https://github.com/huggingface/text-generation-inference</a>,
          as it cannot be easily overridden.</p>

          '
        raw: Wrong token causes issues with https://github.com/huggingface/text-generation-inference,
          as it cannot be easily overridden.
        updatedAt: '2023-06-11T11:13:13.312Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - qftie
    id: 6485ac49a3893fa104f36249
    type: comment
  author: grafail
  content: Wrong token causes issues with https://github.com/huggingface/text-generation-inference,
    as it cannot be easily overridden.
  created_at: 2023-06-11 10:13:13+00:00
  edited: false
  hidden: false
  id: 6485ac49a3893fa104f36249
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: /avatars/409fe0d0477258cc5c16a503e2d26f1a.svg
      fullname: Rafail Giavrimis
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: grafail
      type: user
    createdAt: '2023-06-11T11:13:14.000Z'
    data:
      oid: 14af36ced19ce85dd97ff69427911c9ea4cf07d5
      parents:
      - b1bcda690655777373f57ea6614eb095ec2c886f
      subject: Updated eos_token to <|end|>
    id: 6485ac4a0000000000000000
    type: commit
  author: grafail
  created_at: 2023-06-11 10:13:14+00:00
  id: 6485ac4a0000000000000000
  oid: 14af36ced19ce85dd97ff69427911c9ea4cf07d5
  summary: Updated eos_token to <|end|>
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594651707950-noauth.jpeg?w=200&h=200&f=face
      fullname: Lewis Tunstall
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: lewtun
      type: user
    createdAt: '2023-06-15T08:21:29.000Z'
    data:
      edited: false
      editors:
      - lewtun
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8583530783653259
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1594651707950-noauth.jpeg?w=200&h=200&f=face
          fullname: Lewis Tunstall
          isHf: true
          isPro: false
          name: lewtun
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;grafail&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/grafail\">@<span class=\"\
          underline\">grafail</span></a></span>\n\n\t</span></span> you can set <code>stop_sequences=[\"\
          &lt;|end|&gt;\"]</code> in the <code>text-generation-python</code> client,\
          \ or <code>stop=[\"&lt;|end|&gt;\"]</code> if you're using the endpoint\
          \ directly. I don't want to tamper with the EOS token since it can causes\
          \ issues in other downstream applications</p>\n"
        raw: Hi @grafail you can set `stop_sequences=["<|end|>"]` in the `text-generation-python`
          client, or `stop=["<|end|>"]` if you're using the endpoint directly. I don't
          want to tamper with the EOS token since it can causes issues in other downstream
          applications
        updatedAt: '2023-06-15T08:21:29.429Z'
      numEdits: 0
      reactions: []
    id: 648aca09bd54eaf716705b78
    type: comment
  author: lewtun
  content: Hi @grafail you can set `stop_sequences=["<|end|>"]` in the `text-generation-python`
    client, or `stop=["<|end|>"]` if you're using the endpoint directly. I don't want
    to tamper with the EOS token since it can causes issues in other downstream applications
  created_at: 2023-06-15 07:21:29+00:00
  edited: false
  hidden: false
  id: 648aca09bd54eaf716705b78
  type: comment
is_pull_request: true
merge_commit_oid: null
num: 3
repo_id: HuggingFaceH4/starchat-beta
repo_type: model
status: open
target_branch: refs/heads/main
title: Updated eos_token to <|end|>
