!!python/object:huggingface_hub.community.DiscussionWithDetails
author: amarrrv
conflicting_files: null
created_at: 2023-06-15 11:16:45+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4fd889619dbfed90f6f36e7204b0679d.svg
      fullname: Amar
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: amarrrv
      type: user
    createdAt: '2023-06-15T12:16:45.000Z'
    data:
      edited: false
      editors:
      - amarrrv
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5423450469970703
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4fd889619dbfed90f6f36e7204b0679d.svg
          fullname: Amar
          isHf: false
          isPro: false
          name: amarrrv
          type: user
        html: '<pre><code>import torch

          from transformers import pipeline


          pipe = pipeline("text-generation", model="HuggingFaceH4/starchat-beta",
          torch_dtype=torch.bfloat16, device_map="auto")


          # We use a variant of ChatML to format each message

          prompt_template = "&lt;|system|&gt;\n&lt;|end|&gt;\n&lt;|user|&gt;\n{query}&lt;|end|&gt;\n&lt;|assistant|&gt;"

          prompt = prompt_template.format(query="How do I sort a list in Python?")


          # We use a special &lt;|end|&gt; token with ID 49155 to denote ends of a
          turn

          outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.2,
          top_k=50, top_p=0.95, eos_token_id=49155)

          </code></pre>

          <p>I am trying to run the above code on Google Colab. I get the following
          error<br><code>RuntimeError: You must initialize the accelerate state by
          calling either `PartialState()` or `Accelerator()` before using the logging
          utility.</code></p>

          <p>The error is generated for the last line<br> <code>outputs = pipe(prompt,
          max_new_tokens=256, do_sample=True, temperature=0.2, top_k=50, top_p=0.95,
          eos_token_id=49155)</code></p>

          <p>Any suggestions on how I can debug and resolve this ?</p>

          '
        raw: "```\r\nimport torch\r\nfrom transformers import pipeline\r\n\r\npipe\
          \ = pipeline(\"text-generation\", model=\"HuggingFaceH4/starchat-beta\"\
          , torch_dtype=torch.bfloat16, device_map=\"auto\")\r\n\r\n# We use a variant\
          \ of ChatML to format each message\r\nprompt_template = \"<|system|>\\n<|end|>\\\
          n<|user|>\\n{query}<|end|>\\n<|assistant|>\"\r\nprompt = prompt_template.format(query=\"\
          How do I sort a list in Python?\")\r\n\r\n# We use a special <|end|> token\
          \ with ID 49155 to denote ends of a turn\r\noutputs = pipe(prompt, max_new_tokens=256,\
          \ do_sample=True, temperature=0.2, top_k=50, top_p=0.95, eos_token_id=49155)\r\
          \n```\r\n\r\nI am trying to run the above code on Google Colab. I get the\
          \ following error\r\n```RuntimeError: You must initialize the accelerate\
          \ state by calling either `PartialState()` or `Accelerator()` before using\
          \ the logging utility.```\r\n\r\nThe error is generated for the last line\r\
          \n ```outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.2,\
          \ top_k=50, top_p=0.95, eos_token_id=49155)```\r\n\r\nAny suggestions on\
          \ how I can debug and resolve this ?"
        updatedAt: '2023-06-15T12:16:45.271Z'
      numEdits: 0
      reactions: []
    id: 648b012d69f9c1227865edf9
    type: comment
  author: amarrrv
  content: "```\r\nimport torch\r\nfrom transformers import pipeline\r\n\r\npipe =\
    \ pipeline(\"text-generation\", model=\"HuggingFaceH4/starchat-beta\", torch_dtype=torch.bfloat16,\
    \ device_map=\"auto\")\r\n\r\n# We use a variant of ChatML to format each message\r\
    \nprompt_template = \"<|system|>\\n<|end|>\\n<|user|>\\n{query}<|end|>\\n<|assistant|>\"\
    \r\nprompt = prompt_template.format(query=\"How do I sort a list in Python?\"\
    )\r\n\r\n# We use a special <|end|> token with ID 49155 to denote ends of a turn\r\
    \noutputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.2,\
    \ top_k=50, top_p=0.95, eos_token_id=49155)\r\n```\r\n\r\nI am trying to run the\
    \ above code on Google Colab. I get the following error\r\n```RuntimeError: You\
    \ must initialize the accelerate state by calling either `PartialState()` or `Accelerator()`\
    \ before using the logging utility.```\r\n\r\nThe error is generated for the last\
    \ line\r\n ```outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.2,\
    \ top_k=50, top_p=0.95, eos_token_id=49155)```\r\n\r\nAny suggestions on how I\
    \ can debug and resolve this ?"
  created_at: 2023-06-15 11:16:45+00:00
  edited: false
  hidden: false
  id: 648b012d69f9c1227865edf9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 7
repo_id: HuggingFaceH4/starchat-beta
repo_type: model
status: open
target_branch: null
title: 'RuntimeError: You must initialize the accelerate state by calling either `PartialState()`
  or `Accelerator()` before using the logging utility.'
