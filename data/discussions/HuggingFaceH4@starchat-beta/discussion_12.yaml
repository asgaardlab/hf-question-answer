!!python/object:huggingface_hub.community.DiscussionWithDetails
author: huytungst
conflicting_files: null
created_at: 2023-06-30 09:19:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d64dee2ddaeed2babe88a6003382d068.svg
      fullname: Huy Tung
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: huytungst
      type: user
    createdAt: '2023-06-30T10:19:48.000Z'
    data:
      edited: true
      editors:
      - huytungst
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9191136360168457
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d64dee2ddaeed2babe88a6003382d068.svg
          fullname: Huy Tung
          isHf: false
          isPro: false
          name: huytungst
          type: user
        html: '<p>I have recently tried to fine-tune the model (using the QLoRA method).
          While the fine-tuning process concluded without issue, the resulting output
          responses did not meet the anticipated standards since the generated contents
          were quite oddly. I suspect the root of this issue may stem from the training
          dataset, which may not have been adequately prepared to facilitate effective
          learning for the model. The model I have previously finetuned was trained
          usin gonly ''text'' column from <a href="https://huggingface.co/datasets/heegyu/namuwiki-extracted">https://huggingface.co/datasets/heegyu/namuwiki-extracted</a>,
          lacking any question-answering format. So, to enhance the finetuned model''s
          performance, I am wondering whether the following format should be like
          this:</p>

          <p>&lt;|system|&gt;\n{system prompt sample}&lt;|end|&gt;\n&lt;|user|&gt;\n{user
          prompt sample}&lt;|end|&gt;\n&lt;|assistant|&gt;\n{assistant prompt sample}&lt;|end|&gt;\n</p>

          <p>As each training session for my model incurs considerable costs due to
          the GPU rental fees, I am hesitant to proceed with further training without
          advice. Therefore, I''m reaching out for opinions from professionals before
          training again. I greatly appreciate any guidance or recommendations that
          can help me optimize my process, my data and potentially save on these significant
          costs.</p>

          '
        raw: 'I have recently tried to fine-tune the model (using the QLoRA method).
          While the fine-tuning process concluded without issue, the resulting output
          responses did not meet the anticipated standards since the generated contents
          were quite oddly. I suspect the root of this issue may stem from the training
          dataset, which may not have been adequately prepared to facilitate effective
          learning for the model. The model I have previously finetuned was trained
          usin gonly ''text'' column from <https://huggingface.co/datasets/heegyu/namuwiki-extracted>,
          lacking any question-answering format. So, to enhance the finetuned model''s
          performance, I am wondering whether the following format should be like
          this:


          <|system|>\n{system prompt sample}<|end|>\n<|user|>\n{user prompt sample}<|end|>\n<|assistant|>\n{assistant
          prompt sample}<|end|>\n


          As each training session for my model incurs considerable costs due to the
          GPU rental fees, I am hesitant to proceed with further training without
          advice. Therefore, I''m reaching out for opinions from professionals before
          training again. I greatly appreciate any guidance or recommendations that
          can help me optimize my process, my data and potentially save on these significant
          costs.'
        updatedAt: '2023-06-30T14:46:11.583Z'
      numEdits: 1
      reactions: []
    id: 649eac44d61f393407be3a65
    type: comment
  author: huytungst
  content: 'I have recently tried to fine-tune the model (using the QLoRA method).
    While the fine-tuning process concluded without issue, the resulting output responses
    did not meet the anticipated standards since the generated contents were quite
    oddly. I suspect the root of this issue may stem from the training dataset, which
    may not have been adequately prepared to facilitate effective learning for the
    model. The model I have previously finetuned was trained usin gonly ''text'' column
    from <https://huggingface.co/datasets/heegyu/namuwiki-extracted>, lacking any
    question-answering format. So, to enhance the finetuned model''s performance,
    I am wondering whether the following format should be like this:


    <|system|>\n{system prompt sample}<|end|>\n<|user|>\n{user prompt sample}<|end|>\n<|assistant|>\n{assistant
    prompt sample}<|end|>\n


    As each training session for my model incurs considerable costs due to the GPU
    rental fees, I am hesitant to proceed with further training without advice. Therefore,
    I''m reaching out for opinions from professionals before training again. I greatly
    appreciate any guidance or recommendations that can help me optimize my process,
    my data and potentially save on these significant costs.'
  created_at: 2023-06-30 09:19:48+00:00
  edited: true
  hidden: false
  id: 649eac44d61f393407be3a65
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/41c81bd99888569d44c23a2cfb2b57a0.svg
      fullname: shawn
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: sunzx0810
      type: user
    createdAt: '2023-07-11T08:31:10.000Z'
    data:
      edited: false
      editors:
      - sunzx0810
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9525564312934875
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/41c81bd99888569d44c23a2cfb2b57a0.svg
          fullname: shawn
          isHf: false
          isPro: false
          name: sunzx0810
          type: user
        html: '<p>hi , does this way of training helps you improve the results?</p>

          '
        raw: hi , does this way of training helps you improve the results?
        updatedAt: '2023-07-11T08:31:10.860Z'
      numEdits: 0
      reactions: []
    id: 64ad134eb7d86b40fd78b1bf
    type: comment
  author: sunzx0810
  content: hi , does this way of training helps you improve the results?
  created_at: 2023-07-11 07:31:10+00:00
  edited: false
  hidden: false
  id: 64ad134eb7d86b40fd78b1bf
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-c3vKdHNHtIgRjphBRVSz.jpeg?w=200&h=200&f=face
      fullname: Lukas Tobias Schmidt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LukasSchmidt
      type: user
    createdAt: '2023-07-11T14:15:39.000Z'
    data:
      edited: false
      editors:
      - LukasSchmidt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.965239405632019
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-c3vKdHNHtIgRjphBRVSz.jpeg?w=200&h=200&f=face
          fullname: Lukas Tobias Schmidt
          isHf: false
          isPro: false
          name: LukasSchmidt
          type: user
        html: '<p>Could you maybe give some details regarding your fine tuning script?</p>

          '
        raw: Could you maybe give some details regarding your fine tuning script?
        updatedAt: '2023-07-11T14:15:39.280Z'
      numEdits: 0
      reactions: []
    id: 64ad640bb7e557b2b976f5f1
    type: comment
  author: LukasSchmidt
  content: Could you maybe give some details regarding your fine tuning script?
  created_at: 2023-07-11 13:15:39+00:00
  edited: false
  hidden: false
  id: 64ad640bb7e557b2b976f5f1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d64dee2ddaeed2babe88a6003382d068.svg
      fullname: Huy Tung
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: huytungst
      type: user
    createdAt: '2023-07-12T08:41:49.000Z'
    data:
      edited: false
      editors:
      - huytungst
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8919597268104553
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d64dee2ddaeed2babe88a6003382d068.svg
          fullname: Huy Tung
          isHf: false
          isPro: false
          name: huytungst
          type: user
        html: "<p>@sunsx0810  <span data-props=\"{&quot;user&quot;:&quot;LukasSchmidt&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/LukasSchmidt\"\
          >@<span class=\"underline\">LukasSchmidt</span></a></span>\n\n\t</span></span>\
          \  </p>\n<p>Here is my script based on QLoRA method. However, the model\u2019\
          s responses became more obscure after fine-tuning. I hope it helps.<br><a\
          \ rel=\"nofollow\" href=\"https://colab.research.google.com/drive/1gz6w2W8OLXpZeAew36RUFr2cmn3Z12vT?usp=sharing\"\
          >https://colab.research.google.com/drive/1gz6w2W8OLXpZeAew36RUFr2cmn3Z12vT?usp=sharing</a></p>\n\
          <p>Does anyone have a suggestion for an effective way to pre-process the\
          \ fine-tuning data to enhance the model\u2019s performance in new foreign\
          \ languages?</p>\n"
        raw: "@sunsx0810  @LukasSchmidt  \n\nHere is my script based on QLoRA method.\
          \ However, the model\u2019s responses became more obscure after fine-tuning.\
          \ I hope it helps.\nhttps://colab.research.google.com/drive/1gz6w2W8OLXpZeAew36RUFr2cmn3Z12vT?usp=sharing\n\
          \nDoes anyone have a suggestion for an effective way to pre-process the\
          \ fine-tuning data to enhance the model\u2019s performance in new foreign\
          \ languages?"
        updatedAt: '2023-07-12T08:41:49.322Z'
      numEdits: 0
      reactions: []
    id: 64ae674db7e557b2b996887b
    type: comment
  author: huytungst
  content: "@sunsx0810  @LukasSchmidt  \n\nHere is my script based on QLoRA method.\
    \ However, the model\u2019s responses became more obscure after fine-tuning. I\
    \ hope it helps.\nhttps://colab.research.google.com/drive/1gz6w2W8OLXpZeAew36RUFr2cmn3Z12vT?usp=sharing\n\
    \nDoes anyone have a suggestion for an effective way to pre-process the fine-tuning\
    \ data to enhance the model\u2019s performance in new foreign languages?"
  created_at: 2023-07-12 07:41:49+00:00
  edited: false
  hidden: false
  id: 64ae674db7e557b2b996887b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-c3vKdHNHtIgRjphBRVSz.jpeg?w=200&h=200&f=face
      fullname: Lukas Tobias Schmidt
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LukasSchmidt
      type: user
    createdAt: '2023-07-12T10:40:34.000Z'
    data:
      edited: false
      editors:
      - LukasSchmidt
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9821637272834778
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/-c3vKdHNHtIgRjphBRVSz.jpeg?w=200&h=200&f=face
          fullname: Lukas Tobias Schmidt
          isHf: false
          isPro: false
          name: LukasSchmidt
          type: user
        html: '<p>The access is currently restricted, so we can''t access it</p>

          '
        raw: The access is currently restricted, so we can't access it
        updatedAt: '2023-07-12T10:40:34.527Z'
      numEdits: 0
      reactions: []
    id: 64ae83223c84ffe29e0d6751
    type: comment
  author: LukasSchmidt
  content: The access is currently restricted, so we can't access it
  created_at: 2023-07-12 09:40:34+00:00
  edited: false
  hidden: false
  id: 64ae83223c84ffe29e0d6751
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6313f6772c7ffdd9f50406b7/EH00VFEJBQ3suoWPG8eKA.jpeg?w=200&h=200&f=face
      fullname: Finn Frotscher
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: LazerJesus
      type: user
    createdAt: '2023-07-22T19:05:28.000Z'
    data:
      edited: false
      editors:
      - LazerJesus
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6421144008636475
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6313f6772c7ffdd9f50406b7/EH00VFEJBQ3suoWPG8eKA.jpeg?w=200&h=200&f=face
          fullname: Finn Frotscher
          isHf: false
          isPro: false
          name: LazerJesus
          type: user
        html: '<p>could this be because you are missing the special tokens <code>{"additional_special_tokens":
          ["&lt;|system|&gt;", "&lt;|assistant|&gt;", "&lt;|user|&gt;", "&lt;|end|&gt;"]}</code>?
          </p>

          '
        raw: "could this be because you are missing the special tokens `{\"additional_special_tokens\"\
          : [\"<|system|>\", \"<|assistant|>\", \"<|user|>\", \"<|end|>\"]}`? \n\n"
        updatedAt: '2023-07-22T19:05:28.125Z'
      numEdits: 0
      reactions: []
    id: 64bc28789a69e8da48af3630
    type: comment
  author: LazerJesus
  content: "could this be because you are missing the special tokens `{\"additional_special_tokens\"\
    : [\"<|system|>\", \"<|assistant|>\", \"<|user|>\", \"<|end|>\"]}`? \n\n"
  created_at: 2023-07-22 18:05:28+00:00
  edited: false
  hidden: false
  id: 64bc28789a69e8da48af3630
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/424a229b70d5ac9b3952c72d8eb3216f.svg
      fullname: Ralph Chahwan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Ralphch97
      type: user
    createdAt: '2023-07-26T19:23:42.000Z'
    data:
      edited: true
      editors:
      - Ralphch97
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8928690552711487
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/424a229b70d5ac9b3952c72d8eb3216f.svg
          fullname: Ralph Chahwan
          isHf: false
          isPro: false
          name: Ralphch97
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;huytungst&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/huytungst\">@<span class=\"\
          underline\">huytungst</span></a></span>\n\n\t</span></span>  where you able\
          \ to find any way to solve this issue?<br>I would like to learn how to finetune\
          \ starchat beta on my own coding scenarios</p>\n"
        raw: '@huytungst  where you able to find any way to solve this issue?

          I would like to learn how to finetune starchat beta on my own coding scenarios'
        updatedAt: '2023-07-26T19:25:08.801Z'
      numEdits: 2
      reactions: []
    id: 64c172bec8a50776281e605a
    type: comment
  author: Ralphch97
  content: '@huytungst  where you able to find any way to solve this issue?

    I would like to learn how to finetune starchat beta on my own coding scenarios'
  created_at: 2023-07-26 18:23:42+00:00
  edited: true
  hidden: false
  id: 64c172bec8a50776281e605a
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: HuggingFaceH4/starchat-beta
repo_type: model
status: open
target_branch: null
title: ' Seeking guidance on enhancingoutput of fine-tuned result'
