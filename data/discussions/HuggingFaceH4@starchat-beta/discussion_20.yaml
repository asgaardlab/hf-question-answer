!!python/object:huggingface_hub.community.DiscussionWithDetails
author: mindplay
conflicting_files: null
created_at: 2023-08-04 10:28:20+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ae7bce2d58740d9e5173e9cbdea0c4f.svg
      fullname: Rasmus Schultz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mindplay
      type: user
    createdAt: '2023-08-04T11:28:20.000Z'
    data:
      edited: true
      editors:
      - mindplay
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9739336371421814
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ae7bce2d58740d9e5173e9cbdea0c4f.svg
          fullname: Rasmus Schultz
          isHf: false
          isPro: false
          name: mindplay
          type: user
        html: '<p>Just came here to say, wow, this model is extremely good - I was
          quite surprised at the helpfulness of this rather small model!</p>

          <p>However, I''ve noticed, after a certain number of turns, it seems to
          cut off abruptly - and if you attempt to continue the conversation, it goes
          completely off the rails! It completely switched from helpful and objective
          to being all like "haha! nope!" and using a whole bunch of emoji.</p>

          <p>I tried to delete the end of the conversation and resume, but this appears
          to happen consistently after a certain number of turns/tokens.</p>

          <p>I''m otherwise extremely surprised and impressed with it''s ability to
          explain some rather complex and exotic programming topics I was asking about!</p>

          <p>Really promising stuff. :-)</p>

          '
        raw: 'Just came here to say, wow, this model is extremely good - I was quite
          surprised at the helpfulness of this rather small model!


          However, I''ve noticed, after a certain number of turns, it seems to cut
          off abruptly - and if you attempt to continue the conversation, it goes
          completely off the rails! It completely switched from helpful and objective
          to being all like "haha! nope!" and using a whole bunch of emoji.


          I tried to delete the end of the conversation and resume, but this appears
          to happen consistently after a certain number of turns/tokens.


          I''m otherwise extremely surprised and impressed with it''s ability to explain
          some rather complex and exotic programming topics I was asking about!


          Really promising stuff. :-)'
        updatedAt: '2023-08-04T11:29:31.181Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - djokowsj90
    id: 64cce0d41867f2d1379680da
    type: comment
  author: mindplay
  content: 'Just came here to say, wow, this model is extremely good - I was quite
    surprised at the helpfulness of this rather small model!


    However, I''ve noticed, after a certain number of turns, it seems to cut off abruptly
    - and if you attempt to continue the conversation, it goes completely off the
    rails! It completely switched from helpful and objective to being all like "haha!
    nope!" and using a whole bunch of emoji.


    I tried to delete the end of the conversation and resume, but this appears to
    happen consistently after a certain number of turns/tokens.


    I''m otherwise extremely surprised and impressed with it''s ability to explain
    some rather complex and exotic programming topics I was asking about!


    Really promising stuff. :-)'
  created_at: 2023-08-04 10:28:20+00:00
  edited: true
  hidden: false
  id: 64cce0d41867f2d1379680da
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9dcb60e8d4250bc94b220ebf7a521c3a.svg
      fullname: Jeremy Wang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: djokowsj90
      type: user
    createdAt: '2023-08-06T23:11:21.000Z'
    data:
      edited: false
      editors:
      - djokowsj90
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9825775623321533
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9dcb60e8d4250bc94b220ebf7a521c3a.svg
          fullname: Jeremy Wang
          isHf: false
          isPro: false
          name: djokowsj90
          type: user
        html: '<p>I noticed the same thing.<br>It started to talk Spanish after answering
          my prompt question. </p>

          '
        raw: 'I noticed the same thing.

          It started to talk Spanish after answering my prompt question. '
        updatedAt: '2023-08-06T23:11:21.744Z'
      numEdits: 0
      reactions: []
    id: 64d02899228324a28be04749
    type: comment
  author: djokowsj90
  content: 'I noticed the same thing.

    It started to talk Spanish after answering my prompt question. '
  created_at: 2023-08-06 22:11:21+00:00
  edited: false
  hidden: false
  id: 64d02899228324a28be04749
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/77fd99337f556e226a1e20cdbdb9eb80.svg
      fullname: Rajath Jain
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Rajath-jain
      type: user
    createdAt: '2023-09-29T10:21:44.000Z'
    data:
      edited: false
      editors:
      - Rajath-jain
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9199966788291931
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/77fd99337f556e226a1e20cdbdb9eb80.svg
          fullname: Rajath Jain
          isHf: false
          isPro: false
          name: Rajath-jain
          type: user
        html: '<p>Hi can you please provide a short snippet on how you used starchat
          as a conversation bot? I deployed starcoder in Sagemaker using the deployment
          script from HF. Using that sample code it only does autocomplete, how to
          use it like a chatbot?</p>

          '
        raw: Hi can you please provide a short snippet on how you used starchat as
          a conversation bot? I deployed starcoder in Sagemaker using the deployment
          script from HF. Using that sample code it only does autocomplete, how to
          use it like a chatbot?
        updatedAt: '2023-09-29T10:21:44.372Z'
      numEdits: 0
      reactions: []
    id: 6516a538b26534355c16a58c
    type: comment
  author: Rajath-jain
  content: Hi can you please provide a short snippet on how you used starchat as a
    conversation bot? I deployed starcoder in Sagemaker using the deployment script
    from HF. Using that sample code it only does autocomplete, how to use it like
    a chatbot?
  created_at: 2023-09-29 09:21:44+00:00
  edited: false
  hidden: false
  id: 6516a538b26534355c16a58c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8ae7bce2d58740d9e5173e9cbdea0c4f.svg
      fullname: Rasmus Schultz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: mindplay
      type: user
    createdAt: '2023-09-29T14:41:01.000Z'
    data:
      edited: false
      editors:
      - mindplay
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.899519681930542
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8ae7bce2d58740d9e5173e9cbdea0c4f.svg
          fullname: Rasmus Schultz
          isHf: false
          isPro: false
          name: mindplay
          type: user
        html: "<p>There's a chat/demo here:</p>\n<p><a href=\"https://huggingface.co/spaces/HuggingFaceH4/starchat-playground\"\
          >https://huggingface.co/spaces/HuggingFaceH4/starchat-playground</a></p>\n\
          <p>By the way, I understand now why the conversation derails - from my limited\
          \ understanding, this happens with all models when you exceed the maximum\
          \ length of the content it was trained on. Some interfaces (such as ChatGPT)\
          \ work around this problem internally, either by truncating or summarizing\
          \ the conversation behind the scenes, when the conversation length starts\
          \ to approach the limit.</p>\n<p>I wonder when we'll start to see implementation\
          \ of this:</p>\n<p><a rel=\"nofollow\" href=\"https://github.com/ggerganov/llama.cpp/discussions/2936\"\
          >https://github.com/ggerganov/llama.cpp/discussions/2936</a></p>\n<p>It\
          \ looks relatively simple, and supposedly solves the conversation length\
          \ issue by enabling the model to selectively forget things that fall out\
          \ of conversation scope. It also apparently speeds up the model by 2-4x!</p>\n\
          <p>David Shapiro talks about it in this video:</p>\n<p><a rel=\"nofollow\"\
          \ href=\"https://www.youtube.com/watch?v=5XaJQKgL9Hs&amp;t=8s&amp;pp=ygULbG0taW5maW5pdGU%3D\"\
          >https://www.youtube.com/watch?v=5XaJQKgL9Hs&amp;t=8s&amp;pp=ygULbG0taW5maW5pdGU%3D</a></p>\n\
          <p>I'm not sure why we're not seeing implementations of this everywhere\
          \ yet - it sounds like a slam dunk. \U0001F642</p>\n"
        raw: "There's a chat/demo here:\n\nhttps://huggingface.co/spaces/HuggingFaceH4/starchat-playground\n\
          \nBy the way, I understand now why the conversation derails - from my limited\
          \ understanding, this happens with all models when you exceed the maximum\
          \ length of the content it was trained on. Some interfaces (such as ChatGPT)\
          \ work around this problem internally, either by truncating or summarizing\
          \ the conversation behind the scenes, when the conversation length starts\
          \ to approach the limit.\n\nI wonder when we'll start to see implementation\
          \ of this:\n\nhttps://github.com/ggerganov/llama.cpp/discussions/2936\n\n\
          It looks relatively simple, and supposedly solves the conversation length\
          \ issue by enabling the model to selectively forget things that fall out\
          \ of conversation scope. It also apparently speeds up the model by 2-4x!\n\
          \nDavid Shapiro talks about it in this video:\n\nhttps://www.youtube.com/watch?v=5XaJQKgL9Hs&t=8s&pp=ygULbG0taW5maW5pdGU%3D\n\
          \nI'm not sure why we're not seeing implementations of this everywhere yet\
          \ - it sounds like a slam dunk. \U0001F642\n"
        updatedAt: '2023-09-29T14:41:01.187Z'
      numEdits: 0
      reactions: []
    id: 6516e1fd0e3a5553d4590691
    type: comment
  author: mindplay
  content: "There's a chat/demo here:\n\nhttps://huggingface.co/spaces/HuggingFaceH4/starchat-playground\n\
    \nBy the way, I understand now why the conversation derails - from my limited\
    \ understanding, this happens with all models when you exceed the maximum length\
    \ of the content it was trained on. Some interfaces (such as ChatGPT) work around\
    \ this problem internally, either by truncating or summarizing the conversation\
    \ behind the scenes, when the conversation length starts to approach the limit.\n\
    \nI wonder when we'll start to see implementation of this:\n\nhttps://github.com/ggerganov/llama.cpp/discussions/2936\n\
    \nIt looks relatively simple, and supposedly solves the conversation length issue\
    \ by enabling the model to selectively forget things that fall out of conversation\
    \ scope. It also apparently speeds up the model by 2-4x!\n\nDavid Shapiro talks\
    \ about it in this video:\n\nhttps://www.youtube.com/watch?v=5XaJQKgL9Hs&t=8s&pp=ygULbG0taW5maW5pdGU%3D\n\
    \nI'm not sure why we're not seeing implementations of this everywhere yet - it\
    \ sounds like a slam dunk. \U0001F642\n"
  created_at: 2023-09-29 13:41:01+00:00
  edited: false
  hidden: false
  id: 6516e1fd0e3a5553d4590691
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 20
repo_id: HuggingFaceH4/starchat-beta
repo_type: model
status: open
target_branch: null
title: Conversation derails after a certain number of tokens (?)
