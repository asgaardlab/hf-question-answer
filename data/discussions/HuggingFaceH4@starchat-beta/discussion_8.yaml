!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aidan377
conflicting_files: null
created_at: 2023-06-19 06:59:35+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af01d7327f6fc70dd2f5d0a9f618f687.svg
      fullname: Aidan Lew
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aidan377
      type: user
    createdAt: '2023-06-19T07:59:35.000Z'
    data:
      edited: false
      editors:
      - aidan377
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5143202543258667
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af01d7327f6fc70dd2f5d0a9f618f687.svg
          fullname: Aidan Lew
          isHf: false
          isPro: false
          name: aidan377
          type: user
        html: "<p>When I use the inference api,it return very short answer,can you\
          \ help to figure out the reason?Do I use wrong code?<br>The code to request:</p>\n\
          <pre><code class=\"language-python\">prompt_template = <span class=\"hljs-string\"\
          >\"&lt;|system|&gt;\\n&lt;|end|&gt;\\n&lt;|user|&gt;\\n{query}&lt;|end|&gt;\\\
          n&lt;|assistant|&gt;\"</span>\nprompt = prompt_template.<span class=\"hljs-built_in\"\
          >format</span>(query=<span class=\"hljs-string\">\"How do I sort a list\
          \ in Python?\"</span>)\n<span class=\"hljs-comment\"># print(prompt)</span>\n\
          \noutput = query({\n    <span class=\"hljs-string\">\"inputs\"</span>: prompt,\n\
          \    <span class=\"hljs-string\">\"parameters\"</span>:{\n        <span\
          \ class=\"hljs-string\">\"max_new_token\"</span>:<span class=\"hljs-number\"\
          >256</span>,\n        <span class=\"hljs-string\">\"temperature\"</span>:<span\
          \ class=\"hljs-number\">0.2</span>,\n        <span class=\"hljs-string\"\
          >\"do_sample\"</span>:<span class=\"hljs-literal\">True</span>,\n      \
          \  <span class=\"hljs-string\">\"top_k\"</span>:<span class=\"hljs-number\"\
          >50</span>,\n        <span class=\"hljs-string\">\"top_p\"</span>:<span\
          \ class=\"hljs-number\">0.95</span>,\n        <span class=\"hljs-string\"\
          >\"eos_token_id\"</span>:<span class=\"hljs-number\">49155</span>,\n   \
          \     <span class=\"hljs-string\">\"return_full_text\"</span>:<span class=\"\
          hljs-literal\">False</span>\n    }\n})\n</code></pre>\n<p>The response:</p>\n\
          <pre><code class=\"language-json\"><span class=\"hljs-punctuation\">[</span><span\
          \ class=\"hljs-punctuation\">{</span>'generated_text'<span class=\"hljs-punctuation\"\
          >:</span> '\\nThere are multiple ways to sort a list in Python. One of the\
          \ most common ways is to'<span class=\"hljs-punctuation\">}</span><span\
          \ class=\"hljs-punctuation\">]</span>\n</code></pre>\n"
        raw: "When I use the inference api,it return very short answer,can you help\
          \ to figure out the reason?Do I use wrong code?\r\nThe code to request:\r\
          \n```python\r\nprompt_template = \"<|system|>\\n<|end|>\\n<|user|>\\n{query}<|end|>\\\
          n<|assistant|>\"\r\nprompt = prompt_template.format(query=\"How do I sort\
          \ a list in Python?\")\r\n# print(prompt)\r\n\r\noutput = query({\r\n  \
          \  \"inputs\": prompt,\r\n    \"parameters\":{\r\n        \"max_new_token\"\
          :256,\r\n        \"temperature\":0.2,\r\n        \"do_sample\":True,\r\n\
          \        \"top_k\":50,\r\n        \"top_p\":0.95,\r\n        \"eos_token_id\"\
          :49155,\r\n        \"return_full_text\":False\r\n    }\r\n})\r\n```\r\n\r\
          \nThe response:\r\n```json\r\n[{'generated_text': '\\nThere are multiple\
          \ ways to sort a list in Python. One of the most common ways is to'}]\r\n\
          ```"
        updatedAt: '2023-06-19T07:59:35.020Z'
      numEdits: 0
      reactions: []
    id: 64900ae79e303415c30ea1e4
    type: comment
  author: aidan377
  content: "When I use the inference api,it return very short answer,can you help\
    \ to figure out the reason?Do I use wrong code?\r\nThe code to request:\r\n```python\r\
    \nprompt_template = \"<|system|>\\n<|end|>\\n<|user|>\\n{query}<|end|>\\n<|assistant|>\"\
    \r\nprompt = prompt_template.format(query=\"How do I sort a list in Python?\"\
    )\r\n# print(prompt)\r\n\r\noutput = query({\r\n    \"inputs\": prompt,\r\n  \
    \  \"parameters\":{\r\n        \"max_new_token\":256,\r\n        \"temperature\"\
    :0.2,\r\n        \"do_sample\":True,\r\n        \"top_k\":50,\r\n        \"top_p\"\
    :0.95,\r\n        \"eos_token_id\":49155,\r\n        \"return_full_text\":False\r\
    \n    }\r\n})\r\n```\r\n\r\nThe response:\r\n```json\r\n[{'generated_text': '\\\
    nThere are multiple ways to sort a list in Python. One of the most common ways\
    \ is to'}]\r\n```"
  created_at: 2023-06-19 06:59:35+00:00
  edited: false
  hidden: false
  id: 64900ae79e303415c30ea1e4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/13655e34194af3cbafe8064302c44a15.svg
      fullname: lynn geo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: heifongni
      type: user
    createdAt: '2023-06-21T06:42:17.000Z'
    data:
      edited: false
      editors:
      - heifongni
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5518015027046204
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/13655e34194af3cbafe8064302c44a15.svg
          fullname: lynn geo
          isHf: false
          isPro: false
          name: heifongni
          type: user
        html: '<p>try to use   "return_full_text":True</p>

          '
        raw: 'try to use   "return_full_text":True

          '
        updatedAt: '2023-06-21T06:42:17.155Z'
      numEdits: 0
      reactions: []
    id: 64929bc94ac59a8c2b2a27b6
    type: comment
  author: heifongni
  content: 'try to use   "return_full_text":True

    '
  created_at: 2023-06-21 05:42:17+00:00
  edited: false
  hidden: false
  id: 64929bc94ac59a8c2b2a27b6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/af01d7327f6fc70dd2f5d0a9f618f687.svg
      fullname: Aidan Lew
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aidan377
      type: user
    createdAt: '2023-08-13T03:12:21.000Z'
    data:
      edited: false
      editors:
      - aidan377
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7804388403892517
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/af01d7327f6fc70dd2f5d0a9f618f687.svg
          fullname: Aidan Lew
          isHf: false
          isPro: false
          name: aidan377
          type: user
        html: "<blockquote>\n<p>try to use   \"return_full_text\":True</p>\n</blockquote>\n\
          <p>I have tried\uFF0Cthe same results.Is there any limitation of api usage?</p>\n"
        raw: "> try to use   \"return_full_text\":True\n\nI have tried\uFF0Cthe same\
          \ results.Is there any limitation of api usage?"
        updatedAt: '2023-08-13T03:12:21.685Z'
      numEdits: 0
      reactions: []
    id: 64d84a158711e883ca8ceac9
    type: comment
  author: aidan377
  content: "> try to use   \"return_full_text\":True\n\nI have tried\uFF0Cthe same\
    \ results.Is there any limitation of api usage?"
  created_at: 2023-08-13 02:12:21+00:00
  edited: false
  hidden: false
  id: 64d84a158711e883ca8ceac9
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 8
repo_id: HuggingFaceH4/starchat-beta
repo_type: model
status: open
target_branch: null
title: The inference api returns inComplete response
