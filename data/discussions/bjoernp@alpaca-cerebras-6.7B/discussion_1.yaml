!!python/object:huggingface_hub.community.DiscussionWithDetails
author: smjain
conflicting_files: null
created_at: 2023-04-01 14:21:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/94eb2907bf28e2c2dd45f96d1f1124a4.svg
      fullname: SHashank
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: smjain
      type: user
    createdAt: '2023-04-01T15:21:05.000Z'
    data:
      edited: false
      editors:
      - smjain
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/94eb2907bf28e2c2dd45f96d1f1124a4.svg
          fullname: SHashank
          isHf: false
          isPro: false
          name: smjain
          type: user
        html: "<p>in &lt;cell line: 1&gt;:1                                      \
          \                                        \u2502<br>\u2502              \
          \                                                                      \
          \              \u2502<br>\u2502 /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:161\
          \ in from_pretrained                 \u2502<br>\u2502                  \
          \                                                                      \
          \          \u2502<br>\u2502   158 \u2502   \u2502   \u2502   filename, map_location=torch.device(\"\
          cuda\" if torch.cuda.is_available() else   \u2502<br>\u2502   159 \u2502\
          \   \u2502   )                                                         \
          \                         \u2502<br>\u2502   160 \u2502   \u2502   # load\
          \ the weights into the model                                           \
          \       \u2502<br>\u2502 \u2771 161 \u2502   \u2502   model = set_peft_model_state_dict(model,\
          \ adapters_weights)                         \u2502<br>\u2502   162 \u2502\
          \   \u2502   if getattr(model, \"hf_device_map\", None) is not None:   \
          \                           \u2502<br>\u2502   163 \u2502   \u2502   \u2502\
          \   device_map = kwargs.get(\"device_map\", \"auto\")                  \
          \                \u2502<br>\u2502   164 \u2502   \u2502   \u2502   max_memory\
          \ = kwargs.get(\"max_memory\", None)                                   \
          \ \u2502<br>\u2502                                                     \
          \                                             \u2502<br>\u2502 /usr/local/lib/python3.9/dist-packages/peft/utils/save_and_load.py:74\
          \ in                         \u2502<br>\u2502 set_peft_model_state_dict\
          \                                                                      \
          \  \u2502<br>\u2502                                                    \
          \                                              \u2502<br>\u2502   71 \u2502\
          \   \u2502   peft_model_state_dict (<code>dict</code>): The state dict of\
          \ the Peft model.                   \u2502<br>\u2502   72 \u2502   \"\"\"\
          \                                                                      \
          \               \u2502<br>\u2502   73 \u2502                           \
          \                                                                \u2502\
          <br>\u2502 \u2771 74 \u2502   model.load_state_dict(peft_model_state_dict,\
          \ strict=False)                              \u2502<br>\u2502   75 \u2502\
          \   if model.peft_config.peft_type != PeftType.LORA:                   \
          \                     \u2502<br>\u2502   76 \u2502   \u2502   model.prompt_encoder.embedding.load_state_dict(\
          \                                     \u2502<br>\u2502   77 \u2502   \u2502\
          \   \u2502   {\"weight\": peft_model_state_dict[\"prompt_embeddings\"]},\
          \ strict=True             \u2502<br>\u2502                             \
          \                                                                     \u2502\
          <br>\u2502 /usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1671\
          \ in load_state_dict        \u2502<br>\u2502                           \
          \                                                                      \
          \ \u2502<br>\u2502   1668 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502\
          \   ', '.join('\"{}\"'.format(k) for k in missing_keys)))              \
          \ \u2502<br>\u2502   1669 \u2502   \u2502                              \
          \                                                       \u2502<br>\u2502\
          \   1670 \u2502   \u2502   if len(error_msgs) &gt; 0:                  \
          \                                         \u2502<br>\u2502 \u2771 1671 \u2502\
          \   \u2502   \u2502   raise RuntimeError('Error(s) in loading state_dict\
          \ for {}:\\n\\t{}'.format(     \u2502<br>\u2502   1672 \u2502   \u2502 \
          \  \u2502   \u2502   \u2502   \u2502   \u2502      self.<strong>class</strong>.<strong>name</strong>,\
          \ \"\\n\\t\".join(error_msgs)))         \u2502<br>\u2502   1673 \u2502 \
          \  \u2502   return _IncompatibleKeys(missing_keys, unexpected_keys)    \
          \  </p>\n"
        raw: "in <cell line: 1>:1                                                \
          \                              \u2502\r\n\u2502                        \
          \                                                                      \
          \    \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:161\
          \ in from_pretrained                 \u2502\r\n\u2502                  \
          \                                                                      \
          \          \u2502\r\n\u2502   158 \u2502   \u2502   \u2502   filename, map_location=torch.device(\"\
          cuda\" if torch.cuda.is_available() else   \u2502\r\n\u2502   159 \u2502\
          \   \u2502   )                                                         \
          \                         \u2502\r\n\u2502   160 \u2502   \u2502   # load\
          \ the weights into the model                                           \
          \       \u2502\r\n\u2502 \u2771 161 \u2502   \u2502   model = set_peft_model_state_dict(model,\
          \ adapters_weights)                         \u2502\r\n\u2502   162 \u2502\
          \   \u2502   if getattr(model, \"hf_device_map\", None) is not None:   \
          \                           \u2502\r\n\u2502   163 \u2502   \u2502   \u2502\
          \   device_map = kwargs.get(\"device_map\", \"auto\")                  \
          \                \u2502\r\n\u2502   164 \u2502   \u2502   \u2502   max_memory\
          \ = kwargs.get(\"max_memory\", None)                                   \
          \ \u2502\r\n\u2502                                                     \
          \                                             \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/utils/save_and_load.py:74\
          \ in                         \u2502\r\n\u2502 set_peft_model_state_dict\
          \                                                                      \
          \  \u2502\r\n\u2502                                                    \
          \                                              \u2502\r\n\u2502   71 \u2502\
          \   \u2502   peft_model_state_dict (`dict`): The state dict of the Peft\
          \ model.                   \u2502\r\n\u2502   72 \u2502   \"\"\"       \
          \                                                                      \
          \        \u2502\r\n\u2502   73 \u2502                                  \
          \                                                         \u2502\r\n\u2502\
          \ \u2771 74 \u2502   model.load_state_dict(peft_model_state_dict, strict=False)\
          \                              \u2502\r\n\u2502   75 \u2502   if model.peft_config.peft_type\
          \ != PeftType.LORA:                                        \u2502\r\n\u2502\
          \   76 \u2502   \u2502   model.prompt_encoder.embedding.load_state_dict(\
          \                                     \u2502\r\n\u2502   77 \u2502   \u2502\
          \   \u2502   {\"weight\": peft_model_state_dict[\"prompt_embeddings\"]},\
          \ strict=True             \u2502\r\n\u2502                             \
          \                                                                     \u2502\
          \r\n\u2502 /usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1671\
          \ in load_state_dict        \u2502\r\n\u2502                           \
          \                                                                      \
          \ \u2502\r\n\u2502   1668 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502\
          \   ', '.join('\"{}\"'.format(k) for k in missing_keys)))              \
          \ \u2502\r\n\u2502   1669 \u2502   \u2502                              \
          \                                                       \u2502\r\n\u2502\
          \   1670 \u2502   \u2502   if len(error_msgs) > 0:                     \
          \                                      \u2502\r\n\u2502 \u2771 1671 \u2502\
          \   \u2502   \u2502   raise RuntimeError('Error(s) in loading state_dict\
          \ for {}:\\n\\t{}'.format(     \u2502\r\n\u2502   1672 \u2502   \u2502 \
          \  \u2502   \u2502   \u2502   \u2502   \u2502      self.__class__.__name__,\
          \ \"\\n\\t\".join(error_msgs)))         \u2502\r\n\u2502   1673 \u2502 \
          \  \u2502   return _IncompatibleKeys(missing_keys, unexpected_keys)    \
          \  "
        updatedAt: '2023-04-01T15:21:05.314Z'
      numEdits: 0
      reactions: []
    id: 64284be1eb2891d3746b047e
    type: comment
  author: smjain
  content: "in <cell line: 1>:1                                                  \
    \                            \u2502\r\n\u2502                                \
    \                                                                  \u2502\r\n\u2502\
    \ /usr/local/lib/python3.9/dist-packages/peft/peft_model.py:161 in from_pretrained\
    \                 \u2502\r\n\u2502                                           \
    \                                                       \u2502\r\n\u2502   158\
    \ \u2502   \u2502   \u2502   filename, map_location=torch.device(\"cuda\" if torch.cuda.is_available()\
    \ else   \u2502\r\n\u2502   159 \u2502   \u2502   )                          \
    \                                                        \u2502\r\n\u2502   160\
    \ \u2502   \u2502   # load the weights into the model                        \
    \                          \u2502\r\n\u2502 \u2771 161 \u2502   \u2502   model\
    \ = set_peft_model_state_dict(model, adapters_weights)                       \
    \  \u2502\r\n\u2502   162 \u2502   \u2502   if getattr(model, \"hf_device_map\"\
    , None) is not None:                              \u2502\r\n\u2502   163 \u2502\
    \   \u2502   \u2502   device_map = kwargs.get(\"device_map\", \"auto\")      \
    \                            \u2502\r\n\u2502   164 \u2502   \u2502   \u2502 \
    \  max_memory = kwargs.get(\"max_memory\", None)                             \
    \       \u2502\r\n\u2502                                                     \
    \                                             \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/peft/utils/save_and_load.py:74\
    \ in                         \u2502\r\n\u2502 set_peft_model_state_dict      \
    \                                                                  \u2502\r\n\u2502\
    \                                                                            \
    \                      \u2502\r\n\u2502   71 \u2502   \u2502   peft_model_state_dict\
    \ (`dict`): The state dict of the Peft model.                   \u2502\r\n\u2502\
    \   72 \u2502   \"\"\"                                                       \
    \                              \u2502\r\n\u2502   73 \u2502                  \
    \                                                                         \u2502\
    \r\n\u2502 \u2771 74 \u2502   model.load_state_dict(peft_model_state_dict, strict=False)\
    \                              \u2502\r\n\u2502   75 \u2502   if model.peft_config.peft_type\
    \ != PeftType.LORA:                                        \u2502\r\n\u2502  \
    \ 76 \u2502   \u2502   model.prompt_encoder.embedding.load_state_dict(       \
    \                              \u2502\r\n\u2502   77 \u2502   \u2502   \u2502\
    \   {\"weight\": peft_model_state_dict[\"prompt_embeddings\"]}, strict=True  \
    \           \u2502\r\n\u2502                                                 \
    \                                                 \u2502\r\n\u2502 /usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1671\
    \ in load_state_dict        \u2502\r\n\u2502                                 \
    \                                                                 \u2502\r\n\u2502\
    \   1668 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   ', '.join('\"{}\"\
    '.format(k) for k in missing_keys)))               \u2502\r\n\u2502   1669 \u2502\
    \   \u2502                                                                   \
    \                  \u2502\r\n\u2502   1670 \u2502   \u2502   if len(error_msgs)\
    \ > 0:                                                           \u2502\r\n\u2502\
    \ \u2771 1671 \u2502   \u2502   \u2502   raise RuntimeError('Error(s) in loading\
    \ state_dict for {}:\\n\\t{}'.format(     \u2502\r\n\u2502   1672 \u2502   \u2502\
    \   \u2502   \u2502   \u2502   \u2502   \u2502      self.__class__.__name__, \"\
    \\n\\t\".join(error_msgs)))         \u2502\r\n\u2502   1673 \u2502   \u2502  \
    \ return _IncompatibleKeys(missing_keys, unexpected_keys)      "
  created_at: 2023-04-01 14:21:05+00:00
  edited: false
  hidden: false
  id: 64284be1eb2891d3746b047e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: bjoernp/alpaca-cerebras-6.7B
repo_type: model
status: open
target_branch: null
title: error in this line model = PeftModel.from_pretrained(model, "bjoernp/alpaca-cerebras-6.7B",
  torch_dtype=torch.float16, device_map='auto')
