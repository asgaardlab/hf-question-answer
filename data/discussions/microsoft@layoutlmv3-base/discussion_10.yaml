!!python/object:huggingface_hub.community.DiscussionWithDetails
author: nn-nikki
conflicting_files: null
created_at: 2023-06-20 05:12:12+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3057ffdc6c5e89c2e89525bab2a21a0f.svg
      fullname: Nikita
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: nn-nikki
      type: user
    createdAt: '2023-06-20T06:12:12.000Z'
    data:
      edited: false
      editors:
      - nn-nikki
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.5726767182350159
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3057ffdc6c5e89c2e89525bab2a21a0f.svg
          fullname: Nikita
          isHf: false
          isPro: false
          name: nn-nikki
          type: user
        html: '<p>I have used the following code for inference after fine-tuning the
          LayoutLMv3 model on the FUNSD dataset and obtained the predicted labels,
          but now I want to know how to associate these labels with the corresponding
          text in the image and extract the text along with their respective labels.</p>

          <p>from PIL import Image<br>import warnings, os, sys<br>from pathlib import
          Path<br>import torch<br>import pytesseract<br>from transformers import AutoModelForTokenClassification,
          AutoProcessor</p>

          <p>warnings.filterwarnings(''ignore'')</p>

          <p>base_dir = Path(<strong>file</strong>).resolve().parent.parent<br>src_path
          = os.path.join(os.path.dirname(base_dir), ''Document_Detection/src'')<br>sys.path.append(src_path)</p>

          <p>pytesseract.pytesseract.tesseract_cmd = r''C:\Program Files\Tesseract-OCR\tesseract.exe''</p>

          <h1 id="loading-trained-model">Loading trained model</h1>

          <p>model = AutoModelForTokenClassification.from_pretrained(r"..\models\checkpoint-1000")<br>processor
          = AutoProcessor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=True)</p>

          <h1 id="loading-the-image">Loading the image</h1>

          <p>val_image_path = r"..\data\image1.png"<br>image = Image.open(val_image_path)<br>image
          = image.convert("RGB")</p>

          <h1 id="calling-processor">calling processor</h1>

          <p>encoding = processor(image, return_tensors="pt")<br>for k,v in encoding.items():<br>  print(k,
          v.shape)</p>

          <p>with torch.no_grad():<br>  outputs = model(**encoding)</p>

          <p>logits = outputs.logits<br>print(f''logits_shape::{logits.shape}'')</p>

          <p>predictions = logits.argmax(-1).squeeze().tolist()<br>print(f"predictions::{predictions}")</p>

          <h1 id="directly-using-this-dictionary-for-mapping-prediction-values-and-labels">Directly
          using this dictionary for mapping prediction values and labels</h1>

          <p>id2label = {<br>    "0": "O",<br>    "1": "B-HEADER",<br>    "2": "I-HEADER",<br>    "3":
          "B-QUESTION",<br>    "4": "I-QUESTION",<br>    "5": "B-ANSWER",<br>    "6":
          "I-ANSWER"<br>  }</p>

          <h1 id="mapping-the-predictions-and-labels">Mapping the predictions and
          labels</h1>

          <p>predicted_labels = [id2label[str(pred)] for pred in predictions]<br>print(f"predicted_labels:
          {predicted_labels}")</p>

          '
        raw: "I have used the following code for inference after fine-tuning the LayoutLMv3\
          \ model on the FUNSD dataset and obtained the predicted labels, but now\
          \ I want to know how to associate these labels with the corresponding text\
          \ in the image and extract the text along with their respective labels.\r\
          \n\r\n\r\nfrom PIL import Image\r\nimport warnings, os, sys\r\nfrom pathlib\
          \ import Path\r\nimport torch\r\nimport pytesseract\r\nfrom transformers\
          \ import AutoModelForTokenClassification, AutoProcessor\r\n\r\nwarnings.filterwarnings('ignore')\r\
          \n\r\nbase_dir = Path(__file__).resolve().parent.parent\r\nsrc_path = os.path.join(os.path.dirname(base_dir),\
          \ 'Document_Detection/src')\r\nsys.path.append(src_path)\r\n\r\npytesseract.pytesseract.tesseract_cmd\
          \ = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\r\n\r\n# Loading\
          \ trained model\r\nmodel = AutoModelForTokenClassification.from_pretrained(r\"\
          ..\\models\\checkpoint-1000\")\r\nprocessor = AutoProcessor.from_pretrained(\"\
          microsoft/layoutlmv3-base\", apply_ocr=True)\r\n\r\n# Loading the image\r\
          \nval_image_path = r\"..\\data\\image1.png\"\r\nimage = Image.open(val_image_path)\r\
          \nimage = image.convert(\"RGB\")\r\n\r\n# calling processor\r\nencoding\
          \ = processor(image, return_tensors=\"pt\")\r\nfor k,v in encoding.items():\r\
          \n  print(k, v.shape)\r\n\r\nwith torch.no_grad():\r\n  outputs = model(**encoding)\r\
          \n\r\nlogits = outputs.logits\r\nprint(f'logits_shape::{logits.shape}')\r\
          \n\r\npredictions = logits.argmax(-1).squeeze().tolist()\r\nprint(f\"predictions::{predictions}\"\
          )\r\n\r\n# Directly using this dictionary for mapping prediction values\
          \ and labels\r\nid2label = {\r\n    \"0\": \"O\",\r\n    \"1\": \"B-HEADER\"\
          ,\r\n    \"2\": \"I-HEADER\",\r\n    \"3\": \"B-QUESTION\",\r\n    \"4\"\
          : \"I-QUESTION\",\r\n    \"5\": \"B-ANSWER\",\r\n    \"6\": \"I-ANSWER\"\
          \r\n  }\r\n\r\n# Mapping the predictions and labels\r\npredicted_labels\
          \ = [id2label[str(pred)] for pred in predictions]\r\nprint(f\"predicted_labels:\
          \ {predicted_labels}\")\r\n"
        updatedAt: '2023-06-20T06:12:12.792Z'
      numEdits: 0
      reactions: []
    id: 6491433c0047cd79a3a9ff4b
    type: comment
  author: nn-nikki
  content: "I have used the following code for inference after fine-tuning the LayoutLMv3\
    \ model on the FUNSD dataset and obtained the predicted labels, but now I want\
    \ to know how to associate these labels with the corresponding text in the image\
    \ and extract the text along with their respective labels.\r\n\r\n\r\nfrom PIL\
    \ import Image\r\nimport warnings, os, sys\r\nfrom pathlib import Path\r\nimport\
    \ torch\r\nimport pytesseract\r\nfrom transformers import AutoModelForTokenClassification,\
    \ AutoProcessor\r\n\r\nwarnings.filterwarnings('ignore')\r\n\r\nbase_dir = Path(__file__).resolve().parent.parent\r\
    \nsrc_path = os.path.join(os.path.dirname(base_dir), 'Document_Detection/src')\r\
    \nsys.path.append(src_path)\r\n\r\npytesseract.pytesseract.tesseract_cmd = r'C:\\\
    Program Files\\Tesseract-OCR\\tesseract.exe'\r\n\r\n# Loading trained model\r\n\
    model = AutoModelForTokenClassification.from_pretrained(r\"..\\models\\checkpoint-1000\"\
    )\r\nprocessor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\",\
    \ apply_ocr=True)\r\n\r\n# Loading the image\r\nval_image_path = r\"..\\data\\\
    image1.png\"\r\nimage = Image.open(val_image_path)\r\nimage = image.convert(\"\
    RGB\")\r\n\r\n# calling processor\r\nencoding = processor(image, return_tensors=\"\
    pt\")\r\nfor k,v in encoding.items():\r\n  print(k, v.shape)\r\n\r\nwith torch.no_grad():\r\
    \n  outputs = model(**encoding)\r\n\r\nlogits = outputs.logits\r\nprint(f'logits_shape::{logits.shape}')\r\
    \n\r\npredictions = logits.argmax(-1).squeeze().tolist()\r\nprint(f\"predictions::{predictions}\"\
    )\r\n\r\n# Directly using this dictionary for mapping prediction values and labels\r\
    \nid2label = {\r\n    \"0\": \"O\",\r\n    \"1\": \"B-HEADER\",\r\n    \"2\":\
    \ \"I-HEADER\",\r\n    \"3\": \"B-QUESTION\",\r\n    \"4\": \"I-QUESTION\",\r\n\
    \    \"5\": \"B-ANSWER\",\r\n    \"6\": \"I-ANSWER\"\r\n  }\r\n\r\n# Mapping the\
    \ predictions and labels\r\npredicted_labels = [id2label[str(pred)] for pred in\
    \ predictions]\r\nprint(f\"predicted_labels: {predicted_labels}\")\r\n"
  created_at: 2023-06-20 05:12:12+00:00
  edited: false
  hidden: false
  id: 6491433c0047cd79a3a9ff4b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: microsoft/layoutlmv3-base
repo_type: model
status: open
target_branch: null
title: Inference on fine tuned LayoutLMv3 model
