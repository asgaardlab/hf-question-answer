!!python/object:huggingface_hub.community.DiscussionWithDetails
author: abhijit57
conflicting_files: null
created_at: 2023-04-27 01:37:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4924fcb20b2bf74d871edfdbd228185c.svg
      fullname: Abhijit Nayak
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhijit57
      type: user
    createdAt: '2023-04-27T02:37:01.000Z'
    data:
      edited: false
      editors:
      - abhijit57
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4924fcb20b2bf74d871edfdbd228185c.svg
          fullname: Abhijit Nayak
          isHf: false
          isPro: false
          name: abhijit57
          type: user
        html: '<p>Hello,</p>

          <p>I am working on a text classification research project and I have a dataset
          of about 500000 rows where each document is of a fairly larger size (70-100
          tokens). I tried this model on nvidia v100 32gb GPU for 10 rows and a candidate
          label size of 804. It took 10 minutes. I cannot reduce the candidate label
          list size as per the requirements. I also tried codon compiler and numba
          to improve the inferences speed but not much luck there.</p>

          <p>Has anyone have worked on the C++ bart model or have used deepspeed to
          improve the predictions for this model?<br>Any leads or help would be greatly
          appreciated, thank you.</p>

          '
        raw: "Hello,\r\n\r\nI am working on a text classification research project\
          \ and I have a dataset of about 500000 rows where each document is of a\
          \ fairly larger size (70-100 tokens). I tried this model on nvidia v100\
          \ 32gb GPU for 10 rows and a candidate label size of 804. It took 10 minutes.\
          \ I cannot reduce the candidate label list size as per the requirements.\
          \ I also tried codon compiler and numba to improve the inferences speed\
          \ but not much luck there.\r\n\r\nHas anyone have worked on the C++ bart\
          \ model or have used deepspeed to improve the predictions for this model?\r\
          \nAny leads or help would be greatly appreciated, thank you."
        updatedAt: '2023-04-27T02:37:01.552Z'
      numEdits: 0
      reactions: []
    id: 6449dfcd958a6aca06140c11
    type: comment
  author: abhijit57
  content: "Hello,\r\n\r\nI am working on a text classification research project and\
    \ I have a dataset of about 500000 rows where each document is of a fairly larger\
    \ size (70-100 tokens). I tried this model on nvidia v100 32gb GPU for 10 rows\
    \ and a candidate label size of 804. It took 10 minutes. I cannot reduce the candidate\
    \ label list size as per the requirements. I also tried codon compiler and numba\
    \ to improve the inferences speed but not much luck there.\r\n\r\nHas anyone have\
    \ worked on the C++ bart model or have used deepspeed to improve the predictions\
    \ for this model?\r\nAny leads or help would be greatly appreciated, thank you."
  created_at: 2023-04-27 01:37:01+00:00
  edited: false
  hidden: false
  id: 6449dfcd958a6aca06140c11
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9f60920ed4f581e913877b9de1d7ed19.svg
      fullname: manoj bhat
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: manbeast3b
      type: user
    createdAt: '2023-11-26T17:17:13.000Z'
    data:
      edited: false
      editors:
      - manbeast3b
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9958943128585815
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9f60920ed4f581e913877b9de1d7ed19.svg
          fullname: manoj bhat
          isHf: false
          isPro: false
          name: manbeast3b
          type: user
        html: '<p>+1, did you find a way?</p>

          '
        raw: +1, did you find a way?
        updatedAt: '2023-11-26T17:17:13.395Z'
      numEdits: 0
      reactions: []
    id: 65637d9930a88a2f1dff5f36
    type: comment
  author: manbeast3b
  content: +1, did you find a way?
  created_at: 2023-11-26 17:17:13+00:00
  edited: false
  hidden: false
  id: 65637d9930a88a2f1dff5f36
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4924fcb20b2bf74d871edfdbd228185c.svg
      fullname: Abhijit Nayak
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: abhijit57
      type: user
    createdAt: '2023-11-26T20:03:52.000Z'
    data:
      edited: false
      editors:
      - abhijit57
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.42769551277160645
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4924fcb20b2bf74d871edfdbd228185c.svg
          fullname: Abhijit Nayak
          isHf: false
          isPro: false
          name: abhijit57
          type: user
        html: '<p>Use deepspeed</p>

          '
        raw: Use deepspeed
        updatedAt: '2023-11-26T20:03:52.971Z'
      numEdits: 0
      reactions: []
    id: 6563a4a85475849b82db1948
    type: comment
  author: abhijit57
  content: Use deepspeed
  created_at: 2023-11-26 20:03:52+00:00
  edited: false
  hidden: false
  id: 6563a4a85475849b82db1948
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: facebook/bart-large-mnli
repo_type: model
status: open
target_branch: null
title: Improving the inference/classification/prediction speed of this bart-large-mnli
  model
