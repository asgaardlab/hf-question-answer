!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Kameleo
conflicting_files: null
created_at: 2023-08-22 05:38:15+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9810373bdb4f14e76f02c717a57fcbfd.svg
      fullname: Gilles
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kameleo
      type: user
    createdAt: '2023-08-22T06:38:15.000Z'
    data:
      edited: false
      editors:
      - Kameleo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6919646859169006
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9810373bdb4f14e76f02c717a57fcbfd.svg
          fullname: Gilles
          isHf: false
          isPro: false
          name: Kameleo
          type: user
        html: '<p>I get this when queuing from your example :</p>

          <p>Error occurred when executing CLIPVisionLoader:</p>

          <p>Error(s) in loading state_dict for CLIPVisionModelWithProjection:<br>size
          mismatch for vision_model.embeddings.class_embedding: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.embeddings.patch_embedding.weight:
          copying a param with shape torch.Size([1664, 3, 14, 14]) from checkpoint,
          the shape in current model is torch.Size([1280, 3, 14, 14]).<br>size mismatch
          for vision_model.embeddings.position_embedding.weight: copying a param with
          shape torch.Size([257, 1664]) from checkpoint, the shape in current model
          is torch.Size([257, 1280]).<br>size mismatch for vision_model.pre_layrnorm.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.pre_layrnorm.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.0.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.0.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.0.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.0.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.0.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.0.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.0.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.0.self_attn.out_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.0.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.0.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.0.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.0.mlp.fc1.bias: copying a param with shape torch.Size([8192])
          from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.0.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.0.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.0.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.0.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.1.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.1.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.1.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.1.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.1.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.1.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.1.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.1.self_attn.out_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.1.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.1.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.1.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.1.mlp.fc1.bias: copying a param with shape torch.Size([8192])
          from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.1.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.1.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.1.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.1.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.2.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.2.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.2.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.2.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.2.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.2.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.2.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.2.self_attn.out_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.2.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.2.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.2.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.2.mlp.fc1.bias: copying a param with shape torch.Size([8192])
          from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.2.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.2.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.2.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.2.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.3.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.3.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.3.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.3.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.3.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.3.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.3.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.3.self_attn.out_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.3.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.3.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.3.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.3.mlp.fc1.bias: copying a param with shape torch.Size([8192])
          from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.3.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.3.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.3.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.3.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.4.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.4.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.4.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.4.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.4.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.4.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.4.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.4.self_attn.out_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.4.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.4.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.4.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.4.mlp.fc1.bias: copying a param with shape torch.Size([8192])
          from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.4.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.4.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.4.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.4.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.5.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.5.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.5.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.5.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.5.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.5.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.5.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.5.self_attn.out_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.5.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.5.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.5.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.5.mlp.fc1.bias: copying a param with shape torch.Size([8192])
          from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.5.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.5.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.5.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.5.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.6.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.6.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.6.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.6.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.6.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.6.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.6.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.6.self_attn.out_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.6.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.6.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.6.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.6.mlp.fc1.bias: copying a param with shape torch.Size([8192])
          from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.6.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.6.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.6.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.6.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.7.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.7.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.7.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.7.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.7.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.7.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.7.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.7.self_attn.out_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.7.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.7.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.7.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.7.mlp.fc1.bias: copying a param with shape torch.Size([8192])
          from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.7.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.7.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.7.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.7.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.8.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.8.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.8.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.8.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.8.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.8.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.8.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.8.self_attn.out_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.8.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.8.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.8.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.8.mlp.fc1.bias: copying a param with shape torch.Size([8192])
          from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.8.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.8.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.8.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.8.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.9.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.9.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.9.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.9.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.9.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.9.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.9.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.9.self_attn.out_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.9.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.9.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.9.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.9.mlp.fc1.bias: copying a param with shape torch.Size([8192])
          from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.9.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.9.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.9.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.9.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.10.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.10.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.10.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.10.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.10.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.10.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.10.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.10.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.10.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.10.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.10.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.10.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.10.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.10.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.10.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.10.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.11.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.11.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.11.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.11.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.11.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.11.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.11.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.11.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.11.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.11.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.11.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.11.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.11.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.11.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.11.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.11.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.12.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.12.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.12.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.12.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.12.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.12.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.12.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.12.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.12.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.12.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.12.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.12.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.12.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.12.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.12.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.12.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.13.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.13.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.13.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.13.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.13.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.13.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.13.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.13.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.13.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.13.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.13.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.13.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.13.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.13.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.13.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.13.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.14.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.14.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.14.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.14.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.14.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.14.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.14.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.14.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.14.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.14.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.14.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.14.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.14.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.14.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.14.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.14.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.15.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.15.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.15.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.15.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.15.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.15.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.15.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.15.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.15.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.15.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.15.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.15.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.15.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.15.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.15.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.15.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.16.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.16.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.16.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.16.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.16.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.16.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.16.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.16.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.16.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.16.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.16.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.16.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.16.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.16.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.16.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.16.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.17.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.17.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.17.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.17.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.17.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.17.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.17.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.17.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.17.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.17.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.17.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.17.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.17.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.17.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.17.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.17.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.18.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.18.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.18.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.18.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.18.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.18.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.18.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.18.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.18.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.18.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.18.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.18.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.18.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.18.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.18.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.18.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.19.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.19.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.19.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.19.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.19.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.19.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.19.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.19.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.19.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.19.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.19.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.19.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.19.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.19.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.19.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.19.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.20.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.20.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.20.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.20.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.20.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.20.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.20.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.20.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.20.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.20.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.20.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.20.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.20.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.20.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.20.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.20.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.21.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.21.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.21.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.21.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.21.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.21.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.21.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.21.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.21.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.21.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.21.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.21.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.21.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.21.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.21.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.21.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.22.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.22.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.22.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.22.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.22.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.22.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.22.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.22.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.22.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.22.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.22.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.22.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.22.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.22.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.22.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.22.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.23.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.23.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.23.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.23.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.23.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.23.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.23.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.23.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.23.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.23.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.23.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.23.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.23.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.23.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.23.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.23.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.24.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.24.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.24.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.24.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.24.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.24.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.24.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.24.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.24.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.24.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.24.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.24.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.24.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.24.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.24.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.24.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.25.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.25.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.25.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.25.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.25.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.25.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.25.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.25.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.25.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.25.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.25.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.25.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.25.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.25.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.25.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.25.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.26.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.26.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.26.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.26.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.26.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.26.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.26.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.26.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.26.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.26.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.26.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.26.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.26.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.26.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.26.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.26.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.27.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.27.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.27.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.27.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.27.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.27.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.27.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.27.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.27.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.27.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.27.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.27.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.27.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.27.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.27.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.27.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.28.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.28.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.28.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.28.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.28.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.28.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.28.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.28.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.28.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.28.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.28.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.28.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.28.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.28.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.28.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.28.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.29.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.29.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.29.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.29.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.29.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.29.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.29.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.29.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.29.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.29.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.29.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.29.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.29.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.29.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.29.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.29.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.30.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.30.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.30.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.30.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.30.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.30.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.30.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.30.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.30.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.30.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.30.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.30.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.30.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.30.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.30.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.30.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.31.self_attn.k_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.31.self_attn.k_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.31.self_attn.v_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.31.self_attn.v_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.31.self_attn.q_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.31.self_attn.q_proj.bias: copying a param with
          shape torch.Size([1664]) from checkpoint, the shape in current model is
          torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.31.self_attn.out_proj.weight:
          copying a param with shape torch.Size([1664, 1664]) from checkpoint, the
          shape in current model is torch.Size([1280, 1280]).<br>size mismatch for
          vision_model.encoder.layers.31.self_attn.out_proj.bias: copying a param
          with shape torch.Size([1664]) from checkpoint, the shape in current model
          is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.31.layer_norm1.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.31.layer_norm1.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.31.mlp.fc1.weight:
          copying a param with shape torch.Size([8192, 1664]) from checkpoint, the
          shape in current model is torch.Size([5120, 1280]).<br>size mismatch for
          vision_model.encoder.layers.31.mlp.fc1.bias: copying a param with shape
          torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).<br>size
          mismatch for vision_model.encoder.layers.31.mlp.fc2.weight: copying a param
          with shape torch.Size([1664, 8192]) from checkpoint, the shape in current
          model is torch.Size([1280, 5120]).<br>size mismatch for vision_model.encoder.layers.31.mlp.fc2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.31.layer_norm2.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.encoder.layers.31.layer_norm2.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.post_layernorm.weight:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for vision_model.post_layernorm.bias:
          copying a param with shape torch.Size([1664]) from checkpoint, the shape
          in current model is torch.Size([1280]).<br>size mismatch for visual_projection.weight:
          copying a param with shape torch.Size([1280, 1664]) from checkpoint, the
          shape in current model is torch.Size([1024, 1280]).</p>

          <p>File "/Users/gbkm1max/ComfyUI/execution.py", line 151, in recursive_execute<br>output_data,
          output_ui = get_output_data(obj, input_data_all)<br>File "/Users/gbkm1max/ComfyUI/execution.py",
          line 81, in get_output_data<br>return_values = map_node_over_list(obj, input_data_all,
          obj.FUNCTION, allow_interrupt=True)<br>File "/Users/gbkm1max/ComfyUI/execution.py",
          line 74, in map_node_over_list<br>results.append(getattr(obj, func)(**slice_dict(input_data_all,
          i)))<br>File "/Users/gbkm1max/ComfyUI/nodes.py", line 727, in load_clip<br>clip_vision
          = comfy.clip_vision.load(clip_path)<br>File "/Users/gbkm1max/ComfyUI/comfy/clip_vision.py",
          line 74, in load<br>return load_clipvision_from_sd(sd)<br>File "/Users/gbkm1max/ComfyUI/comfy/clip_vision.py",
          line 63, in load_clipvision_from_sd<br>m, u = clip.load_sd(sd)<br>File "/Users/gbkm1max/ComfyUI/comfy/clip_vision.py",
          line 24, in load_sd<br>return self.model.load_state_dict(sd, strict=False)<br>File
          "/Users/gbkm1max/.pyenv/versions/3.9.2/lib/python3.9/site-packages/torch/nn/modules/module.py",
          line 2152, in load_state_dict<br>raise RuntimeError(''Error(s) in loading
          state_dict for {}:\n\t{}''.format(</p>

          '
        raw: "I get this when queuing from your example :\r\n\r\nError occurred when\
          \ executing CLIPVisionLoader:\r\n\r\nError(s) in loading state_dict for\
          \ CLIPVisionModelWithProjection:\r\nsize mismatch for vision_model.embeddings.class_embedding:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.embeddings.patch_embedding.weight:\
          \ copying a param with shape torch.Size([1664, 3, 14, 14]) from checkpoint,\
          \ the shape in current model is torch.Size([1280, 3, 14, 14]).\r\nsize mismatch\
          \ for vision_model.embeddings.position_embedding.weight: copying a param\
          \ with shape torch.Size([257, 1664]) from checkpoint, the shape in current\
          \ model is torch.Size([257, 1280]).\r\nsize mismatch for vision_model.pre_layrnorm.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.pre_layrnorm.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.0.self_attn.k_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.0.self_attn.v_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.0.self_attn.q_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.0.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.0.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.0.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.0.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.1.self_attn.k_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.1.self_attn.v_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.1.self_attn.q_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.1.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.1.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.1.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.1.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.2.self_attn.k_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.2.self_attn.v_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.2.self_attn.q_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.2.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.2.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.2.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.2.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.3.self_attn.k_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.3.self_attn.v_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.3.self_attn.q_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.3.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.3.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.3.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.3.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.4.self_attn.k_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.4.self_attn.v_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.4.self_attn.q_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.4.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.4.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.4.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.4.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.5.self_attn.k_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.5.self_attn.v_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.5.self_attn.q_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.5.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.5.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.5.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.5.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.6.self_attn.k_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.6.self_attn.v_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.6.self_attn.q_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.6.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.6.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.6.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.6.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.7.self_attn.k_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.7.self_attn.v_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.7.self_attn.q_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.7.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.7.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.7.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.7.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.8.self_attn.k_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.8.self_attn.v_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.8.self_attn.q_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.8.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.8.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.8.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.8.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.9.self_attn.k_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.9.self_attn.v_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.9.self_attn.q_proj.bias: copying a param with\
          \ shape torch.Size([1664]) from checkpoint, the shape in current model is\
          \ torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.9.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.9.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.9.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.9.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.10.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.10.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.10.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.10.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.10.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.10.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.10.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.11.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.11.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.11.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.11.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.11.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.11.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.11.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.12.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.12.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.12.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.12.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.12.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.12.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.12.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.13.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.13.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.13.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.13.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.13.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.13.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.13.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.14.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.14.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.14.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.14.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.14.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.14.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.14.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.15.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.15.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.15.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.15.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.15.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.15.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.15.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.16.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.16.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.16.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.16.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.16.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.16.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.16.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.17.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.17.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.17.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.17.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.17.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.17.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.17.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.18.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.18.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.18.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.18.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.18.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.18.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.18.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.19.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.19.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.19.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.19.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.19.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.19.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.19.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.20.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.20.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.20.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.20.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.20.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.20.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.20.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.21.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.21.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.21.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.21.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.21.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.21.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.21.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.22.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.22.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.22.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.22.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.22.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.22.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.22.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.23.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.23.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.23.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.23.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.23.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.23.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.23.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.24.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.24.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.24.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.24.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.24.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.24.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.24.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.25.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.25.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.25.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.25.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.25.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.25.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.25.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.26.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.26.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.26.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.26.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.26.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.26.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.26.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.27.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.27.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.27.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.27.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.27.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.27.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.27.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.28.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.28.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.28.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.28.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.28.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.28.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.28.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.29.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.29.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.29.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.29.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.29.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.29.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.29.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.30.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.30.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.30.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.30.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.30.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.30.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.30.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.k_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.31.self_attn.k_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.v_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.31.self_attn.v_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.q_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.31.self_attn.q_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.out_proj.weight:\
          \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.31.self_attn.out_proj.bias: copying a param\
          \ with shape torch.Size([1664]) from checkpoint, the shape in current model\
          \ is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.layer_norm1.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.layer_norm1.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.mlp.fc1.weight:\
          \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([5120, 1280]).\r\nsize mismatch for\
          \ vision_model.encoder.layers.31.mlp.fc1.bias: copying a param with shape\
          \ torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([5120]).\r\
          \nsize mismatch for vision_model.encoder.layers.31.mlp.fc2.weight: copying\
          \ a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
          \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.31.mlp.fc2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.layer_norm2.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.layer_norm2.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.post_layernorm.weight:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for vision_model.post_layernorm.bias:\
          \ copying a param with shape torch.Size([1664]) from checkpoint, the shape\
          \ in current model is torch.Size([1280]).\r\nsize mismatch for visual_projection.weight:\
          \ copying a param with shape torch.Size([1280, 1664]) from checkpoint, the\
          \ shape in current model is torch.Size([1024, 1280]).\r\n\r\nFile \"/Users/gbkm1max/ComfyUI/execution.py\"\
          , line 151, in recursive_execute\r\noutput_data, output_ui = get_output_data(obj,\
          \ input_data_all)\r\nFile \"/Users/gbkm1max/ComfyUI/execution.py\", line\
          \ 81, in get_output_data\r\nreturn_values = map_node_over_list(obj, input_data_all,\
          \ obj.FUNCTION, allow_interrupt=True)\r\nFile \"/Users/gbkm1max/ComfyUI/execution.py\"\
          , line 74, in map_node_over_list\r\nresults.append(getattr(obj, func)(**slice_dict(input_data_all,\
          \ i)))\r\nFile \"/Users/gbkm1max/ComfyUI/nodes.py\", line 727, in load_clip\r\
          \nclip_vision = comfy.clip_vision.load(clip_path)\r\nFile \"/Users/gbkm1max/ComfyUI/comfy/clip_vision.py\"\
          , line 74, in load\r\nreturn load_clipvision_from_sd(sd)\r\nFile \"/Users/gbkm1max/ComfyUI/comfy/clip_vision.py\"\
          , line 63, in load_clipvision_from_sd\r\nm, u = clip.load_sd(sd)\r\nFile\
          \ \"/Users/gbkm1max/ComfyUI/comfy/clip_vision.py\", line 24, in load_sd\r\
          \nreturn self.model.load_state_dict(sd, strict=False)\r\nFile \"/Users/gbkm1max/.pyenv/versions/3.9.2/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
          , line 2152, in load_state_dict\r\nraise RuntimeError('Error(s) in loading\
          \ state_dict for {}:\\n\\t{}'.format("
        updatedAt: '2023-08-22T06:38:15.219Z'
      numEdits: 0
      reactions: []
    id: 64e457d758579025cbbc0dbf
    type: comment
  author: Kameleo
  content: "I get this when queuing from your example :\r\n\r\nError occurred when\
    \ executing CLIPVisionLoader:\r\n\r\nError(s) in loading state_dict for CLIPVisionModelWithProjection:\r\
    \nsize mismatch for vision_model.embeddings.class_embedding: copying a param with\
    \ shape torch.Size([1664]) from checkpoint, the shape in current model is torch.Size([1280]).\r\
    \nsize mismatch for vision_model.embeddings.patch_embedding.weight: copying a\
    \ param with shape torch.Size([1664, 3, 14, 14]) from checkpoint, the shape in\
    \ current model is torch.Size([1280, 3, 14, 14]).\r\nsize mismatch for vision_model.embeddings.position_embedding.weight:\
    \ copying a param with shape torch.Size([257, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([257, 1280]).\r\nsize mismatch for vision_model.pre_layrnorm.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.pre_layrnorm.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.0.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.0.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.0.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.0.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.0.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.1.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.1.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.1.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.1.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.1.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.2.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.2.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.2.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.2.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.2.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.3.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.3.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.3.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.3.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.3.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.4.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.4.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.4.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.4.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.4.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.5.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.5.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.5.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.5.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.5.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.6.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.6.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.6.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.6.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.6.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.7.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.7.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.7.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.7.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.7.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.8.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.8.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.8.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.8.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.8.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.9.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.9.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.9.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.9.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.9.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.10.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.10.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.10.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.10.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.10.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.11.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.11.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.11.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.11.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.11.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.12.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.12.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.12.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.12.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.12.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.13.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.13.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.13.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.13.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.13.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.14.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.14.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.14.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.14.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.14.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.15.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.15.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.15.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.15.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.15.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.16.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.16.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.16.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.16.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.16.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.17.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.17.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.17.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.17.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.17.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.18.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.18.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.18.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.18.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.18.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.19.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.19.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.19.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.19.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.19.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.20.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.20.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.20.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.20.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.20.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.21.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.21.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.21.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.21.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.21.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.22.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.22.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.22.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.22.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.22.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.23.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.23.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.23.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.23.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.23.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.24.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.24.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.24.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.24.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.24.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.25.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.25.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.25.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.25.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.25.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.26.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.26.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.26.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.26.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.26.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.27.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.27.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.27.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.27.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.27.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.28.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.28.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.28.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.28.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.28.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.29.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.29.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.29.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.29.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.29.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.30.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.30.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.30.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.30.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.30.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.k_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.k_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.v_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.v_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.q_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.q_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.out_proj.weight:\
    \ copying a param with shape torch.Size([1664, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1280]).\r\nsize mismatch for vision_model.encoder.layers.31.self_attn.out_proj.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.layer_norm1.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.layer_norm1.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.mlp.fc1.weight:\
    \ copying a param with shape torch.Size([8192, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([5120, 1280]).\r\nsize mismatch for vision_model.encoder.layers.31.mlp.fc1.bias:\
    \ copying a param with shape torch.Size([8192]) from checkpoint, the shape in\
    \ current model is torch.Size([5120]).\r\nsize mismatch for vision_model.encoder.layers.31.mlp.fc2.weight:\
    \ copying a param with shape torch.Size([1664, 8192]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 5120]).\r\nsize mismatch for vision_model.encoder.layers.31.mlp.fc2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.layer_norm2.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.encoder.layers.31.layer_norm2.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.post_layernorm.weight:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for vision_model.post_layernorm.bias:\
    \ copying a param with shape torch.Size([1664]) from checkpoint, the shape in\
    \ current model is torch.Size([1280]).\r\nsize mismatch for visual_projection.weight:\
    \ copying a param with shape torch.Size([1280, 1664]) from checkpoint, the shape\
    \ in current model is torch.Size([1024, 1280]).\r\n\r\nFile \"/Users/gbkm1max/ComfyUI/execution.py\"\
    , line 151, in recursive_execute\r\noutput_data, output_ui = get_output_data(obj,\
    \ input_data_all)\r\nFile \"/Users/gbkm1max/ComfyUI/execution.py\", line 81, in\
    \ get_output_data\r\nreturn_values = map_node_over_list(obj, input_data_all, obj.FUNCTION,\
    \ allow_interrupt=True)\r\nFile \"/Users/gbkm1max/ComfyUI/execution.py\", line\
    \ 74, in map_node_over_list\r\nresults.append(getattr(obj, func)(**slice_dict(input_data_all,\
    \ i)))\r\nFile \"/Users/gbkm1max/ComfyUI/nodes.py\", line 727, in load_clip\r\n\
    clip_vision = comfy.clip_vision.load(clip_path)\r\nFile \"/Users/gbkm1max/ComfyUI/comfy/clip_vision.py\"\
    , line 74, in load\r\nreturn load_clipvision_from_sd(sd)\r\nFile \"/Users/gbkm1max/ComfyUI/comfy/clip_vision.py\"\
    , line 63, in load_clipvision_from_sd\r\nm, u = clip.load_sd(sd)\r\nFile \"/Users/gbkm1max/ComfyUI/comfy/clip_vision.py\"\
    , line 24, in load_sd\r\nreturn self.model.load_state_dict(sd, strict=False)\r\
    \nFile \"/Users/gbkm1max/.pyenv/versions/3.9.2/lib/python3.9/site-packages/torch/nn/modules/module.py\"\
    , line 2152, in load_state_dict\r\nraise RuntimeError('Error(s) in loading state_dict\
    \ for {}:\\n\\t{}'.format("
  created_at: 2023-08-22 05:38:15+00:00
  edited: false
  hidden: false
  id: 64e457d758579025cbbc0dbf
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: comfyanonymous/clip_vision_g
repo_type: model
status: open
target_branch: null
title: Error on M1max64go
