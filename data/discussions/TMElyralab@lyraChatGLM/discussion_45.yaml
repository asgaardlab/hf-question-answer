!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ushow
conflicting_files: null
created_at: 2023-07-03 01:21:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d23225ab8c720a51cf571dc8be1d0d4e.svg
      fullname: ushow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ushow
      type: user
    createdAt: '2023-07-03T02:21:09.000Z'
    data:
      edited: true
      editors:
      - ushow
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.2773621678352356
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d23225ab8c720a51cf571dc8be1d0d4e.svg
          fullname: ushow
          isHf: false
          isPro: false
          name: ushow
          type: user
        html: "<p>\u73AF\u5883\uFF1AAnaconda  \uFF0C Python 3.10.11 \uFF0C win10 \u3002\
          \u5E0C\u671B\u5F97\u5230\u60A8\u7684\u5E2E\u52A9\uFF0C\u8C22\u8C22\uFF01\
          <br><a rel=\"nofollow\" href=\"https://cdn-uploads.huggingface.co/production/uploads/64a22fb5f824e15453d71940/l0tznBGs4eHmDzeXOrPgK.png\"\
          ><img alt=\"\u5FAE\u4FE1\u622A\u56FE_20230703103456.png\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64a22fb5f824e15453d71940/l0tznBGs4eHmDzeXOrPgK.png\"\
          ></a><br>\u7CFB\u7EDF\u5F39\u7A97\u5982\u4E0A\uFF0C\u540C\u65F6\u62A5\u9519\
          \u5982\u4E0B\uFF1A</p>\n<p>(lyraChatGLM) D:\\lyraChatGLM&gt;python demo.py<br>Loading\
          \ tokenizer from .<br>[INFO] Load Our Highly Optimized LyraChatGLM6B model</p>\n\
          <ul>\n<li>head_num.................: 32</li>\n<li>size_per_head............:\
          \ 128</li>\n<li>layer_num................: 28</li>\n<li>tensor_para_size.........:\
          \ 1</li>\n<li>vocab_size...............: 130528</li>\n<li>start_id.................:\
          \ 130004</li>\n<li>end_id...................: 130005</li>\n<li>weights_data_type........:\
          \ fp16</li>\n<li>layernorm_eps............: 1e-05</li>\n<li>inference_data_type......:\
          \ fp16</li>\n<li>rotary_embedding_dim.....: 64</li>\n<li>max_seq_len..............:\
          \ 0</li>\n<li>pipeline_para_size.......: 1</li>\n<li>shared_contexts_ratio....:\
          \ 0.0</li>\n<li>int8_mode................: 0</li>\n<li>model_path...............:\
          \ .\\models\\1-gpu-fp16.bin</li>\n<li>cuda_version.............: 11<br>Loading\
          \ tokenizer from .\\models\\1-gpu-fp16.bin<br>Traceback (most recent call\
          \ last):<br>  File \"D:\\lyraChatGLM\\demo.py\", line 12, in <br> model\
          \ = LyraChatGLM6B(model_path, tokenizer_path, data_type, int8_mode, arch,\
          \ cuda_version)<br>  File \"D:\\lyraChatGLM\\lyraChatGLM\\lyra_glm.py\"\
          , line 24, in <strong>init</strong><br> self.model, self.tokenizer = self.load_model_and_tokenizer()<br>\
          \  File \"D:\\lyraChatGLM\\lyraChatGLM\\lyra_glm.py\", line 108, in load_model_and_tokenizer<br>\
          \ model = ChatGLM6BModel(arch=self.arch,**model_args)<br>  File \"D:\\lyraChatGLM\\\
          lyraChatGLM\\model.py\", line 103, in <strong>init</strong><br> torch.classes.load_library(os.path.abspath(lib_path))<br>\
          \  File \"C:\\Users\\ushow_AI.conda\\envs\\lyraChatGLM\\lib\\site-packages\\\
          torch_classes.py\", line 51, in load_library<br> torch.ops.load_library(path)<br>\
          \  File \"C:\\Users\\ushow_AI.conda\\envs\\lyraChatGLM\\lib\\site-packages\\\
          torch_ops.py\", line 643, in load_library<br> ctypes.CDLL(path)<br>  File\
          \ \"C:\\Users\\ushow_AI.conda\\envs\\lyraChatGLM\\lib\\ctypes_<em>init</em>_.py\"\
          , line 374, in <strong>init</strong><br> self._handle = _dlopen(self._name,\
          \ mode)<br>OSError: [WinError 193] %1 \u4E0D\u662F\u6709\u6548\u7684 Win32\
          \ \u5E94\u7528\u7A0B\u5E8F\u3002</li>\n</ul>\n"
        raw: "\u73AF\u5883\uFF1AAnaconda  \uFF0C Python 3.10.11 \uFF0C win10 \u3002\
          \u5E0C\u671B\u5F97\u5230\u60A8\u7684\u5E2E\u52A9\uFF0C\u8C22\u8C22\uFF01\
          \n![\u5FAE\u4FE1\u622A\u56FE_20230703103456.png](https://cdn-uploads.huggingface.co/production/uploads/64a22fb5f824e15453d71940/l0tznBGs4eHmDzeXOrPgK.png)\n\
          \u7CFB\u7EDF\u5F39\u7A97\u5982\u4E0A\uFF0C\u540C\u65F6\u62A5\u9519\u5982\
          \u4E0B\uFF1A\n\n(lyraChatGLM) D:\\lyraChatGLM>python demo.py\nLoading tokenizer\
          \ from .\n[INFO] Load Our Highly Optimized LyraChatGLM6B model\n - head_num.................:\
          \ 32\n - size_per_head............: 128\n - layer_num................: 28\n\
          \ - tensor_para_size.........: 1\n - vocab_size...............: 130528\n\
          \ - start_id.................: 130004\n - end_id...................: 130005\n\
          \ - weights_data_type........: fp16\n - layernorm_eps............: 1e-05\n\
          \ - inference_data_type......: fp16\n - rotary_embedding_dim.....: 64\n\
          \ - max_seq_len..............: 0\n - pipeline_para_size.......: 1\n - shared_contexts_ratio....:\
          \ 0.0\n - int8_mode................: 0\n - model_path...............: .\\\
          models\\1-gpu-fp16.bin\n - cuda_version.............: 11\nLoading tokenizer\
          \ from .\\models\\1-gpu-fp16.bin\nTraceback (most recent call last):\n \
          \ File \"D:\\lyraChatGLM\\demo.py\", line 12, in <module>\n    model = LyraChatGLM6B(model_path,\
          \ tokenizer_path, data_type, int8_mode, arch, cuda_version)\n  File \"D:\\\
          lyraChatGLM\\lyraChatGLM\\lyra_glm.py\", line 24, in __init__\n    self.model,\
          \ self.tokenizer = self.load_model_and_tokenizer()\n  File \"D:\\lyraChatGLM\\\
          lyraChatGLM\\lyra_glm.py\", line 108, in load_model_and_tokenizer\n    model\
          \ = ChatGLM6BModel(arch=self.arch,**model_args)\n  File \"D:\\lyraChatGLM\\\
          lyraChatGLM\\model.py\", line 103, in __init__\n    torch.classes.load_library(os.path.abspath(lib_path))\n\
          \  File \"C:\\Users\\ushow_AI\\.conda\\envs\\lyraChatGLM\\lib\\site-packages\\\
          torch\\_classes.py\", line 51, in load_library\n    torch.ops.load_library(path)\n\
          \  File \"C:\\Users\\ushow_AI\\.conda\\envs\\lyraChatGLM\\lib\\site-packages\\\
          torch\\_ops.py\", line 643, in load_library\n    ctypes.CDLL(path)\n  File\
          \ \"C:\\Users\\ushow_AI\\.conda\\envs\\lyraChatGLM\\lib\\ctypes\\__init__.py\"\
          , line 374, in __init__\n    self._handle = _dlopen(self._name, mode)\n\
          OSError: [WinError 193] %1 \u4E0D\u662F\u6709\u6548\u7684 Win32 \u5E94\u7528\
          \u7A0B\u5E8F\u3002"
        updatedAt: '2023-07-03T02:37:37.596Z'
      numEdits: 1
      reactions: []
    id: 64a23095720ef7b92d3b98bb
    type: comment
  author: ushow
  content: "\u73AF\u5883\uFF1AAnaconda  \uFF0C Python 3.10.11 \uFF0C win10 \u3002\u5E0C\
    \u671B\u5F97\u5230\u60A8\u7684\u5E2E\u52A9\uFF0C\u8C22\u8C22\uFF01\n![\u5FAE\u4FE1\
    \u622A\u56FE_20230703103456.png](https://cdn-uploads.huggingface.co/production/uploads/64a22fb5f824e15453d71940/l0tznBGs4eHmDzeXOrPgK.png)\n\
    \u7CFB\u7EDF\u5F39\u7A97\u5982\u4E0A\uFF0C\u540C\u65F6\u62A5\u9519\u5982\u4E0B\
    \uFF1A\n\n(lyraChatGLM) D:\\lyraChatGLM>python demo.py\nLoading tokenizer from\
    \ .\n[INFO] Load Our Highly Optimized LyraChatGLM6B model\n - head_num.................:\
    \ 32\n - size_per_head............: 128\n - layer_num................: 28\n -\
    \ tensor_para_size.........: 1\n - vocab_size...............: 130528\n - start_id.................:\
    \ 130004\n - end_id...................: 130005\n - weights_data_type........:\
    \ fp16\n - layernorm_eps............: 1e-05\n - inference_data_type......: fp16\n\
    \ - rotary_embedding_dim.....: 64\n - max_seq_len..............: 0\n - pipeline_para_size.......:\
    \ 1\n - shared_contexts_ratio....: 0.0\n - int8_mode................: 0\n - model_path...............:\
    \ .\\models\\1-gpu-fp16.bin\n - cuda_version.............: 11\nLoading tokenizer\
    \ from .\\models\\1-gpu-fp16.bin\nTraceback (most recent call last):\n  File \"\
    D:\\lyraChatGLM\\demo.py\", line 12, in <module>\n    model = LyraChatGLM6B(model_path,\
    \ tokenizer_path, data_type, int8_mode, arch, cuda_version)\n  File \"D:\\lyraChatGLM\\\
    lyraChatGLM\\lyra_glm.py\", line 24, in __init__\n    self.model, self.tokenizer\
    \ = self.load_model_and_tokenizer()\n  File \"D:\\lyraChatGLM\\lyraChatGLM\\lyra_glm.py\"\
    , line 108, in load_model_and_tokenizer\n    model = ChatGLM6BModel(arch=self.arch,**model_args)\n\
    \  File \"D:\\lyraChatGLM\\lyraChatGLM\\model.py\", line 103, in __init__\n  \
    \  torch.classes.load_library(os.path.abspath(lib_path))\n  File \"C:\\Users\\\
    ushow_AI\\.conda\\envs\\lyraChatGLM\\lib\\site-packages\\torch\\_classes.py\"\
    , line 51, in load_library\n    torch.ops.load_library(path)\n  File \"C:\\Users\\\
    ushow_AI\\.conda\\envs\\lyraChatGLM\\lib\\site-packages\\torch\\_ops.py\", line\
    \ 643, in load_library\n    ctypes.CDLL(path)\n  File \"C:\\Users\\ushow_AI\\\
    .conda\\envs\\lyraChatGLM\\lib\\ctypes\\__init__.py\", line 374, in __init__\n\
    \    self._handle = _dlopen(self._name, mode)\nOSError: [WinError 193] %1 \u4E0D\
    \u662F\u6709\u6548\u7684 Win32 \u5E94\u7528\u7A0B\u5E8F\u3002"
  created_at: 2023-07-03 01:21:09+00:00
  edited: true
  hidden: false
  id: 64a23095720ef7b92d3b98bb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d23225ab8c720a51cf571dc8be1d0d4e.svg
      fullname: ushow
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ushow
      type: user
    createdAt: '2023-07-03T02:22:00.000Z'
    data:
      edited: false
      editors:
      - ushow
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.9986479878425598
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d23225ab8c720a51cf571dc8be1d0d4e.svg
          fullname: ushow
          isHf: false
          isPro: false
          name: ushow
          type: user
        html: "<p>\u5728\u7F51\u7EDC\u4E0A\u6CA1\u6709\u627E\u5230\u6709\u7528\u4FE1\
          \u606F\uFF0C\u8BF7\u5927\u5BB6\u5E2E\u5FD9\u5206\u6790\u4E00\u4E0B\u89E3\
          \u51B3\u529E\u6CD5\uFF0C\u611F\u8C22\uFF01</p>\n"
        raw: "\u5728\u7F51\u7EDC\u4E0A\u6CA1\u6709\u627E\u5230\u6709\u7528\u4FE1\u606F\
          \uFF0C\u8BF7\u5927\u5BB6\u5E2E\u5FD9\u5206\u6790\u4E00\u4E0B\u89E3\u51B3\
          \u529E\u6CD5\uFF0C\u611F\u8C22\uFF01"
        updatedAt: '2023-07-03T02:22:00.291Z'
      numEdits: 0
      reactions: []
    id: 64a230c88f953945fa4ba517
    type: comment
  author: ushow
  content: "\u5728\u7F51\u7EDC\u4E0A\u6CA1\u6709\u627E\u5230\u6709\u7528\u4FE1\u606F\
    \uFF0C\u8BF7\u5927\u5BB6\u5E2E\u5FD9\u5206\u6790\u4E00\u4E0B\u89E3\u51B3\u529E\
    \u6CD5\uFF0C\u611F\u8C22\uFF01"
  created_at: 2023-07-03 01:22:00+00:00
  edited: false
  hidden: false
  id: 64a230c88f953945fa4ba517
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/n0RQ_qmhz6_MvTE3gVHNr.jpeg?w=200&h=200&f=face
      fullname: moyanwang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: bigmoyan
      type: user
    createdAt: '2023-07-05T08:09:46.000Z'
    data:
      edited: false
      editors:
      - bigmoyan
      hidden: false
      identifiedLanguage:
        language: zh
        probability: 0.919531524181366
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/n0RQ_qmhz6_MvTE3gVHNr.jpeg?w=200&h=200&f=face
          fullname: moyanwang
          isHf: false
          isPro: false
          name: bigmoyan
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;ushow&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/ushow\">@<span class=\"\
          underline\">ushow</span></a></span>\n\n\t</span></span> \u2026\u2026\u4E0D\
          \u8981\u592A\u79BB\u8C31\uFF0C\u8FD9\u538B\u6839\u5C31\u4E0D\u662Ffor windows\u7684\
          </p>\n"
        raw: "@ushow \u2026\u2026\u4E0D\u8981\u592A\u79BB\u8C31\uFF0C\u8FD9\u538B\u6839\
          \u5C31\u4E0D\u662Ffor windows\u7684"
        updatedAt: '2023-07-05T08:09:46.616Z'
      numEdits: 0
      reactions: []
    id: 64a5254a4c5b04a29614d907
    type: comment
  author: bigmoyan
  content: "@ushow \u2026\u2026\u4E0D\u8981\u592A\u79BB\u8C31\uFF0C\u8FD9\u538B\u6839\
    \u5C31\u4E0D\u662Ffor windows\u7684"
  created_at: 2023-07-05 07:09:46+00:00
  edited: false
  hidden: false
  id: 64a5254a4c5b04a29614d907
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 45
repo_id: TMElyralab/lyraChatGLM
repo_type: model
status: open
target_branch: null
title: "\u6C42\u52A9\uFF01\u62A5\u9519OSError: [WinError 193] %1 \u4E0D\u662F\u6709\
  \u6548\u7684 Win32 \u5E94\u7528\u7A0B\u5E8F\u3002"
