!!python/object:huggingface_hub.community.DiscussionWithDetails
author: jspsoli
conflicting_files: null
created_at: 2023-11-11 01:08:21+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
      fullname: Joao Oliveira
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jspsoli
      type: user
    createdAt: '2023-11-11T01:08:21.000Z'
    data:
      edited: false
      editors:
      - jspsoli
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.439933180809021
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
          fullname: Joao Oliveira
          isHf: false
          isPro: false
          name: jspsoli
          type: user
        html: "<p>Sorry to bother you again.<br>Made a quick conversion of the .onnx\
          \ model to fp16 and compared the results with fp32 on 5 imgs and they were\
          \ exactly the same. Whatever precision is lost - is worth the VRAM tradeoff.<br>I\
          \ want users of my script to be able to download the model directly from\
          \ your page - if possible.</p>\n<p>You can easily convert with this script:</p>\n\
          <p>import os<br>import onnx<br>from onnxconverter_common import float16<br>import\
          \ argparse</p>\n<p>if <strong>name</strong> == \"<strong>main</strong>\"\
          :<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(\"\
          --fp32_model\", type=str, required=True, help=\"Full path for the fp32 .onnx\
          \ model.\")<br>    args = parser.parse_args()</p>\n<pre><code>if os.path.isfile(args.fp32_model)\
          \ and args.fp32_model.lower().endswith(\".onnx\"):\n    new_model_path =\
          \ args.fp32_model.lower().replace(\".onnx\", \"_fp16.onnx\")\n    model\
          \ = onnx.load(args.fp32_model)\n    model_fp16 = float16.convert_float_to_float16(model)\n\
          \    onnx.save(model_fp16, new_model_path)\n    print(f\"Model successfully\
          \ converted and stored in: {new_model_path}\")\nelse:\n    print(\"Invalid\
          \ path!\")\n</code></pre>\n"
        raw: "Sorry to bother you again.\r\nMade a quick conversion of the .onnx model\
          \ to fp16 and compared the results with fp32 on 5 imgs and they were exactly\
          \ the same. Whatever precision is lost - is worth the VRAM tradeoff.\r\n\
          I want users of my script to be able to download the model directly from\
          \ your page - if possible.\r\n\r\nYou can easily convert with this script:\r\
          \n\r\nimport os\r\nimport onnx\r\nfrom onnxconverter_common import float16\r\
          \nimport argparse\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.ArgumentParser()\r\
          \n    parser.add_argument(\"--fp32_model\", type=str, required=True, help=\"\
          Full path for the fp32 .onnx model.\")\r\n    args = parser.parse_args()\r\
          \n\r\n    if os.path.isfile(args.fp32_model) and args.fp32_model.lower().endswith(\"\
          .onnx\"):\r\n        new_model_path = args.fp32_model.lower().replace(\"\
          .onnx\", \"_fp16.onnx\")\r\n        model = onnx.load(args.fp32_model)\r\
          \n        model_fp16 = float16.convert_float_to_float16(model)\r\n     \
          \   onnx.save(model_fp16, new_model_path)\r\n        print(f\"Model successfully\
          \ converted and stored in: {new_model_path}\")\r\n    else:\r\n        print(\"\
          Invalid path!\")"
        updatedAt: '2023-11-11T01:08:21.846Z'
      numEdits: 0
      reactions: []
    id: 654ed40519c62ea90f0057a3
    type: comment
  author: jspsoli
  content: "Sorry to bother you again.\r\nMade a quick conversion of the .onnx model\
    \ to fp16 and compared the results with fp32 on 5 imgs and they were exactly the\
    \ same. Whatever precision is lost - is worth the VRAM tradeoff.\r\nI want users\
    \ of my script to be able to download the model directly from your page - if possible.\r\
    \n\r\nYou can easily convert with this script:\r\n\r\nimport os\r\nimport onnx\r\
    \nfrom onnxconverter_common import float16\r\nimport argparse\r\n\r\nif __name__\
    \ == \"__main__\":\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"\
    --fp32_model\", type=str, required=True, help=\"Full path for the fp32 .onnx model.\"\
    )\r\n    args = parser.parse_args()\r\n\r\n    if os.path.isfile(args.fp32_model)\
    \ and args.fp32_model.lower().endswith(\".onnx\"):\r\n        new_model_path =\
    \ args.fp32_model.lower().replace(\".onnx\", \"_fp16.onnx\")\r\n        model\
    \ = onnx.load(args.fp32_model)\r\n        model_fp16 = float16.convert_float_to_float16(model)\r\
    \n        onnx.save(model_fp16, new_model_path)\r\n        print(f\"Model successfully\
    \ converted and stored in: {new_model_path}\")\r\n    else:\r\n        print(\"\
    Invalid path!\")"
  created_at: 2023-11-11 01:08:21+00:00
  edited: false
  hidden: false
  id: 654ed40519c62ea90f0057a3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/22f73ea9b2b156133e0ce4fd5621e7b9.svg
      fullname: Thouph
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: Thouph
      type: user
    createdAt: '2023-11-11T07:58:55.000Z'
    data:
      edited: false
      editors:
      - Thouph
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7136289477348328
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/22f73ea9b2b156133e0ce4fd5621e7b9.svg
          fullname: Thouph
          isHf: false
          isPro: false
          name: Thouph
          type: user
        html: '<p>ONNX fp16 model added!</p>

          '
        raw: ONNX fp16 model added!
        updatedAt: '2023-11-11T07:58:55.442Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - jspsoli
    id: 654f343f45c0dccd57f4dc57
    type: comment
  author: Thouph
  content: ONNX fp16 model added!
  created_at: 2023-11-11 07:58:55+00:00
  edited: false
  hidden: false
  id: 654f343f45c0dccd57f4dc57
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/db0ae4bcf7e1b08c7240687d607571c3.svg
      fullname: Joao Oliveira
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: jspsoli
      type: user
    createdAt: '2023-11-11T17:17:16.000Z'
    data:
      status: closed
    id: 654fb71cbebf0c4c51e495f7
    type: status-change
  author: jspsoli
  created_at: 2023-11-11 17:17:16+00:00
  id: 654fb71cbebf0c4c51e495f7
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Thouph/eva02-clip-vit-large-7704
repo_type: model
status: closed
target_branch: null
title: '[REQUEST] ONNX fp16'
