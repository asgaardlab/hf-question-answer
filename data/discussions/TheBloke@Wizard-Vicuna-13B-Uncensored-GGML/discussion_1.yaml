!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MichaelBui
conflicting_files: null
created_at: 2023-05-13 10:48:01+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8790ed4b203b1fd78e650e06596e27f5.svg
      fullname: Michael Bui
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MichaelBui
      type: user
    createdAt: '2023-05-13T11:48:01.000Z'
    data:
      edited: false
      editors:
      - MichaelBui
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8790ed4b203b1fd78e650e06596e27f5.svg
          fullname: Michael Bui
          isHf: false
          isPro: false
          name: MichaelBui
          type: user
        html: "<p>I know this is not supported by <code>oobabooga/text-generation-webui</code>\
          \ yet because it's still using old llama.cpp version. However, I'd like\
          \ to create this thread for people to follow up when oobabooga is ready\
          \ \U0001F44D<br>I'm currently watching this issue: <a rel=\"nofollow\" href=\"\
          https://github.com/oobabooga/text-generation-webui/issues/2020\">https://github.com/oobabooga/text-generation-webui/issues/2020</a></p>\n"
        raw: "I know this is not supported by `oobabooga/text-generation-webui` yet\
          \ because it's still using old llama.cpp version. However, I'd like to create\
          \ this thread for people to follow up when oobabooga is ready \U0001F44D\
          \r\nI'm currently watching this issue: https://github.com/oobabooga/text-generation-webui/issues/2020"
        updatedAt: '2023-05-13T11:48:01.373Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - Hanssep123
    id: 645f78f1a1f1dedc46d4fe27
    type: comment
  author: MichaelBui
  content: "I know this is not supported by `oobabooga/text-generation-webui` yet\
    \ because it's still using old llama.cpp version. However, I'd like to create\
    \ this thread for people to follow up when oobabooga is ready \U0001F44D\r\nI'm\
    \ currently watching this issue: https://github.com/oobabooga/text-generation-webui/issues/2020"
  created_at: 2023-05-13 10:48:01+00:00
  edited: false
  hidden: false
  id: 645f78f1a1f1dedc46d4fe27
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/3dd8ff0e53b517d1dbf7f34ef625189a.svg
      fullname: Jakub Strnad
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: creative420
      type: user
    createdAt: '2023-05-13T16:11:56.000Z'
    data:
      edited: false
      editors:
      - creative420
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/3dd8ff0e53b517d1dbf7f34ef625189a.svg
          fullname: Jakub Strnad
          isHf: false
          isPro: false
          name: creative420
          type: user
        html: '<p>I quantized it with the older version f llama.cpp: <a href="https://huggingface.co/creative420/Wizard-Vicuna-13b-Uncensored_old_ggml">https://huggingface.co/creative420/Wizard-Vicuna-13b-Uncensored_old_ggml</a></p>

          '
        raw: 'I quantized it with the older version f llama.cpp: https://huggingface.co/creative420/Wizard-Vicuna-13b-Uncensored_old_ggml'
        updatedAt: '2023-05-13T16:11:56.861Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - MichaelBui
        - mJBHY7L
        - TheBloke
    id: 645fb6cc4357049a57f5aaa3
    type: comment
  author: creative420
  content: 'I quantized it with the older version f llama.cpp: https://huggingface.co/creative420/Wizard-Vicuna-13b-Uncensored_old_ggml'
  created_at: 2023-05-13 15:11:56+00:00
  edited: false
  hidden: false
  id: 645fb6cc4357049a57f5aaa3
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8790ed4b203b1fd78e650e06596e27f5.svg
      fullname: Michael Bui
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MichaelBui
      type: user
    createdAt: '2023-05-13T17:18:24.000Z'
    data:
      edited: false
      editors:
      - MichaelBui
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8790ed4b203b1fd78e650e06596e27f5.svg
          fullname: Michael Bui
          isHf: false
          isPro: false
          name: MichaelBui
          type: user
        html: '<p>FYI, we also can download the version for previous LLaMA from the
          branch <code>previous_llama</code>:<br><a href="https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GGML/tree/previous_llama">https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GGML/tree/previous_llama</a></p>

          '
        raw: 'FYI, we also can download the version for previous LLaMA from the branch
          `previous_llama`:

          https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GGML/tree/previous_llama'
        updatedAt: '2023-05-13T17:18:24.793Z'
      numEdits: 0
      reactions:
      - count: 3
        reaction: "\U0001F44D"
        users:
        - creative420
        - TheBloke
        - SRJee
    id: 645fc66072397238b22f8f3b
    type: comment
  author: MichaelBui
  content: 'FYI, we also can download the version for previous LLaMA from the branch
    `previous_llama`:

    https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GGML/tree/previous_llama'
  created_at: 2023-05-13 16:18:24+00:00
  edited: false
  hidden: false
  id: 645fc66072397238b22f8f3b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8790ed4b203b1fd78e650e06596e27f5.svg
      fullname: Michael Bui
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MichaelBui
      type: user
    createdAt: '2023-05-15T15:14:34.000Z'
    data:
      edited: false
      editors:
      - MichaelBui
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8790ed4b203b1fd78e650e06596e27f5.svg
          fullname: Michael Bui
          isHf: false
          isPro: false
          name: MichaelBui
          type: user
        html: "<p>For who are using oobabooga, you can follow this instruction to\
          \ use the new format of llama:</p>\n<p>Current <code>requirements.txt</code>:</p>\n\
          <pre><code>accelerate==0.19.0\ncolorama\ndatasets\nflexgen==0.1.7\ngradio_client==0.1.4\n\
          gradio==3.25.0\nmarkdown\nnumpy\npandas\nPillow&gt;=9.5.0\npyyaml\nrequests\n\
          rwkv==0.7.3\nsafetensors==0.3.1\nsentencepiece\ntqdm\ngit+https://github.com/huggingface/peft\n\
          transformers==4.28.1\nbitsandbytes==0.38.1; platform_system != \"Windows\"\
          \nllama-cpp-python==0.1.45; platform_system != \"Windows\"\nhttps://github.com/abetlen/llama-cpp-python/releases/download/v0.1.45/llama_cpp_python-0.1.45-cp310-cp310-win_amd64.whl;\
          \ platform_system == \"Windows\"\n</code></pre>\n<ol>\n<li>Change <code>llama-cpp-python==0.1.45</code>\
          \ to <code>llama-cpp-python==0.1.50</code></li>\n<li>Run <code>pip install\
          \ -r requirements.txt</code></li>\n</ol>\n<p>Re-run your normal oobabooga\
          \ with the models in the new llama format \U0001F44D</p>\n"
        raw: "For who are using oobabooga, you can follow this instruction to use\
          \ the new format of llama:\n\nCurrent `requirements.txt`:\n```\naccelerate==0.19.0\n\
          colorama\ndatasets\nflexgen==0.1.7\ngradio_client==0.1.4\ngradio==3.25.0\n\
          markdown\nnumpy\npandas\nPillow>=9.5.0\npyyaml\nrequests\nrwkv==0.7.3\n\
          safetensors==0.3.1\nsentencepiece\ntqdm\ngit+https://github.com/huggingface/peft\n\
          transformers==4.28.1\nbitsandbytes==0.38.1; platform_system != \"Windows\"\
          \nllama-cpp-python==0.1.45; platform_system != \"Windows\"\nhttps://github.com/abetlen/llama-cpp-python/releases/download/v0.1.45/llama_cpp_python-0.1.45-cp310-cp310-win_amd64.whl;\
          \ platform_system == \"Windows\"\n```\n\n1. Change `llama-cpp-python==0.1.45`\
          \ to `llama-cpp-python==0.1.50`\n2. Run `pip install -r requirements.txt`\n\
          \nRe-run your normal oobabooga with the models in the new llama format \U0001F44D"
        updatedAt: '2023-05-15T15:14:34.391Z'
      numEdits: 0
      reactions: []
    id: 64624c5a904bbc4cf2df8122
    type: comment
  author: MichaelBui
  content: "For who are using oobabooga, you can follow this instruction to use the\
    \ new format of llama:\n\nCurrent `requirements.txt`:\n```\naccelerate==0.19.0\n\
    colorama\ndatasets\nflexgen==0.1.7\ngradio_client==0.1.4\ngradio==3.25.0\nmarkdown\n\
    numpy\npandas\nPillow>=9.5.0\npyyaml\nrequests\nrwkv==0.7.3\nsafetensors==0.3.1\n\
    sentencepiece\ntqdm\ngit+https://github.com/huggingface/peft\ntransformers==4.28.1\n\
    bitsandbytes==0.38.1; platform_system != \"Windows\"\nllama-cpp-python==0.1.45;\
    \ platform_system != \"Windows\"\nhttps://github.com/abetlen/llama-cpp-python/releases/download/v0.1.45/llama_cpp_python-0.1.45-cp310-cp310-win_amd64.whl;\
    \ platform_system == \"Windows\"\n```\n\n1. Change `llama-cpp-python==0.1.45`\
    \ to `llama-cpp-python==0.1.50`\n2. Run `pip install -r requirements.txt`\n\n\
    Re-run your normal oobabooga with the models in the new llama format \U0001F44D"
  created_at: 2023-05-15 14:14:34+00:00
  edited: false
  hidden: false
  id: 64624c5a904bbc4cf2df8122
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-15T15:21:08.000Z'
    data:
      edited: true
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Thanks Michael but didn''t text-gen-ui already update?  So I think
          you just need to update text-gen-ui normally and you''ll get this commit:<br><a
          rel="nofollow" href="https://github.com/oobabooga/text-generation-webui/commit/eee986348c3ef1cb0070b287ae865a682084922d">https://github.com/oobabooga/text-generation-webui/commit/eee986348c3ef1cb0070b287ae865a682084922d</a></p>

          '
        raw: 'Thanks Michael but didn''t text-gen-ui already update?  So I think you
          just need to update text-gen-ui normally and you''ll get this commit:

          https://github.com/oobabooga/text-generation-webui/commit/eee986348c3ef1cb0070b287ae865a682084922d'
        updatedAt: '2023-05-15T15:21:35.652Z'
      numEdits: 1
      reactions: []
    id: 64624de4cce92c7d882c6334
    type: comment
  author: TheBloke
  content: 'Thanks Michael but didn''t text-gen-ui already update?  So I think you
    just need to update text-gen-ui normally and you''ll get this commit:

    https://github.com/oobabooga/text-generation-webui/commit/eee986348c3ef1cb0070b287ae865a682084922d'
  created_at: 2023-05-15 14:21:08+00:00
  edited: true
  hidden: false
  id: 64624de4cce92c7d882c6334
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/8790ed4b203b1fd78e650e06596e27f5.svg
      fullname: Michael Bui
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MichaelBui
      type: user
    createdAt: '2023-05-15T15:39:08.000Z'
    data:
      edited: false
      editors:
      - MichaelBui
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/8790ed4b203b1fd78e650e06596e27f5.svg
          fullname: Michael Bui
          isHf: false
          isPro: false
          name: MichaelBui
          type: user
        html: "<p>Oh yeah, I didn't notice it. Was quite busy since yesterday &amp;\
          \ share it as soon as I'm back. This world is moving blazing fast \U0001F605\
          <br>Btw, thanks for sharing this great model. Really love it \U0001F60D\
          </p>\n"
        raw: "Oh yeah, I didn't notice it. Was quite busy since yesterday & share\
          \ it as soon as I'm back. This world is moving blazing fast \U0001F605\n\
          Btw, thanks for sharing this great model. Really love it \U0001F60D"
        updatedAt: '2023-05-15T15:39:08.490Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - TheBloke
      relatedEventId: 6462521ccce92c7d882c8af7
    id: 6462521ccce92c7d882c8af6
    type: comment
  author: MichaelBui
  content: "Oh yeah, I didn't notice it. Was quite busy since yesterday & share it\
    \ as soon as I'm back. This world is moving blazing fast \U0001F605\nBtw, thanks\
    \ for sharing this great model. Really love it \U0001F60D"
  created_at: 2023-05-15 14:39:08+00:00
  edited: false
  hidden: false
  id: 6462521ccce92c7d882c8af6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/8790ed4b203b1fd78e650e06596e27f5.svg
      fullname: Michael Bui
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MichaelBui
      type: user
    createdAt: '2023-05-15T15:39:08.000Z'
    data:
      status: closed
    id: 6462521ccce92c7d882c8af7
    type: status-change
  author: MichaelBui
  created_at: 2023-05-15 14:39:08+00:00
  id: 6462521ccce92c7d882c8af7
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/Wizard-Vicuna-13B-Uncensored-GGML
repo_type: model
status: closed
target_branch: null
title: Support for oobabooga/text-generation-webui
