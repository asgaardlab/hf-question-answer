!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tibetgao
conflicting_files: null
created_at: 2024-01-18 03:39:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/0bf0372ba3465dadbd091bd0a0cc9e03.svg
      fullname: Tian Gao
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tibetgao
      type: user
    createdAt: '2024-01-18T03:39:08.000Z'
    data:
      edited: false
      editors:
      - tibetgao
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9435238242149353
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/0bf0372ba3465dadbd091bd0a0cc9e03.svg
          fullname: Tian Gao
          isHf: false
          isPro: false
          name: tibetgao
          type: user
        html: '<p>Hi there,<br>According to your tech report, you have mentioned that
          there is a position-aware vision-language adaptor, which comprise a single-layer
          cross-attention. However, though reading your code I can''t find this module,
          but only a concatenation of the visual embedding and the hidden state.  Will
          you kindly point it out please?</p>

          <p>Best regards</p>

          '
        raw: "Hi there,\r\nAccording to your tech report, you have mentioned that\
          \ there is a position-aware vision-language adaptor, which comprise a single-layer\
          \ cross-attention. However, though reading your code I can't find this module,\
          \ but only a concatenation of the visual embedding and the hidden state.\
          \  Will you kindly point it out please?\r\n\r\nBest regards"
        updatedAt: '2024-01-18T03:39:08.652Z'
      numEdits: 0
      reactions: []
    id: 65a89d5c2984fa7203d9dd8f
    type: comment
  author: tibetgao
  content: "Hi there,\r\nAccording to your tech report, you have mentioned that there\
    \ is a position-aware vision-language adaptor, which comprise a single-layer cross-attention.\
    \ However, though reading your code I can't find this module, but only a concatenation\
    \ of the visual embedding and the hidden state.  Will you kindly point it out\
    \ please?\r\n\r\nBest regards"
  created_at: 2024-01-18 03:39:08+00:00
  edited: false
  hidden: false
  id: 65a89d5c2984fa7203d9dd8f
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 9
repo_id: Qwen/Qwen-VL-Chat
repo_type: model
status: open
target_branch: null
title: A confusion on cross-attention module
