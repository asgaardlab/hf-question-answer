!!python/object:huggingface_hub.community.DiscussionWithDetails
author: JosephusCheung
conflicting_files: null
created_at: 2023-08-23 15:03:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f54abfaa4be54e61c1052720eb498703.svg
      fullname: "Jos\xE9phus Cheung"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JosephusCheung
      type: user
    createdAt: '2023-08-23T16:03:14.000Z'
    data:
      edited: false
      editors:
      - JosephusCheung
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9767246842384338
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f54abfaa4be54e61c1052720eb498703.svg
          fullname: "Jos\xE9phus Cheung"
          isHf: false
          isPro: false
          name: JosephusCheung
          type: user
        html: '<p>After testing the Vision part from this repo with the Qwen-7B-Chat
          weights, it was observed that certain tasks such as Chinese OCR are coupled
          with the attention mechanism of this (VL-Chat) specific version of LLM,
          while other tasks like English OCR, general Chinese, and English VQA are
          not coupled with the LLM (based on Qwen-7B-Base). </p>

          <p>It can be inferred that in order to achieve better scores in certain
          tasks, some tasks were trained on the LLM, and there is reason to believe
          that the LLM has degraded. I would like you to examine the benchmark test
          results of the LLM.</p>

          '
        raw: "After testing the Vision part from this repo with the Qwen-7B-Chat weights,\
          \ it was observed that certain tasks such as Chinese OCR are coupled with\
          \ the attention mechanism of this (VL-Chat) specific version of LLM, while\
          \ other tasks like English OCR, general Chinese, and English VQA are not\
          \ coupled with the LLM (based on Qwen-7B-Base). \r\n\r\nIt can be inferred\
          \ that in order to achieve better scores in certain tasks, some tasks were\
          \ trained on the LLM, and there is reason to believe that the LLM has degraded.\
          \ I would like you to examine the benchmark test results of the LLM."
        updatedAt: '2023-08-23T16:03:14.339Z'
      numEdits: 0
      reactions: []
    id: 64e62dc21e767a6a140ff287
    type: comment
  author: JosephusCheung
  content: "After testing the Vision part from this repo with the Qwen-7B-Chat weights,\
    \ it was observed that certain tasks such as Chinese OCR are coupled with the\
    \ attention mechanism of this (VL-Chat) specific version of LLM, while other tasks\
    \ like English OCR, general Chinese, and English VQA are not coupled with the\
    \ LLM (based on Qwen-7B-Base). \r\n\r\nIt can be inferred that in order to achieve\
    \ better scores in certain tasks, some tasks were trained on the LLM, and there\
    \ is reason to believe that the LLM has degraded. I would like you to examine\
    \ the benchmark test results of the LLM."
  created_at: 2023-08-23 15:03:14+00:00
  edited: false
  hidden: false
  id: 64e62dc21e767a6a140ff287
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/93d9e397ae6079ea0672d6b54234f388.svg
      fullname: Shijie Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: simonJJJ
      type: user
    createdAt: '2023-08-23T16:17:24.000Z'
    data:
      edited: false
      editors:
      - simonJJJ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9591853022575378
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/93d9e397ae6079ea0672d6b54234f388.svg
          fullname: Shijie Wang
          isHf: false
          isPro: false
          name: simonJJJ
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;JosephusCheung&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/JosephusCheung\"\
          >@<span class=\"underline\">JosephusCheung</span></a></span>\n\n\t</span></span>,\
          \ thanks for your point. We have fine-tuned the LLM during the training\
          \ of Qwen-VL, so the LLM weights are different from Qwen-7B &amp; Chat.\
          \ There is the potential that the fine-tuned LLM has degraded. We will examine\
          \ the benchmark test results of the fine-tuned LLM sonn.</p>\n"
        raw: Hi @JosephusCheung, thanks for your point. We have fine-tuned the LLM
          during the training of Qwen-VL, so the LLM weights are different from Qwen-7B
          & Chat. There is the potential that the fine-tuned LLM has degraded. We
          will examine the benchmark test results of the fine-tuned LLM sonn.
        updatedAt: '2023-08-23T16:17:24.623Z'
      numEdits: 0
      reactions: []
    id: 64e63114b1a130543001b884
    type: comment
  author: simonJJJ
  content: Hi @JosephusCheung, thanks for your point. We have fine-tuned the LLM during
    the training of Qwen-VL, so the LLM weights are different from Qwen-7B & Chat.
    There is the potential that the fine-tuned LLM has degraded. We will examine the
    benchmark test results of the fine-tuned LLM sonn.
  created_at: 2023-08-23 15:17:24+00:00
  edited: false
  hidden: false
  id: 64e63114b1a130543001b884
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/f54abfaa4be54e61c1052720eb498703.svg
      fullname: "Jos\xE9phus Cheung"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JosephusCheung
      type: user
    createdAt: '2023-08-23T16:20:46.000Z'
    data:
      edited: false
      editors:
      - JosephusCheung
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9474289417266846
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/f54abfaa4be54e61c1052720eb498703.svg
          fullname: "Jos\xE9phus Cheung"
          isHf: false
          isPro: false
          name: JosephusCheung
          type: user
        html: '<p>If possible, I would like to consider incorporating these changes
          by using adapters for on-the-fly loading during image reasoning only, in
          order to modify the attention weights of LLM. I believe that from a practical
          standpoint, this can be done without affecting the effectiveness of text
          reasoning. If there is no official implementation available, I would also
          consider implementing it myself.</p>

          '
        raw: If possible, I would like to consider incorporating these changes by
          using adapters for on-the-fly loading during image reasoning only, in order
          to modify the attention weights of LLM. I believe that from a practical
          standpoint, this can be done without affecting the effectiveness of text
          reasoning. If there is no official implementation available, I would also
          consider implementing it myself.
        updatedAt: '2023-08-23T16:20:46.452Z'
      numEdits: 0
      reactions: []
    id: 64e631de4e0203df3b82c065
    type: comment
  author: JosephusCheung
  content: If possible, I would like to consider incorporating these changes by using
    adapters for on-the-fly loading during image reasoning only, in order to modify
    the attention weights of LLM. I believe that from a practical standpoint, this
    can be done without affecting the effectiveness of text reasoning. If there is
    no official implementation available, I would also consider implementing it myself.
  created_at: 2023-08-23 15:20:46+00:00
  edited: false
  hidden: false
  id: 64e631de4e0203df3b82c065
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/93d9e397ae6079ea0672d6b54234f388.svg
      fullname: Shijie Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: simonJJJ
      type: user
    createdAt: '2023-08-23T16:29:18.000Z'
    data:
      edited: false
      editors:
      - simonJJJ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9207949638366699
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/93d9e397ae6079ea0672d6b54234f388.svg
          fullname: Shijie Wang
          isHf: false
          isPro: false
          name: simonJJJ
          type: user
        html: '<p>Sure! You can use LoRA or other adapter techniques. Due to the computation
          budget, we don''t implement it. You can try it yourself and feel free to
          contact us with any issue.</p>

          '
        raw: Sure! You can use LoRA or other adapter techniques. Due to the computation
          budget, we don't implement it. You can try it yourself and feel free to
          contact us with any issue.
        updatedAt: '2023-08-23T16:29:18.097Z'
      numEdits: 0
      reactions: []
    id: 64e633de25d7ac1df8b3866b
    type: comment
  author: simonJJJ
  content: Sure! You can use LoRA or other adapter techniques. Due to the computation
    budget, we don't implement it. You can try it yourself and feel free to contact
    us with any issue.
  created_at: 2023-08-23 15:29:18+00:00
  edited: false
  hidden: false
  id: 64e633de25d7ac1df8b3866b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/f54abfaa4be54e61c1052720eb498703.svg
      fullname: "Jos\xE9phus Cheung"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JosephusCheung
      type: user
    createdAt: '2023-09-06T15:50:47.000Z'
    data:
      status: closed
    id: 64f89fd70590f3db14a3e3e1
    type: status-change
  author: JosephusCheung
  created_at: 2023-09-06 14:50:47+00:00
  id: 64f89fd70590f3db14a3e3e1
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Qwen/Qwen-VL-Chat
repo_type: model
status: closed
target_branch: null
title: Coupling specific tasks with LM-attn poses potential risks of LLM degradation.
