!!python/object:huggingface_hub.community.DiscussionWithDetails
author: edwardDali
conflicting_files: null
created_at: 2023-08-09 06:42:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1d1de0691cd0f64062591a5a96d09239.svg
      fullname: eduardT
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: edwardDali
      type: user
    createdAt: '2023-08-09T07:42:04.000Z'
    data:
      edited: false
      editors:
      - edwardDali
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9639119505882263
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1d1de0691cd0f64062591a5a96d09239.svg
          fullname: eduardT
          isHf: false
          isPro: false
          name: edwardDali
          type: user
        html: '<p>Please add a ggml version as well. Thank you for your efforts!</p>

          '
        raw: Please add a ggml version as well. Thank you for your efforts!
        updatedAt: '2023-08-09T07:42:04.837Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - basiliskinstitute
    id: 64d3434cdafee18fafb29718
    type: comment
  author: edwardDali
  content: Please add a ggml version as well. Thank you for your efforts!
  created_at: 2023-08-09 06:42:04+00:00
  edited: false
  hidden: false
  id: 64d3434cdafee18fafb29718
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/636e952267692798149c7a1a/8Jrnvw7JheURWzI5JnoxJ.jpeg?w=200&h=200&f=face
      fullname: Cheshireai
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: basiliskinstitute
      type: user
    createdAt: '2023-08-09T09:02:03.000Z'
    data:
      edited: false
      editors:
      - basiliskinstitute
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9023850560188293
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/636e952267692798149c7a1a/8Jrnvw7JheURWzI5JnoxJ.jpeg?w=200&h=200&f=face
          fullname: Cheshireai
          isHf: false
          isPro: false
          name: basiliskinstitute
          type: user
        html: '<p>Qwen is a different architecture from llama so someone will need
          to figure out how to get it working with ggml. Way above my pay grade. I
          just used the qwen-support branch of AutoGPTQ: <a rel="nofollow" href="https://github.com/PanQiWei/AutoGPTQ/tree/support-qwen">https://github.com/PanQiWei/AutoGPTQ/tree/support-qwen</a>.</p>

          <p>If someone works out the code for ggml I will happily convert it any
          which way. </p>

          '
        raw: 'Qwen is a different architecture from llama so someone will need to
          figure out how to get it working with ggml. Way above my pay grade. I just
          used the qwen-support branch of AutoGPTQ: https://github.com/PanQiWei/AutoGPTQ/tree/support-qwen.


          If someone works out the code for ggml I will happily convert it any which
          way. '
        updatedAt: '2023-08-09T09:02:03.719Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - edwardDali
    id: 64d3560b1074f37ed54264fc
    type: comment
  author: basiliskinstitute
  content: 'Qwen is a different architecture from llama so someone will need to figure
    out how to get it working with ggml. Way above my pay grade. I just used the qwen-support
    branch of AutoGPTQ: https://github.com/PanQiWei/AutoGPTQ/tree/support-qwen.


    If someone works out the code for ggml I will happily convert it any which way. '
  created_at: 2023-08-09 08:02:03+00:00
  edited: false
  hidden: false
  id: 64d3560b1074f37ed54264fc
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: openerotica/Qwen-7B-GPTQ
repo_type: model
status: open
target_branch: null
title: Ggml version?
