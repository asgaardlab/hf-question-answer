!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Phil337
conflicting_files: null
created_at: 2023-11-05 19:26:59+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-11-05T19:26:59.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9811932444572449
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>I tested the top ~12 13b LLMs and the best performing one was AYT.
          That is until I came across this one. Must have missed it because it wasn''t
          on the leaderboard.</p>

          <p>However, the top Mistral 7bs (Dolphin 2.1 and Zephyr Beta) are now performing
          slightly better than both AYT and Xwin 0.2 across a wide range of tests,
          which makes me think if you made a Mistral it would be the best performing
          13b or smaller LLM.  </p>

          '
        raw: "I tested the top ~12 13b LLMs and the best performing one was AYT. That\
          \ is until I came across this one. Must have missed it because it wasn't\
          \ on the leaderboard.\r\n\r\nHowever, the top Mistral 7bs (Dolphin 2.1 and\
          \ Zephyr Beta) are now performing slightly better than both AYT and Xwin\
          \ 0.2 across a wide range of tests, which makes me think if you made a Mistral\
          \ it would be the best performing 13b or smaller LLM.  "
        updatedAt: '2023-11-05T19:26:59.089Z'
      numEdits: 0
      reactions: []
    id: 6547ec836b1695ac33d70f72
    type: comment
  author: Phil337
  content: "I tested the top ~12 13b LLMs and the best performing one was AYT. That\
    \ is until I came across this one. Must have missed it because it wasn't on the\
    \ leaderboard.\r\n\r\nHowever, the top Mistral 7bs (Dolphin 2.1 and Zephyr Beta)\
    \ are now performing slightly better than both AYT and Xwin 0.2 across a wide\
    \ range of tests, which makes me think if you made a Mistral it would be the best\
    \ performing 13b or smaller LLM.  "
  created_at: 2023-11-05 19:26:59+00:00
  edited: false
  hidden: false
  id: 6547ec836b1695ac33d70f72
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-11-06T06:12:27.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9298999309539795
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>I find the contrasting strengths of 13b LLama 2 AYT and Xwin 0.2
          fascinating.</p>

          <p>AYT is the "smartest" and most "talented" 13b Llama 2. It can solve tricky
          logic, math and coding problems that Xwin 0.2 can''t. It can also write
          technically superior stories and poems. Sure enough AYT scores notably higher
          on objective tests (e.g. 65.5 on Hugging Face).</p>

          <p>However, Xwin 0.2 is basically better at everything else. For example,
          it wrote a story about the TV show Friends and got all their jobs, personalities...
          correct (AYT kept making absurd mistakes, such as having the siblings Ross
          and Monica date). Xwin also respected my long list of prompt directions.</p>

          <p>Xwin 0.2 basically acts like the friendly and helpful average IQ receptionist,
          while AYT acts like the brainy and antisocial IT guys down in the basement.
          Why do LLMs split like this? Why can''t someone make a smart chat bot? Would
          making Xwin 0.2 "smarter" by including a large amount of explanation/instruction
          tuning also make it score much lower on tests like AlpacaEval?</p>

          '
        raw: 'I find the contrasting strengths of 13b LLama 2 AYT and Xwin 0.2 fascinating.


          AYT is the "smartest" and most "talented" 13b Llama 2. It can solve tricky
          logic, math and coding problems that Xwin 0.2 can''t. It can also write
          technically superior stories and poems. Sure enough AYT scores notably higher
          on objective tests (e.g. 65.5 on Hugging Face).


          However, Xwin 0.2 is basically better at everything else. For example, it
          wrote a story about the TV show Friends and got all their jobs, personalities...
          correct (AYT kept making absurd mistakes, such as having the siblings Ross
          and Monica date). Xwin also respected my long list of prompt directions.


          Xwin 0.2 basically acts like the friendly and helpful average IQ receptionist,
          while AYT acts like the brainy and antisocial IT guys down in the basement.
          Why do LLMs split like this? Why can''t someone make a smart chat bot? Would
          making Xwin 0.2 "smarter" by including a large amount of explanation/instruction
          tuning also make it score much lower on tests like AlpacaEval?'
        updatedAt: '2023-11-06T06:12:27.034Z'
      numEdits: 0
      reactions: []
    id: 654883cb96c46859c22f7295
    type: comment
  author: Phil337
  content: 'I find the contrasting strengths of 13b LLama 2 AYT and Xwin 0.2 fascinating.


    AYT is the "smartest" and most "talented" 13b Llama 2. It can solve tricky logic,
    math and coding problems that Xwin 0.2 can''t. It can also write technically superior
    stories and poems. Sure enough AYT scores notably higher on objective tests (e.g.
    65.5 on Hugging Face).


    However, Xwin 0.2 is basically better at everything else. For example, it wrote
    a story about the TV show Friends and got all their jobs, personalities... correct
    (AYT kept making absurd mistakes, such as having the siblings Ross and Monica
    date). Xwin also respected my long list of prompt directions.


    Xwin 0.2 basically acts like the friendly and helpful average IQ receptionist,
    while AYT acts like the brainy and antisocial IT guys down in the basement. Why
    do LLMs split like this? Why can''t someone make a smart chat bot? Would making
    Xwin 0.2 "smarter" by including a large amount of explanation/instruction tuning
    also make it score much lower on tests like AlpacaEval?'
  created_at: 2023-11-06 06:12:27+00:00
  edited: false
  hidden: false
  id: 654883cb96c46859c22f7295
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
      fullname: Yu
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Yhyu13
      type: user
    createdAt: '2023-11-06T07:04:47.000Z'
    data:
      edited: false
      editors:
      - Yhyu13
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9572919011116028
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/19f9eeb9281b47b34f68c312092ca468.svg
          fullname: Yu
          isHf: false
          isPro: false
          name: Yhyu13
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Phil337&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/Phil337\">@<span class=\"\
          underline\">Phil337</span></a></span>\n\n\t</span></span> Care to point\
          \ at which AYT model that you were referring to? Just curious. Is it this\
          \ one? <a href=\"https://huggingface.co/posicube/Llama2-chat-AYT-13B\">https://huggingface.co/posicube/Llama2-chat-AYT-13B</a></p>\n\
          <p>By AYT author :</p>\n<blockquote>\n<p>We hypotheize that if we find a\
          \ method to ensemble the top rankers in each benchmark effectively, its\
          \ performance maximizes as well.</p>\n</blockquote>\n<p>I believe the difference\
          \ are made by their fine-tuning method. AYT is enabled by fine-tuning with\
          \ best sft datasets (OpenOrca, Alpaca), whereas Xwin is fine-tuned by some\
          \ WIP state of the art RLHF method.</p>\n<p>There is no promise that Xwin\
          \ v0.2 has used the same dataaset that AYT has been using. </p>\n<p>So surely\
          \ Xwin would performance less than AYT on benchmarks where modesl fine-tuned\
          \ by OpenOrca, Alpaca would succeed, but Xwin exceled on AlpacaEval due\
          \ to its RLHF-ed nature by being more \"human-preferred\".</p>\n"
        raw: "@Phil337 Care to point at which AYT model that you were referring to?\
          \ Just curious. Is it this one? https://huggingface.co/posicube/Llama2-chat-AYT-13B\n\
          \nBy AYT author :\n> We hypotheize that if we find a method to ensemble\
          \ the top rankers in each benchmark effectively, its performance maximizes\
          \ as well.\n\n\nI believe the difference are made by their fine-tuning method.\
          \ AYT is enabled by fine-tuning with best sft datasets (OpenOrca, Alpaca),\
          \ whereas Xwin is fine-tuned by some WIP state of the art RLHF method.\n\
          \nThere is no promise that Xwin v0.2 has used the same dataaset that AYT\
          \ has been using. \n\nSo surely Xwin would performance less than AYT on\
          \ benchmarks where modesl fine-tuned by OpenOrca, Alpaca would succeed,\
          \ but Xwin exceled on AlpacaEval due to its RLHF-ed nature by being more\
          \ \"human-preferred\".\n\n"
        updatedAt: '2023-11-06T07:04:47.179Z'
      numEdits: 0
      reactions: []
    id: 6548900fcf50edb69f33be5c
    type: comment
  author: Yhyu13
  content: "@Phil337 Care to point at which AYT model that you were referring to?\
    \ Just curious. Is it this one? https://huggingface.co/posicube/Llama2-chat-AYT-13B\n\
    \nBy AYT author :\n> We hypotheize that if we find a method to ensemble the top\
    \ rankers in each benchmark effectively, its performance maximizes as well.\n\n\
    \nI believe the difference are made by their fine-tuning method. AYT is enabled\
    \ by fine-tuning with best sft datasets (OpenOrca, Alpaca), whereas Xwin is fine-tuned\
    \ by some WIP state of the art RLHF method.\n\nThere is no promise that Xwin v0.2\
    \ has used the same dataaset that AYT has been using. \n\nSo surely Xwin would\
    \ performance less than AYT on benchmarks where modesl fine-tuned by OpenOrca,\
    \ Alpaca would succeed, but Xwin exceled on AlpacaEval due to its RLHF-ed nature\
    \ by being more \"human-preferred\".\n\n"
  created_at: 2023-11-06 07:04:47+00:00
  edited: false
  hidden: false
  id: 6548900fcf50edb69f33be5c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
      fullname: Phil Foster
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Phil337
      type: user
    createdAt: '2023-11-06T07:38:39.000Z'
    data:
      edited: false
      editors:
      - Phil337
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9436939358711243
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/eb73653279d1996ec4ecd6477049caea.svg
          fullname: Phil Foster
          isHf: false
          isPro: false
          name: Phil337
          type: user
        html: '<p>Yes, that''s the AYT I''m using.</p>

          <p>I prefer Xwin because respecting the prompt and facts (e.g. not having
          siblings date in fan fiction) is more important to be than marginally better
          logic, math, coding and writing.</p>

          <p>It''s just a little frustrating that having both in the same LLM doesn''t
          appear to be possible. Making a high performing LLM like Mistral 7b Dolphin
          2.1 (67) more human-preferred reduces its objective performance, while making
          the best human-preferred LLM like Xwin perform better on objective tests
          by adding more explanation/instruction tuning appears to reduce its human-preferred
          scores on tests like AlpacaEval.</p>

          '
        raw: 'Yes, that''s the AYT I''m using.


          I prefer Xwin because respecting the prompt and facts (e.g. not having siblings
          date in fan fiction) is more important to be than marginally better logic,
          math, coding and writing.


          It''s just a little frustrating that having both in the same LLM doesn''t
          appear to be possible. Making a high performing LLM like Mistral 7b Dolphin
          2.1 (67) more human-preferred reduces its objective performance, while making
          the best human-preferred LLM like Xwin perform better on objective tests
          by adding more explanation/instruction tuning appears to reduce its human-preferred
          scores on tests like AlpacaEval.'
        updatedAt: '2023-11-06T07:38:39.826Z'
      numEdits: 0
      reactions: []
    id: 654897ff33972a012f9bbe6d
    type: comment
  author: Phil337
  content: 'Yes, that''s the AYT I''m using.


    I prefer Xwin because respecting the prompt and facts (e.g. not having siblings
    date in fan fiction) is more important to be than marginally better logic, math,
    coding and writing.


    It''s just a little frustrating that having both in the same LLM doesn''t appear
    to be possible. Making a high performing LLM like Mistral 7b Dolphin 2.1 (67)
    more human-preferred reduces its objective performance, while making the best
    human-preferred LLM like Xwin perform better on objective tests by adding more
    explanation/instruction tuning appears to reduce its human-preferred scores on
    tests like AlpacaEval.'
  created_at: 2023-11-06 07:38:39+00:00
  edited: false
  hidden: false
  id: 654897ff33972a012f9bbe6d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: Xwin-LM/Xwin-LM-13B-V0.2
repo_type: model
status: open
target_branch: null
title: This is probably the best 13b. Hope you're considering making a Mistral.
