!!python/object:huggingface_hub.community.DiscussionWithDetails
author: deleted
conflicting_files: null
created_at: 2023-08-11 12:39:05+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    createdAt: '2023-08-11T13:39:05.000Z'
    data:
      edited: false
      editors:
      - deleted
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.18847188353538513
      isReport: false
      latest:
        html: "<p>\u041F\u0440\u0438 \u043F\u043E\u043F\u044B\u0442\u043A\u0435 \u0433\
          \u0435\u043D\u0435\u0440\u0430\u0446\u0438\u0438 \u043D\u0438\u0447\u0435\
          \u0433\u043E \u043D\u0435 \u043F\u0440\u043E\u0438\u0441\u0445\u043E\u0434\
          \u0438\u0442, \u0432 \u043A\u043E\u043D\u0441\u043E\u043B\u0438 \u043E\u0448\
          \u0438\u0431\u043A\u0438:<br>Traceback (most recent call last):<br>  File\
          \ \"E:\\ai\\oobabooga_windows_GPU\\text-generation-webui\\modules\\callbacks.py\"\
          , line 55, in gentask<br>    ret = self.mfunc(callback=_callback, *args,\
          \ **self.kwargs)<br>  File \"E:\\ai\\oobabooga_windows_GPU\\text-generation-webui\\\
          modules\\text_generation.py\", line 293, in generate_with_callback<br> \
          \   shared.model.generate(**kwargs)<br>  File \"E:\\ai\\oobabooga_windows_GPU\\\
          installer_files\\env\\lib\\site-packages\\torch\\utils_contextlib.py\",\
          \ line 115, in decorate_context<br>    return func(*args, **kwargs)<br>\
          \  File \"E:\\ai\\oobabooga_windows_GPU\\installer_files\\env\\lib\\site-packages\\\
          transformers\\generation\\utils.py\", line 1296, in generate<br>    eos_token_id\
          \ = eos_token_id[0]<br>IndexError: list index out of range</p>\n"
        raw: "\u041F\u0440\u0438 \u043F\u043E\u043F\u044B\u0442\u043A\u0435 \u0433\
          \u0435\u043D\u0435\u0440\u0430\u0446\u0438\u0438 \u043D\u0438\u0447\u0435\
          \u0433\u043E \u043D\u0435 \u043F\u0440\u043E\u0438\u0441\u0445\u043E\u0434\
          \u0438\u0442, \u0432 \u043A\u043E\u043D\u0441\u043E\u043B\u0438 \u043E\u0448\
          \u0438\u0431\u043A\u0438:\r\nTraceback (most recent call last):\r\n  File\
          \ \"E:\\ai\\oobabooga_windows_GPU\\text-generation-webui\\modules\\callbacks.py\"\
          , line 55, in gentask\r\n    ret = self.mfunc(callback=_callback, *args,\
          \ **self.kwargs)\r\n  File \"E:\\ai\\oobabooga_windows_GPU\\text-generation-webui\\\
          modules\\text_generation.py\", line 293, in generate_with_callback\r\n \
          \   shared.model.generate(**kwargs)\r\n  File \"E:\\ai\\oobabooga_windows_GPU\\\
          installer_files\\env\\lib\\site-packages\\torch\\utils\\_contextlib.py\"\
          , line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n\
          \  File \"E:\\ai\\oobabooga_windows_GPU\\installer_files\\env\\lib\\site-packages\\\
          transformers\\generation\\utils.py\", line 1296, in generate\r\n    eos_token_id\
          \ = eos_token_id[0]\r\nIndexError: list index out of range"
        updatedAt: '2023-08-11T13:39:05.755Z'
      numEdits: 0
      reactions: []
    id: 64d639f9a146b1c0a667c93f
    type: comment
  author: deleted
  content: "\u041F\u0440\u0438 \u043F\u043E\u043F\u044B\u0442\u043A\u0435 \u0433\u0435\
    \u043D\u0435\u0440\u0430\u0446\u0438\u0438 \u043D\u0438\u0447\u0435\u0433\u043E\
    \ \u043D\u0435 \u043F\u0440\u043E\u0438\u0441\u0445\u043E\u0434\u0438\u0442, \u0432\
    \ \u043A\u043E\u043D\u0441\u043E\u043B\u0438 \u043E\u0448\u0438\u0431\u043A\u0438\
    :\r\nTraceback (most recent call last):\r\n  File \"E:\\ai\\oobabooga_windows_GPU\\\
    text-generation-webui\\modules\\callbacks.py\", line 55, in gentask\r\n    ret\
    \ = self.mfunc(callback=_callback, *args, **self.kwargs)\r\n  File \"E:\\ai\\\
    oobabooga_windows_GPU\\text-generation-webui\\modules\\text_generation.py\", line\
    \ 293, in generate_with_callback\r\n    shared.model.generate(**kwargs)\r\n  File\
    \ \"E:\\ai\\oobabooga_windows_GPU\\installer_files\\env\\lib\\site-packages\\\
    torch\\utils\\_contextlib.py\", line 115, in decorate_context\r\n    return func(*args,\
    \ **kwargs)\r\n  File \"E:\\ai\\oobabooga_windows_GPU\\installer_files\\env\\\
    lib\\site-packages\\transformers\\generation\\utils.py\", line 1296, in generate\r\
    \n    eos_token_id = eos_token_id[0]\r\nIndexError: list index out of range"
  created_at: 2023-08-11 12:39:05+00:00
  edited: false
  hidden: false
  id: 64d639f9a146b1c0a667c93f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
      fullname: zlsl
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: false
      name: zlsl
      type: user
    createdAt: '2023-08-11T13:41:57.000Z'
    data:
      edited: true
      editors:
      - zlsl
      hidden: false
      identifiedLanguage:
        language: ru
        probability: 0.9395332336425781
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/634ac294574bb72b10f117a3/OmxgtLSViStxc1hLo7VSn.jpeg?w=200&h=200&f=face
          fullname: zlsl
          isHf: false
          isPro: false
          name: zlsl
          type: user
        html: "<p>\u0414\u0430, \u0442\u0430\u043C \u043F\u043E\u043B\u043E\u043C\u0430\
          \u043D\u0430 \u0437\u0430\u0433\u0440\u0443\u0437\u043A\u0430 GPT-2, GPT-NEO\
          \ \u043C\u043E\u0434\u0435\u043B\u0435\u0439.<br>\u0418\u0441\u043F\u0440\
          \u0430\u0432\u043B\u044F\u0435\u0442\u0441\u044F \u043B\u0435\u0433\u043A\
          \u043E, \u0432 \u0444\u0430\u0439\u043B modules/models.py \u0432 \u0444\u0443\
          \u043D\u043A\u0446\u0438\u044E load_tokenizer() \u043D\u0430\u0434\u043E\
          \ \u0434\u043E\u0431\u0430\u0432\u0438\u0442\u044C \u0441\u0442\u0440\u043E\
          \u0447\u043A\u0443<br><code>tokenizer.eos_token_id = 2</code><br>\u043F\u0435\
          \u0440\u0435\u0434<br><code>return tokenizer</code></p>\n"
        raw: "\u0414\u0430, \u0442\u0430\u043C \u043F\u043E\u043B\u043E\u043C\u0430\
          \u043D\u0430 \u0437\u0430\u0433\u0440\u0443\u0437\u043A\u0430 GPT-2, GPT-NEO\
          \ \u043C\u043E\u0434\u0435\u043B\u0435\u0439.\n\u0418\u0441\u043F\u0440\u0430\
          \u0432\u043B\u044F\u0435\u0442\u0441\u044F \u043B\u0435\u0433\u043A\u043E\
          , \u0432 \u0444\u0430\u0439\u043B modules/models.py \u0432 \u0444\u0443\u043D\
          \u043A\u0446\u0438\u044E load_tokenizer() \u043D\u0430\u0434\u043E \u0434\
          \u043E\u0431\u0430\u0432\u0438\u0442\u044C \u0441\u0442\u0440\u043E\u0447\
          \u043A\u0443\n<code>tokenizer.eos_token_id = 2</code>\n\u043F\u0435\u0440\
          \u0435\u0434\n<code>return tokenizer</code>"
        updatedAt: '2023-08-11T13:42:23.360Z'
      numEdits: 1
      reactions: []
    id: 64d63aa5aa89fb548a9adb82
    type: comment
  author: zlsl
  content: "\u0414\u0430, \u0442\u0430\u043C \u043F\u043E\u043B\u043E\u043C\u0430\u043D\
    \u0430 \u0437\u0430\u0433\u0440\u0443\u0437\u043A\u0430 GPT-2, GPT-NEO \u043C\u043E\
    \u0434\u0435\u043B\u0435\u0439.\n\u0418\u0441\u043F\u0440\u0430\u0432\u043B\u044F\
    \u0435\u0442\u0441\u044F \u043B\u0435\u0433\u043A\u043E, \u0432 \u0444\u0430\u0439\
    \u043B modules/models.py \u0432 \u0444\u0443\u043D\u043A\u0446\u0438\u044E load_tokenizer()\
    \ \u043D\u0430\u0434\u043E \u0434\u043E\u0431\u0430\u0432\u0438\u0442\u044C \u0441\
    \u0442\u0440\u043E\u0447\u043A\u0443\n<code>tokenizer.eos_token_id = 2</code>\n\
    \u043F\u0435\u0440\u0435\u0434\n<code>return tokenizer</code>"
  created_at: 2023-08-11 12:41:57+00:00
  edited: true
  hidden: false
  id: 64d63aa5aa89fb548a9adb82
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: zlsl/l_erotic_kink_chat
repo_type: model
status: open
target_branch: null
title: "\u041D\u0435 \u0440\u0430\u0431\u043E\u0442\u0430\u0435\u0442 \u0432 text-generation-webui?"
