!!python/object:huggingface_hub.community.DiscussionWithDetails
author: HR1777
conflicting_files: null
created_at: 2024-01-06 08:39:08+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
      fullname: H R
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HR1777
      type: user
    createdAt: '2024-01-06T08:39:08.000Z'
    data:
      edited: false
      editors:
      - HR1777
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7890398502349854
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2707764ac65c625b420c698440ca226c.svg
          fullname: H R
          isHf: false
          isPro: false
          name: HR1777
          type: user
        html: '<p>I follow the provided prompt template (Zephyr) but it only generates  "&lt;|system|&gt;"
          in the output. Whats wrong with this model? How should i fic it?</p>

          '
        raw: I follow the provided prompt template (Zephyr) but it only generates  "<|system|>"
          in the output. Whats wrong with this model? How should i fic it?
        updatedAt: '2024-01-06T08:39:08.665Z'
      numEdits: 0
      reactions: []
    id: 659911acbf533e3c0d03d4e7
    type: comment
  author: HR1777
  content: I follow the provided prompt template (Zephyr) but it only generates  "<|system|>"
    in the output. Whats wrong with this model? How should i fic it?
  created_at: 2024-01-06 08:39:08+00:00
  edited: false
  hidden: false
  id: 659911acbf533e3c0d03d4e7
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638581711769b7c4b10f0523/v95VFXJqueQ_pp9ZURu4R.jpeg?w=200&h=200&f=face
      fullname: Gardner Bickford
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: gardner
      type: user
    createdAt: '2024-01-19T04:24:39.000Z'
    data:
      edited: false
      editors:
      - gardner
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9117896556854248
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/638581711769b7c4b10f0523/v95VFXJqueQ_pp9ZURu4R.jpeg?w=200&h=200&f=face
          fullname: Gardner Bickford
          isHf: false
          isPro: false
          name: gardner
          type: user
        html: '<p>Please review this article on how to ask questions in a way that
          people can give you answers: <a rel="nofollow" href="http://www.catb.org/%7Eesr/faqs/smart-questions.html">http://www.catb.org/%7Eesr/faqs/smart-questions.html</a></p>

          <p>Please include more information about how you are running the inference.
          What tool are you using?</p>

          '
        raw: 'Please review this article on how to ask questions in a way that people
          can give you answers: http://www.catb.org/%7Eesr/faqs/smart-questions.html


          Please include more information about how you are running the inference.
          What tool are you using?'
        updatedAt: '2024-01-19T04:24:39.134Z'
      numEdits: 0
      reactions: []
    id: 65a9f9872ed95c799fe862ac
    type: comment
  author: gardner
  content: 'Please review this article on how to ask questions in a way that people
    can give you answers: http://www.catb.org/%7Eesr/faqs/smart-questions.html


    Please include more information about how you are running the inference. What
    tool are you using?'
  created_at: 2024-01-19 04:24:39+00:00
  edited: false
  hidden: false
  id: 65a9f9872ed95c799fe862ac
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF
repo_type: model
status: open
target_branch: null
title: The model doesn't generate output
