!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xueqing12
conflicting_files: null
created_at: 2023-07-01 02:04:53+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/e6295e474a9f4732a2df8ea53e50acf6.svg
      fullname: xueqing huang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xueqing12
      type: user
    createdAt: '2023-07-01T03:04:53.000Z'
    data:
      edited: false
      editors:
      - xueqing12
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.708640456199646
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/e6295e474a9f4732a2df8ea53e50acf6.svg
          fullname: xueqing huang
          isHf: false
          isPro: false
          name: xueqing12
          type: user
        html: '<p>*** Error running process: D:\SD2\extensions\sd-webui-controlnet\scripts\controlnet.py<br>    Traceback
          (most recent call last):<br>      File "D:\SD2\modules\scripts.py", line
          474, in process<br>        script.process(p, *script_args)<br>      File
          "D:\SD2\extensions\sd-webui-controlnet\scripts\controlnet.py", line 736,
          in process<br>        model_net = Script.load_control_model(p, unet, unit.model,
          unit.low_vram)<br>      File "D:\SD2\extensions\sd-webui-controlnet\scripts\controlnet.py",
          line 299, in load_control_model<br>        model_net = Script.build_control_model(p,
          unet, model, lowvram)<br>      File "D:\SD2\extensions\sd-webui-controlnet\scripts\controlnet.py",
          line 382, in build_control_model<br>        network = network_module(<br>      File
          "D:\SD2\extensions\sd-webui-controlnet\scripts\cldm.py", line 91, in <strong>init</strong><br>        self.control_model.load_state_dict(state_dict)<br>      File
          "C:\Users\Admin\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py",
          line 2041, in load_state_dict<br>        raise RuntimeError(''Error(s) in
          loading state_dict for {}:\n\t{}''.format(<br>    RuntimeError: Error(s)
          in loading state_dict for ControlNet:<br>        size mismatch for input_blocks.1.1.proj_in.weight:
          copying a param with shape torch.Size([320, 320, 1, 1]) from checkpoint,
          the shape in current model is torch.Size([320, 320]).<br>        size mismatch
          for input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight: copying a param
          with shape torch.Size([320, 768]) from checkpoint, the shape in current
          model is torch.Size([320, 1024]).<br>        size mismatch for input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight:
          copying a param with shape torch.Size([320, 768]) from checkpoint, the shape
          in current model is torch.Size([320, 1024]).<br>        size mismatch for
          input_blocks.1.1.proj_out.weight: copying a param with shape torch.Size([320,
          320, 1, 1]) from checkpoint, the shape in current model is torch.Size([320,
          320]).<br>        size mismatch for input_blocks.2.1.proj_in.weight: copying
          a param with shape torch.Size([320, 320, 1, 1]) from checkpoint, the shape
          in current model is torch.Size([320, 320]).<br>        size mismatch for
          input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight: copying a param
          with shape torch.Size([320, 768]) from checkpoint, the shape in current
          model is torch.Size([320, 1024]).<br>        size mismatch for input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight:
          copying a param with shape torch.Size([320, 768]) from checkpoint, the shape
          in current model is torch.Size([320, 1024]).<br>        size mismatch for
          input_blocks.2.1.proj_out.weight: copying a param with shape torch.Size([320,
          320, 1, 1]) from checkpoint, the shape in current model is torch.Size([320,
          320]).<br>        size mismatch for input_blocks.4.1.proj_in.weight: copying
          a param with shape torch.Size([640, 640, 1, 1]) from checkpoint, the shape
          in current model is torch.Size([640, 640]).<br>        size mismatch for
          input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight: copying a param
          with shape torch.Size([640, 768]) from checkpoint, the shape in current
          model is torch.Size([640, 1024]).<br>        size mismatch for input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight:
          copying a param with shape torch.Size([640, 768]) from checkpoint, the shape
          in current model is torch.Size([640, 1024]).<br>        size mismatch for
          input_blocks.4.1.proj_out.weight: copying a param with shape torch.Size([640,
          640, 1, 1]) from checkpoint, the shape in current model is torch.Size([640,
          640]).<br>        size mismatch for input_blocks.5.1.proj_in.weight: copying
          a param with shape torch.Size([640, 640, 1, 1]) from checkpoint, the shape
          in current model is torch.Size([640, 640]).<br>        size mismatch for
          input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight: copying a param
          with shape torch.Size([640, 768]) from checkpoint, the shape in current
          model is torch.Size([640, 1024]).<br>        size mismatch for input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight:
          copying a param with shape torch.Size([640, 768]) from checkpoint, the shape
          in current model is torch.Size([640, 1024]).<br>        size mismatch for
          input_blocks.5.1.proj_out.weight: copying a param with shape torch.Size([640,
          640, 1, 1]) from checkpoint, the shape in current model is torch.Size([640,
          640]).<br>        size mismatch for input_blocks.7.1.proj_in.weight: copying
          a param with shape torch.Size([1280, 1280, 1, 1]) from checkpoint, the shape
          in current model is torch.Size([1280, 1280]).<br>        size mismatch for
          input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight: copying a param
          with shape torch.Size([1280, 768]) from checkpoint, the shape in current
          model is torch.Size([1280, 1024]).<br>        size mismatch for input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight:
          copying a param with shape torch.Size([1280, 768]) from checkpoint, the
          shape in current model is torch.Size([1280, 1024]).<br>        size mismatch
          for input_blocks.7.1.proj_out.weight: copying a param with shape torch.Size([1280,
          1280, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280,
          1280]).<br>        size mismatch for input_blocks.8.1.proj_in.weight: copying
          a param with shape torch.Size([1280, 1280, 1, 1]) from checkpoint, the shape
          in current model is torch.Size([1280, 1280]).<br>        size mismatch for
          input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight: copying a param
          with shape torch.Size([1280, 768]) from checkpoint, the shape in current
          model is torch.Size([1280, 1024]).<br>        size mismatch for input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight:
          copying a param with shape torch.Size([1280, 768]) from checkpoint, the
          shape in current model is torch.Size([1280, 1024]).<br>        size mismatch
          for input_blocks.8.1.proj_out.weight: copying a param with shape torch.Size([1280,
          1280, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280,
          1280]).<br>        size mismatch for middle_block.1.proj_in.weight: copying
          a param with shape torch.Size([1280, 1280, 1, 1]) from checkpoint, the shape
          in current model is torch.Size([1280, 1280]).<br>        size mismatch for
          middle_block.1.transformer_blocks.0.attn2.to_k.weight: copying a param with
          shape torch.Size([1280, 768]) from checkpoint, the shape in current model
          is torch.Size([1280, 1024]).<br>        size mismatch for middle_block.1.transformer_blocks.0.attn2.to_v.weight:
          copying a param with shape torch.Size([1280, 768]) from checkpoint, the
          shape in current model is torch.Size([1280, 1024]).<br>        size mismatch
          for middle_block.1.proj_out.weight: copying a param with shape torch.Size([1280,
          1280, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280,
          1280]).</p>

          '
        raw: "*** Error running process: D:\\SD2\\extensions\\sd-webui-controlnet\\\
          scripts\\controlnet.py\r\n    Traceback (most recent call last):\r\n   \
          \   File \"D:\\SD2\\modules\\scripts.py\", line 474, in process\r\n    \
          \    script.process(p, *script_args)\r\n      File \"D:\\SD2\\extensions\\\
          sd-webui-controlnet\\scripts\\controlnet.py\", line 736, in process\r\n\
          \        model_net = Script.load_control_model(p, unet, unit.model, unit.low_vram)\r\
          \n      File \"D:\\SD2\\extensions\\sd-webui-controlnet\\scripts\\controlnet.py\"\
          , line 299, in load_control_model\r\n        model_net = Script.build_control_model(p,\
          \ unet, model, lowvram)\r\n      File \"D:\\SD2\\extensions\\sd-webui-controlnet\\\
          scripts\\controlnet.py\", line 382, in build_control_model\r\n        network\
          \ = network_module(\r\n      File \"D:\\SD2\\extensions\\sd-webui-controlnet\\\
          scripts\\cldm.py\", line 91, in __init__\r\n        self.control_model.load_state_dict(state_dict)\r\
          \n      File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\\
          torch\\nn\\modules\\module.py\", line 2041, in load_state_dict\r\n     \
          \   raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\r\
          \n    RuntimeError: Error(s) in loading state_dict for ControlNet:\r\n \
          \       size mismatch for input_blocks.1.1.proj_in.weight: copying a param\
          \ with shape torch.Size([320, 320, 1, 1]) from checkpoint, the shape in\
          \ current model is torch.Size([320, 320]).\r\n        size mismatch for\
          \ input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight: copying a param\
          \ with shape torch.Size([320, 768]) from checkpoint, the shape in current\
          \ model is torch.Size([320, 1024]).\r\n        size mismatch for input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight:\
          \ copying a param with shape torch.Size([320, 768]) from checkpoint, the\
          \ shape in current model is torch.Size([320, 1024]).\r\n        size mismatch\
          \ for input_blocks.1.1.proj_out.weight: copying a param with shape torch.Size([320,\
          \ 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([320,\
          \ 320]).\r\n        size mismatch for input_blocks.2.1.proj_in.weight: copying\
          \ a param with shape torch.Size([320, 320, 1, 1]) from checkpoint, the shape\
          \ in current model is torch.Size([320, 320]).\r\n        size mismatch for\
          \ input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight: copying a param\
          \ with shape torch.Size([320, 768]) from checkpoint, the shape in current\
          \ model is torch.Size([320, 1024]).\r\n        size mismatch for input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight:\
          \ copying a param with shape torch.Size([320, 768]) from checkpoint, the\
          \ shape in current model is torch.Size([320, 1024]).\r\n        size mismatch\
          \ for input_blocks.2.1.proj_out.weight: copying a param with shape torch.Size([320,\
          \ 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([320,\
          \ 320]).\r\n        size mismatch for input_blocks.4.1.proj_in.weight: copying\
          \ a param with shape torch.Size([640, 640, 1, 1]) from checkpoint, the shape\
          \ in current model is torch.Size([640, 640]).\r\n        size mismatch for\
          \ input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight: copying a param\
          \ with shape torch.Size([640, 768]) from checkpoint, the shape in current\
          \ model is torch.Size([640, 1024]).\r\n        size mismatch for input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight:\
          \ copying a param with shape torch.Size([640, 768]) from checkpoint, the\
          \ shape in current model is torch.Size([640, 1024]).\r\n        size mismatch\
          \ for input_blocks.4.1.proj_out.weight: copying a param with shape torch.Size([640,\
          \ 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([640,\
          \ 640]).\r\n        size mismatch for input_blocks.5.1.proj_in.weight: copying\
          \ a param with shape torch.Size([640, 640, 1, 1]) from checkpoint, the shape\
          \ in current model is torch.Size([640, 640]).\r\n        size mismatch for\
          \ input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight: copying a param\
          \ with shape torch.Size([640, 768]) from checkpoint, the shape in current\
          \ model is torch.Size([640, 1024]).\r\n        size mismatch for input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight:\
          \ copying a param with shape torch.Size([640, 768]) from checkpoint, the\
          \ shape in current model is torch.Size([640, 1024]).\r\n        size mismatch\
          \ for input_blocks.5.1.proj_out.weight: copying a param with shape torch.Size([640,\
          \ 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([640,\
          \ 640]).\r\n        size mismatch for input_blocks.7.1.proj_in.weight: copying\
          \ a param with shape torch.Size([1280, 1280, 1, 1]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\n        size mismatch\
          \ for input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight: copying a\
          \ param with shape torch.Size([1280, 768]) from checkpoint, the shape in\
          \ current model is torch.Size([1280, 1024]).\r\n        size mismatch for\
          \ input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight: copying a param\
          \ with shape torch.Size([1280, 768]) from checkpoint, the shape in current\
          \ model is torch.Size([1280, 1024]).\r\n        size mismatch for input_blocks.7.1.proj_out.weight:\
          \ copying a param with shape torch.Size([1280, 1280, 1, 1]) from checkpoint,\
          \ the shape in current model is torch.Size([1280, 1280]).\r\n        size\
          \ mismatch for input_blocks.8.1.proj_in.weight: copying a param with shape\
          \ torch.Size([1280, 1280, 1, 1]) from checkpoint, the shape in current model\
          \ is torch.Size([1280, 1280]).\r\n        size mismatch for input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight:\
          \ copying a param with shape torch.Size([1280, 768]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1024]).\r\n        size mismatch\
          \ for input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight: copying a\
          \ param with shape torch.Size([1280, 768]) from checkpoint, the shape in\
          \ current model is torch.Size([1280, 1024]).\r\n        size mismatch for\
          \ input_blocks.8.1.proj_out.weight: copying a param with shape torch.Size([1280,\
          \ 1280, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280,\
          \ 1280]).\r\n        size mismatch for middle_block.1.proj_in.weight: copying\
          \ a param with shape torch.Size([1280, 1280, 1, 1]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1280]).\r\n        size mismatch\
          \ for middle_block.1.transformer_blocks.0.attn2.to_k.weight: copying a param\
          \ with shape torch.Size([1280, 768]) from checkpoint, the shape in current\
          \ model is torch.Size([1280, 1024]).\r\n        size mismatch for middle_block.1.transformer_blocks.0.attn2.to_v.weight:\
          \ copying a param with shape torch.Size([1280, 768]) from checkpoint, the\
          \ shape in current model is torch.Size([1280, 1024]).\r\n        size mismatch\
          \ for middle_block.1.proj_out.weight: copying a param with shape torch.Size([1280,\
          \ 1280, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280,\
          \ 1280])."
        updatedAt: '2023-07-01T03:04:53.670Z'
      numEdits: 0
      reactions: []
    id: 649f97d5b310029e9849ea7d
    type: comment
  author: xueqing12
  content: "*** Error running process: D:\\SD2\\extensions\\sd-webui-controlnet\\\
    scripts\\controlnet.py\r\n    Traceback (most recent call last):\r\n      File\
    \ \"D:\\SD2\\modules\\scripts.py\", line 474, in process\r\n        script.process(p,\
    \ *script_args)\r\n      File \"D:\\SD2\\extensions\\sd-webui-controlnet\\scripts\\\
    controlnet.py\", line 736, in process\r\n        model_net = Script.load_control_model(p,\
    \ unet, unit.model, unit.low_vram)\r\n      File \"D:\\SD2\\extensions\\sd-webui-controlnet\\\
    scripts\\controlnet.py\", line 299, in load_control_model\r\n        model_net\
    \ = Script.build_control_model(p, unet, model, lowvram)\r\n      File \"D:\\SD2\\\
    extensions\\sd-webui-controlnet\\scripts\\controlnet.py\", line 382, in build_control_model\r\
    \n        network = network_module(\r\n      File \"D:\\SD2\\extensions\\sd-webui-controlnet\\\
    scripts\\cldm.py\", line 91, in __init__\r\n        self.control_model.load_state_dict(state_dict)\r\
    \n      File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\\
    torch\\nn\\modules\\module.py\", line 2041, in load_state_dict\r\n        raise\
    \ RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\r\n  \
    \  RuntimeError: Error(s) in loading state_dict for ControlNet:\r\n        size\
    \ mismatch for input_blocks.1.1.proj_in.weight: copying a param with shape torch.Size([320,\
    \ 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([320,\
    \ 320]).\r\n        size mismatch for input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight:\
    \ copying a param with shape torch.Size([320, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([320, 1024]).\r\n        size mismatch for input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight:\
    \ copying a param with shape torch.Size([320, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([320, 1024]).\r\n        size mismatch for input_blocks.1.1.proj_out.weight:\
    \ copying a param with shape torch.Size([320, 320, 1, 1]) from checkpoint, the\
    \ shape in current model is torch.Size([320, 320]).\r\n        size mismatch for\
    \ input_blocks.2.1.proj_in.weight: copying a param with shape torch.Size([320,\
    \ 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([320,\
    \ 320]).\r\n        size mismatch for input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight:\
    \ copying a param with shape torch.Size([320, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([320, 1024]).\r\n        size mismatch for input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight:\
    \ copying a param with shape torch.Size([320, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([320, 1024]).\r\n        size mismatch for input_blocks.2.1.proj_out.weight:\
    \ copying a param with shape torch.Size([320, 320, 1, 1]) from checkpoint, the\
    \ shape in current model is torch.Size([320, 320]).\r\n        size mismatch for\
    \ input_blocks.4.1.proj_in.weight: copying a param with shape torch.Size([640,\
    \ 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([640,\
    \ 640]).\r\n        size mismatch for input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight:\
    \ copying a param with shape torch.Size([640, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([640, 1024]).\r\n        size mismatch for input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight:\
    \ copying a param with shape torch.Size([640, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([640, 1024]).\r\n        size mismatch for input_blocks.4.1.proj_out.weight:\
    \ copying a param with shape torch.Size([640, 640, 1, 1]) from checkpoint, the\
    \ shape in current model is torch.Size([640, 640]).\r\n        size mismatch for\
    \ input_blocks.5.1.proj_in.weight: copying a param with shape torch.Size([640,\
    \ 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([640,\
    \ 640]).\r\n        size mismatch for input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight:\
    \ copying a param with shape torch.Size([640, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([640, 1024]).\r\n        size mismatch for input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight:\
    \ copying a param with shape torch.Size([640, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([640, 1024]).\r\n        size mismatch for input_blocks.5.1.proj_out.weight:\
    \ copying a param with shape torch.Size([640, 640, 1, 1]) from checkpoint, the\
    \ shape in current model is torch.Size([640, 640]).\r\n        size mismatch for\
    \ input_blocks.7.1.proj_in.weight: copying a param with shape torch.Size([1280,\
    \ 1280, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280,\
    \ 1280]).\r\n        size mismatch for input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight:\
    \ copying a param with shape torch.Size([1280, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1024]).\r\n        size mismatch for input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight:\
    \ copying a param with shape torch.Size([1280, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1024]).\r\n        size mismatch for input_blocks.7.1.proj_out.weight:\
    \ copying a param with shape torch.Size([1280, 1280, 1, 1]) from checkpoint, the\
    \ shape in current model is torch.Size([1280, 1280]).\r\n        size mismatch\
    \ for input_blocks.8.1.proj_in.weight: copying a param with shape torch.Size([1280,\
    \ 1280, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280,\
    \ 1280]).\r\n        size mismatch for input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight:\
    \ copying a param with shape torch.Size([1280, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1024]).\r\n        size mismatch for input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight:\
    \ copying a param with shape torch.Size([1280, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1024]).\r\n        size mismatch for input_blocks.8.1.proj_out.weight:\
    \ copying a param with shape torch.Size([1280, 1280, 1, 1]) from checkpoint, the\
    \ shape in current model is torch.Size([1280, 1280]).\r\n        size mismatch\
    \ for middle_block.1.proj_in.weight: copying a param with shape torch.Size([1280,\
    \ 1280, 1, 1]) from checkpoint, the shape in current model is torch.Size([1280,\
    \ 1280]).\r\n        size mismatch for middle_block.1.transformer_blocks.0.attn2.to_k.weight:\
    \ copying a param with shape torch.Size([1280, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1024]).\r\n        size mismatch for middle_block.1.transformer_blocks.0.attn2.to_v.weight:\
    \ copying a param with shape torch.Size([1280, 768]) from checkpoint, the shape\
    \ in current model is torch.Size([1280, 1024]).\r\n        size mismatch for middle_block.1.proj_out.weight:\
    \ copying a param with shape torch.Size([1280, 1280, 1, 1]) from checkpoint, the\
    \ shape in current model is torch.Size([1280, 1280])."
  created_at: 2023-07-01 02:04:53+00:00
  edited: false
  hidden: false
  id: 649f97d5b310029e9849ea7d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/e6295e474a9f4732a2df8ea53e50acf6.svg
      fullname: xueqing huang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xueqing12
      type: user
    createdAt: '2023-07-11T11:42:18.000Z'
    data:
      status: closed
    id: 64ad401ac1da7c4dbc763c24
    type: status-change
  author: xueqing12
  created_at: 2023-07-11 10:42:18+00:00
  id: 64ad401ac1da7c4dbc763c24
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 10
repo_id: ioclab/control_v1u_sd15_illumination_webui
repo_type: model
status: closed
target_branch: null
title: error plz
