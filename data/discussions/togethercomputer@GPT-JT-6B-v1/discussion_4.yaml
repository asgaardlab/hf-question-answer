!!python/object:huggingface_hub.community.DiscussionWithDetails
author: zhangce
conflicting_files: null
created_at: 2022-11-30 05:08:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/277ff242cf15b380b80bdabfc0cfa030.svg
      fullname: Ce Zhang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: zhangce
      type: user
    createdAt: '2022-11-30T05:08:02.000Z'
    data:
      edited: false
      editors:
      - zhangce
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/277ff242cf15b380b80bdabfc0cfa030.svg
          fullname: Ce Zhang
          isHf: false
          isPro: false
          name: zhangce
          type: user
        html: '<p>We are starting to work on V2 and would love to hear your suggestions
          and top requests!</p>

          '
        raw: We are starting to work on V2 and would love to hear your suggestions
          and top requests!
        updatedAt: '2022-11-30T05:08:02.055Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - yahma
    id: 6386e5329d7b8afb0e876050
    type: comment
  author: zhangce
  content: We are starting to work on V2 and would love to hear your suggestions and
    top requests!
  created_at: 2022-11-30 05:08:02+00:00
  edited: false
  hidden: false
  id: 6386e5329d7b8afb0e876050
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/277ff242cf15b380b80bdabfc0cfa030.svg
      fullname: Ce Zhang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: zhangce
      type: user
    createdAt: '2022-11-30T05:12:23.000Z'
    data:
      edited: false
      editors:
      - zhangce
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/277ff242cf15b380b80bdabfc0cfa030.svg
          fullname: Ce Zhang
          isHf: false
          isPro: false
          name: zhangce
          type: user
        html: '<p>Great suggestion from @<a rel="nofollow" href="https://twitter.com/espadrine">espadrine</a>
          on Twitter:  FLAN support</p>

          <p>This is top of our list for v2 right now!</p>

          '
        raw: 'Great suggestion from @[espadrine](https://twitter.com/espadrine) on
          Twitter:  FLAN support


          This is top of our list for v2 right now!'
        updatedAt: '2022-11-30T05:12:23.234Z'
      numEdits: 0
      reactions: []
    id: 6386e6375ea0bcbedb177fe1
    type: comment
  author: zhangce
  content: 'Great suggestion from @[espadrine](https://twitter.com/espadrine) on Twitter:  FLAN
    support


    This is top of our list for v2 right now!'
  created_at: 2022-11-30 05:12:23+00:00
  edited: false
  hidden: false
  id: 6386e6375ea0bcbedb177fe1
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d6863f14e93bbcdec56bfeb776324e66.svg
      fullname: Michael Cosmas Mallya
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Mike3tdd
      type: user
    createdAt: '2022-12-04T17:25:56.000Z'
    data:
      edited: false
      editors:
      - Mike3tdd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d6863f14e93bbcdec56bfeb776324e66.svg
          fullname: Michael Cosmas Mallya
          isHf: false
          isPro: false
          name: Mike3tdd
          type: user
        html: '<p>Increase input sequences more than 2048 tokens</p>

          '
        raw: Increase input sequences more than 2048 tokens
        updatedAt: '2022-12-04T17:25:56.570Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - aolko
        - Mike3tdd
        - BigSalmon
        - drpatrickchankh
    id: 638cd824092a73a14a32dc92
    type: comment
  author: Mike3tdd
  content: Increase input sequences more than 2048 tokens
  created_at: 2022-12-04 17:25:56+00:00
  edited: false
  hidden: false
  id: 638cd824092a73a14a32dc92
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667400523201-noauth.jpeg?w=200&h=200&f=face
      fullname: Mihai Ilie
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: iliemihai
      type: user
    createdAt: '2022-12-10T00:59:34.000Z'
    data:
      edited: true
      editors:
      - iliemihai
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1667400523201-noauth.jpeg?w=200&h=200&f=face
          fullname: Mihai Ilie
          isHf: false
          isPro: false
          name: iliemihai
          type: user
        html: '<p>Can you train it also with Reinforcement Learning, like Open ai?</p>

          '
        raw: Can you train it also with Reinforcement Learning, like Open ai?
        updatedAt: '2022-12-10T01:00:11.137Z'
      numEdits: 1
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MatthewK
    id: 6393d9f622484a5cff7a41a6
    type: comment
  author: iliemihai
  content: Can you train it also with Reinforcement Learning, like Open ai?
  created_at: 2022-12-10 00:59:34+00:00
  edited: true
  hidden: false
  id: 6393d9f622484a5cff7a41a6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/277ff242cf15b380b80bdabfc0cfa030.svg
      fullname: Ce Zhang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: zhangce
      type: user
    createdAt: '2022-12-12T04:31:52.000Z'
    data:
      edited: false
      editors:
      - zhangce
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/277ff242cf15b380b80bdabfc0cfa030.svg
          fullname: Ce Zhang
          isHf: false
          isPro: false
          name: zhangce
          type: user
        html: '<p>Sparse Upcycling might be cool to try! <a rel="nofollow" href="https://twitter.com/arankomatsuzaki/status/1602126140696629249?s=20&amp;t=qnFaselW3mXcm-UZn7ISlA">https://twitter.com/arankomatsuzaki/status/1602126140696629249?s=20&amp;t=qnFaselW3mXcm-UZn7ISlA</a></p>

          '
        raw: Sparse Upcycling might be cool to try! https://twitter.com/arankomatsuzaki/status/1602126140696629249?s=20&t=qnFaselW3mXcm-UZn7ISlA
        updatedAt: '2022-12-12T04:31:52.887Z'
      numEdits: 0
      reactions: []
    id: 6396aeb861eda30a3649f819
    type: comment
  author: zhangce
  content: Sparse Upcycling might be cool to try! https://twitter.com/arankomatsuzaki/status/1602126140696629249?s=20&t=qnFaselW3mXcm-UZn7ISlA
  created_at: 2022-12-12 04:31:52+00:00
  edited: false
  hidden: false
  id: 6396aeb861eda30a3649f819
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ac47d13204dd22452e4bc46e280842d5.svg
      fullname: JunnanLi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JunnanLi
      type: user
    createdAt: '2023-02-03T02:23:35.000Z'
    data:
      edited: true
      editors:
      - JunnanLi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ac47d13204dd22452e4bc46e280842d5.svg
          fullname: JunnanLi
          isHf: false
          isPro: false
          name: JunnanLi
          type: user
        html: '<p>Great work! Any timeline on when will V2 be available?<br>We are
          very interested in using GPT-JT for our BLIP-2 model: <a rel="nofollow"
          href="https://twitter.com/LiJunnan0409/status/1620259379223343107">https://twitter.com/LiJunnan0409/status/1620259379223343107</a><br>From
          our current experiments, GPT-JT v1 outperforms OPT6.7B but still underperforms
          FLAN-T5</p>

          '
        raw: 'Great work! Any timeline on when will V2 be available?

          We are very interested in using GPT-JT for our BLIP-2 model: https://twitter.com/LiJunnan0409/status/1620259379223343107

          From our current experiments, GPT-JT v1 outperforms OPT6.7B but still underperforms
          FLAN-T5'
        updatedAt: '2023-02-03T02:24:52.048Z'
      numEdits: 1
      reactions: []
    id: 63dc70272a0239d221131450
    type: comment
  author: JunnanLi
  content: 'Great work! Any timeline on when will V2 be available?

    We are very interested in using GPT-JT for our BLIP-2 model: https://twitter.com/LiJunnan0409/status/1620259379223343107

    From our current experiments, GPT-JT v1 outperforms OPT6.7B but still underperforms
    FLAN-T5'
  created_at: 2023-02-03 02:23:35+00:00
  edited: true
  hidden: false
  id: 63dc70272a0239d221131450
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669380535028-61dce5c2af6d5e733e0fb08b.jpeg?w=200&h=200&f=face
      fullname: Jue Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: juewang
      type: user
    createdAt: '2023-02-05T05:36:05.000Z'
    data:
      edited: false
      editors:
      - juewang
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669380535028-61dce5c2af6d5e733e0fb08b.jpeg?w=200&h=200&f=face
          fullname: Jue Wang
          isHf: false
          isPro: false
          name: juewang
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;JunnanLi&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/JunnanLi\">@<span class=\"\
          underline\">JunnanLi</span></a></span>\n\n\t</span></span> Thank you for\
          \ your interest! Our team is actively testing larger models and more data.\
          \ We will release new models in the near future, possibly within a couple\
          \ of weeks. Keep an eye out for updates!</p>\n"
        raw: '@JunnanLi Thank you for your interest! Our team is actively testing
          larger models and more data. We will release new models in the near future,
          possibly within a couple of weeks. Keep an eye out for updates!'
        updatedAt: '2023-02-05T05:36:05.118Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - JunnanLi
    id: 63df40453479d337b642d8a5
    type: comment
  author: juewang
  content: '@JunnanLi Thank you for your interest! Our team is actively testing larger
    models and more data. We will release new models in the near future, possibly
    within a couple of weeks. Keep an eye out for updates!'
  created_at: 2023-02-05 05:36:05+00:00
  edited: false
  hidden: false
  id: 63df40453479d337b642d8a5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/ac47d13204dd22452e4bc46e280842d5.svg
      fullname: JunnanLi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: JunnanLi
      type: user
    createdAt: '2023-02-28T08:35:59.000Z'
    data:
      edited: false
      editors:
      - JunnanLi
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/ac47d13204dd22452e4bc46e280842d5.svg
          fullname: JunnanLi
          isHf: false
          isPro: false
          name: JunnanLi
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;juewang&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/juewang\">@<span class=\"\
          underline\">juewang</span></a></span>\n\n\t</span></span> any news on V2?</p>\n"
        raw: Hi @juewang any news on V2?
        updatedAt: '2023-02-28T08:35:59.291Z'
      numEdits: 0
      reactions: []
    id: 63fdbcef49632f13d06132ff
    type: comment
  author: JunnanLi
  content: Hi @juewang any news on V2?
  created_at: 2023-02-28 08:35:59+00:00
  edited: false
  hidden: false
  id: 63fdbcef49632f13d06132ff
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665957845326-noauth.jpeg?w=200&h=200&f=face
      fullname: James Scott
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Admaxtv
      type: user
    createdAt: '2023-03-18T18:49:59.000Z'
    data:
      edited: false
      editors:
      - Admaxtv
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1665957845326-noauth.jpeg?w=200&h=200&f=face
          fullname: James Scott
          isHf: false
          isPro: false
          name: Admaxtv
          type: user
        html: '<p>I have a rtx3090, how long should I expect for the model to load
          and respond if it''s loaded locally?  I was hoping the model would stay
          loaded like with Stable Diffusion so that I could continue to use it without
          having to reload it each time I call the program.</p>

          '
        raw: I have a rtx3090, how long should I expect for the model to load and
          respond if it's loaded locally?  I was hoping the model would stay loaded
          like with Stable Diffusion so that I could continue to use it without having
          to reload it each time I call the program.
        updatedAt: '2023-03-18T18:49:59.941Z'
      numEdits: 0
      reactions: []
    id: 641607d7e9e50fef5809c2ee
    type: comment
  author: Admaxtv
  content: I have a rtx3090, how long should I expect for the model to load and respond
    if it's loaded locally?  I was hoping the model would stay loaded like with Stable
    Diffusion so that I could continue to use it without having to reload it each
    time I call the program.
  created_at: 2023-03-18 17:49:59+00:00
  edited: false
  hidden: false
  id: 641607d7e9e50fef5809c2ee
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669380535028-61dce5c2af6d5e733e0fb08b.jpeg?w=200&h=200&f=face
      fullname: Jue Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: juewang
      type: user
    createdAt: '2023-03-23T02:12:33.000Z'
    data:
      edited: false
      editors:
      - juewang
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669380535028-61dce5c2af6d5e733e0fb08b.jpeg?w=200&h=200&f=face
          fullname: Jue Wang
          isHf: false
          isPro: false
          name: juewang
          type: user
        html: '<blockquote>

          <p>I have a rtx3090, how long should I expect for the model to load and
          respond if it''s loaded locally?  I was hoping the model would stay loaded
          like with Stable Diffusion so that I could continue to use it without having
          to reload it each time I call the program.</p>

          </blockquote>

          <p>If you''re using the <code>from_pretrained</code> function to load the
          model locally, it typically takes around 2-3 minutes -- most of this time
          is spent on random initialization. And sure you can keep it loaded so that
          you don''t have to reload it each time.</p>

          <p>The inference response time will depend on your generation configuration,
          particularly the <code>max_new_tokens</code> setting. Generally, the response
          time is linearly related to <code>max_new_tokens</code>. For most configurations,
          the response time is typically several seconds at most; if your expected
          response is short, you can set a small value to accelerate inference.</p>

          '
        raw: '> I have a rtx3090, how long should I expect for the model to load and
          respond if it''s loaded locally?  I was hoping the model would stay loaded
          like with Stable Diffusion so that I could continue to use it without having
          to reload it each time I call the program.


          If you''re using the `from_pretrained` function to load the model locally,
          it typically takes around 2-3 minutes -- most of this time is spent on random
          initialization. And sure you can keep it loaded so that you don''t have
          to reload it each time.


          The inference response time will depend on your generation configuration,
          particularly the `max_new_tokens` setting. Generally, the response time
          is linearly related to `max_new_tokens`. For most configurations, the response
          time is typically several seconds at most; if your expected response is
          short, you can set a small value to accelerate inference.'
        updatedAt: '2023-03-23T02:12:33.930Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - Admaxtv
    id: 641bb591d42926275daa38fa
    type: comment
  author: juewang
  content: '> I have a rtx3090, how long should I expect for the model to load and
    respond if it''s loaded locally?  I was hoping the model would stay loaded like
    with Stable Diffusion so that I could continue to use it without having to reload
    it each time I call the program.


    If you''re using the `from_pretrained` function to load the model locally, it
    typically takes around 2-3 minutes -- most of this time is spent on random initialization.
    And sure you can keep it loaded so that you don''t have to reload it each time.


    The inference response time will depend on your generation configuration, particularly
    the `max_new_tokens` setting. Generally, the response time is linearly related
    to `max_new_tokens`. For most configurations, the response time is typically several
    seconds at most; if your expected response is short, you can set a small value
    to accelerate inference.'
  created_at: 2023-03-23 01:12:33+00:00
  edited: false
  hidden: false
  id: 641bb591d42926275daa38fa
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: togethercomputer/GPT-JT-6B-v1
repo_type: model
status: open
target_branch: null
title: Feature requests and suggestions for V2
