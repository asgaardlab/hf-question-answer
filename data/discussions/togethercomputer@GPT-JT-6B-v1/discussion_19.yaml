!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tmishinev
conflicting_files: null
created_at: 2023-01-09 11:54:46+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/51f3249da9f1dd746042cc0636a1e8c9.svg
      fullname: Todor Mishinev
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tmishinev
      type: user
    createdAt: '2023-01-09T11:54:46.000Z'
    data:
      edited: false
      editors:
      - tmishinev
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/51f3249da9f1dd746042cc0636a1e8c9.svg
          fullname: Todor Mishinev
          isHf: false
          isPro: false
          name: tmishinev
          type: user
        html: '<p>Hello,</p>

          <p>  Does anyone use this model as a Reader in a QnA pipeline over document
          collection? I see I can use it with a<br>''''''<br>Context:<br>XXXXX</p>

          <p>Q:XXXXX<br>A:<br>''''''<br>  This kind of promt works and I can fetch
          context via embedding retrieval. Is there any other way I can train it with
          the document corpus ?</p>

          <p>Best Regards,<br>Todor</p>

          '
        raw: "Hello,\r\n\r\n  Does anyone use this model as a Reader in a QnA pipeline\
          \ over document collection? I see I can use it with a \r\n'''\r\nContext:\
          \ \r\nXXXXX\r\n\r\nQ:XXXXX\r\nA:\r\n'''\r\n  This kind of promt works and\
          \ I can fetch context via embedding retrieval. Is there any other way I\
          \ can train it with the document corpus ?\r\n\r\nBest Regards,\r\nTodor"
        updatedAt: '2023-01-09T11:54:46.771Z'
      numEdits: 0
      reactions: []
    id: 63bc00861374e3ef912e9c4a
    type: comment
  author: tmishinev
  content: "Hello,\r\n\r\n  Does anyone use this model as a Reader in a QnA pipeline\
    \ over document collection? I see I can use it with a \r\n'''\r\nContext: \r\n\
    XXXXX\r\n\r\nQ:XXXXX\r\nA:\r\n'''\r\n  This kind of promt works and I can fetch\
    \ context via embedding retrieval. Is there any other way I can train it with\
    \ the document corpus ?\r\n\r\nBest Regards,\r\nTodor"
  created_at: 2023-01-09 11:54:46+00:00
  edited: false
  hidden: false
  id: 63bc00861374e3ef912e9c4a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669380535028-61dce5c2af6d5e733e0fb08b.jpeg?w=200&h=200&f=face
      fullname: Jue Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: juewang
      type: user
    createdAt: '2023-01-23T02:39:25.000Z'
    data:
      edited: false
      editors:
      - juewang
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669380535028-61dce5c2af6d5e733e0fb08b.jpeg?w=200&h=200&f=face
          fullname: Jue Wang
          isHf: false
          isPro: false
          name: juewang
          type: user
        html: '<p>Hi, reading comprehension task should be doable, but the result
          should depend on the length type of the context. To improve accuracy, it
          is recommended to include a small number of examples :)</p>

          '
        raw: Hi, reading comprehension task should be doable, but the result should
          depend on the length type of the context. To improve accuracy, it is recommended
          to include a small number of examples :)
        updatedAt: '2023-01-23T02:39:25.843Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\u2764\uFE0F"
        users:
        - AayushShah
    id: 63cdf35de75230ae94f1429c
    type: comment
  author: juewang
  content: Hi, reading comprehension task should be doable, but the result should
    depend on the length type of the context. To improve accuracy, it is recommended
    to include a small number of examples :)
  created_at: 2023-01-23 02:39:25+00:00
  edited: false
  hidden: false
  id: 63cdf35de75230ae94f1429c
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
      fullname: AayushShah
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: AayushShah
      type: user
    createdAt: '2023-03-09T02:42:22.000Z'
    data:
      edited: false
      editors:
      - AayushShah
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63ff5fc4fe6383d50b29052e/Vk9R5rKqG-Z_ou-55J9x-.jpeg?w=200&h=200&f=face
          fullname: AayushShah
          isHf: false
          isPro: false
          name: AayushShah
          type: user
        html: "<p>Hey, <span data-props=\"{&quot;user&quot;:&quot;juewang&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/juewang\"\
          >@<span class=\"underline\">juewang</span></a></span>\n\n\t</span></span>\
          \ you really are amazing and helpful in helping out, I have been following\
          \ you in the discussions here.<br>I need guidance in my project if you could\
          \ help.</p>\n<p>I want to tune the model (if it is possible either with\
          \ the Trainer or other way) with some dataset of specific domain and then\
          \ I should be able to ask the questions. Now, here I can see that we also\
          \ need to pass the context from which we need to generate the answer.</p>\n\
          <p>Is there a way that doesn't require the context to be supplied? Just\
          \ ask question and the model can answer? Like the close book answering procedure?\
          \ If yes, could you direct me in that direction please.</p>\n<p>Thanks,<br>Aayush</p>\n"
        raw: 'Hey, @juewang you really are amazing and helpful in helping out, I have
          been following you in the discussions here.

          I need guidance in my project if you could help.


          I want to tune the model (if it is possible either with the Trainer or other
          way) with some dataset of specific domain and then I should be able to ask
          the questions. Now, here I can see that we also need to pass the context
          from which we need to generate the answer.


          Is there a way that doesn''t require the context to be supplied? Just ask
          question and the model can answer? Like the close book answering procedure?
          If yes, could you direct me in that direction please.


          Thanks,

          Aayush'
        updatedAt: '2023-03-09T02:42:22.415Z'
      numEdits: 0
      reactions: []
    id: 6409478e78566d59c4dc1e90
    type: comment
  author: AayushShah
  content: 'Hey, @juewang you really are amazing and helpful in helping out, I have
    been following you in the discussions here.

    I need guidance in my project if you could help.


    I want to tune the model (if it is possible either with the Trainer or other way)
    with some dataset of specific domain and then I should be able to ask the questions.
    Now, here I can see that we also need to pass the context from which we need to
    generate the answer.


    Is there a way that doesn''t require the context to be supplied? Just ask question
    and the model can answer? Like the close book answering procedure? If yes, could
    you direct me in that direction please.


    Thanks,

    Aayush'
  created_at: 2023-03-09 02:42:22+00:00
  edited: false
  hidden: false
  id: 6409478e78566d59c4dc1e90
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669380535028-61dce5c2af6d5e733e0fb08b.jpeg?w=200&h=200&f=face
      fullname: Jue Wang
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: juewang
      type: user
    createdAt: '2023-03-11T09:18:03.000Z'
    data:
      edited: false
      editors:
      - juewang
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669380535028-61dce5c2af6d5e733e0fb08b.jpeg?w=200&h=200&f=face
          fullname: Jue Wang
          isHf: false
          isPro: false
          name: juewang
          type: user
        html: "<blockquote>\n<p>Hey, <span data-props=\"{&quot;user&quot;:&quot;juewang&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/juewang\"\
          >@<span class=\"underline\">juewang</span></a></span>\n\n\t</span></span>\
          \ you really are amazing and helpful in helping out, I have been following\
          \ you in the discussions here.<br>I need guidance in my project if you could\
          \ help.</p>\n<p>I want to tune the model (if it is possible either with\
          \ the Trainer or other way) with some dataset of specific domain and then\
          \ I should be able to ask the questions. Now, here I can see that we also\
          \ need to pass the context from which we need to generate the answer.</p>\n\
          <p>Is there a way that doesn't require the context to be supplied? Just\
          \ ask question and the model can answer? Like the close book answering procedure?\
          \ If yes, could you direct me in that direction please.</p>\n<p>Thanks,<br>Aayush</p>\n\
          </blockquote>\n<p>Hello! Sure, closed-book answering is possible! We have\
          \ recently released OpenChatKit, along with its <a rel=\"nofollow\" href=\"\
          https://github.com/togethercomputer/OpenChatKit/tree/main/training\">training\
          \ code base</a>, which is designed for training chatbot models but can also\
          \ be used to fine-tune GPT-JT (with <code>dist_prefixlm_train.py</code>).\
          \ You shall prepare your dataset in <code>jsonl</code> format and perform\
          \ fine-tuning.</p>\n"
        raw: "> Hey, @juewang you really are amazing and helpful in helping out, I\
          \ have been following you in the discussions here.\n> I need guidance in\
          \ my project if you could help.\n> \n> I want to tune the model (if it is\
          \ possible either with the Trainer or other way) with some dataset of specific\
          \ domain and then I should be able to ask the questions. Now, here I can\
          \ see that we also need to pass the context from which we need to generate\
          \ the answer.\n> \n> Is there a way that doesn't require the context to\
          \ be supplied? Just ask question and the model can answer? Like the close\
          \ book answering procedure? If yes, could you direct me in that direction\
          \ please.\n> \n> Thanks,\n> Aayush\n\nHello! Sure, closed-book answering\
          \ is possible! We have recently released OpenChatKit, along with its [training\
          \ code base](https://github.com/togethercomputer/OpenChatKit/tree/main/training),\
          \ which is designed for training chatbot models but can also be used to\
          \ fine-tune GPT-JT (with `dist_prefixlm_train.py`). You shall prepare your\
          \ dataset in `jsonl` format and perform fine-tuning."
        updatedAt: '2023-03-11T09:18:03.551Z'
      numEdits: 0
      reactions: []
    id: 640c474bb34b3bd49130eca6
    type: comment
  author: juewang
  content: "> Hey, @juewang you really are amazing and helpful in helping out, I have\
    \ been following you in the discussions here.\n> I need guidance in my project\
    \ if you could help.\n> \n> I want to tune the model (if it is possible either\
    \ with the Trainer or other way) with some dataset of specific domain and then\
    \ I should be able to ask the questions. Now, here I can see that we also need\
    \ to pass the context from which we need to generate the answer.\n> \n> Is there\
    \ a way that doesn't require the context to be supplied? Just ask question and\
    \ the model can answer? Like the close book answering procedure? If yes, could\
    \ you direct me in that direction please.\n> \n> Thanks,\n> Aayush\n\nHello! Sure,\
    \ closed-book answering is possible! We have recently released OpenChatKit, along\
    \ with its [training code base](https://github.com/togethercomputer/OpenChatKit/tree/main/training),\
    \ which is designed for training chatbot models but can also be used to fine-tune\
    \ GPT-JT (with `dist_prefixlm_train.py`). You shall prepare your dataset in `jsonl`\
    \ format and perform fine-tuning."
  created_at: 2023-03-11 09:18:03+00:00
  edited: false
  hidden: false
  id: 640c474bb34b3bd49130eca6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: togethercomputer/GPT-JT-6B-v1
repo_type: model
status: open
target_branch: null
title: Question-Answering over documents
