!!python/object:huggingface_hub.community.DiscussionWithDetails
author: vilimus
conflicting_files: null
created_at: 2022-12-12 03:53:55+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/2d82507650914477b00449d3a7214417.svg
      fullname: "vilimus\U0001F3F3\uFE0F\u200D\u26A7\uFE0F"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vilimus
      type: user
    createdAt: '2022-12-12T03:53:55.000Z'
    data:
      edited: true
      editors:
      - vilimus
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/2d82507650914477b00449d3a7214417.svg
          fullname: "vilimus\U0001F3F3\uFE0F\u200D\u26A7\uFE0F"
          isHf: false
          isPro: false
          name: vilimus
          type: user
        html: '<p>I wonder if there are any plans to produce an 8bit (quantized) version
          of GPT-JT, as was done for the original GPT-J in <a href="https://huggingface.co/hivemind/gpt-j-6B-8bit">hivemind/gpt-j-6B-8bit</a>.
          Could address steep hardware requirements as in <a href="https://huggingface.co/togethercomputer/GPT-JT-6B-v1/discussions/9">discussion
          </a><a href="/togethercomputer/GPT-JT-6B-v1/discussions/9">#9</a>.</p>

          <p>hivemind provides the script they used to quantize GPT-J (convert-gpt-j.ipynb
          in the model repo), but my attempt was unsuccessful.</p>

          '
        raw: 'I wonder if there are any plans to produce an 8bit (quantized) version
          of GPT-JT, as was done for the original GPT-J in [hivemind/gpt-j-6B-8bit](https://huggingface.co/hivemind/gpt-j-6B-8bit).
          Could address steep hardware requirements as in [discussion #9](https://huggingface.co/togethercomputer/GPT-JT-6B-v1/discussions/9).


          hivemind provides the script they used to quantize GPT-J (convert-gpt-j.ipynb
          in the model repo), but my attempt was unsuccessful.'
        updatedAt: '2022-12-12T03:58:05.629Z'
      numEdits: 4
      reactions: []
    id: 6396a5d3e6e09d597d614745
    type: comment
  author: vilimus
  content: 'I wonder if there are any plans to produce an 8bit (quantized) version
    of GPT-JT, as was done for the original GPT-J in [hivemind/gpt-j-6B-8bit](https://huggingface.co/hivemind/gpt-j-6B-8bit).
    Could address steep hardware requirements as in [discussion #9](https://huggingface.co/togethercomputer/GPT-JT-6B-v1/discussions/9).


    hivemind provides the script they used to quantize GPT-J (convert-gpt-j.ipynb
    in the model repo), but my attempt was unsuccessful.'
  created_at: 2022-12-12 03:53:55+00:00
  edited: true
  hidden: false
  id: 6396a5d3e6e09d597d614745
  type: comment
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/2d82507650914477b00449d3a7214417.svg
      fullname: "vilimus\U0001F3F3\uFE0F\u200D\u26A7\uFE0F"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vilimus
      type: user
    createdAt: '2022-12-12T03:57:38.000Z'
    data:
      from: Quantization of GPT-JT
      to: Quantization
    id: 6396a6b2e6e09d597d6160a8
    type: title-change
  author: vilimus
  created_at: 2022-12-12 03:57:38+00:00
  id: 6396a6b2e6e09d597d6160a8
  new_title: Quantization
  old_title: Quantization of GPT-JT
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionTitleChange
  _event:
    author:
      avatarUrl: /avatars/2d82507650914477b00449d3a7214417.svg
      fullname: "vilimus\U0001F3F3\uFE0F\u200D\u26A7\uFE0F"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vilimus
      type: user
    createdAt: '2022-12-18T05:17:13.000Z'
    data:
      from: Quantization
      to: 8bit quantization
    id: 639ea2597145123e0d5c700b
    type: title-change
  author: vilimus
  created_at: 2022-12-18 05:17:13+00:00
  id: 639ea2597145123e0d5c700b
  new_title: 8bit quantization
  old_title: Quantization
  type: title-change
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669349247932-62d8e171c60d1450a1ee17d2.png?w=200&h=200&f=face
      fullname: Vipul Ved Prakash
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: true
      name: vipul
      type: user
    createdAt: '2022-12-24T09:06:29.000Z'
    data:
      edited: false
      editors:
      - vipul
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1669349247932-62d8e171c60d1450a1ee17d2.png?w=200&h=200&f=face
          fullname: Vipul Ved Prakash
          isHf: false
          isPro: true
          name: vipul
          type: user
        html: '<p>We have one in the lab, and does quite well on benchmarks. We''ll
          release it once we''ve done more performance work on it.</p>

          '
        raw: We have one in the lab, and does quite well on benchmarks. We'll release
          it once we've done more performance work on it.
        updatedAt: '2022-12-24T09:06:29.013Z'
      numEdits: 0
      reactions:
      - count: 6
        reaction: "\u2764\uFE0F"
        users:
        - mbukowski
        - DarwinAnim8or
        - yahma
        - nicolasmicaux
        - JunnanLi
        - appvoid
      - count: 2
        reaction: "\U0001F44D"
        users:
        - yahma
        - JunnanLi
    id: 63a6c115212304972a737b06
    type: comment
  author: vipul
  content: We have one in the lab, and does quite well on benchmarks. We'll release
    it once we've done more performance work on it.
  created_at: 2022-12-24 09:06:29+00:00
  edited: false
  hidden: false
  id: 63a6c115212304972a737b06
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663665910626-60afb2c0f4592396928ef8ac.png?w=200&h=200&f=face
      fullname: Alberto Cetoli
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: true
      name: fractalego
      type: user
    createdAt: '2023-01-01T00:32:46.000Z'
    data:
      edited: false
      editors:
      - fractalego
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1663665910626-60afb2c0f4592396928ef8ac.png?w=200&h=200&f=face
          fullname: Alberto Cetoli
          isHf: false
          isPro: true
          name: fractalego
          type: user
        html: '<p>I''ve used from_pretrained(... , load_in_8bit=True) and it seems
          to work. Haven''t benchmarked it yet. Memory-wise it seems to stay under
          10GB this way.</p>

          '
        raw: I've used from_pretrained(... , load_in_8bit=True) and it seems to work.
          Haven't benchmarked it yet. Memory-wise it seems to stay under 10GB this
          way.
        updatedAt: '2023-01-01T00:32:46.536Z'
      numEdits: 0
      reactions: []
    id: 63b0d4ae4355994b16a7d5ba
    type: comment
  author: fractalego
  content: I've used from_pretrained(... , load_in_8bit=True) and it seems to work.
    Haven't benchmarked it yet. Memory-wise it seems to stay under 10GB this way.
  created_at: 2023-01-01 00:32:46+00:00
  edited: false
  hidden: false
  id: 63b0d4ae4355994b16a7d5ba
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1ed4ae9be9492e21d8296ccb2d2629fd.svg
      fullname: Max
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: DarwinAnim8or
      type: user
    createdAt: '2023-01-05T03:19:55.000Z'
    data:
      edited: false
      editors:
      - DarwinAnim8or
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1ed4ae9be9492e21d8296ccb2d2629fd.svg
          fullname: Max
          isHf: false
          isPro: false
          name: DarwinAnim8or
          type: user
        html: '<blockquote>

          <p>We have one in the lab, and does quite well on benchmarks. We''ll release
          it once we''ve done more performance work on it.</p>

          </blockquote>

          <p>This is exciting news! Any idea how the performance stacks up to the
          regular version? (if you can share that already of course)</p>

          '
        raw: '> We have one in the lab, and does quite well on benchmarks. We''ll
          release it once we''ve done more performance work on it.


          This is exciting news! Any idea how the performance stacks up to the regular
          version? (if you can share that already of course)'
        updatedAt: '2023-01-05T03:19:55.399Z'
      numEdits: 0
      reactions: []
    id: 63b641db58b5e43bddf74e2b
    type: comment
  author: DarwinAnim8or
  content: '> We have one in the lab, and does quite well on benchmarks. We''ll release
    it once we''ve done more performance work on it.


    This is exciting news! Any idea how the performance stacks up to the regular version?
    (if you can share that already of course)'
  created_at: 2023-01-05 03:19:55+00:00
  edited: false
  hidden: false
  id: 63b641db58b5e43bddf74e2b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672330023435-62c6faed53c7156f5bf767ed.png?w=200&h=200&f=face
      fullname: Gene Ruebsamen
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: yahma
      type: user
    createdAt: '2023-01-06T16:27:18.000Z'
    data:
      edited: false
      editors:
      - yahma
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672330023435-62c6faed53c7156f5bf767ed.png?w=200&h=200&f=face
          fullname: Gene Ruebsamen
          isHf: false
          isPro: false
          name: yahma
          type: user
        html: '<p>Looking forward to the release of the 8-bit quantized model.. </p>

          <p>Considering the UL2 training objective used in this model, would adjustments
          need to be made to fine-tuning this model, or is it no different than fine-tuning
          regular GPT-J?</p>

          '
        raw: "Looking forward to the release of the 8-bit quantized model.. \n\nConsidering\
          \ the UL2 training objective used in this model, would adjustments need\
          \ to be made to fine-tuning this model, or is it no different than fine-tuning\
          \ regular GPT-J?"
        updatedAt: '2023-01-06T16:27:18.924Z'
      numEdits: 0
      reactions: []
    id: 63b84be6fcdb2323b1d3454d
    type: comment
  author: yahma
  content: "Looking forward to the release of the 8-bit quantized model.. \n\nConsidering\
    \ the UL2 training objective used in this model, would adjustments need to be\
    \ made to fine-tuning this model, or is it no different than fine-tuning regular\
    \ GPT-J?"
  created_at: 2023-01-06 16:27:18+00:00
  edited: false
  hidden: false
  id: 63b84be6fcdb2323b1d3454d
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 12
repo_id: togethercomputer/GPT-JT-6B-v1
repo_type: model
status: open
target_branch: null
title: 8bit quantization
