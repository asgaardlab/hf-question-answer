!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xiaojinchuan
conflicting_files: null
created_at: 2023-06-08 07:04:14+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/667e46d953482c66d4bb63620e76fb4d.svg
      fullname: xiaojinchuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xiaojinchuan
      type: user
    createdAt: '2023-06-08T08:04:14.000Z'
    data:
      edited: false
      editors:
      - xiaojinchuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.29817962646484375
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/667e46d953482c66d4bb63620e76fb4d.svg
          fullname: xiaojinchuan
          isHf: false
          isPro: false
          name: xiaojinchuan
          type: user
        html: '<p><a rel="nofollow" href="https://cdn-uploads.huggingface.co/production/uploads/647ef5cbaa8c04bbf9360844/DrlG9cXbbFfjVE_LcGTvS.png"><img
          alt="image.png" src="https://cdn-uploads.huggingface.co/production/uploads/647ef5cbaa8c04bbf9360844/DrlG9cXbbFfjVE_LcGTvS.png"></a></p>

          '
        raw: "\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/647ef5cbaa8c04bbf9360844/DrlG9cXbbFfjVE_LcGTvS.png)\r\
          \n\r\n"
        updatedAt: '2023-06-08T08:04:14.889Z'
      numEdits: 0
      reactions: []
    id: 64818b7e50b759c75d5d9a78
    type: comment
  author: xiaojinchuan
  content: "\r\n![image.png](https://cdn-uploads.huggingface.co/production/uploads/647ef5cbaa8c04bbf9360844/DrlG9cXbbFfjVE_LcGTvS.png)\r\
    \n\r\n"
  created_at: 2023-06-08 07:04:14+00:00
  edited: false
  hidden: false
  id: 64818b7e50b759c75d5d9a78
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-08T08:19:33.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9185382723808289
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>There''s a bug in llama.cpp at the moment, where on Windows the
          new quant methods result in gibberish: <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/issues/1735">https://github.com/ggerganov/llama.cpp/issues/1735</a></p>

          <p>Please follow the above Issue for further details.  You could maybe try
          going back to an older build of llama.cpp</p>

          '
        raw: 'There''s a bug in llama.cpp at the moment, where on Windows the new
          quant methods result in gibberish: https://github.com/ggerganov/llama.cpp/issues/1735


          Please follow the above Issue for further details.  You could maybe try
          going back to an older build of llama.cpp'
        updatedAt: '2023-06-08T08:19:33.413Z'
      numEdits: 0
      reactions: []
    id: 64818f15722e358ebf83dffb
    type: comment
  author: TheBloke
  content: 'There''s a bug in llama.cpp at the moment, where on Windows the new quant
    methods result in gibberish: https://github.com/ggerganov/llama.cpp/issues/1735


    Please follow the above Issue for further details.  You could maybe try going
    back to an older build of llama.cpp'
  created_at: 2023-06-08 07:19:33+00:00
  edited: false
  hidden: false
  id: 64818f15722e358ebf83dffb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/667e46d953482c66d4bb63620e76fb4d.svg
      fullname: xiaojinchuan
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xiaojinchuan
      type: user
    createdAt: '2023-06-08T08:45:39.000Z'
    data:
      edited: false
      editors:
      - xiaojinchuan
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.911816418170929
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/667e46d953482c66d4bb63620e76fb4d.svg
          fullname: xiaojinchuan
          isHf: false
          isPro: false
          name: xiaojinchuan
          type: user
        html: '<blockquote>

          <p>There''s a bug in llama.cpp at the moment, where on Windows the new quant
          methods result in gibberish: <a rel="nofollow" href="https://github.com/ggerganov/llama.cpp/issues/1735">https://github.com/ggerganov/llama.cpp/issues/1735</a></p>

          <p>Please follow the above Issue for further details.  You could maybe try
          going back to an older build of llama.cpp</p>

          </blockquote>

          <p>I''m running on ubuntu, does the bug described above only affect windows?<br>Thank
          you so much!</p>

          '
        raw: "> There's a bug in llama.cpp at the moment, where on Windows the new\
          \ quant methods result in gibberish: https://github.com/ggerganov/llama.cpp/issues/1735\n\
          > \n> Please follow the above Issue for further details.  You could maybe\
          \ try going back to an older build of llama.cpp\n\nI'm running on ubuntu,\
          \ does the bug described above only affect windows?\nThank you so much!"
        updatedAt: '2023-06-08T08:45:39.260Z'
      numEdits: 0
      reactions: []
    id: 6481953317f2fba0008846ab
    type: comment
  author: xiaojinchuan
  content: "> There's a bug in llama.cpp at the moment, where on Windows the new quant\
    \ methods result in gibberish: https://github.com/ggerganov/llama.cpp/issues/1735\n\
    > \n> Please follow the above Issue for further details.  You could maybe try\
    \ going back to an older build of llama.cpp\n\nI'm running on ubuntu, does the\
    \ bug described above only affect windows?\nThank you so much!"
  created_at: 2023-06-08 07:45:39+00:00
  edited: false
  hidden: false
  id: 6481953317f2fba0008846ab
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-06-08T08:53:13.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9764782190322876
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Everyone reporting it on that thread is using Windows.  But your
          symptom is the same, and the developer does mention that theoretically the
          bug could exist in Linux also.</p>

          <p>Could you please post in the bug report Issue and give your findings?</p>

          <p>In any case there''s nothing I can do about it, as the models themselves
          do work OK.</p>

          '
        raw: 'Everyone reporting it on that thread is using Windows.  But your symptom
          is the same, and the developer does mention that theoretically the bug could
          exist in Linux also.


          Could you please post in the bug report Issue and give your findings?


          In any case there''s nothing I can do about it, as the models themselves
          do work OK.'
        updatedAt: '2023-06-08T08:53:13.204Z'
      numEdits: 0
      reactions: []
    id: 648196f9722e358ebf84827b
    type: comment
  author: TheBloke
  content: 'Everyone reporting it on that thread is using Windows.  But your symptom
    is the same, and the developer does mention that theoretically the bug could exist
    in Linux also.


    Could you please post in the bug report Issue and give your findings?


    In any case there''s nothing I can do about it, as the models themselves do work
    OK.'
  created_at: 2023-06-08 07:53:13+00:00
  edited: false
  hidden: false
  id: 648196f9722e358ebf84827b
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: TheBloke/guanaco-33B-GGML
repo_type: model
status: open
target_branch: null
title: Run guanaco model with llama.cpp,  get gibberish output.
