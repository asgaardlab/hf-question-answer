!!python/object:huggingface_hub.community.DiscussionWithDetails
author: SFconvertbot
conflicting_files: []
created_at: 2023-08-22 15:00:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/635fd4cc14657fb8cff2a081/GDkyDwAcuqDBpaOvQgJuq.png?w=200&h=200&f=face
      fullname: Safetensors convertbot
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SFconvertbot
      type: user
    createdAt: '2023-08-22T16:00:09.000Z'
    data:
      edited: false
      editors:
      - SFconvertbot
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.881471574306488
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/635fd4cc14657fb8cff2a081/GDkyDwAcuqDBpaOvQgJuq.png?w=200&h=200&f=face
          fullname: Safetensors convertbot
          isHf: false
          isPro: false
          name: SFconvertbot
          type: user
        html: '<p>This is an automated PR created with <a href="https://huggingface.co/spaces/safetensors/convert">https://huggingface.co/spaces/safetensors/convert</a></p>

          <p>This new file is equivalent to <code>pytorch_model.bin</code> but safe
          in the sense that<br>no arbitrary code can be put into it.</p>

          <p>These files also happen to load much faster than their pytorch counterpart:<br><a
          rel="nofollow" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/safetensors_doc/en/speed.ipynb">https://colab.research.google.com/github/huggingface/notebooks/blob/main/safetensors_doc/en/speed.ipynb</a></p>

          <p>The widgets on your model page will run using this model even if this
          is not merged<br>making sure the file actually works.</p>

          <p>If you find any issues: please report here: <a href="https://huggingface.co/spaces/safetensors/convert/discussions">https://huggingface.co/spaces/safetensors/convert/discussions</a></p>

          <p>Feel free to ignore this PR.</p>

          '
        raw: 'This is an automated PR created with https://huggingface.co/spaces/safetensors/convert


          This new file is equivalent to `pytorch_model.bin` but safe in the sense
          that

          no arbitrary code can be put into it.


          These files also happen to load much faster than their pytorch counterpart:

          https://colab.research.google.com/github/huggingface/notebooks/blob/main/safetensors_doc/en/speed.ipynb


          The widgets on your model page will run using this model even if this is
          not merged

          making sure the file actually works.


          If you find any issues: please report here: https://huggingface.co/spaces/safetensors/convert/discussions


          Feel free to ignore this PR.'
        updatedAt: '2023-08-22T16:00:09.573Z'
      numEdits: 0
      reactions: []
    id: 64e4db891887a952de9f7dec
    type: comment
  author: SFconvertbot
  content: 'This is an automated PR created with https://huggingface.co/spaces/safetensors/convert


    This new file is equivalent to `pytorch_model.bin` but safe in the sense that

    no arbitrary code can be put into it.


    These files also happen to load much faster than their pytorch counterpart:

    https://colab.research.google.com/github/huggingface/notebooks/blob/main/safetensors_doc/en/speed.ipynb


    The widgets on your model page will run using this model even if this is not merged

    making sure the file actually works.


    If you find any issues: please report here: https://huggingface.co/spaces/safetensors/convert/discussions


    Feel free to ignore this PR.'
  created_at: 2023-08-22 15:00:09+00:00
  edited: false
  hidden: false
  id: 64e4db891887a952de9f7dec
  type: comment
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/635fd4cc14657fb8cff2a081/GDkyDwAcuqDBpaOvQgJuq.png?w=200&h=200&f=face
      fullname: Safetensors convertbot
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: SFconvertbot
      type: user
    createdAt: '2023-08-22T16:00:10.000Z'
    data:
      oid: c94de34263f29f94b7fb0686498fcbd0d7e841ec
      parents:
      - 6ab22205dde06da3a07e47abaa994460125bfd90
      subject: Adding `safetensors` variant of this model
    id: 64e4db8a0000000000000000
    type: commit
  author: SFconvertbot
  created_at: 2023-08-22 15:00:10+00:00
  id: 64e4db8a0000000000000000
  oid: c94de34263f29f94b7fb0686498fcbd0d7e841ec
  summary: Adding `safetensors` variant of this model
  type: commit
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/1018b29e2da89f5920a58482e17a1948.svg
      fullname: J Bochi
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: jbochi
      type: user
    createdAt: '2023-09-19T21:04:32.000Z'
    data:
      edited: false
      editors:
      - jbochi
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7345059514045715
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/1018b29e2da89f5920a58482e17a1948.svg
          fullname: J Bochi
          isHf: false
          isPro: false
          name: jbochi
          type: user
        html: "<p>I tested this PR with candle (requires <a rel=\"nofollow\" href=\"\
          https://github.com/huggingface/candle/pull/903\">https://github.com/huggingface/candle/pull/903</a>):</p>\n\
          <pre><code> $ cargo run --release --example t5 -- --model-id \"grammarly/coedit-large\"\
          \ --revision \"refs/pr/4\"   --prompt \"Fix the grammar: When I grow up,\
          \ I start to understand what he said is quite right.\" --temperature 0 --decode\n\
          \   Compiling candle-transformers v0.2.3 (/Users/jbochi/dev/github/huggingface/candle/candle-transformers)\n\
          \   Compiling candle-examples v0.2.3 (/Users/jbochi/dev/github/huggingface/candle/candle-examples)\n\
          \    Finished release [optimized] target(s) in 6.58s\n     Running `target/release/examples/t5\
          \ --model-id grammarly/coedit-large --revision refs/pr/4 --prompt 'Fix the\
          \ grammar: When I grow up, I start to understand what he said is quite right.'\
          \ --temperature 0 --decode`\nRunning on CPU, to run on GPU, build this example\
          \ with `--features cuda`\n When I grow up, I will start to understand what\
          \ he said is quite right.\n19 tokens generated (4.72 token/s)\n</code></pre>\n"
        raw: "I tested this PR with candle (requires https://github.com/huggingface/candle/pull/903):\n\
          \n```\n $ cargo run --release --example t5 -- --model-id \"grammarly/coedit-large\"\
          \ --revision \"refs/pr/4\"   --prompt \"Fix the grammar: When I grow up,\
          \ I start to understand what he said is quite right.\" --temperature 0 --decode\n\
          \   Compiling candle-transformers v0.2.3 (/Users/jbochi/dev/github/huggingface/candle/candle-transformers)\n\
          \   Compiling candle-examples v0.2.3 (/Users/jbochi/dev/github/huggingface/candle/candle-examples)\n\
          \    Finished release [optimized] target(s) in 6.58s\n     Running `target/release/examples/t5\
          \ --model-id grammarly/coedit-large --revision refs/pr/4 --prompt 'Fix the\
          \ grammar: When I grow up, I start to understand what he said is quite right.'\
          \ --temperature 0 --decode`\nRunning on CPU, to run on GPU, build this example\
          \ with `--features cuda`\n When I grow up, I will start to understand what\
          \ he said is quite right.\n19 tokens generated (4.72 token/s)\n```\n"
        updatedAt: '2023-09-19T21:04:32.958Z'
      numEdits: 0
      reactions: []
    id: 650a0ce0ad753305dedc7e94
    type: comment
  author: jbochi
  content: "I tested this PR with candle (requires https://github.com/huggingface/candle/pull/903):\n\
    \n```\n $ cargo run --release --example t5 -- --model-id \"grammarly/coedit-large\"\
    \ --revision \"refs/pr/4\"   --prompt \"Fix the grammar: When I grow up, I start\
    \ to understand what he said is quite right.\" --temperature 0 --decode\n   Compiling\
    \ candle-transformers v0.2.3 (/Users/jbochi/dev/github/huggingface/candle/candle-transformers)\n\
    \   Compiling candle-examples v0.2.3 (/Users/jbochi/dev/github/huggingface/candle/candle-examples)\n\
    \    Finished release [optimized] target(s) in 6.58s\n     Running `target/release/examples/t5\
    \ --model-id grammarly/coedit-large --revision refs/pr/4 --prompt 'Fix the grammar:\
    \ When I grow up, I start to understand what he said is quite right.' --temperature\
    \ 0 --decode`\nRunning on CPU, to run on GPU, build this example with `--features\
    \ cuda`\n When I grow up, I will start to understand what he said is quite right.\n\
    19 tokens generated (4.72 token/s)\n```\n"
  created_at: 2023-09-19 20:04:32+00:00
  edited: false
  hidden: false
  id: 650a0ce0ad753305dedc7e94
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/3c37bf4b7c9db83a46af7c473ee4eb86.svg
      fullname: Vipul Raheja
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: machineteacher
      type: user
    createdAt: '2023-09-19T22:40:42.000Z'
    data:
      status: merged
    id: 650a236ab5a04c8675dde78e
    type: status-change
  author: machineteacher
  created_at: 2023-09-19 21:40:42+00:00
  id: 650a236ab5a04c8675dde78e
  new_status: merged
  type: status-change
is_pull_request: true
merge_commit_oid: 50ea1631f35aaba1fe7a1157cf92b40ab3c0be09
num: 4
repo_id: grammarly/coedit-large
repo_type: model
status: merged
target_branch: refs/heads/main
title: Adding `safetensors` variant of this model
