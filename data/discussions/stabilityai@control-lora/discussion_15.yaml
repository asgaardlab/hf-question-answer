!!python/object:huggingface_hub.community.DiscussionWithDetails
author: Managerfirst
conflicting_files: null
created_at: 2023-08-22 04:43:37+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/bfabb78a0b6509e36e6f421b4a9e58c8.svg
      fullname: Manager First
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Managerfirst
      type: user
    createdAt: '2023-08-22T05:43:37.000Z'
    data:
      edited: false
      editors:
      - Managerfirst
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.27171075344085693
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/bfabb78a0b6509e36e6f421b4a9e58c8.svg
          fullname: Manager First
          isHf: false
          isPro: false
          name: Managerfirst
          type: user
        html: '<p>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\execution.py",
          line 151, in recursive_execute<br>output_data, output_ui = get_output_data(obj,
          input_data_all)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\execution.py",
          line 81, in get_output_data<br>return_values = map_node_over_list(obj, input_data_all,
          obj.FUNCTION, allow_interrupt=True)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\execution.py",
          line 74, in map_node_over_list<br>results.append(getattr(obj, func)(**slice_dict(input_data_all,
          i)))<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\nodes.py",
          line 1206, in sample<br>return common_ksampler(model, seed, steps, cfg,
          sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\nodes.py",
          line 1176, in common_ksampler<br>samples = comfy.sample.sample(model, noise,
          steps, cfg, sampler_name, scheduler, positive, negative, latent_image,<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\sample.py",
          line 93, in sample<br>samples = sampler.sample(noise, positive_copy, negative_copy,
          cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step,
          force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas,
          callback=callback, disable_pbar=disable_pbar, seed=seed)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\samplers.py",
          line 733, in sample<br>samples = getattr(k_diffusion_sampling, "sample_{}".format(self.sampler))(self.model_k,
          noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch\utils_contextlib.py",
          line 115, in decorate_context<br>return func(*args, **kwargs)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\k_diffusion\sampling.py",
          line 154, in sample_euler_ancestral<br>denoised = model(x, sigmas[i] * s_in,
          **extra_args)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch\nn\modules\module.py",
          line 1501, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\samplers.py",
          line 323, in forward<br>out = self.inner_model(x, sigma, cond=cond, uncond=uncond,
          cond_scale=cond_scale, cond_concat=cond_concat, model_options=model_options,
          seed=seed)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch\nn\modules\module.py",
          line 1501, in <em>call_impl<br>return forward_call(*args, **kwargs)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\k_diffusion\external.py",
          line 125, in forward<br>eps = self.get_eps(input * c_in, self.sigma_to_t(sigma),
          **kwargs)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\k_diffusion\external.py",
          line 151, in get_eps<br>return self.inner_model.apply_model(*args, **kwargs)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\samplers.py",
          line 311, in apply_model<br>out = sampling_function(self.inner_model.apply_model,
          x, timestep, uncond, cond, cond_scale, cond_concat, model_options=model_options,
          seed=seed)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\samplers.py",
          line 289, in sampling_function<br>cond, uncond = calc_cond_uncond_batch(model_function,
          cond, uncond, x, timestep, max_total_area, cond_concat, model_options)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\samplers.py",
          line 241, in calc_cond_uncond_batch<br>c[''control''] = control.get_control(input_x,
          timestep</em>, c, len(cond_or_uncond))<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\sd.py",
          line 809, in get_control<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch\nn\modules\module.py",
          line 1501, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\cldm\cldm.py",
          line 307, in forward<br>return outs<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch\nn\modules\module.py",
          line 1501, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py",
          line 43, in forward<br>x = layer(x, context, transformer_options)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch\nn\modules\module.py",
          line 1501, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\ldm\modules\attention.py",
          line 696, in forward<br>x = block(x, context=context[i], transformer_options=transformer_options)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch\nn\modules\module.py",
          line 1501, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\ldm\modules\attention.py",
          line 528, in forward<br>return checkpoint(self._forward, (x, context, transformer_options),
          self.parameters(), self.checkpoint)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\ldm\modules\diffusionmodules\util.py",
          line 123, in checkpoint<br>return func(*inputs)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\ldm\modules\attention.py",
          line 628, in _forward<br>n = self.attn2(n, context=context_attn2, value=value_attn2)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch\nn\modules\module.py",
          line 1501, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\ldm\modules\attention.py",
          line 421, in forward<br>q = self.to_q(x)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch\nn\modules\module.py",
          line 1501, in _call_impl<br>return forward_call(*args, **kwargs)<br>File
          "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\ComfyUI\comfy\sd.py",
          line 862, in forward<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch_prims_common\wrappers.py",
          line 220, in <em>fn<br>result = fn(*args, **kwargs)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch_prims_common\wrappers.py",
          line 130, in <em>fn<br>result = fn(**bound.arguments)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch_refs_<em>init</em></em>.py",
          line 975, in add<br>return prims.add(a, b)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch_ops.py",
          line 287, in <strong>call</strong><br>return self.<em>op(*args, **kwargs
          or {})<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch_prims_<em>init</em></em>.py",
          line 346, in <em>elementwise_meta<br>utils.check_same_device(*args</em>,
          allow_cpu_scalar_tensors=True)<br>File "D:\ComfyUI_windows_portable_nvidia_cu118_or_cpu\ComfyUI_windows_portable\python_embeded\lib\site-packages\torch_prims_common_<em>init</em></em>.py",
          line 596, in check_same_device<br>raise RuntimeError(msg)</p>

          <hr>

          <p>It only seems to happen once I have already made one canny or depth image
          with the new clora, then I cannot make any more I have to go to another
          workflow, reload the already "loaded" tensors, and then go back and load
          the model a third time for only a single new image to complete...</p>

          <p>Anyone know how to fix this on the windows portable install? I installed
          the nodes through Comfy Manager.</p>

          <p>Thanks!</p>

          '
        raw: "File \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\execution.py\", line 151, in recursive_execute\r\noutput_data,\
          \ output_ui = get_output_data(obj, input_data_all)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 81, in get_output_data\r\
          \nreturn_values = map_node_over_list(obj, input_data_all, obj.FUNCTION,\
          \ allow_interrupt=True)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 74, in map_node_over_list\r\
          \nresults.append(getattr(obj, func)(**slice_dict(input_data_all, i)))\r\n\
          File \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\nodes.py\", line 1206, in sample\r\nreturn common_ksampler(model,\
          \ seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\
          \ denoise=denoise)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\nodes.py\", line 1176, in common_ksampler\r\
          \nsamples = comfy.sample.sample(model, noise, steps, cfg, sampler_name,\
          \ scheduler, positive, negative, latent_image,\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\comfy\\sample.py\", line 93, in sample\r\
          \nsamples = sampler.sample(noise, positive_copy, negative_copy, cfg=cfg,\
          \ latent_image=latent_image, start_step=start_step, last_step=last_step,\
          \ force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas,\
          \ callback=callback, disable_pbar=disable_pbar, seed=seed)\r\nFile \"D:\\\
          ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\comfy\\samplers.py\", line 733, in sample\r\nsamples = getattr(k_diffusion_sampling,\
          \ \"sample_{}\".format(self.sampler))(self.model_k, noise, sigmas, extra_args=extra_args,\
          \ callback=k_callback, disable=disable_pbar)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\utils\\\
          _contextlib.py\", line 115, in decorate_context\r\nreturn func(*args, **kwargs)\r\
          \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\comfy\\k_diffusion\\sampling.py\", line 154, in sample_euler_ancestral\r\
          \ndenoised = model(x, sigmas[i] * s_in, **extra_args)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\nn\\\
          modules\\module.py\", line 1501, in _call_impl\r\nreturn forward_call(*args,\
          \ **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\comfy\\samplers.py\", line 323, in forward\r\
          \nout = self.inner_model(x, sigma, cond=cond, uncond=uncond, cond_scale=cond_scale,\
          \ cond_concat=cond_concat, model_options=model_options, seed=seed)\r\nFile\
          \ \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          python_embeded\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line\
          \ 1501, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\nFile \"\
          D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\comfy\\k_diffusion\\external.py\", line 125, in forward\r\neps\
          \ = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\r\nFile\
          \ \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\comfy\\k_diffusion\\external.py\", line 151, in get_eps\r\nreturn\
          \ self.inner_model.apply_model(*args, **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\comfy\\samplers.py\", line 311, in apply_model\r\
          \nout = sampling_function(self.inner_model.apply_model, x, timestep, uncond,\
          \ cond, cond_scale, cond_concat, model_options=model_options, seed=seed)\r\
          \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\comfy\\samplers.py\", line 289, in sampling_function\r\ncond, uncond\
          \ = calc_cond_uncond_batch(model_function, cond, uncond, x, timestep, max_total_area,\
          \ cond_concat, model_options)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\comfy\\samplers.py\", line 241, in calc_cond_uncond_batch\r\
          \nc['control'] = control.get_control(input_x, timestep_, c, len(cond_or_uncond))\r\
          \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\comfy\\sd.py\", line 809, in get_control\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\nn\\\
          modules\\module.py\", line 1501, in _call_impl\r\nreturn forward_call(*args,\
          \ **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\comfy\\cldm\\cldm.py\", line 307, in\
          \ forward\r\nreturn outs\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\nn\\\
          modules\\module.py\", line 1501, in _call_impl\r\nreturn forward_call(*args,\
          \ **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\comfy\\ldm\\modules\\diffusionmodules\\\
          openaimodel.py\", line 43, in forward\r\nx = layer(x, context, transformer_options)\r\
          \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          python_embeded\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line\
          \ 1501, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\nFile \"\
          D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\comfy\\ldm\\modules\\attention.py\", line 696, in forward\r\nx\
          \ = block(x, context=context[i], transformer_options=transformer_options)\r\
          \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          python_embeded\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line\
          \ 1501, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\nFile \"\
          D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\comfy\\ldm\\modules\\attention.py\", line 528, in forward\r\nreturn\
          \ checkpoint(self._forward, (x, context, transformer_options), self.parameters(),\
          \ self.checkpoint)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\comfy\\ldm\\modules\\diffusionmodules\\\
          util.py\", line 123, in checkpoint\r\nreturn func(*inputs)\r\nFile \"D:\\\
          ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\comfy\\ldm\\modules\\attention.py\", line 628, in _forward\r\n\
          n = self.attn2(n, context=context_attn2, value=value_attn2)\r\nFile \"D:\\\
          ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          python_embeded\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line\
          \ 1501, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\nFile \"\
          D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          ComfyUI\\comfy\\ldm\\modules\\attention.py\", line 421, in forward\r\nq\
          \ = self.to_q(x)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\nn\\\
          modules\\module.py\", line 1501, in _call_impl\r\nreturn forward_call(*args,\
          \ **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\ComfyUI\\comfy\\sd.py\", line 862, in forward\r\
          \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          python_embeded\\lib\\site-packages\\torch\\_prims_common\\wrappers.py\"\
          , line 220, in _fn\r\nresult = fn(*args, **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\_prims_common\\\
          wrappers.py\", line 130, in _fn\r\nresult = fn(**bound.arguments)\r\nFile\
          \ \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          python_embeded\\lib\\site-packages\\torch\\_refs\\__init__.py\", line 975,\
          \ in add\r\nreturn prims.add(a, b)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
          ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\_ops.py\"\
          , line 287, in __call__\r\nreturn self._op(*args, **kwargs or {})\r\nFile\
          \ \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          python_embeded\\lib\\site-packages\\torch\\_prims\\__init__.py\", line 346,\
          \ in _elementwise_meta\r\nutils.check_same_device(*args_, allow_cpu_scalar_tensors=True)\r\
          \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
          python_embeded\\lib\\site-packages\\torch\\_prims_common\\__init__.py\"\
          , line 596, in check_same_device\r\nraise RuntimeError(msg)\r\n\r\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\
          \nIt only seems to happen once I have already made one canny or depth image\
          \ with the new clora, then I cannot make any more I have to go to another\
          \ workflow, reload the already \"loaded\" tensors, and then go back and\
          \ load the model a third time for only a single new image to complete...\r\
          \n\r\nAnyone know how to fix this on the windows portable install? I installed\
          \ the nodes through Comfy Manager.\r\n\r\nThanks!"
        updatedAt: '2023-08-22T05:43:37.750Z'
      numEdits: 0
      reactions: []
    id: 64e44b09030431c0c6888d7d
    type: comment
  author: Managerfirst
  content: "File \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    ComfyUI\\execution.py\", line 151, in recursive_execute\r\noutput_data, output_ui\
    \ = get_output_data(obj, input_data_all)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 81, in get_output_data\r\
    \nreturn_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)\r\
    \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    ComfyUI\\execution.py\", line 74, in map_node_over_list\r\nresults.append(getattr(obj,\
    \ func)(**slice_dict(input_data_all, i)))\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\nodes.py\", line 1206, in sample\r\nreturn\
    \ common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive,\
    \ negative, latent_image, denoise=denoise)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\nodes.py\", line 1176, in common_ksampler\r\
    \nsamples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler,\
    \ positive, negative, latent_image,\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\comfy\\sample.py\", line 93, in sample\r\n\
    samples = sampler.sample(noise, positive_copy, negative_copy, cfg=cfg, latent_image=latent_image,\
    \ start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise,\
    \ denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar,\
    \ seed=seed)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    ComfyUI\\comfy\\samplers.py\", line 733, in sample\r\nsamples = getattr(k_diffusion_sampling,\
    \ \"sample_{}\".format(self.sampler))(self.model_k, noise, sigmas, extra_args=extra_args,\
    \ callback=k_callback, disable=disable_pbar)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\utils\\_contextlib.py\"\
    , line 115, in decorate_context\r\nreturn func(*args, **kwargs)\r\nFile \"D:\\\
    ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\ComfyUI\\\
    comfy\\k_diffusion\\sampling.py\", line 154, in sample_euler_ancestral\r\ndenoised\
    \ = model(x, sigmas[i] * s_in, **extra_args)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\nn\\modules\\\
    module.py\", line 1501, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\
    \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    ComfyUI\\comfy\\samplers.py\", line 323, in forward\r\nout = self.inner_model(x,\
    \ sigma, cond=cond, uncond=uncond, cond_scale=cond_scale, cond_concat=cond_concat,\
    \ model_options=model_options, seed=seed)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\nn\\modules\\\
    module.py\", line 1501, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\
    \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    ComfyUI\\comfy\\k_diffusion\\external.py\", line 125, in forward\r\neps = self.get_eps(input\
    \ * c_in, self.sigma_to_t(sigma), **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\comfy\\k_diffusion\\external.py\", line 151,\
    \ in get_eps\r\nreturn self.inner_model.apply_model(*args, **kwargs)\r\nFile \"\
    D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\ComfyUI\\\
    comfy\\samplers.py\", line 311, in apply_model\r\nout = sampling_function(self.inner_model.apply_model,\
    \ x, timestep, uncond, cond, cond_scale, cond_concat, model_options=model_options,\
    \ seed=seed)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    ComfyUI\\comfy\\samplers.py\", line 289, in sampling_function\r\ncond, uncond\
    \ = calc_cond_uncond_batch(model_function, cond, uncond, x, timestep, max_total_area,\
    \ cond_concat, model_options)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\comfy\\samplers.py\", line 241, in calc_cond_uncond_batch\r\
    \nc['control'] = control.get_control(input_x, timestep_, c, len(cond_or_uncond))\r\
    \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    ComfyUI\\comfy\\sd.py\", line 809, in get_control\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\nn\\modules\\\
    module.py\", line 1501, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\
    \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    ComfyUI\\comfy\\cldm\\cldm.py\", line 307, in forward\r\nreturn outs\r\nFile \"\
    D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\python_embeded\\\
    lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\r\
    \nreturn forward_call(*args, **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\comfy\\ldm\\modules\\diffusionmodules\\openaimodel.py\"\
    , line 43, in forward\r\nx = layer(x, context, transformer_options)\r\nFile \"\
    D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\python_embeded\\\
    lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\r\
    \nreturn forward_call(*args, **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\comfy\\ldm\\modules\\attention.py\", line 696,\
    \ in forward\r\nx = block(x, context=context[i], transformer_options=transformer_options)\r\
    \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    python_embeded\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501,\
    \ in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\comfy\\ldm\\modules\\attention.py\", line 528,\
    \ in forward\r\nreturn checkpoint(self._forward, (x, context, transformer_options),\
    \ self.parameters(), self.checkpoint)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\comfy\\ldm\\modules\\diffusionmodules\\util.py\"\
    , line 123, in checkpoint\r\nreturn func(*inputs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\comfy\\ldm\\modules\\attention.py\", line 628,\
    \ in _forward\r\nn = self.attn2(n, context=context_attn2, value=value_attn2)\r\
    \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    python_embeded\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501,\
    \ in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\ComfyUI\\comfy\\ldm\\modules\\attention.py\", line 421,\
    \ in forward\r\nq = self.to_q(x)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\nn\\modules\\\
    module.py\", line 1501, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\
    \nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\\
    ComfyUI\\comfy\\sd.py\", line 862, in forward\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\_prims_common\\\
    wrappers.py\", line 220, in _fn\r\nresult = fn(*args, **kwargs)\r\nFile \"D:\\\
    ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\python_embeded\\\
    lib\\site-packages\\torch\\_prims_common\\wrappers.py\", line 130, in _fn\r\n\
    result = fn(**bound.arguments)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\_refs\\__init__.py\"\
    , line 975, in add\r\nreturn prims.add(a, b)\r\nFile \"D:\\ComfyUI_windows_portable_nvidia_cu118_or_cpu\\\
    ComfyUI_windows_portable\\python_embeded\\lib\\site-packages\\torch\\_ops.py\"\
    , line 287, in __call__\r\nreturn self._op(*args, **kwargs or {})\r\nFile \"D:\\\
    ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\python_embeded\\\
    lib\\site-packages\\torch\\_prims\\__init__.py\", line 346, in _elementwise_meta\r\
    \nutils.check_same_device(*args_, allow_cpu_scalar_tensors=True)\r\nFile \"D:\\\
    ComfyUI_windows_portable_nvidia_cu118_or_cpu\\ComfyUI_windows_portable\\python_embeded\\\
    lib\\site-packages\\torch\\_prims_common\\__init__.py\", line 596, in check_same_device\r\
    \nraise RuntimeError(msg)\r\n\r\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\
    \nIt only seems to happen once I have already made one canny or depth image with\
    \ the new clora, then I cannot make any more I have to go to another workflow,\
    \ reload the already \"loaded\" tensors, and then go back and load the model a\
    \ third time for only a single new image to complete...\r\n\r\nAnyone know how\
    \ to fix this on the windows portable install? I installed the nodes through Comfy\
    \ Manager.\r\n\r\nThanks!"
  created_at: 2023-08-22 04:43:37+00:00
  edited: false
  hidden: false
  id: 64e44b09030431c0c6888d7d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/014f8895e7dc4c52ee88650f6b526493.svg
      fullname: Bram Vera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bramvera
      type: user
    createdAt: '2023-08-22T10:10:16.000Z'
    data:
      edited: false
      editors:
      - bramvera
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6357278227806091
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/014f8895e7dc4c52ee88650f6b526493.svg
          fullname: Bram Vera
          isHf: false
          isPro: false
          name: bramvera
          type: user
        html: '<p>update Comfyui, try rank128<br><a href="https://huggingface.co/stabilityai/control-lora/discussions/3">https://huggingface.co/stabilityai/control-lora/discussions/3</a></p>

          '
        raw: 'update Comfyui, try rank128

          https://huggingface.co/stabilityai/control-lora/discussions/3


          '
        updatedAt: '2023-08-22T10:10:16.696Z'
      numEdits: 0
      reactions: []
    id: 64e48988ae2516de414c4ab0
    type: comment
  author: bramvera
  content: 'update Comfyui, try rank128

    https://huggingface.co/stabilityai/control-lora/discussions/3


    '
  created_at: 2023-08-22 09:10:16+00:00
  edited: false
  hidden: false
  id: 64e48988ae2516de414c4ab0
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/032a9061668aa7ba5fca3543aaed207f.svg
      fullname: Kringo Krungo
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Kringokrungo
      type: user
    createdAt: '2023-08-22T22:05:14.000Z'
    data:
      edited: true
      editors:
      - Kringokrungo
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9628030061721802
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/032a9061668aa7ba5fca3543aaed207f.svg
          fullname: Kringo Krungo
          isHf: false
          isPro: false
          name: Kringokrungo
          type: user
        html: '<p>I''ve updated to the latest version of comfyui which appears to
          have fixsd this problem but now I''m getting out of memory errors - not
          the end of the world, except for that he fact that I think it''s a ug. </p>

          <p>Error occurred when executing CLIPTextEncode:</p>

          <p>Allocation on device 0 would exceed allowed memory. (out of memory)<br>Currently
          allocated     : 1.40 GiB<br>Requested               : 25.00 MiB<br>Device
          limit            : 10.75 GiB<br>Free (according to CUDA): 25.62 MiB<br>PyTorch
          limit (set by user-supplied memory fraction)<br>                        :
          17179869184.00 GiB</p>

          <p>While I''d love to have a few million terabytes of VRAM I'' don''t think
          that''s accurate - and I think there''s likely sdomething wrong when I''m
          requesting 25mb of vvram with 1.4 gb allocated  but maybe not?<br>EDIT:
          Nevermind, had another process running ;D</p>

          '
        raw: "I've updated to the latest version of comfyui which appears to have\
          \ fixsd this problem but now I'm getting out of memory errors - not the\
          \ end of the world, except for that he fact that I think it's a ug. \n\n\
          Error occurred when executing CLIPTextEncode:\n\nAllocation on device 0\
          \ would exceed allowed memory. (out of memory)\nCurrently allocated    \
          \ : 1.40 GiB\nRequested               : 25.00 MiB\nDevice limit        \
          \    : 10.75 GiB\nFree (according to CUDA): 25.62 MiB\nPyTorch limit (set\
          \ by user-supplied memory fraction)\n                        : 17179869184.00\
          \ GiB\n\nWhile I'd love to have a few million terabytes of VRAM I' don't\
          \ think that's accurate - and I think there's likely sdomething wrong when\
          \ I'm requesting 25mb of vvram with 1.4 gb allocated  but maybe not?\nEDIT:\
          \ Nevermind, had another process running ;D"
        updatedAt: '2023-08-22T22:06:10.382Z'
      numEdits: 1
      reactions: []
    id: 64e5311a57d6d38e125a9dd2
    type: comment
  author: Kringokrungo
  content: "I've updated to the latest version of comfyui which appears to have fixsd\
    \ this problem but now I'm getting out of memory errors - not the end of the world,\
    \ except for that he fact that I think it's a ug. \n\nError occurred when executing\
    \ CLIPTextEncode:\n\nAllocation on device 0 would exceed allowed memory. (out\
    \ of memory)\nCurrently allocated     : 1.40 GiB\nRequested               : 25.00\
    \ MiB\nDevice limit            : 10.75 GiB\nFree (according to CUDA): 25.62 MiB\n\
    PyTorch limit (set by user-supplied memory fraction)\n                       \
    \ : 17179869184.00 GiB\n\nWhile I'd love to have a few million terabytes of VRAM\
    \ I' don't think that's accurate - and I think there's likely sdomething wrong\
    \ when I'm requesting 25mb of vvram with 1.4 gb allocated  but maybe not?\nEDIT:\
    \ Nevermind, had another process running ;D"
  created_at: 2023-08-22 21:05:14+00:00
  edited: true
  hidden: false
  id: 64e5311a57d6d38e125a9dd2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/014f8895e7dc4c52ee88650f6b526493.svg
      fullname: Bram Vera
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bramvera
      type: user
    createdAt: '2023-08-23T04:05:58.000Z'
    data:
      edited: false
      editors:
      - bramvera
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9640834927558899
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/014f8895e7dc4c52ee88650f6b526493.svg
          fullname: Bram Vera
          isHf: false
          isPro: false
          name: bramvera
          type: user
        html: "<p><span data-props=\"{&quot;user&quot;:&quot;Kringokrungo&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/Kringokrungo\"\
          >@<span class=\"underline\">Kringokrungo</span></a></span>\n\n\t</span></span>\
          \ lol been there, glad you made it</p>\n"
        raw: '@Kringokrungo lol been there, glad you made it'
        updatedAt: '2023-08-23T04:05:58.476Z'
      numEdits: 0
      reactions: []
    id: 64e585a6b78bc92221d086e6
    type: comment
  author: bramvera
  content: '@Kringokrungo lol been there, glad you made it'
  created_at: 2023-08-23 03:05:58+00:00
  edited: false
  hidden: false
  id: 64e585a6b78bc92221d086e6
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 15
repo_id: stabilityai/control-lora
repo_type: model
status: open
target_branch: null
title: 'Error occurred when executing KSampler:  Tensor on device cuda:0 is not on
  the expected device meta!'
