!!python/object:huggingface_hub.community.DiscussionWithDetails
author: GaiaM
conflicting_files: null
created_at: 2023-04-01 20:04:24+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/33889e9f21f1f32b17a69297cc6c9349.svg
      fullname: Georgia Maniati
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: GaiaM
      type: user
    createdAt: '2023-04-01T21:04:24.000Z'
    data:
      edited: false
      editors:
      - GaiaM
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/33889e9f21f1f32b17a69297cc6c9349.svg
          fullname: Georgia Maniati
          isHf: false
          isPro: false
          name: GaiaM
          type: user
        html: '<p>Thanks in advance for fine-tuning for Greek and apologies in case
          my question is too basic! I am new here. :)</p>

          <p>I am using the model via transformers AutoModel and AutoProcessor and
          I''d like to transcribe a long audio (~11mins).<br>To my disappointment,
          I only get a transcription of up to the very first seconds of the audio
          file (9-10s). I have experimented with the options max_new_tokens, and no_speech_threshold
          and also removed any long silence from the audio, without resolving the
          issue.<br>I previously used the multilingual OpenAI model via the whisper
          cli command and the entire audio was transcribed, so I am wondering if you
          have any idea what could be causing the generation/decoding to stop early.
          </p>

          <p>Any advice is very welcome!</p>

          '
        raw: "Thanks in advance for fine-tuning for Greek and apologies in case my\
          \ question is too basic! I am new here. :)\r\n\r\nI am using the model via\
          \ transformers AutoModel and AutoProcessor and I'd like to transcribe a\
          \ long audio (~11mins). \r\nTo my disappointment, I only get a transcription\
          \ of up to the very first seconds of the audio file (9-10s). I have experimented\
          \ with the options max_new_tokens, and no_speech_threshold and also removed\
          \ any long silence from the audio, without resolving the issue. \r\nI previously\
          \ used the multilingual OpenAI model via the whisper cli command and the\
          \ entire audio was transcribed, so I am wondering if you have any idea what\
          \ could be causing the generation/decoding to stop early. \r\n\r\nAny advice\
          \ is very welcome!"
        updatedAt: '2023-04-01T21:04:24.899Z'
      numEdits: 0
      reactions: []
    id: 64289c5888215cee63b6c314
    type: comment
  author: GaiaM
  content: "Thanks in advance for fine-tuning for Greek and apologies in case my question\
    \ is too basic! I am new here. :)\r\n\r\nI am using the model via transformers\
    \ AutoModel and AutoProcessor and I'd like to transcribe a long audio (~11mins).\
    \ \r\nTo my disappointment, I only get a transcription of up to the very first\
    \ seconds of the audio file (9-10s). I have experimented with the options max_new_tokens,\
    \ and no_speech_threshold and also removed any long silence from the audio, without\
    \ resolving the issue. \r\nI previously used the multilingual OpenAI model via\
    \ the whisper cli command and the entire audio was transcribed, so I am wondering\
    \ if you have any idea what could be causing the generation/decoding to stop early.\
    \ \r\n\r\nAny advice is very welcome!"
  created_at: 2023-04-01 20:04:24+00:00
  edited: false
  hidden: false
  id: 64289c5888215cee63b6c314
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: Charalampos/whisper-large-el
repo_type: model
status: open
target_branch: null
title: Overcoming stopping of generation
