!!python/object:huggingface_hub.community.DiscussionWithDetails
author: MisakP
conflicting_files: null
created_at: 2023-04-23 20:00:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/a15e61b6cf9ea4cbfe75e76529d983e3.svg
      fullname: "Petr Mi\u0161\xE1k"
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: MisakP
      type: user
    createdAt: '2023-04-23T21:00:58.000Z'
    data:
      edited: false
      editors:
      - MisakP
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/a15e61b6cf9ea4cbfe75e76529d983e3.svg
          fullname: "Petr Mi\u0161\xE1k"
          isHf: false
          isPro: false
          name: MisakP
          type: user
        html: "<p>When it tries to load, it gets stuck at<br>Loading Thireus_Vicuna13B-v1.1-8bit-128g...<br>Auto-assiging\
          \ --gpu-memory 23 for your GPU to try to prevent out-of-memory errors.<br>You\
          \ can manually set other values.<br>Loading checkpoint shards:   0%|   \
          \                                                              | 0/3 [00:00&lt;?,\
          \ ?it/s]</p>\n<p>And the Gradio environment throws an error </p>\n<p>Traceback\
          \ (most recent call last):<br>File \u201CE:\\AI\\oobabooga\\installer_files\\\
          env\\lib\\site-packages\\transformers\\modeling_utils.py\u201D, line 442,\
          \ in load_state_dict<br>return torch.load(checkpoint_file, map_location=\u201C\
          cpu\u201D)<br>File \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\\
          site-packages\\torch\\serialization.py\u201D, line 791, in load<br>with\
          \ _open_file_like(f, \u2018rb\u2019) as opened_file:<br>File \u201CE:\\\
          AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\torch\\serialization.py\u201D\
          , line 271, in _open_file_like<br>return _open_file(name_or_buffer, mode)<br>File\
          \ \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\torch\\\
          serialization.py\u201D, line 252, in init<br>super().init(open(name, mode))<br>FileNotFoundError:\
          \ [Errno 2] No such file or directory: \u2018models\\Thireus_Vicuna13B-v1.1-8bit-128g\\\
          pytorch_model-00001-of-00003.bin\u2019</p>\n<p>During handling of the above\
          \ exception, another exception occurred:</p>\n<p>Traceback (most recent\
          \ call last):<br>File \u201CE:\\AI\\oobabooga\\text-generation-webui\\server.py\u201D\
          , line 101, in load_model_wrapper<br>shared.model, shared.tokenizer = load_model(shared.model_name)<br>File\
          \ \u201CE:\\AI\\oobabooga\\text-generation-webui\\modules\\models.py\u201D\
          , line 207, in load_model<br>model = LoaderClass.from_pretrained(checkpoint,\
          \ **params)<br>File \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\\
          site-packages\\transformers\\models\\auto\\auto_factory.py\u201D, line 471,\
          \ in from_pretrained<br>return model_class.from_pretrained(<br>File \u201C\
          E:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\transformers\\\
          modeling_utils.py\u201D, line 2795, in from_pretrained<br>) = cls._load_pretrained_model(<br>File\
          \ \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\transformers\\\
          modeling_utils.py\u201D, line 3109, in _load_pretrained_model<br>state_dict\
          \ = load_state_dict(shard_file)<br>File \u201CE:\\AI\\oobabooga\\installer_files\\\
          env\\lib\\site-packages\\transformers\\modeling_utils.py\u201D, line 445,\
          \ in load_state_dict<br>with open(checkpoint_file) as f:<br>FileNotFoundError:\
          \ [Errno 2] No such file or directory: \u2018models\\Thireus_Vicuna13B-v1.1-8bit-128g\\\
          pytorch_model-00001-of-00003.bin\u2019</p>\n"
        raw: "When it tries to load, it gets stuck at \r\nLoading Thireus_Vicuna13B-v1.1-8bit-128g...\r\
          \nAuto-assiging --gpu-memory 23 for your GPU to try to prevent out-of-memory\
          \ errors.\r\nYou can manually set other values.\r\nLoading checkpoint shards:\
          \   0%|                                                                \
          \ | 0/3 [00:00<?, ?it/s]\r\n\r\nAnd the Gradio environment throws an error\
          \ \r\n\r\nTraceback (most recent call last):\r\nFile \u201CE:\\AI\\oobabooga\\\
          installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py\u201D\
          , line 442, in load_state_dict\r\nreturn torch.load(checkpoint_file, map_location=\u201C\
          cpu\u201D)\r\nFile \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\\
          site-packages\\torch\\serialization.py\u201D, line 791, in load\r\nwith\
          \ _open_file_like(f, \u2018rb\u2019) as opened_file:\r\nFile \u201CE:\\\
          AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\torch\\serialization.py\u201D\
          , line 271, in _open_file_like\r\nreturn _open_file(name_or_buffer, mode)\r\
          \nFile \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\\
          torch\\serialization.py\u201D, line 252, in init\r\nsuper().init(open(name,\
          \ mode))\r\nFileNotFoundError: [Errno 2] No such file or directory: \u2018\
          models\\Thireus_Vicuna13B-v1.1-8bit-128g\\pytorch_model-00001-of-00003.bin\u2019\
          \r\n\r\nDuring handling of the above exception, another exception occurred:\r\
          \n\r\nTraceback (most recent call last):\r\nFile \u201CE:\\AI\\oobabooga\\\
          text-generation-webui\\server.py\u201D, line 101, in load_model_wrapper\r\
          \nshared.model, shared.tokenizer = load_model(shared.model_name)\r\nFile\
          \ \u201CE:\\AI\\oobabooga\\text-generation-webui\\modules\\models.py\u201D\
          , line 207, in load_model\r\nmodel = LoaderClass.from_pretrained(checkpoint,\
          \ **params)\r\nFile \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\\
          site-packages\\transformers\\models\\auto\\auto_factory.py\u201D, line 471,\
          \ in from_pretrained\r\nreturn model_class.from_pretrained(\r\nFile \u201C\
          E:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\transformers\\\
          modeling_utils.py\u201D, line 2795, in from_pretrained\r\n) = cls._load_pretrained_model(\r\
          \nFile \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\\
          transformers\\modeling_utils.py\u201D, line 3109, in _load_pretrained_model\r\
          \nstate_dict = load_state_dict(shard_file)\r\nFile \u201CE:\\AI\\oobabooga\\\
          installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py\u201D\
          , line 445, in load_state_dict\r\nwith open(checkpoint_file) as f:\r\nFileNotFoundError:\
          \ [Errno 2] No such file or directory: \u2018models\\Thireus_Vicuna13B-v1.1-8bit-128g\\\
          pytorch_model-00001-of-00003.bin\u2019"
        updatedAt: '2023-04-23T21:00:58.083Z'
      numEdits: 0
      reactions: []
    id: 64459c8ab272430bdbf4d001
    type: comment
  author: MisakP
  content: "When it tries to load, it gets stuck at \r\nLoading Thireus_Vicuna13B-v1.1-8bit-128g...\r\
    \nAuto-assiging --gpu-memory 23 for your GPU to try to prevent out-of-memory errors.\r\
    \nYou can manually set other values.\r\nLoading checkpoint shards:   0%|     \
    \                                                            | 0/3 [00:00<?, ?it/s]\r\
    \n\r\nAnd the Gradio environment throws an error \r\n\r\nTraceback (most recent\
    \ call last):\r\nFile \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\\
    transformers\\modeling_utils.py\u201D, line 442, in load_state_dict\r\nreturn\
    \ torch.load(checkpoint_file, map_location=\u201Ccpu\u201D)\r\nFile \u201CE:\\\
    AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\torch\\serialization.py\u201D\
    , line 791, in load\r\nwith _open_file_like(f, \u2018rb\u2019) as opened_file:\r\
    \nFile \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\torch\\\
    serialization.py\u201D, line 271, in _open_file_like\r\nreturn _open_file(name_or_buffer,\
    \ mode)\r\nFile \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\\
    torch\\serialization.py\u201D, line 252, in init\r\nsuper().init(open(name, mode))\r\
    \nFileNotFoundError: [Errno 2] No such file or directory: \u2018models\\Thireus_Vicuna13B-v1.1-8bit-128g\\\
    pytorch_model-00001-of-00003.bin\u2019\r\n\r\nDuring handling of the above exception,\
    \ another exception occurred:\r\n\r\nTraceback (most recent call last):\r\nFile\
    \ \u201CE:\\AI\\oobabooga\\text-generation-webui\\server.py\u201D, line 101, in\
    \ load_model_wrapper\r\nshared.model, shared.tokenizer = load_model(shared.model_name)\r\
    \nFile \u201CE:\\AI\\oobabooga\\text-generation-webui\\modules\\models.py\u201D\
    , line 207, in load_model\r\nmodel = LoaderClass.from_pretrained(checkpoint, **params)\r\
    \nFile \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\transformers\\\
    models\\auto\\auto_factory.py\u201D, line 471, in from_pretrained\r\nreturn model_class.from_pretrained(\r\
    \nFile \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\transformers\\\
    modeling_utils.py\u201D, line 2795, in from_pretrained\r\n) = cls._load_pretrained_model(\r\
    \nFile \u201CE:\\AI\\oobabooga\\installer_files\\env\\lib\\site-packages\\transformers\\\
    modeling_utils.py\u201D, line 3109, in _load_pretrained_model\r\nstate_dict =\
    \ load_state_dict(shard_file)\r\nFile \u201CE:\\AI\\oobabooga\\installer_files\\\
    env\\lib\\site-packages\\transformers\\modeling_utils.py\u201D, line 445, in load_state_dict\r\
    \nwith open(checkpoint_file) as f:\r\nFileNotFoundError: [Errno 2] No such file\
    \ or directory: \u2018models\\Thireus_Vicuna13B-v1.1-8bit-128g\\pytorch_model-00001-of-00003.bin\u2019"
  created_at: 2023-04-23 20:00:58+00:00
  edited: false
  hidden: false
  id: 64459c8ab272430bdbf4d001
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/550d708358ea9ee7722d833d6f307484.svg
      fullname: John Dietz
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jdietz
      type: user
    createdAt: '2023-04-25T08:40:46.000Z'
    data:
      edited: false
      editors:
      - Jdietz
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/550d708358ea9ee7722d833d6f307484.svg
          fullname: John Dietz
          isHf: false
          isPro: false
          name: Jdietz
          type: user
        html: '<p>Same</p>

          '
        raw: Same
        updatedAt: '2023-04-25T08:40:46.535Z'
      numEdits: 0
      reactions: []
    id: 6447920e058f3572dd06a13c
    type: comment
  author: Jdietz
  content: Same
  created_at: 2023-04-25 07:40:46+00:00
  edited: false
  hidden: false
  id: 6447920e058f3572dd06a13c
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 4
repo_id: Thireus/Vicuna13B-v1.1-8bit-128g
repo_type: model
status: open
target_branch: null
title: The model does not work for me with "oobabooga"
