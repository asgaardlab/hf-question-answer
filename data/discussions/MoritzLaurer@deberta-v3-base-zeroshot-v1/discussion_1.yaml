!!python/object:huggingface_hub.community.DiscussionWithDetails
author: HassanStar
conflicting_files: null
created_at: 2023-09-29 11:34:50+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9b4a0966b777096c629783caa87d3713.svg
      fullname: Hassan LOULOU
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: HassanStar
      type: user
    createdAt: '2023-09-29T12:34:50.000Z'
    data:
      edited: false
      editors:
      - HassanStar
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.894698441028595
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9b4a0966b777096c629783caa87d3713.svg
          fullname: Hassan LOULOU
          isHf: false
          isPro: false
          name: HassanStar
          type: user
        html: '<p>can you please explain more how to finetune it on new classification
          task and the code to use?</p>

          '
        raw: can you please explain more how to finetune it on new classification
          task and the code to use?
        updatedAt: '2023-09-29T12:34:50.500Z'
      numEdits: 0
      reactions: []
    id: 6516c46ad2e12a8885c8b83e
    type: comment
  author: HassanStar
  content: can you please explain more how to finetune it on new classification task
    and the code to use?
  created_at: 2023-09-29 11:34:50+00:00
  edited: false
  hidden: false
  id: 6516c46ad2e12a8885c8b83e
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/02a175c351183cc87b2112ddbaf7f373.svg
      fullname: Aung Kyaw Htet
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: akhtet
      type: user
    createdAt: '2023-10-02T07:02:54.000Z'
    data:
      edited: false
      editors:
      - akhtet
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9663209915161133
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/02a175c351183cc87b2112ddbaf7f373.svg
          fullname: Aung Kyaw Htet
          isHf: false
          isPro: false
          name: akhtet
          type: user
        html: '<p>It is likely that the model already works with your task without
          additional fine-tuning, as it supports zero-shot classification. You can
          try the sample code provided on the model card.</p>

          '
        raw: It is likely that the model already works with your task without additional
          fine-tuning, as it supports zero-shot classification. You can try the sample
          code provided on the model card.
        updatedAt: '2023-10-02T07:02:54.479Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - MoritzLaurer
    id: 651a6b1e15e21edaf7fe8f01
    type: comment
  author: akhtet
  content: It is likely that the model already works with your task without additional
    fine-tuning, as it supports zero-shot classification. You can try the sample code
    provided on the model card.
  created_at: 2023-10-02 06:02:54+00:00
  edited: false
  hidden: false
  id: 651a6b1e15e21edaf7fe8f01
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
      fullname: Moritz Laurer
      isHf: true
      isOrgMember: false
      isOwner: true
      isPro: false
      name: MoritzLaurer
      type: user
    createdAt: '2023-10-05T12:10:15.000Z'
    data:
      edited: false
      editors:
      - MoritzLaurer
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9312365651130676
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1613511937628-5fb15d1e84389b139cf3b508.jpeg?w=200&h=200&f=face
          fullname: Moritz Laurer
          isHf: true
          isPro: false
          name: MoritzLaurer
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;HassanStar&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/HassanStar\"\
          >@<span class=\"underline\">HassanStar</span></a></span>\n\n\t</span></span>,\
          \ you have two options for fine-tuning: (1) you do standard fine-tuning\
          \ as with any BERT model. This would delete the universal NLI task head\
          \ and create a new classification head for your task. (2) you can continuously\
          \ fine-tune the model including the universal NLI head (this is recommended\
          \ if you have roughly &lt;= 1000 datapoints. If you have more data than\
          \ 2000, normal fine-tuning is probably better). You can find example code\
          \ for this in notebook nr. 4 here: <a rel=\"nofollow\" href=\"https://github.com/MoritzLaurer/summer-school-transformers-2023\"\
          >https://github.com/MoritzLaurer/summer-school-transformers-2023</a></p>\n\
          <p>and as <span data-props=\"{&quot;user&quot;:&quot;akhtet&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/akhtet\">@<span class=\"\
          underline\">akhtet</span></a></span>\n\n\t</span></span> said, you can also\
          \ use it without fine-tuning with the example code from the model card.\
          \ </p>\n"
        raw: 'Hi @HassanStar, you have two options for fine-tuning: (1) you do standard
          fine-tuning as with any BERT model. This would delete the universal NLI
          task head and create a new classification head for your task. (2) you can
          continuously fine-tune the model including the universal NLI head (this
          is recommended if you have roughly <= 1000 datapoints. If you have more
          data than 2000, normal fine-tuning is probably better). You can find example
          code for this in notebook nr. 4 here: https://github.com/MoritzLaurer/summer-school-transformers-2023


          and as @akhtet said, you can also use it without fine-tuning with the example
          code from the model card. '
        updatedAt: '2023-10-05T12:10:15.783Z'
      numEdits: 0
      reactions: []
    id: 651ea7a78eb15cd4483c8018
    type: comment
  author: MoritzLaurer
  content: 'Hi @HassanStar, you have two options for fine-tuning: (1) you do standard
    fine-tuning as with any BERT model. This would delete the universal NLI task head
    and create a new classification head for your task. (2) you can continuously fine-tune
    the model including the universal NLI head (this is recommended if you have roughly
    <= 1000 datapoints. If you have more data than 2000, normal fine-tuning is probably
    better). You can find example code for this in notebook nr. 4 here: https://github.com/MoritzLaurer/summer-school-transformers-2023


    and as @akhtet said, you can also use it without fine-tuning with the example
    code from the model card. '
  created_at: 2023-10-05 11:10:15+00:00
  edited: false
  hidden: false
  id: 651ea7a78eb15cd4483c8018
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: MoritzLaurer/deberta-v3-base-zeroshot-v1
repo_type: model
status: open
target_branch: null
title: Finetuning
