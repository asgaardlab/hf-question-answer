!!python/object:huggingface_hub.community.DiscussionWithDetails
author: wolfram
conflicting_files: null
created_at: 2023-08-22 15:00:18+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303ca537373aacccd85d8a7/JZqLjXZVGWXJdWUNI99db.jpeg?w=200&h=200&f=face
      fullname: Wolfram Ravenwolf
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: wolfram
      type: user
    createdAt: '2023-08-22T16:00:18.000Z'
    data:
      edited: false
      editors:
      - wolfram
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9551304578781128
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6303ca537373aacccd85d8a7/JZqLjXZVGWXJdWUNI99db.jpeg?w=200&h=200&f=face
          fullname: Wolfram Ravenwolf
          isHf: false
          isPro: false
          name: wolfram
          type: user
        html: '<p>I was asked to test your model, so I tested TheBloke''s q5_K_M quantized
          version of h2ogpt-4096-llama2-13B-chat-GGML, and I''ve noticed it''s giving
          100 % identical responses as Llama 2 Chat 13B (same q5_K_M quant)!</p>

          <p>Since I''m using deterministic settings, same input results in same output
          if all other variables are the exact same. But this is supposedly a different
          model, I even checked its checksum to make sure it wasn''t just a renamed
          version of the original Llama 2 Chat model.</p>

          <p>The same applies no matter if I use Llama 2 Chat''s prompt format or
          your H2O format as mentioned on TheBloke''s model card.</p>

          <p>You didn''t just take Meta''s Llama 2 Chat model and renamed it h2oGPT
          without making any changes, did you? You write "h2oGPT fine-tuned model
          based on Meta''s Llama 2 13B Chat.", but shouldn''t fine-tunes be based
          on the <em>base</em> model?</p>

          <p>Just wondering if your model is a 1:1 copy of meta''s original? Or if
          there was a mistake/mix-up when the model was quantized/uploaded? (I did
          check my files again and again, making sure I didn''t mix them up locally!)</p>

          '
        raw: "I was asked to test your model, so I tested TheBloke's q5_K_M quantized\
          \ version of h2ogpt-4096-llama2-13B-chat-GGML, and I've noticed it's giving\
          \ 100 % identical responses as Llama 2 Chat 13B (same q5_K_M quant)!\r\n\
          \r\nSince I'm using deterministic settings, same input results in same output\
          \ if all other variables are the exact same. But this is supposedly a different\
          \ model, I even checked its checksum to make sure it wasn't just a renamed\
          \ version of the original Llama 2 Chat model.\r\n\r\nThe same applies no\
          \ matter if I use Llama 2 Chat's prompt format or your H2O format as mentioned\
          \ on TheBloke's model card.\r\n\r\nYou didn't just take Meta's Llama 2 Chat\
          \ model and renamed it h2oGPT without making any changes, did you? You write\
          \ \"h2oGPT fine-tuned model based on Meta's Llama 2 13B Chat.\", but shouldn't\
          \ fine-tunes be based on the *base* model?\r\n\r\nJust wondering if your\
          \ model is a 1:1 copy of meta's original? Or if there was a mistake/mix-up\
          \ when the model was quantized/uploaded? (I did check my files again and\
          \ again, making sure I didn't mix them up locally!)"
        updatedAt: '2023-08-22T16:00:18.198Z'
      numEdits: 0
      reactions: []
    id: 64e4db92a07739bcc48c686a
    type: comment
  author: wolfram
  content: "I was asked to test your model, so I tested TheBloke's q5_K_M quantized\
    \ version of h2ogpt-4096-llama2-13B-chat-GGML, and I've noticed it's giving 100\
    \ % identical responses as Llama 2 Chat 13B (same q5_K_M quant)!\r\n\r\nSince\
    \ I'm using deterministic settings, same input results in same output if all other\
    \ variables are the exact same. But this is supposedly a different model, I even\
    \ checked its checksum to make sure it wasn't just a renamed version of the original\
    \ Llama 2 Chat model.\r\n\r\nThe same applies no matter if I use Llama 2 Chat's\
    \ prompt format or your H2O format as mentioned on TheBloke's model card.\r\n\r\
    \nYou didn't just take Meta's Llama 2 Chat model and renamed it h2oGPT without\
    \ making any changes, did you? You write \"h2oGPT fine-tuned model based on Meta's\
    \ Llama 2 13B Chat.\", but shouldn't fine-tunes be based on the *base* model?\r\
    \n\r\nJust wondering if your model is a 1:1 copy of meta's original? Or if there\
    \ was a mistake/mix-up when the model was quantized/uploaded? (I did check my\
    \ files again and again, making sure I didn't mix them up locally!)"
  created_at: 2023-08-22 15:00:18+00:00
  edited: false
  hidden: false
  id: 64e4db92a07739bcc48c686a
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633f4bd5c11d723b1809dbf8/iFvJ7jYSo0heZMgrnInqo.jpeg?w=200&h=200&f=face
      fullname: Arno Candel
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: arnocandel
      type: user
    createdAt: '2023-08-22T16:25:28.000Z'
    data:
      edited: false
      editors:
      - arnocandel
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8194369673728943
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633f4bd5c11d723b1809dbf8/iFvJ7jYSo0heZMgrnInqo.jpeg?w=200&h=200&f=face
          fullname: Arno Candel
          isHf: false
          isPro: false
          name: arnocandel
          type: user
        html: '<p>yes, it''s exactly the same as <a href="https://huggingface.co/meta-llama/Llama-2-13b-chat-hf">https://huggingface.co/meta-llama/Llama-2-13b-chat-hf</a>
          or <a href="https://huggingface.co/TheBloke/Llama-2-13B-Chat-fp16">https://huggingface.co/TheBloke/Llama-2-13B-Chat-fp16</a>,
          just making it easier for potential users of h2oGPT (what''s demoed on <a
          rel="nofollow" href="http://gpt.h2o.ai">http://gpt.h2o.ai</a>) to get access
          to the models, the same Meta license still applies.</p>

          <p>Yes, we are fine-tuning the non-chat base models. I''ll improve the description.
          Thanks!</p>

          '
        raw: 'yes, it''s exactly the same as https://huggingface.co/meta-llama/Llama-2-13b-chat-hf
          or https://huggingface.co/TheBloke/Llama-2-13B-Chat-fp16, just making it
          easier for potential users of h2oGPT (what''s demoed on http://gpt.h2o.ai)
          to get access to the models, the same Meta license still applies.


          Yes, we are fine-tuning the non-chat base models. I''ll improve the description.
          Thanks!'
        updatedAt: '2023-08-22T16:25:28.266Z'
      numEdits: 0
      reactions: []
      relatedEventId: 64e4e1783796b54432ee85db
    id: 64e4e1783796b54432ee85da
    type: comment
  author: arnocandel
  content: 'yes, it''s exactly the same as https://huggingface.co/meta-llama/Llama-2-13b-chat-hf
    or https://huggingface.co/TheBloke/Llama-2-13B-Chat-fp16, just making it easier
    for potential users of h2oGPT (what''s demoed on http://gpt.h2o.ai) to get access
    to the models, the same Meta license still applies.


    Yes, we are fine-tuning the non-chat base models. I''ll improve the description.
    Thanks!'
  created_at: 2023-08-22 15:25:28+00:00
  edited: false
  hidden: false
  id: 64e4e1783796b54432ee85da
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/633f4bd5c11d723b1809dbf8/iFvJ7jYSo0heZMgrnInqo.jpeg?w=200&h=200&f=face
      fullname: Arno Candel
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: arnocandel
      type: user
    createdAt: '2023-08-22T16:25:28.000Z'
    data:
      status: closed
    id: 64e4e1783796b54432ee85db
    type: status-change
  author: arnocandel
  created_at: 2023-08-22 15:25:28+00:00
  id: 64e4e1783796b54432ee85db
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: h2oai/h2ogpt-4096-llama2-13b-chat
repo_type: model
status: closed
target_branch: null
title: Why is this model the exact same as Llama 2 Chat 13B?
