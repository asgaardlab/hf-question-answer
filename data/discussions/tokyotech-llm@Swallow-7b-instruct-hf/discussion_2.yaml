!!python/object:huggingface_hub.community.DiscussionWithDetails
author: leonardlin
conflicting_files: null
created_at: 2023-12-21 12:51:48+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a7422854f1d0225b075bfc/XGYAcDPZG5ZEsNBWG6guw.jpeg?w=200&h=200&f=face
      fullname: lhl
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: leonardlin
      type: user
    createdAt: '2023-12-21T12:51:48.000Z'
    data:
      edited: false
      editors:
      - leonardlin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.3063407242298126
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a7422854f1d0225b075bfc/XGYAcDPZG5ZEsNBWG6guw.jpeg?w=200&h=200&f=face
          fullname: lhl
          isHf: false
          isPro: false
          name: leonardlin
          type: user
        html: "<p>If anyone wants to use HF's new <a href=\"https://huggingface.co/docs/transformers/main/chat_templating\"\
          >chat templates</a> here's the formatting exactly matching the output docs:</p>\n\
          <pre><code>tokenizer.chat_template = \"{% if not add_generation_prompt is\
          \ defined %}{% set add_generation_prompt = false %}{% endif %}{% for message\
          \ in messages %}{% if message['role'] == 'system' %}{{ message['content']\
          \ + '\\n\\n' }}{% elif message['role'] == 'user' %}{{'### \u6307\u793A:\\\
          n' + message['content'] + '\\n\\n'}}{% elif message['role'] == 'assistant'\
          \ %}{{'### \u5FDC\u7B54:\\n' + message['content'] + '\\n\\n'}}{% endif %}{%\
          \ endfor %}{% if add_generation_prompt %}{{ '### \u5FDC\u7B54:' }}{% endif\
          \ %}\"\n</code></pre>\n<p>The roles are <code>system</code>, <code>user</code>,\
          \ and <code>assistant</code>, and you could start with the suggested prompt:</p>\n\
          <pre><code>PROMPT = \"\u4EE5\u4E0B\u306B\u3001\u3042\u308B\u30BF\u30B9\u30AF\
          \u3092\u8AAC\u660E\u3059\u308B\u6307\u793A\u304C\u3042\u308A\u307E\u3059\
          \u3002\u30EA\u30AF\u30A8\u30B9\u30C8\u3092\u9069\u5207\u306B\u5B8C\u4E86\
          \u3059\u308B\u305F\u3081\u306E\u56DE\u7B54\u3092\u8A18\u8FF0\u3057\u3066\
          \u304F\u3060\u3055\u3044\u3002\"\nchat = []\nchat.append({\"role\": \"system\"\
          , \"content\": PROMPT})\n</code></pre>\n"
        raw: "If anyone wants to use HF's new [chat templates](https://huggingface.co/docs/transformers/main/chat_templating)\
          \ here's the formatting exactly matching the output docs:\r\n```\r\ntokenizer.chat_template\
          \ = \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt\
          \ = false %}{% endif %}{% for message in messages %}{% if message['role']\
          \ == 'system' %}{{ message['content'] + '\\n\\n' }}{% elif message['role']\
          \ == 'user' %}{{'### \u6307\u793A:\\n' + message['content'] + '\\n\\n'}}{%\
          \ elif message['role'] == 'assistant' %}{{'### \u5FDC\u7B54:\\n' + message['content']\
          \ + '\\n\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '###\
          \ \u5FDC\u7B54:' }}{% endif %}\"\r\n```\r\nThe roles are `system`, `user`,\
          \ and `assistant`, and you could start with the suggested prompt:\r\n```\r\
          \nPROMPT = \"\u4EE5\u4E0B\u306B\u3001\u3042\u308B\u30BF\u30B9\u30AF\u3092\
          \u8AAC\u660E\u3059\u308B\u6307\u793A\u304C\u3042\u308A\u307E\u3059\u3002\
          \u30EA\u30AF\u30A8\u30B9\u30C8\u3092\u9069\u5207\u306B\u5B8C\u4E86\u3059\
          \u308B\u305F\u3081\u306E\u56DE\u7B54\u3092\u8A18\u8FF0\u3057\u3066\u304F\
          \u3060\u3055\u3044\u3002\"\r\nchat = []\r\nchat.append({\"role\": \"system\"\
          , \"content\": PROMPT})\r\n```"
        updatedAt: '2023-12-21T12:51:48.848Z'
      numEdits: 0
      reactions: []
    id: 658434e4cbb381e7888e3da6
    type: comment
  author: leonardlin
  content: "If anyone wants to use HF's new [chat templates](https://huggingface.co/docs/transformers/main/chat_templating)\
    \ here's the formatting exactly matching the output docs:\r\n```\r\ntokenizer.chat_template\
    \ = \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt\
    \ = false %}{% endif %}{% for message in messages %}{% if message['role'] == 'system'\
    \ %}{{ message['content'] + '\\n\\n' }}{% elif message['role'] == 'user' %}{{'###\
    \ \u6307\u793A:\\n' + message['content'] + '\\n\\n'}}{% elif message['role'] ==\
    \ 'assistant' %}{{'### \u5FDC\u7B54:\\n' + message['content'] + '\\n\\n'}}{% endif\
    \ %}{% endfor %}{% if add_generation_prompt %}{{ '### \u5FDC\u7B54:' }}{% endif\
    \ %}\"\r\n```\r\nThe roles are `system`, `user`, and `assistant`, and you could\
    \ start with the suggested prompt:\r\n```\r\nPROMPT = \"\u4EE5\u4E0B\u306B\u3001\
    \u3042\u308B\u30BF\u30B9\u30AF\u3092\u8AAC\u660E\u3059\u308B\u6307\u793A\u304C\
    \u3042\u308A\u307E\u3059\u3002\u30EA\u30AF\u30A8\u30B9\u30C8\u3092\u9069\u5207\
    \u306B\u5B8C\u4E86\u3059\u308B\u305F\u3081\u306E\u56DE\u7B54\u3092\u8A18\u8FF0\
    \u3057\u3066\u304F\u3060\u3055\u3044\u3002\"\r\nchat = []\r\nchat.append({\"role\"\
    : \"system\", \"content\": PROMPT})\r\n```"
  created_at: 2023-12-21 12:51:48+00:00
  edited: false
  hidden: false
  id: 658434e4cbb381e7888e3da6
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a7422854f1d0225b075bfc/XGYAcDPZG5ZEsNBWG6guw.jpeg?w=200&h=200&f=face
      fullname: lhl
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: leonardlin
      type: user
    createdAt: '2023-12-21T14:10:15.000Z'
    data:
      edited: false
      editors:
      - leonardlin
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7849569916725159
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/63a7422854f1d0225b075bfc/XGYAcDPZG5ZEsNBWG6guw.jpeg?w=200&h=200&f=face
          fullname: lhl
          isHf: false
          isPro: false
          name: leonardlin
          type: user
        html: '<p>For those looking for MT-Bench formatting, I also made a version
          that''s close (not sure if the ADD_COLON_SINGLE adds the appropriate \n
          or not): <a rel="nofollow" href="https://github.com/AUGMXNT/shisa/wiki/Evals-:-JA-MT%E2%80%90Bench#swallow">https://github.com/AUGMXNT/shisa/wiki/Evals-:-JA-MT%E2%80%90Bench#swallow</a></p>

          '
        raw: 'For those looking for MT-Bench formatting, I also made a version that''s
          close (not sure if the ADD_COLON_SINGLE adds the appropriate \n or not):
          https://github.com/AUGMXNT/shisa/wiki/Evals-:-JA-MT%E2%80%90Bench#swallow'
        updatedAt: '2023-12-21T14:10:15.323Z'
      numEdits: 0
      reactions: []
    id: 65844747d7327de57ad008ee
    type: comment
  author: leonardlin
  content: 'For those looking for MT-Bench formatting, I also made a version that''s
    close (not sure if the ADD_COLON_SINGLE adds the appropriate \n or not): https://github.com/AUGMXNT/shisa/wiki/Evals-:-JA-MT%E2%80%90Bench#swallow'
  created_at: 2023-12-21 14:10:15+00:00
  edited: false
  hidden: false
  id: 65844747d7327de57ad008ee
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: tokyotech-llm/Swallow-7b-instruct-hf
repo_type: model
status: open
target_branch: null
title: tokenizer.chat_template
