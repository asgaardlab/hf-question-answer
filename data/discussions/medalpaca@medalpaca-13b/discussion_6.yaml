!!python/object:huggingface_hub.community.DiscussionWithDetails
author: brianhur
conflicting_files: null
created_at: 2023-06-01 00:10:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d2f8dc3c1fbcdaf9f1f3b277b299ad0e.svg
      fullname: Brian Hur
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brianhur
      type: user
    createdAt: '2023-06-01T01:10:02.000Z'
    data:
      edited: false
      editors:
      - brianhur
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d2f8dc3c1fbcdaf9f1f3b277b299ad0e.svg
          fullname: Brian Hur
          isHf: false
          isPro: false
          name: brianhur
          type: user
        html: '<p>Using the example: qa_pipeline = pipeline("question-answering",
          model="medalpaca/medalpaca-13b", tokenizer="medalpaca/medalpaca-13b")</p>

          <h2 id="i-get-the-error">I get the error: </h2>

          <p>RecursionError                            Traceback (most recent call
          last)<br>Cell In[4], line 1<br>----&gt; 1 qa_pipeline = pipeline("question-answering",
          model="medalpaca/medalpaca-13b", tokenizer="medalpaca/medalpaca-13b")</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/pipelines/<strong>init</strong>.py:885,
          in pipeline(task, model, config, tokenizer, feature_extractor, image_processor,
          framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype,
          trust_remote_code, model_kwargs, pipeline_class, **kwargs)<br>    882             tokenizer_kwargs
          = model_kwargs.copy()<br>    883             tokenizer_kwargs.pop("torch_dtype",
          None)<br>--&gt; 885         tokenizer = AutoTokenizer.from_pretrained(<br>    886             tokenizer_identifier,
          use_fast=use_fast, _from_pipeline=task, **hub_kwargs, **tokenizer_kwargs<br>    887         )<br>    889
          if load_image_processor:<br>    890     # Try to infer image processor from
          model or config name (if provided as str)<br>    891     if image_processor
          is None:</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:694,
          in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,
          **kwargs)<br>    690     if tokenizer_class is None:<br>    691         raise
          ValueError(<br>    692             f"Tokenizer class {tokenizer_class_candidate}
          does not exist or is not currently imported."<br>    693         )<br>--&gt;
          694     return tokenizer_class.from_pretrained(pretrained_model_name_or_path,
          *inputs, **kwargs)<br>    696 # Otherwise we have to be creative.<br>    697
          # if model is an encoder decoder, the encoder tokenizer class is used by
          default<br>    698 if isinstance(config, EncoderDecoderConfig):</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1820,
          in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,
          *init_inputs, **kwargs)<br>   1817     else:<br>   1818         logger.info(f"loading
          file {file_path} from cache at {resolved_vocab_files[file_id]}")<br>-&gt;
          1820 return cls._from_pretrained(<br>   1821     resolved_vocab_files,<br>   1822     pretrained_model_name_or_path,<br>   1823     init_configuration,<br>   1824     *init_inputs,<br>   1825     use_auth_token=use_auth_token,<br>   1826     cache_dir=cache_dir,<br>   1827     local_files_only=local_files_only,<br>   1828     _commit_hash=commit_hash,<br>   1829     _is_local=is_local,<br>   1830     **kwargs,<br>   1831
          )</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1983,
          in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,
          init_configuration, use_auth_token, cache_dir, local_files_only, _commit_hash,
          _is_local, *init_inputs, **kwargs)<br>   1981 # Instantiate tokenizer.<br>   1982
          try:<br>-&gt; 1983     tokenizer = cls(*init_inputs, **init_kwargs)<br>   1984
          except OSError:<br>   1985     raise OSError(<br>   1986         "Unable
          to load vocabulary from file. "<br>   1987         "Please check that the
          provided vocabulary is accessible and not corrupted."<br>   1988     )</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama_fast.py:104,
          in LlamaTokenizerFast.<strong>init</strong>(self, vocab_file, tokenizer_file,
          clean_up_tokenization_spaces, unk_token, bos_token, eos_token, add_bos_token,
          add_eos_token, **kwargs)<br>    102 self._add_bos_token = add_bos_token<br>    103
          self._add_eos_token = add_eos_token<br>--&gt; 104 self.update_post_processor()<br>    106
          self.vocab_file = vocab_file<br>    107 self.can_save_slow_tokenizer = False
          if not self.vocab_file else True</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama_fast.py:111,
          in LlamaTokenizerFast.update_post_processor(self)<br>    109 def update_post_processor(self):<br>    110     bos
          = self.bos_token<br>--&gt; 111     bos_token_id = self.bos_token_id<br>    113     eos
          = self.eos_token<br>    114     eos_token_id = self.eos_token_id</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1131,
          in SpecialTokensMixin.bos_token_id(self)<br>   1129 if self._bos_token is
          None:<br>   1130     return None<br>-&gt; 1131 return self.convert_tokens_to_ids(self.bos_token)</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:250,
          in PreTrainedTokenizerFast.convert_tokens_to_ids(self, tokens)<br>    247     return
          None<br>    249 if isinstance(tokens, str):<br>--&gt; 250     return self._convert_token_to_id_with_added_voc(tokens)<br>    252
          return [self._convert_token_to_id_with_added_voc(token) for token in tokens]</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:257,
          in PreTrainedTokenizerFast._convert_token_to_id_with_added_voc(self, token)<br>    255
          index = self._tokenizer.token_to_id(token)<br>    256 if index is None:<br>--&gt;
          257     return self.unk_token_id<br>    258 return index</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1150,
          in SpecialTokensMixin.unk_token_id(self)<br>   1148 if self._unk_token is
          None:<br>   1149     return None<br>-&gt; 1150 return self.convert_tokens_to_ids(self.unk_token)</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:250,
          in PreTrainedTokenizerFast.convert_tokens_to_ids(self, tokens)<br>    247     return
          None<br>    249 if isinstance(tokens, str):<br>--&gt; 250     return self._convert_token_to_id_with_added_voc(tokens)<br>    252
          return [self._convert_token_to_id_with_added_voc(token) for token in tokens]</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:257,
          in PreTrainedTokenizerFast._convert_token_to_id_with_added_voc(self, token)<br>    255
          index = self._tokenizer.token_to_id(token)<br>    256 if index is None:<br>--&gt;
          257     return self.unk_token_id<br>    258 return index</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1150,
          in SpecialTokensMixin.unk_token_id(self)<br>   1148 if self._unk_token is
          None:<br>   1149     return None<br>-&gt; 1150 return self.convert_tokens_to_ids(self.unk_token)</p>

          <pre><code>[... skipping similar frames: PreTrainedTokenizerFast._convert_token_to_id_with_added_voc
          at line 257 (985 times), PreTrainedTokenizerFast.convert_tokens_to_ids at
          line 250 (985 times), SpecialTokensMixin.unk_token_id at line 1150 (985
          times)]

          </code></pre>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:250,
          in PreTrainedTokenizerFast.convert_tokens_to_ids(self, tokens)<br>    247     return
          None<br>    249 if isinstance(tokens, str):<br>--&gt; 250     return self._convert_token_to_id_with_added_voc(tokens)<br>    252
          return [self._convert_token_to_id_with_added_voc(token) for token in tokens]</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:257,
          in PreTrainedTokenizerFast._convert_token_to_id_with_added_voc(self, token)<br>    255
          index = self._tokenizer.token_to_id(token)<br>    256 if index is None:<br>--&gt;
          257     return self.unk_token_id<br>    258 return index</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1150,
          in SpecialTokensMixin.unk_token_id(self)<br>   1148 if self._unk_token is
          None:<br>   1149     return None<br>-&gt; 1150 return self.convert_tokens_to_ids(self.unk_token)</p>

          <p>File ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1030,
          in SpecialTokensMixin.unk_token(self)<br>   1028         logger.error("Using
          unk_token, but it is not set yet.")<br>   1029     return None<br>-&gt;
          1030 return str(self._unk_token)</p>

          <p>RecursionError: maximum recursion depth exceeded while calling a Python
          object</p>

          '
        raw: "Using the example: qa_pipeline = pipeline(\"question-answering\", model=\"\
          medalpaca/medalpaca-13b\", tokenizer=\"medalpaca/medalpaca-13b\")\r\n\r\n\
          I get the error: \r\n---------------------------------------------------------------------------\r\
          \nRecursionError                            Traceback (most recent call\
          \ last)\r\nCell In[4], line 1\r\n----> 1 qa_pipeline = pipeline(\"question-answering\"\
          , model=\"medalpaca/medalpaca-13b\", tokenizer=\"medalpaca/medalpaca-13b\"\
          )\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/pipelines/__init__.py:885,\
          \ in pipeline(task, model, config, tokenizer, feature_extractor, image_processor,\
          \ framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype,\
          \ trust_remote_code, model_kwargs, pipeline_class, **kwargs)\r\n    882\
          \             tokenizer_kwargs = model_kwargs.copy()\r\n    883        \
          \     tokenizer_kwargs.pop(\"torch_dtype\", None)\r\n--> 885         tokenizer\
          \ = AutoTokenizer.from_pretrained(\r\n    886             tokenizer_identifier,\
          \ use_fast=use_fast, _from_pipeline=task, **hub_kwargs, **tokenizer_kwargs\r\
          \n    887         )\r\n    889 if load_image_processor:\r\n    890     #\
          \ Try to infer image processor from model or config name (if provided as\
          \ str)\r\n    891     if image_processor is None:\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:694,\
          \ in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,\
          \ **kwargs)\r\n    690     if tokenizer_class is None:\r\n    691      \
          \   raise ValueError(\r\n    692             f\"Tokenizer class {tokenizer_class_candidate}\
          \ does not exist or is not currently imported.\"\r\n    693         )\r\n\
          --> 694     return tokenizer_class.from_pretrained(pretrained_model_name_or_path,\
          \ *inputs, **kwargs)\r\n    696 # Otherwise we have to be creative.\r\n\
          \    697 # if model is an encoder decoder, the encoder tokenizer class is\
          \ used by default\r\n    698 if isinstance(config, EncoderDecoderConfig):\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1820,\
          \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
          \ *init_inputs, **kwargs)\r\n   1817     else:\r\n   1818         logger.info(f\"\
          loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\
          )\r\n-> 1820 return cls._from_pretrained(\r\n   1821     resolved_vocab_files,\r\
          \n   1822     pretrained_model_name_or_path,\r\n   1823     init_configuration,\r\
          \n   1824     *init_inputs,\r\n   1825     use_auth_token=use_auth_token,\r\
          \n   1826     cache_dir=cache_dir,\r\n   1827     local_files_only=local_files_only,\r\
          \n   1828     _commit_hash=commit_hash,\r\n   1829     _is_local=is_local,\r\
          \n   1830     **kwargs,\r\n   1831 )\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1983,\
          \ in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files,\
          \ pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir,\
          \ local_files_only, _commit_hash, _is_local, *init_inputs, **kwargs)\r\n\
          \   1981 # Instantiate tokenizer.\r\n   1982 try:\r\n-> 1983     tokenizer\
          \ = cls(*init_inputs, **init_kwargs)\r\n   1984 except OSError:\r\n   1985\
          \     raise OSError(\r\n   1986         \"Unable to load vocabulary from\
          \ file. \"\r\n   1987         \"Please check that the provided vocabulary\
          \ is accessible and not corrupted.\"\r\n   1988     )\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama_fast.py:104,\
          \ in LlamaTokenizerFast.__init__(self, vocab_file, tokenizer_file, clean_up_tokenization_spaces,\
          \ unk_token, bos_token, eos_token, add_bos_token, add_eos_token, **kwargs)\r\
          \n    102 self._add_bos_token = add_bos_token\r\n    103 self._add_eos_token\
          \ = add_eos_token\r\n--> 104 self.update_post_processor()\r\n    106 self.vocab_file\
          \ = vocab_file\r\n    107 self.can_save_slow_tokenizer = False if not self.vocab_file\
          \ else True\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama_fast.py:111,\
          \ in LlamaTokenizerFast.update_post_processor(self)\r\n    109 def update_post_processor(self):\r\
          \n    110     bos = self.bos_token\r\n--> 111     bos_token_id = self.bos_token_id\r\
          \n    113     eos = self.eos_token\r\n    114     eos_token_id = self.eos_token_id\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1131,\
          \ in SpecialTokensMixin.bos_token_id(self)\r\n   1129 if self._bos_token\
          \ is None:\r\n   1130     return None\r\n-> 1131 return self.convert_tokens_to_ids(self.bos_token)\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:250,\
          \ in PreTrainedTokenizerFast.convert_tokens_to_ids(self, tokens)\r\n   \
          \ 247     return None\r\n    249 if isinstance(tokens, str):\r\n--> 250\
          \     return self._convert_token_to_id_with_added_voc(tokens)\r\n    252\
          \ return [self._convert_token_to_id_with_added_voc(token) for token in tokens]\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:257,\
          \ in PreTrainedTokenizerFast._convert_token_to_id_with_added_voc(self, token)\r\
          \n    255 index = self._tokenizer.token_to_id(token)\r\n    256 if index\
          \ is None:\r\n--> 257     return self.unk_token_id\r\n    258 return index\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1150,\
          \ in SpecialTokensMixin.unk_token_id(self)\r\n   1148 if self._unk_token\
          \ is None:\r\n   1149     return None\r\n-> 1150 return self.convert_tokens_to_ids(self.unk_token)\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:250,\
          \ in PreTrainedTokenizerFast.convert_tokens_to_ids(self, tokens)\r\n   \
          \ 247     return None\r\n    249 if isinstance(tokens, str):\r\n--> 250\
          \     return self._convert_token_to_id_with_added_voc(tokens)\r\n    252\
          \ return [self._convert_token_to_id_with_added_voc(token) for token in tokens]\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:257,\
          \ in PreTrainedTokenizerFast._convert_token_to_id_with_added_voc(self, token)\r\
          \n    255 index = self._tokenizer.token_to_id(token)\r\n    256 if index\
          \ is None:\r\n--> 257     return self.unk_token_id\r\n    258 return index\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1150,\
          \ in SpecialTokensMixin.unk_token_id(self)\r\n   1148 if self._unk_token\
          \ is None:\r\n   1149     return None\r\n-> 1150 return self.convert_tokens_to_ids(self.unk_token)\r\
          \n\r\n    [... skipping similar frames: PreTrainedTokenizerFast._convert_token_to_id_with_added_voc\
          \ at line 257 (985 times), PreTrainedTokenizerFast.convert_tokens_to_ids\
          \ at line 250 (985 times), SpecialTokensMixin.unk_token_id at line 1150\
          \ (985 times)]\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:250,\
          \ in PreTrainedTokenizerFast.convert_tokens_to_ids(self, tokens)\r\n   \
          \ 247     return None\r\n    249 if isinstance(tokens, str):\r\n--> 250\
          \     return self._convert_token_to_id_with_added_voc(tokens)\r\n    252\
          \ return [self._convert_token_to_id_with_added_voc(token) for token in tokens]\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:257,\
          \ in PreTrainedTokenizerFast._convert_token_to_id_with_added_voc(self, token)\r\
          \n    255 index = self._tokenizer.token_to_id(token)\r\n    256 if index\
          \ is None:\r\n--> 257     return self.unk_token_id\r\n    258 return index\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1150,\
          \ in SpecialTokensMixin.unk_token_id(self)\r\n   1148 if self._unk_token\
          \ is None:\r\n   1149     return None\r\n-> 1150 return self.convert_tokens_to_ids(self.unk_token)\r\
          \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1030,\
          \ in SpecialTokensMixin.unk_token(self)\r\n   1028         logger.error(\"\
          Using unk_token, but it is not set yet.\")\r\n   1029     return None\r\n\
          -> 1030 return str(self._unk_token)\r\n\r\nRecursionError: maximum recursion\
          \ depth exceeded while calling a Python object"
        updatedAt: '2023-06-01T01:10:02.696Z'
      numEdits: 0
      reactions: []
    id: 6477efea312e39090199b545
    type: comment
  author: brianhur
  content: "Using the example: qa_pipeline = pipeline(\"question-answering\", model=\"\
    medalpaca/medalpaca-13b\", tokenizer=\"medalpaca/medalpaca-13b\")\r\n\r\nI get\
    \ the error: \r\n---------------------------------------------------------------------------\r\
    \nRecursionError                            Traceback (most recent call last)\r\
    \nCell In[4], line 1\r\n----> 1 qa_pipeline = pipeline(\"question-answering\"\
    , model=\"medalpaca/medalpaca-13b\", tokenizer=\"medalpaca/medalpaca-13b\")\r\n\
    \r\nFile ~/hf/lib/python3.10/site-packages/transformers/pipelines/__init__.py:885,\
    \ in pipeline(task, model, config, tokenizer, feature_extractor, image_processor,\
    \ framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype,\
    \ trust_remote_code, model_kwargs, pipeline_class, **kwargs)\r\n    882      \
    \       tokenizer_kwargs = model_kwargs.copy()\r\n    883             tokenizer_kwargs.pop(\"\
    torch_dtype\", None)\r\n--> 885         tokenizer = AutoTokenizer.from_pretrained(\r\
    \n    886             tokenizer_identifier, use_fast=use_fast, _from_pipeline=task,\
    \ **hub_kwargs, **tokenizer_kwargs\r\n    887         )\r\n    889 if load_image_processor:\r\
    \n    890     # Try to infer image processor from model or config name (if provided\
    \ as str)\r\n    891     if image_processor is None:\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:694,\
    \ in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs,\
    \ **kwargs)\r\n    690     if tokenizer_class is None:\r\n    691         raise\
    \ ValueError(\r\n    692             f\"Tokenizer class {tokenizer_class_candidate}\
    \ does not exist or is not currently imported.\"\r\n    693         )\r\n--> 694\
    \     return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs,\
    \ **kwargs)\r\n    696 # Otherwise we have to be creative.\r\n    697 # if model\
    \ is an encoder decoder, the encoder tokenizer class is used by default\r\n  \
    \  698 if isinstance(config, EncoderDecoderConfig):\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1820,\
    \ in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path,\
    \ *init_inputs, **kwargs)\r\n   1817     else:\r\n   1818         logger.info(f\"\
    loading file {file_path} from cache at {resolved_vocab_files[file_id]}\")\r\n\
    -> 1820 return cls._from_pretrained(\r\n   1821     resolved_vocab_files,\r\n\
    \   1822     pretrained_model_name_or_path,\r\n   1823     init_configuration,\r\
    \n   1824     *init_inputs,\r\n   1825     use_auth_token=use_auth_token,\r\n\
    \   1826     cache_dir=cache_dir,\r\n   1827     local_files_only=local_files_only,\r\
    \n   1828     _commit_hash=commit_hash,\r\n   1829     _is_local=is_local,\r\n\
    \   1830     **kwargs,\r\n   1831 )\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1983,\
    \ in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path,\
    \ init_configuration, use_auth_token, cache_dir, local_files_only, _commit_hash,\
    \ _is_local, *init_inputs, **kwargs)\r\n   1981 # Instantiate tokenizer.\r\n \
    \  1982 try:\r\n-> 1983     tokenizer = cls(*init_inputs, **init_kwargs)\r\n \
    \  1984 except OSError:\r\n   1985     raise OSError(\r\n   1986         \"Unable\
    \ to load vocabulary from file. \"\r\n   1987         \"Please check that the\
    \ provided vocabulary is accessible and not corrupted.\"\r\n   1988     )\r\n\r\
    \nFile ~/hf/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama_fast.py:104,\
    \ in LlamaTokenizerFast.__init__(self, vocab_file, tokenizer_file, clean_up_tokenization_spaces,\
    \ unk_token, bos_token, eos_token, add_bos_token, add_eos_token, **kwargs)\r\n\
    \    102 self._add_bos_token = add_bos_token\r\n    103 self._add_eos_token =\
    \ add_eos_token\r\n--> 104 self.update_post_processor()\r\n    106 self.vocab_file\
    \ = vocab_file\r\n    107 self.can_save_slow_tokenizer = False if not self.vocab_file\
    \ else True\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama_fast.py:111,\
    \ in LlamaTokenizerFast.update_post_processor(self)\r\n    109 def update_post_processor(self):\r\
    \n    110     bos = self.bos_token\r\n--> 111     bos_token_id = self.bos_token_id\r\
    \n    113     eos = self.eos_token\r\n    114     eos_token_id = self.eos_token_id\r\
    \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1131,\
    \ in SpecialTokensMixin.bos_token_id(self)\r\n   1129 if self._bos_token is None:\r\
    \n   1130     return None\r\n-> 1131 return self.convert_tokens_to_ids(self.bos_token)\r\
    \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:250,\
    \ in PreTrainedTokenizerFast.convert_tokens_to_ids(self, tokens)\r\n    247  \
    \   return None\r\n    249 if isinstance(tokens, str):\r\n--> 250     return self._convert_token_to_id_with_added_voc(tokens)\r\
    \n    252 return [self._convert_token_to_id_with_added_voc(token) for token in\
    \ tokens]\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:257,\
    \ in PreTrainedTokenizerFast._convert_token_to_id_with_added_voc(self, token)\r\
    \n    255 index = self._tokenizer.token_to_id(token)\r\n    256 if index is None:\r\
    \n--> 257     return self.unk_token_id\r\n    258 return index\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1150,\
    \ in SpecialTokensMixin.unk_token_id(self)\r\n   1148 if self._unk_token is None:\r\
    \n   1149     return None\r\n-> 1150 return self.convert_tokens_to_ids(self.unk_token)\r\
    \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:250,\
    \ in PreTrainedTokenizerFast.convert_tokens_to_ids(self, tokens)\r\n    247  \
    \   return None\r\n    249 if isinstance(tokens, str):\r\n--> 250     return self._convert_token_to_id_with_added_voc(tokens)\r\
    \n    252 return [self._convert_token_to_id_with_added_voc(token) for token in\
    \ tokens]\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:257,\
    \ in PreTrainedTokenizerFast._convert_token_to_id_with_added_voc(self, token)\r\
    \n    255 index = self._tokenizer.token_to_id(token)\r\n    256 if index is None:\r\
    \n--> 257     return self.unk_token_id\r\n    258 return index\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1150,\
    \ in SpecialTokensMixin.unk_token_id(self)\r\n   1148 if self._unk_token is None:\r\
    \n   1149     return None\r\n-> 1150 return self.convert_tokens_to_ids(self.unk_token)\r\
    \n\r\n    [... skipping similar frames: PreTrainedTokenizerFast._convert_token_to_id_with_added_voc\
    \ at line 257 (985 times), PreTrainedTokenizerFast.convert_tokens_to_ids at line\
    \ 250 (985 times), SpecialTokensMixin.unk_token_id at line 1150 (985 times)]\r\
    \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:250,\
    \ in PreTrainedTokenizerFast.convert_tokens_to_ids(self, tokens)\r\n    247  \
    \   return None\r\n    249 if isinstance(tokens, str):\r\n--> 250     return self._convert_token_to_id_with_added_voc(tokens)\r\
    \n    252 return [self._convert_token_to_id_with_added_voc(token) for token in\
    \ tokens]\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:257,\
    \ in PreTrainedTokenizerFast._convert_token_to_id_with_added_voc(self, token)\r\
    \n    255 index = self._tokenizer.token_to_id(token)\r\n    256 if index is None:\r\
    \n--> 257     return self.unk_token_id\r\n    258 return index\r\n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1150,\
    \ in SpecialTokensMixin.unk_token_id(self)\r\n   1148 if self._unk_token is None:\r\
    \n   1149     return None\r\n-> 1150 return self.convert_tokens_to_ids(self.unk_token)\r\
    \n\r\nFile ~/hf/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1030,\
    \ in SpecialTokensMixin.unk_token(self)\r\n   1028         logger.error(\"Using\
    \ unk_token, but it is not set yet.\")\r\n   1029     return None\r\n-> 1030 return\
    \ str(self._unk_token)\r\n\r\nRecursionError: maximum recursion depth exceeded\
    \ while calling a Python object"
  created_at: 2023-06-01 00:10:02+00:00
  edited: false
  hidden: false
  id: 6477efea312e39090199b545
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1656522926135-noauth.jpeg?w=200&h=200&f=face
      fullname: Ben Viggiano
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: bviggiano
      type: user
    createdAt: '2023-06-01T03:34:52.000Z'
    data:
      edited: false
      editors:
      - bviggiano
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1656522926135-noauth.jpeg?w=200&h=200&f=face
          fullname: Ben Viggiano
          isHf: false
          isPro: false
          name: bviggiano
          type: user
        html: '<p>I am also getting this error</p>

          '
        raw: I am also getting this error
        updatedAt: '2023-06-01T03:34:52.049Z'
      numEdits: 0
      reactions: []
    id: 647811dcf911e9e76c70b9b4
    type: comment
  author: bviggiano
  content: I am also getting this error
  created_at: 2023-06-01 02:34:52+00:00
  edited: false
  hidden: false
  id: 647811dcf911e9e76c70b9b4
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/d2f8dc3c1fbcdaf9f1f3b277b299ad0e.svg
      fullname: Brian Hur
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: brianhur
      type: user
    createdAt: '2023-06-01T21:05:08.000Z'
    data:
      edited: false
      editors:
      - brianhur
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/d2f8dc3c1fbcdaf9f1f3b277b299ad0e.svg
          fullname: Brian Hur
          isHf: false
          isPro: false
          name: brianhur
          type: user
        html: "<p>I believe it's caused by the issue listed here where it's using\
          \ an older tokenizer library in the model card: <a rel=\"nofollow\" href=\"\
          https://github.com/huggingface/transformers/issues/22762\">https://github.com/huggingface/transformers/issues/22762</a></p>\n\
          <p>Any chance you can confirm and get this updated <span data-props=\"{&quot;user&quot;:&quot;kbressem&quot;}\"\
          \ data-target=\"UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\"\
          >\n\n<span class=\"inline-block\"><span class=\"contents\"><a href=\"/kbressem\"\
          >@<span class=\"underline\">kbressem</span></a></span>\n\n\t</span></span>\
          \ , <span data-props=\"{&quot;user&quot;:&quot;dtruhn&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/dtruhn\">@<span class=\"\
          underline\">dtruhn</span></a></span>\n\n\t</span></span>  or <span data-props=\"\
          {&quot;user&quot;:&quot;peterhan91&quot;}\" data-target=\"UserMention\"\
          \ class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"inline-block\"\
          ><span class=\"contents\"><a href=\"/peterhan91\">@<span class=\"underline\"\
          >peterhan91</span></a></span>\n\n\t</span></span> ?</p>\n"
        raw: 'I believe it''s caused by the issue listed here where it''s using an
          older tokenizer library in the model card: https://github.com/huggingface/transformers/issues/22762


          Any chance you can confirm and get this updated @kbressem , @dtruhn  or
          @peterhan91 ?'
        updatedAt: '2023-06-01T21:05:08.679Z'
      numEdits: 0
      reactions: []
    id: 64790804dbf97e0b5cc8935d
    type: comment
  author: brianhur
  content: 'I believe it''s caused by the issue listed here where it''s using an older
    tokenizer library in the model card: https://github.com/huggingface/transformers/issues/22762


    Any chance you can confirm and get this updated @kbressem , @dtruhn  or @peterhan91
    ?'
  created_at: 2023-06-01 20:05:08+00:00
  edited: false
  hidden: false
  id: 64790804dbf97e0b5cc8935d
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/cc5bbc9bf7f8c9e1b3066750df518a82.svg
      fullname: Keno Bressem
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: kbressem
      type: user
    createdAt: '2023-06-04T16:38:17.000Z'
    data:
      edited: false
      editors:
      - kbressem
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9433126449584961
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/cc5bbc9bf7f8c9e1b3066750df518a82.svg
          fullname: Keno Bressem
          isHf: false
          isPro: false
          name: kbressem
          type: user
        html: '<p>We will probably update the model in the future. There are plenty
          of things we like to improve, but it will take some time. In the meantime,
          try out the inferer class on our GitHub repo. This should work. </p>

          '
        raw: 'We will probably update the model in the future. There are plenty of
          things we like to improve, but it will take some time. In the meantime,
          try out the inferer class on our GitHub repo. This should work. '
        updatedAt: '2023-06-04T16:38:17.530Z'
      numEdits: 0
      reactions: []
      relatedEventId: 647cbdf91c0644de8d2b80cb
    id: 647cbdf91c0644de8d2b80c8
    type: comment
  author: kbressem
  content: 'We will probably update the model in the future. There are plenty of things
    we like to improve, but it will take some time. In the meantime, try out the inferer
    class on our GitHub repo. This should work. '
  created_at: 2023-06-04 15:38:17+00:00
  edited: false
  hidden: false
  id: 647cbdf91c0644de8d2b80c8
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/cc5bbc9bf7f8c9e1b3066750df518a82.svg
      fullname: Keno Bressem
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: kbressem
      type: user
    createdAt: '2023-06-04T16:38:17.000Z'
    data:
      status: closed
    id: 647cbdf91c0644de8d2b80cb
    type: status-change
  author: kbressem
  created_at: 2023-06-04 15:38:17+00:00
  id: 647cbdf91c0644de8d2b80cb
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: medalpaca/medalpaca-13b
repo_type: model
status: closed
target_branch: null
title: 'RecursionError: maximum recursion depth exceeded while calling a Python object'
