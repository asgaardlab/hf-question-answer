!!python/object:huggingface_hub.community.DiscussionWithDetails
author: xijiang
conflicting_files: null
created_at: 2023-08-15 05:57:09+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/80b036761b4bcb6a6d50a6db2e36650d.svg
      fullname: zhuxijiang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xijiang
      type: user
    createdAt: '2023-08-15T06:57:09.000Z'
    data:
      edited: false
      editors:
      - xijiang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.26024365425109863
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/80b036761b4bcb6a6d50a6db2e36650d.svg
          fullname: zhuxijiang
          isHf: false
          isPro: false
          name: xijiang
          type: user
        html: '<blockquote>

          <blockquote>

          <blockquote>

          <p>prompt = "# language: Python\n# write a bubble sort function\n"<br>inputs
          = tokenizer.encode(prompt, return_tensors="pt").to(model.device)<br>generate_args
          = {"max_length": 256, "eos_token_id": 2, "pad_token_id": 2}<br>outputs =
          model.generate(inputs, **generate_args)<br>print(tokenizer.decode(outputs[0]))</p>

          </blockquote>

          </blockquote>

          </blockquote>

          <h1 id="language-python">language: Python</h1>

          <h1 id="write-a-bubble-sort-function">write a bubble sort function</h1>

          <p>def bubble_sort(list):<br>    for i in range(len(list) - 1):<br>        for
          j in range(len(list) - 1):<br>            if list[j] &gt; list[j + 1]:<br>                list[j],
          list[j + 1] = list[j + 1], list[j]<br>    return list</p>

          <p>print(bubble_sort([5, 2, 4, 6, 1, 3]))</p>

          <blockquote>

          <blockquote>

          <blockquote>

          <p>prompt = "# language: C++\n# write a bubble sort function\n"<br>inputs
          = tokenizer.encode(prompt, return_tensors="pt").to(model.device)<br>generate_args
          = {"max_length": 256, "eos_token_id": 2, "pad_token_id": 2}<br>outputs =
          model.generate(inputs, **generate_args)<br>print(tokenizer.decode(outputs[0]))</p>

          </blockquote>

          </blockquote>

          </blockquote>

          <h1 id="language-c">language: C++</h1>

          <h1 id="write-a-bubble-sort-function-1">write a bubble sort function</h1>

          <p>def bubble_sort(list):<br>    for i in range(len(list) - 1):<br>        for
          j in range(len(list) - 1):<br>            if list[j] &gt; list[j + 1]:<br>                list[j],
          list[j + 1] = list[j + 1], list[j]<br>    return list</p>

          <p>print(bubble_sort([5, 2, 1, 8, 4]))</p>

          '
        raw: ">>> prompt = \"# language: Python\\n# write a bubble sort function\\\
          n\"\r\n>>> inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\r\
          \n>>> generate_args = {\"max_length\": 256, \"eos_token_id\": 2, \"pad_token_id\"\
          : 2}\r\n>>> outputs = model.generate(inputs, **generate_args)\r\n>>> print(tokenizer.decode(outputs[0]))\r\
          \n# language: Python\r\n# write a bubble sort function\r\n\r\n\r\ndef bubble_sort(list):\r\
          \n    for i in range(len(list) - 1):\r\n        for j in range(len(list)\
          \ - 1):\r\n            if list[j] > list[j + 1]:\r\n                list[j],\
          \ list[j + 1] = list[j + 1], list[j]\r\n    return list\r\n\r\n\r\nprint(bubble_sort([5,\
          \ 2, 4, 6, 1, 3]))\r\n>>>\r\n>>> prompt = \"# language: C++\\n# write a\
          \ bubble sort function\\n\"\r\n>>> inputs = tokenizer.encode(prompt, return_tensors=\"\
          pt\").to(model.device)\r\n>>> generate_args = {\"max_length\": 256, \"eos_token_id\"\
          : 2, \"pad_token_id\": 2}\r\n>>> outputs = model.generate(inputs, **generate_args)\r\
          \n>>> print(tokenizer.decode(outputs[0]))\r\n# language: C++\r\n# write\
          \ a bubble sort function\r\n\r\n\r\ndef bubble_sort(list):\r\n    for i\
          \ in range(len(list) - 1):\r\n        for j in range(len(list) - 1):\r\n\
          \            if list[j] > list[j + 1]:\r\n                list[j], list[j\
          \ + 1] = list[j + 1], list[j]\r\n    return list\r\n\r\n\r\nprint(bubble_sort([5,\
          \ 2, 1, 8, 4]))\r\n"
        updatedAt: '2023-08-15T06:57:09.169Z'
      numEdits: 0
      reactions: []
    id: 64db21c57f8116a6ab400370
    type: comment
  author: xijiang
  content: ">>> prompt = \"# language: Python\\n# write a bubble sort function\\n\"\
    \r\n>>> inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\r\
    \n>>> generate_args = {\"max_length\": 256, \"eos_token_id\": 2, \"pad_token_id\"\
    : 2}\r\n>>> outputs = model.generate(inputs, **generate_args)\r\n>>> print(tokenizer.decode(outputs[0]))\r\
    \n# language: Python\r\n# write a bubble sort function\r\n\r\n\r\ndef bubble_sort(list):\r\
    \n    for i in range(len(list) - 1):\r\n        for j in range(len(list) - 1):\r\
    \n            if list[j] > list[j + 1]:\r\n                list[j], list[j + 1]\
    \ = list[j + 1], list[j]\r\n    return list\r\n\r\n\r\nprint(bubble_sort([5, 2,\
    \ 4, 6, 1, 3]))\r\n>>>\r\n>>> prompt = \"# language: C++\\n# write a bubble sort\
    \ function\\n\"\r\n>>> inputs = tokenizer.encode(prompt, return_tensors=\"pt\"\
    ).to(model.device)\r\n>>> generate_args = {\"max_length\": 256, \"eos_token_id\"\
    : 2, \"pad_token_id\": 2}\r\n>>> outputs = model.generate(inputs, **generate_args)\r\
    \n>>> print(tokenizer.decode(outputs[0]))\r\n# language: C++\r\n# write a bubble\
    \ sort function\r\n\r\n\r\ndef bubble_sort(list):\r\n    for i in range(len(list)\
    \ - 1):\r\n        for j in range(len(list) - 1):\r\n            if list[j] >\
    \ list[j + 1]:\r\n                list[j], list[j + 1] = list[j + 1], list[j]\r\
    \n    return list\r\n\r\n\r\nprint(bubble_sort([5, 2, 1, 8, 4]))\r\n"
  created_at: 2023-08-15 05:57:09+00:00
  edited: false
  hidden: false
  id: 64db21c57f8116a6ab400370
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1664543160657-6231576e92e83fd1179ac3f0.jpeg?w=200&h=200&f=face
      fullname: Qinkai Zheng
      isHf: false
      isOrgMember: true
      isOwner: false
      isPro: false
      name: Stanislas
      type: user
    createdAt: '2023-08-31T16:32:29.000Z'
    data:
      edited: false
      editors:
      - Stanislas
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.741730809211731
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1664543160657-6231576e92e83fd1179ac3f0.jpeg?w=200&h=200&f=face
          fullname: Qinkai Zheng
          isHf: false
          isPro: false
          name: Stanislas
          type: user
        html: '<p>Hi, the prompts are incorrect. The open-source CodeGeeX2-6B is a
          foundation code model, it should be used according to the coding conventions
          of a specific language. For instance, C++ should use the comment symbol
          "//". The language tag should be "// language: C++", and the prompt should
          be "// [prompt]". In your example, you used "#", which is a comment symbol
          unique to Python, so it naturally generated Python code. </p>

          '
        raw: 'Hi, the prompts are incorrect. The open-source CodeGeeX2-6B is a foundation
          code model, it should be used according to the coding conventions of a specific
          language. For instance, C++ should use the comment symbol "//". The language
          tag should be "// language: C++", and the prompt should be "// [prompt]".
          In your example, you used "#", which is a comment symbol unique to Python,
          so it naturally generated Python code. '
        updatedAt: '2023-08-31T16:32:29.051Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - zoigo
        - Jason233
    id: 64f0c09d2af8b54edf07ec20
    type: comment
  author: Stanislas
  content: 'Hi, the prompts are incorrect. The open-source CodeGeeX2-6B is a foundation
    code model, it should be used according to the coding conventions of a specific
    language. For instance, C++ should use the comment symbol "//". The language tag
    should be "// language: C++", and the prompt should be "// [prompt]". In your
    example, you used "#", which is a comment symbol unique to Python, so it naturally
    generated Python code. '
  created_at: 2023-08-31 15:32:29+00:00
  edited: false
  hidden: false
  id: 64f0c09d2af8b54edf07ec20
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/80b036761b4bcb6a6d50a6db2e36650d.svg
      fullname: zhuxijiang
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: xijiang
      type: user
    createdAt: '2023-09-01T07:59:10.000Z'
    data:
      edited: false
      editors:
      - xijiang
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7611013650894165
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/80b036761b4bcb6a6d50a6db2e36650d.svg
          fullname: zhuxijiang
          isHf: false
          isPro: false
          name: xijiang
          type: user
        html: '<blockquote>

          <p>Hi, the prompts are incorrect. The open-source CodeGeeX2-6B is a foundation
          code model, it should be used according to the coding conventions of a specific
          language. For instance, C++ should use the comment symbol "//". The language
          tag should be "// language: C++", and the prompt should be "// [prompt]".
          In your example, you used "#", which is a comment symbol unique to Python,
          so it naturally generated Python code.</p>

          </blockquote>

          <p>Thanks  I got it</p>

          '
        raw: '> Hi, the prompts are incorrect. The open-source CodeGeeX2-6B is a foundation
          code model, it should be used according to the coding conventions of a specific
          language. For instance, C++ should use the comment symbol "//". The language
          tag should be "// language: C++", and the prompt should be "// [prompt]".
          In your example, you used "#", which is a comment symbol unique to Python,
          so it naturally generated Python code.


          Thanks  I got it'
        updatedAt: '2023-09-01T07:59:10.086Z'
      numEdits: 0
      reactions: []
    id: 64f199ce082efb37fb17f04e
    type: comment
  author: xijiang
  content: '> Hi, the prompts are incorrect. The open-source CodeGeeX2-6B is a foundation
    code model, it should be used according to the coding conventions of a specific
    language. For instance, C++ should use the comment symbol "//". The language tag
    should be "// language: C++", and the prompt should be "// [prompt]". In your
    example, you used "#", which is a comment symbol unique to Python, so it naturally
    generated Python code.


    Thanks  I got it'
  created_at: 2023-09-01 06:59:10+00:00
  edited: false
  hidden: false
  id: 64f199ce082efb37fb17f04e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 6
repo_id: THUDM/codegeex2-6b
repo_type: model
status: open
target_branch: null
title: "Unable to distinguish my language field\uFF0Call is python"
