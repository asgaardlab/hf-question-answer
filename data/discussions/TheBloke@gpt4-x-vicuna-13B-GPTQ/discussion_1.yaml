!!python/object:huggingface_hub.community.DiscussionWithDetails
author: tosaddler
conflicting_files: null
created_at: 2023-05-05 18:08:52+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/310c8ec6fdf88b5a2c5f6de832fb8790.svg
      fullname: Trey Saddler
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: tosaddler
      type: user
    createdAt: '2023-05-05T19:08:52.000Z'
    data:
      edited: false
      editors:
      - tosaddler
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/310c8ec6fdf88b5a2c5f6de832fb8790.svg
          fullname: Trey Saddler
          isHf: false
          isPro: false
          name: tosaddler
          type: user
        html: '<p>Searched around and couldn''t find anyway to contact you directly,
          but I had a request. I''m still learning about LLMs, but MosaicML just released
          <a rel="nofollow" href="https://www.mosaicml.com/blog/mpt-7b">https://www.mosaicml.com/blog/mpt-7b</a>
          and I was trying to use Llama.cpp to convert to ggml for use in LangChain.
          I seem to be missing something though as I can''t get it to convert properly.
          You seem really good at doing these conversions, so I was wondering if I
          could bug you about this. My Discord username is Oh-now-uh#6551 if you wanted
          to reach out there. Thank you for all of the work that you do!</p>

          '
        raw: Searched around and couldn't find anyway to contact you directly, but
          I had a request. I'm still learning about LLMs, but MosaicML just released
          https://www.mosaicml.com/blog/mpt-7b and I was trying to use Llama.cpp to
          convert to ggml for use in LangChain. I seem to be missing something though
          as I can't get it to convert properly. You seem really good at doing these
          conversions, so I was wondering if I could bug you about this. My Discord
          username is Oh-now-uh#6551 if you wanted to reach out there. Thank you for
          all of the work that you do!
        updatedAt: '2023-05-05T19:08:52.888Z'
      numEdits: 0
      reactions: []
    id: 645554449d37c3fb3329a74b
    type: comment
  author: tosaddler
  content: Searched around and couldn't find anyway to contact you directly, but I
    had a request. I'm still learning about LLMs, but MosaicML just released https://www.mosaicml.com/blog/mpt-7b
    and I was trying to use Llama.cpp to convert to ggml for use in LangChain. I seem
    to be missing something though as I can't get it to convert properly. You seem
    really good at doing these conversions, so I was wondering if I could bug you
    about this. My Discord username is Oh-now-uh#6551 if you wanted to reach out there.
    Thank you for all of the work that you do!
  created_at: 2023-05-05 18:08:52+00:00
  edited: false
  hidden: false
  id: 645554449d37c3fb3329a74b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
      fullname: Tom Jobbins
      isHf: false
      isOrgMember: false
      isOwner: true
      isPro: true
      name: TheBloke
      type: user
    createdAt: '2023-05-05T19:32:48.000Z'
    data:
      edited: false
      editors:
      - TheBloke
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/6426d3f3a7723d62b53c259b/tvPikpAzKTKGN5wrpadOJ.jpeg?w=200&h=200&f=face
          fullname: Tom Jobbins
          isHf: false
          isPro: true
          name: TheBloke
          type: user
        html: '<p>Best way to reach me is on Discord, I''m TheBloke#9741 and you can
          find me on these Discords:<br>Alpaca Lora: <a rel="nofollow" href="https://discord.gg/eSdptpkm">https://discord.gg/eSdptpkm</a><br>GPT4All:
          <a rel="nofollow" href="https://discord.gg/sfWUbDKH">https://discord.gg/sfWUbDKH</a><br>LmSys
          (Vicuna): <a rel="nofollow" href="https://discord.gg/CPz84krv">https://discord.gg/CPz84krv</a></p>

          <p>MPT 7B looks amazing but I''m afraid right now you can''t use it in llama.cpp
          or in ooba text-gen-webui or anywhere else like that, as it''s a brand new
          model format.  It''ll take a little time - a few days or a week maybe -
          until it''s usable in the popular software.</p>

          <p>The efforts are already beginning. Check out #announcements in the GPT4All
          Discord I linked above - the GPT4All team are already looking to start work
          on making GGML support for it.</p>

          '
        raw: 'Best way to reach me is on Discord, I''m TheBloke#9741 and you can find
          me on these Discords:

          Alpaca Lora: https://discord.gg/eSdptpkm

          GPT4All: https://discord.gg/sfWUbDKH

          LmSys (Vicuna): https://discord.gg/CPz84krv


          MPT 7B looks amazing but I''m afraid right now you can''t use it in llama.cpp
          or in ooba text-gen-webui or anywhere else like that, as it''s a brand new
          model format.  It''ll take a little time - a few days or a week maybe -
          until it''s usable in the popular software.


          The efforts are already beginning. Check out #announcements in the GPT4All
          Discord I linked above - the GPT4All team are already looking to start work
          on making GGML support for it.'
        updatedAt: '2023-05-05T19:32:48.272Z'
      numEdits: 0
      reactions: []
    id: 645559e0f61f10d69dcedc82
    type: comment
  author: TheBloke
  content: 'Best way to reach me is on Discord, I''m TheBloke#9741 and you can find
    me on these Discords:

    Alpaca Lora: https://discord.gg/eSdptpkm

    GPT4All: https://discord.gg/sfWUbDKH

    LmSys (Vicuna): https://discord.gg/CPz84krv


    MPT 7B looks amazing but I''m afraid right now you can''t use it in llama.cpp
    or in ooba text-gen-webui or anywhere else like that, as it''s a brand new model
    format.  It''ll take a little time - a few days or a week maybe - until it''s
    usable in the popular software.


    The efforts are already beginning. Check out #announcements in the GPT4All Discord
    I linked above - the GPT4All team are already looking to start work on making
    GGML support for it.'
  created_at: 2023-05-05 18:32:48+00:00
  edited: false
  hidden: false
  id: 645559e0f61f10d69dcedc82
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: TheBloke/gpt4-x-vicuna-13B-GPTQ
repo_type: model
status: open
target_branch: null
title: Had a request
