!!python/object:huggingface_hub.community.DiscussionWithDetails
author: syddharth
conflicting_files: null
created_at: 2023-09-14 08:56:58+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/14401ff770324e5795e23b89bc5236a6.svg
      fullname: S M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: syddharth
      type: user
    createdAt: '2023-09-14T09:56:58.000Z'
    data:
      edited: true
      editors:
      - syddharth
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.350658118724823
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/14401ff770324e5795e23b89bc5236a6.svg
          fullname: S M
          isHf: false
          isPro: false
          name: syddharth
          type: user
        html: '<p>When running the code snippet on the Model card, the following error
          is encountered :</p>

          <hr>

          <p>TypeError                                 Traceback (most recent call
          last)<br>/home/syddharth/AI/colab/wuertschen.ipynb Cell 2 line 1<br>      7
          pipeline =  AutoPipelineForText2Image.from_pretrained(<br>      8     "warp-diffusion/wuerstchen",<br>      9     torch_dtype=dtype,<br>     10     requires_safety_checker=False,<br>     11
          ).to(device)<br>     13 caption = "Anthropomorphic cat dressed as a fire
          fighter"<br>---&gt; 15 output = pipeline(<br>     16     prompt=caption,<br>     17     height=1024,<br>     18     width=1024,<br>     19     prior_guidance_scale=4.0,<br>     20     decoder_guidance_scale=0.0,<br>     21
          ).images</p>

          <p>File ~/AI/colab/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115,
          in context_decorator..decorate_context(*args, **kwargs)<br>    112 @functools.wraps(func)<br>    113
          def decorate_context(*args, **kwargs):<br>    114     with ctx_factory():<br>--&gt;
          115         return func(*args, **kwargs)</p>

          <p>File ~/AI/colab/venv/lib/python3.10/site-packages/diffusers/pipelines/wuerstchen/pipeline_wuerstchen_combined.py:248,
          in WuerstchenCombinedPipeline.<strong>call</strong>(self, prompt, height,
          width, prior_num_inference_steps, prior_timesteps, prior_guidance_scale,
          num_inference_steps, decoder_timesteps, decoder_guidance_scale, negative_prompt,
          prompt_embeds, negative_prompt_embeds, num_images_per_prompt, generator,
          latents, output_type, return_dict)<br>    165 """<br>    166 Function invoked
          when calling the pipeline for generation.<br>    167<br>   (...)<br>    230     otherwise
          a <code>tuple</code>. When returning a tuple, the first element is a list
          with the generated images.<br>    231 """<br>    232 prior_outputs = self.prior_pipe(<br>    233     prompt=prompt
          if prompt_embeds is None else None,<br>    234     height=height,<br>   (...)<br>    246     return_dict=False,<br>    247
          )<br>--&gt; 248 image_embeddings = prior_outputs[0]<br>    250 outputs =
          self.decoder_pipe(<br>    251     image_embeddings=image_embeddings,<br>    252     prompt=prompt,<br>   (...)<br>    259     return_dict=return_dict,<br>    260
          )<br>    261 return outputs</p>

          <p>TypeError: ''generator'' object is not subscriptable</p>

          '
        raw: "When running the code snippet on the Model card, the following error\
          \ is encountered :\n\n---------------------------------------------------------------------------\n\
          TypeError                                 Traceback (most recent call last)\n\
          /home/syddharth/AI/colab/wuertschen.ipynb Cell 2 line 1\n      7 pipeline\
          \ =  AutoPipelineForText2Image.from_pretrained(\n      8     \"warp-diffusion/wuerstchen\"\
          ,\n      9     torch_dtype=dtype,\n     10     requires_safety_checker=False,\n\
          \     11 ).to(device)\n     13 caption = \"Anthropomorphic cat dressed as\
          \ a fire fighter\"\n---> 15 output = pipeline(\n     16     prompt=caption,\n\
          \     17     height=1024,\n     18     width=1024,\n     19     prior_guidance_scale=4.0,\n\
          \     20     decoder_guidance_scale=0.0,\n     21 ).images\n\nFile ~/AI/colab/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115,\
          \ in context_decorator.<locals>.decorate_context(*args, **kwargs)\n    112\
          \ @functools.wraps(func)\n    113 def decorate_context(*args, **kwargs):\n\
          \    114     with ctx_factory():\n--> 115         return func(*args, **kwargs)\n\
          \nFile ~/AI/colab/venv/lib/python3.10/site-packages/diffusers/pipelines/wuerstchen/pipeline_wuerstchen_combined.py:248,\
          \ in WuerstchenCombinedPipeline.__call__(self, prompt, height, width, prior_num_inference_steps,\
          \ prior_timesteps, prior_guidance_scale, num_inference_steps, decoder_timesteps,\
          \ decoder_guidance_scale, negative_prompt, prompt_embeds, negative_prompt_embeds,\
          \ num_images_per_prompt, generator, latents, output_type, return_dict)\n\
          \    165 \"\"\"\n    166 Function invoked when calling the pipeline for\
          \ generation.\n    167 \n   (...)\n    230     otherwise a `tuple`. When\
          \ returning a tuple, the first element is a list with the generated images.\n\
          \    231 \"\"\"\n    232 prior_outputs = self.prior_pipe(\n    233     prompt=prompt\
          \ if prompt_embeds is None else None,\n    234     height=height,\n   (...)\n\
          \    246     return_dict=False,\n    247 )\n--> 248 image_embeddings = prior_outputs[0]\n\
          \    250 outputs = self.decoder_pipe(\n    251     image_embeddings=image_embeddings,\n\
          \    252     prompt=prompt,\n   (...)\n    259     return_dict=return_dict,\n\
          \    260 )\n    261 return outputs\n\nTypeError: 'generator' object is not\
          \ subscriptable"
        updatedAt: '2023-09-14T09:57:18.754Z'
      numEdits: 1
      reactions: []
    id: 6502d8eae373323dabc8c71b
    type: comment
  author: syddharth
  content: "When running the code snippet on the Model card, the following error is\
    \ encountered :\n\n---------------------------------------------------------------------------\n\
    TypeError                                 Traceback (most recent call last)\n\
    /home/syddharth/AI/colab/wuertschen.ipynb Cell 2 line 1\n      7 pipeline =  AutoPipelineForText2Image.from_pretrained(\n\
    \      8     \"warp-diffusion/wuerstchen\",\n      9     torch_dtype=dtype,\n\
    \     10     requires_safety_checker=False,\n     11 ).to(device)\n     13 caption\
    \ = \"Anthropomorphic cat dressed as a fire fighter\"\n---> 15 output = pipeline(\n\
    \     16     prompt=caption,\n     17     height=1024,\n     18     width=1024,\n\
    \     19     prior_guidance_scale=4.0,\n     20     decoder_guidance_scale=0.0,\n\
    \     21 ).images\n\nFile ~/AI/colab/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115,\
    \ in context_decorator.<locals>.decorate_context(*args, **kwargs)\n    112 @functools.wraps(func)\n\
    \    113 def decorate_context(*args, **kwargs):\n    114     with ctx_factory():\n\
    --> 115         return func(*args, **kwargs)\n\nFile ~/AI/colab/venv/lib/python3.10/site-packages/diffusers/pipelines/wuerstchen/pipeline_wuerstchen_combined.py:248,\
    \ in WuerstchenCombinedPipeline.__call__(self, prompt, height, width, prior_num_inference_steps,\
    \ prior_timesteps, prior_guidance_scale, num_inference_steps, decoder_timesteps,\
    \ decoder_guidance_scale, negative_prompt, prompt_embeds, negative_prompt_embeds,\
    \ num_images_per_prompt, generator, latents, output_type, return_dict)\n    165\
    \ \"\"\"\n    166 Function invoked when calling the pipeline for generation.\n\
    \    167 \n   (...)\n    230     otherwise a `tuple`. When returning a tuple,\
    \ the first element is a list with the generated images.\n    231 \"\"\"\n   \
    \ 232 prior_outputs = self.prior_pipe(\n    233     prompt=prompt if prompt_embeds\
    \ is None else None,\n    234     height=height,\n   (...)\n    246     return_dict=False,\n\
    \    247 )\n--> 248 image_embeddings = prior_outputs[0]\n    250 outputs = self.decoder_pipe(\n\
    \    251     image_embeddings=image_embeddings,\n    252     prompt=prompt,\n\
    \   (...)\n    259     return_dict=return_dict,\n    260 )\n    261 return outputs\n\
    \nTypeError: 'generator' object is not subscriptable"
  created_at: 2023-09-14 08:56:58+00:00
  edited: true
  hidden: false
  id: 6502d8eae373323dabc8c71b
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/14401ff770324e5795e23b89bc5236a6.svg
      fullname: S M
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: syddharth
      type: user
    createdAt: '2023-09-14T11:16:22.000Z'
    data:
      status: closed
    id: 6502eb868e46888d6739481c
    type: status-change
  author: syddharth
  created_at: 2023-09-14 10:16:22+00:00
  id: 6502eb868e46888d6739481c
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 2
repo_id: warp-ai/wuerstchen
repo_type: model
status: closed
target_branch: null
title: 'TypeError: ''generator'' object is not subscriptable'
