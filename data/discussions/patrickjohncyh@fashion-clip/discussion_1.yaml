!!python/object:huggingface_hub.community.DiscussionWithDetails
author: matbreotten
conflicting_files: null
created_at: 2023-03-08 21:51:04+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4eaeef175db533e0234251f111341ae2.svg
      fullname: Matthias
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: matbreotten
      type: user
    createdAt: '2023-03-08T21:51:04.000Z'
    data:
      edited: false
      editors:
      - matbreotten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4eaeef175db533e0234251f111341ae2.svg
          fullname: Matthias
          isHf: false
          isPro: false
          name: matbreotten
          type: user
        html: '<p>The following command shown as an example did not work for me in
          Python 3.9 having installed the latest version:</p>

          <pre><code class="language-bash">pip install open-clip-torch

          </code></pre>

          <pre><code class="language-python"><span class="hljs-keyword">import</span>
          open_clip


          model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(<span
          class="hljs-string">''hf-hub:patrickjohncyh/fashion-clip''</span>)

          tokenizer = open_clip.get_tokenizer(<span class="hljs-string">''hf-hub:patrickjohncyh/fashion-clip''</span>)

          </code></pre>

          <p>Should the example be used with the CLIP model from OpenAI? Can you update
          the example code to be able to run the model?</p>

          '
        raw: "The following command shown as an example did not work for me in Python\
          \ 3.9 having installed the latest version:\r\n```bash\r\npip install open-clip-torch\r\
          \n```\r\n\r\n```python\r\nimport open_clip\r\n\r\nmodel, preprocess_train,\
          \ preprocess_val = open_clip.create_model_and_transforms('hf-hub:patrickjohncyh/fashion-clip')\r\
          \ntokenizer = open_clip.get_tokenizer('hf-hub:patrickjohncyh/fashion-clip')\r\
          \n```\r\n\r\nShould the example be used with the CLIP model from OpenAI?\
          \ Can you update the example code to be able to run the model?"
        updatedAt: '2023-03-08T21:51:04.826Z'
      numEdits: 0
      reactions: []
    id: 640903489e9f790c905732a2
    type: comment
  author: matbreotten
  content: "The following command shown as an example did not work for me in Python\
    \ 3.9 having installed the latest version:\r\n```bash\r\npip install open-clip-torch\r\
    \n```\r\n\r\n```python\r\nimport open_clip\r\n\r\nmodel, preprocess_train, preprocess_val\
    \ = open_clip.create_model_and_transforms('hf-hub:patrickjohncyh/fashion-clip')\r\
    \ntokenizer = open_clip.get_tokenizer('hf-hub:patrickjohncyh/fashion-clip')\r\n\
    ```\r\n\r\nShould the example be used with the CLIP model from OpenAI? Can you\
    \ update the example code to be able to run the model?"
  created_at: 2023-03-08 21:51:04+00:00
  edited: false
  hidden: false
  id: 640903489e9f790c905732a2
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625214886903-603f7c7af84ebe399f1c85cf.jpeg?w=200&h=200&f=face
      fullname: Federico Bianchi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vinid
      type: user
    createdAt: '2023-03-08T23:15:47.000Z'
    data:
      edited: false
      editors:
      - vinid
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625214886903-603f7c7af84ebe399f1c85cf.jpeg?w=200&h=200&f=face
          fullname: Federico Bianchi
          isHf: false
          isPro: false
          name: vinid
          type: user
        html: '<p>This should work with the HF API, if you can point us to how to
          adapt the model to open clip APIs happy to work on this</p>

          '
        raw: This should work with the HF API, if you can point us to how to adapt
          the model to open clip APIs happy to work on this
        updatedAt: '2023-03-08T23:15:47.924Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - matbreotten
    id: 640917234bf9635aa5105442
    type: comment
  author: vinid
  content: This should work with the HF API, if you can point us to how to adapt the
    model to open clip APIs happy to work on this
  created_at: 2023-03-08 23:15:47+00:00
  edited: false
  hidden: false
  id: 640917234bf9635aa5105442
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625214886903-603f7c7af84ebe399f1c85cf.jpeg?w=200&h=200&f=face
      fullname: Federico Bianchi
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: vinid
      type: user
    createdAt: '2023-03-09T03:20:17.000Z'
    data:
      edited: false
      editors:
      - vinid
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1625214886903-603f7c7af84ebe399f1c85cf.jpeg?w=200&h=200&f=face
          fullname: Federico Bianchi
          isHf: false
          isPro: false
          name: vinid
          type: user
        html: '<p>We removed the open clip part for now, you can use the HF model
          (there is a quick tutorial on the colab you will find on the <a rel="nofollow"
          href="https://github.com/patrickjohncyh/fashion-clip">repo</a>)</p>

          '
        raw: We removed the open clip part for now, you can use the HF model (there
          is a quick tutorial on the colab you will find on the [repo](https://github.com/patrickjohncyh/fashion-clip))
        updatedAt: '2023-03-09T03:20:17.097Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F44D"
        users:
        - matbreotten
    id: 6409507178566d59c4dcb5a9
    type: comment
  author: vinid
  content: We removed the open clip part for now, you can use the HF model (there
    is a quick tutorial on the colab you will find on the [repo](https://github.com/patrickjohncyh/fashion-clip))
  created_at: 2023-03-09 03:20:17+00:00
  edited: false
  hidden: false
  id: 6409507178566d59c4dcb5a9
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/4eaeef175db533e0234251f111341ae2.svg
      fullname: Matthias
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: matbreotten
      type: user
    createdAt: '2023-03-10T07:55:09.000Z'
    data:
      edited: false
      editors:
      - matbreotten
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/4eaeef175db533e0234251f111341ae2.svg
          fullname: Matthias
          isHf: false
          isPro: false
          name: matbreotten
          type: user
        html: "<p>Hi <span data-props=\"{&quot;user&quot;:&quot;vinid&quot;}\" data-target=\"\
          UserMention\" class=\"SVELTE_PARTIAL_HYDRATER contents\">\n\n<span class=\"\
          inline-block\"><span class=\"contents\"><a href=\"/vinid\">@<span class=\"\
          underline\">vinid</span></a></span>\n\n\t</span></span>, thank you for the\
          \ Google Colab - I made it work now with the <code>transformers</code> API\
          \ from Hugginface using the <code>CLIPProcessor</code> and <code>CLIPModel</code>\
          \ classes.</p>\n"
        raw: Hi @vinid, thank you for the Google Colab - I made it work now with the
          `transformers` API from Hugginface using the `CLIPProcessor` and `CLIPModel`
          classes.
        updatedAt: '2023-03-10T07:55:09.985Z'
      numEdits: 0
      reactions: []
      relatedEventId: 640ae25d30d20e85e6ca1bdc
    id: 640ae25d30d20e85e6ca1bdb
    type: comment
  author: matbreotten
  content: Hi @vinid, thank you for the Google Colab - I made it work now with the
    `transformers` API from Hugginface using the `CLIPProcessor` and `CLIPModel` classes.
  created_at: 2023-03-10 07:55:09+00:00
  edited: false
  hidden: false
  id: 640ae25d30d20e85e6ca1bdb
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/4eaeef175db533e0234251f111341ae2.svg
      fullname: Matthias
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: matbreotten
      type: user
    createdAt: '2023-03-10T07:55:09.000Z'
    data:
      status: closed
    id: 640ae25d30d20e85e6ca1bdc
    type: status-change
  author: matbreotten
  created_at: 2023-03-10 07:55:09+00:00
  id: 640ae25d30d20e85e6ca1bdc
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: patrickjohncyh/fashion-clip
repo_type: model
status: closed
target_branch: null
title: Cannot use the example to make it work with OpenCLIP
