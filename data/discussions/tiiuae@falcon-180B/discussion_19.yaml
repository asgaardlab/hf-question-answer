!!python/object:huggingface_hub.community.DiscussionWithDetails
author: aliosk
conflicting_files: null
created_at: 2023-09-18 11:40:44+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9419fe2b4533709d9924d599f8177f19.svg
      fullname: Ali Oskooei
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aliosk
      type: user
    createdAt: '2023-09-18T12:40:44.000Z'
    data:
      edited: false
      editors:
      - aliosk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.9231259226799011
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9419fe2b4533709d9924d599f8177f19.svg
          fullname: Ali Oskooei
          isHf: false
          isPro: false
          name: aliosk
          type: user
        html: '<p>I have already accepted T&amp;C and given access to the gated model
          ("Gated model<br>You have been granted access to this model").  I login
          via<br><code>hugginface_hub.notebook_login(new_session=True)</code></p>

          <p>and I try loading the model per documentation using a "text generation"
          pipeline.  Transformers version is 4.33.2.</p>

          <p>Upon doing this, I receive a 401 access error, saying it cannot access
          the tokenizer config json file. I tried opening the file via browser and
          I can access it. This problem seems to be specific to this particular model.
          I can load other gated models such as Llama-2-70b without a problem.</p>

          <p>Any help would be appreciated. </p>

          '
        raw: "I have already accepted T&C and given access to the gated model (\"\
          Gated model\r\nYou have been granted access to this model\").  I login via\
          \ \r\n``` hugginface_hub.notebook_login(new_session=True) ```\r\n\r\nand\
          \ I try loading the model per documentation using a \"text generation\"\
          \ pipeline.  Transformers version is 4.33.2.\r\n\r\nUpon doing this, I receive\
          \ a 401 access error, saying it cannot access the tokenizer config json\
          \ file. I tried opening the file via browser and I can access it. This problem\
          \ seems to be specific to this particular model. I can load other gated\
          \ models such as Llama-2-70b without a problem.\r\n\r\nAny help would be\
          \ appreciated. "
        updatedAt: '2023-09-18T12:40:44.684Z'
      numEdits: 0
      reactions: []
    id: 6508454c0c87331947c0637f
    type: comment
  author: aliosk
  content: "I have already accepted T&C and given access to the gated model (\"Gated\
    \ model\r\nYou have been granted access to this model\").  I login via \r\n```\
    \ hugginface_hub.notebook_login(new_session=True) ```\r\n\r\nand I try loading\
    \ the model per documentation using a \"text generation\" pipeline.  Transformers\
    \ version is 4.33.2.\r\n\r\nUpon doing this, I receive a 401 access error, saying\
    \ it cannot access the tokenizer config json file. I tried opening the file via\
    \ browser and I can access it. This problem seems to be specific to this particular\
    \ model. I can load other gated models such as Llama-2-70b without a problem.\r\
    \n\r\nAny help would be appreciated. "
  created_at: 2023-09-18 11:40:44+00:00
  edited: false
  hidden: false
  id: 6508454c0c87331947c0637f
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/9419fe2b4533709d9924d599f8177f19.svg
      fullname: Ali Oskooei
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aliosk
      type: user
    createdAt: '2023-09-18T12:57:15.000Z'
    data:
      edited: false
      editors:
      - aliosk
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8880569338798523
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/9419fe2b4533709d9924d599f8177f19.svg
          fullname: Ali Oskooei
          isHf: false
          isPro: false
          name: aliosk
          type: user
        html: '<p>The issue is related to the capitalization of "b" in the model name.
          Must use 180B instead of 180b. </p>

          '
        raw: 'The issue is related to the capitalization of "b" in the model name.
          Must use 180B instead of 180b. '
        updatedAt: '2023-09-18T12:57:15.285Z'
      numEdits: 0
      reactions: []
      relatedEventId: 6508492bada48d4be2851fc6
    id: 6508492bada48d4be2851fc5
    type: comment
  author: aliosk
  content: 'The issue is related to the capitalization of "b" in the model name. Must
    use 180B instead of 180b. '
  created_at: 2023-09-18 11:57:15+00:00
  edited: false
  hidden: false
  id: 6508492bada48d4be2851fc5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: /avatars/9419fe2b4533709d9924d599f8177f19.svg
      fullname: Ali Oskooei
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: aliosk
      type: user
    createdAt: '2023-09-18T12:57:15.000Z'
    data:
      status: closed
    id: 6508492bada48d4be2851fc6
    type: status-change
  author: aliosk
  created_at: 2023-09-18 11:57:15+00:00
  id: 6508492bada48d4be2851fc6
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 19
repo_id: tiiuae/falcon-180B
repo_type: model
status: closed
target_branch: null
title: 401 Error when trying to load the model
