!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ArthurZ
conflicting_files: []
created_at: 2023-10-10 10:00:29+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-10T11:00:29.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7017827033996582
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: "<p>Following the merge of <a rel=\"nofollow\" href=\"https://github.com/huggingface/transformers/pull/24310\"\
          >a PR</a> in <code>transformers</code> it appeared that this model was not\
          \ properly converted. This PR will fix the inference and was tested using\
          \ the following script:</p>\n<pre><code class=\"language-python\"><span\
          \ class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-keyword\">from</span>\
          \ transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer,\
          \ MarianMTModel\n<span class=\"hljs-meta\">&gt;&gt;&gt; </span>tokenizer\
          \ = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">'Helsinki-NLP/opus-mt-tc-big-ar-itc'</span>)\n\
          <span class=\"hljs-meta\">&gt;&gt;&gt; </span>inputs = tokenizer(<span class=\"\
          hljs-string\">\"\u064A\u0627!\u062F\u0639\u0648\u0646\u0627 \u0646\u062A\
          \u0639\u0644\u0645 \u0645\u0639\u0627\"</span>, return_tensors=<span class=\"\
          hljs-string\">\"pt\"</span>, padding=<span class=\"hljs-literal\">True</span>)\n\
          <span class=\"hljs-meta\">&gt;&gt;&gt; </span>model = MarianMTModel.from_pretrained(<span\
          \ class=\"hljs-string\">'Helsinki-NLP/opus-mt-tc-big-ar-itc'</span>)\n<span\
          \ class=\"hljs-meta\">&gt;&gt;&gt; </span><span class=\"hljs-built_in\"\
          >print</span>(tokenizer.batch_decode(model.generate(**inputs)))\n[<span\
          \ class=\"hljs-string\">'&lt;pad&gt;,,,, , ,                       !   \
          \                                                                      \
          \                                                                      \
          \                                                                      \
          \                                                                      \
          \                                                                      \
          \                                                                      \
          \                                                 &lt;/s&gt;'</span>]\n\
          </code></pre>\n"
        raw: "Following the merge of [a PR](https://github.com/huggingface/transformers/pull/24310)\
          \ in `transformers` it appeared that this model was not properly converted.\
          \ This PR will fix the inference and was tested using the following script:\n\
          ```python\n>>> from transformers import AutoTokenizer, MarianMTModel\n>>>\
          \ tokenizer = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-tc-big-ar-itc')\n\
          >>> inputs = tokenizer(\"\u064A\u0627!\u062F\u0639\u0648\u0646\u0627 \u0646\
          \u062A\u0639\u0644\u0645 \u0645\u0639\u0627\", return_tensors=\"pt\", padding=True)\n\
          >>> model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-tc-big-ar-itc')\n\
          >>> print(tokenizer.batch_decode(model.generate(**inputs)))\n['<pad>,,,,\
          \ , ,                       !                                          \
          \                                                                      \
          \                                                                      \
          \                                                                      \
          \                                                                      \
          \                                                                      \
          \                                                                      \
          \          </s>']\n```"
        updatedAt: '2023-10-10T11:00:29.714Z'
      numEdits: 0
      reactions: []
    id: 65252ecdb9f25427c93a7279
    type: comment
  author: ArthurZ
  content: "Following the merge of [a PR](https://github.com/huggingface/transformers/pull/24310)\
    \ in `transformers` it appeared that this model was not properly converted. This\
    \ PR will fix the inference and was tested using the following script:\n```python\n\
    >>> from transformers import AutoTokenizer, MarianMTModel\n>>> tokenizer = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-tc-big-ar-itc')\n\
    >>> inputs = tokenizer(\"\u064A\u0627!\u062F\u0639\u0648\u0646\u0627 \u0646\u062A\
    \u0639\u0644\u0645 \u0645\u0639\u0627\", return_tensors=\"pt\", padding=True)\n\
    >>> model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-tc-big-ar-itc')\n\
    >>> print(tokenizer.batch_decode(model.generate(**inputs)))\n['<pad>,,,, , , \
    \                      !                                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                       </s>']\n```"
  created_at: 2023-10-10 10:00:29+00:00
  edited: false
  hidden: false
  id: 65252ecdb9f25427c93a7279
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-10T11:00:30.000Z'
    data:
      edited: false
      editors:
      - ArthurZ
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.7309709191322327
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
          fullname: Arthur Zucker
          isHf: true
          isPro: false
          name: ArthurZ
          type: user
        html: '<p>Automatically merging the PR.</p>

          '
        raw: Automatically merging the PR.
        updatedAt: '2023-10-10T11:00:30.219Z'
      numEdits: 0
      reactions: []
      relatedEventId: 65252ecee1c63be429ba5bef
    id: 65252ecee1c63be429ba5be5
    type: comment
  author: ArthurZ
  content: Automatically merging the PR.
  created_at: 2023-10-10 10:00:30+00:00
  edited: false
  hidden: false
  id: 65252ecee1c63be429ba5be5
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-10T11:00:30.000Z'
    data:
      status: merged
    id: 65252ecee1c63be429ba5bef
    type: status-change
  author: ArthurZ
  created_at: 2023-10-10 10:00:30+00:00
  id: 65252ecee1c63be429ba5bef
  new_status: merged
  type: status-change
- !!python/object:huggingface_hub.community.DiscussionCommit
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&h=200&f=face
      fullname: Arthur Zucker
      isHf: true
      isOrgMember: true
      isOwner: false
      isPro: false
      name: ArthurZ
      type: user
    createdAt: '2023-10-10T11:00:30.000Z'
    data:
      oid: c23a0f6d0f69065e99a8f208196f5c9318bd689a
      parents:
      - 6e0f31a8282e2c5189537a8a09acc3a14ff194af
      subject: Update checkpoint for transformers>=4.29
    id: 65252ece0000000000000000
    type: commit
  author: ArthurZ
  created_at: 2023-10-10 10:00:30+00:00
  id: 65252ece0000000000000000
  oid: c23a0f6d0f69065e99a8f208196f5c9318bd689a
  summary: Update checkpoint for transformers>=4.29
  type: commit
is_pull_request: true
merge_commit_oid: 014c3e2789b1dec6f528ff87d0db91a72674c5e5
num: 2
repo_id: Helsinki-NLP/opus-mt-tc-big-ar-itc
repo_type: model
status: merged
target_branch: refs/heads/main
title: Update checkpoint for transformers>=4.29
