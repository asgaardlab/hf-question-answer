!!python/object:huggingface_hub.community.DiscussionWithDetails
author: ybsid
conflicting_files: null
created_at: 2024-01-01 19:02:02+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/b62420cb3df3ab9eaebbd1f4b2079cdb.svg
      fullname: Siddharth
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: ybsid
      type: user
    createdAt: '2024-01-01T19:02:02.000Z'
    data:
      edited: false
      editors:
      - ybsid
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.904830276966095
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/b62420cb3df3ab9eaebbd1f4b2079cdb.svg
          fullname: Siddharth
          isHf: false
          isPro: false
          name: ybsid
          type: user
        html: '<p>Hello  , </p>

          <p>I want to use tinyLlama as base model and fine tune it on my custom use
          case dataset. (I need to leverage a small model for my application)<br>The
          dataset is a set of raw text stored in database.</p>

          <p>How can I use the text data to fine tune this model , for answering user
          queries related to my dataset.</p>

          <p>Any steps / code would be appreciated.</p>

          <p>Thanks &amp; Happy new Year.</p>

          '
        raw: "Hello  , \r\n\r\nI want to use tinyLlama as base model and fine tune\
          \ it on my custom use case dataset. (I need to leverage a small model for\
          \ my application)\r\nThe dataset is a set of raw text stored in database.\r\
          \n\r\nHow can I use the text data to fine tune this model , for answering\
          \ user queries related to my dataset.\r\n\r\nAny steps / code would be appreciated.\r\
          \n\r\nThanks & Happy new Year."
        updatedAt: '2024-01-01T19:02:02.156Z'
      numEdits: 0
      reactions:
      - count: 1
        reaction: "\U0001F91D"
        users:
        - ysdede
    id: 65930c2aac02633c0df5affa
    type: comment
  author: ybsid
  content: "Hello  , \r\n\r\nI want to use tinyLlama as base model and fine tune it\
    \ on my custom use case dataset. (I need to leverage a small model for my application)\r\
    \nThe dataset is a set of raw text stored in database.\r\n\r\nHow can I use the\
    \ text data to fine tune this model , for answering user queries related to my\
    \ dataset.\r\n\r\nAny steps / code would be appreciated.\r\n\r\nThanks & Happy\
    \ new Year."
  created_at: 2024-01-01 19:02:02+00:00
  edited: false
  hidden: false
  id: 65930c2aac02633c0df5affa
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: /avatars/c02f9f8d27cb83be65dba0c7b945daa4.svg
      fullname: Jenish-23
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: Jenish-23
      type: user
    createdAt: '2024-01-01T19:19:31.000Z'
    data:
      edited: false
      editors:
      - Jenish-23
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.6591088771820068
      isReport: false
      latest:
        author:
          avatarUrl: /avatars/c02f9f8d27cb83be65dba0c7b945daa4.svg
          fullname: Jenish-23
          isHf: false
          isPro: false
          name: Jenish-23
          type: user
        html: '<p>Unsloth_ai released a Google <a rel="nofollow" href="https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing">colab
          script</a>. Maybe you can use that.</p>

          '
        raw: Unsloth_ai released a Google [colab script](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing).
          Maybe you can use that.
        updatedAt: '2024-01-01T19:19:31.692Z'
      numEdits: 0
      reactions:
      - count: 4
        reaction: "\U0001F44D"
        users:
        - Dallidalli
        - ysdede
        - Guerrados
        - sagard21
    id: 65931043754092f6b1f98d51
    type: comment
  author: Jenish-23
  content: Unsloth_ai released a Google [colab script](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing).
    Maybe you can use that.
  created_at: 2024-01-01 19:19:31+00:00
  edited: false
  hidden: false
  id: 65931043754092f6b1f98d51
  type: comment
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/ccdRI3IPuaTRO4YLUfjo0.png?w=200&h=200&f=face
      fullname: Dimitri
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: demetera
      type: user
    createdAt: '2024-01-04T19:38:30.000Z'
    data:
      edited: false
      editors:
      - demetera
      hidden: false
      identifiedLanguage:
        language: en
        probability: 0.8371350765228271
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/noauth/ccdRI3IPuaTRO4YLUfjo0.png?w=200&h=200&f=face
          fullname: Dimitri
          isHf: false
          isPro: false
          name: demetera
          type: user
        html: '<p>Dataset must be in this format : <a href="https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k">https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k</a><br>I
          was using this easy approach for fine tuning : <a rel="nofollow" href="https://www.kaggle.com/code/tommyadams/fine-tuning-tinyllama">https://www.kaggle.com/code/tommyadams/fine-tuning-tinyllama</a><br>(but
          in this script author feeding chunks of lines without template)</p>

          <p>As an output you will have an adapter - can be loaded separately or merged
          with the main model<br>(but need to have equal precision for the main model
          and adapter).</p>

          '
        raw: "Dataset must be in this format : https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k\n\
          I was using this easy approach for fine tuning : https://www.kaggle.com/code/tommyadams/fine-tuning-tinyllama\n\
          (but in this script author feeding chunks of lines without template)\n\n\
          As an output you will have an adapter - can be loaded separately or merged\
          \ with the main model \n(but need to have equal precision for the main model\
          \ and adapter).\n\n"
        updatedAt: '2024-01-04T19:38:30.236Z'
      numEdits: 0
      reactions:
      - count: 2
        reaction: "\U0001F44D"
        users:
        - Guerrados
        - sagard21
    id: 6597093667b8fc627910c21e
    type: comment
  author: demetera
  content: "Dataset must be in this format : https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k\n\
    I was using this easy approach for fine tuning : https://www.kaggle.com/code/tommyadams/fine-tuning-tinyllama\n\
    (but in this script author feeding chunks of lines without template)\n\nAs an\
    \ output you will have an adapter - can be loaded separately or merged with the\
    \ main model \n(but need to have equal precision for the main model and adapter).\n\
    \n"
  created_at: 2024-01-04 19:38:30+00:00
  edited: false
  hidden: false
  id: 6597093667b8fc627910c21e
  type: comment
is_pull_request: false
merge_commit_oid: null
num: 5
repo_id: TinyLlama/TinyLlama-1.1B-Chat-v1.0
repo_type: model
status: open
target_branch: null
title: Fine Tuning
