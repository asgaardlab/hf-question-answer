!!python/object:huggingface_hub.community.DiscussionWithDetails
author: darraghd
conflicting_files: null
created_at: 2023-02-01 17:23:06+00:00
diff: null
endpoint: https://huggingface.co
events:
- !!python/object:huggingface_hub.community.DiscussionComment
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672916347066-636112a46483eb3832c443f7.jpeg?w=200&h=200&f=face
      fullname: Darragh Hanley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: darraghd
      type: user
    createdAt: '2023-02-01T17:23:06.000Z'
    data:
      edited: false
      editors:
      - darraghd
      hidden: false
      isReport: false
      latest:
        author:
          avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672916347066-636112a46483eb3832c443f7.jpeg?w=200&h=200&f=face
          fullname: Darragh Hanley
          isHf: false
          isPro: false
          name: darraghd
          type: user
        html: '<p>Very nice work, after some initial teething problems, like <a rel="nofollow"
          href="https://github.com/huggingface/transformers/issues/21391">here</a>,
          I have this running on A100. The results on my prompts are showing to be
          slightly better than the <code>google/tf-flan-xxl</code> with full precision.
          Maybe this is be down to chance but there was an improvement on a number
          of prompts.<br>In any case, the memory usage is way down, 40GB for full
          precision and a short prompt, down to around 18GB for your 8-bit version.
          This is great, it allows me to experiment with much larger prompts...<br>Thanks
          a lot for releasing this !!</p>

          '
        raw: "Very nice work, after some initial teething problems, like [here](https://github.com/huggingface/transformers/issues/21391),\
          \ I have this running on A100. The results on my prompts are showing to\
          \ be slightly better than the `google/tf-flan-xxl` with full precision.\
          \ Maybe this is be down to chance but there was an improvement on a number\
          \ of prompts. \r\nIn any case, the memory usage is way down, 40GB for full\
          \ precision and a short prompt, down to around 18GB for your 8-bit version.\
          \ This is great, it allows me to experiment with much larger prompts...\r\
          \nThanks a lot for releasing this !!\r\n"
        updatedAt: '2023-02-01T17:23:06.025Z'
      numEdits: 0
      reactions: []
    id: 63da9ffa0cc3bc12bc057d46
    type: comment
  author: darraghd
  content: "Very nice work, after some initial teething problems, like [here](https://github.com/huggingface/transformers/issues/21391),\
    \ I have this running on A100. The results on my prompts are showing to be slightly\
    \ better than the `google/tf-flan-xxl` with full precision. Maybe this is be down\
    \ to chance but there was an improvement on a number of prompts. \r\nIn any case,\
    \ the memory usage is way down, 40GB for full precision and a short prompt, down\
    \ to around 18GB for your 8-bit version. This is great, it allows me to experiment\
    \ with much larger prompts...\r\nThanks a lot for releasing this !!\r\n"
  created_at: 2023-02-01 17:23:06+00:00
  edited: false
  hidden: false
  id: 63da9ffa0cc3bc12bc057d46
  type: comment
- !!python/object:huggingface_hub.community.DiscussionStatusChange
  _event:
    author:
      avatarUrl: https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1672916347066-636112a46483eb3832c443f7.jpeg?w=200&h=200&f=face
      fullname: Darragh Hanley
      isHf: false
      isOrgMember: false
      isOwner: false
      isPro: false
      name: darraghd
      type: user
    createdAt: '2023-02-07T09:51:40.000Z'
    data:
      status: closed
    id: 63e21f2c1c0d033a0f9a6632
    type: status-change
  author: darraghd
  created_at: 2023-02-07 09:51:40+00:00
  id: 63e21f2c1c0d033a0f9a6632
  new_status: closed
  type: status-change
is_pull_request: false
merge_commit_oid: null
num: 1
repo_id: philschmid/flan-t5-xxl-sharded-fp16
repo_type: model
status: closed
target_branch: null
title: Nice results
